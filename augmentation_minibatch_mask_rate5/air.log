2024-05-25 00:42:03 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-25 00:42:03 [INFO]: Using the given device: cuda:0
2024-05-25 00:42:03 [INFO]: Model files will be saved to augmentation_saved_results/round_0/SAITS_air_quality/20240525_T004203
2024-05-25 00:42:03 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/SAITS_air_quality/20240525_T004203/tensorboard
2024-05-25 00:42:03 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 00:42:09 [INFO]: Epoch 001 - training loss: 1.0553, validation loss: 0.5434
2024-05-25 00:42:09 [INFO]: Epoch 002 - training loss: 0.7635, validation loss: 0.4264
2024-05-25 00:42:10 [INFO]: Epoch 003 - training loss: 0.6584, validation loss: 0.3522
2024-05-25 00:42:10 [INFO]: Epoch 004 - training loss: 0.5806, validation loss: 0.3136
2024-05-25 00:42:11 [INFO]: Epoch 005 - training loss: 0.5245, validation loss: 0.2940
2024-05-25 00:42:12 [INFO]: Epoch 006 - training loss: 0.4864, validation loss: 0.2851
2024-05-25 00:42:12 [INFO]: Epoch 007 - training loss: 0.4623, validation loss: 0.2719
2024-05-25 00:42:13 [INFO]: Epoch 008 - training loss: 0.4413, validation loss: 0.2663
2024-05-25 00:42:14 [INFO]: Epoch 009 - training loss: 0.4270, validation loss: 0.2618
2024-05-25 00:42:14 [INFO]: Epoch 010 - training loss: 0.4174, validation loss: 0.2578
2024-05-25 00:42:15 [INFO]: Epoch 011 - training loss: 0.4061, validation loss: 0.2512
2024-05-25 00:42:16 [INFO]: Epoch 012 - training loss: 0.3985, validation loss: 0.2492
2024-05-25 00:42:16 [INFO]: Epoch 013 - training loss: 0.3904, validation loss: 0.2448
2024-05-25 00:42:17 [INFO]: Epoch 014 - training loss: 0.3820, validation loss: 0.2427
2024-05-25 00:42:18 [INFO]: Epoch 015 - training loss: 0.3771, validation loss: 0.2395
2024-05-25 00:42:18 [INFO]: Epoch 016 - training loss: 0.3711, validation loss: 0.2374
2024-05-25 00:42:19 [INFO]: Epoch 017 - training loss: 0.3668, validation loss: 0.2352
2024-05-25 00:42:20 [INFO]: Epoch 018 - training loss: 0.3616, validation loss: 0.2346
2024-05-25 00:42:20 [INFO]: Epoch 019 - training loss: 0.3577, validation loss: 0.2304
2024-05-25 00:42:21 [INFO]: Epoch 020 - training loss: 0.3528, validation loss: 0.2289
2024-05-25 00:42:22 [INFO]: Epoch 021 - training loss: 0.3494, validation loss: 0.2278
2024-05-25 00:42:22 [INFO]: Epoch 022 - training loss: 0.3467, validation loss: 0.2256
2024-05-25 00:42:23 [INFO]: Epoch 023 - training loss: 0.3431, validation loss: 0.2255
2024-05-25 00:42:24 [INFO]: Epoch 024 - training loss: 0.3402, validation loss: 0.2227
2024-05-25 00:42:24 [INFO]: Epoch 025 - training loss: 0.3383, validation loss: 0.2212
2024-05-25 00:42:25 [INFO]: Epoch 026 - training loss: 0.3358, validation loss: 0.2209
2024-05-25 00:42:26 [INFO]: Epoch 027 - training loss: 0.3330, validation loss: 0.2184
2024-05-25 00:42:26 [INFO]: Epoch 028 - training loss: 0.3305, validation loss: 0.2177
2024-05-25 00:42:27 [INFO]: Epoch 029 - training loss: 0.3271, validation loss: 0.2160
2024-05-25 00:42:28 [INFO]: Epoch 030 - training loss: 0.3263, validation loss: 0.2144
2024-05-25 00:42:28 [INFO]: Epoch 031 - training loss: 0.3231, validation loss: 0.2146
2024-05-25 00:42:29 [INFO]: Epoch 032 - training loss: 0.3209, validation loss: 0.2126
2024-05-25 00:42:30 [INFO]: Epoch 033 - training loss: 0.3195, validation loss: 0.2105
2024-05-25 00:42:30 [INFO]: Epoch 034 - training loss: 0.3168, validation loss: 0.2108
2024-05-25 00:42:31 [INFO]: Epoch 035 - training loss: 0.3184, validation loss: 0.2102
2024-05-25 00:42:32 [INFO]: Epoch 036 - training loss: 0.3155, validation loss: 0.2097
2024-05-25 00:42:32 [INFO]: Epoch 037 - training loss: 0.3136, validation loss: 0.2070
2024-05-25 00:42:33 [INFO]: Epoch 038 - training loss: 0.3093, validation loss: 0.2068
2024-05-25 00:42:34 [INFO]: Epoch 039 - training loss: 0.3089, validation loss: 0.2053
2024-05-25 00:42:34 [INFO]: Epoch 040 - training loss: 0.3064, validation loss: 0.2040
2024-05-25 00:42:35 [INFO]: Epoch 041 - training loss: 0.3044, validation loss: 0.2031
2024-05-25 00:42:36 [INFO]: Epoch 042 - training loss: 0.3020, validation loss: 0.2029
2024-05-25 00:42:36 [INFO]: Epoch 043 - training loss: 0.3017, validation loss: 0.2015
2024-05-25 00:42:37 [INFO]: Epoch 044 - training loss: 0.3007, validation loss: 0.2011
2024-05-25 00:42:38 [INFO]: Epoch 045 - training loss: 0.2979, validation loss: 0.2011
2024-05-25 00:42:38 [INFO]: Epoch 046 - training loss: 0.2987, validation loss: 0.1998
2024-05-25 00:42:39 [INFO]: Epoch 047 - training loss: 0.2973, validation loss: 0.1984
2024-05-25 00:42:40 [INFO]: Epoch 048 - training loss: 0.2932, validation loss: 0.1984
2024-05-25 00:42:40 [INFO]: Epoch 049 - training loss: 0.2940, validation loss: 0.1972
2024-05-25 00:42:41 [INFO]: Epoch 050 - training loss: 0.2912, validation loss: 0.1966
2024-05-25 00:42:41 [INFO]: Epoch 051 - training loss: 0.2916, validation loss: 0.1971
2024-05-25 00:42:42 [INFO]: Epoch 052 - training loss: 0.2898, validation loss: 0.1951
2024-05-25 00:42:43 [INFO]: Epoch 053 - training loss: 0.2886, validation loss: 0.1948
2024-05-25 00:42:43 [INFO]: Epoch 054 - training loss: 0.2864, validation loss: 0.1940
2024-05-25 00:42:44 [INFO]: Epoch 055 - training loss: 0.2848, validation loss: 0.1931
2024-05-25 00:42:45 [INFO]: Epoch 056 - training loss: 0.2838, validation loss: 0.1922
2024-05-25 00:42:45 [INFO]: Epoch 057 - training loss: 0.2823, validation loss: 0.1909
2024-05-25 00:42:46 [INFO]: Epoch 058 - training loss: 0.2823, validation loss: 0.1905
2024-05-25 00:42:47 [INFO]: Epoch 059 - training loss: 0.2805, validation loss: 0.1900
2024-05-25 00:42:47 [INFO]: Epoch 060 - training loss: 0.2808, validation loss: 0.1902
2024-05-25 00:42:48 [INFO]: Epoch 061 - training loss: 0.2776, validation loss: 0.1901
2024-05-25 00:42:49 [INFO]: Epoch 062 - training loss: 0.2763, validation loss: 0.1887
2024-05-25 00:42:49 [INFO]: Epoch 063 - training loss: 0.2755, validation loss: 0.1885
2024-05-25 00:42:50 [INFO]: Epoch 064 - training loss: 0.2749, validation loss: 0.1876
2024-05-25 00:42:51 [INFO]: Epoch 065 - training loss: 0.2727, validation loss: 0.1876
2024-05-25 00:42:51 [INFO]: Epoch 066 - training loss: 0.2715, validation loss: 0.1870
2024-05-25 00:42:52 [INFO]: Epoch 067 - training loss: 0.2702, validation loss: 0.1860
2024-05-25 00:42:53 [INFO]: Epoch 068 - training loss: 0.2703, validation loss: 0.1855
2024-05-25 00:42:53 [INFO]: Epoch 069 - training loss: 0.2677, validation loss: 0.1854
2024-05-25 00:42:54 [INFO]: Epoch 070 - training loss: 0.2671, validation loss: 0.1856
2024-05-25 00:42:55 [INFO]: Epoch 071 - training loss: 0.2658, validation loss: 0.1845
2024-05-25 00:42:55 [INFO]: Epoch 072 - training loss: 0.2657, validation loss: 0.1830
2024-05-25 00:42:56 [INFO]: Epoch 073 - training loss: 0.2662, validation loss: 0.1833
2024-05-25 00:42:57 [INFO]: Epoch 074 - training loss: 0.2638, validation loss: 0.1827
2024-05-25 00:42:57 [INFO]: Epoch 075 - training loss: 0.2623, validation loss: 0.1822
2024-05-25 00:42:58 [INFO]: Epoch 076 - training loss: 0.2615, validation loss: 0.1820
2024-05-25 00:42:59 [INFO]: Epoch 077 - training loss: 0.2610, validation loss: 0.1818
2024-05-25 00:42:59 [INFO]: Epoch 078 - training loss: 0.2611, validation loss: 0.1823
2024-05-25 00:43:00 [INFO]: Epoch 079 - training loss: 0.2603, validation loss: 0.1808
2024-05-25 00:43:01 [INFO]: Epoch 080 - training loss: 0.2574, validation loss: 0.1807
2024-05-25 00:43:01 [INFO]: Epoch 081 - training loss: 0.2578, validation loss: 0.1809
2024-05-25 00:43:02 [INFO]: Epoch 082 - training loss: 0.2576, validation loss: 0.1801
2024-05-25 00:43:03 [INFO]: Epoch 083 - training loss: 0.2562, validation loss: 0.1795
2024-05-25 00:43:03 [INFO]: Epoch 084 - training loss: 0.2546, validation loss: 0.1789
2024-05-25 00:43:04 [INFO]: Epoch 085 - training loss: 0.2534, validation loss: 0.1789
2024-05-25 00:43:05 [INFO]: Epoch 086 - training loss: 0.2533, validation loss: 0.1780
2024-05-25 00:43:05 [INFO]: Epoch 087 - training loss: 0.2540, validation loss: 0.1783
2024-05-25 00:43:06 [INFO]: Epoch 088 - training loss: 0.2536, validation loss: 0.1779
2024-05-25 00:43:07 [INFO]: Epoch 089 - training loss: 0.2516, validation loss: 0.1775
2024-05-25 00:43:07 [INFO]: Epoch 090 - training loss: 0.2504, validation loss: 0.1767
2024-05-25 00:43:08 [INFO]: Epoch 091 - training loss: 0.2500, validation loss: 0.1769
2024-05-25 00:43:09 [INFO]: Epoch 092 - training loss: 0.2496, validation loss: 0.1762
2024-05-25 00:43:09 [INFO]: Epoch 093 - training loss: 0.2492, validation loss: 0.1761
2024-05-25 00:43:10 [INFO]: Epoch 094 - training loss: 0.2472, validation loss: 0.1757
2024-05-25 00:43:10 [INFO]: Epoch 095 - training loss: 0.2475, validation loss: 0.1759
2024-05-25 00:43:11 [INFO]: Epoch 096 - training loss: 0.2469, validation loss: 0.1757
2024-05-25 00:43:12 [INFO]: Epoch 097 - training loss: 0.2482, validation loss: 0.1756
2024-05-25 00:43:12 [INFO]: Epoch 098 - training loss: 0.2459, validation loss: 0.1749
2024-05-25 00:43:13 [INFO]: Epoch 099 - training loss: 0.2448, validation loss: 0.1757
2024-05-25 00:43:14 [INFO]: Epoch 100 - training loss: 0.2465, validation loss: 0.1747
2024-05-25 00:43:14 [INFO]: Epoch 101 - training loss: 0.2451, validation loss: 0.1742
2024-05-25 00:43:15 [INFO]: Epoch 102 - training loss: 0.2440, validation loss: 0.1740
2024-05-25 00:43:16 [INFO]: Epoch 103 - training loss: 0.2429, validation loss: 0.1743
2024-05-25 00:43:16 [INFO]: Epoch 104 - training loss: 0.2426, validation loss: 0.1739
2024-05-25 00:43:17 [INFO]: Epoch 105 - training loss: 0.2430, validation loss: 0.1737
2024-05-25 00:43:18 [INFO]: Epoch 106 - training loss: 0.2420, validation loss: 0.1731
2024-05-25 00:43:18 [INFO]: Epoch 107 - training loss: 0.2417, validation loss: 0.1733
2024-05-25 00:43:19 [INFO]: Epoch 108 - training loss: 0.2405, validation loss: 0.1727
2024-05-25 00:43:20 [INFO]: Epoch 109 - training loss: 0.2401, validation loss: 0.1731
2024-05-25 00:43:20 [INFO]: Epoch 110 - training loss: 0.2409, validation loss: 0.1727
2024-05-25 00:43:21 [INFO]: Epoch 111 - training loss: 0.2396, validation loss: 0.1732
2024-05-25 00:43:22 [INFO]: Epoch 112 - training loss: 0.2383, validation loss: 0.1716
2024-05-25 00:43:22 [INFO]: Epoch 113 - training loss: 0.2368, validation loss: 0.1715
2024-05-25 00:43:23 [INFO]: Epoch 114 - training loss: 0.2371, validation loss: 0.1715
2024-05-25 00:43:24 [INFO]: Epoch 115 - training loss: 0.2379, validation loss: 0.1704
2024-05-25 00:43:24 [INFO]: Epoch 116 - training loss: 0.2376, validation loss: 0.1705
2024-05-25 00:43:25 [INFO]: Epoch 117 - training loss: 0.2352, validation loss: 0.1708
2024-05-25 00:43:26 [INFO]: Epoch 118 - training loss: 0.2349, validation loss: 0.1710
2024-05-25 00:43:26 [INFO]: Epoch 119 - training loss: 0.2340, validation loss: 0.1699
2024-05-25 00:43:27 [INFO]: Epoch 120 - training loss: 0.2331, validation loss: 0.1704
2024-05-25 00:43:28 [INFO]: Epoch 121 - training loss: 0.2324, validation loss: 0.1691
2024-05-25 00:43:28 [INFO]: Epoch 122 - training loss: 0.2342, validation loss: 0.1697
2024-05-25 00:43:29 [INFO]: Epoch 123 - training loss: 0.2347, validation loss: 0.1693
2024-05-25 00:43:30 [INFO]: Epoch 124 - training loss: 0.2320, validation loss: 0.1691
2024-05-25 00:43:30 [INFO]: Epoch 125 - training loss: 0.2323, validation loss: 0.1692
2024-05-25 00:43:31 [INFO]: Epoch 126 - training loss: 0.2313, validation loss: 0.1685
2024-05-25 00:43:32 [INFO]: Epoch 127 - training loss: 0.2326, validation loss: 0.1691
2024-05-25 00:43:32 [INFO]: Epoch 128 - training loss: 0.2309, validation loss: 0.1696
2024-05-25 00:43:33 [INFO]: Epoch 129 - training loss: 0.2301, validation loss: 0.1688
2024-05-25 00:43:34 [INFO]: Epoch 130 - training loss: 0.2300, validation loss: 0.1683
2024-05-25 00:43:34 [INFO]: Epoch 131 - training loss: 0.2298, validation loss: 0.1683
2024-05-25 00:43:35 [INFO]: Epoch 132 - training loss: 0.2300, validation loss: 0.1681
2024-05-25 00:43:36 [INFO]: Epoch 133 - training loss: 0.2289, validation loss: 0.1686
2024-05-25 00:43:36 [INFO]: Epoch 134 - training loss: 0.2279, validation loss: 0.1678
2024-05-25 00:43:37 [INFO]: Epoch 135 - training loss: 0.2270, validation loss: 0.1676
2024-05-25 00:43:38 [INFO]: Epoch 136 - training loss: 0.2283, validation loss: 0.1684
2024-05-25 00:43:38 [INFO]: Epoch 137 - training loss: 0.2279, validation loss: 0.1673
2024-05-25 00:43:39 [INFO]: Epoch 138 - training loss: 0.2264, validation loss: 0.1673
2024-05-25 00:43:39 [INFO]: Epoch 139 - training loss: 0.2248, validation loss: 0.1666
2024-05-25 00:43:40 [INFO]: Epoch 140 - training loss: 0.2258, validation loss: 0.1656
2024-05-25 00:43:41 [INFO]: Epoch 141 - training loss: 0.2263, validation loss: 0.1664
2024-05-25 00:43:41 [INFO]: Epoch 142 - training loss: 0.2249, validation loss: 0.1659
2024-05-25 00:43:42 [INFO]: Epoch 143 - training loss: 0.2246, validation loss: 0.1653
2024-05-25 00:43:43 [INFO]: Epoch 144 - training loss: 0.2235, validation loss: 0.1647
2024-05-25 00:43:43 [INFO]: Epoch 145 - training loss: 0.2238, validation loss: 0.1659
2024-05-25 00:43:44 [INFO]: Epoch 146 - training loss: 0.2232, validation loss: 0.1654
2024-05-25 00:43:45 [INFO]: Epoch 147 - training loss: 0.2249, validation loss: 0.1653
2024-05-25 00:43:45 [INFO]: Epoch 148 - training loss: 0.2224, validation loss: 0.1661
2024-05-25 00:43:46 [INFO]: Epoch 149 - training loss: 0.2231, validation loss: 0.1646
2024-05-25 00:43:47 [INFO]: Epoch 150 - training loss: 0.2233, validation loss: 0.1649
2024-05-25 00:43:47 [INFO]: Epoch 151 - training loss: 0.2229, validation loss: 0.1645
2024-05-25 00:43:48 [INFO]: Epoch 152 - training loss: 0.2216, validation loss: 0.1639
2024-05-25 00:43:49 [INFO]: Epoch 153 - training loss: 0.2202, validation loss: 0.1638
2024-05-25 00:43:49 [INFO]: Epoch 154 - training loss: 0.2205, validation loss: 0.1644
2024-05-25 00:43:50 [INFO]: Epoch 155 - training loss: 0.2218, validation loss: 0.1631
2024-05-25 00:43:51 [INFO]: Epoch 156 - training loss: 0.2193, validation loss: 0.1638
2024-05-25 00:43:51 [INFO]: Epoch 157 - training loss: 0.2194, validation loss: 0.1636
2024-05-25 00:43:52 [INFO]: Epoch 158 - training loss: 0.2200, validation loss: 0.1635
2024-05-25 00:43:53 [INFO]: Epoch 159 - training loss: 0.2189, validation loss: 0.1632
2024-05-25 00:43:53 [INFO]: Epoch 160 - training loss: 0.2198, validation loss: 0.1637
2024-05-25 00:43:54 [INFO]: Epoch 161 - training loss: 0.2194, validation loss: 0.1626
2024-05-25 00:43:55 [INFO]: Epoch 162 - training loss: 0.2226, validation loss: 0.1627
2024-05-25 00:43:55 [INFO]: Epoch 163 - training loss: 0.2193, validation loss: 0.1623
2024-05-25 00:43:56 [INFO]: Epoch 164 - training loss: 0.2169, validation loss: 0.1629
2024-05-25 00:43:57 [INFO]: Epoch 165 - training loss: 0.2175, validation loss: 0.1627
2024-05-25 00:43:57 [INFO]: Epoch 166 - training loss: 0.2180, validation loss: 0.1628
2024-05-25 00:43:58 [INFO]: Epoch 167 - training loss: 0.2169, validation loss: 0.1628
2024-05-25 00:43:59 [INFO]: Epoch 168 - training loss: 0.2165, validation loss: 0.1624
2024-05-25 00:43:59 [INFO]: Epoch 169 - training loss: 0.2167, validation loss: 0.1623
2024-05-25 00:44:00 [INFO]: Epoch 170 - training loss: 0.2166, validation loss: 0.1616
2024-05-25 00:44:01 [INFO]: Epoch 171 - training loss: 0.2167, validation loss: 0.1620
2024-05-25 00:44:01 [INFO]: Epoch 172 - training loss: 0.2182, validation loss: 0.1628
2024-05-25 00:44:02 [INFO]: Epoch 173 - training loss: 0.2148, validation loss: 0.1616
2024-05-25 00:44:03 [INFO]: Epoch 174 - training loss: 0.2140, validation loss: 0.1612
2024-05-25 00:44:03 [INFO]: Epoch 175 - training loss: 0.2138, validation loss: 0.1627
2024-05-25 00:44:04 [INFO]: Epoch 176 - training loss: 0.2145, validation loss: 0.1619
2024-05-25 00:44:05 [INFO]: Epoch 177 - training loss: 0.2137, validation loss: 0.1617
2024-05-25 00:44:05 [INFO]: Epoch 178 - training loss: 0.2150, validation loss: 0.1623
2024-05-25 00:44:06 [INFO]: Epoch 179 - training loss: 0.2127, validation loss: 0.1619
2024-05-25 00:44:06 [INFO]: Epoch 180 - training loss: 0.2136, validation loss: 0.1617
2024-05-25 00:44:07 [INFO]: Epoch 181 - training loss: 0.2144, validation loss: 0.1624
2024-05-25 00:44:08 [INFO]: Epoch 182 - training loss: 0.2185, validation loss: 0.1614
2024-05-25 00:44:08 [INFO]: Epoch 183 - training loss: 0.2131, validation loss: 0.1610
2024-05-25 00:44:09 [INFO]: Epoch 184 - training loss: 0.2124, validation loss: 0.1613
2024-05-25 00:44:10 [INFO]: Epoch 185 - training loss: 0.2115, validation loss: 0.1612
2024-05-25 00:44:10 [INFO]: Epoch 186 - training loss: 0.2123, validation loss: 0.1606
2024-05-25 00:44:11 [INFO]: Epoch 187 - training loss: 0.2111, validation loss: 0.1605
2024-05-25 00:44:12 [INFO]: Epoch 188 - training loss: 0.2108, validation loss: 0.1606
2024-05-25 00:44:12 [INFO]: Epoch 189 - training loss: 0.2110, validation loss: 0.1599
2024-05-25 00:44:13 [INFO]: Epoch 190 - training loss: 0.2115, validation loss: 0.1613
2024-05-25 00:44:14 [INFO]: Epoch 191 - training loss: 0.2106, validation loss: 0.1598
2024-05-25 00:44:14 [INFO]: Epoch 192 - training loss: 0.2101, validation loss: 0.1601
2024-05-25 00:44:15 [INFO]: Epoch 193 - training loss: 0.2090, validation loss: 0.1602
2024-05-25 00:44:16 [INFO]: Epoch 194 - training loss: 0.2087, validation loss: 0.1604
2024-05-25 00:44:16 [INFO]: Epoch 195 - training loss: 0.2099, validation loss: 0.1602
2024-05-25 00:44:17 [INFO]: Epoch 196 - training loss: 0.2092, validation loss: 0.1604
2024-05-25 00:44:18 [INFO]: Epoch 197 - training loss: 0.2090, validation loss: 0.1597
2024-05-25 00:44:18 [INFO]: Epoch 198 - training loss: 0.2077, validation loss: 0.1599
2024-05-25 00:44:19 [INFO]: Epoch 199 - training loss: 0.2083, validation loss: 0.1594
2024-05-25 00:44:20 [INFO]: Epoch 200 - training loss: 0.2076, validation loss: 0.1594
2024-05-25 00:44:20 [INFO]: Epoch 201 - training loss: 0.2080, validation loss: 0.1590
2024-05-25 00:44:21 [INFO]: Epoch 202 - training loss: 0.2088, validation loss: 0.1583
2024-05-25 00:44:22 [INFO]: Epoch 203 - training loss: 0.2083, validation loss: 0.1582
2024-05-25 00:44:22 [INFO]: Epoch 204 - training loss: 0.2079, validation loss: 0.1589
2024-05-25 00:44:23 [INFO]: Epoch 205 - training loss: 0.2064, validation loss: 0.1588
2024-05-25 00:44:24 [INFO]: Epoch 206 - training loss: 0.2066, validation loss: 0.1587
2024-05-25 00:44:24 [INFO]: Epoch 207 - training loss: 0.2053, validation loss: 0.1579
2024-05-25 00:44:25 [INFO]: Epoch 208 - training loss: 0.2058, validation loss: 0.1586
2024-05-25 00:44:26 [INFO]: Epoch 209 - training loss: 0.2084, validation loss: 0.1582
2024-05-25 00:44:26 [INFO]: Epoch 210 - training loss: 0.2058, validation loss: 0.1582
2024-05-25 00:44:27 [INFO]: Epoch 211 - training loss: 0.2053, validation loss: 0.1588
2024-05-25 00:44:28 [INFO]: Epoch 212 - training loss: 0.2033, validation loss: 0.1584
2024-05-25 00:44:28 [INFO]: Epoch 213 - training loss: 0.2050, validation loss: 0.1578
2024-05-25 00:44:29 [INFO]: Epoch 214 - training loss: 0.2050, validation loss: 0.1594
2024-05-25 00:44:30 [INFO]: Epoch 215 - training loss: 0.2042, validation loss: 0.1582
2024-05-25 00:44:30 [INFO]: Epoch 216 - training loss: 0.2038, validation loss: 0.1580
2024-05-25 00:44:31 [INFO]: Epoch 217 - training loss: 0.2034, validation loss: 0.1583
2024-05-25 00:44:32 [INFO]: Epoch 218 - training loss: 0.2027, validation loss: 0.1580
2024-05-25 00:44:32 [INFO]: Epoch 219 - training loss: 0.2034, validation loss: 0.1576
2024-05-25 00:44:33 [INFO]: Epoch 220 - training loss: 0.2034, validation loss: 0.1580
2024-05-25 00:44:33 [INFO]: Epoch 221 - training loss: 0.2034, validation loss: 0.1578
2024-05-25 00:44:34 [INFO]: Epoch 222 - training loss: 0.2047, validation loss: 0.1577
2024-05-25 00:44:35 [INFO]: Epoch 223 - training loss: 0.2039, validation loss: 0.1575
2024-05-25 00:44:35 [INFO]: Epoch 224 - training loss: 0.2018, validation loss: 0.1571
2024-05-25 00:44:36 [INFO]: Epoch 225 - training loss: 0.2019, validation loss: 0.1577
2024-05-25 00:44:37 [INFO]: Epoch 226 - training loss: 0.2013, validation loss: 0.1576
2024-05-25 00:44:37 [INFO]: Epoch 227 - training loss: 0.2019, validation loss: 0.1570
2024-05-25 00:44:38 [INFO]: Epoch 228 - training loss: 0.2018, validation loss: 0.1575
2024-05-25 00:44:39 [INFO]: Epoch 229 - training loss: 0.2019, validation loss: 0.1573
2024-05-25 00:44:39 [INFO]: Epoch 230 - training loss: 0.2013, validation loss: 0.1568
2024-05-25 00:44:40 [INFO]: Epoch 231 - training loss: 0.2008, validation loss: 0.1564
2024-05-25 00:44:41 [INFO]: Epoch 232 - training loss: 0.2002, validation loss: 0.1573
2024-05-25 00:44:41 [INFO]: Epoch 233 - training loss: 0.2013, validation loss: 0.1578
2024-05-25 00:44:42 [INFO]: Epoch 234 - training loss: 0.2005, validation loss: 0.1571
2024-05-25 00:44:43 [INFO]: Epoch 235 - training loss: 0.2015, validation loss: 0.1565
2024-05-25 00:44:43 [INFO]: Epoch 236 - training loss: 0.2027, validation loss: 0.1572
2024-05-25 00:44:44 [INFO]: Epoch 237 - training loss: 0.2019, validation loss: 0.1576
2024-05-25 00:44:45 [INFO]: Epoch 238 - training loss: 0.1998, validation loss: 0.1561
2024-05-25 00:44:45 [INFO]: Epoch 239 - training loss: 0.2016, validation loss: 0.1568
2024-05-25 00:44:46 [INFO]: Epoch 240 - training loss: 0.1984, validation loss: 0.1569
2024-05-25 00:44:47 [INFO]: Epoch 241 - training loss: 0.1985, validation loss: 0.1562
2024-05-25 00:44:47 [INFO]: Epoch 242 - training loss: 0.1982, validation loss: 0.1564
2024-05-25 00:44:48 [INFO]: Epoch 243 - training loss: 0.1999, validation loss: 0.1565
2024-05-25 00:44:49 [INFO]: Epoch 244 - training loss: 0.1989, validation loss: 0.1565
2024-05-25 00:44:49 [INFO]: Epoch 245 - training loss: 0.1994, validation loss: 0.1556
2024-05-25 00:44:50 [INFO]: Epoch 246 - training loss: 0.1976, validation loss: 0.1564
2024-05-25 00:44:51 [INFO]: Epoch 247 - training loss: 0.1987, validation loss: 0.1557
2024-05-25 00:44:51 [INFO]: Epoch 248 - training loss: 0.1976, validation loss: 0.1554
2024-05-25 00:44:52 [INFO]: Epoch 249 - training loss: 0.1952, validation loss: 0.1552
2024-05-25 00:44:53 [INFO]: Epoch 250 - training loss: 0.1973, validation loss: 0.1546
2024-05-25 00:44:53 [INFO]: Epoch 251 - training loss: 0.1960, validation loss: 0.1553
2024-05-25 00:44:54 [INFO]: Epoch 252 - training loss: 0.1973, validation loss: 0.1552
2024-05-25 00:44:55 [INFO]: Epoch 253 - training loss: 0.1969, validation loss: 0.1545
2024-05-25 00:44:55 [INFO]: Epoch 254 - training loss: 0.1960, validation loss: 0.1548
2024-05-25 00:44:56 [INFO]: Epoch 255 - training loss: 0.1963, validation loss: 0.1556
2024-05-25 00:44:57 [INFO]: Epoch 256 - training loss: 0.1968, validation loss: 0.1557
2024-05-25 00:44:57 [INFO]: Epoch 257 - training loss: 0.1951, validation loss: 0.1557
2024-05-25 00:44:58 [INFO]: Epoch 258 - training loss: 0.1943, validation loss: 0.1567
2024-05-25 00:44:59 [INFO]: Epoch 259 - training loss: 0.1948, validation loss: 0.1561
2024-05-25 00:44:59 [INFO]: Epoch 260 - training loss: 0.1957, validation loss: 0.1565
2024-05-25 00:45:00 [INFO]: Epoch 261 - training loss: 0.1958, validation loss: 0.1571
2024-05-25 00:45:00 [INFO]: Epoch 262 - training loss: 0.1982, validation loss: 0.1552
2024-05-25 00:45:01 [INFO]: Epoch 263 - training loss: 0.1959, validation loss: 0.1561
2024-05-25 00:45:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:45:01 [INFO]: Finished training. The best model is from epoch#253.
2024-05-25 00:45:01 [INFO]: Saved the model to augmentation_saved_results/round_0/SAITS_air_quality/20240525_T004203/SAITS.pypots
2024-05-25 00:45:01 [INFO]: SAITS on Air-Quality: MAE=0.1424, MSE=0.0910
2024-05-25 00:45:01 [INFO]: Successfully saved to augmentation_saved_results/round_0/SAITS_air_quality/imputation.pkl
2024-05-25 00:45:01 [INFO]: Using the given device: cuda:0
2024-05-25 00:45:01 [INFO]: Model files will be saved to augmentation_saved_results/round_0/Transformer_air_quality/20240525_T004501
2024-05-25 00:45:01 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/Transformer_air_quality/20240525_T004501/tensorboard
2024-05-25 00:45:01 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 00:45:02 [INFO]: Epoch 001 - training loss: 0.9379, validation loss: 0.4958
2024-05-25 00:45:02 [INFO]: Epoch 002 - training loss: 0.5871, validation loss: 0.3932
2024-05-25 00:45:03 [INFO]: Epoch 003 - training loss: 0.4902, validation loss: 0.3267
2024-05-25 00:45:03 [INFO]: Epoch 004 - training loss: 0.4397, validation loss: 0.3025
2024-05-25 00:45:03 [INFO]: Epoch 005 - training loss: 0.4116, validation loss: 0.2914
2024-05-25 00:45:03 [INFO]: Epoch 006 - training loss: 0.3926, validation loss: 0.2787
2024-05-25 00:45:04 [INFO]: Epoch 007 - training loss: 0.3792, validation loss: 0.2716
2024-05-25 00:45:04 [INFO]: Epoch 008 - training loss: 0.3646, validation loss: 0.2655
2024-05-25 00:45:04 [INFO]: Epoch 009 - training loss: 0.3567, validation loss: 0.2596
2024-05-25 00:45:05 [INFO]: Epoch 010 - training loss: 0.3492, validation loss: 0.2548
2024-05-25 00:45:05 [INFO]: Epoch 011 - training loss: 0.3436, validation loss: 0.2510
2024-05-25 00:45:05 [INFO]: Epoch 012 - training loss: 0.3349, validation loss: 0.2474
2024-05-25 00:45:06 [INFO]: Epoch 013 - training loss: 0.3301, validation loss: 0.2432
2024-05-25 00:45:06 [INFO]: Epoch 014 - training loss: 0.3250, validation loss: 0.2404
2024-05-25 00:45:06 [INFO]: Epoch 015 - training loss: 0.3223, validation loss: 0.2389
2024-05-25 00:45:07 [INFO]: Epoch 016 - training loss: 0.3226, validation loss: 0.2355
2024-05-25 00:45:07 [INFO]: Epoch 017 - training loss: 0.3210, validation loss: 0.2308
2024-05-25 00:45:07 [INFO]: Epoch 018 - training loss: 0.3141, validation loss: 0.2292
2024-05-25 00:45:07 [INFO]: Epoch 019 - training loss: 0.3104, validation loss: 0.2264
2024-05-25 00:45:08 [INFO]: Epoch 020 - training loss: 0.3060, validation loss: 0.2231
2024-05-25 00:45:08 [INFO]: Epoch 021 - training loss: 0.3024, validation loss: 0.2216
2024-05-25 00:45:08 [INFO]: Epoch 022 - training loss: 0.3032, validation loss: 0.2220
2024-05-25 00:45:09 [INFO]: Epoch 023 - training loss: 0.3002, validation loss: 0.2187
2024-05-25 00:45:09 [INFO]: Epoch 024 - training loss: 0.2993, validation loss: 0.2188
2024-05-25 00:45:09 [INFO]: Epoch 025 - training loss: 0.2955, validation loss: 0.2157
2024-05-25 00:45:10 [INFO]: Epoch 026 - training loss: 0.2933, validation loss: 0.2168
2024-05-25 00:45:10 [INFO]: Epoch 027 - training loss: 0.2939, validation loss: 0.2171
2024-05-25 00:45:10 [INFO]: Epoch 028 - training loss: 0.2898, validation loss: 0.2154
2024-05-25 00:45:11 [INFO]: Epoch 029 - training loss: 0.2885, validation loss: 0.2136
2024-05-25 00:45:11 [INFO]: Epoch 030 - training loss: 0.2869, validation loss: 0.2128
2024-05-25 00:45:11 [INFO]: Epoch 031 - training loss: 0.2862, validation loss: 0.2115
2024-05-25 00:45:11 [INFO]: Epoch 032 - training loss: 0.2836, validation loss: 0.2117
2024-05-25 00:45:12 [INFO]: Epoch 033 - training loss: 0.2805, validation loss: 0.2117
2024-05-25 00:45:12 [INFO]: Epoch 034 - training loss: 0.2802, validation loss: 0.2106
2024-05-25 00:45:12 [INFO]: Epoch 035 - training loss: 0.2803, validation loss: 0.2097
2024-05-25 00:45:13 [INFO]: Epoch 036 - training loss: 0.2795, validation loss: 0.2116
2024-05-25 00:45:13 [INFO]: Epoch 037 - training loss: 0.2786, validation loss: 0.2102
2024-05-25 00:45:13 [INFO]: Epoch 038 - training loss: 0.2763, validation loss: 0.2079
2024-05-25 00:45:14 [INFO]: Epoch 039 - training loss: 0.2739, validation loss: 0.2076
2024-05-25 00:45:14 [INFO]: Epoch 040 - training loss: 0.2729, validation loss: 0.2071
2024-05-25 00:45:14 [INFO]: Epoch 041 - training loss: 0.2729, validation loss: 0.2066
2024-05-25 00:45:15 [INFO]: Epoch 042 - training loss: 0.2724, validation loss: 0.2065
2024-05-25 00:45:15 [INFO]: Epoch 043 - training loss: 0.2707, validation loss: 0.2058
2024-05-25 00:45:15 [INFO]: Epoch 044 - training loss: 0.2700, validation loss: 0.2054
2024-05-25 00:45:15 [INFO]: Epoch 045 - training loss: 0.2679, validation loss: 0.2051
2024-05-25 00:45:16 [INFO]: Epoch 046 - training loss: 0.2682, validation loss: 0.2045
2024-05-25 00:45:16 [INFO]: Epoch 047 - training loss: 0.2677, validation loss: 0.2027
2024-05-25 00:45:16 [INFO]: Epoch 048 - training loss: 0.2661, validation loss: 0.2028
2024-05-25 00:45:17 [INFO]: Epoch 049 - training loss: 0.2728, validation loss: 0.2020
2024-05-25 00:45:17 [INFO]: Epoch 050 - training loss: 0.2669, validation loss: 0.2028
2024-05-25 00:45:17 [INFO]: Epoch 051 - training loss: 0.2628, validation loss: 0.2018
2024-05-25 00:45:18 [INFO]: Epoch 052 - training loss: 0.2639, validation loss: 0.2006
2024-05-25 00:45:18 [INFO]: Epoch 053 - training loss: 0.2606, validation loss: 0.2018
2024-05-25 00:45:18 [INFO]: Epoch 054 - training loss: 0.2617, validation loss: 0.2003
2024-05-25 00:45:19 [INFO]: Epoch 055 - training loss: 0.2583, validation loss: 0.1994
2024-05-25 00:45:19 [INFO]: Epoch 056 - training loss: 0.2577, validation loss: 0.1993
2024-05-25 00:45:19 [INFO]: Epoch 057 - training loss: 0.2593, validation loss: 0.2000
2024-05-25 00:45:19 [INFO]: Epoch 058 - training loss: 0.2630, validation loss: 0.1999
2024-05-25 00:45:20 [INFO]: Epoch 059 - training loss: 0.2586, validation loss: 0.1980
2024-05-25 00:45:20 [INFO]: Epoch 060 - training loss: 0.2568, validation loss: 0.2011
2024-05-25 00:45:20 [INFO]: Epoch 061 - training loss: 0.2561, validation loss: 0.1977
2024-05-25 00:45:21 [INFO]: Epoch 062 - training loss: 0.2551, validation loss: 0.1963
2024-05-25 00:45:21 [INFO]: Epoch 063 - training loss: 0.2529, validation loss: 0.1965
2024-05-25 00:45:21 [INFO]: Epoch 064 - training loss: 0.2510, validation loss: 0.1950
2024-05-25 00:45:22 [INFO]: Epoch 065 - training loss: 0.2509, validation loss: 0.1954
2024-05-25 00:45:22 [INFO]: Epoch 066 - training loss: 0.2498, validation loss: 0.1957
2024-05-25 00:45:22 [INFO]: Epoch 067 - training loss: 0.2503, validation loss: 0.1951
2024-05-25 00:45:23 [INFO]: Epoch 068 - training loss: 0.2506, validation loss: 0.1949
2024-05-25 00:45:23 [INFO]: Epoch 069 - training loss: 0.2489, validation loss: 0.1954
2024-05-25 00:45:23 [INFO]: Epoch 070 - training loss: 0.2467, validation loss: 0.1926
2024-05-25 00:45:24 [INFO]: Epoch 071 - training loss: 0.2459, validation loss: 0.1926
2024-05-25 00:45:24 [INFO]: Epoch 072 - training loss: 0.2464, validation loss: 0.1939
2024-05-25 00:45:24 [INFO]: Epoch 073 - training loss: 0.2472, validation loss: 0.1918
2024-05-25 00:45:24 [INFO]: Epoch 074 - training loss: 0.2452, validation loss: 0.1924
2024-05-25 00:45:25 [INFO]: Epoch 075 - training loss: 0.2445, validation loss: 0.1923
2024-05-25 00:45:25 [INFO]: Epoch 076 - training loss: 0.2447, validation loss: 0.1921
2024-05-25 00:45:25 [INFO]: Epoch 077 - training loss: 0.2440, validation loss: 0.1925
2024-05-25 00:45:26 [INFO]: Epoch 078 - training loss: 0.2431, validation loss: 0.1910
2024-05-25 00:45:26 [INFO]: Epoch 079 - training loss: 0.2429, validation loss: 0.1901
2024-05-25 00:45:26 [INFO]: Epoch 080 - training loss: 0.2414, validation loss: 0.1897
2024-05-25 00:45:27 [INFO]: Epoch 081 - training loss: 0.2416, validation loss: 0.1908
2024-05-25 00:45:27 [INFO]: Epoch 082 - training loss: 0.2410, validation loss: 0.1907
2024-05-25 00:45:27 [INFO]: Epoch 083 - training loss: 0.2420, validation loss: 0.1875
2024-05-25 00:45:28 [INFO]: Epoch 084 - training loss: 0.2382, validation loss: 0.1878
2024-05-25 00:45:28 [INFO]: Epoch 085 - training loss: 0.2384, validation loss: 0.1910
2024-05-25 00:45:28 [INFO]: Epoch 086 - training loss: 0.2392, validation loss: 0.1878
2024-05-25 00:45:28 [INFO]: Epoch 087 - training loss: 0.2369, validation loss: 0.1887
2024-05-25 00:45:29 [INFO]: Epoch 088 - training loss: 0.2381, validation loss: 0.1876
2024-05-25 00:45:29 [INFO]: Epoch 089 - training loss: 0.2363, validation loss: 0.1867
2024-05-25 00:45:29 [INFO]: Epoch 090 - training loss: 0.2356, validation loss: 0.1868
2024-05-25 00:45:30 [INFO]: Epoch 091 - training loss: 0.2358, validation loss: 0.1882
2024-05-25 00:45:30 [INFO]: Epoch 092 - training loss: 0.2371, validation loss: 0.1863
2024-05-25 00:45:30 [INFO]: Epoch 093 - training loss: 0.2335, validation loss: 0.1863
2024-05-25 00:45:31 [INFO]: Epoch 094 - training loss: 0.2351, validation loss: 0.1853
2024-05-25 00:45:31 [INFO]: Epoch 095 - training loss: 0.2331, validation loss: 0.1872
2024-05-25 00:45:31 [INFO]: Epoch 096 - training loss: 0.2303, validation loss: 0.1856
2024-05-25 00:45:32 [INFO]: Epoch 097 - training loss: 0.2349, validation loss: 0.1846
2024-05-25 00:45:32 [INFO]: Epoch 098 - training loss: 0.2314, validation loss: 0.1842
2024-05-25 00:45:32 [INFO]: Epoch 099 - training loss: 0.2293, validation loss: 0.1842
2024-05-25 00:45:33 [INFO]: Epoch 100 - training loss: 0.2298, validation loss: 0.1848
2024-05-25 00:45:33 [INFO]: Epoch 101 - training loss: 0.2338, validation loss: 0.1852
2024-05-25 00:45:33 [INFO]: Epoch 102 - training loss: 0.2362, validation loss: 0.1855
2024-05-25 00:45:33 [INFO]: Epoch 103 - training loss: 0.2340, validation loss: 0.1837
2024-05-25 00:45:34 [INFO]: Epoch 104 - training loss: 0.2317, validation loss: 0.1845
2024-05-25 00:45:34 [INFO]: Epoch 105 - training loss: 0.2328, validation loss: 0.1833
2024-05-25 00:45:34 [INFO]: Epoch 106 - training loss: 0.2283, validation loss: 0.1822
2024-05-25 00:45:35 [INFO]: Epoch 107 - training loss: 0.2268, validation loss: 0.1823
2024-05-25 00:45:35 [INFO]: Epoch 108 - training loss: 0.2268, validation loss: 0.1820
2024-05-25 00:45:35 [INFO]: Epoch 109 - training loss: 0.2259, validation loss: 0.1813
2024-05-25 00:45:36 [INFO]: Epoch 110 - training loss: 0.2252, validation loss: 0.1828
2024-05-25 00:45:36 [INFO]: Epoch 111 - training loss: 0.2277, validation loss: 0.1812
2024-05-25 00:45:36 [INFO]: Epoch 112 - training loss: 0.2270, validation loss: 0.1837
2024-05-25 00:45:36 [INFO]: Epoch 113 - training loss: 0.2236, validation loss: 0.1819
2024-05-25 00:45:37 [INFO]: Epoch 114 - training loss: 0.2231, validation loss: 0.1818
2024-05-25 00:45:37 [INFO]: Epoch 115 - training loss: 0.2225, validation loss: 0.1815
2024-05-25 00:45:37 [INFO]: Epoch 116 - training loss: 0.2229, validation loss: 0.1810
2024-05-25 00:45:38 [INFO]: Epoch 117 - training loss: 0.2212, validation loss: 0.1806
2024-05-25 00:45:38 [INFO]: Epoch 118 - training loss: 0.2220, validation loss: 0.1803
2024-05-25 00:45:39 [INFO]: Epoch 119 - training loss: 0.2219, validation loss: 0.1786
2024-05-25 00:45:39 [INFO]: Epoch 120 - training loss: 0.2195, validation loss: 0.1805
2024-05-25 00:45:39 [INFO]: Epoch 121 - training loss: 0.2208, validation loss: 0.1798
2024-05-25 00:45:39 [INFO]: Epoch 122 - training loss: 0.2211, validation loss: 0.1789
2024-05-25 00:45:40 [INFO]: Epoch 123 - training loss: 0.2194, validation loss: 0.1780
2024-05-25 00:45:40 [INFO]: Epoch 124 - training loss: 0.2180, validation loss: 0.1800
2024-05-25 00:45:40 [INFO]: Epoch 125 - training loss: 0.2193, validation loss: 0.1775
2024-05-25 00:45:41 [INFO]: Epoch 126 - training loss: 0.2190, validation loss: 0.1774
2024-05-25 00:45:41 [INFO]: Epoch 127 - training loss: 0.2168, validation loss: 0.1793
2024-05-25 00:45:41 [INFO]: Epoch 128 - training loss: 0.2163, validation loss: 0.1774
2024-05-25 00:45:42 [INFO]: Epoch 129 - training loss: 0.2166, validation loss: 0.1776
2024-05-25 00:45:42 [INFO]: Epoch 130 - training loss: 0.2193, validation loss: 0.1772
2024-05-25 00:45:42 [INFO]: Epoch 131 - training loss: 0.2173, validation loss: 0.1784
2024-05-25 00:45:43 [INFO]: Epoch 132 - training loss: 0.2168, validation loss: 0.1785
2024-05-25 00:45:43 [INFO]: Epoch 133 - training loss: 0.2179, validation loss: 0.1758
2024-05-25 00:45:43 [INFO]: Epoch 134 - training loss: 0.2169, validation loss: 0.1768
2024-05-25 00:45:43 [INFO]: Epoch 135 - training loss: 0.2140, validation loss: 0.1770
2024-05-25 00:45:44 [INFO]: Epoch 136 - training loss: 0.2152, validation loss: 0.1752
2024-05-25 00:45:44 [INFO]: Epoch 137 - training loss: 0.2147, validation loss: 0.1776
2024-05-25 00:45:44 [INFO]: Epoch 138 - training loss: 0.2130, validation loss: 0.1768
2024-05-25 00:45:45 [INFO]: Epoch 139 - training loss: 0.2132, validation loss: 0.1766
2024-05-25 00:45:45 [INFO]: Epoch 140 - training loss: 0.2126, validation loss: 0.1759
2024-05-25 00:45:45 [INFO]: Epoch 141 - training loss: 0.2130, validation loss: 0.1755
2024-05-25 00:45:46 [INFO]: Epoch 142 - training loss: 0.2145, validation loss: 0.1752
2024-05-25 00:45:46 [INFO]: Epoch 143 - training loss: 0.2139, validation loss: 0.1768
2024-05-25 00:45:46 [INFO]: Epoch 144 - training loss: 0.2150, validation loss: 0.1748
2024-05-25 00:45:47 [INFO]: Epoch 145 - training loss: 0.2151, validation loss: 0.1748
2024-05-25 00:45:47 [INFO]: Epoch 146 - training loss: 0.2127, validation loss: 0.1745
2024-05-25 00:45:47 [INFO]: Epoch 147 - training loss: 0.2097, validation loss: 0.1750
2024-05-25 00:45:47 [INFO]: Epoch 148 - training loss: 0.2120, validation loss: 0.1756
2024-05-25 00:45:48 [INFO]: Epoch 149 - training loss: 0.2111, validation loss: 0.1753
2024-05-25 00:45:48 [INFO]: Epoch 150 - training loss: 0.2125, validation loss: 0.1737
2024-05-25 00:45:48 [INFO]: Epoch 151 - training loss: 0.2122, validation loss: 0.1732
2024-05-25 00:45:49 [INFO]: Epoch 152 - training loss: 0.2098, validation loss: 0.1731
2024-05-25 00:45:49 [INFO]: Epoch 153 - training loss: 0.2086, validation loss: 0.1742
2024-05-25 00:45:49 [INFO]: Epoch 154 - training loss: 0.2101, validation loss: 0.1725
2024-05-25 00:45:50 [INFO]: Epoch 155 - training loss: 0.2090, validation loss: 0.1748
2024-05-25 00:45:50 [INFO]: Epoch 156 - training loss: 0.2133, validation loss: 0.1747
2024-05-25 00:45:50 [INFO]: Epoch 157 - training loss: 0.2098, validation loss: 0.1717
2024-05-25 00:45:51 [INFO]: Epoch 158 - training loss: 0.2068, validation loss: 0.1726
2024-05-25 00:45:51 [INFO]: Epoch 159 - training loss: 0.2070, validation loss: 0.1723
2024-05-25 00:45:51 [INFO]: Epoch 160 - training loss: 0.2086, validation loss: 0.1727
2024-05-25 00:45:51 [INFO]: Epoch 161 - training loss: 0.2057, validation loss: 0.1723
2024-05-25 00:45:52 [INFO]: Epoch 162 - training loss: 0.2057, validation loss: 0.1724
2024-05-25 00:45:52 [INFO]: Epoch 163 - training loss: 0.2069, validation loss: 0.1714
2024-05-25 00:45:52 [INFO]: Epoch 164 - training loss: 0.2072, validation loss: 0.1717
2024-05-25 00:45:53 [INFO]: Epoch 165 - training loss: 0.2079, validation loss: 0.1720
2024-05-25 00:45:53 [INFO]: Epoch 166 - training loss: 0.2098, validation loss: 0.1715
2024-05-25 00:45:53 [INFO]: Epoch 167 - training loss: 0.2071, validation loss: 0.1728
2024-05-25 00:45:54 [INFO]: Epoch 168 - training loss: 0.2095, validation loss: 0.1726
2024-05-25 00:45:54 [INFO]: Epoch 169 - training loss: 0.2079, validation loss: 0.1717
2024-05-25 00:45:54 [INFO]: Epoch 170 - training loss: 0.2041, validation loss: 0.1707
2024-05-25 00:45:55 [INFO]: Epoch 171 - training loss: 0.2040, validation loss: 0.1709
2024-05-25 00:45:55 [INFO]: Epoch 172 - training loss: 0.2046, validation loss: 0.1698
2024-05-25 00:45:55 [INFO]: Epoch 173 - training loss: 0.2039, validation loss: 0.1708
2024-05-25 00:45:55 [INFO]: Epoch 174 - training loss: 0.2046, validation loss: 0.1698
2024-05-25 00:45:56 [INFO]: Epoch 175 - training loss: 0.2029, validation loss: 0.1704
2024-05-25 00:45:56 [INFO]: Epoch 176 - training loss: 0.2023, validation loss: 0.1702
2024-05-25 00:45:56 [INFO]: Epoch 177 - training loss: 0.2036, validation loss: 0.1697
2024-05-25 00:45:57 [INFO]: Epoch 178 - training loss: 0.2019, validation loss: 0.1688
2024-05-25 00:45:57 [INFO]: Epoch 179 - training loss: 0.2009, validation loss: 0.1695
2024-05-25 00:45:57 [INFO]: Epoch 180 - training loss: 0.2015, validation loss: 0.1686
2024-05-25 00:45:58 [INFO]: Epoch 181 - training loss: 0.2031, validation loss: 0.1699
2024-05-25 00:45:58 [INFO]: Epoch 182 - training loss: 0.2019, validation loss: 0.1691
2024-05-25 00:45:58 [INFO]: Epoch 183 - training loss: 0.2015, validation loss: 0.1695
2024-05-25 00:45:59 [INFO]: Epoch 184 - training loss: 0.2019, validation loss: 0.1688
2024-05-25 00:45:59 [INFO]: Epoch 185 - training loss: 0.1998, validation loss: 0.1691
2024-05-25 00:45:59 [INFO]: Epoch 186 - training loss: 0.2002, validation loss: 0.1697
2024-05-25 00:46:00 [INFO]: Epoch 187 - training loss: 0.2011, validation loss: 0.1686
2024-05-25 00:46:00 [INFO]: Epoch 188 - training loss: 0.1998, validation loss: 0.1702
2024-05-25 00:46:00 [INFO]: Epoch 189 - training loss: 0.2005, validation loss: 0.1683
2024-05-25 00:46:01 [INFO]: Epoch 190 - training loss: 0.1994, validation loss: 0.1683
2024-05-25 00:46:01 [INFO]: Epoch 191 - training loss: 0.2008, validation loss: 0.1691
2024-05-25 00:46:01 [INFO]: Epoch 192 - training loss: 0.1986, validation loss: 0.1689
2024-05-25 00:46:02 [INFO]: Epoch 193 - training loss: 0.2007, validation loss: 0.1682
2024-05-25 00:46:02 [INFO]: Epoch 194 - training loss: 0.2017, validation loss: 0.1685
2024-05-25 00:46:02 [INFO]: Epoch 195 - training loss: 0.1977, validation loss: 0.1680
2024-05-25 00:46:02 [INFO]: Epoch 196 - training loss: 0.1968, validation loss: 0.1671
2024-05-25 00:46:03 [INFO]: Epoch 197 - training loss: 0.1979, validation loss: 0.1681
2024-05-25 00:46:03 [INFO]: Epoch 198 - training loss: 0.1964, validation loss: 0.1675
2024-05-25 00:46:03 [INFO]: Epoch 199 - training loss: 0.1983, validation loss: 0.1678
2024-05-25 00:46:04 [INFO]: Epoch 200 - training loss: 0.2007, validation loss: 0.1674
2024-05-25 00:46:04 [INFO]: Epoch 201 - training loss: 0.2008, validation loss: 0.1668
2024-05-25 00:46:04 [INFO]: Epoch 202 - training loss: 0.1987, validation loss: 0.1669
2024-05-25 00:46:05 [INFO]: Epoch 203 - training loss: 0.1985, validation loss: 0.1671
2024-05-25 00:46:05 [INFO]: Epoch 204 - training loss: 0.1984, validation loss: 0.1665
2024-05-25 00:46:05 [INFO]: Epoch 205 - training loss: 0.1957, validation loss: 0.1655
2024-05-25 00:46:06 [INFO]: Epoch 206 - training loss: 0.1954, validation loss: 0.1678
2024-05-25 00:46:06 [INFO]: Epoch 207 - training loss: 0.1947, validation loss: 0.1671
2024-05-25 00:46:06 [INFO]: Epoch 208 - training loss: 0.1960, validation loss: 0.1662
2024-05-25 00:46:06 [INFO]: Epoch 209 - training loss: 0.1967, validation loss: 0.1660
2024-05-25 00:46:07 [INFO]: Epoch 210 - training loss: 0.1931, validation loss: 0.1670
2024-05-25 00:46:07 [INFO]: Epoch 211 - training loss: 0.1935, validation loss: 0.1668
2024-05-25 00:46:07 [INFO]: Epoch 212 - training loss: 0.1931, validation loss: 0.1654
2024-05-25 00:46:08 [INFO]: Epoch 213 - training loss: 0.1940, validation loss: 0.1657
2024-05-25 00:46:08 [INFO]: Epoch 214 - training loss: 0.1937, validation loss: 0.1661
2024-05-25 00:46:08 [INFO]: Epoch 215 - training loss: 0.1951, validation loss: 0.1660
2024-05-25 00:46:09 [INFO]: Epoch 216 - training loss: 0.1970, validation loss: 0.1647
2024-05-25 00:46:09 [INFO]: Epoch 217 - training loss: 0.1936, validation loss: 0.1659
2024-05-25 00:46:09 [INFO]: Epoch 218 - training loss: 0.1926, validation loss: 0.1655
2024-05-25 00:46:10 [INFO]: Epoch 219 - training loss: 0.1930, validation loss: 0.1649
2024-05-25 00:46:10 [INFO]: Epoch 220 - training loss: 0.1957, validation loss: 0.1643
2024-05-25 00:46:10 [INFO]: Epoch 221 - training loss: 0.1929, validation loss: 0.1650
2024-05-25 00:46:11 [INFO]: Epoch 222 - training loss: 0.1929, validation loss: 0.1644
2024-05-25 00:46:11 [INFO]: Epoch 223 - training loss: 0.1924, validation loss: 0.1659
2024-05-25 00:46:11 [INFO]: Epoch 224 - training loss: 0.1930, validation loss: 0.1639
2024-05-25 00:46:11 [INFO]: Epoch 225 - training loss: 0.1957, validation loss: 0.1654
2024-05-25 00:46:12 [INFO]: Epoch 226 - training loss: 0.1923, validation loss: 0.1647
2024-05-25 00:46:12 [INFO]: Epoch 227 - training loss: 0.1914, validation loss: 0.1634
2024-05-25 00:46:12 [INFO]: Epoch 228 - training loss: 0.1909, validation loss: 0.1649
2024-05-25 00:46:13 [INFO]: Epoch 229 - training loss: 0.1914, validation loss: 0.1646
2024-05-25 00:46:13 [INFO]: Epoch 230 - training loss: 0.1921, validation loss: 0.1648
2024-05-25 00:46:13 [INFO]: Epoch 231 - training loss: 0.1914, validation loss: 0.1647
2024-05-25 00:46:14 [INFO]: Epoch 232 - training loss: 0.1902, validation loss: 0.1641
2024-05-25 00:46:14 [INFO]: Epoch 233 - training loss: 0.1888, validation loss: 0.1648
2024-05-25 00:46:14 [INFO]: Epoch 234 - training loss: 0.1896, validation loss: 0.1645
2024-05-25 00:46:15 [INFO]: Epoch 235 - training loss: 0.1916, validation loss: 0.1637
2024-05-25 00:46:15 [INFO]: Epoch 236 - training loss: 0.1912, validation loss: 0.1625
2024-05-25 00:46:15 [INFO]: Epoch 237 - training loss: 0.1890, validation loss: 0.1630
2024-05-25 00:46:16 [INFO]: Epoch 238 - training loss: 0.1901, validation loss: 0.1637
2024-05-25 00:46:16 [INFO]: Epoch 239 - training loss: 0.1889, validation loss: 0.1624
2024-05-25 00:46:16 [INFO]: Epoch 240 - training loss: 0.1922, validation loss: 0.1665
2024-05-25 00:46:16 [INFO]: Epoch 241 - training loss: 0.1884, validation loss: 0.1636
2024-05-25 00:46:17 [INFO]: Epoch 242 - training loss: 0.1875, validation loss: 0.1634
2024-05-25 00:46:17 [INFO]: Epoch 243 - training loss: 0.1897, validation loss: 0.1642
2024-05-25 00:46:17 [INFO]: Epoch 244 - training loss: 0.1901, validation loss: 0.1635
2024-05-25 00:46:18 [INFO]: Epoch 245 - training loss: 0.1883, validation loss: 0.1622
2024-05-25 00:46:18 [INFO]: Epoch 246 - training loss: 0.1872, validation loss: 0.1636
2024-05-25 00:46:18 [INFO]: Epoch 247 - training loss: 0.1870, validation loss: 0.1616
2024-05-25 00:46:19 [INFO]: Epoch 248 - training loss: 0.1860, validation loss: 0.1628
2024-05-25 00:46:19 [INFO]: Epoch 249 - training loss: 0.1851, validation loss: 0.1638
2024-05-25 00:46:19 [INFO]: Epoch 250 - training loss: 0.1868, validation loss: 0.1629
2024-05-25 00:46:20 [INFO]: Epoch 251 - training loss: 0.1868, validation loss: 0.1620
2024-05-25 00:46:20 [INFO]: Epoch 252 - training loss: 0.1856, validation loss: 0.1637
2024-05-25 00:46:20 [INFO]: Epoch 253 - training loss: 0.1852, validation loss: 0.1634
2024-05-25 00:46:21 [INFO]: Epoch 254 - training loss: 0.1834, validation loss: 0.1622
2024-05-25 00:46:21 [INFO]: Epoch 255 - training loss: 0.1840, validation loss: 0.1626
2024-05-25 00:46:21 [INFO]: Epoch 256 - training loss: 0.1847, validation loss: 0.1622
2024-05-25 00:46:21 [INFO]: Epoch 257 - training loss: 0.1867, validation loss: 0.1610
2024-05-25 00:46:22 [INFO]: Epoch 258 - training loss: 0.1858, validation loss: 0.1625
2024-05-25 00:46:22 [INFO]: Epoch 259 - training loss: 0.1876, validation loss: 0.1629
2024-05-25 00:46:22 [INFO]: Epoch 260 - training loss: 0.1857, validation loss: 0.1625
2024-05-25 00:46:23 [INFO]: Epoch 261 - training loss: 0.1836, validation loss: 0.1622
2024-05-25 00:46:23 [INFO]: Epoch 262 - training loss: 0.1827, validation loss: 0.1620
2024-05-25 00:46:23 [INFO]: Epoch 263 - training loss: 0.1844, validation loss: 0.1626
2024-05-25 00:46:24 [INFO]: Epoch 264 - training loss: 0.1883, validation loss: 0.1622
2024-05-25 00:46:24 [INFO]: Epoch 265 - training loss: 0.1867, validation loss: 0.1622
2024-05-25 00:46:24 [INFO]: Epoch 266 - training loss: 0.1851, validation loss: 0.1608
2024-05-25 00:46:25 [INFO]: Epoch 267 - training loss: 0.1848, validation loss: 0.1610
2024-05-25 00:46:25 [INFO]: Epoch 268 - training loss: 0.1842, validation loss: 0.1609
2024-05-25 00:46:25 [INFO]: Epoch 269 - training loss: 0.1827, validation loss: 0.1602
2024-05-25 00:46:25 [INFO]: Epoch 270 - training loss: 0.1846, validation loss: 0.1604
2024-05-25 00:46:26 [INFO]: Epoch 271 - training loss: 0.1837, validation loss: 0.1609
2024-05-25 00:46:26 [INFO]: Epoch 272 - training loss: 0.1839, validation loss: 0.1615
2024-05-25 00:46:26 [INFO]: Epoch 273 - training loss: 0.1833, validation loss: 0.1625
2024-05-25 00:46:27 [INFO]: Epoch 274 - training loss: 0.1823, validation loss: 0.1603
2024-05-25 00:46:27 [INFO]: Epoch 275 - training loss: 0.1829, validation loss: 0.1605
2024-05-25 00:46:27 [INFO]: Epoch 276 - training loss: 0.1833, validation loss: 0.1610
2024-05-25 00:46:28 [INFO]: Epoch 277 - training loss: 0.1826, validation loss: 0.1602
2024-05-25 00:46:28 [INFO]: Epoch 278 - training loss: 0.1814, validation loss: 0.1604
2024-05-25 00:46:28 [INFO]: Epoch 279 - training loss: 0.1855, validation loss: 0.1604
2024-05-25 00:46:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:46:28 [INFO]: Finished training. The best model is from epoch#269.
2024-05-25 00:46:28 [INFO]: Saved the model to augmentation_saved_results/round_0/Transformer_air_quality/20240525_T004501/Transformer.pypots
2024-05-25 00:46:28 [INFO]: Transformer on Air-Quality: MAE=0.1579, MSE=0.1027
2024-05-25 00:46:28 [INFO]: Successfully saved to augmentation_saved_results/round_0/Transformer_air_quality/imputation.pkl
2024-05-25 00:46:28 [INFO]: Using the given device: cuda:0
2024-05-25 00:46:28 [INFO]: Model files will be saved to augmentation_saved_results/round_0/TimesNet_air_quality/20240525_T004628
2024-05-25 00:46:28 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/TimesNet_air_quality/20240525_T004628/tensorboard
2024-05-25 00:46:29 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 00:46:30 [INFO]: Epoch 001 - training loss: 0.2755, validation loss: 0.2836
2024-05-25 00:46:31 [INFO]: Epoch 002 - training loss: 0.2390, validation loss: 0.2650
2024-05-25 00:46:31 [INFO]: Epoch 003 - training loss: 0.1910, validation loss: 0.2488
2024-05-25 00:46:32 [INFO]: Epoch 004 - training loss: 0.1775, validation loss: 0.2270
2024-05-25 00:46:32 [INFO]: Epoch 005 - training loss: 0.1811, validation loss: 0.2383
2024-05-25 00:46:33 [INFO]: Epoch 006 - training loss: 0.1632, validation loss: 0.2261
2024-05-25 00:46:33 [INFO]: Epoch 007 - training loss: 0.1690, validation loss: 0.2341
2024-05-25 00:46:34 [INFO]: Epoch 008 - training loss: 0.1782, validation loss: 0.2206
2024-05-25 00:46:34 [INFO]: Epoch 009 - training loss: 0.1611, validation loss: 0.2193
2024-05-25 00:46:35 [INFO]: Epoch 010 - training loss: 0.1381, validation loss: 0.2134
2024-05-25 00:46:35 [INFO]: Epoch 011 - training loss: 0.1358, validation loss: 0.2119
2024-05-25 00:46:36 [INFO]: Epoch 012 - training loss: 0.1476, validation loss: 0.2109
2024-05-25 00:46:36 [INFO]: Epoch 013 - training loss: 0.1452, validation loss: 0.2063
2024-05-25 00:46:37 [INFO]: Epoch 014 - training loss: 0.1316, validation loss: 0.2017
2024-05-25 00:46:37 [INFO]: Epoch 015 - training loss: 0.1353, validation loss: 0.2023
2024-05-25 00:46:38 [INFO]: Epoch 016 - training loss: 0.1212, validation loss: 0.2039
2024-05-25 00:46:38 [INFO]: Epoch 017 - training loss: 0.1198, validation loss: 0.2019
2024-05-25 00:46:39 [INFO]: Epoch 018 - training loss: 0.1308, validation loss: 0.2081
2024-05-25 00:46:39 [INFO]: Epoch 019 - training loss: 0.1341, validation loss: 0.2033
2024-05-25 00:46:40 [INFO]: Epoch 020 - training loss: 0.1194, validation loss: 0.2010
2024-05-25 00:46:41 [INFO]: Epoch 021 - training loss: 0.1290, validation loss: 0.2013
2024-05-25 00:46:41 [INFO]: Epoch 022 - training loss: 0.1312, validation loss: 0.1929
2024-05-25 00:46:42 [INFO]: Epoch 023 - training loss: 0.1361, validation loss: 0.1869
2024-05-25 00:46:42 [INFO]: Epoch 024 - training loss: 0.1166, validation loss: 0.2055
2024-05-25 00:46:43 [INFO]: Epoch 025 - training loss: 0.1292, validation loss: 0.2006
2024-05-25 00:46:43 [INFO]: Epoch 026 - training loss: 0.1318, validation loss: 0.2001
2024-05-25 00:46:44 [INFO]: Epoch 027 - training loss: 0.1097, validation loss: 0.1928
2024-05-25 00:46:44 [INFO]: Epoch 028 - training loss: 0.1098, validation loss: 0.2009
2024-05-25 00:46:45 [INFO]: Epoch 029 - training loss: 0.1354, validation loss: 0.2018
2024-05-25 00:46:45 [INFO]: Epoch 030 - training loss: 0.1208, validation loss: 0.1934
2024-05-25 00:46:46 [INFO]: Epoch 031 - training loss: 0.1177, validation loss: 0.1905
2024-05-25 00:46:46 [INFO]: Epoch 032 - training loss: 0.0985, validation loss: 0.1955
2024-05-25 00:46:47 [INFO]: Epoch 033 - training loss: 0.1185, validation loss: 0.1999
2024-05-25 00:46:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:46:47 [INFO]: Finished training. The best model is from epoch#23.
2024-05-25 00:46:47 [INFO]: Saved the model to augmentation_saved_results/round_0/TimesNet_air_quality/20240525_T004628/TimesNet.pypots
2024-05-25 00:46:47 [INFO]: TimesNet on Air-Quality: MAE=0.1673, MSE=0.1472
2024-05-25 00:46:47 [INFO]: Successfully saved to augmentation_saved_results/round_0/TimesNet_air_quality/imputation.pkl
2024-05-25 00:46:47 [INFO]: Using the given device: cuda:0
2024-05-25 00:46:47 [INFO]: Model files will be saved to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647
2024-05-25 00:46:47 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/tensorboard
2024-05-25 00:46:47 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 00:47:04 [INFO]: Epoch 001 - training loss: 0.4848, validation loss: 0.3436
2024-05-25 00:47:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch1_loss0.3435834765434265.pypots
2024-05-25 00:47:21 [INFO]: Epoch 002 - training loss: 0.2938, validation loss: 0.2777
2024-05-25 00:47:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch2_loss0.277736958861351.pypots
2024-05-25 00:47:38 [INFO]: Epoch 003 - training loss: 0.2498, validation loss: 0.2359
2024-05-25 00:47:38 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch3_loss0.23590076118707656.pypots
2024-05-25 00:47:55 [INFO]: Epoch 004 - training loss: 0.2340, validation loss: 0.2200
2024-05-25 00:47:55 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch4_loss0.2200033411383629.pypots
2024-05-25 00:48:12 [INFO]: Epoch 005 - training loss: 0.2240, validation loss: 0.1979
2024-05-25 00:48:12 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch5_loss0.19791077077388763.pypots
2024-05-25 00:48:29 [INFO]: Epoch 006 - training loss: 0.1986, validation loss: 0.1871
2024-05-25 00:48:29 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch6_loss0.1870574250817299.pypots
2024-05-25 00:48:45 [INFO]: Epoch 007 - training loss: 0.1836, validation loss: 0.1749
2024-05-25 00:48:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch7_loss0.17488322108983995.pypots
2024-05-25 00:49:02 [INFO]: Epoch 008 - training loss: 0.1896, validation loss: 0.1614
2024-05-25 00:49:02 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch8_loss0.1614477589726448.pypots
2024-05-25 00:49:19 [INFO]: Epoch 009 - training loss: 0.1626, validation loss: 0.1586
2024-05-25 00:49:19 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch9_loss0.15858064144849776.pypots
2024-05-25 00:49:36 [INFO]: Epoch 010 - training loss: 0.1834, validation loss: 0.1569
2024-05-25 00:49:36 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch10_loss0.15686543583869933.pypots
2024-05-25 00:49:53 [INFO]: Epoch 011 - training loss: 0.1674, validation loss: 0.1486
2024-05-25 00:49:53 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch11_loss0.14855801910161973.pypots
2024-05-25 00:50:10 [INFO]: Epoch 012 - training loss: 0.1652, validation loss: 0.1472
2024-05-25 00:50:10 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch12_loss0.1471570149064064.pypots
2024-05-25 00:50:27 [INFO]: Epoch 013 - training loss: 0.1592, validation loss: 0.1452
2024-05-25 00:50:27 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch13_loss0.1452019691467285.pypots
2024-05-25 00:50:43 [INFO]: Epoch 014 - training loss: 0.1502, validation loss: 0.1432
2024-05-25 00:50:43 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch14_loss0.1432001531124115.pypots
2024-05-25 00:51:00 [INFO]: Epoch 015 - training loss: 0.1732, validation loss: 0.1523
2024-05-25 00:51:00 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch15_loss0.1523422673344612.pypots
2024-05-25 00:51:17 [INFO]: Epoch 016 - training loss: 0.1699, validation loss: 0.1425
2024-05-25 00:51:17 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch16_loss0.1425095245242119.pypots
2024-05-25 00:51:34 [INFO]: Epoch 017 - training loss: 0.1840, validation loss: 0.1411
2024-05-25 00:51:34 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch17_loss0.1410589560866356.pypots
2024-05-25 00:51:51 [INFO]: Epoch 018 - training loss: 0.1469, validation loss: 0.1397
2024-05-25 00:51:51 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch18_loss0.1396586537361145.pypots
2024-05-25 00:52:08 [INFO]: Epoch 019 - training loss: 0.1785, validation loss: 0.1347
2024-05-25 00:52:08 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch19_loss0.1347211107611656.pypots
2024-05-25 00:52:25 [INFO]: Epoch 020 - training loss: 0.1372, validation loss: 0.1344
2024-05-25 00:52:25 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch20_loss0.13436608090996743.pypots
2024-05-25 00:52:41 [INFO]: Epoch 021 - training loss: 0.1545, validation loss: 0.1370
2024-05-25 00:52:41 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch21_loss0.13697577342391015.pypots
2024-05-25 00:52:58 [INFO]: Epoch 022 - training loss: 0.1429, validation loss: 0.1349
2024-05-25 00:52:58 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch22_loss0.13493763282895088.pypots
2024-05-25 00:53:15 [INFO]: Epoch 023 - training loss: 0.1517, validation loss: 0.1371
2024-05-25 00:53:15 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch23_loss0.13706109076738357.pypots
2024-05-25 00:53:32 [INFO]: Epoch 024 - training loss: 0.1532, validation loss: 0.1291
2024-05-25 00:53:32 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch24_loss0.12905815318226815.pypots
2024-05-25 00:53:49 [INFO]: Epoch 025 - training loss: 0.1538, validation loss: 0.1333
2024-05-25 00:53:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch25_loss0.13329047262668609.pypots
2024-05-25 00:54:06 [INFO]: Epoch 026 - training loss: 0.1506, validation loss: 0.1327
2024-05-25 00:54:06 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch26_loss0.13265760838985444.pypots
2024-05-25 00:54:23 [INFO]: Epoch 027 - training loss: 0.1559, validation loss: 0.1340
2024-05-25 00:54:23 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch27_loss0.13404315635561942.pypots
2024-05-25 00:54:39 [INFO]: Epoch 028 - training loss: 0.1511, validation loss: 0.1368
2024-05-25 00:54:39 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch28_loss0.1368145689368248.pypots
2024-05-25 00:54:56 [INFO]: Epoch 029 - training loss: 0.1315, validation loss: 0.1333
2024-05-25 00:54:56 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch29_loss0.1333344928920269.pypots
2024-05-25 00:55:13 [INFO]: Epoch 030 - training loss: 0.1545, validation loss: 0.1273
2024-05-25 00:55:13 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch30_loss0.12732906639575958.pypots
2024-05-25 00:55:30 [INFO]: Epoch 031 - training loss: 0.1421, validation loss: 0.1283
2024-05-25 00:55:30 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch31_loss0.12827879786491395.pypots
2024-05-25 00:55:47 [INFO]: Epoch 032 - training loss: 0.1344, validation loss: 0.1294
2024-05-25 00:55:47 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch32_loss0.1293836861848831.pypots
2024-05-25 00:56:04 [INFO]: Epoch 033 - training loss: 0.1297, validation loss: 0.1237
2024-05-25 00:56:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch33_loss0.12369214221835137.pypots
2024-05-25 00:56:21 [INFO]: Epoch 034 - training loss: 0.1320, validation loss: 0.1221
2024-05-25 00:56:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch34_loss0.12206244468688965.pypots
2024-05-25 00:56:37 [INFO]: Epoch 035 - training loss: 0.1256, validation loss: 0.1289
2024-05-25 00:56:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch35_loss0.12890820056200028.pypots
2024-05-25 00:56:54 [INFO]: Epoch 036 - training loss: 0.1538, validation loss: 0.1225
2024-05-25 00:56:54 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch36_loss0.12250168845057488.pypots
2024-05-25 00:57:11 [INFO]: Epoch 037 - training loss: 0.1401, validation loss: 0.1228
2024-05-25 00:57:11 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch37_loss0.12281146124005318.pypots
2024-05-25 00:57:28 [INFO]: Epoch 038 - training loss: 0.1422, validation loss: 0.1211
2024-05-25 00:57:28 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch38_loss0.1210742674767971.pypots
2024-05-25 00:57:45 [INFO]: Epoch 039 - training loss: 0.1214, validation loss: 0.1202
2024-05-25 00:57:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch39_loss0.12015462219715119.pypots
2024-05-25 00:58:02 [INFO]: Epoch 040 - training loss: 0.1495, validation loss: 0.1196
2024-05-25 00:58:02 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch40_loss0.11963614150881767.pypots
2024-05-25 00:58:19 [INFO]: Epoch 041 - training loss: 0.1396, validation loss: 0.1175
2024-05-25 00:58:19 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch41_loss0.1175079196691513.pypots
2024-05-25 00:58:35 [INFO]: Epoch 042 - training loss: 0.1193, validation loss: 0.1189
2024-05-25 00:58:35 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch42_loss0.1188523828983307.pypots
2024-05-25 00:58:52 [INFO]: Epoch 043 - training loss: 0.1278, validation loss: 0.1169
2024-05-25 00:58:52 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch43_loss0.11686920747160912.pypots
2024-05-25 00:59:09 [INFO]: Epoch 044 - training loss: 0.1257, validation loss: 0.1235
2024-05-25 00:59:09 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch44_loss0.12353154346346855.pypots
2024-05-25 00:59:26 [INFO]: Epoch 045 - training loss: 0.1234, validation loss: 0.1173
2024-05-25 00:59:26 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch45_loss0.11730730533599854.pypots
2024-05-25 00:59:43 [INFO]: Epoch 046 - training loss: 0.1222, validation loss: 0.1160
2024-05-25 00:59:43 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch46_loss0.11595831662416459.pypots
2024-05-25 01:00:00 [INFO]: Epoch 047 - training loss: 0.1368, validation loss: 0.1232
2024-05-25 01:00:00 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch47_loss0.12315188273787499.pypots
2024-05-25 01:00:17 [INFO]: Epoch 048 - training loss: 0.1302, validation loss: 0.1151
2024-05-25 01:00:17 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch48_loss0.11507114619016648.pypots
2024-05-25 01:00:34 [INFO]: Epoch 049 - training loss: 0.1302, validation loss: 0.1147
2024-05-25 01:00:34 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch49_loss0.11470473334193229.pypots
2024-05-25 01:00:51 [INFO]: Epoch 050 - training loss: 0.1279, validation loss: 0.1149
2024-05-25 01:00:51 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch50_loss0.11485519632697105.pypots
2024-05-25 01:01:07 [INFO]: Epoch 051 - training loss: 0.1393, validation loss: 0.1101
2024-05-25 01:01:07 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch51_loss0.11010276079177857.pypots
2024-05-25 01:01:24 [INFO]: Epoch 052 - training loss: 0.1341, validation loss: 0.1126
2024-05-25 01:01:24 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch52_loss0.11258070021867753.pypots
2024-05-25 01:01:41 [INFO]: Epoch 053 - training loss: 0.1274, validation loss: 0.1106
2024-05-25 01:01:41 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch53_loss0.11064989268779754.pypots
2024-05-25 01:01:58 [INFO]: Epoch 054 - training loss: 0.1181, validation loss: 0.1154
2024-05-25 01:01:58 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch54_loss0.11541344299912452.pypots
2024-05-25 01:02:15 [INFO]: Epoch 055 - training loss: 0.1195, validation loss: 0.1120
2024-05-25 01:02:15 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch55_loss0.11195137649774552.pypots
2024-05-25 01:02:32 [INFO]: Epoch 056 - training loss: 0.1189, validation loss: 0.1105
2024-05-25 01:02:32 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch56_loss0.11054113060235977.pypots
2024-05-25 01:02:49 [INFO]: Epoch 057 - training loss: 0.1160, validation loss: 0.1138
2024-05-25 01:02:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch57_loss0.11382684409618378.pypots
2024-05-25 01:03:06 [INFO]: Epoch 058 - training loss: 0.1103, validation loss: 0.1120
2024-05-25 01:03:06 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch58_loss0.1119616411626339.pypots
2024-05-25 01:03:22 [INFO]: Epoch 059 - training loss: 0.1249, validation loss: 0.1093
2024-05-25 01:03:22 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch59_loss0.1092713713645935.pypots
2024-05-25 01:03:39 [INFO]: Epoch 060 - training loss: 0.1259, validation loss: 0.1125
2024-05-25 01:03:39 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch60_loss0.1125114917755127.pypots
2024-05-25 01:03:56 [INFO]: Epoch 061 - training loss: 0.1245, validation loss: 0.1107
2024-05-25 01:03:56 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch61_loss0.11072190925478935.pypots
2024-05-25 01:04:13 [INFO]: Epoch 062 - training loss: 0.1319, validation loss: 0.1103
2024-05-25 01:04:13 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch62_loss0.11028911620378494.pypots
2024-05-25 01:04:30 [INFO]: Epoch 063 - training loss: 0.1168, validation loss: 0.1073
2024-05-25 01:04:30 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch63_loss0.10731672942638397.pypots
2024-05-25 01:04:47 [INFO]: Epoch 064 - training loss: 0.1241, validation loss: 0.1112
2024-05-25 01:04:47 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch64_loss0.11124300733208656.pypots
2024-05-25 01:05:04 [INFO]: Epoch 065 - training loss: 0.1277, validation loss: 0.1104
2024-05-25 01:05:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch65_loss0.11037060096859933.pypots
2024-05-25 01:05:21 [INFO]: Epoch 066 - training loss: 0.1204, validation loss: 0.1071
2024-05-25 01:05:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch66_loss0.10711671859025955.pypots
2024-05-25 01:05:37 [INFO]: Epoch 067 - training loss: 0.1232, validation loss: 0.1067
2024-05-25 01:05:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch67_loss0.10665819048881531.pypots
2024-05-25 01:05:54 [INFO]: Epoch 068 - training loss: 0.1160, validation loss: 0.1066
2024-05-25 01:05:54 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch68_loss0.10663784816861152.pypots
2024-05-25 01:06:11 [INFO]: Epoch 069 - training loss: 0.1161, validation loss: 0.1103
2024-05-25 01:06:11 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch69_loss0.11025076657533646.pypots
2024-05-25 01:06:28 [INFO]: Epoch 070 - training loss: 0.1121, validation loss: 0.1044
2024-05-25 01:06:28 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch70_loss0.10444900691509247.pypots
2024-05-25 01:06:45 [INFO]: Epoch 071 - training loss: 0.1072, validation loss: 0.1081
2024-05-25 01:06:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch71_loss0.10809800177812576.pypots
2024-05-25 01:07:02 [INFO]: Epoch 072 - training loss: 0.1078, validation loss: 0.1101
2024-05-25 01:07:02 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch72_loss0.11008370965719223.pypots
2024-05-25 01:07:19 [INFO]: Epoch 073 - training loss: 0.1266, validation loss: 0.1061
2024-05-25 01:07:19 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch73_loss0.10613341331481933.pypots
2024-05-25 01:07:36 [INFO]: Epoch 074 - training loss: 0.1203, validation loss: 0.1057
2024-05-25 01:07:36 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch74_loss0.10574938952922822.pypots
2024-05-25 01:07:52 [INFO]: Epoch 075 - training loss: 0.1243, validation loss: 0.1098
2024-05-25 01:07:52 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch75_loss0.10982621908187866.pypots
2024-05-25 01:08:09 [INFO]: Epoch 076 - training loss: 0.1130, validation loss: 0.1061
2024-05-25 01:08:09 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch76_loss0.10613326728343964.pypots
2024-05-25 01:08:26 [INFO]: Epoch 077 - training loss: 0.1242, validation loss: 0.1069
2024-05-25 01:08:26 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch77_loss0.1068931370973587.pypots
2024-05-25 01:08:43 [INFO]: Epoch 078 - training loss: 0.1155, validation loss: 0.1063
2024-05-25 01:08:43 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch78_loss0.10627945959568023.pypots
2024-05-25 01:09:00 [INFO]: Epoch 079 - training loss: 0.1116, validation loss: 0.1049
2024-05-25 01:09:00 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch79_loss0.10487848594784736.pypots
2024-05-25 01:09:17 [INFO]: Epoch 080 - training loss: 0.1230, validation loss: 0.1046
2024-05-25 01:09:17 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI_epoch80_loss0.10455357059836387.pypots
2024-05-25 01:09:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:09:17 [INFO]: Finished training. The best model is from epoch#70.
2024-05-25 01:09:17 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T004647/CSDI.pypots
2024-05-25 01:11:38 [INFO]: CSDI on Air-Quality: MAE=0.1036, MSE=0.1151
2024-05-25 01:11:38 [INFO]: Successfully saved to augmentation_saved_results/round_0/CSDI_air_quality/imputation.pkl
2024-05-25 01:11:38 [INFO]: Using the given device: cuda:0
2024-05-25 01:11:38 [INFO]: Model files will be saved to augmentation_saved_results/round_0/GPVAE_air_quality/20240525_T011138
2024-05-25 01:11:38 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/GPVAE_air_quality/20240525_T011138/tensorboard
2024-05-25 01:11:38 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 01:11:38 [INFO]: Epoch 001 - training loss: 63697.0437, validation loss: 0.6852
2024-05-25 01:11:38 [INFO]: Epoch 002 - training loss: 42069.1010, validation loss: 0.6131
2024-05-25 01:11:39 [INFO]: Epoch 003 - training loss: 41756.1706, validation loss: 0.5450
2024-05-25 01:11:39 [INFO]: Epoch 004 - training loss: 41617.7159, validation loss: 0.4934
2024-05-25 01:11:39 [INFO]: Epoch 005 - training loss: 41589.8912, validation loss: 0.4954
2024-05-25 01:11:40 [INFO]: Epoch 006 - training loss: 41519.8401, validation loss: 0.4279
2024-05-25 01:11:40 [INFO]: Epoch 007 - training loss: 41452.7866, validation loss: 0.3975
2024-05-25 01:11:40 [INFO]: Epoch 008 - training loss: 41418.4462, validation loss: 0.3823
2024-05-25 01:11:41 [INFO]: Epoch 009 - training loss: 41383.7652, validation loss: 0.3694
2024-05-25 01:11:41 [INFO]: Epoch 010 - training loss: 41369.1884, validation loss: 0.3602
2024-05-25 01:11:41 [INFO]: Epoch 011 - training loss: 41341.8478, validation loss: 0.3537
2024-05-25 01:11:42 [INFO]: Epoch 012 - training loss: 41321.2807, validation loss: 0.3507
2024-05-25 01:11:42 [INFO]: Epoch 013 - training loss: 41321.4488, validation loss: 0.4187
2024-05-25 01:11:42 [INFO]: Epoch 014 - training loss: 41360.8845, validation loss: 0.3513
2024-05-25 01:11:43 [INFO]: Epoch 015 - training loss: 41341.8468, validation loss: 0.3533
2024-05-25 01:11:43 [INFO]: Epoch 016 - training loss: 41315.0392, validation loss: 0.3382
2024-05-25 01:11:43 [INFO]: Epoch 017 - training loss: 41289.2872, validation loss: 0.3200
2024-05-25 01:11:44 [INFO]: Epoch 018 - training loss: 41268.1787, validation loss: 0.3084
2024-05-25 01:11:44 [INFO]: Epoch 019 - training loss: 41259.6970, validation loss: 0.3366
2024-05-25 01:11:44 [INFO]: Epoch 020 - training loss: 41260.6076, validation loss: 0.3236
2024-05-25 01:11:44 [INFO]: Epoch 021 - training loss: 41244.8970, validation loss: 0.3195
2024-05-25 01:11:45 [INFO]: Epoch 022 - training loss: 41270.8315, validation loss: 0.3106
2024-05-25 01:11:45 [INFO]: Epoch 023 - training loss: 41247.0334, validation loss: 0.3026
2024-05-25 01:11:45 [INFO]: Epoch 024 - training loss: 41242.9123, validation loss: 0.3140
2024-05-25 01:11:46 [INFO]: Epoch 025 - training loss: 41230.7907, validation loss: 0.2977
2024-05-25 01:11:46 [INFO]: Epoch 026 - training loss: 41219.6312, validation loss: 0.2981
2024-05-25 01:11:46 [INFO]: Epoch 027 - training loss: 41218.8215, validation loss: 0.2940
2024-05-25 01:11:47 [INFO]: Epoch 028 - training loss: 41216.5667, validation loss: 0.2888
2024-05-25 01:11:47 [INFO]: Epoch 029 - training loss: 41220.6739, validation loss: 0.2896
2024-05-25 01:11:47 [INFO]: Epoch 030 - training loss: 41207.9222, validation loss: 0.2951
2024-05-25 01:11:48 [INFO]: Epoch 031 - training loss: 41227.7390, validation loss: 0.2942
2024-05-25 01:11:48 [INFO]: Epoch 032 - training loss: 41202.9779, validation loss: 0.2819
2024-05-25 01:11:48 [INFO]: Epoch 033 - training loss: 41199.0512, validation loss: 0.2851
2024-05-25 01:11:48 [INFO]: Epoch 034 - training loss: 41202.4899, validation loss: 0.2907
2024-05-25 01:11:49 [INFO]: Epoch 035 - training loss: 41229.6713, validation loss: 0.3418
2024-05-25 01:11:49 [INFO]: Epoch 036 - training loss: 41306.0045, validation loss: 0.3111
2024-05-25 01:11:49 [INFO]: Epoch 037 - training loss: 41264.6220, validation loss: 0.3089
2024-05-25 01:11:50 [INFO]: Epoch 038 - training loss: 41226.5612, validation loss: 0.2859
2024-05-25 01:11:50 [INFO]: Epoch 039 - training loss: 41209.9119, validation loss: 0.2778
2024-05-25 01:11:50 [INFO]: Epoch 040 - training loss: 41196.0278, validation loss: 0.2797
2024-05-25 01:11:51 [INFO]: Epoch 041 - training loss: 41181.6367, validation loss: 0.2774
2024-05-25 01:11:51 [INFO]: Epoch 042 - training loss: 41183.2763, validation loss: 0.2812
2024-05-25 01:11:51 [INFO]: Epoch 043 - training loss: 41190.3083, validation loss: 0.2712
2024-05-25 01:11:52 [INFO]: Epoch 044 - training loss: 41181.6567, validation loss: 0.2874
2024-05-25 01:11:52 [INFO]: Epoch 045 - training loss: 41186.9288, validation loss: 0.2889
2024-05-25 01:11:52 [INFO]: Epoch 046 - training loss: 41202.3902, validation loss: 0.2907
2024-05-25 01:11:53 [INFO]: Epoch 047 - training loss: 41216.3477, validation loss: 0.3021
2024-05-25 01:11:53 [INFO]: Epoch 048 - training loss: 41214.1845, validation loss: 0.2717
2024-05-25 01:11:53 [INFO]: Epoch 049 - training loss: 41178.4596, validation loss: 0.2791
2024-05-25 01:11:54 [INFO]: Epoch 050 - training loss: 41185.5726, validation loss: 0.2882
2024-05-25 01:11:54 [INFO]: Epoch 051 - training loss: 41187.1975, validation loss: 0.2995
2024-05-25 01:11:54 [INFO]: Epoch 052 - training loss: 41183.9219, validation loss: 0.3066
2024-05-25 01:11:54 [INFO]: Epoch 053 - training loss: 41178.2891, validation loss: 0.2804
2024-05-25 01:11:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:11:54 [INFO]: Finished training. The best model is from epoch#43.
2024-05-25 01:11:55 [INFO]: Saved the model to augmentation_saved_results/round_0/GPVAE_air_quality/20240525_T011138/GPVAE.pypots
2024-05-25 01:11:55 [INFO]: GP-VAE on Air-Quality: MAE=0.2818, MSE=0.2243
2024-05-25 01:11:55 [INFO]: Successfully saved to augmentation_saved_results/round_0/GPVAE_air_quality/imputation.pkl
2024-05-25 01:11:55 [INFO]: Using the given device: cuda:0
2024-05-25 01:11:55 [INFO]: Model files will be saved to augmentation_saved_results/round_0/USGAN_air_quality/20240525_T011155
2024-05-25 01:11:55 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/USGAN_air_quality/20240525_T011155/tensorboard
2024-05-25 01:11:55 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 01:12:00 [INFO]: Epoch 001 - generator training loss: 0.6004, discriminator training loss: 0.2878, validation loss: 0.5445
2024-05-25 01:12:04 [INFO]: Epoch 002 - generator training loss: 0.2900, discriminator training loss: 0.0677, validation loss: 0.4168
2024-05-25 01:12:08 [INFO]: Epoch 003 - generator training loss: 0.2200, discriminator training loss: 0.0632, validation loss: 0.3520
2024-05-25 01:12:12 [INFO]: Epoch 004 - generator training loss: 0.1803, discriminator training loss: 0.0624, validation loss: 0.3138
2024-05-25 01:12:16 [INFO]: Epoch 005 - generator training loss: 0.1576, discriminator training loss: 0.0619, validation loss: 0.2885
2024-05-25 01:12:20 [INFO]: Epoch 006 - generator training loss: 0.1394, discriminator training loss: 0.0614, validation loss: 0.2709
2024-05-25 01:12:24 [INFO]: Epoch 007 - generator training loss: 0.1289, discriminator training loss: 0.0606, validation loss: 0.2577
2024-05-25 01:12:28 [INFO]: Epoch 008 - generator training loss: 0.1163, discriminator training loss: 0.0600, validation loss: 0.2474
2024-05-25 01:12:32 [INFO]: Epoch 009 - generator training loss: 0.1076, discriminator training loss: 0.0593, validation loss: 0.2392
2024-05-25 01:12:36 [INFO]: Epoch 010 - generator training loss: 0.1008, discriminator training loss: 0.0585, validation loss: 0.2325
2024-05-25 01:12:40 [INFO]: Epoch 011 - generator training loss: 0.0965, discriminator training loss: 0.0578, validation loss: 0.2254
2024-05-25 01:12:44 [INFO]: Epoch 012 - generator training loss: 0.0921, discriminator training loss: 0.0567, validation loss: 0.2209
2024-05-25 01:12:48 [INFO]: Epoch 013 - generator training loss: 0.0858, discriminator training loss: 0.0559, validation loss: 0.2171
2024-05-25 01:12:52 [INFO]: Epoch 014 - generator training loss: 0.0822, discriminator training loss: 0.0544, validation loss: 0.2122
2024-05-25 01:12:56 [INFO]: Epoch 015 - generator training loss: 0.0810, discriminator training loss: 0.0523, validation loss: 0.2094
2024-05-25 01:13:00 [INFO]: Epoch 016 - generator training loss: 0.0775, discriminator training loss: 0.0510, validation loss: 0.2066
2024-05-25 01:13:04 [INFO]: Epoch 017 - generator training loss: 0.0770, discriminator training loss: 0.0489, validation loss: 0.2036
2024-05-25 01:13:09 [INFO]: Epoch 018 - generator training loss: 0.0743, discriminator training loss: 0.0482, validation loss: 0.2016
2024-05-25 01:13:13 [INFO]: Epoch 019 - generator training loss: 0.0735, discriminator training loss: 0.0465, validation loss: 0.1986
2024-05-25 01:13:17 [INFO]: Epoch 020 - generator training loss: 0.0715, discriminator training loss: 0.0455, validation loss: 0.1968
2024-05-25 01:13:21 [INFO]: Epoch 021 - generator training loss: 0.0692, discriminator training loss: 0.0448, validation loss: 0.1946
2024-05-25 01:13:25 [INFO]: Epoch 022 - generator training loss: 0.0699, discriminator training loss: 0.0436, validation loss: 0.1924
2024-05-25 01:13:29 [INFO]: Epoch 023 - generator training loss: 0.0655, discriminator training loss: 0.0435, validation loss: 0.1907
2024-05-25 01:13:33 [INFO]: Epoch 024 - generator training loss: 0.0659, discriminator training loss: 0.0424, validation loss: 0.1897
2024-05-25 01:13:37 [INFO]: Epoch 025 - generator training loss: 0.0638, discriminator training loss: 0.0420, validation loss: 0.1879
2024-05-25 01:13:41 [INFO]: Epoch 026 - generator training loss: 0.0624, discriminator training loss: 0.0412, validation loss: 0.1863
2024-05-25 01:13:45 [INFO]: Epoch 027 - generator training loss: 0.0610, discriminator training loss: 0.0407, validation loss: 0.1851
2024-05-25 01:13:49 [INFO]: Epoch 028 - generator training loss: 0.0636, discriminator training loss: 0.0399, validation loss: 0.1840
2024-05-25 01:13:53 [INFO]: Epoch 029 - generator training loss: 0.0609, discriminator training loss: 0.0388, validation loss: 0.1832
2024-05-25 01:13:57 [INFO]: Epoch 030 - generator training loss: 0.0609, discriminator training loss: 0.0377, validation loss: 0.1819
2024-05-25 01:14:01 [INFO]: Epoch 031 - generator training loss: 0.0589, discriminator training loss: 0.0370, validation loss: 0.1809
2024-05-25 01:14:05 [INFO]: Epoch 032 - generator training loss: 0.0581, discriminator training loss: 0.0364, validation loss: 0.1807
2024-05-25 01:14:09 [INFO]: Epoch 033 - generator training loss: 0.0593, discriminator training loss: 0.0355, validation loss: 0.1786
2024-05-25 01:14:13 [INFO]: Epoch 034 - generator training loss: 0.0595, discriminator training loss: 0.0345, validation loss: 0.1781
2024-05-25 01:14:17 [INFO]: Epoch 035 - generator training loss: 0.0579, discriminator training loss: 0.0336, validation loss: 0.1779
2024-05-25 01:14:21 [INFO]: Epoch 036 - generator training loss: 0.0598, discriminator training loss: 0.0329, validation loss: 0.1770
2024-05-25 01:14:26 [INFO]: Epoch 037 - generator training loss: 0.0565, discriminator training loss: 0.0325, validation loss: 0.1764
2024-05-25 01:14:30 [INFO]: Epoch 038 - generator training loss: 0.0576, discriminator training loss: 0.0317, validation loss: 0.1752
2024-05-25 01:14:34 [INFO]: Epoch 039 - generator training loss: 0.0578, discriminator training loss: 0.0313, validation loss: 0.1749
2024-05-25 01:14:38 [INFO]: Epoch 040 - generator training loss: 0.0560, discriminator training loss: 0.0305, validation loss: 0.1741
2024-05-25 01:14:42 [INFO]: Epoch 041 - generator training loss: 0.0556, discriminator training loss: 0.0299, validation loss: 0.1735
2024-05-25 01:14:46 [INFO]: Epoch 042 - generator training loss: 0.0572, discriminator training loss: 0.0291, validation loss: 0.1730
2024-05-25 01:14:50 [INFO]: Epoch 043 - generator training loss: 0.0547, discriminator training loss: 0.0288, validation loss: 0.1720
2024-05-25 01:14:54 [INFO]: Epoch 044 - generator training loss: 0.0559, discriminator training loss: 0.0282, validation loss: 0.1713
2024-05-25 01:14:58 [INFO]: Epoch 045 - generator training loss: 0.0560, discriminator training loss: 0.0275, validation loss: 0.1705
2024-05-25 01:15:02 [INFO]: Epoch 046 - generator training loss: 0.0543, discriminator training loss: 0.0272, validation loss: 0.1700
2024-05-25 01:15:06 [INFO]: Epoch 047 - generator training loss: 0.0539, discriminator training loss: 0.0267, validation loss: 0.1698
2024-05-25 01:15:10 [INFO]: Epoch 048 - generator training loss: 0.0538, discriminator training loss: 0.0263, validation loss: 0.1688
2024-05-25 01:15:14 [INFO]: Epoch 049 - generator training loss: 0.0530, discriminator training loss: 0.0260, validation loss: 0.1680
2024-05-25 01:15:18 [INFO]: Epoch 050 - generator training loss: 0.0526, discriminator training loss: 0.0256, validation loss: 0.1672
2024-05-25 01:15:22 [INFO]: Epoch 051 - generator training loss: 0.0526, discriminator training loss: 0.0250, validation loss: 0.1674
2024-05-25 01:15:26 [INFO]: Epoch 052 - generator training loss: 0.0518, discriminator training loss: 0.0248, validation loss: 0.1669
2024-05-25 01:15:30 [INFO]: Epoch 053 - generator training loss: 0.0519, discriminator training loss: 0.0242, validation loss: 0.1651
2024-05-25 01:15:34 [INFO]: Epoch 054 - generator training loss: 0.0518, discriminator training loss: 0.0239, validation loss: 0.1658
2024-05-25 01:15:38 [INFO]: Epoch 055 - generator training loss: 0.0519, discriminator training loss: 0.0233, validation loss: 0.1658
2024-05-25 01:15:42 [INFO]: Epoch 056 - generator training loss: 0.0513, discriminator training loss: 0.0230, validation loss: 0.1652
2024-05-25 01:15:46 [INFO]: Epoch 057 - generator training loss: 0.0500, discriminator training loss: 0.0230, validation loss: 0.1639
2024-05-25 01:15:51 [INFO]: Epoch 058 - generator training loss: 0.0498, discriminator training loss: 0.0227, validation loss: 0.1630
2024-05-25 01:15:55 [INFO]: Epoch 059 - generator training loss: 0.0510, discriminator training loss: 0.0221, validation loss: 0.1625
2024-05-25 01:15:59 [INFO]: Epoch 060 - generator training loss: 0.0495, discriminator training loss: 0.0217, validation loss: 0.1617
2024-05-25 01:16:03 [INFO]: Epoch 061 - generator training loss: 0.0496, discriminator training loss: 0.0216, validation loss: 0.1613
2024-05-25 01:16:07 [INFO]: Epoch 062 - generator training loss: 0.0496, discriminator training loss: 0.0212, validation loss: 0.1607
2024-05-25 01:16:11 [INFO]: Epoch 063 - generator training loss: 0.0485, discriminator training loss: 0.0210, validation loss: 0.1602
2024-05-25 01:16:15 [INFO]: Epoch 064 - generator training loss: 0.0480, discriminator training loss: 0.0208, validation loss: 0.1599
2024-05-25 01:16:19 [INFO]: Epoch 065 - generator training loss: 0.0479, discriminator training loss: 0.0205, validation loss: 0.1597
2024-05-25 01:16:23 [INFO]: Epoch 066 - generator training loss: 0.0489, discriminator training loss: 0.0204, validation loss: 0.1593
2024-05-25 01:16:27 [INFO]: Epoch 067 - generator training loss: 0.0484, discriminator training loss: 0.0200, validation loss: 0.1592
2024-05-25 01:16:31 [INFO]: Epoch 068 - generator training loss: 0.0494, discriminator training loss: 0.0199, validation loss: 0.1585
2024-05-25 01:16:35 [INFO]: Epoch 069 - generator training loss: 0.0490, discriminator training loss: 0.0195, validation loss: 0.1589
2024-05-25 01:16:39 [INFO]: Epoch 070 - generator training loss: 0.0476, discriminator training loss: 0.0197, validation loss: 0.1580
2024-05-25 01:16:43 [INFO]: Epoch 071 - generator training loss: 0.0460, discriminator training loss: 0.0193, validation loss: 0.1581
2024-05-25 01:16:47 [INFO]: Epoch 072 - generator training loss: 0.0465, discriminator training loss: 0.0189, validation loss: 0.1570
2024-05-25 01:16:51 [INFO]: Epoch 073 - generator training loss: 0.0457, discriminator training loss: 0.0190, validation loss: 0.1566
2024-05-25 01:16:55 [INFO]: Epoch 074 - generator training loss: 0.0455, discriminator training loss: 0.0185, validation loss: 0.1568
2024-05-25 01:16:59 [INFO]: Epoch 075 - generator training loss: 0.0454, discriminator training loss: 0.0187, validation loss: 0.1565
2024-05-25 01:17:03 [INFO]: Epoch 076 - generator training loss: 0.0465, discriminator training loss: 0.0184, validation loss: 0.1555
2024-05-25 01:17:07 [INFO]: Epoch 077 - generator training loss: 0.0452, discriminator training loss: 0.0182, validation loss: 0.1563
2024-05-25 01:17:11 [INFO]: Epoch 078 - generator training loss: 0.0447, discriminator training loss: 0.0179, validation loss: 0.1558
2024-05-25 01:17:16 [INFO]: Epoch 079 - generator training loss: 0.0442, discriminator training loss: 0.0180, validation loss: 0.1552
2024-05-25 01:17:20 [INFO]: Epoch 080 - generator training loss: 0.0444, discriminator training loss: 0.0177, validation loss: 0.1553
2024-05-25 01:17:24 [INFO]: Epoch 081 - generator training loss: 0.0442, discriminator training loss: 0.0176, validation loss: 0.1543
2024-05-25 01:17:28 [INFO]: Epoch 082 - generator training loss: 0.0438, discriminator training loss: 0.0174, validation loss: 0.1538
2024-05-25 01:17:32 [INFO]: Epoch 083 - generator training loss: 0.0446, discriminator training loss: 0.0170, validation loss: 0.1539
2024-05-25 01:17:36 [INFO]: Epoch 084 - generator training loss: 0.0440, discriminator training loss: 0.0174, validation loss: 0.1535
2024-05-25 01:17:40 [INFO]: Epoch 085 - generator training loss: 0.0433, discriminator training loss: 0.0170, validation loss: 0.1537
2024-05-25 01:17:44 [INFO]: Epoch 086 - generator training loss: 0.0445, discriminator training loss: 0.0170, validation loss: 0.1531
2024-05-25 01:17:48 [INFO]: Epoch 087 - generator training loss: 0.0430, discriminator training loss: 0.0169, validation loss: 0.1532
2024-05-25 01:17:52 [INFO]: Epoch 088 - generator training loss: 0.0428, discriminator training loss: 0.0168, validation loss: 0.1527
2024-05-25 01:17:56 [INFO]: Epoch 089 - generator training loss: 0.0418, discriminator training loss: 0.0166, validation loss: 0.1530
2024-05-25 01:18:00 [INFO]: Epoch 090 - generator training loss: 0.0419, discriminator training loss: 0.0164, validation loss: 0.1522
2024-05-25 01:18:04 [INFO]: Epoch 091 - generator training loss: 0.0423, discriminator training loss: 0.0163, validation loss: 0.1523
2024-05-25 01:18:08 [INFO]: Epoch 092 - generator training loss: 0.0417, discriminator training loss: 0.0161, validation loss: 0.1520
2024-05-25 01:18:12 [INFO]: Epoch 093 - generator training loss: 0.0412, discriminator training loss: 0.0160, validation loss: 0.1515
2024-05-25 01:18:16 [INFO]: Epoch 094 - generator training loss: 0.0406, discriminator training loss: 0.0161, validation loss: 0.1519
2024-05-25 01:18:20 [INFO]: Epoch 095 - generator training loss: 0.0409, discriminator training loss: 0.0160, validation loss: 0.1521
2024-05-25 01:18:24 [INFO]: Epoch 096 - generator training loss: 0.0405, discriminator training loss: 0.0157, validation loss: 0.1511
2024-05-25 01:18:28 [INFO]: Epoch 097 - generator training loss: 0.0406, discriminator training loss: 0.0159, validation loss: 0.1511
2024-05-25 01:18:32 [INFO]: Epoch 098 - generator training loss: 0.0404, discriminator training loss: 0.0156, validation loss: 0.1506
2024-05-25 01:18:36 [INFO]: Epoch 099 - generator training loss: 0.0402, discriminator training loss: 0.0153, validation loss: 0.1509
2024-05-25 01:18:40 [INFO]: Epoch 100 - generator training loss: 0.0396, discriminator training loss: 0.0157, validation loss: 0.1507
2024-05-25 01:18:44 [INFO]: Epoch 101 - generator training loss: 0.0398, discriminator training loss: 0.0155, validation loss: 0.1510
2024-05-25 01:18:48 [INFO]: Epoch 102 - generator training loss: 0.0399, discriminator training loss: 0.0154, validation loss: 0.1501
2024-05-25 01:18:53 [INFO]: Epoch 103 - generator training loss: 0.0392, discriminator training loss: 0.0154, validation loss: 0.1499
2024-05-25 01:18:57 [INFO]: Epoch 104 - generator training loss: 0.0397, discriminator training loss: 0.0151, validation loss: 0.1505
2024-05-25 01:19:01 [INFO]: Epoch 105 - generator training loss: 0.0397, discriminator training loss: 0.0149, validation loss: 0.1497
2024-05-25 01:19:05 [INFO]: Epoch 106 - generator training loss: 0.0399, discriminator training loss: 0.0149, validation loss: 0.1490
2024-05-25 01:19:09 [INFO]: Epoch 107 - generator training loss: 0.0394, discriminator training loss: 0.0149, validation loss: 0.1487
2024-05-25 01:19:13 [INFO]: Epoch 108 - generator training loss: 0.0389, discriminator training loss: 0.0149, validation loss: 0.1499
2024-05-25 01:19:17 [INFO]: Epoch 109 - generator training loss: 0.0384, discriminator training loss: 0.0147, validation loss: 0.1495
2024-05-25 01:19:21 [INFO]: Epoch 110 - generator training loss: 0.0379, discriminator training loss: 0.0145, validation loss: 0.1493
2024-05-25 01:19:25 [INFO]: Epoch 111 - generator training loss: 0.0380, discriminator training loss: 0.0146, validation loss: 0.1490
2024-05-25 01:19:29 [INFO]: Epoch 112 - generator training loss: 0.0382, discriminator training loss: 0.0145, validation loss: 0.1488
2024-05-25 01:19:33 [INFO]: Epoch 113 - generator training loss: 0.0382, discriminator training loss: 0.0144, validation loss: 0.1484
2024-05-25 01:19:37 [INFO]: Epoch 114 - generator training loss: 0.0388, discriminator training loss: 0.0144, validation loss: 0.1489
2024-05-25 01:19:41 [INFO]: Epoch 115 - generator training loss: 0.0383, discriminator training loss: 0.0145, validation loss: 0.1483
2024-05-25 01:19:45 [INFO]: Epoch 116 - generator training loss: 0.0375, discriminator training loss: 0.0142, validation loss: 0.1489
2024-05-25 01:19:49 [INFO]: Epoch 117 - generator training loss: 0.0373, discriminator training loss: 0.0143, validation loss: 0.1483
2024-05-25 01:19:53 [INFO]: Epoch 118 - generator training loss: 0.0375, discriminator training loss: 0.0141, validation loss: 0.1480
2024-05-25 01:19:57 [INFO]: Epoch 119 - generator training loss: 0.0368, discriminator training loss: 0.0142, validation loss: 0.1478
2024-05-25 01:20:01 [INFO]: Epoch 120 - generator training loss: 0.0365, discriminator training loss: 0.0140, validation loss: 0.1487
2024-05-25 01:20:05 [INFO]: Epoch 121 - generator training loss: 0.0375, discriminator training loss: 0.0142, validation loss: 0.1485
2024-05-25 01:20:09 [INFO]: Epoch 122 - generator training loss: 0.0371, discriminator training loss: 0.0139, validation loss: 0.1480
2024-05-25 01:20:13 [INFO]: Epoch 123 - generator training loss: 0.0361, discriminator training loss: 0.0138, validation loss: 0.1479
2024-05-25 01:20:17 [INFO]: Epoch 124 - generator training loss: 0.0359, discriminator training loss: 0.0138, validation loss: 0.1474
2024-05-25 01:20:21 [INFO]: Epoch 125 - generator training loss: 0.0364, discriminator training loss: 0.0137, validation loss: 0.1477
2024-05-25 01:20:25 [INFO]: Epoch 126 - generator training loss: 0.0360, discriminator training loss: 0.0136, validation loss: 0.1471
2024-05-25 01:20:29 [INFO]: Epoch 127 - generator training loss: 0.0365, discriminator training loss: 0.0135, validation loss: 0.1474
2024-05-25 01:20:33 [INFO]: Epoch 128 - generator training loss: 0.0355, discriminator training loss: 0.0137, validation loss: 0.1474
2024-05-25 01:20:38 [INFO]: Epoch 129 - generator training loss: 0.0357, discriminator training loss: 0.0135, validation loss: 0.1494
2024-05-25 01:20:42 [INFO]: Epoch 130 - generator training loss: 0.0361, discriminator training loss: 0.0135, validation loss: 0.1463
2024-05-25 01:20:46 [INFO]: Epoch 131 - generator training loss: 0.0367, discriminator training loss: 0.0134, validation loss: 0.1502
2024-05-25 01:20:50 [INFO]: Epoch 132 - generator training loss: 0.0365, discriminator training loss: 0.0134, validation loss: 0.1475
2024-05-25 01:20:54 [INFO]: Epoch 133 - generator training loss: 0.0362, discriminator training loss: 0.0132, validation loss: 0.1482
2024-05-25 01:20:58 [INFO]: Epoch 134 - generator training loss: 0.0348, discriminator training loss: 0.0132, validation loss: 0.1467
2024-05-25 01:21:02 [INFO]: Epoch 135 - generator training loss: 0.0348, discriminator training loss: 0.0133, validation loss: 0.1477
2024-05-25 01:21:06 [INFO]: Epoch 136 - generator training loss: 0.0358, discriminator training loss: 0.0131, validation loss: 0.1476
2024-05-25 01:21:10 [INFO]: Epoch 137 - generator training loss: 0.0346, discriminator training loss: 0.0134, validation loss: 0.1469
2024-05-25 01:21:14 [INFO]: Epoch 138 - generator training loss: 0.0357, discriminator training loss: 0.0131, validation loss: 0.1467
2024-05-25 01:21:18 [INFO]: Epoch 139 - generator training loss: 0.0348, discriminator training loss: 0.0129, validation loss: 0.1471
2024-05-25 01:21:23 [INFO]: Epoch 140 - generator training loss: 0.0344, discriminator training loss: 0.0129, validation loss: 0.1461
2024-05-25 01:21:27 [INFO]: Epoch 141 - generator training loss: 0.0341, discriminator training loss: 0.0127, validation loss: 0.1460
2024-05-25 01:21:31 [INFO]: Epoch 142 - generator training loss: 0.0340, discriminator training loss: 0.0126, validation loss: 0.1461
2024-05-25 01:21:35 [INFO]: Epoch 143 - generator training loss: 0.0340, discriminator training loss: 0.0127, validation loss: 0.1468
2024-05-25 01:21:39 [INFO]: Epoch 144 - generator training loss: 0.0344, discriminator training loss: 0.0127, validation loss: 0.1469
2024-05-25 01:21:43 [INFO]: Epoch 145 - generator training loss: 0.0340, discriminator training loss: 0.0126, validation loss: 0.1460
2024-05-25 01:21:47 [INFO]: Epoch 146 - generator training loss: 0.0338, discriminator training loss: 0.0125, validation loss: 0.1474
2024-05-25 01:21:51 [INFO]: Epoch 147 - generator training loss: 0.0337, discriminator training loss: 0.0125, validation loss: 0.1461
2024-05-25 01:21:55 [INFO]: Epoch 148 - generator training loss: 0.0337, discriminator training loss: 0.0124, validation loss: 0.1455
2024-05-25 01:21:59 [INFO]: Epoch 149 - generator training loss: 0.0335, discriminator training loss: 0.0125, validation loss: 0.1461
2024-05-25 01:22:03 [INFO]: Epoch 150 - generator training loss: 0.0338, discriminator training loss: 0.0124, validation loss: 0.1452
2024-05-25 01:22:07 [INFO]: Epoch 151 - generator training loss: 0.0328, discriminator training loss: 0.0124, validation loss: 0.1452
2024-05-25 01:22:11 [INFO]: Epoch 152 - generator training loss: 0.0332, discriminator training loss: 0.0123, validation loss: 0.1451
2024-05-25 01:22:15 [INFO]: Epoch 153 - generator training loss: 0.0332, discriminator training loss: 0.0123, validation loss: 0.1452
2024-05-25 01:22:19 [INFO]: Epoch 154 - generator training loss: 0.0335, discriminator training loss: 0.0123, validation loss: 0.1454
2024-05-25 01:22:23 [INFO]: Epoch 155 - generator training loss: 0.0327, discriminator training loss: 0.0124, validation loss: 0.1455
2024-05-25 01:22:27 [INFO]: Epoch 156 - generator training loss: 0.0330, discriminator training loss: 0.0123, validation loss: 0.1459
2024-05-25 01:22:31 [INFO]: Epoch 157 - generator training loss: 0.0334, discriminator training loss: 0.0121, validation loss: 0.1457
2024-05-25 01:22:35 [INFO]: Epoch 158 - generator training loss: 0.0343, discriminator training loss: 0.0120, validation loss: 0.1477
2024-05-25 01:22:39 [INFO]: Epoch 159 - generator training loss: 0.0352, discriminator training loss: 0.0120, validation loss: 0.1476
2024-05-25 01:22:44 [INFO]: Epoch 160 - generator training loss: 0.0337, discriminator training loss: 0.0122, validation loss: 0.1444
2024-05-25 01:22:48 [INFO]: Epoch 161 - generator training loss: 0.0325, discriminator training loss: 0.0120, validation loss: 0.1452
2024-05-25 01:22:52 [INFO]: Epoch 162 - generator training loss: 0.0321, discriminator training loss: 0.0119, validation loss: 0.1448
2024-05-25 01:22:56 [INFO]: Epoch 163 - generator training loss: 0.0319, discriminator training loss: 0.0118, validation loss: 0.1450
2024-05-25 01:23:00 [INFO]: Epoch 164 - generator training loss: 0.0319, discriminator training loss: 0.0116, validation loss: 0.1460
2024-05-25 01:23:04 [INFO]: Epoch 165 - generator training loss: 0.0321, discriminator training loss: 0.0117, validation loss: 0.1449
2024-05-25 01:23:08 [INFO]: Epoch 166 - generator training loss: 0.0319, discriminator training loss: 0.0118, validation loss: 0.1441
2024-05-25 01:23:12 [INFO]: Epoch 167 - generator training loss: 0.0320, discriminator training loss: 0.0117, validation loss: 0.1441
2024-05-25 01:23:16 [INFO]: Epoch 168 - generator training loss: 0.0315, discriminator training loss: 0.0117, validation loss: 0.1453
2024-05-25 01:23:20 [INFO]: Epoch 169 - generator training loss: 0.0320, discriminator training loss: 0.0116, validation loss: 0.1453
2024-05-25 01:23:24 [INFO]: Epoch 170 - generator training loss: 0.0318, discriminator training loss: 0.0117, validation loss: 0.1452
2024-05-25 01:23:28 [INFO]: Epoch 171 - generator training loss: 0.0316, discriminator training loss: 0.0116, validation loss: 0.1445
2024-05-25 01:23:32 [INFO]: Epoch 172 - generator training loss: 0.0320, discriminator training loss: 0.0115, validation loss: 0.1454
2024-05-25 01:23:36 [INFO]: Epoch 173 - generator training loss: 0.0317, discriminator training loss: 0.0115, validation loss: 0.1460
2024-05-25 01:23:40 [INFO]: Epoch 174 - generator training loss: 0.0316, discriminator training loss: 0.0115, validation loss: 0.1454
2024-05-25 01:23:44 [INFO]: Epoch 175 - generator training loss: 0.0313, discriminator training loss: 0.0115, validation loss: 0.1444
2024-05-25 01:23:48 [INFO]: Epoch 176 - generator training loss: 0.0314, discriminator training loss: 0.0113, validation loss: 0.1451
2024-05-25 01:23:53 [INFO]: Epoch 177 - generator training loss: 0.0312, discriminator training loss: 0.0113, validation loss: 0.1451
2024-05-25 01:23:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:23:53 [INFO]: Finished training. The best model is from epoch#167.
2024-05-25 01:23:53 [INFO]: Saved the model to augmentation_saved_results/round_0/USGAN_air_quality/20240525_T011155/USGAN.pypots
2024-05-25 01:23:53 [INFO]: US-GAN on Air-Quality: MAE=0.1609, MSE=0.0997
2024-05-25 01:23:53 [INFO]: Successfully saved to augmentation_saved_results/round_0/USGAN_air_quality/imputation.pkl
2024-05-25 01:23:53 [INFO]: Using the given device: cuda:0
2024-05-25 01:23:53 [INFO]: Model files will be saved to augmentation_saved_results/round_0/BRITS_air_quality/20240525_T012353
2024-05-25 01:23:53 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/BRITS_air_quality/20240525_T012353/tensorboard
2024-05-25 01:23:53 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 01:23:57 [INFO]: Epoch 001 - training loss: 1.4088, validation loss: 0.9651
2024-05-25 01:24:00 [INFO]: Epoch 002 - training loss: 1.1346, validation loss: 0.7202
2024-05-25 01:24:02 [INFO]: Epoch 003 - training loss: 0.9403, validation loss: 0.6086
2024-05-25 01:24:05 [INFO]: Epoch 004 - training loss: 0.8286, validation loss: 0.5422
2024-05-25 01:24:08 [INFO]: Epoch 005 - training loss: 0.7542, validation loss: 0.4967
2024-05-25 01:24:11 [INFO]: Epoch 006 - training loss: 0.6989, validation loss: 0.4598
2024-05-25 01:24:13 [INFO]: Epoch 007 - training loss: 0.6553, validation loss: 0.4324
2024-05-25 01:24:16 [INFO]: Epoch 008 - training loss: 0.6220, validation loss: 0.4093
2024-05-25 01:24:19 [INFO]: Epoch 009 - training loss: 0.5954, validation loss: 0.3896
2024-05-25 01:24:22 [INFO]: Epoch 010 - training loss: 0.5722, validation loss: 0.3745
2024-05-25 01:24:25 [INFO]: Epoch 011 - training loss: 0.5560, validation loss: 0.3620
2024-05-25 01:24:27 [INFO]: Epoch 012 - training loss: 0.5395, validation loss: 0.3504
2024-05-25 01:24:30 [INFO]: Epoch 013 - training loss: 0.5265, validation loss: 0.3411
2024-05-25 01:24:33 [INFO]: Epoch 014 - training loss: 0.5142, validation loss: 0.3327
2024-05-25 01:24:36 [INFO]: Epoch 015 - training loss: 0.5038, validation loss: 0.3259
2024-05-25 01:24:38 [INFO]: Epoch 016 - training loss: 0.4934, validation loss: 0.3193
2024-05-25 01:24:41 [INFO]: Epoch 017 - training loss: 0.4853, validation loss: 0.3136
2024-05-25 01:24:44 [INFO]: Epoch 018 - training loss: 0.4759, validation loss: 0.3080
2024-05-25 01:24:47 [INFO]: Epoch 019 - training loss: 0.4689, validation loss: 0.3034
2024-05-25 01:24:49 [INFO]: Epoch 020 - training loss: 0.4625, validation loss: 0.2988
2024-05-25 01:24:52 [INFO]: Epoch 021 - training loss: 0.4550, validation loss: 0.2944
2024-05-25 01:24:55 [INFO]: Epoch 022 - training loss: 0.4479, validation loss: 0.2897
2024-05-25 01:24:58 [INFO]: Epoch 023 - training loss: 0.4418, validation loss: 0.2862
2024-05-25 01:25:01 [INFO]: Epoch 024 - training loss: 0.4356, validation loss: 0.2824
2024-05-25 01:25:03 [INFO]: Epoch 025 - training loss: 0.4300, validation loss: 0.2790
2024-05-25 01:25:06 [INFO]: Epoch 026 - training loss: 0.4250, validation loss: 0.2760
2024-05-25 01:25:09 [INFO]: Epoch 027 - training loss: 0.4200, validation loss: 0.2723
2024-05-25 01:25:12 [INFO]: Epoch 028 - training loss: 0.4140, validation loss: 0.2691
2024-05-25 01:25:14 [INFO]: Epoch 029 - training loss: 0.4091, validation loss: 0.2662
2024-05-25 01:25:17 [INFO]: Epoch 030 - training loss: 0.4049, validation loss: 0.2632
2024-05-25 01:25:20 [INFO]: Epoch 031 - training loss: 0.4003, validation loss: 0.2608
2024-05-25 01:25:23 [INFO]: Epoch 032 - training loss: 0.3961, validation loss: 0.2573
2024-05-25 01:25:26 [INFO]: Epoch 033 - training loss: 0.3916, validation loss: 0.2545
2024-05-25 01:25:28 [INFO]: Epoch 034 - training loss: 0.3891, validation loss: 0.2526
2024-05-25 01:25:31 [INFO]: Epoch 035 - training loss: 0.3845, validation loss: 0.2497
2024-05-25 01:25:34 [INFO]: Epoch 036 - training loss: 0.3806, validation loss: 0.2470
2024-05-25 01:25:37 [INFO]: Epoch 037 - training loss: 0.3770, validation loss: 0.2443
2024-05-25 01:25:39 [INFO]: Epoch 038 - training loss: 0.3743, validation loss: 0.2423
2024-05-25 01:25:42 [INFO]: Epoch 039 - training loss: 0.3701, validation loss: 0.2402
2024-05-25 01:25:45 [INFO]: Epoch 040 - training loss: 0.3664, validation loss: 0.2386
2024-05-25 01:25:48 [INFO]: Epoch 041 - training loss: 0.3643, validation loss: 0.2364
2024-05-25 01:25:50 [INFO]: Epoch 042 - training loss: 0.3606, validation loss: 0.2348
2024-05-25 01:25:53 [INFO]: Epoch 043 - training loss: 0.3576, validation loss: 0.2333
2024-05-25 01:25:56 [INFO]: Epoch 044 - training loss: 0.3548, validation loss: 0.2321
2024-05-25 01:25:59 [INFO]: Epoch 045 - training loss: 0.3518, validation loss: 0.2307
2024-05-25 01:26:02 [INFO]: Epoch 046 - training loss: 0.3496, validation loss: 0.2296
2024-05-25 01:26:04 [INFO]: Epoch 047 - training loss: 0.3469, validation loss: 0.2285
2024-05-25 01:26:07 [INFO]: Epoch 048 - training loss: 0.3441, validation loss: 0.2274
2024-05-25 01:26:10 [INFO]: Epoch 049 - training loss: 0.3412, validation loss: 0.2265
2024-05-25 01:26:13 [INFO]: Epoch 050 - training loss: 0.3393, validation loss: 0.2260
2024-05-25 01:26:15 [INFO]: Epoch 051 - training loss: 0.3375, validation loss: 0.2249
2024-05-25 01:26:18 [INFO]: Epoch 052 - training loss: 0.3350, validation loss: 0.2244
2024-05-25 01:26:21 [INFO]: Epoch 053 - training loss: 0.3322, validation loss: 0.2237
2024-05-25 01:26:24 [INFO]: Epoch 054 - training loss: 0.3307, validation loss: 0.2231
2024-05-25 01:26:26 [INFO]: Epoch 055 - training loss: 0.3283, validation loss: 0.2224
2024-05-25 01:26:29 [INFO]: Epoch 056 - training loss: 0.3268, validation loss: 0.2219
2024-05-25 01:26:32 [INFO]: Epoch 057 - training loss: 0.3252, validation loss: 0.2214
2024-05-25 01:26:35 [INFO]: Epoch 058 - training loss: 0.3230, validation loss: 0.2209
2024-05-25 01:26:38 [INFO]: Epoch 059 - training loss: 0.3217, validation loss: 0.2204
2024-05-25 01:26:40 [INFO]: Epoch 060 - training loss: 0.3193, validation loss: 0.2200
2024-05-25 01:26:43 [INFO]: Epoch 061 - training loss: 0.3176, validation loss: 0.2196
2024-05-25 01:26:46 [INFO]: Epoch 062 - training loss: 0.3161, validation loss: 0.2191
2024-05-25 01:26:49 [INFO]: Epoch 063 - training loss: 0.3153, validation loss: 0.2185
2024-05-25 01:26:51 [INFO]: Epoch 064 - training loss: 0.3133, validation loss: 0.2179
2024-05-25 01:26:54 [INFO]: Epoch 065 - training loss: 0.3131, validation loss: 0.2177
2024-05-25 01:26:57 [INFO]: Epoch 066 - training loss: 0.3108, validation loss: 0.2169
2024-05-25 01:27:00 [INFO]: Epoch 067 - training loss: 0.3090, validation loss: 0.2168
2024-05-25 01:27:02 [INFO]: Epoch 068 - training loss: 0.3080, validation loss: 0.2160
2024-05-25 01:27:05 [INFO]: Epoch 069 - training loss: 0.3075, validation loss: 0.2157
2024-05-25 01:27:08 [INFO]: Epoch 070 - training loss: 0.3062, validation loss: 0.2155
2024-05-25 01:27:11 [INFO]: Epoch 071 - training loss: 0.3049, validation loss: 0.2148
2024-05-25 01:27:14 [INFO]: Epoch 072 - training loss: 0.3033, validation loss: 0.2140
2024-05-25 01:27:16 [INFO]: Epoch 073 - training loss: 0.3026, validation loss: 0.2135
2024-05-25 01:27:19 [INFO]: Epoch 074 - training loss: 0.3007, validation loss: 0.2134
2024-05-25 01:27:22 [INFO]: Epoch 075 - training loss: 0.3008, validation loss: 0.2126
2024-05-25 01:27:25 [INFO]: Epoch 076 - training loss: 0.2990, validation loss: 0.2119
2024-05-25 01:27:28 [INFO]: Epoch 077 - training loss: 0.2981, validation loss: 0.2115
2024-05-25 01:27:30 [INFO]: Epoch 078 - training loss: 0.2966, validation loss: 0.2112
2024-05-25 01:27:33 [INFO]: Epoch 079 - training loss: 0.2962, validation loss: 0.2105
2024-05-25 01:27:36 [INFO]: Epoch 080 - training loss: 0.2952, validation loss: 0.2100
2024-05-25 01:27:39 [INFO]: Epoch 081 - training loss: 0.2941, validation loss: 0.2095
2024-05-25 01:27:41 [INFO]: Epoch 082 - training loss: 0.2928, validation loss: 0.2089
2024-05-25 01:27:44 [INFO]: Epoch 083 - training loss: 0.2919, validation loss: 0.2083
2024-05-25 01:27:47 [INFO]: Epoch 084 - training loss: 0.2911, validation loss: 0.2079
2024-05-25 01:27:50 [INFO]: Epoch 085 - training loss: 0.2907, validation loss: 0.2074
2024-05-25 01:27:52 [INFO]: Epoch 086 - training loss: 0.2895, validation loss: 0.2069
2024-05-25 01:27:55 [INFO]: Epoch 087 - training loss: 0.2891, validation loss: 0.2064
2024-05-25 01:27:58 [INFO]: Epoch 088 - training loss: 0.2883, validation loss: 0.2057
2024-05-25 01:28:01 [INFO]: Epoch 089 - training loss: 0.2871, validation loss: 0.2054
2024-05-25 01:28:04 [INFO]: Epoch 090 - training loss: 0.2870, validation loss: 0.2048
2024-05-25 01:28:06 [INFO]: Epoch 091 - training loss: 0.2863, validation loss: 0.2042
2024-05-25 01:28:09 [INFO]: Epoch 092 - training loss: 0.2849, validation loss: 0.2037
2024-05-25 01:28:12 [INFO]: Epoch 093 - training loss: 0.2845, validation loss: 0.2033
2024-05-25 01:28:15 [INFO]: Epoch 094 - training loss: 0.2847, validation loss: 0.2029
2024-05-25 01:28:17 [INFO]: Epoch 095 - training loss: 0.2830, validation loss: 0.2021
2024-05-25 01:28:20 [INFO]: Epoch 096 - training loss: 0.2829, validation loss: 0.2018
2024-05-25 01:28:23 [INFO]: Epoch 097 - training loss: 0.2818, validation loss: 0.2012
2024-05-25 01:28:26 [INFO]: Epoch 098 - training loss: 0.2814, validation loss: 0.2008
2024-05-25 01:28:28 [INFO]: Epoch 099 - training loss: 0.2803, validation loss: 0.2004
2024-05-25 01:28:31 [INFO]: Epoch 100 - training loss: 0.2799, validation loss: 0.1999
2024-05-25 01:28:34 [INFO]: Epoch 101 - training loss: 0.2793, validation loss: 0.1993
2024-05-25 01:28:37 [INFO]: Epoch 102 - training loss: 0.2785, validation loss: 0.1989
2024-05-25 01:28:39 [INFO]: Epoch 103 - training loss: 0.2776, validation loss: 0.1984
2024-05-25 01:28:42 [INFO]: Epoch 104 - training loss: 0.2771, validation loss: 0.1979
2024-05-25 01:28:45 [INFO]: Epoch 105 - training loss: 0.2764, validation loss: 0.1975
2024-05-25 01:28:48 [INFO]: Epoch 106 - training loss: 0.2766, validation loss: 0.1969
2024-05-25 01:28:51 [INFO]: Epoch 107 - training loss: 0.2756, validation loss: 0.1965
2024-05-25 01:28:53 [INFO]: Epoch 108 - training loss: 0.2752, validation loss: 0.1961
2024-05-25 01:28:56 [INFO]: Epoch 109 - training loss: 0.2740, validation loss: 0.1957
2024-05-25 01:28:59 [INFO]: Epoch 110 - training loss: 0.2737, validation loss: 0.1951
2024-05-25 01:29:02 [INFO]: Epoch 111 - training loss: 0.2727, validation loss: 0.1946
2024-05-25 01:29:04 [INFO]: Epoch 112 - training loss: 0.2730, validation loss: 0.1944
2024-05-25 01:29:07 [INFO]: Epoch 113 - training loss: 0.2721, validation loss: 0.1939
2024-05-25 01:29:10 [INFO]: Epoch 114 - training loss: 0.2714, validation loss: 0.1932
2024-05-25 01:29:13 [INFO]: Epoch 115 - training loss: 0.2714, validation loss: 0.1929
2024-05-25 01:29:15 [INFO]: Epoch 116 - training loss: 0.2706, validation loss: 0.1923
2024-05-25 01:29:18 [INFO]: Epoch 117 - training loss: 0.2699, validation loss: 0.1920
2024-05-25 01:29:21 [INFO]: Epoch 118 - training loss: 0.2692, validation loss: 0.1919
2024-05-25 01:29:24 [INFO]: Epoch 119 - training loss: 0.2695, validation loss: 0.1913
2024-05-25 01:29:27 [INFO]: Epoch 120 - training loss: 0.2688, validation loss: 0.1908
2024-05-25 01:29:29 [INFO]: Epoch 121 - training loss: 0.2687, validation loss: 0.1903
2024-05-25 01:29:32 [INFO]: Epoch 122 - training loss: 0.2681, validation loss: 0.1900
2024-05-25 01:29:35 [INFO]: Epoch 123 - training loss: 0.2668, validation loss: 0.1897
2024-05-25 01:29:38 [INFO]: Epoch 124 - training loss: 0.2665, validation loss: 0.1892
2024-05-25 01:29:40 [INFO]: Epoch 125 - training loss: 0.2661, validation loss: 0.1889
2024-05-25 01:29:43 [INFO]: Epoch 126 - training loss: 0.2657, validation loss: 0.1886
2024-05-25 01:29:46 [INFO]: Epoch 127 - training loss: 0.2656, validation loss: 0.1880
2024-05-25 01:29:49 [INFO]: Epoch 128 - training loss: 0.2651, validation loss: 0.1877
2024-05-25 01:29:51 [INFO]: Epoch 129 - training loss: 0.2649, validation loss: 0.1874
2024-05-25 01:29:54 [INFO]: Epoch 130 - training loss: 0.2637, validation loss: 0.1871
2024-05-25 01:29:57 [INFO]: Epoch 131 - training loss: 0.2638, validation loss: 0.1868
2024-05-25 01:30:00 [INFO]: Epoch 132 - training loss: 0.2634, validation loss: 0.1863
2024-05-25 01:30:02 [INFO]: Epoch 133 - training loss: 0.2629, validation loss: 0.1860
2024-05-25 01:30:05 [INFO]: Epoch 134 - training loss: 0.2628, validation loss: 0.1856
2024-05-25 01:30:08 [INFO]: Epoch 135 - training loss: 0.2619, validation loss: 0.1852
2024-05-25 01:30:11 [INFO]: Epoch 136 - training loss: 0.2611, validation loss: 0.1850
2024-05-25 01:30:13 [INFO]: Epoch 137 - training loss: 0.2615, validation loss: 0.1845
2024-05-25 01:30:16 [INFO]: Epoch 138 - training loss: 0.2609, validation loss: 0.1842
2024-05-25 01:30:19 [INFO]: Epoch 139 - training loss: 0.2602, validation loss: 0.1839
2024-05-25 01:30:22 [INFO]: Epoch 140 - training loss: 0.2604, validation loss: 0.1835
2024-05-25 01:30:25 [INFO]: Epoch 141 - training loss: 0.2601, validation loss: 0.1832
2024-05-25 01:30:27 [INFO]: Epoch 142 - training loss: 0.2595, validation loss: 0.1829
2024-05-25 01:30:30 [INFO]: Epoch 143 - training loss: 0.2591, validation loss: 0.1825
2024-05-25 01:30:33 [INFO]: Epoch 144 - training loss: 0.2585, validation loss: 0.1823
2024-05-25 01:30:36 [INFO]: Epoch 145 - training loss: 0.2584, validation loss: 0.1819
2024-05-25 01:30:38 [INFO]: Epoch 146 - training loss: 0.2573, validation loss: 0.1816
2024-05-25 01:30:41 [INFO]: Epoch 147 - training loss: 0.2582, validation loss: 0.1813
2024-05-25 01:30:44 [INFO]: Epoch 148 - training loss: 0.2576, validation loss: 0.1809
2024-05-25 01:30:47 [INFO]: Epoch 149 - training loss: 0.2570, validation loss: 0.1807
2024-05-25 01:30:50 [INFO]: Epoch 150 - training loss: 0.2562, validation loss: 0.1805
2024-05-25 01:30:52 [INFO]: Epoch 151 - training loss: 0.2572, validation loss: 0.1801
2024-05-25 01:30:55 [INFO]: Epoch 152 - training loss: 0.2555, validation loss: 0.1798
2024-05-25 01:30:58 [INFO]: Epoch 153 - training loss: 0.2554, validation loss: 0.1795
2024-05-25 01:31:01 [INFO]: Epoch 154 - training loss: 0.2552, validation loss: 0.1792
2024-05-25 01:31:04 [INFO]: Epoch 155 - training loss: 0.2554, validation loss: 0.1791
2024-05-25 01:31:06 [INFO]: Epoch 156 - training loss: 0.2547, validation loss: 0.1788
2024-05-25 01:31:09 [INFO]: Epoch 157 - training loss: 0.2544, validation loss: 0.1783
2024-05-25 01:31:12 [INFO]: Epoch 158 - training loss: 0.2538, validation loss: 0.1782
2024-05-25 01:31:15 [INFO]: Epoch 159 - training loss: 0.2543, validation loss: 0.1779
2024-05-25 01:31:18 [INFO]: Epoch 160 - training loss: 0.2540, validation loss: 0.1776
2024-05-25 01:31:20 [INFO]: Epoch 161 - training loss: 0.2526, validation loss: 0.1775
2024-05-25 01:31:23 [INFO]: Epoch 162 - training loss: 0.2532, validation loss: 0.1771
2024-05-25 01:31:26 [INFO]: Epoch 163 - training loss: 0.2523, validation loss: 0.1767
2024-05-25 01:31:29 [INFO]: Epoch 164 - training loss: 0.2526, validation loss: 0.1767
2024-05-25 01:31:31 [INFO]: Epoch 165 - training loss: 0.2521, validation loss: 0.1763
2024-05-25 01:31:34 [INFO]: Epoch 166 - training loss: 0.2517, validation loss: 0.1759
2024-05-25 01:31:37 [INFO]: Epoch 167 - training loss: 0.2515, validation loss: 0.1758
2024-05-25 01:31:40 [INFO]: Epoch 168 - training loss: 0.2514, validation loss: 0.1755
2024-05-25 01:31:43 [INFO]: Epoch 169 - training loss: 0.2515, validation loss: 0.1753
2024-05-25 01:31:45 [INFO]: Epoch 170 - training loss: 0.2507, validation loss: 0.1748
2024-05-25 01:31:48 [INFO]: Epoch 171 - training loss: 0.2503, validation loss: 0.1747
2024-05-25 01:31:51 [INFO]: Epoch 172 - training loss: 0.2502, validation loss: 0.1746
2024-05-25 01:31:54 [INFO]: Epoch 173 - training loss: 0.2504, validation loss: 0.1742
2024-05-25 01:31:56 [INFO]: Epoch 174 - training loss: 0.2495, validation loss: 0.1740
2024-05-25 01:31:59 [INFO]: Epoch 175 - training loss: 0.2497, validation loss: 0.1739
2024-05-25 01:32:02 [INFO]: Epoch 176 - training loss: 0.2493, validation loss: 0.1737
2024-05-25 01:32:05 [INFO]: Epoch 177 - training loss: 0.2491, validation loss: 0.1735
2024-05-25 01:32:07 [INFO]: Epoch 178 - training loss: 0.2487, validation loss: 0.1732
2024-05-25 01:32:10 [INFO]: Epoch 179 - training loss: 0.2487, validation loss: 0.1729
2024-05-25 01:32:13 [INFO]: Epoch 180 - training loss: 0.2481, validation loss: 0.1726
2024-05-25 01:32:16 [INFO]: Epoch 181 - training loss: 0.2475, validation loss: 0.1724
2024-05-25 01:32:19 [INFO]: Epoch 182 - training loss: 0.2479, validation loss: 0.1723
2024-05-25 01:32:21 [INFO]: Epoch 183 - training loss: 0.2479, validation loss: 0.1722
2024-05-25 01:32:24 [INFO]: Epoch 184 - training loss: 0.2475, validation loss: 0.1717
2024-05-25 01:32:27 [INFO]: Epoch 185 - training loss: 0.2471, validation loss: 0.1716
2024-05-25 01:32:30 [INFO]: Epoch 186 - training loss: 0.2464, validation loss: 0.1713
2024-05-25 01:32:32 [INFO]: Epoch 187 - training loss: 0.2462, validation loss: 0.1713
2024-05-25 01:32:35 [INFO]: Epoch 188 - training loss: 0.2460, validation loss: 0.1711
2024-05-25 01:32:38 [INFO]: Epoch 189 - training loss: 0.2461, validation loss: 0.1709
2024-05-25 01:32:41 [INFO]: Epoch 190 - training loss: 0.2458, validation loss: 0.1708
2024-05-25 01:32:43 [INFO]: Epoch 191 - training loss: 0.2459, validation loss: 0.1706
2024-05-25 01:32:46 [INFO]: Epoch 192 - training loss: 0.2457, validation loss: 0.1703
2024-05-25 01:32:49 [INFO]: Epoch 193 - training loss: 0.2451, validation loss: 0.1703
2024-05-25 01:32:52 [INFO]: Epoch 194 - training loss: 0.2451, validation loss: 0.1700
2024-05-25 01:32:55 [INFO]: Epoch 195 - training loss: 0.2451, validation loss: 0.1697
2024-05-25 01:32:57 [INFO]: Epoch 196 - training loss: 0.2447, validation loss: 0.1695
2024-05-25 01:33:00 [INFO]: Epoch 197 - training loss: 0.2443, validation loss: 0.1693
2024-05-25 01:33:03 [INFO]: Epoch 198 - training loss: 0.2439, validation loss: 0.1692
2024-05-25 01:33:06 [INFO]: Epoch 199 - training loss: 0.2440, validation loss: 0.1689
2024-05-25 01:33:08 [INFO]: Epoch 200 - training loss: 0.2438, validation loss: 0.1688
2024-05-25 01:33:11 [INFO]: Epoch 201 - training loss: 0.2433, validation loss: 0.1686
2024-05-25 01:33:14 [INFO]: Epoch 202 - training loss: 0.2440, validation loss: 0.1684
2024-05-25 01:33:17 [INFO]: Epoch 203 - training loss: 0.2434, validation loss: 0.1684
2024-05-25 01:33:19 [INFO]: Epoch 204 - training loss: 0.2427, validation loss: 0.1680
2024-05-25 01:33:22 [INFO]: Epoch 205 - training loss: 0.2427, validation loss: 0.1679
2024-05-25 01:33:25 [INFO]: Epoch 206 - training loss: 0.2420, validation loss: 0.1679
2024-05-25 01:33:28 [INFO]: Epoch 207 - training loss: 0.2421, validation loss: 0.1676
2024-05-25 01:33:31 [INFO]: Epoch 208 - training loss: 0.2428, validation loss: 0.1676
2024-05-25 01:33:33 [INFO]: Epoch 209 - training loss: 0.2426, validation loss: 0.1673
2024-05-25 01:33:36 [INFO]: Epoch 210 - training loss: 0.2418, validation loss: 0.1672
2024-05-25 01:33:39 [INFO]: Epoch 211 - training loss: 0.2415, validation loss: 0.1670
2024-05-25 01:33:42 [INFO]: Epoch 212 - training loss: 0.2412, validation loss: 0.1669
2024-05-25 01:33:44 [INFO]: Epoch 213 - training loss: 0.2412, validation loss: 0.1666
2024-05-25 01:33:47 [INFO]: Epoch 214 - training loss: 0.2417, validation loss: 0.1665
2024-05-25 01:33:50 [INFO]: Epoch 215 - training loss: 0.2416, validation loss: 0.1665
2024-05-25 01:33:53 [INFO]: Epoch 216 - training loss: 0.2408, validation loss: 0.1663
2024-05-25 01:33:56 [INFO]: Epoch 217 - training loss: 0.2405, validation loss: 0.1660
2024-05-25 01:33:58 [INFO]: Epoch 218 - training loss: 0.2401, validation loss: 0.1659
2024-05-25 01:34:01 [INFO]: Epoch 219 - training loss: 0.2403, validation loss: 0.1657
2024-05-25 01:34:04 [INFO]: Epoch 220 - training loss: 0.2398, validation loss: 0.1656
2024-05-25 01:34:07 [INFO]: Epoch 221 - training loss: 0.2400, validation loss: 0.1656
2024-05-25 01:34:09 [INFO]: Epoch 222 - training loss: 0.2400, validation loss: 0.1652
2024-05-25 01:34:12 [INFO]: Epoch 223 - training loss: 0.2392, validation loss: 0.1653
2024-05-25 01:34:15 [INFO]: Epoch 224 - training loss: 0.2391, validation loss: 0.1650
2024-05-25 01:34:18 [INFO]: Epoch 225 - training loss: 0.2390, validation loss: 0.1649
2024-05-25 01:34:20 [INFO]: Epoch 226 - training loss: 0.2395, validation loss: 0.1648
2024-05-25 01:34:23 [INFO]: Epoch 227 - training loss: 0.2387, validation loss: 0.1646
2024-05-25 01:34:26 [INFO]: Epoch 228 - training loss: 0.2385, validation loss: 0.1646
2024-05-25 01:34:29 [INFO]: Epoch 229 - training loss: 0.2379, validation loss: 0.1643
2024-05-25 01:34:32 [INFO]: Epoch 230 - training loss: 0.2383, validation loss: 0.1643
2024-05-25 01:34:34 [INFO]: Epoch 231 - training loss: 0.2379, validation loss: 0.1641
2024-05-25 01:34:37 [INFO]: Epoch 232 - training loss: 0.2378, validation loss: 0.1638
2024-05-25 01:34:40 [INFO]: Epoch 233 - training loss: 0.2376, validation loss: 0.1638
2024-05-25 01:34:43 [INFO]: Epoch 234 - training loss: 0.2380, validation loss: 0.1637
2024-05-25 01:34:45 [INFO]: Epoch 235 - training loss: 0.2375, validation loss: 0.1636
2024-05-25 01:34:48 [INFO]: Epoch 236 - training loss: 0.2378, validation loss: 0.1635
2024-05-25 01:34:51 [INFO]: Epoch 237 - training loss: 0.2370, validation loss: 0.1633
2024-05-25 01:34:54 [INFO]: Epoch 238 - training loss: 0.2371, validation loss: 0.1632
2024-05-25 01:34:56 [INFO]: Epoch 239 - training loss: 0.2369, validation loss: 0.1630
2024-05-25 01:34:59 [INFO]: Epoch 240 - training loss: 0.2368, validation loss: 0.1630
2024-05-25 01:35:02 [INFO]: Epoch 241 - training loss: 0.2361, validation loss: 0.1629
2024-05-25 01:35:05 [INFO]: Epoch 242 - training loss: 0.2363, validation loss: 0.1627
2024-05-25 01:35:07 [INFO]: Epoch 243 - training loss: 0.2363, validation loss: 0.1626
2024-05-25 01:35:10 [INFO]: Epoch 244 - training loss: 0.2362, validation loss: 0.1624
2024-05-25 01:35:13 [INFO]: Epoch 245 - training loss: 0.2362, validation loss: 0.1624
2024-05-25 01:35:16 [INFO]: Epoch 246 - training loss: 0.2361, validation loss: 0.1623
2024-05-25 01:35:19 [INFO]: Epoch 247 - training loss: 0.2362, validation loss: 0.1622
2024-05-25 01:35:21 [INFO]: Epoch 248 - training loss: 0.2355, validation loss: 0.1621
2024-05-25 01:35:24 [INFO]: Epoch 249 - training loss: 0.2351, validation loss: 0.1621
2024-05-25 01:35:27 [INFO]: Epoch 250 - training loss: 0.2357, validation loss: 0.1619
2024-05-25 01:35:30 [INFO]: Epoch 251 - training loss: 0.2357, validation loss: 0.1618
2024-05-25 01:35:32 [INFO]: Epoch 252 - training loss: 0.2352, validation loss: 0.1615
2024-05-25 01:35:35 [INFO]: Epoch 253 - training loss: 0.2346, validation loss: 0.1614
2024-05-25 01:35:38 [INFO]: Epoch 254 - training loss: 0.2347, validation loss: 0.1614
2024-05-25 01:35:41 [INFO]: Epoch 255 - training loss: 0.2348, validation loss: 0.1613
2024-05-25 01:35:44 [INFO]: Epoch 256 - training loss: 0.2344, validation loss: 0.1613
2024-05-25 01:35:46 [INFO]: Epoch 257 - training loss: 0.2343, validation loss: 0.1611
2024-05-25 01:35:49 [INFO]: Epoch 258 - training loss: 0.2343, validation loss: 0.1610
2024-05-25 01:35:52 [INFO]: Epoch 259 - training loss: 0.2338, validation loss: 0.1609
2024-05-25 01:35:55 [INFO]: Epoch 260 - training loss: 0.2336, validation loss: 0.1608
2024-05-25 01:35:57 [INFO]: Epoch 261 - training loss: 0.2338, validation loss: 0.1606
2024-05-25 01:36:00 [INFO]: Epoch 262 - training loss: 0.2336, validation loss: 0.1606
2024-05-25 01:36:03 [INFO]: Epoch 263 - training loss: 0.2337, validation loss: 0.1605
2024-05-25 01:36:06 [INFO]: Epoch 264 - training loss: 0.2336, validation loss: 0.1605
2024-05-25 01:36:08 [INFO]: Epoch 265 - training loss: 0.2330, validation loss: 0.1602
2024-05-25 01:36:11 [INFO]: Epoch 266 - training loss: 0.2337, validation loss: 0.1603
2024-05-25 01:36:14 [INFO]: Epoch 267 - training loss: 0.2333, validation loss: 0.1602
2024-05-25 01:36:17 [INFO]: Epoch 268 - training loss: 0.2325, validation loss: 0.1599
2024-05-25 01:36:19 [INFO]: Epoch 269 - training loss: 0.2325, validation loss: 0.1599
2024-05-25 01:36:22 [INFO]: Epoch 270 - training loss: 0.2324, validation loss: 0.1601
2024-05-25 01:36:25 [INFO]: Epoch 271 - training loss: 0.2328, validation loss: 0.1598
2024-05-25 01:36:28 [INFO]: Epoch 272 - training loss: 0.2320, validation loss: 0.1596
2024-05-25 01:36:31 [INFO]: Epoch 273 - training loss: 0.2322, validation loss: 0.1595
2024-05-25 01:36:33 [INFO]: Epoch 274 - training loss: 0.2319, validation loss: 0.1595
2024-05-25 01:36:36 [INFO]: Epoch 275 - training loss: 0.2321, validation loss: 0.1593
2024-05-25 01:36:39 [INFO]: Epoch 276 - training loss: 0.2319, validation loss: 0.1594
2024-05-25 01:36:42 [INFO]: Epoch 277 - training loss: 0.2321, validation loss: 0.1593
2024-05-25 01:36:44 [INFO]: Epoch 278 - training loss: 0.2317, validation loss: 0.1590
2024-05-25 01:36:47 [INFO]: Epoch 279 - training loss: 0.2316, validation loss: 0.1591
2024-05-25 01:36:50 [INFO]: Epoch 280 - training loss: 0.2315, validation loss: 0.1590
2024-05-25 01:36:53 [INFO]: Epoch 281 - training loss: 0.2316, validation loss: 0.1590
2024-05-25 01:36:56 [INFO]: Epoch 282 - training loss: 0.2312, validation loss: 0.1587
2024-05-25 01:36:58 [INFO]: Epoch 283 - training loss: 0.2313, validation loss: 0.1590
2024-05-25 01:37:01 [INFO]: Epoch 284 - training loss: 0.2310, validation loss: 0.1588
2024-05-25 01:37:04 [INFO]: Epoch 285 - training loss: 0.2314, validation loss: 0.1587
2024-05-25 01:37:07 [INFO]: Epoch 286 - training loss: 0.2308, validation loss: 0.1585
2024-05-25 01:37:09 [INFO]: Epoch 287 - training loss: 0.2312, validation loss: 0.1583
2024-05-25 01:37:12 [INFO]: Epoch 288 - training loss: 0.2310, validation loss: 0.1585
2024-05-25 01:37:15 [INFO]: Epoch 289 - training loss: 0.2310, validation loss: 0.1583
2024-05-25 01:37:18 [INFO]: Epoch 290 - training loss: 0.2307, validation loss: 0.1583
2024-05-25 01:37:20 [INFO]: Epoch 291 - training loss: 0.2303, validation loss: 0.1581
2024-05-25 01:37:23 [INFO]: Epoch 292 - training loss: 0.2307, validation loss: 0.1580
2024-05-25 01:37:26 [INFO]: Epoch 293 - training loss: 0.2302, validation loss: 0.1581
2024-05-25 01:37:29 [INFO]: Epoch 294 - training loss: 0.2302, validation loss: 0.1581
2024-05-25 01:37:32 [INFO]: Epoch 295 - training loss: 0.2303, validation loss: 0.1579
2024-05-25 01:37:34 [INFO]: Epoch 296 - training loss: 0.2302, validation loss: 0.1578
2024-05-25 01:37:37 [INFO]: Epoch 297 - training loss: 0.2294, validation loss: 0.1578
2024-05-25 01:37:40 [INFO]: Epoch 298 - training loss: 0.2294, validation loss: 0.1578
2024-05-25 01:37:43 [INFO]: Epoch 299 - training loss: 0.2303, validation loss: 0.1575
2024-05-25 01:37:45 [INFO]: Epoch 300 - training loss: 0.2295, validation loss: 0.1577
2024-05-25 01:37:45 [INFO]: Finished training. The best model is from epoch#299.
2024-05-25 01:37:45 [INFO]: Saved the model to augmentation_saved_results/round_0/BRITS_air_quality/20240525_T012353/BRITS.pypots
2024-05-25 01:37:46 [INFO]: BRITS on Air-Quality: MAE=0.1381, MSE=0.0907
2024-05-25 01:37:46 [INFO]: Successfully saved to augmentation_saved_results/round_0/BRITS_air_quality/imputation.pkl
2024-05-25 01:37:46 [INFO]: Using the given device: cuda:0
2024-05-25 01:37:46 [INFO]: Model files will be saved to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746
2024-05-25 01:37:46 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/tensorboard
2024-05-25 01:37:46 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 01:37:51 [INFO]: Epoch 001 - training loss: 1.4704, validation loss: 0.8201
2024-05-25 01:37:51 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch1_loss0.8201385945081711.pypots
2024-05-25 01:37:55 [INFO]: Epoch 002 - training loss: 1.0593, validation loss: 0.7683
2024-05-25 01:37:55 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch2_loss0.7682895183563232.pypots
2024-05-25 01:37:59 [INFO]: Epoch 003 - training loss: 0.9985, validation loss: 0.7498
2024-05-25 01:37:59 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch3_loss0.7498183190822602.pypots
2024-05-25 01:38:02 [INFO]: Epoch 004 - training loss: 0.9782, validation loss: 0.7367
2024-05-25 01:38:02 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch4_loss0.7366734683513642.pypots
2024-05-25 01:38:06 [INFO]: Epoch 005 - training loss: 0.9647, validation loss: 0.7295
2024-05-25 01:38:06 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch5_loss0.7294642925262451.pypots
2024-05-25 01:38:10 [INFO]: Epoch 006 - training loss: 0.9437, validation loss: 0.7242
2024-05-25 01:38:10 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch6_loss0.7242387056350708.pypots
2024-05-25 01:38:14 [INFO]: Epoch 007 - training loss: 0.9310, validation loss: 0.7197
2024-05-25 01:38:14 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch7_loss0.7196511209011078.pypots
2024-05-25 01:38:18 [INFO]: Epoch 008 - training loss: 0.9293, validation loss: 0.7164
2024-05-25 01:38:18 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch8_loss0.7163892686367035.pypots
2024-05-25 01:38:22 [INFO]: Epoch 009 - training loss: 0.9444, validation loss: 0.7141
2024-05-25 01:38:22 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch9_loss0.7141432285308837.pypots
2024-05-25 01:38:26 [INFO]: Epoch 010 - training loss: 0.9115, validation loss: 0.7120
2024-05-25 01:38:26 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch10_loss0.7120139718055725.pypots
2024-05-25 01:38:30 [INFO]: Epoch 011 - training loss: 0.9169, validation loss: 0.7098
2024-05-25 01:38:30 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch11_loss0.709795606136322.pypots
2024-05-25 01:38:33 [INFO]: Epoch 012 - training loss: 0.9187, validation loss: 0.7073
2024-05-25 01:38:33 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch12_loss0.7072939217090607.pypots
2024-05-25 01:38:37 [INFO]: Epoch 013 - training loss: 0.8974, validation loss: 0.7080
2024-05-25 01:38:37 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch13_loss0.7080289870500565.pypots
2024-05-25 01:38:41 [INFO]: Epoch 014 - training loss: 0.9072, validation loss: 0.7082
2024-05-25 01:38:41 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch14_loss0.7082199454307556.pypots
2024-05-25 01:38:45 [INFO]: Epoch 015 - training loss: 0.9097, validation loss: 0.7064
2024-05-25 01:38:45 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch15_loss0.7064006567001343.pypots
2024-05-25 01:38:49 [INFO]: Epoch 016 - training loss: 0.9009, validation loss: 0.7051
2024-05-25 01:38:49 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch16_loss0.705138185620308.pypots
2024-05-25 01:38:53 [INFO]: Epoch 017 - training loss: 0.8820, validation loss: 0.7041
2024-05-25 01:38:53 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch17_loss0.7041132897138596.pypots
2024-05-25 01:38:57 [INFO]: Epoch 018 - training loss: 0.8964, validation loss: 0.7047
2024-05-25 01:38:57 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch18_loss0.7047492146492005.pypots
2024-05-25 01:39:00 [INFO]: Epoch 019 - training loss: 0.8916, validation loss: 0.7049
2024-05-25 01:39:00 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch19_loss0.7049436718225479.pypots
2024-05-25 01:39:04 [INFO]: Epoch 020 - training loss: 0.8916, validation loss: 0.7040
2024-05-25 01:39:04 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch20_loss0.7039776355028152.pypots
2024-05-25 01:39:08 [INFO]: Epoch 021 - training loss: 0.8732, validation loss: 0.7069
2024-05-25 01:39:08 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch21_loss0.7068593978881836.pypots
2024-05-25 01:39:12 [INFO]: Epoch 022 - training loss: 0.8685, validation loss: 0.7059
2024-05-25 01:39:12 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch22_loss0.7058676034212112.pypots
2024-05-25 01:39:16 [INFO]: Epoch 023 - training loss: 0.8608, validation loss: 0.7088
2024-05-25 01:39:16 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch23_loss0.7088365226984024.pypots
2024-05-25 01:39:20 [INFO]: Epoch 024 - training loss: 0.8692, validation loss: 0.7105
2024-05-25 01:39:20 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch24_loss0.710473895072937.pypots
2024-05-25 01:39:24 [INFO]: Epoch 025 - training loss: 0.9018, validation loss: 0.7078
2024-05-25 01:39:24 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch25_loss0.7078439146280289.pypots
2024-05-25 01:39:28 [INFO]: Epoch 026 - training loss: 0.8768, validation loss: 0.7099
2024-05-25 01:39:28 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch26_loss0.7099302560091019.pypots
2024-05-25 01:39:31 [INFO]: Epoch 027 - training loss: 0.8512, validation loss: 0.7100
2024-05-25 01:39:31 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch27_loss0.7100382387638092.pypots
2024-05-25 01:39:35 [INFO]: Epoch 028 - training loss: 0.8582, validation loss: 0.7101
2024-05-25 01:39:35 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch28_loss0.7101185888051986.pypots
2024-05-25 01:39:39 [INFO]: Epoch 029 - training loss: 0.8619, validation loss: 0.7092
2024-05-25 01:39:39 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch29_loss0.7092227458953857.pypots
2024-05-25 01:39:43 [INFO]: Epoch 030 - training loss: 0.8609, validation loss: 0.7137
2024-05-25 01:39:43 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN_epoch30_loss0.7137337535619735.pypots
2024-05-25 01:39:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:39:43 [INFO]: Finished training. The best model is from epoch#20.
2024-05-25 01:39:43 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T013746/MRNN.pypots
2024-05-25 01:39:44 [INFO]: MRNN on Air-Quality: MAE=0.5241, MSE=0.6052
2024-05-25 01:39:44 [INFO]: Successfully saved to augmentation_saved_results/round_0/MRNN_air_quality/imputation.pkl
2024-05-25 01:39:44 [INFO]: Using the given device: cpu
2024-05-25 01:39:44 [INFO]: LOCF on Air-Quality: MAE=0.2006, MSE=0.1979
2024-05-25 01:39:44 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_air_quality".
2024-05-25 01:39:44 [INFO]: Successfully saved to augmentation_saved_results/round_0/LOCF_air_quality/imputation.pkl
2024-05-25 01:39:44 [INFO]: Median on Air-Quality: MAE=0.6700, MSE=1.0040
2024-05-25 01:39:44 [INFO]: Successfully created the given path "saved_results/round_0/Median_air_quality".
2024-05-25 01:39:44 [INFO]: Successfully saved to augmentation_saved_results/round_0/Median_air_quality/imputation.pkl
2024-05-25 01:39:44 [INFO]: Mean on Air-Quality: MAE=0.6975, MSE=0.9352
2024-05-25 01:39:44 [INFO]: Successfully created the given path "saved_results/round_0/Mean_air_quality".
2024-05-25 01:39:44 [INFO]: Successfully saved to augmentation_saved_results/round_0/Mean_air_quality/imputation.pkl
2024-05-25 01:39:44 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-25 01:39:44 [INFO]: Using the given device: cuda:0
2024-05-25 01:39:44 [INFO]: Model files will be saved to augmentation_saved_results/round_1/SAITS_air_quality/20240525_T013944
2024-05-25 01:39:44 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/SAITS_air_quality/20240525_T013944/tensorboard
2024-05-25 01:39:44 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 01:39:45 [INFO]: Epoch 001 - training loss: 1.0523, validation loss: 0.5415
2024-05-25 01:39:45 [INFO]: Epoch 002 - training loss: 0.7487, validation loss: 0.4278
2024-05-25 01:39:46 [INFO]: Epoch 003 - training loss: 0.6404, validation loss: 0.3601
2024-05-25 01:39:47 [INFO]: Epoch 004 - training loss: 0.5674, validation loss: 0.3187
2024-05-25 01:39:47 [INFO]: Epoch 005 - training loss: 0.5196, validation loss: 0.2934
2024-05-25 01:39:48 [INFO]: Epoch 006 - training loss: 0.4823, validation loss: 0.2809
2024-05-25 01:39:49 [INFO]: Epoch 007 - training loss: 0.4580, validation loss: 0.2723
2024-05-25 01:39:49 [INFO]: Epoch 008 - training loss: 0.4397, validation loss: 0.2668
2024-05-25 01:39:50 [INFO]: Epoch 009 - training loss: 0.4272, validation loss: 0.2588
2024-05-25 01:39:51 [INFO]: Epoch 010 - training loss: 0.4143, validation loss: 0.2552
2024-05-25 01:39:51 [INFO]: Epoch 011 - training loss: 0.4049, validation loss: 0.2524
2024-05-25 01:39:52 [INFO]: Epoch 012 - training loss: 0.3965, validation loss: 0.2471
2024-05-25 01:39:53 [INFO]: Epoch 013 - training loss: 0.3883, validation loss: 0.2425
2024-05-25 01:39:53 [INFO]: Epoch 014 - training loss: 0.3823, validation loss: 0.2402
2024-05-25 01:39:54 [INFO]: Epoch 015 - training loss: 0.3757, validation loss: 0.2389
2024-05-25 01:39:55 [INFO]: Epoch 016 - training loss: 0.3702, validation loss: 0.2373
2024-05-25 01:39:56 [INFO]: Epoch 017 - training loss: 0.3650, validation loss: 0.2335
2024-05-25 01:39:56 [INFO]: Epoch 018 - training loss: 0.3615, validation loss: 0.2311
2024-05-25 01:39:57 [INFO]: Epoch 019 - training loss: 0.3570, validation loss: 0.2312
2024-05-25 01:39:58 [INFO]: Epoch 020 - training loss: 0.3546, validation loss: 0.2268
2024-05-25 01:39:58 [INFO]: Epoch 021 - training loss: 0.3499, validation loss: 0.2262
2024-05-25 01:39:59 [INFO]: Epoch 022 - training loss: 0.3454, validation loss: 0.2236
2024-05-25 01:40:00 [INFO]: Epoch 023 - training loss: 0.3427, validation loss: 0.2221
2024-05-25 01:40:00 [INFO]: Epoch 024 - training loss: 0.3414, validation loss: 0.2201
2024-05-25 01:40:01 [INFO]: Epoch 025 - training loss: 0.3380, validation loss: 0.2188
2024-05-25 01:40:02 [INFO]: Epoch 026 - training loss: 0.3342, validation loss: 0.2174
2024-05-25 01:40:02 [INFO]: Epoch 027 - training loss: 0.3314, validation loss: 0.2150
2024-05-25 01:40:03 [INFO]: Epoch 028 - training loss: 0.3279, validation loss: 0.2143
2024-05-25 01:40:04 [INFO]: Epoch 029 - training loss: 0.3257, validation loss: 0.2131
2024-05-25 01:40:04 [INFO]: Epoch 030 - training loss: 0.3240, validation loss: 0.2118
2024-05-25 01:40:05 [INFO]: Epoch 031 - training loss: 0.3250, validation loss: 0.2102
2024-05-25 01:40:06 [INFO]: Epoch 032 - training loss: 0.3188, validation loss: 0.2083
2024-05-25 01:40:06 [INFO]: Epoch 033 - training loss: 0.3169, validation loss: 0.2067
2024-05-25 01:40:07 [INFO]: Epoch 034 - training loss: 0.3155, validation loss: 0.2058
2024-05-25 01:40:08 [INFO]: Epoch 035 - training loss: 0.3129, validation loss: 0.2041
2024-05-25 01:40:08 [INFO]: Epoch 036 - training loss: 0.3135, validation loss: 0.2041
2024-05-25 01:40:09 [INFO]: Epoch 037 - training loss: 0.3126, validation loss: 0.2029
2024-05-25 01:40:10 [INFO]: Epoch 038 - training loss: 0.3109, validation loss: 0.2018
2024-05-25 01:40:10 [INFO]: Epoch 039 - training loss: 0.3076, validation loss: 0.2006
2024-05-25 01:40:11 [INFO]: Epoch 040 - training loss: 0.3047, validation loss: 0.1998
2024-05-25 01:40:12 [INFO]: Epoch 041 - training loss: 0.3030, validation loss: 0.1985
2024-05-25 01:40:12 [INFO]: Epoch 042 - training loss: 0.3013, validation loss: 0.1986
2024-05-25 01:40:13 [INFO]: Epoch 043 - training loss: 0.2995, validation loss: 0.1970
2024-05-25 01:40:14 [INFO]: Epoch 044 - training loss: 0.2991, validation loss: 0.1964
2024-05-25 01:40:14 [INFO]: Epoch 045 - training loss: 0.2965, validation loss: 0.1954
2024-05-25 01:40:15 [INFO]: Epoch 046 - training loss: 0.2948, validation loss: 0.1956
2024-05-25 01:40:16 [INFO]: Epoch 047 - training loss: 0.2948, validation loss: 0.1941
2024-05-25 01:40:16 [INFO]: Epoch 048 - training loss: 0.2938, validation loss: 0.1938
2024-05-25 01:40:17 [INFO]: Epoch 049 - training loss: 0.2918, validation loss: 0.1931
2024-05-25 01:40:18 [INFO]: Epoch 050 - training loss: 0.2892, validation loss: 0.1932
2024-05-25 01:40:18 [INFO]: Epoch 051 - training loss: 0.2883, validation loss: 0.1922
2024-05-25 01:40:19 [INFO]: Epoch 052 - training loss: 0.2890, validation loss: 0.1920
2024-05-25 01:40:20 [INFO]: Epoch 053 - training loss: 0.2858, validation loss: 0.1905
2024-05-25 01:40:20 [INFO]: Epoch 054 - training loss: 0.2831, validation loss: 0.1902
2024-05-25 01:40:21 [INFO]: Epoch 055 - training loss: 0.2827, validation loss: 0.1896
2024-05-25 01:40:22 [INFO]: Epoch 056 - training loss: 0.2811, validation loss: 0.1890
2024-05-25 01:40:22 [INFO]: Epoch 057 - training loss: 0.2813, validation loss: 0.1885
2024-05-25 01:40:23 [INFO]: Epoch 058 - training loss: 0.2806, validation loss: 0.1888
2024-05-25 01:40:24 [INFO]: Epoch 059 - training loss: 0.2772, validation loss: 0.1882
2024-05-25 01:40:24 [INFO]: Epoch 060 - training loss: 0.2767, validation loss: 0.1874
2024-05-25 01:40:25 [INFO]: Epoch 061 - training loss: 0.2749, validation loss: 0.1866
2024-05-25 01:40:26 [INFO]: Epoch 062 - training loss: 0.2736, validation loss: 0.1867
2024-05-25 01:40:26 [INFO]: Epoch 063 - training loss: 0.2728, validation loss: 0.1864
2024-05-25 01:40:27 [INFO]: Epoch 064 - training loss: 0.2727, validation loss: 0.1858
2024-05-25 01:40:28 [INFO]: Epoch 065 - training loss: 0.2708, validation loss: 0.1855
2024-05-25 01:40:28 [INFO]: Epoch 066 - training loss: 0.2712, validation loss: 0.1842
2024-05-25 01:40:29 [INFO]: Epoch 067 - training loss: 0.2689, validation loss: 0.1845
2024-05-25 01:40:30 [INFO]: Epoch 068 - training loss: 0.2677, validation loss: 0.1843
2024-05-25 01:40:30 [INFO]: Epoch 069 - training loss: 0.2675, validation loss: 0.1840
2024-05-25 01:40:31 [INFO]: Epoch 070 - training loss: 0.2661, validation loss: 0.1838
2024-05-25 01:40:32 [INFO]: Epoch 071 - training loss: 0.2646, validation loss: 0.1837
2024-05-25 01:40:32 [INFO]: Epoch 072 - training loss: 0.2643, validation loss: 0.1829
2024-05-25 01:40:33 [INFO]: Epoch 073 - training loss: 0.2628, validation loss: 0.1829
2024-05-25 01:40:34 [INFO]: Epoch 074 - training loss: 0.2637, validation loss: 0.1820
2024-05-25 01:40:34 [INFO]: Epoch 075 - training loss: 0.2620, validation loss: 0.1821
2024-05-25 01:40:35 [INFO]: Epoch 076 - training loss: 0.2606, validation loss: 0.1815
2024-05-25 01:40:36 [INFO]: Epoch 077 - training loss: 0.2600, validation loss: 0.1812
2024-05-25 01:40:36 [INFO]: Epoch 078 - training loss: 0.2598, validation loss: 0.1810
2024-05-25 01:40:37 [INFO]: Epoch 079 - training loss: 0.2579, validation loss: 0.1814
2024-05-25 01:40:38 [INFO]: Epoch 080 - training loss: 0.2581, validation loss: 0.1809
2024-05-25 01:40:38 [INFO]: Epoch 081 - training loss: 0.2571, validation loss: 0.1803
2024-05-25 01:40:39 [INFO]: Epoch 082 - training loss: 0.2586, validation loss: 0.1792
2024-05-25 01:40:40 [INFO]: Epoch 083 - training loss: 0.2565, validation loss: 0.1786
2024-05-25 01:40:40 [INFO]: Epoch 084 - training loss: 0.2552, validation loss: 0.1792
2024-05-25 01:40:41 [INFO]: Epoch 085 - training loss: 0.2535, validation loss: 0.1788
2024-05-25 01:40:42 [INFO]: Epoch 086 - training loss: 0.2543, validation loss: 0.1782
2024-05-25 01:40:42 [INFO]: Epoch 087 - training loss: 0.2549, validation loss: 0.1783
2024-05-25 01:40:43 [INFO]: Epoch 088 - training loss: 0.2536, validation loss: 0.1785
2024-05-25 01:40:44 [INFO]: Epoch 089 - training loss: 0.2529, validation loss: 0.1778
2024-05-25 01:40:44 [INFO]: Epoch 090 - training loss: 0.2516, validation loss: 0.1779
2024-05-25 01:40:45 [INFO]: Epoch 091 - training loss: 0.2501, validation loss: 0.1778
2024-05-25 01:40:46 [INFO]: Epoch 092 - training loss: 0.2503, validation loss: 0.1770
2024-05-25 01:40:46 [INFO]: Epoch 093 - training loss: 0.2494, validation loss: 0.1760
2024-05-25 01:40:47 [INFO]: Epoch 094 - training loss: 0.2493, validation loss: 0.1765
2024-05-25 01:40:48 [INFO]: Epoch 095 - training loss: 0.2473, validation loss: 0.1756
2024-05-25 01:40:48 [INFO]: Epoch 096 - training loss: 0.2472, validation loss: 0.1758
2024-05-25 01:40:49 [INFO]: Epoch 097 - training loss: 0.2464, validation loss: 0.1761
2024-05-25 01:40:50 [INFO]: Epoch 098 - training loss: 0.2456, validation loss: 0.1750
2024-05-25 01:40:50 [INFO]: Epoch 099 - training loss: 0.2460, validation loss: 0.1755
2024-05-25 01:40:51 [INFO]: Epoch 100 - training loss: 0.2476, validation loss: 0.1749
2024-05-25 01:40:52 [INFO]: Epoch 101 - training loss: 0.2470, validation loss: 0.1740
2024-05-25 01:40:52 [INFO]: Epoch 102 - training loss: 0.2435, validation loss: 0.1747
2024-05-25 01:40:53 [INFO]: Epoch 103 - training loss: 0.2436, validation loss: 0.1739
2024-05-25 01:40:54 [INFO]: Epoch 104 - training loss: 0.2447, validation loss: 0.1730
2024-05-25 01:40:54 [INFO]: Epoch 105 - training loss: 0.2421, validation loss: 0.1736
2024-05-25 01:40:55 [INFO]: Epoch 106 - training loss: 0.2409, validation loss: 0.1730
2024-05-25 01:40:56 [INFO]: Epoch 107 - training loss: 0.2407, validation loss: 0.1724
2024-05-25 01:40:56 [INFO]: Epoch 108 - training loss: 0.2409, validation loss: 0.1728
2024-05-25 01:40:57 [INFO]: Epoch 109 - training loss: 0.2410, validation loss: 0.1719
2024-05-25 01:40:58 [INFO]: Epoch 110 - training loss: 0.2391, validation loss: 0.1724
2024-05-25 01:40:59 [INFO]: Epoch 111 - training loss: 0.2389, validation loss: 0.1743
2024-05-25 01:40:59 [INFO]: Epoch 112 - training loss: 0.2381, validation loss: 0.1716
2024-05-25 01:41:00 [INFO]: Epoch 113 - training loss: 0.2385, validation loss: 0.1723
2024-05-25 01:41:01 [INFO]: Epoch 114 - training loss: 0.2376, validation loss: 0.1723
2024-05-25 01:41:01 [INFO]: Epoch 115 - training loss: 0.2377, validation loss: 0.1723
2024-05-25 01:41:02 [INFO]: Epoch 116 - training loss: 0.2378, validation loss: 0.1718
2024-05-25 01:41:03 [INFO]: Epoch 117 - training loss: 0.2371, validation loss: 0.1706
2024-05-25 01:41:03 [INFO]: Epoch 118 - training loss: 0.2361, validation loss: 0.1702
2024-05-25 01:41:04 [INFO]: Epoch 119 - training loss: 0.2348, validation loss: 0.1702
2024-05-25 01:41:05 [INFO]: Epoch 120 - training loss: 0.2341, validation loss: 0.1708
2024-05-25 01:41:05 [INFO]: Epoch 121 - training loss: 0.2349, validation loss: 0.1711
2024-05-25 01:41:06 [INFO]: Epoch 122 - training loss: 0.2343, validation loss: 0.1710
2024-05-25 01:41:07 [INFO]: Epoch 123 - training loss: 0.2345, validation loss: 0.1695
2024-05-25 01:41:07 [INFO]: Epoch 124 - training loss: 0.2333, validation loss: 0.1700
2024-05-25 01:41:08 [INFO]: Epoch 125 - training loss: 0.2322, validation loss: 0.1691
2024-05-25 01:41:09 [INFO]: Epoch 126 - training loss: 0.2326, validation loss: 0.1690
2024-05-25 01:41:09 [INFO]: Epoch 127 - training loss: 0.2316, validation loss: 0.1697
2024-05-25 01:41:10 [INFO]: Epoch 128 - training loss: 0.2329, validation loss: 0.1692
2024-05-25 01:41:11 [INFO]: Epoch 129 - training loss: 0.2310, validation loss: 0.1687
2024-05-25 01:41:11 [INFO]: Epoch 130 - training loss: 0.2315, validation loss: 0.1681
2024-05-25 01:41:12 [INFO]: Epoch 131 - training loss: 0.2317, validation loss: 0.1675
2024-05-25 01:41:13 [INFO]: Epoch 132 - training loss: 0.2294, validation loss: 0.1674
2024-05-25 01:41:13 [INFO]: Epoch 133 - training loss: 0.2293, validation loss: 0.1665
2024-05-25 01:41:14 [INFO]: Epoch 134 - training loss: 0.2284, validation loss: 0.1668
2024-05-25 01:41:15 [INFO]: Epoch 135 - training loss: 0.2281, validation loss: 0.1669
2024-05-25 01:41:15 [INFO]: Epoch 136 - training loss: 0.2271, validation loss: 0.1664
2024-05-25 01:41:16 [INFO]: Epoch 137 - training loss: 0.2285, validation loss: 0.1668
2024-05-25 01:41:17 [INFO]: Epoch 138 - training loss: 0.2276, validation loss: 0.1657
2024-05-25 01:41:17 [INFO]: Epoch 139 - training loss: 0.2265, validation loss: 0.1677
2024-05-25 01:41:18 [INFO]: Epoch 140 - training loss: 0.2281, validation loss: 0.1659
2024-05-25 01:41:19 [INFO]: Epoch 141 - training loss: 0.2259, validation loss: 0.1661
2024-05-25 01:41:19 [INFO]: Epoch 142 - training loss: 0.2259, validation loss: 0.1654
2024-05-25 01:41:20 [INFO]: Epoch 143 - training loss: 0.2263, validation loss: 0.1664
2024-05-25 01:41:21 [INFO]: Epoch 144 - training loss: 0.2262, validation loss: 0.1651
2024-05-25 01:41:21 [INFO]: Epoch 145 - training loss: 0.2249, validation loss: 0.1642
2024-05-25 01:41:22 [INFO]: Epoch 146 - training loss: 0.2247, validation loss: 0.1645
2024-05-25 01:41:23 [INFO]: Epoch 147 - training loss: 0.2255, validation loss: 0.1663
2024-05-25 01:41:24 [INFO]: Epoch 148 - training loss: 0.2254, validation loss: 0.1643
2024-05-25 01:41:24 [INFO]: Epoch 149 - training loss: 0.2231, validation loss: 0.1641
2024-05-25 01:41:25 [INFO]: Epoch 150 - training loss: 0.2239, validation loss: 0.1650
2024-05-25 01:41:26 [INFO]: Epoch 151 - training loss: 0.2232, validation loss: 0.1652
2024-05-25 01:41:26 [INFO]: Epoch 152 - training loss: 0.2210, validation loss: 0.1655
2024-05-25 01:41:27 [INFO]: Epoch 153 - training loss: 0.2219, validation loss: 0.1646
2024-05-25 01:41:28 [INFO]: Epoch 154 - training loss: 0.2209, validation loss: 0.1639
2024-05-25 01:41:28 [INFO]: Epoch 155 - training loss: 0.2200, validation loss: 0.1634
2024-05-25 01:41:29 [INFO]: Epoch 156 - training loss: 0.2209, validation loss: 0.1651
2024-05-25 01:41:30 [INFO]: Epoch 157 - training loss: 0.2214, validation loss: 0.1637
2024-05-25 01:41:30 [INFO]: Epoch 158 - training loss: 0.2212, validation loss: 0.1637
2024-05-25 01:41:31 [INFO]: Epoch 159 - training loss: 0.2207, validation loss: 0.1657
2024-05-25 01:41:32 [INFO]: Epoch 160 - training loss: 0.2208, validation loss: 0.1636
2024-05-25 01:41:32 [INFO]: Epoch 161 - training loss: 0.2209, validation loss: 0.1640
2024-05-25 01:41:33 [INFO]: Epoch 162 - training loss: 0.2197, validation loss: 0.1633
2024-05-25 01:41:34 [INFO]: Epoch 163 - training loss: 0.2177, validation loss: 0.1623
2024-05-25 01:41:34 [INFO]: Epoch 164 - training loss: 0.2188, validation loss: 0.1634
2024-05-25 01:41:35 [INFO]: Epoch 165 - training loss: 0.2185, validation loss: 0.1625
2024-05-25 01:41:36 [INFO]: Epoch 166 - training loss: 0.2178, validation loss: 0.1634
2024-05-25 01:41:36 [INFO]: Epoch 167 - training loss: 0.2187, validation loss: 0.1625
2024-05-25 01:41:37 [INFO]: Epoch 168 - training loss: 0.2167, validation loss: 0.1626
2024-05-25 01:41:38 [INFO]: Epoch 169 - training loss: 0.2170, validation loss: 0.1627
2024-05-25 01:41:38 [INFO]: Epoch 170 - training loss: 0.2157, validation loss: 0.1626
2024-05-25 01:41:39 [INFO]: Epoch 171 - training loss: 0.2165, validation loss: 0.1617
2024-05-25 01:41:40 [INFO]: Epoch 172 - training loss: 0.2148, validation loss: 0.1624
2024-05-25 01:41:40 [INFO]: Epoch 173 - training loss: 0.2154, validation loss: 0.1620
2024-05-25 01:41:41 [INFO]: Epoch 174 - training loss: 0.2147, validation loss: 0.1627
2024-05-25 01:41:42 [INFO]: Epoch 175 - training loss: 0.2165, validation loss: 0.1624
2024-05-25 01:41:42 [INFO]: Epoch 176 - training loss: 0.2173, validation loss: 0.1625
2024-05-25 01:41:43 [INFO]: Epoch 177 - training loss: 0.2144, validation loss: 0.1618
2024-05-25 01:41:44 [INFO]: Epoch 178 - training loss: 0.2132, validation loss: 0.1625
2024-05-25 01:41:44 [INFO]: Epoch 179 - training loss: 0.2135, validation loss: 0.1604
2024-05-25 01:41:45 [INFO]: Epoch 180 - training loss: 0.2134, validation loss: 0.1616
2024-05-25 01:41:46 [INFO]: Epoch 181 - training loss: 0.2130, validation loss: 0.1620
2024-05-25 01:41:46 [INFO]: Epoch 182 - training loss: 0.2127, validation loss: 0.1616
2024-05-25 01:41:47 [INFO]: Epoch 183 - training loss: 0.2129, validation loss: 0.1627
2024-05-25 01:41:48 [INFO]: Epoch 184 - training loss: 0.2135, validation loss: 0.1604
2024-05-25 01:41:48 [INFO]: Epoch 185 - training loss: 0.2138, validation loss: 0.1609
2024-05-25 01:41:49 [INFO]: Epoch 186 - training loss: 0.2129, validation loss: 0.1613
2024-05-25 01:41:50 [INFO]: Epoch 187 - training loss: 0.2122, validation loss: 0.1609
2024-05-25 01:41:50 [INFO]: Epoch 188 - training loss: 0.2111, validation loss: 0.1617
2024-05-25 01:41:51 [INFO]: Epoch 189 - training loss: 0.2111, validation loss: 0.1616
2024-05-25 01:41:52 [INFO]: Epoch 190 - training loss: 0.2102, validation loss: 0.1611
2024-05-25 01:41:52 [INFO]: Epoch 191 - training loss: 0.2100, validation loss: 0.1613
2024-05-25 01:41:53 [INFO]: Epoch 192 - training loss: 0.2100, validation loss: 0.1619
2024-05-25 01:41:54 [INFO]: Epoch 193 - training loss: 0.2098, validation loss: 0.1607
2024-05-25 01:41:54 [INFO]: Epoch 194 - training loss: 0.2097, validation loss: 0.1613
2024-05-25 01:41:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:41:54 [INFO]: Finished training. The best model is from epoch#184.
2024-05-25 01:41:55 [INFO]: Saved the model to augmentation_saved_results/round_1/SAITS_air_quality/20240525_T013944/SAITS.pypots
2024-05-25 01:41:55 [INFO]: SAITS on Air-Quality: MAE=0.1490, MSE=0.0943
2024-05-25 01:41:55 [INFO]: Successfully saved to augmentation_saved_results/round_1/SAITS_air_quality/imputation.pkl
2024-05-25 01:41:55 [INFO]: Using the given device: cuda:0
2024-05-25 01:41:55 [INFO]: Model files will be saved to augmentation_saved_results/round_1/Transformer_air_quality/20240525_T014155
2024-05-25 01:41:55 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/Transformer_air_quality/20240525_T014155/tensorboard
2024-05-25 01:41:55 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 01:41:55 [INFO]: Epoch 001 - training loss: 0.9054, validation loss: 0.5010
2024-05-25 01:41:55 [INFO]: Epoch 002 - training loss: 0.5751, validation loss: 0.3843
2024-05-25 01:41:56 [INFO]: Epoch 003 - training loss: 0.4839, validation loss: 0.3285
2024-05-25 01:41:56 [INFO]: Epoch 004 - training loss: 0.4361, validation loss: 0.3028
2024-05-25 01:41:56 [INFO]: Epoch 005 - training loss: 0.4087, validation loss: 0.2891
2024-05-25 01:41:57 [INFO]: Epoch 006 - training loss: 0.3924, validation loss: 0.2794
2024-05-25 01:41:57 [INFO]: Epoch 007 - training loss: 0.3764, validation loss: 0.2717
2024-05-25 01:41:57 [INFO]: Epoch 008 - training loss: 0.3639, validation loss: 0.2653
2024-05-25 01:41:58 [INFO]: Epoch 009 - training loss: 0.3564, validation loss: 0.2606
2024-05-25 01:41:58 [INFO]: Epoch 010 - training loss: 0.3480, validation loss: 0.2562
2024-05-25 01:41:58 [INFO]: Epoch 011 - training loss: 0.3405, validation loss: 0.2537
2024-05-25 01:41:59 [INFO]: Epoch 012 - training loss: 0.3370, validation loss: 0.2491
2024-05-25 01:41:59 [INFO]: Epoch 013 - training loss: 0.3316, validation loss: 0.2443
2024-05-25 01:41:59 [INFO]: Epoch 014 - training loss: 0.3278, validation loss: 0.2436
2024-05-25 01:42:00 [INFO]: Epoch 015 - training loss: 0.3306, validation loss: 0.2384
2024-05-25 01:42:00 [INFO]: Epoch 016 - training loss: 0.3197, validation loss: 0.2353
2024-05-25 01:42:00 [INFO]: Epoch 017 - training loss: 0.3174, validation loss: 0.2321
2024-05-25 01:42:00 [INFO]: Epoch 018 - training loss: 0.3139, validation loss: 0.2305
2024-05-25 01:42:01 [INFO]: Epoch 019 - training loss: 0.3106, validation loss: 0.2278
2024-05-25 01:42:01 [INFO]: Epoch 020 - training loss: 0.3065, validation loss: 0.2247
2024-05-25 01:42:01 [INFO]: Epoch 021 - training loss: 0.3046, validation loss: 0.2224
2024-05-25 01:42:02 [INFO]: Epoch 022 - training loss: 0.2995, validation loss: 0.2210
2024-05-25 01:42:02 [INFO]: Epoch 023 - training loss: 0.2999, validation loss: 0.2190
2024-05-25 01:42:02 [INFO]: Epoch 024 - training loss: 0.2966, validation loss: 0.2186
2024-05-25 01:42:03 [INFO]: Epoch 025 - training loss: 0.2946, validation loss: 0.2160
2024-05-25 01:42:03 [INFO]: Epoch 026 - training loss: 0.2928, validation loss: 0.2161
2024-05-25 01:42:03 [INFO]: Epoch 027 - training loss: 0.2913, validation loss: 0.2165
2024-05-25 01:42:04 [INFO]: Epoch 028 - training loss: 0.2905, validation loss: 0.2148
2024-05-25 01:42:04 [INFO]: Epoch 029 - training loss: 0.2899, validation loss: 0.2138
2024-05-25 01:42:04 [INFO]: Epoch 030 - training loss: 0.2852, validation loss: 0.2113
2024-05-25 01:42:05 [INFO]: Epoch 031 - training loss: 0.2832, validation loss: 0.2107
2024-05-25 01:42:05 [INFO]: Epoch 032 - training loss: 0.2845, validation loss: 0.2101
2024-05-25 01:42:05 [INFO]: Epoch 033 - training loss: 0.2839, validation loss: 0.2104
2024-05-25 01:42:06 [INFO]: Epoch 034 - training loss: 0.2825, validation loss: 0.2089
2024-05-25 01:42:06 [INFO]: Epoch 035 - training loss: 0.2797, validation loss: 0.2094
2024-05-25 01:42:06 [INFO]: Epoch 036 - training loss: 0.2785, validation loss: 0.2079
2024-05-25 01:42:06 [INFO]: Epoch 037 - training loss: 0.2774, validation loss: 0.2074
2024-05-25 01:42:07 [INFO]: Epoch 038 - training loss: 0.2752, validation loss: 0.2100
2024-05-25 01:42:07 [INFO]: Epoch 039 - training loss: 0.2764, validation loss: 0.2070
2024-05-25 01:42:07 [INFO]: Epoch 040 - training loss: 0.2766, validation loss: 0.2064
2024-05-25 01:42:08 [INFO]: Epoch 041 - training loss: 0.2720, validation loss: 0.2058
2024-05-25 01:42:08 [INFO]: Epoch 042 - training loss: 0.2691, validation loss: 0.2065
2024-05-25 01:42:08 [INFO]: Epoch 043 - training loss: 0.2700, validation loss: 0.2052
2024-05-25 01:42:09 [INFO]: Epoch 044 - training loss: 0.2686, validation loss: 0.2032
2024-05-25 01:42:09 [INFO]: Epoch 045 - training loss: 0.2661, validation loss: 0.2040
2024-05-25 01:42:09 [INFO]: Epoch 046 - training loss: 0.2692, validation loss: 0.2055
2024-05-25 01:42:10 [INFO]: Epoch 047 - training loss: 0.2683, validation loss: 0.2054
2024-05-25 01:42:10 [INFO]: Epoch 048 - training loss: 0.2644, validation loss: 0.2049
2024-05-25 01:42:10 [INFO]: Epoch 049 - training loss: 0.2650, validation loss: 0.2024
2024-05-25 01:42:11 [INFO]: Epoch 050 - training loss: 0.2635, validation loss: 0.2027
2024-05-25 01:42:11 [INFO]: Epoch 051 - training loss: 0.2633, validation loss: 0.2009
2024-05-25 01:42:11 [INFO]: Epoch 052 - training loss: 0.2627, validation loss: 0.2009
2024-05-25 01:42:12 [INFO]: Epoch 053 - training loss: 0.2623, validation loss: 0.2017
2024-05-25 01:42:12 [INFO]: Epoch 054 - training loss: 0.2618, validation loss: 0.1997
2024-05-25 01:42:12 [INFO]: Epoch 055 - training loss: 0.2576, validation loss: 0.2013
2024-05-25 01:42:12 [INFO]: Epoch 056 - training loss: 0.2591, validation loss: 0.2002
2024-05-25 01:42:13 [INFO]: Epoch 057 - training loss: 0.2574, validation loss: 0.2001
2024-05-25 01:42:13 [INFO]: Epoch 058 - training loss: 0.2571, validation loss: 0.2004
2024-05-25 01:42:13 [INFO]: Epoch 059 - training loss: 0.2558, validation loss: 0.2014
2024-05-25 01:42:14 [INFO]: Epoch 060 - training loss: 0.2543, validation loss: 0.1992
2024-05-25 01:42:14 [INFO]: Epoch 061 - training loss: 0.2551, validation loss: 0.1974
2024-05-25 01:42:14 [INFO]: Epoch 062 - training loss: 0.2568, validation loss: 0.1982
2024-05-25 01:42:15 [INFO]: Epoch 063 - training loss: 0.2533, validation loss: 0.1970
2024-05-25 01:42:15 [INFO]: Epoch 064 - training loss: 0.2565, validation loss: 0.2008
2024-05-25 01:42:15 [INFO]: Epoch 065 - training loss: 0.2534, validation loss: 0.1971
2024-05-25 01:42:16 [INFO]: Epoch 066 - training loss: 0.2511, validation loss: 0.1959
2024-05-25 01:42:16 [INFO]: Epoch 067 - training loss: 0.2509, validation loss: 0.1950
2024-05-25 01:42:16 [INFO]: Epoch 068 - training loss: 0.2497, validation loss: 0.1943
2024-05-25 01:42:17 [INFO]: Epoch 069 - training loss: 0.2482, validation loss: 0.1941
2024-05-25 01:42:17 [INFO]: Epoch 070 - training loss: 0.2486, validation loss: 0.1940
2024-05-25 01:42:17 [INFO]: Epoch 071 - training loss: 0.2489, validation loss: 0.1950
2024-05-25 01:42:18 [INFO]: Epoch 072 - training loss: 0.2491, validation loss: 0.1936
2024-05-25 01:42:18 [INFO]: Epoch 073 - training loss: 0.2493, validation loss: 0.1935
2024-05-25 01:42:18 [INFO]: Epoch 074 - training loss: 0.2443, validation loss: 0.1937
2024-05-25 01:42:19 [INFO]: Epoch 075 - training loss: 0.2440, validation loss: 0.1925
2024-05-25 01:42:19 [INFO]: Epoch 076 - training loss: 0.2429, validation loss: 0.1912
2024-05-25 01:42:19 [INFO]: Epoch 077 - training loss: 0.2426, validation loss: 0.1919
2024-05-25 01:42:19 [INFO]: Epoch 078 - training loss: 0.2411, validation loss: 0.1936
2024-05-25 01:42:20 [INFO]: Epoch 079 - training loss: 0.2419, validation loss: 0.1909
2024-05-25 01:42:20 [INFO]: Epoch 080 - training loss: 0.2414, validation loss: 0.1897
2024-05-25 01:42:20 [INFO]: Epoch 081 - training loss: 0.2427, validation loss: 0.1904
2024-05-25 01:42:21 [INFO]: Epoch 082 - training loss: 0.2417, validation loss: 0.1892
2024-05-25 01:42:21 [INFO]: Epoch 083 - training loss: 0.2388, validation loss: 0.1898
2024-05-25 01:42:21 [INFO]: Epoch 084 - training loss: 0.2402, validation loss: 0.1884
2024-05-25 01:42:22 [INFO]: Epoch 085 - training loss: 0.2407, validation loss: 0.1870
2024-05-25 01:42:22 [INFO]: Epoch 086 - training loss: 0.2381, validation loss: 0.1876
2024-05-25 01:42:22 [INFO]: Epoch 087 - training loss: 0.2375, validation loss: 0.1885
2024-05-25 01:42:23 [INFO]: Epoch 088 - training loss: 0.2362, validation loss: 0.1885
2024-05-25 01:42:23 [INFO]: Epoch 089 - training loss: 0.2348, validation loss: 0.1884
2024-05-25 01:42:23 [INFO]: Epoch 090 - training loss: 0.2345, validation loss: 0.1883
2024-05-25 01:42:24 [INFO]: Epoch 091 - training loss: 0.2358, validation loss: 0.1878
2024-05-25 01:42:24 [INFO]: Epoch 092 - training loss: 0.2409, validation loss: 0.1880
2024-05-25 01:42:24 [INFO]: Epoch 093 - training loss: 0.2350, validation loss: 0.1875
2024-05-25 01:42:25 [INFO]: Epoch 094 - training loss: 0.2322, validation loss: 0.1855
2024-05-25 01:42:25 [INFO]: Epoch 095 - training loss: 0.2333, validation loss: 0.1841
2024-05-25 01:42:25 [INFO]: Epoch 096 - training loss: 0.2307, validation loss: 0.1843
2024-05-25 01:42:25 [INFO]: Epoch 097 - training loss: 0.2323, validation loss: 0.1839
2024-05-25 01:42:26 [INFO]: Epoch 098 - training loss: 0.2309, validation loss: 0.1844
2024-05-25 01:42:26 [INFO]: Epoch 099 - training loss: 0.2312, validation loss: 0.1836
2024-05-25 01:42:26 [INFO]: Epoch 100 - training loss: 0.2293, validation loss: 0.1824
2024-05-25 01:42:27 [INFO]: Epoch 101 - training loss: 0.2317, validation loss: 0.1817
2024-05-25 01:42:27 [INFO]: Epoch 102 - training loss: 0.2335, validation loss: 0.1815
2024-05-25 01:42:27 [INFO]: Epoch 103 - training loss: 0.2294, validation loss: 0.1834
2024-05-25 01:42:28 [INFO]: Epoch 104 - training loss: 0.2284, validation loss: 0.1828
2024-05-25 01:42:28 [INFO]: Epoch 105 - training loss: 0.2273, validation loss: 0.1807
2024-05-25 01:42:28 [INFO]: Epoch 106 - training loss: 0.2313, validation loss: 0.1810
2024-05-25 01:42:29 [INFO]: Epoch 107 - training loss: 0.2278, validation loss: 0.1823
2024-05-25 01:42:29 [INFO]: Epoch 108 - training loss: 0.2260, validation loss: 0.1813
2024-05-25 01:42:29 [INFO]: Epoch 109 - training loss: 0.2253, validation loss: 0.1806
2024-05-25 01:42:30 [INFO]: Epoch 110 - training loss: 0.2238, validation loss: 0.1794
2024-05-25 01:42:30 [INFO]: Epoch 111 - training loss: 0.2235, validation loss: 0.1785
2024-05-25 01:42:30 [INFO]: Epoch 112 - training loss: 0.2246, validation loss: 0.1781
2024-05-25 01:42:31 [INFO]: Epoch 113 - training loss: 0.2219, validation loss: 0.1797
2024-05-25 01:42:31 [INFO]: Epoch 114 - training loss: 0.2231, validation loss: 0.1794
2024-05-25 01:42:31 [INFO]: Epoch 115 - training loss: 0.2259, validation loss: 0.1775
2024-05-25 01:42:31 [INFO]: Epoch 116 - training loss: 0.2230, validation loss: 0.1789
2024-05-25 01:42:32 [INFO]: Epoch 117 - training loss: 0.2230, validation loss: 0.1792
2024-05-25 01:42:32 [INFO]: Epoch 118 - training loss: 0.2225, validation loss: 0.1793
2024-05-25 01:42:32 [INFO]: Epoch 119 - training loss: 0.2199, validation loss: 0.1796
2024-05-25 01:42:33 [INFO]: Epoch 120 - training loss: 0.2190, validation loss: 0.1778
2024-05-25 01:42:33 [INFO]: Epoch 121 - training loss: 0.2204, validation loss: 0.1781
2024-05-25 01:42:34 [INFO]: Epoch 122 - training loss: 0.2197, validation loss: 0.1771
2024-05-25 01:42:34 [INFO]: Epoch 123 - training loss: 0.2197, validation loss: 0.1768
2024-05-25 01:42:34 [INFO]: Epoch 124 - training loss: 0.2202, validation loss: 0.1777
2024-05-25 01:42:34 [INFO]: Epoch 125 - training loss: 0.2193, validation loss: 0.1769
2024-05-25 01:42:35 [INFO]: Epoch 126 - training loss: 0.2173, validation loss: 0.1780
2024-05-25 01:42:35 [INFO]: Epoch 127 - training loss: 0.2168, validation loss: 0.1758
2024-05-25 01:42:35 [INFO]: Epoch 128 - training loss: 0.2200, validation loss: 0.1772
2024-05-25 01:42:36 [INFO]: Epoch 129 - training loss: 0.2207, validation loss: 0.1771
2024-05-25 01:42:36 [INFO]: Epoch 130 - training loss: 0.2188, validation loss: 0.1760
2024-05-25 01:42:36 [INFO]: Epoch 131 - training loss: 0.2150, validation loss: 0.1755
2024-05-25 01:42:37 [INFO]: Epoch 132 - training loss: 0.2150, validation loss: 0.1764
2024-05-25 01:42:37 [INFO]: Epoch 133 - training loss: 0.2168, validation loss: 0.1784
2024-05-25 01:42:37 [INFO]: Epoch 134 - training loss: 0.2226, validation loss: 0.1747
2024-05-25 01:42:38 [INFO]: Epoch 135 - training loss: 0.2172, validation loss: 0.1754
2024-05-25 01:42:38 [INFO]: Epoch 136 - training loss: 0.2161, validation loss: 0.1742
2024-05-25 01:42:38 [INFO]: Epoch 137 - training loss: 0.2138, validation loss: 0.1751
2024-05-25 01:42:39 [INFO]: Epoch 138 - training loss: 0.2158, validation loss: 0.1766
2024-05-25 01:42:39 [INFO]: Epoch 139 - training loss: 0.2149, validation loss: 0.1744
2024-05-25 01:42:39 [INFO]: Epoch 140 - training loss: 0.2142, validation loss: 0.1746
2024-05-25 01:42:40 [INFO]: Epoch 141 - training loss: 0.2142, validation loss: 0.1758
2024-05-25 01:42:40 [INFO]: Epoch 142 - training loss: 0.2141, validation loss: 0.1754
2024-05-25 01:42:40 [INFO]: Epoch 143 - training loss: 0.2115, validation loss: 0.1735
2024-05-25 01:42:40 [INFO]: Epoch 144 - training loss: 0.2110, validation loss: 0.1744
2024-05-25 01:42:41 [INFO]: Epoch 145 - training loss: 0.2113, validation loss: 0.1740
2024-05-25 01:42:41 [INFO]: Epoch 146 - training loss: 0.2113, validation loss: 0.1742
2024-05-25 01:42:41 [INFO]: Epoch 147 - training loss: 0.2138, validation loss: 0.1732
2024-05-25 01:42:42 [INFO]: Epoch 148 - training loss: 0.2101, validation loss: 0.1727
2024-05-25 01:42:42 [INFO]: Epoch 149 - training loss: 0.2097, validation loss: 0.1723
2024-05-25 01:42:42 [INFO]: Epoch 150 - training loss: 0.2104, validation loss: 0.1725
2024-05-25 01:42:43 [INFO]: Epoch 151 - training loss: 0.2115, validation loss: 0.1717
2024-05-25 01:42:43 [INFO]: Epoch 152 - training loss: 0.2099, validation loss: 0.1726
2024-05-25 01:42:43 [INFO]: Epoch 153 - training loss: 0.2122, validation loss: 0.1719
2024-05-25 01:42:44 [INFO]: Epoch 154 - training loss: 0.2096, validation loss: 0.1713
2024-05-25 01:42:44 [INFO]: Epoch 155 - training loss: 0.2070, validation loss: 0.1738
2024-05-25 01:42:44 [INFO]: Epoch 156 - training loss: 0.2093, validation loss: 0.1717
2024-05-25 01:42:45 [INFO]: Epoch 157 - training loss: 0.2097, validation loss: 0.1722
2024-05-25 01:42:45 [INFO]: Epoch 158 - training loss: 0.2068, validation loss: 0.1725
2024-05-25 01:42:45 [INFO]: Epoch 159 - training loss: 0.2074, validation loss: 0.1730
2024-05-25 01:42:46 [INFO]: Epoch 160 - training loss: 0.2102, validation loss: 0.1728
2024-05-25 01:42:46 [INFO]: Epoch 161 - training loss: 0.2067, validation loss: 0.1704
2024-05-25 01:42:46 [INFO]: Epoch 162 - training loss: 0.2059, validation loss: 0.1709
2024-05-25 01:42:47 [INFO]: Epoch 163 - training loss: 0.2051, validation loss: 0.1705
2024-05-25 01:42:47 [INFO]: Epoch 164 - training loss: 0.2052, validation loss: 0.1718
2024-05-25 01:42:47 [INFO]: Epoch 165 - training loss: 0.2055, validation loss: 0.1707
2024-05-25 01:42:48 [INFO]: Epoch 166 - training loss: 0.2050, validation loss: 0.1718
2024-05-25 01:42:48 [INFO]: Epoch 167 - training loss: 0.2044, validation loss: 0.1711
2024-05-25 01:42:48 [INFO]: Epoch 168 - training loss: 0.2044, validation loss: 0.1708
2024-05-25 01:42:48 [INFO]: Epoch 169 - training loss: 0.2056, validation loss: 0.1696
2024-05-25 01:42:49 [INFO]: Epoch 170 - training loss: 0.2062, validation loss: 0.1705
2024-05-25 01:42:49 [INFO]: Epoch 171 - training loss: 0.2058, validation loss: 0.1705
2024-05-25 01:42:49 [INFO]: Epoch 172 - training loss: 0.2041, validation loss: 0.1702
2024-05-25 01:42:50 [INFO]: Epoch 173 - training loss: 0.2059, validation loss: 0.1700
2024-05-25 01:42:50 [INFO]: Epoch 174 - training loss: 0.2052, validation loss: 0.1701
2024-05-25 01:42:50 [INFO]: Epoch 175 - training loss: 0.2037, validation loss: 0.1699
2024-05-25 01:42:51 [INFO]: Epoch 176 - training loss: 0.2025, validation loss: 0.1712
2024-05-25 01:42:51 [INFO]: Epoch 177 - training loss: 0.2030, validation loss: 0.1707
2024-05-25 01:42:51 [INFO]: Epoch 178 - training loss: 0.2015, validation loss: 0.1698
2024-05-25 01:42:52 [INFO]: Epoch 179 - training loss: 0.2023, validation loss: 0.1709
2024-05-25 01:42:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:42:52 [INFO]: Finished training. The best model is from epoch#169.
2024-05-25 01:42:52 [INFO]: Saved the model to augmentation_saved_results/round_1/Transformer_air_quality/20240525_T014155/Transformer.pypots
2024-05-25 01:42:52 [INFO]: Transformer on Air-Quality: MAE=0.1641, MSE=0.1131
2024-05-25 01:42:52 [INFO]: Successfully saved to augmentation_saved_results/round_1/Transformer_air_quality/imputation.pkl
2024-05-25 01:42:52 [INFO]: Using the given device: cuda:0
2024-05-25 01:42:52 [INFO]: Model files will be saved to augmentation_saved_results/round_1/TimesNet_air_quality/20240525_T014252
2024-05-25 01:42:52 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/TimesNet_air_quality/20240525_T014252/tensorboard
2024-05-25 01:42:52 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 01:42:53 [INFO]: Epoch 001 - training loss: 0.2922, validation loss: 0.3027
2024-05-25 01:42:53 [INFO]: Epoch 002 - training loss: 0.2353, validation loss: 0.2714
2024-05-25 01:42:54 [INFO]: Epoch 003 - training loss: 0.2029, validation loss: 0.2417
2024-05-25 01:42:54 [INFO]: Epoch 004 - training loss: 0.1924, validation loss: 0.2434
2024-05-25 01:42:55 [INFO]: Epoch 005 - training loss: 0.1650, validation loss: 0.2366
2024-05-25 01:42:55 [INFO]: Epoch 006 - training loss: 0.1737, validation loss: 0.2325
2024-05-25 01:42:56 [INFO]: Epoch 007 - training loss: 0.1676, validation loss: 0.2505
2024-05-25 01:42:56 [INFO]: Epoch 008 - training loss: 0.1768, validation loss: 0.2229
2024-05-25 01:42:57 [INFO]: Epoch 009 - training loss: 0.1309, validation loss: 0.2182
2024-05-25 01:42:57 [INFO]: Epoch 010 - training loss: 0.1440, validation loss: 0.2204
2024-05-25 01:42:58 [INFO]: Epoch 011 - training loss: 0.1316, validation loss: 0.2329
2024-05-25 01:42:58 [INFO]: Epoch 012 - training loss: 0.1434, validation loss: 0.2056
2024-05-25 01:42:59 [INFO]: Epoch 013 - training loss: 0.1299, validation loss: 0.2147
2024-05-25 01:42:59 [INFO]: Epoch 014 - training loss: 0.1495, validation loss: 0.2087
2024-05-25 01:43:00 [INFO]: Epoch 015 - training loss: 0.1354, validation loss: 0.2068
2024-05-25 01:43:01 [INFO]: Epoch 016 - training loss: 0.1328, validation loss: 0.2062
2024-05-25 01:43:01 [INFO]: Epoch 017 - training loss: 0.1440, validation loss: 0.2041
2024-05-25 01:43:02 [INFO]: Epoch 018 - training loss: 0.1283, validation loss: 0.2026
2024-05-25 01:43:02 [INFO]: Epoch 019 - training loss: 0.1260, validation loss: 0.2144
2024-05-25 01:43:03 [INFO]: Epoch 020 - training loss: 0.1209, validation loss: 0.2104
2024-05-25 01:43:03 [INFO]: Epoch 021 - training loss: 0.1221, validation loss: 0.2010
2024-05-25 01:43:04 [INFO]: Epoch 022 - training loss: 0.1174, validation loss: 0.2151
2024-05-25 01:43:04 [INFO]: Epoch 023 - training loss: 0.1172, validation loss: 0.2074
2024-05-25 01:43:05 [INFO]: Epoch 024 - training loss: 0.1286, validation loss: 0.2031
2024-05-25 01:43:05 [INFO]: Epoch 025 - training loss: 0.1321, validation loss: 0.2093
2024-05-25 01:43:06 [INFO]: Epoch 026 - training loss: 0.1234, validation loss: 0.2030
2024-05-25 01:43:06 [INFO]: Epoch 027 - training loss: 0.1181, validation loss: 0.2091
2024-05-25 01:43:07 [INFO]: Epoch 028 - training loss: 0.1190, validation loss: 0.1980
2024-05-25 01:43:07 [INFO]: Epoch 029 - training loss: 0.1157, validation loss: 0.1954
2024-05-25 01:43:08 [INFO]: Epoch 030 - training loss: 0.1210, validation loss: 0.1984
2024-05-25 01:43:08 [INFO]: Epoch 031 - training loss: 0.1093, validation loss: 0.2045
2024-05-25 01:43:09 [INFO]: Epoch 032 - training loss: 0.1051, validation loss: 0.1979
2024-05-25 01:43:09 [INFO]: Epoch 033 - training loss: 0.1279, validation loss: 0.2027
2024-05-25 01:43:10 [INFO]: Epoch 034 - training loss: 0.1129, validation loss: 0.1914
2024-05-25 01:43:11 [INFO]: Epoch 035 - training loss: 0.1180, validation loss: 0.2002
2024-05-25 01:43:11 [INFO]: Epoch 036 - training loss: 0.1280, validation loss: 0.2003
2024-05-25 01:43:12 [INFO]: Epoch 037 - training loss: 0.1243, validation loss: 0.1998
2024-05-25 01:43:12 [INFO]: Epoch 038 - training loss: 0.1088, validation loss: 0.2070
2024-05-25 01:43:13 [INFO]: Epoch 039 - training loss: 0.1053, validation loss: 0.2055
2024-05-25 01:43:13 [INFO]: Epoch 040 - training loss: 0.1069, validation loss: 0.2126
2024-05-25 01:43:14 [INFO]: Epoch 041 - training loss: 0.1156, validation loss: 0.2000
2024-05-25 01:43:14 [INFO]: Epoch 042 - training loss: 0.1205, validation loss: 0.2055
2024-05-25 01:43:15 [INFO]: Epoch 043 - training loss: 0.1081, validation loss: 0.2145
2024-05-25 01:43:15 [INFO]: Epoch 044 - training loss: 0.1139, validation loss: 0.2191
2024-05-25 01:43:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:43:15 [INFO]: Finished training. The best model is from epoch#34.
2024-05-25 01:43:15 [INFO]: Saved the model to augmentation_saved_results/round_1/TimesNet_air_quality/20240525_T014252/TimesNet.pypots
2024-05-25 01:43:16 [INFO]: TimesNet on Air-Quality: MAE=0.1647, MSE=0.1522
2024-05-25 01:43:16 [INFO]: Successfully saved to augmentation_saved_results/round_1/TimesNet_air_quality/imputation.pkl
2024-05-25 01:43:16 [INFO]: Using the given device: cuda:0
2024-05-25 01:43:16 [INFO]: Model files will be saved to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316
2024-05-25 01:43:16 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/tensorboard
2024-05-25 01:43:16 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 01:43:32 [INFO]: Epoch 001 - training loss: 0.4781, validation loss: 0.3472
2024-05-25 01:43:32 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch1_loss0.3471659064292908.pypots
2024-05-25 01:43:49 [INFO]: Epoch 002 - training loss: 0.2920, validation loss: 0.2909
2024-05-25 01:43:49 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch2_loss0.2908653289079666.pypots
2024-05-25 01:44:06 [INFO]: Epoch 003 - training loss: 0.2505, validation loss: 0.2477
2024-05-25 01:44:06 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch3_loss0.2476794794201851.pypots
2024-05-25 01:44:23 [INFO]: Epoch 004 - training loss: 0.2313, validation loss: 0.2171
2024-05-25 01:44:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch4_loss0.21708252280950546.pypots
2024-05-25 01:44:40 [INFO]: Epoch 005 - training loss: 0.2045, validation loss: 0.2102
2024-05-25 01:44:40 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch5_loss0.21016879826784135.pypots
2024-05-25 01:44:57 [INFO]: Epoch 006 - training loss: 0.2038, validation loss: 0.1875
2024-05-25 01:44:57 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch6_loss0.1874548614025116.pypots
2024-05-25 01:45:14 [INFO]: Epoch 007 - training loss: 0.2099, validation loss: 0.1746
2024-05-25 01:45:14 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch7_loss0.17463404089212417.pypots
2024-05-25 01:45:30 [INFO]: Epoch 008 - training loss: 0.1831, validation loss: 0.1646
2024-05-25 01:45:30 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch8_loss0.16460890918970109.pypots
2024-05-25 01:45:47 [INFO]: Epoch 009 - training loss: 0.1616, validation loss: 0.1572
2024-05-25 01:45:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch9_loss0.1572030946612358.pypots
2024-05-25 01:46:04 [INFO]: Epoch 010 - training loss: 0.1818, validation loss: 0.1957
2024-05-25 01:46:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch10_loss0.19573376178741456.pypots
2024-05-25 01:46:21 [INFO]: Epoch 011 - training loss: 0.1673, validation loss: 0.1559
2024-05-25 01:46:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch11_loss0.15587287098169328.pypots
2024-05-25 01:46:38 [INFO]: Epoch 012 - training loss: 0.1813, validation loss: 0.1497
2024-05-25 01:46:38 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch12_loss0.14968424439430236.pypots
2024-05-25 01:46:55 [INFO]: Epoch 013 - training loss: 0.1708, validation loss: 0.1452
2024-05-25 01:46:55 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch13_loss0.14520496129989624.pypots
2024-05-25 01:47:12 [INFO]: Epoch 014 - training loss: 0.1564, validation loss: 0.1416
2024-05-25 01:47:12 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch14_loss0.1416094921529293.pypots
2024-05-25 01:47:28 [INFO]: Epoch 015 - training loss: 0.1533, validation loss: 0.1507
2024-05-25 01:47:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch15_loss0.15070847123861314.pypots
2024-05-25 01:47:45 [INFO]: Epoch 016 - training loss: 0.1449, validation loss: 0.1413
2024-05-25 01:47:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch16_loss0.14132576286792756.pypots
2024-05-25 01:48:02 [INFO]: Epoch 017 - training loss: 0.1510, validation loss: 0.1382
2024-05-25 01:48:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch17_loss0.1382455535233021.pypots
2024-05-25 01:48:19 [INFO]: Epoch 018 - training loss: 0.1461, validation loss: 0.1361
2024-05-25 01:48:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch18_loss0.13614191338419915.pypots
2024-05-25 01:48:36 [INFO]: Epoch 019 - training loss: 0.1351, validation loss: 0.1405
2024-05-25 01:48:36 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch19_loss0.14049641713500022.pypots
2024-05-25 01:48:53 [INFO]: Epoch 020 - training loss: 0.1634, validation loss: 0.1357
2024-05-25 01:48:53 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch20_loss0.13570359498262405.pypots
2024-05-25 01:49:10 [INFO]: Epoch 021 - training loss: 0.1332, validation loss: 0.1308
2024-05-25 01:49:10 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch21_loss0.13080777674913407.pypots
2024-05-25 01:49:27 [INFO]: Epoch 022 - training loss: 0.1596, validation loss: 0.1348
2024-05-25 01:49:27 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch22_loss0.13479981571435928.pypots
2024-05-25 01:49:43 [INFO]: Epoch 023 - training loss: 0.1459, validation loss: 0.1366
2024-05-25 01:49:44 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch23_loss0.13658033683896065.pypots
2024-05-25 01:50:00 [INFO]: Epoch 024 - training loss: 0.1365, validation loss: 0.1322
2024-05-25 01:50:00 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch24_loss0.1321958653628826.pypots
2024-05-25 01:50:17 [INFO]: Epoch 025 - training loss: 0.1477, validation loss: 0.1299
2024-05-25 01:50:17 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch25_loss0.1299239806830883.pypots
2024-05-25 01:50:34 [INFO]: Epoch 026 - training loss: 0.1417, validation loss: 0.1342
2024-05-25 01:50:34 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch26_loss0.13417854011058808.pypots
2024-05-25 01:50:51 [INFO]: Epoch 027 - training loss: 0.1561, validation loss: 0.1257
2024-05-25 01:50:51 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch27_loss0.12569375038146974.pypots
2024-05-25 01:51:08 [INFO]: Epoch 028 - training loss: 0.1435, validation loss: 0.1289
2024-05-25 01:51:08 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch28_loss0.12890089452266693.pypots
2024-05-25 01:51:25 [INFO]: Epoch 029 - training loss: 0.1330, validation loss: 0.1270
2024-05-25 01:51:25 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch29_loss0.12704015523195267.pypots
2024-05-25 01:51:42 [INFO]: Epoch 030 - training loss: 0.1198, validation loss: 0.1242
2024-05-25 01:51:42 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch30_loss0.1242403320968151.pypots
2024-05-25 01:51:58 [INFO]: Epoch 031 - training loss: 0.1299, validation loss: 0.1254
2024-05-25 01:51:58 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch31_loss0.12535540163516998.pypots
2024-05-25 01:52:15 [INFO]: Epoch 032 - training loss: 0.1416, validation loss: 0.1195
2024-05-25 01:52:15 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch32_loss0.1194555014371872.pypots
2024-05-25 01:52:32 [INFO]: Epoch 033 - training loss: 0.1328, validation loss: 0.1210
2024-05-25 01:52:32 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch33_loss0.12097407877445221.pypots
2024-05-25 01:52:49 [INFO]: Epoch 034 - training loss: 0.1410, validation loss: 0.1201
2024-05-25 01:52:49 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch34_loss0.12009494602680207.pypots
2024-05-25 01:53:06 [INFO]: Epoch 035 - training loss: 0.1257, validation loss: 0.1192
2024-05-25 01:53:06 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch35_loss0.11922820210456848.pypots
2024-05-25 01:53:23 [INFO]: Epoch 036 - training loss: 0.1402, validation loss: 0.1274
2024-05-25 01:53:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch36_loss0.12742383256554604.pypots
2024-05-25 01:53:40 [INFO]: Epoch 037 - training loss: 0.1157, validation loss: 0.1222
2024-05-25 01:53:40 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch37_loss0.12217754274606704.pypots
2024-05-25 01:53:56 [INFO]: Epoch 038 - training loss: 0.1389, validation loss: 0.1212
2024-05-25 01:53:57 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch38_loss0.1212010070681572.pypots
2024-05-25 01:54:13 [INFO]: Epoch 039 - training loss: 0.1382, validation loss: 0.1216
2024-05-25 01:54:13 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch39_loss0.1215840071439743.pypots
2024-05-25 01:54:30 [INFO]: Epoch 040 - training loss: 0.1148, validation loss: 0.1175
2024-05-25 01:54:30 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch40_loss0.11749519482254982.pypots
2024-05-25 01:54:47 [INFO]: Epoch 041 - training loss: 0.1297, validation loss: 0.1237
2024-05-25 01:54:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch41_loss0.12369587942957878.pypots
2024-05-25 01:55:04 [INFO]: Epoch 042 - training loss: 0.1541, validation loss: 0.1209
2024-05-25 01:55:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch42_loss0.12089763954281807.pypots
2024-05-25 01:55:21 [INFO]: Epoch 043 - training loss: 0.1394, validation loss: 0.1171
2024-05-25 01:55:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch43_loss0.11706205382943154.pypots
2024-05-25 01:55:38 [INFO]: Epoch 044 - training loss: 0.1354, validation loss: 0.1134
2024-05-25 01:55:38 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch44_loss0.113374163210392.pypots
2024-05-25 01:55:55 [INFO]: Epoch 045 - training loss: 0.1151, validation loss: 0.1129
2024-05-25 01:55:55 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch45_loss0.11291111558675766.pypots
2024-05-25 01:56:11 [INFO]: Epoch 046 - training loss: 0.1366, validation loss: 0.1120
2024-05-25 01:56:11 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch46_loss0.11201805099844933.pypots
2024-05-25 01:56:28 [INFO]: Epoch 047 - training loss: 0.1277, validation loss: 0.1114
2024-05-25 01:56:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch47_loss0.11142295524477959.pypots
2024-05-25 01:56:45 [INFO]: Epoch 048 - training loss: 0.1184, validation loss: 0.1173
2024-05-25 01:56:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch48_loss0.11734929010272026.pypots
2024-05-25 01:57:02 [INFO]: Epoch 049 - training loss: 0.1229, validation loss: 0.1248
2024-05-25 01:57:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch49_loss0.12477324083447457.pypots
2024-05-25 01:57:19 [INFO]: Epoch 050 - training loss: 0.1289, validation loss: 0.1133
2024-05-25 01:57:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch50_loss0.11334980204701424.pypots
2024-05-25 01:57:36 [INFO]: Epoch 051 - training loss: 0.1158, validation loss: 0.1128
2024-05-25 01:57:36 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch51_loss0.11284021660685539.pypots
2024-05-25 01:57:53 [INFO]: Epoch 052 - training loss: 0.1104, validation loss: 0.1146
2024-05-25 01:57:53 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch52_loss0.11460437998175621.pypots
2024-05-25 01:58:09 [INFO]: Epoch 053 - training loss: 0.1308, validation loss: 0.1137
2024-05-25 01:58:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch53_loss0.11372673213481903.pypots
2024-05-25 01:58:26 [INFO]: Epoch 054 - training loss: 0.1237, validation loss: 0.1127
2024-05-25 01:58:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch54_loss0.11265241801738739.pypots
2024-05-25 01:58:43 [INFO]: Epoch 055 - training loss: 0.1247, validation loss: 0.1131
2024-05-25 01:58:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch55_loss0.11313443258404732.pypots
2024-05-25 01:59:00 [INFO]: Epoch 056 - training loss: 0.1085, validation loss: 0.1113
2024-05-25 01:59:00 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch56_loss0.11131213307380676.pypots
2024-05-25 01:59:17 [INFO]: Epoch 057 - training loss: 0.1224, validation loss: 0.1106
2024-05-25 01:59:17 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch57_loss0.11063923910260201.pypots
2024-05-25 01:59:34 [INFO]: Epoch 058 - training loss: 0.1303, validation loss: 0.1098
2024-05-25 01:59:34 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch58_loss0.10978132262825965.pypots
2024-05-25 01:59:51 [INFO]: Epoch 059 - training loss: 0.1080, validation loss: 0.1074
2024-05-25 01:59:51 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch59_loss0.1073512390255928.pypots
2024-05-25 02:00:07 [INFO]: Epoch 060 - training loss: 0.1225, validation loss: 0.1169
2024-05-25 02:00:07 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch60_loss0.11687338799238205.pypots
2024-05-25 02:00:24 [INFO]: Epoch 061 - training loss: 0.1307, validation loss: 0.1108
2024-05-25 02:00:24 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch61_loss0.11078557819128036.pypots
2024-05-25 02:00:41 [INFO]: Epoch 062 - training loss: 0.1257, validation loss: 0.1082
2024-05-25 02:00:41 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch62_loss0.10816271230578423.pypots
2024-05-25 02:00:58 [INFO]: Epoch 063 - training loss: 0.1239, validation loss: 0.1079
2024-05-25 02:00:58 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch63_loss0.10788992121815681.pypots
2024-05-25 02:01:15 [INFO]: Epoch 064 - training loss: 0.1125, validation loss: 0.1076
2024-05-25 02:01:15 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch64_loss0.1076294243335724.pypots
2024-05-25 02:01:32 [INFO]: Epoch 065 - training loss: 0.1234, validation loss: 0.1077
2024-05-25 02:01:32 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch65_loss0.1077128916978836.pypots
2024-05-25 02:01:49 [INFO]: Epoch 066 - training loss: 0.1123, validation loss: 0.1069
2024-05-25 02:01:49 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch66_loss0.10687766671180725.pypots
2024-05-25 02:02:06 [INFO]: Epoch 067 - training loss: 0.1017, validation loss: 0.1055
2024-05-25 02:02:06 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch67_loss0.1055424690246582.pypots
2024-05-25 02:02:22 [INFO]: Epoch 068 - training loss: 0.1273, validation loss: 0.1133
2024-05-25 02:02:22 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch68_loss0.11326135396957397.pypots
2024-05-25 02:02:39 [INFO]: Epoch 069 - training loss: 0.1103, validation loss: 0.1139
2024-05-25 02:02:39 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch69_loss0.11392370834946633.pypots
2024-05-25 02:02:56 [INFO]: Epoch 070 - training loss: 0.1123, validation loss: 0.1104
2024-05-25 02:02:56 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch70_loss0.11041850298643112.pypots
2024-05-25 02:03:13 [INFO]: Epoch 071 - training loss: 0.1113, validation loss: 0.1091
2024-05-25 02:03:13 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch71_loss0.109086874127388.pypots
2024-05-25 02:03:30 [INFO]: Epoch 072 - training loss: 0.1120, validation loss: 0.1068
2024-05-25 02:03:30 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch72_loss0.10675141960382462.pypots
2024-05-25 02:03:47 [INFO]: Epoch 073 - training loss: 0.1147, validation loss: 0.1075
2024-05-25 02:03:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch73_loss0.1075252890586853.pypots
2024-05-25 02:04:04 [INFO]: Epoch 074 - training loss: 0.1126, validation loss: 0.1076
2024-05-25 02:04:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch74_loss0.10761327967047692.pypots
2024-05-25 02:04:21 [INFO]: Epoch 075 - training loss: 0.1108, validation loss: 0.1128
2024-05-25 02:04:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch75_loss0.11283652260899543.pypots
2024-05-25 02:04:37 [INFO]: Epoch 076 - training loss: 0.1101, validation loss: 0.1067
2024-05-25 02:04:37 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch76_loss0.10665663331747055.pypots
2024-05-25 02:04:54 [INFO]: Epoch 077 - training loss: 0.1211, validation loss: 0.1035
2024-05-25 02:04:54 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch77_loss0.10354437753558159.pypots
2024-05-25 02:05:11 [INFO]: Epoch 078 - training loss: 0.1143, validation loss: 0.1040
2024-05-25 02:05:11 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch78_loss0.10395728051662445.pypots
2024-05-25 02:05:28 [INFO]: Epoch 079 - training loss: 0.1144, validation loss: 0.1035
2024-05-25 02:05:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch79_loss0.10352904573082924.pypots
2024-05-25 02:05:45 [INFO]: Epoch 080 - training loss: 0.1205, validation loss: 0.1069
2024-05-25 02:05:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch80_loss0.10691280290484428.pypots
2024-05-25 02:06:02 [INFO]: Epoch 081 - training loss: 0.1200, validation loss: 0.1101
2024-05-25 02:06:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch81_loss0.1101393535733223.pypots
2024-05-25 02:06:19 [INFO]: Epoch 082 - training loss: 0.1271, validation loss: 0.1113
2024-05-25 02:06:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch82_loss0.11133671253919601.pypots
2024-05-25 02:06:36 [INFO]: Epoch 083 - training loss: 0.1099, validation loss: 0.1070
2024-05-25 02:06:36 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch83_loss0.1070225104689598.pypots
2024-05-25 02:06:52 [INFO]: Epoch 084 - training loss: 0.1129, validation loss: 0.1046
2024-05-25 02:06:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch84_loss0.10458008125424385.pypots
2024-05-25 02:07:09 [INFO]: Epoch 085 - training loss: 0.1227, validation loss: 0.1046
2024-05-25 02:07:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch85_loss0.10460559055209159.pypots
2024-05-25 02:07:26 [INFO]: Epoch 086 - training loss: 0.1029, validation loss: 0.1039
2024-05-25 02:07:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch86_loss0.10392138212919236.pypots
2024-05-25 02:07:43 [INFO]: Epoch 087 - training loss: 0.1111, validation loss: 0.1042
2024-05-25 02:07:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch87_loss0.10424372404813767.pypots
2024-05-25 02:08:00 [INFO]: Epoch 088 - training loss: 0.1251, validation loss: 0.1055
2024-05-25 02:08:00 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch88_loss0.10548876821994782.pypots
2024-05-25 02:08:17 [INFO]: Epoch 089 - training loss: 0.1102, validation loss: 0.1045
2024-05-25 02:08:17 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI_epoch89_loss0.10447480231523514.pypots
2024-05-25 02:08:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:08:17 [INFO]: Finished training. The best model is from epoch#79.
2024-05-25 02:08:17 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T014316/CSDI.pypots
2024-05-25 02:10:37 [INFO]: CSDI on Air-Quality: MAE=0.1064, MSE=0.0955
2024-05-25 02:10:37 [INFO]: Successfully saved to augmentation_saved_results/round_1/CSDI_air_quality/imputation.pkl
2024-05-25 02:10:37 [INFO]: Using the given device: cuda:0
2024-05-25 02:10:38 [INFO]: Model files will be saved to augmentation_saved_results/round_1/GPVAE_air_quality/20240525_T021037
2024-05-25 02:10:38 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/GPVAE_air_quality/20240525_T021037/tensorboard
2024-05-25 02:10:38 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 02:10:38 [INFO]: Epoch 001 - training loss: 63802.7429, validation loss: 0.7006
2024-05-25 02:10:38 [INFO]: Epoch 002 - training loss: 42064.9284, validation loss: 0.6270
2024-05-25 02:10:39 [INFO]: Epoch 003 - training loss: 41773.8611, validation loss: 0.5741
2024-05-25 02:10:39 [INFO]: Epoch 004 - training loss: 41637.1709, validation loss: 0.5082
2024-05-25 02:10:39 [INFO]: Epoch 005 - training loss: 41555.9786, validation loss: 0.4780
2024-05-25 02:10:39 [INFO]: Epoch 006 - training loss: 41496.0657, validation loss: 0.4427
2024-05-25 02:10:40 [INFO]: Epoch 007 - training loss: 41469.0493, validation loss: 0.4345
2024-05-25 02:10:40 [INFO]: Epoch 008 - training loss: 41422.8364, validation loss: 0.3873
2024-05-25 02:10:40 [INFO]: Epoch 009 - training loss: 41376.1254, validation loss: 0.3632
2024-05-25 02:10:41 [INFO]: Epoch 010 - training loss: 41359.1927, validation loss: 0.3647
2024-05-25 02:10:41 [INFO]: Epoch 011 - training loss: 41415.3675, validation loss: 0.3802
2024-05-25 02:10:41 [INFO]: Epoch 012 - training loss: 41396.2448, validation loss: 0.3934
2024-05-25 02:10:42 [INFO]: Epoch 013 - training loss: 41401.4737, validation loss: 0.3642
2024-05-25 02:10:42 [INFO]: Epoch 014 - training loss: 41377.5041, validation loss: 0.3550
2024-05-25 02:10:42 [INFO]: Epoch 015 - training loss: 41326.2138, validation loss: 0.3314
2024-05-25 02:10:43 [INFO]: Epoch 016 - training loss: 41303.8584, validation loss: 0.3370
2024-05-25 02:10:43 [INFO]: Epoch 017 - training loss: 41300.2501, validation loss: 0.3270
2024-05-25 02:10:43 [INFO]: Epoch 018 - training loss: 41280.7824, validation loss: 0.3174
2024-05-25 02:10:44 [INFO]: Epoch 019 - training loss: 41265.9268, validation loss: 0.3076
2024-05-25 02:10:44 [INFO]: Epoch 020 - training loss: 41255.7808, validation loss: 0.3031
2024-05-25 02:10:44 [INFO]: Epoch 021 - training loss: 41247.5774, validation loss: 0.3089
2024-05-25 02:10:45 [INFO]: Epoch 022 - training loss: 41243.9708, validation loss: 0.3028
2024-05-25 02:10:45 [INFO]: Epoch 023 - training loss: 41250.6649, validation loss: 0.3066
2024-05-25 02:10:45 [INFO]: Epoch 024 - training loss: 41276.0247, validation loss: 0.3186
2024-05-25 02:10:46 [INFO]: Epoch 025 - training loss: 41274.4109, validation loss: 0.3133
2024-05-25 02:10:46 [INFO]: Epoch 026 - training loss: 41255.2407, validation loss: 0.2975
2024-05-25 02:10:46 [INFO]: Epoch 027 - training loss: 41247.3260, validation loss: 0.3018
2024-05-25 02:10:47 [INFO]: Epoch 028 - training loss: 41226.9661, validation loss: 0.2894
2024-05-25 02:10:47 [INFO]: Epoch 029 - training loss: 41215.3992, validation loss: 0.2914
2024-05-25 02:10:47 [INFO]: Epoch 030 - training loss: 41224.4981, validation loss: 0.2926
2024-05-25 02:10:48 [INFO]: Epoch 031 - training loss: 41223.0352, validation loss: 0.3073
2024-05-25 02:10:48 [INFO]: Epoch 032 - training loss: 41224.6555, validation loss: 0.3194
2024-05-25 02:10:48 [INFO]: Epoch 033 - training loss: 41212.8520, validation loss: 0.2805
2024-05-25 02:10:49 [INFO]: Epoch 034 - training loss: 41198.3111, validation loss: 0.2811
2024-05-25 02:10:49 [INFO]: Epoch 035 - training loss: 41189.2093, validation loss: 0.2775
2024-05-25 02:10:49 [INFO]: Epoch 036 - training loss: 41202.8613, validation loss: 0.2927
2024-05-25 02:10:50 [INFO]: Epoch 037 - training loss: 41202.1043, validation loss: 0.2794
2024-05-25 02:10:50 [INFO]: Epoch 038 - training loss: 41195.2260, validation loss: 0.2834
2024-05-25 02:10:50 [INFO]: Epoch 039 - training loss: 41201.8883, validation loss: 0.2930
2024-05-25 02:10:51 [INFO]: Epoch 040 - training loss: 41210.7611, validation loss: 0.2872
2024-05-25 02:10:51 [INFO]: Epoch 041 - training loss: 41348.3859, validation loss: 0.3333
2024-05-25 02:10:51 [INFO]: Epoch 042 - training loss: 41249.5292, validation loss: 0.2865
2024-05-25 02:10:52 [INFO]: Epoch 043 - training loss: 41244.3034, validation loss: 0.2973
2024-05-25 02:10:52 [INFO]: Epoch 044 - training loss: 41230.7263, validation loss: 0.2800
2024-05-25 02:10:52 [INFO]: Epoch 045 - training loss: 41213.1924, validation loss: 0.2952
2024-05-25 02:10:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:10:52 [INFO]: Finished training. The best model is from epoch#35.
2024-05-25 02:10:52 [INFO]: Saved the model to augmentation_saved_results/round_1/GPVAE_air_quality/20240525_T021037/GPVAE.pypots
2024-05-25 02:10:52 [INFO]: GP-VAE on Air-Quality: MAE=0.2920, MSE=0.2354
2024-05-25 02:10:52 [INFO]: Successfully saved to augmentation_saved_results/round_1/GPVAE_air_quality/imputation.pkl
2024-05-25 02:10:52 [INFO]: Using the given device: cuda:0
2024-05-25 02:10:52 [INFO]: Model files will be saved to augmentation_saved_results/round_1/USGAN_air_quality/20240525_T021052
2024-05-25 02:10:52 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/USGAN_air_quality/20240525_T021052/tensorboard
2024-05-25 02:10:52 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 02:10:57 [INFO]: Epoch 001 - generator training loss: 0.6136, discriminator training loss: 0.2937, validation loss: 0.5478
2024-05-25 02:11:01 [INFO]: Epoch 002 - generator training loss: 0.2948, discriminator training loss: 0.0673, validation loss: 0.4200
2024-05-25 02:11:05 [INFO]: Epoch 003 - generator training loss: 0.2209, discriminator training loss: 0.0633, validation loss: 0.3504
2024-05-25 02:11:10 [INFO]: Epoch 004 - generator training loss: 0.1773, discriminator training loss: 0.0629, validation loss: 0.3110
2024-05-25 02:11:14 [INFO]: Epoch 005 - generator training loss: 0.1493, discriminator training loss: 0.0625, validation loss: 0.2869
2024-05-25 02:11:18 [INFO]: Epoch 006 - generator training loss: 0.1339, discriminator training loss: 0.0611, validation loss: 0.2691
2024-05-25 02:11:22 [INFO]: Epoch 007 - generator training loss: 0.1190, discriminator training loss: 0.0609, validation loss: 0.2569
2024-05-25 02:11:26 [INFO]: Epoch 008 - generator training loss: 0.1096, discriminator training loss: 0.0597, validation loss: 0.2470
2024-05-25 02:11:30 [INFO]: Epoch 009 - generator training loss: 0.1003, discriminator training loss: 0.0591, validation loss: 0.2382
2024-05-25 02:11:34 [INFO]: Epoch 010 - generator training loss: 0.0942, discriminator training loss: 0.0581, validation loss: 0.2319
2024-05-25 02:11:38 [INFO]: Epoch 011 - generator training loss: 0.0908, discriminator training loss: 0.0574, validation loss: 0.2269
2024-05-25 02:11:43 [INFO]: Epoch 012 - generator training loss: 0.0839, discriminator training loss: 0.0563, validation loss: 0.2217
2024-05-25 02:11:47 [INFO]: Epoch 013 - generator training loss: 0.0800, discriminator training loss: 0.0546, validation loss: 0.2174
2024-05-25 02:11:51 [INFO]: Epoch 014 - generator training loss: 0.0783, discriminator training loss: 0.0529, validation loss: 0.2135
2024-05-25 02:11:55 [INFO]: Epoch 015 - generator training loss: 0.0750, discriminator training loss: 0.0523, validation loss: 0.2101
2024-05-25 02:11:59 [INFO]: Epoch 016 - generator training loss: 0.0721, discriminator training loss: 0.0508, validation loss: 0.2073
2024-05-25 02:12:03 [INFO]: Epoch 017 - generator training loss: 0.0716, discriminator training loss: 0.0491, validation loss: 0.2050
2024-05-25 02:12:07 [INFO]: Epoch 018 - generator training loss: 0.0687, discriminator training loss: 0.0475, validation loss: 0.2024
2024-05-25 02:12:11 [INFO]: Epoch 019 - generator training loss: 0.0686, discriminator training loss: 0.0463, validation loss: 0.1999
2024-05-25 02:12:16 [INFO]: Epoch 020 - generator training loss: 0.0657, discriminator training loss: 0.0454, validation loss: 0.1985
2024-05-25 02:12:20 [INFO]: Epoch 021 - generator training loss: 0.0642, discriminator training loss: 0.0454, validation loss: 0.1962
2024-05-25 02:12:24 [INFO]: Epoch 022 - generator training loss: 0.0621, discriminator training loss: 0.0444, validation loss: 0.1945
2024-05-25 02:12:28 [INFO]: Epoch 023 - generator training loss: 0.0606, discriminator training loss: 0.0437, validation loss: 0.1931
2024-05-25 02:12:32 [INFO]: Epoch 024 - generator training loss: 0.0602, discriminator training loss: 0.0424, validation loss: 0.1916
2024-05-25 02:12:36 [INFO]: Epoch 025 - generator training loss: 0.0602, discriminator training loss: 0.0419, validation loss: 0.1895
2024-05-25 02:12:40 [INFO]: Epoch 026 - generator training loss: 0.0575, discriminator training loss: 0.0411, validation loss: 0.1884
2024-05-25 02:12:44 [INFO]: Epoch 027 - generator training loss: 0.0570, discriminator training loss: 0.0407, validation loss: 0.1858
2024-05-25 02:12:49 [INFO]: Epoch 028 - generator training loss: 0.0559, discriminator training loss: 0.0392, validation loss: 0.1840
2024-05-25 02:12:53 [INFO]: Epoch 029 - generator training loss: 0.0554, discriminator training loss: 0.0389, validation loss: 0.1829
2024-05-25 02:12:57 [INFO]: Epoch 030 - generator training loss: 0.0553, discriminator training loss: 0.0377, validation loss: 0.1806
2024-05-25 02:13:01 [INFO]: Epoch 031 - generator training loss: 0.0541, discriminator training loss: 0.0368, validation loss: 0.1817
2024-05-25 02:13:05 [INFO]: Epoch 032 - generator training loss: 0.0544, discriminator training loss: 0.0359, validation loss: 0.1789
2024-05-25 02:13:09 [INFO]: Epoch 033 - generator training loss: 0.0536, discriminator training loss: 0.0351, validation loss: 0.1780
2024-05-25 02:13:13 [INFO]: Epoch 034 - generator training loss: 0.0529, discriminator training loss: 0.0348, validation loss: 0.1769
2024-05-25 02:13:18 [INFO]: Epoch 035 - generator training loss: 0.0531, discriminator training loss: 0.0336, validation loss: 0.1759
2024-05-25 02:13:22 [INFO]: Epoch 036 - generator training loss: 0.0524, discriminator training loss: 0.0329, validation loss: 0.1751
2024-05-25 02:13:26 [INFO]: Epoch 037 - generator training loss: 0.0519, discriminator training loss: 0.0323, validation loss: 0.1745
2024-05-25 02:13:30 [INFO]: Epoch 038 - generator training loss: 0.0517, discriminator training loss: 0.0315, validation loss: 0.1734
2024-05-25 02:13:34 [INFO]: Epoch 039 - generator training loss: 0.0514, discriminator training loss: 0.0310, validation loss: 0.1726
2024-05-25 02:13:38 [INFO]: Epoch 040 - generator training loss: 0.0508, discriminator training loss: 0.0303, validation loss: 0.1725
2024-05-25 02:13:42 [INFO]: Epoch 041 - generator training loss: 0.0503, discriminator training loss: 0.0299, validation loss: 0.1709
2024-05-25 02:13:46 [INFO]: Epoch 042 - generator training loss: 0.0512, discriminator training loss: 0.0290, validation loss: 0.1704
2024-05-25 02:13:51 [INFO]: Epoch 043 - generator training loss: 0.0502, discriminator training loss: 0.0284, validation loss: 0.1694
2024-05-25 02:13:55 [INFO]: Epoch 044 - generator training loss: 0.0504, discriminator training loss: 0.0279, validation loss: 0.1698
2024-05-25 02:13:59 [INFO]: Epoch 045 - generator training loss: 0.0501, discriminator training loss: 0.0278, validation loss: 0.1689
2024-05-25 02:14:03 [INFO]: Epoch 046 - generator training loss: 0.0488, discriminator training loss: 0.0272, validation loss: 0.1678
2024-05-25 02:14:07 [INFO]: Epoch 047 - generator training loss: 0.0487, discriminator training loss: 0.0266, validation loss: 0.1667
2024-05-25 02:14:11 [INFO]: Epoch 048 - generator training loss: 0.0481, discriminator training loss: 0.0263, validation loss: 0.1665
2024-05-25 02:14:15 [INFO]: Epoch 049 - generator training loss: 0.0496, discriminator training loss: 0.0257, validation loss: 0.1662
2024-05-25 02:14:19 [INFO]: Epoch 050 - generator training loss: 0.0477, discriminator training loss: 0.0253, validation loss: 0.1651
2024-05-25 02:14:24 [INFO]: Epoch 051 - generator training loss: 0.0471, discriminator training loss: 0.0249, validation loss: 0.1649
2024-05-25 02:14:28 [INFO]: Epoch 052 - generator training loss: 0.0469, discriminator training loss: 0.0247, validation loss: 0.1640
2024-05-25 02:14:32 [INFO]: Epoch 053 - generator training loss: 0.0468, discriminator training loss: 0.0243, validation loss: 0.1636
2024-05-25 02:14:36 [INFO]: Epoch 054 - generator training loss: 0.0466, discriminator training loss: 0.0239, validation loss: 0.1636
2024-05-25 02:14:40 [INFO]: Epoch 055 - generator training loss: 0.0459, discriminator training loss: 0.0235, validation loss: 0.1657
2024-05-25 02:14:44 [INFO]: Epoch 056 - generator training loss: 0.0449, discriminator training loss: 0.0233, validation loss: 0.1752
2024-05-25 02:14:48 [INFO]: Epoch 057 - generator training loss: 0.0448, discriminator training loss: 0.0228, validation loss: 0.1776
2024-05-25 02:14:53 [INFO]: Epoch 058 - generator training loss: 0.0447, discriminator training loss: 0.0227, validation loss: 0.1781
2024-05-25 02:14:57 [INFO]: Epoch 059 - generator training loss: 0.0446, discriminator training loss: 0.0223, validation loss: 0.1776
2024-05-25 02:15:01 [INFO]: Epoch 060 - generator training loss: 0.0440, discriminator training loss: 0.0220, validation loss: 0.1769
2024-05-25 02:15:05 [INFO]: Epoch 061 - generator training loss: 0.0437, discriminator training loss: 0.0215, validation loss: 0.1760
2024-05-25 02:15:09 [INFO]: Epoch 062 - generator training loss: 0.0426, discriminator training loss: 0.0217, validation loss: 0.1757
2024-05-25 02:15:13 [INFO]: Epoch 063 - generator training loss: 0.0428, discriminator training loss: 0.0213, validation loss: 0.1749
2024-05-25 02:15:17 [INFO]: Epoch 064 - generator training loss: 0.0426, discriminator training loss: 0.0210, validation loss: 0.1739
2024-05-25 02:15:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:15:17 [INFO]: Finished training. The best model is from epoch#54.
2024-05-25 02:15:17 [INFO]: Saved the model to augmentation_saved_results/round_1/USGAN_air_quality/20240525_T021052/USGAN.pypots
2024-05-25 02:15:18 [INFO]: US-GAN on Air-Quality: MAE=0.1656, MSE=0.0978
2024-05-25 02:15:18 [INFO]: Successfully saved to augmentation_saved_results/round_1/USGAN_air_quality/imputation.pkl
2024-05-25 02:15:18 [INFO]: Using the given device: cuda:0
2024-05-25 02:15:18 [INFO]: Model files will be saved to augmentation_saved_results/round_1/BRITS_air_quality/20240525_T021518
2024-05-25 02:15:18 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/BRITS_air_quality/20240525_T021518/tensorboard
2024-05-25 02:15:18 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 02:15:21 [INFO]: Epoch 001 - training loss: 1.4275, validation loss: 0.9702
2024-05-25 02:15:24 [INFO]: Epoch 002 - training loss: 1.1453, validation loss: 0.7246
2024-05-25 02:15:27 [INFO]: Epoch 003 - training loss: 0.9527, validation loss: 0.6140
2024-05-25 02:15:30 [INFO]: Epoch 004 - training loss: 0.8425, validation loss: 0.5488
2024-05-25 02:15:33 [INFO]: Epoch 005 - training loss: 0.7684, validation loss: 0.5002
2024-05-25 02:15:35 [INFO]: Epoch 006 - training loss: 0.7077, validation loss: 0.4650
2024-05-25 02:15:38 [INFO]: Epoch 007 - training loss: 0.6599, validation loss: 0.4348
2024-05-25 02:15:41 [INFO]: Epoch 008 - training loss: 0.6260, validation loss: 0.4116
2024-05-25 02:15:44 [INFO]: Epoch 009 - training loss: 0.6005, validation loss: 0.3927
2024-05-25 02:15:47 [INFO]: Epoch 010 - training loss: 0.5768, validation loss: 0.3780
2024-05-25 02:15:49 [INFO]: Epoch 011 - training loss: 0.5585, validation loss: 0.3646
2024-05-25 02:15:52 [INFO]: Epoch 012 - training loss: 0.5443, validation loss: 0.3539
2024-05-25 02:15:55 [INFO]: Epoch 013 - training loss: 0.5308, validation loss: 0.3440
2024-05-25 02:15:58 [INFO]: Epoch 014 - training loss: 0.5191, validation loss: 0.3352
2024-05-25 02:16:01 [INFO]: Epoch 015 - training loss: 0.5064, validation loss: 0.3280
2024-05-25 02:16:03 [INFO]: Epoch 016 - training loss: 0.4976, validation loss: 0.3221
2024-05-25 02:16:06 [INFO]: Epoch 017 - training loss: 0.4876, validation loss: 0.3159
2024-05-25 02:16:09 [INFO]: Epoch 018 - training loss: 0.4803, validation loss: 0.3107
2024-05-25 02:16:12 [INFO]: Epoch 019 - training loss: 0.4724, validation loss: 0.3053
2024-05-25 02:16:14 [INFO]: Epoch 020 - training loss: 0.4650, validation loss: 0.3011
2024-05-25 02:16:17 [INFO]: Epoch 021 - training loss: 0.4579, validation loss: 0.2971
2024-05-25 02:16:20 [INFO]: Epoch 022 - training loss: 0.4509, validation loss: 0.2928
2024-05-25 02:16:23 [INFO]: Epoch 023 - training loss: 0.4452, validation loss: 0.2889
2024-05-25 02:16:26 [INFO]: Epoch 024 - training loss: 0.4384, validation loss: 0.2855
2024-05-25 02:16:28 [INFO]: Epoch 025 - training loss: 0.4335, validation loss: 0.2822
2024-05-25 02:16:31 [INFO]: Epoch 026 - training loss: 0.4273, validation loss: 0.2788
2024-05-25 02:16:34 [INFO]: Epoch 027 - training loss: 0.4219, validation loss: 0.2752
2024-05-25 02:16:37 [INFO]: Epoch 028 - training loss: 0.4171, validation loss: 0.2723
2024-05-25 02:16:39 [INFO]: Epoch 029 - training loss: 0.4123, validation loss: 0.2694
2024-05-25 02:16:42 [INFO]: Epoch 030 - training loss: 0.4081, validation loss: 0.2665
2024-05-25 02:16:45 [INFO]: Epoch 031 - training loss: 0.4025, validation loss: 0.2641
2024-05-25 02:16:48 [INFO]: Epoch 032 - training loss: 0.3990, validation loss: 0.2606
2024-05-25 02:16:51 [INFO]: Epoch 033 - training loss: 0.3944, validation loss: 0.2582
2024-05-25 02:16:53 [INFO]: Epoch 034 - training loss: 0.3910, validation loss: 0.2556
2024-05-25 02:16:56 [INFO]: Epoch 035 - training loss: 0.3867, validation loss: 0.2528
2024-05-25 02:16:59 [INFO]: Epoch 036 - training loss: 0.3841, validation loss: 0.2503
2024-05-25 02:17:02 [INFO]: Epoch 037 - training loss: 0.3797, validation loss: 0.2478
2024-05-25 02:17:05 [INFO]: Epoch 038 - training loss: 0.3756, validation loss: 0.2456
2024-05-25 02:17:07 [INFO]: Epoch 039 - training loss: 0.3724, validation loss: 0.2431
2024-05-25 02:17:10 [INFO]: Epoch 040 - training loss: 0.3693, validation loss: 0.2407
2024-05-25 02:17:13 [INFO]: Epoch 041 - training loss: 0.3661, validation loss: 0.2388
2024-05-25 02:17:16 [INFO]: Epoch 042 - training loss: 0.3632, validation loss: 0.2363
2024-05-25 02:17:18 [INFO]: Epoch 043 - training loss: 0.3598, validation loss: 0.2345
2024-05-25 02:17:21 [INFO]: Epoch 044 - training loss: 0.3562, validation loss: 0.2326
2024-05-25 02:17:24 [INFO]: Epoch 045 - training loss: 0.3539, validation loss: 0.2309
2024-05-25 02:17:27 [INFO]: Epoch 046 - training loss: 0.3509, validation loss: 0.2292
2024-05-25 02:17:30 [INFO]: Epoch 047 - training loss: 0.3478, validation loss: 0.2278
2024-05-25 02:17:32 [INFO]: Epoch 048 - training loss: 0.3462, validation loss: 0.2264
2024-05-25 02:17:35 [INFO]: Epoch 049 - training loss: 0.3433, validation loss: 0.2253
2024-05-25 02:17:38 [INFO]: Epoch 050 - training loss: 0.3416, validation loss: 0.2239
2024-05-25 02:17:41 [INFO]: Epoch 051 - training loss: 0.3389, validation loss: 0.2232
2024-05-25 02:17:44 [INFO]: Epoch 052 - training loss: 0.3362, validation loss: 0.2224
2024-05-25 02:17:46 [INFO]: Epoch 053 - training loss: 0.3341, validation loss: 0.2211
2024-05-25 02:17:49 [INFO]: Epoch 054 - training loss: 0.3327, validation loss: 0.2202
2024-05-25 02:17:52 [INFO]: Epoch 055 - training loss: 0.3290, validation loss: 0.2195
2024-05-25 02:17:55 [INFO]: Epoch 056 - training loss: 0.3279, validation loss: 0.2189
2024-05-25 02:17:58 [INFO]: Epoch 057 - training loss: 0.3265, validation loss: 0.2182
2024-05-25 02:18:00 [INFO]: Epoch 058 - training loss: 0.3262, validation loss: 0.2177
2024-05-25 02:18:03 [INFO]: Epoch 059 - training loss: 0.3232, validation loss: 0.2165
2024-05-25 02:18:06 [INFO]: Epoch 060 - training loss: 0.3206, validation loss: 0.2159
2024-05-25 02:18:09 [INFO]: Epoch 061 - training loss: 0.3196, validation loss: 0.2152
2024-05-25 02:18:11 [INFO]: Epoch 062 - training loss: 0.3181, validation loss: 0.2151
2024-05-25 02:18:14 [INFO]: Epoch 063 - training loss: 0.3162, validation loss: 0.2142
2024-05-25 02:18:17 [INFO]: Epoch 064 - training loss: 0.3146, validation loss: 0.2139
2024-05-25 02:18:20 [INFO]: Epoch 065 - training loss: 0.3133, validation loss: 0.2133
2024-05-25 02:18:23 [INFO]: Epoch 066 - training loss: 0.3126, validation loss: 0.2129
2024-05-25 02:18:25 [INFO]: Epoch 067 - training loss: 0.3101, validation loss: 0.2128
2024-05-25 02:18:28 [INFO]: Epoch 068 - training loss: 0.3090, validation loss: 0.2119
2024-05-25 02:18:31 [INFO]: Epoch 069 - training loss: 0.3085, validation loss: 0.2120
2024-05-25 02:18:34 [INFO]: Epoch 070 - training loss: 0.3067, validation loss: 0.2113
2024-05-25 02:18:37 [INFO]: Epoch 071 - training loss: 0.3053, validation loss: 0.2110
2024-05-25 02:18:39 [INFO]: Epoch 072 - training loss: 0.3049, validation loss: 0.2102
2024-05-25 02:18:42 [INFO]: Epoch 073 - training loss: 0.3034, validation loss: 0.2100
2024-05-25 02:18:45 [INFO]: Epoch 074 - training loss: 0.3023, validation loss: 0.2096
2024-05-25 02:18:48 [INFO]: Epoch 075 - training loss: 0.3008, validation loss: 0.2092
2024-05-25 02:18:50 [INFO]: Epoch 076 - training loss: 0.2993, validation loss: 0.2088
2024-05-25 02:18:53 [INFO]: Epoch 077 - training loss: 0.2997, validation loss: 0.2088
2024-05-25 02:18:56 [INFO]: Epoch 078 - training loss: 0.2978, validation loss: 0.2081
2024-05-25 02:18:59 [INFO]: Epoch 079 - training loss: 0.2969, validation loss: 0.2076
2024-05-25 02:19:02 [INFO]: Epoch 080 - training loss: 0.2965, validation loss: 0.2076
2024-05-25 02:19:04 [INFO]: Epoch 081 - training loss: 0.2948, validation loss: 0.2068
2024-05-25 02:19:07 [INFO]: Epoch 082 - training loss: 0.2941, validation loss: 0.2065
2024-05-25 02:19:10 [INFO]: Epoch 083 - training loss: 0.2930, validation loss: 0.2062
2024-05-25 02:19:13 [INFO]: Epoch 084 - training loss: 0.2924, validation loss: 0.2058
2024-05-25 02:19:16 [INFO]: Epoch 085 - training loss: 0.2909, validation loss: 0.2056
2024-05-25 02:19:18 [INFO]: Epoch 086 - training loss: 0.2906, validation loss: 0.2053
2024-05-25 02:19:21 [INFO]: Epoch 087 - training loss: 0.2899, validation loss: 0.2049
2024-05-25 02:19:24 [INFO]: Epoch 088 - training loss: 0.2887, validation loss: 0.2045
2024-05-25 02:19:27 [INFO]: Epoch 089 - training loss: 0.2880, validation loss: 0.2043
2024-05-25 02:19:29 [INFO]: Epoch 090 - training loss: 0.2872, validation loss: 0.2040
2024-05-25 02:19:32 [INFO]: Epoch 091 - training loss: 0.2866, validation loss: 0.2036
2024-05-25 02:19:35 [INFO]: Epoch 092 - training loss: 0.2858, validation loss: 0.2032
2024-05-25 02:19:38 [INFO]: Epoch 093 - training loss: 0.2849, validation loss: 0.2028
2024-05-25 02:19:41 [INFO]: Epoch 094 - training loss: 0.2842, validation loss: 0.2028
2024-05-25 02:19:43 [INFO]: Epoch 095 - training loss: 0.2837, validation loss: 0.2024
2024-05-25 02:19:46 [INFO]: Epoch 096 - training loss: 0.2841, validation loss: 0.2020
2024-05-25 02:19:49 [INFO]: Epoch 097 - training loss: 0.2821, validation loss: 0.2016
2024-05-25 02:19:52 [INFO]: Epoch 098 - training loss: 0.2819, validation loss: 0.2011
2024-05-25 02:19:55 [INFO]: Epoch 099 - training loss: 0.2810, validation loss: 0.2009
2024-05-25 02:19:57 [INFO]: Epoch 100 - training loss: 0.2801, validation loss: 0.2005
2024-05-25 02:20:00 [INFO]: Epoch 101 - training loss: 0.2797, validation loss: 0.2002
2024-05-25 02:20:03 [INFO]: Epoch 102 - training loss: 0.2795, validation loss: 0.1998
2024-05-25 02:20:06 [INFO]: Epoch 103 - training loss: 0.2783, validation loss: 0.1994
2024-05-25 02:20:08 [INFO]: Epoch 104 - training loss: 0.2776, validation loss: 0.1990
2024-05-25 02:20:11 [INFO]: Epoch 105 - training loss: 0.2777, validation loss: 0.1984
2024-05-25 02:20:14 [INFO]: Epoch 106 - training loss: 0.2765, validation loss: 0.1982
2024-05-25 02:20:17 [INFO]: Epoch 107 - training loss: 0.2761, validation loss: 0.1977
2024-05-25 02:20:20 [INFO]: Epoch 108 - training loss: 0.2753, validation loss: 0.1971
2024-05-25 02:20:22 [INFO]: Epoch 109 - training loss: 0.2752, validation loss: 0.1966
2024-05-25 02:20:25 [INFO]: Epoch 110 - training loss: 0.2748, validation loss: 0.1961
2024-05-25 02:20:28 [INFO]: Epoch 111 - training loss: 0.2736, validation loss: 0.1957
2024-05-25 02:20:31 [INFO]: Epoch 112 - training loss: 0.2728, validation loss: 0.1954
2024-05-25 02:20:33 [INFO]: Epoch 113 - training loss: 0.2727, validation loss: 0.1949
2024-05-25 02:20:36 [INFO]: Epoch 114 - training loss: 0.2719, validation loss: 0.1944
2024-05-25 02:20:39 [INFO]: Epoch 115 - training loss: 0.2716, validation loss: 0.1941
2024-05-25 02:20:42 [INFO]: Epoch 116 - training loss: 0.2710, validation loss: 0.1936
2024-05-25 02:20:45 [INFO]: Epoch 117 - training loss: 0.2706, validation loss: 0.1931
2024-05-25 02:20:47 [INFO]: Epoch 118 - training loss: 0.2704, validation loss: 0.1927
2024-05-25 02:20:50 [INFO]: Epoch 119 - training loss: 0.2697, validation loss: 0.1923
2024-05-25 02:20:53 [INFO]: Epoch 120 - training loss: 0.2693, validation loss: 0.1918
2024-05-25 02:20:56 [INFO]: Epoch 121 - training loss: 0.2685, validation loss: 0.1913
2024-05-25 02:20:58 [INFO]: Epoch 122 - training loss: 0.2682, validation loss: 0.1909
2024-05-25 02:21:01 [INFO]: Epoch 123 - training loss: 0.2682, validation loss: 0.1906
2024-05-25 02:21:04 [INFO]: Epoch 124 - training loss: 0.2673, validation loss: 0.1903
2024-05-25 02:21:07 [INFO]: Epoch 125 - training loss: 0.2665, validation loss: 0.1900
2024-05-25 02:21:10 [INFO]: Epoch 126 - training loss: 0.2662, validation loss: 0.1894
2024-05-25 02:21:13 [INFO]: Epoch 127 - training loss: 0.2652, validation loss: 0.1890
2024-05-25 02:21:15 [INFO]: Epoch 128 - training loss: 0.2654, validation loss: 0.1888
2024-05-25 02:21:18 [INFO]: Epoch 129 - training loss: 0.2646, validation loss: 0.1884
2024-05-25 02:21:21 [INFO]: Epoch 130 - training loss: 0.2647, validation loss: 0.1877
2024-05-25 02:21:24 [INFO]: Epoch 131 - training loss: 0.2644, validation loss: 0.1876
2024-05-25 02:21:26 [INFO]: Epoch 132 - training loss: 0.2638, validation loss: 0.1872
2024-05-25 02:21:29 [INFO]: Epoch 133 - training loss: 0.2631, validation loss: 0.1867
2024-05-25 02:21:32 [INFO]: Epoch 134 - training loss: 0.2629, validation loss: 0.1866
2024-05-25 02:21:35 [INFO]: Epoch 135 - training loss: 0.2623, validation loss: 0.1860
2024-05-25 02:21:38 [INFO]: Epoch 136 - training loss: 0.2618, validation loss: 0.1859
2024-05-25 02:21:40 [INFO]: Epoch 137 - training loss: 0.2618, validation loss: 0.1855
2024-05-25 02:21:43 [INFO]: Epoch 138 - training loss: 0.2614, validation loss: 0.1852
2024-05-25 02:21:46 [INFO]: Epoch 139 - training loss: 0.2604, validation loss: 0.1849
2024-05-25 02:21:49 [INFO]: Epoch 140 - training loss: 0.2611, validation loss: 0.1846
2024-05-25 02:21:52 [INFO]: Epoch 141 - training loss: 0.2600, validation loss: 0.1842
2024-05-25 02:21:54 [INFO]: Epoch 142 - training loss: 0.2597, validation loss: 0.1838
2024-05-25 02:21:57 [INFO]: Epoch 143 - training loss: 0.2591, validation loss: 0.1836
2024-05-25 02:22:00 [INFO]: Epoch 144 - training loss: 0.2595, validation loss: 0.1832
2024-05-25 02:22:03 [INFO]: Epoch 145 - training loss: 0.2591, validation loss: 0.1829
2024-05-25 02:22:05 [INFO]: Epoch 146 - training loss: 0.2590, validation loss: 0.1827
2024-05-25 02:22:08 [INFO]: Epoch 147 - training loss: 0.2577, validation loss: 0.1822
2024-05-25 02:22:11 [INFO]: Epoch 148 - training loss: 0.2574, validation loss: 0.1819
2024-05-25 02:22:14 [INFO]: Epoch 149 - training loss: 0.2577, validation loss: 0.1817
2024-05-25 02:22:16 [INFO]: Epoch 150 - training loss: 0.2568, validation loss: 0.1813
2024-05-25 02:22:19 [INFO]: Epoch 151 - training loss: 0.2564, validation loss: 0.1810
2024-05-25 02:22:22 [INFO]: Epoch 152 - training loss: 0.2565, validation loss: 0.1809
2024-05-25 02:22:25 [INFO]: Epoch 153 - training loss: 0.2563, validation loss: 0.1804
2024-05-25 02:22:28 [INFO]: Epoch 154 - training loss: 0.2559, validation loss: 0.1802
2024-05-25 02:22:30 [INFO]: Epoch 155 - training loss: 0.2558, validation loss: 0.1800
2024-05-25 02:22:33 [INFO]: Epoch 156 - training loss: 0.2554, validation loss: 0.1798
2024-05-25 02:22:36 [INFO]: Epoch 157 - training loss: 0.2550, validation loss: 0.1795
2024-05-25 02:22:39 [INFO]: Epoch 158 - training loss: 0.2543, validation loss: 0.1792
2024-05-25 02:22:41 [INFO]: Epoch 159 - training loss: 0.2539, validation loss: 0.1789
2024-05-25 02:22:44 [INFO]: Epoch 160 - training loss: 0.2543, validation loss: 0.1786
2024-05-25 02:22:47 [INFO]: Epoch 161 - training loss: 0.2530, validation loss: 0.1782
2024-05-25 02:22:50 [INFO]: Epoch 162 - training loss: 0.2532, validation loss: 0.1781
2024-05-25 02:22:53 [INFO]: Epoch 163 - training loss: 0.2534, validation loss: 0.1777
2024-05-25 02:22:55 [INFO]: Epoch 164 - training loss: 0.2527, validation loss: 0.1777
2024-05-25 02:22:58 [INFO]: Epoch 165 - training loss: 0.2521, validation loss: 0.1773
2024-05-25 02:23:01 [INFO]: Epoch 166 - training loss: 0.2514, validation loss: 0.1769
2024-05-25 02:23:04 [INFO]: Epoch 167 - training loss: 0.2519, validation loss: 0.1770
2024-05-25 02:23:06 [INFO]: Epoch 168 - training loss: 0.2518, validation loss: 0.1767
2024-05-25 02:23:09 [INFO]: Epoch 169 - training loss: 0.2514, validation loss: 0.1762
2024-05-25 02:23:12 [INFO]: Epoch 170 - training loss: 0.2507, validation loss: 0.1761
2024-05-25 02:23:15 [INFO]: Epoch 171 - training loss: 0.2515, validation loss: 0.1758
2024-05-25 02:23:17 [INFO]: Epoch 172 - training loss: 0.2502, validation loss: 0.1759
2024-05-25 02:23:20 [INFO]: Epoch 173 - training loss: 0.2504, validation loss: 0.1757
2024-05-25 02:23:23 [INFO]: Epoch 174 - training loss: 0.2496, validation loss: 0.1752
2024-05-25 02:23:26 [INFO]: Epoch 175 - training loss: 0.2498, validation loss: 0.1750
2024-05-25 02:23:29 [INFO]: Epoch 176 - training loss: 0.2494, validation loss: 0.1747
2024-05-25 02:23:31 [INFO]: Epoch 177 - training loss: 0.2489, validation loss: 0.1746
2024-05-25 02:23:34 [INFO]: Epoch 178 - training loss: 0.2489, validation loss: 0.1743
2024-05-25 02:23:37 [INFO]: Epoch 179 - training loss: 0.2490, validation loss: 0.1743
2024-05-25 02:23:40 [INFO]: Epoch 180 - training loss: 0.2487, validation loss: 0.1740
2024-05-25 02:23:43 [INFO]: Epoch 181 - training loss: 0.2484, validation loss: 0.1739
2024-05-25 02:23:46 [INFO]: Epoch 182 - training loss: 0.2481, validation loss: 0.1736
2024-05-25 02:23:49 [INFO]: Epoch 183 - training loss: 0.2472, validation loss: 0.1734
2024-05-25 02:23:51 [INFO]: Epoch 184 - training loss: 0.2479, validation loss: 0.1731
2024-05-25 02:23:54 [INFO]: Epoch 185 - training loss: 0.2473, validation loss: 0.1729
2024-05-25 02:23:57 [INFO]: Epoch 186 - training loss: 0.2466, validation loss: 0.1727
2024-05-25 02:24:00 [INFO]: Epoch 187 - training loss: 0.2468, validation loss: 0.1726
2024-05-25 02:24:03 [INFO]: Epoch 188 - training loss: 0.2465, validation loss: 0.1725
2024-05-25 02:24:05 [INFO]: Epoch 189 - training loss: 0.2461, validation loss: 0.1722
2024-05-25 02:24:08 [INFO]: Epoch 190 - training loss: 0.2461, validation loss: 0.1719
2024-05-25 02:24:11 [INFO]: Epoch 191 - training loss: 0.2461, validation loss: 0.1719
2024-05-25 02:24:14 [INFO]: Epoch 192 - training loss: 0.2455, validation loss: 0.1716
2024-05-25 02:24:16 [INFO]: Epoch 193 - training loss: 0.2456, validation loss: 0.1714
2024-05-25 02:24:19 [INFO]: Epoch 194 - training loss: 0.2455, validation loss: 0.1712
2024-05-25 02:24:22 [INFO]: Epoch 195 - training loss: 0.2454, validation loss: 0.1712
2024-05-25 02:24:25 [INFO]: Epoch 196 - training loss: 0.2448, validation loss: 0.1709
2024-05-25 02:24:28 [INFO]: Epoch 197 - training loss: 0.2449, validation loss: 0.1709
2024-05-25 02:24:30 [INFO]: Epoch 198 - training loss: 0.2449, validation loss: 0.1706
2024-05-25 02:24:33 [INFO]: Epoch 199 - training loss: 0.2443, validation loss: 0.1704
2024-05-25 02:24:36 [INFO]: Epoch 200 - training loss: 0.2441, validation loss: 0.1701
2024-05-25 02:24:39 [INFO]: Epoch 201 - training loss: 0.2439, validation loss: 0.1701
2024-05-25 02:24:41 [INFO]: Epoch 202 - training loss: 0.2436, validation loss: 0.1699
2024-05-25 02:24:44 [INFO]: Epoch 203 - training loss: 0.2432, validation loss: 0.1698
2024-05-25 02:24:47 [INFO]: Epoch 204 - training loss: 0.2435, validation loss: 0.1696
2024-05-25 02:24:50 [INFO]: Epoch 205 - training loss: 0.2426, validation loss: 0.1693
2024-05-25 02:24:53 [INFO]: Epoch 206 - training loss: 0.2428, validation loss: 0.1692
2024-05-25 02:24:55 [INFO]: Epoch 207 - training loss: 0.2425, validation loss: 0.1691
2024-05-25 02:24:58 [INFO]: Epoch 208 - training loss: 0.2426, validation loss: 0.1689
2024-05-25 02:25:01 [INFO]: Epoch 209 - training loss: 0.2423, validation loss: 0.1688
2024-05-25 02:25:04 [INFO]: Epoch 210 - training loss: 0.2419, validation loss: 0.1687
2024-05-25 02:25:07 [INFO]: Epoch 211 - training loss: 0.2415, validation loss: 0.1684
2024-05-25 02:25:09 [INFO]: Epoch 212 - training loss: 0.2417, validation loss: 0.1683
2024-05-25 02:25:12 [INFO]: Epoch 213 - training loss: 0.2420, validation loss: 0.1680
2024-05-25 02:25:15 [INFO]: Epoch 214 - training loss: 0.2417, validation loss: 0.1679
2024-05-25 02:25:18 [INFO]: Epoch 215 - training loss: 0.2416, validation loss: 0.1679
2024-05-25 02:25:20 [INFO]: Epoch 216 - training loss: 0.2413, validation loss: 0.1677
2024-05-25 02:25:23 [INFO]: Epoch 217 - training loss: 0.2413, validation loss: 0.1677
2024-05-25 02:25:26 [INFO]: Epoch 218 - training loss: 0.2406, validation loss: 0.1674
2024-05-25 02:25:29 [INFO]: Epoch 219 - training loss: 0.2403, validation loss: 0.1674
2024-05-25 02:25:32 [INFO]: Epoch 220 - training loss: 0.2404, validation loss: 0.1670
2024-05-25 02:25:34 [INFO]: Epoch 221 - training loss: 0.2397, validation loss: 0.1670
2024-05-25 02:25:37 [INFO]: Epoch 222 - training loss: 0.2399, validation loss: 0.1670
2024-05-25 02:25:40 [INFO]: Epoch 223 - training loss: 0.2394, validation loss: 0.1666
2024-05-25 02:25:43 [INFO]: Epoch 224 - training loss: 0.2395, validation loss: 0.1666
2024-05-25 02:25:46 [INFO]: Epoch 225 - training loss: 0.2394, validation loss: 0.1666
2024-05-25 02:25:48 [INFO]: Epoch 226 - training loss: 0.2388, validation loss: 0.1662
2024-05-25 02:25:51 [INFO]: Epoch 227 - training loss: 0.2387, validation loss: 0.1662
2024-05-25 02:25:54 [INFO]: Epoch 228 - training loss: 0.2387, validation loss: 0.1662
2024-05-25 02:25:57 [INFO]: Epoch 229 - training loss: 0.2391, validation loss: 0.1658
2024-05-25 02:26:00 [INFO]: Epoch 230 - training loss: 0.2385, validation loss: 0.1658
2024-05-25 02:26:02 [INFO]: Epoch 231 - training loss: 0.2382, validation loss: 0.1657
2024-05-25 02:26:05 [INFO]: Epoch 232 - training loss: 0.2380, validation loss: 0.1656
2024-05-25 02:26:08 [INFO]: Epoch 233 - training loss: 0.2378, validation loss: 0.1655
2024-05-25 02:26:11 [INFO]: Epoch 234 - training loss: 0.2381, validation loss: 0.1653
2024-05-25 02:26:13 [INFO]: Epoch 235 - training loss: 0.2376, validation loss: 0.1652
2024-05-25 02:26:16 [INFO]: Epoch 236 - training loss: 0.2375, validation loss: 0.1651
2024-05-25 02:26:19 [INFO]: Epoch 237 - training loss: 0.2376, validation loss: 0.1649
2024-05-25 02:26:22 [INFO]: Epoch 238 - training loss: 0.2377, validation loss: 0.1649
2024-05-25 02:26:25 [INFO]: Epoch 239 - training loss: 0.2373, validation loss: 0.1647
2024-05-25 02:26:27 [INFO]: Epoch 240 - training loss: 0.2366, validation loss: 0.1645
2024-05-25 02:26:30 [INFO]: Epoch 241 - training loss: 0.2370, validation loss: 0.1645
2024-05-25 02:26:33 [INFO]: Epoch 242 - training loss: 0.2366, validation loss: 0.1644
2024-05-25 02:26:36 [INFO]: Epoch 243 - training loss: 0.2367, validation loss: 0.1643
2024-05-25 02:26:38 [INFO]: Epoch 244 - training loss: 0.2362, validation loss: 0.1642
2024-05-25 02:26:41 [INFO]: Epoch 245 - training loss: 0.2365, validation loss: 0.1641
2024-05-25 02:26:44 [INFO]: Epoch 246 - training loss: 0.2363, validation loss: 0.1640
2024-05-25 02:26:47 [INFO]: Epoch 247 - training loss: 0.2360, validation loss: 0.1637
2024-05-25 02:26:50 [INFO]: Epoch 248 - training loss: 0.2362, validation loss: 0.1637
2024-05-25 02:26:53 [INFO]: Epoch 249 - training loss: 0.2360, validation loss: 0.1636
2024-05-25 02:26:56 [INFO]: Epoch 250 - training loss: 0.2362, validation loss: 0.1636
2024-05-25 02:26:58 [INFO]: Epoch 251 - training loss: 0.2355, validation loss: 0.1632
2024-05-25 02:27:01 [INFO]: Epoch 252 - training loss: 0.2353, validation loss: 0.1632
2024-05-25 02:27:04 [INFO]: Epoch 253 - training loss: 0.2353, validation loss: 0.1629
2024-05-25 02:27:07 [INFO]: Epoch 254 - training loss: 0.2348, validation loss: 0.1632
2024-05-25 02:27:10 [INFO]: Epoch 255 - training loss: 0.2346, validation loss: 0.1630
2024-05-25 02:27:12 [INFO]: Epoch 256 - training loss: 0.2350, validation loss: 0.1628
2024-05-25 02:27:15 [INFO]: Epoch 257 - training loss: 0.2348, validation loss: 0.1628
2024-05-25 02:27:18 [INFO]: Epoch 258 - training loss: 0.2340, validation loss: 0.1627
2024-05-25 02:27:21 [INFO]: Epoch 259 - training loss: 0.2345, validation loss: 0.1625
2024-05-25 02:27:24 [INFO]: Epoch 260 - training loss: 0.2336, validation loss: 0.1625
2024-05-25 02:27:26 [INFO]: Epoch 261 - training loss: 0.2340, validation loss: 0.1624
2024-05-25 02:27:29 [INFO]: Epoch 262 - training loss: 0.2341, validation loss: 0.1624
2024-05-25 02:27:32 [INFO]: Epoch 263 - training loss: 0.2336, validation loss: 0.1622
2024-05-25 02:27:35 [INFO]: Epoch 264 - training loss: 0.2331, validation loss: 0.1619
2024-05-25 02:27:38 [INFO]: Epoch 265 - training loss: 0.2332, validation loss: 0.1619
2024-05-25 02:27:40 [INFO]: Epoch 266 - training loss: 0.2332, validation loss: 0.1619
2024-05-25 02:27:43 [INFO]: Epoch 267 - training loss: 0.2334, validation loss: 0.1617
2024-05-25 02:27:46 [INFO]: Epoch 268 - training loss: 0.2334, validation loss: 0.1618
2024-05-25 02:27:49 [INFO]: Epoch 269 - training loss: 0.2331, validation loss: 0.1616
2024-05-25 02:27:52 [INFO]: Epoch 270 - training loss: 0.2333, validation loss: 0.1616
2024-05-25 02:27:54 [INFO]: Epoch 271 - training loss: 0.2330, validation loss: 0.1615
2024-05-25 02:27:57 [INFO]: Epoch 272 - training loss: 0.2325, validation loss: 0.1614
2024-05-25 02:28:00 [INFO]: Epoch 273 - training loss: 0.2324, validation loss: 0.1613
2024-05-25 02:28:03 [INFO]: Epoch 274 - training loss: 0.2326, validation loss: 0.1612
2024-05-25 02:28:06 [INFO]: Epoch 275 - training loss: 0.2323, validation loss: 0.1613
2024-05-25 02:28:08 [INFO]: Epoch 276 - training loss: 0.2320, validation loss: 0.1612
2024-05-25 02:28:11 [INFO]: Epoch 277 - training loss: 0.2323, validation loss: 0.1610
2024-05-25 02:28:14 [INFO]: Epoch 278 - training loss: 0.2313, validation loss: 0.1610
2024-05-25 02:28:17 [INFO]: Epoch 279 - training loss: 0.2318, validation loss: 0.1609
2024-05-25 02:28:20 [INFO]: Epoch 280 - training loss: 0.2314, validation loss: 0.1607
2024-05-25 02:28:22 [INFO]: Epoch 281 - training loss: 0.2316, validation loss: 0.1607
2024-05-25 02:28:25 [INFO]: Epoch 282 - training loss: 0.2312, validation loss: 0.1608
2024-05-25 02:28:28 [INFO]: Epoch 283 - training loss: 0.2308, validation loss: 0.1606
2024-05-25 02:28:31 [INFO]: Epoch 284 - training loss: 0.2311, validation loss: 0.1605
2024-05-25 02:28:33 [INFO]: Epoch 285 - training loss: 0.2313, validation loss: 0.1604
2024-05-25 02:28:36 [INFO]: Epoch 286 - training loss: 0.2305, validation loss: 0.1604
2024-05-25 02:28:39 [INFO]: Epoch 287 - training loss: 0.2308, validation loss: 0.1602
2024-05-25 02:28:42 [INFO]: Epoch 288 - training loss: 0.2312, validation loss: 0.1602
2024-05-25 02:28:45 [INFO]: Epoch 289 - training loss: 0.2304, validation loss: 0.1601
2024-05-25 02:28:47 [INFO]: Epoch 290 - training loss: 0.2304, validation loss: 0.1601
2024-05-25 02:28:50 [INFO]: Epoch 291 - training loss: 0.2306, validation loss: 0.1599
2024-05-25 02:28:53 [INFO]: Epoch 292 - training loss: 0.2304, validation loss: 0.1600
2024-05-25 02:28:56 [INFO]: Epoch 293 - training loss: 0.2298, validation loss: 0.1599
2024-05-25 02:28:59 [INFO]: Epoch 294 - training loss: 0.2301, validation loss: 0.1598
2024-05-25 02:29:01 [INFO]: Epoch 295 - training loss: 0.2302, validation loss: 0.1597
2024-05-25 02:29:04 [INFO]: Epoch 296 - training loss: 0.2299, validation loss: 0.1599
2024-05-25 02:29:07 [INFO]: Epoch 297 - training loss: 0.2299, validation loss: 0.1595
2024-05-25 02:29:10 [INFO]: Epoch 298 - training loss: 0.2301, validation loss: 0.1595
2024-05-25 02:29:13 [INFO]: Epoch 299 - training loss: 0.2297, validation loss: 0.1597
2024-05-25 02:29:15 [INFO]: Epoch 300 - training loss: 0.2295, validation loss: 0.1595
2024-05-25 02:29:15 [INFO]: Finished training. The best model is from epoch#298.
2024-05-25 02:29:15 [INFO]: Saved the model to augmentation_saved_results/round_1/BRITS_air_quality/20240525_T021518/BRITS.pypots
2024-05-25 02:29:16 [INFO]: BRITS on Air-Quality: MAE=0.1377, MSE=0.0899
2024-05-25 02:29:16 [INFO]: Successfully saved to augmentation_saved_results/round_1/BRITS_air_quality/imputation.pkl
2024-05-25 02:29:16 [INFO]: Using the given device: cuda:0
2024-05-25 02:29:16 [INFO]: Model files will be saved to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916
2024-05-25 02:29:16 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/tensorboard
2024-05-25 02:29:16 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 02:29:21 [INFO]: Epoch 001 - training loss: 1.4222, validation loss: 0.8268
2024-05-25 02:29:21 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch1_loss0.8268406182527542.pypots
2024-05-25 02:29:25 [INFO]: Epoch 002 - training loss: 1.0438, validation loss: 0.7730
2024-05-25 02:29:25 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch2_loss0.7730183005332947.pypots
2024-05-25 02:29:28 [INFO]: Epoch 003 - training loss: 0.9768, validation loss: 0.7550
2024-05-25 02:29:28 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch3_loss0.7550395488739013.pypots
2024-05-25 02:29:32 [INFO]: Epoch 004 - training loss: 0.9658, validation loss: 0.7414
2024-05-25 02:29:32 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch4_loss0.741388526558876.pypots
2024-05-25 02:29:36 [INFO]: Epoch 005 - training loss: 0.9428, validation loss: 0.7320
2024-05-25 02:29:36 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch5_loss0.7319699257612229.pypots
2024-05-25 02:29:40 [INFO]: Epoch 006 - training loss: 0.9484, validation loss: 0.7261
2024-05-25 02:29:40 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch6_loss0.7260817438364029.pypots
2024-05-25 02:29:44 [INFO]: Epoch 007 - training loss: 0.9905, validation loss: 0.7211
2024-05-25 02:29:44 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch7_loss0.7210650682449341.pypots
2024-05-25 02:29:48 [INFO]: Epoch 008 - training loss: 0.9556, validation loss: 0.7164
2024-05-25 02:29:48 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch8_loss0.7164169818162918.pypots
2024-05-25 02:29:52 [INFO]: Epoch 009 - training loss: 0.9328, validation loss: 0.7149
2024-05-25 02:29:52 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch9_loss0.7148854464292527.pypots
2024-05-25 02:29:56 [INFO]: Epoch 010 - training loss: 0.9226, validation loss: 0.7114
2024-05-25 02:29:56 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch10_loss0.711353349685669.pypots
2024-05-25 02:30:00 [INFO]: Epoch 011 - training loss: 0.9324, validation loss: 0.7100
2024-05-25 02:30:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch11_loss0.7100468158721924.pypots
2024-05-25 02:30:03 [INFO]: Epoch 012 - training loss: 0.9158, validation loss: 0.7093
2024-05-25 02:30:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch12_loss0.7093247026205063.pypots
2024-05-25 02:30:07 [INFO]: Epoch 013 - training loss: 0.9158, validation loss: 0.7076
2024-05-25 02:30:07 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch13_loss0.7075797259807587.pypots
2024-05-25 02:30:11 [INFO]: Epoch 014 - training loss: 0.9024, validation loss: 0.7073
2024-05-25 02:30:11 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch14_loss0.707299679517746.pypots
2024-05-25 02:30:15 [INFO]: Epoch 015 - training loss: 0.9052, validation loss: 0.7066
2024-05-25 02:30:15 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch15_loss0.7066390573978424.pypots
2024-05-25 02:30:19 [INFO]: Epoch 016 - training loss: 0.9018, validation loss: 0.7072
2024-05-25 02:30:19 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch16_loss0.7072453916072845.pypots
2024-05-25 02:30:23 [INFO]: Epoch 017 - training loss: 0.8856, validation loss: 0.7071
2024-05-25 02:30:23 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch17_loss0.7070866316556931.pypots
2024-05-25 02:30:27 [INFO]: Epoch 018 - training loss: 0.8936, validation loss: 0.7052
2024-05-25 02:30:27 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch18_loss0.7052369475364685.pypots
2024-05-25 02:30:31 [INFO]: Epoch 019 - training loss: 0.8892, validation loss: 0.7053
2024-05-25 02:30:31 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch19_loss0.7053119897842407.pypots
2024-05-25 02:30:34 [INFO]: Epoch 020 - training loss: 0.8886, validation loss: 0.7057
2024-05-25 02:30:34 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch20_loss0.7057339012622833.pypots
2024-05-25 02:30:38 [INFO]: Epoch 021 - training loss: 0.8948, validation loss: 0.7054
2024-05-25 02:30:38 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch21_loss0.7053527384996414.pypots
2024-05-25 02:30:42 [INFO]: Epoch 022 - training loss: 0.8809, validation loss: 0.7062
2024-05-25 02:30:42 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch22_loss0.7062333792448043.pypots
2024-05-25 02:30:46 [INFO]: Epoch 023 - training loss: 0.8859, validation loss: 0.7060
2024-05-25 02:30:46 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch23_loss0.7060427814722061.pypots
2024-05-25 02:30:50 [INFO]: Epoch 024 - training loss: 0.8808, validation loss: 0.7080
2024-05-25 02:30:50 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch24_loss0.7080362170934678.pypots
2024-05-25 02:30:54 [INFO]: Epoch 025 - training loss: 0.8750, validation loss: 0.7073
2024-05-25 02:30:54 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch25_loss0.7072825223207474.pypots
2024-05-25 02:30:58 [INFO]: Epoch 026 - training loss: 0.8816, validation loss: 0.7076
2024-05-25 02:30:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch26_loss0.7075721502304078.pypots
2024-05-25 02:31:02 [INFO]: Epoch 027 - training loss: 0.8525, validation loss: 0.7075
2024-05-25 02:31:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch27_loss0.7074612766504288.pypots
2024-05-25 02:31:05 [INFO]: Epoch 028 - training loss: 0.8658, validation loss: 0.7082
2024-05-25 02:31:06 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN_epoch28_loss0.7081861644983292.pypots
2024-05-25 02:31:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:31:06 [INFO]: Finished training. The best model is from epoch#18.
2024-05-25 02:31:06 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T022916/MRNN.pypots
2024-05-25 02:31:06 [INFO]: MRNN on Air-Quality: MAE=0.5232, MSE=0.6009
2024-05-25 02:31:06 [INFO]: Successfully saved to augmentation_saved_results/round_1/MRNN_air_quality/imputation.pkl
2024-05-25 02:31:06 [INFO]: Using the given device: cpu
2024-05-25 02:31:06 [INFO]: LOCF on Air-Quality: MAE=0.2006, MSE=0.1979
2024-05-25 02:31:06 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_air_quality".
2024-05-25 02:31:06 [INFO]: Successfully saved to augmentation_saved_results/round_1/LOCF_air_quality/imputation.pkl
2024-05-25 02:31:06 [INFO]: Median on Air-Quality: MAE=0.6700, MSE=1.0040
2024-05-25 02:31:06 [INFO]: Successfully created the given path "saved_results/round_1/Median_air_quality".
2024-05-25 02:31:06 [INFO]: Successfully saved to augmentation_saved_results/round_1/Median_air_quality/imputation.pkl
2024-05-25 02:31:06 [INFO]: Mean on Air-Quality: MAE=0.6975, MSE=0.9352
2024-05-25 02:31:06 [INFO]: Successfully created the given path "saved_results/round_1/Mean_air_quality".
2024-05-25 02:31:06 [INFO]: Successfully saved to augmentation_saved_results/round_1/Mean_air_quality/imputation.pkl
2024-05-25 02:31:06 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-25 02:31:06 [INFO]: Using the given device: cuda:0
2024-05-25 02:31:06 [INFO]: Model files will be saved to augmentation_saved_results/round_2/SAITS_air_quality/20240525_T023106
2024-05-25 02:31:06 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/SAITS_air_quality/20240525_T023106/tensorboard
2024-05-25 02:31:07 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 02:31:07 [INFO]: Epoch 001 - training loss: 1.0583, validation loss: 0.5530
2024-05-25 02:31:08 [INFO]: Epoch 002 - training loss: 0.7601, validation loss: 0.4252
2024-05-25 02:31:09 [INFO]: Epoch 003 - training loss: 0.6514, validation loss: 0.3518
2024-05-25 02:31:09 [INFO]: Epoch 004 - training loss: 0.5814, validation loss: 0.3155
2024-05-25 02:31:10 [INFO]: Epoch 005 - training loss: 0.5266, validation loss: 0.2945
2024-05-25 02:31:11 [INFO]: Epoch 006 - training loss: 0.4869, validation loss: 0.2796
2024-05-25 02:31:11 [INFO]: Epoch 007 - training loss: 0.4604, validation loss: 0.2701
2024-05-25 02:31:12 [INFO]: Epoch 008 - training loss: 0.4394, validation loss: 0.2643
2024-05-25 02:31:13 [INFO]: Epoch 009 - training loss: 0.4256, validation loss: 0.2589
2024-05-25 02:31:13 [INFO]: Epoch 010 - training loss: 0.4135, validation loss: 0.2539
2024-05-25 02:31:14 [INFO]: Epoch 011 - training loss: 0.4031, validation loss: 0.2506
2024-05-25 02:31:15 [INFO]: Epoch 012 - training loss: 0.3973, validation loss: 0.2462
2024-05-25 02:31:15 [INFO]: Epoch 013 - training loss: 0.3884, validation loss: 0.2446
2024-05-25 02:31:16 [INFO]: Epoch 014 - training loss: 0.3812, validation loss: 0.2411
2024-05-25 02:31:17 [INFO]: Epoch 015 - training loss: 0.3764, validation loss: 0.2386
2024-05-25 02:31:17 [INFO]: Epoch 016 - training loss: 0.3714, validation loss: 0.2364
2024-05-25 02:31:18 [INFO]: Epoch 017 - training loss: 0.3659, validation loss: 0.2362
2024-05-25 02:31:19 [INFO]: Epoch 018 - training loss: 0.3589, validation loss: 0.2336
2024-05-25 02:31:19 [INFO]: Epoch 019 - training loss: 0.3567, validation loss: 0.2313
2024-05-25 02:31:20 [INFO]: Epoch 020 - training loss: 0.3521, validation loss: 0.2296
2024-05-25 02:31:21 [INFO]: Epoch 021 - training loss: 0.3495, validation loss: 0.2291
2024-05-25 02:31:21 [INFO]: Epoch 022 - training loss: 0.3464, validation loss: 0.2261
2024-05-25 02:31:22 [INFO]: Epoch 023 - training loss: 0.3426, validation loss: 0.2252
2024-05-25 02:31:23 [INFO]: Epoch 024 - training loss: 0.3398, validation loss: 0.2228
2024-05-25 02:31:23 [INFO]: Epoch 025 - training loss: 0.3379, validation loss: 0.2221
2024-05-25 02:31:24 [INFO]: Epoch 026 - training loss: 0.3340, validation loss: 0.2206
2024-05-25 02:31:25 [INFO]: Epoch 027 - training loss: 0.3309, validation loss: 0.2205
2024-05-25 02:31:25 [INFO]: Epoch 028 - training loss: 0.3291, validation loss: 0.2184
2024-05-25 02:31:26 [INFO]: Epoch 029 - training loss: 0.3272, validation loss: 0.2175
2024-05-25 02:31:27 [INFO]: Epoch 030 - training loss: 0.3262, validation loss: 0.2164
2024-05-25 02:31:27 [INFO]: Epoch 031 - training loss: 0.3233, validation loss: 0.2150
2024-05-25 02:31:28 [INFO]: Epoch 032 - training loss: 0.3205, validation loss: 0.2132
2024-05-25 02:31:29 [INFO]: Epoch 033 - training loss: 0.3174, validation loss: 0.2127
2024-05-25 02:31:29 [INFO]: Epoch 034 - training loss: 0.3168, validation loss: 0.2118
2024-05-25 02:31:30 [INFO]: Epoch 035 - training loss: 0.3165, validation loss: 0.2106
2024-05-25 02:31:31 [INFO]: Epoch 036 - training loss: 0.3139, validation loss: 0.2089
2024-05-25 02:31:31 [INFO]: Epoch 037 - training loss: 0.3111, validation loss: 0.2094
2024-05-25 02:31:32 [INFO]: Epoch 038 - training loss: 0.3087, validation loss: 0.2083
2024-05-25 02:31:33 [INFO]: Epoch 039 - training loss: 0.3077, validation loss: 0.2068
2024-05-25 02:31:33 [INFO]: Epoch 040 - training loss: 0.3052, validation loss: 0.2049
2024-05-25 02:31:34 [INFO]: Epoch 041 - training loss: 0.3049, validation loss: 0.2043
2024-05-25 02:31:35 [INFO]: Epoch 042 - training loss: 0.3030, validation loss: 0.2049
2024-05-25 02:31:35 [INFO]: Epoch 043 - training loss: 0.2999, validation loss: 0.2036
2024-05-25 02:31:36 [INFO]: Epoch 044 - training loss: 0.2980, validation loss: 0.2032
2024-05-25 02:31:37 [INFO]: Epoch 045 - training loss: 0.2969, validation loss: 0.2022
2024-05-25 02:31:37 [INFO]: Epoch 046 - training loss: 0.2958, validation loss: 0.2012
2024-05-25 02:31:38 [INFO]: Epoch 047 - training loss: 0.2951, validation loss: 0.2003
2024-05-25 02:31:39 [INFO]: Epoch 048 - training loss: 0.2950, validation loss: 0.1988
2024-05-25 02:31:39 [INFO]: Epoch 049 - training loss: 0.2917, validation loss: 0.1969
2024-05-25 02:31:40 [INFO]: Epoch 050 - training loss: 0.2899, validation loss: 0.1978
2024-05-25 02:31:41 [INFO]: Epoch 051 - training loss: 0.2899, validation loss: 0.1973
2024-05-25 02:31:41 [INFO]: Epoch 052 - training loss: 0.2872, validation loss: 0.1962
2024-05-25 02:31:42 [INFO]: Epoch 053 - training loss: 0.2862, validation loss: 0.1951
2024-05-25 02:31:43 [INFO]: Epoch 054 - training loss: 0.2844, validation loss: 0.1953
2024-05-25 02:31:43 [INFO]: Epoch 055 - training loss: 0.2833, validation loss: 0.1941
2024-05-25 02:31:44 [INFO]: Epoch 056 - training loss: 0.2819, validation loss: 0.1937
2024-05-25 02:31:45 [INFO]: Epoch 057 - training loss: 0.2801, validation loss: 0.1931
2024-05-25 02:31:45 [INFO]: Epoch 058 - training loss: 0.2806, validation loss: 0.1914
2024-05-25 02:31:46 [INFO]: Epoch 059 - training loss: 0.2782, validation loss: 0.1922
2024-05-25 02:31:47 [INFO]: Epoch 060 - training loss: 0.2775, validation loss: 0.1900
2024-05-25 02:31:47 [INFO]: Epoch 061 - training loss: 0.2769, validation loss: 0.1914
2024-05-25 02:31:48 [INFO]: Epoch 062 - training loss: 0.2763, validation loss: 0.1904
2024-05-25 02:31:49 [INFO]: Epoch 063 - training loss: 0.2737, validation loss: 0.1892
2024-05-25 02:31:49 [INFO]: Epoch 064 - training loss: 0.2731, validation loss: 0.1894
2024-05-25 02:31:50 [INFO]: Epoch 065 - training loss: 0.2720, validation loss: 0.1889
2024-05-25 02:31:51 [INFO]: Epoch 066 - training loss: 0.2711, validation loss: 0.1879
2024-05-25 02:31:52 [INFO]: Epoch 067 - training loss: 0.2689, validation loss: 0.1868
2024-05-25 02:31:52 [INFO]: Epoch 068 - training loss: 0.2695, validation loss: 0.1872
2024-05-25 02:31:53 [INFO]: Epoch 069 - training loss: 0.2678, validation loss: 0.1858
2024-05-25 02:31:54 [INFO]: Epoch 070 - training loss: 0.2666, validation loss: 0.1858
2024-05-25 02:31:54 [INFO]: Epoch 071 - training loss: 0.2660, validation loss: 0.1852
2024-05-25 02:31:55 [INFO]: Epoch 072 - training loss: 0.2634, validation loss: 0.1855
2024-05-25 02:31:56 [INFO]: Epoch 073 - training loss: 0.2636, validation loss: 0.1839
2024-05-25 02:31:56 [INFO]: Epoch 074 - training loss: 0.2633, validation loss: 0.1845
2024-05-25 02:31:57 [INFO]: Epoch 075 - training loss: 0.2642, validation loss: 0.1829
2024-05-25 02:31:58 [INFO]: Epoch 076 - training loss: 0.2623, validation loss: 0.1833
2024-05-25 02:31:58 [INFO]: Epoch 077 - training loss: 0.2614, validation loss: 0.1819
2024-05-25 02:31:59 [INFO]: Epoch 078 - training loss: 0.2602, validation loss: 0.1821
2024-05-25 02:32:00 [INFO]: Epoch 079 - training loss: 0.2586, validation loss: 0.1808
2024-05-25 02:32:00 [INFO]: Epoch 080 - training loss: 0.2579, validation loss: 0.1813
2024-05-25 02:32:01 [INFO]: Epoch 081 - training loss: 0.2580, validation loss: 0.1808
2024-05-25 02:32:02 [INFO]: Epoch 082 - training loss: 0.2568, validation loss: 0.1807
2024-05-25 02:32:02 [INFO]: Epoch 083 - training loss: 0.2568, validation loss: 0.1803
2024-05-25 02:32:03 [INFO]: Epoch 084 - training loss: 0.2546, validation loss: 0.1798
2024-05-25 02:32:04 [INFO]: Epoch 085 - training loss: 0.2549, validation loss: 0.1797
2024-05-25 02:32:04 [INFO]: Epoch 086 - training loss: 0.2542, validation loss: 0.1792
2024-05-25 02:32:05 [INFO]: Epoch 087 - training loss: 0.2531, validation loss: 0.1794
2024-05-25 02:32:06 [INFO]: Epoch 088 - training loss: 0.2528, validation loss: 0.1785
2024-05-25 02:32:06 [INFO]: Epoch 089 - training loss: 0.2546, validation loss: 0.1786
2024-05-25 02:32:07 [INFO]: Epoch 090 - training loss: 0.2554, validation loss: 0.1785
2024-05-25 02:32:08 [INFO]: Epoch 091 - training loss: 0.2537, validation loss: 0.1780
2024-05-25 02:32:08 [INFO]: Epoch 092 - training loss: 0.2504, validation loss: 0.1770
2024-05-25 02:32:09 [INFO]: Epoch 093 - training loss: 0.2499, validation loss: 0.1764
2024-05-25 02:32:10 [INFO]: Epoch 094 - training loss: 0.2475, validation loss: 0.1760
2024-05-25 02:32:10 [INFO]: Epoch 095 - training loss: 0.2495, validation loss: 0.1763
2024-05-25 02:32:11 [INFO]: Epoch 096 - training loss: 0.2477, validation loss: 0.1760
2024-05-25 02:32:12 [INFO]: Epoch 097 - training loss: 0.2486, validation loss: 0.1743
2024-05-25 02:32:12 [INFO]: Epoch 098 - training loss: 0.2481, validation loss: 0.1740
2024-05-25 02:32:13 [INFO]: Epoch 099 - training loss: 0.2469, validation loss: 0.1745
2024-05-25 02:32:14 [INFO]: Epoch 100 - training loss: 0.2461, validation loss: 0.1748
2024-05-25 02:32:14 [INFO]: Epoch 101 - training loss: 0.2441, validation loss: 0.1741
2024-05-25 02:32:15 [INFO]: Epoch 102 - training loss: 0.2441, validation loss: 0.1730
2024-05-25 02:32:16 [INFO]: Epoch 103 - training loss: 0.2440, validation loss: 0.1735
2024-05-25 02:32:16 [INFO]: Epoch 104 - training loss: 0.2431, validation loss: 0.1727
2024-05-25 02:32:17 [INFO]: Epoch 105 - training loss: 0.2420, validation loss: 0.1725
2024-05-25 02:32:18 [INFO]: Epoch 106 - training loss: 0.2424, validation loss: 0.1719
2024-05-25 02:32:18 [INFO]: Epoch 107 - training loss: 0.2429, validation loss: 0.1717
2024-05-25 02:32:19 [INFO]: Epoch 108 - training loss: 0.2408, validation loss: 0.1726
2024-05-25 02:32:20 [INFO]: Epoch 109 - training loss: 0.2405, validation loss: 0.1723
2024-05-25 02:32:20 [INFO]: Epoch 110 - training loss: 0.2413, validation loss: 0.1711
2024-05-25 02:32:21 [INFO]: Epoch 111 - training loss: 0.2403, validation loss: 0.1711
2024-05-25 02:32:22 [INFO]: Epoch 112 - training loss: 0.2391, validation loss: 0.1704
2024-05-25 02:32:22 [INFO]: Epoch 113 - training loss: 0.2380, validation loss: 0.1696
2024-05-25 02:32:23 [INFO]: Epoch 114 - training loss: 0.2379, validation loss: 0.1699
2024-05-25 02:32:24 [INFO]: Epoch 115 - training loss: 0.2371, validation loss: 0.1696
2024-05-25 02:32:24 [INFO]: Epoch 116 - training loss: 0.2375, validation loss: 0.1700
2024-05-25 02:32:25 [INFO]: Epoch 117 - training loss: 0.2364, validation loss: 0.1698
2024-05-25 02:32:26 [INFO]: Epoch 118 - training loss: 0.2363, validation loss: 0.1691
2024-05-25 02:32:26 [INFO]: Epoch 119 - training loss: 0.2359, validation loss: 0.1694
2024-05-25 02:32:27 [INFO]: Epoch 120 - training loss: 0.2355, validation loss: 0.1686
2024-05-25 02:32:28 [INFO]: Epoch 121 - training loss: 0.2352, validation loss: 0.1683
2024-05-25 02:32:28 [INFO]: Epoch 122 - training loss: 0.2337, validation loss: 0.1678
2024-05-25 02:32:29 [INFO]: Epoch 123 - training loss: 0.2352, validation loss: 0.1667
2024-05-25 02:32:30 [INFO]: Epoch 124 - training loss: 0.2332, validation loss: 0.1668
2024-05-25 02:32:30 [INFO]: Epoch 125 - training loss: 0.2322, validation loss: 0.1667
2024-05-25 02:32:31 [INFO]: Epoch 126 - training loss: 0.2339, validation loss: 0.1666
2024-05-25 02:32:32 [INFO]: Epoch 127 - training loss: 0.2322, validation loss: 0.1656
2024-05-25 02:32:32 [INFO]: Epoch 128 - training loss: 0.2318, validation loss: 0.1651
2024-05-25 02:32:33 [INFO]: Epoch 129 - training loss: 0.2311, validation loss: 0.1654
2024-05-25 02:32:34 [INFO]: Epoch 130 - training loss: 0.2313, validation loss: 0.1651
2024-05-25 02:32:34 [INFO]: Epoch 131 - training loss: 0.2307, validation loss: 0.1647
2024-05-25 02:32:35 [INFO]: Epoch 132 - training loss: 0.2310, validation loss: 0.1655
2024-05-25 02:32:36 [INFO]: Epoch 133 - training loss: 0.2316, validation loss: 0.1642
2024-05-25 02:32:36 [INFO]: Epoch 134 - training loss: 0.2314, validation loss: 0.1644
2024-05-25 02:32:37 [INFO]: Epoch 135 - training loss: 0.2316, validation loss: 0.1643
2024-05-25 02:32:38 [INFO]: Epoch 136 - training loss: 0.2300, validation loss: 0.1631
2024-05-25 02:32:38 [INFO]: Epoch 137 - training loss: 0.2279, validation loss: 0.1633
2024-05-25 02:32:39 [INFO]: Epoch 138 - training loss: 0.2282, validation loss: 0.1632
2024-05-25 02:32:40 [INFO]: Epoch 139 - training loss: 0.2269, validation loss: 0.1624
2024-05-25 02:32:40 [INFO]: Epoch 140 - training loss: 0.2270, validation loss: 0.1625
2024-05-25 02:32:41 [INFO]: Epoch 141 - training loss: 0.2264, validation loss: 0.1622
2024-05-25 02:32:42 [INFO]: Epoch 142 - training loss: 0.2261, validation loss: 0.1625
2024-05-25 02:32:42 [INFO]: Epoch 143 - training loss: 0.2271, validation loss: 0.1617
2024-05-25 02:32:43 [INFO]: Epoch 144 - training loss: 0.2249, validation loss: 0.1617
2024-05-25 02:32:44 [INFO]: Epoch 145 - training loss: 0.2253, validation loss: 0.1622
2024-05-25 02:32:45 [INFO]: Epoch 146 - training loss: 0.2257, validation loss: 0.1620
2024-05-25 02:32:45 [INFO]: Epoch 147 - training loss: 0.2259, validation loss: 0.1615
2024-05-25 02:32:46 [INFO]: Epoch 148 - training loss: 0.2236, validation loss: 0.1616
2024-05-25 02:32:47 [INFO]: Epoch 149 - training loss: 0.2237, validation loss: 0.1618
2024-05-25 02:32:47 [INFO]: Epoch 150 - training loss: 0.2228, validation loss: 0.1612
2024-05-25 02:32:48 [INFO]: Epoch 151 - training loss: 0.2239, validation loss: 0.1613
2024-05-25 02:32:49 [INFO]: Epoch 152 - training loss: 0.2236, validation loss: 0.1617
2024-05-25 02:32:49 [INFO]: Epoch 153 - training loss: 0.2220, validation loss: 0.1611
2024-05-25 02:32:50 [INFO]: Epoch 154 - training loss: 0.2220, validation loss: 0.1606
2024-05-25 02:32:51 [INFO]: Epoch 155 - training loss: 0.2223, validation loss: 0.1610
2024-05-25 02:32:51 [INFO]: Epoch 156 - training loss: 0.2210, validation loss: 0.1606
2024-05-25 02:32:52 [INFO]: Epoch 157 - training loss: 0.2198, validation loss: 0.1590
2024-05-25 02:32:53 [INFO]: Epoch 158 - training loss: 0.2209, validation loss: 0.1600
2024-05-25 02:32:53 [INFO]: Epoch 159 - training loss: 0.2207, validation loss: 0.1609
2024-05-25 02:32:54 [INFO]: Epoch 160 - training loss: 0.2221, validation loss: 0.1591
2024-05-25 02:32:55 [INFO]: Epoch 161 - training loss: 0.2219, validation loss: 0.1596
2024-05-25 02:32:55 [INFO]: Epoch 162 - training loss: 0.2190, validation loss: 0.1586
2024-05-25 02:32:56 [INFO]: Epoch 163 - training loss: 0.2192, validation loss: 0.1591
2024-05-25 02:32:57 [INFO]: Epoch 164 - training loss: 0.2182, validation loss: 0.1579
2024-05-25 02:32:57 [INFO]: Epoch 165 - training loss: 0.2172, validation loss: 0.1582
2024-05-25 02:32:58 [INFO]: Epoch 166 - training loss: 0.2183, validation loss: 0.1574
2024-05-25 02:32:59 [INFO]: Epoch 167 - training loss: 0.2172, validation loss: 0.1576
2024-05-25 02:32:59 [INFO]: Epoch 168 - training loss: 0.2168, validation loss: 0.1573
2024-05-25 02:33:00 [INFO]: Epoch 169 - training loss: 0.2154, validation loss: 0.1567
2024-05-25 02:33:01 [INFO]: Epoch 170 - training loss: 0.2180, validation loss: 0.1580
2024-05-25 02:33:01 [INFO]: Epoch 171 - training loss: 0.2191, validation loss: 0.1591
2024-05-25 02:33:02 [INFO]: Epoch 172 - training loss: 0.2160, validation loss: 0.1576
2024-05-25 02:33:03 [INFO]: Epoch 173 - training loss: 0.2156, validation loss: 0.1576
2024-05-25 02:33:03 [INFO]: Epoch 174 - training loss: 0.2161, validation loss: 0.1569
2024-05-25 02:33:04 [INFO]: Epoch 175 - training loss: 0.2172, validation loss: 0.1572
2024-05-25 02:33:05 [INFO]: Epoch 176 - training loss: 0.2168, validation loss: 0.1564
2024-05-25 02:33:05 [INFO]: Epoch 177 - training loss: 0.2155, validation loss: 0.1566
2024-05-25 02:33:06 [INFO]: Epoch 178 - training loss: 0.2153, validation loss: 0.1556
2024-05-25 02:33:07 [INFO]: Epoch 179 - training loss: 0.2154, validation loss: 0.1556
2024-05-25 02:33:07 [INFO]: Epoch 180 - training loss: 0.2150, validation loss: 0.1557
2024-05-25 02:33:08 [INFO]: Epoch 181 - training loss: 0.2138, validation loss: 0.1560
2024-05-25 02:33:09 [INFO]: Epoch 182 - training loss: 0.2141, validation loss: 0.1558
2024-05-25 02:33:09 [INFO]: Epoch 183 - training loss: 0.2168, validation loss: 0.1565
2024-05-25 02:33:10 [INFO]: Epoch 184 - training loss: 0.2151, validation loss: 0.1551
2024-05-25 02:33:11 [INFO]: Epoch 185 - training loss: 0.2122, validation loss: 0.1553
2024-05-25 02:33:11 [INFO]: Epoch 186 - training loss: 0.2107, validation loss: 0.1547
2024-05-25 02:33:12 [INFO]: Epoch 187 - training loss: 0.2119, validation loss: 0.1552
2024-05-25 02:33:13 [INFO]: Epoch 188 - training loss: 0.2108, validation loss: 0.1555
2024-05-25 02:33:13 [INFO]: Epoch 189 - training loss: 0.2114, validation loss: 0.1550
2024-05-25 02:33:14 [INFO]: Epoch 190 - training loss: 0.2101, validation loss: 0.1555
2024-05-25 02:33:15 [INFO]: Epoch 191 - training loss: 0.2097, validation loss: 0.1549
2024-05-25 02:33:15 [INFO]: Epoch 192 - training loss: 0.2103, validation loss: 0.1542
2024-05-25 02:33:16 [INFO]: Epoch 193 - training loss: 0.2093, validation loss: 0.1544
2024-05-25 02:33:17 [INFO]: Epoch 194 - training loss: 0.2090, validation loss: 0.1548
2024-05-25 02:33:17 [INFO]: Epoch 195 - training loss: 0.2095, validation loss: 0.1536
2024-05-25 02:33:18 [INFO]: Epoch 196 - training loss: 0.2085, validation loss: 0.1538
2024-05-25 02:33:19 [INFO]: Epoch 197 - training loss: 0.2081, validation loss: 0.1542
2024-05-25 02:33:19 [INFO]: Epoch 198 - training loss: 0.2082, validation loss: 0.1538
2024-05-25 02:33:20 [INFO]: Epoch 199 - training loss: 0.2085, validation loss: 0.1549
2024-05-25 02:33:21 [INFO]: Epoch 200 - training loss: 0.2082, validation loss: 0.1540
2024-05-25 02:33:21 [INFO]: Epoch 201 - training loss: 0.2074, validation loss: 0.1535
2024-05-25 02:33:22 [INFO]: Epoch 202 - training loss: 0.2080, validation loss: 0.1554
2024-05-25 02:33:23 [INFO]: Epoch 203 - training loss: 0.2088, validation loss: 0.1534
2024-05-25 02:33:23 [INFO]: Epoch 204 - training loss: 0.2086, validation loss: 0.1534
2024-05-25 02:33:24 [INFO]: Epoch 205 - training loss: 0.2076, validation loss: 0.1530
2024-05-25 02:33:25 [INFO]: Epoch 206 - training loss: 0.2065, validation loss: 0.1532
2024-05-25 02:33:25 [INFO]: Epoch 207 - training loss: 0.2068, validation loss: 0.1532
2024-05-25 02:33:26 [INFO]: Epoch 208 - training loss: 0.2066, validation loss: 0.1531
2024-05-25 02:33:27 [INFO]: Epoch 209 - training loss: 0.2068, validation loss: 0.1534
2024-05-25 02:33:27 [INFO]: Epoch 210 - training loss: 0.2062, validation loss: 0.1537
2024-05-25 02:33:28 [INFO]: Epoch 211 - training loss: 0.2058, validation loss: 0.1532
2024-05-25 02:33:29 [INFO]: Epoch 212 - training loss: 0.2061, validation loss: 0.1541
2024-05-25 02:33:29 [INFO]: Epoch 213 - training loss: 0.2058, validation loss: 0.1537
2024-05-25 02:33:30 [INFO]: Epoch 214 - training loss: 0.2043, validation loss: 0.1529
2024-05-25 02:33:31 [INFO]: Epoch 215 - training loss: 0.2044, validation loss: 0.1528
2024-05-25 02:33:31 [INFO]: Epoch 216 - training loss: 0.2053, validation loss: 0.1532
2024-05-25 02:33:32 [INFO]: Epoch 217 - training loss: 0.2028, validation loss: 0.1536
2024-05-25 02:33:33 [INFO]: Epoch 218 - training loss: 0.2035, validation loss: 0.1536
2024-05-25 02:33:33 [INFO]: Epoch 219 - training loss: 0.2049, validation loss: 0.1544
2024-05-25 02:33:34 [INFO]: Epoch 220 - training loss: 0.2039, validation loss: 0.1542
2024-05-25 02:33:35 [INFO]: Epoch 221 - training loss: 0.2022, validation loss: 0.1539
2024-05-25 02:33:35 [INFO]: Epoch 222 - training loss: 0.2027, validation loss: 0.1537
2024-05-25 02:33:36 [INFO]: Epoch 223 - training loss: 0.2026, validation loss: 0.1544
2024-05-25 02:33:37 [INFO]: Epoch 224 - training loss: 0.2044, validation loss: 0.1533
2024-05-25 02:33:37 [INFO]: Epoch 225 - training loss: 0.2042, validation loss: 0.1539
2024-05-25 02:33:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:33:37 [INFO]: Finished training. The best model is from epoch#215.
2024-05-25 02:33:38 [INFO]: Saved the model to augmentation_saved_results/round_2/SAITS_air_quality/20240525_T023106/SAITS.pypots
2024-05-25 02:33:38 [INFO]: SAITS on Air-Quality: MAE=0.1440, MSE=0.0920
2024-05-25 02:33:38 [INFO]: Successfully saved to augmentation_saved_results/round_2/SAITS_air_quality/imputation.pkl
2024-05-25 02:33:38 [INFO]: Using the given device: cuda:0
2024-05-25 02:33:38 [INFO]: Model files will be saved to augmentation_saved_results/round_2/Transformer_air_quality/20240525_T023338
2024-05-25 02:33:38 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/Transformer_air_quality/20240525_T023338/tensorboard
2024-05-25 02:33:38 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 02:33:38 [INFO]: Epoch 001 - training loss: 0.9321, validation loss: 0.4992
2024-05-25 02:33:38 [INFO]: Epoch 002 - training loss: 0.5840, validation loss: 0.3898
2024-05-25 02:33:39 [INFO]: Epoch 003 - training loss: 0.4930, validation loss: 0.3296
2024-05-25 02:33:39 [INFO]: Epoch 004 - training loss: 0.4468, validation loss: 0.3059
2024-05-25 02:33:39 [INFO]: Epoch 005 - training loss: 0.4157, validation loss: 0.2874
2024-05-25 02:33:40 [INFO]: Epoch 006 - training loss: 0.3938, validation loss: 0.2765
2024-05-25 02:33:40 [INFO]: Epoch 007 - training loss: 0.3793, validation loss: 0.2691
2024-05-25 02:33:40 [INFO]: Epoch 008 - training loss: 0.3638, validation loss: 0.2629
2024-05-25 02:33:41 [INFO]: Epoch 009 - training loss: 0.3553, validation loss: 0.2584
2024-05-25 02:33:41 [INFO]: Epoch 010 - training loss: 0.3512, validation loss: 0.2539
2024-05-25 02:33:41 [INFO]: Epoch 011 - training loss: 0.3430, validation loss: 0.2494
2024-05-25 02:33:42 [INFO]: Epoch 012 - training loss: 0.3351, validation loss: 0.2448
2024-05-25 02:33:42 [INFO]: Epoch 013 - training loss: 0.3280, validation loss: 0.2403
2024-05-25 02:33:42 [INFO]: Epoch 014 - training loss: 0.3251, validation loss: 0.2378
2024-05-25 02:33:43 [INFO]: Epoch 015 - training loss: 0.3252, validation loss: 0.2340
2024-05-25 02:33:43 [INFO]: Epoch 016 - training loss: 0.3171, validation loss: 0.2318
2024-05-25 02:33:43 [INFO]: Epoch 017 - training loss: 0.3133, validation loss: 0.2289
2024-05-25 02:33:43 [INFO]: Epoch 018 - training loss: 0.3106, validation loss: 0.2272
2024-05-25 02:33:44 [INFO]: Epoch 019 - training loss: 0.3094, validation loss: 0.2245
2024-05-25 02:33:44 [INFO]: Epoch 020 - training loss: 0.3076, validation loss: 0.2243
2024-05-25 02:33:44 [INFO]: Epoch 021 - training loss: 0.3036, validation loss: 0.2208
2024-05-25 02:33:45 [INFO]: Epoch 022 - training loss: 0.3023, validation loss: 0.2190
2024-05-25 02:33:45 [INFO]: Epoch 023 - training loss: 0.2976, validation loss: 0.2178
2024-05-25 02:33:45 [INFO]: Epoch 024 - training loss: 0.2994, validation loss: 0.2147
2024-05-25 02:33:46 [INFO]: Epoch 025 - training loss: 0.2965, validation loss: 0.2167
2024-05-25 02:33:46 [INFO]: Epoch 026 - training loss: 0.2932, validation loss: 0.2145
2024-05-25 02:33:46 [INFO]: Epoch 027 - training loss: 0.2914, validation loss: 0.2134
2024-05-25 02:33:47 [INFO]: Epoch 028 - training loss: 0.2894, validation loss: 0.2133
2024-05-25 02:33:47 [INFO]: Epoch 029 - training loss: 0.2865, validation loss: 0.2128
2024-05-25 02:33:47 [INFO]: Epoch 030 - training loss: 0.2861, validation loss: 0.2111
2024-05-25 02:33:48 [INFO]: Epoch 031 - training loss: 0.2855, validation loss: 0.2101
2024-05-25 02:33:48 [INFO]: Epoch 032 - training loss: 0.2840, validation loss: 0.2126
2024-05-25 02:33:48 [INFO]: Epoch 033 - training loss: 0.2822, validation loss: 0.2096
2024-05-25 02:33:49 [INFO]: Epoch 034 - training loss: 0.2822, validation loss: 0.2095
2024-05-25 02:33:49 [INFO]: Epoch 035 - training loss: 0.2813, validation loss: 0.2091
2024-05-25 02:33:49 [INFO]: Epoch 036 - training loss: 0.2783, validation loss: 0.2076
2024-05-25 02:33:49 [INFO]: Epoch 037 - training loss: 0.2788, validation loss: 0.2075
2024-05-25 02:33:50 [INFO]: Epoch 038 - training loss: 0.2759, validation loss: 0.2076
2024-05-25 02:33:50 [INFO]: Epoch 039 - training loss: 0.2767, validation loss: 0.2058
2024-05-25 02:33:50 [INFO]: Epoch 040 - training loss: 0.2744, validation loss: 0.2069
2024-05-25 02:33:51 [INFO]: Epoch 041 - training loss: 0.2724, validation loss: 0.2046
2024-05-25 02:33:51 [INFO]: Epoch 042 - training loss: 0.2708, validation loss: 0.2052
2024-05-25 02:33:51 [INFO]: Epoch 043 - training loss: 0.2727, validation loss: 0.2048
2024-05-25 02:33:52 [INFO]: Epoch 044 - training loss: 0.2688, validation loss: 0.2034
2024-05-25 02:33:52 [INFO]: Epoch 045 - training loss: 0.2678, validation loss: 0.2030
2024-05-25 02:33:52 [INFO]: Epoch 046 - training loss: 0.2660, validation loss: 0.2024
2024-05-25 02:33:53 [INFO]: Epoch 047 - training loss: 0.2646, validation loss: 0.2024
2024-05-25 02:33:53 [INFO]: Epoch 048 - training loss: 0.2641, validation loss: 0.2031
2024-05-25 02:33:53 [INFO]: Epoch 049 - training loss: 0.2648, validation loss: 0.2031
2024-05-25 02:33:54 [INFO]: Epoch 050 - training loss: 0.2658, validation loss: 0.2010
2024-05-25 02:33:54 [INFO]: Epoch 051 - training loss: 0.2615, validation loss: 0.1999
2024-05-25 02:33:54 [INFO]: Epoch 052 - training loss: 0.2605, validation loss: 0.1993
2024-05-25 02:33:55 [INFO]: Epoch 053 - training loss: 0.2586, validation loss: 0.1996
2024-05-25 02:33:55 [INFO]: Epoch 054 - training loss: 0.2574, validation loss: 0.1997
2024-05-25 02:33:55 [INFO]: Epoch 055 - training loss: 0.2573, validation loss: 0.1990
2024-05-25 02:33:55 [INFO]: Epoch 056 - training loss: 0.2579, validation loss: 0.1997
2024-05-25 02:33:56 [INFO]: Epoch 057 - training loss: 0.2589, validation loss: 0.1990
2024-05-25 02:33:56 [INFO]: Epoch 058 - training loss: 0.2574, validation loss: 0.1979
2024-05-25 02:33:56 [INFO]: Epoch 059 - training loss: 0.2536, validation loss: 0.1971
2024-05-25 02:33:57 [INFO]: Epoch 060 - training loss: 0.2531, validation loss: 0.1969
2024-05-25 02:33:57 [INFO]: Epoch 061 - training loss: 0.2512, validation loss: 0.1957
2024-05-25 02:33:57 [INFO]: Epoch 062 - training loss: 0.2539, validation loss: 0.1976
2024-05-25 02:33:58 [INFO]: Epoch 063 - training loss: 0.2561, validation loss: 0.1959
2024-05-25 02:33:58 [INFO]: Epoch 064 - training loss: 0.2538, validation loss: 0.1948
2024-05-25 02:33:58 [INFO]: Epoch 065 - training loss: 0.2519, validation loss: 0.1948
2024-05-25 02:33:59 [INFO]: Epoch 066 - training loss: 0.2499, validation loss: 0.1949
2024-05-25 02:33:59 [INFO]: Epoch 067 - training loss: 0.2492, validation loss: 0.1939
2024-05-25 02:33:59 [INFO]: Epoch 068 - training loss: 0.2490, validation loss: 0.1937
2024-05-25 02:34:00 [INFO]: Epoch 069 - training loss: 0.2475, validation loss: 0.1936
2024-05-25 02:34:00 [INFO]: Epoch 070 - training loss: 0.2475, validation loss: 0.1913
2024-05-25 02:34:00 [INFO]: Epoch 071 - training loss: 0.2508, validation loss: 0.1943
2024-05-25 02:34:01 [INFO]: Epoch 072 - training loss: 0.2472, validation loss: 0.1926
2024-05-25 02:34:01 [INFO]: Epoch 073 - training loss: 0.2454, validation loss: 0.1932
2024-05-25 02:34:01 [INFO]: Epoch 074 - training loss: 0.2422, validation loss: 0.1913
2024-05-25 02:34:02 [INFO]: Epoch 075 - training loss: 0.2434, validation loss: 0.1909
2024-05-25 02:34:02 [INFO]: Epoch 076 - training loss: 0.2448, validation loss: 0.1915
2024-05-25 02:34:02 [INFO]: Epoch 077 - training loss: 0.2471, validation loss: 0.1923
2024-05-25 02:34:02 [INFO]: Epoch 078 - training loss: 0.2460, validation loss: 0.1932
2024-05-25 02:34:03 [INFO]: Epoch 079 - training loss: 0.2425, validation loss: 0.1893
2024-05-25 02:34:03 [INFO]: Epoch 080 - training loss: 0.2407, validation loss: 0.1896
2024-05-25 02:34:03 [INFO]: Epoch 081 - training loss: 0.2386, validation loss: 0.1917
2024-05-25 02:34:04 [INFO]: Epoch 082 - training loss: 0.2395, validation loss: 0.1882
2024-05-25 02:34:04 [INFO]: Epoch 083 - training loss: 0.2377, validation loss: 0.1882
2024-05-25 02:34:04 [INFO]: Epoch 084 - training loss: 0.2371, validation loss: 0.1883
2024-05-25 02:34:05 [INFO]: Epoch 085 - training loss: 0.2359, validation loss: 0.1903
2024-05-25 02:34:05 [INFO]: Epoch 086 - training loss: 0.2354, validation loss: 0.1867
2024-05-25 02:34:05 [INFO]: Epoch 087 - training loss: 0.2353, validation loss: 0.1865
2024-05-25 02:34:06 [INFO]: Epoch 088 - training loss: 0.2384, validation loss: 0.1894
2024-05-25 02:34:06 [INFO]: Epoch 089 - training loss: 0.2371, validation loss: 0.1858
2024-05-25 02:34:06 [INFO]: Epoch 090 - training loss: 0.2344, validation loss: 0.1850
2024-05-25 02:34:07 [INFO]: Epoch 091 - training loss: 0.2327, validation loss: 0.1851
2024-05-25 02:34:07 [INFO]: Epoch 092 - training loss: 0.2306, validation loss: 0.1845
2024-05-25 02:34:07 [INFO]: Epoch 093 - training loss: 0.2316, validation loss: 0.1855
2024-05-25 02:34:08 [INFO]: Epoch 094 - training loss: 0.2326, validation loss: 0.1855
2024-05-25 02:34:08 [INFO]: Epoch 095 - training loss: 0.2324, validation loss: 0.1824
2024-05-25 02:34:08 [INFO]: Epoch 096 - training loss: 0.2333, validation loss: 0.1862
2024-05-25 02:34:08 [INFO]: Epoch 097 - training loss: 0.2406, validation loss: 0.1845
2024-05-25 02:34:09 [INFO]: Epoch 098 - training loss: 0.2323, validation loss: 0.1819
2024-05-25 02:34:09 [INFO]: Epoch 099 - training loss: 0.2280, validation loss: 0.1847
2024-05-25 02:34:10 [INFO]: Epoch 100 - training loss: 0.2278, validation loss: 0.1828
2024-05-25 02:34:10 [INFO]: Epoch 101 - training loss: 0.2285, validation loss: 0.1819
2024-05-25 02:34:10 [INFO]: Epoch 102 - training loss: 0.2277, validation loss: 0.1817
2024-05-25 02:34:10 [INFO]: Epoch 103 - training loss: 0.2263, validation loss: 0.1817
2024-05-25 02:34:11 [INFO]: Epoch 104 - training loss: 0.2253, validation loss: 0.1814
2024-05-25 02:34:11 [INFO]: Epoch 105 - training loss: 0.2282, validation loss: 0.1818
2024-05-25 02:34:11 [INFO]: Epoch 106 - training loss: 0.2257, validation loss: 0.1810
2024-05-25 02:34:12 [INFO]: Epoch 107 - training loss: 0.2260, validation loss: 0.1814
2024-05-25 02:34:12 [INFO]: Epoch 108 - training loss: 0.2289, validation loss: 0.1793
2024-05-25 02:34:12 [INFO]: Epoch 109 - training loss: 0.2278, validation loss: 0.1807
2024-05-25 02:34:13 [INFO]: Epoch 110 - training loss: 0.2266, validation loss: 0.1797
2024-05-25 02:34:13 [INFO]: Epoch 111 - training loss: 0.2274, validation loss: 0.1815
2024-05-25 02:34:13 [INFO]: Epoch 112 - training loss: 0.2256, validation loss: 0.1801
2024-05-25 02:34:14 [INFO]: Epoch 113 - training loss: 0.2232, validation loss: 0.1788
2024-05-25 02:34:14 [INFO]: Epoch 114 - training loss: 0.2220, validation loss: 0.1796
2024-05-25 02:34:14 [INFO]: Epoch 115 - training loss: 0.2203, validation loss: 0.1777
2024-05-25 02:34:15 [INFO]: Epoch 116 - training loss: 0.2200, validation loss: 0.1773
2024-05-25 02:34:15 [INFO]: Epoch 117 - training loss: 0.2191, validation loss: 0.1773
2024-05-25 02:34:15 [INFO]: Epoch 118 - training loss: 0.2207, validation loss: 0.1766
2024-05-25 02:34:16 [INFO]: Epoch 119 - training loss: 0.2225, validation loss: 0.1775
2024-05-25 02:34:16 [INFO]: Epoch 120 - training loss: 0.2212, validation loss: 0.1757
2024-05-25 02:34:16 [INFO]: Epoch 121 - training loss: 0.2192, validation loss: 0.1771
2024-05-25 02:34:16 [INFO]: Epoch 122 - training loss: 0.2180, validation loss: 0.1770
2024-05-25 02:34:17 [INFO]: Epoch 123 - training loss: 0.2205, validation loss: 0.1773
2024-05-25 02:34:17 [INFO]: Epoch 124 - training loss: 0.2186, validation loss: 0.1757
2024-05-25 02:34:17 [INFO]: Epoch 125 - training loss: 0.2176, validation loss: 0.1778
2024-05-25 02:34:18 [INFO]: Epoch 126 - training loss: 0.2166, validation loss: 0.1756
2024-05-25 02:34:18 [INFO]: Epoch 127 - training loss: 0.2181, validation loss: 0.1771
2024-05-25 02:34:18 [INFO]: Epoch 128 - training loss: 0.2202, validation loss: 0.1768
2024-05-25 02:34:19 [INFO]: Epoch 129 - training loss: 0.2217, validation loss: 0.1750
2024-05-25 02:34:19 [INFO]: Epoch 130 - training loss: 0.2197, validation loss: 0.1769
2024-05-25 02:34:19 [INFO]: Epoch 131 - training loss: 0.2165, validation loss: 0.1753
2024-05-25 02:34:20 [INFO]: Epoch 132 - training loss: 0.2161, validation loss: 0.1739
2024-05-25 02:34:20 [INFO]: Epoch 133 - training loss: 0.2167, validation loss: 0.1777
2024-05-25 02:34:20 [INFO]: Epoch 134 - training loss: 0.2170, validation loss: 0.1739
2024-05-25 02:34:21 [INFO]: Epoch 135 - training loss: 0.2157, validation loss: 0.1754
2024-05-25 02:34:21 [INFO]: Epoch 136 - training loss: 0.2142, validation loss: 0.1736
2024-05-25 02:34:21 [INFO]: Epoch 137 - training loss: 0.2138, validation loss: 0.1743
2024-05-25 02:34:22 [INFO]: Epoch 138 - training loss: 0.2144, validation loss: 0.1721
2024-05-25 02:34:22 [INFO]: Epoch 139 - training loss: 0.2148, validation loss: 0.1728
2024-05-25 02:34:22 [INFO]: Epoch 140 - training loss: 0.2106, validation loss: 0.1730
2024-05-25 02:34:23 [INFO]: Epoch 141 - training loss: 0.2124, validation loss: 0.1741
2024-05-25 02:34:23 [INFO]: Epoch 142 - training loss: 0.2137, validation loss: 0.1726
2024-05-25 02:34:23 [INFO]: Epoch 143 - training loss: 0.2110, validation loss: 0.1731
2024-05-25 02:34:23 [INFO]: Epoch 144 - training loss: 0.2124, validation loss: 0.1731
2024-05-25 02:34:24 [INFO]: Epoch 145 - training loss: 0.2103, validation loss: 0.1729
2024-05-25 02:34:24 [INFO]: Epoch 146 - training loss: 0.2096, validation loss: 0.1725
2024-05-25 02:34:24 [INFO]: Epoch 147 - training loss: 0.2116, validation loss: 0.1728
2024-05-25 02:34:25 [INFO]: Epoch 148 - training loss: 0.2102, validation loss: 0.1720
2024-05-25 02:34:25 [INFO]: Epoch 149 - training loss: 0.2085, validation loss: 0.1706
2024-05-25 02:34:25 [INFO]: Epoch 150 - training loss: 0.2082, validation loss: 0.1732
2024-05-25 02:34:26 [INFO]: Epoch 151 - training loss: 0.2089, validation loss: 0.1716
2024-05-25 02:34:26 [INFO]: Epoch 152 - training loss: 0.2069, validation loss: 0.1712
2024-05-25 02:34:26 [INFO]: Epoch 153 - training loss: 0.2070, validation loss: 0.1718
2024-05-25 02:34:27 [INFO]: Epoch 154 - training loss: 0.2088, validation loss: 0.1729
2024-05-25 02:34:27 [INFO]: Epoch 155 - training loss: 0.2096, validation loss: 0.1713
2024-05-25 02:34:27 [INFO]: Epoch 156 - training loss: 0.2070, validation loss: 0.1730
2024-05-25 02:34:28 [INFO]: Epoch 157 - training loss: 0.2081, validation loss: 0.1723
2024-05-25 02:34:28 [INFO]: Epoch 158 - training loss: 0.2086, validation loss: 0.1731
2024-05-25 02:34:28 [INFO]: Epoch 159 - training loss: 0.2061, validation loss: 0.1715
2024-05-25 02:34:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:34:28 [INFO]: Finished training. The best model is from epoch#149.
2024-05-25 02:34:28 [INFO]: Saved the model to augmentation_saved_results/round_2/Transformer_air_quality/20240525_T023338/Transformer.pypots
2024-05-25 02:34:28 [INFO]: Transformer on Air-Quality: MAE=0.1642, MSE=0.1141
2024-05-25 02:34:28 [INFO]: Successfully saved to augmentation_saved_results/round_2/Transformer_air_quality/imputation.pkl
2024-05-25 02:34:28 [INFO]: Using the given device: cuda:0
2024-05-25 02:34:28 [INFO]: Model files will be saved to augmentation_saved_results/round_2/TimesNet_air_quality/20240525_T023428
2024-05-25 02:34:28 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/TimesNet_air_quality/20240525_T023428/tensorboard
2024-05-25 02:34:29 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 02:34:29 [INFO]: Epoch 001 - training loss: 0.2730, validation loss: 0.3016
2024-05-25 02:34:30 [INFO]: Epoch 002 - training loss: 0.2418, validation loss: 0.2657
2024-05-25 02:34:30 [INFO]: Epoch 003 - training loss: 0.1934, validation loss: 0.2520
2024-05-25 02:34:31 [INFO]: Epoch 004 - training loss: 0.1904, validation loss: 0.2386
2024-05-25 02:34:31 [INFO]: Epoch 005 - training loss: 0.1759, validation loss: 0.2467
2024-05-25 02:34:32 [INFO]: Epoch 006 - training loss: 0.1865, validation loss: 0.2304
2024-05-25 02:34:32 [INFO]: Epoch 007 - training loss: 0.1518, validation loss: 0.2208
2024-05-25 02:34:33 [INFO]: Epoch 008 - training loss: 0.1518, validation loss: 0.2295
2024-05-25 02:34:33 [INFO]: Epoch 009 - training loss: 0.1618, validation loss: 0.2232
2024-05-25 02:34:34 [INFO]: Epoch 010 - training loss: 0.1419, validation loss: 0.2152
2024-05-25 02:34:35 [INFO]: Epoch 011 - training loss: 0.1521, validation loss: 0.2210
2024-05-25 02:34:35 [INFO]: Epoch 012 - training loss: 0.1409, validation loss: 0.2216
2024-05-25 02:34:36 [INFO]: Epoch 013 - training loss: 0.1440, validation loss: 0.2083
2024-05-25 02:34:36 [INFO]: Epoch 014 - training loss: 0.1475, validation loss: 0.2060
2024-05-25 02:34:37 [INFO]: Epoch 015 - training loss: 0.1449, validation loss: 0.2217
2024-05-25 02:34:37 [INFO]: Epoch 016 - training loss: 0.1500, validation loss: 0.2160
2024-05-25 02:34:38 [INFO]: Epoch 017 - training loss: 0.1305, validation loss: 0.2237
2024-05-25 02:34:38 [INFO]: Epoch 018 - training loss: 0.1435, validation loss: 0.2135
2024-05-25 02:34:39 [INFO]: Epoch 019 - training loss: 0.1350, validation loss: 0.2174
2024-05-25 02:34:39 [INFO]: Epoch 020 - training loss: 0.1053, validation loss: 0.2119
2024-05-25 02:34:40 [INFO]: Epoch 021 - training loss: 0.1147, validation loss: 0.2093
2024-05-25 02:34:40 [INFO]: Epoch 022 - training loss: 0.1252, validation loss: 0.2095
2024-05-25 02:34:41 [INFO]: Epoch 023 - training loss: 0.1267, validation loss: 0.2127
2024-05-25 02:34:41 [INFO]: Epoch 024 - training loss: 0.1255, validation loss: 0.2096
2024-05-25 02:34:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:34:41 [INFO]: Finished training. The best model is from epoch#14.
2024-05-25 02:34:42 [INFO]: Saved the model to augmentation_saved_results/round_2/TimesNet_air_quality/20240525_T023428/TimesNet.pypots
2024-05-25 02:34:42 [INFO]: TimesNet on Air-Quality: MAE=0.1711, MSE=0.1461
2024-05-25 02:34:42 [INFO]: Successfully saved to augmentation_saved_results/round_2/TimesNet_air_quality/imputation.pkl
2024-05-25 02:34:42 [INFO]: Using the given device: cuda:0
2024-05-25 02:34:42 [INFO]: Model files will be saved to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442
2024-05-25 02:34:42 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/tensorboard
2024-05-25 02:34:42 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 02:34:58 [INFO]: Epoch 001 - training loss: 0.4801, validation loss: 0.3547
2024-05-25 02:34:58 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch1_loss0.3546819180250168.pypots
2024-05-25 02:35:15 [INFO]: Epoch 002 - training loss: 0.3095, validation loss: 0.2967
2024-05-25 02:35:15 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch2_loss0.29673994779586793.pypots
2024-05-25 02:35:32 [INFO]: Epoch 003 - training loss: 0.2499, validation loss: 0.2179
2024-05-25 02:35:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch3_loss0.21785536408424377.pypots
2024-05-25 02:35:49 [INFO]: Epoch 004 - training loss: 0.2167, validation loss: 0.2038
2024-05-25 02:35:49 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch4_loss0.20375744104385377.pypots
2024-05-25 02:36:06 [INFO]: Epoch 005 - training loss: 0.2044, validation loss: 0.1878
2024-05-25 02:36:06 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch5_loss0.18784875124692918.pypots
2024-05-25 02:36:22 [INFO]: Epoch 006 - training loss: 0.1929, validation loss: 0.1677
2024-05-25 02:36:22 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch6_loss0.16769230216741562.pypots
2024-05-25 02:36:39 [INFO]: Epoch 007 - training loss: 0.1857, validation loss: 0.1671
2024-05-25 02:36:39 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch7_loss0.1670564740896225.pypots
2024-05-25 02:36:56 [INFO]: Epoch 008 - training loss: 0.1932, validation loss: 0.1632
2024-05-25 02:36:56 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch8_loss0.16322864592075348.pypots
2024-05-25 02:37:13 [INFO]: Epoch 009 - training loss: 0.1667, validation loss: 0.1552
2024-05-25 02:37:13 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch9_loss0.1551613003015518.pypots
2024-05-25 02:37:30 [INFO]: Epoch 010 - training loss: 0.1662, validation loss: 0.1540
2024-05-25 02:37:30 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch10_loss0.15403337329626082.pypots
2024-05-25 02:37:46 [INFO]: Epoch 011 - training loss: 0.1990, validation loss: 0.1532
2024-05-25 02:37:46 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch11_loss0.1532350391149521.pypots
2024-05-25 02:38:03 [INFO]: Epoch 012 - training loss: 0.1629, validation loss: 0.1482
2024-05-25 02:38:03 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch12_loss0.14823110699653624.pypots
2024-05-25 02:38:20 [INFO]: Epoch 013 - training loss: 0.1566, validation loss: 0.1429
2024-05-25 02:38:20 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch13_loss0.1428720198571682.pypots
2024-05-25 02:38:37 [INFO]: Epoch 014 - training loss: 0.1497, validation loss: 0.1522
2024-05-25 02:38:37 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch14_loss0.1521914854645729.pypots
2024-05-25 02:38:54 [INFO]: Epoch 015 - training loss: 0.1560, validation loss: 0.1438
2024-05-25 02:38:54 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch15_loss0.14382022023200988.pypots
2024-05-25 02:39:10 [INFO]: Epoch 016 - training loss: 0.1398, validation loss: 0.1418
2024-05-25 02:39:10 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch16_loss0.14176533445715905.pypots
2024-05-25 02:39:27 [INFO]: Epoch 017 - training loss: 0.1621, validation loss: 0.1419
2024-05-25 02:39:27 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch17_loss0.1418687753379345.pypots
2024-05-25 02:39:44 [INFO]: Epoch 018 - training loss: 0.1553, validation loss: 0.1449
2024-05-25 02:39:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch18_loss0.14492886364459992.pypots
2024-05-25 02:40:01 [INFO]: Epoch 019 - training loss: 0.1647, validation loss: 0.1411
2024-05-25 02:40:01 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch19_loss0.14106077775359155.pypots
2024-05-25 02:40:18 [INFO]: Epoch 020 - training loss: 0.1660, validation loss: 0.1372
2024-05-25 02:40:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch20_loss0.1372014708817005.pypots
2024-05-25 02:40:34 [INFO]: Epoch 021 - training loss: 0.1555, validation loss: 0.1431
2024-05-25 02:40:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch21_loss0.1431185320019722.pypots
2024-05-25 02:40:51 [INFO]: Epoch 022 - training loss: 0.1512, validation loss: 0.1360
2024-05-25 02:40:51 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch22_loss0.13596321195363997.pypots
2024-05-25 02:41:08 [INFO]: Epoch 023 - training loss: 0.1636, validation loss: 0.1390
2024-05-25 02:41:08 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch23_loss0.13896960988640786.pypots
2024-05-25 02:41:25 [INFO]: Epoch 024 - training loss: 0.1496, validation loss: 0.1310
2024-05-25 02:41:25 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch24_loss0.1309504933655262.pypots
2024-05-25 02:41:42 [INFO]: Epoch 025 - training loss: 0.1384, validation loss: 0.1343
2024-05-25 02:41:42 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch25_loss0.13430366963148116.pypots
2024-05-25 02:41:58 [INFO]: Epoch 026 - training loss: 0.1455, validation loss: 0.1352
2024-05-25 02:41:58 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch26_loss0.1352002240717411.pypots
2024-05-25 02:42:15 [INFO]: Epoch 027 - training loss: 0.1375, validation loss: 0.1265
2024-05-25 02:42:15 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch27_loss0.12653944343328477.pypots
2024-05-25 02:42:32 [INFO]: Epoch 028 - training loss: 0.1461, validation loss: 0.1307
2024-05-25 02:42:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch28_loss0.13066111803054808.pypots
2024-05-25 02:42:49 [INFO]: Epoch 029 - training loss: 0.1505, validation loss: 0.1270
2024-05-25 02:42:49 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch29_loss0.12703720927238465.pypots
2024-05-25 02:43:06 [INFO]: Epoch 030 - training loss: 0.1482, validation loss: 0.1273
2024-05-25 02:43:06 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch30_loss0.12734799534082414.pypots
2024-05-25 02:43:22 [INFO]: Epoch 031 - training loss: 0.1328, validation loss: 0.1299
2024-05-25 02:43:22 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch31_loss0.12992692664265632.pypots
2024-05-25 02:43:39 [INFO]: Epoch 032 - training loss: 0.1389, validation loss: 0.1256
2024-05-25 02:43:39 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch32_loss0.12557336539030076.pypots
2024-05-25 02:43:56 [INFO]: Epoch 033 - training loss: 0.1589, validation loss: 0.1280
2024-05-25 02:43:56 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch33_loss0.12799854725599288.pypots
2024-05-25 02:44:13 [INFO]: Epoch 034 - training loss: 0.1394, validation loss: 0.1315
2024-05-25 02:44:13 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch34_loss0.131536129117012.pypots
2024-05-25 02:44:30 [INFO]: Epoch 035 - training loss: 0.1510, validation loss: 0.1310
2024-05-25 02:44:30 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch35_loss0.13099009469151496.pypots
2024-05-25 02:44:46 [INFO]: Epoch 036 - training loss: 0.1364, validation loss: 0.1256
2024-05-25 02:44:46 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch36_loss0.12555421739816666.pypots
2024-05-25 02:45:03 [INFO]: Epoch 037 - training loss: 0.1417, validation loss: 0.1218
2024-05-25 02:45:03 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch37_loss0.12184013277292252.pypots
2024-05-25 02:45:20 [INFO]: Epoch 038 - training loss: 0.1315, validation loss: 0.1226
2024-05-25 02:45:20 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch38_loss0.1226038582623005.pypots
2024-05-25 02:45:37 [INFO]: Epoch 039 - training loss: 0.1137, validation loss: 0.1223
2024-05-25 02:45:37 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch39_loss0.12228033915162087.pypots
2024-05-25 02:45:54 [INFO]: Epoch 040 - training loss: 0.1389, validation loss: 0.1223
2024-05-25 02:45:54 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch40_loss0.12233473360538483.pypots
2024-05-25 02:46:10 [INFO]: Epoch 041 - training loss: 0.1382, validation loss: 0.1218
2024-05-25 02:46:10 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch41_loss0.12179727256298065.pypots
2024-05-25 02:46:27 [INFO]: Epoch 042 - training loss: 0.1329, validation loss: 0.1186
2024-05-25 02:46:27 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch42_loss0.11859203651547431.pypots
2024-05-25 02:46:44 [INFO]: Epoch 043 - training loss: 0.1429, validation loss: 0.1309
2024-05-25 02:46:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch43_loss0.1308670535683632.pypots
2024-05-25 02:47:01 [INFO]: Epoch 044 - training loss: 0.1276, validation loss: 0.1251
2024-05-25 02:47:01 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch44_loss0.12510793209075927.pypots
2024-05-25 02:47:17 [INFO]: Epoch 045 - training loss: 0.1366, validation loss: 0.1249
2024-05-25 02:47:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch45_loss0.12487210631370545.pypots
2024-05-25 02:47:34 [INFO]: Epoch 046 - training loss: 0.1184, validation loss: 0.1212
2024-05-25 02:47:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch46_loss0.1211845874786377.pypots
2024-05-25 02:47:51 [INFO]: Epoch 047 - training loss: 0.1344, validation loss: 0.1181
2024-05-25 02:47:51 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch47_loss0.11809149384498596.pypots
2024-05-25 02:48:08 [INFO]: Epoch 048 - training loss: 0.1267, validation loss: 0.1200
2024-05-25 02:48:08 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch48_loss0.11996664330363274.pypots
2024-05-25 02:48:25 [INFO]: Epoch 049 - training loss: 0.1339, validation loss: 0.1164
2024-05-25 02:48:25 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch49_loss0.11640707179903984.pypots
2024-05-25 02:48:41 [INFO]: Epoch 050 - training loss: 0.1337, validation loss: 0.1241
2024-05-25 02:48:41 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch50_loss0.12406585589051247.pypots
2024-05-25 02:48:58 [INFO]: Epoch 051 - training loss: 0.1353, validation loss: 0.1180
2024-05-25 02:48:58 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch51_loss0.11797887310385705.pypots
2024-05-25 02:49:15 [INFO]: Epoch 052 - training loss: 0.1171, validation loss: 0.1165
2024-05-25 02:49:15 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch52_loss0.11654311940073966.pypots
2024-05-25 02:49:32 [INFO]: Epoch 053 - training loss: 0.1291, validation loss: 0.1123
2024-05-25 02:49:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch53_loss0.11228346973657607.pypots
2024-05-25 02:49:49 [INFO]: Epoch 054 - training loss: 0.1131, validation loss: 0.1153
2024-05-25 02:49:49 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch54_loss0.11526274010539055.pypots
2024-05-25 02:50:05 [INFO]: Epoch 055 - training loss: 0.1241, validation loss: 0.1156
2024-05-25 02:50:05 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch55_loss0.11564355045557022.pypots
2024-05-25 02:50:22 [INFO]: Epoch 056 - training loss: 0.1084, validation loss: 0.1158
2024-05-25 02:50:22 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch56_loss0.11575721651315689.pypots
2024-05-25 02:50:39 [INFO]: Epoch 057 - training loss: 0.1301, validation loss: 0.1113
2024-05-25 02:50:39 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch57_loss0.11134488806128502.pypots
2024-05-25 02:50:56 [INFO]: Epoch 058 - training loss: 0.1466, validation loss: 0.1173
2024-05-25 02:50:56 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch58_loss0.11733785718679428.pypots
2024-05-25 02:51:13 [INFO]: Epoch 059 - training loss: 0.1354, validation loss: 0.1115
2024-05-25 02:51:13 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch59_loss0.11154644638299942.pypots
2024-05-25 02:51:30 [INFO]: Epoch 060 - training loss: 0.1147, validation loss: 0.1110
2024-05-25 02:51:30 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch60_loss0.11096919625997544.pypots
2024-05-25 02:51:46 [INFO]: Epoch 061 - training loss: 0.1226, validation loss: 0.1165
2024-05-25 02:51:46 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch61_loss0.11654486730694771.pypots
2024-05-25 02:52:03 [INFO]: Epoch 062 - training loss: 0.1353, validation loss: 0.1122
2024-05-25 02:52:03 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch62_loss0.11217539682984352.pypots
2024-05-25 02:52:20 [INFO]: Epoch 063 - training loss: 0.1184, validation loss: 0.1112
2024-05-25 02:52:20 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch63_loss0.11117781698703766.pypots
2024-05-25 02:52:37 [INFO]: Epoch 064 - training loss: 0.1209, validation loss: 0.1104
2024-05-25 02:52:37 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch64_loss0.11042460277676583.pypots
2024-05-25 02:52:54 [INFO]: Epoch 065 - training loss: 0.1108, validation loss: 0.1143
2024-05-25 02:52:54 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch65_loss0.1143254354596138.pypots
2024-05-25 02:53:10 [INFO]: Epoch 066 - training loss: 0.1131, validation loss: 0.1105
2024-05-25 02:53:10 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch66_loss0.11047130897641182.pypots
2024-05-25 02:53:27 [INFO]: Epoch 067 - training loss: 0.1275, validation loss: 0.1085
2024-05-25 02:53:27 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch67_loss0.10846583172678947.pypots
2024-05-25 02:53:44 [INFO]: Epoch 068 - training loss: 0.1162, validation loss: 0.1081
2024-05-25 02:53:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch68_loss0.1080916740000248.pypots
2024-05-25 02:54:01 [INFO]: Epoch 069 - training loss: 0.1162, validation loss: 0.1065
2024-05-25 02:54:01 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch69_loss0.10647669956088066.pypots
2024-05-25 02:54:18 [INFO]: Epoch 070 - training loss: 0.1290, validation loss: 0.1081
2024-05-25 02:54:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch70_loss0.10811748653650284.pypots
2024-05-25 02:54:34 [INFO]: Epoch 071 - training loss: 0.1235, validation loss: 0.1155
2024-05-25 02:54:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch71_loss0.11554905921220779.pypots
2024-05-25 02:54:51 [INFO]: Epoch 072 - training loss: 0.1258, validation loss: 0.1101
2024-05-25 02:54:51 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch72_loss0.11013353243470192.pypots
2024-05-25 02:55:08 [INFO]: Epoch 073 - training loss: 0.1192, validation loss: 0.1124
2024-05-25 02:55:08 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch73_loss0.11242324635386466.pypots
2024-05-25 02:55:25 [INFO]: Epoch 074 - training loss: 0.1264, validation loss: 0.1099
2024-05-25 02:55:25 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch74_loss0.10985927432775497.pypots
2024-05-25 02:55:42 [INFO]: Epoch 075 - training loss: 0.1188, validation loss: 0.1115
2024-05-25 02:55:42 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch75_loss0.11147596389055252.pypots
2024-05-25 02:55:58 [INFO]: Epoch 076 - training loss: 0.1199, validation loss: 0.1061
2024-05-25 02:55:58 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch76_loss0.10611604005098343.pypots
2024-05-25 02:56:15 [INFO]: Epoch 077 - training loss: 0.1086, validation loss: 0.1079
2024-05-25 02:56:15 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch77_loss0.10792568922042847.pypots
2024-05-25 02:56:32 [INFO]: Epoch 078 - training loss: 0.1063, validation loss: 0.1068
2024-05-25 02:56:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch78_loss0.10679867416620255.pypots
2024-05-25 02:56:49 [INFO]: Epoch 079 - training loss: 0.1235, validation loss: 0.1078
2024-05-25 02:56:49 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch79_loss0.10777871087193489.pypots
2024-05-25 02:57:06 [INFO]: Epoch 080 - training loss: 0.1209, validation loss: 0.1128
2024-05-25 02:57:06 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch80_loss0.1127786748111248.pypots
2024-05-25 02:57:22 [INFO]: Epoch 081 - training loss: 0.1182, validation loss: 0.1061
2024-05-25 02:57:23 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch81_loss0.10607306733727455.pypots
2024-05-25 02:57:39 [INFO]: Epoch 082 - training loss: 0.1139, validation loss: 0.1057
2024-05-25 02:57:39 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch82_loss0.105710968375206.pypots
2024-05-25 02:57:56 [INFO]: Epoch 083 - training loss: 0.1288, validation loss: 0.1047
2024-05-25 02:57:56 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch83_loss0.10470146238803864.pypots
2024-05-25 02:58:13 [INFO]: Epoch 084 - training loss: 0.1257, validation loss: 0.1052
2024-05-25 02:58:13 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch84_loss0.10521462559700012.pypots
2024-05-25 02:58:30 [INFO]: Epoch 085 - training loss: 0.1231, validation loss: 0.1080
2024-05-25 02:58:30 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch85_loss0.1079522930085659.pypots
2024-05-25 02:58:47 [INFO]: Epoch 086 - training loss: 0.1121, validation loss: 0.1065
2024-05-25 02:58:47 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch86_loss0.10647936835885048.pypots
2024-05-25 02:59:03 [INFO]: Epoch 087 - training loss: 0.1209, validation loss: 0.1094
2024-05-25 02:59:03 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch87_loss0.10938324257731438.pypots
2024-05-25 02:59:20 [INFO]: Epoch 088 - training loss: 0.1139, validation loss: 0.1068
2024-05-25 02:59:20 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch88_loss0.10680018588900567.pypots
2024-05-25 02:59:37 [INFO]: Epoch 089 - training loss: 0.1314, validation loss: 0.1051
2024-05-25 02:59:37 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch89_loss0.10514728575944901.pypots
2024-05-25 02:59:54 [INFO]: Epoch 090 - training loss: 0.1079, validation loss: 0.1087
2024-05-25 02:59:54 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch90_loss0.10865033343434334.pypots
2024-05-25 03:00:11 [INFO]: Epoch 091 - training loss: 0.1311, validation loss: 0.1044
2024-05-25 03:00:11 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch91_loss0.10442457348108292.pypots
2024-05-25 03:00:27 [INFO]: Epoch 092 - training loss: 0.1311, validation loss: 0.1046
2024-05-25 03:00:27 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch92_loss0.10455420836806298.pypots
2024-05-25 03:00:44 [INFO]: Epoch 093 - training loss: 0.1236, validation loss: 0.1074
2024-05-25 03:00:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch93_loss0.10744247809052468.pypots
2024-05-25 03:01:01 [INFO]: Epoch 094 - training loss: 0.1277, validation loss: 0.1013
2024-05-25 03:01:01 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch94_loss0.10132767856121064.pypots
2024-05-25 03:01:18 [INFO]: Epoch 095 - training loss: 0.1092, validation loss: 0.1060
2024-05-25 03:01:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch95_loss0.10604954585433006.pypots
2024-05-25 03:01:35 [INFO]: Epoch 096 - training loss: 0.1131, validation loss: 0.1133
2024-05-25 03:01:35 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch96_loss0.11327393203973771.pypots
2024-05-25 03:01:51 [INFO]: Epoch 097 - training loss: 0.1084, validation loss: 0.1064
2024-05-25 03:01:51 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch97_loss0.10637772679328919.pypots
2024-05-25 03:02:08 [INFO]: Epoch 098 - training loss: 0.1070, validation loss: 0.1040
2024-05-25 03:02:08 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch98_loss0.10399966388940811.pypots
2024-05-25 03:02:25 [INFO]: Epoch 099 - training loss: 0.1040, validation loss: 0.1037
2024-05-25 03:02:25 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch99_loss0.10369584709405899.pypots
2024-05-25 03:02:42 [INFO]: Epoch 100 - training loss: 0.1250, validation loss: 0.1030
2024-05-25 03:02:42 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch100_loss0.10301764085888862.pypots
2024-05-25 03:02:59 [INFO]: Epoch 101 - training loss: 0.1171, validation loss: 0.1041
2024-05-25 03:02:59 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch101_loss0.104108265042305.pypots
2024-05-25 03:03:15 [INFO]: Epoch 102 - training loss: 0.1190, validation loss: 0.1019
2024-05-25 03:03:15 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch102_loss0.10185783356428146.pypots
2024-05-25 03:03:32 [INFO]: Epoch 103 - training loss: 0.1224, validation loss: 0.1047
2024-05-25 03:03:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch103_loss0.10472916811704636.pypots
2024-05-25 03:03:49 [INFO]: Epoch 104 - training loss: 0.1146, validation loss: 0.1020
2024-05-25 03:03:49 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI_epoch104_loss0.10201791897416115.pypots
2024-05-25 03:03:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:03:49 [INFO]: Finished training. The best model is from epoch#94.
2024-05-25 03:03:49 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T023442/CSDI.pypots
2024-05-25 03:06:09 [INFO]: CSDI on Air-Quality: MAE=0.1016, MSE=0.0982
2024-05-25 03:06:09 [INFO]: Successfully saved to augmentation_saved_results/round_2/CSDI_air_quality/imputation.pkl
2024-05-25 03:06:09 [INFO]: Using the given device: cuda:0
2024-05-25 03:06:09 [INFO]: Model files will be saved to augmentation_saved_results/round_2/GPVAE_air_quality/20240525_T030609
2024-05-25 03:06:09 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/GPVAE_air_quality/20240525_T030609/tensorboard
2024-05-25 03:06:09 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 03:06:10 [INFO]: Epoch 001 - training loss: 63653.0414, validation loss: 0.6963
2024-05-25 03:06:10 [INFO]: Epoch 002 - training loss: 42086.2745, validation loss: 0.6073
2024-05-25 03:06:10 [INFO]: Epoch 003 - training loss: 41798.5855, validation loss: 0.6355
2024-05-25 03:06:11 [INFO]: Epoch 004 - training loss: 41689.7637, validation loss: 0.5442
2024-05-25 03:06:11 [INFO]: Epoch 005 - training loss: 41557.8262, validation loss: 0.4736
2024-05-25 03:06:11 [INFO]: Epoch 006 - training loss: 41485.6302, validation loss: 0.4472
2024-05-25 03:06:12 [INFO]: Epoch 007 - training loss: 41460.6448, validation loss: 0.4049
2024-05-25 03:06:12 [INFO]: Epoch 008 - training loss: 41413.3814, validation loss: 0.3890
2024-05-25 03:06:13 [INFO]: Epoch 009 - training loss: 41392.3163, validation loss: 0.3694
2024-05-25 03:06:13 [INFO]: Epoch 010 - training loss: 41382.0612, validation loss: 0.4033
2024-05-25 03:06:13 [INFO]: Epoch 011 - training loss: 41388.8924, validation loss: 0.4119
2024-05-25 03:06:14 [INFO]: Epoch 012 - training loss: 41380.4793, validation loss: 0.3573
2024-05-25 03:06:14 [INFO]: Epoch 013 - training loss: 41338.0602, validation loss: 0.3472
2024-05-25 03:06:14 [INFO]: Epoch 014 - training loss: 41313.4544, validation loss: 0.3454
2024-05-25 03:06:15 [INFO]: Epoch 015 - training loss: 41306.4942, validation loss: 0.3347
2024-05-25 03:06:15 [INFO]: Epoch 016 - training loss: 41322.9008, validation loss: 0.3324
2024-05-25 03:06:15 [INFO]: Epoch 017 - training loss: 41301.4061, validation loss: 0.3442
2024-05-25 03:06:16 [INFO]: Epoch 018 - training loss: 41295.3691, validation loss: 0.3322
2024-05-25 03:06:16 [INFO]: Epoch 019 - training loss: 41275.6330, validation loss: 0.3102
2024-05-25 03:06:16 [INFO]: Epoch 020 - training loss: 41276.0819, validation loss: 0.3348
2024-05-25 03:06:17 [INFO]: Epoch 021 - training loss: 41322.1441, validation loss: 0.3240
2024-05-25 03:06:17 [INFO]: Epoch 022 - training loss: 41265.6939, validation loss: 0.3187
2024-05-25 03:06:17 [INFO]: Epoch 023 - training loss: 41272.4223, validation loss: 0.3151
2024-05-25 03:06:18 [INFO]: Epoch 024 - training loss: 41259.5399, validation loss: 0.3077
2024-05-25 03:06:18 [INFO]: Epoch 025 - training loss: 41237.6630, validation loss: 0.2976
2024-05-25 03:06:18 [INFO]: Epoch 026 - training loss: 41222.2928, validation loss: 0.2902
2024-05-25 03:06:19 [INFO]: Epoch 027 - training loss: 41216.0936, validation loss: 0.2898
2024-05-25 03:06:19 [INFO]: Epoch 028 - training loss: 41221.8024, validation loss: 0.2951
2024-05-25 03:06:19 [INFO]: Epoch 029 - training loss: 41253.4398, validation loss: 0.3056
2024-05-25 03:06:20 [INFO]: Epoch 030 - training loss: 41226.6280, validation loss: 0.2936
2024-05-25 03:06:20 [INFO]: Epoch 031 - training loss: 41215.6616, validation loss: 0.2788
2024-05-25 03:06:20 [INFO]: Epoch 032 - training loss: 41208.2315, validation loss: 0.2854
2024-05-25 03:06:21 [INFO]: Epoch 033 - training loss: 41211.3743, validation loss: 0.2814
2024-05-25 03:06:21 [INFO]: Epoch 034 - training loss: 41219.2105, validation loss: 0.2867
2024-05-25 03:06:21 [INFO]: Epoch 035 - training loss: 41266.2869, validation loss: 0.2979
2024-05-25 03:06:22 [INFO]: Epoch 036 - training loss: 41258.0213, validation loss: 0.3145
2024-05-25 03:06:22 [INFO]: Epoch 037 - training loss: 41267.4462, validation loss: 0.3846
2024-05-25 03:06:22 [INFO]: Epoch 038 - training loss: 41244.5530, validation loss: 0.2866
2024-05-25 03:06:23 [INFO]: Epoch 039 - training loss: 41301.6607, validation loss: 0.3127
2024-05-25 03:06:23 [INFO]: Epoch 040 - training loss: 41281.4067, validation loss: 0.3027
2024-05-25 03:06:23 [INFO]: Epoch 041 - training loss: 41246.8644, validation loss: 0.2883
2024-05-25 03:06:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:06:23 [INFO]: Finished training. The best model is from epoch#31.
2024-05-25 03:06:23 [INFO]: Saved the model to augmentation_saved_results/round_2/GPVAE_air_quality/20240525_T030609/GPVAE.pypots
2024-05-25 03:06:23 [INFO]: GP-VAE on Air-Quality: MAE=0.2891, MSE=0.2291
2024-05-25 03:06:23 [INFO]: Successfully saved to augmentation_saved_results/round_2/GPVAE_air_quality/imputation.pkl
2024-05-25 03:06:23 [INFO]: Using the given device: cuda:0
2024-05-25 03:06:23 [INFO]: Model files will be saved to augmentation_saved_results/round_2/USGAN_air_quality/20240525_T030623
2024-05-25 03:06:23 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/USGAN_air_quality/20240525_T030623/tensorboard
2024-05-25 03:06:23 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 03:06:28 [INFO]: Epoch 001 - generator training loss: 0.5947, discriminator training loss: 0.2946, validation loss: 0.5269
2024-05-25 03:06:32 [INFO]: Epoch 002 - generator training loss: 0.2837, discriminator training loss: 0.0677, validation loss: 0.4100
2024-05-25 03:06:37 [INFO]: Epoch 003 - generator training loss: 0.2109, discriminator training loss: 0.0636, validation loss: 0.3454
2024-05-25 03:06:41 [INFO]: Epoch 004 - generator training loss: 0.1749, discriminator training loss: 0.0626, validation loss: 0.3056
2024-05-25 03:06:45 [INFO]: Epoch 005 - generator training loss: 0.1540, discriminator training loss: 0.0614, validation loss: 0.2798
2024-05-25 03:06:49 [INFO]: Epoch 006 - generator training loss: 0.1340, discriminator training loss: 0.0616, validation loss: 0.2632
2024-05-25 03:06:53 [INFO]: Epoch 007 - generator training loss: 0.1185, discriminator training loss: 0.0608, validation loss: 0.2507
2024-05-25 03:06:57 [INFO]: Epoch 008 - generator training loss: 0.1084, discriminator training loss: 0.0603, validation loss: 0.2413
2024-05-25 03:07:01 [INFO]: Epoch 009 - generator training loss: 0.0996, discriminator training loss: 0.0603, validation loss: 0.2350
2024-05-25 03:07:05 [INFO]: Epoch 010 - generator training loss: 0.0939, discriminator training loss: 0.0589, validation loss: 0.2298
2024-05-25 03:07:09 [INFO]: Epoch 011 - generator training loss: 0.0877, discriminator training loss: 0.0587, validation loss: 0.2257
2024-05-25 03:07:13 [INFO]: Epoch 012 - generator training loss: 0.0853, discriminator training loss: 0.0566, validation loss: 0.2219
2024-05-25 03:07:18 [INFO]: Epoch 013 - generator training loss: 0.0828, discriminator training loss: 0.0556, validation loss: 0.2186
2024-05-25 03:07:22 [INFO]: Epoch 014 - generator training loss: 0.0784, discriminator training loss: 0.0540, validation loss: 0.2166
2024-05-25 03:07:26 [INFO]: Epoch 015 - generator training loss: 0.0753, discriminator training loss: 0.0520, validation loss: 0.2140
2024-05-25 03:07:30 [INFO]: Epoch 016 - generator training loss: 0.0733, discriminator training loss: 0.0504, validation loss: 0.2125
2024-05-25 03:07:34 [INFO]: Epoch 017 - generator training loss: 0.0721, discriminator training loss: 0.0489, validation loss: 0.2099
2024-05-25 03:07:38 [INFO]: Epoch 018 - generator training loss: 0.0694, discriminator training loss: 0.0480, validation loss: 0.2080
2024-05-25 03:07:42 [INFO]: Epoch 019 - generator training loss: 0.0679, discriminator training loss: 0.0467, validation loss: 0.2067
2024-05-25 03:07:46 [INFO]: Epoch 020 - generator training loss: 0.0667, discriminator training loss: 0.0455, validation loss: 0.2052
2024-05-25 03:07:50 [INFO]: Epoch 021 - generator training loss: 0.0653, discriminator training loss: 0.0446, validation loss: 0.2045
2024-05-25 03:07:54 [INFO]: Epoch 022 - generator training loss: 0.0631, discriminator training loss: 0.0443, validation loss: 0.2034
2024-05-25 03:07:59 [INFO]: Epoch 023 - generator training loss: 0.0621, discriminator training loss: 0.0432, validation loss: 0.2021
2024-05-25 03:08:03 [INFO]: Epoch 024 - generator training loss: 0.0609, discriminator training loss: 0.0425, validation loss: 0.2006
2024-05-25 03:08:07 [INFO]: Epoch 025 - generator training loss: 0.0607, discriminator training loss: 0.0418, validation loss: 0.1998
2024-05-25 03:08:11 [INFO]: Epoch 026 - generator training loss: 0.0574, discriminator training loss: 0.0416, validation loss: 0.1988
2024-05-25 03:08:15 [INFO]: Epoch 027 - generator training loss: 0.0566, discriminator training loss: 0.0405, validation loss: 0.1986
2024-05-25 03:08:19 [INFO]: Epoch 028 - generator training loss: 0.0557, discriminator training loss: 0.0397, validation loss: 0.1972
2024-05-25 03:08:23 [INFO]: Epoch 029 - generator training loss: 0.0554, discriminator training loss: 0.0389, validation loss: 0.1963
2024-05-25 03:08:27 [INFO]: Epoch 030 - generator training loss: 0.0546, discriminator training loss: 0.0380, validation loss: 0.1957
2024-05-25 03:08:31 [INFO]: Epoch 031 - generator training loss: 0.0540, discriminator training loss: 0.0376, validation loss: 0.1952
2024-05-25 03:08:36 [INFO]: Epoch 032 - generator training loss: 0.0535, discriminator training loss: 0.0367, validation loss: 0.1944
2024-05-25 03:08:40 [INFO]: Epoch 033 - generator training loss: 0.0545, discriminator training loss: 0.0355, validation loss: 0.1934
2024-05-25 03:08:44 [INFO]: Epoch 034 - generator training loss: 0.0532, discriminator training loss: 0.0350, validation loss: 0.1933
2024-05-25 03:08:48 [INFO]: Epoch 035 - generator training loss: 0.0533, discriminator training loss: 0.0341, validation loss: 0.1928
2024-05-25 03:08:52 [INFO]: Epoch 036 - generator training loss: 0.0533, discriminator training loss: 0.0334, validation loss: 0.1915
2024-05-25 03:08:56 [INFO]: Epoch 037 - generator training loss: 0.0541, discriminator training loss: 0.0324, validation loss: 0.1907
2024-05-25 03:09:00 [INFO]: Epoch 038 - generator training loss: 0.0537, discriminator training loss: 0.0318, validation loss: 0.1903
2024-05-25 03:09:04 [INFO]: Epoch 039 - generator training loss: 0.0521, discriminator training loss: 0.0310, validation loss: 0.1891
2024-05-25 03:09:09 [INFO]: Epoch 040 - generator training loss: 0.0528, discriminator training loss: 0.0305, validation loss: 0.1889
2024-05-25 03:09:13 [INFO]: Epoch 041 - generator training loss: 0.0523, discriminator training loss: 0.0298, validation loss: 0.1885
2024-05-25 03:09:17 [INFO]: Epoch 042 - generator training loss: 0.0526, discriminator training loss: 0.0296, validation loss: 0.1884
2024-05-25 03:09:21 [INFO]: Epoch 043 - generator training loss: 0.0521, discriminator training loss: 0.0292, validation loss: 0.1874
2024-05-25 03:09:25 [INFO]: Epoch 044 - generator training loss: 0.0503, discriminator training loss: 0.0286, validation loss: 0.1877
2024-05-25 03:09:29 [INFO]: Epoch 045 - generator training loss: 0.0509, discriminator training loss: 0.0278, validation loss: 0.1860
2024-05-25 03:09:33 [INFO]: Epoch 046 - generator training loss: 0.0505, discriminator training loss: 0.0275, validation loss: 0.1854
2024-05-25 03:09:37 [INFO]: Epoch 047 - generator training loss: 0.0504, discriminator training loss: 0.0269, validation loss: 0.1850
2024-05-25 03:09:41 [INFO]: Epoch 048 - generator training loss: 0.0497, discriminator training loss: 0.0263, validation loss: 0.1850
2024-05-25 03:09:46 [INFO]: Epoch 049 - generator training loss: 0.0493, discriminator training loss: 0.0259, validation loss: 0.1842
2024-05-25 03:09:50 [INFO]: Epoch 050 - generator training loss: 0.0488, discriminator training loss: 0.0257, validation loss: 0.1832
2024-05-25 03:09:54 [INFO]: Epoch 051 - generator training loss: 0.0499, discriminator training loss: 0.0252, validation loss: 0.1837
2024-05-25 03:09:58 [INFO]: Epoch 052 - generator training loss: 0.0487, discriminator training loss: 0.0246, validation loss: 0.1825
2024-05-25 03:10:02 [INFO]: Epoch 053 - generator training loss: 0.0480, discriminator training loss: 0.0243, validation loss: 0.1821
2024-05-25 03:10:06 [INFO]: Epoch 054 - generator training loss: 0.0479, discriminator training loss: 0.0240, validation loss: 0.1819
2024-05-25 03:10:10 [INFO]: Epoch 055 - generator training loss: 0.0476, discriminator training loss: 0.0238, validation loss: 0.1809
2024-05-25 03:10:14 [INFO]: Epoch 056 - generator training loss: 0.0477, discriminator training loss: 0.0233, validation loss: 0.1805
2024-05-25 03:10:18 [INFO]: Epoch 057 - generator training loss: 0.0468, discriminator training loss: 0.0236, validation loss: 0.1808
2024-05-25 03:10:22 [INFO]: Epoch 058 - generator training loss: 0.0469, discriminator training loss: 0.0227, validation loss: 0.1801
2024-05-25 03:10:26 [INFO]: Epoch 059 - generator training loss: 0.0469, discriminator training loss: 0.0222, validation loss: 0.1798
2024-05-25 03:10:31 [INFO]: Epoch 060 - generator training loss: 0.0461, discriminator training loss: 0.0221, validation loss: 0.1793
2024-05-25 03:10:35 [INFO]: Epoch 061 - generator training loss: 0.0465, discriminator training loss: 0.0218, validation loss: 0.1786
2024-05-25 03:10:39 [INFO]: Epoch 062 - generator training loss: 0.0463, discriminator training loss: 0.0213, validation loss: 0.1790
2024-05-25 03:10:43 [INFO]: Epoch 063 - generator training loss: 0.0466, discriminator training loss: 0.0213, validation loss: 0.1793
2024-05-25 03:10:47 [INFO]: Epoch 064 - generator training loss: 0.0459, discriminator training loss: 0.0212, validation loss: 0.1777
2024-05-25 03:10:51 [INFO]: Epoch 065 - generator training loss: 0.0457, discriminator training loss: 0.0209, validation loss: 0.1766
2024-05-25 03:10:55 [INFO]: Epoch 066 - generator training loss: 0.0449, discriminator training loss: 0.0208, validation loss: 0.1766
2024-05-25 03:10:59 [INFO]: Epoch 067 - generator training loss: 0.0463, discriminator training loss: 0.0203, validation loss: 0.1775
2024-05-25 03:11:03 [INFO]: Epoch 068 - generator training loss: 0.0470, discriminator training loss: 0.0203, validation loss: 0.1764
2024-05-25 03:11:07 [INFO]: Epoch 069 - generator training loss: 0.0455, discriminator training loss: 0.0201, validation loss: 0.1753
2024-05-25 03:11:11 [INFO]: Epoch 070 - generator training loss: 0.0445, discriminator training loss: 0.0198, validation loss: 0.1754
2024-05-25 03:11:15 [INFO]: Epoch 071 - generator training loss: 0.0440, discriminator training loss: 0.0195, validation loss: 0.1749
2024-05-25 03:11:20 [INFO]: Epoch 072 - generator training loss: 0.0439, discriminator training loss: 0.0193, validation loss: 0.1748
2024-05-25 03:11:24 [INFO]: Epoch 073 - generator training loss: 0.0433, discriminator training loss: 0.0191, validation loss: 0.1741
2024-05-25 03:11:28 [INFO]: Epoch 074 - generator training loss: 0.0431, discriminator training loss: 0.0190, validation loss: 0.1737
2024-05-25 03:11:32 [INFO]: Epoch 075 - generator training loss: 0.0437, discriminator training loss: 0.0189, validation loss: 0.1735
2024-05-25 03:11:36 [INFO]: Epoch 076 - generator training loss: 0.0424, discriminator training loss: 0.0185, validation loss: 0.1730
2024-05-25 03:11:40 [INFO]: Epoch 077 - generator training loss: 0.0426, discriminator training loss: 0.0184, validation loss: 0.1726
2024-05-25 03:11:44 [INFO]: Epoch 078 - generator training loss: 0.0423, discriminator training loss: 0.0183, validation loss: 0.1728
2024-05-25 03:11:48 [INFO]: Epoch 079 - generator training loss: 0.0424, discriminator training loss: 0.0182, validation loss: 0.1718
2024-05-25 03:11:52 [INFO]: Epoch 080 - generator training loss: 0.0429, discriminator training loss: 0.0180, validation loss: 0.1734
2024-05-25 03:11:56 [INFO]: Epoch 081 - generator training loss: 0.0436, discriminator training loss: 0.0179, validation loss: 0.1716
2024-05-25 03:12:00 [INFO]: Epoch 082 - generator training loss: 0.0440, discriminator training loss: 0.0176, validation loss: 0.1724
2024-05-25 03:12:04 [INFO]: Epoch 083 - generator training loss: 0.0420, discriminator training loss: 0.0177, validation loss: 0.1707
2024-05-25 03:12:08 [INFO]: Epoch 084 - generator training loss: 0.0417, discriminator training loss: 0.0173, validation loss: 0.1706
2024-05-25 03:12:12 [INFO]: Epoch 085 - generator training loss: 0.0416, discriminator training loss: 0.0173, validation loss: 0.1723
2024-05-25 03:12:16 [INFO]: Epoch 086 - generator training loss: 0.0425, discriminator training loss: 0.0172, validation loss: 0.1716
2024-05-25 03:12:21 [INFO]: Epoch 087 - generator training loss: 0.0413, discriminator training loss: 0.0170, validation loss: 0.1709
2024-05-25 03:12:25 [INFO]: Epoch 088 - generator training loss: 0.0412, discriminator training loss: 0.0169, validation loss: 0.1703
2024-05-25 03:12:29 [INFO]: Epoch 089 - generator training loss: 0.0404, discriminator training loss: 0.0169, validation loss: 0.1704
2024-05-25 03:12:33 [INFO]: Epoch 090 - generator training loss: 0.0409, discriminator training loss: 0.0167, validation loss: 0.1701
2024-05-25 03:12:37 [INFO]: Epoch 091 - generator training loss: 0.0406, discriminator training loss: 0.0167, validation loss: 0.1697
2024-05-25 03:12:41 [INFO]: Epoch 092 - generator training loss: 0.0424, discriminator training loss: 0.0165, validation loss: 0.1717
2024-05-25 03:12:45 [INFO]: Epoch 093 - generator training loss: 0.0429, discriminator training loss: 0.0164, validation loss: 0.1700
2024-05-25 03:12:49 [INFO]: Epoch 094 - generator training loss: 0.0413, discriminator training loss: 0.0161, validation loss: 0.1696
2024-05-25 03:12:53 [INFO]: Epoch 095 - generator training loss: 0.0401, discriminator training loss: 0.0161, validation loss: 0.1706
2024-05-25 03:12:57 [INFO]: Epoch 096 - generator training loss: 0.0405, discriminator training loss: 0.0160, validation loss: 0.1696
2024-05-25 03:13:01 [INFO]: Epoch 097 - generator training loss: 0.0390, discriminator training loss: 0.0158, validation loss: 0.1684
2024-05-25 03:13:05 [INFO]: Epoch 098 - generator training loss: 0.0388, discriminator training loss: 0.0157, validation loss: 0.1680
2024-05-25 03:13:09 [INFO]: Epoch 099 - generator training loss: 0.0384, discriminator training loss: 0.0155, validation loss: 0.1685
2024-05-25 03:13:14 [INFO]: Epoch 100 - generator training loss: 0.0390, discriminator training loss: 0.0156, validation loss: 0.1687
2024-05-25 03:13:18 [INFO]: Epoch 101 - generator training loss: 0.0391, discriminator training loss: 0.0154, validation loss: 0.1679
2024-05-25 03:13:22 [INFO]: Epoch 102 - generator training loss: 0.0384, discriminator training loss: 0.0152, validation loss: 0.1680
2024-05-25 03:13:26 [INFO]: Epoch 103 - generator training loss: 0.0383, discriminator training loss: 0.0152, validation loss: 0.1690
2024-05-25 03:13:30 [INFO]: Epoch 104 - generator training loss: 0.0384, discriminator training loss: 0.0153, validation loss: 0.1681
2024-05-25 03:13:34 [INFO]: Epoch 105 - generator training loss: 0.0406, discriminator training loss: 0.0152, validation loss: 0.1678
2024-05-25 03:13:38 [INFO]: Epoch 106 - generator training loss: 0.0397, discriminator training loss: 0.0152, validation loss: 0.1679
2024-05-25 03:13:42 [INFO]: Epoch 107 - generator training loss: 0.0389, discriminator training loss: 0.0151, validation loss: 0.1679
2024-05-25 03:13:46 [INFO]: Epoch 108 - generator training loss: 0.0386, discriminator training loss: 0.0147, validation loss: 0.1686
2024-05-25 03:13:50 [INFO]: Epoch 109 - generator training loss: 0.0377, discriminator training loss: 0.0147, validation loss: 0.1671
2024-05-25 03:13:54 [INFO]: Epoch 110 - generator training loss: 0.0371, discriminator training loss: 0.0150, validation loss: 0.1666
2024-05-25 03:13:58 [INFO]: Epoch 111 - generator training loss: 0.0369, discriminator training loss: 0.0146, validation loss: 0.1673
2024-05-25 03:14:02 [INFO]: Epoch 112 - generator training loss: 0.0366, discriminator training loss: 0.0146, validation loss: 0.1665
2024-05-25 03:14:06 [INFO]: Epoch 113 - generator training loss: 0.0363, discriminator training loss: 0.0144, validation loss: 0.1661
2024-05-25 03:14:10 [INFO]: Epoch 114 - generator training loss: 0.0360, discriminator training loss: 0.0145, validation loss: 0.1665
2024-05-25 03:14:15 [INFO]: Epoch 115 - generator training loss: 0.0365, discriminator training loss: 0.0143, validation loss: 0.1667
2024-05-25 03:14:19 [INFO]: Epoch 116 - generator training loss: 0.0357, discriminator training loss: 0.0142, validation loss: 0.1665
2024-05-25 03:14:23 [INFO]: Epoch 117 - generator training loss: 0.0360, discriminator training loss: 0.0143, validation loss: 0.1671
2024-05-25 03:14:27 [INFO]: Epoch 118 - generator training loss: 0.0367, discriminator training loss: 0.0141, validation loss: 0.1689
2024-05-25 03:14:31 [INFO]: Epoch 119 - generator training loss: 0.0390, discriminator training loss: 0.0143, validation loss: 0.1680
2024-05-25 03:14:35 [INFO]: Epoch 120 - generator training loss: 0.0371, discriminator training loss: 0.0140, validation loss: 0.1675
2024-05-25 03:14:39 [INFO]: Epoch 121 - generator training loss: 0.0365, discriminator training loss: 0.0138, validation loss: 0.1670
2024-05-25 03:14:43 [INFO]: Epoch 122 - generator training loss: 0.0365, discriminator training loss: 0.0138, validation loss: 0.1672
2024-05-25 03:14:47 [INFO]: Epoch 123 - generator training loss: 0.0355, discriminator training loss: 0.0139, validation loss: 0.1671
2024-05-25 03:14:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:14:47 [INFO]: Finished training. The best model is from epoch#113.
2024-05-25 03:14:47 [INFO]: Saved the model to augmentation_saved_results/round_2/USGAN_air_quality/20240525_T030623/USGAN.pypots
2024-05-25 03:14:48 [INFO]: US-GAN on Air-Quality: MAE=0.1606, MSE=0.0975
2024-05-25 03:14:48 [INFO]: Successfully saved to augmentation_saved_results/round_2/USGAN_air_quality/imputation.pkl
2024-05-25 03:14:48 [INFO]: Using the given device: cuda:0
2024-05-25 03:14:48 [INFO]: Model files will be saved to augmentation_saved_results/round_2/BRITS_air_quality/20240525_T031448
2024-05-25 03:14:48 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/BRITS_air_quality/20240525_T031448/tensorboard
2024-05-25 03:14:48 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 03:14:51 [INFO]: Epoch 001 - training loss: 1.3952, validation loss: 0.9542
2024-05-25 03:14:54 [INFO]: Epoch 002 - training loss: 1.1241, validation loss: 0.7249
2024-05-25 03:14:57 [INFO]: Epoch 003 - training loss: 0.9382, validation loss: 0.6150
2024-05-25 03:15:00 [INFO]: Epoch 004 - training loss: 0.8293, validation loss: 0.5493
2024-05-25 03:15:02 [INFO]: Epoch 005 - training loss: 0.7569, validation loss: 0.5031
2024-05-25 03:15:05 [INFO]: Epoch 006 - training loss: 0.7005, validation loss: 0.4657
2024-05-25 03:15:08 [INFO]: Epoch 007 - training loss: 0.6590, validation loss: 0.4362
2024-05-25 03:15:11 [INFO]: Epoch 008 - training loss: 0.6213, validation loss: 0.4130
2024-05-25 03:15:14 [INFO]: Epoch 009 - training loss: 0.5953, validation loss: 0.3923
2024-05-25 03:15:16 [INFO]: Epoch 010 - training loss: 0.5740, validation loss: 0.3765
2024-05-25 03:15:19 [INFO]: Epoch 011 - training loss: 0.5561, validation loss: 0.3637
2024-05-25 03:15:22 [INFO]: Epoch 012 - training loss: 0.5407, validation loss: 0.3526
2024-05-25 03:15:25 [INFO]: Epoch 013 - training loss: 0.5273, validation loss: 0.3430
2024-05-25 03:15:28 [INFO]: Epoch 014 - training loss: 0.5163, validation loss: 0.3350
2024-05-25 03:15:30 [INFO]: Epoch 015 - training loss: 0.5057, validation loss: 0.3273
2024-05-25 03:15:33 [INFO]: Epoch 016 - training loss: 0.4962, validation loss: 0.3204
2024-05-25 03:15:36 [INFO]: Epoch 017 - training loss: 0.4872, validation loss: 0.3153
2024-05-25 03:15:39 [INFO]: Epoch 018 - training loss: 0.4784, validation loss: 0.3096
2024-05-25 03:15:42 [INFO]: Epoch 019 - training loss: 0.4712, validation loss: 0.3045
2024-05-25 03:15:44 [INFO]: Epoch 020 - training loss: 0.4623, validation loss: 0.3001
2024-05-25 03:15:47 [INFO]: Epoch 021 - training loss: 0.4572, validation loss: 0.2958
2024-05-25 03:15:50 [INFO]: Epoch 022 - training loss: 0.4491, validation loss: 0.2911
2024-05-25 03:15:53 [INFO]: Epoch 023 - training loss: 0.4442, validation loss: 0.2877
2024-05-25 03:15:55 [INFO]: Epoch 024 - training loss: 0.4380, validation loss: 0.2841
2024-05-25 03:15:58 [INFO]: Epoch 025 - training loss: 0.4310, validation loss: 0.2806
2024-05-25 03:16:01 [INFO]: Epoch 026 - training loss: 0.4258, validation loss: 0.2770
2024-05-25 03:16:04 [INFO]: Epoch 027 - training loss: 0.4201, validation loss: 0.2741
2024-05-25 03:16:07 [INFO]: Epoch 028 - training loss: 0.4158, validation loss: 0.2704
2024-05-25 03:16:09 [INFO]: Epoch 029 - training loss: 0.4108, validation loss: 0.2676
2024-05-25 03:16:12 [INFO]: Epoch 030 - training loss: 0.4068, validation loss: 0.2647
2024-05-25 03:16:15 [INFO]: Epoch 031 - training loss: 0.4016, validation loss: 0.2615
2024-05-25 03:16:18 [INFO]: Epoch 032 - training loss: 0.3974, validation loss: 0.2589
2024-05-25 03:16:20 [INFO]: Epoch 033 - training loss: 0.3936, validation loss: 0.2560
2024-05-25 03:16:23 [INFO]: Epoch 034 - training loss: 0.3894, validation loss: 0.2533
2024-05-25 03:16:26 [INFO]: Epoch 035 - training loss: 0.3857, validation loss: 0.2502
2024-05-25 03:16:29 [INFO]: Epoch 036 - training loss: 0.3814, validation loss: 0.2479
2024-05-25 03:16:32 [INFO]: Epoch 037 - training loss: 0.3778, validation loss: 0.2453
2024-05-25 03:16:34 [INFO]: Epoch 038 - training loss: 0.3738, validation loss: 0.2425
2024-05-25 03:16:37 [INFO]: Epoch 039 - training loss: 0.3703, validation loss: 0.2406
2024-05-25 03:16:40 [INFO]: Epoch 040 - training loss: 0.3683, validation loss: 0.2380
2024-05-25 03:16:43 [INFO]: Epoch 041 - training loss: 0.3651, validation loss: 0.2356
2024-05-25 03:16:46 [INFO]: Epoch 042 - training loss: 0.3624, validation loss: 0.2334
2024-05-25 03:16:48 [INFO]: Epoch 043 - training loss: 0.3584, validation loss: 0.2312
2024-05-25 03:16:51 [INFO]: Epoch 044 - training loss: 0.3558, validation loss: 0.2296
2024-05-25 03:16:54 [INFO]: Epoch 045 - training loss: 0.3526, validation loss: 0.2276
2024-05-25 03:16:57 [INFO]: Epoch 046 - training loss: 0.3503, validation loss: 0.2260
2024-05-25 03:16:59 [INFO]: Epoch 047 - training loss: 0.3481, validation loss: 0.2244
2024-05-25 03:17:02 [INFO]: Epoch 048 - training loss: 0.3453, validation loss: 0.2229
2024-05-25 03:17:05 [INFO]: Epoch 049 - training loss: 0.3426, validation loss: 0.2216
2024-05-25 03:17:08 [INFO]: Epoch 050 - training loss: 0.3400, validation loss: 0.2202
2024-05-25 03:17:11 [INFO]: Epoch 051 - training loss: 0.3379, validation loss: 0.2191
2024-05-25 03:17:13 [INFO]: Epoch 052 - training loss: 0.3364, validation loss: 0.2183
2024-05-25 03:17:16 [INFO]: Epoch 053 - training loss: 0.3334, validation loss: 0.2171
2024-05-25 03:17:19 [INFO]: Epoch 054 - training loss: 0.3317, validation loss: 0.2159
2024-05-25 03:17:22 [INFO]: Epoch 055 - training loss: 0.3298, validation loss: 0.2152
2024-05-25 03:17:25 [INFO]: Epoch 056 - training loss: 0.3276, validation loss: 0.2142
2024-05-25 03:17:27 [INFO]: Epoch 057 - training loss: 0.3261, validation loss: 0.2134
2024-05-25 03:17:30 [INFO]: Epoch 058 - training loss: 0.3240, validation loss: 0.2129
2024-05-25 03:17:33 [INFO]: Epoch 059 - training loss: 0.3223, validation loss: 0.2123
2024-05-25 03:17:36 [INFO]: Epoch 060 - training loss: 0.3206, validation loss: 0.2118
2024-05-25 03:17:39 [INFO]: Epoch 061 - training loss: 0.3193, validation loss: 0.2112
2024-05-25 03:17:41 [INFO]: Epoch 062 - training loss: 0.3170, validation loss: 0.2105
2024-05-25 03:17:44 [INFO]: Epoch 063 - training loss: 0.3152, validation loss: 0.2102
2024-05-25 03:17:47 [INFO]: Epoch 064 - training loss: 0.3143, validation loss: 0.2098
2024-05-25 03:17:50 [INFO]: Epoch 065 - training loss: 0.3130, validation loss: 0.2094
2024-05-25 03:17:52 [INFO]: Epoch 066 - training loss: 0.3109, validation loss: 0.2089
2024-05-25 03:17:55 [INFO]: Epoch 067 - training loss: 0.3101, validation loss: 0.2086
2024-05-25 03:17:58 [INFO]: Epoch 068 - training loss: 0.3085, validation loss: 0.2079
2024-05-25 03:18:01 [INFO]: Epoch 069 - training loss: 0.3072, validation loss: 0.2078
2024-05-25 03:18:04 [INFO]: Epoch 070 - training loss: 0.3062, validation loss: 0.2075
2024-05-25 03:18:06 [INFO]: Epoch 071 - training loss: 0.3048, validation loss: 0.2069
2024-05-25 03:18:09 [INFO]: Epoch 072 - training loss: 0.3036, validation loss: 0.2065
2024-05-25 03:18:12 [INFO]: Epoch 073 - training loss: 0.3030, validation loss: 0.2064
2024-05-25 03:18:15 [INFO]: Epoch 074 - training loss: 0.3016, validation loss: 0.2056
2024-05-25 03:18:18 [INFO]: Epoch 075 - training loss: 0.3003, validation loss: 0.2057
2024-05-25 03:18:20 [INFO]: Epoch 076 - training loss: 0.2997, validation loss: 0.2051
2024-05-25 03:18:23 [INFO]: Epoch 077 - training loss: 0.2979, validation loss: 0.2047
2024-05-25 03:18:26 [INFO]: Epoch 078 - training loss: 0.2971, validation loss: 0.2048
2024-05-25 03:18:29 [INFO]: Epoch 079 - training loss: 0.2971, validation loss: 0.2044
2024-05-25 03:18:32 [INFO]: Epoch 080 - training loss: 0.2956, validation loss: 0.2037
2024-05-25 03:18:34 [INFO]: Epoch 081 - training loss: 0.2940, validation loss: 0.2035
2024-05-25 03:18:37 [INFO]: Epoch 082 - training loss: 0.2932, validation loss: 0.2033
2024-05-25 03:18:40 [INFO]: Epoch 083 - training loss: 0.2922, validation loss: 0.2027
2024-05-25 03:18:43 [INFO]: Epoch 084 - training loss: 0.2915, validation loss: 0.2026
2024-05-25 03:18:45 [INFO]: Epoch 085 - training loss: 0.2907, validation loss: 0.2025
2024-05-25 03:18:48 [INFO]: Epoch 086 - training loss: 0.2897, validation loss: 0.2020
2024-05-25 03:18:51 [INFO]: Epoch 087 - training loss: 0.2891, validation loss: 0.2018
2024-05-25 03:18:54 [INFO]: Epoch 088 - training loss: 0.2881, validation loss: 0.2017
2024-05-25 03:18:57 [INFO]: Epoch 089 - training loss: 0.2869, validation loss: 0.2012
2024-05-25 03:18:59 [INFO]: Epoch 090 - training loss: 0.2860, validation loss: 0.2009
2024-05-25 03:19:02 [INFO]: Epoch 091 - training loss: 0.2863, validation loss: 0.2004
2024-05-25 03:19:05 [INFO]: Epoch 092 - training loss: 0.2851, validation loss: 0.2001
2024-05-25 03:19:08 [INFO]: Epoch 093 - training loss: 0.2840, validation loss: 0.1995
2024-05-25 03:19:10 [INFO]: Epoch 094 - training loss: 0.2834, validation loss: 0.1993
2024-05-25 03:19:13 [INFO]: Epoch 095 - training loss: 0.2828, validation loss: 0.1989
2024-05-25 03:19:16 [INFO]: Epoch 096 - training loss: 0.2826, validation loss: 0.1985
2024-05-25 03:19:19 [INFO]: Epoch 097 - training loss: 0.2812, validation loss: 0.1980
2024-05-25 03:19:22 [INFO]: Epoch 098 - training loss: 0.2811, validation loss: 0.1976
2024-05-25 03:19:24 [INFO]: Epoch 099 - training loss: 0.2803, validation loss: 0.1974
2024-05-25 03:19:27 [INFO]: Epoch 100 - training loss: 0.2791, validation loss: 0.1967
2024-05-25 03:19:30 [INFO]: Epoch 101 - training loss: 0.2787, validation loss: 0.1965
2024-05-25 03:19:33 [INFO]: Epoch 102 - training loss: 0.2788, validation loss: 0.1960
2024-05-25 03:19:36 [INFO]: Epoch 103 - training loss: 0.2773, validation loss: 0.1956
2024-05-25 03:19:38 [INFO]: Epoch 104 - training loss: 0.2768, validation loss: 0.1951
2024-05-25 03:19:41 [INFO]: Epoch 105 - training loss: 0.2767, validation loss: 0.1946
2024-05-25 03:19:44 [INFO]: Epoch 106 - training loss: 0.2761, validation loss: 0.1942
2024-05-25 03:19:47 [INFO]: Epoch 107 - training loss: 0.2759, validation loss: 0.1940
2024-05-25 03:19:50 [INFO]: Epoch 108 - training loss: 0.2750, validation loss: 0.1934
2024-05-25 03:19:53 [INFO]: Epoch 109 - training loss: 0.2743, validation loss: 0.1929
2024-05-25 03:19:55 [INFO]: Epoch 110 - training loss: 0.2734, validation loss: 0.1925
2024-05-25 03:19:58 [INFO]: Epoch 111 - training loss: 0.2732, validation loss: 0.1920
2024-05-25 03:20:01 [INFO]: Epoch 112 - training loss: 0.2722, validation loss: 0.1918
2024-05-25 03:20:04 [INFO]: Epoch 113 - training loss: 0.2725, validation loss: 0.1912
2024-05-25 03:20:07 [INFO]: Epoch 114 - training loss: 0.2716, validation loss: 0.1909
2024-05-25 03:20:09 [INFO]: Epoch 115 - training loss: 0.2711, validation loss: 0.1904
2024-05-25 03:20:12 [INFO]: Epoch 116 - training loss: 0.2705, validation loss: 0.1903
2024-05-25 03:20:15 [INFO]: Epoch 117 - training loss: 0.2697, validation loss: 0.1897
2024-05-25 03:20:18 [INFO]: Epoch 118 - training loss: 0.2693, validation loss: 0.1892
2024-05-25 03:20:20 [INFO]: Epoch 119 - training loss: 0.2685, validation loss: 0.1891
2024-05-25 03:20:23 [INFO]: Epoch 120 - training loss: 0.2686, validation loss: 0.1885
2024-05-25 03:20:26 [INFO]: Epoch 121 - training loss: 0.2673, validation loss: 0.1882
2024-05-25 03:20:29 [INFO]: Epoch 122 - training loss: 0.2676, validation loss: 0.1878
2024-05-25 03:20:32 [INFO]: Epoch 123 - training loss: 0.2674, validation loss: 0.1876
2024-05-25 03:20:34 [INFO]: Epoch 124 - training loss: 0.2672, validation loss: 0.1870
2024-05-25 03:20:37 [INFO]: Epoch 125 - training loss: 0.2663, validation loss: 0.1867
2024-05-25 03:20:40 [INFO]: Epoch 126 - training loss: 0.2666, validation loss: 0.1862
2024-05-25 03:20:43 [INFO]: Epoch 127 - training loss: 0.2651, validation loss: 0.1858
2024-05-25 03:20:45 [INFO]: Epoch 128 - training loss: 0.2649, validation loss: 0.1855
2024-05-25 03:20:48 [INFO]: Epoch 129 - training loss: 0.2642, validation loss: 0.1853
2024-05-25 03:20:51 [INFO]: Epoch 130 - training loss: 0.2643, validation loss: 0.1848
2024-05-25 03:20:54 [INFO]: Epoch 131 - training loss: 0.2642, validation loss: 0.1848
2024-05-25 03:20:57 [INFO]: Epoch 132 - training loss: 0.2629, validation loss: 0.1840
2024-05-25 03:20:59 [INFO]: Epoch 133 - training loss: 0.2627, validation loss: 0.1837
2024-05-25 03:21:02 [INFO]: Epoch 134 - training loss: 0.2624, validation loss: 0.1836
2024-05-25 03:21:05 [INFO]: Epoch 135 - training loss: 0.2618, validation loss: 0.1830
2024-05-25 03:21:08 [INFO]: Epoch 136 - training loss: 0.2613, validation loss: 0.1829
2024-05-25 03:21:10 [INFO]: Epoch 137 - training loss: 0.2610, validation loss: 0.1826
2024-05-25 03:21:13 [INFO]: Epoch 138 - training loss: 0.2606, validation loss: 0.1822
2024-05-25 03:21:16 [INFO]: Epoch 139 - training loss: 0.2603, validation loss: 0.1818
2024-05-25 03:21:19 [INFO]: Epoch 140 - training loss: 0.2600, validation loss: 0.1816
2024-05-25 03:21:22 [INFO]: Epoch 141 - training loss: 0.2596, validation loss: 0.1814
2024-05-25 03:21:25 [INFO]: Epoch 142 - training loss: 0.2596, validation loss: 0.1811
2024-05-25 03:21:27 [INFO]: Epoch 143 - training loss: 0.2587, validation loss: 0.1807
2024-05-25 03:21:30 [INFO]: Epoch 144 - training loss: 0.2582, validation loss: 0.1804
2024-05-25 03:21:33 [INFO]: Epoch 145 - training loss: 0.2578, validation loss: 0.1801
2024-05-25 03:21:36 [INFO]: Epoch 146 - training loss: 0.2581, validation loss: 0.1798
2024-05-25 03:21:38 [INFO]: Epoch 147 - training loss: 0.2575, validation loss: 0.1794
2024-05-25 03:21:41 [INFO]: Epoch 148 - training loss: 0.2568, validation loss: 0.1791
2024-05-25 03:21:44 [INFO]: Epoch 149 - training loss: 0.2567, validation loss: 0.1789
2024-05-25 03:21:47 [INFO]: Epoch 150 - training loss: 0.2565, validation loss: 0.1786
2024-05-25 03:21:50 [INFO]: Epoch 151 - training loss: 0.2558, validation loss: 0.1782
2024-05-25 03:21:52 [INFO]: Epoch 152 - training loss: 0.2556, validation loss: 0.1780
2024-05-25 03:21:55 [INFO]: Epoch 153 - training loss: 0.2554, validation loss: 0.1779
2024-05-25 03:21:58 [INFO]: Epoch 154 - training loss: 0.2549, validation loss: 0.1777
2024-05-25 03:22:01 [INFO]: Epoch 155 - training loss: 0.2544, validation loss: 0.1774
2024-05-25 03:22:03 [INFO]: Epoch 156 - training loss: 0.2541, validation loss: 0.1770
2024-05-25 03:22:06 [INFO]: Epoch 157 - training loss: 0.2541, validation loss: 0.1767
2024-05-25 03:22:09 [INFO]: Epoch 158 - training loss: 0.2534, validation loss: 0.1764
2024-05-25 03:22:12 [INFO]: Epoch 159 - training loss: 0.2537, validation loss: 0.1762
2024-05-25 03:22:15 [INFO]: Epoch 160 - training loss: 0.2529, validation loss: 0.1759
2024-05-25 03:22:17 [INFO]: Epoch 161 - training loss: 0.2535, validation loss: 0.1758
2024-05-25 03:22:20 [INFO]: Epoch 162 - training loss: 0.2532, validation loss: 0.1754
2024-05-25 03:22:23 [INFO]: Epoch 163 - training loss: 0.2524, validation loss: 0.1751
2024-05-25 03:22:26 [INFO]: Epoch 164 - training loss: 0.2521, validation loss: 0.1750
2024-05-25 03:22:28 [INFO]: Epoch 165 - training loss: 0.2520, validation loss: 0.1747
2024-05-25 03:22:31 [INFO]: Epoch 166 - training loss: 0.2513, validation loss: 0.1746
2024-05-25 03:22:34 [INFO]: Epoch 167 - training loss: 0.2517, validation loss: 0.1741
2024-05-25 03:22:37 [INFO]: Epoch 168 - training loss: 0.2507, validation loss: 0.1740
2024-05-25 03:22:40 [INFO]: Epoch 169 - training loss: 0.2503, validation loss: 0.1739
2024-05-25 03:22:42 [INFO]: Epoch 170 - training loss: 0.2508, validation loss: 0.1736
2024-05-25 03:22:45 [INFO]: Epoch 171 - training loss: 0.2503, validation loss: 0.1731
2024-05-25 03:22:48 [INFO]: Epoch 172 - training loss: 0.2503, validation loss: 0.1729
2024-05-25 03:22:51 [INFO]: Epoch 173 - training loss: 0.2496, validation loss: 0.1728
2024-05-25 03:22:54 [INFO]: Epoch 174 - training loss: 0.2492, validation loss: 0.1725
2024-05-25 03:22:56 [INFO]: Epoch 175 - training loss: 0.2489, validation loss: 0.1724
2024-05-25 03:22:59 [INFO]: Epoch 176 - training loss: 0.2487, validation loss: 0.1721
2024-05-25 03:23:02 [INFO]: Epoch 177 - training loss: 0.2489, validation loss: 0.1719
2024-05-25 03:23:05 [INFO]: Epoch 178 - training loss: 0.2482, validation loss: 0.1716
2024-05-25 03:23:07 [INFO]: Epoch 179 - training loss: 0.2487, validation loss: 0.1715
2024-05-25 03:23:10 [INFO]: Epoch 180 - training loss: 0.2479, validation loss: 0.1715
2024-05-25 03:23:13 [INFO]: Epoch 181 - training loss: 0.2478, validation loss: 0.1711
2024-05-25 03:23:16 [INFO]: Epoch 182 - training loss: 0.2477, validation loss: 0.1708
2024-05-25 03:23:19 [INFO]: Epoch 183 - training loss: 0.2471, validation loss: 0.1707
2024-05-25 03:23:21 [INFO]: Epoch 184 - training loss: 0.2474, validation loss: 0.1705
2024-05-25 03:23:24 [INFO]: Epoch 185 - training loss: 0.2469, validation loss: 0.1702
2024-05-25 03:23:27 [INFO]: Epoch 186 - training loss: 0.2471, validation loss: 0.1701
2024-05-25 03:23:30 [INFO]: Epoch 187 - training loss: 0.2460, validation loss: 0.1698
2024-05-25 03:23:33 [INFO]: Epoch 188 - training loss: 0.2461, validation loss: 0.1696
2024-05-25 03:23:35 [INFO]: Epoch 189 - training loss: 0.2461, validation loss: 0.1697
2024-05-25 03:23:38 [INFO]: Epoch 190 - training loss: 0.2456, validation loss: 0.1694
2024-05-25 03:23:41 [INFO]: Epoch 191 - training loss: 0.2454, validation loss: 0.1692
2024-05-25 03:23:44 [INFO]: Epoch 192 - training loss: 0.2454, validation loss: 0.1690
2024-05-25 03:23:46 [INFO]: Epoch 193 - training loss: 0.2451, validation loss: 0.1688
2024-05-25 03:23:49 [INFO]: Epoch 194 - training loss: 0.2448, validation loss: 0.1686
2024-05-25 03:23:52 [INFO]: Epoch 195 - training loss: 0.2441, validation loss: 0.1684
2024-05-25 03:23:55 [INFO]: Epoch 196 - training loss: 0.2442, validation loss: 0.1683
2024-05-25 03:23:58 [INFO]: Epoch 197 - training loss: 0.2445, validation loss: 0.1681
2024-05-25 03:24:00 [INFO]: Epoch 198 - training loss: 0.2439, validation loss: 0.1680
2024-05-25 03:24:03 [INFO]: Epoch 199 - training loss: 0.2436, validation loss: 0.1678
2024-05-25 03:24:06 [INFO]: Epoch 200 - training loss: 0.2433, validation loss: 0.1677
2024-05-25 03:24:09 [INFO]: Epoch 201 - training loss: 0.2433, validation loss: 0.1673
2024-05-25 03:24:11 [INFO]: Epoch 202 - training loss: 0.2431, validation loss: 0.1671
2024-05-25 03:24:14 [INFO]: Epoch 203 - training loss: 0.2433, validation loss: 0.1671
2024-05-25 03:24:17 [INFO]: Epoch 204 - training loss: 0.2424, validation loss: 0.1668
2024-05-25 03:24:20 [INFO]: Epoch 205 - training loss: 0.2426, validation loss: 0.1668
2024-05-25 03:24:23 [INFO]: Epoch 206 - training loss: 0.2423, validation loss: 0.1667
2024-05-25 03:24:25 [INFO]: Epoch 207 - training loss: 0.2426, validation loss: 0.1663
2024-05-25 03:24:28 [INFO]: Epoch 208 - training loss: 0.2419, validation loss: 0.1662
2024-05-25 03:24:31 [INFO]: Epoch 209 - training loss: 0.2424, validation loss: 0.1662
2024-05-25 03:24:34 [INFO]: Epoch 210 - training loss: 0.2416, validation loss: 0.1659
2024-05-25 03:24:37 [INFO]: Epoch 211 - training loss: 0.2413, validation loss: 0.1658
2024-05-25 03:24:39 [INFO]: Epoch 212 - training loss: 0.2413, validation loss: 0.1657
2024-05-25 03:24:42 [INFO]: Epoch 213 - training loss: 0.2405, validation loss: 0.1654
2024-05-25 03:24:45 [INFO]: Epoch 214 - training loss: 0.2407, validation loss: 0.1654
2024-05-25 03:24:48 [INFO]: Epoch 215 - training loss: 0.2409, validation loss: 0.1651
2024-05-25 03:24:50 [INFO]: Epoch 216 - training loss: 0.2401, validation loss: 0.1652
2024-05-25 03:24:53 [INFO]: Epoch 217 - training loss: 0.2407, validation loss: 0.1650
2024-05-25 03:24:56 [INFO]: Epoch 218 - training loss: 0.2402, validation loss: 0.1650
2024-05-25 03:24:59 [INFO]: Epoch 219 - training loss: 0.2399, validation loss: 0.1647
2024-05-25 03:25:02 [INFO]: Epoch 220 - training loss: 0.2398, validation loss: 0.1644
2024-05-25 03:25:04 [INFO]: Epoch 221 - training loss: 0.2396, validation loss: 0.1644
2024-05-25 03:25:07 [INFO]: Epoch 222 - training loss: 0.2386, validation loss: 0.1643
2024-05-25 03:25:10 [INFO]: Epoch 223 - training loss: 0.2393, validation loss: 0.1642
2024-05-25 03:25:13 [INFO]: Epoch 224 - training loss: 0.2396, validation loss: 0.1640
2024-05-25 03:25:15 [INFO]: Epoch 225 - training loss: 0.2388, validation loss: 0.1638
2024-05-25 03:25:18 [INFO]: Epoch 226 - training loss: 0.2390, validation loss: 0.1635
2024-05-25 03:25:21 [INFO]: Epoch 227 - training loss: 0.2392, validation loss: 0.1638
2024-05-25 03:25:24 [INFO]: Epoch 228 - training loss: 0.2390, validation loss: 0.1635
2024-05-25 03:25:27 [INFO]: Epoch 229 - training loss: 0.2382, validation loss: 0.1634
2024-05-25 03:25:30 [INFO]: Epoch 230 - training loss: 0.2381, validation loss: 0.1632
2024-05-25 03:25:32 [INFO]: Epoch 231 - training loss: 0.2382, validation loss: 0.1630
2024-05-25 03:25:35 [INFO]: Epoch 232 - training loss: 0.2376, validation loss: 0.1630
2024-05-25 03:25:38 [INFO]: Epoch 233 - training loss: 0.2378, validation loss: 0.1629
2024-05-25 03:25:41 [INFO]: Epoch 234 - training loss: 0.2377, validation loss: 0.1625
2024-05-25 03:25:43 [INFO]: Epoch 235 - training loss: 0.2376, validation loss: 0.1627
2024-05-25 03:25:46 [INFO]: Epoch 236 - training loss: 0.2375, validation loss: 0.1624
2024-05-25 03:25:49 [INFO]: Epoch 237 - training loss: 0.2371, validation loss: 0.1623
2024-05-25 03:25:52 [INFO]: Epoch 238 - training loss: 0.2370, validation loss: 0.1621
2024-05-25 03:25:55 [INFO]: Epoch 239 - training loss: 0.2365, validation loss: 0.1621
2024-05-25 03:25:57 [INFO]: Epoch 240 - training loss: 0.2369, validation loss: 0.1619
2024-05-25 03:26:00 [INFO]: Epoch 241 - training loss: 0.2365, validation loss: 0.1620
2024-05-25 03:26:03 [INFO]: Epoch 242 - training loss: 0.2365, validation loss: 0.1618
2024-05-25 03:26:06 [INFO]: Epoch 243 - training loss: 0.2361, validation loss: 0.1617
2024-05-25 03:26:08 [INFO]: Epoch 244 - training loss: 0.2357, validation loss: 0.1616
2024-05-25 03:26:11 [INFO]: Epoch 245 - training loss: 0.2355, validation loss: 0.1614
2024-05-25 03:26:14 [INFO]: Epoch 246 - training loss: 0.2358, validation loss: 0.1613
2024-05-25 03:26:17 [INFO]: Epoch 247 - training loss: 0.2352, validation loss: 0.1612
2024-05-25 03:26:20 [INFO]: Epoch 248 - training loss: 0.2361, validation loss: 0.1612
2024-05-25 03:26:22 [INFO]: Epoch 249 - training loss: 0.2356, validation loss: 0.1610
2024-05-25 03:26:25 [INFO]: Epoch 250 - training loss: 0.2355, validation loss: 0.1611
2024-05-25 03:26:28 [INFO]: Epoch 251 - training loss: 0.2349, validation loss: 0.1609
2024-05-25 03:26:31 [INFO]: Epoch 252 - training loss: 0.2346, validation loss: 0.1609
2024-05-25 03:26:33 [INFO]: Epoch 253 - training loss: 0.2345, validation loss: 0.1606
2024-05-25 03:26:36 [INFO]: Epoch 254 - training loss: 0.2345, validation loss: 0.1605
2024-05-25 03:26:39 [INFO]: Epoch 255 - training loss: 0.2342, validation loss: 0.1604
2024-05-25 03:26:42 [INFO]: Epoch 256 - training loss: 0.2343, validation loss: 0.1603
2024-05-25 03:26:45 [INFO]: Epoch 257 - training loss: 0.2339, validation loss: 0.1603
2024-05-25 03:26:47 [INFO]: Epoch 258 - training loss: 0.2337, validation loss: 0.1602
2024-05-25 03:26:50 [INFO]: Epoch 259 - training loss: 0.2343, validation loss: 0.1600
2024-05-25 03:26:53 [INFO]: Epoch 260 - training loss: 0.2339, validation loss: 0.1602
2024-05-25 03:26:56 [INFO]: Epoch 261 - training loss: 0.2335, validation loss: 0.1599
2024-05-25 03:26:59 [INFO]: Epoch 262 - training loss: 0.2334, validation loss: 0.1599
2024-05-25 03:27:01 [INFO]: Epoch 263 - training loss: 0.2333, validation loss: 0.1597
2024-05-25 03:27:04 [INFO]: Epoch 264 - training loss: 0.2332, validation loss: 0.1596
2024-05-25 03:27:07 [INFO]: Epoch 265 - training loss: 0.2332, validation loss: 0.1596
2024-05-25 03:27:10 [INFO]: Epoch 266 - training loss: 0.2330, validation loss: 0.1595
2024-05-25 03:27:12 [INFO]: Epoch 267 - training loss: 0.2328, validation loss: 0.1595
2024-05-25 03:27:15 [INFO]: Epoch 268 - training loss: 0.2328, validation loss: 0.1595
2024-05-25 03:27:18 [INFO]: Epoch 269 - training loss: 0.2329, validation loss: 0.1592
2024-05-25 03:27:21 [INFO]: Epoch 270 - training loss: 0.2321, validation loss: 0.1592
2024-05-25 03:27:24 [INFO]: Epoch 271 - training loss: 0.2322, validation loss: 0.1589
2024-05-25 03:27:26 [INFO]: Epoch 272 - training loss: 0.2320, validation loss: 0.1588
2024-05-25 03:27:29 [INFO]: Epoch 273 - training loss: 0.2326, validation loss: 0.1590
2024-05-25 03:27:32 [INFO]: Epoch 274 - training loss: 0.2323, validation loss: 0.1589
2024-05-25 03:27:35 [INFO]: Epoch 275 - training loss: 0.2318, validation loss: 0.1587
2024-05-25 03:27:38 [INFO]: Epoch 276 - training loss: 0.2316, validation loss: 0.1587
2024-05-25 03:27:40 [INFO]: Epoch 277 - training loss: 0.2317, validation loss: 0.1586
2024-05-25 03:27:43 [INFO]: Epoch 278 - training loss: 0.2313, validation loss: 0.1584
2024-05-25 03:27:46 [INFO]: Epoch 279 - training loss: 0.2316, validation loss: 0.1584
2024-05-25 03:27:49 [INFO]: Epoch 280 - training loss: 0.2315, validation loss: 0.1585
2024-05-25 03:27:51 [INFO]: Epoch 281 - training loss: 0.2310, validation loss: 0.1583
2024-05-25 03:27:54 [INFO]: Epoch 282 - training loss: 0.2310, validation loss: 0.1583
2024-05-25 03:27:57 [INFO]: Epoch 283 - training loss: 0.2310, validation loss: 0.1581
2024-05-25 03:28:00 [INFO]: Epoch 284 - training loss: 0.2308, validation loss: 0.1581
2024-05-25 03:28:03 [INFO]: Epoch 285 - training loss: 0.2308, validation loss: 0.1582
2024-05-25 03:28:05 [INFO]: Epoch 286 - training loss: 0.2306, validation loss: 0.1579
2024-05-25 03:28:08 [INFO]: Epoch 287 - training loss: 0.2305, validation loss: 0.1578
2024-05-25 03:28:11 [INFO]: Epoch 288 - training loss: 0.2310, validation loss: 0.1578
2024-05-25 03:28:14 [INFO]: Epoch 289 - training loss: 0.2308, validation loss: 0.1576
2024-05-25 03:28:17 [INFO]: Epoch 290 - training loss: 0.2301, validation loss: 0.1578
2024-05-25 03:28:19 [INFO]: Epoch 291 - training loss: 0.2299, validation loss: 0.1577
2024-05-25 03:28:22 [INFO]: Epoch 292 - training loss: 0.2301, validation loss: 0.1575
2024-05-25 03:28:25 [INFO]: Epoch 293 - training loss: 0.2302, validation loss: 0.1574
2024-05-25 03:28:28 [INFO]: Epoch 294 - training loss: 0.2300, validation loss: 0.1575
2024-05-25 03:28:30 [INFO]: Epoch 295 - training loss: 0.2301, validation loss: 0.1575
2024-05-25 03:28:33 [INFO]: Epoch 296 - training loss: 0.2301, validation loss: 0.1572
2024-05-25 03:28:36 [INFO]: Epoch 297 - training loss: 0.2295, validation loss: 0.1571
2024-05-25 03:28:39 [INFO]: Epoch 298 - training loss: 0.2298, validation loss: 0.1572
2024-05-25 03:28:42 [INFO]: Epoch 299 - training loss: 0.2293, validation loss: 0.1570
2024-05-25 03:28:44 [INFO]: Epoch 300 - training loss: 0.2294, validation loss: 0.1570
2024-05-25 03:28:44 [INFO]: Finished training. The best model is from epoch#299.
2024-05-25 03:28:44 [INFO]: Saved the model to augmentation_saved_results/round_2/BRITS_air_quality/20240525_T031448/BRITS.pypots
2024-05-25 03:28:45 [INFO]: BRITS on Air-Quality: MAE=0.1379, MSE=0.0900
2024-05-25 03:28:45 [INFO]: Successfully saved to augmentation_saved_results/round_2/BRITS_air_quality/imputation.pkl
2024-05-25 03:28:45 [INFO]: Using the given device: cuda:0
2024-05-25 03:28:45 [INFO]: Model files will be saved to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845
2024-05-25 03:28:45 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/tensorboard
2024-05-25 03:28:45 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 03:28:50 [INFO]: Epoch 001 - training loss: 1.4720, validation loss: 0.8341
2024-05-25 03:28:50 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch1_loss0.8340757817029953.pypots
2024-05-25 03:28:54 [INFO]: Epoch 002 - training loss: 1.0706, validation loss: 0.7721
2024-05-25 03:28:54 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch2_loss0.7720682621002197.pypots
2024-05-25 03:28:57 [INFO]: Epoch 003 - training loss: 0.9905, validation loss: 0.7520
2024-05-25 03:28:57 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch3_loss0.7519895017147065.pypots
2024-05-25 03:29:01 [INFO]: Epoch 004 - training loss: 0.9536, validation loss: 0.7393
2024-05-25 03:29:01 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch4_loss0.7392909854650498.pypots
2024-05-25 03:29:05 [INFO]: Epoch 005 - training loss: 0.9788, validation loss: 0.7313
2024-05-25 03:29:05 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch5_loss0.7312853276729584.pypots
2024-05-25 03:29:09 [INFO]: Epoch 006 - training loss: 0.9751, validation loss: 0.7254
2024-05-25 03:29:09 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch6_loss0.7253687620162964.pypots
2024-05-25 03:29:13 [INFO]: Epoch 007 - training loss: 0.9321, validation loss: 0.7207
2024-05-25 03:29:13 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch7_loss0.7206613272428513.pypots
2024-05-25 03:29:17 [INFO]: Epoch 008 - training loss: 0.9344, validation loss: 0.7178
2024-05-25 03:29:17 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch8_loss0.7177598297595977.pypots
2024-05-25 03:29:21 [INFO]: Epoch 009 - training loss: 0.9282, validation loss: 0.7151
2024-05-25 03:29:21 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch9_loss0.7151479899883271.pypots
2024-05-25 03:29:24 [INFO]: Epoch 010 - training loss: 0.9158, validation loss: 0.7127
2024-05-25 03:29:24 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch10_loss0.7127467513084411.pypots
2024-05-25 03:29:28 [INFO]: Epoch 011 - training loss: 0.9329, validation loss: 0.7103
2024-05-25 03:29:28 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch11_loss0.7103249669075012.pypots
2024-05-25 03:29:32 [INFO]: Epoch 012 - training loss: 0.9182, validation loss: 0.7097
2024-05-25 03:29:32 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch12_loss0.7096808403730392.pypots
2024-05-25 03:29:36 [INFO]: Epoch 013 - training loss: 0.9134, validation loss: 0.7094
2024-05-25 03:29:36 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch13_loss0.7093802779912949.pypots
2024-05-25 03:29:40 [INFO]: Epoch 014 - training loss: 0.9095, validation loss: 0.7068
2024-05-25 03:29:40 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch14_loss0.706764143705368.pypots
2024-05-25 03:29:44 [INFO]: Epoch 015 - training loss: 0.9076, validation loss: 0.7076
2024-05-25 03:29:44 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch15_loss0.7075811624526978.pypots
2024-05-25 03:29:48 [INFO]: Epoch 016 - training loss: 0.9090, validation loss: 0.7071
2024-05-25 03:29:48 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch16_loss0.7071348309516907.pypots
2024-05-25 03:29:52 [INFO]: Epoch 017 - training loss: 0.8931, validation loss: 0.7078
2024-05-25 03:29:52 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch17_loss0.707759615778923.pypots
2024-05-25 03:29:55 [INFO]: Epoch 018 - training loss: 0.9048, validation loss: 0.7069
2024-05-25 03:29:55 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch18_loss0.7069439858198165.pypots
2024-05-25 03:29:59 [INFO]: Epoch 019 - training loss: 0.8879, validation loss: 0.7088
2024-05-25 03:29:59 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch19_loss0.7087818861007691.pypots
2024-05-25 03:30:03 [INFO]: Epoch 020 - training loss: 0.8773, validation loss: 0.7071
2024-05-25 03:30:03 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch20_loss0.7070924341678619.pypots
2024-05-25 03:30:07 [INFO]: Epoch 021 - training loss: 0.8822, validation loss: 0.7060
2024-05-25 03:30:07 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch21_loss0.7059506237506866.pypots
2024-05-25 03:30:11 [INFO]: Epoch 022 - training loss: 0.8845, validation loss: 0.7072
2024-05-25 03:30:11 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch22_loss0.707239431142807.pypots
2024-05-25 03:30:15 [INFO]: Epoch 023 - training loss: 0.8758, validation loss: 0.7078
2024-05-25 03:30:15 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch23_loss0.7077597260475159.pypots
2024-05-25 03:30:19 [INFO]: Epoch 024 - training loss: 0.8810, validation loss: 0.7088
2024-05-25 03:30:19 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch24_loss0.7088460415601731.pypots
2024-05-25 03:30:23 [INFO]: Epoch 025 - training loss: 0.8970, validation loss: 0.7102
2024-05-25 03:30:23 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch25_loss0.7101926028728485.pypots
2024-05-25 03:30:26 [INFO]: Epoch 026 - training loss: 0.8843, validation loss: 0.7078
2024-05-25 03:30:26 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch26_loss0.7078103661537171.pypots
2024-05-25 03:30:30 [INFO]: Epoch 027 - training loss: 0.8952, validation loss: 0.7069
2024-05-25 03:30:30 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch27_loss0.7069276541471481.pypots
2024-05-25 03:30:34 [INFO]: Epoch 028 - training loss: 0.8799, validation loss: 0.7097
2024-05-25 03:30:34 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch28_loss0.7097437113523484.pypots
2024-05-25 03:30:38 [INFO]: Epoch 029 - training loss: 0.8578, validation loss: 0.7129
2024-05-25 03:30:38 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch29_loss0.7129322677850723.pypots
2024-05-25 03:30:42 [INFO]: Epoch 030 - training loss: 0.8560, validation loss: 0.7101
2024-05-25 03:30:42 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch30_loss0.7101328581571579.pypots
2024-05-25 03:30:46 [INFO]: Epoch 031 - training loss: 0.8759, validation loss: 0.7105
2024-05-25 03:30:46 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN_epoch31_loss0.7105349600315094.pypots
2024-05-25 03:30:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:30:46 [INFO]: Finished training. The best model is from epoch#21.
2024-05-25 03:30:46 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T032845/MRNN.pypots
2024-05-25 03:30:46 [INFO]: MRNN on Air-Quality: MAE=0.5244, MSE=0.6036
2024-05-25 03:30:46 [INFO]: Successfully saved to augmentation_saved_results/round_2/MRNN_air_quality/imputation.pkl
2024-05-25 03:30:46 [INFO]: Using the given device: cpu
2024-05-25 03:30:46 [INFO]: LOCF on Air-Quality: MAE=0.2006, MSE=0.1979
2024-05-25 03:30:46 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_air_quality".
2024-05-25 03:30:46 [INFO]: Successfully saved to augmentation_saved_results/round_2/LOCF_air_quality/imputation.pkl
2024-05-25 03:30:46 [INFO]: Median on Air-Quality: MAE=0.6700, MSE=1.0040
2024-05-25 03:30:46 [INFO]: Successfully created the given path "saved_results/round_2/Median_air_quality".
2024-05-25 03:30:46 [INFO]: Successfully saved to augmentation_saved_results/round_2/Median_air_quality/imputation.pkl
2024-05-25 03:30:47 [INFO]: Mean on Air-Quality: MAE=0.6975, MSE=0.9352
2024-05-25 03:30:47 [INFO]: Successfully created the given path "saved_results/round_2/Mean_air_quality".
2024-05-25 03:30:47 [INFO]: Successfully saved to augmentation_saved_results/round_2/Mean_air_quality/imputation.pkl
2024-05-25 03:30:47 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-25 03:30:47 [INFO]: Using the given device: cuda:0
2024-05-25 03:30:47 [INFO]: Model files will be saved to augmentation_saved_results/round_3/SAITS_air_quality/20240525_T033047
2024-05-25 03:30:47 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/SAITS_air_quality/20240525_T033047/tensorboard
2024-05-25 03:30:47 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 03:30:47 [INFO]: Epoch 001 - training loss: 1.0581, validation loss: 0.5534
2024-05-25 03:30:48 [INFO]: Epoch 002 - training loss: 0.7659, validation loss: 0.4339
2024-05-25 03:30:49 [INFO]: Epoch 003 - training loss: 0.6562, validation loss: 0.3551
2024-05-25 03:30:49 [INFO]: Epoch 004 - training loss: 0.5811, validation loss: 0.3193
2024-05-25 03:30:50 [INFO]: Epoch 005 - training loss: 0.5251, validation loss: 0.2956
2024-05-25 03:30:51 [INFO]: Epoch 006 - training loss: 0.4870, validation loss: 0.2828
2024-05-25 03:30:51 [INFO]: Epoch 007 - training loss: 0.4609, validation loss: 0.2733
2024-05-25 03:30:52 [INFO]: Epoch 008 - training loss: 0.4427, validation loss: 0.2662
2024-05-25 03:30:53 [INFO]: Epoch 009 - training loss: 0.4277, validation loss: 0.2600
2024-05-25 03:30:53 [INFO]: Epoch 010 - training loss: 0.4169, validation loss: 0.2551
2024-05-25 03:30:54 [INFO]: Epoch 011 - training loss: 0.4063, validation loss: 0.2505
2024-05-25 03:30:55 [INFO]: Epoch 012 - training loss: 0.3972, validation loss: 0.2464
2024-05-25 03:30:56 [INFO]: Epoch 013 - training loss: 0.3888, validation loss: 0.2437
2024-05-25 03:30:56 [INFO]: Epoch 014 - training loss: 0.3837, validation loss: 0.2405
2024-05-25 03:30:57 [INFO]: Epoch 015 - training loss: 0.3769, validation loss: 0.2410
2024-05-25 03:30:58 [INFO]: Epoch 016 - training loss: 0.3714, validation loss: 0.2365
2024-05-25 03:30:58 [INFO]: Epoch 017 - training loss: 0.3659, validation loss: 0.2339
2024-05-25 03:30:59 [INFO]: Epoch 018 - training loss: 0.3608, validation loss: 0.2322
2024-05-25 03:31:00 [INFO]: Epoch 019 - training loss: 0.3571, validation loss: 0.2295
2024-05-25 03:31:00 [INFO]: Epoch 020 - training loss: 0.3527, validation loss: 0.2282
2024-05-25 03:31:01 [INFO]: Epoch 021 - training loss: 0.3471, validation loss: 0.2262
2024-05-25 03:31:02 [INFO]: Epoch 022 - training loss: 0.3453, validation loss: 0.2242
2024-05-25 03:31:02 [INFO]: Epoch 023 - training loss: 0.3424, validation loss: 0.2240
2024-05-25 03:31:03 [INFO]: Epoch 024 - training loss: 0.3394, validation loss: 0.2215
2024-05-25 03:31:04 [INFO]: Epoch 025 - training loss: 0.3368, validation loss: 0.2196
2024-05-25 03:31:04 [INFO]: Epoch 026 - training loss: 0.3322, validation loss: 0.2177
2024-05-25 03:31:05 [INFO]: Epoch 027 - training loss: 0.3302, validation loss: 0.2166
2024-05-25 03:31:06 [INFO]: Epoch 028 - training loss: 0.3279, validation loss: 0.2145
2024-05-25 03:31:06 [INFO]: Epoch 029 - training loss: 0.3269, validation loss: 0.2133
2024-05-25 03:31:07 [INFO]: Epoch 030 - training loss: 0.3236, validation loss: 0.2107
2024-05-25 03:31:08 [INFO]: Epoch 031 - training loss: 0.3215, validation loss: 0.2096
2024-05-25 03:31:08 [INFO]: Epoch 032 - training loss: 0.3223, validation loss: 0.2096
2024-05-25 03:31:09 [INFO]: Epoch 033 - training loss: 0.3180, validation loss: 0.2073
2024-05-25 03:31:10 [INFO]: Epoch 034 - training loss: 0.3156, validation loss: 0.2066
2024-05-25 03:31:10 [INFO]: Epoch 035 - training loss: 0.3136, validation loss: 0.2052
2024-05-25 03:31:11 [INFO]: Epoch 036 - training loss: 0.3132, validation loss: 0.2040
2024-05-25 03:31:12 [INFO]: Epoch 037 - training loss: 0.3111, validation loss: 0.2013
2024-05-25 03:31:12 [INFO]: Epoch 038 - training loss: 0.3082, validation loss: 0.2010
2024-05-25 03:31:13 [INFO]: Epoch 039 - training loss: 0.3080, validation loss: 0.1993
2024-05-25 03:31:14 [INFO]: Epoch 040 - training loss: 0.3068, validation loss: 0.1990
2024-05-25 03:31:14 [INFO]: Epoch 041 - training loss: 0.3042, validation loss: 0.1980
2024-05-25 03:31:15 [INFO]: Epoch 042 - training loss: 0.3023, validation loss: 0.1970
2024-05-25 03:31:16 [INFO]: Epoch 043 - training loss: 0.3011, validation loss: 0.1964
2024-05-25 03:31:16 [INFO]: Epoch 044 - training loss: 0.2989, validation loss: 0.1948
2024-05-25 03:31:17 [INFO]: Epoch 045 - training loss: 0.2970, validation loss: 0.1944
2024-05-25 03:31:18 [INFO]: Epoch 046 - training loss: 0.2965, validation loss: 0.1940
2024-05-25 03:31:18 [INFO]: Epoch 047 - training loss: 0.2948, validation loss: 0.1926
2024-05-25 03:31:19 [INFO]: Epoch 048 - training loss: 0.2932, validation loss: 0.1919
2024-05-25 03:31:20 [INFO]: Epoch 049 - training loss: 0.2919, validation loss: 0.1910
2024-05-25 03:31:20 [INFO]: Epoch 050 - training loss: 0.2913, validation loss: 0.1906
2024-05-25 03:31:21 [INFO]: Epoch 051 - training loss: 0.2896, validation loss: 0.1910
2024-05-25 03:31:22 [INFO]: Epoch 052 - training loss: 0.2874, validation loss: 0.1894
2024-05-25 03:31:22 [INFO]: Epoch 053 - training loss: 0.2869, validation loss: 0.1898
2024-05-25 03:31:23 [INFO]: Epoch 054 - training loss: 0.2864, validation loss: 0.1890
2024-05-25 03:31:24 [INFO]: Epoch 055 - training loss: 0.2857, validation loss: 0.1889
2024-05-25 03:31:24 [INFO]: Epoch 056 - training loss: 0.2834, validation loss: 0.1874
2024-05-25 03:31:25 [INFO]: Epoch 057 - training loss: 0.2809, validation loss: 0.1870
2024-05-25 03:31:26 [INFO]: Epoch 058 - training loss: 0.2803, validation loss: 0.1875
2024-05-25 03:31:26 [INFO]: Epoch 059 - training loss: 0.2798, validation loss: 0.1867
2024-05-25 03:31:27 [INFO]: Epoch 060 - training loss: 0.2790, validation loss: 0.1865
2024-05-25 03:31:28 [INFO]: Epoch 061 - training loss: 0.2776, validation loss: 0.1862
2024-05-25 03:31:28 [INFO]: Epoch 062 - training loss: 0.2767, validation loss: 0.1854
2024-05-25 03:31:29 [INFO]: Epoch 063 - training loss: 0.2773, validation loss: 0.1856
2024-05-25 03:31:30 [INFO]: Epoch 064 - training loss: 0.2752, validation loss: 0.1858
2024-05-25 03:31:30 [INFO]: Epoch 065 - training loss: 0.2743, validation loss: 0.1841
2024-05-25 03:31:31 [INFO]: Epoch 066 - training loss: 0.2718, validation loss: 0.1844
2024-05-25 03:31:32 [INFO]: Epoch 067 - training loss: 0.2700, validation loss: 0.1840
2024-05-25 03:31:32 [INFO]: Epoch 068 - training loss: 0.2696, validation loss: 0.1830
2024-05-25 03:31:33 [INFO]: Epoch 069 - training loss: 0.2690, validation loss: 0.1822
2024-05-25 03:31:34 [INFO]: Epoch 070 - training loss: 0.2688, validation loss: 0.1824
2024-05-25 03:31:34 [INFO]: Epoch 071 - training loss: 0.2663, validation loss: 0.1825
2024-05-25 03:31:35 [INFO]: Epoch 072 - training loss: 0.2647, validation loss: 0.1825
2024-05-25 03:31:36 [INFO]: Epoch 073 - training loss: 0.2648, validation loss: 0.1814
2024-05-25 03:31:36 [INFO]: Epoch 074 - training loss: 0.2642, validation loss: 0.1815
2024-05-25 03:31:37 [INFO]: Epoch 075 - training loss: 0.2643, validation loss: 0.1807
2024-05-25 03:31:38 [INFO]: Epoch 076 - training loss: 0.2632, validation loss: 0.1812
2024-05-25 03:31:38 [INFO]: Epoch 077 - training loss: 0.2623, validation loss: 0.1799
2024-05-25 03:31:39 [INFO]: Epoch 078 - training loss: 0.2622, validation loss: 0.1797
2024-05-25 03:31:40 [INFO]: Epoch 079 - training loss: 0.2613, validation loss: 0.1796
2024-05-25 03:31:40 [INFO]: Epoch 080 - training loss: 0.2599, validation loss: 0.1786
2024-05-25 03:31:41 [INFO]: Epoch 081 - training loss: 0.2586, validation loss: 0.1795
2024-05-25 03:31:42 [INFO]: Epoch 082 - training loss: 0.2578, validation loss: 0.1786
2024-05-25 03:31:43 [INFO]: Epoch 083 - training loss: 0.2577, validation loss: 0.1779
2024-05-25 03:31:43 [INFO]: Epoch 084 - training loss: 0.2559, validation loss: 0.1783
2024-05-25 03:31:44 [INFO]: Epoch 085 - training loss: 0.2556, validation loss: 0.1775
2024-05-25 03:31:45 [INFO]: Epoch 086 - training loss: 0.2547, validation loss: 0.1780
2024-05-25 03:31:45 [INFO]: Epoch 087 - training loss: 0.2541, validation loss: 0.1774
2024-05-25 03:31:46 [INFO]: Epoch 088 - training loss: 0.2544, validation loss: 0.1776
2024-05-25 03:31:47 [INFO]: Epoch 089 - training loss: 0.2524, validation loss: 0.1775
2024-05-25 03:31:47 [INFO]: Epoch 090 - training loss: 0.2514, validation loss: 0.1768
2024-05-25 03:31:48 [INFO]: Epoch 091 - training loss: 0.2517, validation loss: 0.1760
2024-05-25 03:31:49 [INFO]: Epoch 092 - training loss: 0.2498, validation loss: 0.1751
2024-05-25 03:31:49 [INFO]: Epoch 093 - training loss: 0.2496, validation loss: 0.1746
2024-05-25 03:31:50 [INFO]: Epoch 094 - training loss: 0.2490, validation loss: 0.1745
2024-05-25 03:31:51 [INFO]: Epoch 095 - training loss: 0.2486, validation loss: 0.1732
2024-05-25 03:31:51 [INFO]: Epoch 096 - training loss: 0.2481, validation loss: 0.1743
2024-05-25 03:31:52 [INFO]: Epoch 097 - training loss: 0.2492, validation loss: 0.1741
2024-05-25 03:31:53 [INFO]: Epoch 098 - training loss: 0.2497, validation loss: 0.1735
2024-05-25 03:31:53 [INFO]: Epoch 099 - training loss: 0.2462, validation loss: 0.1738
2024-05-25 03:31:54 [INFO]: Epoch 100 - training loss: 0.2448, validation loss: 0.1728
2024-05-25 03:31:55 [INFO]: Epoch 101 - training loss: 0.2454, validation loss: 0.1732
2024-05-25 03:31:55 [INFO]: Epoch 102 - training loss: 0.2443, validation loss: 0.1721
2024-05-25 03:31:56 [INFO]: Epoch 103 - training loss: 0.2437, validation loss: 0.1718
2024-05-25 03:31:57 [INFO]: Epoch 104 - training loss: 0.2432, validation loss: 0.1715
2024-05-25 03:31:57 [INFO]: Epoch 105 - training loss: 0.2429, validation loss: 0.1715
2024-05-25 03:31:58 [INFO]: Epoch 106 - training loss: 0.2430, validation loss: 0.1705
2024-05-25 03:31:59 [INFO]: Epoch 107 - training loss: 0.2430, validation loss: 0.1706
2024-05-25 03:31:59 [INFO]: Epoch 108 - training loss: 0.2458, validation loss: 0.1711
2024-05-25 03:32:00 [INFO]: Epoch 109 - training loss: 0.2415, validation loss: 0.1703
2024-05-25 03:32:01 [INFO]: Epoch 110 - training loss: 0.2437, validation loss: 0.1707
2024-05-25 03:32:01 [INFO]: Epoch 111 - training loss: 0.2404, validation loss: 0.1705
2024-05-25 03:32:02 [INFO]: Epoch 112 - training loss: 0.2382, validation loss: 0.1700
2024-05-25 03:32:03 [INFO]: Epoch 113 - training loss: 0.2407, validation loss: 0.1690
2024-05-25 03:32:03 [INFO]: Epoch 114 - training loss: 0.2383, validation loss: 0.1686
2024-05-25 03:32:04 [INFO]: Epoch 115 - training loss: 0.2384, validation loss: 0.1691
2024-05-25 03:32:05 [INFO]: Epoch 116 - training loss: 0.2383, validation loss: 0.1679
2024-05-25 03:32:05 [INFO]: Epoch 117 - training loss: 0.2398, validation loss: 0.1684
2024-05-25 03:32:06 [INFO]: Epoch 118 - training loss: 0.2380, validation loss: 0.1674
2024-05-25 03:32:07 [INFO]: Epoch 119 - training loss: 0.2366, validation loss: 0.1672
2024-05-25 03:32:07 [INFO]: Epoch 120 - training loss: 0.2358, validation loss: 0.1675
2024-05-25 03:32:08 [INFO]: Epoch 121 - training loss: 0.2358, validation loss: 0.1670
2024-05-25 03:32:09 [INFO]: Epoch 122 - training loss: 0.2340, validation loss: 0.1676
2024-05-25 03:32:09 [INFO]: Epoch 123 - training loss: 0.2345, validation loss: 0.1671
2024-05-25 03:32:10 [INFO]: Epoch 124 - training loss: 0.2336, validation loss: 0.1672
2024-05-25 03:32:11 [INFO]: Epoch 125 - training loss: 0.2339, validation loss: 0.1674
2024-05-25 03:32:11 [INFO]: Epoch 126 - training loss: 0.2329, validation loss: 0.1674
2024-05-25 03:32:12 [INFO]: Epoch 127 - training loss: 0.2338, validation loss: 0.1670
2024-05-25 03:32:13 [INFO]: Epoch 128 - training loss: 0.2339, validation loss: 0.1675
2024-05-25 03:32:13 [INFO]: Epoch 129 - training loss: 0.2318, validation loss: 0.1670
2024-05-25 03:32:14 [INFO]: Epoch 130 - training loss: 0.2305, validation loss: 0.1664
2024-05-25 03:32:15 [INFO]: Epoch 131 - training loss: 0.2310, validation loss: 0.1665
2024-05-25 03:32:15 [INFO]: Epoch 132 - training loss: 0.2303, validation loss: 0.1662
2024-05-25 03:32:16 [INFO]: Epoch 133 - training loss: 0.2295, validation loss: 0.1659
2024-05-25 03:32:17 [INFO]: Epoch 134 - training loss: 0.2306, validation loss: 0.1655
2024-05-25 03:32:17 [INFO]: Epoch 135 - training loss: 0.2296, validation loss: 0.1658
2024-05-25 03:32:18 [INFO]: Epoch 136 - training loss: 0.2286, validation loss: 0.1660
2024-05-25 03:32:19 [INFO]: Epoch 137 - training loss: 0.2277, validation loss: 0.1663
2024-05-25 03:32:19 [INFO]: Epoch 138 - training loss: 0.2286, validation loss: 0.1661
2024-05-25 03:32:20 [INFO]: Epoch 139 - training loss: 0.2281, validation loss: 0.1658
2024-05-25 03:32:21 [INFO]: Epoch 140 - training loss: 0.2268, validation loss: 0.1670
2024-05-25 03:32:21 [INFO]: Epoch 141 - training loss: 0.2287, validation loss: 0.1658
2024-05-25 03:32:22 [INFO]: Epoch 142 - training loss: 0.2293, validation loss: 0.1658
2024-05-25 03:32:23 [INFO]: Epoch 143 - training loss: 0.2273, validation loss: 0.1650
2024-05-25 03:32:23 [INFO]: Epoch 144 - training loss: 0.2264, validation loss: 0.1648
2024-05-25 03:32:24 [INFO]: Epoch 145 - training loss: 0.2261, validation loss: 0.1656
2024-05-25 03:32:25 [INFO]: Epoch 146 - training loss: 0.2251, validation loss: 0.1654
2024-05-25 03:32:25 [INFO]: Epoch 147 - training loss: 0.2251, validation loss: 0.1655
2024-05-25 03:32:26 [INFO]: Epoch 148 - training loss: 0.2252, validation loss: 0.1643
2024-05-25 03:32:27 [INFO]: Epoch 149 - training loss: 0.2239, validation loss: 0.1646
2024-05-25 03:32:27 [INFO]: Epoch 150 - training loss: 0.2239, validation loss: 0.1632
2024-05-25 03:32:28 [INFO]: Epoch 151 - training loss: 0.2231, validation loss: 0.1638
2024-05-25 03:32:29 [INFO]: Epoch 152 - training loss: 0.2238, validation loss: 0.1641
2024-05-25 03:32:30 [INFO]: Epoch 153 - training loss: 0.2231, validation loss: 0.1642
2024-05-25 03:32:30 [INFO]: Epoch 154 - training loss: 0.2222, validation loss: 0.1624
2024-05-25 03:32:31 [INFO]: Epoch 155 - training loss: 0.2226, validation loss: 0.1635
2024-05-25 03:32:32 [INFO]: Epoch 156 - training loss: 0.2233, validation loss: 0.1629
2024-05-25 03:32:32 [INFO]: Epoch 157 - training loss: 0.2230, validation loss: 0.1633
2024-05-25 03:32:33 [INFO]: Epoch 158 - training loss: 0.2210, validation loss: 0.1628
2024-05-25 03:32:34 [INFO]: Epoch 159 - training loss: 0.2199, validation loss: 0.1613
2024-05-25 03:32:34 [INFO]: Epoch 160 - training loss: 0.2199, validation loss: 0.1618
2024-05-25 03:32:35 [INFO]: Epoch 161 - training loss: 0.2184, validation loss: 0.1622
2024-05-25 03:32:36 [INFO]: Epoch 162 - training loss: 0.2194, validation loss: 0.1607
2024-05-25 03:32:36 [INFO]: Epoch 163 - training loss: 0.2192, validation loss: 0.1609
2024-05-25 03:32:37 [INFO]: Epoch 164 - training loss: 0.2183, validation loss: 0.1621
2024-05-25 03:32:38 [INFO]: Epoch 165 - training loss: 0.2191, validation loss: 0.1615
2024-05-25 03:32:38 [INFO]: Epoch 166 - training loss: 0.2186, validation loss: 0.1608
2024-05-25 03:32:39 [INFO]: Epoch 167 - training loss: 0.2187, validation loss: 0.1614
2024-05-25 03:32:40 [INFO]: Epoch 168 - training loss: 0.2189, validation loss: 0.1611
2024-05-25 03:32:40 [INFO]: Epoch 169 - training loss: 0.2199, validation loss: 0.1617
2024-05-25 03:32:41 [INFO]: Epoch 170 - training loss: 0.2197, validation loss: 0.1626
2024-05-25 03:32:42 [INFO]: Epoch 171 - training loss: 0.2192, validation loss: 0.1619
2024-05-25 03:32:42 [INFO]: Epoch 172 - training loss: 0.2170, validation loss: 0.1616
2024-05-25 03:32:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:32:42 [INFO]: Finished training. The best model is from epoch#162.
2024-05-25 03:32:42 [INFO]: Saved the model to augmentation_saved_results/round_3/SAITS_air_quality/20240525_T033047/SAITS.pypots
2024-05-25 03:32:42 [INFO]: SAITS on Air-Quality: MAE=0.1511, MSE=0.0989
2024-05-25 03:32:42 [INFO]: Successfully saved to augmentation_saved_results/round_3/SAITS_air_quality/imputation.pkl
2024-05-25 03:32:42 [INFO]: Using the given device: cuda:0
2024-05-25 03:32:42 [INFO]: Model files will be saved to augmentation_saved_results/round_3/Transformer_air_quality/20240525_T033242
2024-05-25 03:32:42 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/Transformer_air_quality/20240525_T033242/tensorboard
2024-05-25 03:32:43 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 03:32:43 [INFO]: Epoch 001 - training loss: 0.9045, validation loss: 0.5036
2024-05-25 03:32:43 [INFO]: Epoch 002 - training loss: 0.5763, validation loss: 0.3883
2024-05-25 03:32:43 [INFO]: Epoch 003 - training loss: 0.4872, validation loss: 0.3294
2024-05-25 03:32:44 [INFO]: Epoch 004 - training loss: 0.4402, validation loss: 0.3040
2024-05-25 03:32:44 [INFO]: Epoch 005 - training loss: 0.4139, validation loss: 0.2888
2024-05-25 03:32:44 [INFO]: Epoch 006 - training loss: 0.3917, validation loss: 0.2798
2024-05-25 03:32:45 [INFO]: Epoch 007 - training loss: 0.3770, validation loss: 0.2711
2024-05-25 03:32:45 [INFO]: Epoch 008 - training loss: 0.3648, validation loss: 0.2683
2024-05-25 03:32:45 [INFO]: Epoch 009 - training loss: 0.3602, validation loss: 0.2643
2024-05-25 03:32:46 [INFO]: Epoch 010 - training loss: 0.3509, validation loss: 0.2568
2024-05-25 03:32:46 [INFO]: Epoch 011 - training loss: 0.3407, validation loss: 0.2520
2024-05-25 03:32:46 [INFO]: Epoch 012 - training loss: 0.3352, validation loss: 0.2493
2024-05-25 03:32:47 [INFO]: Epoch 013 - training loss: 0.3285, validation loss: 0.2460
2024-05-25 03:32:47 [INFO]: Epoch 014 - training loss: 0.3273, validation loss: 0.2423
2024-05-25 03:32:47 [INFO]: Epoch 015 - training loss: 0.3218, validation loss: 0.2400
2024-05-25 03:32:48 [INFO]: Epoch 016 - training loss: 0.3200, validation loss: 0.2376
2024-05-25 03:32:48 [INFO]: Epoch 017 - training loss: 0.3164, validation loss: 0.2361
2024-05-25 03:32:48 [INFO]: Epoch 018 - training loss: 0.3126, validation loss: 0.2303
2024-05-25 03:32:49 [INFO]: Epoch 019 - training loss: 0.3096, validation loss: 0.2279
2024-05-25 03:32:49 [INFO]: Epoch 020 - training loss: 0.3053, validation loss: 0.2257
2024-05-25 03:32:49 [INFO]: Epoch 021 - training loss: 0.3032, validation loss: 0.2230
2024-05-25 03:32:49 [INFO]: Epoch 022 - training loss: 0.3038, validation loss: 0.2228
2024-05-25 03:32:50 [INFO]: Epoch 023 - training loss: 0.3018, validation loss: 0.2208
2024-05-25 03:32:50 [INFO]: Epoch 024 - training loss: 0.2983, validation loss: 0.2195
2024-05-25 03:32:50 [INFO]: Epoch 025 - training loss: 0.2951, validation loss: 0.2170
2024-05-25 03:32:51 [INFO]: Epoch 026 - training loss: 0.2936, validation loss: 0.2178
2024-05-25 03:32:51 [INFO]: Epoch 027 - training loss: 0.2951, validation loss: 0.2172
2024-05-25 03:32:51 [INFO]: Epoch 028 - training loss: 0.2905, validation loss: 0.2145
2024-05-25 03:32:52 [INFO]: Epoch 029 - training loss: 0.2859, validation loss: 0.2138
2024-05-25 03:32:52 [INFO]: Epoch 030 - training loss: 0.2873, validation loss: 0.2122
2024-05-25 03:32:52 [INFO]: Epoch 031 - training loss: 0.2848, validation loss: 0.2118
2024-05-25 03:32:53 [INFO]: Epoch 032 - training loss: 0.2841, validation loss: 0.2117
2024-05-25 03:32:53 [INFO]: Epoch 033 - training loss: 0.2833, validation loss: 0.2108
2024-05-25 03:32:53 [INFO]: Epoch 034 - training loss: 0.2818, validation loss: 0.2106
2024-05-25 03:32:54 [INFO]: Epoch 035 - training loss: 0.2791, validation loss: 0.2101
2024-05-25 03:32:54 [INFO]: Epoch 036 - training loss: 0.2778, validation loss: 0.2077
2024-05-25 03:32:54 [INFO]: Epoch 037 - training loss: 0.2768, validation loss: 0.2094
2024-05-25 03:32:55 [INFO]: Epoch 038 - training loss: 0.2745, validation loss: 0.2082
2024-05-25 03:32:55 [INFO]: Epoch 039 - training loss: 0.2738, validation loss: 0.2063
2024-05-25 03:32:55 [INFO]: Epoch 040 - training loss: 0.2735, validation loss: 0.2060
2024-05-25 03:32:55 [INFO]: Epoch 041 - training loss: 0.2756, validation loss: 0.2056
2024-05-25 03:32:56 [INFO]: Epoch 042 - training loss: 0.2721, validation loss: 0.2054
2024-05-25 03:32:56 [INFO]: Epoch 043 - training loss: 0.2725, validation loss: 0.2041
2024-05-25 03:32:56 [INFO]: Epoch 044 - training loss: 0.2690, validation loss: 0.2042
2024-05-25 03:32:57 [INFO]: Epoch 045 - training loss: 0.2714, validation loss: 0.2041
2024-05-25 03:32:57 [INFO]: Epoch 046 - training loss: 0.2674, validation loss: 0.2019
2024-05-25 03:32:57 [INFO]: Epoch 047 - training loss: 0.2677, validation loss: 0.2022
2024-05-25 03:32:58 [INFO]: Epoch 048 - training loss: 0.2702, validation loss: 0.2023
2024-05-25 03:32:58 [INFO]: Epoch 049 - training loss: 0.2670, validation loss: 0.2027
2024-05-25 03:32:58 [INFO]: Epoch 050 - training loss: 0.2654, validation loss: 0.2014
2024-05-25 03:32:59 [INFO]: Epoch 051 - training loss: 0.2628, validation loss: 0.2007
2024-05-25 03:32:59 [INFO]: Epoch 052 - training loss: 0.2625, validation loss: 0.1986
2024-05-25 03:32:59 [INFO]: Epoch 053 - training loss: 0.2609, validation loss: 0.2000
2024-05-25 03:33:00 [INFO]: Epoch 054 - training loss: 0.2613, validation loss: 0.2001
2024-05-25 03:33:00 [INFO]: Epoch 055 - training loss: 0.2600, validation loss: 0.2002
2024-05-25 03:33:00 [INFO]: Epoch 056 - training loss: 0.2590, validation loss: 0.1976
2024-05-25 03:33:01 [INFO]: Epoch 057 - training loss: 0.2591, validation loss: 0.1976
2024-05-25 03:33:01 [INFO]: Epoch 058 - training loss: 0.2573, validation loss: 0.1972
2024-05-25 03:33:01 [INFO]: Epoch 059 - training loss: 0.2554, validation loss: 0.1982
2024-05-25 03:33:01 [INFO]: Epoch 060 - training loss: 0.2559, validation loss: 0.1953
2024-05-25 03:33:02 [INFO]: Epoch 061 - training loss: 0.2551, validation loss: 0.1964
2024-05-25 03:33:02 [INFO]: Epoch 062 - training loss: 0.2576, validation loss: 0.1966
2024-05-25 03:33:02 [INFO]: Epoch 063 - training loss: 0.2562, validation loss: 0.1949
2024-05-25 03:33:03 [INFO]: Epoch 064 - training loss: 0.2546, validation loss: 0.1943
2024-05-25 03:33:03 [INFO]: Epoch 065 - training loss: 0.2535, validation loss: 0.1943
2024-05-25 03:33:03 [INFO]: Epoch 066 - training loss: 0.2513, validation loss: 0.1946
2024-05-25 03:33:04 [INFO]: Epoch 067 - training loss: 0.2511, validation loss: 0.1922
2024-05-25 03:33:04 [INFO]: Epoch 068 - training loss: 0.2504, validation loss: 0.1941
2024-05-25 03:33:04 [INFO]: Epoch 069 - training loss: 0.2490, validation loss: 0.1915
2024-05-25 03:33:05 [INFO]: Epoch 070 - training loss: 0.2467, validation loss: 0.1938
2024-05-25 03:33:05 [INFO]: Epoch 071 - training loss: 0.2456, validation loss: 0.1917
2024-05-25 03:33:05 [INFO]: Epoch 072 - training loss: 0.2495, validation loss: 0.1919
2024-05-25 03:33:06 [INFO]: Epoch 073 - training loss: 0.2477, validation loss: 0.1912
2024-05-25 03:33:06 [INFO]: Epoch 074 - training loss: 0.2466, validation loss: 0.1925
2024-05-25 03:33:06 [INFO]: Epoch 075 - training loss: 0.2437, validation loss: 0.1915
2024-05-25 03:33:07 [INFO]: Epoch 076 - training loss: 0.2475, validation loss: 0.1902
2024-05-25 03:33:07 [INFO]: Epoch 077 - training loss: 0.2472, validation loss: 0.1920
2024-05-25 03:33:07 [INFO]: Epoch 078 - training loss: 0.2436, validation loss: 0.1906
2024-05-25 03:33:07 [INFO]: Epoch 079 - training loss: 0.2434, validation loss: 0.1889
2024-05-25 03:33:08 [INFO]: Epoch 080 - training loss: 0.2408, validation loss: 0.1895
2024-05-25 03:33:08 [INFO]: Epoch 081 - training loss: 0.2413, validation loss: 0.1890
2024-05-25 03:33:08 [INFO]: Epoch 082 - training loss: 0.2389, validation loss: 0.1893
2024-05-25 03:33:09 [INFO]: Epoch 083 - training loss: 0.2427, validation loss: 0.1898
2024-05-25 03:33:09 [INFO]: Epoch 084 - training loss: 0.2403, validation loss: 0.1881
2024-05-25 03:33:09 [INFO]: Epoch 085 - training loss: 0.2398, validation loss: 0.1877
2024-05-25 03:33:10 [INFO]: Epoch 086 - training loss: 0.2378, validation loss: 0.1873
2024-05-25 03:33:10 [INFO]: Epoch 087 - training loss: 0.2353, validation loss: 0.1886
2024-05-25 03:33:10 [INFO]: Epoch 088 - training loss: 0.2350, validation loss: 0.1862
2024-05-25 03:33:11 [INFO]: Epoch 089 - training loss: 0.2338, validation loss: 0.1864
2024-05-25 03:33:11 [INFO]: Epoch 090 - training loss: 0.2346, validation loss: 0.1856
2024-05-25 03:33:11 [INFO]: Epoch 091 - training loss: 0.2373, validation loss: 0.1899
2024-05-25 03:33:12 [INFO]: Epoch 092 - training loss: 0.2359, validation loss: 0.1850
2024-05-25 03:33:12 [INFO]: Epoch 093 - training loss: 0.2329, validation loss: 0.1853
2024-05-25 03:33:12 [INFO]: Epoch 094 - training loss: 0.2322, validation loss: 0.1848
2024-05-25 03:33:13 [INFO]: Epoch 095 - training loss: 0.2327, validation loss: 0.1885
2024-05-25 03:33:13 [INFO]: Epoch 096 - training loss: 0.2376, validation loss: 0.1838
2024-05-25 03:33:13 [INFO]: Epoch 097 - training loss: 0.2379, validation loss: 0.1827
2024-05-25 03:33:13 [INFO]: Epoch 098 - training loss: 0.2323, validation loss: 0.1836
2024-05-25 03:33:14 [INFO]: Epoch 099 - training loss: 0.2306, validation loss: 0.1818
2024-05-25 03:33:14 [INFO]: Epoch 100 - training loss: 0.2304, validation loss: 0.1832
2024-05-25 03:33:14 [INFO]: Epoch 101 - training loss: 0.2292, validation loss: 0.1840
2024-05-25 03:33:15 [INFO]: Epoch 102 - training loss: 0.2281, validation loss: 0.1823
2024-05-25 03:33:15 [INFO]: Epoch 103 - training loss: 0.2273, validation loss: 0.1815
2024-05-25 03:33:15 [INFO]: Epoch 104 - training loss: 0.2288, validation loss: 0.1823
2024-05-25 03:33:16 [INFO]: Epoch 105 - training loss: 0.2276, validation loss: 0.1819
2024-05-25 03:33:16 [INFO]: Epoch 106 - training loss: 0.2260, validation loss: 0.1850
2024-05-25 03:33:16 [INFO]: Epoch 107 - training loss: 0.2256, validation loss: 0.1815
2024-05-25 03:33:17 [INFO]: Epoch 108 - training loss: 0.2254, validation loss: 0.1805
2024-05-25 03:33:17 [INFO]: Epoch 109 - training loss: 0.2251, validation loss: 0.1802
2024-05-25 03:33:17 [INFO]: Epoch 110 - training loss: 0.2240, validation loss: 0.1801
2024-05-25 03:33:18 [INFO]: Epoch 111 - training loss: 0.2245, validation loss: 0.1806
2024-05-25 03:33:18 [INFO]: Epoch 112 - training loss: 0.2239, validation loss: 0.1797
2024-05-25 03:33:18 [INFO]: Epoch 113 - training loss: 0.2233, validation loss: 0.1798
2024-05-25 03:33:19 [INFO]: Epoch 114 - training loss: 0.2234, validation loss: 0.1814
2024-05-25 03:33:19 [INFO]: Epoch 115 - training loss: 0.2226, validation loss: 0.1793
2024-05-25 03:33:19 [INFO]: Epoch 116 - training loss: 0.2229, validation loss: 0.1792
2024-05-25 03:33:19 [INFO]: Epoch 117 - training loss: 0.2222, validation loss: 0.1804
2024-05-25 03:33:20 [INFO]: Epoch 118 - training loss: 0.2218, validation loss: 0.1786
2024-05-25 03:33:20 [INFO]: Epoch 119 - training loss: 0.2233, validation loss: 0.1784
2024-05-25 03:33:20 [INFO]: Epoch 120 - training loss: 0.2230, validation loss: 0.1777
2024-05-25 03:33:21 [INFO]: Epoch 121 - training loss: 0.2215, validation loss: 0.1789
2024-05-25 03:33:21 [INFO]: Epoch 122 - training loss: 0.2264, validation loss: 0.1780
2024-05-25 03:33:21 [INFO]: Epoch 123 - training loss: 0.2196, validation loss: 0.1779
2024-05-25 03:33:22 [INFO]: Epoch 124 - training loss: 0.2211, validation loss: 0.1784
2024-05-25 03:33:22 [INFO]: Epoch 125 - training loss: 0.2205, validation loss: 0.1775
2024-05-25 03:33:22 [INFO]: Epoch 126 - training loss: 0.2188, validation loss: 0.1773
2024-05-25 03:33:23 [INFO]: Epoch 127 - training loss: 0.2178, validation loss: 0.1768
2024-05-25 03:33:23 [INFO]: Epoch 128 - training loss: 0.2174, validation loss: 0.1781
2024-05-25 03:33:23 [INFO]: Epoch 129 - training loss: 0.2177, validation loss: 0.1777
2024-05-25 03:33:24 [INFO]: Epoch 130 - training loss: 0.2164, validation loss: 0.1776
2024-05-25 03:33:24 [INFO]: Epoch 131 - training loss: 0.2163, validation loss: 0.1771
2024-05-25 03:33:24 [INFO]: Epoch 132 - training loss: 0.2154, validation loss: 0.1753
2024-05-25 03:33:25 [INFO]: Epoch 133 - training loss: 0.2140, validation loss: 0.1761
2024-05-25 03:33:25 [INFO]: Epoch 134 - training loss: 0.2134, validation loss: 0.1755
2024-05-25 03:33:25 [INFO]: Epoch 135 - training loss: 0.2154, validation loss: 0.1776
2024-05-25 03:33:25 [INFO]: Epoch 136 - training loss: 0.2142, validation loss: 0.1754
2024-05-25 03:33:26 [INFO]: Epoch 137 - training loss: 0.2174, validation loss: 0.1760
2024-05-25 03:33:26 [INFO]: Epoch 138 - training loss: 0.2134, validation loss: 0.1744
2024-05-25 03:33:26 [INFO]: Epoch 139 - training loss: 0.2149, validation loss: 0.1743
2024-05-25 03:33:27 [INFO]: Epoch 140 - training loss: 0.2157, validation loss: 0.1743
2024-05-25 03:33:27 [INFO]: Epoch 141 - training loss: 0.2127, validation loss: 0.1739
2024-05-25 03:33:27 [INFO]: Epoch 142 - training loss: 0.2137, validation loss: 0.1745
2024-05-25 03:33:28 [INFO]: Epoch 143 - training loss: 0.2119, validation loss: 0.1723
2024-05-25 03:33:28 [INFO]: Epoch 144 - training loss: 0.2119, validation loss: 0.1737
2024-05-25 03:33:28 [INFO]: Epoch 145 - training loss: 0.2115, validation loss: 0.1732
2024-05-25 03:33:29 [INFO]: Epoch 146 - training loss: 0.2149, validation loss: 0.1733
2024-05-25 03:33:29 [INFO]: Epoch 147 - training loss: 0.2109, validation loss: 0.1723
2024-05-25 03:33:29 [INFO]: Epoch 148 - training loss: 0.2093, validation loss: 0.1731
2024-05-25 03:33:30 [INFO]: Epoch 149 - training loss: 0.2091, validation loss: 0.1729
2024-05-25 03:33:30 [INFO]: Epoch 150 - training loss: 0.2078, validation loss: 0.1737
2024-05-25 03:33:30 [INFO]: Epoch 151 - training loss: 0.2088, validation loss: 0.1730
2024-05-25 03:33:31 [INFO]: Epoch 152 - training loss: 0.2086, validation loss: 0.1730
2024-05-25 03:33:31 [INFO]: Epoch 153 - training loss: 0.2143, validation loss: 0.1723
2024-05-25 03:33:31 [INFO]: Epoch 154 - training loss: 0.2118, validation loss: 0.1721
2024-05-25 03:33:31 [INFO]: Epoch 155 - training loss: 0.2094, validation loss: 0.1708
2024-05-25 03:33:32 [INFO]: Epoch 156 - training loss: 0.2093, validation loss: 0.1715
2024-05-25 03:33:32 [INFO]: Epoch 157 - training loss: 0.2086, validation loss: 0.1716
2024-05-25 03:33:32 [INFO]: Epoch 158 - training loss: 0.2069, validation loss: 0.1713
2024-05-25 03:33:33 [INFO]: Epoch 159 - training loss: 0.2074, validation loss: 0.1723
2024-05-25 03:33:33 [INFO]: Epoch 160 - training loss: 0.2074, validation loss: 0.1701
2024-05-25 03:33:33 [INFO]: Epoch 161 - training loss: 0.2062, validation loss: 0.1711
2024-05-25 03:33:34 [INFO]: Epoch 162 - training loss: 0.2045, validation loss: 0.1733
2024-05-25 03:33:34 [INFO]: Epoch 163 - training loss: 0.2090, validation loss: 0.1729
2024-05-25 03:33:34 [INFO]: Epoch 164 - training loss: 0.2052, validation loss: 0.1720
2024-05-25 03:33:35 [INFO]: Epoch 165 - training loss: 0.2054, validation loss: 0.1718
2024-05-25 03:33:35 [INFO]: Epoch 166 - training loss: 0.2053, validation loss: 0.1699
2024-05-25 03:33:35 [INFO]: Epoch 167 - training loss: 0.2060, validation loss: 0.1720
2024-05-25 03:33:36 [INFO]: Epoch 168 - training loss: 0.2058, validation loss: 0.1699
2024-05-25 03:33:36 [INFO]: Epoch 169 - training loss: 0.2044, validation loss: 0.1704
2024-05-25 03:33:36 [INFO]: Epoch 170 - training loss: 0.2052, validation loss: 0.1690
2024-05-25 03:33:37 [INFO]: Epoch 171 - training loss: 0.2039, validation loss: 0.1710
2024-05-25 03:33:37 [INFO]: Epoch 172 - training loss: 0.2022, validation loss: 0.1697
2024-05-25 03:33:37 [INFO]: Epoch 173 - training loss: 0.2016, validation loss: 0.1699
2024-05-25 03:33:37 [INFO]: Epoch 174 - training loss: 0.2044, validation loss: 0.1700
2024-05-25 03:33:38 [INFO]: Epoch 175 - training loss: 0.2041, validation loss: 0.1677
2024-05-25 03:33:38 [INFO]: Epoch 176 - training loss: 0.2007, validation loss: 0.1688
2024-05-25 03:33:38 [INFO]: Epoch 177 - training loss: 0.2006, validation loss: 0.1696
2024-05-25 03:33:39 [INFO]: Epoch 178 - training loss: 0.2018, validation loss: 0.1685
2024-05-25 03:33:39 [INFO]: Epoch 179 - training loss: 0.2000, validation loss: 0.1688
2024-05-25 03:33:39 [INFO]: Epoch 180 - training loss: 0.2012, validation loss: 0.1684
2024-05-25 03:33:40 [INFO]: Epoch 181 - training loss: 0.2011, validation loss: 0.1687
2024-05-25 03:33:40 [INFO]: Epoch 182 - training loss: 0.2020, validation loss: 0.1683
2024-05-25 03:33:40 [INFO]: Epoch 183 - training loss: 0.2005, validation loss: 0.1690
2024-05-25 03:33:41 [INFO]: Epoch 184 - training loss: 0.2007, validation loss: 0.1674
2024-05-25 03:33:41 [INFO]: Epoch 185 - training loss: 0.1994, validation loss: 0.1685
2024-05-25 03:33:41 [INFO]: Epoch 186 - training loss: 0.1997, validation loss: 0.1678
2024-05-25 03:33:42 [INFO]: Epoch 187 - training loss: 0.1998, validation loss: 0.1686
2024-05-25 03:33:42 [INFO]: Epoch 188 - training loss: 0.1997, validation loss: 0.1676
2024-05-25 03:33:42 [INFO]: Epoch 189 - training loss: 0.1995, validation loss: 0.1678
2024-05-25 03:33:43 [INFO]: Epoch 190 - training loss: 0.1994, validation loss: 0.1672
2024-05-25 03:33:43 [INFO]: Epoch 191 - training loss: 0.1984, validation loss: 0.1679
2024-05-25 03:33:43 [INFO]: Epoch 192 - training loss: 0.1976, validation loss: 0.1687
2024-05-25 03:33:43 [INFO]: Epoch 193 - training loss: 0.1976, validation loss: 0.1684
2024-05-25 03:33:44 [INFO]: Epoch 194 - training loss: 0.1985, validation loss: 0.1671
2024-05-25 03:33:44 [INFO]: Epoch 195 - training loss: 0.1959, validation loss: 0.1673
2024-05-25 03:33:44 [INFO]: Epoch 196 - training loss: 0.1967, validation loss: 0.1673
2024-05-25 03:33:45 [INFO]: Epoch 197 - training loss: 0.1964, validation loss: 0.1666
2024-05-25 03:33:45 [INFO]: Epoch 198 - training loss: 0.1967, validation loss: 0.1688
2024-05-25 03:33:45 [INFO]: Epoch 199 - training loss: 0.1993, validation loss: 0.1691
2024-05-25 03:33:46 [INFO]: Epoch 200 - training loss: 0.1977, validation loss: 0.1683
2024-05-25 03:33:46 [INFO]: Epoch 201 - training loss: 0.1959, validation loss: 0.1657
2024-05-25 03:33:46 [INFO]: Epoch 202 - training loss: 0.1958, validation loss: 0.1663
2024-05-25 03:33:47 [INFO]: Epoch 203 - training loss: 0.1958, validation loss: 0.1659
2024-05-25 03:33:47 [INFO]: Epoch 204 - training loss: 0.2011, validation loss: 0.1667
2024-05-25 03:33:47 [INFO]: Epoch 205 - training loss: 0.1978, validation loss: 0.1669
2024-05-25 03:33:48 [INFO]: Epoch 206 - training loss: 0.1978, validation loss: 0.1685
2024-05-25 03:33:48 [INFO]: Epoch 207 - training loss: 0.1973, validation loss: 0.1668
2024-05-25 03:33:48 [INFO]: Epoch 208 - training loss: 0.1944, validation loss: 0.1668
2024-05-25 03:33:49 [INFO]: Epoch 209 - training loss: 0.1944, validation loss: 0.1672
2024-05-25 03:33:49 [INFO]: Epoch 210 - training loss: 0.1935, validation loss: 0.1692
2024-05-25 03:33:49 [INFO]: Epoch 211 - training loss: 0.1958, validation loss: 0.1678
2024-05-25 03:33:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:33:49 [INFO]: Finished training. The best model is from epoch#201.
2024-05-25 03:33:49 [INFO]: Saved the model to augmentation_saved_results/round_3/Transformer_air_quality/20240525_T033242/Transformer.pypots
2024-05-25 03:33:49 [INFO]: Transformer on Air-Quality: MAE=0.1616, MSE=0.1093
2024-05-25 03:33:49 [INFO]: Successfully saved to augmentation_saved_results/round_3/Transformer_air_quality/imputation.pkl
2024-05-25 03:33:49 [INFO]: Using the given device: cuda:0
2024-05-25 03:33:49 [INFO]: Model files will be saved to augmentation_saved_results/round_3/TimesNet_air_quality/20240525_T033349
2024-05-25 03:33:49 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/TimesNet_air_quality/20240525_T033349/tensorboard
2024-05-25 03:33:50 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 03:33:50 [INFO]: Epoch 001 - training loss: 0.3193, validation loss: 0.3007
2024-05-25 03:33:51 [INFO]: Epoch 002 - training loss: 0.2266, validation loss: 0.2366
2024-05-25 03:33:51 [INFO]: Epoch 003 - training loss: 0.1993, validation loss: 0.2383
2024-05-25 03:33:52 [INFO]: Epoch 004 - training loss: 0.1699, validation loss: 0.2685
2024-05-25 03:33:52 [INFO]: Epoch 005 - training loss: 0.1785, validation loss: 0.2329
2024-05-25 03:33:53 [INFO]: Epoch 006 - training loss: 0.1837, validation loss: 0.2307
2024-05-25 03:33:53 [INFO]: Epoch 007 - training loss: 0.1531, validation loss: 0.2320
2024-05-25 03:33:54 [INFO]: Epoch 008 - training loss: 0.1457, validation loss: 0.2345
2024-05-25 03:33:54 [INFO]: Epoch 009 - training loss: 0.1581, validation loss: 0.2231
2024-05-25 03:33:55 [INFO]: Epoch 010 - training loss: 0.1752, validation loss: 0.2104
2024-05-25 03:33:55 [INFO]: Epoch 011 - training loss: 0.1465, validation loss: 0.2177
2024-05-25 03:33:56 [INFO]: Epoch 012 - training loss: 0.1460, validation loss: 0.2062
2024-05-25 03:33:56 [INFO]: Epoch 013 - training loss: 0.1413, validation loss: 0.2074
2024-05-25 03:33:57 [INFO]: Epoch 014 - training loss: 0.1481, validation loss: 0.2183
2024-05-25 03:33:58 [INFO]: Epoch 015 - training loss: 0.1550, validation loss: 0.2098
2024-05-25 03:33:58 [INFO]: Epoch 016 - training loss: 0.1436, validation loss: 0.2090
2024-05-25 03:33:59 [INFO]: Epoch 017 - training loss: 0.1281, validation loss: 0.2057
2024-05-25 03:33:59 [INFO]: Epoch 018 - training loss: 0.1216, validation loss: 0.2107
2024-05-25 03:34:00 [INFO]: Epoch 019 - training loss: 0.1243, validation loss: 0.2060
2024-05-25 03:34:00 [INFO]: Epoch 020 - training loss: 0.1437, validation loss: 0.2028
2024-05-25 03:34:01 [INFO]: Epoch 021 - training loss: 0.1182, validation loss: 0.2039
2024-05-25 03:34:01 [INFO]: Epoch 022 - training loss: 0.1216, validation loss: 0.2071
2024-05-25 03:34:02 [INFO]: Epoch 023 - training loss: 0.1193, validation loss: 0.2004
2024-05-25 03:34:02 [INFO]: Epoch 024 - training loss: 0.1188, validation loss: 0.1989
2024-05-25 03:34:03 [INFO]: Epoch 025 - training loss: 0.0954, validation loss: 0.2069
2024-05-25 03:34:03 [INFO]: Epoch 026 - training loss: 0.1551, validation loss: 0.2019
2024-05-25 03:34:04 [INFO]: Epoch 027 - training loss: 0.1138, validation loss: 0.2049
2024-05-25 03:34:04 [INFO]: Epoch 028 - training loss: 0.1227, validation loss: 0.2093
2024-05-25 03:34:05 [INFO]: Epoch 029 - training loss: 0.1164, validation loss: 0.1984
2024-05-25 03:34:05 [INFO]: Epoch 030 - training loss: 0.1240, validation loss: 0.2013
2024-05-25 03:34:06 [INFO]: Epoch 031 - training loss: 0.1099, validation loss: 0.2002
2024-05-25 03:34:06 [INFO]: Epoch 032 - training loss: 0.1174, validation loss: 0.2077
2024-05-25 03:34:07 [INFO]: Epoch 033 - training loss: 0.1117, validation loss: 0.1981
2024-05-25 03:34:08 [INFO]: Epoch 034 - training loss: 0.0953, validation loss: 0.1992
2024-05-25 03:34:08 [INFO]: Epoch 035 - training loss: 0.1056, validation loss: 0.1999
2024-05-25 03:34:09 [INFO]: Epoch 036 - training loss: 0.1300, validation loss: 0.1949
2024-05-25 03:34:09 [INFO]: Epoch 037 - training loss: 0.1161, validation loss: 0.1990
2024-05-25 03:34:10 [INFO]: Epoch 038 - training loss: 0.1105, validation loss: 0.1991
2024-05-25 03:34:10 [INFO]: Epoch 039 - training loss: 0.1045, validation loss: 0.1914
2024-05-25 03:34:11 [INFO]: Epoch 040 - training loss: 0.1032, validation loss: 0.2010
2024-05-25 03:34:11 [INFO]: Epoch 041 - training loss: 0.1165, validation loss: 0.1886
2024-05-25 03:34:12 [INFO]: Epoch 042 - training loss: 0.1073, validation loss: 0.1923
2024-05-25 03:34:12 [INFO]: Epoch 043 - training loss: 0.0994, validation loss: 0.1930
2024-05-25 03:34:13 [INFO]: Epoch 044 - training loss: 0.1137, validation loss: 0.1961
2024-05-25 03:34:13 [INFO]: Epoch 045 - training loss: 0.1074, validation loss: 0.1924
2024-05-25 03:34:14 [INFO]: Epoch 046 - training loss: 0.1018, validation loss: 0.1905
2024-05-25 03:34:14 [INFO]: Epoch 047 - training loss: 0.1009, validation loss: 0.1967
2024-05-25 03:34:15 [INFO]: Epoch 048 - training loss: 0.1083, validation loss: 0.1893
2024-05-25 03:34:15 [INFO]: Epoch 049 - training loss: 0.1120, validation loss: 0.1926
2024-05-25 03:34:16 [INFO]: Epoch 050 - training loss: 0.1025, validation loss: 0.1981
2024-05-25 03:34:16 [INFO]: Epoch 051 - training loss: 0.1041, validation loss: 0.2017
2024-05-25 03:34:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:34:16 [INFO]: Finished training. The best model is from epoch#41.
2024-05-25 03:34:17 [INFO]: Saved the model to augmentation_saved_results/round_3/TimesNet_air_quality/20240525_T033349/TimesNet.pypots
2024-05-25 03:34:17 [INFO]: TimesNet on Air-Quality: MAE=0.1626, MSE=0.1388
2024-05-25 03:34:17 [INFO]: Successfully saved to augmentation_saved_results/round_3/TimesNet_air_quality/imputation.pkl
2024-05-25 03:34:17 [INFO]: Using the given device: cuda:0
2024-05-25 03:34:17 [INFO]: Model files will be saved to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417
2024-05-25 03:34:17 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/tensorboard
2024-05-25 03:34:17 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 03:34:34 [INFO]: Epoch 001 - training loss: 0.4970, validation loss: 0.3479
2024-05-25 03:34:34 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch1_loss0.3478736877441406.pypots
2024-05-25 03:34:50 [INFO]: Epoch 002 - training loss: 0.2993, validation loss: 0.2755
2024-05-25 03:34:50 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch2_loss0.27547267377376555.pypots
2024-05-25 03:35:07 [INFO]: Epoch 003 - training loss: 0.2316, validation loss: 0.2369
2024-05-25 03:35:07 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch3_loss0.2369394689798355.pypots
2024-05-25 03:35:24 [INFO]: Epoch 004 - training loss: 0.2449, validation loss: 0.2174
2024-05-25 03:35:24 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch4_loss0.21738420575857162.pypots
2024-05-25 03:35:41 [INFO]: Epoch 005 - training loss: 0.2087, validation loss: 0.1902
2024-05-25 03:35:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch5_loss0.1902236148715019.pypots
2024-05-25 03:35:58 [INFO]: Epoch 006 - training loss: 0.1813, validation loss: 0.1746
2024-05-25 03:35:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch6_loss0.17464161068201065.pypots
2024-05-25 03:36:15 [INFO]: Epoch 007 - training loss: 0.1770, validation loss: 0.1691
2024-05-25 03:36:15 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch7_loss0.16914496570825577.pypots
2024-05-25 03:36:31 [INFO]: Epoch 008 - training loss: 0.1710, validation loss: 0.1730
2024-05-25 03:36:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch8_loss0.17304818630218505.pypots
2024-05-25 03:36:48 [INFO]: Epoch 009 - training loss: 0.1782, validation loss: 0.1597
2024-05-25 03:36:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch9_loss0.15972163379192353.pypots
2024-05-25 03:37:05 [INFO]: Epoch 010 - training loss: 0.1756, validation loss: 0.1642
2024-05-25 03:37:05 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch10_loss0.16421395242214204.pypots
2024-05-25 03:37:22 [INFO]: Epoch 011 - training loss: 0.1763, validation loss: 0.1593
2024-05-25 03:37:22 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch11_loss0.15929126739501953.pypots
2024-05-25 03:37:39 [INFO]: Epoch 012 - training loss: 0.1834, validation loss: 0.1488
2024-05-25 03:37:39 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch12_loss0.14880330562591554.pypots
2024-05-25 03:37:56 [INFO]: Epoch 013 - training loss: 0.1809, validation loss: 0.1445
2024-05-25 03:37:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch13_loss0.1445435419678688.pypots
2024-05-25 03:38:13 [INFO]: Epoch 014 - training loss: 0.1621, validation loss: 0.1510
2024-05-25 03:38:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch14_loss0.1509509190917015.pypots
2024-05-25 03:38:29 [INFO]: Epoch 015 - training loss: 0.1668, validation loss: 0.1410
2024-05-25 03:38:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch15_loss0.14095507562160492.pypots
2024-05-25 03:38:46 [INFO]: Epoch 016 - training loss: 0.1493, validation loss: 0.1505
2024-05-25 03:38:46 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch16_loss0.15048884451389313.pypots
2024-05-25 03:39:03 [INFO]: Epoch 017 - training loss: 0.1607, validation loss: 0.1419
2024-05-25 03:39:03 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch17_loss0.14187813103199004.pypots
2024-05-25 03:39:20 [INFO]: Epoch 018 - training loss: 0.1700, validation loss: 0.1381
2024-05-25 03:39:20 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch18_loss0.13812599182128907.pypots
2024-05-25 03:39:37 [INFO]: Epoch 019 - training loss: 0.1529, validation loss: 0.1420
2024-05-25 03:39:37 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch19_loss0.14197176098823547.pypots
2024-05-25 03:39:54 [INFO]: Epoch 020 - training loss: 0.1821, validation loss: 0.1399
2024-05-25 03:39:54 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch20_loss0.13986285254359246.pypots
2024-05-25 03:40:10 [INFO]: Epoch 021 - training loss: 0.1404, validation loss: 0.1349
2024-05-25 03:40:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch21_loss0.134938133507967.pypots
2024-05-25 03:40:27 [INFO]: Epoch 022 - training loss: 0.1778, validation loss: 0.1384
2024-05-25 03:40:27 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch22_loss0.1384122371673584.pypots
2024-05-25 03:40:44 [INFO]: Epoch 023 - training loss: 0.1521, validation loss: 0.1373
2024-05-25 03:40:44 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch23_loss0.13730089068412782.pypots
2024-05-25 03:41:01 [INFO]: Epoch 024 - training loss: 0.1514, validation loss: 0.1374
2024-05-25 03:41:01 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch24_loss0.13741040825843812.pypots
2024-05-25 03:41:18 [INFO]: Epoch 025 - training loss: 0.1582, validation loss: 0.1310
2024-05-25 03:41:18 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch25_loss0.1310020312666893.pypots
2024-05-25 03:41:35 [INFO]: Epoch 026 - training loss: 0.1399, validation loss: 0.1313
2024-05-25 03:41:35 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch26_loss0.13126055151224136.pypots
2024-05-25 03:41:52 [INFO]: Epoch 027 - training loss: 0.1384, validation loss: 0.1335
2024-05-25 03:41:52 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch27_loss0.1334691636264324.pypots
2024-05-25 03:42:08 [INFO]: Epoch 028 - training loss: 0.1474, validation loss: 0.1276
2024-05-25 03:42:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch28_loss0.12761764749884605.pypots
2024-05-25 03:42:25 [INFO]: Epoch 029 - training loss: 0.1497, validation loss: 0.1283
2024-05-25 03:42:25 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch29_loss0.1283440075814724.pypots
2024-05-25 03:42:42 [INFO]: Epoch 030 - training loss: 0.1426, validation loss: 0.1313
2024-05-25 03:42:42 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch30_loss0.1313059687614441.pypots
2024-05-25 03:42:59 [INFO]: Epoch 031 - training loss: 0.1528, validation loss: 0.1291
2024-05-25 03:42:59 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch31_loss0.12909700348973274.pypots
2024-05-25 03:43:16 [INFO]: Epoch 032 - training loss: 0.1363, validation loss: 0.1293
2024-05-25 03:43:16 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch32_loss0.12930483520030975.pypots
2024-05-25 03:43:33 [INFO]: Epoch 033 - training loss: 0.1449, validation loss: 0.1275
2024-05-25 03:43:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch33_loss0.12753071039915084.pypots
2024-05-25 03:43:49 [INFO]: Epoch 034 - training loss: 0.1375, validation loss: 0.1247
2024-05-25 03:43:49 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch34_loss0.12468107864260673.pypots
2024-05-25 03:44:06 [INFO]: Epoch 035 - training loss: 0.1477, validation loss: 0.1256
2024-05-25 03:44:06 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch35_loss0.1256176047027111.pypots
2024-05-25 03:44:23 [INFO]: Epoch 036 - training loss: 0.1438, validation loss: 0.1194
2024-05-25 03:44:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch36_loss0.11942276656627655.pypots
2024-05-25 03:44:40 [INFO]: Epoch 037 - training loss: 0.1357, validation loss: 0.1199
2024-05-25 03:44:40 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch37_loss0.11990047395229339.pypots
2024-05-25 03:44:57 [INFO]: Epoch 038 - training loss: 0.1247, validation loss: 0.1225
2024-05-25 03:44:57 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch38_loss0.12246726900339126.pypots
2024-05-25 03:45:14 [INFO]: Epoch 039 - training loss: 0.1344, validation loss: 0.1241
2024-05-25 03:45:14 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch39_loss0.12406118586659431.pypots
2024-05-25 03:45:31 [INFO]: Epoch 040 - training loss: 0.1296, validation loss: 0.1193
2024-05-25 03:45:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch40_loss0.11929719895124435.pypots
2024-05-25 03:45:48 [INFO]: Epoch 041 - training loss: 0.1340, validation loss: 0.1177
2024-05-25 03:45:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch41_loss0.11770591139793396.pypots
2024-05-25 03:46:04 [INFO]: Epoch 042 - training loss: 0.1253, validation loss: 0.1229
2024-05-25 03:46:05 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch42_loss0.12285546287894249.pypots
2024-05-25 03:46:21 [INFO]: Epoch 043 - training loss: 0.1259, validation loss: 0.1162
2024-05-25 03:46:21 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch43_loss0.11618973761796951.pypots
2024-05-25 03:46:38 [INFO]: Epoch 044 - training loss: 0.1308, validation loss: 0.1177
2024-05-25 03:46:38 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch44_loss0.11767968907952309.pypots
2024-05-25 03:46:55 [INFO]: Epoch 045 - training loss: 0.1312, validation loss: 0.1154
2024-05-25 03:46:55 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch45_loss0.11537698209285736.pypots
2024-05-25 03:47:12 [INFO]: Epoch 046 - training loss: 0.1252, validation loss: 0.1157
2024-05-25 03:47:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch46_loss0.11567669138312339.pypots
2024-05-25 03:47:29 [INFO]: Epoch 047 - training loss: 0.1223, validation loss: 0.1160
2024-05-25 03:47:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch47_loss0.11603525802493095.pypots
2024-05-25 03:47:46 [INFO]: Epoch 048 - training loss: 0.1246, validation loss: 0.1179
2024-05-25 03:47:46 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch48_loss0.11785566508769989.pypots
2024-05-25 03:48:03 [INFO]: Epoch 049 - training loss: 0.1401, validation loss: 0.1183
2024-05-25 03:48:03 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch49_loss0.1182732954621315.pypots
2024-05-25 03:48:19 [INFO]: Epoch 050 - training loss: 0.1242, validation loss: 0.1169
2024-05-25 03:48:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch50_loss0.11685133799910545.pypots
2024-05-25 03:48:36 [INFO]: Epoch 051 - training loss: 0.1289, validation loss: 0.1146
2024-05-25 03:48:36 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch51_loss0.11458471417427063.pypots
2024-05-25 03:48:53 [INFO]: Epoch 052 - training loss: 0.1283, validation loss: 0.1180
2024-05-25 03:48:53 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch52_loss0.11802028864622116.pypots
2024-05-25 03:49:10 [INFO]: Epoch 053 - training loss: 0.1156, validation loss: 0.1125
2024-05-25 03:49:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch53_loss0.11254439726471901.pypots
2024-05-25 03:49:27 [INFO]: Epoch 054 - training loss: 0.1225, validation loss: 0.1124
2024-05-25 03:49:27 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch54_loss0.11241955757141113.pypots
2024-05-25 03:49:44 [INFO]: Epoch 055 - training loss: 0.1172, validation loss: 0.1133
2024-05-25 03:49:44 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch55_loss0.11330003142356873.pypots
2024-05-25 03:50:01 [INFO]: Epoch 056 - training loss: 0.1255, validation loss: 0.1120
2024-05-25 03:50:01 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch56_loss0.11198554709553718.pypots
2024-05-25 03:50:17 [INFO]: Epoch 057 - training loss: 0.1189, validation loss: 0.1114
2024-05-25 03:50:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch57_loss0.11138159409165382.pypots
2024-05-25 03:50:34 [INFO]: Epoch 058 - training loss: 0.1164, validation loss: 0.1118
2024-05-25 03:50:34 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch58_loss0.11179926544427872.pypots
2024-05-25 03:50:51 [INFO]: Epoch 059 - training loss: 0.1149, validation loss: 0.1109
2024-05-25 03:50:51 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch59_loss0.11086484417319298.pypots
2024-05-25 03:51:08 [INFO]: Epoch 060 - training loss: 0.1239, validation loss: 0.1119
2024-05-25 03:51:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch60_loss0.11190275326371193.pypots
2024-05-25 03:51:25 [INFO]: Epoch 061 - training loss: 0.1245, validation loss: 0.1125
2024-05-25 03:51:25 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch61_loss0.11248600855469704.pypots
2024-05-25 03:51:42 [INFO]: Epoch 062 - training loss: 0.1203, validation loss: 0.1106
2024-05-25 03:51:42 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch62_loss0.1106497310101986.pypots
2024-05-25 03:51:59 [INFO]: Epoch 063 - training loss: 0.1401, validation loss: 0.1106
2024-05-25 03:51:59 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch63_loss0.11055119633674622.pypots
2024-05-25 03:52:16 [INFO]: Epoch 064 - training loss: 0.1087, validation loss: 0.1128
2024-05-25 03:52:16 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch64_loss0.11284589618444443.pypots
2024-05-25 03:52:32 [INFO]: Epoch 065 - training loss: 0.1115, validation loss: 0.1107
2024-05-25 03:52:32 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch65_loss0.11070880815386772.pypots
2024-05-25 03:52:49 [INFO]: Epoch 066 - training loss: 0.1196, validation loss: 0.1116
2024-05-25 03:52:49 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch66_loss0.11159834116697312.pypots
2024-05-25 03:53:06 [INFO]: Epoch 067 - training loss: 0.1255, validation loss: 0.1173
2024-05-25 03:53:06 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch67_loss0.11730078905820847.pypots
2024-05-25 03:53:23 [INFO]: Epoch 068 - training loss: 0.1221, validation loss: 0.1120
2024-05-25 03:53:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch68_loss0.11202890574932098.pypots
2024-05-25 03:53:40 [INFO]: Epoch 069 - training loss: 0.1175, validation loss: 0.1117
2024-05-25 03:53:40 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch69_loss0.11165500283241273.pypots
2024-05-25 03:53:57 [INFO]: Epoch 070 - training loss: 0.1246, validation loss: 0.1171
2024-05-25 03:53:57 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch70_loss0.11711855083703995.pypots
2024-05-25 03:54:14 [INFO]: Epoch 071 - training loss: 0.1263, validation loss: 0.1116
2024-05-25 03:54:14 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch71_loss0.11157914698123932.pypots
2024-05-25 03:54:30 [INFO]: Epoch 072 - training loss: 0.1156, validation loss: 0.1077
2024-05-25 03:54:30 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch72_loss0.10774868726730347.pypots
2024-05-25 03:54:47 [INFO]: Epoch 073 - training loss: 0.1199, validation loss: 0.1059
2024-05-25 03:54:47 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch73_loss0.10589176788926125.pypots
2024-05-25 03:55:04 [INFO]: Epoch 074 - training loss: 0.1192, validation loss: 0.1104
2024-05-25 03:55:04 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch74_loss0.11036159694194794.pypots
2024-05-25 03:55:21 [INFO]: Epoch 075 - training loss: 0.1140, validation loss: 0.1272
2024-05-25 03:55:21 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch75_loss0.12718565091490747.pypots
2024-05-25 03:55:38 [INFO]: Epoch 076 - training loss: 0.1242, validation loss: 0.1065
2024-05-25 03:55:38 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch76_loss0.10652034208178521.pypots
2024-05-25 03:55:55 [INFO]: Epoch 077 - training loss: 0.1123, validation loss: 0.1076
2024-05-25 03:55:55 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch77_loss0.10761451572179795.pypots
2024-05-25 03:56:12 [INFO]: Epoch 078 - training loss: 0.1224, validation loss: 0.1075
2024-05-25 03:56:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch78_loss0.10753247365355492.pypots
2024-05-25 03:56:28 [INFO]: Epoch 079 - training loss: 0.1176, validation loss: 0.1079
2024-05-25 03:56:28 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch79_loss0.1078726552426815.pypots
2024-05-25 03:56:45 [INFO]: Epoch 080 - training loss: 0.1276, validation loss: 0.1067
2024-05-25 03:56:45 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch80_loss0.10671497061848641.pypots
2024-05-25 03:57:02 [INFO]: Epoch 081 - training loss: 0.1169, validation loss: 0.1054
2024-05-25 03:57:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch81_loss0.10535669699311256.pypots
2024-05-25 03:57:19 [INFO]: Epoch 082 - training loss: 0.1077, validation loss: 0.1041
2024-05-25 03:57:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch82_loss0.10414541959762573.pypots
2024-05-25 03:57:36 [INFO]: Epoch 083 - training loss: 0.1093, validation loss: 0.1053
2024-05-25 03:57:36 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch83_loss0.10530665069818497.pypots
2024-05-25 03:57:53 [INFO]: Epoch 084 - training loss: 0.1110, validation loss: 0.1084
2024-05-25 03:57:53 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch84_loss0.10842802599072457.pypots
2024-05-25 03:58:10 [INFO]: Epoch 085 - training loss: 0.1120, validation loss: 0.1065
2024-05-25 03:58:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch85_loss0.10649267435073853.pypots
2024-05-25 03:58:26 [INFO]: Epoch 086 - training loss: 0.1070, validation loss: 0.1038
2024-05-25 03:58:27 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch86_loss0.10383585393428803.pypots
2024-05-25 03:58:43 [INFO]: Epoch 087 - training loss: 0.1193, validation loss: 0.1038
2024-05-25 03:58:43 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch87_loss0.10384779274463654.pypots
2024-05-25 03:59:00 [INFO]: Epoch 088 - training loss: 0.1154, validation loss: 0.1046
2024-05-25 03:59:00 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch88_loss0.10456200540065766.pypots
2024-05-25 03:59:17 [INFO]: Epoch 089 - training loss: 0.1124, validation loss: 0.1125
2024-05-25 03:59:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch89_loss0.1124665766954422.pypots
2024-05-25 03:59:34 [INFO]: Epoch 090 - training loss: 0.1161, validation loss: 0.1085
2024-05-25 03:59:34 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch90_loss0.1084833599627018.pypots
2024-05-25 03:59:51 [INFO]: Epoch 091 - training loss: 0.1176, validation loss: 0.1050
2024-05-25 03:59:51 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch91_loss0.10502710938453674.pypots
2024-05-25 04:00:08 [INFO]: Epoch 092 - training loss: 0.1316, validation loss: 0.1059
2024-05-25 04:00:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch92_loss0.10588421151041985.pypots
2024-05-25 04:00:25 [INFO]: Epoch 093 - training loss: 0.1108, validation loss: 0.1033
2024-05-25 04:00:25 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch93_loss0.10328301414847374.pypots
2024-05-25 04:00:41 [INFO]: Epoch 094 - training loss: 0.1143, validation loss: 0.1069
2024-05-25 04:00:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch94_loss0.10692831948399543.pypots
2024-05-25 04:00:58 [INFO]: Epoch 095 - training loss: 0.1090, validation loss: 0.1027
2024-05-25 04:00:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch95_loss0.10271255001425743.pypots
2024-05-25 04:01:15 [INFO]: Epoch 096 - training loss: 0.1213, validation loss: 0.1041
2024-05-25 04:01:15 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch96_loss0.1040678270161152.pypots
2024-05-25 04:01:32 [INFO]: Epoch 097 - training loss: 0.1095, validation loss: 0.1063
2024-05-25 04:01:32 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch97_loss0.1062702514231205.pypots
2024-05-25 04:01:49 [INFO]: Epoch 098 - training loss: 0.1149, validation loss: 0.1045
2024-05-25 04:01:49 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch98_loss0.1044868603348732.pypots
2024-05-25 04:02:06 [INFO]: Epoch 099 - training loss: 0.1102, validation loss: 0.1032
2024-05-25 04:02:06 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch99_loss0.10322269797325134.pypots
2024-05-25 04:02:23 [INFO]: Epoch 100 - training loss: 0.1060, validation loss: 0.1030
2024-05-25 04:02:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch100_loss0.10303614288568497.pypots
2024-05-25 04:02:39 [INFO]: Epoch 101 - training loss: 0.1286, validation loss: 0.1030
2024-05-25 04:02:39 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch101_loss0.10300106331706047.pypots
2024-05-25 04:02:56 [INFO]: Epoch 102 - training loss: 0.1092, validation loss: 0.1036
2024-05-25 04:02:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch102_loss0.10359327048063278.pypots
2024-05-25 04:03:13 [INFO]: Epoch 103 - training loss: 0.1217, validation loss: 0.1042
2024-05-25 04:03:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch103_loss0.1041606567800045.pypots
2024-05-25 04:03:30 [INFO]: Epoch 104 - training loss: 0.1140, validation loss: 0.1050
2024-05-25 04:03:30 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch104_loss0.1049884594976902.pypots
2024-05-25 04:03:47 [INFO]: Epoch 105 - training loss: 0.1016, validation loss: 0.1040
2024-05-25 04:03:47 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI_epoch105_loss0.10403468757867813.pypots
2024-05-25 04:03:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:03:47 [INFO]: Finished training. The best model is from epoch#95.
2024-05-25 04:03:47 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T033417/CSDI.pypots
2024-05-25 04:06:08 [INFO]: CSDI on Air-Quality: MAE=0.1016, MSE=0.0740
2024-05-25 04:06:08 [INFO]: Successfully saved to augmentation_saved_results/round_3/CSDI_air_quality/imputation.pkl
2024-05-25 04:06:08 [INFO]: Using the given device: cuda:0
2024-05-25 04:06:08 [INFO]: Model files will be saved to augmentation_saved_results/round_3/GPVAE_air_quality/20240525_T040608
2024-05-25 04:06:08 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/GPVAE_air_quality/20240525_T040608/tensorboard
2024-05-25 04:06:08 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 04:06:08 [INFO]: Epoch 001 - training loss: 62765.4505, validation loss: 0.6800
2024-05-25 04:06:08 [INFO]: Epoch 002 - training loss: 42057.2810, validation loss: 0.5982
2024-05-25 04:06:09 [INFO]: Epoch 003 - training loss: 41740.4899, validation loss: 0.5371
2024-05-25 04:06:09 [INFO]: Epoch 004 - training loss: 41649.6308, validation loss: 0.5017
2024-05-25 04:06:09 [INFO]: Epoch 005 - training loss: 41543.1918, validation loss: 0.4588
2024-05-25 04:06:10 [INFO]: Epoch 006 - training loss: 41481.4097, validation loss: 0.4264
2024-05-25 04:06:10 [INFO]: Epoch 007 - training loss: 41429.7446, validation loss: 0.4149
2024-05-25 04:06:10 [INFO]: Epoch 008 - training loss: 41403.1124, validation loss: 0.3867
2024-05-25 04:06:11 [INFO]: Epoch 009 - training loss: 41377.5067, validation loss: 0.3724
2024-05-25 04:06:11 [INFO]: Epoch 010 - training loss: 41354.0703, validation loss: 0.3581
2024-05-25 04:06:11 [INFO]: Epoch 011 - training loss: 41337.8615, validation loss: 0.3668
2024-05-25 04:06:12 [INFO]: Epoch 012 - training loss: 41329.3176, validation loss: 0.3584
2024-05-25 04:06:12 [INFO]: Epoch 013 - training loss: 41322.0243, validation loss: 0.3464
2024-05-25 04:06:12 [INFO]: Epoch 014 - training loss: 41347.0046, validation loss: 0.3561
2024-05-25 04:06:13 [INFO]: Epoch 015 - training loss: 41333.5657, validation loss: 0.3603
2024-05-25 04:06:13 [INFO]: Epoch 016 - training loss: 41314.1662, validation loss: 0.3292
2024-05-25 04:06:13 [INFO]: Epoch 017 - training loss: 41311.7674, validation loss: 0.3429
2024-05-25 04:06:14 [INFO]: Epoch 018 - training loss: 41351.2109, validation loss: 0.3460
2024-05-25 04:06:14 [INFO]: Epoch 019 - training loss: 41326.6508, validation loss: 0.3112
2024-05-25 04:06:14 [INFO]: Epoch 020 - training loss: 41261.3834, validation loss: 0.3132
2024-05-25 04:06:15 [INFO]: Epoch 021 - training loss: 41246.3844, validation loss: 0.3039
2024-05-25 04:06:15 [INFO]: Epoch 022 - training loss: 41241.9766, validation loss: 0.3062
2024-05-25 04:06:15 [INFO]: Epoch 023 - training loss: 41245.8070, validation loss: 0.3153
2024-05-25 04:06:15 [INFO]: Epoch 024 - training loss: 41256.5773, validation loss: 0.3014
2024-05-25 04:06:16 [INFO]: Epoch 025 - training loss: 41265.7776, validation loss: 0.3237
2024-05-25 04:06:16 [INFO]: Epoch 026 - training loss: 41238.5476, validation loss: 0.3028
2024-05-25 04:06:16 [INFO]: Epoch 027 - training loss: 41235.8883, validation loss: 0.3286
2024-05-25 04:06:17 [INFO]: Epoch 028 - training loss: 41237.2069, validation loss: 0.3013
2024-05-25 04:06:17 [INFO]: Epoch 029 - training loss: 41215.6895, validation loss: 0.3064
2024-05-25 04:06:17 [INFO]: Epoch 030 - training loss: 41213.6291, validation loss: 0.2804
2024-05-25 04:06:18 [INFO]: Epoch 031 - training loss: 41205.3054, validation loss: 0.2938
2024-05-25 04:06:18 [INFO]: Epoch 032 - training loss: 41207.6185, validation loss: 0.2870
2024-05-25 04:06:18 [INFO]: Epoch 033 - training loss: 41203.9227, validation loss: 0.3014
2024-05-25 04:06:19 [INFO]: Epoch 034 - training loss: 41229.1045, validation loss: 0.2907
2024-05-25 04:06:19 [INFO]: Epoch 035 - training loss: 41209.7338, validation loss: 0.2965
2024-05-25 04:06:19 [INFO]: Epoch 036 - training loss: 41214.8883, validation loss: 0.2826
2024-05-25 04:06:20 [INFO]: Epoch 037 - training loss: 41195.9810, validation loss: 0.2834
2024-05-25 04:06:20 [INFO]: Epoch 038 - training loss: 41190.5301, validation loss: 0.3201
2024-05-25 04:06:20 [INFO]: Epoch 039 - training loss: 41216.4544, validation loss: 0.2839
2024-05-25 04:06:21 [INFO]: Epoch 040 - training loss: 41201.5635, validation loss: 0.2709
2024-05-25 04:06:21 [INFO]: Epoch 041 - training loss: 41180.7872, validation loss: 0.2707
2024-05-25 04:06:21 [INFO]: Epoch 042 - training loss: 41174.7348, validation loss: 0.2690
2024-05-25 04:06:22 [INFO]: Epoch 043 - training loss: 41171.1292, validation loss: 0.2649
2024-05-25 04:06:22 [INFO]: Epoch 044 - training loss: 41174.5297, validation loss: 0.2658
2024-05-25 04:06:22 [INFO]: Epoch 045 - training loss: 41189.9857, validation loss: 0.2646
2024-05-25 04:06:23 [INFO]: Epoch 046 - training loss: 41181.3731, validation loss: 0.2781
2024-05-25 04:06:23 [INFO]: Epoch 047 - training loss: 41214.2396, validation loss: 0.2844
2024-05-25 04:06:23 [INFO]: Epoch 048 - training loss: 41224.3649, validation loss: 0.2807
2024-05-25 04:06:24 [INFO]: Epoch 049 - training loss: 41206.1147, validation loss: 0.2705
2024-05-25 04:06:24 [INFO]: Epoch 050 - training loss: 41180.8705, validation loss: 0.2684
2024-05-25 04:06:24 [INFO]: Epoch 051 - training loss: 41171.7520, validation loss: 0.2672
2024-05-25 04:06:25 [INFO]: Epoch 052 - training loss: 41161.4452, validation loss: 0.2651
2024-05-25 04:06:25 [INFO]: Epoch 053 - training loss: 41163.2747, validation loss: 0.2638
2024-05-25 04:06:25 [INFO]: Epoch 054 - training loss: 41157.4760, validation loss: 0.2599
2024-05-25 04:06:26 [INFO]: Epoch 055 - training loss: 41153.9815, validation loss: 0.2651
2024-05-25 04:06:26 [INFO]: Epoch 056 - training loss: 41155.4158, validation loss: 0.2701
2024-05-25 04:06:26 [INFO]: Epoch 057 - training loss: 41159.6042, validation loss: 0.2644
2024-05-25 04:06:27 [INFO]: Epoch 058 - training loss: 41157.4300, validation loss: 0.2807
2024-05-25 04:06:27 [INFO]: Epoch 059 - training loss: 41200.3511, validation loss: 0.2701
2024-05-25 04:06:27 [INFO]: Epoch 060 - training loss: 41166.8060, validation loss: 0.2628
2024-05-25 04:06:27 [INFO]: Epoch 061 - training loss: 41170.9462, validation loss: 0.2666
2024-05-25 04:06:28 [INFO]: Epoch 062 - training loss: 41167.3979, validation loss: 0.2834
2024-05-25 04:06:28 [INFO]: Epoch 063 - training loss: 41165.4008, validation loss: 0.2634
2024-05-25 04:06:28 [INFO]: Epoch 064 - training loss: 41166.7616, validation loss: 0.2674
2024-05-25 04:06:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:06:28 [INFO]: Finished training. The best model is from epoch#54.
2024-05-25 04:06:28 [INFO]: Saved the model to augmentation_saved_results/round_3/GPVAE_air_quality/20240525_T040608/GPVAE.pypots
2024-05-25 04:06:29 [INFO]: GP-VAE on Air-Quality: MAE=0.2807, MSE=0.2133
2024-05-25 04:06:29 [INFO]: Successfully saved to augmentation_saved_results/round_3/GPVAE_air_quality/imputation.pkl
2024-05-25 04:06:29 [INFO]: Using the given device: cuda:0
2024-05-25 04:06:29 [INFO]: Model files will be saved to augmentation_saved_results/round_3/USGAN_air_quality/20240525_T040629
2024-05-25 04:06:29 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/USGAN_air_quality/20240525_T040629/tensorboard
2024-05-25 04:06:29 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 04:06:33 [INFO]: Epoch 001 - generator training loss: 0.6202, discriminator training loss: 0.2903, validation loss: 0.5456
2024-05-25 04:06:38 [INFO]: Epoch 002 - generator training loss: 0.2918, discriminator training loss: 0.0674, validation loss: 0.4165
2024-05-25 04:06:42 [INFO]: Epoch 003 - generator training loss: 0.2183, discriminator training loss: 0.0631, validation loss: 0.3514
2024-05-25 04:06:46 [INFO]: Epoch 004 - generator training loss: 0.1812, discriminator training loss: 0.0622, validation loss: 0.3120
2024-05-25 04:06:50 [INFO]: Epoch 005 - generator training loss: 0.1543, discriminator training loss: 0.0619, validation loss: 0.2844
2024-05-25 04:06:54 [INFO]: Epoch 006 - generator training loss: 0.1360, discriminator training loss: 0.0621, validation loss: 0.2666
2024-05-25 04:06:58 [INFO]: Epoch 007 - generator training loss: 0.1278, discriminator training loss: 0.0612, validation loss: 0.2525
2024-05-25 04:07:02 [INFO]: Epoch 008 - generator training loss: 0.1113, discriminator training loss: 0.0602, validation loss: 0.2415
2024-05-25 04:07:06 [INFO]: Epoch 009 - generator training loss: 0.1022, discriminator training loss: 0.0600, validation loss: 0.2342
2024-05-25 04:07:10 [INFO]: Epoch 010 - generator training loss: 0.0951, discriminator training loss: 0.0592, validation loss: 0.2274
2024-05-25 04:07:14 [INFO]: Epoch 011 - generator training loss: 0.0903, discriminator training loss: 0.0579, validation loss: 0.2215
2024-05-25 04:07:18 [INFO]: Epoch 012 - generator training loss: 0.0860, discriminator training loss: 0.0558, validation loss: 0.2165
2024-05-25 04:07:23 [INFO]: Epoch 013 - generator training loss: 0.0811, discriminator training loss: 0.0544, validation loss: 0.2109
2024-05-25 04:07:27 [INFO]: Epoch 014 - generator training loss: 0.0806, discriminator training loss: 0.0528, validation loss: 0.2070
2024-05-25 04:07:31 [INFO]: Epoch 015 - generator training loss: 0.0774, discriminator training loss: 0.0509, validation loss: 0.2034
2024-05-25 04:07:35 [INFO]: Epoch 016 - generator training loss: 0.0741, discriminator training loss: 0.0497, validation loss: 0.1994
2024-05-25 04:07:39 [INFO]: Epoch 017 - generator training loss: 0.0712, discriminator training loss: 0.0486, validation loss: 0.1973
2024-05-25 04:07:43 [INFO]: Epoch 018 - generator training loss: 0.0703, discriminator training loss: 0.0474, validation loss: 0.1953
2024-05-25 04:07:47 [INFO]: Epoch 019 - generator training loss: 0.0703, discriminator training loss: 0.0463, validation loss: 0.1928
2024-05-25 04:07:51 [INFO]: Epoch 020 - generator training loss: 0.0669, discriminator training loss: 0.0449, validation loss: 0.1916
2024-05-25 04:07:55 [INFO]: Epoch 021 - generator training loss: 0.0669, discriminator training loss: 0.0441, validation loss: 0.1895
2024-05-25 04:07:59 [INFO]: Epoch 022 - generator training loss: 0.0637, discriminator training loss: 0.0441, validation loss: 0.1880
2024-05-25 04:08:03 [INFO]: Epoch 023 - generator training loss: 0.0628, discriminator training loss: 0.0428, validation loss: 0.1868
2024-05-25 04:08:07 [INFO]: Epoch 024 - generator training loss: 0.0617, discriminator training loss: 0.0423, validation loss: 0.1853
2024-05-25 04:08:12 [INFO]: Epoch 025 - generator training loss: 0.0608, discriminator training loss: 0.0416, validation loss: 0.1843
2024-05-25 04:08:16 [INFO]: Epoch 026 - generator training loss: 0.0592, discriminator training loss: 0.0412, validation loss: 0.1848
2024-05-25 04:08:20 [INFO]: Epoch 027 - generator training loss: 0.0582, discriminator training loss: 0.0404, validation loss: 0.1871
2024-05-25 04:08:24 [INFO]: Epoch 028 - generator training loss: 0.0574, discriminator training loss: 0.0397, validation loss: 0.1885
2024-05-25 04:08:28 [INFO]: Epoch 029 - generator training loss: 0.0563, discriminator training loss: 0.0384, validation loss: 0.1890
2024-05-25 04:08:32 [INFO]: Epoch 030 - generator training loss: 0.0551, discriminator training loss: 0.0375, validation loss: 0.1893
2024-05-25 04:08:36 [INFO]: Epoch 031 - generator training loss: 0.0547, discriminator training loss: 0.0368, validation loss: 0.1885
2024-05-25 04:08:40 [INFO]: Epoch 032 - generator training loss: 0.0544, discriminator training loss: 0.0363, validation loss: 0.1885
2024-05-25 04:08:44 [INFO]: Epoch 033 - generator training loss: 0.0536, discriminator training loss: 0.0354, validation loss: 0.1873
2024-05-25 04:08:48 [INFO]: Epoch 034 - generator training loss: 0.0537, discriminator training loss: 0.0345, validation loss: 0.1871
2024-05-25 04:08:53 [INFO]: Epoch 035 - generator training loss: 0.0524, discriminator training loss: 0.0335, validation loss: 0.1865
2024-05-25 04:08:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:08:53 [INFO]: Finished training. The best model is from epoch#25.
2024-05-25 04:08:53 [INFO]: Saved the model to augmentation_saved_results/round_3/USGAN_air_quality/20240525_T040629/USGAN.pypots
2024-05-25 04:08:53 [INFO]: US-GAN on Air-Quality: MAE=0.1886, MSE=0.1217
2024-05-25 04:08:53 [INFO]: Successfully saved to augmentation_saved_results/round_3/USGAN_air_quality/imputation.pkl
2024-05-25 04:08:53 [INFO]: Using the given device: cuda:0
2024-05-25 04:08:53 [INFO]: Model files will be saved to augmentation_saved_results/round_3/BRITS_air_quality/20240525_T040853
2024-05-25 04:08:53 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/BRITS_air_quality/20240525_T040853/tensorboard
2024-05-25 04:08:53 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 04:08:57 [INFO]: Epoch 001 - training loss: 1.3938, validation loss: 0.9336
2024-05-25 04:09:00 [INFO]: Epoch 002 - training loss: 1.1214, validation loss: 0.7035
2024-05-25 04:09:02 [INFO]: Epoch 003 - training loss: 0.9358, validation loss: 0.6039
2024-05-25 04:09:05 [INFO]: Epoch 004 - training loss: 0.8291, validation loss: 0.5398
2024-05-25 04:09:08 [INFO]: Epoch 005 - training loss: 0.7535, validation loss: 0.4955
2024-05-25 04:09:11 [INFO]: Epoch 006 - training loss: 0.6982, validation loss: 0.4603
2024-05-25 04:09:14 [INFO]: Epoch 007 - training loss: 0.6536, validation loss: 0.4320
2024-05-25 04:09:17 [INFO]: Epoch 008 - training loss: 0.6202, validation loss: 0.4085
2024-05-25 04:09:19 [INFO]: Epoch 009 - training loss: 0.5942, validation loss: 0.3903
2024-05-25 04:09:22 [INFO]: Epoch 010 - training loss: 0.5707, validation loss: 0.3737
2024-05-25 04:09:25 [INFO]: Epoch 011 - training loss: 0.5536, validation loss: 0.3609
2024-05-25 04:09:28 [INFO]: Epoch 012 - training loss: 0.5387, validation loss: 0.3497
2024-05-25 04:09:31 [INFO]: Epoch 013 - training loss: 0.5246, validation loss: 0.3403
2024-05-25 04:09:33 [INFO]: Epoch 014 - training loss: 0.5134, validation loss: 0.3323
2024-05-25 04:09:36 [INFO]: Epoch 015 - training loss: 0.5027, validation loss: 0.3249
2024-05-25 04:09:39 [INFO]: Epoch 016 - training loss: 0.4922, validation loss: 0.3183
2024-05-25 04:09:42 [INFO]: Epoch 017 - training loss: 0.4827, validation loss: 0.3126
2024-05-25 04:09:45 [INFO]: Epoch 018 - training loss: 0.4750, validation loss: 0.3077
2024-05-25 04:09:47 [INFO]: Epoch 019 - training loss: 0.4664, validation loss: 0.3027
2024-05-25 04:09:50 [INFO]: Epoch 020 - training loss: 0.4604, validation loss: 0.2980
2024-05-25 04:09:53 [INFO]: Epoch 021 - training loss: 0.4539, validation loss: 0.2938
2024-05-25 04:09:56 [INFO]: Epoch 022 - training loss: 0.4458, validation loss: 0.2896
2024-05-25 04:09:59 [INFO]: Epoch 023 - training loss: 0.4397, validation loss: 0.2857
2024-05-25 04:10:01 [INFO]: Epoch 024 - training loss: 0.4339, validation loss: 0.2823
2024-05-25 04:10:04 [INFO]: Epoch 025 - training loss: 0.4290, validation loss: 0.2783
2024-05-25 04:10:07 [INFO]: Epoch 026 - training loss: 0.4231, validation loss: 0.2755
2024-05-25 04:10:10 [INFO]: Epoch 027 - training loss: 0.4175, validation loss: 0.2721
2024-05-25 04:10:13 [INFO]: Epoch 028 - training loss: 0.4125, validation loss: 0.2691
2024-05-25 04:10:16 [INFO]: Epoch 029 - training loss: 0.4078, validation loss: 0.2661
2024-05-25 04:10:18 [INFO]: Epoch 030 - training loss: 0.4029, validation loss: 0.2634
2024-05-25 04:10:21 [INFO]: Epoch 031 - training loss: 0.3983, validation loss: 0.2606
2024-05-25 04:10:24 [INFO]: Epoch 032 - training loss: 0.3958, validation loss: 0.2577
2024-05-25 04:10:27 [INFO]: Epoch 033 - training loss: 0.3899, validation loss: 0.2552
2024-05-25 04:10:30 [INFO]: Epoch 034 - training loss: 0.3866, validation loss: 0.2528
2024-05-25 04:10:32 [INFO]: Epoch 035 - training loss: 0.3820, validation loss: 0.2500
2024-05-25 04:10:35 [INFO]: Epoch 036 - training loss: 0.3783, validation loss: 0.2478
2024-05-25 04:10:38 [INFO]: Epoch 037 - training loss: 0.3754, validation loss: 0.2458
2024-05-25 04:10:41 [INFO]: Epoch 038 - training loss: 0.3716, validation loss: 0.2438
2024-05-25 04:10:44 [INFO]: Epoch 039 - training loss: 0.3689, validation loss: 0.2417
2024-05-25 04:10:46 [INFO]: Epoch 040 - training loss: 0.3657, validation loss: 0.2399
2024-05-25 04:10:49 [INFO]: Epoch 041 - training loss: 0.3622, validation loss: 0.2379
2024-05-25 04:10:52 [INFO]: Epoch 042 - training loss: 0.3586, validation loss: 0.2365
2024-05-25 04:10:55 [INFO]: Epoch 043 - training loss: 0.3559, validation loss: 0.2351
2024-05-25 04:10:58 [INFO]: Epoch 044 - training loss: 0.3536, validation loss: 0.2332
2024-05-25 04:11:00 [INFO]: Epoch 045 - training loss: 0.3504, validation loss: 0.2321
2024-05-25 04:11:03 [INFO]: Epoch 046 - training loss: 0.3480, validation loss: 0.2310
2024-05-25 04:11:06 [INFO]: Epoch 047 - training loss: 0.3454, validation loss: 0.2303
2024-05-25 04:11:09 [INFO]: Epoch 048 - training loss: 0.3424, validation loss: 0.2292
2024-05-25 04:11:12 [INFO]: Epoch 049 - training loss: 0.3409, validation loss: 0.2283
2024-05-25 04:11:15 [INFO]: Epoch 050 - training loss: 0.3382, validation loss: 0.2276
2024-05-25 04:11:17 [INFO]: Epoch 051 - training loss: 0.3360, validation loss: 0.2264
2024-05-25 04:11:20 [INFO]: Epoch 052 - training loss: 0.3334, validation loss: 0.2258
2024-05-25 04:11:23 [INFO]: Epoch 053 - training loss: 0.3312, validation loss: 0.2251
2024-05-25 04:11:26 [INFO]: Epoch 054 - training loss: 0.3300, validation loss: 0.2242
2024-05-25 04:11:29 [INFO]: Epoch 055 - training loss: 0.3286, validation loss: 0.2236
2024-05-25 04:11:31 [INFO]: Epoch 056 - training loss: 0.3254, validation loss: 0.2235
2024-05-25 04:11:34 [INFO]: Epoch 057 - training loss: 0.3239, validation loss: 0.2229
2024-05-25 04:11:37 [INFO]: Epoch 058 - training loss: 0.3230, validation loss: 0.2223
2024-05-25 04:11:40 [INFO]: Epoch 059 - training loss: 0.3212, validation loss: 0.2215
2024-05-25 04:11:43 [INFO]: Epoch 060 - training loss: 0.3187, validation loss: 0.2208
2024-05-25 04:11:46 [INFO]: Epoch 061 - training loss: 0.3181, validation loss: 0.2202
2024-05-25 04:11:49 [INFO]: Epoch 062 - training loss: 0.3158, validation loss: 0.2196
2024-05-25 04:11:51 [INFO]: Epoch 063 - training loss: 0.3139, validation loss: 0.2192
2024-05-25 04:11:54 [INFO]: Epoch 064 - training loss: 0.3137, validation loss: 0.2187
2024-05-25 04:11:57 [INFO]: Epoch 065 - training loss: 0.3110, validation loss: 0.2183
2024-05-25 04:12:00 [INFO]: Epoch 066 - training loss: 0.3098, validation loss: 0.2177
2024-05-25 04:12:03 [INFO]: Epoch 067 - training loss: 0.3093, validation loss: 0.2170
2024-05-25 04:12:05 [INFO]: Epoch 068 - training loss: 0.3075, validation loss: 0.2165
2024-05-25 04:12:08 [INFO]: Epoch 069 - training loss: 0.3064, validation loss: 0.2157
2024-05-25 04:12:11 [INFO]: Epoch 070 - training loss: 0.3051, validation loss: 0.2153
2024-05-25 04:12:14 [INFO]: Epoch 071 - training loss: 0.3037, validation loss: 0.2150
2024-05-25 04:12:16 [INFO]: Epoch 072 - training loss: 0.3027, validation loss: 0.2143
2024-05-25 04:12:19 [INFO]: Epoch 073 - training loss: 0.3015, validation loss: 0.2137
2024-05-25 04:12:22 [INFO]: Epoch 074 - training loss: 0.3007, validation loss: 0.2135
2024-05-25 04:12:25 [INFO]: Epoch 075 - training loss: 0.2994, validation loss: 0.2128
2024-05-25 04:12:27 [INFO]: Epoch 076 - training loss: 0.2990, validation loss: 0.2121
2024-05-25 04:12:30 [INFO]: Epoch 077 - training loss: 0.2977, validation loss: 0.2115
2024-05-25 04:12:33 [INFO]: Epoch 078 - training loss: 0.2964, validation loss: 0.2110
2024-05-25 04:12:36 [INFO]: Epoch 079 - training loss: 0.2960, validation loss: 0.2103
2024-05-25 04:12:39 [INFO]: Epoch 080 - training loss: 0.2944, validation loss: 0.2098
2024-05-25 04:12:41 [INFO]: Epoch 081 - training loss: 0.2937, validation loss: 0.2094
2024-05-25 04:12:44 [INFO]: Epoch 082 - training loss: 0.2925, validation loss: 0.2088
2024-05-25 04:12:47 [INFO]: Epoch 083 - training loss: 0.2918, validation loss: 0.2084
2024-05-25 04:12:50 [INFO]: Epoch 084 - training loss: 0.2914, validation loss: 0.2075
2024-05-25 04:12:52 [INFO]: Epoch 085 - training loss: 0.2903, validation loss: 0.2073
2024-05-25 04:12:55 [INFO]: Epoch 086 - training loss: 0.2896, validation loss: 0.2065
2024-05-25 04:12:58 [INFO]: Epoch 087 - training loss: 0.2896, validation loss: 0.2062
2024-05-25 04:13:01 [INFO]: Epoch 088 - training loss: 0.2878, validation loss: 0.2056
2024-05-25 04:13:03 [INFO]: Epoch 089 - training loss: 0.2877, validation loss: 0.2050
2024-05-25 04:13:06 [INFO]: Epoch 090 - training loss: 0.2867, validation loss: 0.2045
2024-05-25 04:13:09 [INFO]: Epoch 091 - training loss: 0.2859, validation loss: 0.2040
2024-05-25 04:13:12 [INFO]: Epoch 092 - training loss: 0.2847, validation loss: 0.2035
2024-05-25 04:13:15 [INFO]: Epoch 093 - training loss: 0.2845, validation loss: 0.2032
2024-05-25 04:13:17 [INFO]: Epoch 094 - training loss: 0.2832, validation loss: 0.2026
2024-05-25 04:13:20 [INFO]: Epoch 095 - training loss: 0.2831, validation loss: 0.2021
2024-05-25 04:13:23 [INFO]: Epoch 096 - training loss: 0.2826, validation loss: 0.2016
2024-05-25 04:13:26 [INFO]: Epoch 097 - training loss: 0.2812, validation loss: 0.2013
2024-05-25 04:13:28 [INFO]: Epoch 098 - training loss: 0.2807, validation loss: 0.2010
2024-05-25 04:13:31 [INFO]: Epoch 099 - training loss: 0.2800, validation loss: 0.2004
2024-05-25 04:13:34 [INFO]: Epoch 100 - training loss: 0.2798, validation loss: 0.1999
2024-05-25 04:13:37 [INFO]: Epoch 101 - training loss: 0.2792, validation loss: 0.1994
2024-05-25 04:13:40 [INFO]: Epoch 102 - training loss: 0.2781, validation loss: 0.1991
2024-05-25 04:13:42 [INFO]: Epoch 103 - training loss: 0.2774, validation loss: 0.1987
2024-05-25 04:13:45 [INFO]: Epoch 104 - training loss: 0.2773, validation loss: 0.1981
2024-05-25 04:13:48 [INFO]: Epoch 105 - training loss: 0.2771, validation loss: 0.1978
2024-05-25 04:13:51 [INFO]: Epoch 106 - training loss: 0.2757, validation loss: 0.1974
2024-05-25 04:13:53 [INFO]: Epoch 107 - training loss: 0.2754, validation loss: 0.1970
2024-05-25 04:13:56 [INFO]: Epoch 108 - training loss: 0.2748, validation loss: 0.1965
2024-05-25 04:13:59 [INFO]: Epoch 109 - training loss: 0.2741, validation loss: 0.1960
2024-05-25 04:14:02 [INFO]: Epoch 110 - training loss: 0.2740, validation loss: 0.1955
2024-05-25 04:14:05 [INFO]: Epoch 111 - training loss: 0.2733, validation loss: 0.1954
2024-05-25 04:14:07 [INFO]: Epoch 112 - training loss: 0.2727, validation loss: 0.1948
2024-05-25 04:14:10 [INFO]: Epoch 113 - training loss: 0.2723, validation loss: 0.1945
2024-05-25 04:14:13 [INFO]: Epoch 114 - training loss: 0.2714, validation loss: 0.1941
2024-05-25 04:14:16 [INFO]: Epoch 115 - training loss: 0.2714, validation loss: 0.1936
2024-05-25 04:14:18 [INFO]: Epoch 116 - training loss: 0.2703, validation loss: 0.1933
2024-05-25 04:14:21 [INFO]: Epoch 117 - training loss: 0.2704, validation loss: 0.1928
2024-05-25 04:14:24 [INFO]: Epoch 118 - training loss: 0.2698, validation loss: 0.1924
2024-05-25 04:14:27 [INFO]: Epoch 119 - training loss: 0.2693, validation loss: 0.1921
2024-05-25 04:14:29 [INFO]: Epoch 120 - training loss: 0.2688, validation loss: 0.1916
2024-05-25 04:14:32 [INFO]: Epoch 121 - training loss: 0.2684, validation loss: 0.1912
2024-05-25 04:14:35 [INFO]: Epoch 122 - training loss: 0.2679, validation loss: 0.1908
2024-05-25 04:14:38 [INFO]: Epoch 123 - training loss: 0.2672, validation loss: 0.1904
2024-05-25 04:14:41 [INFO]: Epoch 124 - training loss: 0.2670, validation loss: 0.1900
2024-05-25 04:14:43 [INFO]: Epoch 125 - training loss: 0.2668, validation loss: 0.1897
2024-05-25 04:14:46 [INFO]: Epoch 126 - training loss: 0.2662, validation loss: 0.1893
2024-05-25 04:14:49 [INFO]: Epoch 127 - training loss: 0.2654, validation loss: 0.1890
2024-05-25 04:14:52 [INFO]: Epoch 128 - training loss: 0.2654, validation loss: 0.1886
2024-05-25 04:14:54 [INFO]: Epoch 129 - training loss: 0.2649, validation loss: 0.1882
2024-05-25 04:14:57 [INFO]: Epoch 130 - training loss: 0.2648, validation loss: 0.1880
2024-05-25 04:15:00 [INFO]: Epoch 131 - training loss: 0.2637, validation loss: 0.1875
2024-05-25 04:15:03 [INFO]: Epoch 132 - training loss: 0.2634, validation loss: 0.1870
2024-05-25 04:15:05 [INFO]: Epoch 133 - training loss: 0.2635, validation loss: 0.1867
2024-05-25 04:15:08 [INFO]: Epoch 134 - training loss: 0.2625, validation loss: 0.1863
2024-05-25 04:15:11 [INFO]: Epoch 135 - training loss: 0.2616, validation loss: 0.1861
2024-05-25 04:15:14 [INFO]: Epoch 136 - training loss: 0.2617, validation loss: 0.1857
2024-05-25 04:15:17 [INFO]: Epoch 137 - training loss: 0.2612, validation loss: 0.1854
2024-05-25 04:15:19 [INFO]: Epoch 138 - training loss: 0.2611, validation loss: 0.1850
2024-05-25 04:15:22 [INFO]: Epoch 139 - training loss: 0.2605, validation loss: 0.1846
2024-05-25 04:15:25 [INFO]: Epoch 140 - training loss: 0.2603, validation loss: 0.1843
2024-05-25 04:15:28 [INFO]: Epoch 141 - training loss: 0.2598, validation loss: 0.1841
2024-05-25 04:15:30 [INFO]: Epoch 142 - training loss: 0.2594, validation loss: 0.1837
2024-05-25 04:15:33 [INFO]: Epoch 143 - training loss: 0.2593, validation loss: 0.1834
2024-05-25 04:15:36 [INFO]: Epoch 144 - training loss: 0.2587, validation loss: 0.1832
2024-05-25 04:15:39 [INFO]: Epoch 145 - training loss: 0.2586, validation loss: 0.1828
2024-05-25 04:15:42 [INFO]: Epoch 146 - training loss: 0.2581, validation loss: 0.1825
2024-05-25 04:15:45 [INFO]: Epoch 147 - training loss: 0.2579, validation loss: 0.1821
2024-05-25 04:15:47 [INFO]: Epoch 148 - training loss: 0.2574, validation loss: 0.1819
2024-05-25 04:15:50 [INFO]: Epoch 149 - training loss: 0.2572, validation loss: 0.1817
2024-05-25 04:15:53 [INFO]: Epoch 150 - training loss: 0.2561, validation loss: 0.1813
2024-05-25 04:15:56 [INFO]: Epoch 151 - training loss: 0.2561, validation loss: 0.1811
2024-05-25 04:15:59 [INFO]: Epoch 152 - training loss: 0.2561, validation loss: 0.1808
2024-05-25 04:16:02 [INFO]: Epoch 153 - training loss: 0.2560, validation loss: 0.1804
2024-05-25 04:16:04 [INFO]: Epoch 154 - training loss: 0.2555, validation loss: 0.1802
2024-05-25 04:16:07 [INFO]: Epoch 155 - training loss: 0.2551, validation loss: 0.1799
2024-05-25 04:16:10 [INFO]: Epoch 156 - training loss: 0.2544, validation loss: 0.1797
2024-05-25 04:16:13 [INFO]: Epoch 157 - training loss: 0.2548, validation loss: 0.1794
2024-05-25 04:16:16 [INFO]: Epoch 158 - training loss: 0.2542, validation loss: 0.1791
2024-05-25 04:16:18 [INFO]: Epoch 159 - training loss: 0.2539, validation loss: 0.1789
2024-05-25 04:16:21 [INFO]: Epoch 160 - training loss: 0.2535, validation loss: 0.1786
2024-05-25 04:16:24 [INFO]: Epoch 161 - training loss: 0.2530, validation loss: 0.1781
2024-05-25 04:16:27 [INFO]: Epoch 162 - training loss: 0.2528, validation loss: 0.1781
2024-05-25 04:16:30 [INFO]: Epoch 163 - training loss: 0.2529, validation loss: 0.1777
2024-05-25 04:16:32 [INFO]: Epoch 164 - training loss: 0.2524, validation loss: 0.1777
2024-05-25 04:16:35 [INFO]: Epoch 165 - training loss: 0.2518, validation loss: 0.1772
2024-05-25 04:16:38 [INFO]: Epoch 166 - training loss: 0.2515, validation loss: 0.1771
2024-05-25 04:16:41 [INFO]: Epoch 167 - training loss: 0.2516, validation loss: 0.1769
2024-05-25 04:16:44 [INFO]: Epoch 168 - training loss: 0.2516, validation loss: 0.1764
2024-05-25 04:16:46 [INFO]: Epoch 169 - training loss: 0.2511, validation loss: 0.1764
2024-05-25 04:16:49 [INFO]: Epoch 170 - training loss: 0.2504, validation loss: 0.1761
2024-05-25 04:16:52 [INFO]: Epoch 171 - training loss: 0.2499, validation loss: 0.1760
2024-05-25 04:16:55 [INFO]: Epoch 172 - training loss: 0.2502, validation loss: 0.1755
2024-05-25 04:16:57 [INFO]: Epoch 173 - training loss: 0.2504, validation loss: 0.1754
2024-05-25 04:17:00 [INFO]: Epoch 174 - training loss: 0.2500, validation loss: 0.1752
2024-05-25 04:17:03 [INFO]: Epoch 175 - training loss: 0.2495, validation loss: 0.1750
2024-05-25 04:17:06 [INFO]: Epoch 176 - training loss: 0.2494, validation loss: 0.1748
2024-05-25 04:17:09 [INFO]: Epoch 177 - training loss: 0.2486, validation loss: 0.1747
2024-05-25 04:17:11 [INFO]: Epoch 178 - training loss: 0.2486, validation loss: 0.1744
2024-05-25 04:17:14 [INFO]: Epoch 179 - training loss: 0.2481, validation loss: 0.1743
2024-05-25 04:17:17 [INFO]: Epoch 180 - training loss: 0.2481, validation loss: 0.1740
2024-05-25 04:17:20 [INFO]: Epoch 181 - training loss: 0.2478, validation loss: 0.1737
2024-05-25 04:17:22 [INFO]: Epoch 182 - training loss: 0.2477, validation loss: 0.1736
2024-05-25 04:17:25 [INFO]: Epoch 183 - training loss: 0.2478, validation loss: 0.1734
2024-05-25 04:17:28 [INFO]: Epoch 184 - training loss: 0.2472, validation loss: 0.1733
2024-05-25 04:17:31 [INFO]: Epoch 185 - training loss: 0.2465, validation loss: 0.1730
2024-05-25 04:17:34 [INFO]: Epoch 186 - training loss: 0.2471, validation loss: 0.1729
2024-05-25 04:17:36 [INFO]: Epoch 187 - training loss: 0.2461, validation loss: 0.1727
2024-05-25 04:17:39 [INFO]: Epoch 188 - training loss: 0.2467, validation loss: 0.1722
2024-05-25 04:17:42 [INFO]: Epoch 189 - training loss: 0.2461, validation loss: 0.1723
2024-05-25 04:17:45 [INFO]: Epoch 190 - training loss: 0.2455, validation loss: 0.1719
2024-05-25 04:17:48 [INFO]: Epoch 191 - training loss: 0.2456, validation loss: 0.1719
2024-05-25 04:17:50 [INFO]: Epoch 192 - training loss: 0.2454, validation loss: 0.1717
2024-05-25 04:17:53 [INFO]: Epoch 193 - training loss: 0.2451, validation loss: 0.1716
2024-05-25 04:17:56 [INFO]: Epoch 194 - training loss: 0.2450, validation loss: 0.1713
2024-05-25 04:17:59 [INFO]: Epoch 195 - training loss: 0.2449, validation loss: 0.1713
2024-05-25 04:18:01 [INFO]: Epoch 196 - training loss: 0.2452, validation loss: 0.1709
2024-05-25 04:18:04 [INFO]: Epoch 197 - training loss: 0.2441, validation loss: 0.1708
2024-05-25 04:18:07 [INFO]: Epoch 198 - training loss: 0.2434, validation loss: 0.1707
2024-05-25 04:18:10 [INFO]: Epoch 199 - training loss: 0.2440, validation loss: 0.1704
2024-05-25 04:18:13 [INFO]: Epoch 200 - training loss: 0.2437, validation loss: 0.1701
2024-05-25 04:18:15 [INFO]: Epoch 201 - training loss: 0.2437, validation loss: 0.1701
2024-05-25 04:18:18 [INFO]: Epoch 202 - training loss: 0.2433, validation loss: 0.1698
2024-05-25 04:18:21 [INFO]: Epoch 203 - training loss: 0.2438, validation loss: 0.1697
2024-05-25 04:18:24 [INFO]: Epoch 204 - training loss: 0.2427, validation loss: 0.1696
2024-05-25 04:18:26 [INFO]: Epoch 205 - training loss: 0.2426, validation loss: 0.1694
2024-05-25 04:18:29 [INFO]: Epoch 206 - training loss: 0.2426, validation loss: 0.1692
2024-05-25 04:18:32 [INFO]: Epoch 207 - training loss: 0.2423, validation loss: 0.1692
2024-05-25 04:18:35 [INFO]: Epoch 208 - training loss: 0.2420, validation loss: 0.1689
2024-05-25 04:18:38 [INFO]: Epoch 209 - training loss: 0.2419, validation loss: 0.1687
2024-05-25 04:18:40 [INFO]: Epoch 210 - training loss: 0.2420, validation loss: 0.1686
2024-05-25 04:18:43 [INFO]: Epoch 211 - training loss: 0.2415, validation loss: 0.1685
2024-05-25 04:18:46 [INFO]: Epoch 212 - training loss: 0.2412, validation loss: 0.1685
2024-05-25 04:18:49 [INFO]: Epoch 213 - training loss: 0.2407, validation loss: 0.1683
2024-05-25 04:18:51 [INFO]: Epoch 214 - training loss: 0.2413, validation loss: 0.1680
2024-05-25 04:18:54 [INFO]: Epoch 215 - training loss: 0.2411, validation loss: 0.1680
2024-05-25 04:18:57 [INFO]: Epoch 216 - training loss: 0.2408, validation loss: 0.1678
2024-05-25 04:19:00 [INFO]: Epoch 217 - training loss: 0.2404, validation loss: 0.1679
2024-05-25 04:19:03 [INFO]: Epoch 218 - training loss: 0.2409, validation loss: 0.1675
2024-05-25 04:19:05 [INFO]: Epoch 219 - training loss: 0.2408, validation loss: 0.1672
2024-05-25 04:19:08 [INFO]: Epoch 220 - training loss: 0.2401, validation loss: 0.1672
2024-05-25 04:19:11 [INFO]: Epoch 221 - training loss: 0.2400, validation loss: 0.1669
2024-05-25 04:19:14 [INFO]: Epoch 222 - training loss: 0.2398, validation loss: 0.1668
2024-05-25 04:19:16 [INFO]: Epoch 223 - training loss: 0.2401, validation loss: 0.1667
2024-05-25 04:19:19 [INFO]: Epoch 224 - training loss: 0.2392, validation loss: 0.1666
2024-05-25 04:19:22 [INFO]: Epoch 225 - training loss: 0.2396, validation loss: 0.1665
2024-05-25 04:19:25 [INFO]: Epoch 226 - training loss: 0.2392, validation loss: 0.1664
2024-05-25 04:19:28 [INFO]: Epoch 227 - training loss: 0.2387, validation loss: 0.1662
2024-05-25 04:19:30 [INFO]: Epoch 228 - training loss: 0.2387, validation loss: 0.1660
2024-05-25 04:19:33 [INFO]: Epoch 229 - training loss: 0.2387, validation loss: 0.1659
2024-05-25 04:19:36 [INFO]: Epoch 230 - training loss: 0.2389, validation loss: 0.1658
2024-05-25 04:19:39 [INFO]: Epoch 231 - training loss: 0.2387, validation loss: 0.1658
2024-05-25 04:19:42 [INFO]: Epoch 232 - training loss: 0.2380, validation loss: 0.1655
2024-05-25 04:19:44 [INFO]: Epoch 233 - training loss: 0.2381, validation loss: 0.1657
2024-05-25 04:19:47 [INFO]: Epoch 234 - training loss: 0.2377, validation loss: 0.1655
2024-05-25 04:19:50 [INFO]: Epoch 235 - training loss: 0.2375, validation loss: 0.1651
2024-05-25 04:19:53 [INFO]: Epoch 236 - training loss: 0.2373, validation loss: 0.1651
2024-05-25 04:19:56 [INFO]: Epoch 237 - training loss: 0.2373, validation loss: 0.1651
2024-05-25 04:19:58 [INFO]: Epoch 238 - training loss: 0.2372, validation loss: 0.1651
2024-05-25 04:20:01 [INFO]: Epoch 239 - training loss: 0.2370, validation loss: 0.1649
2024-05-25 04:20:04 [INFO]: Epoch 240 - training loss: 0.2366, validation loss: 0.1646
2024-05-25 04:20:07 [INFO]: Epoch 241 - training loss: 0.2370, validation loss: 0.1646
2024-05-25 04:20:09 [INFO]: Epoch 242 - training loss: 0.2364, validation loss: 0.1645
2024-05-25 04:20:12 [INFO]: Epoch 243 - training loss: 0.2362, validation loss: 0.1644
2024-05-25 04:20:15 [INFO]: Epoch 244 - training loss: 0.2362, validation loss: 0.1642
2024-05-25 04:20:18 [INFO]: Epoch 245 - training loss: 0.2359, validation loss: 0.1642
2024-05-25 04:20:21 [INFO]: Epoch 246 - training loss: 0.2360, validation loss: 0.1640
2024-05-25 04:20:23 [INFO]: Epoch 247 - training loss: 0.2361, validation loss: 0.1640
2024-05-25 04:20:26 [INFO]: Epoch 248 - training loss: 0.2353, validation loss: 0.1640
2024-05-25 04:20:29 [INFO]: Epoch 249 - training loss: 0.2356, validation loss: 0.1636
2024-05-25 04:20:32 [INFO]: Epoch 250 - training loss: 0.2356, validation loss: 0.1638
2024-05-25 04:20:34 [INFO]: Epoch 251 - training loss: 0.2348, validation loss: 0.1635
2024-05-25 04:20:37 [INFO]: Epoch 252 - training loss: 0.2351, validation loss: 0.1635
2024-05-25 04:20:40 [INFO]: Epoch 253 - training loss: 0.2347, validation loss: 0.1633
2024-05-25 04:20:43 [INFO]: Epoch 254 - training loss: 0.2347, validation loss: 0.1632
2024-05-25 04:20:46 [INFO]: Epoch 255 - training loss: 0.2348, validation loss: 0.1632
2024-05-25 04:20:48 [INFO]: Epoch 256 - training loss: 0.2342, validation loss: 0.1630
2024-05-25 04:20:51 [INFO]: Epoch 257 - training loss: 0.2347, validation loss: 0.1630
2024-05-25 04:20:54 [INFO]: Epoch 258 - training loss: 0.2342, validation loss: 0.1628
2024-05-25 04:20:57 [INFO]: Epoch 259 - training loss: 0.2343, validation loss: 0.1629
2024-05-25 04:20:59 [INFO]: Epoch 260 - training loss: 0.2340, validation loss: 0.1627
2024-05-25 04:21:02 [INFO]: Epoch 261 - training loss: 0.2343, validation loss: 0.1626
2024-05-25 04:21:05 [INFO]: Epoch 262 - training loss: 0.2337, validation loss: 0.1625
2024-05-25 04:21:08 [INFO]: Epoch 263 - training loss: 0.2336, validation loss: 0.1624
2024-05-25 04:21:11 [INFO]: Epoch 264 - training loss: 0.2331, validation loss: 0.1622
2024-05-25 04:21:13 [INFO]: Epoch 265 - training loss: 0.2331, validation loss: 0.1623
2024-05-25 04:21:16 [INFO]: Epoch 266 - training loss: 0.2335, validation loss: 0.1622
2024-05-25 04:21:19 [INFO]: Epoch 267 - training loss: 0.2337, validation loss: 0.1622
2024-05-25 04:21:22 [INFO]: Epoch 268 - training loss: 0.2332, validation loss: 0.1619
2024-05-25 04:21:24 [INFO]: Epoch 269 - training loss: 0.2334, validation loss: 0.1618
2024-05-25 04:21:27 [INFO]: Epoch 270 - training loss: 0.2326, validation loss: 0.1618
2024-05-25 04:21:30 [INFO]: Epoch 271 - training loss: 0.2331, validation loss: 0.1617
2024-05-25 04:21:33 [INFO]: Epoch 272 - training loss: 0.2326, validation loss: 0.1618
2024-05-25 04:21:36 [INFO]: Epoch 273 - training loss: 0.2322, validation loss: 0.1615
2024-05-25 04:21:38 [INFO]: Epoch 274 - training loss: 0.2324, validation loss: 0.1615
2024-05-25 04:21:41 [INFO]: Epoch 275 - training loss: 0.2321, validation loss: 0.1613
2024-05-25 04:21:44 [INFO]: Epoch 276 - training loss: 0.2325, validation loss: 0.1613
2024-05-25 04:21:47 [INFO]: Epoch 277 - training loss: 0.2322, validation loss: 0.1613
2024-05-25 04:21:50 [INFO]: Epoch 278 - training loss: 0.2316, validation loss: 0.1612
2024-05-25 04:21:52 [INFO]: Epoch 279 - training loss: 0.2320, validation loss: 0.1611
2024-05-25 04:21:55 [INFO]: Epoch 280 - training loss: 0.2317, validation loss: 0.1609
2024-05-25 04:21:58 [INFO]: Epoch 281 - training loss: 0.2312, validation loss: 0.1609
2024-05-25 04:22:01 [INFO]: Epoch 282 - training loss: 0.2314, validation loss: 0.1610
2024-05-25 04:22:04 [INFO]: Epoch 283 - training loss: 0.2314, validation loss: 0.1609
2024-05-25 04:22:06 [INFO]: Epoch 284 - training loss: 0.2310, validation loss: 0.1608
2024-05-25 04:22:09 [INFO]: Epoch 285 - training loss: 0.2310, validation loss: 0.1606
2024-05-25 04:22:12 [INFO]: Epoch 286 - training loss: 0.2311, validation loss: 0.1607
2024-05-25 04:22:15 [INFO]: Epoch 287 - training loss: 0.2310, validation loss: 0.1604
2024-05-25 04:22:17 [INFO]: Epoch 288 - training loss: 0.2307, validation loss: 0.1605
2024-05-25 04:22:20 [INFO]: Epoch 289 - training loss: 0.2307, validation loss: 0.1604
2024-05-25 04:22:23 [INFO]: Epoch 290 - training loss: 0.2308, validation loss: 0.1604
2024-05-25 04:22:26 [INFO]: Epoch 291 - training loss: 0.2303, validation loss: 0.1603
2024-05-25 04:22:29 [INFO]: Epoch 292 - training loss: 0.2311, validation loss: 0.1601
2024-05-25 04:22:31 [INFO]: Epoch 293 - training loss: 0.2306, validation loss: 0.1603
2024-05-25 04:22:34 [INFO]: Epoch 294 - training loss: 0.2303, validation loss: 0.1600
2024-05-25 04:22:37 [INFO]: Epoch 295 - training loss: 0.2303, validation loss: 0.1600
2024-05-25 04:22:40 [INFO]: Epoch 296 - training loss: 0.2304, validation loss: 0.1600
2024-05-25 04:22:42 [INFO]: Epoch 297 - training loss: 0.2302, validation loss: 0.1601
2024-05-25 04:22:45 [INFO]: Epoch 298 - training loss: 0.2308, validation loss: 0.1597
2024-05-25 04:22:48 [INFO]: Epoch 299 - training loss: 0.2295, validation loss: 0.1598
2024-05-25 04:22:51 [INFO]: Epoch 300 - training loss: 0.2298, validation loss: 0.1597
2024-05-25 04:22:51 [INFO]: Finished training. The best model is from epoch#298.
2024-05-25 04:22:51 [INFO]: Saved the model to augmentation_saved_results/round_3/BRITS_air_quality/20240525_T040853/BRITS.pypots
2024-05-25 04:22:51 [INFO]: BRITS on Air-Quality: MAE=0.1391, MSE=0.0923
2024-05-25 04:22:51 [INFO]: Successfully saved to augmentation_saved_results/round_3/BRITS_air_quality/imputation.pkl
2024-05-25 04:22:51 [INFO]: Using the given device: cuda:0
2024-05-25 04:22:51 [INFO]: Model files will be saved to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251
2024-05-25 04:22:51 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/tensorboard
2024-05-25 04:22:51 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 04:22:56 [INFO]: Epoch 001 - training loss: 1.3920, validation loss: 0.8263
2024-05-25 04:22:56 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch1_loss0.8262662470340729.pypots
2024-05-25 04:23:00 [INFO]: Epoch 002 - training loss: 1.0340, validation loss: 0.7713
2024-05-25 04:23:00 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch2_loss0.7713227301836014.pypots
2024-05-25 04:23:04 [INFO]: Epoch 003 - training loss: 0.9807, validation loss: 0.7526
2024-05-25 04:23:04 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch3_loss0.7525508612394333.pypots
2024-05-25 04:23:08 [INFO]: Epoch 004 - training loss: 0.9490, validation loss: 0.7406
2024-05-25 04:23:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch4_loss0.7406165599822998.pypots
2024-05-25 04:23:12 [INFO]: Epoch 005 - training loss: 0.9482, validation loss: 0.7322
2024-05-25 04:23:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch5_loss0.7321951448917389.pypots
2024-05-25 04:23:15 [INFO]: Epoch 006 - training loss: 0.9226, validation loss: 0.7267
2024-05-25 04:23:15 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch6_loss0.7267441838979721.pypots
2024-05-25 04:23:19 [INFO]: Epoch 007 - training loss: 0.9215, validation loss: 0.7212
2024-05-25 04:23:19 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch7_loss0.7211795926094056.pypots
2024-05-25 04:23:23 [INFO]: Epoch 008 - training loss: 0.9358, validation loss: 0.7176
2024-05-25 04:23:23 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch8_loss0.7176217794418335.pypots
2024-05-25 04:23:27 [INFO]: Epoch 009 - training loss: 0.9206, validation loss: 0.7146
2024-05-25 04:23:27 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch9_loss0.714558807015419.pypots
2024-05-25 04:23:31 [INFO]: Epoch 010 - training loss: 0.9183, validation loss: 0.7118
2024-05-25 04:23:31 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch10_loss0.711831659078598.pypots
2024-05-25 04:23:35 [INFO]: Epoch 011 - training loss: 0.9116, validation loss: 0.7104
2024-05-25 04:23:35 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch11_loss0.7104390740394593.pypots
2024-05-25 04:23:39 [INFO]: Epoch 012 - training loss: 0.9020, validation loss: 0.7084
2024-05-25 04:23:39 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch12_loss0.7084367036819458.pypots
2024-05-25 04:23:42 [INFO]: Epoch 013 - training loss: 0.8950, validation loss: 0.7079
2024-05-25 04:23:42 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch13_loss0.7079281747341156.pypots
2024-05-25 04:23:46 [INFO]: Epoch 014 - training loss: 0.8957, validation loss: 0.7071
2024-05-25 04:23:46 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch14_loss0.7071345239877701.pypots
2024-05-25 04:23:50 [INFO]: Epoch 015 - training loss: 0.8848, validation loss: 0.7079
2024-05-25 04:23:50 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch15_loss0.7079019904136657.pypots
2024-05-25 04:23:54 [INFO]: Epoch 016 - training loss: 0.8769, validation loss: 0.7069
2024-05-25 04:23:54 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch16_loss0.7068517535924912.pypots
2024-05-25 04:23:58 [INFO]: Epoch 017 - training loss: 0.8813, validation loss: 0.7069
2024-05-25 04:23:58 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch17_loss0.706935030221939.pypots
2024-05-25 04:24:02 [INFO]: Epoch 018 - training loss: 0.8868, validation loss: 0.7052
2024-05-25 04:24:02 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch18_loss0.7051768809556961.pypots
2024-05-25 04:24:06 [INFO]: Epoch 019 - training loss: 0.8815, validation loss: 0.7059
2024-05-25 04:24:06 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch19_loss0.7059281647205353.pypots
2024-05-25 04:24:10 [INFO]: Epoch 020 - training loss: 0.8933, validation loss: 0.7073
2024-05-25 04:24:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch20_loss0.707327026128769.pypots
2024-05-25 04:24:13 [INFO]: Epoch 021 - training loss: 0.8663, validation loss: 0.7070
2024-05-25 04:24:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch21_loss0.7070478290319443.pypots
2024-05-25 04:24:17 [INFO]: Epoch 022 - training loss: 0.8734, validation loss: 0.7080
2024-05-25 04:24:17 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch22_loss0.7079880654811859.pypots
2024-05-25 04:24:21 [INFO]: Epoch 023 - training loss: 0.8702, validation loss: 0.7057
2024-05-25 04:24:21 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch23_loss0.7057208985090255.pypots
2024-05-25 04:24:25 [INFO]: Epoch 024 - training loss: 0.8677, validation loss: 0.7074
2024-05-25 04:24:25 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch24_loss0.7073689222335815.pypots
2024-05-25 04:24:29 [INFO]: Epoch 025 - training loss: 0.8895, validation loss: 0.7063
2024-05-25 04:24:29 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch25_loss0.7062626272439957.pypots
2024-05-25 04:24:33 [INFO]: Epoch 026 - training loss: 0.8644, validation loss: 0.7077
2024-05-25 04:24:33 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch26_loss0.7077455043792724.pypots
2024-05-25 04:24:37 [INFO]: Epoch 027 - training loss: 0.8716, validation loss: 0.7065
2024-05-25 04:24:37 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch27_loss0.7064560681581498.pypots
2024-05-25 04:24:41 [INFO]: Epoch 028 - training loss: 0.8610, validation loss: 0.7077
2024-05-25 04:24:41 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN_epoch28_loss0.7076600641012192.pypots
2024-05-25 04:24:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:24:41 [INFO]: Finished training. The best model is from epoch#18.
2024-05-25 04:24:41 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T042251/MRNN.pypots
2024-05-25 04:24:41 [INFO]: MRNN on Air-Quality: MAE=0.5220, MSE=0.5999
2024-05-25 04:24:41 [INFO]: Successfully saved to augmentation_saved_results/round_3/MRNN_air_quality/imputation.pkl
2024-05-25 04:24:41 [INFO]: Using the given device: cpu
2024-05-25 04:24:41 [INFO]: LOCF on Air-Quality: MAE=0.2006, MSE=0.1979
2024-05-25 04:24:41 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_air_quality".
2024-05-25 04:24:41 [INFO]: Successfully saved to augmentation_saved_results/round_3/LOCF_air_quality/imputation.pkl
2024-05-25 04:24:41 [INFO]: Median on Air-Quality: MAE=0.6700, MSE=1.0040
2024-05-25 04:24:41 [INFO]: Successfully created the given path "saved_results/round_3/Median_air_quality".
2024-05-25 04:24:41 [INFO]: Successfully saved to augmentation_saved_results/round_3/Median_air_quality/imputation.pkl
2024-05-25 04:24:41 [INFO]: Mean on Air-Quality: MAE=0.6975, MSE=0.9352
2024-05-25 04:24:41 [INFO]: Successfully created the given path "saved_results/round_3/Mean_air_quality".
2024-05-25 04:24:41 [INFO]: Successfully saved to augmentation_saved_results/round_3/Mean_air_quality/imputation.pkl
2024-05-25 04:24:41 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-25 04:24:41 [INFO]: Using the given device: cuda:0
2024-05-25 04:24:41 [INFO]: Model files will be saved to augmentation_saved_results/round_4/SAITS_air_quality/20240525_T042441
2024-05-25 04:24:41 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/SAITS_air_quality/20240525_T042441/tensorboard
2024-05-25 04:24:42 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 04:24:42 [INFO]: Epoch 001 - training loss: 1.0577, validation loss: 0.5374
2024-05-25 04:24:43 [INFO]: Epoch 002 - training loss: 0.7519, validation loss: 0.4224
2024-05-25 04:24:44 [INFO]: Epoch 003 - training loss: 0.6445, validation loss: 0.3493
2024-05-25 04:24:44 [INFO]: Epoch 004 - training loss: 0.5712, validation loss: 0.3122
2024-05-25 04:24:45 [INFO]: Epoch 005 - training loss: 0.5166, validation loss: 0.2954
2024-05-25 04:24:46 [INFO]: Epoch 006 - training loss: 0.4809, validation loss: 0.2794
2024-05-25 04:24:46 [INFO]: Epoch 007 - training loss: 0.4559, validation loss: 0.2711
2024-05-25 04:24:47 [INFO]: Epoch 008 - training loss: 0.4394, validation loss: 0.2622
2024-05-25 04:24:48 [INFO]: Epoch 009 - training loss: 0.4255, validation loss: 0.2582
2024-05-25 04:24:48 [INFO]: Epoch 010 - training loss: 0.4137, validation loss: 0.2526
2024-05-25 04:24:49 [INFO]: Epoch 011 - training loss: 0.4040, validation loss: 0.2504
2024-05-25 04:24:50 [INFO]: Epoch 012 - training loss: 0.3968, validation loss: 0.2462
2024-05-25 04:24:50 [INFO]: Epoch 013 - training loss: 0.3900, validation loss: 0.2444
2024-05-25 04:24:51 [INFO]: Epoch 014 - training loss: 0.3818, validation loss: 0.2409
2024-05-25 04:24:52 [INFO]: Epoch 015 - training loss: 0.3748, validation loss: 0.2385
2024-05-25 04:24:52 [INFO]: Epoch 016 - training loss: 0.3699, validation loss: 0.2357
2024-05-25 04:24:53 [INFO]: Epoch 017 - training loss: 0.3650, validation loss: 0.2334
2024-05-25 04:24:54 [INFO]: Epoch 018 - training loss: 0.3607, validation loss: 0.2313
2024-05-25 04:24:54 [INFO]: Epoch 019 - training loss: 0.3554, validation loss: 0.2288
2024-05-25 04:24:55 [INFO]: Epoch 020 - training loss: 0.3525, validation loss: 0.2281
2024-05-25 04:24:56 [INFO]: Epoch 021 - training loss: 0.3506, validation loss: 0.2257
2024-05-25 04:24:56 [INFO]: Epoch 022 - training loss: 0.3457, validation loss: 0.2234
2024-05-25 04:24:57 [INFO]: Epoch 023 - training loss: 0.3429, validation loss: 0.2238
2024-05-25 04:24:58 [INFO]: Epoch 024 - training loss: 0.3403, validation loss: 0.2221
2024-05-25 04:24:58 [INFO]: Epoch 025 - training loss: 0.3363, validation loss: 0.2197
2024-05-25 04:24:59 [INFO]: Epoch 026 - training loss: 0.3337, validation loss: 0.2174
2024-05-25 04:25:00 [INFO]: Epoch 027 - training loss: 0.3325, validation loss: 0.2169
2024-05-25 04:25:00 [INFO]: Epoch 028 - training loss: 0.3295, validation loss: 0.2157
2024-05-25 04:25:01 [INFO]: Epoch 029 - training loss: 0.3267, validation loss: 0.2136
2024-05-25 04:25:02 [INFO]: Epoch 030 - training loss: 0.3243, validation loss: 0.2117
2024-05-25 04:25:02 [INFO]: Epoch 031 - training loss: 0.3238, validation loss: 0.2118
2024-05-25 04:25:03 [INFO]: Epoch 032 - training loss: 0.3214, validation loss: 0.2102
2024-05-25 04:25:04 [INFO]: Epoch 033 - training loss: 0.3188, validation loss: 0.2079
2024-05-25 04:25:04 [INFO]: Epoch 034 - training loss: 0.3190, validation loss: 0.2086
2024-05-25 04:25:05 [INFO]: Epoch 035 - training loss: 0.3165, validation loss: 0.2065
2024-05-25 04:25:06 [INFO]: Epoch 036 - training loss: 0.3132, validation loss: 0.2048
2024-05-25 04:25:06 [INFO]: Epoch 037 - training loss: 0.3106, validation loss: 0.2042
2024-05-25 04:25:07 [INFO]: Epoch 038 - training loss: 0.3112, validation loss: 0.2031
2024-05-25 04:25:08 [INFO]: Epoch 039 - training loss: 0.3074, validation loss: 0.2017
2024-05-25 04:25:08 [INFO]: Epoch 040 - training loss: 0.3064, validation loss: 0.2010
2024-05-25 04:25:09 [INFO]: Epoch 041 - training loss: 0.3042, validation loss: 0.2001
2024-05-25 04:25:10 [INFO]: Epoch 042 - training loss: 0.3039, validation loss: 0.2003
2024-05-25 04:25:10 [INFO]: Epoch 043 - training loss: 0.3016, validation loss: 0.1989
2024-05-25 04:25:11 [INFO]: Epoch 044 - training loss: 0.3005, validation loss: 0.1974
2024-05-25 04:25:12 [INFO]: Epoch 045 - training loss: 0.2986, validation loss: 0.1975
2024-05-25 04:25:12 [INFO]: Epoch 046 - training loss: 0.2966, validation loss: 0.1964
2024-05-25 04:25:13 [INFO]: Epoch 047 - training loss: 0.2961, validation loss: 0.1952
2024-05-25 04:25:14 [INFO]: Epoch 048 - training loss: 0.2933, validation loss: 0.1944
2024-05-25 04:25:14 [INFO]: Epoch 049 - training loss: 0.2921, validation loss: 0.1940
2024-05-25 04:25:15 [INFO]: Epoch 050 - training loss: 0.2923, validation loss: 0.1936
2024-05-25 04:25:16 [INFO]: Epoch 051 - training loss: 0.2902, validation loss: 0.1934
2024-05-25 04:25:16 [INFO]: Epoch 052 - training loss: 0.2900, validation loss: 0.1913
2024-05-25 04:25:17 [INFO]: Epoch 053 - training loss: 0.2884, validation loss: 0.1915
2024-05-25 04:25:18 [INFO]: Epoch 054 - training loss: 0.2873, validation loss: 0.1917
2024-05-25 04:25:18 [INFO]: Epoch 055 - training loss: 0.2860, validation loss: 0.1905
2024-05-25 04:25:19 [INFO]: Epoch 056 - training loss: 0.2849, validation loss: 0.1901
2024-05-25 04:25:20 [INFO]: Epoch 057 - training loss: 0.2830, validation loss: 0.1893
2024-05-25 04:25:20 [INFO]: Epoch 058 - training loss: 0.2808, validation loss: 0.1892
2024-05-25 04:25:21 [INFO]: Epoch 059 - training loss: 0.2801, validation loss: 0.1886
2024-05-25 04:25:22 [INFO]: Epoch 060 - training loss: 0.2789, validation loss: 0.1879
2024-05-25 04:25:22 [INFO]: Epoch 061 - training loss: 0.2787, validation loss: 0.1872
2024-05-25 04:25:23 [INFO]: Epoch 062 - training loss: 0.2778, validation loss: 0.1869
2024-05-25 04:25:24 [INFO]: Epoch 063 - training loss: 0.2762, validation loss: 0.1863
2024-05-25 04:25:24 [INFO]: Epoch 064 - training loss: 0.2746, validation loss: 0.1857
2024-05-25 04:25:25 [INFO]: Epoch 065 - training loss: 0.2737, validation loss: 0.1852
2024-05-25 04:25:26 [INFO]: Epoch 066 - training loss: 0.2737, validation loss: 0.1852
2024-05-25 04:25:26 [INFO]: Epoch 067 - training loss: 0.2739, validation loss: 0.1854
2024-05-25 04:25:27 [INFO]: Epoch 068 - training loss: 0.2715, validation loss: 0.1844
2024-05-25 04:25:28 [INFO]: Epoch 069 - training loss: 0.2714, validation loss: 0.1836
2024-05-25 04:25:28 [INFO]: Epoch 070 - training loss: 0.2691, validation loss: 0.1835
2024-05-25 04:25:29 [INFO]: Epoch 071 - training loss: 0.2676, validation loss: 0.1825
2024-05-25 04:25:30 [INFO]: Epoch 072 - training loss: 0.2661, validation loss: 0.1820
2024-05-25 04:25:30 [INFO]: Epoch 073 - training loss: 0.2639, validation loss: 0.1822
2024-05-25 04:25:31 [INFO]: Epoch 074 - training loss: 0.2653, validation loss: 0.1811
2024-05-25 04:25:32 [INFO]: Epoch 075 - training loss: 0.2641, validation loss: 0.1806
2024-05-25 04:25:32 [INFO]: Epoch 076 - training loss: 0.2634, validation loss: 0.1804
2024-05-25 04:25:33 [INFO]: Epoch 077 - training loss: 0.2620, validation loss: 0.1808
2024-05-25 04:25:34 [INFO]: Epoch 078 - training loss: 0.2618, validation loss: 0.1796
2024-05-25 04:25:34 [INFO]: Epoch 079 - training loss: 0.2604, validation loss: 0.1799
2024-05-25 04:25:35 [INFO]: Epoch 080 - training loss: 0.2604, validation loss: 0.1793
2024-05-25 04:25:36 [INFO]: Epoch 081 - training loss: 0.2587, validation loss: 0.1789
2024-05-25 04:25:36 [INFO]: Epoch 082 - training loss: 0.2592, validation loss: 0.1779
2024-05-25 04:25:37 [INFO]: Epoch 083 - training loss: 0.2564, validation loss: 0.1770
2024-05-25 04:25:38 [INFO]: Epoch 084 - training loss: 0.2569, validation loss: 0.1770
2024-05-25 04:25:38 [INFO]: Epoch 085 - training loss: 0.2557, validation loss: 0.1775
2024-05-25 04:25:39 [INFO]: Epoch 086 - training loss: 0.2550, validation loss: 0.1770
2024-05-25 04:25:40 [INFO]: Epoch 087 - training loss: 0.2537, validation loss: 0.1764
2024-05-25 04:25:40 [INFO]: Epoch 088 - training loss: 0.2543, validation loss: 0.1770
2024-05-25 04:25:41 [INFO]: Epoch 089 - training loss: 0.2531, validation loss: 0.1749
2024-05-25 04:25:42 [INFO]: Epoch 090 - training loss: 0.2522, validation loss: 0.1741
2024-05-25 04:25:42 [INFO]: Epoch 091 - training loss: 0.2519, validation loss: 0.1748
2024-05-25 04:25:43 [INFO]: Epoch 092 - training loss: 0.2510, validation loss: 0.1739
2024-05-25 04:25:44 [INFO]: Epoch 093 - training loss: 0.2503, validation loss: 0.1742
2024-05-25 04:25:44 [INFO]: Epoch 094 - training loss: 0.2513, validation loss: 0.1742
2024-05-25 04:25:45 [INFO]: Epoch 095 - training loss: 0.2496, validation loss: 0.1737
2024-05-25 04:25:46 [INFO]: Epoch 096 - training loss: 0.2489, validation loss: 0.1729
2024-05-25 04:25:46 [INFO]: Epoch 097 - training loss: 0.2482, validation loss: 0.1726
2024-05-25 04:25:47 [INFO]: Epoch 098 - training loss: 0.2477, validation loss: 0.1714
2024-05-25 04:25:48 [INFO]: Epoch 099 - training loss: 0.2476, validation loss: 0.1712
2024-05-25 04:25:48 [INFO]: Epoch 100 - training loss: 0.2466, validation loss: 0.1708
2024-05-25 04:25:49 [INFO]: Epoch 101 - training loss: 0.2450, validation loss: 0.1706
2024-05-25 04:25:50 [INFO]: Epoch 102 - training loss: 0.2445, validation loss: 0.1710
2024-05-25 04:25:50 [INFO]: Epoch 103 - training loss: 0.2440, validation loss: 0.1701
2024-05-25 04:25:51 [INFO]: Epoch 104 - training loss: 0.2453, validation loss: 0.1702
2024-05-25 04:25:52 [INFO]: Epoch 105 - training loss: 0.2436, validation loss: 0.1684
2024-05-25 04:25:53 [INFO]: Epoch 106 - training loss: 0.2441, validation loss: 0.1685
2024-05-25 04:25:53 [INFO]: Epoch 107 - training loss: 0.2435, validation loss: 0.1694
2024-05-25 04:25:54 [INFO]: Epoch 108 - training loss: 0.2432, validation loss: 0.1682
2024-05-25 04:25:55 [INFO]: Epoch 109 - training loss: 0.2434, validation loss: 0.1679
2024-05-25 04:25:55 [INFO]: Epoch 110 - training loss: 0.2421, validation loss: 0.1679
2024-05-25 04:25:56 [INFO]: Epoch 111 - training loss: 0.2409, validation loss: 0.1675
2024-05-25 04:25:57 [INFO]: Epoch 112 - training loss: 0.2412, validation loss: 0.1679
2024-05-25 04:25:57 [INFO]: Epoch 113 - training loss: 0.2408, validation loss: 0.1663
2024-05-25 04:25:58 [INFO]: Epoch 114 - training loss: 0.2399, validation loss: 0.1665
2024-05-25 04:25:59 [INFO]: Epoch 115 - training loss: 0.2381, validation loss: 0.1667
2024-05-25 04:25:59 [INFO]: Epoch 116 - training loss: 0.2388, validation loss: 0.1660
2024-05-25 04:26:00 [INFO]: Epoch 117 - training loss: 0.2371, validation loss: 0.1662
2024-05-25 04:26:01 [INFO]: Epoch 118 - training loss: 0.2366, validation loss: 0.1657
2024-05-25 04:26:01 [INFO]: Epoch 119 - training loss: 0.2355, validation loss: 0.1659
2024-05-25 04:26:02 [INFO]: Epoch 120 - training loss: 0.2362, validation loss: 0.1663
2024-05-25 04:26:03 [INFO]: Epoch 121 - training loss: 0.2361, validation loss: 0.1659
2024-05-25 04:26:03 [INFO]: Epoch 122 - training loss: 0.2360, validation loss: 0.1654
2024-05-25 04:26:04 [INFO]: Epoch 123 - training loss: 0.2349, validation loss: 0.1655
2024-05-25 04:26:05 [INFO]: Epoch 124 - training loss: 0.2348, validation loss: 0.1651
2024-05-25 04:26:05 [INFO]: Epoch 125 - training loss: 0.2341, validation loss: 0.1662
2024-05-25 04:26:06 [INFO]: Epoch 126 - training loss: 0.2354, validation loss: 0.1644
2024-05-25 04:26:07 [INFO]: Epoch 127 - training loss: 0.2337, validation loss: 0.1641
2024-05-25 04:26:07 [INFO]: Epoch 128 - training loss: 0.2329, validation loss: 0.1640
2024-05-25 04:26:08 [INFO]: Epoch 129 - training loss: 0.2333, validation loss: 0.1644
2024-05-25 04:26:09 [INFO]: Epoch 130 - training loss: 0.2341, validation loss: 0.1636
2024-05-25 04:26:09 [INFO]: Epoch 131 - training loss: 0.2325, validation loss: 0.1634
2024-05-25 04:26:10 [INFO]: Epoch 132 - training loss: 0.2311, validation loss: 0.1624
2024-05-25 04:26:11 [INFO]: Epoch 133 - training loss: 0.2306, validation loss: 0.1633
2024-05-25 04:26:11 [INFO]: Epoch 134 - training loss: 0.2297, validation loss: 0.1629
2024-05-25 04:26:12 [INFO]: Epoch 135 - training loss: 0.2297, validation loss: 0.1628
2024-05-25 04:26:13 [INFO]: Epoch 136 - training loss: 0.2297, validation loss: 0.1620
2024-05-25 04:26:13 [INFO]: Epoch 137 - training loss: 0.2281, validation loss: 0.1619
2024-05-25 04:26:14 [INFO]: Epoch 138 - training loss: 0.2300, validation loss: 0.1610
2024-05-25 04:26:15 [INFO]: Epoch 139 - training loss: 0.2288, validation loss: 0.1613
2024-05-25 04:26:15 [INFO]: Epoch 140 - training loss: 0.2273, validation loss: 0.1612
2024-05-25 04:26:16 [INFO]: Epoch 141 - training loss: 0.2274, validation loss: 0.1606
2024-05-25 04:26:17 [INFO]: Epoch 142 - training loss: 0.2268, validation loss: 0.1598
2024-05-25 04:26:17 [INFO]: Epoch 143 - training loss: 0.2261, validation loss: 0.1601
2024-05-25 04:26:18 [INFO]: Epoch 144 - training loss: 0.2279, validation loss: 0.1598
2024-05-25 04:26:19 [INFO]: Epoch 145 - training loss: 0.2274, validation loss: 0.1605
2024-05-25 04:26:19 [INFO]: Epoch 146 - training loss: 0.2263, validation loss: 0.1599
2024-05-25 04:26:20 [INFO]: Epoch 147 - training loss: 0.2261, validation loss: 0.1596
2024-05-25 04:26:21 [INFO]: Epoch 148 - training loss: 0.2253, validation loss: 0.1587
2024-05-25 04:26:21 [INFO]: Epoch 149 - training loss: 0.2252, validation loss: 0.1597
2024-05-25 04:26:22 [INFO]: Epoch 150 - training loss: 0.2249, validation loss: 0.1592
2024-05-25 04:26:23 [INFO]: Epoch 151 - training loss: 0.2233, validation loss: 0.1590
2024-05-25 04:26:23 [INFO]: Epoch 152 - training loss: 0.2223, validation loss: 0.1592
2024-05-25 04:26:24 [INFO]: Epoch 153 - training loss: 0.2226, validation loss: 0.1582
2024-05-25 04:26:25 [INFO]: Epoch 154 - training loss: 0.2231, validation loss: 0.1587
2024-05-25 04:26:25 [INFO]: Epoch 155 - training loss: 0.2234, validation loss: 0.1585
2024-05-25 04:26:26 [INFO]: Epoch 156 - training loss: 0.2232, validation loss: 0.1582
2024-05-25 04:26:27 [INFO]: Epoch 157 - training loss: 0.2230, validation loss: 0.1580
2024-05-25 04:26:27 [INFO]: Epoch 158 - training loss: 0.2223, validation loss: 0.1580
2024-05-25 04:26:28 [INFO]: Epoch 159 - training loss: 0.2220, validation loss: 0.1584
2024-05-25 04:26:29 [INFO]: Epoch 160 - training loss: 0.2216, validation loss: 0.1578
2024-05-25 04:26:29 [INFO]: Epoch 161 - training loss: 0.2205, validation loss: 0.1577
2024-05-25 04:26:30 [INFO]: Epoch 162 - training loss: 0.2194, validation loss: 0.1573
2024-05-25 04:26:31 [INFO]: Epoch 163 - training loss: 0.2200, validation loss: 0.1575
2024-05-25 04:26:31 [INFO]: Epoch 164 - training loss: 0.2196, validation loss: 0.1574
2024-05-25 04:26:32 [INFO]: Epoch 165 - training loss: 0.2193, validation loss: 0.1571
2024-05-25 04:26:33 [INFO]: Epoch 166 - training loss: 0.2188, validation loss: 0.1566
2024-05-25 04:26:33 [INFO]: Epoch 167 - training loss: 0.2192, validation loss: 0.1578
2024-05-25 04:26:34 [INFO]: Epoch 168 - training loss: 0.2193, validation loss: 0.1566
2024-05-25 04:26:35 [INFO]: Epoch 169 - training loss: 0.2179, validation loss: 0.1563
2024-05-25 04:26:35 [INFO]: Epoch 170 - training loss: 0.2175, validation loss: 0.1557
2024-05-25 04:26:36 [INFO]: Epoch 171 - training loss: 0.2189, validation loss: 0.1558
2024-05-25 04:26:37 [INFO]: Epoch 172 - training loss: 0.2196, validation loss: 0.1562
2024-05-25 04:26:37 [INFO]: Epoch 173 - training loss: 0.2185, validation loss: 0.1564
2024-05-25 04:26:38 [INFO]: Epoch 174 - training loss: 0.2177, validation loss: 0.1555
2024-05-25 04:26:39 [INFO]: Epoch 175 - training loss: 0.2159, validation loss: 0.1562
2024-05-25 04:26:39 [INFO]: Epoch 176 - training loss: 0.2154, validation loss: 0.1562
2024-05-25 04:26:40 [INFO]: Epoch 177 - training loss: 0.2148, validation loss: 0.1555
2024-05-25 04:26:41 [INFO]: Epoch 178 - training loss: 0.2154, validation loss: 0.1554
2024-05-25 04:26:41 [INFO]: Epoch 179 - training loss: 0.2153, validation loss: 0.1553
2024-05-25 04:26:42 [INFO]: Epoch 180 - training loss: 0.2138, validation loss: 0.1548
2024-05-25 04:26:43 [INFO]: Epoch 181 - training loss: 0.2146, validation loss: 0.1550
2024-05-25 04:26:43 [INFO]: Epoch 182 - training loss: 0.2162, validation loss: 0.1554
2024-05-25 04:26:44 [INFO]: Epoch 183 - training loss: 0.2150, validation loss: 0.1549
2024-05-25 04:26:45 [INFO]: Epoch 184 - training loss: 0.2136, validation loss: 0.1555
2024-05-25 04:26:45 [INFO]: Epoch 185 - training loss: 0.2119, validation loss: 0.1548
2024-05-25 04:26:46 [INFO]: Epoch 186 - training loss: 0.2125, validation loss: 0.1548
2024-05-25 04:26:47 [INFO]: Epoch 187 - training loss: 0.2136, validation loss: 0.1554
2024-05-25 04:26:47 [INFO]: Epoch 188 - training loss: 0.2139, validation loss: 0.1556
2024-05-25 04:26:48 [INFO]: Epoch 189 - training loss: 0.2124, validation loss: 0.1550
2024-05-25 04:26:49 [INFO]: Epoch 190 - training loss: 0.2135, validation loss: 0.1552
2024-05-25 04:26:49 [INFO]: Epoch 191 - training loss: 0.2114, validation loss: 0.1549
2024-05-25 04:26:50 [INFO]: Epoch 192 - training loss: 0.2109, validation loss: 0.1538
2024-05-25 04:26:51 [INFO]: Epoch 193 - training loss: 0.2103, validation loss: 0.1540
2024-05-25 04:26:51 [INFO]: Epoch 194 - training loss: 0.2104, validation loss: 0.1549
2024-05-25 04:26:52 [INFO]: Epoch 195 - training loss: 0.2111, validation loss: 0.1533
2024-05-25 04:26:53 [INFO]: Epoch 196 - training loss: 0.2109, validation loss: 0.1540
2024-05-25 04:26:53 [INFO]: Epoch 197 - training loss: 0.2110, validation loss: 0.1535
2024-05-25 04:26:54 [INFO]: Epoch 198 - training loss: 0.2101, validation loss: 0.1549
2024-05-25 04:26:55 [INFO]: Epoch 199 - training loss: 0.2112, validation loss: 0.1539
2024-05-25 04:26:55 [INFO]: Epoch 200 - training loss: 0.2092, validation loss: 0.1533
2024-05-25 04:26:56 [INFO]: Epoch 201 - training loss: 0.2102, validation loss: 0.1535
2024-05-25 04:26:57 [INFO]: Epoch 202 - training loss: 0.2095, validation loss: 0.1533
2024-05-25 04:26:57 [INFO]: Epoch 203 - training loss: 0.2087, validation loss: 0.1531
2024-05-25 04:26:58 [INFO]: Epoch 204 - training loss: 0.2087, validation loss: 0.1540
2024-05-25 04:26:59 [INFO]: Epoch 205 - training loss: 0.2082, validation loss: 0.1531
2024-05-25 04:26:59 [INFO]: Epoch 206 - training loss: 0.2075, validation loss: 0.1532
2024-05-25 04:27:00 [INFO]: Epoch 207 - training loss: 0.2080, validation loss: 0.1531
2024-05-25 04:27:01 [INFO]: Epoch 208 - training loss: 0.2076, validation loss: 0.1536
2024-05-25 04:27:01 [INFO]: Epoch 209 - training loss: 0.2080, validation loss: 0.1534
2024-05-25 04:27:02 [INFO]: Epoch 210 - training loss: 0.2058, validation loss: 0.1533
2024-05-25 04:27:03 [INFO]: Epoch 211 - training loss: 0.2068, validation loss: 0.1532
2024-05-25 04:27:03 [INFO]: Epoch 212 - training loss: 0.2070, validation loss: 0.1538
2024-05-25 04:27:04 [INFO]: Epoch 213 - training loss: 0.2068, validation loss: 0.1528
2024-05-25 04:27:05 [INFO]: Epoch 214 - training loss: 0.2068, validation loss: 0.1525
2024-05-25 04:27:05 [INFO]: Epoch 215 - training loss: 0.2060, validation loss: 0.1536
2024-05-25 04:27:06 [INFO]: Epoch 216 - training loss: 0.2061, validation loss: 0.1535
2024-05-25 04:27:07 [INFO]: Epoch 217 - training loss: 0.2082, validation loss: 0.1537
2024-05-25 04:27:07 [INFO]: Epoch 218 - training loss: 0.2070, validation loss: 0.1533
2024-05-25 04:27:08 [INFO]: Epoch 219 - training loss: 0.2063, validation loss: 0.1528
2024-05-25 04:27:09 [INFO]: Epoch 220 - training loss: 0.2057, validation loss: 0.1519
2024-05-25 04:27:09 [INFO]: Epoch 221 - training loss: 0.2040, validation loss: 0.1528
2024-05-25 04:27:10 [INFO]: Epoch 222 - training loss: 0.2035, validation loss: 0.1525
2024-05-25 04:27:11 [INFO]: Epoch 223 - training loss: 0.2042, validation loss: 0.1521
2024-05-25 04:27:11 [INFO]: Epoch 224 - training loss: 0.2030, validation loss: 0.1520
2024-05-25 04:27:12 [INFO]: Epoch 225 - training loss: 0.2021, validation loss: 0.1524
2024-05-25 04:27:13 [INFO]: Epoch 226 - training loss: 0.2044, validation loss: 0.1522
2024-05-25 04:27:13 [INFO]: Epoch 227 - training loss: 0.2049, validation loss: 0.1525
2024-05-25 04:27:14 [INFO]: Epoch 228 - training loss: 0.2053, validation loss: 0.1523
2024-05-25 04:27:15 [INFO]: Epoch 229 - training loss: 0.2030, validation loss: 0.1520
2024-05-25 04:27:15 [INFO]: Epoch 230 - training loss: 0.2033, validation loss: 0.1521
2024-05-25 04:27:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:27:15 [INFO]: Finished training. The best model is from epoch#220.
2024-05-25 04:27:16 [INFO]: Saved the model to augmentation_saved_results/round_4/SAITS_air_quality/20240525_T042441/SAITS.pypots
2024-05-25 04:27:16 [INFO]: SAITS on Air-Quality: MAE=0.1436, MSE=0.0917
2024-05-25 04:27:16 [INFO]: Successfully saved to augmentation_saved_results/round_4/SAITS_air_quality/imputation.pkl
2024-05-25 04:27:16 [INFO]: Using the given device: cuda:0
2024-05-25 04:27:16 [INFO]: Model files will be saved to augmentation_saved_results/round_4/Transformer_air_quality/20240525_T042716
2024-05-25 04:27:16 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/Transformer_air_quality/20240525_T042716/tensorboard
2024-05-25 04:27:16 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 04:27:16 [INFO]: Epoch 001 - training loss: 0.9244, validation loss: 0.4893
2024-05-25 04:27:16 [INFO]: Epoch 002 - training loss: 0.5750, validation loss: 0.3874
2024-05-25 04:27:17 [INFO]: Epoch 003 - training loss: 0.4863, validation loss: 0.3298
2024-05-25 04:27:17 [INFO]: Epoch 004 - training loss: 0.4379, validation loss: 0.3016
2024-05-25 04:27:17 [INFO]: Epoch 005 - training loss: 0.4082, validation loss: 0.2867
2024-05-25 04:27:18 [INFO]: Epoch 006 - training loss: 0.3940, validation loss: 0.2771
2024-05-25 04:27:18 [INFO]: Epoch 007 - training loss: 0.3771, validation loss: 0.2725
2024-05-25 04:27:18 [INFO]: Epoch 008 - training loss: 0.3655, validation loss: 0.2635
2024-05-25 04:27:19 [INFO]: Epoch 009 - training loss: 0.3560, validation loss: 0.2606
2024-05-25 04:27:19 [INFO]: Epoch 010 - training loss: 0.3470, validation loss: 0.2557
2024-05-25 04:27:19 [INFO]: Epoch 011 - training loss: 0.3448, validation loss: 0.2522
2024-05-25 04:27:20 [INFO]: Epoch 012 - training loss: 0.3368, validation loss: 0.2491
2024-05-25 04:27:20 [INFO]: Epoch 013 - training loss: 0.3357, validation loss: 0.2465
2024-05-25 04:27:20 [INFO]: Epoch 014 - training loss: 0.3286, validation loss: 0.2422
2024-05-25 04:27:21 [INFO]: Epoch 015 - training loss: 0.3223, validation loss: 0.2404
2024-05-25 04:27:21 [INFO]: Epoch 016 - training loss: 0.3196, validation loss: 0.2364
2024-05-25 04:27:21 [INFO]: Epoch 017 - training loss: 0.3193, validation loss: 0.2317
2024-05-25 04:27:21 [INFO]: Epoch 018 - training loss: 0.3140, validation loss: 0.2297
2024-05-25 04:27:22 [INFO]: Epoch 019 - training loss: 0.3103, validation loss: 0.2267
2024-05-25 04:27:22 [INFO]: Epoch 020 - training loss: 0.3064, validation loss: 0.2250
2024-05-25 04:27:22 [INFO]: Epoch 021 - training loss: 0.3059, validation loss: 0.2242
2024-05-25 04:27:23 [INFO]: Epoch 022 - training loss: 0.3093, validation loss: 0.2204
2024-05-25 04:27:23 [INFO]: Epoch 023 - training loss: 0.3042, validation loss: 0.2194
2024-05-25 04:27:23 [INFO]: Epoch 024 - training loss: 0.2982, validation loss: 0.2179
2024-05-25 04:27:24 [INFO]: Epoch 025 - training loss: 0.2958, validation loss: 0.2166
2024-05-25 04:27:24 [INFO]: Epoch 026 - training loss: 0.2934, validation loss: 0.2144
2024-05-25 04:27:24 [INFO]: Epoch 027 - training loss: 0.2931, validation loss: 0.2141
2024-05-25 04:27:25 [INFO]: Epoch 028 - training loss: 0.2902, validation loss: 0.2147
2024-05-25 04:27:25 [INFO]: Epoch 029 - training loss: 0.2892, validation loss: 0.2131
2024-05-25 04:27:25 [INFO]: Epoch 030 - training loss: 0.2858, validation loss: 0.2108
2024-05-25 04:27:26 [INFO]: Epoch 031 - training loss: 0.2838, validation loss: 0.2109
2024-05-25 04:27:26 [INFO]: Epoch 032 - training loss: 0.2840, validation loss: 0.2106
2024-05-25 04:27:26 [INFO]: Epoch 033 - training loss: 0.2830, validation loss: 0.2105
2024-05-25 04:27:27 [INFO]: Epoch 034 - training loss: 0.2811, validation loss: 0.2082
2024-05-25 04:27:27 [INFO]: Epoch 035 - training loss: 0.2803, validation loss: 0.2084
2024-05-25 04:27:27 [INFO]: Epoch 036 - training loss: 0.2783, validation loss: 0.2086
2024-05-25 04:27:27 [INFO]: Epoch 037 - training loss: 0.2764, validation loss: 0.2070
2024-05-25 04:27:28 [INFO]: Epoch 038 - training loss: 0.2754, validation loss: 0.2082
2024-05-25 04:27:28 [INFO]: Epoch 039 - training loss: 0.2748, validation loss: 0.2060
2024-05-25 04:27:28 [INFO]: Epoch 040 - training loss: 0.2749, validation loss: 0.2071
2024-05-25 04:27:29 [INFO]: Epoch 041 - training loss: 0.2739, validation loss: 0.2066
2024-05-25 04:27:29 [INFO]: Epoch 042 - training loss: 0.2712, validation loss: 0.2051
2024-05-25 04:27:29 [INFO]: Epoch 043 - training loss: 0.2697, validation loss: 0.2052
2024-05-25 04:27:30 [INFO]: Epoch 044 - training loss: 0.2693, validation loss: 0.2030
2024-05-25 04:27:30 [INFO]: Epoch 045 - training loss: 0.2686, validation loss: 0.2033
2024-05-25 04:27:30 [INFO]: Epoch 046 - training loss: 0.2710, validation loss: 0.2031
2024-05-25 04:27:31 [INFO]: Epoch 047 - training loss: 0.2718, validation loss: 0.2040
2024-05-25 04:27:31 [INFO]: Epoch 048 - training loss: 0.2657, validation loss: 0.2024
2024-05-25 04:27:31 [INFO]: Epoch 049 - training loss: 0.2647, validation loss: 0.2028
2024-05-25 04:27:32 [INFO]: Epoch 050 - training loss: 0.2665, validation loss: 0.2019
2024-05-25 04:27:32 [INFO]: Epoch 051 - training loss: 0.2641, validation loss: 0.2011
2024-05-25 04:27:32 [INFO]: Epoch 052 - training loss: 0.2610, validation loss: 0.1996
2024-05-25 04:27:32 [INFO]: Epoch 053 - training loss: 0.2635, validation loss: 0.1986
2024-05-25 04:27:33 [INFO]: Epoch 054 - training loss: 0.2613, validation loss: 0.2009
2024-05-25 04:27:33 [INFO]: Epoch 055 - training loss: 0.2609, validation loss: 0.1991
2024-05-25 04:27:33 [INFO]: Epoch 056 - training loss: 0.2592, validation loss: 0.1981
2024-05-25 04:27:34 [INFO]: Epoch 057 - training loss: 0.2571, validation loss: 0.1986
2024-05-25 04:27:34 [INFO]: Epoch 058 - training loss: 0.2561, validation loss: 0.1985
2024-05-25 04:27:34 [INFO]: Epoch 059 - training loss: 0.2567, validation loss: 0.1958
2024-05-25 04:27:35 [INFO]: Epoch 060 - training loss: 0.2539, validation loss: 0.1978
2024-05-25 04:27:35 [INFO]: Epoch 061 - training loss: 0.2549, validation loss: 0.1973
2024-05-25 04:27:35 [INFO]: Epoch 062 - training loss: 0.2551, validation loss: 0.1957
2024-05-25 04:27:36 [INFO]: Epoch 063 - training loss: 0.2541, validation loss: 0.1986
2024-05-25 04:27:36 [INFO]: Epoch 064 - training loss: 0.2534, validation loss: 0.1949
2024-05-25 04:27:36 [INFO]: Epoch 065 - training loss: 0.2525, validation loss: 0.1956
2024-05-25 04:27:37 [INFO]: Epoch 066 - training loss: 0.2509, validation loss: 0.1941
2024-05-25 04:27:37 [INFO]: Epoch 067 - training loss: 0.2522, validation loss: 0.1953
2024-05-25 04:27:37 [INFO]: Epoch 068 - training loss: 0.2492, validation loss: 0.1930
2024-05-25 04:27:38 [INFO]: Epoch 069 - training loss: 0.2484, validation loss: 0.1952
2024-05-25 04:27:38 [INFO]: Epoch 070 - training loss: 0.2479, validation loss: 0.1931
2024-05-25 04:27:38 [INFO]: Epoch 071 - training loss: 0.2491, validation loss: 0.1926
2024-05-25 04:27:38 [INFO]: Epoch 072 - training loss: 0.2474, validation loss: 0.1921
2024-05-25 04:27:39 [INFO]: Epoch 073 - training loss: 0.2477, validation loss: 0.1924
2024-05-25 04:27:39 [INFO]: Epoch 074 - training loss: 0.2460, validation loss: 0.1943
2024-05-25 04:27:39 [INFO]: Epoch 075 - training loss: 0.2433, validation loss: 0.1921
2024-05-25 04:27:40 [INFO]: Epoch 076 - training loss: 0.2431, validation loss: 0.1910
2024-05-25 04:27:40 [INFO]: Epoch 077 - training loss: 0.2452, validation loss: 0.1895
2024-05-25 04:27:40 [INFO]: Epoch 078 - training loss: 0.2455, validation loss: 0.1922
2024-05-25 04:27:41 [INFO]: Epoch 079 - training loss: 0.2432, validation loss: 0.1892
2024-05-25 04:27:41 [INFO]: Epoch 080 - training loss: 0.2407, validation loss: 0.1899
2024-05-25 04:27:41 [INFO]: Epoch 081 - training loss: 0.2385, validation loss: 0.1890
2024-05-25 04:27:42 [INFO]: Epoch 082 - training loss: 0.2387, validation loss: 0.1903
2024-05-25 04:27:42 [INFO]: Epoch 083 - training loss: 0.2397, validation loss: 0.1876
2024-05-25 04:27:42 [INFO]: Epoch 084 - training loss: 0.2395, validation loss: 0.1856
2024-05-25 04:27:43 [INFO]: Epoch 085 - training loss: 0.2371, validation loss: 0.1881
2024-05-25 04:27:43 [INFO]: Epoch 086 - training loss: 0.2369, validation loss: 0.1860
2024-05-25 04:27:43 [INFO]: Epoch 087 - training loss: 0.2367, validation loss: 0.1861
2024-05-25 04:27:44 [INFO]: Epoch 088 - training loss: 0.2387, validation loss: 0.1861
2024-05-25 04:27:44 [INFO]: Epoch 089 - training loss: 0.2376, validation loss: 0.1851
2024-05-25 04:27:44 [INFO]: Epoch 090 - training loss: 0.2350, validation loss: 0.1853
2024-05-25 04:27:44 [INFO]: Epoch 091 - training loss: 0.2332, validation loss: 0.1853
2024-05-25 04:27:45 [INFO]: Epoch 092 - training loss: 0.2325, validation loss: 0.1854
2024-05-25 04:27:45 [INFO]: Epoch 093 - training loss: 0.2313, validation loss: 0.1835
2024-05-25 04:27:45 [INFO]: Epoch 094 - training loss: 0.2304, validation loss: 0.1835
2024-05-25 04:27:46 [INFO]: Epoch 095 - training loss: 0.2314, validation loss: 0.1849
2024-05-25 04:27:46 [INFO]: Epoch 096 - training loss: 0.2310, validation loss: 0.1854
2024-05-25 04:27:46 [INFO]: Epoch 097 - training loss: 0.2299, validation loss: 0.1844
2024-05-25 04:27:47 [INFO]: Epoch 098 - training loss: 0.2341, validation loss: 0.1829
2024-05-25 04:27:47 [INFO]: Epoch 099 - training loss: 0.2332, validation loss: 0.1827
2024-05-25 04:27:47 [INFO]: Epoch 100 - training loss: 0.2292, validation loss: 0.1820
2024-05-25 04:27:48 [INFO]: Epoch 101 - training loss: 0.2297, validation loss: 0.1812
2024-05-25 04:27:48 [INFO]: Epoch 102 - training loss: 0.2275, validation loss: 0.1833
2024-05-25 04:27:48 [INFO]: Epoch 103 - training loss: 0.2281, validation loss: 0.1816
2024-05-25 04:27:49 [INFO]: Epoch 104 - training loss: 0.2278, validation loss: 0.1809
2024-05-25 04:27:49 [INFO]: Epoch 105 - training loss: 0.2298, validation loss: 0.1796
2024-05-25 04:27:49 [INFO]: Epoch 106 - training loss: 0.2297, validation loss: 0.1804
2024-05-25 04:27:50 [INFO]: Epoch 107 - training loss: 0.2307, validation loss: 0.1795
2024-05-25 04:27:50 [INFO]: Epoch 108 - training loss: 0.2338, validation loss: 0.1795
2024-05-25 04:27:50 [INFO]: Epoch 109 - training loss: 0.2276, validation loss: 0.1795
2024-05-25 04:27:50 [INFO]: Epoch 110 - training loss: 0.2233, validation loss: 0.1790
2024-05-25 04:27:51 [INFO]: Epoch 111 - training loss: 0.2252, validation loss: 0.1769
2024-05-25 04:27:51 [INFO]: Epoch 112 - training loss: 0.2228, validation loss: 0.1788
2024-05-25 04:27:51 [INFO]: Epoch 113 - training loss: 0.2274, validation loss: 0.1815
2024-05-25 04:27:52 [INFO]: Epoch 114 - training loss: 0.2254, validation loss: 0.1805
2024-05-25 04:27:52 [INFO]: Epoch 115 - training loss: 0.2241, validation loss: 0.1785
2024-05-25 04:27:52 [INFO]: Epoch 116 - training loss: 0.2208, validation loss: 0.1783
2024-05-25 04:27:53 [INFO]: Epoch 117 - training loss: 0.2228, validation loss: 0.1777
2024-05-25 04:27:53 [INFO]: Epoch 118 - training loss: 0.2215, validation loss: 0.1781
2024-05-25 04:27:53 [INFO]: Epoch 119 - training loss: 0.2200, validation loss: 0.1770
2024-05-25 04:27:54 [INFO]: Epoch 120 - training loss: 0.2245, validation loss: 0.1784
2024-05-25 04:27:54 [INFO]: Epoch 121 - training loss: 0.2214, validation loss: 0.1767
2024-05-25 04:27:54 [INFO]: Epoch 122 - training loss: 0.2187, validation loss: 0.1765
2024-05-25 04:27:55 [INFO]: Epoch 123 - training loss: 0.2174, validation loss: 0.1757
2024-05-25 04:27:55 [INFO]: Epoch 124 - training loss: 0.2173, validation loss: 0.1763
2024-05-25 04:27:55 [INFO]: Epoch 125 - training loss: 0.2177, validation loss: 0.1770
2024-05-25 04:27:56 [INFO]: Epoch 126 - training loss: 0.2191, validation loss: 0.1763
2024-05-25 04:27:56 [INFO]: Epoch 127 - training loss: 0.2178, validation loss: 0.1754
2024-05-25 04:27:56 [INFO]: Epoch 128 - training loss: 0.2189, validation loss: 0.1757
2024-05-25 04:27:56 [INFO]: Epoch 129 - training loss: 0.2165, validation loss: 0.1749
2024-05-25 04:27:57 [INFO]: Epoch 130 - training loss: 0.2181, validation loss: 0.1754
2024-05-25 04:27:57 [INFO]: Epoch 131 - training loss: 0.2179, validation loss: 0.1757
2024-05-25 04:27:57 [INFO]: Epoch 132 - training loss: 0.2154, validation loss: 0.1754
2024-05-25 04:27:58 [INFO]: Epoch 133 - training loss: 0.2150, validation loss: 0.1745
2024-05-25 04:27:58 [INFO]: Epoch 134 - training loss: 0.2139, validation loss: 0.1759
2024-05-25 04:27:58 [INFO]: Epoch 135 - training loss: 0.2139, validation loss: 0.1743
2024-05-25 04:27:59 [INFO]: Epoch 136 - training loss: 0.2136, validation loss: 0.1755
2024-05-25 04:27:59 [INFO]: Epoch 137 - training loss: 0.2135, validation loss: 0.1753
2024-05-25 04:27:59 [INFO]: Epoch 138 - training loss: 0.2147, validation loss: 0.1774
2024-05-25 04:28:00 [INFO]: Epoch 139 - training loss: 0.2130, validation loss: 0.1738
2024-05-25 04:28:00 [INFO]: Epoch 140 - training loss: 0.2127, validation loss: 0.1741
2024-05-25 04:28:00 [INFO]: Epoch 141 - training loss: 0.2125, validation loss: 0.1742
2024-05-25 04:28:01 [INFO]: Epoch 142 - training loss: 0.2129, validation loss: 0.1749
2024-05-25 04:28:01 [INFO]: Epoch 143 - training loss: 0.2132, validation loss: 0.1727
2024-05-25 04:28:01 [INFO]: Epoch 144 - training loss: 0.2122, validation loss: 0.1736
2024-05-25 04:28:02 [INFO]: Epoch 145 - training loss: 0.2111, validation loss: 0.1734
2024-05-25 04:28:02 [INFO]: Epoch 146 - training loss: 0.2120, validation loss: 0.1730
2024-05-25 04:28:02 [INFO]: Epoch 147 - training loss: 0.2119, validation loss: 0.1716
2024-05-25 04:28:02 [INFO]: Epoch 148 - training loss: 0.2083, validation loss: 0.1740
2024-05-25 04:28:03 [INFO]: Epoch 149 - training loss: 0.2089, validation loss: 0.1723
2024-05-25 04:28:03 [INFO]: Epoch 150 - training loss: 0.2113, validation loss: 0.1736
2024-05-25 04:28:03 [INFO]: Epoch 151 - training loss: 0.2114, validation loss: 0.1726
2024-05-25 04:28:04 [INFO]: Epoch 152 - training loss: 0.2084, validation loss: 0.1725
2024-05-25 04:28:04 [INFO]: Epoch 153 - training loss: 0.2079, validation loss: 0.1738
2024-05-25 04:28:04 [INFO]: Epoch 154 - training loss: 0.2093, validation loss: 0.1725
2024-05-25 04:28:05 [INFO]: Epoch 155 - training loss: 0.2074, validation loss: 0.1700
2024-05-25 04:28:05 [INFO]: Epoch 156 - training loss: 0.2057, validation loss: 0.1721
2024-05-25 04:28:05 [INFO]: Epoch 157 - training loss: 0.2056, validation loss: 0.1723
2024-05-25 04:28:06 [INFO]: Epoch 158 - training loss: 0.2075, validation loss: 0.1719
2024-05-25 04:28:06 [INFO]: Epoch 159 - training loss: 0.2075, validation loss: 0.1707
2024-05-25 04:28:06 [INFO]: Epoch 160 - training loss: 0.2068, validation loss: 0.1709
2024-05-25 04:28:07 [INFO]: Epoch 161 - training loss: 0.2069, validation loss: 0.1717
2024-05-25 04:28:07 [INFO]: Epoch 162 - training loss: 0.2054, validation loss: 0.1699
2024-05-25 04:28:07 [INFO]: Epoch 163 - training loss: 0.2067, validation loss: 0.1696
2024-05-25 04:28:07 [INFO]: Epoch 164 - training loss: 0.2053, validation loss: 0.1699
2024-05-25 04:28:08 [INFO]: Epoch 165 - training loss: 0.2062, validation loss: 0.1704
2024-05-25 04:28:08 [INFO]: Epoch 166 - training loss: 0.2053, validation loss: 0.1701
2024-05-25 04:28:08 [INFO]: Epoch 167 - training loss: 0.2050, validation loss: 0.1702
2024-05-25 04:28:09 [INFO]: Epoch 168 - training loss: 0.2055, validation loss: 0.1702
2024-05-25 04:28:09 [INFO]: Epoch 169 - training loss: 0.2074, validation loss: 0.1700
2024-05-25 04:28:09 [INFO]: Epoch 170 - training loss: 0.2061, validation loss: 0.1689
2024-05-25 04:28:10 [INFO]: Epoch 171 - training loss: 0.2023, validation loss: 0.1695
2024-05-25 04:28:10 [INFO]: Epoch 172 - training loss: 0.2030, validation loss: 0.1692
2024-05-25 04:28:10 [INFO]: Epoch 173 - training loss: 0.2036, validation loss: 0.1688
2024-05-25 04:28:11 [INFO]: Epoch 174 - training loss: 0.2052, validation loss: 0.1711
2024-05-25 04:28:11 [INFO]: Epoch 175 - training loss: 0.2065, validation loss: 0.1701
2024-05-25 04:28:11 [INFO]: Epoch 176 - training loss: 0.2038, validation loss: 0.1683
2024-05-25 04:28:12 [INFO]: Epoch 177 - training loss: 0.2019, validation loss: 0.1692
2024-05-25 04:28:12 [INFO]: Epoch 178 - training loss: 0.2020, validation loss: 0.1671
2024-05-25 04:28:12 [INFO]: Epoch 179 - training loss: 0.2005, validation loss: 0.1678
2024-05-25 04:28:13 [INFO]: Epoch 180 - training loss: 0.1999, validation loss: 0.1674
2024-05-25 04:28:13 [INFO]: Epoch 181 - training loss: 0.2029, validation loss: 0.1682
2024-05-25 04:28:13 [INFO]: Epoch 182 - training loss: 0.2009, validation loss: 0.1687
2024-05-25 04:28:13 [INFO]: Epoch 183 - training loss: 0.1995, validation loss: 0.1671
2024-05-25 04:28:14 [INFO]: Epoch 184 - training loss: 0.1989, validation loss: 0.1686
2024-05-25 04:28:14 [INFO]: Epoch 185 - training loss: 0.2009, validation loss: 0.1676
2024-05-25 04:28:14 [INFO]: Epoch 186 - training loss: 0.2005, validation loss: 0.1682
2024-05-25 04:28:15 [INFO]: Epoch 187 - training loss: 0.2002, validation loss: 0.1685
2024-05-25 04:28:15 [INFO]: Epoch 188 - training loss: 0.2006, validation loss: 0.1664
2024-05-25 04:28:15 [INFO]: Epoch 189 - training loss: 0.2011, validation loss: 0.1675
2024-05-25 04:28:16 [INFO]: Epoch 190 - training loss: 0.2013, validation loss: 0.1698
2024-05-25 04:28:16 [INFO]: Epoch 191 - training loss: 0.2004, validation loss: 0.1687
2024-05-25 04:28:16 [INFO]: Epoch 192 - training loss: 0.2005, validation loss: 0.1679
2024-05-25 04:28:17 [INFO]: Epoch 193 - training loss: 0.1995, validation loss: 0.1682
2024-05-25 04:28:17 [INFO]: Epoch 194 - training loss: 0.1987, validation loss: 0.1671
2024-05-25 04:28:17 [INFO]: Epoch 195 - training loss: 0.1997, validation loss: 0.1668
2024-05-25 04:28:18 [INFO]: Epoch 196 - training loss: 0.1991, validation loss: 0.1681
2024-05-25 04:28:18 [INFO]: Epoch 197 - training loss: 0.2003, validation loss: 0.1677
2024-05-25 04:28:18 [INFO]: Epoch 198 - training loss: 0.1963, validation loss: 0.1660
2024-05-25 04:28:19 [INFO]: Epoch 199 - training loss: 0.1988, validation loss: 0.1672
2024-05-25 04:28:19 [INFO]: Epoch 200 - training loss: 0.2007, validation loss: 0.1661
2024-05-25 04:28:19 [INFO]: Epoch 201 - training loss: 0.1964, validation loss: 0.1662
2024-05-25 04:28:19 [INFO]: Epoch 202 - training loss: 0.1967, validation loss: 0.1666
2024-05-25 04:28:20 [INFO]: Epoch 203 - training loss: 0.1950, validation loss: 0.1660
2024-05-25 04:28:20 [INFO]: Epoch 204 - training loss: 0.1949, validation loss: 0.1660
2024-05-25 04:28:20 [INFO]: Epoch 205 - training loss: 0.1950, validation loss: 0.1653
2024-05-25 04:28:21 [INFO]: Epoch 206 - training loss: 0.1986, validation loss: 0.1671
2024-05-25 04:28:21 [INFO]: Epoch 207 - training loss: 0.1978, validation loss: 0.1662
2024-05-25 04:28:21 [INFO]: Epoch 208 - training loss: 0.1967, validation loss: 0.1671
2024-05-25 04:28:22 [INFO]: Epoch 209 - training loss: 0.1943, validation loss: 0.1656
2024-05-25 04:28:22 [INFO]: Epoch 210 - training loss: 0.1954, validation loss: 0.1653
2024-05-25 04:28:22 [INFO]: Epoch 211 - training loss: 0.1955, validation loss: 0.1654
2024-05-25 04:28:23 [INFO]: Epoch 212 - training loss: 0.1966, validation loss: 0.1651
2024-05-25 04:28:23 [INFO]: Epoch 213 - training loss: 0.1939, validation loss: 0.1652
2024-05-25 04:28:23 [INFO]: Epoch 214 - training loss: 0.1919, validation loss: 0.1655
2024-05-25 04:28:24 [INFO]: Epoch 215 - training loss: 0.1934, validation loss: 0.1643
2024-05-25 04:28:24 [INFO]: Epoch 216 - training loss: 0.1957, validation loss: 0.1693
2024-05-25 04:28:24 [INFO]: Epoch 217 - training loss: 0.1958, validation loss: 0.1643
2024-05-25 04:28:24 [INFO]: Epoch 218 - training loss: 0.1970, validation loss: 0.1652
2024-05-25 04:28:25 [INFO]: Epoch 219 - training loss: 0.1947, validation loss: 0.1640
2024-05-25 04:28:25 [INFO]: Epoch 220 - training loss: 0.1928, validation loss: 0.1663
2024-05-25 04:28:25 [INFO]: Epoch 221 - training loss: 0.1941, validation loss: 0.1638
2024-05-25 04:28:26 [INFO]: Epoch 222 - training loss: 0.1892, validation loss: 0.1643
2024-05-25 04:28:26 [INFO]: Epoch 223 - training loss: 0.1897, validation loss: 0.1642
2024-05-25 04:28:26 [INFO]: Epoch 224 - training loss: 0.1902, validation loss: 0.1636
2024-05-25 04:28:27 [INFO]: Epoch 225 - training loss: 0.1899, validation loss: 0.1651
2024-05-25 04:28:27 [INFO]: Epoch 226 - training loss: 0.1905, validation loss: 0.1648
2024-05-25 04:28:27 [INFO]: Epoch 227 - training loss: 0.1908, validation loss: 0.1642
2024-05-25 04:28:28 [INFO]: Epoch 228 - training loss: 0.1895, validation loss: 0.1647
2024-05-25 04:28:28 [INFO]: Epoch 229 - training loss: 0.1890, validation loss: 0.1636
2024-05-25 04:28:28 [INFO]: Epoch 230 - training loss: 0.1894, validation loss: 0.1631
2024-05-25 04:28:29 [INFO]: Epoch 231 - training loss: 0.1907, validation loss: 0.1634
2024-05-25 04:28:29 [INFO]: Epoch 232 - training loss: 0.1905, validation loss: 0.1628
2024-05-25 04:28:29 [INFO]: Epoch 233 - training loss: 0.1921, validation loss: 0.1629
2024-05-25 04:28:30 [INFO]: Epoch 234 - training loss: 0.1896, validation loss: 0.1630
2024-05-25 04:28:30 [INFO]: Epoch 235 - training loss: 0.1905, validation loss: 0.1646
2024-05-25 04:28:30 [INFO]: Epoch 236 - training loss: 0.1890, validation loss: 0.1642
2024-05-25 04:28:30 [INFO]: Epoch 237 - training loss: 0.1875, validation loss: 0.1633
2024-05-25 04:28:31 [INFO]: Epoch 238 - training loss: 0.1867, validation loss: 0.1624
2024-05-25 04:28:31 [INFO]: Epoch 239 - training loss: 0.1881, validation loss: 0.1628
2024-05-25 04:28:31 [INFO]: Epoch 240 - training loss: 0.1880, validation loss: 0.1639
2024-05-25 04:28:32 [INFO]: Epoch 241 - training loss: 0.1893, validation loss: 0.1630
2024-05-25 04:28:32 [INFO]: Epoch 242 - training loss: 0.1881, validation loss: 0.1631
2024-05-25 04:28:32 [INFO]: Epoch 243 - training loss: 0.1888, validation loss: 0.1625
2024-05-25 04:28:33 [INFO]: Epoch 244 - training loss: 0.1881, validation loss: 0.1618
2024-05-25 04:28:33 [INFO]: Epoch 245 - training loss: 0.1895, validation loss: 0.1633
2024-05-25 04:28:33 [INFO]: Epoch 246 - training loss: 0.1864, validation loss: 0.1630
2024-05-25 04:28:34 [INFO]: Epoch 247 - training loss: 0.1869, validation loss: 0.1626
2024-05-25 04:28:34 [INFO]: Epoch 248 - training loss: 0.1865, validation loss: 0.1611
2024-05-25 04:28:34 [INFO]: Epoch 249 - training loss: 0.1861, validation loss: 0.1619
2024-05-25 04:28:35 [INFO]: Epoch 250 - training loss: 0.1856, validation loss: 0.1606
2024-05-25 04:28:35 [INFO]: Epoch 251 - training loss: 0.1865, validation loss: 0.1612
2024-05-25 04:28:35 [INFO]: Epoch 252 - training loss: 0.1851, validation loss: 0.1621
2024-05-25 04:28:36 [INFO]: Epoch 253 - training loss: 0.1838, validation loss: 0.1617
2024-05-25 04:28:36 [INFO]: Epoch 254 - training loss: 0.1854, validation loss: 0.1598
2024-05-25 04:28:36 [INFO]: Epoch 255 - training loss: 0.1847, validation loss: 0.1607
2024-05-25 04:28:36 [INFO]: Epoch 256 - training loss: 0.1846, validation loss: 0.1613
2024-05-25 04:28:37 [INFO]: Epoch 257 - training loss: 0.1844, validation loss: 0.1613
2024-05-25 04:28:37 [INFO]: Epoch 258 - training loss: 0.1858, validation loss: 0.1606
2024-05-25 04:28:37 [INFO]: Epoch 259 - training loss: 0.1832, validation loss: 0.1613
2024-05-25 04:28:38 [INFO]: Epoch 260 - training loss: 0.1832, validation loss: 0.1604
2024-05-25 04:28:38 [INFO]: Epoch 261 - training loss: 0.1828, validation loss: 0.1612
2024-05-25 04:28:38 [INFO]: Epoch 262 - training loss: 0.1846, validation loss: 0.1614
2024-05-25 04:28:39 [INFO]: Epoch 263 - training loss: 0.1838, validation loss: 0.1615
2024-05-25 04:28:39 [INFO]: Epoch 264 - training loss: 0.1836, validation loss: 0.1612
2024-05-25 04:28:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:28:39 [INFO]: Finished training. The best model is from epoch#254.
2024-05-25 04:28:39 [INFO]: Saved the model to augmentation_saved_results/round_4/Transformer_air_quality/20240525_T042716/Transformer.pypots
2024-05-25 04:28:39 [INFO]: Transformer on Air-Quality: MAE=0.1566, MSE=0.1038
2024-05-25 04:28:39 [INFO]: Successfully saved to augmentation_saved_results/round_4/Transformer_air_quality/imputation.pkl
2024-05-25 04:28:39 [INFO]: Using the given device: cuda:0
2024-05-25 04:28:39 [INFO]: Model files will be saved to augmentation_saved_results/round_4/TimesNet_air_quality/20240525_T042839
2024-05-25 04:28:39 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/TimesNet_air_quality/20240525_T042839/tensorboard
2024-05-25 04:28:40 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 04:28:40 [INFO]: Epoch 001 - training loss: 0.3000, validation loss: 0.3098
2024-05-25 04:28:41 [INFO]: Epoch 002 - training loss: 0.2250, validation loss: 0.2678
2024-05-25 04:28:41 [INFO]: Epoch 003 - training loss: 0.1940, validation loss: 0.2545
2024-05-25 04:28:42 [INFO]: Epoch 004 - training loss: 0.1866, validation loss: 0.2555
2024-05-25 04:28:42 [INFO]: Epoch 005 - training loss: 0.1752, validation loss: 0.2224
2024-05-25 04:28:43 [INFO]: Epoch 006 - training loss: 0.2078, validation loss: 0.2313
2024-05-25 04:28:43 [INFO]: Epoch 007 - training loss: 0.1477, validation loss: 0.2176
2024-05-25 04:28:44 [INFO]: Epoch 008 - training loss: 0.1400, validation loss: 0.2165
2024-05-25 04:28:44 [INFO]: Epoch 009 - training loss: 0.1647, validation loss: 0.2156
2024-05-25 04:28:45 [INFO]: Epoch 010 - training loss: 0.1402, validation loss: 0.2194
2024-05-25 04:28:45 [INFO]: Epoch 011 - training loss: 0.1458, validation loss: 0.2157
2024-05-25 04:28:46 [INFO]: Epoch 012 - training loss: 0.1262, validation loss: 0.2122
2024-05-25 04:28:46 [INFO]: Epoch 013 - training loss: 0.1259, validation loss: 0.2218
2024-05-25 04:28:47 [INFO]: Epoch 014 - training loss: 0.1326, validation loss: 0.2122
2024-05-25 04:28:47 [INFO]: Epoch 015 - training loss: 0.1369, validation loss: 0.2177
2024-05-25 04:28:48 [INFO]: Epoch 016 - training loss: 0.1372, validation loss: 0.2187
2024-05-25 04:28:48 [INFO]: Epoch 017 - training loss: 0.1334, validation loss: 0.2113
2024-05-25 04:28:49 [INFO]: Epoch 018 - training loss: 0.1339, validation loss: 0.2090
2024-05-25 04:28:49 [INFO]: Epoch 019 - training loss: 0.1215, validation loss: 0.2191
2024-05-25 04:28:50 [INFO]: Epoch 020 - training loss: 0.1506, validation loss: 0.1974
2024-05-25 04:28:51 [INFO]: Epoch 021 - training loss: 0.1202, validation loss: 0.2021
2024-05-25 04:28:51 [INFO]: Epoch 022 - training loss: 0.1359, validation loss: 0.2026
2024-05-25 04:28:52 [INFO]: Epoch 023 - training loss: 0.1299, validation loss: 0.2084
2024-05-25 04:28:52 [INFO]: Epoch 024 - training loss: 0.1187, validation loss: 0.2153
2024-05-25 04:28:53 [INFO]: Epoch 025 - training loss: 0.1337, validation loss: 0.2136
2024-05-25 04:28:53 [INFO]: Epoch 026 - training loss: 0.1169, validation loss: 0.2074
2024-05-25 04:28:54 [INFO]: Epoch 027 - training loss: 0.1221, validation loss: 0.2030
2024-05-25 04:28:54 [INFO]: Epoch 028 - training loss: 0.1118, validation loss: 0.2058
2024-05-25 04:28:55 [INFO]: Epoch 029 - training loss: 0.1254, validation loss: 0.2151
2024-05-25 04:28:55 [INFO]: Epoch 030 - training loss: 0.1303, validation loss: 0.2055
2024-05-25 04:28:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:28:55 [INFO]: Finished training. The best model is from epoch#20.
2024-05-25 04:28:55 [INFO]: Saved the model to augmentation_saved_results/round_4/TimesNet_air_quality/20240525_T042839/TimesNet.pypots
2024-05-25 04:28:55 [INFO]: TimesNet on Air-Quality: MAE=0.1684, MSE=0.1359
2024-05-25 04:28:55 [INFO]: Successfully saved to augmentation_saved_results/round_4/TimesNet_air_quality/imputation.pkl
2024-05-25 04:28:55 [INFO]: Using the given device: cuda:0
2024-05-25 04:28:55 [INFO]: Model files will be saved to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855
2024-05-25 04:28:55 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/tensorboard
2024-05-25 04:28:55 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 04:29:12 [INFO]: Epoch 001 - training loss: 0.4954, validation loss: 0.3549
2024-05-25 04:29:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch1_loss0.3548999845981598.pypots
2024-05-25 04:29:29 [INFO]: Epoch 002 - training loss: 0.2976, validation loss: 0.3090
2024-05-25 04:29:29 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch2_loss0.3089830458164215.pypots
2024-05-25 04:29:46 [INFO]: Epoch 003 - training loss: 0.2483, validation loss: 0.2427
2024-05-25 04:29:46 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch3_loss0.2427086904644966.pypots
2024-05-25 04:30:03 [INFO]: Epoch 004 - training loss: 0.2361, validation loss: 0.2046
2024-05-25 04:30:03 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch4_loss0.20456089079380035.pypots
2024-05-25 04:30:20 [INFO]: Epoch 005 - training loss: 0.2165, validation loss: 0.1931
2024-05-25 04:30:20 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch5_loss0.19305402487516404.pypots
2024-05-25 04:30:37 [INFO]: Epoch 006 - training loss: 0.2009, validation loss: 0.1821
2024-05-25 04:30:37 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch6_loss0.18211313039064408.pypots
2024-05-25 04:30:53 [INFO]: Epoch 007 - training loss: 0.1848, validation loss: 0.1704
2024-05-25 04:30:53 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch7_loss0.17043024748563768.pypots
2024-05-25 04:31:10 [INFO]: Epoch 008 - training loss: 0.1771, validation loss: 0.1689
2024-05-25 04:31:10 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch8_loss0.1688898265361786.pypots
2024-05-25 04:31:27 [INFO]: Epoch 009 - training loss: 0.1607, validation loss: 0.1575
2024-05-25 04:31:27 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch9_loss0.15745951980352402.pypots
2024-05-25 04:31:44 [INFO]: Epoch 010 - training loss: 0.1610, validation loss: 0.1570
2024-05-25 04:31:44 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch10_loss0.15704809725284577.pypots
2024-05-25 04:32:01 [INFO]: Epoch 011 - training loss: 0.1708, validation loss: 0.1494
2024-05-25 04:32:01 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch11_loss0.14941593110561371.pypots
2024-05-25 04:32:18 [INFO]: Epoch 012 - training loss: 0.1742, validation loss: 0.1504
2024-05-25 04:32:18 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch12_loss0.15040790885686875.pypots
2024-05-25 04:32:35 [INFO]: Epoch 013 - training loss: 0.1503, validation loss: 0.1527
2024-05-25 04:32:35 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch13_loss0.15265295952558516.pypots
2024-05-25 04:32:51 [INFO]: Epoch 014 - training loss: 0.1677, validation loss: 0.1423
2024-05-25 04:32:51 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch14_loss0.1423049546778202.pypots
2024-05-25 04:33:08 [INFO]: Epoch 015 - training loss: 0.1617, validation loss: 0.1422
2024-05-25 04:33:08 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch15_loss0.1422326758503914.pypots
2024-05-25 04:33:25 [INFO]: Epoch 016 - training loss: 0.1725, validation loss: 0.1463
2024-05-25 04:33:25 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch16_loss0.1463125765323639.pypots
2024-05-25 04:33:42 [INFO]: Epoch 017 - training loss: 0.1631, validation loss: 0.1397
2024-05-25 04:33:42 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch17_loss0.13969518840312958.pypots
2024-05-25 04:33:59 [INFO]: Epoch 018 - training loss: 0.1461, validation loss: 0.1365
2024-05-25 04:33:59 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch18_loss0.13650566413998605.pypots
2024-05-25 04:34:16 [INFO]: Epoch 019 - training loss: 0.1671, validation loss: 0.1393
2024-05-25 04:34:16 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch19_loss0.13927622362971306.pypots
2024-05-25 04:34:33 [INFO]: Epoch 020 - training loss: 0.1534, validation loss: 0.1366
2024-05-25 04:34:33 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch20_loss0.13658235594630241.pypots
2024-05-25 04:34:49 [INFO]: Epoch 021 - training loss: 0.1538, validation loss: 0.1545
2024-05-25 04:34:49 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch21_loss0.15452704578638077.pypots
2024-05-25 04:35:06 [INFO]: Epoch 022 - training loss: 0.1592, validation loss: 0.1393
2024-05-25 04:35:06 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch22_loss0.13928991109132766.pypots
2024-05-25 04:35:23 [INFO]: Epoch 023 - training loss: 0.1726, validation loss: 0.1419
2024-05-25 04:35:23 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch23_loss0.14185773059725762.pypots
2024-05-25 04:35:40 [INFO]: Epoch 024 - training loss: 0.1684, validation loss: 0.1307
2024-05-25 04:35:40 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch24_loss0.13065890446305276.pypots
2024-05-25 04:35:57 [INFO]: Epoch 025 - training loss: 0.1387, validation loss: 0.1356
2024-05-25 04:35:57 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch25_loss0.13555908277630807.pypots
2024-05-25 04:36:14 [INFO]: Epoch 026 - training loss: 0.1462, validation loss: 0.1294
2024-05-25 04:36:14 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch26_loss0.12939721271395682.pypots
2024-05-25 04:36:30 [INFO]: Epoch 027 - training loss: 0.1431, validation loss: 0.1350
2024-05-25 04:36:31 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch27_loss0.13503364771604537.pypots
2024-05-25 04:36:47 [INFO]: Epoch 028 - training loss: 0.1478, validation loss: 0.1332
2024-05-25 04:36:47 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch28_loss0.13321432694792748.pypots
2024-05-25 04:37:04 [INFO]: Epoch 029 - training loss: 0.1422, validation loss: 0.1282
2024-05-25 04:37:04 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch29_loss0.12815539836883544.pypots
2024-05-25 04:37:21 [INFO]: Epoch 030 - training loss: 0.1444, validation loss: 0.1329
2024-05-25 04:37:21 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch30_loss0.13286027908325196.pypots
2024-05-25 04:37:38 [INFO]: Epoch 031 - training loss: 0.1465, validation loss: 0.1248
2024-05-25 04:37:38 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch31_loss0.1248389258980751.pypots
2024-05-25 04:37:55 [INFO]: Epoch 032 - training loss: 0.1240, validation loss: 0.1225
2024-05-25 04:37:55 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch32_loss0.1225381575524807.pypots
2024-05-25 04:38:12 [INFO]: Epoch 033 - training loss: 0.1504, validation loss: 0.1309
2024-05-25 04:38:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch33_loss0.13091785535216333.pypots
2024-05-25 04:38:28 [INFO]: Epoch 034 - training loss: 0.1490, validation loss: 0.1237
2024-05-25 04:38:28 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch34_loss0.12365169748663903.pypots
2024-05-25 04:38:45 [INFO]: Epoch 035 - training loss: 0.1350, validation loss: 0.1242
2024-05-25 04:38:45 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch35_loss0.12417938560247421.pypots
2024-05-25 04:39:02 [INFO]: Epoch 036 - training loss: 0.1247, validation loss: 0.1233
2024-05-25 04:39:02 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch36_loss0.12334425821900367.pypots
2024-05-25 04:39:19 [INFO]: Epoch 037 - training loss: 0.1317, validation loss: 0.1213
2024-05-25 04:39:19 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch37_loss0.12129145860671997.pypots
2024-05-25 04:39:36 [INFO]: Epoch 038 - training loss: 0.1302, validation loss: 0.1194
2024-05-25 04:39:36 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch38_loss0.11943828985095024.pypots
2024-05-25 04:39:53 [INFO]: Epoch 039 - training loss: 0.1323, validation loss: 0.1209
2024-05-25 04:39:53 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch39_loss0.12092206180095673.pypots
2024-05-25 04:40:10 [INFO]: Epoch 040 - training loss: 0.1405, validation loss: 0.1170
2024-05-25 04:40:10 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch40_loss0.1169511467218399.pypots
2024-05-25 04:40:26 [INFO]: Epoch 041 - training loss: 0.1310, validation loss: 0.1225
2024-05-25 04:40:26 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch41_loss0.1224735401570797.pypots
2024-05-25 04:40:43 [INFO]: Epoch 042 - training loss: 0.1345, validation loss: 0.1225
2024-05-25 04:40:43 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch42_loss0.12248560413718224.pypots
2024-05-25 04:41:00 [INFO]: Epoch 043 - training loss: 0.1261, validation loss: 0.1192
2024-05-25 04:41:00 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch43_loss0.11915581524372101.pypots
2024-05-25 04:41:17 [INFO]: Epoch 044 - training loss: 0.1418, validation loss: 0.1230
2024-05-25 04:41:17 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch44_loss0.1230410285294056.pypots
2024-05-25 04:41:34 [INFO]: Epoch 045 - training loss: 0.1327, validation loss: 0.1201
2024-05-25 04:41:34 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch45_loss0.12005074545741082.pypots
2024-05-25 04:41:51 [INFO]: Epoch 046 - training loss: 0.1183, validation loss: 0.1261
2024-05-25 04:41:51 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch46_loss0.12612432911992072.pypots
2024-05-25 04:42:08 [INFO]: Epoch 047 - training loss: 0.1283, validation loss: 0.1187
2024-05-25 04:42:08 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch47_loss0.11872761547565461.pypots
2024-05-25 04:42:24 [INFO]: Epoch 048 - training loss: 0.1353, validation loss: 0.1161
2024-05-25 04:42:25 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch48_loss0.11610266268253326.pypots
2024-05-25 04:42:41 [INFO]: Epoch 049 - training loss: 0.1401, validation loss: 0.1187
2024-05-25 04:42:41 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch49_loss0.11872607320547104.pypots
2024-05-25 04:42:58 [INFO]: Epoch 050 - training loss: 0.1240, validation loss: 0.1151
2024-05-25 04:42:58 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch50_loss0.11506852209568023.pypots
2024-05-25 04:43:15 [INFO]: Epoch 051 - training loss: 0.1295, validation loss: 0.1179
2024-05-25 04:43:15 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch51_loss0.11791024953126908.pypots
2024-05-25 04:43:32 [INFO]: Epoch 052 - training loss: 0.1068, validation loss: 0.1158
2024-05-25 04:43:32 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch52_loss0.11579728573560714.pypots
2024-05-25 04:43:49 [INFO]: Epoch 053 - training loss: 0.1255, validation loss: 0.1126
2024-05-25 04:43:49 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch53_loss0.11259293183684349.pypots
2024-05-25 04:44:06 [INFO]: Epoch 054 - training loss: 0.1229, validation loss: 0.1142
2024-05-25 04:44:06 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch54_loss0.11415610238909721.pypots
2024-05-25 04:44:22 [INFO]: Epoch 055 - training loss: 0.1129, validation loss: 0.1227
2024-05-25 04:44:22 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch55_loss0.12272700443863868.pypots
2024-05-25 04:44:39 [INFO]: Epoch 056 - training loss: 0.1298, validation loss: 0.1165
2024-05-25 04:44:39 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch56_loss0.11645522639155388.pypots
2024-05-25 04:44:56 [INFO]: Epoch 057 - training loss: 0.1168, validation loss: 0.1126
2024-05-25 04:44:56 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch57_loss0.11259222701191902.pypots
2024-05-25 04:45:13 [INFO]: Epoch 058 - training loss: 0.1286, validation loss: 0.1142
2024-05-25 04:45:13 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch58_loss0.1141772985458374.pypots
2024-05-25 04:45:30 [INFO]: Epoch 059 - training loss: 0.1280, validation loss: 0.1129
2024-05-25 04:45:30 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch59_loss0.11293000653386116.pypots
2024-05-25 04:45:47 [INFO]: Epoch 060 - training loss: 0.1289, validation loss: 0.1126
2024-05-25 04:45:47 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch60_loss0.11261863261461258.pypots
2024-05-25 04:46:04 [INFO]: Epoch 061 - training loss: 0.1385, validation loss: 0.1090
2024-05-25 04:46:04 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch61_loss0.10895667374134063.pypots
2024-05-25 04:46:20 [INFO]: Epoch 062 - training loss: 0.1266, validation loss: 0.1109
2024-05-25 04:46:20 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch62_loss0.11092655807733535.pypots
2024-05-25 04:46:37 [INFO]: Epoch 063 - training loss: 0.1272, validation loss: 0.1142
2024-05-25 04:46:37 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch63_loss0.1141891360282898.pypots
2024-05-25 04:46:54 [INFO]: Epoch 064 - training loss: 0.1264, validation loss: 0.1111
2024-05-25 04:46:54 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch64_loss0.11113695427775383.pypots
2024-05-25 04:47:11 [INFO]: Epoch 065 - training loss: 0.1407, validation loss: 0.1079
2024-05-25 04:47:11 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch65_loss0.10792310535907745.pypots
2024-05-25 04:47:28 [INFO]: Epoch 066 - training loss: 0.1143, validation loss: 0.1077
2024-05-25 04:47:28 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch66_loss0.10768737494945527.pypots
2024-05-25 04:47:45 [INFO]: Epoch 067 - training loss: 0.1260, validation loss: 0.1079
2024-05-25 04:47:45 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch67_loss0.10794820562005043.pypots
2024-05-25 04:48:02 [INFO]: Epoch 068 - training loss: 0.1265, validation loss: 0.1113
2024-05-25 04:48:02 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch68_loss0.11128558963537216.pypots
2024-05-25 04:48:18 [INFO]: Epoch 069 - training loss: 0.1254, validation loss: 0.1197
2024-05-25 04:48:18 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch69_loss0.1196610152721405.pypots
2024-05-25 04:48:35 [INFO]: Epoch 070 - training loss: 0.1212, validation loss: 0.1091
2024-05-25 04:48:35 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch70_loss0.10908797457814216.pypots
2024-05-25 04:48:52 [INFO]: Epoch 071 - training loss: 0.1070, validation loss: 0.1085
2024-05-25 04:48:52 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch71_loss0.10847325697541237.pypots
2024-05-25 04:49:09 [INFO]: Epoch 072 - training loss: 0.1212, validation loss: 0.1078
2024-05-25 04:49:09 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch72_loss0.10775059983134269.pypots
2024-05-25 04:49:26 [INFO]: Epoch 073 - training loss: 0.1126, validation loss: 0.1067
2024-05-25 04:49:26 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch73_loss0.10665942803025245.pypots
2024-05-25 04:49:43 [INFO]: Epoch 074 - training loss: 0.1154, validation loss: 0.1069
2024-05-25 04:49:43 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch74_loss0.10694196298718453.pypots
2024-05-25 04:50:00 [INFO]: Epoch 075 - training loss: 0.1117, validation loss: 0.1077
2024-05-25 04:50:00 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch75_loss0.10770553424954414.pypots
2024-05-25 04:50:16 [INFO]: Epoch 076 - training loss: 0.1274, validation loss: 0.1067
2024-05-25 04:50:16 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch76_loss0.10667707920074462.pypots
2024-05-25 04:50:33 [INFO]: Epoch 077 - training loss: 0.1136, validation loss: 0.1071
2024-05-25 04:50:33 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch77_loss0.1070858471095562.pypots
2024-05-25 04:50:50 [INFO]: Epoch 078 - training loss: 0.1268, validation loss: 0.1054
2024-05-25 04:50:50 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch78_loss0.1054311141371727.pypots
2024-05-25 04:51:07 [INFO]: Epoch 079 - training loss: 0.1152, validation loss: 0.1039
2024-05-25 04:51:07 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch79_loss0.103905588388443.pypots
2024-05-25 04:51:24 [INFO]: Epoch 080 - training loss: 0.1120, validation loss: 0.1091
2024-05-25 04:51:24 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch80_loss0.10907775685191154.pypots
2024-05-25 04:51:41 [INFO]: Epoch 081 - training loss: 0.1150, validation loss: 0.1054
2024-05-25 04:51:41 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch81_loss0.10540585741400718.pypots
2024-05-25 04:51:58 [INFO]: Epoch 082 - training loss: 0.1131, validation loss: 0.1039
2024-05-25 04:51:58 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch82_loss0.1039237029850483.pypots
2024-05-25 04:52:14 [INFO]: Epoch 083 - training loss: 0.1139, validation loss: 0.1043
2024-05-25 04:52:14 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch83_loss0.10427061468362808.pypots
2024-05-25 04:52:31 [INFO]: Epoch 084 - training loss: 0.1050, validation loss: 0.1027
2024-05-25 04:52:31 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch84_loss0.10269282683730126.pypots
2024-05-25 04:52:48 [INFO]: Epoch 085 - training loss: 0.1317, validation loss: 0.1078
2024-05-25 04:52:48 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch85_loss0.10778049528598785.pypots
2024-05-25 04:53:05 [INFO]: Epoch 086 - training loss: 0.1116, validation loss: 0.1059
2024-05-25 04:53:05 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch86_loss0.10586281046271324.pypots
2024-05-25 04:53:22 [INFO]: Epoch 087 - training loss: 0.1243, validation loss: 0.1060
2024-05-25 04:53:22 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch87_loss0.10597704276442528.pypots
2024-05-25 04:53:39 [INFO]: Epoch 088 - training loss: 0.1143, validation loss: 0.1051
2024-05-25 04:53:39 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch88_loss0.10508572310209274.pypots
2024-05-25 04:53:56 [INFO]: Epoch 089 - training loss: 0.1236, validation loss: 0.1050
2024-05-25 04:53:56 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch89_loss0.10503747090697288.pypots
2024-05-25 04:54:12 [INFO]: Epoch 090 - training loss: 0.1056, validation loss: 0.1029
2024-05-25 04:54:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch90_loss0.10285956412553787.pypots
2024-05-25 04:54:29 [INFO]: Epoch 091 - training loss: 0.1248, validation loss: 0.1063
2024-05-25 04:54:29 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch91_loss0.10632351785898209.pypots
2024-05-25 04:54:46 [INFO]: Epoch 092 - training loss: 0.1206, validation loss: 0.1060
2024-05-25 04:54:46 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch92_loss0.10600540116429329.pypots
2024-05-25 04:55:03 [INFO]: Epoch 093 - training loss: 0.1159, validation loss: 0.1063
2024-05-25 04:55:03 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch93_loss0.10629160478711128.pypots
2024-05-25 04:55:20 [INFO]: Epoch 094 - training loss: 0.1150, validation loss: 0.1022
2024-05-25 04:55:20 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch94_loss0.10216596946120263.pypots
2024-05-25 04:55:37 [INFO]: Epoch 095 - training loss: 0.1059, validation loss: 0.1038
2024-05-25 04:55:37 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch95_loss0.10379674658179283.pypots
2024-05-25 04:55:54 [INFO]: Epoch 096 - training loss: 0.1182, validation loss: 0.1046
2024-05-25 04:55:54 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch96_loss0.10456500872969628.pypots
2024-05-25 04:56:10 [INFO]: Epoch 097 - training loss: 0.1096, validation loss: 0.1054
2024-05-25 04:56:10 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch97_loss0.10541514977812767.pypots
2024-05-25 04:56:27 [INFO]: Epoch 098 - training loss: 0.1313, validation loss: 0.1064
2024-05-25 04:56:27 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch98_loss0.1063846468925476.pypots
2024-05-25 04:56:44 [INFO]: Epoch 099 - training loss: 0.1067, validation loss: 0.1014
2024-05-25 04:56:44 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch99_loss0.10135137811303138.pypots
2024-05-25 04:57:01 [INFO]: Epoch 100 - training loss: 0.1262, validation loss: 0.1022
2024-05-25 04:57:01 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch100_loss0.10215532779693604.pypots
2024-05-25 04:57:18 [INFO]: Epoch 101 - training loss: 0.1115, validation loss: 0.1024
2024-05-25 04:57:18 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch101_loss0.10242233127355575.pypots
2024-05-25 04:57:35 [INFO]: Epoch 102 - training loss: 0.1102, validation loss: 0.1011
2024-05-25 04:57:35 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch102_loss0.10108473151922226.pypots
2024-05-25 04:57:52 [INFO]: Epoch 103 - training loss: 0.1112, validation loss: 0.1027
2024-05-25 04:57:52 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch103_loss0.10269752889871597.pypots
2024-05-25 04:58:08 [INFO]: Epoch 104 - training loss: 0.1174, validation loss: 0.1027
2024-05-25 04:58:08 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch104_loss0.10267357230186462.pypots
2024-05-25 04:58:25 [INFO]: Epoch 105 - training loss: 0.1108, validation loss: 0.1068
2024-05-25 04:58:25 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch105_loss0.1068157747387886.pypots
2024-05-25 04:58:42 [INFO]: Epoch 106 - training loss: 0.1110, validation loss: 0.1096
2024-05-25 04:58:42 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch106_loss0.10963800847530365.pypots
2024-05-25 04:58:59 [INFO]: Epoch 107 - training loss: 0.1250, validation loss: 0.1066
2024-05-25 04:58:59 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch107_loss0.10655548050999641.pypots
2024-05-25 04:59:16 [INFO]: Epoch 108 - training loss: 0.1002, validation loss: 0.1028
2024-05-25 04:59:16 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch108_loss0.10277973264455795.pypots
2024-05-25 04:59:33 [INFO]: Epoch 109 - training loss: 0.1080, validation loss: 0.0989
2024-05-25 04:59:33 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch109_loss0.09888092502951622.pypots
2024-05-25 04:59:49 [INFO]: Epoch 110 - training loss: 0.1187, validation loss: 0.1003
2024-05-25 04:59:50 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch110_loss0.10026527643203735.pypots
2024-05-25 05:00:06 [INFO]: Epoch 111 - training loss: 0.1213, validation loss: 0.1028
2024-05-25 05:00:06 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch111_loss0.10280582904815674.pypots
2024-05-25 05:00:23 [INFO]: Epoch 112 - training loss: 0.1037, validation loss: 0.0989
2024-05-25 05:00:23 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch112_loss0.09887703806161881.pypots
2024-05-25 05:00:40 [INFO]: Epoch 113 - training loss: 0.1077, validation loss: 0.1006
2024-05-25 05:00:40 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch113_loss0.10055513605475426.pypots
2024-05-25 05:00:57 [INFO]: Epoch 114 - training loss: 0.1085, validation loss: 0.1010
2024-05-25 05:00:57 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch114_loss0.10102056041359901.pypots
2024-05-25 05:01:14 [INFO]: Epoch 115 - training loss: 0.1129, validation loss: 0.0999
2024-05-25 05:01:14 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch115_loss0.099913090467453.pypots
2024-05-25 05:01:31 [INFO]: Epoch 116 - training loss: 0.1125, validation loss: 0.1025
2024-05-25 05:01:31 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch116_loss0.1025102011859417.pypots
2024-05-25 05:01:48 [INFO]: Epoch 117 - training loss: 0.1160, validation loss: 0.1040
2024-05-25 05:01:48 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch117_loss0.1040265642106533.pypots
2024-05-25 05:02:04 [INFO]: Epoch 118 - training loss: 0.1247, validation loss: 0.1025
2024-05-25 05:02:04 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch118_loss0.10251364409923554.pypots
2024-05-25 05:02:21 [INFO]: Epoch 119 - training loss: 0.1148, validation loss: 0.1043
2024-05-25 05:02:21 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch119_loss0.1042819082736969.pypots
2024-05-25 05:02:38 [INFO]: Epoch 120 - training loss: 0.1138, validation loss: 0.1000
2024-05-25 05:02:38 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch120_loss0.1000128872692585.pypots
2024-05-25 05:02:55 [INFO]: Epoch 121 - training loss: 0.1125, validation loss: 0.1001
2024-05-25 05:02:55 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch121_loss0.10014308840036393.pypots
2024-05-25 05:03:12 [INFO]: Epoch 122 - training loss: 0.1186, validation loss: 0.1014
2024-05-25 05:03:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI_epoch122_loss0.10143411606550216.pypots
2024-05-25 05:03:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:03:12 [INFO]: Finished training. The best model is from epoch#112.
2024-05-25 05:03:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T042855/CSDI.pypots
2024-05-25 05:05:33 [INFO]: CSDI on Air-Quality: MAE=0.0963, MSE=0.0721
2024-05-25 05:05:33 [INFO]: Successfully saved to augmentation_saved_results/round_4/CSDI_air_quality/imputation.pkl
2024-05-25 05:05:33 [INFO]: Using the given device: cuda:0
2024-05-25 05:05:33 [INFO]: Model files will be saved to augmentation_saved_results/round_4/GPVAE_air_quality/20240525_T050533
2024-05-25 05:05:33 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/GPVAE_air_quality/20240525_T050533/tensorboard
2024-05-25 05:05:33 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 05:05:33 [INFO]: Epoch 001 - training loss: 63761.7685, validation loss: 0.7188
2024-05-25 05:05:33 [INFO]: Epoch 002 - training loss: 42073.8432, validation loss: 0.6102
2024-05-25 05:05:34 [INFO]: Epoch 003 - training loss: 41768.9630, validation loss: 0.5568
2024-05-25 05:05:34 [INFO]: Epoch 004 - training loss: 41637.1024, validation loss: 0.5304
2024-05-25 05:05:34 [INFO]: Epoch 005 - training loss: 41545.0553, validation loss: 0.4951
2024-05-25 05:05:35 [INFO]: Epoch 006 - training loss: 41521.2361, validation loss: 0.5146
2024-05-25 05:05:35 [INFO]: Epoch 007 - training loss: 41505.3883, validation loss: 0.4227
2024-05-25 05:05:35 [INFO]: Epoch 008 - training loss: 41444.2590, validation loss: 0.4381
2024-05-25 05:05:36 [INFO]: Epoch 009 - training loss: 41404.3779, validation loss: 0.3799
2024-05-25 05:05:36 [INFO]: Epoch 010 - training loss: 41367.5499, validation loss: 0.4011
2024-05-25 05:05:36 [INFO]: Epoch 011 - training loss: 41397.9395, validation loss: 0.3727
2024-05-25 05:05:37 [INFO]: Epoch 012 - training loss: 41373.2836, validation loss: 0.3621
2024-05-25 05:05:37 [INFO]: Epoch 013 - training loss: 41342.2292, validation loss: 0.3571
2024-05-25 05:05:37 [INFO]: Epoch 014 - training loss: 41313.6221, validation loss: 0.3383
2024-05-25 05:05:38 [INFO]: Epoch 015 - training loss: 41305.6466, validation loss: 0.3335
2024-05-25 05:05:38 [INFO]: Epoch 016 - training loss: 41292.8038, validation loss: 0.3351
2024-05-25 05:05:38 [INFO]: Epoch 017 - training loss: 41296.1438, validation loss: 0.3496
2024-05-25 05:05:39 [INFO]: Epoch 018 - training loss: 41284.9851, validation loss: 0.3231
2024-05-25 05:05:39 [INFO]: Epoch 019 - training loss: 41268.8139, validation loss: 0.3186
2024-05-25 05:05:39 [INFO]: Epoch 020 - training loss: 41254.5043, validation loss: 0.3040
2024-05-25 05:05:40 [INFO]: Epoch 021 - training loss: 41288.3821, validation loss: 0.3548
2024-05-25 05:05:40 [INFO]: Epoch 022 - training loss: 41618.9034, validation loss: 0.3736
2024-05-25 05:05:40 [INFO]: Epoch 023 - training loss: 41373.5978, validation loss: 0.3356
2024-05-25 05:05:40 [INFO]: Epoch 024 - training loss: 41276.1840, validation loss: 0.3136
2024-05-25 05:05:41 [INFO]: Epoch 025 - training loss: 41257.9330, validation loss: 0.3187
2024-05-25 05:05:41 [INFO]: Epoch 026 - training loss: 41239.3641, validation loss: 0.2989
2024-05-25 05:05:41 [INFO]: Epoch 027 - training loss: 41231.7530, validation loss: 0.3084
2024-05-25 05:05:42 [INFO]: Epoch 028 - training loss: 41222.2665, validation loss: 0.2907
2024-05-25 05:05:42 [INFO]: Epoch 029 - training loss: 41217.4194, validation loss: 0.2918
2024-05-25 05:05:42 [INFO]: Epoch 030 - training loss: 41223.5039, validation loss: 0.2892
2024-05-25 05:05:43 [INFO]: Epoch 031 - training loss: 41226.4517, validation loss: 0.2924
2024-05-25 05:05:43 [INFO]: Epoch 032 - training loss: 41208.4547, validation loss: 0.2822
2024-05-25 05:05:43 [INFO]: Epoch 033 - training loss: 41204.7357, validation loss: 0.3235
2024-05-25 05:05:44 [INFO]: Epoch 034 - training loss: 41235.9925, validation loss: 0.2837
2024-05-25 05:05:44 [INFO]: Epoch 035 - training loss: 41203.2170, validation loss: 0.2794
2024-05-25 05:05:44 [INFO]: Epoch 036 - training loss: 41193.6949, validation loss: 0.2770
2024-05-25 05:05:45 [INFO]: Epoch 037 - training loss: 41190.6865, validation loss: 0.2782
2024-05-25 05:05:45 [INFO]: Epoch 038 - training loss: 41197.2091, validation loss: 0.2782
2024-05-25 05:05:45 [INFO]: Epoch 039 - training loss: 41191.0651, validation loss: 0.2808
2024-05-25 05:05:46 [INFO]: Epoch 040 - training loss: 41195.7765, validation loss: 0.2874
2024-05-25 05:05:46 [INFO]: Epoch 041 - training loss: 41229.2381, validation loss: 0.2808
2024-05-25 05:05:46 [INFO]: Epoch 042 - training loss: 41193.9852, validation loss: 0.2714
2024-05-25 05:05:47 [INFO]: Epoch 043 - training loss: 41181.6950, validation loss: 0.2734
2024-05-25 05:05:47 [INFO]: Epoch 044 - training loss: 41181.4553, validation loss: 0.2717
2024-05-25 05:05:47 [INFO]: Epoch 045 - training loss: 41181.0100, validation loss: 0.2658
2024-05-25 05:05:48 [INFO]: Epoch 046 - training loss: 41175.9978, validation loss: 0.2652
2024-05-25 05:05:48 [INFO]: Epoch 047 - training loss: 41197.2280, validation loss: 0.2920
2024-05-25 05:05:48 [INFO]: Epoch 048 - training loss: 41204.3388, validation loss: 0.2794
2024-05-25 05:05:49 [INFO]: Epoch 049 - training loss: 41193.9936, validation loss: 0.2738
2024-05-25 05:05:49 [INFO]: Epoch 050 - training loss: 41175.6904, validation loss: 0.2654
2024-05-25 05:05:49 [INFO]: Epoch 051 - training loss: 41168.9287, validation loss: 0.2638
2024-05-25 05:05:49 [INFO]: Epoch 052 - training loss: 41163.5810, validation loss: 0.2638
2024-05-25 05:05:50 [INFO]: Epoch 053 - training loss: 41165.6398, validation loss: 0.2634
2024-05-25 05:05:50 [INFO]: Epoch 054 - training loss: 41158.7070, validation loss: 0.2647
2024-05-25 05:05:50 [INFO]: Epoch 055 - training loss: 41166.4277, validation loss: 0.2650
2024-05-25 05:05:51 [INFO]: Epoch 056 - training loss: 41166.9067, validation loss: 0.2683
2024-05-25 05:05:51 [INFO]: Epoch 057 - training loss: 41169.1583, validation loss: 0.2948
2024-05-25 05:05:51 [INFO]: Epoch 058 - training loss: 41252.6157, validation loss: 0.2877
2024-05-25 05:05:52 [INFO]: Epoch 059 - training loss: 41201.9327, validation loss: 0.2825
2024-05-25 05:05:52 [INFO]: Epoch 060 - training loss: 41189.0592, validation loss: 0.2715
2024-05-25 05:05:52 [INFO]: Epoch 061 - training loss: 41182.3951, validation loss: 0.2625
2024-05-25 05:05:53 [INFO]: Epoch 062 - training loss: 41173.8235, validation loss: 0.2837
2024-05-25 05:05:53 [INFO]: Epoch 063 - training loss: 41199.2483, validation loss: 0.2709
2024-05-25 05:05:53 [INFO]: Epoch 064 - training loss: 41180.2590, validation loss: 0.2600
2024-05-25 05:05:54 [INFO]: Epoch 065 - training loss: 41159.2922, validation loss: 0.2605
2024-05-25 05:05:54 [INFO]: Epoch 066 - training loss: 41156.0072, validation loss: 0.2591
2024-05-25 05:05:54 [INFO]: Epoch 067 - training loss: 41153.5760, validation loss: 0.2629
2024-05-25 05:05:55 [INFO]: Epoch 068 - training loss: 41158.2758, validation loss: 0.2824
2024-05-25 05:05:55 [INFO]: Epoch 069 - training loss: 41185.6696, validation loss: 0.2780
2024-05-25 05:05:55 [INFO]: Epoch 070 - training loss: 41151.7062, validation loss: 0.2593
2024-05-25 05:05:56 [INFO]: Epoch 071 - training loss: 41141.2459, validation loss: 0.2602
2024-05-25 05:05:56 [INFO]: Epoch 072 - training loss: 41143.6775, validation loss: 0.2619
2024-05-25 05:05:56 [INFO]: Epoch 073 - training loss: 41147.4666, validation loss: 0.2598
2024-05-25 05:05:57 [INFO]: Epoch 074 - training loss: 41148.8160, validation loss: 0.2601
2024-05-25 05:05:57 [INFO]: Epoch 075 - training loss: 41137.7381, validation loss: 0.2566
2024-05-25 05:05:57 [INFO]: Epoch 076 - training loss: 41136.6777, validation loss: 0.2627
2024-05-25 05:05:58 [INFO]: Epoch 077 - training loss: 41139.2303, validation loss: 0.2598
2024-05-25 05:05:58 [INFO]: Epoch 078 - training loss: 41144.3160, validation loss: 0.2578
2024-05-25 05:05:58 [INFO]: Epoch 079 - training loss: 41163.2179, validation loss: 0.2688
2024-05-25 05:05:58 [INFO]: Epoch 080 - training loss: 41163.3364, validation loss: 0.2736
2024-05-25 05:05:59 [INFO]: Epoch 081 - training loss: 41143.9822, validation loss: 0.2636
2024-05-25 05:05:59 [INFO]: Epoch 082 - training loss: 41152.0832, validation loss: 0.2688
2024-05-25 05:05:59 [INFO]: Epoch 083 - training loss: 41143.2011, validation loss: 0.2563
2024-05-25 05:06:00 [INFO]: Epoch 084 - training loss: 41140.5699, validation loss: 0.2604
2024-05-25 05:06:00 [INFO]: Epoch 085 - training loss: 41133.0894, validation loss: 0.2625
2024-05-25 05:06:00 [INFO]: Epoch 086 - training loss: 41127.0473, validation loss: 0.2574
2024-05-25 05:06:01 [INFO]: Epoch 087 - training loss: 41133.7837, validation loss: 0.2702
2024-05-25 05:06:01 [INFO]: Epoch 088 - training loss: 41156.0593, validation loss: 0.2643
2024-05-25 05:06:01 [INFO]: Epoch 089 - training loss: 41143.3346, validation loss: 0.2642
2024-05-25 05:06:02 [INFO]: Epoch 090 - training loss: 41141.8550, validation loss: 0.2569
2024-05-25 05:06:02 [INFO]: Epoch 091 - training loss: 41157.9693, validation loss: 0.2646
2024-05-25 05:06:02 [INFO]: Epoch 092 - training loss: 41154.7762, validation loss: 0.2546
2024-05-25 05:06:03 [INFO]: Epoch 093 - training loss: 41136.3475, validation loss: 0.2555
2024-05-25 05:06:03 [INFO]: Epoch 094 - training loss: 41134.0602, validation loss: 0.2553
2024-05-25 05:06:03 [INFO]: Epoch 095 - training loss: 41130.7795, validation loss: 0.2555
2024-05-25 05:06:04 [INFO]: Epoch 096 - training loss: 41122.0965, validation loss: 0.2555
2024-05-25 05:06:04 [INFO]: Epoch 097 - training loss: 41120.4812, validation loss: 0.2604
2024-05-25 05:06:04 [INFO]: Epoch 098 - training loss: 41118.2148, validation loss: 0.2559
2024-05-25 05:06:05 [INFO]: Epoch 099 - training loss: 41116.7814, validation loss: 0.2575
2024-05-25 05:06:05 [INFO]: Epoch 100 - training loss: 41130.4688, validation loss: 0.2634
2024-05-25 05:06:05 [INFO]: Epoch 101 - training loss: 41130.8993, validation loss: 0.2629
2024-05-25 05:06:06 [INFO]: Epoch 102 - training loss: 41120.4307, validation loss: 0.2543
2024-05-25 05:06:06 [INFO]: Epoch 103 - training loss: 41115.7130, validation loss: 0.2526
2024-05-25 05:06:06 [INFO]: Epoch 104 - training loss: 41118.8911, validation loss: 0.2632
2024-05-25 05:06:06 [INFO]: Epoch 105 - training loss: 41118.3995, validation loss: 0.2587
2024-05-25 05:06:07 [INFO]: Epoch 106 - training loss: 41150.9323, validation loss: 0.2534
2024-05-25 05:06:07 [INFO]: Epoch 107 - training loss: 41131.8008, validation loss: 0.2537
2024-05-25 05:06:07 [INFO]: Epoch 108 - training loss: 41123.5327, validation loss: 0.2507
2024-05-25 05:06:08 [INFO]: Epoch 109 - training loss: 41122.4612, validation loss: 0.2448
2024-05-25 05:06:08 [INFO]: Epoch 110 - training loss: 41114.2173, validation loss: 0.2560
2024-05-25 05:06:08 [INFO]: Epoch 111 - training loss: 41112.8589, validation loss: 0.2566
2024-05-25 05:06:09 [INFO]: Epoch 112 - training loss: 41103.8746, validation loss: 0.2499
2024-05-25 05:06:09 [INFO]: Epoch 113 - training loss: 41104.2046, validation loss: 0.2571
2024-05-25 05:06:09 [INFO]: Epoch 114 - training loss: 41107.7170, validation loss: 0.2547
2024-05-25 05:06:10 [INFO]: Epoch 115 - training loss: 41103.9281, validation loss: 0.2490
2024-05-25 05:06:10 [INFO]: Epoch 116 - training loss: 41108.1198, validation loss: 0.2542
2024-05-25 05:06:10 [INFO]: Epoch 117 - training loss: 41116.8424, validation loss: 0.2659
2024-05-25 05:06:11 [INFO]: Epoch 118 - training loss: 41151.9627, validation loss: 0.2600
2024-05-25 05:06:11 [INFO]: Epoch 119 - training loss: 41134.0835, validation loss: 0.2351
2024-05-25 05:06:11 [INFO]: Epoch 120 - training loss: 41111.9920, validation loss: 0.2515
2024-05-25 05:06:12 [INFO]: Epoch 121 - training loss: 41114.6842, validation loss: 0.2420
2024-05-25 05:06:12 [INFO]: Epoch 122 - training loss: 41104.2920, validation loss: 0.2529
2024-05-25 05:06:12 [INFO]: Epoch 123 - training loss: 41119.7920, validation loss: 0.2513
2024-05-25 05:06:13 [INFO]: Epoch 124 - training loss: 41102.5904, validation loss: 0.2545
2024-05-25 05:06:13 [INFO]: Epoch 125 - training loss: 41109.8216, validation loss: 0.2418
2024-05-25 05:06:13 [INFO]: Epoch 126 - training loss: 41112.9159, validation loss: 0.2504
2024-05-25 05:06:14 [INFO]: Epoch 127 - training loss: 41105.2292, validation loss: 0.2330
2024-05-25 05:06:14 [INFO]: Epoch 128 - training loss: 41124.9070, validation loss: 0.2666
2024-05-25 05:06:14 [INFO]: Epoch 129 - training loss: 41134.4926, validation loss: 0.2565
2024-05-25 05:06:14 [INFO]: Epoch 130 - training loss: 41108.5095, validation loss: 0.2427
2024-05-25 05:06:15 [INFO]: Epoch 131 - training loss: 41117.0644, validation loss: 0.2517
2024-05-25 05:06:15 [INFO]: Epoch 132 - training loss: 41103.2535, validation loss: 0.2459
2024-05-25 05:06:15 [INFO]: Epoch 133 - training loss: 41094.0537, validation loss: 0.2525
2024-05-25 05:06:16 [INFO]: Epoch 134 - training loss: 41089.4423, validation loss: 0.2406
2024-05-25 05:06:16 [INFO]: Epoch 135 - training loss: 41100.9734, validation loss: 0.2604
2024-05-25 05:06:16 [INFO]: Epoch 136 - training loss: 41157.0281, validation loss: 0.2337
2024-05-25 05:06:17 [INFO]: Epoch 137 - training loss: 41170.7144, validation loss: 0.2585
2024-05-25 05:06:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:06:17 [INFO]: Finished training. The best model is from epoch#127.
2024-05-25 05:06:17 [INFO]: Saved the model to augmentation_saved_results/round_4/GPVAE_air_quality/20240525_T050533/GPVAE.pypots
2024-05-25 05:06:17 [INFO]: GP-VAE on Air-Quality: MAE=0.2626, MSE=0.2009
2024-05-25 05:06:17 [INFO]: Successfully saved to augmentation_saved_results/round_4/GPVAE_air_quality/imputation.pkl
2024-05-25 05:06:17 [INFO]: Using the given device: cuda:0
2024-05-25 05:06:17 [INFO]: Model files will be saved to augmentation_saved_results/round_4/USGAN_air_quality/20240525_T050617
2024-05-25 05:06:17 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/USGAN_air_quality/20240525_T050617/tensorboard
2024-05-25 05:06:17 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 05:06:22 [INFO]: Epoch 001 - generator training loss: 0.5970, discriminator training loss: 0.2705, validation loss: 0.5285
2024-05-25 05:06:26 [INFO]: Epoch 002 - generator training loss: 0.2790, discriminator training loss: 0.0670, validation loss: 0.4105
2024-05-25 05:06:30 [INFO]: Epoch 003 - generator training loss: 0.2076, discriminator training loss: 0.0635, validation loss: 0.3469
2024-05-25 05:06:34 [INFO]: Epoch 004 - generator training loss: 0.1719, discriminator training loss: 0.0618, validation loss: 0.3123
2024-05-25 05:06:38 [INFO]: Epoch 005 - generator training loss: 0.1485, discriminator training loss: 0.0623, validation loss: 0.2865
2024-05-25 05:06:42 [INFO]: Epoch 006 - generator training loss: 0.1379, discriminator training loss: 0.0607, validation loss: 0.2720
2024-05-25 05:06:46 [INFO]: Epoch 007 - generator training loss: 0.1177, discriminator training loss: 0.0603, validation loss: 0.2597
2024-05-25 05:06:50 [INFO]: Epoch 008 - generator training loss: 0.1097, discriminator training loss: 0.0597, validation loss: 0.2504
2024-05-25 05:06:54 [INFO]: Epoch 009 - generator training loss: 0.1011, discriminator training loss: 0.0597, validation loss: 0.2441
2024-05-25 05:06:58 [INFO]: Epoch 010 - generator training loss: 0.0950, discriminator training loss: 0.0585, validation loss: 0.2394
2024-05-25 05:07:03 [INFO]: Epoch 011 - generator training loss: 0.0930, discriminator training loss: 0.0570, validation loss: 0.2338
2024-05-25 05:07:07 [INFO]: Epoch 012 - generator training loss: 0.0877, discriminator training loss: 0.0557, validation loss: 0.2300
2024-05-25 05:07:11 [INFO]: Epoch 013 - generator training loss: 0.0878, discriminator training loss: 0.0539, validation loss: 0.2259
2024-05-25 05:07:15 [INFO]: Epoch 014 - generator training loss: 0.0825, discriminator training loss: 0.0522, validation loss: 0.2239
2024-05-25 05:07:19 [INFO]: Epoch 015 - generator training loss: 0.0820, discriminator training loss: 0.0504, validation loss: 0.2212
2024-05-25 05:07:23 [INFO]: Epoch 016 - generator training loss: 0.0780, discriminator training loss: 0.0494, validation loss: 0.2191
2024-05-25 05:07:27 [INFO]: Epoch 017 - generator training loss: 0.0797, discriminator training loss: 0.0477, validation loss: 0.2166
2024-05-25 05:07:31 [INFO]: Epoch 018 - generator training loss: 0.0760, discriminator training loss: 0.0466, validation loss: 0.2144
2024-05-25 05:07:35 [INFO]: Epoch 019 - generator training loss: 0.0727, discriminator training loss: 0.0462, validation loss: 0.2131
2024-05-25 05:07:39 [INFO]: Epoch 020 - generator training loss: 0.0707, discriminator training loss: 0.0451, validation loss: 0.2108
2024-05-25 05:07:43 [INFO]: Epoch 021 - generator training loss: 0.0707, discriminator training loss: 0.0436, validation loss: 0.2097
2024-05-25 05:07:48 [INFO]: Epoch 022 - generator training loss: 0.0671, discriminator training loss: 0.0428, validation loss: 0.2077
2024-05-25 05:07:52 [INFO]: Epoch 023 - generator training loss: 0.0670, discriminator training loss: 0.0427, validation loss: 0.2073
2024-05-25 05:07:56 [INFO]: Epoch 024 - generator training loss: 0.0646, discriminator training loss: 0.0419, validation loss: 0.2061
2024-05-25 05:08:00 [INFO]: Epoch 025 - generator training loss: 0.0651, discriminator training loss: 0.0409, validation loss: 0.2041
2024-05-25 05:08:04 [INFO]: Epoch 026 - generator training loss: 0.0633, discriminator training loss: 0.0401, validation loss: 0.2036
2024-05-25 05:08:08 [INFO]: Epoch 027 - generator training loss: 0.0615, discriminator training loss: 0.0398, validation loss: 0.2017
2024-05-25 05:08:12 [INFO]: Epoch 028 - generator training loss: 0.0612, discriminator training loss: 0.0385, validation loss: 0.2007
2024-05-25 05:08:16 [INFO]: Epoch 029 - generator training loss: 0.0606, discriminator training loss: 0.0377, validation loss: 0.1992
2024-05-25 05:08:20 [INFO]: Epoch 030 - generator training loss: 0.0599, discriminator training loss: 0.0371, validation loss: 0.1985
2024-05-25 05:08:24 [INFO]: Epoch 031 - generator training loss: 0.0591, discriminator training loss: 0.0360, validation loss: 0.1973
2024-05-25 05:08:28 [INFO]: Epoch 032 - generator training loss: 0.0579, discriminator training loss: 0.0355, validation loss: 0.1961
2024-05-25 05:08:33 [INFO]: Epoch 033 - generator training loss: 0.0576, discriminator training loss: 0.0345, validation loss: 0.1950
2024-05-25 05:08:37 [INFO]: Epoch 034 - generator training loss: 0.0563, discriminator training loss: 0.0340, validation loss: 0.1944
2024-05-25 05:08:41 [INFO]: Epoch 035 - generator training loss: 0.0563, discriminator training loss: 0.0333, validation loss: 0.1933
2024-05-25 05:08:45 [INFO]: Epoch 036 - generator training loss: 0.0572, discriminator training loss: 0.0325, validation loss: 0.1921
2024-05-25 05:08:49 [INFO]: Epoch 037 - generator training loss: 0.0570, discriminator training loss: 0.0314, validation loss: 0.1916
2024-05-25 05:08:53 [INFO]: Epoch 038 - generator training loss: 0.0544, discriminator training loss: 0.0313, validation loss: 0.1901
2024-05-25 05:08:57 [INFO]: Epoch 039 - generator training loss: 0.0548, discriminator training loss: 0.0303, validation loss: 0.1893
2024-05-25 05:09:01 [INFO]: Epoch 040 - generator training loss: 0.0537, discriminator training loss: 0.0301, validation loss: 0.1879
2024-05-25 05:09:05 [INFO]: Epoch 041 - generator training loss: 0.0535, discriminator training loss: 0.0291, validation loss: 0.1859
2024-05-25 05:09:09 [INFO]: Epoch 042 - generator training loss: 0.0525, discriminator training loss: 0.0287, validation loss: 0.1835
2024-05-25 05:09:13 [INFO]: Epoch 043 - generator training loss: 0.0525, discriminator training loss: 0.0281, validation loss: 0.1824
2024-05-25 05:09:17 [INFO]: Epoch 044 - generator training loss: 0.0514, discriminator training loss: 0.0273, validation loss: 0.1815
2024-05-25 05:09:22 [INFO]: Epoch 045 - generator training loss: 0.0509, discriminator training loss: 0.0269, validation loss: 0.1800
2024-05-25 05:09:26 [INFO]: Epoch 046 - generator training loss: 0.0504, discriminator training loss: 0.0266, validation loss: 0.1800
2024-05-25 05:09:30 [INFO]: Epoch 047 - generator training loss: 0.0505, discriminator training loss: 0.0260, validation loss: 0.1782
2024-05-25 05:09:34 [INFO]: Epoch 048 - generator training loss: 0.0496, discriminator training loss: 0.0257, validation loss: 0.1779
2024-05-25 05:09:38 [INFO]: Epoch 049 - generator training loss: 0.0496, discriminator training loss: 0.0250, validation loss: 0.1765
2024-05-25 05:09:42 [INFO]: Epoch 050 - generator training loss: 0.0489, discriminator training loss: 0.0246, validation loss: 0.1754
2024-05-25 05:09:46 [INFO]: Epoch 051 - generator training loss: 0.0490, discriminator training loss: 0.0243, validation loss: 0.1751
2024-05-25 05:09:50 [INFO]: Epoch 052 - generator training loss: 0.0483, discriminator training loss: 0.0240, validation loss: 0.1733
2024-05-25 05:09:54 [INFO]: Epoch 053 - generator training loss: 0.0483, discriminator training loss: 0.0238, validation loss: 0.1734
2024-05-25 05:09:58 [INFO]: Epoch 054 - generator training loss: 0.0475, discriminator training loss: 0.0233, validation loss: 0.1730
2024-05-25 05:10:02 [INFO]: Epoch 055 - generator training loss: 0.0465, discriminator training loss: 0.0230, validation loss: 0.1714
2024-05-25 05:10:07 [INFO]: Epoch 056 - generator training loss: 0.0466, discriminator training loss: 0.0225, validation loss: 0.1716
2024-05-25 05:10:11 [INFO]: Epoch 057 - generator training loss: 0.0465, discriminator training loss: 0.0225, validation loss: 0.1708
2024-05-25 05:10:15 [INFO]: Epoch 058 - generator training loss: 0.0458, discriminator training loss: 0.0221, validation loss: 0.1705
2024-05-25 05:10:19 [INFO]: Epoch 059 - generator training loss: 0.0453, discriminator training loss: 0.0217, validation loss: 0.1693
2024-05-25 05:10:23 [INFO]: Epoch 060 - generator training loss: 0.0457, discriminator training loss: 0.0215, validation loss: 0.1686
2024-05-25 05:10:27 [INFO]: Epoch 061 - generator training loss: 0.0444, discriminator training loss: 0.0215, validation loss: 0.1679
2024-05-25 05:10:31 [INFO]: Epoch 062 - generator training loss: 0.0441, discriminator training loss: 0.0210, validation loss: 0.1674
2024-05-25 05:10:35 [INFO]: Epoch 063 - generator training loss: 0.0439, discriminator training loss: 0.0206, validation loss: 0.1670
2024-05-25 05:10:39 [INFO]: Epoch 064 - generator training loss: 0.0432, discriminator training loss: 0.0204, validation loss: 0.1661
2024-05-25 05:10:43 [INFO]: Epoch 065 - generator training loss: 0.0429, discriminator training loss: 0.0204, validation loss: 0.1657
2024-05-25 05:10:47 [INFO]: Epoch 066 - generator training loss: 0.0422, discriminator training loss: 0.0200, validation loss: 0.1659
2024-05-25 05:10:52 [INFO]: Epoch 067 - generator training loss: 0.0417, discriminator training loss: 0.0200, validation loss: 0.1654
2024-05-25 05:10:56 [INFO]: Epoch 068 - generator training loss: 0.0417, discriminator training loss: 0.0197, validation loss: 0.1646
2024-05-25 05:11:00 [INFO]: Epoch 069 - generator training loss: 0.0404, discriminator training loss: 0.0195, validation loss: 0.1645
2024-05-25 05:11:04 [INFO]: Epoch 070 - generator training loss: 0.0406, discriminator training loss: 0.0193, validation loss: 0.1632
2024-05-25 05:11:08 [INFO]: Epoch 071 - generator training loss: 0.0403, discriminator training loss: 0.0191, validation loss: 0.1626
2024-05-25 05:11:12 [INFO]: Epoch 072 - generator training loss: 0.0399, discriminator training loss: 0.0189, validation loss: 0.1630
2024-05-25 05:11:16 [INFO]: Epoch 073 - generator training loss: 0.0396, discriminator training loss: 0.0188, validation loss: 0.1616
2024-05-25 05:11:20 [INFO]: Epoch 074 - generator training loss: 0.0394, discriminator training loss: 0.0185, validation loss: 0.1613
2024-05-25 05:11:24 [INFO]: Epoch 075 - generator training loss: 0.0390, discriminator training loss: 0.0185, validation loss: 0.1611
2024-05-25 05:11:28 [INFO]: Epoch 076 - generator training loss: 0.0387, discriminator training loss: 0.0182, validation loss: 0.1601
2024-05-25 05:11:32 [INFO]: Epoch 077 - generator training loss: 0.0382, discriminator training loss: 0.0181, validation loss: 0.1599
2024-05-25 05:11:36 [INFO]: Epoch 078 - generator training loss: 0.0380, discriminator training loss: 0.0183, validation loss: 0.1594
2024-05-25 05:11:41 [INFO]: Epoch 079 - generator training loss: 0.0383, discriminator training loss: 0.0177, validation loss: 0.1587
2024-05-25 05:11:45 [INFO]: Epoch 080 - generator training loss: 0.0381, discriminator training loss: 0.0176, validation loss: 0.1589
2024-05-25 05:11:49 [INFO]: Epoch 081 - generator training loss: 0.0381, discriminator training loss: 0.0173, validation loss: 0.1582
2024-05-25 05:11:53 [INFO]: Epoch 082 - generator training loss: 0.0377, discriminator training loss: 0.0175, validation loss: 0.1585
2024-05-25 05:11:57 [INFO]: Epoch 083 - generator training loss: 0.0385, discriminator training loss: 0.0173, validation loss: 0.1580
2024-05-25 05:12:01 [INFO]: Epoch 084 - generator training loss: 0.0373, discriminator training loss: 0.0170, validation loss: 0.1580
2024-05-25 05:12:05 [INFO]: Epoch 085 - generator training loss: 0.0370, discriminator training loss: 0.0172, validation loss: 0.1575
2024-05-25 05:12:09 [INFO]: Epoch 086 - generator training loss: 0.0370, discriminator training loss: 0.0168, validation loss: 0.1573
2024-05-25 05:12:13 [INFO]: Epoch 087 - generator training loss: 0.0387, discriminator training loss: 0.0169, validation loss: 0.1568
2024-05-25 05:12:17 [INFO]: Epoch 088 - generator training loss: 0.0368, discriminator training loss: 0.0166, validation loss: 0.1564
2024-05-25 05:12:21 [INFO]: Epoch 089 - generator training loss: 0.0368, discriminator training loss: 0.0164, validation loss: 0.1565
2024-05-25 05:12:26 [INFO]: Epoch 090 - generator training loss: 0.0362, discriminator training loss: 0.0165, validation loss: 0.1553
2024-05-25 05:12:30 [INFO]: Epoch 091 - generator training loss: 0.0363, discriminator training loss: 0.0161, validation loss: 0.1549
2024-05-25 05:12:34 [INFO]: Epoch 092 - generator training loss: 0.0356, discriminator training loss: 0.0162, validation loss: 0.1552
2024-05-25 05:12:38 [INFO]: Epoch 093 - generator training loss: 0.0358, discriminator training loss: 0.0161, validation loss: 0.1544
2024-05-25 05:12:42 [INFO]: Epoch 094 - generator training loss: 0.0355, discriminator training loss: 0.0161, validation loss: 0.1553
2024-05-25 05:12:46 [INFO]: Epoch 095 - generator training loss: 0.0358, discriminator training loss: 0.0158, validation loss: 0.1682
2024-05-25 05:12:50 [INFO]: Epoch 096 - generator training loss: 0.0387, discriminator training loss: 0.0158, validation loss: 0.1539
2024-05-25 05:12:54 [INFO]: Epoch 097 - generator training loss: 0.0371, discriminator training loss: 0.0158, validation loss: 0.1523
2024-05-25 05:12:58 [INFO]: Epoch 098 - generator training loss: 0.0359, discriminator training loss: 0.0155, validation loss: 0.1540
2024-05-25 05:13:02 [INFO]: Epoch 099 - generator training loss: 0.0355, discriminator training loss: 0.0155, validation loss: 0.1527
2024-05-25 05:13:06 [INFO]: Epoch 100 - generator training loss: 0.0355, discriminator training loss: 0.0152, validation loss: 0.1536
2024-05-25 05:13:10 [INFO]: Epoch 101 - generator training loss: 0.0351, discriminator training loss: 0.0154, validation loss: 0.1527
2024-05-25 05:13:15 [INFO]: Epoch 102 - generator training loss: 0.0346, discriminator training loss: 0.0152, validation loss: 0.1525
2024-05-25 05:13:19 [INFO]: Epoch 103 - generator training loss: 0.0347, discriminator training loss: 0.0152, validation loss: 0.1521
2024-05-25 05:13:23 [INFO]: Epoch 104 - generator training loss: 0.0343, discriminator training loss: 0.0149, validation loss: 0.1526
2024-05-25 05:13:27 [INFO]: Epoch 105 - generator training loss: 0.0339, discriminator training loss: 0.0151, validation loss: 0.1525
2024-05-25 05:13:31 [INFO]: Epoch 106 - generator training loss: 0.0337, discriminator training loss: 0.0151, validation loss: 0.1517
2024-05-25 05:13:35 [INFO]: Epoch 107 - generator training loss: 0.0342, discriminator training loss: 0.0147, validation loss: 0.1518
2024-05-25 05:13:39 [INFO]: Epoch 108 - generator training loss: 0.0333, discriminator training loss: 0.0149, validation loss: 0.1516
2024-05-25 05:13:43 [INFO]: Epoch 109 - generator training loss: 0.0334, discriminator training loss: 0.0148, validation loss: 0.1514
2024-05-25 05:13:47 [INFO]: Epoch 110 - generator training loss: 0.0332, discriminator training loss: 0.0146, validation loss: 0.1518
2024-05-25 05:13:51 [INFO]: Epoch 111 - generator training loss: 0.0338, discriminator training loss: 0.0144, validation loss: 0.1511
2024-05-25 05:13:55 [INFO]: Epoch 112 - generator training loss: 0.0344, discriminator training loss: 0.0144, validation loss: 0.1514
2024-05-25 05:14:00 [INFO]: Epoch 113 - generator training loss: 0.0336, discriminator training loss: 0.0144, validation loss: 0.1505
2024-05-25 05:14:04 [INFO]: Epoch 114 - generator training loss: 0.0334, discriminator training loss: 0.0143, validation loss: 0.1505
2024-05-25 05:14:08 [INFO]: Epoch 115 - generator training loss: 0.0332, discriminator training loss: 0.0144, validation loss: 0.1498
2024-05-25 05:14:12 [INFO]: Epoch 116 - generator training loss: 0.0332, discriminator training loss: 0.0142, validation loss: 0.1502
2024-05-25 05:14:16 [INFO]: Epoch 117 - generator training loss: 0.0335, discriminator training loss: 0.0142, validation loss: 0.1503
2024-05-25 05:14:20 [INFO]: Epoch 118 - generator training loss: 0.0326, discriminator training loss: 0.0141, validation loss: 0.1503
2024-05-25 05:14:24 [INFO]: Epoch 119 - generator training loss: 0.0327, discriminator training loss: 0.0140, validation loss: 0.1502
2024-05-25 05:14:28 [INFO]: Epoch 120 - generator training loss: 0.0336, discriminator training loss: 0.0139, validation loss: 0.1508
2024-05-25 05:14:32 [INFO]: Epoch 121 - generator training loss: 0.0324, discriminator training loss: 0.0138, validation loss: 0.1494
2024-05-25 05:14:36 [INFO]: Epoch 122 - generator training loss: 0.0326, discriminator training loss: 0.0137, validation loss: 0.1497
2024-05-25 05:14:40 [INFO]: Epoch 123 - generator training loss: 0.0322, discriminator training loss: 0.0138, validation loss: 0.1498
2024-05-25 05:14:44 [INFO]: Epoch 124 - generator training loss: 0.0319, discriminator training loss: 0.0139, validation loss: 0.1499
2024-05-25 05:14:49 [INFO]: Epoch 125 - generator training loss: 0.0318, discriminator training loss: 0.0137, validation loss: 0.1492
2024-05-25 05:14:53 [INFO]: Epoch 126 - generator training loss: 0.0319, discriminator training loss: 0.0136, validation loss: 0.1494
2024-05-25 05:14:57 [INFO]: Epoch 127 - generator training loss: 0.0320, discriminator training loss: 0.0137, validation loss: 0.1509
2024-05-25 05:15:01 [INFO]: Epoch 128 - generator training loss: 0.0321, discriminator training loss: 0.0136, validation loss: 0.1491
2024-05-25 05:15:05 [INFO]: Epoch 129 - generator training loss: 0.0323, discriminator training loss: 0.0134, validation loss: 0.1502
2024-05-25 05:15:09 [INFO]: Epoch 130 - generator training loss: 0.0321, discriminator training loss: 0.0132, validation loss: 0.1487
2024-05-25 05:15:13 [INFO]: Epoch 131 - generator training loss: 0.0316, discriminator training loss: 0.0131, validation loss: 0.1486
2024-05-25 05:15:17 [INFO]: Epoch 132 - generator training loss: 0.0315, discriminator training loss: 0.0132, validation loss: 0.1489
2024-05-25 05:15:21 [INFO]: Epoch 133 - generator training loss: 0.0314, discriminator training loss: 0.0132, validation loss: 0.1504
2024-05-25 05:15:25 [INFO]: Epoch 134 - generator training loss: 0.0320, discriminator training loss: 0.0133, validation loss: 0.1488
2024-05-25 05:15:29 [INFO]: Epoch 135 - generator training loss: 0.0310, discriminator training loss: 0.0129, validation loss: 0.1489
2024-05-25 05:15:33 [INFO]: Epoch 136 - generator training loss: 0.0306, discriminator training loss: 0.0131, validation loss: 0.1495
2024-05-25 05:15:38 [INFO]: Epoch 137 - generator training loss: 0.0313, discriminator training loss: 0.0130, validation loss: 0.1480
2024-05-25 05:15:42 [INFO]: Epoch 138 - generator training loss: 0.0310, discriminator training loss: 0.0129, validation loss: 0.1491
2024-05-25 05:15:46 [INFO]: Epoch 139 - generator training loss: 0.0306, discriminator training loss: 0.0129, validation loss: 0.1480
2024-05-25 05:15:50 [INFO]: Epoch 140 - generator training loss: 0.0309, discriminator training loss: 0.0129, validation loss: 0.1487
2024-05-25 05:15:54 [INFO]: Epoch 141 - generator training loss: 0.0308, discriminator training loss: 0.0129, validation loss: 0.1486
2024-05-25 05:15:58 [INFO]: Epoch 142 - generator training loss: 0.0306, discriminator training loss: 0.0128, validation loss: 0.1481
2024-05-25 05:16:02 [INFO]: Epoch 143 - generator training loss: 0.0303, discriminator training loss: 0.0124, validation loss: 0.1490
2024-05-25 05:16:06 [INFO]: Epoch 144 - generator training loss: 0.0306, discriminator training loss: 0.0126, validation loss: 0.1480
2024-05-25 05:16:10 [INFO]: Epoch 145 - generator training loss: 0.0301, discriminator training loss: 0.0126, validation loss: 0.1475
2024-05-25 05:16:14 [INFO]: Epoch 146 - generator training loss: 0.0302, discriminator training loss: 0.0127, validation loss: 0.1488
2024-05-25 05:16:18 [INFO]: Epoch 147 - generator training loss: 0.0304, discriminator training loss: 0.0123, validation loss: 0.1486
2024-05-25 05:16:22 [INFO]: Epoch 148 - generator training loss: 0.0306, discriminator training loss: 0.0126, validation loss: 0.1502
2024-05-25 05:16:27 [INFO]: Epoch 149 - generator training loss: 0.0312, discriminator training loss: 0.0125, validation loss: 0.1488
2024-05-25 05:16:31 [INFO]: Epoch 150 - generator training loss: 0.0316, discriminator training loss: 0.0124, validation loss: 0.1477
2024-05-25 05:16:35 [INFO]: Epoch 151 - generator training loss: 0.0309, discriminator training loss: 0.0125, validation loss: 0.1470
2024-05-25 05:16:39 [INFO]: Epoch 152 - generator training loss: 0.0299, discriminator training loss: 0.0122, validation loss: 0.1474
2024-05-25 05:16:43 [INFO]: Epoch 153 - generator training loss: 0.0303, discriminator training loss: 0.0124, validation loss: 0.1474
2024-05-25 05:16:47 [INFO]: Epoch 154 - generator training loss: 0.0303, discriminator training loss: 0.0123, validation loss: 0.1475
2024-05-25 05:16:51 [INFO]: Epoch 155 - generator training loss: 0.0298, discriminator training loss: 0.0122, validation loss: 0.1478
2024-05-25 05:16:55 [INFO]: Epoch 156 - generator training loss: 0.0299, discriminator training loss: 0.0119, validation loss: 0.1468
2024-05-25 05:16:59 [INFO]: Epoch 157 - generator training loss: 0.0296, discriminator training loss: 0.0120, validation loss: 0.1467
2024-05-25 05:17:03 [INFO]: Epoch 158 - generator training loss: 0.0296, discriminator training loss: 0.0120, validation loss: 0.1466
2024-05-25 05:17:07 [INFO]: Epoch 159 - generator training loss: 0.0296, discriminator training loss: 0.0120, validation loss: 0.1470
2024-05-25 05:17:11 [INFO]: Epoch 160 - generator training loss: 0.0298, discriminator training loss: 0.0119, validation loss: 0.1494
2024-05-25 05:17:15 [INFO]: Epoch 161 - generator training loss: 0.0299, discriminator training loss: 0.0119, validation loss: 0.1484
2024-05-25 05:17:20 [INFO]: Epoch 162 - generator training loss: 0.0317, discriminator training loss: 0.0117, validation loss: 0.1544
2024-05-25 05:17:24 [INFO]: Epoch 163 - generator training loss: 0.0322, discriminator training loss: 0.0117, validation loss: 0.1484
2024-05-25 05:17:28 [INFO]: Epoch 164 - generator training loss: 0.0311, discriminator training loss: 0.0117, validation loss: 0.1490
2024-05-25 05:17:32 [INFO]: Epoch 165 - generator training loss: 0.0299, discriminator training loss: 0.0117, validation loss: 0.1478
2024-05-25 05:17:36 [INFO]: Epoch 166 - generator training loss: 0.0296, discriminator training loss: 0.0117, validation loss: 0.1480
2024-05-25 05:17:40 [INFO]: Epoch 167 - generator training loss: 0.0293, discriminator training loss: 0.0119, validation loss: 0.1479
2024-05-25 05:17:44 [INFO]: Epoch 168 - generator training loss: 0.0299, discriminator training loss: 0.0118, validation loss: 0.1475
2024-05-25 05:17:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:17:44 [INFO]: Finished training. The best model is from epoch#158.
2024-05-25 05:17:44 [INFO]: Saved the model to augmentation_saved_results/round_4/USGAN_air_quality/20240525_T050617/USGAN.pypots
2024-05-25 05:17:45 [INFO]: US-GAN on Air-Quality: MAE=0.1508, MSE=0.0915
2024-05-25 05:17:45 [INFO]: Successfully saved to augmentation_saved_results/round_4/USGAN_air_quality/imputation.pkl
2024-05-25 05:17:45 [INFO]: Using the given device: cuda:0
2024-05-25 05:17:45 [INFO]: Model files will be saved to augmentation_saved_results/round_4/BRITS_air_quality/20240525_T051745
2024-05-25 05:17:45 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/BRITS_air_quality/20240525_T051745/tensorboard
2024-05-25 05:17:45 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 05:17:48 [INFO]: Epoch 001 - training loss: 1.4093, validation loss: 0.9690
2024-05-25 05:17:51 [INFO]: Epoch 002 - training loss: 1.1338, validation loss: 0.7266
2024-05-25 05:17:54 [INFO]: Epoch 003 - training loss: 0.9439, validation loss: 0.6138
2024-05-25 05:17:57 [INFO]: Epoch 004 - training loss: 0.8333, validation loss: 0.5469
2024-05-25 05:17:59 [INFO]: Epoch 005 - training loss: 0.7599, validation loss: 0.4995
2024-05-25 05:18:02 [INFO]: Epoch 006 - training loss: 0.7041, validation loss: 0.4633
2024-05-25 05:18:05 [INFO]: Epoch 007 - training loss: 0.6598, validation loss: 0.4354
2024-05-25 05:18:08 [INFO]: Epoch 008 - training loss: 0.6258, validation loss: 0.4119
2024-05-25 05:18:11 [INFO]: Epoch 009 - training loss: 0.5992, validation loss: 0.3937
2024-05-25 05:18:13 [INFO]: Epoch 010 - training loss: 0.5766, validation loss: 0.3782
2024-05-25 05:18:16 [INFO]: Epoch 011 - training loss: 0.5590, validation loss: 0.3644
2024-05-25 05:18:19 [INFO]: Epoch 012 - training loss: 0.5441, validation loss: 0.3544
2024-05-25 05:18:22 [INFO]: Epoch 013 - training loss: 0.5288, validation loss: 0.3443
2024-05-25 05:18:24 [INFO]: Epoch 014 - training loss: 0.5186, validation loss: 0.3359
2024-05-25 05:18:27 [INFO]: Epoch 015 - training loss: 0.5082, validation loss: 0.3286
2024-05-25 05:18:30 [INFO]: Epoch 016 - training loss: 0.4990, validation loss: 0.3221
2024-05-25 05:18:33 [INFO]: Epoch 017 - training loss: 0.4879, validation loss: 0.3163
2024-05-25 05:18:36 [INFO]: Epoch 018 - training loss: 0.4797, validation loss: 0.3100
2024-05-25 05:18:38 [INFO]: Epoch 019 - training loss: 0.4717, validation loss: 0.3052
2024-05-25 05:18:41 [INFO]: Epoch 020 - training loss: 0.4634, validation loss: 0.3007
2024-05-25 05:18:44 [INFO]: Epoch 021 - training loss: 0.4568, validation loss: 0.2964
2024-05-25 05:18:47 [INFO]: Epoch 022 - training loss: 0.4493, validation loss: 0.2921
2024-05-25 05:18:50 [INFO]: Epoch 023 - training loss: 0.4436, validation loss: 0.2881
2024-05-25 05:18:52 [INFO]: Epoch 024 - training loss: 0.4372, validation loss: 0.2846
2024-05-25 05:18:55 [INFO]: Epoch 025 - training loss: 0.4311, validation loss: 0.2807
2024-05-25 05:18:58 [INFO]: Epoch 026 - training loss: 0.4260, validation loss: 0.2773
2024-05-25 05:19:01 [INFO]: Epoch 027 - training loss: 0.4206, validation loss: 0.2740
2024-05-25 05:19:04 [INFO]: Epoch 028 - training loss: 0.4158, validation loss: 0.2710
2024-05-25 05:19:06 [INFO]: Epoch 029 - training loss: 0.4110, validation loss: 0.2676
2024-05-25 05:19:09 [INFO]: Epoch 030 - training loss: 0.4071, validation loss: 0.2650
2024-05-25 05:19:12 [INFO]: Epoch 031 - training loss: 0.4017, validation loss: 0.2620
2024-05-25 05:19:15 [INFO]: Epoch 032 - training loss: 0.3968, validation loss: 0.2594
2024-05-25 05:19:18 [INFO]: Epoch 033 - training loss: 0.3935, validation loss: 0.2568
2024-05-25 05:19:20 [INFO]: Epoch 034 - training loss: 0.3894, validation loss: 0.2542
2024-05-25 05:19:23 [INFO]: Epoch 035 - training loss: 0.3853, validation loss: 0.2519
2024-05-25 05:19:26 [INFO]: Epoch 036 - training loss: 0.3809, validation loss: 0.2499
2024-05-25 05:19:29 [INFO]: Epoch 037 - training loss: 0.3774, validation loss: 0.2478
2024-05-25 05:19:31 [INFO]: Epoch 038 - training loss: 0.3738, validation loss: 0.2456
2024-05-25 05:19:34 [INFO]: Epoch 039 - training loss: 0.3710, validation loss: 0.2434
2024-05-25 05:19:37 [INFO]: Epoch 040 - training loss: 0.3689, validation loss: 0.2413
2024-05-25 05:19:40 [INFO]: Epoch 041 - training loss: 0.3640, validation loss: 0.2397
2024-05-25 05:19:42 [INFO]: Epoch 042 - training loss: 0.3618, validation loss: 0.2385
2024-05-25 05:19:45 [INFO]: Epoch 043 - training loss: 0.3584, validation loss: 0.2365
2024-05-25 05:19:48 [INFO]: Epoch 044 - training loss: 0.3557, validation loss: 0.2351
2024-05-25 05:19:51 [INFO]: Epoch 045 - training loss: 0.3531, validation loss: 0.2338
2024-05-25 05:19:54 [INFO]: Epoch 046 - training loss: 0.3502, validation loss: 0.2328
2024-05-25 05:19:56 [INFO]: Epoch 047 - training loss: 0.3474, validation loss: 0.2319
2024-05-25 05:19:59 [INFO]: Epoch 048 - training loss: 0.3458, validation loss: 0.2309
2024-05-25 05:20:02 [INFO]: Epoch 049 - training loss: 0.3430, validation loss: 0.2301
2024-05-25 05:20:05 [INFO]: Epoch 050 - training loss: 0.3406, validation loss: 0.2291
2024-05-25 05:20:08 [INFO]: Epoch 051 - training loss: 0.3378, validation loss: 0.2286
2024-05-25 05:20:10 [INFO]: Epoch 052 - training loss: 0.3360, validation loss: 0.2277
2024-05-25 05:20:13 [INFO]: Epoch 053 - training loss: 0.3341, validation loss: 0.2269
2024-05-25 05:20:16 [INFO]: Epoch 054 - training loss: 0.3317, validation loss: 0.2265
2024-05-25 05:20:19 [INFO]: Epoch 055 - training loss: 0.3298, validation loss: 0.2259
2024-05-25 05:20:22 [INFO]: Epoch 056 - training loss: 0.3274, validation loss: 0.2250
2024-05-25 05:20:24 [INFO]: Epoch 057 - training loss: 0.3262, validation loss: 0.2244
2024-05-25 05:20:27 [INFO]: Epoch 058 - training loss: 0.3232, validation loss: 0.2241
2024-05-25 05:20:30 [INFO]: Epoch 059 - training loss: 0.3216, validation loss: 0.2239
2024-05-25 05:20:33 [INFO]: Epoch 060 - training loss: 0.3200, validation loss: 0.2229
2024-05-25 05:20:36 [INFO]: Epoch 061 - training loss: 0.3189, validation loss: 0.2223
2024-05-25 05:20:38 [INFO]: Epoch 062 - training loss: 0.3173, validation loss: 0.2221
2024-05-25 05:20:41 [INFO]: Epoch 063 - training loss: 0.3158, validation loss: 0.2210
2024-05-25 05:20:44 [INFO]: Epoch 064 - training loss: 0.3148, validation loss: 0.2205
2024-05-25 05:20:47 [INFO]: Epoch 065 - training loss: 0.3133, validation loss: 0.2202
2024-05-25 05:20:49 [INFO]: Epoch 066 - training loss: 0.3118, validation loss: 0.2193
2024-05-25 05:20:52 [INFO]: Epoch 067 - training loss: 0.3097, validation loss: 0.2188
2024-05-25 05:20:55 [INFO]: Epoch 068 - training loss: 0.3086, validation loss: 0.2182
2024-05-25 05:20:58 [INFO]: Epoch 069 - training loss: 0.3073, validation loss: 0.2175
2024-05-25 05:21:01 [INFO]: Epoch 070 - training loss: 0.3066, validation loss: 0.2169
2024-05-25 05:21:04 [INFO]: Epoch 071 - training loss: 0.3048, validation loss: 0.2167
2024-05-25 05:21:06 [INFO]: Epoch 072 - training loss: 0.3034, validation loss: 0.2156
2024-05-25 05:21:09 [INFO]: Epoch 073 - training loss: 0.3028, validation loss: 0.2151
2024-05-25 05:21:12 [INFO]: Epoch 074 - training loss: 0.3022, validation loss: 0.2145
2024-05-25 05:21:15 [INFO]: Epoch 075 - training loss: 0.3007, validation loss: 0.2138
2024-05-25 05:21:18 [INFO]: Epoch 076 - training loss: 0.3002, validation loss: 0.2133
2024-05-25 05:21:20 [INFO]: Epoch 077 - training loss: 0.2987, validation loss: 0.2126
2024-05-25 05:21:23 [INFO]: Epoch 078 - training loss: 0.2977, validation loss: 0.2121
2024-05-25 05:21:26 [INFO]: Epoch 079 - training loss: 0.2970, validation loss: 0.2118
2024-05-25 05:21:29 [INFO]: Epoch 080 - training loss: 0.2955, validation loss: 0.2113
2024-05-25 05:21:31 [INFO]: Epoch 081 - training loss: 0.2954, validation loss: 0.2105
2024-05-25 05:21:34 [INFO]: Epoch 082 - training loss: 0.2940, validation loss: 0.2099
2024-05-25 05:21:37 [INFO]: Epoch 083 - training loss: 0.2933, validation loss: 0.2093
2024-05-25 05:21:40 [INFO]: Epoch 084 - training loss: 0.2919, validation loss: 0.2089
2024-05-25 05:21:43 [INFO]: Epoch 085 - training loss: 0.2912, validation loss: 0.2084
2024-05-25 05:21:45 [INFO]: Epoch 086 - training loss: 0.2901, validation loss: 0.2078
2024-05-25 05:21:48 [INFO]: Epoch 087 - training loss: 0.2904, validation loss: 0.2071
2024-05-25 05:21:51 [INFO]: Epoch 088 - training loss: 0.2893, validation loss: 0.2068
2024-05-25 05:21:54 [INFO]: Epoch 089 - training loss: 0.2881, validation loss: 0.2061
2024-05-25 05:21:57 [INFO]: Epoch 090 - training loss: 0.2871, validation loss: 0.2055
2024-05-25 05:21:59 [INFO]: Epoch 091 - training loss: 0.2863, validation loss: 0.2051
2024-05-25 05:22:02 [INFO]: Epoch 092 - training loss: 0.2858, validation loss: 0.2046
2024-05-25 05:22:05 [INFO]: Epoch 093 - training loss: 0.2852, validation loss: 0.2041
2024-05-25 05:22:08 [INFO]: Epoch 094 - training loss: 0.2842, validation loss: 0.2034
2024-05-25 05:22:11 [INFO]: Epoch 095 - training loss: 0.2838, validation loss: 0.2032
2024-05-25 05:22:13 [INFO]: Epoch 096 - training loss: 0.2830, validation loss: 0.2024
2024-05-25 05:22:16 [INFO]: Epoch 097 - training loss: 0.2826, validation loss: 0.2021
2024-05-25 05:22:19 [INFO]: Epoch 098 - training loss: 0.2820, validation loss: 0.2015
2024-05-25 05:22:22 [INFO]: Epoch 099 - training loss: 0.2807, validation loss: 0.2011
2024-05-25 05:22:25 [INFO]: Epoch 100 - training loss: 0.2804, validation loss: 0.2006
2024-05-25 05:22:27 [INFO]: Epoch 101 - training loss: 0.2802, validation loss: 0.1999
2024-05-25 05:22:30 [INFO]: Epoch 102 - training loss: 0.2791, validation loss: 0.1997
2024-05-25 05:22:33 [INFO]: Epoch 103 - training loss: 0.2790, validation loss: 0.1993
2024-05-25 05:22:36 [INFO]: Epoch 104 - training loss: 0.2779, validation loss: 0.1983
2024-05-25 05:22:39 [INFO]: Epoch 105 - training loss: 0.2776, validation loss: 0.1981
2024-05-25 05:22:41 [INFO]: Epoch 106 - training loss: 0.2768, validation loss: 0.1977
2024-05-25 05:22:44 [INFO]: Epoch 107 - training loss: 0.2763, validation loss: 0.1969
2024-05-25 05:22:47 [INFO]: Epoch 108 - training loss: 0.2756, validation loss: 0.1965
2024-05-25 05:22:50 [INFO]: Epoch 109 - training loss: 0.2747, validation loss: 0.1962
2024-05-25 05:22:52 [INFO]: Epoch 110 - training loss: 0.2746, validation loss: 0.1958
2024-05-25 05:22:55 [INFO]: Epoch 111 - training loss: 0.2743, validation loss: 0.1952
2024-05-25 05:22:58 [INFO]: Epoch 112 - training loss: 0.2732, validation loss: 0.1948
2024-05-25 05:23:01 [INFO]: Epoch 113 - training loss: 0.2729, validation loss: 0.1943
2024-05-25 05:23:04 [INFO]: Epoch 114 - training loss: 0.2720, validation loss: 0.1939
2024-05-25 05:23:07 [INFO]: Epoch 115 - training loss: 0.2721, validation loss: 0.1935
2024-05-25 05:23:09 [INFO]: Epoch 116 - training loss: 0.2713, validation loss: 0.1930
2024-05-25 05:23:12 [INFO]: Epoch 117 - training loss: 0.2706, validation loss: 0.1926
2024-05-25 05:23:15 [INFO]: Epoch 118 - training loss: 0.2703, validation loss: 0.1923
2024-05-25 05:23:18 [INFO]: Epoch 119 - training loss: 0.2700, validation loss: 0.1920
2024-05-25 05:23:21 [INFO]: Epoch 120 - training loss: 0.2703, validation loss: 0.1915
2024-05-25 05:23:23 [INFO]: Epoch 121 - training loss: 0.2687, validation loss: 0.1911
2024-05-25 05:23:26 [INFO]: Epoch 122 - training loss: 0.2684, validation loss: 0.1908
2024-05-25 05:23:29 [INFO]: Epoch 123 - training loss: 0.2680, validation loss: 0.1905
2024-05-25 05:23:32 [INFO]: Epoch 124 - training loss: 0.2672, validation loss: 0.1900
2024-05-25 05:23:34 [INFO]: Epoch 125 - training loss: 0.2673, validation loss: 0.1896
2024-05-25 05:23:37 [INFO]: Epoch 126 - training loss: 0.2667, validation loss: 0.1893
2024-05-25 05:23:40 [INFO]: Epoch 127 - training loss: 0.2663, validation loss: 0.1889
2024-05-25 05:23:43 [INFO]: Epoch 128 - training loss: 0.2655, validation loss: 0.1885
2024-05-25 05:23:46 [INFO]: Epoch 129 - training loss: 0.2653, validation loss: 0.1881
2024-05-25 05:23:48 [INFO]: Epoch 130 - training loss: 0.2649, validation loss: 0.1878
2024-05-25 05:23:51 [INFO]: Epoch 131 - training loss: 0.2647, validation loss: 0.1873
2024-05-25 05:23:54 [INFO]: Epoch 132 - training loss: 0.2638, validation loss: 0.1872
2024-05-25 05:23:57 [INFO]: Epoch 133 - training loss: 0.2636, validation loss: 0.1867
2024-05-25 05:24:00 [INFO]: Epoch 134 - training loss: 0.2635, validation loss: 0.1865
2024-05-25 05:24:02 [INFO]: Epoch 135 - training loss: 0.2630, validation loss: 0.1859
2024-05-25 05:24:05 [INFO]: Epoch 136 - training loss: 0.2624, validation loss: 0.1857
2024-05-25 05:24:08 [INFO]: Epoch 137 - training loss: 0.2622, validation loss: 0.1854
2024-05-25 05:24:11 [INFO]: Epoch 138 - training loss: 0.2615, validation loss: 0.1851
2024-05-25 05:24:14 [INFO]: Epoch 139 - training loss: 0.2610, validation loss: 0.1848
2024-05-25 05:24:16 [INFO]: Epoch 140 - training loss: 0.2604, validation loss: 0.1844
2024-05-25 05:24:19 [INFO]: Epoch 141 - training loss: 0.2606, validation loss: 0.1842
2024-05-25 05:24:22 [INFO]: Epoch 142 - training loss: 0.2603, validation loss: 0.1838
2024-05-25 05:24:25 [INFO]: Epoch 143 - training loss: 0.2593, validation loss: 0.1833
2024-05-25 05:24:28 [INFO]: Epoch 144 - training loss: 0.2589, validation loss: 0.1831
2024-05-25 05:24:30 [INFO]: Epoch 145 - training loss: 0.2592, validation loss: 0.1828
2024-05-25 05:24:33 [INFO]: Epoch 146 - training loss: 0.2587, validation loss: 0.1824
2024-05-25 05:24:36 [INFO]: Epoch 147 - training loss: 0.2580, validation loss: 0.1820
2024-05-25 05:24:39 [INFO]: Epoch 148 - training loss: 0.2572, validation loss: 0.1818
2024-05-25 05:24:41 [INFO]: Epoch 149 - training loss: 0.2577, validation loss: 0.1816
2024-05-25 05:24:44 [INFO]: Epoch 150 - training loss: 0.2575, validation loss: 0.1811
2024-05-25 05:24:47 [INFO]: Epoch 151 - training loss: 0.2569, validation loss: 0.1810
2024-05-25 05:24:50 [INFO]: Epoch 152 - training loss: 0.2571, validation loss: 0.1808
2024-05-25 05:24:53 [INFO]: Epoch 153 - training loss: 0.2558, validation loss: 0.1803
2024-05-25 05:24:55 [INFO]: Epoch 154 - training loss: 0.2561, validation loss: 0.1802
2024-05-25 05:24:58 [INFO]: Epoch 155 - training loss: 0.2552, validation loss: 0.1798
2024-05-25 05:25:01 [INFO]: Epoch 156 - training loss: 0.2553, validation loss: 0.1795
2024-05-25 05:25:04 [INFO]: Epoch 157 - training loss: 0.2555, validation loss: 0.1793
2024-05-25 05:25:07 [INFO]: Epoch 158 - training loss: 0.2543, validation loss: 0.1791
2024-05-25 05:25:10 [INFO]: Epoch 159 - training loss: 0.2545, validation loss: 0.1787
2024-05-25 05:25:12 [INFO]: Epoch 160 - training loss: 0.2538, validation loss: 0.1783
2024-05-25 05:25:15 [INFO]: Epoch 161 - training loss: 0.2535, validation loss: 0.1783
2024-05-25 05:25:18 [INFO]: Epoch 162 - training loss: 0.2535, validation loss: 0.1781
2024-05-25 05:25:21 [INFO]: Epoch 163 - training loss: 0.2539, validation loss: 0.1777
2024-05-25 05:25:23 [INFO]: Epoch 164 - training loss: 0.2529, validation loss: 0.1774
2024-05-25 05:25:26 [INFO]: Epoch 165 - training loss: 0.2526, validation loss: 0.1772
2024-05-25 05:25:29 [INFO]: Epoch 166 - training loss: 0.2522, validation loss: 0.1769
2024-05-25 05:25:32 [INFO]: Epoch 167 - training loss: 0.2522, validation loss: 0.1767
2024-05-25 05:25:35 [INFO]: Epoch 168 - training loss: 0.2518, validation loss: 0.1764
2024-05-25 05:25:37 [INFO]: Epoch 169 - training loss: 0.2514, validation loss: 0.1762
2024-05-25 05:25:40 [INFO]: Epoch 170 - training loss: 0.2513, validation loss: 0.1759
2024-05-25 05:25:43 [INFO]: Epoch 171 - training loss: 0.2510, validation loss: 0.1758
2024-05-25 05:25:46 [INFO]: Epoch 172 - training loss: 0.2508, validation loss: 0.1756
2024-05-25 05:25:49 [INFO]: Epoch 173 - training loss: 0.2501, validation loss: 0.1752
2024-05-25 05:25:51 [INFO]: Epoch 174 - training loss: 0.2498, validation loss: 0.1750
2024-05-25 05:25:54 [INFO]: Epoch 175 - training loss: 0.2499, validation loss: 0.1748
2024-05-25 05:25:57 [INFO]: Epoch 176 - training loss: 0.2499, validation loss: 0.1748
2024-05-25 05:26:00 [INFO]: Epoch 177 - training loss: 0.2492, validation loss: 0.1745
2024-05-25 05:26:03 [INFO]: Epoch 178 - training loss: 0.2490, validation loss: 0.1742
2024-05-25 05:26:05 [INFO]: Epoch 179 - training loss: 0.2490, validation loss: 0.1740
2024-05-25 05:26:08 [INFO]: Epoch 180 - training loss: 0.2485, validation loss: 0.1737
2024-05-25 05:26:11 [INFO]: Epoch 181 - training loss: 0.2484, validation loss: 0.1735
2024-05-25 05:26:14 [INFO]: Epoch 182 - training loss: 0.2482, validation loss: 0.1735
2024-05-25 05:26:17 [INFO]: Epoch 183 - training loss: 0.2476, validation loss: 0.1732
2024-05-25 05:26:19 [INFO]: Epoch 184 - training loss: 0.2479, validation loss: 0.1731
2024-05-25 05:26:22 [INFO]: Epoch 185 - training loss: 0.2477, validation loss: 0.1727
2024-05-25 05:26:25 [INFO]: Epoch 186 - training loss: 0.2479, validation loss: 0.1726
2024-05-25 05:26:28 [INFO]: Epoch 187 - training loss: 0.2471, validation loss: 0.1723
2024-05-25 05:26:30 [INFO]: Epoch 188 - training loss: 0.2470, validation loss: 0.1722
2024-05-25 05:26:33 [INFO]: Epoch 189 - training loss: 0.2461, validation loss: 0.1719
2024-05-25 05:26:36 [INFO]: Epoch 190 - training loss: 0.2461, validation loss: 0.1719
2024-05-25 05:26:39 [INFO]: Epoch 191 - training loss: 0.2460, validation loss: 0.1716
2024-05-25 05:26:42 [INFO]: Epoch 192 - training loss: 0.2459, validation loss: 0.1714
2024-05-25 05:26:44 [INFO]: Epoch 193 - training loss: 0.2456, validation loss: 0.1712
2024-05-25 05:26:47 [INFO]: Epoch 194 - training loss: 0.2452, validation loss: 0.1712
2024-05-25 05:26:50 [INFO]: Epoch 195 - training loss: 0.2452, validation loss: 0.1709
2024-05-25 05:26:53 [INFO]: Epoch 196 - training loss: 0.2450, validation loss: 0.1706
2024-05-25 05:26:56 [INFO]: Epoch 197 - training loss: 0.2445, validation loss: 0.1706
2024-05-25 05:26:58 [INFO]: Epoch 198 - training loss: 0.2443, validation loss: 0.1705
2024-05-25 05:27:01 [INFO]: Epoch 199 - training loss: 0.2450, validation loss: 0.1702
2024-05-25 05:27:04 [INFO]: Epoch 200 - training loss: 0.2442, validation loss: 0.1700
2024-05-25 05:27:07 [INFO]: Epoch 201 - training loss: 0.2436, validation loss: 0.1700
2024-05-25 05:27:10 [INFO]: Epoch 202 - training loss: 0.2435, validation loss: 0.1697
2024-05-25 05:27:12 [INFO]: Epoch 203 - training loss: 0.2435, validation loss: 0.1694
2024-05-25 05:27:15 [INFO]: Epoch 204 - training loss: 0.2434, validation loss: 0.1694
2024-05-25 05:27:18 [INFO]: Epoch 205 - training loss: 0.2435, validation loss: 0.1693
2024-05-25 05:27:21 [INFO]: Epoch 206 - training loss: 0.2429, validation loss: 0.1692
2024-05-25 05:27:24 [INFO]: Epoch 207 - training loss: 0.2426, validation loss: 0.1688
2024-05-25 05:27:26 [INFO]: Epoch 208 - training loss: 0.2425, validation loss: 0.1687
2024-05-25 05:27:29 [INFO]: Epoch 209 - training loss: 0.2428, validation loss: 0.1685
2024-05-25 05:27:32 [INFO]: Epoch 210 - training loss: 0.2422, validation loss: 0.1685
2024-05-25 05:27:35 [INFO]: Epoch 211 - training loss: 0.2424, validation loss: 0.1682
2024-05-25 05:27:38 [INFO]: Epoch 212 - training loss: 0.2426, validation loss: 0.1683
2024-05-25 05:27:40 [INFO]: Epoch 213 - training loss: 0.2420, validation loss: 0.1679
2024-05-25 05:27:43 [INFO]: Epoch 214 - training loss: 0.2416, validation loss: 0.1677
2024-05-25 05:27:46 [INFO]: Epoch 215 - training loss: 0.2415, validation loss: 0.1676
2024-05-25 05:27:49 [INFO]: Epoch 216 - training loss: 0.2413, validation loss: 0.1676
2024-05-25 05:27:52 [INFO]: Epoch 217 - training loss: 0.2411, validation loss: 0.1674
2024-05-25 05:27:54 [INFO]: Epoch 218 - training loss: 0.2406, validation loss: 0.1671
2024-05-25 05:27:57 [INFO]: Epoch 219 - training loss: 0.2402, validation loss: 0.1670
2024-05-25 05:28:00 [INFO]: Epoch 220 - training loss: 0.2405, validation loss: 0.1669
2024-05-25 05:28:03 [INFO]: Epoch 221 - training loss: 0.2406, validation loss: 0.1668
2024-05-25 05:28:06 [INFO]: Epoch 222 - training loss: 0.2405, validation loss: 0.1666
2024-05-25 05:28:08 [INFO]: Epoch 223 - training loss: 0.2402, validation loss: 0.1664
2024-05-25 05:28:11 [INFO]: Epoch 224 - training loss: 0.2396, validation loss: 0.1664
2024-05-25 05:28:14 [INFO]: Epoch 225 - training loss: 0.2397, validation loss: 0.1661
2024-05-25 05:28:17 [INFO]: Epoch 226 - training loss: 0.2399, validation loss: 0.1662
2024-05-25 05:28:20 [INFO]: Epoch 227 - training loss: 0.2389, validation loss: 0.1660
2024-05-25 05:28:22 [INFO]: Epoch 228 - training loss: 0.2389, validation loss: 0.1657
2024-05-25 05:28:25 [INFO]: Epoch 229 - training loss: 0.2391, validation loss: 0.1659
2024-05-25 05:28:28 [INFO]: Epoch 230 - training loss: 0.2385, validation loss: 0.1656
2024-05-25 05:28:31 [INFO]: Epoch 231 - training loss: 0.2388, validation loss: 0.1655
2024-05-25 05:28:34 [INFO]: Epoch 232 - training loss: 0.2383, validation loss: 0.1653
2024-05-25 05:28:36 [INFO]: Epoch 233 - training loss: 0.2381, validation loss: 0.1652
2024-05-25 05:28:39 [INFO]: Epoch 234 - training loss: 0.2377, validation loss: 0.1651
2024-05-25 05:28:42 [INFO]: Epoch 235 - training loss: 0.2380, validation loss: 0.1651
2024-05-25 05:28:45 [INFO]: Epoch 236 - training loss: 0.2382, validation loss: 0.1649
2024-05-25 05:28:48 [INFO]: Epoch 237 - training loss: 0.2377, validation loss: 0.1647
2024-05-25 05:28:50 [INFO]: Epoch 238 - training loss: 0.2375, validation loss: 0.1647
2024-05-25 05:28:53 [INFO]: Epoch 239 - training loss: 0.2371, validation loss: 0.1646
2024-05-25 05:28:56 [INFO]: Epoch 240 - training loss: 0.2372, validation loss: 0.1644
2024-05-25 05:28:59 [INFO]: Epoch 241 - training loss: 0.2374, validation loss: 0.1642
2024-05-25 05:29:02 [INFO]: Epoch 242 - training loss: 0.2368, validation loss: 0.1641
2024-05-25 05:29:04 [INFO]: Epoch 243 - training loss: 0.2367, validation loss: 0.1640
2024-05-25 05:29:07 [INFO]: Epoch 244 - training loss: 0.2365, validation loss: 0.1640
2024-05-25 05:29:10 [INFO]: Epoch 245 - training loss: 0.2366, validation loss: 0.1637
2024-05-25 05:29:13 [INFO]: Epoch 246 - training loss: 0.2363, validation loss: 0.1637
2024-05-25 05:29:16 [INFO]: Epoch 247 - training loss: 0.2362, validation loss: 0.1635
2024-05-25 05:29:19 [INFO]: Epoch 248 - training loss: 0.2361, validation loss: 0.1635
2024-05-25 05:29:21 [INFO]: Epoch 249 - training loss: 0.2360, validation loss: 0.1634
2024-05-25 05:29:24 [INFO]: Epoch 250 - training loss: 0.2358, validation loss: 0.1633
2024-05-25 05:29:27 [INFO]: Epoch 251 - training loss: 0.2359, validation loss: 0.1631
2024-05-25 05:29:30 [INFO]: Epoch 252 - training loss: 0.2351, validation loss: 0.1629
2024-05-25 05:29:33 [INFO]: Epoch 253 - training loss: 0.2361, validation loss: 0.1628
2024-05-25 05:29:35 [INFO]: Epoch 254 - training loss: 0.2353, validation loss: 0.1631
2024-05-25 05:29:38 [INFO]: Epoch 255 - training loss: 0.2353, validation loss: 0.1628
2024-05-25 05:29:41 [INFO]: Epoch 256 - training loss: 0.2350, validation loss: 0.1628
2024-05-25 05:29:44 [INFO]: Epoch 257 - training loss: 0.2348, validation loss: 0.1625
2024-05-25 05:29:47 [INFO]: Epoch 258 - training loss: 0.2344, validation loss: 0.1624
2024-05-25 05:29:49 [INFO]: Epoch 259 - training loss: 0.2346, validation loss: 0.1623
2024-05-25 05:29:52 [INFO]: Epoch 260 - training loss: 0.2340, validation loss: 0.1623
2024-05-25 05:29:55 [INFO]: Epoch 261 - training loss: 0.2341, validation loss: 0.1623
2024-05-25 05:29:58 [INFO]: Epoch 262 - training loss: 0.2342, validation loss: 0.1620
2024-05-25 05:30:01 [INFO]: Epoch 263 - training loss: 0.2337, validation loss: 0.1619
2024-05-25 05:30:03 [INFO]: Epoch 264 - training loss: 0.2339, validation loss: 0.1619
2024-05-25 05:30:06 [INFO]: Epoch 265 - training loss: 0.2338, validation loss: 0.1619
2024-05-25 05:30:09 [INFO]: Epoch 266 - training loss: 0.2334, validation loss: 0.1617
2024-05-25 05:30:12 [INFO]: Epoch 267 - training loss: 0.2334, validation loss: 0.1617
2024-05-25 05:30:15 [INFO]: Epoch 268 - training loss: 0.2336, validation loss: 0.1617
2024-05-25 05:30:17 [INFO]: Epoch 269 - training loss: 0.2335, validation loss: 0.1615
2024-05-25 05:30:20 [INFO]: Epoch 270 - training loss: 0.2331, validation loss: 0.1615
2024-05-25 05:30:23 [INFO]: Epoch 271 - training loss: 0.2326, validation loss: 0.1615
2024-05-25 05:30:26 [INFO]: Epoch 272 - training loss: 0.2329, validation loss: 0.1611
2024-05-25 05:30:29 [INFO]: Epoch 273 - training loss: 0.2331, validation loss: 0.1611
2024-05-25 05:30:31 [INFO]: Epoch 274 - training loss: 0.2329, validation loss: 0.1611
2024-05-25 05:30:34 [INFO]: Epoch 275 - training loss: 0.2325, validation loss: 0.1610
2024-05-25 05:30:37 [INFO]: Epoch 276 - training loss: 0.2324, validation loss: 0.1609
2024-05-25 05:30:40 [INFO]: Epoch 277 - training loss: 0.2320, validation loss: 0.1608
2024-05-25 05:30:43 [INFO]: Epoch 278 - training loss: 0.2322, validation loss: 0.1609
2024-05-25 05:30:45 [INFO]: Epoch 279 - training loss: 0.2317, validation loss: 0.1607
2024-05-25 05:30:48 [INFO]: Epoch 280 - training loss: 0.2316, validation loss: 0.1608
2024-05-25 05:30:51 [INFO]: Epoch 281 - training loss: 0.2317, validation loss: 0.1605
2024-05-25 05:30:54 [INFO]: Epoch 282 - training loss: 0.2313, validation loss: 0.1605
2024-05-25 05:30:57 [INFO]: Epoch 283 - training loss: 0.2318, validation loss: 0.1604
2024-05-25 05:31:00 [INFO]: Epoch 284 - training loss: 0.2314, validation loss: 0.1603
2024-05-25 05:31:02 [INFO]: Epoch 285 - training loss: 0.2311, validation loss: 0.1603
2024-05-25 05:31:05 [INFO]: Epoch 286 - training loss: 0.2313, validation loss: 0.1602
2024-05-25 05:31:08 [INFO]: Epoch 287 - training loss: 0.2318, validation loss: 0.1601
2024-05-25 05:31:11 [INFO]: Epoch 288 - training loss: 0.2309, validation loss: 0.1601
2024-05-25 05:31:14 [INFO]: Epoch 289 - training loss: 0.2311, validation loss: 0.1600
2024-05-25 05:31:16 [INFO]: Epoch 290 - training loss: 0.2306, validation loss: 0.1600
2024-05-25 05:31:19 [INFO]: Epoch 291 - training loss: 0.2304, validation loss: 0.1601
2024-05-25 05:31:22 [INFO]: Epoch 292 - training loss: 0.2308, validation loss: 0.1599
2024-05-25 05:31:25 [INFO]: Epoch 293 - training loss: 0.2305, validation loss: 0.1597
2024-05-25 05:31:28 [INFO]: Epoch 294 - training loss: 0.2305, validation loss: 0.1596
2024-05-25 05:31:31 [INFO]: Epoch 295 - training loss: 0.2302, validation loss: 0.1595
2024-05-25 05:31:33 [INFO]: Epoch 296 - training loss: 0.2305, validation loss: 0.1596
2024-05-25 05:31:36 [INFO]: Epoch 297 - training loss: 0.2309, validation loss: 0.1593
2024-05-25 05:31:39 [INFO]: Epoch 298 - training loss: 0.2297, validation loss: 0.1593
2024-05-25 05:31:42 [INFO]: Epoch 299 - training loss: 0.2302, validation loss: 0.1593
2024-05-25 05:31:45 [INFO]: Epoch 300 - training loss: 0.2299, validation loss: 0.1591
2024-05-25 05:31:45 [INFO]: Finished training. The best model is from epoch#300.
2024-05-25 05:31:45 [INFO]: Saved the model to augmentation_saved_results/round_4/BRITS_air_quality/20240525_T051745/BRITS.pypots
2024-05-25 05:31:45 [INFO]: BRITS on Air-Quality: MAE=0.1392, MSE=0.0909
2024-05-25 05:31:45 [INFO]: Successfully saved to augmentation_saved_results/round_4/BRITS_air_quality/imputation.pkl
2024-05-25 05:31:45 [INFO]: Using the given device: cuda:0
2024-05-25 05:31:45 [INFO]: Model files will be saved to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145
2024-05-25 05:31:45 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/tensorboard
2024-05-25 05:31:45 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 05:31:50 [INFO]: Epoch 001 - training loss: 1.4238, validation loss: 0.8375
2024-05-25 05:31:50 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch1_loss0.837485209107399.pypots
2024-05-25 05:31:54 [INFO]: Epoch 002 - training loss: 1.0596, validation loss: 0.7771
2024-05-25 05:31:54 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch2_loss0.7770786643028259.pypots
2024-05-25 05:31:58 [INFO]: Epoch 003 - training loss: 0.9722, validation loss: 0.7548
2024-05-25 05:31:58 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch3_loss0.7547855794429779.pypots
2024-05-25 05:32:02 [INFO]: Epoch 004 - training loss: 0.9588, validation loss: 0.7416
2024-05-25 05:32:02 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch4_loss0.7416211545467377.pypots
2024-05-25 05:32:05 [INFO]: Epoch 005 - training loss: 0.9528, validation loss: 0.7320
2024-05-25 05:32:05 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch5_loss0.7320024758577347.pypots
2024-05-25 05:32:09 [INFO]: Epoch 006 - training loss: 0.9347, validation loss: 0.7255
2024-05-25 05:32:09 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch6_loss0.7254903733730316.pypots
2024-05-25 05:32:13 [INFO]: Epoch 007 - training loss: 0.9248, validation loss: 0.7208
2024-05-25 05:32:13 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch7_loss0.720796924829483.pypots
2024-05-25 05:32:17 [INFO]: Epoch 008 - training loss: 0.9284, validation loss: 0.7171
2024-05-25 05:32:17 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch8_loss0.7170714676380158.pypots
2024-05-25 05:32:21 [INFO]: Epoch 009 - training loss: 0.9157, validation loss: 0.7136
2024-05-25 05:32:21 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch9_loss0.7136270195245743.pypots
2024-05-25 05:32:25 [INFO]: Epoch 010 - training loss: 0.8964, validation loss: 0.7114
2024-05-25 05:32:25 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch10_loss0.7114190310239792.pypots
2024-05-25 05:32:29 [INFO]: Epoch 011 - training loss: 0.9117, validation loss: 0.7112
2024-05-25 05:32:29 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch11_loss0.7111728727817536.pypots
2024-05-25 05:32:32 [INFO]: Epoch 012 - training loss: 0.9035, validation loss: 0.7097
2024-05-25 05:32:32 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch12_loss0.7096878230571747.pypots
2024-05-25 05:32:36 [INFO]: Epoch 013 - training loss: 0.8863, validation loss: 0.7087
2024-05-25 05:32:36 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch13_loss0.7087483882904053.pypots
2024-05-25 05:32:40 [INFO]: Epoch 014 - training loss: 0.9210, validation loss: 0.7068
2024-05-25 05:32:40 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch14_loss0.7067880451679229.pypots
2024-05-25 05:32:44 [INFO]: Epoch 015 - training loss: 0.8866, validation loss: 0.7062
2024-05-25 05:32:44 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch15_loss0.7061928242444993.pypots
2024-05-25 05:32:48 [INFO]: Epoch 016 - training loss: 0.9010, validation loss: 0.7061
2024-05-25 05:32:48 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch16_loss0.7061126917600632.pypots
2024-05-25 05:32:52 [INFO]: Epoch 017 - training loss: 0.9152, validation loss: 0.7054
2024-05-25 05:32:52 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch17_loss0.7053927540779114.pypots
2024-05-25 05:32:56 [INFO]: Epoch 018 - training loss: 0.8811, validation loss: 0.7055
2024-05-25 05:32:56 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch18_loss0.7054619729518891.pypots
2024-05-25 05:32:59 [INFO]: Epoch 019 - training loss: 0.8787, validation loss: 0.7061
2024-05-25 05:32:59 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch19_loss0.7060740172863007.pypots
2024-05-25 05:33:03 [INFO]: Epoch 020 - training loss: 0.8644, validation loss: 0.7052
2024-05-25 05:33:03 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch20_loss0.7052081972360611.pypots
2024-05-25 05:33:07 [INFO]: Epoch 021 - training loss: 0.8822, validation loss: 0.7063
2024-05-25 05:33:07 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch21_loss0.7062866598367691.pypots
2024-05-25 05:33:11 [INFO]: Epoch 022 - training loss: 0.8910, validation loss: 0.7068
2024-05-25 05:33:11 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch22_loss0.7067958146333695.pypots
2024-05-25 05:33:15 [INFO]: Epoch 023 - training loss: 0.8528, validation loss: 0.7065
2024-05-25 05:33:15 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch23_loss0.7065456748008728.pypots
2024-05-25 05:33:19 [INFO]: Epoch 024 - training loss: 0.8669, validation loss: 0.7065
2024-05-25 05:33:19 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch24_loss0.7065083116292954.pypots
2024-05-25 05:33:23 [INFO]: Epoch 025 - training loss: 0.8690, validation loss: 0.7082
2024-05-25 05:33:23 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch25_loss0.708181443810463.pypots
2024-05-25 05:33:26 [INFO]: Epoch 026 - training loss: 0.8689, validation loss: 0.7084
2024-05-25 05:33:26 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch26_loss0.7083615869283676.pypots
2024-05-25 05:33:30 [INFO]: Epoch 027 - training loss: 0.8899, validation loss: 0.7098
2024-05-25 05:33:30 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch27_loss0.7098034709692002.pypots
2024-05-25 05:33:34 [INFO]: Epoch 028 - training loss: 0.8561, validation loss: 0.7091
2024-05-25 05:33:34 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch28_loss0.7090649992227555.pypots
2024-05-25 05:33:38 [INFO]: Epoch 029 - training loss: 0.8562, validation loss: 0.7103
2024-05-25 05:33:38 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch29_loss0.7103135824203491.pypots
2024-05-25 05:33:42 [INFO]: Epoch 030 - training loss: 0.8514, validation loss: 0.7084
2024-05-25 05:33:42 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN_epoch30_loss0.708429017663002.pypots
2024-05-25 05:33:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:33:42 [INFO]: Finished training. The best model is from epoch#20.
2024-05-25 05:33:42 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T053145/MRNN.pypots
2024-05-25 05:33:43 [INFO]: MRNN on Air-Quality: MAE=0.5235, MSE=0.6008
2024-05-25 05:33:43 [INFO]: Successfully saved to augmentation_saved_results/round_4/MRNN_air_quality/imputation.pkl
2024-05-25 05:33:43 [INFO]: Using the given device: cpu
2024-05-25 05:33:43 [INFO]: LOCF on Air-Quality: MAE=0.2006, MSE=0.1979
2024-05-25 05:33:43 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_air_quality".
2024-05-25 05:33:43 [INFO]: Successfully saved to augmentation_saved_results/round_4/LOCF_air_quality/imputation.pkl
2024-05-25 05:33:43 [INFO]: Median on Air-Quality: MAE=0.6700, MSE=1.0040
2024-05-25 05:33:43 [INFO]: Successfully created the given path "saved_results/round_4/Median_air_quality".
2024-05-25 05:33:43 [INFO]: Successfully saved to augmentation_saved_results/round_4/Median_air_quality/imputation.pkl
2024-05-25 05:33:43 [INFO]: Mean on Air-Quality: MAE=0.6975, MSE=0.9352
2024-05-25 05:33:43 [INFO]: Successfully created the given path "saved_results/round_4/Mean_air_quality".
2024-05-25 05:33:43 [INFO]: Successfully saved to augmentation_saved_results/round_4/Mean_air_quality/imputation.pkl
2024-05-25 05:33:43 [INFO]: 
SAITS on data/air_quality: MAE=0.1460.0033827202254510893, MSE=0.0940.0028917590743505897
Transformer on data/air_quality: MAE=0.1610.0031477782575576236, MSE=0.1090.004663783234292466
TimesNet on data/air_quality: MAE=0.1670.0029256115518396316, MSE=0.1440.005905314736051764
CSDI on data/air_quality: MAE=0.1020.0032986494395024295, MSE=0.0910.01613770283596401
GPVAE on data/air_quality: MAE=0.2810.010262404771219653, MSE=0.2210.012222727269965416
USGAN on data/air_quality: MAE=0.1650.012596783125665435, MSE=0.1020.010388844169318456
BRITS on data/air_quality: MAE=0.1380.0006079706311738132, MSE=0.0910.0008431931933769677
MRNN on data/air_quality: MAE=0.5230.0008252044970644416, MSE=0.6020.0019656237800326245
LOCF on data/air_quality: MAE=0.2010.0, MSE=0.1980.0
Median on data/air_quality: MAE=0.6700.0, MSE=1.0040.0
Mean on data/air_quality: MAE=0.6970.0, MSE=0.9350.0

