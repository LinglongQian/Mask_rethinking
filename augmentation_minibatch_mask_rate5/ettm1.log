2024-05-25 00:56:41 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-25 00:56:42 [INFO]: Using the given device: cuda:0
2024-05-25 00:56:42 [INFO]: Model files will be saved to augmentation_saved_results/round_0/SAITS_ettm1/20240525_T005642
2024-05-25 00:56:42 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/SAITS_ettm1/20240525_T005642/tensorboard
2024-05-25 00:56:42 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 00:56:43 [INFO]: Epoch 001 - training loss: 1.2183, validation loss: 0.2592
2024-05-25 00:56:44 [INFO]: Epoch 002 - training loss: 0.8963, validation loss: 0.1165
2024-05-25 00:56:44 [INFO]: Epoch 003 - training loss: 0.8107, validation loss: 0.0846
2024-05-25 00:56:45 [INFO]: Epoch 004 - training loss: 0.7347, validation loss: 0.0789
2024-05-25 00:56:45 [INFO]: Epoch 005 - training loss: 0.7013, validation loss: 0.0788
2024-05-25 00:56:46 [INFO]: Epoch 006 - training loss: 0.6617, validation loss: 0.0646
2024-05-25 00:56:46 [INFO]: Epoch 007 - training loss: 0.6500, validation loss: 0.0560
2024-05-25 00:56:47 [INFO]: Epoch 008 - training loss: 0.6323, validation loss: 0.0579
2024-05-25 00:56:47 [INFO]: Epoch 009 - training loss: 0.6155, validation loss: 0.0515
2024-05-25 00:56:48 [INFO]: Epoch 010 - training loss: 0.6049, validation loss: 0.0642
2024-05-25 00:56:48 [INFO]: Epoch 011 - training loss: 0.6019, validation loss: 0.0564
2024-05-25 00:56:49 [INFO]: Epoch 012 - training loss: 0.5880, validation loss: 0.0694
2024-05-25 00:56:49 [INFO]: Epoch 013 - training loss: 0.5947, validation loss: 0.0525
2024-05-25 00:56:50 [INFO]: Epoch 014 - training loss: 0.5692, validation loss: 0.0411
2024-05-25 00:56:50 [INFO]: Epoch 015 - training loss: 0.5592, validation loss: 0.0496
2024-05-25 00:56:51 [INFO]: Epoch 016 - training loss: 0.5565, validation loss: 0.0475
2024-05-25 00:56:51 [INFO]: Epoch 017 - training loss: 0.5636, validation loss: 0.0519
2024-05-25 00:56:52 [INFO]: Epoch 018 - training loss: 0.5419, validation loss: 0.0481
2024-05-25 00:56:52 [INFO]: Epoch 019 - training loss: 0.5344, validation loss: 0.0588
2024-05-25 00:56:53 [INFO]: Epoch 020 - training loss: 0.5430, validation loss: 0.0476
2024-05-25 00:56:53 [INFO]: Epoch 021 - training loss: 0.5372, validation loss: 0.0336
2024-05-25 00:56:54 [INFO]: Epoch 022 - training loss: 0.5176, validation loss: 0.0378
2024-05-25 00:56:55 [INFO]: Epoch 023 - training loss: 0.5203, validation loss: 0.1563
2024-05-25 00:56:55 [INFO]: Epoch 024 - training loss: 0.5662, validation loss: 0.0398
2024-05-25 00:56:56 [INFO]: Epoch 025 - training loss: 0.5287, validation loss: 0.0555
2024-05-25 00:56:56 [INFO]: Epoch 026 - training loss: 0.5010, validation loss: 0.0362
2024-05-25 00:56:57 [INFO]: Epoch 027 - training loss: 0.5003, validation loss: 0.0411
2024-05-25 00:56:57 [INFO]: Epoch 028 - training loss: 0.4952, validation loss: 0.0422
2024-05-25 00:56:58 [INFO]: Epoch 029 - training loss: 0.4978, validation loss: 0.0344
2024-05-25 00:56:58 [INFO]: Epoch 030 - training loss: 0.4844, validation loss: 0.0421
2024-05-25 00:56:59 [INFO]: Epoch 031 - training loss: 0.4767, validation loss: 0.0358
2024-05-25 00:56:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:56:59 [INFO]: Finished training. The best model is from epoch#21.
2024-05-25 00:56:59 [INFO]: Saved the model to augmentation_saved_results/round_0/SAITS_ettm1/20240525_T005642/SAITS.pypots
2024-05-25 00:56:59 [INFO]: SAITS on ETTm1: MAE=0.1532, MSE=0.0458
2024-05-25 00:56:59 [INFO]: Successfully saved to augmentation_saved_results/round_0/SAITS_ettm1/imputation.pkl
2024-05-25 00:56:59 [INFO]: Using the given device: cuda:0
2024-05-25 00:56:59 [INFO]: Model files will be saved to augmentation_saved_results/round_0/Transformer_ettm1/20240525_T005659
2024-05-25 00:56:59 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/Transformer_ettm1/20240525_T005659/tensorboard
2024-05-25 00:56:59 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 00:56:59 [INFO]: Epoch 001 - training loss: 1.2029, validation loss: 0.3063
2024-05-25 00:56:59 [INFO]: Epoch 002 - training loss: 0.7204, validation loss: 0.1399
2024-05-25 00:56:59 [INFO]: Epoch 003 - training loss: 0.5894, validation loss: 0.1085
2024-05-25 00:57:00 [INFO]: Epoch 004 - training loss: 0.5273, validation loss: 0.0739
2024-05-25 00:57:00 [INFO]: Epoch 005 - training loss: 0.4941, validation loss: 0.0653
2024-05-25 00:57:00 [INFO]: Epoch 006 - training loss: 0.4582, validation loss: 0.0625
2024-05-25 00:57:00 [INFO]: Epoch 007 - training loss: 0.4481, validation loss: 0.0539
2024-05-25 00:57:01 [INFO]: Epoch 008 - training loss: 0.4222, validation loss: 0.0516
2024-05-25 00:57:01 [INFO]: Epoch 009 - training loss: 0.4000, validation loss: 0.0499
2024-05-25 00:57:01 [INFO]: Epoch 010 - training loss: 0.3925, validation loss: 0.0463
2024-05-25 00:57:01 [INFO]: Epoch 011 - training loss: 0.3871, validation loss: 0.0475
2024-05-25 00:57:02 [INFO]: Epoch 012 - training loss: 0.3788, validation loss: 0.0495
2024-05-25 00:57:02 [INFO]: Epoch 013 - training loss: 0.3655, validation loss: 0.0443
2024-05-25 00:57:02 [INFO]: Epoch 014 - training loss: 0.3578, validation loss: 0.0436
2024-05-25 00:57:02 [INFO]: Epoch 015 - training loss: 0.3547, validation loss: 0.0415
2024-05-25 00:57:02 [INFO]: Epoch 016 - training loss: 0.3417, validation loss: 0.0496
2024-05-25 00:57:03 [INFO]: Epoch 017 - training loss: 0.3419, validation loss: 0.0381
2024-05-25 00:57:03 [INFO]: Epoch 018 - training loss: 0.3294, validation loss: 0.0352
2024-05-25 00:57:03 [INFO]: Epoch 019 - training loss: 0.3353, validation loss: 0.0396
2024-05-25 00:57:03 [INFO]: Epoch 020 - training loss: 0.3216, validation loss: 0.0392
2024-05-25 00:57:03 [INFO]: Epoch 021 - training loss: 0.3186, validation loss: 0.0345
2024-05-25 00:57:04 [INFO]: Epoch 022 - training loss: 0.3152, validation loss: 0.0345
2024-05-25 00:57:04 [INFO]: Epoch 023 - training loss: 0.3086, validation loss: 0.0369
2024-05-25 00:57:04 [INFO]: Epoch 024 - training loss: 0.3071, validation loss: 0.0314
2024-05-25 00:57:04 [INFO]: Epoch 025 - training loss: 0.3016, validation loss: 0.0312
2024-05-25 00:57:05 [INFO]: Epoch 026 - training loss: 0.3022, validation loss: 0.0328
2024-05-25 00:57:05 [INFO]: Epoch 027 - training loss: 0.2990, validation loss: 0.0294
2024-05-25 00:57:05 [INFO]: Epoch 028 - training loss: 0.2910, validation loss: 0.0293
2024-05-25 00:57:05 [INFO]: Epoch 029 - training loss: 0.2890, validation loss: 0.0305
2024-05-25 00:57:05 [INFO]: Epoch 030 - training loss: 0.2878, validation loss: 0.0293
2024-05-25 00:57:06 [INFO]: Epoch 031 - training loss: 0.2828, validation loss: 0.0361
2024-05-25 00:57:06 [INFO]: Epoch 032 - training loss: 0.2849, validation loss: 0.0333
2024-05-25 00:57:06 [INFO]: Epoch 033 - training loss: 0.2803, validation loss: 0.0284
2024-05-25 00:57:06 [INFO]: Epoch 034 - training loss: 0.2729, validation loss: 0.0301
2024-05-25 00:57:06 [INFO]: Epoch 035 - training loss: 0.2706, validation loss: 0.0269
2024-05-25 00:57:07 [INFO]: Epoch 036 - training loss: 0.2712, validation loss: 0.0262
2024-05-25 00:57:07 [INFO]: Epoch 037 - training loss: 0.2660, validation loss: 0.0334
2024-05-25 00:57:07 [INFO]: Epoch 038 - training loss: 0.2651, validation loss: 0.0295
2024-05-25 00:57:07 [INFO]: Epoch 039 - training loss: 0.2634, validation loss: 0.0248
2024-05-25 00:57:08 [INFO]: Epoch 040 - training loss: 0.2549, validation loss: 0.0261
2024-05-25 00:57:08 [INFO]: Epoch 041 - training loss: 0.2503, validation loss: 0.0291
2024-05-25 00:57:08 [INFO]: Epoch 042 - training loss: 0.2613, validation loss: 0.0326
2024-05-25 00:57:08 [INFO]: Epoch 043 - training loss: 0.2545, validation loss: 0.0349
2024-05-25 00:57:08 [INFO]: Epoch 044 - training loss: 0.2556, validation loss: 0.0256
2024-05-25 00:57:09 [INFO]: Epoch 045 - training loss: 0.2481, validation loss: 0.0232
2024-05-25 00:57:09 [INFO]: Epoch 046 - training loss: 0.2455, validation loss: 0.0247
2024-05-25 00:57:09 [INFO]: Epoch 047 - training loss: 0.2470, validation loss: 0.0251
2024-05-25 00:57:09 [INFO]: Epoch 048 - training loss: 0.2399, validation loss: 0.0300
2024-05-25 00:57:09 [INFO]: Epoch 049 - training loss: 0.2506, validation loss: 0.0256
2024-05-25 00:57:10 [INFO]: Epoch 050 - training loss: 0.2399, validation loss: 0.0232
2024-05-25 00:57:10 [INFO]: Epoch 051 - training loss: 0.2366, validation loss: 0.0252
2024-05-25 00:57:10 [INFO]: Epoch 052 - training loss: 0.2383, validation loss: 0.0282
2024-05-25 00:57:10 [INFO]: Epoch 053 - training loss: 0.2367, validation loss: 0.0246
2024-05-25 00:57:11 [INFO]: Epoch 054 - training loss: 0.2252, validation loss: 0.0240
2024-05-25 00:57:11 [INFO]: Epoch 055 - training loss: 0.2285, validation loss: 0.0236
2024-05-25 00:57:11 [INFO]: Epoch 056 - training loss: 0.2267, validation loss: 0.0247
2024-05-25 00:57:11 [INFO]: Epoch 057 - training loss: 0.2259, validation loss: 0.0225
2024-05-25 00:57:11 [INFO]: Epoch 058 - training loss: 0.2213, validation loss: 0.0247
2024-05-25 00:57:12 [INFO]: Epoch 059 - training loss: 0.2260, validation loss: 0.0211
2024-05-25 00:57:12 [INFO]: Epoch 060 - training loss: 0.2185, validation loss: 0.0253
2024-05-25 00:57:12 [INFO]: Epoch 061 - training loss: 0.2301, validation loss: 0.0229
2024-05-25 00:57:12 [INFO]: Epoch 062 - training loss: 0.2176, validation loss: 0.0232
2024-05-25 00:57:12 [INFO]: Epoch 063 - training loss: 0.2211, validation loss: 0.0211
2024-05-25 00:57:13 [INFO]: Epoch 064 - training loss: 0.2228, validation loss: 0.0258
2024-05-25 00:57:13 [INFO]: Epoch 065 - training loss: 0.2258, validation loss: 0.0225
2024-05-25 00:57:13 [INFO]: Epoch 066 - training loss: 0.2177, validation loss: 0.0230
2024-05-25 00:57:13 [INFO]: Epoch 067 - training loss: 0.2210, validation loss: 0.0241
2024-05-25 00:57:14 [INFO]: Epoch 068 - training loss: 0.2145, validation loss: 0.0227
2024-05-25 00:57:14 [INFO]: Epoch 069 - training loss: 0.2183, validation loss: 0.0224
2024-05-25 00:57:14 [INFO]: Epoch 070 - training loss: 0.2102, validation loss: 0.0247
2024-05-25 00:57:14 [INFO]: Epoch 071 - training loss: 0.2140, validation loss: 0.0223
2024-05-25 00:57:14 [INFO]: Epoch 072 - training loss: 0.2096, validation loss: 0.0229
2024-05-25 00:57:15 [INFO]: Epoch 073 - training loss: 0.2085, validation loss: 0.0218
2024-05-25 00:57:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:57:15 [INFO]: Finished training. The best model is from epoch#63.
2024-05-25 00:57:15 [INFO]: Saved the model to augmentation_saved_results/round_0/Transformer_ettm1/20240525_T005659/Transformer.pypots
2024-05-25 00:57:15 [INFO]: Transformer on ETTm1: MAE=0.1230, MSE=0.0299
2024-05-25 00:57:15 [INFO]: Successfully saved to augmentation_saved_results/round_0/Transformer_ettm1/imputation.pkl
2024-05-25 00:57:15 [INFO]: Using the given device: cuda:0
2024-05-25 00:57:15 [INFO]: Model files will be saved to augmentation_saved_results/round_0/TimesNet_ettm1/20240525_T005715
2024-05-25 00:57:15 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/TimesNet_ettm1/20240525_T005715/tensorboard
2024-05-25 00:57:15 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 00:57:15 [INFO]: Epoch 001 - training loss: 0.1631, validation loss: 0.0532
2024-05-25 00:57:16 [INFO]: Epoch 002 - training loss: 0.0772, validation loss: 0.0405
2024-05-25 00:57:16 [INFO]: Epoch 003 - training loss: 0.0579, validation loss: 0.0325
2024-05-25 00:57:16 [INFO]: Epoch 004 - training loss: 0.0501, validation loss: 0.0295
2024-05-25 00:57:16 [INFO]: Epoch 005 - training loss: 0.0487, validation loss: 0.0294
2024-05-25 00:57:16 [INFO]: Epoch 006 - training loss: 0.0457, validation loss: 0.0289
2024-05-25 00:57:17 [INFO]: Epoch 007 - training loss: 0.0481, validation loss: 0.0320
2024-05-25 00:57:17 [INFO]: Epoch 008 - training loss: 0.0484, validation loss: 0.0264
2024-05-25 00:57:17 [INFO]: Epoch 009 - training loss: 0.0459, validation loss: 0.0277
2024-05-25 00:57:17 [INFO]: Epoch 010 - training loss: 0.0431, validation loss: 0.0275
2024-05-25 00:57:18 [INFO]: Epoch 011 - training loss: 0.0428, validation loss: 0.0286
2024-05-25 00:57:18 [INFO]: Epoch 012 - training loss: 0.0418, validation loss: 0.0273
2024-05-25 00:57:18 [INFO]: Epoch 013 - training loss: 0.0418, validation loss: 0.0268
2024-05-25 00:57:18 [INFO]: Epoch 014 - training loss: 0.0416, validation loss: 0.0278
2024-05-25 00:57:18 [INFO]: Epoch 015 - training loss: 0.0390, validation loss: 0.0279
2024-05-25 00:57:19 [INFO]: Epoch 016 - training loss: 0.0415, validation loss: 0.0294
2024-05-25 00:57:19 [INFO]: Epoch 017 - training loss: 0.0440, validation loss: 0.0321
2024-05-25 00:57:19 [INFO]: Epoch 018 - training loss: 0.0467, validation loss: 0.0312
2024-05-25 00:57:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:57:19 [INFO]: Finished training. The best model is from epoch#8.
2024-05-25 00:57:19 [INFO]: Saved the model to augmentation_saved_results/round_0/TimesNet_ettm1/20240525_T005715/TimesNet.pypots
2024-05-25 00:57:19 [INFO]: TimesNet on ETTm1: MAE=0.1309, MSE=0.0349
2024-05-25 00:57:19 [INFO]: Successfully saved to augmentation_saved_results/round_0/TimesNet_ettm1/imputation.pkl
2024-05-25 00:57:19 [INFO]: Using the given device: cuda:0
2024-05-25 00:57:19 [INFO]: Model files will be saved to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719
2024-05-25 00:57:19 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/tensorboard
2024-05-25 00:57:19 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 00:57:21 [INFO]: Epoch 001 - training loss: 0.7080, validation loss: 0.4574
2024-05-25 00:57:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch1_loss0.4573787897825241.pypots
2024-05-25 00:57:23 [INFO]: Epoch 002 - training loss: 0.4308, validation loss: 0.3681
2024-05-25 00:57:23 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch2_loss0.3680920675396919.pypots
2024-05-25 00:57:25 [INFO]: Epoch 003 - training loss: 0.3288, validation loss: 0.3272
2024-05-25 00:57:25 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch3_loss0.3271923065185547.pypots
2024-05-25 00:57:28 [INFO]: Epoch 004 - training loss: 0.2615, validation loss: 0.2916
2024-05-25 00:57:28 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch4_loss0.29156845062971115.pypots
2024-05-25 00:57:30 [INFO]: Epoch 005 - training loss: 0.2925, validation loss: 0.2758
2024-05-25 00:57:30 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch5_loss0.27579955011606216.pypots
2024-05-25 00:57:32 [INFO]: Epoch 006 - training loss: 0.2855, validation loss: 0.2777
2024-05-25 00:57:32 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch6_loss0.2776685208082199.pypots
2024-05-25 00:57:34 [INFO]: Epoch 007 - training loss: 0.2651, validation loss: 0.2931
2024-05-25 00:57:34 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch7_loss0.29312482476234436.pypots
2024-05-25 00:57:36 [INFO]: Epoch 008 - training loss: 0.3272, validation loss: 0.2666
2024-05-25 00:57:36 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch8_loss0.2666420415043831.pypots
2024-05-25 00:57:38 [INFO]: Epoch 009 - training loss: 0.2563, validation loss: 0.2528
2024-05-25 00:57:38 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch9_loss0.2527626305818558.pypots
2024-05-25 00:57:40 [INFO]: Epoch 010 - training loss: 0.2781, validation loss: 0.2465
2024-05-25 00:57:40 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch10_loss0.24650933220982552.pypots
2024-05-25 00:57:42 [INFO]: Epoch 011 - training loss: 0.2420, validation loss: 0.2365
2024-05-25 00:57:42 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch11_loss0.23648487031459808.pypots
2024-05-25 00:57:44 [INFO]: Epoch 012 - training loss: 0.2504, validation loss: 0.2263
2024-05-25 00:57:44 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch12_loss0.22633347287774086.pypots
2024-05-25 00:57:46 [INFO]: Epoch 013 - training loss: 0.2054, validation loss: 0.2862
2024-05-25 00:57:46 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch13_loss0.28624726831912994.pypots
2024-05-25 00:57:48 [INFO]: Epoch 014 - training loss: 0.2630, validation loss: 0.2863
2024-05-25 00:57:48 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch14_loss0.2863176241517067.pypots
2024-05-25 00:57:50 [INFO]: Epoch 015 - training loss: 0.2291, validation loss: 0.2425
2024-05-25 00:57:50 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch15_loss0.24247803539037704.pypots
2024-05-25 00:57:53 [INFO]: Epoch 016 - training loss: 0.2076, validation loss: 0.2332
2024-05-25 00:57:53 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch16_loss0.23322726786136627.pypots
2024-05-25 00:57:55 [INFO]: Epoch 017 - training loss: 0.2063, validation loss: 0.2084
2024-05-25 00:57:55 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch17_loss0.20835409685969353.pypots
2024-05-25 00:57:57 [INFO]: Epoch 018 - training loss: 0.2255, validation loss: 0.2137
2024-05-25 00:57:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch18_loss0.21366553008556366.pypots
2024-05-25 00:57:59 [INFO]: Epoch 019 - training loss: 0.2826, validation loss: 0.2148
2024-05-25 00:57:59 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch19_loss0.21476691961288452.pypots
2024-05-25 00:58:01 [INFO]: Epoch 020 - training loss: 0.2092, validation loss: 0.2024
2024-05-25 00:58:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch20_loss0.20237994194030762.pypots
2024-05-25 00:58:03 [INFO]: Epoch 021 - training loss: 0.2106, validation loss: 0.1957
2024-05-25 00:58:03 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch21_loss0.1957486942410469.pypots
2024-05-25 00:58:05 [INFO]: Epoch 022 - training loss: 0.1798, validation loss: 0.1856
2024-05-25 00:58:05 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch22_loss0.18555069714784622.pypots
2024-05-25 00:58:07 [INFO]: Epoch 023 - training loss: 0.1943, validation loss: 0.1819
2024-05-25 00:58:07 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch23_loss0.181865643709898.pypots
2024-05-25 00:58:09 [INFO]: Epoch 024 - training loss: 0.1846, validation loss: 0.1756
2024-05-25 00:58:09 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch24_loss0.17559973523020744.pypots
2024-05-25 00:58:11 [INFO]: Epoch 025 - training loss: 0.1951, validation loss: 0.1675
2024-05-25 00:58:11 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch25_loss0.16748624294996262.pypots
2024-05-25 00:58:13 [INFO]: Epoch 026 - training loss: 0.2050, validation loss: 0.1696
2024-05-25 00:58:13 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch26_loss0.16959667578339577.pypots
2024-05-25 00:58:15 [INFO]: Epoch 027 - training loss: 0.2409, validation loss: 0.1880
2024-05-25 00:58:15 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch27_loss0.1879761852324009.pypots
2024-05-25 00:58:18 [INFO]: Epoch 028 - training loss: 0.2014, validation loss: 0.2031
2024-05-25 00:58:18 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch28_loss0.20306381210684776.pypots
2024-05-25 00:58:20 [INFO]: Epoch 029 - training loss: 0.2274, validation loss: 0.1970
2024-05-25 00:58:20 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch29_loss0.1970011554658413.pypots
2024-05-25 00:58:22 [INFO]: Epoch 030 - training loss: 0.2331, validation loss: 0.1735
2024-05-25 00:58:22 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch30_loss0.17350568994879723.pypots
2024-05-25 00:58:24 [INFO]: Epoch 031 - training loss: 0.1841, validation loss: 0.1776
2024-05-25 00:58:24 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch31_loss0.17762048915028572.pypots
2024-05-25 00:58:26 [INFO]: Epoch 032 - training loss: 0.1766, validation loss: 0.1586
2024-05-25 00:58:26 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch32_loss0.158560112118721.pypots
2024-05-25 00:58:28 [INFO]: Epoch 033 - training loss: 0.1635, validation loss: 0.1581
2024-05-25 00:58:28 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch33_loss0.15814950689673424.pypots
2024-05-25 00:58:30 [INFO]: Epoch 034 - training loss: 0.1610, validation loss: 0.1513
2024-05-25 00:58:30 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch34_loss0.1512867882847786.pypots
2024-05-25 00:58:32 [INFO]: Epoch 035 - training loss: 0.2218, validation loss: 0.1502
2024-05-25 00:58:32 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch35_loss0.15024384111166.pypots
2024-05-25 00:58:34 [INFO]: Epoch 036 - training loss: 0.1491, validation loss: 0.1494
2024-05-25 00:58:34 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch36_loss0.1494481936097145.pypots
2024-05-25 00:58:36 [INFO]: Epoch 037 - training loss: 0.1674, validation loss: 0.1498
2024-05-25 00:58:36 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch37_loss0.1497940868139267.pypots
2024-05-25 00:58:38 [INFO]: Epoch 038 - training loss: 0.1595, validation loss: 0.1495
2024-05-25 00:58:38 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch38_loss0.14947590231895447.pypots
2024-05-25 00:58:40 [INFO]: Epoch 039 - training loss: 0.1751, validation loss: 0.1437
2024-05-25 00:58:41 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch39_loss0.14371033012866974.pypots
2024-05-25 00:58:43 [INFO]: Epoch 040 - training loss: 0.1630, validation loss: 0.1403
2024-05-25 00:58:43 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch40_loss0.1402600333094597.pypots
2024-05-25 00:58:45 [INFO]: Epoch 041 - training loss: 0.1547, validation loss: 0.1388
2024-05-25 00:58:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch41_loss0.13879641517996788.pypots
2024-05-25 00:58:47 [INFO]: Epoch 042 - training loss: 0.1503, validation loss: 0.1399
2024-05-25 00:58:47 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch42_loss0.139853585511446.pypots
2024-05-25 00:58:49 [INFO]: Epoch 043 - training loss: 0.1700, validation loss: 0.1468
2024-05-25 00:58:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch43_loss0.1467728614807129.pypots
2024-05-25 00:58:51 [INFO]: Epoch 044 - training loss: 0.1631, validation loss: 0.1377
2024-05-25 00:58:51 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch44_loss0.1376590095460415.pypots
2024-05-25 00:58:53 [INFO]: Epoch 045 - training loss: 0.1729, validation loss: 0.1380
2024-05-25 00:58:53 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch45_loss0.13800300285220146.pypots
2024-05-25 00:58:55 [INFO]: Epoch 046 - training loss: 0.1559, validation loss: 0.1361
2024-05-25 00:58:55 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch46_loss0.13614923134446144.pypots
2024-05-25 00:58:57 [INFO]: Epoch 047 - training loss: 0.1832, validation loss: 0.1428
2024-05-25 00:58:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch47_loss0.1427799016237259.pypots
2024-05-25 00:58:59 [INFO]: Epoch 048 - training loss: 0.1946, validation loss: 0.2210
2024-05-25 00:58:59 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch48_loss0.221035186201334.pypots
2024-05-25 00:59:01 [INFO]: Epoch 049 - training loss: 0.2362, validation loss: 0.2442
2024-05-25 00:59:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch49_loss0.24416020140051842.pypots
2024-05-25 00:59:03 [INFO]: Epoch 050 - training loss: 0.2374, validation loss: 0.1908
2024-05-25 00:59:03 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch50_loss0.19084405526518822.pypots
2024-05-25 00:59:06 [INFO]: Epoch 051 - training loss: 0.2612, validation loss: 0.1765
2024-05-25 00:59:06 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch51_loss0.17647668719291687.pypots
2024-05-25 00:59:08 [INFO]: Epoch 052 - training loss: 0.1967, validation loss: 0.1752
2024-05-25 00:59:08 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch52_loss0.17517434060573578.pypots
2024-05-25 00:59:10 [INFO]: Epoch 053 - training loss: 0.1983, validation loss: 0.1898
2024-05-25 00:59:10 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch53_loss0.18982573971152306.pypots
2024-05-25 00:59:12 [INFO]: Epoch 054 - training loss: 0.2105, validation loss: 0.1853
2024-05-25 00:59:12 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch54_loss0.1853191778063774.pypots
2024-05-25 00:59:14 [INFO]: Epoch 055 - training loss: 0.2567, validation loss: 0.1658
2024-05-25 00:59:14 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch55_loss0.16583380848169327.pypots
2024-05-25 00:59:16 [INFO]: Epoch 056 - training loss: 0.1772, validation loss: 0.1579
2024-05-25 00:59:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI_epoch56_loss0.1579352393746376.pypots
2024-05-25 00:59:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:59:16 [INFO]: Finished training. The best model is from epoch#46.
2024-05-25 00:59:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T005719/CSDI.pypots
2024-05-25 00:59:32 [INFO]: CSDI on ETTm1: MAE=0.2845, MSE=1.4610
2024-05-25 00:59:32 [INFO]: Successfully saved to augmentation_saved_results/round_0/CSDI_ettm1/imputation.pkl
2024-05-25 00:59:32 [INFO]: Using the given device: cuda:0
2024-05-25 00:59:32 [INFO]: Model files will be saved to augmentation_saved_results/round_0/GPVAE_ettm1/20240525_T005932
2024-05-25 00:59:32 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/GPVAE_ettm1/20240525_T005932/tensorboard
2024-05-25 00:59:32 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 00:59:32 [INFO]: Epoch 001 - training loss: 24332.0160, validation loss: 0.9774
2024-05-25 00:59:32 [INFO]: Epoch 002 - training loss: 22175.2151, validation loss: 0.9682
2024-05-25 00:59:32 [INFO]: Epoch 003 - training loss: 20287.0098, validation loss: 0.9604
2024-05-25 00:59:33 [INFO]: Epoch 004 - training loss: 18375.1467, validation loss: 0.9509
2024-05-25 00:59:33 [INFO]: Epoch 005 - training loss: 16741.1741, validation loss: 0.9249
2024-05-25 00:59:33 [INFO]: Epoch 006 - training loss: 14915.3249, validation loss: 0.8778
2024-05-25 00:59:33 [INFO]: Epoch 007 - training loss: 13557.0235, validation loss: 0.7938
2024-05-25 00:59:33 [INFO]: Epoch 008 - training loss: 12660.2139, validation loss: 0.6787
2024-05-25 00:59:33 [INFO]: Epoch 009 - training loss: 11907.7094, validation loss: 0.5790
2024-05-25 00:59:33 [INFO]: Epoch 010 - training loss: 11308.9548, validation loss: 0.5316
2024-05-25 00:59:33 [INFO]: Epoch 011 - training loss: 10951.2308, validation loss: 0.5067
2024-05-25 00:59:34 [INFO]: Epoch 012 - training loss: 10658.0177, validation loss: 0.4884
2024-05-25 00:59:34 [INFO]: Epoch 013 - training loss: 10428.4413, validation loss: 0.4729
2024-05-25 00:59:34 [INFO]: Epoch 014 - training loss: 10265.4494, validation loss: 0.4488
2024-05-25 00:59:34 [INFO]: Epoch 015 - training loss: 10179.3016, validation loss: 0.4463
2024-05-25 00:59:34 [INFO]: Epoch 016 - training loss: 10073.0657, validation loss: 0.4113
2024-05-25 00:59:34 [INFO]: Epoch 017 - training loss: 9947.5870, validation loss: 0.3818
2024-05-25 00:59:34 [INFO]: Epoch 018 - training loss: 9882.1088, validation loss: 0.3607
2024-05-25 00:59:34 [INFO]: Epoch 019 - training loss: 9863.2535, validation loss: 0.3463
2024-05-25 00:59:35 [INFO]: Epoch 020 - training loss: 9774.6069, validation loss: 0.3348
2024-05-25 00:59:35 [INFO]: Epoch 021 - training loss: 9755.4674, validation loss: 0.3277
2024-05-25 00:59:35 [INFO]: Epoch 022 - training loss: 9699.2850, validation loss: 0.3143
2024-05-25 00:59:35 [INFO]: Epoch 023 - training loss: 9673.4695, validation loss: 0.3030
2024-05-25 00:59:35 [INFO]: Epoch 024 - training loss: 9657.1281, validation loss: 0.2927
2024-05-25 00:59:35 [INFO]: Epoch 025 - training loss: 9631.4630, validation loss: 0.2840
2024-05-25 00:59:35 [INFO]: Epoch 026 - training loss: 9590.9281, validation loss: 0.2729
2024-05-25 00:59:35 [INFO]: Epoch 027 - training loss: 9567.1223, validation loss: 0.2646
2024-05-25 00:59:36 [INFO]: Epoch 028 - training loss: 9547.1468, validation loss: 0.2600
2024-05-25 00:59:36 [INFO]: Epoch 029 - training loss: 9532.0811, validation loss: 0.2524
2024-05-25 00:59:36 [INFO]: Epoch 030 - training loss: 9534.5712, validation loss: 0.2442
2024-05-25 00:59:36 [INFO]: Epoch 031 - training loss: 9512.3413, validation loss: 0.2336
2024-05-25 00:59:36 [INFO]: Epoch 032 - training loss: 9499.2298, validation loss: 0.2276
2024-05-25 00:59:36 [INFO]: Epoch 033 - training loss: 9485.7524, validation loss: 0.2190
2024-05-25 00:59:36 [INFO]: Epoch 034 - training loss: 9480.4531, validation loss: 0.2143
2024-05-25 00:59:36 [INFO]: Epoch 035 - training loss: 9473.7792, validation loss: 0.2074
2024-05-25 00:59:37 [INFO]: Epoch 036 - training loss: 9459.4092, validation loss: 0.2002
2024-05-25 00:59:37 [INFO]: Epoch 037 - training loss: 9464.6193, validation loss: 0.1948
2024-05-25 00:59:37 [INFO]: Epoch 038 - training loss: 9453.2739, validation loss: 0.1936
2024-05-25 00:59:37 [INFO]: Epoch 039 - training loss: 9443.7810, validation loss: 0.1861
2024-05-25 00:59:37 [INFO]: Epoch 040 - training loss: 9431.6047, validation loss: 0.1781
2024-05-25 00:59:37 [INFO]: Epoch 041 - training loss: 9427.4484, validation loss: 0.1748
2024-05-25 00:59:37 [INFO]: Epoch 042 - training loss: 9421.7584, validation loss: 0.1700
2024-05-25 00:59:37 [INFO]: Epoch 043 - training loss: 9421.4761, validation loss: 0.1653
2024-05-25 00:59:38 [INFO]: Epoch 044 - training loss: 9409.4637, validation loss: 0.1595
2024-05-25 00:59:38 [INFO]: Epoch 045 - training loss: 9408.5190, validation loss: 0.1571
2024-05-25 00:59:38 [INFO]: Epoch 046 - training loss: 9401.0769, validation loss: 0.1527
2024-05-25 00:59:38 [INFO]: Epoch 047 - training loss: 9398.7747, validation loss: 0.1466
2024-05-25 00:59:38 [INFO]: Epoch 048 - training loss: 9397.1536, validation loss: 0.1458
2024-05-25 00:59:38 [INFO]: Epoch 049 - training loss: 9390.2177, validation loss: 0.1427
2024-05-25 00:59:38 [INFO]: Epoch 050 - training loss: 9387.5189, validation loss: 0.1410
2024-05-25 00:59:38 [INFO]: Epoch 051 - training loss: 9384.7220, validation loss: 0.1376
2024-05-25 00:59:39 [INFO]: Epoch 052 - training loss: 9381.2352, validation loss: 0.1355
2024-05-25 00:59:39 [INFO]: Epoch 053 - training loss: 9388.9360, validation loss: 0.1331
2024-05-25 00:59:39 [INFO]: Epoch 054 - training loss: 9378.0690, validation loss: 0.1323
2024-05-25 00:59:39 [INFO]: Epoch 055 - training loss: 9376.2453, validation loss: 0.1290
2024-05-25 00:59:39 [INFO]: Epoch 056 - training loss: 9370.8148, validation loss: 0.1271
2024-05-25 00:59:39 [INFO]: Epoch 057 - training loss: 9370.6770, validation loss: 0.1267
2024-05-25 00:59:39 [INFO]: Epoch 058 - training loss: 9367.5618, validation loss: 0.1268
2024-05-25 00:59:39 [INFO]: Epoch 059 - training loss: 9365.6511, validation loss: 0.1256
2024-05-25 00:59:40 [INFO]: Epoch 060 - training loss: 9364.1230, validation loss: 0.1234
2024-05-25 00:59:40 [INFO]: Epoch 061 - training loss: 9382.2780, validation loss: 0.1229
2024-05-25 00:59:40 [INFO]: Epoch 062 - training loss: 9357.8734, validation loss: 0.1209
2024-05-25 00:59:40 [INFO]: Epoch 063 - training loss: 9360.1473, validation loss: 0.1208
2024-05-25 00:59:40 [INFO]: Epoch 064 - training loss: 9364.3679, validation loss: 0.1206
2024-05-25 00:59:40 [INFO]: Epoch 065 - training loss: 9356.7711, validation loss: 0.1183
2024-05-25 00:59:40 [INFO]: Epoch 066 - training loss: 9354.9908, validation loss: 0.1185
2024-05-25 00:59:40 [INFO]: Epoch 067 - training loss: 9350.0348, validation loss: 0.1167
2024-05-25 00:59:41 [INFO]: Epoch 068 - training loss: 9356.5203, validation loss: 0.1168
2024-05-25 00:59:41 [INFO]: Epoch 069 - training loss: 9354.0701, validation loss: 0.1146
2024-05-25 00:59:41 [INFO]: Epoch 070 - training loss: 9348.8779, validation loss: 0.1153
2024-05-25 00:59:41 [INFO]: Epoch 071 - training loss: 9346.1647, validation loss: 0.1135
2024-05-25 00:59:41 [INFO]: Epoch 072 - training loss: 9345.3026, validation loss: 0.1132
2024-05-25 00:59:41 [INFO]: Epoch 073 - training loss: 9357.1165, validation loss: 0.1106
2024-05-25 00:59:41 [INFO]: Epoch 074 - training loss: 9343.8187, validation loss: 0.1114
2024-05-25 00:59:41 [INFO]: Epoch 075 - training loss: 9343.4815, validation loss: 0.1114
2024-05-25 00:59:42 [INFO]: Epoch 076 - training loss: 9349.7574, validation loss: 0.1118
2024-05-25 00:59:42 [INFO]: Epoch 077 - training loss: 9340.8040, validation loss: 0.1100
2024-05-25 00:59:42 [INFO]: Epoch 078 - training loss: 9338.9783, validation loss: 0.1087
2024-05-25 00:59:42 [INFO]: Epoch 079 - training loss: 9339.2183, validation loss: 0.1082
2024-05-25 00:59:42 [INFO]: Epoch 080 - training loss: 9338.1860, validation loss: 0.1082
2024-05-25 00:59:42 [INFO]: Epoch 081 - training loss: 9338.0380, validation loss: 0.1073
2024-05-25 00:59:42 [INFO]: Epoch 082 - training loss: 9337.3964, validation loss: 0.1086
2024-05-25 00:59:42 [INFO]: Epoch 083 - training loss: 9336.2662, validation loss: 0.1056
2024-05-25 00:59:43 [INFO]: Epoch 084 - training loss: 9338.0206, validation loss: 0.1064
2024-05-25 00:59:43 [INFO]: Epoch 085 - training loss: 9339.8434, validation loss: 0.1056
2024-05-25 00:59:43 [INFO]: Epoch 086 - training loss: 9333.7459, validation loss: 0.1062
2024-05-25 00:59:43 [INFO]: Epoch 087 - training loss: 9332.1451, validation loss: 0.1053
2024-05-25 00:59:43 [INFO]: Epoch 088 - training loss: 9332.7435, validation loss: 0.1023
2024-05-25 00:59:43 [INFO]: Epoch 089 - training loss: 9334.4733, validation loss: 0.1023
2024-05-25 00:59:43 [INFO]: Epoch 090 - training loss: 9331.1896, validation loss: 0.1035
2024-05-25 00:59:43 [INFO]: Epoch 091 - training loss: 9330.1390, validation loss: 0.1030
2024-05-25 00:59:44 [INFO]: Epoch 092 - training loss: 9335.7311, validation loss: 0.1023
2024-05-25 00:59:44 [INFO]: Epoch 093 - training loss: 9330.6211, validation loss: 0.1010
2024-05-25 00:59:44 [INFO]: Epoch 094 - training loss: 9329.0925, validation loss: 0.0993
2024-05-25 00:59:44 [INFO]: Epoch 095 - training loss: 9327.1366, validation loss: 0.1010
2024-05-25 00:59:44 [INFO]: Epoch 096 - training loss: 9328.9995, validation loss: 0.0991
2024-05-25 00:59:44 [INFO]: Epoch 097 - training loss: 9326.6517, validation loss: 0.0987
2024-05-25 00:59:44 [INFO]: Epoch 098 - training loss: 9326.7566, validation loss: 0.0991
2024-05-25 00:59:44 [INFO]: Epoch 099 - training loss: 9328.9088, validation loss: 0.0981
2024-05-25 00:59:45 [INFO]: Epoch 100 - training loss: 9326.0334, validation loss: 0.0983
2024-05-25 00:59:45 [INFO]: Epoch 101 - training loss: 9325.5560, validation loss: 0.0970
2024-05-25 00:59:45 [INFO]: Epoch 102 - training loss: 9323.6937, validation loss: 0.0980
2024-05-25 00:59:45 [INFO]: Epoch 103 - training loss: 9324.1750, validation loss: 0.0961
2024-05-25 00:59:45 [INFO]: Epoch 104 - training loss: 9323.6803, validation loss: 0.0962
2024-05-25 00:59:45 [INFO]: Epoch 105 - training loss: 9322.2036, validation loss: 0.0961
2024-05-25 00:59:45 [INFO]: Epoch 106 - training loss: 9323.3400, validation loss: 0.0961
2024-05-25 00:59:45 [INFO]: Epoch 107 - training loss: 9324.1767, validation loss: 0.0948
2024-05-25 00:59:46 [INFO]: Epoch 108 - training loss: 9322.5268, validation loss: 0.0952
2024-05-25 00:59:46 [INFO]: Epoch 109 - training loss: 9325.2954, validation loss: 0.0930
2024-05-25 00:59:46 [INFO]: Epoch 110 - training loss: 9320.2396, validation loss: 0.0931
2024-05-25 00:59:46 [INFO]: Epoch 111 - training loss: 9322.2360, validation loss: 0.0932
2024-05-25 00:59:46 [INFO]: Epoch 112 - training loss: 9321.4769, validation loss: 0.0936
2024-05-25 00:59:46 [INFO]: Epoch 113 - training loss: 9320.6971, validation loss: 0.0923
2024-05-25 00:59:46 [INFO]: Epoch 114 - training loss: 9323.2336, validation loss: 0.0935
2024-05-25 00:59:46 [INFO]: Epoch 115 - training loss: 9319.1058, validation loss: 0.0926
2024-05-25 00:59:47 [INFO]: Epoch 116 - training loss: 9319.9400, validation loss: 0.0907
2024-05-25 00:59:47 [INFO]: Epoch 117 - training loss: 9319.9177, validation loss: 0.0896
2024-05-25 00:59:47 [INFO]: Epoch 118 - training loss: 9318.4625, validation loss: 0.0911
2024-05-25 00:59:47 [INFO]: Epoch 119 - training loss: 9319.1759, validation loss: 0.0904
2024-05-25 00:59:47 [INFO]: Epoch 120 - training loss: 9319.2962, validation loss: 0.0892
2024-05-25 00:59:47 [INFO]: Epoch 121 - training loss: 9324.3534, validation loss: 0.0892
2024-05-25 00:59:47 [INFO]: Epoch 122 - training loss: 9318.7312, validation loss: 0.0895
2024-05-25 00:59:47 [INFO]: Epoch 123 - training loss: 9316.9918, validation loss: 0.0894
2024-05-25 00:59:48 [INFO]: Epoch 124 - training loss: 9315.8856, validation loss: 0.0890
2024-05-25 00:59:48 [INFO]: Epoch 125 - training loss: 9316.3762, validation loss: 0.0893
2024-05-25 00:59:48 [INFO]: Epoch 126 - training loss: 9317.7217, validation loss: 0.0882
2024-05-25 00:59:48 [INFO]: Epoch 127 - training loss: 9315.0716, validation loss: 0.0866
2024-05-25 00:59:48 [INFO]: Epoch 128 - training loss: 9314.7812, validation loss: 0.0874
2024-05-25 00:59:48 [INFO]: Epoch 129 - training loss: 9316.3049, validation loss: 0.0871
2024-05-25 00:59:48 [INFO]: Epoch 130 - training loss: 9314.5292, validation loss: 0.0862
2024-05-25 00:59:48 [INFO]: Epoch 131 - training loss: 9315.6101, validation loss: 0.0858
2024-05-25 00:59:49 [INFO]: Epoch 132 - training loss: 9314.4333, validation loss: 0.0871
2024-05-25 00:59:49 [INFO]: Epoch 133 - training loss: 9314.0378, validation loss: 0.0846
2024-05-25 00:59:49 [INFO]: Epoch 134 - training loss: 9315.1511, validation loss: 0.0855
2024-05-25 00:59:49 [INFO]: Epoch 135 - training loss: 9314.6865, validation loss: 0.0856
2024-05-25 00:59:49 [INFO]: Epoch 136 - training loss: 9313.1763, validation loss: 0.0846
2024-05-25 00:59:49 [INFO]: Epoch 137 - training loss: 9316.0865, validation loss: 0.0830
2024-05-25 00:59:49 [INFO]: Epoch 138 - training loss: 9316.4304, validation loss: 0.0842
2024-05-25 00:59:49 [INFO]: Epoch 139 - training loss: 9314.4877, validation loss: 0.0848
2024-05-25 00:59:50 [INFO]: Epoch 140 - training loss: 9313.7518, validation loss: 0.0831
2024-05-25 00:59:50 [INFO]: Epoch 141 - training loss: 9314.6965, validation loss: 0.0826
2024-05-25 00:59:50 [INFO]: Epoch 142 - training loss: 9312.8701, validation loss: 0.0829
2024-05-25 00:59:50 [INFO]: Epoch 143 - training loss: 9312.4453, validation loss: 0.0832
2024-05-25 00:59:50 [INFO]: Epoch 144 - training loss: 9311.4744, validation loss: 0.0827
2024-05-25 00:59:50 [INFO]: Epoch 145 - training loss: 9312.2603, validation loss: 0.0826
2024-05-25 00:59:50 [INFO]: Epoch 146 - training loss: 9312.4341, validation loss: 0.0815
2024-05-25 00:59:50 [INFO]: Epoch 147 - training loss: 9313.0474, validation loss: 0.0816
2024-05-25 00:59:51 [INFO]: Epoch 148 - training loss: 9312.5548, validation loss: 0.0827
2024-05-25 00:59:51 [INFO]: Epoch 149 - training loss: 9311.4340, validation loss: 0.0824
2024-05-25 00:59:51 [INFO]: Epoch 150 - training loss: 9312.3766, validation loss: 0.0821
2024-05-25 00:59:51 [INFO]: Epoch 151 - training loss: 9311.2616, validation loss: 0.0805
2024-05-25 00:59:51 [INFO]: Epoch 152 - training loss: 9310.1238, validation loss: 0.0789
2024-05-25 00:59:51 [INFO]: Epoch 153 - training loss: 9311.3228, validation loss: 0.0804
2024-05-25 00:59:51 [INFO]: Epoch 154 - training loss: 9312.0573, validation loss: 0.0808
2024-05-25 00:59:51 [INFO]: Epoch 155 - training loss: 9310.5818, validation loss: 0.0782
2024-05-25 00:59:52 [INFO]: Epoch 156 - training loss: 9311.1554, validation loss: 0.0793
2024-05-25 00:59:52 [INFO]: Epoch 157 - training loss: 9309.6996, validation loss: 0.0801
2024-05-25 00:59:52 [INFO]: Epoch 158 - training loss: 9310.0457, validation loss: 0.0788
2024-05-25 00:59:52 [INFO]: Epoch 159 - training loss: 9308.9086, validation loss: 0.0782
2024-05-25 00:59:52 [INFO]: Epoch 160 - training loss: 9311.1945, validation loss: 0.0783
2024-05-25 00:59:52 [INFO]: Epoch 161 - training loss: 9309.4137, validation loss: 0.0795
2024-05-25 00:59:52 [INFO]: Epoch 162 - training loss: 9309.1572, validation loss: 0.0786
2024-05-25 00:59:52 [INFO]: Epoch 163 - training loss: 9310.7294, validation loss: 0.0777
2024-05-25 00:59:53 [INFO]: Epoch 164 - training loss: 9309.0448, validation loss: 0.0780
2024-05-25 00:59:53 [INFO]: Epoch 165 - training loss: 9309.7360, validation loss: 0.0760
2024-05-25 00:59:53 [INFO]: Epoch 166 - training loss: 9309.7345, validation loss: 0.0772
2024-05-25 00:59:53 [INFO]: Epoch 167 - training loss: 9309.7363, validation loss: 0.0775
2024-05-25 00:59:53 [INFO]: Epoch 168 - training loss: 9308.3444, validation loss: 0.0756
2024-05-25 00:59:53 [INFO]: Epoch 169 - training loss: 9308.3002, validation loss: 0.0770
2024-05-25 00:59:53 [INFO]: Epoch 170 - training loss: 9309.4080, validation loss: 0.0759
2024-05-25 00:59:53 [INFO]: Epoch 171 - training loss: 9309.1645, validation loss: 0.0776
2024-05-25 00:59:54 [INFO]: Epoch 172 - training loss: 9308.4559, validation loss: 0.0753
2024-05-25 00:59:54 [INFO]: Epoch 173 - training loss: 9308.7465, validation loss: 0.0780
2024-05-25 00:59:54 [INFO]: Epoch 174 - training loss: 9308.1635, validation loss: 0.0783
2024-05-25 00:59:54 [INFO]: Epoch 175 - training loss: 9309.1337, validation loss: 0.0764
2024-05-25 00:59:54 [INFO]: Epoch 176 - training loss: 9308.1704, validation loss: 0.0753
2024-05-25 00:59:54 [INFO]: Epoch 177 - training loss: 9308.3355, validation loss: 0.0754
2024-05-25 00:59:54 [INFO]: Epoch 178 - training loss: 9308.4403, validation loss: 0.0749
2024-05-25 00:59:54 [INFO]: Epoch 179 - training loss: 9307.5037, validation loss: 0.0772
2024-05-25 00:59:55 [INFO]: Epoch 180 - training loss: 9307.6907, validation loss: 0.0747
2024-05-25 00:59:55 [INFO]: Epoch 181 - training loss: 9307.9230, validation loss: 0.0757
2024-05-25 00:59:55 [INFO]: Epoch 182 - training loss: 9307.1458, validation loss: 0.0762
2024-05-25 00:59:55 [INFO]: Epoch 183 - training loss: 9308.6443, validation loss: 0.0751
2024-05-25 00:59:55 [INFO]: Epoch 184 - training loss: 9306.9144, validation loss: 0.0738
2024-05-25 00:59:55 [INFO]: Epoch 185 - training loss: 9308.2210, validation loss: 0.0737
2024-05-25 00:59:55 [INFO]: Epoch 186 - training loss: 9306.5697, validation loss: 0.0746
2024-05-25 00:59:55 [INFO]: Epoch 187 - training loss: 9306.5839, validation loss: 0.0736
2024-05-25 00:59:56 [INFO]: Epoch 188 - training loss: 9307.3964, validation loss: 0.0741
2024-05-25 00:59:56 [INFO]: Epoch 189 - training loss: 9305.6790, validation loss: 0.0732
2024-05-25 00:59:56 [INFO]: Epoch 190 - training loss: 9307.6042, validation loss: 0.0736
2024-05-25 00:59:56 [INFO]: Epoch 191 - training loss: 9306.4984, validation loss: 0.0747
2024-05-25 00:59:56 [INFO]: Epoch 192 - training loss: 9307.6171, validation loss: 0.0732
2024-05-25 00:59:56 [INFO]: Epoch 193 - training loss: 9305.8499, validation loss: 0.0720
2024-05-25 00:59:56 [INFO]: Epoch 194 - training loss: 9306.3737, validation loss: 0.0728
2024-05-25 00:59:56 [INFO]: Epoch 195 - training loss: 9305.4714, validation loss: 0.0721
2024-05-25 00:59:57 [INFO]: Epoch 196 - training loss: 9306.1396, validation loss: 0.0735
2024-05-25 00:59:57 [INFO]: Epoch 197 - training loss: 9305.1013, validation loss: 0.0743
2024-05-25 00:59:57 [INFO]: Epoch 198 - training loss: 9305.2068, validation loss: 0.0733
2024-05-25 00:59:57 [INFO]: Epoch 199 - training loss: 9307.5088, validation loss: 0.0713
2024-05-25 00:59:57 [INFO]: Epoch 200 - training loss: 9306.8849, validation loss: 0.0735
2024-05-25 00:59:57 [INFO]: Epoch 201 - training loss: 9305.4879, validation loss: 0.0726
2024-05-25 00:59:57 [INFO]: Epoch 202 - training loss: 9305.7178, validation loss: 0.0720
2024-05-25 00:59:57 [INFO]: Epoch 203 - training loss: 9304.8781, validation loss: 0.0721
2024-05-25 00:59:58 [INFO]: Epoch 204 - training loss: 9305.6311, validation loss: 0.0716
2024-05-25 00:59:58 [INFO]: Epoch 205 - training loss: 9306.0081, validation loss: 0.0715
2024-05-25 00:59:58 [INFO]: Epoch 206 - training loss: 9304.3867, validation loss: 0.0716
2024-05-25 00:59:58 [INFO]: Epoch 207 - training loss: 9304.1998, validation loss: 0.0707
2024-05-25 00:59:58 [INFO]: Epoch 208 - training loss: 9304.8816, validation loss: 0.0721
2024-05-25 00:59:58 [INFO]: Epoch 209 - training loss: 9305.1638, validation loss: 0.0720
2024-05-25 00:59:58 [INFO]: Epoch 210 - training loss: 9304.2964, validation loss: 0.0720
2024-05-25 00:59:58 [INFO]: Epoch 211 - training loss: 9305.1896, validation loss: 0.0707
2024-05-25 00:59:59 [INFO]: Epoch 212 - training loss: 9305.7025, validation loss: 0.0701
2024-05-25 00:59:59 [INFO]: Epoch 213 - training loss: 9305.6658, validation loss: 0.0707
2024-05-25 00:59:59 [INFO]: Epoch 214 - training loss: 9304.2870, validation loss: 0.0740
2024-05-25 00:59:59 [INFO]: Epoch 215 - training loss: 9305.3333, validation loss: 0.0703
2024-05-25 00:59:59 [INFO]: Epoch 216 - training loss: 9304.1513, validation loss: 0.0715
2024-05-25 00:59:59 [INFO]: Epoch 217 - training loss: 9303.1484, validation loss: 0.0719
2024-05-25 00:59:59 [INFO]: Epoch 218 - training loss: 9304.4631, validation loss: 0.0714
2024-05-25 00:59:59 [INFO]: Epoch 219 - training loss: 9304.3170, validation loss: 0.0705
2024-05-25 01:00:00 [INFO]: Epoch 220 - training loss: 9305.1218, validation loss: 0.0707
2024-05-25 01:00:00 [INFO]: Epoch 221 - training loss: 9304.5106, validation loss: 0.0695
2024-05-25 01:00:00 [INFO]: Epoch 222 - training loss: 9304.8961, validation loss: 0.0696
2024-05-25 01:00:00 [INFO]: Epoch 223 - training loss: 9304.3930, validation loss: 0.0707
2024-05-25 01:00:00 [INFO]: Epoch 224 - training loss: 9303.3745, validation loss: 0.0712
2024-05-25 01:00:00 [INFO]: Epoch 225 - training loss: 9303.1497, validation loss: 0.0726
2024-05-25 01:00:00 [INFO]: Epoch 226 - training loss: 9304.6274, validation loss: 0.0704
2024-05-25 01:00:00 [INFO]: Epoch 227 - training loss: 9303.9818, validation loss: 0.0703
2024-05-25 01:00:01 [INFO]: Epoch 228 - training loss: 9302.9632, validation loss: 0.0694
2024-05-25 01:00:01 [INFO]: Epoch 229 - training loss: 9304.3702, validation loss: 0.0699
2024-05-25 01:00:01 [INFO]: Epoch 230 - training loss: 9302.8998, validation loss: 0.0703
2024-05-25 01:00:01 [INFO]: Epoch 231 - training loss: 9302.9173, validation loss: 0.0703
2024-05-25 01:00:01 [INFO]: Epoch 232 - training loss: 9302.6768, validation loss: 0.0696
2024-05-25 01:00:01 [INFO]: Epoch 233 - training loss: 9303.8232, validation loss: 0.0707
2024-05-25 01:00:01 [INFO]: Epoch 234 - training loss: 9303.6344, validation loss: 0.0698
2024-05-25 01:00:01 [INFO]: Epoch 235 - training loss: 9304.7794, validation loss: 0.0695
2024-05-25 01:00:02 [INFO]: Epoch 236 - training loss: 9304.5372, validation loss: 0.0692
2024-05-25 01:00:02 [INFO]: Epoch 237 - training loss: 9303.8068, validation loss: 0.0713
2024-05-25 01:00:02 [INFO]: Epoch 238 - training loss: 9302.9782, validation loss: 0.0710
2024-05-25 01:00:02 [INFO]: Epoch 239 - training loss: 9308.1320, validation loss: 0.0692
2024-05-25 01:00:02 [INFO]: Epoch 240 - training loss: 9302.4318, validation loss: 0.0709
2024-05-25 01:00:02 [INFO]: Epoch 241 - training loss: 9302.6974, validation loss: 0.0697
2024-05-25 01:00:02 [INFO]: Epoch 242 - training loss: 9305.1346, validation loss: 0.0697
2024-05-25 01:00:02 [INFO]: Epoch 243 - training loss: 9302.5395, validation loss: 0.0684
2024-05-25 01:00:03 [INFO]: Epoch 244 - training loss: 9303.3760, validation loss: 0.0706
2024-05-25 01:00:03 [INFO]: Epoch 245 - training loss: 9303.2338, validation loss: 0.0722
2024-05-25 01:00:03 [INFO]: Epoch 246 - training loss: 9302.5126, validation loss: 0.0716
2024-05-25 01:00:03 [INFO]: Epoch 247 - training loss: 9302.6075, validation loss: 0.0706
2024-05-25 01:00:03 [INFO]: Epoch 248 - training loss: 9301.8387, validation loss: 0.0689
2024-05-25 01:00:03 [INFO]: Epoch 249 - training loss: 9305.0386, validation loss: 0.0698
2024-05-25 01:00:03 [INFO]: Epoch 250 - training loss: 9303.5731, validation loss: 0.0721
2024-05-25 01:00:03 [INFO]: Epoch 251 - training loss: 9302.3960, validation loss: 0.0703
2024-05-25 01:00:04 [INFO]: Epoch 252 - training loss: 9301.6713, validation loss: 0.0705
2024-05-25 01:00:04 [INFO]: Epoch 253 - training loss: 9302.4839, validation loss: 0.0691
2024-05-25 01:00:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:00:04 [INFO]: Finished training. The best model is from epoch#243.
2024-05-25 01:00:04 [INFO]: Saved the model to augmentation_saved_results/round_0/GPVAE_ettm1/20240525_T005932/GPVAE.pypots
2024-05-25 01:00:04 [INFO]: GP-VAE on ETTm1: MAE=0.2863, MSE=0.1704
2024-05-25 01:00:04 [INFO]: Successfully saved to augmentation_saved_results/round_0/GPVAE_ettm1/imputation.pkl
2024-05-25 01:00:04 [INFO]: Using the given device: cuda:0
2024-05-25 01:00:04 [INFO]: Model files will be saved to augmentation_saved_results/round_0/USGAN_ettm1/20240525_T010004
2024-05-25 01:00:04 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/USGAN_ettm1/20240525_T010004/tensorboard
2024-05-25 01:00:04 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 01:00:15 [INFO]: Epoch 001 - generator training loss: 0.5866, discriminator training loss: 0.3374, validation loss: 0.2853
2024-05-25 01:00:24 [INFO]: Epoch 002 - generator training loss: 0.0278, discriminator training loss: 0.2084, validation loss: 0.0952
2024-05-25 01:00:33 [INFO]: Epoch 003 - generator training loss: -0.0661, discriminator training loss: 0.1993, validation loss: 0.0654
2024-05-25 01:00:42 [INFO]: Epoch 004 - generator training loss: -0.0789, discriminator training loss: 0.1954, validation loss: 0.0551
2024-05-25 01:00:51 [INFO]: Epoch 005 - generator training loss: -0.0834, discriminator training loss: 0.1905, validation loss: 0.0453
2024-05-25 01:01:00 [INFO]: Epoch 006 - generator training loss: -0.0829, discriminator training loss: 0.1857, validation loss: 0.0427
2024-05-25 01:01:09 [INFO]: Epoch 007 - generator training loss: -0.0833, discriminator training loss: 0.1825, validation loss: 0.0403
2024-05-25 01:01:18 [INFO]: Epoch 008 - generator training loss: -0.0750, discriminator training loss: 0.1739, validation loss: 0.0390
2024-05-25 01:01:27 [INFO]: Epoch 009 - generator training loss: -0.0667, discriminator training loss: 0.1656, validation loss: 0.0388
2024-05-25 01:01:36 [INFO]: Epoch 010 - generator training loss: -0.0546, discriminator training loss: 0.1513, validation loss: 0.0373
2024-05-25 01:01:45 [INFO]: Epoch 011 - generator training loss: -0.0424, discriminator training loss: 0.1381, validation loss: 0.0381
2024-05-25 01:01:54 [INFO]: Epoch 012 - generator training loss: -0.0306, discriminator training loss: 0.1243, validation loss: 0.0384
2024-05-25 01:02:03 [INFO]: Epoch 013 - generator training loss: -0.0225, discriminator training loss: 0.1105, validation loss: 0.0373
2024-05-25 01:02:12 [INFO]: Epoch 014 - generator training loss: -0.0184, discriminator training loss: 0.1024, validation loss: 0.0355
2024-05-25 01:02:21 [INFO]: Epoch 015 - generator training loss: -0.0140, discriminator training loss: 0.0949, validation loss: 0.0346
2024-05-25 01:02:30 [INFO]: Epoch 016 - generator training loss: -0.0112, discriminator training loss: 0.0894, validation loss: 0.0342
2024-05-25 01:02:39 [INFO]: Epoch 017 - generator training loss: -0.0127, discriminator training loss: 0.0864, validation loss: 0.0334
2024-05-25 01:02:48 [INFO]: Epoch 018 - generator training loss: -0.0100, discriminator training loss: 0.0854, validation loss: 0.0336
2024-05-25 01:02:58 [INFO]: Epoch 019 - generator training loss: -0.0103, discriminator training loss: 0.0816, validation loss: 0.0335
2024-05-25 01:03:07 [INFO]: Epoch 020 - generator training loss: -0.0090, discriminator training loss: 0.0786, validation loss: 0.0341
2024-05-25 01:03:16 [INFO]: Epoch 021 - generator training loss: -0.0108, discriminator training loss: 0.0793, validation loss: 0.0320
2024-05-25 01:03:25 [INFO]: Epoch 022 - generator training loss: -0.0102, discriminator training loss: 0.0801, validation loss: 0.0319
2024-05-25 01:03:34 [INFO]: Epoch 023 - generator training loss: -0.0093, discriminator training loss: 0.0799, validation loss: 0.0327
2024-05-25 01:03:43 [INFO]: Epoch 024 - generator training loss: -0.0099, discriminator training loss: 0.0799, validation loss: 0.0321
2024-05-25 01:03:52 [INFO]: Epoch 025 - generator training loss: -0.0097, discriminator training loss: 0.0782, validation loss: 0.0309
2024-05-25 01:04:01 [INFO]: Epoch 026 - generator training loss: -0.0106, discriminator training loss: 0.0744, validation loss: 0.0298
2024-05-25 01:04:10 [INFO]: Epoch 027 - generator training loss: -0.0126, discriminator training loss: 0.0723, validation loss: 0.0299
2024-05-25 01:04:19 [INFO]: Epoch 028 - generator training loss: -0.0118, discriminator training loss: 0.0729, validation loss: 0.0309
2024-05-25 01:04:28 [INFO]: Epoch 029 - generator training loss: -0.0099, discriminator training loss: 0.0733, validation loss: 0.0297
2024-05-25 01:04:36 [INFO]: Epoch 030 - generator training loss: -0.0120, discriminator training loss: 0.0736, validation loss: 0.0291
2024-05-25 01:04:46 [INFO]: Epoch 031 - generator training loss: -0.0095, discriminator training loss: 0.0749, validation loss: 0.0296
2024-05-25 01:04:55 [INFO]: Epoch 032 - generator training loss: -0.0116, discriminator training loss: 0.0734, validation loss: 0.0294
2024-05-25 01:05:03 [INFO]: Epoch 033 - generator training loss: -0.0118, discriminator training loss: 0.0740, validation loss: 0.0287
2024-05-25 01:05:12 [INFO]: Epoch 034 - generator training loss: -0.0124, discriminator training loss: 0.0713, validation loss: 0.0279
2024-05-25 01:05:21 [INFO]: Epoch 035 - generator training loss: -0.0156, discriminator training loss: 0.0724, validation loss: 0.0275
2024-05-25 01:05:30 [INFO]: Epoch 036 - generator training loss: -0.0119, discriminator training loss: 0.0728, validation loss: 0.0283
2024-05-25 01:05:39 [INFO]: Epoch 037 - generator training loss: -0.0106, discriminator training loss: 0.0705, validation loss: 0.0289
2024-05-25 01:05:48 [INFO]: Epoch 038 - generator training loss: -0.0155, discriminator training loss: 0.0704, validation loss: 0.0289
2024-05-25 01:05:57 [INFO]: Epoch 039 - generator training loss: -0.0126, discriminator training loss: 0.0706, validation loss: 0.0269
2024-05-25 01:06:07 [INFO]: Epoch 040 - generator training loss: -0.0140, discriminator training loss: 0.0710, validation loss: 0.0294
2024-05-25 01:06:15 [INFO]: Epoch 041 - generator training loss: -0.0164, discriminator training loss: 0.0731, validation loss: 0.0271
2024-05-25 01:06:25 [INFO]: Epoch 042 - generator training loss: -0.0171, discriminator training loss: 0.0711, validation loss: 0.0285
2024-05-25 01:06:34 [INFO]: Epoch 043 - generator training loss: -0.0165, discriminator training loss: 0.0735, validation loss: 0.0274
2024-05-25 01:06:43 [INFO]: Epoch 044 - generator training loss: -0.0159, discriminator training loss: 0.0731, validation loss: 0.0263
2024-05-25 01:06:52 [INFO]: Epoch 045 - generator training loss: -0.0164, discriminator training loss: 0.0702, validation loss: 0.0266
2024-05-25 01:07:01 [INFO]: Epoch 046 - generator training loss: -0.0167, discriminator training loss: 0.0708, validation loss: 0.0255
2024-05-25 01:07:10 [INFO]: Epoch 047 - generator training loss: -0.0181, discriminator training loss: 0.0674, validation loss: 0.0250
2024-05-25 01:07:19 [INFO]: Epoch 048 - generator training loss: -0.0193, discriminator training loss: 0.0695, validation loss: 0.0248
2024-05-25 01:07:28 [INFO]: Epoch 049 - generator training loss: -0.0181, discriminator training loss: 0.0679, validation loss: 0.0248
2024-05-25 01:07:37 [INFO]: Epoch 050 - generator training loss: -0.0180, discriminator training loss: 0.0696, validation loss: 0.0233
2024-05-25 01:07:45 [INFO]: Epoch 051 - generator training loss: -0.0184, discriminator training loss: 0.0677, validation loss: 0.0238
2024-05-25 01:07:55 [INFO]: Epoch 052 - generator training loss: -0.0186, discriminator training loss: 0.0689, validation loss: 0.0231
2024-05-25 01:08:03 [INFO]: Epoch 053 - generator training loss: -0.0186, discriminator training loss: 0.0675, validation loss: 0.0234
2024-05-25 01:08:12 [INFO]: Epoch 054 - generator training loss: -0.0204, discriminator training loss: 0.0673, validation loss: 0.0229
2024-05-25 01:08:21 [INFO]: Epoch 055 - generator training loss: -0.0200, discriminator training loss: 0.0701, validation loss: 0.0233
2024-05-25 01:08:30 [INFO]: Epoch 056 - generator training loss: -0.0208, discriminator training loss: 0.0687, validation loss: 0.0220
2024-05-25 01:08:39 [INFO]: Epoch 057 - generator training loss: -0.0199, discriminator training loss: 0.0700, validation loss: 0.0222
2024-05-25 01:08:48 [INFO]: Epoch 058 - generator training loss: -0.0198, discriminator training loss: 0.0688, validation loss: 0.0222
2024-05-25 01:08:57 [INFO]: Epoch 059 - generator training loss: -0.0227, discriminator training loss: 0.0696, validation loss: 0.0223
2024-05-25 01:09:06 [INFO]: Epoch 060 - generator training loss: -0.0174, discriminator training loss: 0.0683, validation loss: 0.0224
2024-05-25 01:09:15 [INFO]: Epoch 061 - generator training loss: -0.0220, discriminator training loss: 0.0668, validation loss: 0.0224
2024-05-25 01:09:24 [INFO]: Epoch 062 - generator training loss: -0.0188, discriminator training loss: 0.0691, validation loss: 0.0219
2024-05-25 01:09:33 [INFO]: Epoch 063 - generator training loss: -0.0209, discriminator training loss: 0.0688, validation loss: 0.0226
2024-05-25 01:09:42 [INFO]: Epoch 064 - generator training loss: -0.0226, discriminator training loss: 0.0690, validation loss: 0.0226
2024-05-25 01:09:51 [INFO]: Epoch 065 - generator training loss: -0.0193, discriminator training loss: 0.0665, validation loss: 0.0220
2024-05-25 01:10:00 [INFO]: Epoch 066 - generator training loss: -0.0200, discriminator training loss: 0.0696, validation loss: 0.0220
2024-05-25 01:10:09 [INFO]: Epoch 067 - generator training loss: -0.0209, discriminator training loss: 0.0672, validation loss: 0.0214
2024-05-25 01:10:18 [INFO]: Epoch 068 - generator training loss: -0.0213, discriminator training loss: 0.0658, validation loss: 0.0219
2024-05-25 01:10:27 [INFO]: Epoch 069 - generator training loss: -0.0227, discriminator training loss: 0.0665, validation loss: 0.0215
2024-05-25 01:10:36 [INFO]: Epoch 070 - generator training loss: -0.0219, discriminator training loss: 0.0677, validation loss: 0.0219
2024-05-25 01:10:45 [INFO]: Epoch 071 - generator training loss: -0.0219, discriminator training loss: 0.0687, validation loss: 0.0220
2024-05-25 01:10:54 [INFO]: Epoch 072 - generator training loss: -0.0218, discriminator training loss: 0.0682, validation loss: 0.0218
2024-05-25 01:11:03 [INFO]: Epoch 073 - generator training loss: -0.0218, discriminator training loss: 0.0689, validation loss: 0.0213
2024-05-25 01:11:12 [INFO]: Epoch 074 - generator training loss: -0.0209, discriminator training loss: 0.0682, validation loss: 0.0211
2024-05-25 01:11:21 [INFO]: Epoch 075 - generator training loss: -0.0231, discriminator training loss: 0.0680, validation loss: 0.0211
2024-05-25 01:11:30 [INFO]: Epoch 076 - generator training loss: -0.0216, discriminator training loss: 0.0684, validation loss: 0.0214
2024-05-25 01:11:39 [INFO]: Epoch 077 - generator training loss: -0.0203, discriminator training loss: 0.0671, validation loss: 0.0215
2024-05-25 01:11:48 [INFO]: Epoch 078 - generator training loss: -0.0222, discriminator training loss: 0.0678, validation loss: 0.0206
2024-05-25 01:11:57 [INFO]: Epoch 079 - generator training loss: -0.0216, discriminator training loss: 0.0677, validation loss: 0.0211
2024-05-25 01:12:06 [INFO]: Epoch 080 - generator training loss: -0.0225, discriminator training loss: 0.0670, validation loss: 0.0209
2024-05-25 01:12:15 [INFO]: Epoch 081 - generator training loss: -0.0205, discriminator training loss: 0.0644, validation loss: 0.0218
2024-05-25 01:12:24 [INFO]: Epoch 082 - generator training loss: -0.0210, discriminator training loss: 0.0671, validation loss: 0.0221
2024-05-25 01:12:33 [INFO]: Epoch 083 - generator training loss: -0.0238, discriminator training loss: 0.0677, validation loss: 0.0212
2024-05-25 01:12:42 [INFO]: Epoch 084 - generator training loss: -0.0227, discriminator training loss: 0.0690, validation loss: 0.0204
2024-05-25 01:12:51 [INFO]: Epoch 085 - generator training loss: -0.0183, discriminator training loss: 0.0675, validation loss: 0.0220
2024-05-25 01:13:01 [INFO]: Epoch 086 - generator training loss: -0.0244, discriminator training loss: 0.0664, validation loss: 0.0218
2024-05-25 01:13:10 [INFO]: Epoch 087 - generator training loss: -0.0205, discriminator training loss: 0.0680, validation loss: 0.0205
2024-05-25 01:13:19 [INFO]: Epoch 088 - generator training loss: -0.0202, discriminator training loss: 0.0652, validation loss: 0.0207
2024-05-25 01:13:28 [INFO]: Epoch 089 - generator training loss: -0.0242, discriminator training loss: 0.0678, validation loss: 0.0209
2024-05-25 01:13:37 [INFO]: Epoch 090 - generator training loss: -0.0227, discriminator training loss: 0.0673, validation loss: 0.0204
2024-05-25 01:13:46 [INFO]: Epoch 091 - generator training loss: -0.0237, discriminator training loss: 0.0660, validation loss: 0.0202
2024-05-25 01:13:55 [INFO]: Epoch 092 - generator training loss: -0.0221, discriminator training loss: 0.0653, validation loss: 0.0216
2024-05-25 01:14:04 [INFO]: Epoch 093 - generator training loss: -0.0223, discriminator training loss: 0.0675, validation loss: 0.0200
2024-05-25 01:14:13 [INFO]: Epoch 094 - generator training loss: -0.0202, discriminator training loss: 0.0649, validation loss: 0.0239
2024-05-25 01:14:22 [INFO]: Epoch 095 - generator training loss: -0.0226, discriminator training loss: 0.0649, validation loss: 0.0205
2024-05-25 01:14:31 [INFO]: Epoch 096 - generator training loss: -0.0214, discriminator training loss: 0.0658, validation loss: 0.0207
2024-05-25 01:14:40 [INFO]: Epoch 097 - generator training loss: -0.0219, discriminator training loss: 0.0660, validation loss: 0.0202
2024-05-25 01:14:49 [INFO]: Epoch 098 - generator training loss: -0.0244, discriminator training loss: 0.0655, validation loss: 0.0197
2024-05-25 01:14:58 [INFO]: Epoch 099 - generator training loss: -0.0216, discriminator training loss: 0.0651, validation loss: 0.0200
2024-05-25 01:15:07 [INFO]: Epoch 100 - generator training loss: -0.0215, discriminator training loss: 0.0644, validation loss: 0.0197
2024-05-25 01:15:16 [INFO]: Epoch 101 - generator training loss: -0.0236, discriminator training loss: 0.0657, validation loss: 0.0191
2024-05-25 01:15:25 [INFO]: Epoch 102 - generator training loss: -0.0238, discriminator training loss: 0.0695, validation loss: 0.0206
2024-05-25 01:15:34 [INFO]: Epoch 103 - generator training loss: -0.0234, discriminator training loss: 0.0674, validation loss: 0.0196
2024-05-25 01:15:43 [INFO]: Epoch 104 - generator training loss: -0.0255, discriminator training loss: 0.0663, validation loss: 0.0201
2024-05-25 01:15:52 [INFO]: Epoch 105 - generator training loss: -0.0211, discriminator training loss: 0.0649, validation loss: 0.0199
2024-05-25 01:16:01 [INFO]: Epoch 106 - generator training loss: -0.0239, discriminator training loss: 0.0643, validation loss: 0.0199
2024-05-25 01:16:10 [INFO]: Epoch 107 - generator training loss: -0.0230, discriminator training loss: 0.0679, validation loss: 0.0192
2024-05-25 01:16:19 [INFO]: Epoch 108 - generator training loss: -0.0227, discriminator training loss: 0.0654, validation loss: 0.0198
2024-05-25 01:16:28 [INFO]: Epoch 109 - generator training loss: -0.0244, discriminator training loss: 0.0662, validation loss: 0.0189
2024-05-25 01:16:37 [INFO]: Epoch 110 - generator training loss: -0.0237, discriminator training loss: 0.0670, validation loss: 0.0191
2024-05-25 01:16:46 [INFO]: Epoch 111 - generator training loss: -0.0249, discriminator training loss: 0.0660, validation loss: 0.0190
2024-05-25 01:16:55 [INFO]: Epoch 112 - generator training loss: -0.0253, discriminator training loss: 0.0656, validation loss: 0.0190
2024-05-25 01:17:04 [INFO]: Epoch 113 - generator training loss: -0.0249, discriminator training loss: 0.0652, validation loss: 0.0192
2024-05-25 01:17:13 [INFO]: Epoch 114 - generator training loss: -0.0245, discriminator training loss: 0.0643, validation loss: 0.0197
2024-05-25 01:17:22 [INFO]: Epoch 115 - generator training loss: -0.0228, discriminator training loss: 0.0655, validation loss: 0.0192
2024-05-25 01:17:31 [INFO]: Epoch 116 - generator training loss: -0.0254, discriminator training loss: 0.0638, validation loss: 0.0196
2024-05-25 01:17:39 [INFO]: Epoch 117 - generator training loss: -0.0264, discriminator training loss: 0.0646, validation loss: 0.0192
2024-05-25 01:17:48 [INFO]: Epoch 118 - generator training loss: -0.0239, discriminator training loss: 0.0659, validation loss: 0.0188
2024-05-25 01:17:57 [INFO]: Epoch 119 - generator training loss: -0.0223, discriminator training loss: 0.0662, validation loss: 0.0189
2024-05-25 01:18:06 [INFO]: Epoch 120 - generator training loss: -0.0248, discriminator training loss: 0.0656, validation loss: 0.0191
2024-05-25 01:18:15 [INFO]: Epoch 121 - generator training loss: -0.0255, discriminator training loss: 0.0653, validation loss: 0.0202
2024-05-25 01:18:24 [INFO]: Epoch 122 - generator training loss: -0.0256, discriminator training loss: 0.0654, validation loss: 0.0197
2024-05-25 01:18:33 [INFO]: Epoch 123 - generator training loss: -0.0257, discriminator training loss: 0.0655, validation loss: 0.0201
2024-05-25 01:18:42 [INFO]: Epoch 124 - generator training loss: -0.0243, discriminator training loss: 0.0640, validation loss: 0.0188
2024-05-25 01:18:51 [INFO]: Epoch 125 - generator training loss: -0.0262, discriminator training loss: 0.0629, validation loss: 0.0185
2024-05-25 01:19:00 [INFO]: Epoch 126 - generator training loss: -0.0272, discriminator training loss: 0.0650, validation loss: 0.0193
2024-05-25 01:19:09 [INFO]: Epoch 127 - generator training loss: -0.0265, discriminator training loss: 0.0635, validation loss: 0.0189
2024-05-25 01:19:18 [INFO]: Epoch 128 - generator training loss: -0.0253, discriminator training loss: 0.0646, validation loss: 0.0182
2024-05-25 01:19:27 [INFO]: Epoch 129 - generator training loss: -0.0243, discriminator training loss: 0.0640, validation loss: 0.0189
2024-05-25 01:19:36 [INFO]: Epoch 130 - generator training loss: -0.0265, discriminator training loss: 0.0660, validation loss: 0.0186
2024-05-25 01:19:45 [INFO]: Epoch 131 - generator training loss: -0.0247, discriminator training loss: 0.0650, validation loss: 0.0193
2024-05-25 01:19:54 [INFO]: Epoch 132 - generator training loss: -0.0257, discriminator training loss: 0.0640, validation loss: 0.0192
2024-05-25 01:20:03 [INFO]: Epoch 133 - generator training loss: -0.0265, discriminator training loss: 0.0657, validation loss: 0.0185
2024-05-25 01:20:12 [INFO]: Epoch 134 - generator training loss: -0.0274, discriminator training loss: 0.0666, validation loss: 0.0187
2024-05-25 01:20:21 [INFO]: Epoch 135 - generator training loss: -0.0245, discriminator training loss: 0.0660, validation loss: 0.0187
2024-05-25 01:20:30 [INFO]: Epoch 136 - generator training loss: -0.0255, discriminator training loss: 0.0635, validation loss: 0.0184
2024-05-25 01:20:39 [INFO]: Epoch 137 - generator training loss: -0.0257, discriminator training loss: 0.0640, validation loss: 0.0185
2024-05-25 01:20:48 [INFO]: Epoch 138 - generator training loss: -0.0258, discriminator training loss: 0.0650, validation loss: 0.0185
2024-05-25 01:20:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:20:48 [INFO]: Finished training. The best model is from epoch#128.
2024-05-25 01:20:48 [INFO]: Saved the model to augmentation_saved_results/round_0/USGAN_ettm1/20240525_T010004/USGAN.pypots
2024-05-25 01:20:49 [INFO]: US-GAN on ETTm1: MAE=0.1486, MSE=0.0557
2024-05-25 01:20:49 [INFO]: Successfully saved to augmentation_saved_results/round_0/USGAN_ettm1/imputation.pkl
2024-05-25 01:20:49 [INFO]: Using the given device: cuda:0
2024-05-25 01:20:49 [INFO]: Model files will be saved to augmentation_saved_results/round_0/BRITS_ettm1/20240525_T012049
2024-05-25 01:20:49 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/BRITS_ettm1/20240525_T012049/tensorboard
2024-05-25 01:20:49 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 01:20:57 [INFO]: Epoch 001 - training loss: 1.3136, validation loss: 0.3361
2024-05-25 01:21:03 [INFO]: Epoch 002 - training loss: 0.8984, validation loss: 0.0782
2024-05-25 01:21:09 [INFO]: Epoch 003 - training loss: 0.7148, validation loss: 0.0544
2024-05-25 01:21:15 [INFO]: Epoch 004 - training loss: 0.6377, validation loss: 0.0446
2024-05-25 01:21:21 [INFO]: Epoch 005 - training loss: 0.5807, validation loss: 0.0397
2024-05-25 01:21:27 [INFO]: Epoch 006 - training loss: 0.5428, validation loss: 0.0377
2024-05-25 01:21:33 [INFO]: Epoch 007 - training loss: 0.5197, validation loss: 0.0349
2024-05-25 01:21:39 [INFO]: Epoch 008 - training loss: 0.5077, validation loss: 0.0370
2024-05-25 01:21:45 [INFO]: Epoch 009 - training loss: 0.4819, validation loss: 0.0322
2024-05-25 01:21:51 [INFO]: Epoch 010 - training loss: 0.4590, validation loss: 0.0296
2024-05-25 01:21:57 [INFO]: Epoch 011 - training loss: 0.4386, validation loss: 0.0269
2024-05-25 01:22:03 [INFO]: Epoch 012 - training loss: 0.4208, validation loss: 0.0248
2024-05-25 01:22:09 [INFO]: Epoch 013 - training loss: 0.4167, validation loss: 0.0252
2024-05-25 01:22:15 [INFO]: Epoch 014 - training loss: 0.4080, validation loss: 0.0240
2024-05-25 01:22:21 [INFO]: Epoch 015 - training loss: 0.4018, validation loss: 0.0241
2024-05-25 01:22:27 [INFO]: Epoch 016 - training loss: 0.3995, validation loss: 0.0234
2024-05-25 01:22:33 [INFO]: Epoch 017 - training loss: 0.4082, validation loss: 0.0227
2024-05-25 01:22:39 [INFO]: Epoch 018 - training loss: 0.3963, validation loss: 0.0233
2024-05-25 01:22:45 [INFO]: Epoch 019 - training loss: 0.3909, validation loss: 0.0222
2024-05-25 01:22:52 [INFO]: Epoch 020 - training loss: 0.3894, validation loss: 0.0227
2024-05-25 01:22:58 [INFO]: Epoch 021 - training loss: 0.3850, validation loss: 0.0222
2024-05-25 01:23:04 [INFO]: Epoch 022 - training loss: 0.3871, validation loss: 0.0221
2024-05-25 01:23:10 [INFO]: Epoch 023 - training loss: 0.3815, validation loss: 0.0231
2024-05-25 01:23:16 [INFO]: Epoch 024 - training loss: 0.3822, validation loss: 0.0224
2024-05-25 01:23:22 [INFO]: Epoch 025 - training loss: 0.3799, validation loss: 0.0221
2024-05-25 01:23:28 [INFO]: Epoch 026 - training loss: 0.3848, validation loss: 0.0224
2024-05-25 01:23:34 [INFO]: Epoch 027 - training loss: 0.3847, validation loss: 0.0222
2024-05-25 01:23:40 [INFO]: Epoch 028 - training loss: 0.3786, validation loss: 0.0219
2024-05-25 01:23:46 [INFO]: Epoch 029 - training loss: 0.3810, validation loss: 0.0220
2024-05-25 01:23:52 [INFO]: Epoch 030 - training loss: 0.3825, validation loss: 0.0222
2024-05-25 01:23:58 [INFO]: Epoch 031 - training loss: 0.3847, validation loss: 0.0218
2024-05-25 01:24:04 [INFO]: Epoch 032 - training loss: 0.3773, validation loss: 0.0219
2024-05-25 01:24:10 [INFO]: Epoch 033 - training loss: 0.3785, validation loss: 0.0218
2024-05-25 01:24:16 [INFO]: Epoch 034 - training loss: 0.3990, validation loss: 0.0222
2024-05-25 01:24:22 [INFO]: Epoch 035 - training loss: 0.3880, validation loss: 0.0226
2024-05-25 01:24:28 [INFO]: Epoch 036 - training loss: 0.3908, validation loss: 0.0225
2024-05-25 01:24:34 [INFO]: Epoch 037 - training loss: 0.3881, validation loss: 0.0222
2024-05-25 01:24:40 [INFO]: Epoch 038 - training loss: 0.3786, validation loss: 0.0221
2024-05-25 01:24:46 [INFO]: Epoch 039 - training loss: 0.3799, validation loss: 0.0221
2024-05-25 01:24:52 [INFO]: Epoch 040 - training loss: 0.3766, validation loss: 0.0219
2024-05-25 01:24:58 [INFO]: Epoch 041 - training loss: 0.3781, validation loss: 0.0218
2024-05-25 01:25:04 [INFO]: Epoch 042 - training loss: 0.3818, validation loss: 0.0219
2024-05-25 01:25:10 [INFO]: Epoch 043 - training loss: 0.3765, validation loss: 0.0225
2024-05-25 01:25:16 [INFO]: Epoch 044 - training loss: 0.3708, validation loss: 0.0214
2024-05-25 01:25:22 [INFO]: Epoch 045 - training loss: 0.3701, validation loss: 0.0222
2024-05-25 01:25:28 [INFO]: Epoch 046 - training loss: 0.3733, validation loss: 0.0221
2024-05-25 01:25:34 [INFO]: Epoch 047 - training loss: 0.3703, validation loss: 0.0222
2024-05-25 01:25:40 [INFO]: Epoch 048 - training loss: 0.3772, validation loss: 0.0223
2024-05-25 01:25:46 [INFO]: Epoch 049 - training loss: 0.3711, validation loss: 0.0217
2024-05-25 01:25:52 [INFO]: Epoch 050 - training loss: 0.3725, validation loss: 0.0219
2024-05-25 01:25:58 [INFO]: Epoch 051 - training loss: 0.3830, validation loss: 0.0217
2024-05-25 01:26:04 [INFO]: Epoch 052 - training loss: 0.3704, validation loss: 0.0215
2024-05-25 01:26:10 [INFO]: Epoch 053 - training loss: 0.3691, validation loss: 0.0223
2024-05-25 01:26:16 [INFO]: Epoch 054 - training loss: 0.3767, validation loss: 0.0229
2024-05-25 01:26:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:26:16 [INFO]: Finished training. The best model is from epoch#44.
2024-05-25 01:26:16 [INFO]: Saved the model to augmentation_saved_results/round_0/BRITS_ettm1/20240525_T012049/BRITS.pypots
2024-05-25 01:26:17 [INFO]: BRITS on ETTm1: MAE=0.1329, MSE=0.0523
2024-05-25 01:26:17 [INFO]: Successfully saved to augmentation_saved_results/round_0/BRITS_ettm1/imputation.pkl
2024-05-25 01:26:17 [INFO]: Using the given device: cuda:0
2024-05-25 01:26:17 [INFO]: Model files will be saved to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617
2024-05-25 01:26:17 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/tensorboard
2024-05-25 01:26:17 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 01:26:19 [INFO]: Epoch 001 - training loss: 1.4197, validation loss: 1.3729
2024-05-25 01:26:19 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch1_loss1.3729093670845032.pypots
2024-05-25 01:26:20 [INFO]: Epoch 002 - training loss: 1.1057, validation loss: 1.2206
2024-05-25 01:26:20 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch2_loss1.2205577492713928.pypots
2024-05-25 01:26:20 [INFO]: Epoch 003 - training loss: 1.0220, validation loss: 1.1180
2024-05-25 01:26:20 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch3_loss1.1179653704166412.pypots
2024-05-25 01:26:20 [INFO]: Epoch 004 - training loss: 0.9794, validation loss: 1.0599
2024-05-25 01:26:20 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch4_loss1.0599489957094193.pypots
2024-05-25 01:26:20 [INFO]: Epoch 005 - training loss: 0.9991, validation loss: 1.0349
2024-05-25 01:26:20 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch5_loss1.0348705649375916.pypots
2024-05-25 01:26:20 [INFO]: Epoch 006 - training loss: 0.9443, validation loss: 1.0298
2024-05-25 01:26:20 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch6_loss1.0297578871250153.pypots
2024-05-25 01:26:20 [INFO]: Epoch 007 - training loss: 0.9495, validation loss: 1.0240
2024-05-25 01:26:20 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch7_loss1.0239622592926025.pypots
2024-05-25 01:26:21 [INFO]: Epoch 008 - training loss: 0.9574, validation loss: 1.0158
2024-05-25 01:26:21 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch8_loss1.0158037841320038.pypots
2024-05-25 01:26:21 [INFO]: Epoch 009 - training loss: 0.9370, validation loss: 1.0145
2024-05-25 01:26:21 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch9_loss1.0144878327846527.pypots
2024-05-25 01:26:21 [INFO]: Epoch 010 - training loss: 0.9517, validation loss: 1.0127
2024-05-25 01:26:21 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch10_loss1.0127342492341995.pypots
2024-05-25 01:26:21 [INFO]: Epoch 011 - training loss: 0.9062, validation loss: 1.0117
2024-05-25 01:26:21 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch11_loss1.0117045044898987.pypots
2024-05-25 01:26:21 [INFO]: Epoch 012 - training loss: 0.8967, validation loss: 1.0137
2024-05-25 01:26:21 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch12_loss1.013672560453415.pypots
2024-05-25 01:26:22 [INFO]: Epoch 013 - training loss: 0.8852, validation loss: 1.0147
2024-05-25 01:26:22 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch13_loss1.0147164463996887.pypots
2024-05-25 01:26:22 [INFO]: Epoch 014 - training loss: 0.9349, validation loss: 1.0150
2024-05-25 01:26:22 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch14_loss1.0149766504764557.pypots
2024-05-25 01:26:22 [INFO]: Epoch 015 - training loss: 0.8590, validation loss: 1.0174
2024-05-25 01:26:22 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch15_loss1.0173742771148682.pypots
2024-05-25 01:26:22 [INFO]: Epoch 016 - training loss: 0.8774, validation loss: 1.0148
2024-05-25 01:26:22 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch16_loss1.0147517621517181.pypots
2024-05-25 01:26:22 [INFO]: Epoch 017 - training loss: 0.8820, validation loss: 1.0116
2024-05-25 01:26:22 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch17_loss1.0116474479436874.pypots
2024-05-25 01:26:23 [INFO]: Epoch 018 - training loss: 0.8855, validation loss: 1.0093
2024-05-25 01:26:23 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch18_loss1.0093420445919037.pypots
2024-05-25 01:26:23 [INFO]: Epoch 019 - training loss: 0.8766, validation loss: 1.0111
2024-05-25 01:26:23 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch19_loss1.0111106634140015.pypots
2024-05-25 01:26:23 [INFO]: Epoch 020 - training loss: 0.8965, validation loss: 1.0091
2024-05-25 01:26:23 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch20_loss1.0090530812740326.pypots
2024-05-25 01:26:23 [INFO]: Epoch 021 - training loss: 0.8915, validation loss: 1.0083
2024-05-25 01:26:23 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch21_loss1.0083370208740234.pypots
2024-05-25 01:26:23 [INFO]: Epoch 022 - training loss: 0.8943, validation loss: 1.0017
2024-05-25 01:26:23 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch22_loss1.0017195045948029.pypots
2024-05-25 01:26:23 [INFO]: Epoch 023 - training loss: 0.9071, validation loss: 1.0014
2024-05-25 01:26:23 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch23_loss1.0014007538557053.pypots
2024-05-25 01:26:24 [INFO]: Epoch 024 - training loss: 0.8719, validation loss: 0.9968
2024-05-25 01:26:24 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch24_loss0.9967814236879349.pypots
2024-05-25 01:26:24 [INFO]: Epoch 025 - training loss: 0.8484, validation loss: 0.9944
2024-05-25 01:26:24 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch25_loss0.9943811595439911.pypots
2024-05-25 01:26:24 [INFO]: Epoch 026 - training loss: 0.8362, validation loss: 0.9894
2024-05-25 01:26:24 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch26_loss0.9893684238195419.pypots
2024-05-25 01:26:24 [INFO]: Epoch 027 - training loss: 0.9057, validation loss: 0.9852
2024-05-25 01:26:24 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch27_loss0.985219195485115.pypots
2024-05-25 01:26:24 [INFO]: Epoch 028 - training loss: 0.8647, validation loss: 0.9836
2024-05-25 01:26:24 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch28_loss0.9835996925830841.pypots
2024-05-25 01:26:25 [INFO]: Epoch 029 - training loss: 0.8466, validation loss: 0.9789
2024-05-25 01:26:25 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch29_loss0.9789112657308578.pypots
2024-05-25 01:26:25 [INFO]: Epoch 030 - training loss: 0.8351, validation loss: 0.9771
2024-05-25 01:26:25 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch30_loss0.9770996272563934.pypots
2024-05-25 01:26:25 [INFO]: Epoch 031 - training loss: 0.8385, validation loss: 0.9736
2024-05-25 01:26:25 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch31_loss0.9736417382955551.pypots
2024-05-25 01:26:25 [INFO]: Epoch 032 - training loss: 0.8390, validation loss: 0.9649
2024-05-25 01:26:25 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch32_loss0.9648834019899368.pypots
2024-05-25 01:26:25 [INFO]: Epoch 033 - training loss: 0.8584, validation loss: 0.9627
2024-05-25 01:26:25 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch33_loss0.9626837372779846.pypots
2024-05-25 01:26:26 [INFO]: Epoch 034 - training loss: 0.8394, validation loss: 0.9618
2024-05-25 01:26:26 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch34_loss0.961768850684166.pypots
2024-05-25 01:26:26 [INFO]: Epoch 035 - training loss: 0.8327, validation loss: 0.9583
2024-05-25 01:26:26 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch35_loss0.9583039879798889.pypots
2024-05-25 01:26:26 [INFO]: Epoch 036 - training loss: 0.8284, validation loss: 0.9540
2024-05-25 01:26:26 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch36_loss0.9539661407470703.pypots
2024-05-25 01:26:26 [INFO]: Epoch 037 - training loss: 0.8058, validation loss: 0.9509
2024-05-25 01:26:26 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch37_loss0.9509122520685196.pypots
2024-05-25 01:26:26 [INFO]: Epoch 038 - training loss: 0.8765, validation loss: 0.9475
2024-05-25 01:26:26 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch38_loss0.9475395232439041.pypots
2024-05-25 01:26:26 [INFO]: Epoch 039 - training loss: 0.8686, validation loss: 0.9453
2024-05-25 01:26:26 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch39_loss0.9453094750642776.pypots
2024-05-25 01:26:27 [INFO]: Epoch 040 - training loss: 0.8266, validation loss: 0.9418
2024-05-25 01:26:27 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch40_loss0.9417754113674164.pypots
2024-05-25 01:26:27 [INFO]: Epoch 041 - training loss: 0.8047, validation loss: 0.9397
2024-05-25 01:26:27 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch41_loss0.9397157430648804.pypots
2024-05-25 01:26:27 [INFO]: Epoch 042 - training loss: 0.8232, validation loss: 0.9376
2024-05-25 01:26:27 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch42_loss0.9375671744346619.pypots
2024-05-25 01:26:27 [INFO]: Epoch 043 - training loss: 0.8134, validation loss: 0.9354
2024-05-25 01:26:27 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch43_loss0.9354478567838669.pypots
2024-05-25 01:26:27 [INFO]: Epoch 044 - training loss: 0.8047, validation loss: 0.9332
2024-05-25 01:26:27 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch44_loss0.9332132637500763.pypots
2024-05-25 01:26:28 [INFO]: Epoch 045 - training loss: 0.8231, validation loss: 0.9305
2024-05-25 01:26:28 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch45_loss0.9304641336202621.pypots
2024-05-25 01:26:28 [INFO]: Epoch 046 - training loss: 0.8123, validation loss: 0.9260
2024-05-25 01:26:28 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch46_loss0.9260227382183075.pypots
2024-05-25 01:26:28 [INFO]: Epoch 047 - training loss: 0.8644, validation loss: 0.9279
2024-05-25 01:26:28 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch47_loss0.9278532862663269.pypots
2024-05-25 01:26:28 [INFO]: Epoch 048 - training loss: 0.8170, validation loss: 0.9205
2024-05-25 01:26:28 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch48_loss0.9204885214567184.pypots
2024-05-25 01:26:28 [INFO]: Epoch 049 - training loss: 0.8122, validation loss: 0.9210
2024-05-25 01:26:28 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch49_loss0.9209975153207779.pypots
2024-05-25 01:26:29 [INFO]: Epoch 050 - training loss: 0.8138, validation loss: 0.9201
2024-05-25 01:26:29 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch50_loss0.920124739408493.pypots
2024-05-25 01:26:29 [INFO]: Epoch 051 - training loss: 0.8038, validation loss: 0.9186
2024-05-25 01:26:29 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch51_loss0.9186475723981857.pypots
2024-05-25 01:26:29 [INFO]: Epoch 052 - training loss: 0.8075, validation loss: 0.9148
2024-05-25 01:26:29 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch52_loss0.9147786945104599.pypots
2024-05-25 01:26:29 [INFO]: Epoch 053 - training loss: 0.8045, validation loss: 0.9156
2024-05-25 01:26:29 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch53_loss0.9156256169080734.pypots
2024-05-25 01:26:29 [INFO]: Epoch 054 - training loss: 0.8077, validation loss: 0.9118
2024-05-25 01:26:29 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch54_loss0.9117865860462189.pypots
2024-05-25 01:26:29 [INFO]: Epoch 055 - training loss: 0.7977, validation loss: 0.9123
2024-05-25 01:26:29 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch55_loss0.9122851192951202.pypots
2024-05-25 01:26:30 [INFO]: Epoch 056 - training loss: 0.7882, validation loss: 0.9118
2024-05-25 01:26:30 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch56_loss0.9118130952119827.pypots
2024-05-25 01:26:30 [INFO]: Epoch 057 - training loss: 0.8037, validation loss: 0.9085
2024-05-25 01:26:30 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch57_loss0.9084565192461014.pypots
2024-05-25 01:26:30 [INFO]: Epoch 058 - training loss: 0.7814, validation loss: 0.9105
2024-05-25 01:26:30 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch58_loss0.9104791134595871.pypots
2024-05-25 01:26:30 [INFO]: Epoch 059 - training loss: 0.8067, validation loss: 0.9077
2024-05-25 01:26:30 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch59_loss0.9077118635177612.pypots
2024-05-25 01:26:30 [INFO]: Epoch 060 - training loss: 0.8134, validation loss: 0.9085
2024-05-25 01:26:30 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch60_loss0.9084866046905518.pypots
2024-05-25 01:26:31 [INFO]: Epoch 061 - training loss: 0.8109, validation loss: 0.9053
2024-05-25 01:26:31 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch61_loss0.9053415656089783.pypots
2024-05-25 01:26:31 [INFO]: Epoch 062 - training loss: 0.7878, validation loss: 0.9028
2024-05-25 01:26:31 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch62_loss0.902840182185173.pypots
2024-05-25 01:26:31 [INFO]: Epoch 063 - training loss: 0.8136, validation loss: 0.9028
2024-05-25 01:26:31 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch63_loss0.9028340727090836.pypots
2024-05-25 01:26:31 [INFO]: Epoch 064 - training loss: 0.7971, validation loss: 0.9007
2024-05-25 01:26:31 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch64_loss0.9007360339164734.pypots
2024-05-25 01:26:31 [INFO]: Epoch 065 - training loss: 0.8257, validation loss: 0.9026
2024-05-25 01:26:31 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch65_loss0.9026442021131516.pypots
2024-05-25 01:26:32 [INFO]: Epoch 066 - training loss: 0.8048, validation loss: 0.8999
2024-05-25 01:26:32 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch66_loss0.8999341428279877.pypots
2024-05-25 01:26:32 [INFO]: Epoch 067 - training loss: 0.8028, validation loss: 0.9003
2024-05-25 01:26:32 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch67_loss0.9002733081579208.pypots
2024-05-25 01:26:32 [INFO]: Epoch 068 - training loss: 0.7938, validation loss: 0.8996
2024-05-25 01:26:32 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch68_loss0.8995804041624069.pypots
2024-05-25 01:26:32 [INFO]: Epoch 069 - training loss: 0.8009, validation loss: 0.8977
2024-05-25 01:26:32 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch69_loss0.8976625353097916.pypots
2024-05-25 01:26:32 [INFO]: Epoch 070 - training loss: 0.8432, validation loss: 0.8967
2024-05-25 01:26:32 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch70_loss0.8967145532369614.pypots
2024-05-25 01:26:32 [INFO]: Epoch 071 - training loss: 0.8068, validation loss: 0.8952
2024-05-25 01:26:32 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch71_loss0.8952438980340958.pypots
2024-05-25 01:26:33 [INFO]: Epoch 072 - training loss: 0.7808, validation loss: 0.8973
2024-05-25 01:26:33 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch72_loss0.897275298833847.pypots
2024-05-25 01:26:33 [INFO]: Epoch 073 - training loss: 0.8013, validation loss: 0.8959
2024-05-25 01:26:33 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch73_loss0.8958986550569534.pypots
2024-05-25 01:26:33 [INFO]: Epoch 074 - training loss: 0.7795, validation loss: 0.8976
2024-05-25 01:26:33 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch74_loss0.8975671380758286.pypots
2024-05-25 01:26:33 [INFO]: Epoch 075 - training loss: 0.7822, validation loss: 0.8951
2024-05-25 01:26:33 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch75_loss0.8950654119253159.pypots
2024-05-25 01:26:33 [INFO]: Epoch 076 - training loss: 0.7958, validation loss: 0.8959
2024-05-25 01:26:33 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch76_loss0.8958766460418701.pypots
2024-05-25 01:26:34 [INFO]: Epoch 077 - training loss: 0.7970, validation loss: 0.8958
2024-05-25 01:26:34 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch77_loss0.8958373665809631.pypots
2024-05-25 01:26:34 [INFO]: Epoch 078 - training loss: 0.8014, validation loss: 0.8940
2024-05-25 01:26:34 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch78_loss0.893981322646141.pypots
2024-05-25 01:26:34 [INFO]: Epoch 079 - training loss: 0.7987, validation loss: 0.8921
2024-05-25 01:26:34 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch79_loss0.8920840919017792.pypots
2024-05-25 01:26:34 [INFO]: Epoch 080 - training loss: 0.8562, validation loss: 0.8938
2024-05-25 01:26:34 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch80_loss0.8938345164060593.pypots
2024-05-25 01:26:34 [INFO]: Epoch 081 - training loss: 0.7909, validation loss: 0.8918
2024-05-25 01:26:34 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch81_loss0.8918122202157974.pypots
2024-05-25 01:26:35 [INFO]: Epoch 082 - training loss: 0.8195, validation loss: 0.8942
2024-05-25 01:26:35 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch82_loss0.8941557109355927.pypots
2024-05-25 01:26:35 [INFO]: Epoch 083 - training loss: 0.7812, validation loss: 0.8944
2024-05-25 01:26:35 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch83_loss0.8944137692451477.pypots
2024-05-25 01:26:35 [INFO]: Epoch 084 - training loss: 0.8164, validation loss: 0.8925
2024-05-25 01:26:35 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch84_loss0.8924860656261444.pypots
2024-05-25 01:26:35 [INFO]: Epoch 085 - training loss: 0.7771, validation loss: 0.8941
2024-05-25 01:26:35 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch85_loss0.8940851241350174.pypots
2024-05-25 01:26:35 [INFO]: Epoch 086 - training loss: 0.7919, validation loss: 0.8944
2024-05-25 01:26:35 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch86_loss0.894390657544136.pypots
2024-05-25 01:26:35 [INFO]: Epoch 087 - training loss: 0.7930, validation loss: 0.8914
2024-05-25 01:26:35 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch87_loss0.8913845419883728.pypots
2024-05-25 01:26:36 [INFO]: Epoch 088 - training loss: 0.7892, validation loss: 0.8912
2024-05-25 01:26:36 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch88_loss0.8912356644868851.pypots
2024-05-25 01:26:36 [INFO]: Epoch 089 - training loss: 0.7785, validation loss: 0.8890
2024-05-25 01:26:36 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch89_loss0.8889669477939606.pypots
2024-05-25 01:26:36 [INFO]: Epoch 090 - training loss: 0.7911, validation loss: 0.8902
2024-05-25 01:26:36 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch90_loss0.8902131021022797.pypots
2024-05-25 01:26:36 [INFO]: Epoch 091 - training loss: 0.7978, validation loss: 0.8896
2024-05-25 01:26:36 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch91_loss0.889647364616394.pypots
2024-05-25 01:26:36 [INFO]: Epoch 092 - training loss: 0.7718, validation loss: 0.8896
2024-05-25 01:26:36 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch92_loss0.8896128684282303.pypots
2024-05-25 01:26:37 [INFO]: Epoch 093 - training loss: 0.7758, validation loss: 0.8900
2024-05-25 01:26:37 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch93_loss0.8899749517440796.pypots
2024-05-25 01:26:37 [INFO]: Epoch 094 - training loss: 0.8094, validation loss: 0.8913
2024-05-25 01:26:37 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch94_loss0.891312837600708.pypots
2024-05-25 01:26:37 [INFO]: Epoch 095 - training loss: 0.7719, validation loss: 0.8903
2024-05-25 01:26:37 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch95_loss0.890269473195076.pypots
2024-05-25 01:26:37 [INFO]: Epoch 096 - training loss: 0.7792, validation loss: 0.8894
2024-05-25 01:26:37 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch96_loss0.8893592655658722.pypots
2024-05-25 01:26:37 [INFO]: Epoch 097 - training loss: 0.7906, validation loss: 0.8918
2024-05-25 01:26:37 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch97_loss0.8918285220861435.pypots
2024-05-25 01:26:38 [INFO]: Epoch 098 - training loss: 0.7895, validation loss: 0.8886
2024-05-25 01:26:38 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch98_loss0.888593852519989.pypots
2024-05-25 01:26:38 [INFO]: Epoch 099 - training loss: 0.7983, validation loss: 0.8899
2024-05-25 01:26:38 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch99_loss0.8899362087249756.pypots
2024-05-25 01:26:38 [INFO]: Epoch 100 - training loss: 0.8171, validation loss: 0.8884
2024-05-25 01:26:38 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch100_loss0.8883557468652725.pypots
2024-05-25 01:26:38 [INFO]: Epoch 101 - training loss: 0.8312, validation loss: 0.8900
2024-05-25 01:26:38 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch101_loss0.8899841606616974.pypots
2024-05-25 01:26:38 [INFO]: Epoch 102 - training loss: 0.7941, validation loss: 0.8900
2024-05-25 01:26:38 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch102_loss0.8899592161178589.pypots
2024-05-25 01:26:38 [INFO]: Epoch 103 - training loss: 0.8209, validation loss: 0.8916
2024-05-25 01:26:38 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch103_loss0.8916075676679611.pypots
2024-05-25 01:26:39 [INFO]: Epoch 104 - training loss: 0.7960, validation loss: 0.8895
2024-05-25 01:26:39 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch104_loss0.8895238786935806.pypots
2024-05-25 01:26:39 [INFO]: Epoch 105 - training loss: 0.7808, validation loss: 0.8899
2024-05-25 01:26:39 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch105_loss0.8899141103029251.pypots
2024-05-25 01:26:39 [INFO]: Epoch 106 - training loss: 0.7690, validation loss: 0.8905
2024-05-25 01:26:39 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch106_loss0.8905428647994995.pypots
2024-05-25 01:26:39 [INFO]: Epoch 107 - training loss: 0.7986, validation loss: 0.8887
2024-05-25 01:26:39 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch107_loss0.8887025713920593.pypots
2024-05-25 01:26:39 [INFO]: Epoch 108 - training loss: 0.7838, validation loss: 0.8884
2024-05-25 01:26:39 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch108_loss0.8883593827486038.pypots
2024-05-25 01:26:40 [INFO]: Epoch 109 - training loss: 0.7831, validation loss: 0.8889
2024-05-25 01:26:40 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch109_loss0.8889295607805252.pypots
2024-05-25 01:26:40 [INFO]: Epoch 110 - training loss: 0.8204, validation loss: 0.8847
2024-05-25 01:26:40 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch110_loss0.8847142159938812.pypots
2024-05-25 01:26:40 [INFO]: Epoch 111 - training loss: 0.7838, validation loss: 0.8890
2024-05-25 01:26:40 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch111_loss0.8890187442302704.pypots
2024-05-25 01:26:40 [INFO]: Epoch 112 - training loss: 0.7832, validation loss: 0.8887
2024-05-25 01:26:40 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch112_loss0.8886571228504181.pypots
2024-05-25 01:26:40 [INFO]: Epoch 113 - training loss: 0.7829, validation loss: 0.8876
2024-05-25 01:26:40 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch113_loss0.887565940618515.pypots
2024-05-25 01:26:41 [INFO]: Epoch 114 - training loss: 0.7733, validation loss: 0.8878
2024-05-25 01:26:41 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch114_loss0.8877629637718201.pypots
2024-05-25 01:26:41 [INFO]: Epoch 115 - training loss: 0.8059, validation loss: 0.8854
2024-05-25 01:26:41 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch115_loss0.8853836953639984.pypots
2024-05-25 01:26:41 [INFO]: Epoch 116 - training loss: 0.7948, validation loss: 0.8858
2024-05-25 01:26:41 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch116_loss0.8857754766941071.pypots
2024-05-25 01:26:41 [INFO]: Epoch 117 - training loss: 0.7872, validation loss: 0.8873
2024-05-25 01:26:41 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch117_loss0.8872619420289993.pypots
2024-05-25 01:26:41 [INFO]: Epoch 118 - training loss: 0.7886, validation loss: 0.8845
2024-05-25 01:26:41 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch118_loss0.8845293819904327.pypots
2024-05-25 01:26:41 [INFO]: Epoch 119 - training loss: 0.7980, validation loss: 0.8841
2024-05-25 01:26:41 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch119_loss0.8841429501771927.pypots
2024-05-25 01:26:42 [INFO]: Epoch 120 - training loss: 0.7793, validation loss: 0.8849
2024-05-25 01:26:42 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch120_loss0.88493911921978.pypots
2024-05-25 01:26:42 [INFO]: Epoch 121 - training loss: 0.8041, validation loss: 0.8863
2024-05-25 01:26:42 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch121_loss0.8863006830215454.pypots
2024-05-25 01:26:42 [INFO]: Epoch 122 - training loss: 0.7917, validation loss: 0.8839
2024-05-25 01:26:42 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch122_loss0.8839281052350998.pypots
2024-05-25 01:26:42 [INFO]: Epoch 123 - training loss: 0.7727, validation loss: 0.8869
2024-05-25 01:26:42 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch123_loss0.8868795782327652.pypots
2024-05-25 01:26:42 [INFO]: Epoch 124 - training loss: 0.7714, validation loss: 0.8845
2024-05-25 01:26:42 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch124_loss0.8845027685165405.pypots
2024-05-25 01:26:43 [INFO]: Epoch 125 - training loss: 0.7930, validation loss: 0.8849
2024-05-25 01:26:43 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch125_loss0.8849125504493713.pypots
2024-05-25 01:26:43 [INFO]: Epoch 126 - training loss: 0.8394, validation loss: 0.8838
2024-05-25 01:26:43 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch126_loss0.88376285135746.pypots
2024-05-25 01:26:43 [INFO]: Epoch 127 - training loss: 0.7816, validation loss: 0.8908
2024-05-25 01:26:43 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch127_loss0.8907879590988159.pypots
2024-05-25 01:26:43 [INFO]: Epoch 128 - training loss: 0.7804, validation loss: 0.8941
2024-05-25 01:26:43 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch128_loss0.8941468745470047.pypots
2024-05-25 01:26:43 [INFO]: Epoch 129 - training loss: 0.8161, validation loss: 0.8833
2024-05-25 01:26:43 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch129_loss0.8832894414663315.pypots
2024-05-25 01:26:44 [INFO]: Epoch 130 - training loss: 0.7889, validation loss: 0.8832
2024-05-25 01:26:44 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch130_loss0.8832034319639206.pypots
2024-05-25 01:26:44 [INFO]: Epoch 131 - training loss: 0.7934, validation loss: 0.8834
2024-05-25 01:26:44 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch131_loss0.8833727240562439.pypots
2024-05-25 01:26:44 [INFO]: Epoch 132 - training loss: 0.7806, validation loss: 0.8859
2024-05-25 01:26:44 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch132_loss0.8859484642744064.pypots
2024-05-25 01:26:44 [INFO]: Epoch 133 - training loss: 0.8122, validation loss: 0.8842
2024-05-25 01:26:44 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch133_loss0.8842466324567795.pypots
2024-05-25 01:26:44 [INFO]: Epoch 134 - training loss: 0.7923, validation loss: 0.8846
2024-05-25 01:26:44 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch134_loss0.8846455812454224.pypots
2024-05-25 01:26:44 [INFO]: Epoch 135 - training loss: 0.7858, validation loss: 0.8858
2024-05-25 01:26:44 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch135_loss0.8857744336128235.pypots
2024-05-25 01:26:45 [INFO]: Epoch 136 - training loss: 0.7826, validation loss: 0.8823
2024-05-25 01:26:45 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch136_loss0.8822517842054367.pypots
2024-05-25 01:26:45 [INFO]: Epoch 137 - training loss: 0.7893, validation loss: 0.8843
2024-05-25 01:26:45 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch137_loss0.8842810690402985.pypots
2024-05-25 01:26:45 [INFO]: Epoch 138 - training loss: 0.7757, validation loss: 0.8835
2024-05-25 01:26:45 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch138_loss0.8835178762674332.pypots
2024-05-25 01:26:45 [INFO]: Epoch 139 - training loss: 0.8105, validation loss: 0.8814
2024-05-25 01:26:45 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch139_loss0.8813959211111069.pypots
2024-05-25 01:26:45 [INFO]: Epoch 140 - training loss: 0.7917, validation loss: 0.8806
2024-05-25 01:26:45 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch140_loss0.8805500864982605.pypots
2024-05-25 01:26:46 [INFO]: Epoch 141 - training loss: 0.7731, validation loss: 0.8818
2024-05-25 01:26:46 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch141_loss0.8817780911922455.pypots
2024-05-25 01:26:46 [INFO]: Epoch 142 - training loss: 0.7752, validation loss: 0.8817
2024-05-25 01:26:46 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch142_loss0.881671667098999.pypots
2024-05-25 01:26:46 [INFO]: Epoch 143 - training loss: 0.7760, validation loss: 0.8814
2024-05-25 01:26:46 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch143_loss0.8813520967960358.pypots
2024-05-25 01:26:46 [INFO]: Epoch 144 - training loss: 0.7782, validation loss: 0.8837
2024-05-25 01:26:46 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch144_loss0.8836960941553116.pypots
2024-05-25 01:26:46 [INFO]: Epoch 145 - training loss: 0.7785, validation loss: 0.8826
2024-05-25 01:26:46 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch145_loss0.8826198577880859.pypots
2024-05-25 01:26:47 [INFO]: Epoch 146 - training loss: 0.7723, validation loss: 0.8805
2024-05-25 01:26:47 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch146_loss0.8805167078971863.pypots
2024-05-25 01:26:47 [INFO]: Epoch 147 - training loss: 0.7920, validation loss: 0.8792
2024-05-25 01:26:47 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch147_loss0.8792451769113541.pypots
2024-05-25 01:26:47 [INFO]: Epoch 148 - training loss: 0.7816, validation loss: 0.8786
2024-05-25 01:26:47 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch148_loss0.8785877972841263.pypots
2024-05-25 01:26:47 [INFO]: Epoch 149 - training loss: 0.8034, validation loss: 0.8819
2024-05-25 01:26:47 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch149_loss0.8818664401769638.pypots
2024-05-25 01:26:47 [INFO]: Epoch 150 - training loss: 0.7822, validation loss: 0.8811
2024-05-25 01:26:47 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch150_loss0.8810620903968811.pypots
2024-05-25 01:26:47 [INFO]: Epoch 151 - training loss: 0.7663, validation loss: 0.8799
2024-05-25 01:26:47 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch151_loss0.8798819780349731.pypots
2024-05-25 01:26:48 [INFO]: Epoch 152 - training loss: 0.7836, validation loss: 0.8784
2024-05-25 01:26:48 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch152_loss0.8784344047307968.pypots
2024-05-25 01:26:48 [INFO]: Epoch 153 - training loss: 0.7829, validation loss: 0.8823
2024-05-25 01:26:48 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch153_loss0.8823401033878326.pypots
2024-05-25 01:26:48 [INFO]: Epoch 154 - training loss: 0.7816, validation loss: 0.8822
2024-05-25 01:26:48 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch154_loss0.8821844160556793.pypots
2024-05-25 01:26:48 [INFO]: Epoch 155 - training loss: 0.7753, validation loss: 0.8782
2024-05-25 01:26:48 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch155_loss0.8781638890504837.pypots
2024-05-25 01:26:48 [INFO]: Epoch 156 - training loss: 0.7803, validation loss: 0.8785
2024-05-25 01:26:48 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch156_loss0.8785121738910675.pypots
2024-05-25 01:26:49 [INFO]: Epoch 157 - training loss: 0.7813, validation loss: 0.8796
2024-05-25 01:26:49 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch157_loss0.8795957267284393.pypots
2024-05-25 01:26:49 [INFO]: Epoch 158 - training loss: 0.7696, validation loss: 0.8794
2024-05-25 01:26:49 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch158_loss0.8793729394674301.pypots
2024-05-25 01:26:49 [INFO]: Epoch 159 - training loss: 0.7932, validation loss: 0.8774
2024-05-25 01:26:49 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch159_loss0.8774251192808151.pypots
2024-05-25 01:26:49 [INFO]: Epoch 160 - training loss: 0.7645, validation loss: 0.8791
2024-05-25 01:26:49 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch160_loss0.8790726363658905.pypots
2024-05-25 01:26:49 [INFO]: Epoch 161 - training loss: 0.7935, validation loss: 0.8735
2024-05-25 01:26:49 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch161_loss0.873536691069603.pypots
2024-05-25 01:26:50 [INFO]: Epoch 162 - training loss: 0.7920, validation loss: 0.8793
2024-05-25 01:26:50 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch162_loss0.8792651891708374.pypots
2024-05-25 01:26:50 [INFO]: Epoch 163 - training loss: 0.7925, validation loss: 0.8761
2024-05-25 01:26:50 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch163_loss0.876098096370697.pypots
2024-05-25 01:26:50 [INFO]: Epoch 164 - training loss: 0.7862, validation loss: 0.8752
2024-05-25 01:26:50 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch164_loss0.8752037286758423.pypots
2024-05-25 01:26:50 [INFO]: Epoch 165 - training loss: 0.7769, validation loss: 0.8754
2024-05-25 01:26:50 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch165_loss0.8753555119037628.pypots
2024-05-25 01:26:50 [INFO]: Epoch 166 - training loss: 0.7642, validation loss: 0.8744
2024-05-25 01:26:50 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch166_loss0.8743973225355148.pypots
2024-05-25 01:26:50 [INFO]: Epoch 167 - training loss: 0.7788, validation loss: 0.8737
2024-05-25 01:26:50 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch167_loss0.8736541718244553.pypots
2024-05-25 01:26:51 [INFO]: Epoch 168 - training loss: 0.7862, validation loss: 0.8774
2024-05-25 01:26:51 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch168_loss0.8773674368858337.pypots
2024-05-25 01:26:51 [INFO]: Epoch 169 - training loss: 0.7834, validation loss: 0.8741
2024-05-25 01:26:51 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch169_loss0.8741331845521927.pypots
2024-05-25 01:26:51 [INFO]: Epoch 170 - training loss: 0.7910, validation loss: 0.8771
2024-05-25 01:26:51 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch170_loss0.8771348744630814.pypots
2024-05-25 01:26:51 [INFO]: Epoch 171 - training loss: 0.8212, validation loss: 0.8752
2024-05-25 01:26:51 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN_epoch171_loss0.8751728683710098.pypots
2024-05-25 01:26:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:26:51 [INFO]: Finished training. The best model is from epoch#161.
2024-05-25 01:26:51 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T012617/MRNN.pypots
2024-05-25 01:26:52 [INFO]: MRNN on ETTm1: MAE=0.6940, MSE=1.1631
2024-05-25 01:26:52 [INFO]: Successfully saved to augmentation_saved_results/round_0/MRNN_ettm1/imputation.pkl
2024-05-25 01:26:52 [INFO]: Using the given device: cpu
2024-05-25 01:26:52 [INFO]: LOCF on ETTm1: MAE=0.1348, MSE=0.0715
2024-05-25 01:26:52 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_ettm1".
2024-05-25 01:26:52 [INFO]: Successfully saved to augmentation_saved_results/round_0/LOCF_ettm1/imputation.pkl
2024-05-25 01:26:52 [INFO]: Median on ETTm1: MAE=0.6516, MSE=0.8223
2024-05-25 01:26:52 [INFO]: Successfully created the given path "saved_results/round_0/Median_ettm1".
2024-05-25 01:26:52 [INFO]: Successfully saved to augmentation_saved_results/round_0/Median_ettm1/imputation.pkl
2024-05-25 01:26:52 [INFO]: Mean on ETTm1: MAE=0.6566, MSE=0.8036
2024-05-25 01:26:52 [INFO]: Successfully created the given path "saved_results/round_0/Mean_ettm1".
2024-05-25 01:26:52 [INFO]: Successfully saved to augmentation_saved_results/round_0/Mean_ettm1/imputation.pkl
2024-05-25 01:26:52 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-25 01:26:52 [INFO]: Using the given device: cuda:0
2024-05-25 01:26:52 [INFO]: Model files will be saved to augmentation_saved_results/round_1/SAITS_ettm1/20240525_T012652
2024-05-25 01:26:52 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/SAITS_ettm1/20240525_T012652/tensorboard
2024-05-25 01:26:52 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 01:26:52 [INFO]: Epoch 001 - training loss: 1.1293, validation loss: 0.2635
2024-05-25 01:26:53 [INFO]: Epoch 002 - training loss: 0.8370, validation loss: 0.1215
2024-05-25 01:26:53 [INFO]: Epoch 003 - training loss: 0.7505, validation loss: 0.1021
2024-05-25 01:26:54 [INFO]: Epoch 004 - training loss: 0.6967, validation loss: 0.0683
2024-05-25 01:26:54 [INFO]: Epoch 005 - training loss: 0.6661, validation loss: 0.0701
2024-05-25 01:26:55 [INFO]: Epoch 006 - training loss: 0.6581, validation loss: 0.0752
2024-05-25 01:26:55 [INFO]: Epoch 007 - training loss: 0.6387, validation loss: 0.0638
2024-05-25 01:26:56 [INFO]: Epoch 008 - training loss: 0.6078, validation loss: 0.0657
2024-05-25 01:26:56 [INFO]: Epoch 009 - training loss: 0.5872, validation loss: 0.0565
2024-05-25 01:26:57 [INFO]: Epoch 010 - training loss: 0.5689, validation loss: 0.0596
2024-05-25 01:26:57 [INFO]: Epoch 011 - training loss: 0.5615, validation loss: 0.0457
2024-05-25 01:26:58 [INFO]: Epoch 012 - training loss: 0.5625, validation loss: 0.0500
2024-05-25 01:26:58 [INFO]: Epoch 013 - training loss: 0.5413, validation loss: 0.0526
2024-05-25 01:26:59 [INFO]: Epoch 014 - training loss: 0.5334, validation loss: 0.0455
2024-05-25 01:26:59 [INFO]: Epoch 015 - training loss: 0.5296, validation loss: 0.0500
2024-05-25 01:27:00 [INFO]: Epoch 016 - training loss: 0.5250, validation loss: 0.0494
2024-05-25 01:27:00 [INFO]: Epoch 017 - training loss: 0.5094, validation loss: 0.0553
2024-05-25 01:27:01 [INFO]: Epoch 018 - training loss: 0.5078, validation loss: 0.0562
2024-05-25 01:27:01 [INFO]: Epoch 019 - training loss: 0.5029, validation loss: 0.0414
2024-05-25 01:27:02 [INFO]: Epoch 020 - training loss: 0.4941, validation loss: 0.0443
2024-05-25 01:27:02 [INFO]: Epoch 021 - training loss: 0.4873, validation loss: 0.0395
2024-05-25 01:27:03 [INFO]: Epoch 022 - training loss: 0.4802, validation loss: 0.0416
2024-05-25 01:27:04 [INFO]: Epoch 023 - training loss: 0.4914, validation loss: 0.0407
2024-05-25 01:27:04 [INFO]: Epoch 024 - training loss: 0.4695, validation loss: 0.0500
2024-05-25 01:27:05 [INFO]: Epoch 025 - training loss: 0.4621, validation loss: 0.0495
2024-05-25 01:27:05 [INFO]: Epoch 026 - training loss: 0.4750, validation loss: 0.0419
2024-05-25 01:27:06 [INFO]: Epoch 027 - training loss: 0.4587, validation loss: 0.0389
2024-05-25 01:27:06 [INFO]: Epoch 028 - training loss: 0.4577, validation loss: 0.0409
2024-05-25 01:27:07 [INFO]: Epoch 029 - training loss: 0.4411, validation loss: 0.0355
2024-05-25 01:27:07 [INFO]: Epoch 030 - training loss: 0.4558, validation loss: 0.0346
2024-05-25 01:27:08 [INFO]: Epoch 031 - training loss: 0.4346, validation loss: 0.0457
2024-05-25 01:27:08 [INFO]: Epoch 032 - training loss: 0.4291, validation loss: 0.0351
2024-05-25 01:27:09 [INFO]: Epoch 033 - training loss: 0.4278, validation loss: 0.0457
2024-05-25 01:27:09 [INFO]: Epoch 034 - training loss: 0.4202, validation loss: 0.0401
2024-05-25 01:27:10 [INFO]: Epoch 035 - training loss: 0.4097, validation loss: 0.0520
2024-05-25 01:27:10 [INFO]: Epoch 036 - training loss: 0.4077, validation loss: 0.0409
2024-05-25 01:27:11 [INFO]: Epoch 037 - training loss: 0.3901, validation loss: 0.0342
2024-05-25 01:27:11 [INFO]: Epoch 038 - training loss: 0.3787, validation loss: 0.0342
2024-05-25 01:27:12 [INFO]: Epoch 039 - training loss: 0.3836, validation loss: 0.0386
2024-05-25 01:27:12 [INFO]: Epoch 040 - training loss: 0.3730, validation loss: 0.0374
2024-05-25 01:27:13 [INFO]: Epoch 041 - training loss: 0.3797, validation loss: 0.0322
2024-05-25 01:27:13 [INFO]: Epoch 042 - training loss: 0.3792, validation loss: 0.0413
2024-05-25 01:27:14 [INFO]: Epoch 043 - training loss: 0.3688, validation loss: 0.0320
2024-05-25 01:27:14 [INFO]: Epoch 044 - training loss: 0.3608, validation loss: 0.0329
2024-05-25 01:27:15 [INFO]: Epoch 045 - training loss: 0.3525, validation loss: 0.0383
2024-05-25 01:27:15 [INFO]: Epoch 046 - training loss: 0.3472, validation loss: 0.0345
2024-05-25 01:27:16 [INFO]: Epoch 047 - training loss: 0.3412, validation loss: 0.0362
2024-05-25 01:27:16 [INFO]: Epoch 048 - training loss: 0.3591, validation loss: 0.0350
2024-05-25 01:27:17 [INFO]: Epoch 049 - training loss: 0.3474, validation loss: 0.0317
2024-05-25 01:27:17 [INFO]: Epoch 050 - training loss: 0.3414, validation loss: 0.0435
2024-05-25 01:27:18 [INFO]: Epoch 051 - training loss: 0.3430, validation loss: 0.0336
2024-05-25 01:27:18 [INFO]: Epoch 052 - training loss: 0.3306, validation loss: 0.0279
2024-05-25 01:27:19 [INFO]: Epoch 053 - training loss: 0.3321, validation loss: 0.0327
2024-05-25 01:27:19 [INFO]: Epoch 054 - training loss: 0.3185, validation loss: 0.0322
2024-05-25 01:27:20 [INFO]: Epoch 055 - training loss: 0.3210, validation loss: 0.0281
2024-05-25 01:27:20 [INFO]: Epoch 056 - training loss: 0.3105, validation loss: 0.0326
2024-05-25 01:27:21 [INFO]: Epoch 057 - training loss: 0.3070, validation loss: 0.0232
2024-05-25 01:27:21 [INFO]: Epoch 058 - training loss: 0.3029, validation loss: 0.0264
2024-05-25 01:27:22 [INFO]: Epoch 059 - training loss: 0.2923, validation loss: 0.0295
2024-05-25 01:27:22 [INFO]: Epoch 060 - training loss: 0.2897, validation loss: 0.0419
2024-05-25 01:27:23 [INFO]: Epoch 061 - training loss: 0.2923, validation loss: 0.0284
2024-05-25 01:27:23 [INFO]: Epoch 062 - training loss: 0.2952, validation loss: 0.0282
2024-05-25 01:27:24 [INFO]: Epoch 063 - training loss: 0.2924, validation loss: 0.0355
2024-05-25 01:27:24 [INFO]: Epoch 064 - training loss: 0.2967, validation loss: 0.0349
2024-05-25 01:27:25 [INFO]: Epoch 065 - training loss: 0.2799, validation loss: 0.0316
2024-05-25 01:27:25 [INFO]: Epoch 066 - training loss: 0.2731, validation loss: 0.0298
2024-05-25 01:27:26 [INFO]: Epoch 067 - training loss: 0.2728, validation loss: 0.0306
2024-05-25 01:27:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:27:26 [INFO]: Finished training. The best model is from epoch#57.
2024-05-25 01:27:26 [INFO]: Saved the model to augmentation_saved_results/round_1/SAITS_ettm1/20240525_T012652/SAITS.pypots
2024-05-25 01:27:26 [INFO]: SAITS on ETTm1: MAE=0.1463, MSE=0.0343
2024-05-25 01:27:26 [INFO]: Successfully saved to augmentation_saved_results/round_1/SAITS_ettm1/imputation.pkl
2024-05-25 01:27:26 [INFO]: Using the given device: cuda:0
2024-05-25 01:27:26 [INFO]: Model files will be saved to augmentation_saved_results/round_1/Transformer_ettm1/20240525_T012726
2024-05-25 01:27:26 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/Transformer_ettm1/20240525_T012726/tensorboard
2024-05-25 01:27:26 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 01:27:26 [INFO]: Epoch 001 - training loss: 1.2163, validation loss: 0.3026
2024-05-25 01:27:27 [INFO]: Epoch 002 - training loss: 0.7464, validation loss: 0.1350
2024-05-25 01:27:27 [INFO]: Epoch 003 - training loss: 0.5992, validation loss: 0.1004
2024-05-25 01:27:27 [INFO]: Epoch 004 - training loss: 0.5268, validation loss: 0.0787
2024-05-25 01:27:27 [INFO]: Epoch 005 - training loss: 0.4959, validation loss: 0.0679
2024-05-25 01:27:27 [INFO]: Epoch 006 - training loss: 0.4672, validation loss: 0.0629
2024-05-25 01:27:28 [INFO]: Epoch 007 - training loss: 0.4406, validation loss: 0.0560
2024-05-25 01:27:28 [INFO]: Epoch 008 - training loss: 0.4412, validation loss: 0.0517
2024-05-25 01:27:28 [INFO]: Epoch 009 - training loss: 0.4259, validation loss: 0.0500
2024-05-25 01:27:28 [INFO]: Epoch 010 - training loss: 0.3978, validation loss: 0.0461
2024-05-25 01:27:29 [INFO]: Epoch 011 - training loss: 0.3821, validation loss: 0.0463
2024-05-25 01:27:29 [INFO]: Epoch 012 - training loss: 0.3744, validation loss: 0.0479
2024-05-25 01:27:29 [INFO]: Epoch 013 - training loss: 0.3649, validation loss: 0.0432
2024-05-25 01:27:29 [INFO]: Epoch 014 - training loss: 0.3586, validation loss: 0.0395
2024-05-25 01:27:29 [INFO]: Epoch 015 - training loss: 0.3447, validation loss: 0.0405
2024-05-25 01:27:30 [INFO]: Epoch 016 - training loss: 0.3379, validation loss: 0.0388
2024-05-25 01:27:30 [INFO]: Epoch 017 - training loss: 0.3399, validation loss: 0.0397
2024-05-25 01:27:30 [INFO]: Epoch 018 - training loss: 0.3314, validation loss: 0.0405
2024-05-25 01:27:30 [INFO]: Epoch 019 - training loss: 0.3259, validation loss: 0.0358
2024-05-25 01:27:31 [INFO]: Epoch 020 - training loss: 0.3273, validation loss: 0.0405
2024-05-25 01:27:31 [INFO]: Epoch 021 - training loss: 0.3217, validation loss: 0.0351
2024-05-25 01:27:31 [INFO]: Epoch 022 - training loss: 0.3195, validation loss: 0.0361
2024-05-25 01:27:31 [INFO]: Epoch 023 - training loss: 0.3105, validation loss: 0.0341
2024-05-25 01:27:31 [INFO]: Epoch 024 - training loss: 0.3119, validation loss: 0.0338
2024-05-25 01:27:32 [INFO]: Epoch 025 - training loss: 0.3039, validation loss: 0.0342
2024-05-25 01:27:32 [INFO]: Epoch 026 - training loss: 0.2966, validation loss: 0.0315
2024-05-25 01:27:32 [INFO]: Epoch 027 - training loss: 0.2934, validation loss: 0.0285
2024-05-25 01:27:32 [INFO]: Epoch 028 - training loss: 0.2891, validation loss: 0.0322
2024-05-25 01:27:32 [INFO]: Epoch 029 - training loss: 0.2909, validation loss: 0.0313
2024-05-25 01:27:33 [INFO]: Epoch 030 - training loss: 0.2842, validation loss: 0.0346
2024-05-25 01:27:33 [INFO]: Epoch 031 - training loss: 0.2793, validation loss: 0.0277
2024-05-25 01:27:33 [INFO]: Epoch 032 - training loss: 0.2726, validation loss: 0.0267
2024-05-25 01:27:33 [INFO]: Epoch 033 - training loss: 0.2725, validation loss: 0.0253
2024-05-25 01:27:34 [INFO]: Epoch 034 - training loss: 0.2646, validation loss: 0.0271
2024-05-25 01:27:34 [INFO]: Epoch 035 - training loss: 0.2656, validation loss: 0.0276
2024-05-25 01:27:34 [INFO]: Epoch 036 - training loss: 0.2680, validation loss: 0.0264
2024-05-25 01:27:34 [INFO]: Epoch 037 - training loss: 0.2666, validation loss: 0.0263
2024-05-25 01:27:34 [INFO]: Epoch 038 - training loss: 0.2628, validation loss: 0.0300
2024-05-25 01:27:35 [INFO]: Epoch 039 - training loss: 0.2637, validation loss: 0.0280
2024-05-25 01:27:35 [INFO]: Epoch 040 - training loss: 0.2532, validation loss: 0.0276
2024-05-25 01:27:35 [INFO]: Epoch 041 - training loss: 0.2513, validation loss: 0.0249
2024-05-25 01:27:35 [INFO]: Epoch 042 - training loss: 0.2493, validation loss: 0.0256
2024-05-25 01:27:36 [INFO]: Epoch 043 - training loss: 0.2565, validation loss: 0.0270
2024-05-25 01:27:36 [INFO]: Epoch 044 - training loss: 0.2505, validation loss: 0.0281
2024-05-25 01:27:36 [INFO]: Epoch 045 - training loss: 0.2462, validation loss: 0.0254
2024-05-25 01:27:36 [INFO]: Epoch 046 - training loss: 0.2427, validation loss: 0.0239
2024-05-25 01:27:36 [INFO]: Epoch 047 - training loss: 0.2433, validation loss: 0.0225
2024-05-25 01:27:37 [INFO]: Epoch 048 - training loss: 0.2377, validation loss: 0.0274
2024-05-25 01:27:37 [INFO]: Epoch 049 - training loss: 0.2378, validation loss: 0.0281
2024-05-25 01:27:37 [INFO]: Epoch 050 - training loss: 0.2417, validation loss: 0.0239
2024-05-25 01:27:37 [INFO]: Epoch 051 - training loss: 0.2311, validation loss: 0.0271
2024-05-25 01:27:37 [INFO]: Epoch 052 - training loss: 0.2333, validation loss: 0.0272
2024-05-25 01:27:38 [INFO]: Epoch 053 - training loss: 0.2338, validation loss: 0.0293
2024-05-25 01:27:38 [INFO]: Epoch 054 - training loss: 0.2310, validation loss: 0.0245
2024-05-25 01:27:38 [INFO]: Epoch 055 - training loss: 0.2253, validation loss: 0.0226
2024-05-25 01:27:38 [INFO]: Epoch 056 - training loss: 0.2297, validation loss: 0.0213
2024-05-25 01:27:39 [INFO]: Epoch 057 - training loss: 0.2221, validation loss: 0.0232
2024-05-25 01:27:39 [INFO]: Epoch 058 - training loss: 0.2200, validation loss: 0.0213
2024-05-25 01:27:39 [INFO]: Epoch 059 - training loss: 0.2249, validation loss: 0.0242
2024-05-25 01:27:39 [INFO]: Epoch 060 - training loss: 0.2208, validation loss: 0.0241
2024-05-25 01:27:39 [INFO]: Epoch 061 - training loss: 0.2256, validation loss: 0.0234
2024-05-25 01:27:40 [INFO]: Epoch 062 - training loss: 0.2244, validation loss: 0.0252
2024-05-25 01:27:40 [INFO]: Epoch 063 - training loss: 0.2220, validation loss: 0.0213
2024-05-25 01:27:40 [INFO]: Epoch 064 - training loss: 0.2180, validation loss: 0.0233
2024-05-25 01:27:40 [INFO]: Epoch 065 - training loss: 0.2185, validation loss: 0.0221
2024-05-25 01:27:41 [INFO]: Epoch 066 - training loss: 0.2112, validation loss: 0.0218
2024-05-25 01:27:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:27:41 [INFO]: Finished training. The best model is from epoch#56.
2024-05-25 01:27:41 [INFO]: Saved the model to augmentation_saved_results/round_1/Transformer_ettm1/20240525_T012726/Transformer.pypots
2024-05-25 01:27:41 [INFO]: Transformer on ETTm1: MAE=0.1246, MSE=0.0297
2024-05-25 01:27:41 [INFO]: Successfully saved to augmentation_saved_results/round_1/Transformer_ettm1/imputation.pkl
2024-05-25 01:27:41 [INFO]: Using the given device: cuda:0
2024-05-25 01:27:41 [INFO]: Model files will be saved to augmentation_saved_results/round_1/TimesNet_ettm1/20240525_T012741
2024-05-25 01:27:41 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/TimesNet_ettm1/20240525_T012741/tensorboard
2024-05-25 01:27:41 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 01:27:41 [INFO]: Epoch 001 - training loss: 0.1560, validation loss: 0.0512
2024-05-25 01:27:41 [INFO]: Epoch 002 - training loss: 0.0637, validation loss: 0.0361
2024-05-25 01:27:41 [INFO]: Epoch 003 - training loss: 0.0500, validation loss: 0.0305
2024-05-25 01:27:42 [INFO]: Epoch 004 - training loss: 0.0483, validation loss: 0.0299
2024-05-25 01:27:42 [INFO]: Epoch 005 - training loss: 0.0449, validation loss: 0.0291
2024-05-25 01:27:42 [INFO]: Epoch 006 - training loss: 0.0417, validation loss: 0.0268
2024-05-25 01:27:42 [INFO]: Epoch 007 - training loss: 0.0439, validation loss: 0.0288
2024-05-25 01:27:42 [INFO]: Epoch 008 - training loss: 0.0439, validation loss: 0.0274
2024-05-25 01:27:43 [INFO]: Epoch 009 - training loss: 0.0426, validation loss: 0.0262
2024-05-25 01:27:43 [INFO]: Epoch 010 - training loss: 0.0417, validation loss: 0.0279
2024-05-25 01:27:43 [INFO]: Epoch 011 - training loss: 0.0422, validation loss: 0.0311
2024-05-25 01:27:43 [INFO]: Epoch 012 - training loss: 0.0452, validation loss: 0.0273
2024-05-25 01:27:44 [INFO]: Epoch 013 - training loss: 0.0444, validation loss: 0.0295
2024-05-25 01:27:44 [INFO]: Epoch 014 - training loss: 0.0462, validation loss: 0.0294
2024-05-25 01:27:44 [INFO]: Epoch 015 - training loss: 0.0426, validation loss: 0.0271
2024-05-25 01:27:44 [INFO]: Epoch 016 - training loss: 0.0420, validation loss: 0.0271
2024-05-25 01:27:44 [INFO]: Epoch 017 - training loss: 0.0408, validation loss: 0.0259
2024-05-25 01:27:45 [INFO]: Epoch 018 - training loss: 0.0393, validation loss: 0.0266
2024-05-25 01:27:45 [INFO]: Epoch 019 - training loss: 0.0398, validation loss: 0.0266
2024-05-25 01:27:45 [INFO]: Epoch 020 - training loss: 0.0422, validation loss: 0.0282
2024-05-25 01:27:45 [INFO]: Epoch 021 - training loss: 0.0454, validation loss: 0.0253
2024-05-25 01:27:45 [INFO]: Epoch 022 - training loss: 0.0434, validation loss: 0.0264
2024-05-25 01:27:46 [INFO]: Epoch 023 - training loss: 0.0406, validation loss: 0.0267
2024-05-25 01:27:46 [INFO]: Epoch 024 - training loss: 0.0422, validation loss: 0.0251
2024-05-25 01:27:46 [INFO]: Epoch 025 - training loss: 0.0387, validation loss: 0.0277
2024-05-25 01:27:46 [INFO]: Epoch 026 - training loss: 0.0385, validation loss: 0.0242
2024-05-25 01:27:46 [INFO]: Epoch 027 - training loss: 0.0427, validation loss: 0.0258
2024-05-25 01:27:47 [INFO]: Epoch 028 - training loss: 0.0412, validation loss: 0.0256
2024-05-25 01:27:47 [INFO]: Epoch 029 - training loss: 0.0377, validation loss: 0.0253
2024-05-25 01:27:47 [INFO]: Epoch 030 - training loss: 0.0389, validation loss: 0.0239
2024-05-25 01:27:47 [INFO]: Epoch 031 - training loss: 0.0396, validation loss: 0.0254
2024-05-25 01:27:48 [INFO]: Epoch 032 - training loss: 0.0444, validation loss: 0.0281
2024-05-25 01:27:48 [INFO]: Epoch 033 - training loss: 0.0541, validation loss: 0.0269
2024-05-25 01:27:48 [INFO]: Epoch 034 - training loss: 0.0391, validation loss: 0.0272
2024-05-25 01:27:48 [INFO]: Epoch 035 - training loss: 0.0392, validation loss: 0.0278
2024-05-25 01:27:48 [INFO]: Epoch 036 - training loss: 0.0399, validation loss: 0.0249
2024-05-25 01:27:49 [INFO]: Epoch 037 - training loss: 0.0361, validation loss: 0.0252
2024-05-25 01:27:49 [INFO]: Epoch 038 - training loss: 0.0347, validation loss: 0.0242
2024-05-25 01:27:49 [INFO]: Epoch 039 - training loss: 0.0356, validation loss: 0.0256
2024-05-25 01:27:49 [INFO]: Epoch 040 - training loss: 0.0360, validation loss: 0.0237
2024-05-25 01:27:49 [INFO]: Epoch 041 - training loss: 0.0344, validation loss: 0.0238
2024-05-25 01:27:50 [INFO]: Epoch 042 - training loss: 0.0364, validation loss: 0.0242
2024-05-25 01:27:50 [INFO]: Epoch 043 - training loss: 0.0373, validation loss: 0.0250
2024-05-25 01:27:50 [INFO]: Epoch 044 - training loss: 0.0378, validation loss: 0.0264
2024-05-25 01:27:50 [INFO]: Epoch 045 - training loss: 0.0342, validation loss: 0.0226
2024-05-25 01:27:51 [INFO]: Epoch 046 - training loss: 0.0332, validation loss: 0.0231
2024-05-25 01:27:51 [INFO]: Epoch 047 - training loss: 0.0338, validation loss: 0.0236
2024-05-25 01:27:51 [INFO]: Epoch 048 - training loss: 0.0371, validation loss: 0.0227
2024-05-25 01:27:51 [INFO]: Epoch 049 - training loss: 0.0377, validation loss: 0.0257
2024-05-25 01:27:51 [INFO]: Epoch 050 - training loss: 0.0365, validation loss: 0.0232
2024-05-25 01:27:52 [INFO]: Epoch 051 - training loss: 0.0329, validation loss: 0.0229
2024-05-25 01:27:52 [INFO]: Epoch 052 - training loss: 0.0329, validation loss: 0.0223
2024-05-25 01:27:52 [INFO]: Epoch 053 - training loss: 0.0324, validation loss: 0.0225
2024-05-25 01:27:52 [INFO]: Epoch 054 - training loss: 0.0344, validation loss: 0.0260
2024-05-25 01:27:52 [INFO]: Epoch 055 - training loss: 0.0373, validation loss: 0.0241
2024-05-25 01:27:53 [INFO]: Epoch 056 - training loss: 0.0332, validation loss: 0.0223
2024-05-25 01:27:53 [INFO]: Epoch 057 - training loss: 0.0325, validation loss: 0.0215
2024-05-25 01:27:53 [INFO]: Epoch 058 - training loss: 0.0335, validation loss: 0.0218
2024-05-25 01:27:53 [INFO]: Epoch 059 - training loss: 0.0335, validation loss: 0.0235
2024-05-25 01:27:53 [INFO]: Epoch 060 - training loss: 0.0336, validation loss: 0.0223
2024-05-25 01:27:54 [INFO]: Epoch 061 - training loss: 0.0335, validation loss: 0.0228
2024-05-25 01:27:54 [INFO]: Epoch 062 - training loss: 0.0313, validation loss: 0.0212
2024-05-25 01:27:54 [INFO]: Epoch 063 - training loss: 0.0302, validation loss: 0.0205
2024-05-25 01:27:54 [INFO]: Epoch 064 - training loss: 0.0307, validation loss: 0.0215
2024-05-25 01:27:55 [INFO]: Epoch 065 - training loss: 0.0324, validation loss: 0.0203
2024-05-25 01:27:55 [INFO]: Epoch 066 - training loss: 0.0317, validation loss: 0.0208
2024-05-25 01:27:55 [INFO]: Epoch 067 - training loss: 0.0358, validation loss: 0.0220
2024-05-25 01:27:55 [INFO]: Epoch 068 - training loss: 0.0357, validation loss: 0.0227
2024-05-25 01:27:55 [INFO]: Epoch 069 - training loss: 0.0323, validation loss: 0.0232
2024-05-25 01:27:56 [INFO]: Epoch 070 - training loss: 0.0326, validation loss: 0.0207
2024-05-25 01:27:56 [INFO]: Epoch 071 - training loss: 0.0312, validation loss: 0.0202
2024-05-25 01:27:56 [INFO]: Epoch 072 - training loss: 0.0315, validation loss: 0.0217
2024-05-25 01:27:56 [INFO]: Epoch 073 - training loss: 0.0294, validation loss: 0.0195
2024-05-25 01:27:56 [INFO]: Epoch 074 - training loss: 0.0292, validation loss: 0.0203
2024-05-25 01:27:57 [INFO]: Epoch 075 - training loss: 0.0292, validation loss: 0.0202
2024-05-25 01:27:57 [INFO]: Epoch 076 - training loss: 0.0289, validation loss: 0.0200
2024-05-25 01:27:57 [INFO]: Epoch 077 - training loss: 0.0286, validation loss: 0.0198
2024-05-25 01:27:57 [INFO]: Epoch 078 - training loss: 0.0293, validation loss: 0.0193
2024-05-25 01:27:57 [INFO]: Epoch 079 - training loss: 0.0300, validation loss: 0.0200
2024-05-25 01:27:58 [INFO]: Epoch 080 - training loss: 0.0310, validation loss: 0.0191
2024-05-25 01:27:58 [INFO]: Epoch 081 - training loss: 0.0292, validation loss: 0.0212
2024-05-25 01:27:58 [INFO]: Epoch 082 - training loss: 0.0295, validation loss: 0.0215
2024-05-25 01:27:58 [INFO]: Epoch 083 - training loss: 0.0296, validation loss: 0.0192
2024-05-25 01:27:59 [INFO]: Epoch 084 - training loss: 0.0278, validation loss: 0.0192
2024-05-25 01:27:59 [INFO]: Epoch 085 - training loss: 0.0290, validation loss: 0.0201
2024-05-25 01:27:59 [INFO]: Epoch 086 - training loss: 0.0288, validation loss: 0.0194
2024-05-25 01:27:59 [INFO]: Epoch 087 - training loss: 0.0295, validation loss: 0.0192
2024-05-25 01:27:59 [INFO]: Epoch 088 - training loss: 0.0297, validation loss: 0.0196
2024-05-25 01:28:00 [INFO]: Epoch 089 - training loss: 0.0333, validation loss: 0.0265
2024-05-25 01:28:00 [INFO]: Epoch 090 - training loss: 0.0335, validation loss: 0.0232
2024-05-25 01:28:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:28:00 [INFO]: Finished training. The best model is from epoch#80.
2024-05-25 01:28:00 [INFO]: Saved the model to augmentation_saved_results/round_1/TimesNet_ettm1/20240525_T012741/TimesNet.pypots
2024-05-25 01:28:00 [INFO]: TimesNet on ETTm1: MAE=0.1125, MSE=0.0282
2024-05-25 01:28:00 [INFO]: Successfully saved to augmentation_saved_results/round_1/TimesNet_ettm1/imputation.pkl
2024-05-25 01:28:00 [INFO]: Using the given device: cuda:0
2024-05-25 01:28:00 [INFO]: Model files will be saved to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800
2024-05-25 01:28:00 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/tensorboard
2024-05-25 01:28:00 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 01:28:02 [INFO]: Epoch 001 - training loss: 0.7047, validation loss: 0.4189
2024-05-25 01:28:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch1_loss0.4189053177833557.pypots
2024-05-25 01:28:04 [INFO]: Epoch 002 - training loss: 0.3710, validation loss: 0.3740
2024-05-25 01:28:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch2_loss0.37403567135334015.pypots
2024-05-25 01:28:06 [INFO]: Epoch 003 - training loss: 0.3851, validation loss: 0.3698
2024-05-25 01:28:06 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch3_loss0.36976945400238037.pypots
2024-05-25 01:28:08 [INFO]: Epoch 004 - training loss: 0.3158, validation loss: 0.3653
2024-05-25 01:28:08 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch4_loss0.3653181493282318.pypots
2024-05-25 01:28:10 [INFO]: Epoch 005 - training loss: 0.3730, validation loss: 0.3445
2024-05-25 01:28:10 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch5_loss0.3444911763072014.pypots
2024-05-25 01:28:12 [INFO]: Epoch 006 - training loss: 0.2947, validation loss: 0.3220
2024-05-25 01:28:12 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch6_loss0.321951687335968.pypots
2024-05-25 01:28:14 [INFO]: Epoch 007 - training loss: 0.2897, validation loss: 0.2820
2024-05-25 01:28:14 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch7_loss0.28204620629549026.pypots
2024-05-25 01:28:17 [INFO]: Epoch 008 - training loss: 0.2585, validation loss: 0.2860
2024-05-25 01:28:17 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch8_loss0.2859869822859764.pypots
2024-05-25 01:28:19 [INFO]: Epoch 009 - training loss: 0.2463, validation loss: 0.2684
2024-05-25 01:28:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch9_loss0.26844362914562225.pypots
2024-05-25 01:28:21 [INFO]: Epoch 010 - training loss: 0.2473, validation loss: 0.2658
2024-05-25 01:28:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch10_loss0.2657521516084671.pypots
2024-05-25 01:28:23 [INFO]: Epoch 011 - training loss: 0.2564, validation loss: 0.2498
2024-05-25 01:28:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch11_loss0.24980057775974274.pypots
2024-05-25 01:28:25 [INFO]: Epoch 012 - training loss: 0.2699, validation loss: 0.2400
2024-05-25 01:28:25 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch12_loss0.23998985439538956.pypots
2024-05-25 01:28:27 [INFO]: Epoch 013 - training loss: 0.2499, validation loss: 0.2409
2024-05-25 01:28:27 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch13_loss0.2409449927508831.pypots
2024-05-25 01:28:29 [INFO]: Epoch 014 - training loss: 0.2121, validation loss: 0.2332
2024-05-25 01:28:29 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch14_loss0.23318316042423248.pypots
2024-05-25 01:28:31 [INFO]: Epoch 015 - training loss: 0.2055, validation loss: 0.2181
2024-05-25 01:28:31 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch15_loss0.2180987484753132.pypots
2024-05-25 01:28:33 [INFO]: Epoch 016 - training loss: 0.2808, validation loss: 0.2043
2024-05-25 01:28:33 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch16_loss0.20432795956730843.pypots
2024-05-25 01:28:35 [INFO]: Epoch 017 - training loss: 0.1993, validation loss: 0.2025
2024-05-25 01:28:35 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch17_loss0.20245690643787384.pypots
2024-05-25 01:28:37 [INFO]: Epoch 018 - training loss: 0.2279, validation loss: 0.2066
2024-05-25 01:28:37 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch18_loss0.20662500709295273.pypots
2024-05-25 01:28:39 [INFO]: Epoch 019 - training loss: 0.2508, validation loss: 0.2228
2024-05-25 01:28:39 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch19_loss0.222773689776659.pypots
2024-05-25 01:28:42 [INFO]: Epoch 020 - training loss: 0.2528, validation loss: 0.2215
2024-05-25 01:28:42 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch20_loss0.2215205915272236.pypots
2024-05-25 01:28:44 [INFO]: Epoch 021 - training loss: 0.2037, validation loss: 0.1874
2024-05-25 01:28:44 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch21_loss0.1873706914484501.pypots
2024-05-25 01:28:46 [INFO]: Epoch 022 - training loss: 0.1887, validation loss: 0.1820
2024-05-25 01:28:46 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch22_loss0.18195578083395958.pypots
2024-05-25 01:28:48 [INFO]: Epoch 023 - training loss: 0.1886, validation loss: 0.1818
2024-05-25 01:28:48 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch23_loss0.18176815286278725.pypots
2024-05-25 01:28:50 [INFO]: Epoch 024 - training loss: 0.2304, validation loss: 0.1874
2024-05-25 01:28:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch24_loss0.18741457164287567.pypots
2024-05-25 01:28:52 [INFO]: Epoch 025 - training loss: 0.1931, validation loss: 0.1717
2024-05-25 01:28:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch25_loss0.17172106355428696.pypots
2024-05-25 01:28:54 [INFO]: Epoch 026 - training loss: 0.1803, validation loss: 0.1700
2024-05-25 01:28:54 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch26_loss0.1699659340083599.pypots
2024-05-25 01:28:56 [INFO]: Epoch 027 - training loss: 0.1662, validation loss: 0.1675
2024-05-25 01:28:56 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch27_loss0.16746526956558228.pypots
2024-05-25 01:28:58 [INFO]: Epoch 028 - training loss: 0.1894, validation loss: 0.1622
2024-05-25 01:28:58 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch28_loss0.16224151477217674.pypots
2024-05-25 01:29:00 [INFO]: Epoch 029 - training loss: 0.1789, validation loss: 0.1577
2024-05-25 01:29:00 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch29_loss0.15769603103399277.pypots
2024-05-25 01:29:02 [INFO]: Epoch 030 - training loss: 0.1603, validation loss: 0.1573
2024-05-25 01:29:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch30_loss0.15727338567376137.pypots
2024-05-25 01:29:04 [INFO]: Epoch 031 - training loss: 0.1873, validation loss: 0.1585
2024-05-25 01:29:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch31_loss0.15854718536138535.pypots
2024-05-25 01:29:07 [INFO]: Epoch 032 - training loss: 0.1878, validation loss: 0.1520
2024-05-25 01:29:07 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch32_loss0.15197306871414185.pypots
2024-05-25 01:29:09 [INFO]: Epoch 033 - training loss: 0.1779, validation loss: 0.1477
2024-05-25 01:29:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch33_loss0.14770646393299103.pypots
2024-05-25 01:29:11 [INFO]: Epoch 034 - training loss: 0.1543, validation loss: 0.1502
2024-05-25 01:29:11 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch34_loss0.15022101998329163.pypots
2024-05-25 01:29:13 [INFO]: Epoch 035 - training loss: 0.1746, validation loss: 0.1515
2024-05-25 01:29:13 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch35_loss0.1515330895781517.pypots
2024-05-25 01:29:15 [INFO]: Epoch 036 - training loss: 0.1668, validation loss: 0.1508
2024-05-25 01:29:15 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch36_loss0.15076573565602303.pypots
2024-05-25 01:29:17 [INFO]: Epoch 037 - training loss: 0.1810, validation loss: 0.1572
2024-05-25 01:29:17 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch37_loss0.15715960785746574.pypots
2024-05-25 01:29:19 [INFO]: Epoch 038 - training loss: 0.1685, validation loss: 0.1664
2024-05-25 01:29:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch38_loss0.16641143709421158.pypots
2024-05-25 01:29:21 [INFO]: Epoch 039 - training loss: 0.1793, validation loss: 0.1462
2024-05-25 01:29:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch39_loss0.14621714130043983.pypots
2024-05-25 01:29:23 [INFO]: Epoch 040 - training loss: 0.1596, validation loss: 0.1442
2024-05-25 01:29:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch40_loss0.1442386694252491.pypots
2024-05-25 01:29:25 [INFO]: Epoch 041 - training loss: 0.1552, validation loss: 0.1429
2024-05-25 01:29:25 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch41_loss0.1429162360727787.pypots
2024-05-25 01:29:27 [INFO]: Epoch 042 - training loss: 0.2239, validation loss: 0.1457
2024-05-25 01:29:27 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch42_loss0.14571716263890266.pypots
2024-05-25 01:29:29 [INFO]: Epoch 043 - training loss: 0.1691, validation loss: 0.1465
2024-05-25 01:29:29 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch43_loss0.1464991196990013.pypots
2024-05-25 01:29:32 [INFO]: Epoch 044 - training loss: 0.1533, validation loss: 0.1418
2024-05-25 01:29:32 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch44_loss0.14183546975255013.pypots
2024-05-25 01:29:34 [INFO]: Epoch 045 - training loss: 0.2334, validation loss: 0.1406
2024-05-25 01:29:34 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch45_loss0.14061562344431877.pypots
2024-05-25 01:29:36 [INFO]: Epoch 046 - training loss: 0.1678, validation loss: 0.1364
2024-05-25 01:29:36 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch46_loss0.13643036037683487.pypots
2024-05-25 01:29:38 [INFO]: Epoch 047 - training loss: 0.1719, validation loss: 0.1409
2024-05-25 01:29:38 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch47_loss0.14086558297276497.pypots
2024-05-25 01:29:40 [INFO]: Epoch 048 - training loss: 0.1765, validation loss: 0.1505
2024-05-25 01:29:40 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch48_loss0.15047381073236465.pypots
2024-05-25 01:29:42 [INFO]: Epoch 049 - training loss: 0.1836, validation loss: 0.1560
2024-05-25 01:29:42 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch49_loss0.15604066848754883.pypots
2024-05-25 01:29:44 [INFO]: Epoch 050 - training loss: 0.1882, validation loss: 0.1469
2024-05-25 01:29:44 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch50_loss0.14692318812012672.pypots
2024-05-25 01:29:46 [INFO]: Epoch 051 - training loss: 0.2154, validation loss: 0.1460
2024-05-25 01:29:46 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch51_loss0.14602963998913765.pypots
2024-05-25 01:29:48 [INFO]: Epoch 052 - training loss: 0.1649, validation loss: 0.1373
2024-05-25 01:29:48 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch52_loss0.13733526691794395.pypots
2024-05-25 01:29:50 [INFO]: Epoch 053 - training loss: 0.1538, validation loss: 0.1379
2024-05-25 01:29:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch53_loss0.13785994052886963.pypots
2024-05-25 01:29:52 [INFO]: Epoch 054 - training loss: 0.1475, validation loss: 0.1325
2024-05-25 01:29:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch54_loss0.13252906501293182.pypots
2024-05-25 01:29:54 [INFO]: Epoch 055 - training loss: 0.1498, validation loss: 0.1318
2024-05-25 01:29:54 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch55_loss0.13178246282041073.pypots
2024-05-25 01:29:57 [INFO]: Epoch 056 - training loss: 0.1235, validation loss: 0.1306
2024-05-25 01:29:57 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch56_loss0.13059385307133198.pypots
2024-05-25 01:29:59 [INFO]: Epoch 057 - training loss: 0.1464, validation loss: 0.1324
2024-05-25 01:29:59 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch57_loss0.1323747355490923.pypots
2024-05-25 01:30:01 [INFO]: Epoch 058 - training loss: 0.1522, validation loss: 0.1268
2024-05-25 01:30:01 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch58_loss0.1268090270459652.pypots
2024-05-25 01:30:03 [INFO]: Epoch 059 - training loss: 0.1683, validation loss: 0.1278
2024-05-25 01:30:03 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch59_loss0.12777618132531643.pypots
2024-05-25 01:30:05 [INFO]: Epoch 060 - training loss: 0.1637, validation loss: 0.1298
2024-05-25 01:30:05 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch60_loss0.12978322245180607.pypots
2024-05-25 01:30:07 [INFO]: Epoch 061 - training loss: 0.2021, validation loss: 0.1336
2024-05-25 01:30:07 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch61_loss0.13359015807509422.pypots
2024-05-25 01:30:09 [INFO]: Epoch 062 - training loss: 0.1754, validation loss: 0.1401
2024-05-25 01:30:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch62_loss0.14013425260782242.pypots
2024-05-25 01:30:11 [INFO]: Epoch 063 - training loss: 0.2325, validation loss: 0.1392
2024-05-25 01:30:11 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch63_loss0.13917215541005135.pypots
2024-05-25 01:30:13 [INFO]: Epoch 064 - training loss: 0.1444, validation loss: 0.1334
2024-05-25 01:30:13 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch64_loss0.13339421153068542.pypots
2024-05-25 01:30:15 [INFO]: Epoch 065 - training loss: 0.1555, validation loss: 0.1299
2024-05-25 01:30:15 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch65_loss0.1299257129430771.pypots
2024-05-25 01:30:17 [INFO]: Epoch 066 - training loss: 0.1461, validation loss: 0.1273
2024-05-25 01:30:17 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch66_loss0.12727048993110657.pypots
2024-05-25 01:30:19 [INFO]: Epoch 067 - training loss: 0.2024, validation loss: 0.1269
2024-05-25 01:30:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch67_loss0.12693634442985058.pypots
2024-05-25 01:30:21 [INFO]: Epoch 068 - training loss: 0.1489, validation loss: 0.1282
2024-05-25 01:30:22 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI_epoch68_loss0.12824052013456821.pypots
2024-05-25 01:30:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:30:22 [INFO]: Finished training. The best model is from epoch#58.
2024-05-25 01:30:22 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T012800/CSDI.pypots
2024-05-25 01:30:37 [INFO]: CSDI on ETTm1: MAE=0.1162, MSE=0.0359
2024-05-25 01:30:37 [INFO]: Successfully saved to augmentation_saved_results/round_1/CSDI_ettm1/imputation.pkl
2024-05-25 01:30:37 [INFO]: Using the given device: cuda:0
2024-05-25 01:30:37 [INFO]: Model files will be saved to augmentation_saved_results/round_1/GPVAE_ettm1/20240525_T013037
2024-05-25 01:30:37 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/GPVAE_ettm1/20240525_T013037/tensorboard
2024-05-25 01:30:37 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 01:30:38 [INFO]: Epoch 001 - training loss: 23875.3318, validation loss: 0.9834
2024-05-25 01:30:38 [INFO]: Epoch 002 - training loss: 21551.1852, validation loss: 0.9803
2024-05-25 01:30:38 [INFO]: Epoch 003 - training loss: 19551.5864, validation loss: 0.9761
2024-05-25 01:30:38 [INFO]: Epoch 004 - training loss: 17522.0197, validation loss: 0.9455
2024-05-25 01:30:38 [INFO]: Epoch 005 - training loss: 15690.4705, validation loss: 0.8814
2024-05-25 01:30:38 [INFO]: Epoch 006 - training loss: 14183.6960, validation loss: 0.7624
2024-05-25 01:30:38 [INFO]: Epoch 007 - training loss: 12983.7420, validation loss: 0.6476
2024-05-25 01:30:39 [INFO]: Epoch 008 - training loss: 12007.7723, validation loss: 0.5643
2024-05-25 01:30:39 [INFO]: Epoch 009 - training loss: 11418.3552, validation loss: 0.4918
2024-05-25 01:30:39 [INFO]: Epoch 010 - training loss: 11001.4777, validation loss: 0.4458
2024-05-25 01:30:39 [INFO]: Epoch 011 - training loss: 10683.9547, validation loss: 0.4131
2024-05-25 01:30:39 [INFO]: Epoch 012 - training loss: 10457.4575, validation loss: 0.3827
2024-05-25 01:30:39 [INFO]: Epoch 013 - training loss: 10343.6166, validation loss: 0.3558
2024-05-25 01:30:39 [INFO]: Epoch 014 - training loss: 10174.4731, validation loss: 0.3296
2024-05-25 01:30:39 [INFO]: Epoch 015 - training loss: 10031.5500, validation loss: 0.2998
2024-05-25 01:30:40 [INFO]: Epoch 016 - training loss: 9933.3688, validation loss: 0.2845
2024-05-25 01:30:40 [INFO]: Epoch 017 - training loss: 9875.1818, validation loss: 0.2731
2024-05-25 01:30:40 [INFO]: Epoch 018 - training loss: 9833.7974, validation loss: 0.2635
2024-05-25 01:30:40 [INFO]: Epoch 019 - training loss: 9791.3770, validation loss: 0.2567
2024-05-25 01:30:40 [INFO]: Epoch 020 - training loss: 9706.7487, validation loss: 0.2472
2024-05-25 01:30:40 [INFO]: Epoch 021 - training loss: 9688.4734, validation loss: 0.2374
2024-05-25 01:30:40 [INFO]: Epoch 022 - training loss: 9645.4177, validation loss: 0.2295
2024-05-25 01:30:41 [INFO]: Epoch 023 - training loss: 9624.7277, validation loss: 0.2265
2024-05-25 01:30:41 [INFO]: Epoch 024 - training loss: 9586.3561, validation loss: 0.2200
2024-05-25 01:30:41 [INFO]: Epoch 025 - training loss: 9584.5823, validation loss: 0.2162
2024-05-25 01:30:41 [INFO]: Epoch 026 - training loss: 9549.7338, validation loss: 0.2096
2024-05-25 01:30:41 [INFO]: Epoch 027 - training loss: 9546.6698, validation loss: 0.2061
2024-05-25 01:30:41 [INFO]: Epoch 028 - training loss: 9531.5157, validation loss: 0.1997
2024-05-25 01:30:41 [INFO]: Epoch 029 - training loss: 9500.9834, validation loss: 0.1931
2024-05-25 01:30:41 [INFO]: Epoch 030 - training loss: 9501.5282, validation loss: 0.1899
2024-05-25 01:30:42 [INFO]: Epoch 031 - training loss: 9478.6519, validation loss: 0.1889
2024-05-25 01:30:42 [INFO]: Epoch 032 - training loss: 9471.2501, validation loss: 0.1844
2024-05-25 01:30:42 [INFO]: Epoch 033 - training loss: 9468.6932, validation loss: 0.1818
2024-05-25 01:30:42 [INFO]: Epoch 034 - training loss: 9483.8355, validation loss: 0.1783
2024-05-25 01:30:42 [INFO]: Epoch 035 - training loss: 9463.9076, validation loss: 0.1727
2024-05-25 01:30:42 [INFO]: Epoch 036 - training loss: 9438.0812, validation loss: 0.1691
2024-05-25 01:30:42 [INFO]: Epoch 037 - training loss: 9426.5615, validation loss: 0.1682
2024-05-25 01:30:43 [INFO]: Epoch 038 - training loss: 9429.3046, validation loss: 0.1660
2024-05-25 01:30:43 [INFO]: Epoch 039 - training loss: 9417.4630, validation loss: 0.1629
2024-05-25 01:30:43 [INFO]: Epoch 040 - training loss: 9413.0044, validation loss: 0.1609
2024-05-25 01:30:43 [INFO]: Epoch 041 - training loss: 9407.3484, validation loss: 0.1563
2024-05-25 01:30:43 [INFO]: Epoch 042 - training loss: 9420.4628, validation loss: 0.1543
2024-05-25 01:30:43 [INFO]: Epoch 043 - training loss: 9403.9903, validation loss: 0.1516
2024-05-25 01:30:43 [INFO]: Epoch 044 - training loss: 9392.3098, validation loss: 0.1502
2024-05-25 01:30:43 [INFO]: Epoch 045 - training loss: 9394.5643, validation loss: 0.1507
2024-05-25 01:30:44 [INFO]: Epoch 046 - training loss: 9388.5500, validation loss: 0.1464
2024-05-25 01:30:44 [INFO]: Epoch 047 - training loss: 9389.0471, validation loss: 0.1441
2024-05-25 01:30:44 [INFO]: Epoch 048 - training loss: 9385.7695, validation loss: 0.1439
2024-05-25 01:30:44 [INFO]: Epoch 049 - training loss: 9384.3046, validation loss: 0.1413
2024-05-25 01:30:44 [INFO]: Epoch 050 - training loss: 9375.8267, validation loss: 0.1415
2024-05-25 01:30:44 [INFO]: Epoch 051 - training loss: 9375.9097, validation loss: 0.1393
2024-05-25 01:30:44 [INFO]: Epoch 052 - training loss: 9371.9352, validation loss: 0.1392
2024-05-25 01:30:45 [INFO]: Epoch 053 - training loss: 9367.4719, validation loss: 0.1381
2024-05-25 01:30:45 [INFO]: Epoch 054 - training loss: 9366.7065, validation loss: 0.1368
2024-05-25 01:30:45 [INFO]: Epoch 055 - training loss: 9374.1334, validation loss: 0.1362
2024-05-25 01:30:45 [INFO]: Epoch 056 - training loss: 9363.3859, validation loss: 0.1352
2024-05-25 01:30:45 [INFO]: Epoch 057 - training loss: 9361.7271, validation loss: 0.1354
2024-05-25 01:30:45 [INFO]: Epoch 058 - training loss: 9357.9739, validation loss: 0.1347
2024-05-25 01:30:45 [INFO]: Epoch 059 - training loss: 9357.5147, validation loss: 0.1326
2024-05-25 01:30:45 [INFO]: Epoch 060 - training loss: 9356.3531, validation loss: 0.1326
2024-05-25 01:30:46 [INFO]: Epoch 061 - training loss: 9356.9693, validation loss: 0.1298
2024-05-25 01:30:46 [INFO]: Epoch 062 - training loss: 9351.8244, validation loss: 0.1307
2024-05-25 01:30:46 [INFO]: Epoch 063 - training loss: 9350.1372, validation loss: 0.1306
2024-05-25 01:30:46 [INFO]: Epoch 064 - training loss: 9351.4921, validation loss: 0.1306
2024-05-25 01:30:46 [INFO]: Epoch 065 - training loss: 9352.1071, validation loss: 0.1290
2024-05-25 01:30:46 [INFO]: Epoch 066 - training loss: 9347.3507, validation loss: 0.1284
2024-05-25 01:30:46 [INFO]: Epoch 067 - training loss: 9352.1953, validation loss: 0.1263
2024-05-25 01:30:47 [INFO]: Epoch 068 - training loss: 9347.3602, validation loss: 0.1289
2024-05-25 01:30:47 [INFO]: Epoch 069 - training loss: 9345.2541, validation loss: 0.1252
2024-05-25 01:30:47 [INFO]: Epoch 070 - training loss: 9344.2366, validation loss: 0.1240
2024-05-25 01:30:47 [INFO]: Epoch 071 - training loss: 9344.1056, validation loss: 0.1233
2024-05-25 01:30:47 [INFO]: Epoch 072 - training loss: 9343.4658, validation loss: 0.1233
2024-05-25 01:30:47 [INFO]: Epoch 073 - training loss: 9341.3450, validation loss: 0.1229
2024-05-25 01:30:47 [INFO]: Epoch 074 - training loss: 9339.4253, validation loss: 0.1226
2024-05-25 01:30:47 [INFO]: Epoch 075 - training loss: 9339.9645, validation loss: 0.1219
2024-05-25 01:30:48 [INFO]: Epoch 076 - training loss: 9336.2529, validation loss: 0.1204
2024-05-25 01:30:48 [INFO]: Epoch 077 - training loss: 9337.2273, validation loss: 0.1193
2024-05-25 01:30:48 [INFO]: Epoch 078 - training loss: 9335.6893, validation loss: 0.1179
2024-05-25 01:30:48 [INFO]: Epoch 079 - training loss: 9336.3201, validation loss: 0.1183
2024-05-25 01:30:48 [INFO]: Epoch 080 - training loss: 9336.0227, validation loss: 0.1178
2024-05-25 01:30:48 [INFO]: Epoch 081 - training loss: 9334.9724, validation loss: 0.1196
2024-05-25 01:30:48 [INFO]: Epoch 082 - training loss: 9332.9741, validation loss: 0.1170
2024-05-25 01:30:49 [INFO]: Epoch 083 - training loss: 9331.8316, validation loss: 0.1152
2024-05-25 01:30:49 [INFO]: Epoch 084 - training loss: 9331.1097, validation loss: 0.1143
2024-05-25 01:30:49 [INFO]: Epoch 085 - training loss: 9334.7916, validation loss: 0.1145
2024-05-25 01:30:49 [INFO]: Epoch 086 - training loss: 9331.3754, validation loss: 0.1138
2024-05-25 01:30:49 [INFO]: Epoch 087 - training loss: 9329.8287, validation loss: 0.1132
2024-05-25 01:30:49 [INFO]: Epoch 088 - training loss: 9328.1337, validation loss: 0.1130
2024-05-25 01:30:49 [INFO]: Epoch 089 - training loss: 9328.7856, validation loss: 0.1111
2024-05-25 01:30:49 [INFO]: Epoch 090 - training loss: 9328.0238, validation loss: 0.1125
2024-05-25 01:30:50 [INFO]: Epoch 091 - training loss: 9328.7625, validation loss: 0.1130
2024-05-25 01:30:50 [INFO]: Epoch 092 - training loss: 9327.2592, validation loss: 0.1116
2024-05-25 01:30:50 [INFO]: Epoch 093 - training loss: 9326.5199, validation loss: 0.1096
2024-05-25 01:30:50 [INFO]: Epoch 094 - training loss: 9328.0447, validation loss: 0.1085
2024-05-25 01:30:50 [INFO]: Epoch 095 - training loss: 9326.8354, validation loss: 0.1088
2024-05-25 01:30:50 [INFO]: Epoch 096 - training loss: 9325.1975, validation loss: 0.1061
2024-05-25 01:30:50 [INFO]: Epoch 097 - training loss: 9325.2724, validation loss: 0.1079
2024-05-25 01:30:51 [INFO]: Epoch 098 - training loss: 9323.4700, validation loss: 0.1060
2024-05-25 01:30:51 [INFO]: Epoch 099 - training loss: 9323.9492, validation loss: 0.1055
2024-05-25 01:30:51 [INFO]: Epoch 100 - training loss: 9324.2434, validation loss: 0.1043
2024-05-25 01:30:51 [INFO]: Epoch 101 - training loss: 9324.5646, validation loss: 0.1053
2024-05-25 01:30:51 [INFO]: Epoch 102 - training loss: 9324.7521, validation loss: 0.1041
2024-05-25 01:30:51 [INFO]: Epoch 103 - training loss: 9322.7185, validation loss: 0.1031
2024-05-25 01:30:51 [INFO]: Epoch 104 - training loss: 9322.0965, validation loss: 0.1040
2024-05-25 01:30:51 [INFO]: Epoch 105 - training loss: 9321.5574, validation loss: 0.1023
2024-05-25 01:30:52 [INFO]: Epoch 106 - training loss: 9322.5573, validation loss: 0.1025
2024-05-25 01:30:52 [INFO]: Epoch 107 - training loss: 9320.9926, validation loss: 0.1013
2024-05-25 01:30:52 [INFO]: Epoch 108 - training loss: 9320.0780, validation loss: 0.1009
2024-05-25 01:30:52 [INFO]: Epoch 109 - training loss: 9319.6310, validation loss: 0.1023
2024-05-25 01:30:52 [INFO]: Epoch 110 - training loss: 9318.9993, validation loss: 0.1000
2024-05-25 01:30:52 [INFO]: Epoch 111 - training loss: 9320.2939, validation loss: 0.0999
2024-05-25 01:30:52 [INFO]: Epoch 112 - training loss: 9318.8560, validation loss: 0.0989
2024-05-25 01:30:53 [INFO]: Epoch 113 - training loss: 9320.1937, validation loss: 0.0995
2024-05-25 01:30:53 [INFO]: Epoch 114 - training loss: 9323.7444, validation loss: 0.0958
2024-05-25 01:30:53 [INFO]: Epoch 115 - training loss: 9317.3688, validation loss: 0.0984
2024-05-25 01:30:53 [INFO]: Epoch 116 - training loss: 9318.0231, validation loss: 0.0962
2024-05-25 01:30:53 [INFO]: Epoch 117 - training loss: 9317.2011, validation loss: 0.0962
2024-05-25 01:30:53 [INFO]: Epoch 118 - training loss: 9318.1251, validation loss: 0.0987
2024-05-25 01:30:53 [INFO]: Epoch 119 - training loss: 9315.7779, validation loss: 0.0973
2024-05-25 01:30:53 [INFO]: Epoch 120 - training loss: 9316.6600, validation loss: 0.0945
2024-05-25 01:30:54 [INFO]: Epoch 121 - training loss: 9316.1663, validation loss: 0.0945
2024-05-25 01:30:54 [INFO]: Epoch 122 - training loss: 9314.4714, validation loss: 0.0957
2024-05-25 01:30:54 [INFO]: Epoch 123 - training loss: 9317.3870, validation loss: 0.0940
2024-05-25 01:30:54 [INFO]: Epoch 124 - training loss: 9315.4749, validation loss: 0.0951
2024-05-25 01:30:54 [INFO]: Epoch 125 - training loss: 9316.5681, validation loss: 0.0946
2024-05-25 01:30:54 [INFO]: Epoch 126 - training loss: 9315.5834, validation loss: 0.0925
2024-05-25 01:30:54 [INFO]: Epoch 127 - training loss: 9315.2111, validation loss: 0.0929
2024-05-25 01:30:55 [INFO]: Epoch 128 - training loss: 9314.3249, validation loss: 0.0926
2024-05-25 01:30:55 [INFO]: Epoch 129 - training loss: 9313.0733, validation loss: 0.0917
2024-05-25 01:30:55 [INFO]: Epoch 130 - training loss: 9313.4938, validation loss: 0.0915
2024-05-25 01:30:55 [INFO]: Epoch 131 - training loss: 9315.1165, validation loss: 0.0911
2024-05-25 01:30:55 [INFO]: Epoch 132 - training loss: 9313.4952, validation loss: 0.0901
2024-05-25 01:30:55 [INFO]: Epoch 133 - training loss: 9312.5859, validation loss: 0.0907
2024-05-25 01:30:55 [INFO]: Epoch 134 - training loss: 9313.7358, validation loss: 0.0906
2024-05-25 01:30:55 [INFO]: Epoch 135 - training loss: 9313.1155, validation loss: 0.0894
2024-05-25 01:30:56 [INFO]: Epoch 136 - training loss: 9315.9749, validation loss: 0.0895
2024-05-25 01:30:56 [INFO]: Epoch 137 - training loss: 9316.1281, validation loss: 0.0881
2024-05-25 01:30:56 [INFO]: Epoch 138 - training loss: 9313.0696, validation loss: 0.0891
2024-05-25 01:30:56 [INFO]: Epoch 139 - training loss: 9311.8694, validation loss: 0.0887
2024-05-25 01:30:56 [INFO]: Epoch 140 - training loss: 9312.2414, validation loss: 0.0892
2024-05-25 01:30:56 [INFO]: Epoch 141 - training loss: 9313.3126, validation loss: 0.0874
2024-05-25 01:30:56 [INFO]: Epoch 142 - training loss: 9311.0414, validation loss: 0.0880
2024-05-25 01:30:57 [INFO]: Epoch 143 - training loss: 9311.6006, validation loss: 0.0870
2024-05-25 01:30:57 [INFO]: Epoch 144 - training loss: 9311.8801, validation loss: 0.0870
2024-05-25 01:30:57 [INFO]: Epoch 145 - training loss: 9311.4238, validation loss: 0.0881
2024-05-25 01:30:57 [INFO]: Epoch 146 - training loss: 9313.2483, validation loss: 0.0867
2024-05-25 01:30:57 [INFO]: Epoch 147 - training loss: 9310.0686, validation loss: 0.0846
2024-05-25 01:30:57 [INFO]: Epoch 148 - training loss: 9309.4177, validation loss: 0.0847
2024-05-25 01:30:57 [INFO]: Epoch 149 - training loss: 9311.4948, validation loss: 0.0847
2024-05-25 01:30:57 [INFO]: Epoch 150 - training loss: 9310.9739, validation loss: 0.0874
2024-05-25 01:30:58 [INFO]: Epoch 151 - training loss: 9311.8411, validation loss: 0.0844
2024-05-25 01:30:58 [INFO]: Epoch 152 - training loss: 9312.5562, validation loss: 0.0893
2024-05-25 01:30:58 [INFO]: Epoch 153 - training loss: 9310.4252, validation loss: 0.0876
2024-05-25 01:30:58 [INFO]: Epoch 154 - training loss: 9310.0184, validation loss: 0.0854
2024-05-25 01:30:58 [INFO]: Epoch 155 - training loss: 9310.2260, validation loss: 0.0850
2024-05-25 01:30:58 [INFO]: Epoch 156 - training loss: 9310.7255, validation loss: 0.0845
2024-05-25 01:30:58 [INFO]: Epoch 157 - training loss: 9310.0092, validation loss: 0.0841
2024-05-25 01:30:59 [INFO]: Epoch 158 - training loss: 9310.7445, validation loss: 0.0837
2024-05-25 01:30:59 [INFO]: Epoch 159 - training loss: 9308.2704, validation loss: 0.0852
2024-05-25 01:30:59 [INFO]: Epoch 160 - training loss: 9309.1515, validation loss: 0.0826
2024-05-25 01:30:59 [INFO]: Epoch 161 - training loss: 9308.2302, validation loss: 0.0823
2024-05-25 01:30:59 [INFO]: Epoch 162 - training loss: 9307.4307, validation loss: 0.0833
2024-05-25 01:30:59 [INFO]: Epoch 163 - training loss: 9308.0955, validation loss: 0.0825
2024-05-25 01:30:59 [INFO]: Epoch 164 - training loss: 9307.0165, validation loss: 0.0818
2024-05-25 01:30:59 [INFO]: Epoch 165 - training loss: 9309.1764, validation loss: 0.0818
2024-05-25 01:31:00 [INFO]: Epoch 166 - training loss: 9308.3638, validation loss: 0.0807
2024-05-25 01:31:00 [INFO]: Epoch 167 - training loss: 9308.5647, validation loss: 0.0798
2024-05-25 01:31:00 [INFO]: Epoch 168 - training loss: 9307.6945, validation loss: 0.0820
2024-05-25 01:31:00 [INFO]: Epoch 169 - training loss: 9308.6888, validation loss: 0.0796
2024-05-25 01:31:00 [INFO]: Epoch 170 - training loss: 9309.3850, validation loss: 0.0803
2024-05-25 01:31:00 [INFO]: Epoch 171 - training loss: 9310.1211, validation loss: 0.0816
2024-05-25 01:31:00 [INFO]: Epoch 172 - training loss: 9308.1268, validation loss: 0.0816
2024-05-25 01:31:01 [INFO]: Epoch 173 - training loss: 9306.5505, validation loss: 0.0821
2024-05-25 01:31:01 [INFO]: Epoch 174 - training loss: 9306.8681, validation loss: 0.0802
2024-05-25 01:31:01 [INFO]: Epoch 175 - training loss: 9306.2524, validation loss: 0.0793
2024-05-25 01:31:01 [INFO]: Epoch 176 - training loss: 9306.8469, validation loss: 0.0794
2024-05-25 01:31:01 [INFO]: Epoch 177 - training loss: 9307.3066, validation loss: 0.0784
2024-05-25 01:31:01 [INFO]: Epoch 178 - training loss: 9305.7661, validation loss: 0.0796
2024-05-25 01:31:01 [INFO]: Epoch 179 - training loss: 9306.4968, validation loss: 0.0789
2024-05-25 01:31:01 [INFO]: Epoch 180 - training loss: 9307.0397, validation loss: 0.0780
2024-05-25 01:31:02 [INFO]: Epoch 181 - training loss: 9307.0314, validation loss: 0.0816
2024-05-25 01:31:02 [INFO]: Epoch 182 - training loss: 9306.8517, validation loss: 0.0793
2024-05-25 01:31:02 [INFO]: Epoch 183 - training loss: 9305.9454, validation loss: 0.0778
2024-05-25 01:31:02 [INFO]: Epoch 184 - training loss: 9306.6509, validation loss: 0.0782
2024-05-25 01:31:02 [INFO]: Epoch 185 - training loss: 9307.5179, validation loss: 0.0796
2024-05-25 01:31:02 [INFO]: Epoch 186 - training loss: 9305.8126, validation loss: 0.0829
2024-05-25 01:31:02 [INFO]: Epoch 187 - training loss: 9306.6497, validation loss: 0.0815
2024-05-25 01:31:03 [INFO]: Epoch 188 - training loss: 9305.4982, validation loss: 0.0776
2024-05-25 01:31:03 [INFO]: Epoch 189 - training loss: 9307.2734, validation loss: 0.0780
2024-05-25 01:31:03 [INFO]: Epoch 190 - training loss: 9304.8282, validation loss: 0.0777
2024-05-25 01:31:03 [INFO]: Epoch 191 - training loss: 9304.9210, validation loss: 0.0791
2024-05-25 01:31:03 [INFO]: Epoch 192 - training loss: 9307.4678, validation loss: 0.0781
2024-05-25 01:31:03 [INFO]: Epoch 193 - training loss: 9305.4164, validation loss: 0.0779
2024-05-25 01:31:03 [INFO]: Epoch 194 - training loss: 9305.5802, validation loss: 0.0770
2024-05-25 01:31:03 [INFO]: Epoch 195 - training loss: 9306.0056, validation loss: 0.0749
2024-05-25 01:31:04 [INFO]: Epoch 196 - training loss: 9306.9792, validation loss: 0.0791
2024-05-25 01:31:04 [INFO]: Epoch 197 - training loss: 9304.7411, validation loss: 0.0771
2024-05-25 01:31:04 [INFO]: Epoch 198 - training loss: 9305.5929, validation loss: 0.0767
2024-05-25 01:31:04 [INFO]: Epoch 199 - training loss: 9304.9325, validation loss: 0.0769
2024-05-25 01:31:04 [INFO]: Epoch 200 - training loss: 9304.0126, validation loss: 0.0775
2024-05-25 01:31:04 [INFO]: Epoch 201 - training loss: 9304.2841, validation loss: 0.0769
2024-05-25 01:31:04 [INFO]: Epoch 202 - training loss: 9304.7625, validation loss: 0.0774
2024-05-25 01:31:05 [INFO]: Epoch 203 - training loss: 9304.9424, validation loss: 0.0768
2024-05-25 01:31:05 [INFO]: Epoch 204 - training loss: 9304.1443, validation loss: 0.0765
2024-05-25 01:31:05 [INFO]: Epoch 205 - training loss: 9304.5031, validation loss: 0.0786
2024-05-25 01:31:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:31:05 [INFO]: Finished training. The best model is from epoch#195.
2024-05-25 01:31:05 [INFO]: Saved the model to augmentation_saved_results/round_1/GPVAE_ettm1/20240525_T013037/GPVAE.pypots
2024-05-25 01:31:05 [INFO]: GP-VAE on ETTm1: MAE=0.2697, MSE=0.1562
2024-05-25 01:31:05 [INFO]: Successfully saved to augmentation_saved_results/round_1/GPVAE_ettm1/imputation.pkl
2024-05-25 01:31:05 [INFO]: Using the given device: cuda:0
2024-05-25 01:31:05 [INFO]: Model files will be saved to augmentation_saved_results/round_1/USGAN_ettm1/20240525_T013105
2024-05-25 01:31:05 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/USGAN_ettm1/20240525_T013105/tensorboard
2024-05-25 01:31:05 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 01:31:16 [INFO]: Epoch 001 - generator training loss: 0.5511, discriminator training loss: 0.3346, validation loss: 0.3934
2024-05-25 01:31:25 [INFO]: Epoch 002 - generator training loss: 0.0591, discriminator training loss: 0.2062, validation loss: 0.1183
2024-05-25 01:31:34 [INFO]: Epoch 003 - generator training loss: -0.0584, discriminator training loss: 0.1988, validation loss: 0.0629
2024-05-25 01:31:43 [INFO]: Epoch 004 - generator training loss: -0.0782, discriminator training loss: 0.1945, validation loss: 0.0494
2024-05-25 01:31:52 [INFO]: Epoch 005 - generator training loss: -0.0842, discriminator training loss: 0.1886, validation loss: 0.0433
2024-05-25 01:32:01 [INFO]: Epoch 006 - generator training loss: -0.0839, discriminator training loss: 0.1857, validation loss: 0.0427
2024-05-25 01:32:10 [INFO]: Epoch 007 - generator training loss: -0.0779, discriminator training loss: 0.1772, validation loss: 0.0386
2024-05-25 01:32:19 [INFO]: Epoch 008 - generator training loss: -0.0700, discriminator training loss: 0.1669, validation loss: 0.0362
2024-05-25 01:32:28 [INFO]: Epoch 009 - generator training loss: -0.0596, discriminator training loss: 0.1548, validation loss: 0.0356
2024-05-25 01:32:37 [INFO]: Epoch 010 - generator training loss: -0.0499, discriminator training loss: 0.1407, validation loss: 0.0348
2024-05-25 01:32:46 [INFO]: Epoch 011 - generator training loss: -0.0379, discriminator training loss: 0.1257, validation loss: 0.0330
2024-05-25 01:32:55 [INFO]: Epoch 012 - generator training loss: -0.0300, discriminator training loss: 0.1140, validation loss: 0.0327
2024-05-25 01:33:04 [INFO]: Epoch 013 - generator training loss: -0.0264, discriminator training loss: 0.1060, validation loss: 0.0316
2024-05-25 01:33:13 [INFO]: Epoch 014 - generator training loss: -0.0218, discriminator training loss: 0.0967, validation loss: 0.0312
2024-05-25 01:33:22 [INFO]: Epoch 015 - generator training loss: -0.0182, discriminator training loss: 0.0910, validation loss: 0.0308
2024-05-25 01:33:31 [INFO]: Epoch 016 - generator training loss: -0.0169, discriminator training loss: 0.0859, validation loss: 0.0304
2024-05-25 01:33:40 [INFO]: Epoch 017 - generator training loss: -0.0155, discriminator training loss: 0.0834, validation loss: 0.0305
2024-05-25 01:33:49 [INFO]: Epoch 018 - generator training loss: -0.0161, discriminator training loss: 0.0816, validation loss: 0.0297
2024-05-25 01:33:58 [INFO]: Epoch 019 - generator training loss: -0.0147, discriminator training loss: 0.0802, validation loss: 0.0295
2024-05-25 01:34:07 [INFO]: Epoch 020 - generator training loss: -0.0118, discriminator training loss: 0.0800, validation loss: 0.0292
2024-05-25 01:34:16 [INFO]: Epoch 021 - generator training loss: -0.0126, discriminator training loss: 0.0775, validation loss: 0.0307
2024-05-25 01:34:25 [INFO]: Epoch 022 - generator training loss: -0.0138, discriminator training loss: 0.0777, validation loss: 0.0281
2024-05-25 01:34:34 [INFO]: Epoch 023 - generator training loss: -0.0111, discriminator training loss: 0.0755, validation loss: 0.0274
2024-05-25 01:34:43 [INFO]: Epoch 024 - generator training loss: -0.0136, discriminator training loss: 0.0763, validation loss: 0.0270
2024-05-25 01:34:52 [INFO]: Epoch 025 - generator training loss: -0.0176, discriminator training loss: 0.0759, validation loss: 0.0268
2024-05-25 01:35:01 [INFO]: Epoch 026 - generator training loss: -0.0155, discriminator training loss: 0.0768, validation loss: 0.0267
2024-05-25 01:35:10 [INFO]: Epoch 027 - generator training loss: -0.0125, discriminator training loss: 0.0754, validation loss: 0.0261
2024-05-25 01:35:19 [INFO]: Epoch 028 - generator training loss: -0.0159, discriminator training loss: 0.0738, validation loss: 0.0265
2024-05-25 01:35:28 [INFO]: Epoch 029 - generator training loss: -0.0161, discriminator training loss: 0.0742, validation loss: 0.0259
2024-05-25 01:35:37 [INFO]: Epoch 030 - generator training loss: -0.0161, discriminator training loss: 0.0726, validation loss: 0.0251
2024-05-25 01:35:46 [INFO]: Epoch 031 - generator training loss: -0.0152, discriminator training loss: 0.0727, validation loss: 0.0250
2024-05-25 01:35:55 [INFO]: Epoch 032 - generator training loss: -0.0158, discriminator training loss: 0.0707, validation loss: 0.0249
2024-05-25 01:36:04 [INFO]: Epoch 033 - generator training loss: -0.0164, discriminator training loss: 0.0730, validation loss: 0.0245
2024-05-25 01:36:13 [INFO]: Epoch 034 - generator training loss: -0.0168, discriminator training loss: 0.0732, validation loss: 0.0245
2024-05-25 01:36:22 [INFO]: Epoch 035 - generator training loss: -0.0169, discriminator training loss: 0.0697, validation loss: 0.0239
2024-05-25 01:36:30 [INFO]: Epoch 036 - generator training loss: -0.0187, discriminator training loss: 0.0739, validation loss: 0.0329
2024-05-25 01:36:39 [INFO]: Epoch 037 - generator training loss: -0.0098, discriminator training loss: 0.0704, validation loss: 0.0273
2024-05-25 01:36:48 [INFO]: Epoch 038 - generator training loss: -0.0143, discriminator training loss: 0.0704, validation loss: 0.0246
2024-05-25 01:36:57 [INFO]: Epoch 039 - generator training loss: -0.0185, discriminator training loss: 0.0688, validation loss: 0.0242
2024-05-25 01:37:06 [INFO]: Epoch 040 - generator training loss: -0.0162, discriminator training loss: 0.0698, validation loss: 0.0239
2024-05-25 01:37:15 [INFO]: Epoch 041 - generator training loss: -0.0152, discriminator training loss: 0.0720, validation loss: 0.0236
2024-05-25 01:37:24 [INFO]: Epoch 042 - generator training loss: -0.0196, discriminator training loss: 0.0687, validation loss: 0.0231
2024-05-25 01:37:33 [INFO]: Epoch 043 - generator training loss: -0.0173, discriminator training loss: 0.0681, validation loss: 0.0230
2024-05-25 01:37:42 [INFO]: Epoch 044 - generator training loss: -0.0181, discriminator training loss: 0.0696, validation loss: 0.0229
2024-05-25 01:37:51 [INFO]: Epoch 045 - generator training loss: -0.0207, discriminator training loss: 0.0730, validation loss: 0.0228
2024-05-25 01:38:00 [INFO]: Epoch 046 - generator training loss: -0.0191, discriminator training loss: 0.0685, validation loss: 0.0224
2024-05-25 01:38:09 [INFO]: Epoch 047 - generator training loss: -0.0186, discriminator training loss: 0.0686, validation loss: 0.0223
2024-05-25 01:38:18 [INFO]: Epoch 048 - generator training loss: -0.0188, discriminator training loss: 0.0700, validation loss: 0.0231
2024-05-25 01:38:27 [INFO]: Epoch 049 - generator training loss: -0.0184, discriminator training loss: 0.0684, validation loss: 0.0220
2024-05-25 01:38:36 [INFO]: Epoch 050 - generator training loss: -0.0209, discriminator training loss: 0.0705, validation loss: 0.0221
2024-05-25 01:38:46 [INFO]: Epoch 051 - generator training loss: -0.0193, discriminator training loss: 0.0688, validation loss: 0.0217
2024-05-25 01:38:55 [INFO]: Epoch 052 - generator training loss: -0.0205, discriminator training loss: 0.0699, validation loss: 0.0224
2024-05-25 01:39:04 [INFO]: Epoch 053 - generator training loss: -0.0211, discriminator training loss: 0.0686, validation loss: 0.0212
2024-05-25 01:39:13 [INFO]: Epoch 054 - generator training loss: -0.0204, discriminator training loss: 0.0675, validation loss: 0.0214
2024-05-25 01:39:22 [INFO]: Epoch 055 - generator training loss: -0.0204, discriminator training loss: 0.0683, validation loss: 0.0213
2024-05-25 01:39:31 [INFO]: Epoch 056 - generator training loss: -0.0196, discriminator training loss: 0.0682, validation loss: 0.0217
2024-05-25 01:39:40 [INFO]: Epoch 057 - generator training loss: -0.0172, discriminator training loss: 0.0681, validation loss: 0.0215
2024-05-25 01:39:49 [INFO]: Epoch 058 - generator training loss: -0.0235, discriminator training loss: 0.0664, validation loss: 0.0215
2024-05-25 01:39:58 [INFO]: Epoch 059 - generator training loss: -0.0206, discriminator training loss: 0.0672, validation loss: 0.0211
2024-05-25 01:40:07 [INFO]: Epoch 060 - generator training loss: -0.0217, discriminator training loss: 0.0697, validation loss: 0.0207
2024-05-25 01:40:16 [INFO]: Epoch 061 - generator training loss: -0.0219, discriminator training loss: 0.0684, validation loss: 0.0207
2024-05-25 01:40:25 [INFO]: Epoch 062 - generator training loss: -0.0242, discriminator training loss: 0.0669, validation loss: 0.0205
2024-05-25 01:40:34 [INFO]: Epoch 063 - generator training loss: -0.0215, discriminator training loss: 0.0680, validation loss: 0.0207
2024-05-25 01:40:43 [INFO]: Epoch 064 - generator training loss: -0.0167, discriminator training loss: 0.0659, validation loss: 0.0201
2024-05-25 01:40:52 [INFO]: Epoch 065 - generator training loss: -0.0236, discriminator training loss: 0.0677, validation loss: 0.0203
2024-05-25 01:41:01 [INFO]: Epoch 066 - generator training loss: -0.0237, discriminator training loss: 0.0680, validation loss: 0.0204
2024-05-25 01:41:10 [INFO]: Epoch 067 - generator training loss: -0.0207, discriminator training loss: 0.0665, validation loss: 0.0210
2024-05-25 01:41:20 [INFO]: Epoch 068 - generator training loss: -0.0256, discriminator training loss: 0.0690, validation loss: 0.0198
2024-05-25 01:41:29 [INFO]: Epoch 069 - generator training loss: -0.0215, discriminator training loss: 0.0683, validation loss: 0.0200
2024-05-25 01:41:38 [INFO]: Epoch 070 - generator training loss: -0.0235, discriminator training loss: 0.0676, validation loss: 0.0198
2024-05-25 01:41:47 [INFO]: Epoch 071 - generator training loss: -0.0210, discriminator training loss: 0.0650, validation loss: 0.0196
2024-05-25 01:41:56 [INFO]: Epoch 072 - generator training loss: -0.0243, discriminator training loss: 0.0668, validation loss: 0.0200
2024-05-25 01:42:05 [INFO]: Epoch 073 - generator training loss: -0.0252, discriminator training loss: 0.0668, validation loss: 0.0196
2024-05-25 01:42:14 [INFO]: Epoch 074 - generator training loss: -0.0231, discriminator training loss: 0.0665, validation loss: 0.0197
2024-05-25 01:42:23 [INFO]: Epoch 075 - generator training loss: -0.0235, discriminator training loss: 0.0655, validation loss: 0.0195
2024-05-25 01:42:32 [INFO]: Epoch 076 - generator training loss: -0.0258, discriminator training loss: 0.0660, validation loss: 0.0197
2024-05-25 01:42:42 [INFO]: Epoch 077 - generator training loss: -0.0241, discriminator training loss: 0.0651, validation loss: 0.0197
2024-05-25 01:42:51 [INFO]: Epoch 078 - generator training loss: -0.0253, discriminator training loss: 0.0675, validation loss: 0.0198
2024-05-25 01:43:00 [INFO]: Epoch 079 - generator training loss: -0.0235, discriminator training loss: 0.0666, validation loss: 0.0196
2024-05-25 01:43:09 [INFO]: Epoch 080 - generator training loss: -0.0227, discriminator training loss: 0.0656, validation loss: 0.0194
2024-05-25 01:43:18 [INFO]: Epoch 081 - generator training loss: -0.0234, discriminator training loss: 0.0661, validation loss: 0.0193
2024-05-25 01:43:27 [INFO]: Epoch 082 - generator training loss: -0.0218, discriminator training loss: 0.0641, validation loss: 0.0194
2024-05-25 01:43:36 [INFO]: Epoch 083 - generator training loss: -0.0267, discriminator training loss: 0.0666, validation loss: 0.0191
2024-05-25 01:43:45 [INFO]: Epoch 084 - generator training loss: -0.0250, discriminator training loss: 0.0666, validation loss: 0.0195
2024-05-25 01:43:54 [INFO]: Epoch 085 - generator training loss: -0.0253, discriminator training loss: 0.0672, validation loss: 0.0198
2024-05-25 01:44:03 [INFO]: Epoch 086 - generator training loss: -0.0225, discriminator training loss: 0.0666, validation loss: 0.0192
2024-05-25 01:44:12 [INFO]: Epoch 087 - generator training loss: -0.0279, discriminator training loss: 0.0671, validation loss: 0.0195
2024-05-25 01:44:21 [INFO]: Epoch 088 - generator training loss: -0.0227, discriminator training loss: 0.0674, validation loss: 0.0191
2024-05-25 01:44:30 [INFO]: Epoch 089 - generator training loss: -0.0216, discriminator training loss: 0.0653, validation loss: 0.0189
2024-05-25 01:44:39 [INFO]: Epoch 090 - generator training loss: -0.0230, discriminator training loss: 0.0650, validation loss: 0.0190
2024-05-25 01:44:48 [INFO]: Epoch 091 - generator training loss: -0.0230, discriminator training loss: 0.0645, validation loss: 0.0189
2024-05-25 01:44:57 [INFO]: Epoch 092 - generator training loss: -0.0238, discriminator training loss: 0.0675, validation loss: 0.0194
2024-05-25 01:45:06 [INFO]: Epoch 093 - generator training loss: -0.0226, discriminator training loss: 0.0653, validation loss: 0.0189
2024-05-25 01:45:15 [INFO]: Epoch 094 - generator training loss: -0.0240, discriminator training loss: 0.0664, validation loss: 0.0193
2024-05-25 01:45:24 [INFO]: Epoch 095 - generator training loss: -0.0237, discriminator training loss: 0.0684, validation loss: 0.0190
2024-05-25 01:45:33 [INFO]: Epoch 096 - generator training loss: -0.0220, discriminator training loss: 0.0655, validation loss: 0.0191
2024-05-25 01:45:42 [INFO]: Epoch 097 - generator training loss: -0.0221, discriminator training loss: 0.0645, validation loss: 0.0188
2024-05-25 01:45:51 [INFO]: Epoch 098 - generator training loss: -0.0234, discriminator training loss: 0.0670, validation loss: 0.0191
2024-05-25 01:46:00 [INFO]: Epoch 099 - generator training loss: -0.0237, discriminator training loss: 0.0658, validation loss: 0.0193
2024-05-25 01:46:09 [INFO]: Epoch 100 - generator training loss: -0.0228, discriminator training loss: 0.0658, validation loss: 0.0194
2024-05-25 01:46:18 [INFO]: Epoch 101 - generator training loss: -0.0225, discriminator training loss: 0.0674, validation loss: 0.0190
2024-05-25 01:46:27 [INFO]: Epoch 102 - generator training loss: -0.0249, discriminator training loss: 0.0665, validation loss: 0.0188
2024-05-25 01:46:36 [INFO]: Epoch 103 - generator training loss: -0.0256, discriminator training loss: 0.0653, validation loss: 0.0195
2024-05-25 01:46:45 [INFO]: Epoch 104 - generator training loss: -0.0244, discriminator training loss: 0.0660, validation loss: 0.0188
2024-05-25 01:46:54 [INFO]: Epoch 105 - generator training loss: -0.0226, discriminator training loss: 0.0645, validation loss: 0.0192
2024-05-25 01:47:03 [INFO]: Epoch 106 - generator training loss: -0.0225, discriminator training loss: 0.0650, validation loss: 0.0186
2024-05-25 01:47:12 [INFO]: Epoch 107 - generator training loss: -0.0232, discriminator training loss: 0.0647, validation loss: 0.0190
2024-05-25 01:47:21 [INFO]: Epoch 108 - generator training loss: -0.0189, discriminator training loss: 0.0647, validation loss: 0.0185
2024-05-25 01:47:30 [INFO]: Epoch 109 - generator training loss: -0.0241, discriminator training loss: 0.0645, validation loss: 0.0191
2024-05-25 01:47:39 [INFO]: Epoch 110 - generator training loss: -0.0228, discriminator training loss: 0.0647, validation loss: 0.0195
2024-05-25 01:47:48 [INFO]: Epoch 111 - generator training loss: -0.0220, discriminator training loss: 0.0644, validation loss: 0.0190
2024-05-25 01:47:57 [INFO]: Epoch 112 - generator training loss: -0.0237, discriminator training loss: 0.0644, validation loss: 0.0186
2024-05-25 01:48:06 [INFO]: Epoch 113 - generator training loss: -0.0252, discriminator training loss: 0.0648, validation loss: 0.0188
2024-05-25 01:48:16 [INFO]: Epoch 114 - generator training loss: -0.0238, discriminator training loss: 0.0657, validation loss: 0.0185
2024-05-25 01:48:25 [INFO]: Epoch 115 - generator training loss: -0.0220, discriminator training loss: 0.0662, validation loss: 0.0188
2024-05-25 01:48:34 [INFO]: Epoch 116 - generator training loss: -0.0243, discriminator training loss: 0.0647, validation loss: 0.0188
2024-05-25 01:48:43 [INFO]: Epoch 117 - generator training loss: -0.0236, discriminator training loss: 0.0642, validation loss: 0.0188
2024-05-25 01:48:52 [INFO]: Epoch 118 - generator training loss: -0.0261, discriminator training loss: 0.0661, validation loss: 0.0186
2024-05-25 01:49:01 [INFO]: Epoch 119 - generator training loss: -0.0235, discriminator training loss: 0.0648, validation loss: 0.0188
2024-05-25 01:49:10 [INFO]: Epoch 120 - generator training loss: -0.0245, discriminator training loss: 0.0645, validation loss: 0.0181
2024-05-25 01:49:19 [INFO]: Epoch 121 - generator training loss: -0.0236, discriminator training loss: 0.0631, validation loss: 0.0185
2024-05-25 01:49:28 [INFO]: Epoch 122 - generator training loss: -0.0248, discriminator training loss: 0.0632, validation loss: 0.0209
2024-05-25 01:49:37 [INFO]: Epoch 123 - generator training loss: -0.0224, discriminator training loss: 0.0648, validation loss: 0.0207
2024-05-25 01:49:46 [INFO]: Epoch 124 - generator training loss: -0.0226, discriminator training loss: 0.0638, validation loss: 0.0192
2024-05-25 01:49:55 [INFO]: Epoch 125 - generator training loss: -0.0241, discriminator training loss: 0.0649, validation loss: 0.0190
2024-05-25 01:50:04 [INFO]: Epoch 126 - generator training loss: -0.0257, discriminator training loss: 0.0652, validation loss: 0.0190
2024-05-25 01:50:13 [INFO]: Epoch 127 - generator training loss: -0.0233, discriminator training loss: 0.0632, validation loss: 0.0190
2024-05-25 01:50:22 [INFO]: Epoch 128 - generator training loss: -0.0252, discriminator training loss: 0.0653, validation loss: 0.0188
2024-05-25 01:50:31 [INFO]: Epoch 129 - generator training loss: -0.0216, discriminator training loss: 0.0640, validation loss: 0.0180
2024-05-25 01:50:40 [INFO]: Epoch 130 - generator training loss: -0.0241, discriminator training loss: 0.0648, validation loss: 0.0190
2024-05-25 01:50:50 [INFO]: Epoch 131 - generator training loss: -0.0218, discriminator training loss: 0.0637, validation loss: 0.0187
2024-05-25 01:50:59 [INFO]: Epoch 132 - generator training loss: -0.0242, discriminator training loss: 0.0649, validation loss: 0.0191
2024-05-25 01:51:08 [INFO]: Epoch 133 - generator training loss: -0.0237, discriminator training loss: 0.0640, validation loss: 0.0186
2024-05-25 01:51:17 [INFO]: Epoch 134 - generator training loss: -0.0238, discriminator training loss: 0.0645, validation loss: 0.0185
2024-05-25 01:51:26 [INFO]: Epoch 135 - generator training loss: -0.0227, discriminator training loss: 0.0648, validation loss: 0.0183
2024-05-25 01:51:35 [INFO]: Epoch 136 - generator training loss: -0.0246, discriminator training loss: 0.0663, validation loss: 0.0187
2024-05-25 01:51:44 [INFO]: Epoch 137 - generator training loss: -0.0221, discriminator training loss: 0.0637, validation loss: 0.0182
2024-05-25 01:51:53 [INFO]: Epoch 138 - generator training loss: -0.0256, discriminator training loss: 0.0644, validation loss: 0.0185
2024-05-25 01:52:02 [INFO]: Epoch 139 - generator training loss: -0.0219, discriminator training loss: 0.0632, validation loss: 0.0188
2024-05-25 01:52:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:52:02 [INFO]: Finished training. The best model is from epoch#129.
2024-05-25 01:52:02 [INFO]: Saved the model to augmentation_saved_results/round_1/USGAN_ettm1/20240525_T013105/USGAN.pypots
2024-05-25 01:52:03 [INFO]: US-GAN on ETTm1: MAE=0.1352, MSE=0.0473
2024-05-25 01:52:03 [INFO]: Successfully saved to augmentation_saved_results/round_1/USGAN_ettm1/imputation.pkl
2024-05-25 01:52:03 [INFO]: Using the given device: cuda:0
2024-05-25 01:52:03 [INFO]: Model files will be saved to augmentation_saved_results/round_1/BRITS_ettm1/20240525_T015203
2024-05-25 01:52:03 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/BRITS_ettm1/20240525_T015203/tensorboard
2024-05-25 01:52:03 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 01:52:11 [INFO]: Epoch 001 - training loss: 1.2934, validation loss: 0.2352
2024-05-25 01:52:17 [INFO]: Epoch 002 - training loss: 0.8579, validation loss: 0.0739
2024-05-25 01:52:23 [INFO]: Epoch 003 - training loss: 0.7242, validation loss: 0.0521
2024-05-25 01:52:29 [INFO]: Epoch 004 - training loss: 0.6319, validation loss: 0.0426
2024-05-25 01:52:35 [INFO]: Epoch 005 - training loss: 0.5853, validation loss: 0.0408
2024-05-25 01:52:41 [INFO]: Epoch 006 - training loss: 0.5498, validation loss: 0.0356
2024-05-25 01:52:47 [INFO]: Epoch 007 - training loss: 0.5273, validation loss: 0.0343
2024-05-25 01:52:53 [INFO]: Epoch 008 - training loss: 0.5028, validation loss: 0.0327
2024-05-25 01:52:59 [INFO]: Epoch 009 - training loss: 0.4791, validation loss: 0.0323
2024-05-25 01:53:05 [INFO]: Epoch 010 - training loss: 0.4596, validation loss: 0.0304
2024-05-25 01:53:11 [INFO]: Epoch 011 - training loss: 0.4426, validation loss: 0.0292
2024-05-25 01:53:17 [INFO]: Epoch 012 - training loss: 0.4267, validation loss: 0.0278
2024-05-25 01:53:24 [INFO]: Epoch 013 - training loss: 0.4154, validation loss: 0.0272
2024-05-25 01:53:30 [INFO]: Epoch 014 - training loss: 0.4049, validation loss: 0.0260
2024-05-25 01:53:36 [INFO]: Epoch 015 - training loss: 0.3988, validation loss: 0.0246
2024-05-25 01:53:42 [INFO]: Epoch 016 - training loss: 0.3940, validation loss: 0.0245
2024-05-25 01:53:48 [INFO]: Epoch 017 - training loss: 0.3874, validation loss: 0.0242
2024-05-25 01:53:54 [INFO]: Epoch 018 - training loss: 0.4036, validation loss: 0.0241
2024-05-25 01:54:00 [INFO]: Epoch 019 - training loss: 0.3918, validation loss: 0.0234
2024-05-25 01:54:06 [INFO]: Epoch 020 - training loss: 0.3848, validation loss: 0.0229
2024-05-25 01:54:12 [INFO]: Epoch 021 - training loss: 0.3876, validation loss: 0.0239
2024-05-25 01:54:18 [INFO]: Epoch 022 - training loss: 0.3835, validation loss: 0.0229
2024-05-25 01:54:24 [INFO]: Epoch 023 - training loss: 0.3796, validation loss: 0.0229
2024-05-25 01:54:30 [INFO]: Epoch 024 - training loss: 0.3929, validation loss: 0.0226
2024-05-25 01:54:36 [INFO]: Epoch 025 - training loss: 0.3848, validation loss: 0.0223
2024-05-25 01:54:42 [INFO]: Epoch 026 - training loss: 0.3802, validation loss: 0.0221
2024-05-25 01:54:48 [INFO]: Epoch 027 - training loss: 0.3866, validation loss: 0.0224
2024-05-25 01:54:54 [INFO]: Epoch 028 - training loss: 0.3806, validation loss: 0.0221
2024-05-25 01:55:00 [INFO]: Epoch 029 - training loss: 0.3786, validation loss: 0.0232
2024-05-25 01:55:06 [INFO]: Epoch 030 - training loss: 0.4193, validation loss: 0.0254
2024-05-25 01:55:12 [INFO]: Epoch 031 - training loss: 0.3868, validation loss: 0.0228
2024-05-25 01:55:18 [INFO]: Epoch 032 - training loss: 0.3845, validation loss: 0.0228
2024-05-25 01:55:24 [INFO]: Epoch 033 - training loss: 0.3883, validation loss: 0.0228
2024-05-25 01:55:30 [INFO]: Epoch 034 - training loss: 0.3770, validation loss: 0.0231
2024-05-25 01:55:36 [INFO]: Epoch 035 - training loss: 0.3843, validation loss: 0.0224
2024-05-25 01:55:42 [INFO]: Epoch 036 - training loss: 0.3841, validation loss: 0.0222
2024-05-25 01:55:48 [INFO]: Epoch 037 - training loss: 0.3729, validation loss: 0.0226
2024-05-25 01:55:54 [INFO]: Epoch 038 - training loss: 0.3671, validation loss: 0.0224
2024-05-25 01:55:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:55:54 [INFO]: Finished training. The best model is from epoch#28.
2024-05-25 01:55:54 [INFO]: Saved the model to augmentation_saved_results/round_1/BRITS_ettm1/20240525_T015203/BRITS.pypots
2024-05-25 01:55:55 [INFO]: BRITS on ETTm1: MAE=0.1213, MSE=0.0451
2024-05-25 01:55:55 [INFO]: Successfully saved to augmentation_saved_results/round_1/BRITS_ettm1/imputation.pkl
2024-05-25 01:55:55 [INFO]: Using the given device: cuda:0
2024-05-25 01:55:55 [INFO]: Model files will be saved to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555
2024-05-25 01:55:55 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/tensorboard
2024-05-25 01:55:55 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 01:55:57 [INFO]: Epoch 001 - training loss: 1.3938, validation loss: 1.2172
2024-05-25 01:55:57 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch1_loss1.2171616703271866.pypots
2024-05-25 01:55:57 [INFO]: Epoch 002 - training loss: 1.0592, validation loss: 1.1244
2024-05-25 01:55:57 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch2_loss1.124401643872261.pypots
2024-05-25 01:55:57 [INFO]: Epoch 003 - training loss: 0.9876, validation loss: 1.0778
2024-05-25 01:55:57 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch3_loss1.0777855664491653.pypots
2024-05-25 01:55:58 [INFO]: Epoch 004 - training loss: 0.9840, validation loss: 1.0486
2024-05-25 01:55:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch4_loss1.0486154407262802.pypots
2024-05-25 01:55:58 [INFO]: Epoch 005 - training loss: 0.9506, validation loss: 1.0348
2024-05-25 01:55:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch5_loss1.0347938984632492.pypots
2024-05-25 01:55:58 [INFO]: Epoch 006 - training loss: 0.9690, validation loss: 1.0243
2024-05-25 01:55:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch6_loss1.024344488978386.pypots
2024-05-25 01:55:58 [INFO]: Epoch 007 - training loss: 0.9374, validation loss: 1.0145
2024-05-25 01:55:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch7_loss1.0145268142223358.pypots
2024-05-25 01:55:58 [INFO]: Epoch 008 - training loss: 0.9188, validation loss: 1.0035
2024-05-25 01:55:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch8_loss1.0034898817539215.pypots
2024-05-25 01:55:59 [INFO]: Epoch 009 - training loss: 0.9042, validation loss: 0.9968
2024-05-25 01:55:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch9_loss0.9967803359031677.pypots
2024-05-25 01:55:59 [INFO]: Epoch 010 - training loss: 0.9186, validation loss: 0.9898
2024-05-25 01:55:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch10_loss0.9898462146520615.pypots
2024-05-25 01:55:59 [INFO]: Epoch 011 - training loss: 0.9010, validation loss: 0.9813
2024-05-25 01:55:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch11_loss0.9813371151685715.pypots
2024-05-25 01:55:59 [INFO]: Epoch 012 - training loss: 0.9251, validation loss: 0.9780
2024-05-25 01:55:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch12_loss0.9779627174139023.pypots
2024-05-25 01:55:59 [INFO]: Epoch 013 - training loss: 0.8867, validation loss: 0.9724
2024-05-25 01:55:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch13_loss0.9723816514015198.pypots
2024-05-25 01:56:00 [INFO]: Epoch 014 - training loss: 0.8953, validation loss: 0.9689
2024-05-25 01:56:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch14_loss0.9689475297927856.pypots
2024-05-25 01:56:00 [INFO]: Epoch 015 - training loss: 0.8803, validation loss: 0.9650
2024-05-25 01:56:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch15_loss0.9649605453014374.pypots
2024-05-25 01:56:00 [INFO]: Epoch 016 - training loss: 0.8944, validation loss: 0.9625
2024-05-25 01:56:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch16_loss0.9625241309404373.pypots
2024-05-25 01:56:00 [INFO]: Epoch 017 - training loss: 0.8873, validation loss: 0.9648
2024-05-25 01:56:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch17_loss0.9647563099861145.pypots
2024-05-25 01:56:00 [INFO]: Epoch 018 - training loss: 0.8676, validation loss: 0.9610
2024-05-25 01:56:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch18_loss0.9609565436840057.pypots
2024-05-25 01:56:00 [INFO]: Epoch 019 - training loss: 0.8571, validation loss: 0.9597
2024-05-25 01:56:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch19_loss0.9596593677997589.pypots
2024-05-25 01:56:01 [INFO]: Epoch 020 - training loss: 0.8593, validation loss: 0.9594
2024-05-25 01:56:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch20_loss0.9594141691923141.pypots
2024-05-25 01:56:01 [INFO]: Epoch 021 - training loss: 0.8591, validation loss: 0.9583
2024-05-25 01:56:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch21_loss0.9583486765623093.pypots
2024-05-25 01:56:01 [INFO]: Epoch 022 - training loss: 0.8526, validation loss: 0.9577
2024-05-25 01:56:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch22_loss0.9576607048511505.pypots
2024-05-25 01:56:01 [INFO]: Epoch 023 - training loss: 0.8417, validation loss: 0.9554
2024-05-25 01:56:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch23_loss0.9554326385259628.pypots
2024-05-25 01:56:01 [INFO]: Epoch 024 - training loss: 0.8487, validation loss: 0.9545
2024-05-25 01:56:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch24_loss0.9544548988342285.pypots
2024-05-25 01:56:02 [INFO]: Epoch 025 - training loss: 0.8369, validation loss: 0.9538
2024-05-25 01:56:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch25_loss0.9538430124521255.pypots
2024-05-25 01:56:02 [INFO]: Epoch 026 - training loss: 0.8413, validation loss: 0.9517
2024-05-25 01:56:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch26_loss0.951674297451973.pypots
2024-05-25 01:56:02 [INFO]: Epoch 027 - training loss: 0.8305, validation loss: 0.9521
2024-05-25 01:56:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch27_loss0.9521341621875763.pypots
2024-05-25 01:56:02 [INFO]: Epoch 028 - training loss: 0.8188, validation loss: 0.9500
2024-05-25 01:56:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch28_loss0.9499729722738266.pypots
2024-05-25 01:56:02 [INFO]: Epoch 029 - training loss: 0.8237, validation loss: 0.9480
2024-05-25 01:56:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch29_loss0.9480434507131577.pypots
2024-05-25 01:56:03 [INFO]: Epoch 030 - training loss: 0.8307, validation loss: 0.9442
2024-05-25 01:56:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch30_loss0.9441619962453842.pypots
2024-05-25 01:56:03 [INFO]: Epoch 031 - training loss: 0.8577, validation loss: 0.9414
2024-05-25 01:56:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch31_loss0.9413951486349106.pypots
2024-05-25 01:56:03 [INFO]: Epoch 032 - training loss: 0.8185, validation loss: 0.9375
2024-05-25 01:56:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch32_loss0.9375105798244476.pypots
2024-05-25 01:56:03 [INFO]: Epoch 033 - training loss: 0.8192, validation loss: 0.9371
2024-05-25 01:56:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch33_loss0.9370922297239304.pypots
2024-05-25 01:56:03 [INFO]: Epoch 034 - training loss: 0.8257, validation loss: 0.9333
2024-05-25 01:56:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch34_loss0.9332608878612518.pypots
2024-05-25 01:56:03 [INFO]: Epoch 035 - training loss: 0.8193, validation loss: 0.9297
2024-05-25 01:56:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch35_loss0.9297177642583847.pypots
2024-05-25 01:56:04 [INFO]: Epoch 036 - training loss: 0.8666, validation loss: 0.9271
2024-05-25 01:56:04 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch36_loss0.9271460622549057.pypots
2024-05-25 01:56:04 [INFO]: Epoch 037 - training loss: 0.8302, validation loss: 0.9249
2024-05-25 01:56:04 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch37_loss0.9248979538679123.pypots
2024-05-25 01:56:04 [INFO]: Epoch 038 - training loss: 0.8296, validation loss: 0.9223
2024-05-25 01:56:04 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch38_loss0.9222757071256638.pypots
2024-05-25 01:56:04 [INFO]: Epoch 039 - training loss: 0.8219, validation loss: 0.9226
2024-05-25 01:56:04 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch39_loss0.9225611537694931.pypots
2024-05-25 01:56:04 [INFO]: Epoch 040 - training loss: 0.8237, validation loss: 0.9211
2024-05-25 01:56:04 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch40_loss0.9211480170488358.pypots
2024-05-25 01:56:05 [INFO]: Epoch 041 - training loss: 0.8016, validation loss: 0.9207
2024-05-25 01:56:05 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch41_loss0.92071333527565.pypots
2024-05-25 01:56:05 [INFO]: Epoch 042 - training loss: 0.8166, validation loss: 0.9172
2024-05-25 01:56:05 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch42_loss0.9172152280807495.pypots
2024-05-25 01:56:05 [INFO]: Epoch 043 - training loss: 0.8186, validation loss: 0.9161
2024-05-25 01:56:05 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch43_loss0.9160780012607574.pypots
2024-05-25 01:56:05 [INFO]: Epoch 044 - training loss: 0.7999, validation loss: 0.9152
2024-05-25 01:56:05 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch44_loss0.9151895344257355.pypots
2024-05-25 01:56:05 [INFO]: Epoch 045 - training loss: 0.7951, validation loss: 0.9137
2024-05-25 01:56:05 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch45_loss0.9136958122253418.pypots
2024-05-25 01:56:06 [INFO]: Epoch 046 - training loss: 0.8099, validation loss: 0.9133
2024-05-25 01:56:06 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch46_loss0.9132977724075317.pypots
2024-05-25 01:56:06 [INFO]: Epoch 047 - training loss: 0.8037, validation loss: 0.9102
2024-05-25 01:56:06 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch47_loss0.9101996719837189.pypots
2024-05-25 01:56:06 [INFO]: Epoch 048 - training loss: 0.7775, validation loss: 0.9113
2024-05-25 01:56:06 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch48_loss0.9113098829984665.pypots
2024-05-25 01:56:06 [INFO]: Epoch 049 - training loss: 0.8360, validation loss: 0.9105
2024-05-25 01:56:06 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch49_loss0.9105244576931.pypots
2024-05-25 01:56:06 [INFO]: Epoch 050 - training loss: 0.8227, validation loss: 0.9109
2024-05-25 01:56:06 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch50_loss0.9108864367008209.pypots
2024-05-25 01:56:06 [INFO]: Epoch 051 - training loss: 0.8127, validation loss: 0.9076
2024-05-25 01:56:06 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch51_loss0.9076154232025146.pypots
2024-05-25 01:56:07 [INFO]: Epoch 052 - training loss: 0.8048, validation loss: 0.9074
2024-05-25 01:56:07 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch52_loss0.9074246883392334.pypots
2024-05-25 01:56:07 [INFO]: Epoch 053 - training loss: 0.7732, validation loss: 0.9029
2024-05-25 01:56:07 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch53_loss0.9028522670269012.pypots
2024-05-25 01:56:07 [INFO]: Epoch 054 - training loss: 0.8143, validation loss: 0.9026
2024-05-25 01:56:07 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch54_loss0.9025997817516327.pypots
2024-05-25 01:56:07 [INFO]: Epoch 055 - training loss: 0.8081, validation loss: 0.9016
2024-05-25 01:56:07 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch55_loss0.9016418159008026.pypots
2024-05-25 01:56:07 [INFO]: Epoch 056 - training loss: 0.8073, validation loss: 0.8991
2024-05-25 01:56:07 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch56_loss0.8990558832883835.pypots
2024-05-25 01:56:08 [INFO]: Epoch 057 - training loss: 0.8071, validation loss: 0.8991
2024-05-25 01:56:08 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch57_loss0.8991157710552216.pypots
2024-05-25 01:56:08 [INFO]: Epoch 058 - training loss: 0.7835, validation loss: 0.8958
2024-05-25 01:56:08 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch58_loss0.8957553654909134.pypots
2024-05-25 01:56:08 [INFO]: Epoch 059 - training loss: 0.8066, validation loss: 0.8960
2024-05-25 01:56:08 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch59_loss0.8960370719432831.pypots
2024-05-25 01:56:08 [INFO]: Epoch 060 - training loss: 0.7911, validation loss: 0.8958
2024-05-25 01:56:08 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch60_loss0.8958473354578018.pypots
2024-05-25 01:56:08 [INFO]: Epoch 061 - training loss: 0.7945, validation loss: 0.8929
2024-05-25 01:56:08 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch61_loss0.8929103165864944.pypots
2024-05-25 01:56:09 [INFO]: Epoch 062 - training loss: 0.7860, validation loss: 0.8949
2024-05-25 01:56:09 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch62_loss0.8949378728866577.pypots
2024-05-25 01:56:09 [INFO]: Epoch 063 - training loss: 0.7952, validation loss: 0.8914
2024-05-25 01:56:09 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch63_loss0.8914181739091873.pypots
2024-05-25 01:56:09 [INFO]: Epoch 064 - training loss: 0.8188, validation loss: 0.8946
2024-05-25 01:56:09 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch64_loss0.8946057707071304.pypots
2024-05-25 01:56:09 [INFO]: Epoch 065 - training loss: 0.8313, validation loss: 0.8874
2024-05-25 01:56:09 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch65_loss0.8873597085475922.pypots
2024-05-25 01:56:09 [INFO]: Epoch 066 - training loss: 0.7772, validation loss: 0.8879
2024-05-25 01:56:09 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch66_loss0.887917086482048.pypots
2024-05-25 01:56:10 [INFO]: Epoch 067 - training loss: 0.8003, validation loss: 0.8871
2024-05-25 01:56:10 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch67_loss0.8870608657598495.pypots
2024-05-25 01:56:10 [INFO]: Epoch 068 - training loss: 0.7888, validation loss: 0.8831
2024-05-25 01:56:10 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch68_loss0.8831191956996918.pypots
2024-05-25 01:56:10 [INFO]: Epoch 069 - training loss: 0.7677, validation loss: 0.8829
2024-05-25 01:56:10 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch69_loss0.8829253017902374.pypots
2024-05-25 01:56:10 [INFO]: Epoch 070 - training loss: 0.8045, validation loss: 0.8816
2024-05-25 01:56:10 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch70_loss0.8815936744213104.pypots
2024-05-25 01:56:10 [INFO]: Epoch 071 - training loss: 0.7971, validation loss: 0.8810
2024-05-25 01:56:10 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch71_loss0.8810047954320908.pypots
2024-05-25 01:56:10 [INFO]: Epoch 072 - training loss: 0.7969, validation loss: 0.8811
2024-05-25 01:56:10 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch72_loss0.88106369972229.pypots
2024-05-25 01:56:11 [INFO]: Epoch 073 - training loss: 0.8083, validation loss: 0.8803
2024-05-25 01:56:11 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch73_loss0.8803027868270874.pypots
2024-05-25 01:56:11 [INFO]: Epoch 074 - training loss: 0.8373, validation loss: 0.8786
2024-05-25 01:56:11 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch74_loss0.8786096721887589.pypots
2024-05-25 01:56:11 [INFO]: Epoch 075 - training loss: 0.8051, validation loss: 0.8790
2024-05-25 01:56:11 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch75_loss0.8789511770009995.pypots
2024-05-25 01:56:11 [INFO]: Epoch 076 - training loss: 0.7988, validation loss: 0.8806
2024-05-25 01:56:11 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch76_loss0.8805831521749496.pypots
2024-05-25 01:56:11 [INFO]: Epoch 077 - training loss: 0.7867, validation loss: 0.8785
2024-05-25 01:56:11 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch77_loss0.8785072565078735.pypots
2024-05-25 01:56:12 [INFO]: Epoch 078 - training loss: 0.7790, validation loss: 0.8778
2024-05-25 01:56:12 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch78_loss0.8778274357318878.pypots
2024-05-25 01:56:12 [INFO]: Epoch 079 - training loss: 0.7810, validation loss: 0.8771
2024-05-25 01:56:12 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch79_loss0.8770776242017746.pypots
2024-05-25 01:56:12 [INFO]: Epoch 080 - training loss: 0.7744, validation loss: 0.8766
2024-05-25 01:56:12 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch80_loss0.876609280705452.pypots
2024-05-25 01:56:12 [INFO]: Epoch 081 - training loss: 0.7975, validation loss: 0.8762
2024-05-25 01:56:12 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch81_loss0.8762236535549164.pypots
2024-05-25 01:56:12 [INFO]: Epoch 082 - training loss: 0.7887, validation loss: 0.8733
2024-05-25 01:56:12 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch82_loss0.8732515573501587.pypots
2024-05-25 01:56:13 [INFO]: Epoch 083 - training loss: 0.7811, validation loss: 0.8736
2024-05-25 01:56:13 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch83_loss0.8736433833837509.pypots
2024-05-25 01:56:13 [INFO]: Epoch 084 - training loss: 0.7814, validation loss: 0.8723
2024-05-25 01:56:13 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch84_loss0.8723430335521698.pypots
2024-05-25 01:56:13 [INFO]: Epoch 085 - training loss: 0.7706, validation loss: 0.8715
2024-05-25 01:56:13 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch85_loss0.8715432584285736.pypots
2024-05-25 01:56:13 [INFO]: Epoch 086 - training loss: 0.7948, validation loss: 0.8744
2024-05-25 01:56:13 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch86_loss0.8743971139192581.pypots
2024-05-25 01:56:13 [INFO]: Epoch 087 - training loss: 0.7757, validation loss: 0.8704
2024-05-25 01:56:13 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch87_loss0.8704107403755188.pypots
2024-05-25 01:56:13 [INFO]: Epoch 088 - training loss: 0.7673, validation loss: 0.8714
2024-05-25 01:56:13 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch88_loss0.8713919520378113.pypots
2024-05-25 01:56:14 [INFO]: Epoch 089 - training loss: 0.7934, validation loss: 0.8721
2024-05-25 01:56:14 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch89_loss0.872078612446785.pypots
2024-05-25 01:56:14 [INFO]: Epoch 090 - training loss: 0.7870, validation loss: 0.8729
2024-05-25 01:56:14 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch90_loss0.8728999048471451.pypots
2024-05-25 01:56:14 [INFO]: Epoch 091 - training loss: 0.7920, validation loss: 0.8704
2024-05-25 01:56:14 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch91_loss0.8703990131616592.pypots
2024-05-25 01:56:14 [INFO]: Epoch 092 - training loss: 0.7843, validation loss: 0.8677
2024-05-25 01:56:14 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch92_loss0.8677048981189728.pypots
2024-05-25 01:56:14 [INFO]: Epoch 093 - training loss: 0.7915, validation loss: 0.8702
2024-05-25 01:56:14 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch93_loss0.8702405989170074.pypots
2024-05-25 01:56:15 [INFO]: Epoch 094 - training loss: 0.7911, validation loss: 0.8691
2024-05-25 01:56:15 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch94_loss0.8691237419843674.pypots
2024-05-25 01:56:15 [INFO]: Epoch 095 - training loss: 0.7893, validation loss: 0.8697
2024-05-25 01:56:15 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch95_loss0.8696774989366531.pypots
2024-05-25 01:56:15 [INFO]: Epoch 096 - training loss: 0.7872, validation loss: 0.8683
2024-05-25 01:56:15 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch96_loss0.8683348596096039.pypots
2024-05-25 01:56:15 [INFO]: Epoch 097 - training loss: 0.7726, validation loss: 0.8690
2024-05-25 01:56:15 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch97_loss0.869049608707428.pypots
2024-05-25 01:56:15 [INFO]: Epoch 098 - training loss: 0.7874, validation loss: 0.8684
2024-05-25 01:56:15 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch98_loss0.8684293627738953.pypots
2024-05-25 01:56:16 [INFO]: Epoch 099 - training loss: 0.7722, validation loss: 0.8684
2024-05-25 01:56:16 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch99_loss0.8684310764074326.pypots
2024-05-25 01:56:16 [INFO]: Epoch 100 - training loss: 0.7602, validation loss: 0.8694
2024-05-25 01:56:16 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch100_loss0.8694118410348892.pypots
2024-05-25 01:56:16 [INFO]: Epoch 101 - training loss: 0.7877, validation loss: 0.8695
2024-05-25 01:56:16 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch101_loss0.8695114552974701.pypots
2024-05-25 01:56:16 [INFO]: Epoch 102 - training loss: 0.7835, validation loss: 0.8680
2024-05-25 01:56:16 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN_epoch102_loss0.8679649978876114.pypots
2024-05-25 01:56:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:56:16 [INFO]: Finished training. The best model is from epoch#92.
2024-05-25 01:56:16 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015555/MRNN.pypots
2024-05-25 01:56:16 [INFO]: MRNN on ETTm1: MAE=0.7762, MSE=1.3599
2024-05-25 01:56:16 [INFO]: Successfully saved to augmentation_saved_results/round_1/MRNN_ettm1/imputation.pkl
2024-05-25 01:56:16 [INFO]: Using the given device: cpu
2024-05-25 01:56:16 [INFO]: LOCF on ETTm1: MAE=0.1348, MSE=0.0715
2024-05-25 01:56:16 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_ettm1".
2024-05-25 01:56:16 [INFO]: Successfully saved to augmentation_saved_results/round_1/LOCF_ettm1/imputation.pkl
2024-05-25 01:56:16 [INFO]: Median on ETTm1: MAE=0.6516, MSE=0.8223
2024-05-25 01:56:16 [INFO]: Successfully created the given path "saved_results/round_1/Median_ettm1".
2024-05-25 01:56:16 [INFO]: Successfully saved to augmentation_saved_results/round_1/Median_ettm1/imputation.pkl
2024-05-25 01:56:16 [INFO]: Mean on ETTm1: MAE=0.6566, MSE=0.8036
2024-05-25 01:56:16 [INFO]: Successfully created the given path "saved_results/round_1/Mean_ettm1".
2024-05-25 01:56:16 [INFO]: Successfully saved to augmentation_saved_results/round_1/Mean_ettm1/imputation.pkl
2024-05-25 01:56:17 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-25 01:56:17 [INFO]: Using the given device: cuda:0
2024-05-25 01:56:17 [INFO]: Model files will be saved to augmentation_saved_results/round_2/SAITS_ettm1/20240525_T015617
2024-05-25 01:56:17 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/SAITS_ettm1/20240525_T015617/tensorboard
2024-05-25 01:56:17 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 01:56:17 [INFO]: Epoch 001 - training loss: 1.1726, validation loss: 0.2631
2024-05-25 01:56:18 [INFO]: Epoch 002 - training loss: 0.8340, validation loss: 0.1301
2024-05-25 01:56:18 [INFO]: Epoch 003 - training loss: 0.7218, validation loss: 0.1351
2024-05-25 01:56:19 [INFO]: Epoch 004 - training loss: 0.6632, validation loss: 0.0946
2024-05-25 01:56:19 [INFO]: Epoch 005 - training loss: 0.6368, validation loss: 0.0780
2024-05-25 01:56:20 [INFO]: Epoch 006 - training loss: 0.5864, validation loss: 0.0850
2024-05-25 01:56:20 [INFO]: Epoch 007 - training loss: 0.5707, validation loss: 0.0837
2024-05-25 01:56:21 [INFO]: Epoch 008 - training loss: 0.5508, validation loss: 0.0605
2024-05-25 01:56:21 [INFO]: Epoch 009 - training loss: 0.5599, validation loss: 0.0661
2024-05-25 01:56:22 [INFO]: Epoch 010 - training loss: 0.5495, validation loss: 0.0679
2024-05-25 01:56:22 [INFO]: Epoch 011 - training loss: 0.5219, validation loss: 0.0790
2024-05-25 01:56:23 [INFO]: Epoch 012 - training loss: 0.5100, validation loss: 0.0704
2024-05-25 01:56:23 [INFO]: Epoch 013 - training loss: 0.4987, validation loss: 0.0597
2024-05-25 01:56:24 [INFO]: Epoch 014 - training loss: 0.4774, validation loss: 0.0643
2024-05-25 01:56:24 [INFO]: Epoch 015 - training loss: 0.4875, validation loss: 0.0585
2024-05-25 01:56:25 [INFO]: Epoch 016 - training loss: 0.4700, validation loss: 0.0542
2024-05-25 01:56:25 [INFO]: Epoch 017 - training loss: 0.4723, validation loss: 0.0526
2024-05-25 01:56:26 [INFO]: Epoch 018 - training loss: 0.4616, validation loss: 0.0433
2024-05-25 01:56:26 [INFO]: Epoch 019 - training loss: 0.4397, validation loss: 0.0414
2024-05-25 01:56:27 [INFO]: Epoch 020 - training loss: 0.4353, validation loss: 0.0502
2024-05-25 01:56:27 [INFO]: Epoch 021 - training loss: 0.4452, validation loss: 0.0515
2024-05-25 01:56:28 [INFO]: Epoch 022 - training loss: 0.4379, validation loss: 0.0370
2024-05-25 01:56:28 [INFO]: Epoch 023 - training loss: 0.4253, validation loss: 0.0461
2024-05-25 01:56:29 [INFO]: Epoch 024 - training loss: 0.4154, validation loss: 0.0469
2024-05-25 01:56:29 [INFO]: Epoch 025 - training loss: 0.4101, validation loss: 0.0434
2024-05-25 01:56:30 [INFO]: Epoch 026 - training loss: 0.4304, validation loss: 0.0452
2024-05-25 01:56:30 [INFO]: Epoch 027 - training loss: 0.4161, validation loss: 0.0550
2024-05-25 01:56:31 [INFO]: Epoch 028 - training loss: 0.4150, validation loss: 0.0452
2024-05-25 01:56:31 [INFO]: Epoch 029 - training loss: 0.3948, validation loss: 0.0413
2024-05-25 01:56:32 [INFO]: Epoch 030 - training loss: 0.3967, validation loss: 0.0453
2024-05-25 01:56:32 [INFO]: Epoch 031 - training loss: 0.3817, validation loss: 0.0331
2024-05-25 01:56:33 [INFO]: Epoch 032 - training loss: 0.3835, validation loss: 0.0340
2024-05-25 01:56:33 [INFO]: Epoch 033 - training loss: 0.3768, validation loss: 0.0443
2024-05-25 01:56:34 [INFO]: Epoch 034 - training loss: 0.3683, validation loss: 0.0354
2024-05-25 01:56:35 [INFO]: Epoch 035 - training loss: 0.3627, validation loss: 0.0370
2024-05-25 01:56:35 [INFO]: Epoch 036 - training loss: 0.3555, validation loss: 0.0317
2024-05-25 01:56:36 [INFO]: Epoch 037 - training loss: 0.3614, validation loss: 0.0315
2024-05-25 01:56:36 [INFO]: Epoch 038 - training loss: 0.3910, validation loss: 0.0351
2024-05-25 01:56:37 [INFO]: Epoch 039 - training loss: 0.3963, validation loss: 0.0453
2024-05-25 01:56:37 [INFO]: Epoch 040 - training loss: 0.3705, validation loss: 0.0402
2024-05-25 01:56:38 [INFO]: Epoch 041 - training loss: 0.3691, validation loss: 0.0421
2024-05-25 01:56:38 [INFO]: Epoch 042 - training loss: 0.3552, validation loss: 0.0341
2024-05-25 01:56:39 [INFO]: Epoch 043 - training loss: 0.3424, validation loss: 0.0297
2024-05-25 01:56:39 [INFO]: Epoch 044 - training loss: 0.3370, validation loss: 0.0427
2024-05-25 01:56:40 [INFO]: Epoch 045 - training loss: 0.3390, validation loss: 0.0339
2024-05-25 01:56:40 [INFO]: Epoch 046 - training loss: 0.3316, validation loss: 0.0417
2024-05-25 01:56:41 [INFO]: Epoch 047 - training loss: 0.3357, validation loss: 0.0349
2024-05-25 01:56:41 [INFO]: Epoch 048 - training loss: 0.3284, validation loss: 0.0296
2024-05-25 01:56:42 [INFO]: Epoch 049 - training loss: 0.3253, validation loss: 0.0324
2024-05-25 01:56:42 [INFO]: Epoch 050 - training loss: 0.3178, validation loss: 0.0357
2024-05-25 01:56:43 [INFO]: Epoch 051 - training loss: 0.3160, validation loss: 0.0309
2024-05-25 01:56:43 [INFO]: Epoch 052 - training loss: 0.3157, validation loss: 0.0278
2024-05-25 01:56:44 [INFO]: Epoch 053 - training loss: 0.3127, validation loss: 0.0261
2024-05-25 01:56:44 [INFO]: Epoch 054 - training loss: 0.3140, validation loss: 0.0271
2024-05-25 01:56:45 [INFO]: Epoch 055 - training loss: 0.3121, validation loss: 0.0316
2024-05-25 01:56:45 [INFO]: Epoch 056 - training loss: 0.3208, validation loss: 0.0362
2024-05-25 01:56:46 [INFO]: Epoch 057 - training loss: 0.3205, validation loss: 0.0337
2024-05-25 01:56:46 [INFO]: Epoch 058 - training loss: 0.3066, validation loss: 0.0329
2024-05-25 01:56:47 [INFO]: Epoch 059 - training loss: 0.3072, validation loss: 0.0285
2024-05-25 01:56:47 [INFO]: Epoch 060 - training loss: 0.3033, validation loss: 0.0306
2024-05-25 01:56:48 [INFO]: Epoch 061 - training loss: 0.3055, validation loss: 0.0369
2024-05-25 01:56:48 [INFO]: Epoch 062 - training loss: 0.3046, validation loss: 0.0393
2024-05-25 01:56:49 [INFO]: Epoch 063 - training loss: 0.3103, validation loss: 0.0374
2024-05-25 01:56:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:56:49 [INFO]: Finished training. The best model is from epoch#53.
2024-05-25 01:56:49 [INFO]: Saved the model to augmentation_saved_results/round_2/SAITS_ettm1/20240525_T015617/SAITS.pypots
2024-05-25 01:56:49 [INFO]: SAITS on ETTm1: MAE=0.1449, MSE=0.0482
2024-05-25 01:56:49 [INFO]: Successfully saved to augmentation_saved_results/round_2/SAITS_ettm1/imputation.pkl
2024-05-25 01:56:49 [INFO]: Using the given device: cuda:0
2024-05-25 01:56:49 [INFO]: Model files will be saved to augmentation_saved_results/round_2/Transformer_ettm1/20240525_T015649
2024-05-25 01:56:49 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/Transformer_ettm1/20240525_T015649/tensorboard
2024-05-25 01:56:49 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 01:56:49 [INFO]: Epoch 001 - training loss: 1.2086, validation loss: 0.3732
2024-05-25 01:56:49 [INFO]: Epoch 002 - training loss: 0.7449, validation loss: 0.1455
2024-05-25 01:56:50 [INFO]: Epoch 003 - training loss: 0.6105, validation loss: 0.1145
2024-05-25 01:56:50 [INFO]: Epoch 004 - training loss: 0.5434, validation loss: 0.0950
2024-05-25 01:56:50 [INFO]: Epoch 005 - training loss: 0.4977, validation loss: 0.0731
2024-05-25 01:56:50 [INFO]: Epoch 006 - training loss: 0.4668, validation loss: 0.0684
2024-05-25 01:56:50 [INFO]: Epoch 007 - training loss: 0.4481, validation loss: 0.0593
2024-05-25 01:56:51 [INFO]: Epoch 008 - training loss: 0.4309, validation loss: 0.0542
2024-05-25 01:56:51 [INFO]: Epoch 009 - training loss: 0.4063, validation loss: 0.0491
2024-05-25 01:56:51 [INFO]: Epoch 010 - training loss: 0.3925, validation loss: 0.0515
2024-05-25 01:56:51 [INFO]: Epoch 011 - training loss: 0.3864, validation loss: 0.0530
2024-05-25 01:56:52 [INFO]: Epoch 012 - training loss: 0.3722, validation loss: 0.0499
2024-05-25 01:56:52 [INFO]: Epoch 013 - training loss: 0.3642, validation loss: 0.0450
2024-05-25 01:56:52 [INFO]: Epoch 014 - training loss: 0.3599, validation loss: 0.0507
2024-05-25 01:56:52 [INFO]: Epoch 015 - training loss: 0.3450, validation loss: 0.0389
2024-05-25 01:56:52 [INFO]: Epoch 016 - training loss: 0.3403, validation loss: 0.0492
2024-05-25 01:56:53 [INFO]: Epoch 017 - training loss: 0.3383, validation loss: 0.0369
2024-05-25 01:56:53 [INFO]: Epoch 018 - training loss: 0.3339, validation loss: 0.0402
2024-05-25 01:56:53 [INFO]: Epoch 019 - training loss: 0.3224, validation loss: 0.0345
2024-05-25 01:56:53 [INFO]: Epoch 020 - training loss: 0.3194, validation loss: 0.0561
2024-05-25 01:56:54 [INFO]: Epoch 021 - training loss: 0.3309, validation loss: 0.0344
2024-05-25 01:56:54 [INFO]: Epoch 022 - training loss: 0.3093, validation loss: 0.0412
2024-05-25 01:56:54 [INFO]: Epoch 023 - training loss: 0.3058, validation loss: 0.0321
2024-05-25 01:56:54 [INFO]: Epoch 024 - training loss: 0.3082, validation loss: 0.0338
2024-05-25 01:56:54 [INFO]: Epoch 025 - training loss: 0.2935, validation loss: 0.0350
2024-05-25 01:56:55 [INFO]: Epoch 026 - training loss: 0.2973, validation loss: 0.0336
2024-05-25 01:56:55 [INFO]: Epoch 027 - training loss: 0.2914, validation loss: 0.0332
2024-05-25 01:56:55 [INFO]: Epoch 028 - training loss: 0.2877, validation loss: 0.0355
2024-05-25 01:56:55 [INFO]: Epoch 029 - training loss: 0.2812, validation loss: 0.0322
2024-05-25 01:56:55 [INFO]: Epoch 030 - training loss: 0.2783, validation loss: 0.0307
2024-05-25 01:56:56 [INFO]: Epoch 031 - training loss: 0.2791, validation loss: 0.0284
2024-05-25 01:56:56 [INFO]: Epoch 032 - training loss: 0.2855, validation loss: 0.0286
2024-05-25 01:56:56 [INFO]: Epoch 033 - training loss: 0.2693, validation loss: 0.0374
2024-05-25 01:56:56 [INFO]: Epoch 034 - training loss: 0.2708, validation loss: 0.0344
2024-05-25 01:56:57 [INFO]: Epoch 035 - training loss: 0.2708, validation loss: 0.0294
2024-05-25 01:56:57 [INFO]: Epoch 036 - training loss: 0.2583, validation loss: 0.0305
2024-05-25 01:56:57 [INFO]: Epoch 037 - training loss: 0.2662, validation loss: 0.0296
2024-05-25 01:56:57 [INFO]: Epoch 038 - training loss: 0.2595, validation loss: 0.0312
2024-05-25 01:56:57 [INFO]: Epoch 039 - training loss: 0.2551, validation loss: 0.0332
2024-05-25 01:56:58 [INFO]: Epoch 040 - training loss: 0.2553, validation loss: 0.0318
2024-05-25 01:56:58 [INFO]: Epoch 041 - training loss: 0.2597, validation loss: 0.0281
2024-05-25 01:56:58 [INFO]: Epoch 042 - training loss: 0.2492, validation loss: 0.0246
2024-05-25 01:56:58 [INFO]: Epoch 043 - training loss: 0.2448, validation loss: 0.0248
2024-05-25 01:56:59 [INFO]: Epoch 044 - training loss: 0.2431, validation loss: 0.0348
2024-05-25 01:56:59 [INFO]: Epoch 045 - training loss: 0.2526, validation loss: 0.0314
2024-05-25 01:56:59 [INFO]: Epoch 046 - training loss: 0.2379, validation loss: 0.0323
2024-05-25 01:56:59 [INFO]: Epoch 047 - training loss: 0.2437, validation loss: 0.0275
2024-05-25 01:56:59 [INFO]: Epoch 048 - training loss: 0.2408, validation loss: 0.0236
2024-05-25 01:57:00 [INFO]: Epoch 049 - training loss: 0.2410, validation loss: 0.0296
2024-05-25 01:57:00 [INFO]: Epoch 050 - training loss: 0.2331, validation loss: 0.0235
2024-05-25 01:57:00 [INFO]: Epoch 051 - training loss: 0.2331, validation loss: 0.0223
2024-05-25 01:57:00 [INFO]: Epoch 052 - training loss: 0.2302, validation loss: 0.0264
2024-05-25 01:57:00 [INFO]: Epoch 053 - training loss: 0.2289, validation loss: 0.0250
2024-05-25 01:57:01 [INFO]: Epoch 054 - training loss: 0.2264, validation loss: 0.0308
2024-05-25 01:57:01 [INFO]: Epoch 055 - training loss: 0.2240, validation loss: 0.0219
2024-05-25 01:57:01 [INFO]: Epoch 056 - training loss: 0.2258, validation loss: 0.0251
2024-05-25 01:57:01 [INFO]: Epoch 057 - training loss: 0.2417, validation loss: 0.0303
2024-05-25 01:57:02 [INFO]: Epoch 058 - training loss: 0.2316, validation loss: 0.0248
2024-05-25 01:57:02 [INFO]: Epoch 059 - training loss: 0.2243, validation loss: 0.0251
2024-05-25 01:57:02 [INFO]: Epoch 060 - training loss: 0.2240, validation loss: 0.0210
2024-05-25 01:57:02 [INFO]: Epoch 061 - training loss: 0.2170, validation loss: 0.0223
2024-05-25 01:57:02 [INFO]: Epoch 062 - training loss: 0.2163, validation loss: 0.0226
2024-05-25 01:57:03 [INFO]: Epoch 063 - training loss: 0.2200, validation loss: 0.0256
2024-05-25 01:57:03 [INFO]: Epoch 064 - training loss: 0.2391, validation loss: 0.0264
2024-05-25 01:57:03 [INFO]: Epoch 065 - training loss: 0.2267, validation loss: 0.0200
2024-05-25 01:57:03 [INFO]: Epoch 066 - training loss: 0.2158, validation loss: 0.0281
2024-05-25 01:57:04 [INFO]: Epoch 067 - training loss: 0.2142, validation loss: 0.0252
2024-05-25 01:57:04 [INFO]: Epoch 068 - training loss: 0.2146, validation loss: 0.0282
2024-05-25 01:57:04 [INFO]: Epoch 069 - training loss: 0.2192, validation loss: 0.0202
2024-05-25 01:57:04 [INFO]: Epoch 070 - training loss: 0.2113, validation loss: 0.0229
2024-05-25 01:57:04 [INFO]: Epoch 071 - training loss: 0.2132, validation loss: 0.0223
2024-05-25 01:57:05 [INFO]: Epoch 072 - training loss: 0.2091, validation loss: 0.0263
2024-05-25 01:57:05 [INFO]: Epoch 073 - training loss: 0.2132, validation loss: 0.0249
2024-05-25 01:57:05 [INFO]: Epoch 074 - training loss: 0.2081, validation loss: 0.0240
2024-05-25 01:57:05 [INFO]: Epoch 075 - training loss: 0.2039, validation loss: 0.0241
2024-05-25 01:57:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:57:05 [INFO]: Finished training. The best model is from epoch#65.
2024-05-25 01:57:05 [INFO]: Saved the model to augmentation_saved_results/round_2/Transformer_ettm1/20240525_T015649/Transformer.pypots
2024-05-25 01:57:05 [INFO]: Transformer on ETTm1: MAE=0.1226, MSE=0.0291
2024-05-25 01:57:05 [INFO]: Successfully saved to augmentation_saved_results/round_2/Transformer_ettm1/imputation.pkl
2024-05-25 01:57:05 [INFO]: Using the given device: cuda:0
2024-05-25 01:57:05 [INFO]: Model files will be saved to augmentation_saved_results/round_2/TimesNet_ettm1/20240525_T015705
2024-05-25 01:57:05 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/TimesNet_ettm1/20240525_T015705/tensorboard
2024-05-25 01:57:06 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 01:57:06 [INFO]: Epoch 001 - training loss: 0.1535, validation loss: 0.0520
2024-05-25 01:57:06 [INFO]: Epoch 002 - training loss: 0.0644, validation loss: 0.0363
2024-05-25 01:57:06 [INFO]: Epoch 003 - training loss: 0.0506, validation loss: 0.0311
2024-05-25 01:57:06 [INFO]: Epoch 004 - training loss: 0.0481, validation loss: 0.0310
2024-05-25 01:57:07 [INFO]: Epoch 005 - training loss: 0.0467, validation loss: 0.0327
2024-05-25 01:57:07 [INFO]: Epoch 006 - training loss: 0.0467, validation loss: 0.0315
2024-05-25 01:57:07 [INFO]: Epoch 007 - training loss: 0.0471, validation loss: 0.0322
2024-05-25 01:57:07 [INFO]: Epoch 008 - training loss: 0.0499, validation loss: 0.0311
2024-05-25 01:57:07 [INFO]: Epoch 009 - training loss: 0.0454, validation loss: 0.0287
2024-05-25 01:57:08 [INFO]: Epoch 010 - training loss: 0.0428, validation loss: 0.0265
2024-05-25 01:57:08 [INFO]: Epoch 011 - training loss: 0.0418, validation loss: 0.0273
2024-05-25 01:57:08 [INFO]: Epoch 012 - training loss: 0.0413, validation loss: 0.0264
2024-05-25 01:57:08 [INFO]: Epoch 013 - training loss: 0.0425, validation loss: 0.0287
2024-05-25 01:57:08 [INFO]: Epoch 014 - training loss: 0.0431, validation loss: 0.0265
2024-05-25 01:57:09 [INFO]: Epoch 015 - training loss: 0.0438, validation loss: 0.0269
2024-05-25 01:57:09 [INFO]: Epoch 016 - training loss: 0.0410, validation loss: 0.0286
2024-05-25 01:57:09 [INFO]: Epoch 017 - training loss: 0.0414, validation loss: 0.0265
2024-05-25 01:57:09 [INFO]: Epoch 018 - training loss: 0.0428, validation loss: 0.0296
2024-05-25 01:57:10 [INFO]: Epoch 019 - training loss: 0.0446, validation loss: 0.0249
2024-05-25 01:57:10 [INFO]: Epoch 020 - training loss: 0.0415, validation loss: 0.0278
2024-05-25 01:57:10 [INFO]: Epoch 021 - training loss: 0.0407, validation loss: 0.0253
2024-05-25 01:57:10 [INFO]: Epoch 022 - training loss: 0.0436, validation loss: 0.0316
2024-05-25 01:57:10 [INFO]: Epoch 023 - training loss: 0.0454, validation loss: 0.0264
2024-05-25 01:57:11 [INFO]: Epoch 024 - training loss: 0.0400, validation loss: 0.0256
2024-05-25 01:57:11 [INFO]: Epoch 025 - training loss: 0.0385, validation loss: 0.0249
2024-05-25 01:57:11 [INFO]: Epoch 026 - training loss: 0.0409, validation loss: 0.0267
2024-05-25 01:57:11 [INFO]: Epoch 027 - training loss: 0.0410, validation loss: 0.0283
2024-05-25 01:57:11 [INFO]: Epoch 028 - training loss: 0.0412, validation loss: 0.0287
2024-05-25 01:57:12 [INFO]: Epoch 029 - training loss: 0.0371, validation loss: 0.0252
2024-05-25 01:57:12 [INFO]: Epoch 030 - training loss: 0.0368, validation loss: 0.0240
2024-05-25 01:57:12 [INFO]: Epoch 031 - training loss: 0.0364, validation loss: 0.0249
2024-05-25 01:57:12 [INFO]: Epoch 032 - training loss: 0.0381, validation loss: 0.0285
2024-05-25 01:57:13 [INFO]: Epoch 033 - training loss: 0.0444, validation loss: 0.0295
2024-05-25 01:57:13 [INFO]: Epoch 034 - training loss: 0.0420, validation loss: 0.0258
2024-05-25 01:57:13 [INFO]: Epoch 035 - training loss: 0.0393, validation loss: 0.0254
2024-05-25 01:57:13 [INFO]: Epoch 036 - training loss: 0.0402, validation loss: 0.0256
2024-05-25 01:57:13 [INFO]: Epoch 037 - training loss: 0.0363, validation loss: 0.0246
2024-05-25 01:57:14 [INFO]: Epoch 038 - training loss: 0.0390, validation loss: 0.0238
2024-05-25 01:57:14 [INFO]: Epoch 039 - training loss: 0.0367, validation loss: 0.0246
2024-05-25 01:57:14 [INFO]: Epoch 040 - training loss: 0.0347, validation loss: 0.0233
2024-05-25 01:57:14 [INFO]: Epoch 041 - training loss: 0.0348, validation loss: 0.0227
2024-05-25 01:57:14 [INFO]: Epoch 042 - training loss: 0.0342, validation loss: 0.0220
2024-05-25 01:57:15 [INFO]: Epoch 043 - training loss: 0.0345, validation loss: 0.0219
2024-05-25 01:57:15 [INFO]: Epoch 044 - training loss: 0.0339, validation loss: 0.0245
2024-05-25 01:57:15 [INFO]: Epoch 045 - training loss: 0.0344, validation loss: 0.0246
2024-05-25 01:57:15 [INFO]: Epoch 046 - training loss: 0.2948, validation loss: 0.0220
2024-05-25 01:57:15 [INFO]: Epoch 047 - training loss: 0.0523, validation loss: 0.0323
2024-05-25 01:57:16 [INFO]: Epoch 048 - training loss: 0.0444, validation loss: 0.0266
2024-05-25 01:57:16 [INFO]: Epoch 049 - training loss: 0.0409, validation loss: 0.0267
2024-05-25 01:57:16 [INFO]: Epoch 050 - training loss: 0.0391, validation loss: 0.0239
2024-05-25 01:57:16 [INFO]: Epoch 051 - training loss: 0.0368, validation loss: 0.0244
2024-05-25 01:57:17 [INFO]: Epoch 052 - training loss: 0.0377, validation loss: 0.0245
2024-05-25 01:57:17 [INFO]: Epoch 053 - training loss: 0.0358, validation loss: 0.0249
2024-05-25 01:57:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:57:17 [INFO]: Finished training. The best model is from epoch#43.
2024-05-25 01:57:17 [INFO]: Saved the model to augmentation_saved_results/round_2/TimesNet_ettm1/20240525_T015705/TimesNet.pypots
2024-05-25 01:57:17 [INFO]: TimesNet on ETTm1: MAE=0.1150, MSE=0.0276
2024-05-25 01:57:17 [INFO]: Successfully saved to augmentation_saved_results/round_2/TimesNet_ettm1/imputation.pkl
2024-05-25 01:57:17 [INFO]: Using the given device: cuda:0
2024-05-25 01:57:17 [INFO]: Model files will be saved to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717
2024-05-25 01:57:17 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/tensorboard
2024-05-25 01:57:17 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 01:57:19 [INFO]: Epoch 001 - training loss: 0.6937, validation loss: 0.4346
2024-05-25 01:57:19 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch1_loss0.43455497920513153.pypots
2024-05-25 01:57:21 [INFO]: Epoch 002 - training loss: 0.3918, validation loss: 0.3666
2024-05-25 01:57:21 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch2_loss0.3665992245078087.pypots
2024-05-25 01:57:23 [INFO]: Epoch 003 - training loss: 0.3713, validation loss: 0.3544
2024-05-25 01:57:23 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch3_loss0.3543533831834793.pypots
2024-05-25 01:57:25 [INFO]: Epoch 004 - training loss: 0.3633, validation loss: 0.3292
2024-05-25 01:57:25 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch4_loss0.32919904589653015.pypots
2024-05-25 01:57:27 [INFO]: Epoch 005 - training loss: 0.2774, validation loss: 0.3099
2024-05-25 01:57:27 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch5_loss0.309939906001091.pypots
2024-05-25 01:57:29 [INFO]: Epoch 006 - training loss: 0.2328, validation loss: 0.2988
2024-05-25 01:57:29 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch6_loss0.29878246784210205.pypots
2024-05-25 01:57:31 [INFO]: Epoch 007 - training loss: 0.2652, validation loss: 0.2680
2024-05-25 01:57:31 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch7_loss0.2680091932415962.pypots
2024-05-25 01:57:34 [INFO]: Epoch 008 - training loss: 0.2962, validation loss: 0.2702
2024-05-25 01:57:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch8_loss0.2702063024044037.pypots
2024-05-25 01:57:36 [INFO]: Epoch 009 - training loss: 0.2489, validation loss: 0.2711
2024-05-25 01:57:36 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch9_loss0.27111272513866425.pypots
2024-05-25 01:57:38 [INFO]: Epoch 010 - training loss: 0.2274, validation loss: 0.2480
2024-05-25 01:57:38 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch10_loss0.24800187349319458.pypots
2024-05-25 01:57:40 [INFO]: Epoch 011 - training loss: 0.2349, validation loss: 0.2493
2024-05-25 01:57:40 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch11_loss0.24933577328920364.pypots
2024-05-25 01:57:42 [INFO]: Epoch 012 - training loss: 0.2342, validation loss: 0.2437
2024-05-25 01:57:42 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch12_loss0.24366087466478348.pypots
2024-05-25 01:57:44 [INFO]: Epoch 013 - training loss: 0.2535, validation loss: 0.2235
2024-05-25 01:57:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch13_loss0.22345322370529175.pypots
2024-05-25 01:57:46 [INFO]: Epoch 014 - training loss: 0.2207, validation loss: 0.2114
2024-05-25 01:57:46 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch14_loss0.21138034388422966.pypots
2024-05-25 01:57:48 [INFO]: Epoch 015 - training loss: 0.2268, validation loss: 0.2140
2024-05-25 01:57:48 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch15_loss0.21399885416030884.pypots
2024-05-25 01:57:50 [INFO]: Epoch 016 - training loss: 0.2738, validation loss: 0.2237
2024-05-25 01:57:50 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch16_loss0.2236904576420784.pypots
2024-05-25 01:57:52 [INFO]: Epoch 017 - training loss: 0.2401, validation loss: 0.2204
2024-05-25 01:57:52 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch17_loss0.2204412817955017.pypots
2024-05-25 01:57:54 [INFO]: Epoch 018 - training loss: 0.2133, validation loss: 0.2012
2024-05-25 01:57:54 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch18_loss0.20119350403547287.pypots
2024-05-25 01:57:56 [INFO]: Epoch 019 - training loss: 0.2186, validation loss: 0.1976
2024-05-25 01:57:56 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch19_loss0.1975945420563221.pypots
2024-05-25 01:57:58 [INFO]: Epoch 020 - training loss: 0.2215, validation loss: 0.1883
2024-05-25 01:57:59 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch20_loss0.1882636994123459.pypots
2024-05-25 01:58:01 [INFO]: Epoch 021 - training loss: 0.2423, validation loss: 0.1911
2024-05-25 01:58:01 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch21_loss0.19107436016201973.pypots
2024-05-25 01:58:03 [INFO]: Epoch 022 - training loss: 0.1896, validation loss: 0.1934
2024-05-25 01:58:03 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch22_loss0.19341115280985832.pypots
2024-05-25 01:58:05 [INFO]: Epoch 023 - training loss: 0.1995, validation loss: 0.1903
2024-05-25 01:58:05 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch23_loss0.1903388351202011.pypots
2024-05-25 01:58:07 [INFO]: Epoch 024 - training loss: 0.2786, validation loss: 0.1862
2024-05-25 01:58:07 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch24_loss0.1862085685133934.pypots
2024-05-25 01:58:09 [INFO]: Epoch 025 - training loss: 0.2156, validation loss: 0.1834
2024-05-25 01:58:09 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch25_loss0.18335654214024544.pypots
2024-05-25 01:58:11 [INFO]: Epoch 026 - training loss: 0.1857, validation loss: 0.1894
2024-05-25 01:58:11 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch26_loss0.1894412524998188.pypots
2024-05-25 01:58:13 [INFO]: Epoch 027 - training loss: 0.2077, validation loss: 0.1694
2024-05-25 01:58:13 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch27_loss0.16936887428164482.pypots
2024-05-25 01:58:15 [INFO]: Epoch 028 - training loss: 0.1748, validation loss: 0.1672
2024-05-25 01:58:15 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch28_loss0.16720249503850937.pypots
2024-05-25 01:58:17 [INFO]: Epoch 029 - training loss: 0.1660, validation loss: 0.1708
2024-05-25 01:58:17 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch29_loss0.17078053206205368.pypots
2024-05-25 01:58:19 [INFO]: Epoch 030 - training loss: 0.1999, validation loss: 0.1703
2024-05-25 01:58:19 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch30_loss0.17032426595687866.pypots
2024-05-25 01:58:21 [INFO]: Epoch 031 - training loss: 0.1578, validation loss: 0.1651
2024-05-25 01:58:21 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch31_loss0.16511661931872368.pypots
2024-05-25 01:58:23 [INFO]: Epoch 032 - training loss: 0.1916, validation loss: 0.1677
2024-05-25 01:58:23 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch32_loss0.16773605346679688.pypots
2024-05-25 01:58:26 [INFO]: Epoch 033 - training loss: 0.1742, validation loss: 0.1612
2024-05-25 01:58:26 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch33_loss0.16119661927223206.pypots
2024-05-25 01:58:28 [INFO]: Epoch 034 - training loss: 0.1986, validation loss: 0.1555
2024-05-25 01:58:28 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch34_loss0.15548566728830338.pypots
2024-05-25 01:58:30 [INFO]: Epoch 035 - training loss: 0.1872, validation loss: 0.1529
2024-05-25 01:58:30 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch35_loss0.15293247625231743.pypots
2024-05-25 01:58:32 [INFO]: Epoch 036 - training loss: 0.2083, validation loss: 0.1721
2024-05-25 01:58:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch36_loss0.17206762731075287.pypots
2024-05-25 01:58:34 [INFO]: Epoch 037 - training loss: 0.1973, validation loss: 0.1614
2024-05-25 01:58:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch37_loss0.1613505259156227.pypots
2024-05-25 01:58:36 [INFO]: Epoch 038 - training loss: 0.1602, validation loss: 0.1570
2024-05-25 01:58:36 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch38_loss0.15703995898365974.pypots
2024-05-25 01:58:38 [INFO]: Epoch 039 - training loss: 0.1755, validation loss: 0.1587
2024-05-25 01:58:38 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch39_loss0.1586642786860466.pypots
2024-05-25 01:58:40 [INFO]: Epoch 040 - training loss: 0.1877, validation loss: 0.1517
2024-05-25 01:58:40 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch40_loss0.15172864124178886.pypots
2024-05-25 01:58:42 [INFO]: Epoch 041 - training loss: 0.1822, validation loss: 0.1504
2024-05-25 01:58:42 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch41_loss0.15043267235159874.pypots
2024-05-25 01:58:44 [INFO]: Epoch 042 - training loss: 0.1576, validation loss: 0.1465
2024-05-25 01:58:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch42_loss0.1465129815042019.pypots
2024-05-25 01:58:46 [INFO]: Epoch 043 - training loss: 0.1861, validation loss: 0.1443
2024-05-25 01:58:46 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch43_loss0.14434386789798737.pypots
2024-05-25 01:58:48 [INFO]: Epoch 044 - training loss: 0.1377, validation loss: 0.1488
2024-05-25 01:58:48 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch44_loss0.1488429382443428.pypots
2024-05-25 01:58:51 [INFO]: Epoch 045 - training loss: 0.1664, validation loss: 0.1429
2024-05-25 01:58:51 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch45_loss0.14285995066165924.pypots
2024-05-25 01:58:53 [INFO]: Epoch 046 - training loss: 0.1745, validation loss: 0.1600
2024-05-25 01:58:53 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch46_loss0.15998103097081184.pypots
2024-05-25 01:58:55 [INFO]: Epoch 047 - training loss: 0.1931, validation loss: 0.1596
2024-05-25 01:58:55 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch47_loss0.15963031724095345.pypots
2024-05-25 01:58:57 [INFO]: Epoch 048 - training loss: 0.1810, validation loss: 0.1440
2024-05-25 01:58:57 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch48_loss0.14403565600514412.pypots
2024-05-25 01:58:59 [INFO]: Epoch 049 - training loss: 0.1708, validation loss: 0.1527
2024-05-25 01:58:59 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch49_loss0.15270576998591423.pypots
2024-05-25 01:59:01 [INFO]: Epoch 050 - training loss: 0.1681, validation loss: 0.1378
2024-05-25 01:59:01 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch50_loss0.13782527670264244.pypots
2024-05-25 01:59:03 [INFO]: Epoch 051 - training loss: 0.1609, validation loss: 0.1378
2024-05-25 01:59:03 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch51_loss0.13776247948408127.pypots
2024-05-25 01:59:05 [INFO]: Epoch 052 - training loss: 0.1608, validation loss: 0.1423
2024-05-25 01:59:05 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch52_loss0.14231397584080696.pypots
2024-05-25 01:59:07 [INFO]: Epoch 053 - training loss: 0.1570, validation loss: 0.1442
2024-05-25 01:59:07 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch53_loss0.14422354847192764.pypots
2024-05-25 01:59:09 [INFO]: Epoch 054 - training loss: 0.1860, validation loss: 0.1649
2024-05-25 01:59:09 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch54_loss0.16488894447684288.pypots
2024-05-25 01:59:11 [INFO]: Epoch 055 - training loss: 0.1991, validation loss: 0.1673
2024-05-25 01:59:11 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch55_loss0.1673203818500042.pypots
2024-05-25 01:59:13 [INFO]: Epoch 056 - training loss: 0.1702, validation loss: 0.1520
2024-05-25 01:59:13 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch56_loss0.1520015448331833.pypots
2024-05-25 01:59:16 [INFO]: Epoch 057 - training loss: 0.2523, validation loss: 0.1501
2024-05-25 01:59:16 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch57_loss0.15008269250392914.pypots
2024-05-25 01:59:18 [INFO]: Epoch 058 - training loss: 0.2181, validation loss: 0.1757
2024-05-25 01:59:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch58_loss0.17568433284759521.pypots
2024-05-25 01:59:20 [INFO]: Epoch 059 - training loss: 0.2216, validation loss: 0.1640
2024-05-25 01:59:20 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch59_loss0.16403379291296005.pypots
2024-05-25 01:59:22 [INFO]: Epoch 060 - training loss: 0.2188, validation loss: 0.1593
2024-05-25 01:59:22 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch60_loss0.15933208912611008.pypots
2024-05-25 01:59:24 [INFO]: Epoch 061 - training loss: 0.1805, validation loss: 0.1611
2024-05-25 01:59:24 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI_epoch61_loss0.16110610216856003.pypots
2024-05-25 01:59:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:59:24 [INFO]: Finished training. The best model is from epoch#51.
2024-05-25 01:59:24 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015717/CSDI.pypots
2024-05-25 01:59:40 [INFO]: CSDI on ETTm1: MAE=0.4518, MSE=3.4976
2024-05-25 01:59:40 [INFO]: Successfully saved to augmentation_saved_results/round_2/CSDI_ettm1/imputation.pkl
2024-05-25 01:59:40 [INFO]: Using the given device: cuda:0
2024-05-25 01:59:40 [INFO]: Model files will be saved to augmentation_saved_results/round_2/GPVAE_ettm1/20240525_T015940
2024-05-25 01:59:40 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/GPVAE_ettm1/20240525_T015940/tensorboard
2024-05-25 01:59:40 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 01:59:40 [INFO]: Epoch 001 - training loss: 23968.0579, validation loss: 0.9720
2024-05-25 01:59:40 [INFO]: Epoch 002 - training loss: 21719.6129, validation loss: 0.9600
2024-05-25 01:59:40 [INFO]: Epoch 003 - training loss: 19495.8794, validation loss: 0.9420
2024-05-25 01:59:40 [INFO]: Epoch 004 - training loss: 17552.2799, validation loss: 0.8905
2024-05-25 01:59:40 [INFO]: Epoch 005 - training loss: 15543.8051, validation loss: 0.8050
2024-05-25 01:59:41 [INFO]: Epoch 006 - training loss: 13962.8195, validation loss: 0.7080
2024-05-25 01:59:41 [INFO]: Epoch 007 - training loss: 12733.7271, validation loss: 0.6164
2024-05-25 01:59:41 [INFO]: Epoch 008 - training loss: 12035.1581, validation loss: 0.5233
2024-05-25 01:59:41 [INFO]: Epoch 009 - training loss: 11380.4468, validation loss: 0.4845
2024-05-25 01:59:41 [INFO]: Epoch 010 - training loss: 10987.4055, validation loss: 0.4625
2024-05-25 01:59:41 [INFO]: Epoch 011 - training loss: 10608.8323, validation loss: 0.4369
2024-05-25 01:59:41 [INFO]: Epoch 012 - training loss: 10407.5013, validation loss: 0.4264
2024-05-25 01:59:41 [INFO]: Epoch 013 - training loss: 10259.1135, validation loss: 0.3982
2024-05-25 01:59:42 [INFO]: Epoch 014 - training loss: 10124.0224, validation loss: 0.3748
2024-05-25 01:59:42 [INFO]: Epoch 015 - training loss: 10094.7049, validation loss: 0.3516
2024-05-25 01:59:42 [INFO]: Epoch 016 - training loss: 9952.6583, validation loss: 0.3349
2024-05-25 01:59:42 [INFO]: Epoch 017 - training loss: 9918.4084, validation loss: 0.3211
2024-05-25 01:59:42 [INFO]: Epoch 018 - training loss: 9820.5934, validation loss: 0.3067
2024-05-25 01:59:42 [INFO]: Epoch 019 - training loss: 9785.6954, validation loss: 0.2993
2024-05-25 01:59:42 [INFO]: Epoch 020 - training loss: 9715.8887, validation loss: 0.2940
2024-05-25 01:59:43 [INFO]: Epoch 021 - training loss: 9682.6401, validation loss: 0.2911
2024-05-25 01:59:43 [INFO]: Epoch 022 - training loss: 9658.9197, validation loss: 0.2830
2024-05-25 01:59:43 [INFO]: Epoch 023 - training loss: 9676.8400, validation loss: 0.2743
2024-05-25 01:59:43 [INFO]: Epoch 024 - training loss: 9596.5354, validation loss: 0.2701
2024-05-25 01:59:43 [INFO]: Epoch 025 - training loss: 9592.0858, validation loss: 0.2637
2024-05-25 01:59:43 [INFO]: Epoch 026 - training loss: 9559.6511, validation loss: 0.2545
2024-05-25 01:59:43 [INFO]: Epoch 027 - training loss: 9536.4812, validation loss: 0.2417
2024-05-25 01:59:43 [INFO]: Epoch 028 - training loss: 9562.9971, validation loss: 0.2290
2024-05-25 01:59:44 [INFO]: Epoch 029 - training loss: 9525.5505, validation loss: 0.2208
2024-05-25 01:59:44 [INFO]: Epoch 030 - training loss: 9489.9443, validation loss: 0.2164
2024-05-25 01:59:44 [INFO]: Epoch 031 - training loss: 9479.1617, validation loss: 0.2133
2024-05-25 01:59:44 [INFO]: Epoch 032 - training loss: 9472.5900, validation loss: 0.2027
2024-05-25 01:59:44 [INFO]: Epoch 033 - training loss: 9475.2121, validation loss: 0.1944
2024-05-25 01:59:44 [INFO]: Epoch 034 - training loss: 9456.7404, validation loss: 0.1916
2024-05-25 01:59:44 [INFO]: Epoch 035 - training loss: 9445.4207, validation loss: 0.1872
2024-05-25 01:59:44 [INFO]: Epoch 036 - training loss: 9438.7845, validation loss: 0.1832
2024-05-25 01:59:45 [INFO]: Epoch 037 - training loss: 9435.6644, validation loss: 0.1799
2024-05-25 01:59:45 [INFO]: Epoch 038 - training loss: 9424.6777, validation loss: 0.1740
2024-05-25 01:59:45 [INFO]: Epoch 039 - training loss: 9424.8424, validation loss: 0.1776
2024-05-25 01:59:45 [INFO]: Epoch 040 - training loss: 9419.9364, validation loss: 0.1726
2024-05-25 01:59:45 [INFO]: Epoch 041 - training loss: 9412.4651, validation loss: 0.1702
2024-05-25 01:59:45 [INFO]: Epoch 042 - training loss: 9413.8375, validation loss: 0.1651
2024-05-25 01:59:45 [INFO]: Epoch 043 - training loss: 9455.3726, validation loss: 0.1659
2024-05-25 01:59:45 [INFO]: Epoch 044 - training loss: 9398.6910, validation loss: 0.1611
2024-05-25 01:59:46 [INFO]: Epoch 045 - training loss: 9401.8592, validation loss: 0.1599
2024-05-25 01:59:46 [INFO]: Epoch 046 - training loss: 9420.3398, validation loss: 0.1589
2024-05-25 01:59:46 [INFO]: Epoch 047 - training loss: 9388.3959, validation loss: 0.1555
2024-05-25 01:59:46 [INFO]: Epoch 048 - training loss: 9382.5721, validation loss: 0.1539
2024-05-25 01:59:46 [INFO]: Epoch 049 - training loss: 9382.1993, validation loss: 0.1553
2024-05-25 01:59:46 [INFO]: Epoch 050 - training loss: 9414.7133, validation loss: 0.1519
2024-05-25 01:59:46 [INFO]: Epoch 051 - training loss: 9379.5488, validation loss: 0.1515
2024-05-25 01:59:47 [INFO]: Epoch 052 - training loss: 9370.4784, validation loss: 0.1513
2024-05-25 01:59:47 [INFO]: Epoch 053 - training loss: 9370.9272, validation loss: 0.1509
2024-05-25 01:59:47 [INFO]: Epoch 054 - training loss: 9368.9128, validation loss: 0.1505
2024-05-25 01:59:47 [INFO]: Epoch 055 - training loss: 9364.4330, validation loss: 0.1470
2024-05-25 01:59:47 [INFO]: Epoch 056 - training loss: 9365.3392, validation loss: 0.1468
2024-05-25 01:59:47 [INFO]: Epoch 057 - training loss: 9362.5005, validation loss: 0.1473
2024-05-25 01:59:47 [INFO]: Epoch 058 - training loss: 9360.0877, validation loss: 0.1457
2024-05-25 01:59:47 [INFO]: Epoch 059 - training loss: 9359.3236, validation loss: 0.1461
2024-05-25 01:59:48 [INFO]: Epoch 060 - training loss: 9359.8101, validation loss: 0.1437
2024-05-25 01:59:48 [INFO]: Epoch 061 - training loss: 9357.9806, validation loss: 0.1426
2024-05-25 01:59:48 [INFO]: Epoch 062 - training loss: 9354.6559, validation loss: 0.1418
2024-05-25 01:59:48 [INFO]: Epoch 063 - training loss: 9353.8713, validation loss: 0.1408
2024-05-25 01:59:48 [INFO]: Epoch 064 - training loss: 9353.2230, validation loss: 0.1394
2024-05-25 01:59:48 [INFO]: Epoch 065 - training loss: 9351.3636, validation loss: 0.1383
2024-05-25 01:59:48 [INFO]: Epoch 066 - training loss: 9349.4016, validation loss: 0.1377
2024-05-25 01:59:48 [INFO]: Epoch 067 - training loss: 9350.9356, validation loss: 0.1371
2024-05-25 01:59:49 [INFO]: Epoch 068 - training loss: 9348.4713, validation loss: 0.1343
2024-05-25 01:59:49 [INFO]: Epoch 069 - training loss: 9348.2140, validation loss: 0.1366
2024-05-25 01:59:49 [INFO]: Epoch 070 - training loss: 9350.0704, validation loss: 0.1334
2024-05-25 01:59:49 [INFO]: Epoch 071 - training loss: 9342.9715, validation loss: 0.1324
2024-05-25 01:59:49 [INFO]: Epoch 072 - training loss: 9378.0055, validation loss: 0.1300
2024-05-25 01:59:49 [INFO]: Epoch 073 - training loss: 9342.3177, validation loss: 0.1290
2024-05-25 01:59:49 [INFO]: Epoch 074 - training loss: 9342.5146, validation loss: 0.1276
2024-05-25 01:59:49 [INFO]: Epoch 075 - training loss: 9339.1650, validation loss: 0.1282
2024-05-25 01:59:50 [INFO]: Epoch 076 - training loss: 9341.4931, validation loss: 0.1255
2024-05-25 01:59:50 [INFO]: Epoch 077 - training loss: 9336.8889, validation loss: 0.1276
2024-05-25 01:59:50 [INFO]: Epoch 078 - training loss: 9338.8046, validation loss: 0.1236
2024-05-25 01:59:50 [INFO]: Epoch 079 - training loss: 9336.2940, validation loss: 0.1251
2024-05-25 01:59:50 [INFO]: Epoch 080 - training loss: 9338.6622, validation loss: 0.1237
2024-05-25 01:59:50 [INFO]: Epoch 081 - training loss: 9334.8287, validation loss: 0.1210
2024-05-25 01:59:50 [INFO]: Epoch 082 - training loss: 9333.3915, validation loss: 0.1212
2024-05-25 01:59:50 [INFO]: Epoch 083 - training loss: 9333.8071, validation loss: 0.1204
2024-05-25 01:59:51 [INFO]: Epoch 084 - training loss: 9331.0287, validation loss: 0.1190
2024-05-25 01:59:51 [INFO]: Epoch 085 - training loss: 9331.5877, validation loss: 0.1187
2024-05-25 01:59:51 [INFO]: Epoch 086 - training loss: 9332.6926, validation loss: 0.1165
2024-05-25 01:59:51 [INFO]: Epoch 087 - training loss: 9333.1351, validation loss: 0.1156
2024-05-25 01:59:51 [INFO]: Epoch 088 - training loss: 9332.6052, validation loss: 0.1148
2024-05-25 01:59:51 [INFO]: Epoch 089 - training loss: 9331.9149, validation loss: 0.1145
2024-05-25 01:59:51 [INFO]: Epoch 090 - training loss: 9328.6735, validation loss: 0.1145
2024-05-25 01:59:52 [INFO]: Epoch 091 - training loss: 9329.4496, validation loss: 0.1123
2024-05-25 01:59:52 [INFO]: Epoch 092 - training loss: 9328.3104, validation loss: 0.1128
2024-05-25 01:59:52 [INFO]: Epoch 093 - training loss: 9325.7269, validation loss: 0.1094
2024-05-25 01:59:52 [INFO]: Epoch 094 - training loss: 9336.8657, validation loss: 0.1104
2024-05-25 01:59:52 [INFO]: Epoch 095 - training loss: 9327.4969, validation loss: 0.1096
2024-05-25 01:59:52 [INFO]: Epoch 096 - training loss: 9327.9763, validation loss: 0.1085
2024-05-25 01:59:52 [INFO]: Epoch 097 - training loss: 9328.3744, validation loss: 0.1080
2024-05-25 01:59:52 [INFO]: Epoch 098 - training loss: 9325.2990, validation loss: 0.1073
2024-05-25 01:59:53 [INFO]: Epoch 099 - training loss: 9326.7417, validation loss: 0.1069
2024-05-25 01:59:53 [INFO]: Epoch 100 - training loss: 9325.3199, validation loss: 0.1058
2024-05-25 01:59:53 [INFO]: Epoch 101 - training loss: 9322.8741, validation loss: 0.1060
2024-05-25 01:59:53 [INFO]: Epoch 102 - training loss: 9323.4385, validation loss: 0.1044
2024-05-25 01:59:53 [INFO]: Epoch 103 - training loss: 9322.8130, validation loss: 0.1040
2024-05-25 01:59:53 [INFO]: Epoch 104 - training loss: 9323.3123, validation loss: 0.1026
2024-05-25 01:59:53 [INFO]: Epoch 105 - training loss: 9323.8520, validation loss: 0.1019
2024-05-25 01:59:53 [INFO]: Epoch 106 - training loss: 9321.6372, validation loss: 0.1012
2024-05-25 01:59:54 [INFO]: Epoch 107 - training loss: 9321.1682, validation loss: 0.1032
2024-05-25 01:59:54 [INFO]: Epoch 108 - training loss: 9319.9593, validation loss: 0.0993
2024-05-25 01:59:54 [INFO]: Epoch 109 - training loss: 9319.3682, validation loss: 0.1018
2024-05-25 01:59:54 [INFO]: Epoch 110 - training loss: 9320.3603, validation loss: 0.0984
2024-05-25 01:59:54 [INFO]: Epoch 111 - training loss: 9318.7426, validation loss: 0.1005
2024-05-25 01:59:54 [INFO]: Epoch 112 - training loss: 9317.7269, validation loss: 0.0989
2024-05-25 01:59:54 [INFO]: Epoch 113 - training loss: 9316.9484, validation loss: 0.0985
2024-05-25 01:59:54 [INFO]: Epoch 114 - training loss: 9316.9497, validation loss: 0.0988
2024-05-25 01:59:55 [INFO]: Epoch 115 - training loss: 9317.7585, validation loss: 0.0967
2024-05-25 01:59:55 [INFO]: Epoch 116 - training loss: 9316.3350, validation loss: 0.0973
2024-05-25 01:59:55 [INFO]: Epoch 117 - training loss: 9316.0005, validation loss: 0.0967
2024-05-25 01:59:55 [INFO]: Epoch 118 - training loss: 9317.2390, validation loss: 0.0960
2024-05-25 01:59:55 [INFO]: Epoch 119 - training loss: 9318.0264, validation loss: 0.0965
2024-05-25 01:59:55 [INFO]: Epoch 120 - training loss: 9316.0845, validation loss: 0.0961
2024-05-25 01:59:55 [INFO]: Epoch 121 - training loss: 9314.5937, validation loss: 0.0940
2024-05-25 01:59:55 [INFO]: Epoch 122 - training loss: 9315.9322, validation loss: 0.0958
2024-05-25 01:59:56 [INFO]: Epoch 123 - training loss: 9317.7446, validation loss: 0.0934
2024-05-25 01:59:56 [INFO]: Epoch 124 - training loss: 9315.9612, validation loss: 0.0926
2024-05-25 01:59:56 [INFO]: Epoch 125 - training loss: 9317.6551, validation loss: 0.0931
2024-05-25 01:59:56 [INFO]: Epoch 126 - training loss: 9313.3511, validation loss: 0.0921
2024-05-25 01:59:56 [INFO]: Epoch 127 - training loss: 9313.9457, validation loss: 0.0932
2024-05-25 01:59:56 [INFO]: Epoch 128 - training loss: 9314.2163, validation loss: 0.0913
2024-05-25 01:59:56 [INFO]: Epoch 129 - training loss: 9313.7773, validation loss: 0.0912
2024-05-25 01:59:57 [INFO]: Epoch 130 - training loss: 9316.7999, validation loss: 0.0918
2024-05-25 01:59:57 [INFO]: Epoch 131 - training loss: 9313.0306, validation loss: 0.0910
2024-05-25 01:59:57 [INFO]: Epoch 132 - training loss: 9316.8218, validation loss: 0.0901
2024-05-25 01:59:57 [INFO]: Epoch 133 - training loss: 9313.0482, validation loss: 0.0879
2024-05-25 01:59:57 [INFO]: Epoch 134 - training loss: 9312.5919, validation loss: 0.0892
2024-05-25 01:59:57 [INFO]: Epoch 135 - training loss: 9315.4603, validation loss: 0.0888
2024-05-25 01:59:57 [INFO]: Epoch 136 - training loss: 9329.2408, validation loss: 0.0882
2024-05-25 01:59:57 [INFO]: Epoch 137 - training loss: 9312.5516, validation loss: 0.0888
2024-05-25 01:59:58 [INFO]: Epoch 138 - training loss: 9312.9674, validation loss: 0.0875
2024-05-25 01:59:58 [INFO]: Epoch 139 - training loss: 9311.6595, validation loss: 0.0879
2024-05-25 01:59:58 [INFO]: Epoch 140 - training loss: 9311.8000, validation loss: 0.0883
2024-05-25 01:59:58 [INFO]: Epoch 141 - training loss: 9310.5344, validation loss: 0.0874
2024-05-25 01:59:58 [INFO]: Epoch 142 - training loss: 9311.3343, validation loss: 0.0869
2024-05-25 01:59:58 [INFO]: Epoch 143 - training loss: 9312.2706, validation loss: 0.0868
2024-05-25 01:59:58 [INFO]: Epoch 144 - training loss: 9313.1042, validation loss: 0.0874
2024-05-25 01:59:58 [INFO]: Epoch 145 - training loss: 9312.3323, validation loss: 0.0837
2024-05-25 01:59:59 [INFO]: Epoch 146 - training loss: 9311.0026, validation loss: 0.0869
2024-05-25 01:59:59 [INFO]: Epoch 147 - training loss: 9310.2668, validation loss: 0.0864
2024-05-25 01:59:59 [INFO]: Epoch 148 - training loss: 9310.0836, validation loss: 0.0860
2024-05-25 01:59:59 [INFO]: Epoch 149 - training loss: 9310.3112, validation loss: 0.0854
2024-05-25 01:59:59 [INFO]: Epoch 150 - training loss: 9311.0190, validation loss: 0.0846
2024-05-25 01:59:59 [INFO]: Epoch 151 - training loss: 9310.5298, validation loss: 0.0848
2024-05-25 01:59:59 [INFO]: Epoch 152 - training loss: 9308.1751, validation loss: 0.0856
2024-05-25 01:59:59 [INFO]: Epoch 153 - training loss: 9310.1566, validation loss: 0.0842
2024-05-25 02:00:00 [INFO]: Epoch 154 - training loss: 9310.2000, validation loss: 0.0839
2024-05-25 02:00:00 [INFO]: Epoch 155 - training loss: 9308.9753, validation loss: 0.0846
2024-05-25 02:00:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:00:00 [INFO]: Finished training. The best model is from epoch#145.
2024-05-25 02:00:00 [INFO]: Saved the model to augmentation_saved_results/round_2/GPVAE_ettm1/20240525_T015940/GPVAE.pypots
2024-05-25 02:00:00 [INFO]: GP-VAE on ETTm1: MAE=0.3039, MSE=0.1783
2024-05-25 02:00:00 [INFO]: Successfully saved to augmentation_saved_results/round_2/GPVAE_ettm1/imputation.pkl
2024-05-25 02:00:00 [INFO]: Using the given device: cuda:0
2024-05-25 02:00:00 [INFO]: Model files will be saved to augmentation_saved_results/round_2/USGAN_ettm1/20240525_T020000
2024-05-25 02:00:00 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/USGAN_ettm1/20240525_T020000/tensorboard
2024-05-25 02:00:00 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 02:00:11 [INFO]: Epoch 001 - generator training loss: 0.5437, discriminator training loss: 0.3199, validation loss: 0.2834
2024-05-25 02:00:19 [INFO]: Epoch 002 - generator training loss: 0.0305, discriminator training loss: 0.2077, validation loss: 0.0893
2024-05-25 02:00:28 [INFO]: Epoch 003 - generator training loss: -0.0601, discriminator training loss: 0.1969, validation loss: 0.0575
2024-05-25 02:00:37 [INFO]: Epoch 004 - generator training loss: -0.0812, discriminator training loss: 0.1923, validation loss: 0.0504
2024-05-25 02:00:46 [INFO]: Epoch 005 - generator training loss: -0.0860, discriminator training loss: 0.1882, validation loss: 0.0431
2024-05-25 02:00:55 [INFO]: Epoch 006 - generator training loss: -0.0800, discriminator training loss: 0.1812, validation loss: 0.0389
2024-05-25 02:01:04 [INFO]: Epoch 007 - generator training loss: -0.0797, discriminator training loss: 0.1768, validation loss: 0.0380
2024-05-25 02:01:13 [INFO]: Epoch 008 - generator training loss: -0.0702, discriminator training loss: 0.1680, validation loss: 0.0362
2024-05-25 02:01:22 [INFO]: Epoch 009 - generator training loss: -0.0585, discriminator training loss: 0.1525, validation loss: 0.0351
2024-05-25 02:01:31 [INFO]: Epoch 010 - generator training loss: -0.0457, discriminator training loss: 0.1380, validation loss: 0.0341
2024-05-25 02:01:40 [INFO]: Epoch 011 - generator training loss: -0.0356, discriminator training loss: 0.1239, validation loss: 0.0352
2024-05-25 02:01:49 [INFO]: Epoch 012 - generator training loss: -0.0263, discriminator training loss: 0.1108, validation loss: 0.0325
2024-05-25 02:01:58 [INFO]: Epoch 013 - generator training loss: -0.0200, discriminator training loss: 0.1020, validation loss: 0.0328
2024-05-25 02:02:07 [INFO]: Epoch 014 - generator training loss: -0.0197, discriminator training loss: 0.0944, validation loss: 0.0320
2024-05-25 02:02:16 [INFO]: Epoch 015 - generator training loss: -0.0161, discriminator training loss: 0.0899, validation loss: 0.0321
2024-05-25 02:02:25 [INFO]: Epoch 016 - generator training loss: -0.0118, discriminator training loss: 0.0872, validation loss: 0.0316
2024-05-25 02:02:34 [INFO]: Epoch 017 - generator training loss: -0.0110, discriminator training loss: 0.0839, validation loss: 0.0327
2024-05-25 02:02:43 [INFO]: Epoch 018 - generator training loss: -0.0120, discriminator training loss: 0.0802, validation loss: 0.0311
2024-05-25 02:02:52 [INFO]: Epoch 019 - generator training loss: -0.0110, discriminator training loss: 0.0800, validation loss: 0.0312
2024-05-25 02:03:01 [INFO]: Epoch 020 - generator training loss: -0.0113, discriminator training loss: 0.0777, validation loss: 0.0297
2024-05-25 02:03:10 [INFO]: Epoch 021 - generator training loss: -0.0140, discriminator training loss: 0.0768, validation loss: 0.0300
2024-05-25 02:03:19 [INFO]: Epoch 022 - generator training loss: -0.0104, discriminator training loss: 0.0768, validation loss: 0.0304
2024-05-25 02:03:28 [INFO]: Epoch 023 - generator training loss: -0.0125, discriminator training loss: 0.0755, validation loss: 0.0296
2024-05-25 02:03:37 [INFO]: Epoch 024 - generator training loss: -0.0120, discriminator training loss: 0.0738, validation loss: 0.0293
2024-05-25 02:03:46 [INFO]: Epoch 025 - generator training loss: -0.0130, discriminator training loss: 0.0739, validation loss: 0.0291
2024-05-25 02:03:55 [INFO]: Epoch 026 - generator training loss: -0.0148, discriminator training loss: 0.0732, validation loss: 0.0283
2024-05-25 02:04:04 [INFO]: Epoch 027 - generator training loss: -0.0130, discriminator training loss: 0.0721, validation loss: 0.0281
2024-05-25 02:04:13 [INFO]: Epoch 028 - generator training loss: -0.0148, discriminator training loss: 0.0733, validation loss: 0.0284
2024-05-25 02:04:22 [INFO]: Epoch 029 - generator training loss: -0.0140, discriminator training loss: 0.0716, validation loss: 0.0281
2024-05-25 02:04:31 [INFO]: Epoch 030 - generator training loss: -0.0129, discriminator training loss: 0.0715, validation loss: 0.0273
2024-05-25 02:04:40 [INFO]: Epoch 031 - generator training loss: -0.0153, discriminator training loss: 0.0718, validation loss: 0.0276
2024-05-25 02:04:49 [INFO]: Epoch 032 - generator training loss: -0.0127, discriminator training loss: 0.0715, validation loss: 0.0274
2024-05-25 02:04:58 [INFO]: Epoch 033 - generator training loss: -0.0146, discriminator training loss: 0.0736, validation loss: 0.0275
2024-05-25 02:05:08 [INFO]: Epoch 034 - generator training loss: -0.0154, discriminator training loss: 0.0734, validation loss: 0.0266
2024-05-25 02:05:17 [INFO]: Epoch 035 - generator training loss: -0.0131, discriminator training loss: 0.0727, validation loss: 0.0267
2024-05-25 02:05:26 [INFO]: Epoch 036 - generator training loss: -0.0170, discriminator training loss: 0.0713, validation loss: 0.0271
2024-05-25 02:05:35 [INFO]: Epoch 037 - generator training loss: -0.0168, discriminator training loss: 0.0690, validation loss: 0.0260
2024-05-25 02:05:44 [INFO]: Epoch 038 - generator training loss: -0.0185, discriminator training loss: 0.0686, validation loss: 0.0284
2024-05-25 02:05:53 [INFO]: Epoch 039 - generator training loss: -0.0166, discriminator training loss: 0.0702, validation loss: 0.0268
2024-05-25 02:06:02 [INFO]: Epoch 040 - generator training loss: -0.0171, discriminator training loss: 0.0685, validation loss: 0.0260
2024-05-25 02:06:11 [INFO]: Epoch 041 - generator training loss: -0.0162, discriminator training loss: 0.0685, validation loss: 0.0252
2024-05-25 02:06:20 [INFO]: Epoch 042 - generator training loss: -0.0172, discriminator training loss: 0.0689, validation loss: 0.0248
2024-05-25 02:06:29 [INFO]: Epoch 043 - generator training loss: -0.0176, discriminator training loss: 0.0710, validation loss: 0.0242
2024-05-25 02:06:38 [INFO]: Epoch 044 - generator training loss: -0.0150, discriminator training loss: 0.0688, validation loss: 0.0243
2024-05-25 02:06:47 [INFO]: Epoch 045 - generator training loss: -0.0186, discriminator training loss: 0.0668, validation loss: 0.0243
2024-05-25 02:06:56 [INFO]: Epoch 046 - generator training loss: -0.0185, discriminator training loss: 0.0690, validation loss: 0.0231
2024-05-25 02:07:05 [INFO]: Epoch 047 - generator training loss: -0.0184, discriminator training loss: 0.0673, validation loss: 0.0235
2024-05-25 02:07:14 [INFO]: Epoch 048 - generator training loss: -0.0196, discriminator training loss: 0.0686, validation loss: 0.0230
2024-05-25 02:07:23 [INFO]: Epoch 049 - generator training loss: -0.0193, discriminator training loss: 0.0677, validation loss: 0.0226
2024-05-25 02:07:33 [INFO]: Epoch 050 - generator training loss: -0.0196, discriminator training loss: 0.0686, validation loss: 0.0225
2024-05-25 02:07:42 [INFO]: Epoch 051 - generator training loss: -0.0194, discriminator training loss: 0.0680, validation loss: 0.0222
2024-05-25 02:07:51 [INFO]: Epoch 052 - generator training loss: -0.0209, discriminator training loss: 0.0686, validation loss: 0.0219
2024-05-25 02:08:00 [INFO]: Epoch 053 - generator training loss: -0.0189, discriminator training loss: 0.0686, validation loss: 0.0219
2024-05-25 02:08:09 [INFO]: Epoch 054 - generator training loss: -0.0211, discriminator training loss: 0.0708, validation loss: 0.0218
2024-05-25 02:08:18 [INFO]: Epoch 055 - generator training loss: -0.0197, discriminator training loss: 0.0690, validation loss: 0.0220
2024-05-25 02:08:27 [INFO]: Epoch 056 - generator training loss: -0.0187, discriminator training loss: 0.0673, validation loss: 0.0208
2024-05-25 02:08:36 [INFO]: Epoch 057 - generator training loss: -0.0208, discriminator training loss: 0.0677, validation loss: 0.0212
2024-05-25 02:08:45 [INFO]: Epoch 058 - generator training loss: -0.0196, discriminator training loss: 0.0677, validation loss: 0.0209
2024-05-25 02:08:54 [INFO]: Epoch 059 - generator training loss: -0.0224, discriminator training loss: 0.0668, validation loss: 0.0205
2024-05-25 02:09:03 [INFO]: Epoch 060 - generator training loss: -0.0243, discriminator training loss: 0.0687, validation loss: 0.0206
2024-05-25 02:09:12 [INFO]: Epoch 061 - generator training loss: -0.0235, discriminator training loss: 0.0670, validation loss: 0.0197
2024-05-25 02:09:21 [INFO]: Epoch 062 - generator training loss: -0.0235, discriminator training loss: 0.0674, validation loss: 0.0198
2024-05-25 02:09:30 [INFO]: Epoch 063 - generator training loss: -0.0240, discriminator training loss: 0.0673, validation loss: 0.0201
2024-05-25 02:09:39 [INFO]: Epoch 064 - generator training loss: -0.0229, discriminator training loss: 0.0648, validation loss: 0.0209
2024-05-25 02:09:48 [INFO]: Epoch 065 - generator training loss: -0.0257, discriminator training loss: 0.0670, validation loss: 0.0206
2024-05-25 02:09:57 [INFO]: Epoch 066 - generator training loss: -0.0236, discriminator training loss: 0.0682, validation loss: 0.0218
2024-05-25 02:10:06 [INFO]: Epoch 067 - generator training loss: -0.0217, discriminator training loss: 0.0679, validation loss: 0.0202
2024-05-25 02:10:15 [INFO]: Epoch 068 - generator training loss: -0.0210, discriminator training loss: 0.0687, validation loss: 0.0213
2024-05-25 02:10:24 [INFO]: Epoch 069 - generator training loss: -0.0225, discriminator training loss: 0.0669, validation loss: 0.0195
2024-05-25 02:10:33 [INFO]: Epoch 070 - generator training loss: -0.0237, discriminator training loss: 0.0673, validation loss: 0.0194
2024-05-25 02:10:43 [INFO]: Epoch 071 - generator training loss: -0.0241, discriminator training loss: 0.0689, validation loss: 0.0195
2024-05-25 02:10:52 [INFO]: Epoch 072 - generator training loss: -0.0226, discriminator training loss: 0.0679, validation loss: 0.0193
2024-05-25 02:11:01 [INFO]: Epoch 073 - generator training loss: -0.0207, discriminator training loss: 0.0655, validation loss: 0.0205
2024-05-25 02:11:10 [INFO]: Epoch 074 - generator training loss: -0.0237, discriminator training loss: 0.0665, validation loss: 0.0191
2024-05-25 02:11:19 [INFO]: Epoch 075 - generator training loss: -0.0239, discriminator training loss: 0.0676, validation loss: 0.0200
2024-05-25 02:11:28 [INFO]: Epoch 076 - generator training loss: -0.0246, discriminator training loss: 0.0676, validation loss: 0.0196
2024-05-25 02:11:37 [INFO]: Epoch 077 - generator training loss: -0.0247, discriminator training loss: 0.0655, validation loss: 0.0190
2024-05-25 02:11:47 [INFO]: Epoch 078 - generator training loss: -0.0240, discriminator training loss: 0.0660, validation loss: 0.0197
2024-05-25 02:11:56 [INFO]: Epoch 079 - generator training loss: -0.0252, discriminator training loss: 0.0666, validation loss: 0.0197
2024-05-25 02:12:05 [INFO]: Epoch 080 - generator training loss: -0.0226, discriminator training loss: 0.0666, validation loss: 0.0196
2024-05-25 02:12:14 [INFO]: Epoch 081 - generator training loss: -0.0246, discriminator training loss: 0.0660, validation loss: 0.0195
2024-05-25 02:12:23 [INFO]: Epoch 082 - generator training loss: -0.0243, discriminator training loss: 0.0661, validation loss: 0.0195
2024-05-25 02:12:32 [INFO]: Epoch 083 - generator training loss: -0.0254, discriminator training loss: 0.0660, validation loss: 0.0195
2024-05-25 02:12:41 [INFO]: Epoch 084 - generator training loss: -0.0280, discriminator training loss: 0.0657, validation loss: 0.0186
2024-05-25 02:12:51 [INFO]: Epoch 085 - generator training loss: -0.0266, discriminator training loss: 0.0683, validation loss: 0.0199
2024-05-25 02:13:00 [INFO]: Epoch 086 - generator training loss: -0.0242, discriminator training loss: 0.0664, validation loss: 0.0191
2024-05-25 02:13:09 [INFO]: Epoch 087 - generator training loss: -0.0246, discriminator training loss: 0.0683, validation loss: 0.0195
2024-05-25 02:13:18 [INFO]: Epoch 088 - generator training loss: -0.0231, discriminator training loss: 0.0665, validation loss: 0.0196
2024-05-25 02:13:27 [INFO]: Epoch 089 - generator training loss: -0.0250, discriminator training loss: 0.0671, validation loss: 0.0195
2024-05-25 02:13:36 [INFO]: Epoch 090 - generator training loss: -0.0229, discriminator training loss: 0.0676, validation loss: 0.0192
2024-05-25 02:13:45 [INFO]: Epoch 091 - generator training loss: -0.0227, discriminator training loss: 0.0658, validation loss: 0.0192
2024-05-25 02:13:54 [INFO]: Epoch 092 - generator training loss: -0.0245, discriminator training loss: 0.0664, validation loss: 0.0193
2024-05-25 02:14:04 [INFO]: Epoch 093 - generator training loss: -0.0247, discriminator training loss: 0.0657, validation loss: 0.0197
2024-05-25 02:14:13 [INFO]: Epoch 094 - generator training loss: -0.0268, discriminator training loss: 0.0647, validation loss: 0.0195
2024-05-25 02:14:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:14:13 [INFO]: Finished training. The best model is from epoch#84.
2024-05-25 02:14:13 [INFO]: Saved the model to augmentation_saved_results/round_2/USGAN_ettm1/20240525_T020000/USGAN.pypots
2024-05-25 02:14:14 [INFO]: US-GAN on ETTm1: MAE=0.1333, MSE=0.0452
2024-05-25 02:14:14 [INFO]: Successfully saved to augmentation_saved_results/round_2/USGAN_ettm1/imputation.pkl
2024-05-25 02:14:14 [INFO]: Using the given device: cuda:0
2024-05-25 02:14:14 [INFO]: Model files will be saved to augmentation_saved_results/round_2/BRITS_ettm1/20240525_T021414
2024-05-25 02:14:14 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/BRITS_ettm1/20240525_T021414/tensorboard
2024-05-25 02:14:14 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 02:14:21 [INFO]: Epoch 001 - training loss: 1.2995, validation loss: 0.3331
2024-05-25 02:14:28 [INFO]: Epoch 002 - training loss: 0.8828, validation loss: 0.1058
2024-05-25 02:14:34 [INFO]: Epoch 003 - training loss: 0.6840, validation loss: 0.0595
2024-05-25 02:14:40 [INFO]: Epoch 004 - training loss: 0.6117, validation loss: 0.0455
2024-05-25 02:14:46 [INFO]: Epoch 005 - training loss: 0.5805, validation loss: 0.0391
2024-05-25 02:14:52 [INFO]: Epoch 006 - training loss: 0.5389, validation loss: 0.0369
2024-05-25 02:14:58 [INFO]: Epoch 007 - training loss: 0.5084, validation loss: 0.0322
2024-05-25 02:15:04 [INFO]: Epoch 008 - training loss: 0.4909, validation loss: 0.0306
2024-05-25 02:15:10 [INFO]: Epoch 009 - training loss: 0.4619, validation loss: 0.0295
2024-05-25 02:15:16 [INFO]: Epoch 010 - training loss: 0.4509, validation loss: 0.0281
2024-05-25 02:15:22 [INFO]: Epoch 011 - training loss: 0.4401, validation loss: 0.0280
2024-05-25 02:15:28 [INFO]: Epoch 012 - training loss: 0.4268, validation loss: 0.0279
2024-05-25 02:15:34 [INFO]: Epoch 013 - training loss: 0.4132, validation loss: 0.0255
2024-05-25 02:15:40 [INFO]: Epoch 014 - training loss: 0.4055, validation loss: 0.0253
2024-05-25 02:15:46 [INFO]: Epoch 015 - training loss: 0.3999, validation loss: 0.0238
2024-05-25 02:15:52 [INFO]: Epoch 016 - training loss: 0.4155, validation loss: 0.0228
2024-05-25 02:15:58 [INFO]: Epoch 017 - training loss: 0.3918, validation loss: 0.0235
2024-05-25 02:16:04 [INFO]: Epoch 018 - training loss: 0.3877, validation loss: 0.0224
2024-05-25 02:16:10 [INFO]: Epoch 019 - training loss: 0.3895, validation loss: 0.0225
2024-05-25 02:16:16 [INFO]: Epoch 020 - training loss: 0.3882, validation loss: 0.0223
2024-05-25 02:16:22 [INFO]: Epoch 021 - training loss: 0.3838, validation loss: 0.0227
2024-05-25 02:16:28 [INFO]: Epoch 022 - training loss: 0.3906, validation loss: 0.0231
2024-05-25 02:16:34 [INFO]: Epoch 023 - training loss: 0.3887, validation loss: 0.0221
2024-05-25 02:16:40 [INFO]: Epoch 024 - training loss: 0.3822, validation loss: 0.0223
2024-05-25 02:16:46 [INFO]: Epoch 025 - training loss: 0.3831, validation loss: 0.0229
2024-05-25 02:16:52 [INFO]: Epoch 026 - training loss: 0.3838, validation loss: 0.0230
2024-05-25 02:16:58 [INFO]: Epoch 027 - training loss: 0.3886, validation loss: 0.0225
2024-05-25 02:17:04 [INFO]: Epoch 028 - training loss: 0.3881, validation loss: 0.0228
2024-05-25 02:17:10 [INFO]: Epoch 029 - training loss: 0.3798, validation loss: 0.0220
2024-05-25 02:17:16 [INFO]: Epoch 030 - training loss: 0.3899, validation loss: 0.0217
2024-05-25 02:17:22 [INFO]: Epoch 031 - training loss: 0.3820, validation loss: 0.0225
2024-05-25 02:17:28 [INFO]: Epoch 032 - training loss: 0.3782, validation loss: 0.0227
2024-05-25 02:17:34 [INFO]: Epoch 033 - training loss: 0.3785, validation loss: 0.0218
2024-05-25 02:17:40 [INFO]: Epoch 034 - training loss: 0.3939, validation loss: 0.0237
2024-05-25 02:17:47 [INFO]: Epoch 035 - training loss: 0.3802, validation loss: 0.0214
2024-05-25 02:17:53 [INFO]: Epoch 036 - training loss: 0.3772, validation loss: 0.0223
2024-05-25 02:17:59 [INFO]: Epoch 037 - training loss: 0.3852, validation loss: 0.0220
2024-05-25 02:18:05 [INFO]: Epoch 038 - training loss: 0.3751, validation loss: 0.0226
2024-05-25 02:18:11 [INFO]: Epoch 039 - training loss: 0.3776, validation loss: 0.0239
2024-05-25 02:18:17 [INFO]: Epoch 040 - training loss: 0.4012, validation loss: 0.0232
2024-05-25 02:18:23 [INFO]: Epoch 041 - training loss: 0.3790, validation loss: 0.0289
2024-05-25 02:18:29 [INFO]: Epoch 042 - training loss: 0.4086, validation loss: 0.0231
2024-05-25 02:18:35 [INFO]: Epoch 043 - training loss: 0.3888, validation loss: 0.0236
2024-05-25 02:18:41 [INFO]: Epoch 044 - training loss: 0.3880, validation loss: 0.0222
2024-05-25 02:18:47 [INFO]: Epoch 045 - training loss: 0.3892, validation loss: 0.0221
2024-05-25 02:18:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:18:47 [INFO]: Finished training. The best model is from epoch#35.
2024-05-25 02:18:47 [INFO]: Saved the model to augmentation_saved_results/round_2/BRITS_ettm1/20240525_T021414/BRITS.pypots
2024-05-25 02:18:48 [INFO]: BRITS on ETTm1: MAE=0.1448, MSE=0.0589
2024-05-25 02:18:48 [INFO]: Successfully saved to augmentation_saved_results/round_2/BRITS_ettm1/imputation.pkl
2024-05-25 02:18:48 [INFO]: Using the given device: cuda:0
2024-05-25 02:18:48 [INFO]: Model files will be saved to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848
2024-05-25 02:18:48 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/tensorboard
2024-05-25 02:18:48 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 02:18:50 [INFO]: Epoch 001 - training loss: 1.3737, validation loss: 1.2879
2024-05-25 02:18:50 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch1_loss1.287916362285614.pypots
2024-05-25 02:18:50 [INFO]: Epoch 002 - training loss: 1.0533, validation loss: 1.1728
2024-05-25 02:18:50 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch2_loss1.172820895910263.pypots
2024-05-25 02:18:50 [INFO]: Epoch 003 - training loss: 0.9810, validation loss: 1.1005
2024-05-25 02:18:50 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch3_loss1.1004697978496552.pypots
2024-05-25 02:18:50 [INFO]: Epoch 004 - training loss: 0.9912, validation loss: 1.0773
2024-05-25 02:18:50 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch4_loss1.0772899091243744.pypots
2024-05-25 02:18:50 [INFO]: Epoch 005 - training loss: 0.9760, validation loss: 1.0609
2024-05-25 02:18:50 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch5_loss1.06086665391922.pypots
2024-05-25 02:18:51 [INFO]: Epoch 006 - training loss: 0.9364, validation loss: 1.0504
2024-05-25 02:18:51 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch6_loss1.0503875762224197.pypots
2024-05-25 02:18:51 [INFO]: Epoch 007 - training loss: 0.9402, validation loss: 1.0429
2024-05-25 02:18:51 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch7_loss1.0428553223609924.pypots
2024-05-25 02:18:51 [INFO]: Epoch 008 - training loss: 0.9203, validation loss: 1.0356
2024-05-25 02:18:51 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch8_loss1.0355896651744843.pypots
2024-05-25 02:18:51 [INFO]: Epoch 009 - training loss: 0.9006, validation loss: 1.0304
2024-05-25 02:18:51 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch9_loss1.0304182320833206.pypots
2024-05-25 02:18:51 [INFO]: Epoch 010 - training loss: 0.9069, validation loss: 1.0302
2024-05-25 02:18:51 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch10_loss1.0301854312419891.pypots
2024-05-25 02:18:52 [INFO]: Epoch 011 - training loss: 0.8869, validation loss: 1.0291
2024-05-25 02:18:52 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch11_loss1.0290833562612534.pypots
2024-05-25 02:18:52 [INFO]: Epoch 012 - training loss: 0.8788, validation loss: 1.0241
2024-05-25 02:18:52 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch12_loss1.0240740776062012.pypots
2024-05-25 02:18:52 [INFO]: Epoch 013 - training loss: 0.8717, validation loss: 1.0189
2024-05-25 02:18:52 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch13_loss1.01886884868145.pypots
2024-05-25 02:18:52 [INFO]: Epoch 014 - training loss: 0.8892, validation loss: 1.0161
2024-05-25 02:18:52 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch14_loss1.0160785764455795.pypots
2024-05-25 02:18:52 [INFO]: Epoch 015 - training loss: 0.8763, validation loss: 1.0147
2024-05-25 02:18:52 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch15_loss1.0146743953227997.pypots
2024-05-25 02:18:53 [INFO]: Epoch 016 - training loss: 0.8775, validation loss: 1.0109
2024-05-25 02:18:53 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch16_loss1.010926142334938.pypots
2024-05-25 02:18:53 [INFO]: Epoch 017 - training loss: 0.8558, validation loss: 1.0036
2024-05-25 02:18:53 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch17_loss1.0035574436187744.pypots
2024-05-25 02:18:53 [INFO]: Epoch 018 - training loss: 0.8600, validation loss: 0.9979
2024-05-25 02:18:53 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch18_loss0.997949630022049.pypots
2024-05-25 02:18:53 [INFO]: Epoch 019 - training loss: 0.8530, validation loss: 0.9973
2024-05-25 02:18:53 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch19_loss0.9973040372133255.pypots
2024-05-25 02:18:53 [INFO]: Epoch 020 - training loss: 0.8360, validation loss: 0.9900
2024-05-25 02:18:53 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch20_loss0.9900385290384293.pypots
2024-05-25 02:18:53 [INFO]: Epoch 021 - training loss: 0.8151, validation loss: 0.9859
2024-05-25 02:18:53 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch21_loss0.9858523607254028.pypots
2024-05-25 02:18:54 [INFO]: Epoch 022 - training loss: 0.8368, validation loss: 0.9815
2024-05-25 02:18:54 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch22_loss0.9814576357603073.pypots
2024-05-25 02:18:54 [INFO]: Epoch 023 - training loss: 0.8733, validation loss: 0.9786
2024-05-25 02:18:54 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch23_loss0.9786381721496582.pypots
2024-05-25 02:18:54 [INFO]: Epoch 024 - training loss: 0.8484, validation loss: 0.9764
2024-05-25 02:18:54 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch24_loss0.9763738811016083.pypots
2024-05-25 02:18:54 [INFO]: Epoch 025 - training loss: 0.8366, validation loss: 0.9757
2024-05-25 02:18:54 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch25_loss0.9756927639245987.pypots
2024-05-25 02:18:54 [INFO]: Epoch 026 - training loss: 0.8341, validation loss: 0.9722
2024-05-25 02:18:54 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch26_loss0.9722353667020798.pypots
2024-05-25 02:18:55 [INFO]: Epoch 027 - training loss: 0.8270, validation loss: 0.9646
2024-05-25 02:18:55 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch27_loss0.9646000862121582.pypots
2024-05-25 02:18:55 [INFO]: Epoch 028 - training loss: 0.8688, validation loss: 0.9601
2024-05-25 02:18:55 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch28_loss0.9600774347782135.pypots
2024-05-25 02:18:55 [INFO]: Epoch 029 - training loss: 0.8735, validation loss: 0.9587
2024-05-25 02:18:55 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch29_loss0.9587409049272537.pypots
2024-05-25 02:18:55 [INFO]: Epoch 030 - training loss: 0.8429, validation loss: 0.9526
2024-05-25 02:18:55 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch30_loss0.9525963664054871.pypots
2024-05-25 02:18:55 [INFO]: Epoch 031 - training loss: 0.8215, validation loss: 0.9520
2024-05-25 02:18:55 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch31_loss0.9520378559827805.pypots
2024-05-25 02:18:56 [INFO]: Epoch 032 - training loss: 0.8257, validation loss: 0.9471
2024-05-25 02:18:56 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch32_loss0.9470751583576202.pypots
2024-05-25 02:18:56 [INFO]: Epoch 033 - training loss: 0.8132, validation loss: 0.9420
2024-05-25 02:18:56 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch33_loss0.9420362561941147.pypots
2024-05-25 02:18:56 [INFO]: Epoch 034 - training loss: 0.8099, validation loss: 0.9395
2024-05-25 02:18:56 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch34_loss0.9395009875297546.pypots
2024-05-25 02:18:56 [INFO]: Epoch 035 - training loss: 0.8066, validation loss: 0.9347
2024-05-25 02:18:56 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch35_loss0.9347164928913116.pypots
2024-05-25 02:18:56 [INFO]: Epoch 036 - training loss: 0.8334, validation loss: 0.9333
2024-05-25 02:18:56 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch36_loss0.9332930743694305.pypots
2024-05-25 02:18:56 [INFO]: Epoch 037 - training loss: 0.8429, validation loss: 0.9336
2024-05-25 02:18:56 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch37_loss0.9336178004741669.pypots
2024-05-25 02:18:57 [INFO]: Epoch 038 - training loss: 0.8031, validation loss: 0.9271
2024-05-25 02:18:57 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch38_loss0.9271186888217926.pypots
2024-05-25 02:18:57 [INFO]: Epoch 039 - training loss: 0.8053, validation loss: 0.9268
2024-05-25 02:18:57 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch39_loss0.9268249124288559.pypots
2024-05-25 02:18:57 [INFO]: Epoch 040 - training loss: 0.8035, validation loss: 0.9241
2024-05-25 02:18:57 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch40_loss0.924058198928833.pypots
2024-05-25 02:18:57 [INFO]: Epoch 041 - training loss: 0.8129, validation loss: 0.9227
2024-05-25 02:18:57 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch41_loss0.922737330198288.pypots
2024-05-25 02:18:57 [INFO]: Epoch 042 - training loss: 0.8112, validation loss: 0.9192
2024-05-25 02:18:57 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch42_loss0.9192408472299576.pypots
2024-05-25 02:18:58 [INFO]: Epoch 043 - training loss: 0.8242, validation loss: 0.9168
2024-05-25 02:18:58 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch43_loss0.9168252497911453.pypots
2024-05-25 02:18:58 [INFO]: Epoch 044 - training loss: 0.8142, validation loss: 0.9128
2024-05-25 02:18:58 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch44_loss0.9128346145153046.pypots
2024-05-25 02:18:58 [INFO]: Epoch 045 - training loss: 0.8189, validation loss: 0.9093
2024-05-25 02:18:58 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch45_loss0.9093146026134491.pypots
2024-05-25 02:18:58 [INFO]: Epoch 046 - training loss: 0.8573, validation loss: 0.9068
2024-05-25 02:18:58 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch46_loss0.9068099558353424.pypots
2024-05-25 02:18:58 [INFO]: Epoch 047 - training loss: 0.8238, validation loss: 0.9032
2024-05-25 02:18:58 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch47_loss0.9031678885221481.pypots
2024-05-25 02:18:59 [INFO]: Epoch 048 - training loss: 0.8237, validation loss: 0.9030
2024-05-25 02:18:59 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch48_loss0.9029973596334457.pypots
2024-05-25 02:18:59 [INFO]: Epoch 049 - training loss: 0.8019, validation loss: 0.8992
2024-05-25 02:18:59 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch49_loss0.8991574496030807.pypots
2024-05-25 02:18:59 [INFO]: Epoch 050 - training loss: 0.8086, validation loss: 0.8977
2024-05-25 02:18:59 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch50_loss0.8977298736572266.pypots
2024-05-25 02:18:59 [INFO]: Epoch 051 - training loss: 0.7932, validation loss: 0.8966
2024-05-25 02:18:59 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch51_loss0.8966079205274582.pypots
2024-05-25 02:18:59 [INFO]: Epoch 052 - training loss: 0.8076, validation loss: 0.8948
2024-05-25 02:18:59 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch52_loss0.8947613537311554.pypots
2024-05-25 02:19:00 [INFO]: Epoch 053 - training loss: 0.8171, validation loss: 0.8956
2024-05-25 02:19:00 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch53_loss0.895602211356163.pypots
2024-05-25 02:19:00 [INFO]: Epoch 054 - training loss: 0.7876, validation loss: 0.8925
2024-05-25 02:19:00 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch54_loss0.892479881644249.pypots
2024-05-25 02:19:00 [INFO]: Epoch 055 - training loss: 0.7989, validation loss: 0.8894
2024-05-25 02:19:00 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch55_loss0.8893927186727524.pypots
2024-05-25 02:19:00 [INFO]: Epoch 056 - training loss: 0.8071, validation loss: 0.8867
2024-05-25 02:19:00 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch56_loss0.8866816610097885.pypots
2024-05-25 02:19:00 [INFO]: Epoch 057 - training loss: 0.7913, validation loss: 0.8876
2024-05-25 02:19:00 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch57_loss0.8875859081745148.pypots
2024-05-25 02:19:00 [INFO]: Epoch 058 - training loss: 0.8008, validation loss: 0.8851
2024-05-25 02:19:00 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch58_loss0.8851284235715866.pypots
2024-05-25 02:19:01 [INFO]: Epoch 059 - training loss: 0.7895, validation loss: 0.8844
2024-05-25 02:19:01 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch59_loss0.8843951523303986.pypots
2024-05-25 02:19:01 [INFO]: Epoch 060 - training loss: 0.8009, validation loss: 0.8830
2024-05-25 02:19:01 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch60_loss0.882985845208168.pypots
2024-05-25 02:19:01 [INFO]: Epoch 061 - training loss: 0.8243, validation loss: 0.8795
2024-05-25 02:19:01 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch61_loss0.8795345276594162.pypots
2024-05-25 02:19:01 [INFO]: Epoch 062 - training loss: 0.8185, validation loss: 0.8804
2024-05-25 02:19:01 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch62_loss0.8803666830062866.pypots
2024-05-25 02:19:01 [INFO]: Epoch 063 - training loss: 0.8158, validation loss: 0.8773
2024-05-25 02:19:01 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch63_loss0.87729212641716.pypots
2024-05-25 02:19:02 [INFO]: Epoch 064 - training loss: 0.8613, validation loss: 0.8768
2024-05-25 02:19:02 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch64_loss0.8768432140350342.pypots
2024-05-25 02:19:02 [INFO]: Epoch 065 - training loss: 0.8097, validation loss: 0.8756
2024-05-25 02:19:02 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch65_loss0.875569149851799.pypots
2024-05-25 02:19:02 [INFO]: Epoch 066 - training loss: 0.8019, validation loss: 0.8737
2024-05-25 02:19:02 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch66_loss0.8736519515514374.pypots
2024-05-25 02:19:02 [INFO]: Epoch 067 - training loss: 0.8017, validation loss: 0.8733
2024-05-25 02:19:02 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch67_loss0.8732719123363495.pypots
2024-05-25 02:19:02 [INFO]: Epoch 068 - training loss: 0.8055, validation loss: 0.8709
2024-05-25 02:19:02 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch68_loss0.870906189084053.pypots
2024-05-25 02:19:03 [INFO]: Epoch 069 - training loss: 0.8093, validation loss: 0.8690
2024-05-25 02:19:03 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch69_loss0.8690399080514908.pypots
2024-05-25 02:19:03 [INFO]: Epoch 070 - training loss: 0.8024, validation loss: 0.8708
2024-05-25 02:19:03 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch70_loss0.8708013445138931.pypots
2024-05-25 02:19:03 [INFO]: Epoch 071 - training loss: 0.8354, validation loss: 0.8713
2024-05-25 02:19:03 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch71_loss0.8712976276874542.pypots
2024-05-25 02:19:03 [INFO]: Epoch 072 - training loss: 0.7998, validation loss: 0.8677
2024-05-25 02:19:03 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch72_loss0.867675319314003.pypots
2024-05-25 02:19:03 [INFO]: Epoch 073 - training loss: 0.7808, validation loss: 0.8679
2024-05-25 02:19:03 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch73_loss0.8678786903619766.pypots
2024-05-25 02:19:03 [INFO]: Epoch 074 - training loss: 0.7719, validation loss: 0.8643
2024-05-25 02:19:03 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch74_loss0.864275649189949.pypots
2024-05-25 02:19:04 [INFO]: Epoch 075 - training loss: 0.7876, validation loss: 0.8643
2024-05-25 02:19:04 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch75_loss0.8643166571855545.pypots
2024-05-25 02:19:04 [INFO]: Epoch 076 - training loss: 0.8104, validation loss: 0.8632
2024-05-25 02:19:04 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch76_loss0.8631781190633774.pypots
2024-05-25 02:19:04 [INFO]: Epoch 077 - training loss: 0.8050, validation loss: 0.8645
2024-05-25 02:19:04 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch77_loss0.864488959312439.pypots
2024-05-25 02:19:04 [INFO]: Epoch 078 - training loss: 0.8236, validation loss: 0.8663
2024-05-25 02:19:04 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch78_loss0.8663280010223389.pypots
2024-05-25 02:19:04 [INFO]: Epoch 079 - training loss: 0.8046, validation loss: 0.8636
2024-05-25 02:19:04 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch79_loss0.8636478334665298.pypots
2024-05-25 02:19:05 [INFO]: Epoch 080 - training loss: 0.7885, validation loss: 0.8627
2024-05-25 02:19:05 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch80_loss0.8627214133739471.pypots
2024-05-25 02:19:05 [INFO]: Epoch 081 - training loss: 0.7989, validation loss: 0.8628
2024-05-25 02:19:05 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch81_loss0.8628412187099457.pypots
2024-05-25 02:19:05 [INFO]: Epoch 082 - training loss: 0.7867, validation loss: 0.8606
2024-05-25 02:19:05 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch82_loss0.8605918437242508.pypots
2024-05-25 02:19:05 [INFO]: Epoch 083 - training loss: 0.7779, validation loss: 0.8613
2024-05-25 02:19:05 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch83_loss0.8612712472677231.pypots
2024-05-25 02:19:05 [INFO]: Epoch 084 - training loss: 0.7820, validation loss: 0.8617
2024-05-25 02:19:05 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch84_loss0.8616573512554169.pypots
2024-05-25 02:19:06 [INFO]: Epoch 085 - training loss: 0.7809, validation loss: 0.8598
2024-05-25 02:19:06 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch85_loss0.8597569018602371.pypots
2024-05-25 02:19:06 [INFO]: Epoch 086 - training loss: 0.8051, validation loss: 0.8618
2024-05-25 02:19:06 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch86_loss0.8618396073579788.pypots
2024-05-25 02:19:06 [INFO]: Epoch 087 - training loss: 0.7896, validation loss: 0.8610
2024-05-25 02:19:06 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch87_loss0.8610304296016693.pypots
2024-05-25 02:19:06 [INFO]: Epoch 088 - training loss: 0.7646, validation loss: 0.8593
2024-05-25 02:19:06 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch88_loss0.859345406293869.pypots
2024-05-25 02:19:06 [INFO]: Epoch 089 - training loss: 0.7722, validation loss: 0.8587
2024-05-25 02:19:06 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch89_loss0.8586894869804382.pypots
2024-05-25 02:19:06 [INFO]: Epoch 090 - training loss: 0.7826, validation loss: 0.8607
2024-05-25 02:19:06 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch90_loss0.8606831580400467.pypots
2024-05-25 02:19:07 [INFO]: Epoch 091 - training loss: 0.7860, validation loss: 0.8577
2024-05-25 02:19:07 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch91_loss0.8576865792274475.pypots
2024-05-25 02:19:07 [INFO]: Epoch 092 - training loss: 0.7933, validation loss: 0.8572
2024-05-25 02:19:07 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch92_loss0.8572266846895218.pypots
2024-05-25 02:19:07 [INFO]: Epoch 093 - training loss: 0.7808, validation loss: 0.8589
2024-05-25 02:19:07 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch93_loss0.8588775247335434.pypots
2024-05-25 02:19:07 [INFO]: Epoch 094 - training loss: 0.8004, validation loss: 0.8584
2024-05-25 02:19:07 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch94_loss0.8584418445825577.pypots
2024-05-25 02:19:07 [INFO]: Epoch 095 - training loss: 0.7654, validation loss: 0.8598
2024-05-25 02:19:07 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch95_loss0.859814003109932.pypots
2024-05-25 02:19:08 [INFO]: Epoch 096 - training loss: 0.8237, validation loss: 0.8572
2024-05-25 02:19:08 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch96_loss0.857208713889122.pypots
2024-05-25 02:19:08 [INFO]: Epoch 097 - training loss: 0.8157, validation loss: 0.8620
2024-05-25 02:19:08 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch97_loss0.8619993776082993.pypots
2024-05-25 02:19:08 [INFO]: Epoch 098 - training loss: 0.8007, validation loss: 0.8621
2024-05-25 02:19:08 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch98_loss0.8620847910642624.pypots
2024-05-25 02:19:08 [INFO]: Epoch 099 - training loss: 0.7840, validation loss: 0.8589
2024-05-25 02:19:08 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch99_loss0.8588699400424957.pypots
2024-05-25 02:19:08 [INFO]: Epoch 100 - training loss: 0.7864, validation loss: 0.8578
2024-05-25 02:19:08 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch100_loss0.8577824831008911.pypots
2024-05-25 02:19:09 [INFO]: Epoch 101 - training loss: 0.7749, validation loss: 0.8560
2024-05-25 02:19:09 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch101_loss0.855998769402504.pypots
2024-05-25 02:19:09 [INFO]: Epoch 102 - training loss: 0.7818, validation loss: 0.8609
2024-05-25 02:19:09 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch102_loss0.8609409034252167.pypots
2024-05-25 02:19:09 [INFO]: Epoch 103 - training loss: 0.7776, validation loss: 0.8581
2024-05-25 02:19:09 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch103_loss0.8580769449472427.pypots
2024-05-25 02:19:09 [INFO]: Epoch 104 - training loss: 0.8074, validation loss: 0.8574
2024-05-25 02:19:09 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch104_loss0.8574410229921341.pypots
2024-05-25 02:19:09 [INFO]: Epoch 105 - training loss: 0.7842, validation loss: 0.8558
2024-05-25 02:19:09 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch105_loss0.8558445572853088.pypots
2024-05-25 02:19:10 [INFO]: Epoch 106 - training loss: 0.7865, validation loss: 0.8619
2024-05-25 02:19:10 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch106_loss0.8618615716695786.pypots
2024-05-25 02:19:10 [INFO]: Epoch 107 - training loss: 0.7899, validation loss: 0.8604
2024-05-25 02:19:10 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch107_loss0.8604274988174438.pypots
2024-05-25 02:19:10 [INFO]: Epoch 108 - training loss: 0.7873, validation loss: 0.8568
2024-05-25 02:19:10 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch108_loss0.8567743450403214.pypots
2024-05-25 02:19:10 [INFO]: Epoch 109 - training loss: 0.8223, validation loss: 0.8599
2024-05-25 02:19:10 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch109_loss0.8598761558532715.pypots
2024-05-25 02:19:10 [INFO]: Epoch 110 - training loss: 0.8067, validation loss: 0.8626
2024-05-25 02:19:10 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch110_loss0.8625605553388596.pypots
2024-05-25 02:19:10 [INFO]: Epoch 111 - training loss: 0.7823, validation loss: 0.8595
2024-05-25 02:19:10 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch111_loss0.8595354408025742.pypots
2024-05-25 02:19:11 [INFO]: Epoch 112 - training loss: 0.7866, validation loss: 0.8590
2024-05-25 02:19:11 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch112_loss0.8590265065431595.pypots
2024-05-25 02:19:11 [INFO]: Epoch 113 - training loss: 0.8254, validation loss: 0.8593
2024-05-25 02:19:11 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch113_loss0.8592871278524399.pypots
2024-05-25 02:19:11 [INFO]: Epoch 114 - training loss: 0.7968, validation loss: 0.8521
2024-05-25 02:19:11 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch114_loss0.8521256297826767.pypots
2024-05-25 02:19:11 [INFO]: Epoch 115 - training loss: 0.7970, validation loss: 0.8584
2024-05-25 02:19:11 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch115_loss0.8583953529596329.pypots
2024-05-25 02:19:11 [INFO]: Epoch 116 - training loss: 0.7827, validation loss: 0.8586
2024-05-25 02:19:11 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch116_loss0.8586037755012512.pypots
2024-05-25 02:19:12 [INFO]: Epoch 117 - training loss: 0.7709, validation loss: 0.8573
2024-05-25 02:19:12 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch117_loss0.8573162704706192.pypots
2024-05-25 02:19:12 [INFO]: Epoch 118 - training loss: 0.8151, validation loss: 0.8608
2024-05-25 02:19:12 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch118_loss0.8607558310031891.pypots
2024-05-25 02:19:12 [INFO]: Epoch 119 - training loss: 0.8069, validation loss: 0.8582
2024-05-25 02:19:12 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch119_loss0.8582084625959396.pypots
2024-05-25 02:19:12 [INFO]: Epoch 120 - training loss: 0.7988, validation loss: 0.8601
2024-05-25 02:19:12 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch120_loss0.8600526452064514.pypots
2024-05-25 02:19:12 [INFO]: Epoch 121 - training loss: 0.8093, validation loss: 0.8583
2024-05-25 02:19:12 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch121_loss0.8582763969898224.pypots
2024-05-25 02:19:13 [INFO]: Epoch 122 - training loss: 0.7805, validation loss: 0.8557
2024-05-25 02:19:13 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch122_loss0.8557419925928116.pypots
2024-05-25 02:19:13 [INFO]: Epoch 123 - training loss: 0.7931, validation loss: 0.8572
2024-05-25 02:19:13 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch123_loss0.8571867495775223.pypots
2024-05-25 02:19:13 [INFO]: Epoch 124 - training loss: 0.7819, validation loss: 0.8528
2024-05-25 02:19:13 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN_epoch124_loss0.8528345227241516.pypots
2024-05-25 02:19:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:19:13 [INFO]: Finished training. The best model is from epoch#114.
2024-05-25 02:19:13 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T021848/MRNN.pypots
2024-05-25 02:19:13 [INFO]: MRNN on ETTm1: MAE=0.6813, MSE=1.1212
2024-05-25 02:19:13 [INFO]: Successfully saved to augmentation_saved_results/round_2/MRNN_ettm1/imputation.pkl
2024-05-25 02:19:13 [INFO]: Using the given device: cpu
2024-05-25 02:19:13 [INFO]: LOCF on ETTm1: MAE=0.1348, MSE=0.0715
2024-05-25 02:19:13 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_ettm1".
2024-05-25 02:19:13 [INFO]: Successfully saved to augmentation_saved_results/round_2/LOCF_ettm1/imputation.pkl
2024-05-25 02:19:13 [INFO]: Median on ETTm1: MAE=0.6516, MSE=0.8223
2024-05-25 02:19:13 [INFO]: Successfully created the given path "saved_results/round_2/Median_ettm1".
2024-05-25 02:19:13 [INFO]: Successfully saved to augmentation_saved_results/round_2/Median_ettm1/imputation.pkl
2024-05-25 02:19:13 [INFO]: Mean on ETTm1: MAE=0.6566, MSE=0.8036
2024-05-25 02:19:13 [INFO]: Successfully created the given path "saved_results/round_2/Mean_ettm1".
2024-05-25 02:19:13 [INFO]: Successfully saved to augmentation_saved_results/round_2/Mean_ettm1/imputation.pkl
2024-05-25 02:19:13 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-25 02:19:13 [INFO]: Using the given device: cuda:0
2024-05-25 02:19:13 [INFO]: Model files will be saved to augmentation_saved_results/round_3/SAITS_ettm1/20240525_T021913
2024-05-25 02:19:13 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/SAITS_ettm1/20240525_T021913/tensorboard
2024-05-25 02:19:13 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 02:19:14 [INFO]: Epoch 001 - training loss: 1.2003, validation loss: 0.3057
2024-05-25 02:19:14 [INFO]: Epoch 002 - training loss: 0.8917, validation loss: 0.1502
2024-05-25 02:19:15 [INFO]: Epoch 003 - training loss: 0.7614, validation loss: 0.0999
2024-05-25 02:19:15 [INFO]: Epoch 004 - training loss: 0.7033, validation loss: 0.1099
2024-05-25 02:19:16 [INFO]: Epoch 005 - training loss: 0.6705, validation loss: 0.0659
2024-05-25 02:19:16 [INFO]: Epoch 006 - training loss: 0.6559, validation loss: 0.0944
2024-05-25 02:19:17 [INFO]: Epoch 007 - training loss: 0.6461, validation loss: 0.0856
2024-05-25 02:19:17 [INFO]: Epoch 008 - training loss: 0.6168, validation loss: 0.0834
2024-05-25 02:19:18 [INFO]: Epoch 009 - training loss: 0.6041, validation loss: 0.0711
2024-05-25 02:19:19 [INFO]: Epoch 010 - training loss: 0.6033, validation loss: 0.0813
2024-05-25 02:19:19 [INFO]: Epoch 011 - training loss: 0.5885, validation loss: 0.0812
2024-05-25 02:19:20 [INFO]: Epoch 012 - training loss: 0.5731, validation loss: 0.0640
2024-05-25 02:19:20 [INFO]: Epoch 013 - training loss: 0.5616, validation loss: 0.0467
2024-05-25 02:19:21 [INFO]: Epoch 014 - training loss: 0.5637, validation loss: 0.0875
2024-05-25 02:19:21 [INFO]: Epoch 015 - training loss: 0.5587, validation loss: 0.0480
2024-05-25 02:19:22 [INFO]: Epoch 016 - training loss: 0.5454, validation loss: 0.0540
2024-05-25 02:19:22 [INFO]: Epoch 017 - training loss: 0.5430, validation loss: 0.0577
2024-05-25 02:19:23 [INFO]: Epoch 018 - training loss: 0.5518, validation loss: 0.0638
2024-05-25 02:19:23 [INFO]: Epoch 019 - training loss: 0.5282, validation loss: 0.0443
2024-05-25 02:19:24 [INFO]: Epoch 020 - training loss: 0.5411, validation loss: 0.0533
2024-05-25 02:19:24 [INFO]: Epoch 021 - training loss: 0.5389, validation loss: 0.0502
2024-05-25 02:19:25 [INFO]: Epoch 022 - training loss: 0.5118, validation loss: 0.0529
2024-05-25 02:19:25 [INFO]: Epoch 023 - training loss: 0.5096, validation loss: 0.0523
2024-05-25 02:19:26 [INFO]: Epoch 024 - training loss: 0.5093, validation loss: 0.0473
2024-05-25 02:19:26 [INFO]: Epoch 025 - training loss: 0.4962, validation loss: 0.0467
2024-05-25 02:19:27 [INFO]: Epoch 026 - training loss: 0.4910, validation loss: 0.0435
2024-05-25 02:19:27 [INFO]: Epoch 027 - training loss: 0.4813, validation loss: 0.0356
2024-05-25 02:19:28 [INFO]: Epoch 028 - training loss: 0.4857, validation loss: 0.0458
2024-05-25 02:19:28 [INFO]: Epoch 029 - training loss: 0.4770, validation loss: 0.0394
2024-05-25 02:19:29 [INFO]: Epoch 030 - training loss: 0.4940, validation loss: 0.0456
2024-05-25 02:19:29 [INFO]: Epoch 031 - training loss: 0.4888, validation loss: 0.0431
2024-05-25 02:19:30 [INFO]: Epoch 032 - training loss: 0.4888, validation loss: 0.0429
2024-05-25 02:19:30 [INFO]: Epoch 033 - training loss: 0.4871, validation loss: 0.0443
2024-05-25 02:19:31 [INFO]: Epoch 034 - training loss: 0.4629, validation loss: 0.0327
2024-05-25 02:19:31 [INFO]: Epoch 035 - training loss: 0.4577, validation loss: 0.0388
2024-05-25 02:19:32 [INFO]: Epoch 036 - training loss: 0.4547, validation loss: 0.0374
2024-05-25 02:19:32 [INFO]: Epoch 037 - training loss: 0.4441, validation loss: 0.0322
2024-05-25 02:19:33 [INFO]: Epoch 038 - training loss: 0.4487, validation loss: 0.0373
2024-05-25 02:19:33 [INFO]: Epoch 039 - training loss: 0.4402, validation loss: 0.0383
2024-05-25 02:19:34 [INFO]: Epoch 040 - training loss: 0.4447, validation loss: 0.0347
2024-05-25 02:19:34 [INFO]: Epoch 041 - training loss: 0.4416, validation loss: 0.0306
2024-05-25 02:19:35 [INFO]: Epoch 042 - training loss: 0.4376, validation loss: 0.0289
2024-05-25 02:19:35 [INFO]: Epoch 043 - training loss: 0.4428, validation loss: 0.0440
2024-05-25 02:19:36 [INFO]: Epoch 044 - training loss: 0.4381, validation loss: 0.0313
2024-05-25 02:19:36 [INFO]: Epoch 045 - training loss: 0.4357, validation loss: 0.0356
2024-05-25 02:19:37 [INFO]: Epoch 046 - training loss: 0.4334, validation loss: 0.0395
2024-05-25 02:19:37 [INFO]: Epoch 047 - training loss: 0.4322, validation loss: 0.0325
2024-05-25 02:19:38 [INFO]: Epoch 048 - training loss: 0.4317, validation loss: 0.0282
2024-05-25 02:19:38 [INFO]: Epoch 049 - training loss: 0.4207, validation loss: 0.0302
2024-05-25 02:19:39 [INFO]: Epoch 050 - training loss: 0.4170, validation loss: 0.0361
2024-05-25 02:19:40 [INFO]: Epoch 051 - training loss: 0.4197, validation loss: 0.0352
2024-05-25 02:19:40 [INFO]: Epoch 052 - training loss: 0.4197, validation loss: 0.0317
2024-05-25 02:19:41 [INFO]: Epoch 053 - training loss: 0.4071, validation loss: 0.0281
2024-05-25 02:19:41 [INFO]: Epoch 054 - training loss: 0.4004, validation loss: 0.0339
2024-05-25 02:19:42 [INFO]: Epoch 055 - training loss: 0.4007, validation loss: 0.0264
2024-05-25 02:19:42 [INFO]: Epoch 056 - training loss: 0.4082, validation loss: 0.0418
2024-05-25 02:19:43 [INFO]: Epoch 057 - training loss: 0.4054, validation loss: 0.0294
2024-05-25 02:19:43 [INFO]: Epoch 058 - training loss: 0.4027, validation loss: 0.0353
2024-05-25 02:19:44 [INFO]: Epoch 059 - training loss: 0.4012, validation loss: 0.0267
2024-05-25 02:19:44 [INFO]: Epoch 060 - training loss: 0.3954, validation loss: 0.0343
2024-05-25 02:19:45 [INFO]: Epoch 061 - training loss: 0.3913, validation loss: 0.0266
2024-05-25 02:19:45 [INFO]: Epoch 062 - training loss: 0.3882, validation loss: 0.0268
2024-05-25 02:19:46 [INFO]: Epoch 063 - training loss: 0.3736, validation loss: 0.0296
2024-05-25 02:19:46 [INFO]: Epoch 064 - training loss: 0.3621, validation loss: 0.0305
2024-05-25 02:19:47 [INFO]: Epoch 065 - training loss: 0.3667, validation loss: 0.0282
2024-05-25 02:19:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:19:47 [INFO]: Finished training. The best model is from epoch#55.
2024-05-25 02:19:47 [INFO]: Saved the model to augmentation_saved_results/round_3/SAITS_ettm1/20240525_T021913/SAITS.pypots
2024-05-25 02:19:47 [INFO]: SAITS on ETTm1: MAE=0.1696, MSE=0.0504
2024-05-25 02:19:47 [INFO]: Successfully saved to augmentation_saved_results/round_3/SAITS_ettm1/imputation.pkl
2024-05-25 02:19:47 [INFO]: Using the given device: cuda:0
2024-05-25 02:19:47 [INFO]: Model files will be saved to augmentation_saved_results/round_3/Transformer_ettm1/20240525_T021947
2024-05-25 02:19:47 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/Transformer_ettm1/20240525_T021947/tensorboard
2024-05-25 02:19:47 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 02:19:47 [INFO]: Epoch 001 - training loss: 1.1760, validation loss: 0.3349
2024-05-25 02:19:47 [INFO]: Epoch 002 - training loss: 0.7489, validation loss: 0.1515
2024-05-25 02:19:47 [INFO]: Epoch 003 - training loss: 0.6092, validation loss: 0.1016
2024-05-25 02:19:48 [INFO]: Epoch 004 - training loss: 0.5253, validation loss: 0.0759
2024-05-25 02:19:48 [INFO]: Epoch 005 - training loss: 0.4818, validation loss: 0.0640
2024-05-25 02:19:48 [INFO]: Epoch 006 - training loss: 0.4556, validation loss: 0.0590
2024-05-25 02:19:48 [INFO]: Epoch 007 - training loss: 0.4386, validation loss: 0.0539
2024-05-25 02:19:49 [INFO]: Epoch 008 - training loss: 0.4233, validation loss: 0.0511
2024-05-25 02:19:49 [INFO]: Epoch 009 - training loss: 0.4066, validation loss: 0.0488
2024-05-25 02:19:49 [INFO]: Epoch 010 - training loss: 0.3931, validation loss: 0.0449
2024-05-25 02:19:49 [INFO]: Epoch 011 - training loss: 0.3789, validation loss: 0.0477
2024-05-25 02:19:49 [INFO]: Epoch 012 - training loss: 0.3754, validation loss: 0.0512
2024-05-25 02:19:50 [INFO]: Epoch 013 - training loss: 0.3703, validation loss: 0.0455
2024-05-25 02:19:50 [INFO]: Epoch 014 - training loss: 0.3642, validation loss: 0.0465
2024-05-25 02:19:50 [INFO]: Epoch 015 - training loss: 0.3514, validation loss: 0.0398
2024-05-25 02:19:50 [INFO]: Epoch 016 - training loss: 0.3389, validation loss: 0.0417
2024-05-25 02:19:51 [INFO]: Epoch 017 - training loss: 0.3393, validation loss: 0.0394
2024-05-25 02:19:51 [INFO]: Epoch 018 - training loss: 0.3291, validation loss: 0.0371
2024-05-25 02:19:51 [INFO]: Epoch 019 - training loss: 0.3282, validation loss: 0.0383
2024-05-25 02:19:51 [INFO]: Epoch 020 - training loss: 0.3308, validation loss: 0.0329
2024-05-25 02:19:51 [INFO]: Epoch 021 - training loss: 0.3314, validation loss: 0.0350
2024-05-25 02:19:52 [INFO]: Epoch 022 - training loss: 0.3187, validation loss: 0.0325
2024-05-25 02:19:52 [INFO]: Epoch 023 - training loss: 0.3116, validation loss: 0.0351
2024-05-25 02:19:52 [INFO]: Epoch 024 - training loss: 0.3093, validation loss: 0.0319
2024-05-25 02:19:52 [INFO]: Epoch 025 - training loss: 0.2977, validation loss: 0.0295
2024-05-25 02:19:52 [INFO]: Epoch 026 - training loss: 0.2918, validation loss: 0.0291
2024-05-25 02:19:53 [INFO]: Epoch 027 - training loss: 0.2940, validation loss: 0.0290
2024-05-25 02:19:53 [INFO]: Epoch 028 - training loss: 0.2935, validation loss: 0.0306
2024-05-25 02:19:53 [INFO]: Epoch 029 - training loss: 0.2945, validation loss: 0.0288
2024-05-25 02:19:53 [INFO]: Epoch 030 - training loss: 0.2816, validation loss: 0.0320
2024-05-25 02:19:54 [INFO]: Epoch 031 - training loss: 0.2793, validation loss: 0.0287
2024-05-25 02:19:54 [INFO]: Epoch 032 - training loss: 0.2766, validation loss: 0.0325
2024-05-25 02:19:54 [INFO]: Epoch 033 - training loss: 0.2738, validation loss: 0.0338
2024-05-25 02:19:54 [INFO]: Epoch 034 - training loss: 0.2717, validation loss: 0.0274
2024-05-25 02:19:54 [INFO]: Epoch 035 - training loss: 0.2652, validation loss: 0.0289
2024-05-25 02:19:55 [INFO]: Epoch 036 - training loss: 0.2655, validation loss: 0.0314
2024-05-25 02:19:55 [INFO]: Epoch 037 - training loss: 0.2633, validation loss: 0.0255
2024-05-25 02:19:55 [INFO]: Epoch 038 - training loss: 0.2625, validation loss: 0.0237
2024-05-25 02:19:55 [INFO]: Epoch 039 - training loss: 0.2576, validation loss: 0.0308
2024-05-25 02:19:56 [INFO]: Epoch 040 - training loss: 0.2554, validation loss: 0.0301
2024-05-25 02:19:56 [INFO]: Epoch 041 - training loss: 0.2517, validation loss: 0.0263
2024-05-25 02:19:56 [INFO]: Epoch 042 - training loss: 0.2567, validation loss: 0.0251
2024-05-25 02:19:56 [INFO]: Epoch 043 - training loss: 0.2553, validation loss: 0.0259
2024-05-25 02:19:56 [INFO]: Epoch 044 - training loss: 0.2530, validation loss: 0.0245
2024-05-25 02:19:57 [INFO]: Epoch 045 - training loss: 0.2503, validation loss: 0.0241
2024-05-25 02:19:57 [INFO]: Epoch 046 - training loss: 0.2429, validation loss: 0.0280
2024-05-25 02:19:57 [INFO]: Epoch 047 - training loss: 0.2476, validation loss: 0.0257
2024-05-25 02:19:57 [INFO]: Epoch 048 - training loss: 0.2447, validation loss: 0.0267
2024-05-25 02:19:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:19:57 [INFO]: Finished training. The best model is from epoch#38.
2024-05-25 02:19:57 [INFO]: Saved the model to augmentation_saved_results/round_3/Transformer_ettm1/20240525_T021947/Transformer.pypots
2024-05-25 02:19:57 [INFO]: Transformer on ETTm1: MAE=0.1289, MSE=0.0320
2024-05-25 02:19:57 [INFO]: Successfully saved to augmentation_saved_results/round_3/Transformer_ettm1/imputation.pkl
2024-05-25 02:19:57 [INFO]: Using the given device: cuda:0
2024-05-25 02:19:57 [INFO]: Model files will be saved to augmentation_saved_results/round_3/TimesNet_ettm1/20240525_T021957
2024-05-25 02:19:57 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/TimesNet_ettm1/20240525_T021957/tensorboard
2024-05-25 02:19:58 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 02:19:58 [INFO]: Epoch 001 - training loss: 0.1525, validation loss: 0.0518
2024-05-25 02:19:58 [INFO]: Epoch 002 - training loss: 0.0638, validation loss: 0.0381
2024-05-25 02:19:58 [INFO]: Epoch 003 - training loss: 0.0547, validation loss: 0.0325
2024-05-25 02:19:58 [INFO]: Epoch 004 - training loss: 0.0498, validation loss: 0.0312
2024-05-25 02:19:59 [INFO]: Epoch 005 - training loss: 0.0476, validation loss: 0.0307
2024-05-25 02:19:59 [INFO]: Epoch 006 - training loss: 0.0482, validation loss: 0.0340
2024-05-25 02:19:59 [INFO]: Epoch 007 - training loss: 0.0461, validation loss: 0.0277
2024-05-25 02:19:59 [INFO]: Epoch 008 - training loss: 0.0427, validation loss: 0.0267
2024-05-25 02:19:59 [INFO]: Epoch 009 - training loss: 0.0433, validation loss: 0.0283
2024-05-25 02:20:00 [INFO]: Epoch 010 - training loss: 0.0426, validation loss: 0.0290
2024-05-25 02:20:00 [INFO]: Epoch 011 - training loss: 0.0429, validation loss: 0.0271
2024-05-25 02:20:00 [INFO]: Epoch 012 - training loss: 0.0436, validation loss: 0.0281
2024-05-25 02:20:00 [INFO]: Epoch 013 - training loss: 0.0426, validation loss: 0.0296
2024-05-25 02:20:00 [INFO]: Epoch 014 - training loss: 0.0426, validation loss: 0.0276
2024-05-25 02:20:01 [INFO]: Epoch 015 - training loss: 0.0399, validation loss: 0.0283
2024-05-25 02:20:01 [INFO]: Epoch 016 - training loss: 0.0413, validation loss: 0.0268
2024-05-25 02:20:01 [INFO]: Epoch 017 - training loss: 0.0400, validation loss: 0.0282
2024-05-25 02:20:01 [INFO]: Epoch 018 - training loss: 0.0398, validation loss: 0.0275
2024-05-25 02:20:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:20:01 [INFO]: Finished training. The best model is from epoch#8.
2024-05-25 02:20:01 [INFO]: Saved the model to augmentation_saved_results/round_3/TimesNet_ettm1/20240525_T021957/TimesNet.pypots
2024-05-25 02:20:01 [INFO]: TimesNet on ETTm1: MAE=0.1206, MSE=0.0301
2024-05-25 02:20:01 [INFO]: Successfully saved to augmentation_saved_results/round_3/TimesNet_ettm1/imputation.pkl
2024-05-25 02:20:01 [INFO]: Using the given device: cuda:0
2024-05-25 02:20:01 [INFO]: Model files will be saved to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001
2024-05-25 02:20:01 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/tensorboard
2024-05-25 02:20:01 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 02:20:04 [INFO]: Epoch 001 - training loss: 0.6877, validation loss: 0.4216
2024-05-25 02:20:04 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch1_loss0.4216356799006462.pypots
2024-05-25 02:20:06 [INFO]: Epoch 002 - training loss: 0.3882, validation loss: 0.3602
2024-05-25 02:20:06 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch2_loss0.3602333664894104.pypots
2024-05-25 02:20:08 [INFO]: Epoch 003 - training loss: 0.3319, validation loss: 0.3396
2024-05-25 02:20:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch3_loss0.3395538181066513.pypots
2024-05-25 02:20:10 [INFO]: Epoch 004 - training loss: 0.3451, validation loss: 0.3163
2024-05-25 02:20:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch4_loss0.31628476083278656.pypots
2024-05-25 02:20:12 [INFO]: Epoch 005 - training loss: 0.3251, validation loss: 0.3131
2024-05-25 02:20:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch5_loss0.31306126713752747.pypots
2024-05-25 02:20:14 [INFO]: Epoch 006 - training loss: 0.3136, validation loss: 0.2930
2024-05-25 02:20:14 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch6_loss0.29296789318323135.pypots
2024-05-25 02:20:16 [INFO]: Epoch 007 - training loss: 0.2822, validation loss: 0.2840
2024-05-25 02:20:16 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch7_loss0.28396325558423996.pypots
2024-05-25 02:20:18 [INFO]: Epoch 008 - training loss: 0.3042, validation loss: 0.2759
2024-05-25 02:20:18 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch8_loss0.2759154289960861.pypots
2024-05-25 02:20:20 [INFO]: Epoch 009 - training loss: 0.2733, validation loss: 0.3032
2024-05-25 02:20:20 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch9_loss0.30315716564655304.pypots
2024-05-25 02:20:22 [INFO]: Epoch 010 - training loss: 0.2938, validation loss: 0.2774
2024-05-25 02:20:22 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch10_loss0.27735039591789246.pypots
2024-05-25 02:20:24 [INFO]: Epoch 011 - training loss: 0.2612, validation loss: 0.2617
2024-05-25 02:20:24 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch11_loss0.26173965632915497.pypots
2024-05-25 02:20:26 [INFO]: Epoch 012 - training loss: 0.2431, validation loss: 0.2522
2024-05-25 02:20:26 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch12_loss0.25218654051423073.pypots
2024-05-25 02:20:29 [INFO]: Epoch 013 - training loss: 0.2067, validation loss: 0.2335
2024-05-25 02:20:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch13_loss0.23354988172650337.pypots
2024-05-25 02:20:31 [INFO]: Epoch 014 - training loss: 0.2244, validation loss: 0.2262
2024-05-25 02:20:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch14_loss0.22622007876634598.pypots
2024-05-25 02:20:33 [INFO]: Epoch 015 - training loss: 0.1989, validation loss: 0.2379
2024-05-25 02:20:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch15_loss0.23794538900256157.pypots
2024-05-25 02:20:35 [INFO]: Epoch 016 - training loss: 0.2372, validation loss: 0.2270
2024-05-25 02:20:35 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch16_loss0.22696072608232498.pypots
2024-05-25 02:20:37 [INFO]: Epoch 017 - training loss: 0.2013, validation loss: 0.2251
2024-05-25 02:20:37 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch17_loss0.2251218892633915.pypots
2024-05-25 02:20:39 [INFO]: Epoch 018 - training loss: 0.2498, validation loss: 0.2254
2024-05-25 02:20:39 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch18_loss0.22536078840494156.pypots
2024-05-25 02:20:41 [INFO]: Epoch 019 - training loss: 0.2295, validation loss: 0.2192
2024-05-25 02:20:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch19_loss0.2191636562347412.pypots
2024-05-25 02:20:43 [INFO]: Epoch 020 - training loss: 0.1981, validation loss: 0.2089
2024-05-25 02:20:43 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch20_loss0.20886769890785217.pypots
2024-05-25 02:20:45 [INFO]: Epoch 021 - training loss: 0.2801, validation loss: 0.2055
2024-05-25 02:20:45 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch21_loss0.2055009864270687.pypots
2024-05-25 02:20:47 [INFO]: Epoch 022 - training loss: 0.2316, validation loss: 0.1999
2024-05-25 02:20:47 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch22_loss0.19991930946707726.pypots
2024-05-25 02:20:49 [INFO]: Epoch 023 - training loss: 0.2487, validation loss: 0.2008
2024-05-25 02:20:49 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch23_loss0.20081466063857079.pypots
2024-05-25 02:20:51 [INFO]: Epoch 024 - training loss: 0.1934, validation loss: 0.2013
2024-05-25 02:20:51 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch24_loss0.2013385407626629.pypots
2024-05-25 02:20:53 [INFO]: Epoch 025 - training loss: 0.1670, validation loss: 0.2163
2024-05-25 02:20:54 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch25_loss0.21634232625365257.pypots
2024-05-25 02:20:56 [INFO]: Epoch 026 - training loss: 0.1817, validation loss: 0.1853
2024-05-25 02:20:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch26_loss0.1852891966700554.pypots
2024-05-25 02:20:58 [INFO]: Epoch 027 - training loss: 0.1918, validation loss: 0.1963
2024-05-25 02:20:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch27_loss0.19625280052423477.pypots
2024-05-25 02:21:00 [INFO]: Epoch 028 - training loss: 0.2750, validation loss: 0.1923
2024-05-25 02:21:00 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch28_loss0.19225285574793816.pypots
2024-05-25 02:21:02 [INFO]: Epoch 029 - training loss: 0.1944, validation loss: 0.1973
2024-05-25 02:21:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch29_loss0.19729287177324295.pypots
2024-05-25 02:21:04 [INFO]: Epoch 030 - training loss: 0.1759, validation loss: 0.1824
2024-05-25 02:21:04 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch30_loss0.18240924179553986.pypots
2024-05-25 02:21:06 [INFO]: Epoch 031 - training loss: 0.1897, validation loss: 0.1670
2024-05-25 02:21:06 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch31_loss0.16697434708476067.pypots
2024-05-25 02:21:08 [INFO]: Epoch 032 - training loss: 0.1815, validation loss: 0.1622
2024-05-25 02:21:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch32_loss0.16215774416923523.pypots
2024-05-25 02:21:10 [INFO]: Epoch 033 - training loss: 0.1676, validation loss: 0.1640
2024-05-25 02:21:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch33_loss0.1639791578054428.pypots
2024-05-25 02:21:12 [INFO]: Epoch 034 - training loss: 0.1953, validation loss: 0.1603
2024-05-25 02:21:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch34_loss0.1602543443441391.pypots
2024-05-25 02:21:14 [INFO]: Epoch 035 - training loss: 0.1795, validation loss: 0.1582
2024-05-25 02:21:14 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch35_loss0.15820759907364845.pypots
2024-05-25 02:21:16 [INFO]: Epoch 036 - training loss: 0.1709, validation loss: 0.1559
2024-05-25 02:21:16 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch36_loss0.15586423873901367.pypots
2024-05-25 02:21:18 [INFO]: Epoch 037 - training loss: 0.2438, validation loss: 0.1691
2024-05-25 02:21:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch37_loss0.16910963878035545.pypots
2024-05-25 02:21:21 [INFO]: Epoch 038 - training loss: 0.1629, validation loss: 0.1639
2024-05-25 02:21:21 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch38_loss0.16391181573271751.pypots
2024-05-25 02:21:23 [INFO]: Epoch 039 - training loss: 0.1641, validation loss: 0.1573
2024-05-25 02:21:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch39_loss0.15727287530899048.pypots
2024-05-25 02:21:25 [INFO]: Epoch 040 - training loss: 0.1520, validation loss: 0.1543
2024-05-25 02:21:25 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch40_loss0.1542944647371769.pypots
2024-05-25 02:21:27 [INFO]: Epoch 041 - training loss: 0.1864, validation loss: 0.1476
2024-05-25 02:21:27 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch41_loss0.1475544422864914.pypots
2024-05-25 02:21:29 [INFO]: Epoch 042 - training loss: 0.1720, validation loss: 0.1482
2024-05-25 02:21:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch42_loss0.14815035089850426.pypots
2024-05-25 02:21:31 [INFO]: Epoch 043 - training loss: 0.1626, validation loss: 0.1488
2024-05-25 02:21:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch43_loss0.1487780250608921.pypots
2024-05-25 02:21:33 [INFO]: Epoch 044 - training loss: 0.1924, validation loss: 0.1454
2024-05-25 02:21:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch44_loss0.14540612697601318.pypots
2024-05-25 02:21:35 [INFO]: Epoch 045 - training loss: 0.1803, validation loss: 0.1433
2024-05-25 02:21:35 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch45_loss0.14333022013306618.pypots
2024-05-25 02:21:37 [INFO]: Epoch 046 - training loss: 0.1838, validation loss: 0.1442
2024-05-25 02:21:37 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch46_loss0.1442212276160717.pypots
2024-05-25 02:21:39 [INFO]: Epoch 047 - training loss: 0.1511, validation loss: 0.1554
2024-05-25 02:21:39 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch47_loss0.15539181604981422.pypots
2024-05-25 02:21:41 [INFO]: Epoch 048 - training loss: 0.1810, validation loss: 0.1557
2024-05-25 02:21:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch48_loss0.15565065667033195.pypots
2024-05-25 02:21:43 [INFO]: Epoch 049 - training loss: 0.2128, validation loss: 0.1689
2024-05-25 02:21:43 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch49_loss0.16889794170856476.pypots
2024-05-25 02:21:46 [INFO]: Epoch 050 - training loss: 0.1687, validation loss: 0.1883
2024-05-25 02:21:46 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch50_loss0.18826522305607796.pypots
2024-05-25 02:21:48 [INFO]: Epoch 051 - training loss: 0.1735, validation loss: 0.1650
2024-05-25 02:21:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch51_loss0.1649792119860649.pypots
2024-05-25 02:21:50 [INFO]: Epoch 052 - training loss: 0.1994, validation loss: 0.1587
2024-05-25 02:21:50 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch52_loss0.158683929592371.pypots
2024-05-25 02:21:52 [INFO]: Epoch 053 - training loss: 0.1645, validation loss: 0.1487
2024-05-25 02:21:52 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch53_loss0.14872882887721062.pypots
2024-05-25 02:21:54 [INFO]: Epoch 054 - training loss: 0.2433, validation loss: 0.1449
2024-05-25 02:21:54 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch54_loss0.14488978311419487.pypots
2024-05-25 02:21:56 [INFO]: Epoch 055 - training loss: 0.1510, validation loss: 0.1432
2024-05-25 02:21:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch55_loss0.14323945716023445.pypots
2024-05-25 02:21:58 [INFO]: Epoch 056 - training loss: 0.1690, validation loss: 0.1459
2024-05-25 02:21:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch56_loss0.14594732597470284.pypots
2024-05-25 02:22:00 [INFO]: Epoch 057 - training loss: 0.1588, validation loss: 0.1448
2024-05-25 02:22:00 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch57_loss0.1447681188583374.pypots
2024-05-25 02:22:02 [INFO]: Epoch 058 - training loss: 0.2042, validation loss: 0.1395
2024-05-25 02:22:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch58_loss0.13949092105031013.pypots
2024-05-25 02:22:04 [INFO]: Epoch 059 - training loss: 0.1808, validation loss: 0.1545
2024-05-25 02:22:04 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch59_loss0.15447670966386795.pypots
2024-05-25 02:22:06 [INFO]: Epoch 060 - training loss: 0.1840, validation loss: 0.1631
2024-05-25 02:22:06 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch60_loss0.16305139288306236.pypots
2024-05-25 02:22:08 [INFO]: Epoch 061 - training loss: 0.1468, validation loss: 0.1627
2024-05-25 02:22:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch61_loss0.1627468429505825.pypots
2024-05-25 02:22:11 [INFO]: Epoch 062 - training loss: 0.1820, validation loss: 0.1478
2024-05-25 02:22:11 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch62_loss0.1478433832526207.pypots
2024-05-25 02:22:13 [INFO]: Epoch 063 - training loss: 0.1974, validation loss: 0.1508
2024-05-25 02:22:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch63_loss0.1507667414844036.pypots
2024-05-25 02:22:15 [INFO]: Epoch 064 - training loss: 0.1825, validation loss: 0.1508
2024-05-25 02:22:15 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch64_loss0.15084734559059143.pypots
2024-05-25 02:22:17 [INFO]: Epoch 065 - training loss: 0.1566, validation loss: 0.1385
2024-05-25 02:22:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch65_loss0.1384718157351017.pypots
2024-05-25 02:22:19 [INFO]: Epoch 066 - training loss: 0.1484, validation loss: 0.1393
2024-05-25 02:22:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch66_loss0.13926347717642784.pypots
2024-05-25 02:22:21 [INFO]: Epoch 067 - training loss: 0.1359, validation loss: 0.1412
2024-05-25 02:22:21 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch67_loss0.14122799038887024.pypots
2024-05-25 02:22:23 [INFO]: Epoch 068 - training loss: 0.1682, validation loss: 0.1401
2024-05-25 02:22:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch68_loss0.1401205137372017.pypots
2024-05-25 02:22:25 [INFO]: Epoch 069 - training loss: 0.1691, validation loss: 0.1487
2024-05-25 02:22:25 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch69_loss0.14870531484484673.pypots
2024-05-25 02:22:27 [INFO]: Epoch 070 - training loss: 0.1855, validation loss: 0.1463
2024-05-25 02:22:27 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch70_loss0.1463131457567215.pypots
2024-05-25 02:22:29 [INFO]: Epoch 071 - training loss: 0.1500, validation loss: 0.1408
2024-05-25 02:22:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch71_loss0.1408149115741253.pypots
2024-05-25 02:22:31 [INFO]: Epoch 072 - training loss: 0.1465, validation loss: 0.1359
2024-05-25 02:22:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch72_loss0.1359216384589672.pypots
2024-05-25 02:22:33 [INFO]: Epoch 073 - training loss: 0.1627, validation loss: 0.1417
2024-05-25 02:22:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch73_loss0.14165183529257774.pypots
2024-05-25 02:22:36 [INFO]: Epoch 074 - training loss: 0.1931, validation loss: 0.1448
2024-05-25 02:22:36 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch74_loss0.14484114944934845.pypots
2024-05-25 02:22:38 [INFO]: Epoch 075 - training loss: 0.1841, validation loss: 0.1391
2024-05-25 02:22:38 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch75_loss0.13912663981318474.pypots
2024-05-25 02:22:40 [INFO]: Epoch 076 - training loss: 0.1618, validation loss: 0.1399
2024-05-25 02:22:40 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch76_loss0.13989195972681046.pypots
2024-05-25 02:22:42 [INFO]: Epoch 077 - training loss: 0.1738, validation loss: 0.1393
2024-05-25 02:22:42 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch77_loss0.13927695527672768.pypots
2024-05-25 02:22:44 [INFO]: Epoch 078 - training loss: 0.1479, validation loss: 0.1306
2024-05-25 02:22:44 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch78_loss0.13061975128948689.pypots
2024-05-25 02:22:46 [INFO]: Epoch 079 - training loss: 0.1542, validation loss: 0.1318
2024-05-25 02:22:46 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch79_loss0.1317848116159439.pypots
2024-05-25 02:22:48 [INFO]: Epoch 080 - training loss: 0.1634, validation loss: 0.1290
2024-05-25 02:22:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch80_loss0.12898272089660168.pypots
2024-05-25 02:22:50 [INFO]: Epoch 081 - training loss: 0.1420, validation loss: 0.1302
2024-05-25 02:22:50 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch81_loss0.13024576753377914.pypots
2024-05-25 02:22:52 [INFO]: Epoch 082 - training loss: 0.2052, validation loss: 0.1258
2024-05-25 02:22:52 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch82_loss0.1257855724543333.pypots
2024-05-25 02:22:54 [INFO]: Epoch 083 - training loss: 0.1561, validation loss: 0.1288
2024-05-25 02:22:54 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch83_loss0.1288010347634554.pypots
2024-05-25 02:22:56 [INFO]: Epoch 084 - training loss: 0.1321, validation loss: 0.1320
2024-05-25 02:22:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch84_loss0.13204732164740562.pypots
2024-05-25 02:22:58 [INFO]: Epoch 085 - training loss: 0.1446, validation loss: 0.1369
2024-05-25 02:22:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch85_loss0.1368594914674759.pypots
2024-05-25 02:23:01 [INFO]: Epoch 086 - training loss: 0.2205, validation loss: 0.1325
2024-05-25 02:23:01 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch86_loss0.132461691275239.pypots
2024-05-25 02:23:03 [INFO]: Epoch 087 - training loss: 0.1839, validation loss: 0.1300
2024-05-25 02:23:03 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch87_loss0.12998904660344124.pypots
2024-05-25 02:23:05 [INFO]: Epoch 088 - training loss: 0.1859, validation loss: 0.1386
2024-05-25 02:23:05 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch88_loss0.13864802569150925.pypots
2024-05-25 02:23:07 [INFO]: Epoch 089 - training loss: 0.1565, validation loss: 0.1378
2024-05-25 02:23:07 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch89_loss0.13776499032974243.pypots
2024-05-25 02:23:09 [INFO]: Epoch 090 - training loss: 0.1536, validation loss: 0.1297
2024-05-25 02:23:09 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch90_loss0.12972771003842354.pypots
2024-05-25 02:23:11 [INFO]: Epoch 091 - training loss: 0.1822, validation loss: 0.1301
2024-05-25 02:23:11 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch91_loss0.1300517190247774.pypots
2024-05-25 02:23:13 [INFO]: Epoch 092 - training loss: 0.1731, validation loss: 0.1333
2024-05-25 02:23:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI_epoch92_loss0.13328770361840725.pypots
2024-05-25 02:23:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:23:13 [INFO]: Finished training. The best model is from epoch#82.
2024-05-25 02:23:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022001/CSDI.pypots
2024-05-25 02:23:29 [INFO]: CSDI on ETTm1: MAE=0.1303, MSE=0.0886
2024-05-25 02:23:29 [INFO]: Successfully saved to augmentation_saved_results/round_3/CSDI_ettm1/imputation.pkl
2024-05-25 02:23:29 [INFO]: Using the given device: cuda:0
2024-05-25 02:23:29 [INFO]: Model files will be saved to augmentation_saved_results/round_3/GPVAE_ettm1/20240525_T022329
2024-05-25 02:23:29 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/GPVAE_ettm1/20240525_T022329/tensorboard
2024-05-25 02:23:29 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 02:23:29 [INFO]: Epoch 001 - training loss: 23748.3844, validation loss: 0.9956
2024-05-25 02:23:29 [INFO]: Epoch 002 - training loss: 21439.4192, validation loss: 0.9821
2024-05-25 02:23:29 [INFO]: Epoch 003 - training loss: 19528.8475, validation loss: 0.9705
2024-05-25 02:23:29 [INFO]: Epoch 004 - training loss: 17341.9550, validation loss: 0.9588
2024-05-25 02:23:30 [INFO]: Epoch 005 - training loss: 15457.7173, validation loss: 0.9256
2024-05-25 02:23:30 [INFO]: Epoch 006 - training loss: 13858.6722, validation loss: 0.8626
2024-05-25 02:23:30 [INFO]: Epoch 007 - training loss: 12745.6237, validation loss: 0.7602
2024-05-25 02:23:30 [INFO]: Epoch 008 - training loss: 11887.2222, validation loss: 0.6450
2024-05-25 02:23:30 [INFO]: Epoch 009 - training loss: 11361.0964, validation loss: 0.5581
2024-05-25 02:23:30 [INFO]: Epoch 010 - training loss: 10924.0875, validation loss: 0.5131
2024-05-25 02:23:30 [INFO]: Epoch 011 - training loss: 10655.9536, validation loss: 0.4856
2024-05-25 02:23:31 [INFO]: Epoch 012 - training loss: 10444.9066, validation loss: 0.4597
2024-05-25 02:23:31 [INFO]: Epoch 013 - training loss: 10241.6194, validation loss: 0.4339
2024-05-25 02:23:31 [INFO]: Epoch 014 - training loss: 10133.5045, validation loss: 0.4020
2024-05-25 02:23:31 [INFO]: Epoch 015 - training loss: 10037.1304, validation loss: 0.3715
2024-05-25 02:23:31 [INFO]: Epoch 016 - training loss: 9919.6099, validation loss: 0.3471
2024-05-25 02:23:31 [INFO]: Epoch 017 - training loss: 9881.1592, validation loss: 0.3270
2024-05-25 02:23:31 [INFO]: Epoch 018 - training loss: 9831.7991, validation loss: 0.3162
2024-05-25 02:23:31 [INFO]: Epoch 019 - training loss: 9745.2164, validation loss: 0.3120
2024-05-25 02:23:32 [INFO]: Epoch 020 - training loss: 9699.8237, validation loss: 0.3002
2024-05-25 02:23:32 [INFO]: Epoch 021 - training loss: 9674.5880, validation loss: 0.2951
2024-05-25 02:23:32 [INFO]: Epoch 022 - training loss: 9640.9279, validation loss: 0.2934
2024-05-25 02:23:32 [INFO]: Epoch 023 - training loss: 9632.6823, validation loss: 0.2872
2024-05-25 02:23:32 [INFO]: Epoch 024 - training loss: 9595.9686, validation loss: 0.2797
2024-05-25 02:23:32 [INFO]: Epoch 025 - training loss: 9560.9451, validation loss: 0.2737
2024-05-25 02:23:32 [INFO]: Epoch 026 - training loss: 9564.7982, validation loss: 0.2685
2024-05-25 02:23:32 [INFO]: Epoch 027 - training loss: 9545.1230, validation loss: 0.2627
2024-05-25 02:23:33 [INFO]: Epoch 028 - training loss: 9513.6940, validation loss: 0.2530
2024-05-25 02:23:33 [INFO]: Epoch 029 - training loss: 9512.1025, validation loss: 0.2480
2024-05-25 02:23:33 [INFO]: Epoch 030 - training loss: 9497.0039, validation loss: 0.2400
2024-05-25 02:23:33 [INFO]: Epoch 031 - training loss: 9489.4696, validation loss: 0.2383
2024-05-25 02:23:33 [INFO]: Epoch 032 - training loss: 9464.3058, validation loss: 0.2329
2024-05-25 02:23:33 [INFO]: Epoch 033 - training loss: 9461.1063, validation loss: 0.2277
2024-05-25 02:23:33 [INFO]: Epoch 034 - training loss: 9461.5903, validation loss: 0.2236
2024-05-25 02:23:33 [INFO]: Epoch 035 - training loss: 9442.2197, validation loss: 0.2157
2024-05-25 02:23:34 [INFO]: Epoch 036 - training loss: 9439.8334, validation loss: 0.2100
2024-05-25 02:23:34 [INFO]: Epoch 037 - training loss: 9430.6215, validation loss: 0.2063
2024-05-25 02:23:34 [INFO]: Epoch 038 - training loss: 9426.8754, validation loss: 0.1974
2024-05-25 02:23:34 [INFO]: Epoch 039 - training loss: 9417.2973, validation loss: 0.1932
2024-05-25 02:23:34 [INFO]: Epoch 040 - training loss: 9418.9105, validation loss: 0.1871
2024-05-25 02:23:34 [INFO]: Epoch 041 - training loss: 9406.7696, validation loss: 0.1776
2024-05-25 02:23:34 [INFO]: Epoch 042 - training loss: 9401.8375, validation loss: 0.1774
2024-05-25 02:23:35 [INFO]: Epoch 043 - training loss: 9398.1415, validation loss: 0.1724
2024-05-25 02:23:35 [INFO]: Epoch 044 - training loss: 9403.8106, validation loss: 0.1654
2024-05-25 02:23:35 [INFO]: Epoch 045 - training loss: 9395.8687, validation loss: 0.1604
2024-05-25 02:23:35 [INFO]: Epoch 046 - training loss: 9387.5267, validation loss: 0.1558
2024-05-25 02:23:35 [INFO]: Epoch 047 - training loss: 9382.4330, validation loss: 0.1491
2024-05-25 02:23:35 [INFO]: Epoch 048 - training loss: 9383.1016, validation loss: 0.1489
2024-05-25 02:23:35 [INFO]: Epoch 049 - training loss: 9378.1172, validation loss: 0.1440
2024-05-25 02:23:35 [INFO]: Epoch 050 - training loss: 9383.3466, validation loss: 0.1408
2024-05-25 02:23:36 [INFO]: Epoch 051 - training loss: 9381.3797, validation loss: 0.1380
2024-05-25 02:23:36 [INFO]: Epoch 052 - training loss: 9372.0635, validation loss: 0.1372
2024-05-25 02:23:36 [INFO]: Epoch 053 - training loss: 9364.9244, validation loss: 0.1351
2024-05-25 02:23:36 [INFO]: Epoch 054 - training loss: 9367.0679, validation loss: 0.1337
2024-05-25 02:23:36 [INFO]: Epoch 055 - training loss: 9362.5291, validation loss: 0.1322
2024-05-25 02:23:36 [INFO]: Epoch 056 - training loss: 9358.4891, validation loss: 0.1291
2024-05-25 02:23:36 [INFO]: Epoch 057 - training loss: 9358.6276, validation loss: 0.1298
2024-05-25 02:23:36 [INFO]: Epoch 058 - training loss: 9355.0358, validation loss: 0.1277
2024-05-25 02:23:37 [INFO]: Epoch 059 - training loss: 9358.5732, validation loss: 0.1260
2024-05-25 02:23:37 [INFO]: Epoch 060 - training loss: 9357.0313, validation loss: 0.1265
2024-05-25 02:23:37 [INFO]: Epoch 061 - training loss: 9349.9367, validation loss: 0.1242
2024-05-25 02:23:37 [INFO]: Epoch 062 - training loss: 9354.6727, validation loss: 0.1240
2024-05-25 02:23:37 [INFO]: Epoch 063 - training loss: 9349.9220, validation loss: 0.1218
2024-05-25 02:23:37 [INFO]: Epoch 064 - training loss: 9348.7050, validation loss: 0.1223
2024-05-25 02:23:37 [INFO]: Epoch 065 - training loss: 9347.4215, validation loss: 0.1212
2024-05-25 02:23:38 [INFO]: Epoch 066 - training loss: 9346.1771, validation loss: 0.1200
2024-05-25 02:23:38 [INFO]: Epoch 067 - training loss: 9342.8065, validation loss: 0.1193
2024-05-25 02:23:38 [INFO]: Epoch 068 - training loss: 9345.0667, validation loss: 0.1175
2024-05-25 02:23:38 [INFO]: Epoch 069 - training loss: 9346.8012, validation loss: 0.1174
2024-05-25 02:23:38 [INFO]: Epoch 070 - training loss: 9342.7405, validation loss: 0.1158
2024-05-25 02:23:38 [INFO]: Epoch 071 - training loss: 9338.5148, validation loss: 0.1166
2024-05-25 02:23:38 [INFO]: Epoch 072 - training loss: 9339.8187, validation loss: 0.1130
2024-05-25 02:23:38 [INFO]: Epoch 073 - training loss: 9337.2189, validation loss: 0.1134
2024-05-25 02:23:39 [INFO]: Epoch 074 - training loss: 9338.0847, validation loss: 0.1131
2024-05-25 02:23:39 [INFO]: Epoch 075 - training loss: 9339.9802, validation loss: 0.1120
2024-05-25 02:23:39 [INFO]: Epoch 076 - training loss: 9338.0775, validation loss: 0.1127
2024-05-25 02:23:39 [INFO]: Epoch 077 - training loss: 9335.6655, validation loss: 0.1109
2024-05-25 02:23:39 [INFO]: Epoch 078 - training loss: 9333.6703, validation loss: 0.1087
2024-05-25 02:23:39 [INFO]: Epoch 079 - training loss: 9333.4801, validation loss: 0.1094
2024-05-25 02:23:39 [INFO]: Epoch 080 - training loss: 9331.8361, validation loss: 0.1113
2024-05-25 02:23:39 [INFO]: Epoch 081 - training loss: 9331.3787, validation loss: 0.1069
2024-05-25 02:23:40 [INFO]: Epoch 082 - training loss: 9332.3114, validation loss: 0.1082
2024-05-25 02:23:40 [INFO]: Epoch 083 - training loss: 9331.0613, validation loss: 0.1062
2024-05-25 02:23:40 [INFO]: Epoch 084 - training loss: 9332.2793, validation loss: 0.1097
2024-05-25 02:23:40 [INFO]: Epoch 085 - training loss: 9327.9658, validation loss: 0.1044
2024-05-25 02:23:40 [INFO]: Epoch 086 - training loss: 9326.9528, validation loss: 0.1073
2024-05-25 02:23:40 [INFO]: Epoch 087 - training loss: 9329.1564, validation loss: 0.1043
2024-05-25 02:23:40 [INFO]: Epoch 088 - training loss: 9327.8436, validation loss: 0.1041
2024-05-25 02:23:40 [INFO]: Epoch 089 - training loss: 9326.4883, validation loss: 0.1027
2024-05-25 02:23:41 [INFO]: Epoch 090 - training loss: 9327.5031, validation loss: 0.1030
2024-05-25 02:23:41 [INFO]: Epoch 091 - training loss: 9325.8125, validation loss: 0.1017
2024-05-25 02:23:41 [INFO]: Epoch 092 - training loss: 9324.8864, validation loss: 0.1017
2024-05-25 02:23:41 [INFO]: Epoch 093 - training loss: 9325.9354, validation loss: 0.1006
2024-05-25 02:23:41 [INFO]: Epoch 094 - training loss: 9323.8899, validation loss: 0.1021
2024-05-25 02:23:41 [INFO]: Epoch 095 - training loss: 9323.9600, validation loss: 0.0993
2024-05-25 02:23:41 [INFO]: Epoch 096 - training loss: 9325.2412, validation loss: 0.0997
2024-05-25 02:23:42 [INFO]: Epoch 097 - training loss: 9321.8611, validation loss: 0.1009
2024-05-25 02:23:42 [INFO]: Epoch 098 - training loss: 9321.8465, validation loss: 0.0973
2024-05-25 02:23:42 [INFO]: Epoch 099 - training loss: 9322.6544, validation loss: 0.0976
2024-05-25 02:23:42 [INFO]: Epoch 100 - training loss: 9322.7229, validation loss: 0.0983
2024-05-25 02:23:42 [INFO]: Epoch 101 - training loss: 9320.9665, validation loss: 0.0963
2024-05-25 02:23:42 [INFO]: Epoch 102 - training loss: 9320.4149, validation loss: 0.0961
2024-05-25 02:23:42 [INFO]: Epoch 103 - training loss: 9319.6232, validation loss: 0.0956
2024-05-25 02:23:42 [INFO]: Epoch 104 - training loss: 9318.7812, validation loss: 0.0947
2024-05-25 02:23:43 [INFO]: Epoch 105 - training loss: 9319.2232, validation loss: 0.0965
2024-05-25 02:23:43 [INFO]: Epoch 106 - training loss: 9319.2566, validation loss: 0.0942
2024-05-25 02:23:43 [INFO]: Epoch 107 - training loss: 9319.4650, validation loss: 0.0951
2024-05-25 02:23:43 [INFO]: Epoch 108 - training loss: 9319.2675, validation loss: 0.0947
2024-05-25 02:23:43 [INFO]: Epoch 109 - training loss: 9318.8322, validation loss: 0.0935
2024-05-25 02:23:43 [INFO]: Epoch 110 - training loss: 9317.5989, validation loss: 0.0939
2024-05-25 02:23:43 [INFO]: Epoch 111 - training loss: 9317.7083, validation loss: 0.0913
2024-05-25 02:23:43 [INFO]: Epoch 112 - training loss: 9318.7023, validation loss: 0.0928
2024-05-25 02:23:44 [INFO]: Epoch 113 - training loss: 9318.4527, validation loss: 0.0913
2024-05-25 02:23:44 [INFO]: Epoch 114 - training loss: 9316.8229, validation loss: 0.0908
2024-05-25 02:23:44 [INFO]: Epoch 115 - training loss: 9314.9532, validation loss: 0.0913
2024-05-25 02:23:44 [INFO]: Epoch 116 - training loss: 9317.3457, validation loss: 0.0919
2024-05-25 02:23:44 [INFO]: Epoch 117 - training loss: 9315.5723, validation loss: 0.0905
2024-05-25 02:23:44 [INFO]: Epoch 118 - training loss: 9316.7642, validation loss: 0.0895
2024-05-25 02:23:44 [INFO]: Epoch 119 - training loss: 9316.9252, validation loss: 0.0909
2024-05-25 02:23:45 [INFO]: Epoch 120 - training loss: 9316.6584, validation loss: 0.0889
2024-05-25 02:23:45 [INFO]: Epoch 121 - training loss: 9314.8867, validation loss: 0.0896
2024-05-25 02:23:45 [INFO]: Epoch 122 - training loss: 9314.0927, validation loss: 0.0892
2024-05-25 02:23:45 [INFO]: Epoch 123 - training loss: 9314.6617, validation loss: 0.0894
2024-05-25 02:23:45 [INFO]: Epoch 124 - training loss: 9313.6348, validation loss: 0.0882
2024-05-25 02:23:45 [INFO]: Epoch 125 - training loss: 9314.0667, validation loss: 0.0884
2024-05-25 02:23:45 [INFO]: Epoch 126 - training loss: 9312.6176, validation loss: 0.0865
2024-05-25 02:23:45 [INFO]: Epoch 127 - training loss: 9312.5586, validation loss: 0.0869
2024-05-25 02:23:46 [INFO]: Epoch 128 - training loss: 9312.8561, validation loss: 0.0872
2024-05-25 02:23:46 [INFO]: Epoch 129 - training loss: 9313.1902, validation loss: 0.0860
2024-05-25 02:23:46 [INFO]: Epoch 130 - training loss: 9312.8983, validation loss: 0.0865
2024-05-25 02:23:46 [INFO]: Epoch 131 - training loss: 9313.7383, validation loss: 0.0870
2024-05-25 02:23:46 [INFO]: Epoch 132 - training loss: 9313.4446, validation loss: 0.0854
2024-05-25 02:23:46 [INFO]: Epoch 133 - training loss: 9311.5803, validation loss: 0.0866
2024-05-25 02:23:46 [INFO]: Epoch 134 - training loss: 9312.2128, validation loss: 0.0861
2024-05-25 02:23:46 [INFO]: Epoch 135 - training loss: 9313.4468, validation loss: 0.0844
2024-05-25 02:23:47 [INFO]: Epoch 136 - training loss: 9310.0582, validation loss: 0.0846
2024-05-25 02:23:47 [INFO]: Epoch 137 - training loss: 9315.9441, validation loss: 0.0844
2024-05-25 02:23:47 [INFO]: Epoch 138 - training loss: 9312.0197, validation loss: 0.0839
2024-05-25 02:23:47 [INFO]: Epoch 139 - training loss: 9311.8577, validation loss: 0.0846
2024-05-25 02:23:47 [INFO]: Epoch 140 - training loss: 9311.1468, validation loss: 0.0826
2024-05-25 02:23:47 [INFO]: Epoch 141 - training loss: 9310.3154, validation loss: 0.0845
2024-05-25 02:23:47 [INFO]: Epoch 142 - training loss: 9311.7835, validation loss: 0.0844
2024-05-25 02:23:47 [INFO]: Epoch 143 - training loss: 9310.4648, validation loss: 0.0831
2024-05-25 02:23:48 [INFO]: Epoch 144 - training loss: 9310.4559, validation loss: 0.0828
2024-05-25 02:23:48 [INFO]: Epoch 145 - training loss: 9310.2236, validation loss: 0.0821
2024-05-25 02:23:48 [INFO]: Epoch 146 - training loss: 9309.4521, validation loss: 0.0825
2024-05-25 02:23:48 [INFO]: Epoch 147 - training loss: 9309.5297, validation loss: 0.0825
2024-05-25 02:23:48 [INFO]: Epoch 148 - training loss: 9308.1796, validation loss: 0.0813
2024-05-25 02:23:48 [INFO]: Epoch 149 - training loss: 9309.5834, validation loss: 0.0813
2024-05-25 02:23:48 [INFO]: Epoch 150 - training loss: 9309.4731, validation loss: 0.0820
2024-05-25 02:23:49 [INFO]: Epoch 151 - training loss: 9309.5231, validation loss: 0.0828
2024-05-25 02:23:49 [INFO]: Epoch 152 - training loss: 9308.3609, validation loss: 0.0824
2024-05-25 02:23:49 [INFO]: Epoch 153 - training loss: 9309.2926, validation loss: 0.0816
2024-05-25 02:23:49 [INFO]: Epoch 154 - training loss: 9308.2436, validation loss: 0.0807
2024-05-25 02:23:49 [INFO]: Epoch 155 - training loss: 9308.4744, validation loss: 0.0800
2024-05-25 02:23:49 [INFO]: Epoch 156 - training loss: 9308.8295, validation loss: 0.0802
2024-05-25 02:23:49 [INFO]: Epoch 157 - training loss: 9307.8008, validation loss: 0.0785
2024-05-25 02:23:49 [INFO]: Epoch 158 - training loss: 9308.5577, validation loss: 0.0804
2024-05-25 02:23:50 [INFO]: Epoch 159 - training loss: 9309.1731, validation loss: 0.0800
2024-05-25 02:23:50 [INFO]: Epoch 160 - training loss: 9307.0543, validation loss: 0.0805
2024-05-25 02:23:50 [INFO]: Epoch 161 - training loss: 9307.7601, validation loss: 0.0796
2024-05-25 02:23:50 [INFO]: Epoch 162 - training loss: 9308.5491, validation loss: 0.0784
2024-05-25 02:23:50 [INFO]: Epoch 163 - training loss: 9308.5828, validation loss: 0.0767
2024-05-25 02:23:50 [INFO]: Epoch 164 - training loss: 9307.4077, validation loss: 0.0783
2024-05-25 02:23:50 [INFO]: Epoch 165 - training loss: 9307.1266, validation loss: 0.0768
2024-05-25 02:23:50 [INFO]: Epoch 166 - training loss: 9308.1050, validation loss: 0.0795
2024-05-25 02:23:51 [INFO]: Epoch 167 - training loss: 9306.2981, validation loss: 0.0810
2024-05-25 02:23:51 [INFO]: Epoch 168 - training loss: 9307.0677, validation loss: 0.0782
2024-05-25 02:23:51 [INFO]: Epoch 169 - training loss: 9307.3121, validation loss: 0.0785
2024-05-25 02:23:51 [INFO]: Epoch 170 - training loss: 9307.9749, validation loss: 0.0781
2024-05-25 02:23:51 [INFO]: Epoch 171 - training loss: 9306.9811, validation loss: 0.0779
2024-05-25 02:23:51 [INFO]: Epoch 172 - training loss: 9306.0481, validation loss: 0.0772
2024-05-25 02:23:51 [INFO]: Epoch 173 - training loss: 9305.6863, validation loss: 0.0761
2024-05-25 02:23:51 [INFO]: Epoch 174 - training loss: 9305.8269, validation loss: 0.0772
2024-05-25 02:23:52 [INFO]: Epoch 175 - training loss: 9307.4493, validation loss: 0.0754
2024-05-25 02:23:52 [INFO]: Epoch 176 - training loss: 9307.0765, validation loss: 0.0746
2024-05-25 02:23:52 [INFO]: Epoch 177 - training loss: 9306.2378, validation loss: 0.0759
2024-05-25 02:23:52 [INFO]: Epoch 178 - training loss: 9306.6364, validation loss: 0.0773
2024-05-25 02:23:52 [INFO]: Epoch 179 - training loss: 9305.4682, validation loss: 0.0790
2024-05-25 02:23:52 [INFO]: Epoch 180 - training loss: 9305.3937, validation loss: 0.0769
2024-05-25 02:23:52 [INFO]: Epoch 181 - training loss: 9306.7100, validation loss: 0.0754
2024-05-25 02:23:53 [INFO]: Epoch 182 - training loss: 9305.9714, validation loss: 0.0749
2024-05-25 02:23:53 [INFO]: Epoch 183 - training loss: 9305.7045, validation loss: 0.0758
2024-05-25 02:23:53 [INFO]: Epoch 184 - training loss: 9304.9730, validation loss: 0.0790
2024-05-25 02:23:53 [INFO]: Epoch 185 - training loss: 9308.6111, validation loss: 0.0768
2024-05-25 02:23:53 [INFO]: Epoch 186 - training loss: 9305.3478, validation loss: 0.0738
2024-05-25 02:23:53 [INFO]: Epoch 187 - training loss: 9306.3763, validation loss: 0.0754
2024-05-25 02:23:53 [INFO]: Epoch 188 - training loss: 9305.8269, validation loss: 0.0743
2024-05-25 02:23:53 [INFO]: Epoch 189 - training loss: 9305.5961, validation loss: 0.0755
2024-05-25 02:23:54 [INFO]: Epoch 190 - training loss: 9304.2491, validation loss: 0.0756
2024-05-25 02:23:54 [INFO]: Epoch 191 - training loss: 9305.1227, validation loss: 0.0751
2024-05-25 02:23:54 [INFO]: Epoch 192 - training loss: 9305.8203, validation loss: 0.0759
2024-05-25 02:23:54 [INFO]: Epoch 193 - training loss: 9304.2448, validation loss: 0.0744
2024-05-25 02:23:54 [INFO]: Epoch 194 - training loss: 9305.5754, validation loss: 0.0762
2024-05-25 02:23:54 [INFO]: Epoch 195 - training loss: 9304.6061, validation loss: 0.0768
2024-05-25 02:23:54 [INFO]: Epoch 196 - training loss: 9305.2477, validation loss: 0.0750
2024-05-25 02:23:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:23:54 [INFO]: Finished training. The best model is from epoch#186.
2024-05-25 02:23:54 [INFO]: Saved the model to augmentation_saved_results/round_3/GPVAE_ettm1/20240525_T022329/GPVAE.pypots
2024-05-25 02:23:54 [INFO]: GP-VAE on ETTm1: MAE=0.2851, MSE=0.1774
2024-05-25 02:23:54 [INFO]: Successfully saved to augmentation_saved_results/round_3/GPVAE_ettm1/imputation.pkl
2024-05-25 02:23:54 [INFO]: Using the given device: cuda:0
2024-05-25 02:23:54 [INFO]: Model files will be saved to augmentation_saved_results/round_3/USGAN_ettm1/20240525_T022354
2024-05-25 02:23:54 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/USGAN_ettm1/20240525_T022354/tensorboard
2024-05-25 02:23:54 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 02:24:05 [INFO]: Epoch 001 - generator training loss: 0.5770, discriminator training loss: 0.3254, validation loss: 0.2968
2024-05-25 02:24:14 [INFO]: Epoch 002 - generator training loss: 0.0516, discriminator training loss: 0.2066, validation loss: 0.1074
2024-05-25 02:24:23 [INFO]: Epoch 003 - generator training loss: -0.0706, discriminator training loss: 0.1989, validation loss: 0.0562
2024-05-25 02:24:32 [INFO]: Epoch 004 - generator training loss: -0.0832, discriminator training loss: 0.1959, validation loss: 0.0498
2024-05-25 02:24:41 [INFO]: Epoch 005 - generator training loss: -0.0870, discriminator training loss: 0.1916, validation loss: 0.0445
2024-05-25 02:24:50 [INFO]: Epoch 006 - generator training loss: -0.0844, discriminator training loss: 0.1881, validation loss: 0.0385
2024-05-25 02:24:59 [INFO]: Epoch 007 - generator training loss: -0.0825, discriminator training loss: 0.1834, validation loss: 0.0364
2024-05-25 02:25:08 [INFO]: Epoch 008 - generator training loss: -0.0785, discriminator training loss: 0.1768, validation loss: 0.0366
2024-05-25 02:25:17 [INFO]: Epoch 009 - generator training loss: -0.0731, discriminator training loss: 0.1677, validation loss: 0.0345
2024-05-25 02:25:26 [INFO]: Epoch 010 - generator training loss: -0.0650, discriminator training loss: 0.1563, validation loss: 0.0347
2024-05-25 02:25:35 [INFO]: Epoch 011 - generator training loss: -0.0480, discriminator training loss: 0.1420, validation loss: 0.0334
2024-05-25 02:25:44 [INFO]: Epoch 012 - generator training loss: -0.0384, discriminator training loss: 0.1288, validation loss: 0.0343
2024-05-25 02:25:53 [INFO]: Epoch 013 - generator training loss: -0.0312, discriminator training loss: 0.1160, validation loss: 0.0333
2024-05-25 02:26:02 [INFO]: Epoch 014 - generator training loss: -0.0249, discriminator training loss: 0.1051, validation loss: 0.0328
2024-05-25 02:26:11 [INFO]: Epoch 015 - generator training loss: -0.0192, discriminator training loss: 0.0969, validation loss: 0.0319
2024-05-25 02:26:20 [INFO]: Epoch 016 - generator training loss: -0.0142, discriminator training loss: 0.0926, validation loss: 0.0319
2024-05-25 02:26:29 [INFO]: Epoch 017 - generator training loss: -0.0150, discriminator training loss: 0.0879, validation loss: 0.0313
2024-05-25 02:26:38 [INFO]: Epoch 018 - generator training loss: -0.0135, discriminator training loss: 0.0850, validation loss: 0.0315
2024-05-25 02:26:47 [INFO]: Epoch 019 - generator training loss: -0.0133, discriminator training loss: 0.0809, validation loss: 0.0316
2024-05-25 02:26:56 [INFO]: Epoch 020 - generator training loss: -0.0120, discriminator training loss: 0.0805, validation loss: 0.0323
2024-05-25 02:27:05 [INFO]: Epoch 021 - generator training loss: -0.0120, discriminator training loss: 0.0800, validation loss: 0.0310
2024-05-25 02:27:14 [INFO]: Epoch 022 - generator training loss: -0.0118, discriminator training loss: 0.0777, validation loss: 0.0302
2024-05-25 02:27:23 [INFO]: Epoch 023 - generator training loss: -0.0105, discriminator training loss: 0.0769, validation loss: 0.0302
2024-05-25 02:27:32 [INFO]: Epoch 024 - generator training loss: -0.0091, discriminator training loss: 0.0744, validation loss: 0.0306
2024-05-25 02:27:41 [INFO]: Epoch 025 - generator training loss: -0.0108, discriminator training loss: 0.0746, validation loss: 0.0301
2024-05-25 02:27:50 [INFO]: Epoch 026 - generator training loss: -0.0125, discriminator training loss: 0.0755, validation loss: 0.0298
2024-05-25 02:28:00 [INFO]: Epoch 027 - generator training loss: -0.0103, discriminator training loss: 0.0738, validation loss: 0.0301
2024-05-25 02:28:09 [INFO]: Epoch 028 - generator training loss: -0.0121, discriminator training loss: 0.0721, validation loss: 0.0289
2024-05-25 02:28:18 [INFO]: Epoch 029 - generator training loss: -0.0114, discriminator training loss: 0.0723, validation loss: 0.0287
2024-05-25 02:28:27 [INFO]: Epoch 030 - generator training loss: -0.0091, discriminator training loss: 0.0725, validation loss: 0.0306
2024-05-25 02:28:36 [INFO]: Epoch 031 - generator training loss: -0.0110, discriminator training loss: 0.0711, validation loss: 0.0296
2024-05-25 02:28:45 [INFO]: Epoch 032 - generator training loss: -0.0131, discriminator training loss: 0.0698, validation loss: 0.0283
2024-05-25 02:28:54 [INFO]: Epoch 033 - generator training loss: -0.0113, discriminator training loss: 0.0716, validation loss: 0.0279
2024-05-25 02:29:03 [INFO]: Epoch 034 - generator training loss: -0.0137, discriminator training loss: 0.0706, validation loss: 0.0285
2024-05-25 02:29:12 [INFO]: Epoch 035 - generator training loss: -0.0117, discriminator training loss: 0.0695, validation loss: 0.0274
2024-05-25 02:29:21 [INFO]: Epoch 036 - generator training loss: -0.0173, discriminator training loss: 0.0694, validation loss: 0.0267
2024-05-25 02:29:30 [INFO]: Epoch 037 - generator training loss: -0.0140, discriminator training loss: 0.0701, validation loss: 0.0266
2024-05-25 02:29:39 [INFO]: Epoch 038 - generator training loss: -0.0169, discriminator training loss: 0.0688, validation loss: 0.0270
2024-05-25 02:29:48 [INFO]: Epoch 039 - generator training loss: -0.0161, discriminator training loss: 0.0693, validation loss: 0.0262
2024-05-25 02:29:57 [INFO]: Epoch 040 - generator training loss: -0.0154, discriminator training loss: 0.0667, validation loss: 0.0256
2024-05-25 02:30:06 [INFO]: Epoch 041 - generator training loss: -0.0180, discriminator training loss: 0.0695, validation loss: 0.0251
2024-05-25 02:30:15 [INFO]: Epoch 042 - generator training loss: -0.0172, discriminator training loss: 0.0690, validation loss: 0.0246
2024-05-25 02:30:24 [INFO]: Epoch 043 - generator training loss: -0.0188, discriminator training loss: 0.0674, validation loss: 0.0252
2024-05-25 02:30:33 [INFO]: Epoch 044 - generator training loss: -0.0192, discriminator training loss: 0.0726, validation loss: 0.0245
2024-05-25 02:30:43 [INFO]: Epoch 045 - generator training loss: -0.0180, discriminator training loss: 0.0707, validation loss: 0.0236
2024-05-25 02:30:52 [INFO]: Epoch 046 - generator training loss: -0.0187, discriminator training loss: 0.0683, validation loss: 0.0236
2024-05-25 02:31:01 [INFO]: Epoch 047 - generator training loss: -0.0193, discriminator training loss: 0.0711, validation loss: 0.0236
2024-05-25 02:31:10 [INFO]: Epoch 048 - generator training loss: -0.0182, discriminator training loss: 0.0681, validation loss: 0.0237
2024-05-25 02:31:19 [INFO]: Epoch 049 - generator training loss: -0.0173, discriminator training loss: 0.0716, validation loss: 0.0238
2024-05-25 02:31:28 [INFO]: Epoch 050 - generator training loss: -0.0186, discriminator training loss: 0.0703, validation loss: 0.0227
2024-05-25 02:31:37 [INFO]: Epoch 051 - generator training loss: -0.0202, discriminator training loss: 0.0689, validation loss: 0.0229
2024-05-25 02:31:46 [INFO]: Epoch 052 - generator training loss: -0.0205, discriminator training loss: 0.0693, validation loss: 0.0229
2024-05-25 02:31:55 [INFO]: Epoch 053 - generator training loss: -0.0211, discriminator training loss: 0.0671, validation loss: 0.0220
2024-05-25 02:32:04 [INFO]: Epoch 054 - generator training loss: -0.0227, discriminator training loss: 0.0687, validation loss: 0.0227
2024-05-25 02:32:14 [INFO]: Epoch 055 - generator training loss: -0.0177, discriminator training loss: 0.0673, validation loss: 0.0227
2024-05-25 02:32:23 [INFO]: Epoch 056 - generator training loss: -0.0226, discriminator training loss: 0.0662, validation loss: 0.0217
2024-05-25 02:32:32 [INFO]: Epoch 057 - generator training loss: -0.0199, discriminator training loss: 0.0707, validation loss: 0.0223
2024-05-25 02:32:41 [INFO]: Epoch 058 - generator training loss: -0.0199, discriminator training loss: 0.0679, validation loss: 0.0223
2024-05-25 02:32:50 [INFO]: Epoch 059 - generator training loss: -0.0213, discriminator training loss: 0.0675, validation loss: 0.0220
2024-05-25 02:32:59 [INFO]: Epoch 060 - generator training loss: -0.0217, discriminator training loss: 0.0682, validation loss: 0.0221
2024-05-25 02:33:08 [INFO]: Epoch 061 - generator training loss: -0.0183, discriminator training loss: 0.0686, validation loss: 0.0215
2024-05-25 02:33:17 [INFO]: Epoch 062 - generator training loss: -0.0227, discriminator training loss: 0.0670, validation loss: 0.0215
2024-05-25 02:33:26 [INFO]: Epoch 063 - generator training loss: -0.0198, discriminator training loss: 0.0695, validation loss: 0.0211
2024-05-25 02:33:35 [INFO]: Epoch 064 - generator training loss: -0.0222, discriminator training loss: 0.0686, validation loss: 0.0216
2024-05-25 02:33:44 [INFO]: Epoch 065 - generator training loss: -0.0240, discriminator training loss: 0.0657, validation loss: 0.0217
2024-05-25 02:33:53 [INFO]: Epoch 066 - generator training loss: -0.0240, discriminator training loss: 0.0675, validation loss: 0.0217
2024-05-25 02:34:02 [INFO]: Epoch 067 - generator training loss: -0.0248, discriminator training loss: 0.0660, validation loss: 0.0214
2024-05-25 02:34:11 [INFO]: Epoch 068 - generator training loss: -0.0217, discriminator training loss: 0.0654, validation loss: 0.0209
2024-05-25 02:34:21 [INFO]: Epoch 069 - generator training loss: -0.0226, discriminator training loss: 0.0663, validation loss: 0.0208
2024-05-25 02:34:30 [INFO]: Epoch 070 - generator training loss: -0.0227, discriminator training loss: 0.0670, validation loss: 0.0209
2024-05-25 02:34:39 [INFO]: Epoch 071 - generator training loss: -0.0213, discriminator training loss: 0.0657, validation loss: 0.0206
2024-05-25 02:34:48 [INFO]: Epoch 072 - generator training loss: -0.0239, discriminator training loss: 0.0667, validation loss: 0.0202
2024-05-25 02:34:57 [INFO]: Epoch 073 - generator training loss: -0.0243, discriminator training loss: 0.0655, validation loss: 0.0212
2024-05-25 02:35:06 [INFO]: Epoch 074 - generator training loss: -0.0234, discriminator training loss: 0.0647, validation loss: 0.0211
2024-05-25 02:35:15 [INFO]: Epoch 075 - generator training loss: -0.0223, discriminator training loss: 0.0670, validation loss: 0.0210
2024-05-25 02:35:24 [INFO]: Epoch 076 - generator training loss: -0.0241, discriminator training loss: 0.0660, validation loss: 0.0201
2024-05-25 02:35:33 [INFO]: Epoch 077 - generator training loss: -0.0242, discriminator training loss: 0.0677, validation loss: 0.0206
2024-05-25 02:35:42 [INFO]: Epoch 078 - generator training loss: -0.0251, discriminator training loss: 0.0689, validation loss: 0.0200
2024-05-25 02:35:51 [INFO]: Epoch 079 - generator training loss: -0.0237, discriminator training loss: 0.0679, validation loss: 0.0197
2024-05-25 02:36:00 [INFO]: Epoch 080 - generator training loss: -0.0246, discriminator training loss: 0.0652, validation loss: 0.0200
2024-05-25 02:36:09 [INFO]: Epoch 081 - generator training loss: -0.0237, discriminator training loss: 0.0662, validation loss: 0.0206
2024-05-25 02:36:18 [INFO]: Epoch 082 - generator training loss: -0.0227, discriminator training loss: 0.0663, validation loss: 0.0229
2024-05-25 02:36:27 [INFO]: Epoch 083 - generator training loss: -0.0249, discriminator training loss: 0.0646, validation loss: 0.0201
2024-05-25 02:36:36 [INFO]: Epoch 084 - generator training loss: -0.0260, discriminator training loss: 0.0666, validation loss: 0.0192
2024-05-25 02:36:45 [INFO]: Epoch 085 - generator training loss: -0.0223, discriminator training loss: 0.0660, validation loss: 0.0200
2024-05-25 02:36:54 [INFO]: Epoch 086 - generator training loss: -0.0250, discriminator training loss: 0.0658, validation loss: 0.0198
2024-05-25 02:37:03 [INFO]: Epoch 087 - generator training loss: -0.0243, discriminator training loss: 0.0649, validation loss: 0.0199
2024-05-25 02:37:12 [INFO]: Epoch 088 - generator training loss: -0.0241, discriminator training loss: 0.0665, validation loss: 0.0198
2024-05-25 02:37:21 [INFO]: Epoch 089 - generator training loss: -0.0238, discriminator training loss: 0.0667, validation loss: 0.0202
2024-05-25 02:37:30 [INFO]: Epoch 090 - generator training loss: -0.0266, discriminator training loss: 0.0636, validation loss: 0.0195
2024-05-25 02:37:39 [INFO]: Epoch 091 - generator training loss: -0.0244, discriminator training loss: 0.0667, validation loss: 0.0196
2024-05-25 02:37:48 [INFO]: Epoch 092 - generator training loss: -0.0234, discriminator training loss: 0.0672, validation loss: 0.0193
2024-05-25 02:37:57 [INFO]: Epoch 093 - generator training loss: -0.0234, discriminator training loss: 0.0654, validation loss: 0.0195
2024-05-25 02:38:06 [INFO]: Epoch 094 - generator training loss: -0.0247, discriminator training loss: 0.0664, validation loss: 0.0199
2024-05-25 02:38:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:38:06 [INFO]: Finished training. The best model is from epoch#84.
2024-05-25 02:38:06 [INFO]: Saved the model to augmentation_saved_results/round_3/USGAN_ettm1/20240525_T022354/USGAN.pypots
2024-05-25 02:38:07 [INFO]: US-GAN on ETTm1: MAE=0.1407, MSE=0.0455
2024-05-25 02:38:07 [INFO]: Successfully saved to augmentation_saved_results/round_3/USGAN_ettm1/imputation.pkl
2024-05-25 02:38:07 [INFO]: Using the given device: cuda:0
2024-05-25 02:38:07 [INFO]: Model files will be saved to augmentation_saved_results/round_3/BRITS_ettm1/20240525_T023807
2024-05-25 02:38:07 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/BRITS_ettm1/20240525_T023807/tensorboard
2024-05-25 02:38:07 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 02:38:15 [INFO]: Epoch 001 - training loss: 1.2746, validation loss: 0.2460
2024-05-25 02:38:21 [INFO]: Epoch 002 - training loss: 0.8263, validation loss: 0.0662
2024-05-25 02:38:27 [INFO]: Epoch 003 - training loss: 0.6888, validation loss: 0.0481
2024-05-25 02:38:33 [INFO]: Epoch 004 - training loss: 0.6430, validation loss: 0.0397
2024-05-25 02:38:39 [INFO]: Epoch 005 - training loss: 0.5887, validation loss: 0.0372
2024-05-25 02:38:45 [INFO]: Epoch 006 - training loss: 0.5552, validation loss: 0.0345
2024-05-25 02:38:51 [INFO]: Epoch 007 - training loss: 0.5433, validation loss: 0.0340
2024-05-25 02:38:57 [INFO]: Epoch 008 - training loss: 0.5065, validation loss: 0.0328
2024-05-25 02:39:03 [INFO]: Epoch 009 - training loss: 0.4918, validation loss: 0.0306
2024-05-25 02:39:09 [INFO]: Epoch 010 - training loss: 0.4682, validation loss: 0.0301
2024-05-25 02:39:15 [INFO]: Epoch 011 - training loss: 0.4997, validation loss: 0.0286
2024-05-25 02:39:21 [INFO]: Epoch 012 - training loss: 0.4644, validation loss: 0.0294
2024-05-25 02:39:27 [INFO]: Epoch 013 - training loss: 0.4409, validation loss: 0.0291
2024-05-25 02:39:33 [INFO]: Epoch 014 - training loss: 0.4251, validation loss: 0.0270
2024-05-25 02:39:39 [INFO]: Epoch 015 - training loss: 0.4089, validation loss: 0.0252
2024-05-25 02:39:45 [INFO]: Epoch 016 - training loss: 0.4088, validation loss: 0.0252
2024-05-25 02:39:51 [INFO]: Epoch 017 - training loss: 0.3966, validation loss: 0.0238
2024-05-25 02:39:57 [INFO]: Epoch 018 - training loss: 0.3897, validation loss: 0.0226
2024-05-25 02:40:03 [INFO]: Epoch 019 - training loss: 0.3973, validation loss: 0.0223
2024-05-25 02:40:09 [INFO]: Epoch 020 - training loss: 0.3945, validation loss: 0.0221
2024-05-25 02:40:15 [INFO]: Epoch 021 - training loss: 0.3838, validation loss: 0.0222
2024-05-25 02:40:21 [INFO]: Epoch 022 - training loss: 0.3803, validation loss: 0.0220
2024-05-25 02:40:27 [INFO]: Epoch 023 - training loss: 0.3816, validation loss: 0.0220
2024-05-25 02:40:33 [INFO]: Epoch 024 - training loss: 0.3802, validation loss: 0.0226
2024-05-25 02:40:39 [INFO]: Epoch 025 - training loss: 0.3838, validation loss: 0.0220
2024-05-25 02:40:45 [INFO]: Epoch 026 - training loss: 0.3821, validation loss: 0.0218
2024-05-25 02:40:51 [INFO]: Epoch 027 - training loss: 0.3772, validation loss: 0.0216
2024-05-25 02:40:57 [INFO]: Epoch 028 - training loss: 0.3735, validation loss: 0.0227
2024-05-25 02:41:03 [INFO]: Epoch 029 - training loss: 0.3996, validation loss: 0.0232
2024-05-25 02:41:09 [INFO]: Epoch 030 - training loss: 0.3849, validation loss: 0.0230
2024-05-25 02:41:15 [INFO]: Epoch 031 - training loss: 0.3771, validation loss: 0.0218
2024-05-25 02:41:21 [INFO]: Epoch 032 - training loss: 0.3776, validation loss: 0.0219
2024-05-25 02:41:27 [INFO]: Epoch 033 - training loss: 0.3705, validation loss: 0.0217
2024-05-25 02:41:33 [INFO]: Epoch 034 - training loss: 0.3730, validation loss: 0.0217
2024-05-25 02:41:39 [INFO]: Epoch 035 - training loss: 0.3830, validation loss: 0.0221
2024-05-25 02:41:45 [INFO]: Epoch 036 - training loss: 0.3784, validation loss: 0.0220
2024-05-25 02:41:51 [INFO]: Epoch 037 - training loss: 0.3749, validation loss: 0.0218
2024-05-25 02:41:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:41:51 [INFO]: Finished training. The best model is from epoch#27.
2024-05-25 02:41:51 [INFO]: Saved the model to augmentation_saved_results/round_3/BRITS_ettm1/20240525_T023807/BRITS.pypots
2024-05-25 02:41:52 [INFO]: BRITS on ETTm1: MAE=0.1220, MSE=0.0433
2024-05-25 02:41:52 [INFO]: Successfully saved to augmentation_saved_results/round_3/BRITS_ettm1/imputation.pkl
2024-05-25 02:41:52 [INFO]: Using the given device: cuda:0
2024-05-25 02:41:52 [INFO]: Model files will be saved to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152
2024-05-25 02:41:52 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/tensorboard
2024-05-25 02:41:52 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 02:41:54 [INFO]: Epoch 001 - training loss: 1.4493, validation loss: 1.3517
2024-05-25 02:41:54 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch1_loss1.351712018251419.pypots
2024-05-25 02:41:54 [INFO]: Epoch 002 - training loss: 1.0961, validation loss: 1.2100
2024-05-25 02:41:54 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch2_loss1.2099786400794983.pypots
2024-05-25 02:41:54 [INFO]: Epoch 003 - training loss: 0.9893, validation loss: 1.1090
2024-05-25 02:41:54 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch3_loss1.1089780777692795.pypots
2024-05-25 02:41:55 [INFO]: Epoch 004 - training loss: 1.0081, validation loss: 1.0656
2024-05-25 02:41:55 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch4_loss1.0656467378139496.pypots
2024-05-25 02:41:55 [INFO]: Epoch 005 - training loss: 0.9473, validation loss: 1.0447
2024-05-25 02:41:55 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch5_loss1.0447455942630768.pypots
2024-05-25 02:41:55 [INFO]: Epoch 006 - training loss: 0.9290, validation loss: 1.0351
2024-05-25 02:41:55 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch6_loss1.0351313203573227.pypots
2024-05-25 02:41:55 [INFO]: Epoch 007 - training loss: 0.9275, validation loss: 1.0288
2024-05-25 02:41:55 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch7_loss1.0288303196430206.pypots
2024-05-25 02:41:55 [INFO]: Epoch 008 - training loss: 0.9243, validation loss: 1.0193
2024-05-25 02:41:55 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch8_loss1.0193372070789337.pypots
2024-05-25 02:41:55 [INFO]: Epoch 009 - training loss: 0.9305, validation loss: 1.0144
2024-05-25 02:41:55 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch9_loss1.0143790692090988.pypots
2024-05-25 02:41:56 [INFO]: Epoch 010 - training loss: 0.9152, validation loss: 1.0087
2024-05-25 02:41:56 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch10_loss1.0087416917085648.pypots
2024-05-25 02:41:56 [INFO]: Epoch 011 - training loss: 0.9038, validation loss: 1.0073
2024-05-25 02:41:56 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch11_loss1.0073216259479523.pypots
2024-05-25 02:41:56 [INFO]: Epoch 012 - training loss: 0.8889, validation loss: 1.0026
2024-05-25 02:41:56 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch12_loss1.0026482045650482.pypots
2024-05-25 02:41:56 [INFO]: Epoch 013 - training loss: 0.8990, validation loss: 1.0004
2024-05-25 02:41:56 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch13_loss1.0003740042448044.pypots
2024-05-25 02:41:56 [INFO]: Epoch 014 - training loss: 0.8789, validation loss: 0.9967
2024-05-25 02:41:56 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch14_loss0.9966608285903931.pypots
2024-05-25 02:41:57 [INFO]: Epoch 015 - training loss: 0.8531, validation loss: 0.9981
2024-05-25 02:41:57 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch15_loss0.9980867803096771.pypots
2024-05-25 02:41:57 [INFO]: Epoch 016 - training loss: 0.8732, validation loss: 0.9981
2024-05-25 02:41:57 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch16_loss0.9980707764625549.pypots
2024-05-25 02:41:57 [INFO]: Epoch 017 - training loss: 0.8886, validation loss: 0.9954
2024-05-25 02:41:57 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch17_loss0.9954178482294083.pypots
2024-05-25 02:41:57 [INFO]: Epoch 018 - training loss: 0.8853, validation loss: 0.9938
2024-05-25 02:41:57 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch18_loss0.9937534183263779.pypots
2024-05-25 02:41:57 [INFO]: Epoch 019 - training loss: 0.8768, validation loss: 0.9939
2024-05-25 02:41:57 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch19_loss0.9939323365688324.pypots
2024-05-25 02:41:58 [INFO]: Epoch 020 - training loss: 0.9166, validation loss: 0.9900
2024-05-25 02:41:58 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch20_loss0.9899614453315735.pypots
2024-05-25 02:41:58 [INFO]: Epoch 021 - training loss: 0.8633, validation loss: 0.9906
2024-05-25 02:41:58 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch21_loss0.9905864745378494.pypots
2024-05-25 02:41:58 [INFO]: Epoch 022 - training loss: 0.8345, validation loss: 0.9892
2024-05-25 02:41:58 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch22_loss0.9892217069864273.pypots
2024-05-25 02:41:58 [INFO]: Epoch 023 - training loss: 0.8357, validation loss: 0.9880
2024-05-25 02:41:58 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch23_loss0.9880016148090363.pypots
2024-05-25 02:41:58 [INFO]: Epoch 024 - training loss: 0.8270, validation loss: 0.9856
2024-05-25 02:41:58 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch24_loss0.9855908006429672.pypots
2024-05-25 02:41:58 [INFO]: Epoch 025 - training loss: 0.8524, validation loss: 0.9808
2024-05-25 02:41:58 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch25_loss0.9807694554328918.pypots
2024-05-25 02:41:59 [INFO]: Epoch 026 - training loss: 0.8337, validation loss: 0.9790
2024-05-25 02:41:59 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch26_loss0.9789651185274124.pypots
2024-05-25 02:41:59 [INFO]: Epoch 027 - training loss: 0.8452, validation loss: 0.9757
2024-05-25 02:41:59 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch27_loss0.9756776988506317.pypots
2024-05-25 02:41:59 [INFO]: Epoch 028 - training loss: 0.8255, validation loss: 0.9732
2024-05-25 02:41:59 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch28_loss0.9731852859258652.pypots
2024-05-25 02:41:59 [INFO]: Epoch 029 - training loss: 0.8647, validation loss: 0.9701
2024-05-25 02:41:59 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch29_loss0.9700973033905029.pypots
2024-05-25 02:41:59 [INFO]: Epoch 030 - training loss: 0.8306, validation loss: 0.9649
2024-05-25 02:41:59 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch30_loss0.9648534953594208.pypots
2024-05-25 02:42:00 [INFO]: Epoch 031 - training loss: 0.8485, validation loss: 0.9615
2024-05-25 02:42:00 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch31_loss0.9615002125501633.pypots
2024-05-25 02:42:00 [INFO]: Epoch 032 - training loss: 0.8251, validation loss: 0.9602
2024-05-25 02:42:00 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch32_loss0.9601791054010391.pypots
2024-05-25 02:42:00 [INFO]: Epoch 033 - training loss: 0.8313, validation loss: 0.9554
2024-05-25 02:42:00 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch33_loss0.9553904235363007.pypots
2024-05-25 02:42:00 [INFO]: Epoch 034 - training loss: 0.8781, validation loss: 0.9502
2024-05-25 02:42:00 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch34_loss0.9501905739307404.pypots
2024-05-25 02:42:00 [INFO]: Epoch 035 - training loss: 0.8213, validation loss: 0.9492
2024-05-25 02:42:00 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch35_loss0.949245348572731.pypots
2024-05-25 02:42:01 [INFO]: Epoch 036 - training loss: 0.8333, validation loss: 0.9470
2024-05-25 02:42:01 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch36_loss0.9469694048166275.pypots
2024-05-25 02:42:01 [INFO]: Epoch 037 - training loss: 0.8514, validation loss: 0.9429
2024-05-25 02:42:01 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch37_loss0.9428867250680923.pypots
2024-05-25 02:42:01 [INFO]: Epoch 038 - training loss: 0.8035, validation loss: 0.9387
2024-05-25 02:42:01 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch38_loss0.9387359321117401.pypots
2024-05-25 02:42:01 [INFO]: Epoch 039 - training loss: 0.8397, validation loss: 0.9361
2024-05-25 02:42:01 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch39_loss0.936130627989769.pypots
2024-05-25 02:42:01 [INFO]: Epoch 040 - training loss: 0.8133, validation loss: 0.9367
2024-05-25 02:42:01 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch40_loss0.9366781711578369.pypots
2024-05-25 02:42:02 [INFO]: Epoch 041 - training loss: 0.8047, validation loss: 0.9305
2024-05-25 02:42:02 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch41_loss0.9305431544780731.pypots
2024-05-25 02:42:02 [INFO]: Epoch 042 - training loss: 0.8122, validation loss: 0.9299
2024-05-25 02:42:02 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch42_loss0.9299097061157227.pypots
2024-05-25 02:42:02 [INFO]: Epoch 043 - training loss: 0.8149, validation loss: 0.9304
2024-05-25 02:42:02 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch43_loss0.9304322451353073.pypots
2024-05-25 02:42:02 [INFO]: Epoch 044 - training loss: 0.8541, validation loss: 0.9246
2024-05-25 02:42:02 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch44_loss0.9246317893266678.pypots
2024-05-25 02:42:02 [INFO]: Epoch 045 - training loss: 0.8278, validation loss: 0.9217
2024-05-25 02:42:02 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch45_loss0.9217466861009598.pypots
2024-05-25 02:42:02 [INFO]: Epoch 046 - training loss: 0.8155, validation loss: 0.9222
2024-05-25 02:42:02 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch46_loss0.9222184270620346.pypots
2024-05-25 02:42:03 [INFO]: Epoch 047 - training loss: 0.8143, validation loss: 0.9198
2024-05-25 02:42:03 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch47_loss0.9197752475738525.pypots
2024-05-25 02:42:03 [INFO]: Epoch 048 - training loss: 0.8181, validation loss: 0.9178
2024-05-25 02:42:03 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch48_loss0.9177624732255936.pypots
2024-05-25 02:42:03 [INFO]: Epoch 049 - training loss: 0.8171, validation loss: 0.9124
2024-05-25 02:42:03 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch49_loss0.9124231934547424.pypots
2024-05-25 02:42:03 [INFO]: Epoch 050 - training loss: 0.8409, validation loss: 0.9113
2024-05-25 02:42:03 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch50_loss0.9113373905420303.pypots
2024-05-25 02:42:03 [INFO]: Epoch 051 - training loss: 0.8315, validation loss: 0.9082
2024-05-25 02:42:03 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch51_loss0.9082037508487701.pypots
2024-05-25 02:42:04 [INFO]: Epoch 052 - training loss: 0.7907, validation loss: 0.9038
2024-05-25 02:42:04 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch52_loss0.9038450717926025.pypots
2024-05-25 02:42:04 [INFO]: Epoch 053 - training loss: 0.7993, validation loss: 0.9019
2024-05-25 02:42:04 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch53_loss0.9018683582544327.pypots
2024-05-25 02:42:04 [INFO]: Epoch 054 - training loss: 0.8026, validation loss: 0.9012
2024-05-25 02:42:04 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch54_loss0.9012006670236588.pypots
2024-05-25 02:42:04 [INFO]: Epoch 055 - training loss: 0.8055, validation loss: 0.9000
2024-05-25 02:42:04 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch55_loss0.899965912103653.pypots
2024-05-25 02:42:04 [INFO]: Epoch 056 - training loss: 0.8108, validation loss: 0.8965
2024-05-25 02:42:04 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch56_loss0.896469309926033.pypots
2024-05-25 02:42:05 [INFO]: Epoch 057 - training loss: 0.8024, validation loss: 0.8955
2024-05-25 02:42:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch57_loss0.8954647481441498.pypots
2024-05-25 02:42:05 [INFO]: Epoch 058 - training loss: 0.8168, validation loss: 0.8934
2024-05-25 02:42:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch58_loss0.8933720141649246.pypots
2024-05-25 02:42:05 [INFO]: Epoch 059 - training loss: 0.7942, validation loss: 0.8929
2024-05-25 02:42:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch59_loss0.8928755819797516.pypots
2024-05-25 02:42:05 [INFO]: Epoch 060 - training loss: 0.7845, validation loss: 0.8880
2024-05-25 02:42:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch60_loss0.8880156427621841.pypots
2024-05-25 02:42:05 [INFO]: Epoch 061 - training loss: 0.7835, validation loss: 0.8862
2024-05-25 02:42:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch61_loss0.8862354159355164.pypots
2024-05-25 02:42:05 [INFO]: Epoch 062 - training loss: 0.8448, validation loss: 0.8856
2024-05-25 02:42:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch62_loss0.8855900168418884.pypots
2024-05-25 02:42:06 [INFO]: Epoch 063 - training loss: 0.7938, validation loss: 0.8839
2024-05-25 02:42:06 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch63_loss0.8838660717010498.pypots
2024-05-25 02:42:06 [INFO]: Epoch 064 - training loss: 0.8177, validation loss: 0.8838
2024-05-25 02:42:06 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch64_loss0.8838111311197281.pypots
2024-05-25 02:42:06 [INFO]: Epoch 065 - training loss: 0.7947, validation loss: 0.8812
2024-05-25 02:42:06 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch65_loss0.8811874985694885.pypots
2024-05-25 02:42:06 [INFO]: Epoch 066 - training loss: 0.7833, validation loss: 0.8799
2024-05-25 02:42:06 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch66_loss0.8799417912960052.pypots
2024-05-25 02:42:06 [INFO]: Epoch 067 - training loss: 0.8315, validation loss: 0.8797
2024-05-25 02:42:06 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch67_loss0.8796759992837906.pypots
2024-05-25 02:42:07 [INFO]: Epoch 068 - training loss: 0.8165, validation loss: 0.8780
2024-05-25 02:42:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch68_loss0.8779824078083038.pypots
2024-05-25 02:42:07 [INFO]: Epoch 069 - training loss: 0.8291, validation loss: 0.8776
2024-05-25 02:42:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch69_loss0.8776376694440842.pypots
2024-05-25 02:42:07 [INFO]: Epoch 070 - training loss: 0.8103, validation loss: 0.8726
2024-05-25 02:42:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch70_loss0.8726230561733246.pypots
2024-05-25 02:42:07 [INFO]: Epoch 071 - training loss: 0.8214, validation loss: 0.8759
2024-05-25 02:42:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch71_loss0.8758679181337357.pypots
2024-05-25 02:42:07 [INFO]: Epoch 072 - training loss: 0.8041, validation loss: 0.8729
2024-05-25 02:42:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch72_loss0.8729377537965775.pypots
2024-05-25 02:42:08 [INFO]: Epoch 073 - training loss: 0.8196, validation loss: 0.8723
2024-05-25 02:42:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch73_loss0.8723488748073578.pypots
2024-05-25 02:42:08 [INFO]: Epoch 074 - training loss: 0.8033, validation loss: 0.8711
2024-05-25 02:42:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch74_loss0.871063619852066.pypots
2024-05-25 02:42:08 [INFO]: Epoch 075 - training loss: 0.7877, validation loss: 0.8720
2024-05-25 02:42:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch75_loss0.8719535171985626.pypots
2024-05-25 02:42:08 [INFO]: Epoch 076 - training loss: 0.7874, validation loss: 0.8708
2024-05-25 02:42:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch76_loss0.8707976788282394.pypots
2024-05-25 02:42:08 [INFO]: Epoch 077 - training loss: 0.8015, validation loss: 0.8730
2024-05-25 02:42:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch77_loss0.873001828789711.pypots
2024-05-25 02:42:09 [INFO]: Epoch 078 - training loss: 0.7834, validation loss: 0.8695
2024-05-25 02:42:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch78_loss0.8694989532232285.pypots
2024-05-25 02:42:09 [INFO]: Epoch 079 - training loss: 0.7895, validation loss: 0.8697
2024-05-25 02:42:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch79_loss0.86970554292202.pypots
2024-05-25 02:42:09 [INFO]: Epoch 080 - training loss: 0.8058, validation loss: 0.8706
2024-05-25 02:42:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch80_loss0.8706343024969101.pypots
2024-05-25 02:42:09 [INFO]: Epoch 081 - training loss: 0.7745, validation loss: 0.8677
2024-05-25 02:42:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch81_loss0.8676828145980835.pypots
2024-05-25 02:42:09 [INFO]: Epoch 082 - training loss: 0.7943, validation loss: 0.8683
2024-05-25 02:42:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch82_loss0.8683126121759415.pypots
2024-05-25 02:42:09 [INFO]: Epoch 083 - training loss: 0.7876, validation loss: 0.8679
2024-05-25 02:42:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch83_loss0.867864578962326.pypots
2024-05-25 02:42:10 [INFO]: Epoch 084 - training loss: 0.8512, validation loss: 0.8678
2024-05-25 02:42:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch84_loss0.8677758276462555.pypots
2024-05-25 02:42:10 [INFO]: Epoch 085 - training loss: 0.7983, validation loss: 0.8697
2024-05-25 02:42:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch85_loss0.8696712851524353.pypots
2024-05-25 02:42:10 [INFO]: Epoch 086 - training loss: 0.8013, validation loss: 0.8642
2024-05-25 02:42:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch86_loss0.8642061650753021.pypots
2024-05-25 02:42:10 [INFO]: Epoch 087 - training loss: 0.8022, validation loss: 0.8673
2024-05-25 02:42:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch87_loss0.8673479110002518.pypots
2024-05-25 02:42:10 [INFO]: Epoch 088 - training loss: 0.8024, validation loss: 0.8683
2024-05-25 02:42:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch88_loss0.8683056533336639.pypots
2024-05-25 02:42:11 [INFO]: Epoch 089 - training loss: 0.7955, validation loss: 0.8679
2024-05-25 02:42:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch89_loss0.8678890317678452.pypots
2024-05-25 02:42:11 [INFO]: Epoch 090 - training loss: 0.7875, validation loss: 0.8639
2024-05-25 02:42:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch90_loss0.8639056086540222.pypots
2024-05-25 02:42:11 [INFO]: Epoch 091 - training loss: 0.7786, validation loss: 0.8650
2024-05-25 02:42:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch91_loss0.8650049418210983.pypots
2024-05-25 02:42:11 [INFO]: Epoch 092 - training loss: 0.7925, validation loss: 0.8666
2024-05-25 02:42:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch92_loss0.8665662407875061.pypots
2024-05-25 02:42:11 [INFO]: Epoch 093 - training loss: 0.8047, validation loss: 0.8645
2024-05-25 02:42:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch93_loss0.8645103871822357.pypots
2024-05-25 02:42:12 [INFO]: Epoch 094 - training loss: 0.7840, validation loss: 0.8661
2024-05-25 02:42:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch94_loss0.8661254197359085.pypots
2024-05-25 02:42:12 [INFO]: Epoch 095 - training loss: 0.7980, validation loss: 0.8650
2024-05-25 02:42:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch95_loss0.8650108277797699.pypots
2024-05-25 02:42:12 [INFO]: Epoch 096 - training loss: 0.7709, validation loss: 0.8654
2024-05-25 02:42:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch96_loss0.8653879761695862.pypots
2024-05-25 02:42:12 [INFO]: Epoch 097 - training loss: 0.8162, validation loss: 0.8681
2024-05-25 02:42:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch97_loss0.8681408762931824.pypots
2024-05-25 02:42:12 [INFO]: Epoch 098 - training loss: 0.7961, validation loss: 0.8648
2024-05-25 02:42:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch98_loss0.864849716424942.pypots
2024-05-25 02:42:12 [INFO]: Epoch 099 - training loss: 0.7989, validation loss: 0.8656
2024-05-25 02:42:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch99_loss0.8656482696533203.pypots
2024-05-25 02:42:13 [INFO]: Epoch 100 - training loss: 0.7881, validation loss: 0.8677
2024-05-25 02:42:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN_epoch100_loss0.8676975965499878.pypots
2024-05-25 02:42:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:42:13 [INFO]: Finished training. The best model is from epoch#90.
2024-05-25 02:42:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024152/MRNN.pypots
2024-05-25 02:42:13 [INFO]: MRNN on ETTm1: MAE=0.7180, MSE=1.2340
2024-05-25 02:42:13 [INFO]: Successfully saved to augmentation_saved_results/round_3/MRNN_ettm1/imputation.pkl
2024-05-25 02:42:13 [INFO]: Using the given device: cpu
2024-05-25 02:42:13 [INFO]: LOCF on ETTm1: MAE=0.1348, MSE=0.0715
2024-05-25 02:42:13 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_ettm1".
2024-05-25 02:42:13 [INFO]: Successfully saved to augmentation_saved_results/round_3/LOCF_ettm1/imputation.pkl
2024-05-25 02:42:13 [INFO]: Median on ETTm1: MAE=0.6516, MSE=0.8223
2024-05-25 02:42:13 [INFO]: Successfully created the given path "saved_results/round_3/Median_ettm1".
2024-05-25 02:42:13 [INFO]: Successfully saved to augmentation_saved_results/round_3/Median_ettm1/imputation.pkl
2024-05-25 02:42:13 [INFO]: Mean on ETTm1: MAE=0.6566, MSE=0.8036
2024-05-25 02:42:13 [INFO]: Successfully created the given path "saved_results/round_3/Mean_ettm1".
2024-05-25 02:42:13 [INFO]: Successfully saved to augmentation_saved_results/round_3/Mean_ettm1/imputation.pkl
2024-05-25 02:42:13 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-25 02:42:13 [INFO]: Using the given device: cuda:0
2024-05-25 02:42:13 [INFO]: Model files will be saved to augmentation_saved_results/round_4/SAITS_ettm1/20240525_T024213
2024-05-25 02:42:13 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/SAITS_ettm1/20240525_T024213/tensorboard
2024-05-25 02:42:13 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 02:42:14 [INFO]: Epoch 001 - training loss: 1.1688, validation loss: 0.2444
2024-05-25 02:42:14 [INFO]: Epoch 002 - training loss: 0.9031, validation loss: 0.1190
2024-05-25 02:42:15 [INFO]: Epoch 003 - training loss: 0.8016, validation loss: 0.0902
2024-05-25 02:42:15 [INFO]: Epoch 004 - training loss: 0.7514, validation loss: 0.0806
2024-05-25 02:42:16 [INFO]: Epoch 005 - training loss: 0.7124, validation loss: 0.0779
2024-05-25 02:42:16 [INFO]: Epoch 006 - training loss: 0.6937, validation loss: 0.0630
2024-05-25 02:42:17 [INFO]: Epoch 007 - training loss: 0.6669, validation loss: 0.0649
2024-05-25 02:42:17 [INFO]: Epoch 008 - training loss: 0.6587, validation loss: 0.0797
2024-05-25 02:42:18 [INFO]: Epoch 009 - training loss: 0.6407, validation loss: 0.0778
2024-05-25 02:42:18 [INFO]: Epoch 010 - training loss: 0.6402, validation loss: 0.0670
2024-05-25 02:42:19 [INFO]: Epoch 011 - training loss: 0.6226, validation loss: 0.0577
2024-05-25 02:42:19 [INFO]: Epoch 012 - training loss: 0.6219, validation loss: 0.0692
2024-05-25 02:42:20 [INFO]: Epoch 013 - training loss: 0.6062, validation loss: 0.0532
2024-05-25 02:42:20 [INFO]: Epoch 014 - training loss: 0.5957, validation loss: 0.0605
2024-05-25 02:42:21 [INFO]: Epoch 015 - training loss: 0.6060, validation loss: 0.0680
2024-05-25 02:42:21 [INFO]: Epoch 016 - training loss: 0.5927, validation loss: 0.0583
2024-05-25 02:42:22 [INFO]: Epoch 017 - training loss: 0.5721, validation loss: 0.0519
2024-05-25 02:42:22 [INFO]: Epoch 018 - training loss: 0.5767, validation loss: 0.0536
2024-05-25 02:42:23 [INFO]: Epoch 019 - training loss: 0.5923, validation loss: 0.0772
2024-05-25 02:42:23 [INFO]: Epoch 020 - training loss: 0.5839, validation loss: 0.0500
2024-05-25 02:42:24 [INFO]: Epoch 021 - training loss: 0.5619, validation loss: 0.0398
2024-05-25 02:42:24 [INFO]: Epoch 022 - training loss: 0.5518, validation loss: 0.0644
2024-05-25 02:42:25 [INFO]: Epoch 023 - training loss: 0.5768, validation loss: 0.0525
2024-05-25 02:42:25 [INFO]: Epoch 024 - training loss: 0.5485, validation loss: 0.0524
2024-05-25 02:42:26 [INFO]: Epoch 025 - training loss: 0.5563, validation loss: 0.0548
2024-05-25 02:42:26 [INFO]: Epoch 026 - training loss: 0.5595, validation loss: 0.0615
2024-05-25 02:42:27 [INFO]: Epoch 027 - training loss: 0.5324, validation loss: 0.0522
2024-05-25 02:42:27 [INFO]: Epoch 028 - training loss: 0.5446, validation loss: 0.0368
2024-05-25 02:42:28 [INFO]: Epoch 029 - training loss: 0.5285, validation loss: 0.0497
2024-05-25 02:42:28 [INFO]: Epoch 030 - training loss: 0.5454, validation loss: 0.0512
2024-05-25 02:42:29 [INFO]: Epoch 031 - training loss: 0.5248, validation loss: 0.0403
2024-05-25 02:42:30 [INFO]: Epoch 032 - training loss: 0.5055, validation loss: 0.0338
2024-05-25 02:42:30 [INFO]: Epoch 033 - training loss: 0.5113, validation loss: 0.0304
2024-05-25 02:42:31 [INFO]: Epoch 034 - training loss: 0.5021, validation loss: 0.0260
2024-05-25 02:42:31 [INFO]: Epoch 035 - training loss: 0.4994, validation loss: 0.0379
2024-05-25 02:42:32 [INFO]: Epoch 036 - training loss: 0.5033, validation loss: 0.0366
2024-05-25 02:42:32 [INFO]: Epoch 037 - training loss: 0.4911, validation loss: 0.0302
2024-05-25 02:42:33 [INFO]: Epoch 038 - training loss: 0.4906, validation loss: 0.0344
2024-05-25 02:42:33 [INFO]: Epoch 039 - training loss: 0.4954, validation loss: 0.0410
2024-05-25 02:42:34 [INFO]: Epoch 040 - training loss: 0.5088, validation loss: 0.0482
2024-05-25 02:42:34 [INFO]: Epoch 041 - training loss: 0.5110, validation loss: 0.0754
2024-05-25 02:42:35 [INFO]: Epoch 042 - training loss: 0.4959, validation loss: 0.0314
2024-05-25 02:42:35 [INFO]: Epoch 043 - training loss: 0.5021, validation loss: 0.0377
2024-05-25 02:42:36 [INFO]: Epoch 044 - training loss: 0.4883, validation loss: 0.0366
2024-05-25 02:42:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:42:36 [INFO]: Finished training. The best model is from epoch#34.
2024-05-25 02:42:36 [INFO]: Saved the model to augmentation_saved_results/round_4/SAITS_ettm1/20240525_T024213/SAITS.pypots
2024-05-25 02:42:36 [INFO]: SAITS on ETTm1: MAE=0.1384, MSE=0.0367
2024-05-25 02:42:36 [INFO]: Successfully saved to augmentation_saved_results/round_4/SAITS_ettm1/imputation.pkl
2024-05-25 02:42:36 [INFO]: Using the given device: cuda:0
2024-05-25 02:42:36 [INFO]: Model files will be saved to augmentation_saved_results/round_4/Transformer_ettm1/20240525_T024236
2024-05-25 02:42:36 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/Transformer_ettm1/20240525_T024236/tensorboard
2024-05-25 02:42:36 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 02:42:36 [INFO]: Epoch 001 - training loss: 1.1711, validation loss: 0.3246
2024-05-25 02:42:36 [INFO]: Epoch 002 - training loss: 0.7349, validation loss: 0.1680
2024-05-25 02:42:36 [INFO]: Epoch 003 - training loss: 0.6006, validation loss: 0.1036
2024-05-25 02:42:37 [INFO]: Epoch 004 - training loss: 0.5333, validation loss: 0.0798
2024-05-25 02:42:37 [INFO]: Epoch 005 - training loss: 0.4900, validation loss: 0.0676
2024-05-25 02:42:37 [INFO]: Epoch 006 - training loss: 0.4642, validation loss: 0.0666
2024-05-25 02:42:37 [INFO]: Epoch 007 - training loss: 0.4342, validation loss: 0.0540
2024-05-25 02:42:38 [INFO]: Epoch 008 - training loss: 0.4168, validation loss: 0.0497
2024-05-25 02:42:38 [INFO]: Epoch 009 - training loss: 0.4018, validation loss: 0.0474
2024-05-25 02:42:38 [INFO]: Epoch 010 - training loss: 0.3856, validation loss: 0.0455
2024-05-25 02:42:38 [INFO]: Epoch 011 - training loss: 0.3734, validation loss: 0.0416
2024-05-25 02:42:38 [INFO]: Epoch 012 - training loss: 0.3651, validation loss: 0.0565
2024-05-25 02:42:39 [INFO]: Epoch 013 - training loss: 0.3587, validation loss: 0.0417
2024-05-25 02:42:39 [INFO]: Epoch 014 - training loss: 0.3533, validation loss: 0.0447
2024-05-25 02:42:39 [INFO]: Epoch 015 - training loss: 0.3521, validation loss: 0.0372
2024-05-25 02:42:39 [INFO]: Epoch 016 - training loss: 0.3461, validation loss: 0.0457
2024-05-25 02:42:39 [INFO]: Epoch 017 - training loss: 0.3339, validation loss: 0.0366
2024-05-25 02:42:40 [INFO]: Epoch 018 - training loss: 0.3331, validation loss: 0.0379
2024-05-25 02:42:40 [INFO]: Epoch 019 - training loss: 0.3237, validation loss: 0.0541
2024-05-25 02:42:40 [INFO]: Epoch 020 - training loss: 0.3301, validation loss: 0.0362
2024-05-25 02:42:40 [INFO]: Epoch 021 - training loss: 0.3199, validation loss: 0.0339
2024-05-25 02:42:41 [INFO]: Epoch 022 - training loss: 0.3076, validation loss: 0.0337
2024-05-25 02:42:41 [INFO]: Epoch 023 - training loss: 0.3140, validation loss: 0.0329
2024-05-25 02:42:41 [INFO]: Epoch 024 - training loss: 0.2973, validation loss: 0.0319
2024-05-25 02:42:41 [INFO]: Epoch 025 - training loss: 0.3024, validation loss: 0.0310
2024-05-25 02:42:41 [INFO]: Epoch 026 - training loss: 0.3004, validation loss: 0.0301
2024-05-25 02:42:42 [INFO]: Epoch 027 - training loss: 0.3060, validation loss: 0.0327
2024-05-25 02:42:42 [INFO]: Epoch 028 - training loss: 0.2960, validation loss: 0.0324
2024-05-25 02:42:42 [INFO]: Epoch 029 - training loss: 0.2906, validation loss: 0.0314
2024-05-25 02:42:42 [INFO]: Epoch 030 - training loss: 0.2831, validation loss: 0.0275
2024-05-25 02:42:43 [INFO]: Epoch 031 - training loss: 0.2752, validation loss: 0.0313
2024-05-25 02:42:43 [INFO]: Epoch 032 - training loss: 0.2778, validation loss: 0.0322
2024-05-25 02:42:43 [INFO]: Epoch 033 - training loss: 0.2726, validation loss: 0.0286
2024-05-25 02:42:43 [INFO]: Epoch 034 - training loss: 0.2654, validation loss: 0.0297
2024-05-25 02:42:43 [INFO]: Epoch 035 - training loss: 0.2666, validation loss: 0.0271
2024-05-25 02:42:44 [INFO]: Epoch 036 - training loss: 0.2626, validation loss: 0.0302
2024-05-25 02:42:44 [INFO]: Epoch 037 - training loss: 0.2601, validation loss: 0.0299
2024-05-25 02:42:44 [INFO]: Epoch 038 - training loss: 0.2593, validation loss: 0.0239
2024-05-25 02:42:44 [INFO]: Epoch 039 - training loss: 0.2550, validation loss: 0.0248
2024-05-25 02:42:44 [INFO]: Epoch 040 - training loss: 0.2546, validation loss: 0.0248
2024-05-25 02:42:45 [INFO]: Epoch 041 - training loss: 0.2512, validation loss: 0.0258
2024-05-25 02:42:45 [INFO]: Epoch 042 - training loss: 0.2553, validation loss: 0.0235
2024-05-25 02:42:45 [INFO]: Epoch 043 - training loss: 0.2478, validation loss: 0.0242
2024-05-25 02:42:45 [INFO]: Epoch 044 - training loss: 0.2469, validation loss: 0.0253
2024-05-25 02:42:46 [INFO]: Epoch 045 - training loss: 0.2473, validation loss: 0.0278
2024-05-25 02:42:46 [INFO]: Epoch 046 - training loss: 0.2488, validation loss: 0.0229
2024-05-25 02:42:46 [INFO]: Epoch 047 - training loss: 0.2430, validation loss: 0.0246
2024-05-25 02:42:46 [INFO]: Epoch 048 - training loss: 0.2398, validation loss: 0.0244
2024-05-25 02:42:46 [INFO]: Epoch 049 - training loss: 0.2387, validation loss: 0.0270
2024-05-25 02:42:47 [INFO]: Epoch 050 - training loss: 0.2350, validation loss: 0.0263
2024-05-25 02:42:47 [INFO]: Epoch 051 - training loss: 0.2325, validation loss: 0.0304
2024-05-25 02:42:47 [INFO]: Epoch 052 - training loss: 0.2440, validation loss: 0.0295
2024-05-25 02:42:47 [INFO]: Epoch 053 - training loss: 0.2398, validation loss: 0.0221
2024-05-25 02:42:48 [INFO]: Epoch 054 - training loss: 0.2296, validation loss: 0.0288
2024-05-25 02:42:48 [INFO]: Epoch 055 - training loss: 0.2301, validation loss: 0.0220
2024-05-25 02:42:48 [INFO]: Epoch 056 - training loss: 0.2225, validation loss: 0.0225
2024-05-25 02:42:48 [INFO]: Epoch 057 - training loss: 0.2242, validation loss: 0.0231
2024-05-25 02:42:48 [INFO]: Epoch 058 - training loss: 0.2297, validation loss: 0.0269
2024-05-25 02:42:49 [INFO]: Epoch 059 - training loss: 0.2248, validation loss: 0.0219
2024-05-25 02:42:49 [INFO]: Epoch 060 - training loss: 0.2254, validation loss: 0.0211
2024-05-25 02:42:49 [INFO]: Epoch 061 - training loss: 0.2223, validation loss: 0.0228
2024-05-25 02:42:49 [INFO]: Epoch 062 - training loss: 0.2205, validation loss: 0.0224
2024-05-25 02:42:49 [INFO]: Epoch 063 - training loss: 0.2165, validation loss: 0.0237
2024-05-25 02:42:50 [INFO]: Epoch 064 - training loss: 0.2140, validation loss: 0.0221
2024-05-25 02:42:50 [INFO]: Epoch 065 - training loss: 0.2094, validation loss: 0.0232
2024-05-25 02:42:50 [INFO]: Epoch 066 - training loss: 0.2216, validation loss: 0.0278
2024-05-25 02:42:50 [INFO]: Epoch 067 - training loss: 0.2199, validation loss: 0.0229
2024-05-25 02:42:51 [INFO]: Epoch 068 - training loss: 0.2140, validation loss: 0.0250
2024-05-25 02:42:51 [INFO]: Epoch 069 - training loss: 0.2124, validation loss: 0.0224
2024-05-25 02:42:51 [INFO]: Epoch 070 - training loss: 0.2144, validation loss: 0.0240
2024-05-25 02:42:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:42:51 [INFO]: Finished training. The best model is from epoch#60.
2024-05-25 02:42:51 [INFO]: Saved the model to augmentation_saved_results/round_4/Transformer_ettm1/20240525_T024236/Transformer.pypots
2024-05-25 02:42:51 [INFO]: Transformer on ETTm1: MAE=0.1172, MSE=0.0264
2024-05-25 02:42:51 [INFO]: Successfully saved to augmentation_saved_results/round_4/Transformer_ettm1/imputation.pkl
2024-05-25 02:42:51 [INFO]: Using the given device: cuda:0
2024-05-25 02:42:51 [INFO]: Model files will be saved to augmentation_saved_results/round_4/TimesNet_ettm1/20240525_T024251
2024-05-25 02:42:51 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/TimesNet_ettm1/20240525_T024251/tensorboard
2024-05-25 02:42:51 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 02:42:52 [INFO]: Epoch 001 - training loss: 0.1648, validation loss: 0.0541
2024-05-25 02:42:52 [INFO]: Epoch 002 - training loss: 0.0651, validation loss: 0.0367
2024-05-25 02:42:52 [INFO]: Epoch 003 - training loss: 0.0497, validation loss: 0.0347
2024-05-25 02:42:52 [INFO]: Epoch 004 - training loss: 0.0485, validation loss: 0.0315
2024-05-25 02:42:52 [INFO]: Epoch 005 - training loss: 0.0491, validation loss: 0.0295
2024-05-25 02:42:53 [INFO]: Epoch 006 - training loss: 0.0432, validation loss: 0.0284
2024-05-25 02:42:53 [INFO]: Epoch 007 - training loss: 0.0428, validation loss: 0.0284
2024-05-25 02:42:53 [INFO]: Epoch 008 - training loss: 0.0432, validation loss: 0.0288
2024-05-25 02:42:53 [INFO]: Epoch 009 - training loss: 0.0430, validation loss: 0.0280
2024-05-25 02:42:53 [INFO]: Epoch 010 - training loss: 0.0430, validation loss: 0.0300
2024-05-25 02:42:54 [INFO]: Epoch 011 - training loss: 0.0442, validation loss: 0.0300
2024-05-25 02:42:54 [INFO]: Epoch 012 - training loss: 0.0437, validation loss: 0.0291
2024-05-25 02:42:54 [INFO]: Epoch 013 - training loss: 0.0453, validation loss: 0.0283
2024-05-25 02:42:54 [INFO]: Epoch 014 - training loss: 0.0482, validation loss: 0.0271
2024-05-25 02:42:54 [INFO]: Epoch 015 - training loss: 0.0452, validation loss: 0.0260
2024-05-25 02:42:55 [INFO]: Epoch 016 - training loss: 0.0422, validation loss: 0.0291
2024-05-25 02:42:55 [INFO]: Epoch 017 - training loss: 0.0416, validation loss: 0.0281
2024-05-25 02:42:55 [INFO]: Epoch 018 - training loss: 0.0422, validation loss: 0.0272
2024-05-25 02:42:55 [INFO]: Epoch 019 - training loss: 0.0427, validation loss: 0.0292
2024-05-25 02:42:56 [INFO]: Epoch 020 - training loss: 0.0460, validation loss: 0.0286
2024-05-25 02:42:56 [INFO]: Epoch 021 - training loss: 0.0501, validation loss: 0.0252
2024-05-25 02:42:56 [INFO]: Epoch 022 - training loss: 0.0414, validation loss: 0.0272
2024-05-25 02:42:56 [INFO]: Epoch 023 - training loss: 0.0408, validation loss: 0.0267
2024-05-25 02:42:56 [INFO]: Epoch 024 - training loss: 0.0401, validation loss: 0.0266
2024-05-25 02:42:57 [INFO]: Epoch 025 - training loss: 0.0393, validation loss: 0.0259
2024-05-25 02:42:57 [INFO]: Epoch 026 - training loss: 0.0380, validation loss: 0.0267
2024-05-25 02:42:57 [INFO]: Epoch 027 - training loss: 0.0389, validation loss: 0.0253
2024-05-25 02:42:57 [INFO]: Epoch 028 - training loss: 0.0403, validation loss: 0.0248
2024-05-25 02:42:57 [INFO]: Epoch 029 - training loss: 0.0391, validation loss: 0.0249
2024-05-25 02:42:58 [INFO]: Epoch 030 - training loss: 0.0388, validation loss: 0.0250
2024-05-25 02:42:58 [INFO]: Epoch 031 - training loss: 0.0393, validation loss: 0.0241
2024-05-25 02:42:58 [INFO]: Epoch 032 - training loss: 0.0380, validation loss: 0.0248
2024-05-25 02:42:58 [INFO]: Epoch 033 - training loss: 0.0398, validation loss: 0.0251
2024-05-25 02:42:59 [INFO]: Epoch 034 - training loss: 0.0381, validation loss: 0.0247
2024-05-25 02:42:59 [INFO]: Epoch 035 - training loss: 0.0373, validation loss: 0.0244
2024-05-25 02:42:59 [INFO]: Epoch 036 - training loss: 0.0345, validation loss: 0.0227
2024-05-25 02:42:59 [INFO]: Epoch 037 - training loss: 0.0349, validation loss: 0.0239
2024-05-25 02:42:59 [INFO]: Epoch 038 - training loss: 0.0342, validation loss: 0.0229
2024-05-25 02:43:00 [INFO]: Epoch 039 - training loss: 0.0364, validation loss: 0.0238
2024-05-25 02:43:00 [INFO]: Epoch 040 - training loss: 0.0357, validation loss: 0.0256
2024-05-25 02:43:00 [INFO]: Epoch 041 - training loss: 0.0381, validation loss: 0.0252
2024-05-25 02:43:00 [INFO]: Epoch 042 - training loss: 0.0368, validation loss: 0.0258
2024-05-25 02:43:00 [INFO]: Epoch 043 - training loss: 0.0335, validation loss: 0.0251
2024-05-25 02:43:01 [INFO]: Epoch 044 - training loss: 0.0355, validation loss: 0.0245
2024-05-25 02:43:01 [INFO]: Epoch 045 - training loss: 0.0353, validation loss: 0.0227
2024-05-25 02:43:01 [INFO]: Epoch 046 - training loss: 0.0340, validation loss: 0.0221
2024-05-25 02:43:01 [INFO]: Epoch 047 - training loss: 0.0352, validation loss: 0.0227
2024-05-25 02:43:01 [INFO]: Epoch 048 - training loss: 0.0337, validation loss: 0.0216
2024-05-25 02:43:02 [INFO]: Epoch 049 - training loss: 0.0338, validation loss: 0.0232
2024-05-25 02:43:02 [INFO]: Epoch 050 - training loss: 0.0363, validation loss: 0.0268
2024-05-25 02:43:02 [INFO]: Epoch 051 - training loss: 0.0460, validation loss: 0.0243
2024-05-25 02:43:02 [INFO]: Epoch 052 - training loss: 0.0355, validation loss: 0.0229
2024-05-25 02:43:03 [INFO]: Epoch 053 - training loss: 0.0342, validation loss: 0.0227
2024-05-25 02:43:03 [INFO]: Epoch 054 - training loss: 0.0372, validation loss: 0.0231
2024-05-25 02:43:03 [INFO]: Epoch 055 - training loss: 0.0361, validation loss: 0.0226
2024-05-25 02:43:03 [INFO]: Epoch 056 - training loss: 0.0346, validation loss: 0.0226
2024-05-25 02:43:03 [INFO]: Epoch 057 - training loss: 0.0351, validation loss: 0.0225
2024-05-25 02:43:04 [INFO]: Epoch 058 - training loss: 0.0345, validation loss: 0.0230
2024-05-25 02:43:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:43:04 [INFO]: Finished training. The best model is from epoch#48.
2024-05-25 02:43:04 [INFO]: Saved the model to augmentation_saved_results/round_4/TimesNet_ettm1/20240525_T024251/TimesNet.pypots
2024-05-25 02:43:04 [INFO]: TimesNet on ETTm1: MAE=0.1095, MSE=0.0255
2024-05-25 02:43:04 [INFO]: Successfully saved to augmentation_saved_results/round_4/TimesNet_ettm1/imputation.pkl
2024-05-25 02:43:04 [INFO]: Using the given device: cuda:0
2024-05-25 02:43:04 [INFO]: Model files will be saved to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304
2024-05-25 02:43:04 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/tensorboard
2024-05-25 02:43:04 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 02:43:06 [INFO]: Epoch 001 - training loss: 0.6815, validation loss: 0.4851
2024-05-25 02:43:06 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch1_loss0.48511094599962234.pypots
2024-05-25 02:43:08 [INFO]: Epoch 002 - training loss: 0.3816, validation loss: 0.3691
2024-05-25 02:43:08 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch2_loss0.36907703429460526.pypots
2024-05-25 02:43:10 [INFO]: Epoch 003 - training loss: 0.3603, validation loss: 0.3513
2024-05-25 02:43:10 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch3_loss0.3513428419828415.pypots
2024-05-25 02:43:12 [INFO]: Epoch 004 - training loss: 0.2984, validation loss: 0.3492
2024-05-25 02:43:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch4_loss0.34916016459465027.pypots
2024-05-25 02:43:14 [INFO]: Epoch 005 - training loss: 0.3567, validation loss: 0.3057
2024-05-25 02:43:14 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch5_loss0.30573098361492157.pypots
2024-05-25 02:43:16 [INFO]: Epoch 006 - training loss: 0.2499, validation loss: 0.2916
2024-05-25 02:43:16 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch6_loss0.29164835810661316.pypots
2024-05-25 02:43:18 [INFO]: Epoch 007 - training loss: 0.2939, validation loss: 0.2910
2024-05-25 02:43:18 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch7_loss0.2910403534770012.pypots
2024-05-25 02:43:20 [INFO]: Epoch 008 - training loss: 0.2608, validation loss: 0.2729
2024-05-25 02:43:20 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch8_loss0.27288076281547546.pypots
2024-05-25 02:43:22 [INFO]: Epoch 009 - training loss: 0.2395, validation loss: 0.2587
2024-05-25 02:43:22 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch9_loss0.2586909681558609.pypots
2024-05-25 02:43:25 [INFO]: Epoch 010 - training loss: 0.1988, validation loss: 0.2348
2024-05-25 02:43:25 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch10_loss0.23475996777415276.pypots
2024-05-25 02:43:27 [INFO]: Epoch 011 - training loss: 0.2491, validation loss: 0.2344
2024-05-25 02:43:27 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch11_loss0.2343660332262516.pypots
2024-05-25 02:43:29 [INFO]: Epoch 012 - training loss: 0.2391, validation loss: 0.2397
2024-05-25 02:43:29 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch12_loss0.2396896667778492.pypots
2024-05-25 02:43:31 [INFO]: Epoch 013 - training loss: 0.2414, validation loss: 0.2243
2024-05-25 02:43:31 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch13_loss0.22433196380734444.pypots
2024-05-25 02:43:33 [INFO]: Epoch 014 - training loss: 0.2343, validation loss: 0.2165
2024-05-25 02:43:33 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch14_loss0.21645262092351913.pypots
2024-05-25 02:43:35 [INFO]: Epoch 015 - training loss: 0.1958, validation loss: 0.2141
2024-05-25 02:43:35 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch15_loss0.21413064375519753.pypots
2024-05-25 02:43:37 [INFO]: Epoch 016 - training loss: 0.2157, validation loss: 0.2121
2024-05-25 02:43:37 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch16_loss0.21211481094360352.pypots
2024-05-25 02:43:39 [INFO]: Epoch 017 - training loss: 0.2270, validation loss: 0.1967
2024-05-25 02:43:39 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch17_loss0.1966526210308075.pypots
2024-05-25 02:43:41 [INFO]: Epoch 018 - training loss: 0.2027, validation loss: 0.1949
2024-05-25 02:43:41 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch18_loss0.19488343968987465.pypots
2024-05-25 02:43:43 [INFO]: Epoch 019 - training loss: 0.1932, validation loss: 0.1920
2024-05-25 02:43:43 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch19_loss0.19196442887187004.pypots
2024-05-25 02:43:45 [INFO]: Epoch 020 - training loss: 0.2048, validation loss: 0.1797
2024-05-25 02:43:45 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch20_loss0.17967771366238594.pypots
2024-05-25 02:43:47 [INFO]: Epoch 021 - training loss: 0.1883, validation loss: 0.1788
2024-05-25 02:43:47 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch21_loss0.1787763573229313.pypots
2024-05-25 02:43:49 [INFO]: Epoch 022 - training loss: 0.1652, validation loss: 0.1794
2024-05-25 02:43:49 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch22_loss0.17937486246228218.pypots
2024-05-25 02:43:52 [INFO]: Epoch 023 - training loss: 0.1672, validation loss: 0.1736
2024-05-25 02:43:52 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch23_loss0.17362427338957787.pypots
2024-05-25 02:43:54 [INFO]: Epoch 024 - training loss: 0.1684, validation loss: 0.1720
2024-05-25 02:43:54 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch24_loss0.17200271040201187.pypots
2024-05-25 02:43:56 [INFO]: Epoch 025 - training loss: 0.2110, validation loss: 0.1907
2024-05-25 02:43:56 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch25_loss0.19070827588438988.pypots
2024-05-25 02:43:58 [INFO]: Epoch 026 - training loss: 0.2650, validation loss: 0.2066
2024-05-25 02:43:58 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch26_loss0.20664753764867783.pypots
2024-05-25 02:44:00 [INFO]: Epoch 027 - training loss: 0.2350, validation loss: 0.1800
2024-05-25 02:44:00 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch27_loss0.18001073971390724.pypots
2024-05-25 02:44:02 [INFO]: Epoch 028 - training loss: 0.2012, validation loss: 0.1885
2024-05-25 02:44:02 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch28_loss0.18847833201289177.pypots
2024-05-25 02:44:04 [INFO]: Epoch 029 - training loss: 0.2079, validation loss: 0.1828
2024-05-25 02:44:04 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch29_loss0.18281306326389313.pypots
2024-05-25 02:44:06 [INFO]: Epoch 030 - training loss: 0.2298, validation loss: 0.1922
2024-05-25 02:44:06 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch30_loss0.19215340912342072.pypots
2024-05-25 02:44:08 [INFO]: Epoch 031 - training loss: 0.2012, validation loss: 0.1768
2024-05-25 02:44:08 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch31_loss0.17682579904794693.pypots
2024-05-25 02:44:10 [INFO]: Epoch 032 - training loss: 0.1885, validation loss: 0.1653
2024-05-25 02:44:10 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch32_loss0.16533806174993515.pypots
2024-05-25 02:44:12 [INFO]: Epoch 033 - training loss: 0.1894, validation loss: 0.1686
2024-05-25 02:44:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch33_loss0.16861511766910553.pypots
2024-05-25 02:44:14 [INFO]: Epoch 034 - training loss: 0.1864, validation loss: 0.1779
2024-05-25 02:44:14 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch34_loss0.17790206521749496.pypots
2024-05-25 02:44:17 [INFO]: Epoch 035 - training loss: 0.2409, validation loss: 0.1660
2024-05-25 02:44:17 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch35_loss0.16599826142191887.pypots
2024-05-25 02:44:19 [INFO]: Epoch 036 - training loss: 0.1842, validation loss: 0.1789
2024-05-25 02:44:19 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch36_loss0.17887099087238312.pypots
2024-05-25 02:44:21 [INFO]: Epoch 037 - training loss: 0.1804, validation loss: 0.1744
2024-05-25 02:44:21 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch37_loss0.17441488057374954.pypots
2024-05-25 02:44:23 [INFO]: Epoch 038 - training loss: 0.2020, validation loss: 0.1700
2024-05-25 02:44:23 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch38_loss0.16996069997549057.pypots
2024-05-25 02:44:25 [INFO]: Epoch 039 - training loss: 0.1907, validation loss: 0.1702
2024-05-25 02:44:25 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch39_loss0.1701555997133255.pypots
2024-05-25 02:44:27 [INFO]: Epoch 040 - training loss: 0.1588, validation loss: 0.1633
2024-05-25 02:44:27 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch40_loss0.16330764815211296.pypots
2024-05-25 02:44:29 [INFO]: Epoch 041 - training loss: 0.1706, validation loss: 0.1555
2024-05-25 02:44:29 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch41_loss0.15550247579813004.pypots
2024-05-25 02:44:31 [INFO]: Epoch 042 - training loss: 0.1600, validation loss: 0.1558
2024-05-25 02:44:31 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch42_loss0.15583530440926552.pypots
2024-05-25 02:44:33 [INFO]: Epoch 043 - training loss: 0.1733, validation loss: 0.1501
2024-05-25 02:44:33 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch43_loss0.15006081014871597.pypots
2024-05-25 02:44:35 [INFO]: Epoch 044 - training loss: 0.2108, validation loss: 0.3406
2024-05-25 02:44:35 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch44_loss0.3406396806240082.pypots
2024-05-25 02:44:37 [INFO]: Epoch 045 - training loss: 0.3204, validation loss: 0.2759
2024-05-25 02:44:37 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch45_loss0.2758777365088463.pypots
2024-05-25 02:44:39 [INFO]: Epoch 046 - training loss: 0.2399, validation loss: 0.2022
2024-05-25 02:44:39 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch46_loss0.20221219211816788.pypots
2024-05-25 02:44:42 [INFO]: Epoch 047 - training loss: 0.2021, validation loss: 0.1974
2024-05-25 02:44:42 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch47_loss0.19736381247639656.pypots
2024-05-25 02:44:44 [INFO]: Epoch 048 - training loss: 0.1800, validation loss: 0.1809
2024-05-25 02:44:44 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch48_loss0.18093832582235336.pypots
2024-05-25 02:44:46 [INFO]: Epoch 049 - training loss: 0.2089, validation loss: 0.1694
2024-05-25 02:44:46 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch49_loss0.16935043409466743.pypots
2024-05-25 02:44:48 [INFO]: Epoch 050 - training loss: 0.1767, validation loss: 0.1691
2024-05-25 02:44:48 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch50_loss0.16911953687667847.pypots
2024-05-25 02:44:50 [INFO]: Epoch 051 - training loss: 0.1877, validation loss: 0.1674
2024-05-25 02:44:50 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch51_loss0.16735342890024185.pypots
2024-05-25 02:44:52 [INFO]: Epoch 052 - training loss: 0.1929, validation loss: 0.1708
2024-05-25 02:44:52 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch52_loss0.17076360806822777.pypots
2024-05-25 02:44:54 [INFO]: Epoch 053 - training loss: 0.2337, validation loss: 0.1627
2024-05-25 02:44:54 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI_epoch53_loss0.16269994527101517.pypots
2024-05-25 02:44:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:44:54 [INFO]: Finished training. The best model is from epoch#43.
2024-05-25 02:44:54 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024304/CSDI.pypots
2024-05-25 02:45:10 [INFO]: CSDI on ETTm1: MAE=0.2918, MSE=1.0286
2024-05-25 02:45:10 [INFO]: Successfully saved to augmentation_saved_results/round_4/CSDI_ettm1/imputation.pkl
2024-05-25 02:45:10 [INFO]: Using the given device: cuda:0
2024-05-25 02:45:10 [INFO]: Model files will be saved to augmentation_saved_results/round_4/GPVAE_ettm1/20240525_T024510
2024-05-25 02:45:10 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/GPVAE_ettm1/20240525_T024510/tensorboard
2024-05-25 02:45:10 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 02:45:10 [INFO]: Epoch 001 - training loss: 24079.8647, validation loss: 0.9870
2024-05-25 02:45:10 [INFO]: Epoch 002 - training loss: 21848.9714, validation loss: 0.9847
2024-05-25 02:45:10 [INFO]: Epoch 003 - training loss: 19788.0773, validation loss: 0.9754
2024-05-25 02:45:10 [INFO]: Epoch 004 - training loss: 17751.9112, validation loss: 0.9477
2024-05-25 02:45:11 [INFO]: Epoch 005 - training loss: 15767.6396, validation loss: 0.8894
2024-05-25 02:45:11 [INFO]: Epoch 006 - training loss: 14101.2553, validation loss: 0.7858
2024-05-25 02:45:11 [INFO]: Epoch 007 - training loss: 12820.7123, validation loss: 0.6763
2024-05-25 02:45:11 [INFO]: Epoch 008 - training loss: 12067.7872, validation loss: 0.6227
2024-05-25 02:45:11 [INFO]: Epoch 009 - training loss: 11465.3801, validation loss: 0.5671
2024-05-25 02:45:11 [INFO]: Epoch 010 - training loss: 10990.0588, validation loss: 0.4958
2024-05-25 02:45:11 [INFO]: Epoch 011 - training loss: 10755.2814, validation loss: 0.4478
2024-05-25 02:45:12 [INFO]: Epoch 012 - training loss: 10538.1158, validation loss: 0.4168
2024-05-25 02:45:12 [INFO]: Epoch 013 - training loss: 10319.3745, validation loss: 0.3998
2024-05-25 02:45:12 [INFO]: Epoch 014 - training loss: 10201.0866, validation loss: 0.3761
2024-05-25 02:45:12 [INFO]: Epoch 015 - training loss: 10099.3660, validation loss: 0.3474
2024-05-25 02:45:12 [INFO]: Epoch 016 - training loss: 9999.5471, validation loss: 0.3178
2024-05-25 02:45:12 [INFO]: Epoch 017 - training loss: 9966.4404, validation loss: 0.3009
2024-05-25 02:45:12 [INFO]: Epoch 018 - training loss: 9859.7836, validation loss: 0.2927
2024-05-25 02:45:12 [INFO]: Epoch 019 - training loss: 9763.7773, validation loss: 0.2789
2024-05-25 02:45:13 [INFO]: Epoch 020 - training loss: 9793.3927, validation loss: 0.2619
2024-05-25 02:45:13 [INFO]: Epoch 021 - training loss: 9680.9149, validation loss: 0.2529
2024-05-25 02:45:13 [INFO]: Epoch 022 - training loss: 9651.1537, validation loss: 0.2399
2024-05-25 02:45:13 [INFO]: Epoch 023 - training loss: 9687.1262, validation loss: 0.2321
2024-05-25 02:45:13 [INFO]: Epoch 024 - training loss: 9584.7545, validation loss: 0.2248
2024-05-25 02:45:13 [INFO]: Epoch 025 - training loss: 9564.9371, validation loss: 0.2190
2024-05-25 02:45:13 [INFO]: Epoch 026 - training loss: 9546.6149, validation loss: 0.2141
2024-05-25 02:45:13 [INFO]: Epoch 027 - training loss: 9532.8627, validation loss: 0.2102
2024-05-25 02:45:14 [INFO]: Epoch 028 - training loss: 9514.8631, validation loss: 0.2064
2024-05-25 02:45:14 [INFO]: Epoch 029 - training loss: 9502.2248, validation loss: 0.1997
2024-05-25 02:45:14 [INFO]: Epoch 030 - training loss: 9512.4698, validation loss: 0.1970
2024-05-25 02:45:14 [INFO]: Epoch 031 - training loss: 9512.5900, validation loss: 0.1940
2024-05-25 02:45:14 [INFO]: Epoch 032 - training loss: 9472.1736, validation loss: 0.1896
2024-05-25 02:45:14 [INFO]: Epoch 033 - training loss: 9465.9445, validation loss: 0.1808
2024-05-25 02:45:14 [INFO]: Epoch 034 - training loss: 9454.7823, validation loss: 0.1774
2024-05-25 02:45:14 [INFO]: Epoch 035 - training loss: 9449.9608, validation loss: 0.1764
2024-05-25 02:45:15 [INFO]: Epoch 036 - training loss: 9440.2460, validation loss: 0.1721
2024-05-25 02:45:15 [INFO]: Epoch 037 - training loss: 9428.3893, validation loss: 0.1689
2024-05-25 02:45:15 [INFO]: Epoch 038 - training loss: 9433.2529, validation loss: 0.1663
2024-05-25 02:45:15 [INFO]: Epoch 039 - training loss: 9419.8165, validation loss: 0.1649
2024-05-25 02:45:15 [INFO]: Epoch 040 - training loss: 9412.8861, validation loss: 0.1623
2024-05-25 02:45:15 [INFO]: Epoch 041 - training loss: 9408.2994, validation loss: 0.1620
2024-05-25 02:45:15 [INFO]: Epoch 042 - training loss: 9408.7695, validation loss: 0.1557
2024-05-25 02:45:15 [INFO]: Epoch 043 - training loss: 9398.8770, validation loss: 0.1528
2024-05-25 02:45:16 [INFO]: Epoch 044 - training loss: 9397.7770, validation loss: 0.1494
2024-05-25 02:45:16 [INFO]: Epoch 045 - training loss: 9393.2250, validation loss: 0.1494
2024-05-25 02:45:16 [INFO]: Epoch 046 - training loss: 9398.8873, validation loss: 0.1460
2024-05-25 02:45:16 [INFO]: Epoch 047 - training loss: 9388.2847, validation loss: 0.1418
2024-05-25 02:45:16 [INFO]: Epoch 048 - training loss: 9387.6855, validation loss: 0.1393
2024-05-25 02:45:16 [INFO]: Epoch 049 - training loss: 9392.4567, validation loss: 0.1385
2024-05-25 02:45:16 [INFO]: Epoch 050 - training loss: 9376.3326, validation loss: 0.1376
2024-05-25 02:45:16 [INFO]: Epoch 051 - training loss: 9373.2890, validation loss: 0.1375
2024-05-25 02:45:17 [INFO]: Epoch 052 - training loss: 9376.3411, validation loss: 0.1351
2024-05-25 02:45:17 [INFO]: Epoch 053 - training loss: 9374.1400, validation loss: 0.1339
2024-05-25 02:45:17 [INFO]: Epoch 054 - training loss: 9369.5695, validation loss: 0.1312
2024-05-25 02:45:17 [INFO]: Epoch 055 - training loss: 9366.8368, validation loss: 0.1324
2024-05-25 02:45:17 [INFO]: Epoch 056 - training loss: 9362.0272, validation loss: 0.1299
2024-05-25 02:45:17 [INFO]: Epoch 057 - training loss: 9360.8831, validation loss: 0.1282
2024-05-25 02:45:17 [INFO]: Epoch 058 - training loss: 9360.2756, validation loss: 0.1278
2024-05-25 02:45:18 [INFO]: Epoch 059 - training loss: 9363.9778, validation loss: 0.1267
2024-05-25 02:45:18 [INFO]: Epoch 060 - training loss: 9360.4456, validation loss: 0.1253
2024-05-25 02:45:18 [INFO]: Epoch 061 - training loss: 9352.8062, validation loss: 0.1249
2024-05-25 02:45:18 [INFO]: Epoch 062 - training loss: 9360.0316, validation loss: 0.1236
2024-05-25 02:45:18 [INFO]: Epoch 063 - training loss: 9357.7537, validation loss: 0.1208
2024-05-25 02:45:18 [INFO]: Epoch 064 - training loss: 9350.0530, validation loss: 0.1207
2024-05-25 02:45:18 [INFO]: Epoch 065 - training loss: 9349.8314, validation loss: 0.1206
2024-05-25 02:45:18 [INFO]: Epoch 066 - training loss: 9349.1052, validation loss: 0.1183
2024-05-25 02:45:19 [INFO]: Epoch 067 - training loss: 9346.0237, validation loss: 0.1187
2024-05-25 02:45:19 [INFO]: Epoch 068 - training loss: 9346.7877, validation loss: 0.1192
2024-05-25 02:45:19 [INFO]: Epoch 069 - training loss: 9346.5830, validation loss: 0.1184
2024-05-25 02:45:19 [INFO]: Epoch 070 - training loss: 9345.5369, validation loss: 0.1163
2024-05-25 02:45:19 [INFO]: Epoch 071 - training loss: 9343.4431, validation loss: 0.1171
2024-05-25 02:45:19 [INFO]: Epoch 072 - training loss: 9341.0192, validation loss: 0.1155
2024-05-25 02:45:19 [INFO]: Epoch 073 - training loss: 9340.5841, validation loss: 0.1149
2024-05-25 02:45:19 [INFO]: Epoch 074 - training loss: 9342.0360, validation loss: 0.1140
2024-05-25 02:45:20 [INFO]: Epoch 075 - training loss: 9342.0861, validation loss: 0.1136
2024-05-25 02:45:20 [INFO]: Epoch 076 - training loss: 9336.9564, validation loss: 0.1116
2024-05-25 02:45:20 [INFO]: Epoch 077 - training loss: 9336.2285, validation loss: 0.1117
2024-05-25 02:45:20 [INFO]: Epoch 078 - training loss: 9336.7822, validation loss: 0.1136
2024-05-25 02:45:20 [INFO]: Epoch 079 - training loss: 9336.2113, validation loss: 0.1132
2024-05-25 02:45:20 [INFO]: Epoch 080 - training loss: 9334.4459, validation loss: 0.1099
2024-05-25 02:45:20 [INFO]: Epoch 081 - training loss: 9336.1001, validation loss: 0.1100
2024-05-25 02:45:20 [INFO]: Epoch 082 - training loss: 9333.9832, validation loss: 0.1068
2024-05-25 02:45:21 [INFO]: Epoch 083 - training loss: 9332.3442, validation loss: 0.1078
2024-05-25 02:45:21 [INFO]: Epoch 084 - training loss: 9333.1118, validation loss: 0.1076
2024-05-25 02:45:21 [INFO]: Epoch 085 - training loss: 9376.6722, validation loss: 0.1069
2024-05-25 02:45:21 [INFO]: Epoch 086 - training loss: 9330.9732, validation loss: 0.1055
2024-05-25 02:45:21 [INFO]: Epoch 087 - training loss: 9330.7619, validation loss: 0.1074
2024-05-25 02:45:21 [INFO]: Epoch 088 - training loss: 9329.4805, validation loss: 0.1064
2024-05-25 02:45:21 [INFO]: Epoch 089 - training loss: 9329.3745, validation loss: 0.1056
2024-05-25 02:45:21 [INFO]: Epoch 090 - training loss: 9327.4073, validation loss: 0.1052
2024-05-25 02:45:22 [INFO]: Epoch 091 - training loss: 9328.7983, validation loss: 0.1047
2024-05-25 02:45:22 [INFO]: Epoch 092 - training loss: 9327.6793, validation loss: 0.1046
2024-05-25 02:45:22 [INFO]: Epoch 093 - training loss: 9328.1639, validation loss: 0.1036
2024-05-25 02:45:22 [INFO]: Epoch 094 - training loss: 9327.4988, validation loss: 0.1022
2024-05-25 02:45:22 [INFO]: Epoch 095 - training loss: 9325.5072, validation loss: 0.1034
2024-05-25 02:45:22 [INFO]: Epoch 096 - training loss: 9326.7634, validation loss: 0.1014
2024-05-25 02:45:22 [INFO]: Epoch 097 - training loss: 9323.7656, validation loss: 0.1022
2024-05-25 02:45:22 [INFO]: Epoch 098 - training loss: 9324.1754, validation loss: 0.1010
2024-05-25 02:45:23 [INFO]: Epoch 099 - training loss: 9324.3346, validation loss: 0.0995
2024-05-25 02:45:23 [INFO]: Epoch 100 - training loss: 9322.0995, validation loss: 0.0996
2024-05-25 02:45:23 [INFO]: Epoch 101 - training loss: 9322.3397, validation loss: 0.0997
2024-05-25 02:45:23 [INFO]: Epoch 102 - training loss: 9322.7715, validation loss: 0.0988
2024-05-25 02:45:23 [INFO]: Epoch 103 - training loss: 9321.7296, validation loss: 0.1004
2024-05-25 02:45:23 [INFO]: Epoch 104 - training loss: 9322.3402, validation loss: 0.0982
2024-05-25 02:45:23 [INFO]: Epoch 105 - training loss: 9321.1465, validation loss: 0.0986
2024-05-25 02:45:24 [INFO]: Epoch 106 - training loss: 9321.1712, validation loss: 0.0966
2024-05-25 02:45:24 [INFO]: Epoch 107 - training loss: 9320.1774, validation loss: 0.0967
2024-05-25 02:45:24 [INFO]: Epoch 108 - training loss: 9321.2726, validation loss: 0.0962
2024-05-25 02:45:24 [INFO]: Epoch 109 - training loss: 9320.8905, validation loss: 0.0953
2024-05-25 02:45:24 [INFO]: Epoch 110 - training loss: 9318.3694, validation loss: 0.0951
2024-05-25 02:45:24 [INFO]: Epoch 111 - training loss: 9320.9418, validation loss: 0.0951
2024-05-25 02:45:24 [INFO]: Epoch 112 - training loss: 9317.2977, validation loss: 0.0953
2024-05-25 02:45:24 [INFO]: Epoch 113 - training loss: 9318.8957, validation loss: 0.0948
2024-05-25 02:45:25 [INFO]: Epoch 114 - training loss: 9319.3849, validation loss: 0.0923
2024-05-25 02:45:25 [INFO]: Epoch 115 - training loss: 9322.0336, validation loss: 0.0930
2024-05-25 02:45:25 [INFO]: Epoch 116 - training loss: 9318.4019, validation loss: 0.0927
2024-05-25 02:45:25 [INFO]: Epoch 117 - training loss: 9316.3238, validation loss: 0.0909
2024-05-25 02:45:25 [INFO]: Epoch 118 - training loss: 9317.2155, validation loss: 0.0921
2024-05-25 02:45:25 [INFO]: Epoch 119 - training loss: 9316.4168, validation loss: 0.0911
2024-05-25 02:45:25 [INFO]: Epoch 120 - training loss: 9318.5295, validation loss: 0.0910
2024-05-25 02:45:25 [INFO]: Epoch 121 - training loss: 9316.4542, validation loss: 0.0890
2024-05-25 02:45:26 [INFO]: Epoch 122 - training loss: 9335.4682, validation loss: 0.0905
2024-05-25 02:45:26 [INFO]: Epoch 123 - training loss: 9315.8986, validation loss: 0.0899
2024-05-25 02:45:26 [INFO]: Epoch 124 - training loss: 9315.7021, validation loss: 0.0892
2024-05-25 02:45:26 [INFO]: Epoch 125 - training loss: 9314.1583, validation loss: 0.0885
2024-05-25 02:45:26 [INFO]: Epoch 126 - training loss: 9313.8015, validation loss: 0.0883
2024-05-25 02:45:26 [INFO]: Epoch 127 - training loss: 9314.9311, validation loss: 0.0892
2024-05-25 02:45:26 [INFO]: Epoch 128 - training loss: 9315.4943, validation loss: 0.0877
2024-05-25 02:45:26 [INFO]: Epoch 129 - training loss: 9314.7506, validation loss: 0.0874
2024-05-25 02:45:27 [INFO]: Epoch 130 - training loss: 9313.9220, validation loss: 0.0888
2024-05-25 02:45:27 [INFO]: Epoch 131 - training loss: 9313.5379, validation loss: 0.0885
2024-05-25 02:45:27 [INFO]: Epoch 132 - training loss: 9313.1357, validation loss: 0.0871
2024-05-25 02:45:27 [INFO]: Epoch 133 - training loss: 9313.7480, validation loss: 0.0868
2024-05-25 02:45:27 [INFO]: Epoch 134 - training loss: 9312.3140, validation loss: 0.0867
2024-05-25 02:45:27 [INFO]: Epoch 135 - training loss: 9312.7155, validation loss: 0.0851
2024-05-25 02:45:27 [INFO]: Epoch 136 - training loss: 9313.0535, validation loss: 0.0853
2024-05-25 02:45:27 [INFO]: Epoch 137 - training loss: 9312.5289, validation loss: 0.0863
2024-05-25 02:45:28 [INFO]: Epoch 138 - training loss: 9311.1967, validation loss: 0.0840
2024-05-25 02:45:28 [INFO]: Epoch 139 - training loss: 9312.8488, validation loss: 0.0843
2024-05-25 02:45:28 [INFO]: Epoch 140 - training loss: 9314.4958, validation loss: 0.0836
2024-05-25 02:45:28 [INFO]: Epoch 141 - training loss: 9311.8548, validation loss: 0.0831
2024-05-25 02:45:28 [INFO]: Epoch 142 - training loss: 9310.9639, validation loss: 0.0829
2024-05-25 02:45:28 [INFO]: Epoch 143 - training loss: 9310.3830, validation loss: 0.0815
2024-05-25 02:45:28 [INFO]: Epoch 144 - training loss: 9311.1205, validation loss: 0.0833
2024-05-25 02:45:28 [INFO]: Epoch 145 - training loss: 9311.0825, validation loss: 0.0818
2024-05-25 02:45:29 [INFO]: Epoch 146 - training loss: 9309.5870, validation loss: 0.0821
2024-05-25 02:45:29 [INFO]: Epoch 147 - training loss: 9309.8234, validation loss: 0.0821
2024-05-25 02:45:29 [INFO]: Epoch 148 - training loss: 9309.3621, validation loss: 0.0815
2024-05-25 02:45:29 [INFO]: Epoch 149 - training loss: 9311.3294, validation loss: 0.0810
2024-05-25 02:45:29 [INFO]: Epoch 150 - training loss: 9309.1444, validation loss: 0.0817
2024-05-25 02:45:29 [INFO]: Epoch 151 - training loss: 9310.2906, validation loss: 0.0813
2024-05-25 02:45:29 [INFO]: Epoch 152 - training loss: 9310.7101, validation loss: 0.0811
2024-05-25 02:45:30 [INFO]: Epoch 153 - training loss: 9309.2098, validation loss: 0.0809
2024-05-25 02:45:30 [INFO]: Epoch 154 - training loss: 9308.9882, validation loss: 0.0822
2024-05-25 02:45:30 [INFO]: Epoch 155 - training loss: 9309.2159, validation loss: 0.0807
2024-05-25 02:45:30 [INFO]: Epoch 156 - training loss: 9308.8672, validation loss: 0.0792
2024-05-25 02:45:30 [INFO]: Epoch 157 - training loss: 9308.1693, validation loss: 0.0797
2024-05-25 02:45:30 [INFO]: Epoch 158 - training loss: 9310.6328, validation loss: 0.0794
2024-05-25 02:45:30 [INFO]: Epoch 159 - training loss: 9307.7546, validation loss: 0.0788
2024-05-25 02:45:30 [INFO]: Epoch 160 - training loss: 9308.3516, validation loss: 0.0784
2024-05-25 02:45:31 [INFO]: Epoch 161 - training loss: 9309.1908, validation loss: 0.0779
2024-05-25 02:45:31 [INFO]: Epoch 162 - training loss: 9307.4197, validation loss: 0.0792
2024-05-25 02:45:31 [INFO]: Epoch 163 - training loss: 9308.1941, validation loss: 0.0777
2024-05-25 02:45:31 [INFO]: Epoch 164 - training loss: 9309.5756, validation loss: 0.0800
2024-05-25 02:45:31 [INFO]: Epoch 165 - training loss: 9308.2104, validation loss: 0.0794
2024-05-25 02:45:31 [INFO]: Epoch 166 - training loss: 9308.0135, validation loss: 0.0783
2024-05-25 02:45:31 [INFO]: Epoch 167 - training loss: 9306.8751, validation loss: 0.0786
2024-05-25 02:45:31 [INFO]: Epoch 168 - training loss: 9310.0918, validation loss: 0.0778
2024-05-25 02:45:32 [INFO]: Epoch 169 - training loss: 9309.1429, validation loss: 0.0828
2024-05-25 02:45:32 [INFO]: Epoch 170 - training loss: 9307.5355, validation loss: 0.0789
2024-05-25 02:45:32 [INFO]: Epoch 171 - training loss: 9306.8601, validation loss: 0.0785
2024-05-25 02:45:32 [INFO]: Epoch 172 - training loss: 9308.6601, validation loss: 0.0780
2024-05-25 02:45:32 [INFO]: Epoch 173 - training loss: 9305.8340, validation loss: 0.0754
2024-05-25 02:45:32 [INFO]: Epoch 174 - training loss: 9307.4951, validation loss: 0.0765
2024-05-25 02:45:32 [INFO]: Epoch 175 - training loss: 9307.3823, validation loss: 0.0777
2024-05-25 02:45:32 [INFO]: Epoch 176 - training loss: 9306.9384, validation loss: 0.0770
2024-05-25 02:45:33 [INFO]: Epoch 177 - training loss: 9306.4797, validation loss: 0.0775
2024-05-25 02:45:33 [INFO]: Epoch 178 - training loss: 9305.3049, validation loss: 0.0769
2024-05-25 02:45:33 [INFO]: Epoch 179 - training loss: 9307.2952, validation loss: 0.0769
2024-05-25 02:45:33 [INFO]: Epoch 180 - training loss: 9306.6391, validation loss: 0.0751
2024-05-25 02:45:33 [INFO]: Epoch 181 - training loss: 9307.3362, validation loss: 0.0751
2024-05-25 02:45:33 [INFO]: Epoch 182 - training loss: 9306.6375, validation loss: 0.0772
2024-05-25 02:45:33 [INFO]: Epoch 183 - training loss: 9305.7723, validation loss: 0.0746
2024-05-25 02:45:33 [INFO]: Epoch 184 - training loss: 9305.2208, validation loss: 0.0750
2024-05-25 02:45:34 [INFO]: Epoch 185 - training loss: 9307.3291, validation loss: 0.0768
2024-05-25 02:45:34 [INFO]: Epoch 186 - training loss: 9305.8409, validation loss: 0.0762
2024-05-25 02:45:34 [INFO]: Epoch 187 - training loss: 9305.2319, validation loss: 0.0741
2024-05-25 02:45:34 [INFO]: Epoch 188 - training loss: 9305.6511, validation loss: 0.0756
2024-05-25 02:45:34 [INFO]: Epoch 189 - training loss: 9305.3568, validation loss: 0.0742
2024-05-25 02:45:34 [INFO]: Epoch 190 - training loss: 9306.2435, validation loss: 0.0736
2024-05-25 02:45:34 [INFO]: Epoch 191 - training loss: 9306.5992, validation loss: 0.0744
2024-05-25 02:45:34 [INFO]: Epoch 192 - training loss: 9304.6650, validation loss: 0.0743
2024-05-25 02:45:35 [INFO]: Epoch 193 - training loss: 9306.3458, validation loss: 0.0738
2024-05-25 02:45:35 [INFO]: Epoch 194 - training loss: 9306.4282, validation loss: 0.0726
2024-05-25 02:45:35 [INFO]: Epoch 195 - training loss: 9305.0659, validation loss: 0.0719
2024-05-25 02:45:35 [INFO]: Epoch 196 - training loss: 9306.7445, validation loss: 0.0727
2024-05-25 02:45:35 [INFO]: Epoch 197 - training loss: 9304.6431, validation loss: 0.0727
2024-05-25 02:45:35 [INFO]: Epoch 198 - training loss: 9305.6071, validation loss: 0.0724
2024-05-25 02:45:35 [INFO]: Epoch 199 - training loss: 9305.3807, validation loss: 0.0716
2024-05-25 02:45:36 [INFO]: Epoch 200 - training loss: 9304.0094, validation loss: 0.0728
2024-05-25 02:45:36 [INFO]: Epoch 201 - training loss: 9304.5421, validation loss: 0.0741
2024-05-25 02:45:36 [INFO]: Epoch 202 - training loss: 9306.1520, validation loss: 0.0730
2024-05-25 02:45:36 [INFO]: Epoch 203 - training loss: 9304.0789, validation loss: 0.0732
2024-05-25 02:45:36 [INFO]: Epoch 204 - training loss: 9305.0115, validation loss: 0.0723
2024-05-25 02:45:36 [INFO]: Epoch 205 - training loss: 9304.2195, validation loss: 0.0726
2024-05-25 02:45:36 [INFO]: Epoch 206 - training loss: 9304.7546, validation loss: 0.0731
2024-05-25 02:45:36 [INFO]: Epoch 207 - training loss: 9305.7896, validation loss: 0.0725
2024-05-25 02:45:37 [INFO]: Epoch 208 - training loss: 9304.1195, validation loss: 0.0731
2024-05-25 02:45:37 [INFO]: Epoch 209 - training loss: 9302.9016, validation loss: 0.0732
2024-05-25 02:45:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:45:37 [INFO]: Finished training. The best model is from epoch#199.
2024-05-25 02:45:37 [INFO]: Saved the model to augmentation_saved_results/round_4/GPVAE_ettm1/20240525_T024510/GPVAE.pypots
2024-05-25 02:45:37 [INFO]: GP-VAE on ETTm1: MAE=0.2645, MSE=0.1531
2024-05-25 02:45:37 [INFO]: Successfully saved to augmentation_saved_results/round_4/GPVAE_ettm1/imputation.pkl
2024-05-25 02:45:37 [INFO]: Using the given device: cuda:0
2024-05-25 02:45:37 [INFO]: Model files will be saved to augmentation_saved_results/round_4/USGAN_ettm1/20240525_T024537
2024-05-25 02:45:37 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/USGAN_ettm1/20240525_T024537/tensorboard
2024-05-25 02:45:37 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 02:45:47 [INFO]: Epoch 001 - generator training loss: 0.6090, discriminator training loss: 0.3255, validation loss: 0.3146
2024-05-25 02:45:56 [INFO]: Epoch 002 - generator training loss: 0.0556, discriminator training loss: 0.2101, validation loss: 0.0973
2024-05-25 02:46:06 [INFO]: Epoch 003 - generator training loss: -0.0585, discriminator training loss: 0.1990, validation loss: 0.0567
2024-05-25 02:46:15 [INFO]: Epoch 004 - generator training loss: -0.0789, discriminator training loss: 0.1950, validation loss: 0.0459
2024-05-25 02:46:24 [INFO]: Epoch 005 - generator training loss: -0.0813, discriminator training loss: 0.1903, validation loss: 0.0406
2024-05-25 02:46:32 [INFO]: Epoch 006 - generator training loss: -0.0838, discriminator training loss: 0.1877, validation loss: 0.0381
2024-05-25 02:46:41 [INFO]: Epoch 007 - generator training loss: -0.0814, discriminator training loss: 0.1831, validation loss: 0.0366
2024-05-25 02:46:50 [INFO]: Epoch 008 - generator training loss: -0.0718, discriminator training loss: 0.1709, validation loss: 0.0360
2024-05-25 02:46:59 [INFO]: Epoch 009 - generator training loss: -0.0609, discriminator training loss: 0.1586, validation loss: 0.0352
2024-05-25 02:47:08 [INFO]: Epoch 010 - generator training loss: -0.0459, discriminator training loss: 0.1427, validation loss: 0.0348
2024-05-25 02:47:17 [INFO]: Epoch 011 - generator training loss: -0.0354, discriminator training loss: 0.1278, validation loss: 0.0345
2024-05-25 02:47:26 [INFO]: Epoch 012 - generator training loss: -0.0273, discriminator training loss: 0.1130, validation loss: 0.0354
2024-05-25 02:47:35 [INFO]: Epoch 013 - generator training loss: -0.0183, discriminator training loss: 0.1042, validation loss: 0.0336
2024-05-25 02:47:44 [INFO]: Epoch 014 - generator training loss: -0.0148, discriminator training loss: 0.0964, validation loss: 0.0331
2024-05-25 02:47:53 [INFO]: Epoch 015 - generator training loss: -0.0102, discriminator training loss: 0.0922, validation loss: 0.0327
2024-05-25 02:48:02 [INFO]: Epoch 016 - generator training loss: -0.0115, discriminator training loss: 0.0862, validation loss: 0.0329
2024-05-25 02:48:11 [INFO]: Epoch 017 - generator training loss: -0.0115, discriminator training loss: 0.0839, validation loss: 0.0323
2024-05-25 02:48:20 [INFO]: Epoch 018 - generator training loss: -0.0099, discriminator training loss: 0.0820, validation loss: 0.0325
2024-05-25 02:48:29 [INFO]: Epoch 019 - generator training loss: -0.0105, discriminator training loss: 0.0824, validation loss: 0.0323
2024-05-25 02:48:38 [INFO]: Epoch 020 - generator training loss: -0.0117, discriminator training loss: 0.0791, validation loss: 0.0318
2024-05-25 02:48:46 [INFO]: Epoch 021 - generator training loss: -0.0094, discriminator training loss: 0.0810, validation loss: 0.0318
2024-05-25 02:48:55 [INFO]: Epoch 022 - generator training loss: -0.0111, discriminator training loss: 0.0784, validation loss: 0.0311
2024-05-25 02:49:04 [INFO]: Epoch 023 - generator training loss: -0.0099, discriminator training loss: 0.0780, validation loss: 0.0312
2024-05-25 02:49:13 [INFO]: Epoch 024 - generator training loss: -0.0090, discriminator training loss: 0.0773, validation loss: 0.0306
2024-05-25 02:49:22 [INFO]: Epoch 025 - generator training loss: -0.0098, discriminator training loss: 0.0787, validation loss: 0.0310
2024-05-25 02:49:31 [INFO]: Epoch 026 - generator training loss: -0.0120, discriminator training loss: 0.0761, validation loss: 0.0306
2024-05-25 02:49:40 [INFO]: Epoch 027 - generator training loss: -0.0101, discriminator training loss: 0.0742, validation loss: 0.0305
2024-05-25 02:49:49 [INFO]: Epoch 028 - generator training loss: -0.0099, discriminator training loss: 0.0735, validation loss: 0.0307
2024-05-25 02:49:58 [INFO]: Epoch 029 - generator training loss: -0.0082, discriminator training loss: 0.0747, validation loss: 0.0309
2024-05-25 02:50:06 [INFO]: Epoch 030 - generator training loss: -0.0109, discriminator training loss: 0.0741, validation loss: 0.0297
2024-05-25 02:50:15 [INFO]: Epoch 031 - generator training loss: -0.0121, discriminator training loss: 0.0720, validation loss: 0.0313
2024-05-25 02:50:25 [INFO]: Epoch 032 - generator training loss: -0.0108, discriminator training loss: 0.0724, validation loss: 0.0302
2024-05-25 02:50:34 [INFO]: Epoch 033 - generator training loss: -0.0113, discriminator training loss: 0.0720, validation loss: 0.0291
2024-05-25 02:50:43 [INFO]: Epoch 034 - generator training loss: -0.0115, discriminator training loss: 0.0751, validation loss: 0.0290
2024-05-25 02:50:52 [INFO]: Epoch 035 - generator training loss: -0.0137, discriminator training loss: 0.0724, validation loss: 0.0284
2024-05-25 02:51:01 [INFO]: Epoch 036 - generator training loss: -0.0126, discriminator training loss: 0.0714, validation loss: 0.0285
2024-05-25 02:51:10 [INFO]: Epoch 037 - generator training loss: -0.0129, discriminator training loss: 0.0717, validation loss: 0.0283
2024-05-25 02:51:19 [INFO]: Epoch 038 - generator training loss: -0.0128, discriminator training loss: 0.0716, validation loss: 0.0277
2024-05-25 02:51:28 [INFO]: Epoch 039 - generator training loss: -0.0142, discriminator training loss: 0.0716, validation loss: 0.0273
2024-05-25 02:51:37 [INFO]: Epoch 040 - generator training loss: -0.0141, discriminator training loss: 0.0706, validation loss: 0.0269
2024-05-25 02:51:47 [INFO]: Epoch 041 - generator training loss: -0.0130, discriminator training loss: 0.0703, validation loss: 0.0268
2024-05-25 02:51:56 [INFO]: Epoch 042 - generator training loss: -0.0143, discriminator training loss: 0.0700, validation loss: 0.0267
2024-05-25 02:52:05 [INFO]: Epoch 043 - generator training loss: -0.0148, discriminator training loss: 0.0713, validation loss: 0.0265
2024-05-25 02:52:14 [INFO]: Epoch 044 - generator training loss: -0.0154, discriminator training loss: 0.0715, validation loss: 0.0262
2024-05-25 02:52:23 [INFO]: Epoch 045 - generator training loss: -0.0144, discriminator training loss: 0.0720, validation loss: 0.0261
2024-05-25 02:52:32 [INFO]: Epoch 046 - generator training loss: -0.0165, discriminator training loss: 0.0713, validation loss: 0.0249
2024-05-25 02:52:41 [INFO]: Epoch 047 - generator training loss: -0.0171, discriminator training loss: 0.0701, validation loss: 0.0251
2024-05-25 02:52:50 [INFO]: Epoch 048 - generator training loss: -0.0186, discriminator training loss: 0.0711, validation loss: 0.0249
2024-05-25 02:52:59 [INFO]: Epoch 049 - generator training loss: -0.0157, discriminator training loss: 0.0703, validation loss: 0.0241
2024-05-25 02:53:08 [INFO]: Epoch 050 - generator training loss: -0.0195, discriminator training loss: 0.0690, validation loss: 0.0237
2024-05-25 02:53:17 [INFO]: Epoch 051 - generator training loss: -0.0181, discriminator training loss: 0.0696, validation loss: 0.0253
2024-05-25 02:53:26 [INFO]: Epoch 052 - generator training loss: -0.0169, discriminator training loss: 0.0699, validation loss: 0.0246
2024-05-25 02:53:35 [INFO]: Epoch 053 - generator training loss: -0.0167, discriminator training loss: 0.0686, validation loss: 0.0232
2024-05-25 02:53:45 [INFO]: Epoch 054 - generator training loss: -0.0175, discriminator training loss: 0.0680, validation loss: 0.0221
2024-05-25 02:53:54 [INFO]: Epoch 055 - generator training loss: -0.0172, discriminator training loss: 0.0690, validation loss: 0.0223
2024-05-25 02:54:03 [INFO]: Epoch 056 - generator training loss: -0.0187, discriminator training loss: 0.0674, validation loss: 0.0221
2024-05-25 02:54:12 [INFO]: Epoch 057 - generator training loss: -0.0228, discriminator training loss: 0.0701, validation loss: 0.0217
2024-05-25 02:54:21 [INFO]: Epoch 058 - generator training loss: -0.0202, discriminator training loss: 0.0688, validation loss: 0.0222
2024-05-25 02:54:30 [INFO]: Epoch 059 - generator training loss: -0.0190, discriminator training loss: 0.0689, validation loss: 0.0216
2024-05-25 02:54:39 [INFO]: Epoch 060 - generator training loss: -0.0205, discriminator training loss: 0.0687, validation loss: 0.0213
2024-05-25 02:54:48 [INFO]: Epoch 061 - generator training loss: -0.0219, discriminator training loss: 0.0682, validation loss: 0.0217
2024-05-25 02:54:57 [INFO]: Epoch 062 - generator training loss: -0.0210, discriminator training loss: 0.0691, validation loss: 0.0214
2024-05-25 02:55:06 [INFO]: Epoch 063 - generator training loss: -0.0206, discriminator training loss: 0.0676, validation loss: 0.0213
2024-05-25 02:55:15 [INFO]: Epoch 064 - generator training loss: -0.0207, discriminator training loss: 0.0689, validation loss: 0.0210
2024-05-25 02:55:24 [INFO]: Epoch 065 - generator training loss: -0.0177, discriminator training loss: 0.0697, validation loss: 0.0214
2024-05-25 02:55:33 [INFO]: Epoch 066 - generator training loss: -0.0158, discriminator training loss: 0.0686, validation loss: 0.0237
2024-05-25 02:55:43 [INFO]: Epoch 067 - generator training loss: -0.0175, discriminator training loss: 0.0681, validation loss: 0.0214
2024-05-25 02:55:52 [INFO]: Epoch 068 - generator training loss: -0.0195, discriminator training loss: 0.0692, validation loss: 0.0210
2024-05-25 02:56:01 [INFO]: Epoch 069 - generator training loss: -0.0211, discriminator training loss: 0.0702, validation loss: 0.0207
2024-05-25 02:56:10 [INFO]: Epoch 070 - generator training loss: -0.0201, discriminator training loss: 0.0681, validation loss: 0.0206
2024-05-25 02:56:19 [INFO]: Epoch 071 - generator training loss: -0.0209, discriminator training loss: 0.0668, validation loss: 0.0205
2024-05-25 02:56:28 [INFO]: Epoch 072 - generator training loss: -0.0195, discriminator training loss: 0.0669, validation loss: 0.0204
2024-05-25 02:56:37 [INFO]: Epoch 073 - generator training loss: -0.0217, discriminator training loss: 0.0679, validation loss: 0.0208
2024-05-25 02:56:46 [INFO]: Epoch 074 - generator training loss: -0.0203, discriminator training loss: 0.0680, validation loss: 0.0204
2024-05-25 02:56:55 [INFO]: Epoch 075 - generator training loss: -0.0210, discriminator training loss: 0.0681, validation loss: 0.0200
2024-05-25 02:57:04 [INFO]: Epoch 076 - generator training loss: -0.0213, discriminator training loss: 0.0697, validation loss: 0.0200
2024-05-25 02:57:13 [INFO]: Epoch 077 - generator training loss: -0.0215, discriminator training loss: 0.0668, validation loss: 0.0208
2024-05-25 02:57:22 [INFO]: Epoch 078 - generator training loss: -0.0217, discriminator training loss: 0.0678, validation loss: 0.0202
2024-05-25 02:57:31 [INFO]: Epoch 079 - generator training loss: -0.0200, discriminator training loss: 0.0675, validation loss: 0.0205
2024-05-25 02:57:40 [INFO]: Epoch 080 - generator training loss: -0.0206, discriminator training loss: 0.0668, validation loss: 0.0202
2024-05-25 02:57:49 [INFO]: Epoch 081 - generator training loss: -0.0219, discriminator training loss: 0.0679, validation loss: 0.0198
2024-05-25 02:57:59 [INFO]: Epoch 082 - generator training loss: -0.0214, discriminator training loss: 0.0670, validation loss: 0.0212
2024-05-25 02:58:08 [INFO]: Epoch 083 - generator training loss: -0.0208, discriminator training loss: 0.0679, validation loss: 0.0204
2024-05-25 02:58:17 [INFO]: Epoch 084 - generator training loss: -0.0206, discriminator training loss: 0.0678, validation loss: 0.0205
2024-05-25 02:58:26 [INFO]: Epoch 085 - generator training loss: -0.0218, discriminator training loss: 0.0669, validation loss: 0.0207
2024-05-25 02:58:35 [INFO]: Epoch 086 - generator training loss: -0.0191, discriminator training loss: 0.0681, validation loss: 0.0211
2024-05-25 02:58:44 [INFO]: Epoch 087 - generator training loss: -0.0217, discriminator training loss: 0.0687, validation loss: 0.0198
2024-05-25 02:58:53 [INFO]: Epoch 088 - generator training loss: -0.0210, discriminator training loss: 0.0655, validation loss: 0.0199
2024-05-25 02:59:02 [INFO]: Epoch 089 - generator training loss: -0.0218, discriminator training loss: 0.0666, validation loss: 0.0196
2024-05-25 02:59:11 [INFO]: Epoch 090 - generator training loss: -0.0205, discriminator training loss: 0.0676, validation loss: 0.0196
2024-05-25 02:59:20 [INFO]: Epoch 091 - generator training loss: -0.0228, discriminator training loss: 0.0675, validation loss: 0.0195
2024-05-25 02:59:29 [INFO]: Epoch 092 - generator training loss: -0.0205, discriminator training loss: 0.0673, validation loss: 0.0199
2024-05-25 02:59:38 [INFO]: Epoch 093 - generator training loss: -0.0224, discriminator training loss: 0.0649, validation loss: 0.0194
2024-05-25 02:59:47 [INFO]: Epoch 094 - generator training loss: -0.0241, discriminator training loss: 0.0668, validation loss: 0.0200
2024-05-25 02:59:56 [INFO]: Epoch 095 - generator training loss: -0.0216, discriminator training loss: 0.0670, validation loss: 0.0196
2024-05-25 03:00:06 [INFO]: Epoch 096 - generator training loss: -0.0234, discriminator training loss: 0.0667, validation loss: 0.0190
2024-05-25 03:00:15 [INFO]: Epoch 097 - generator training loss: -0.0243, discriminator training loss: 0.0646, validation loss: 0.0194
2024-05-25 03:00:24 [INFO]: Epoch 098 - generator training loss: -0.0249, discriminator training loss: 0.0664, validation loss: 0.0191
2024-05-25 03:00:33 [INFO]: Epoch 099 - generator training loss: -0.0213, discriminator training loss: 0.0658, validation loss: 0.0187
2024-05-25 03:00:42 [INFO]: Epoch 100 - generator training loss: -0.0221, discriminator training loss: 0.0666, validation loss: 0.0198
2024-05-25 03:00:51 [INFO]: Epoch 101 - generator training loss: -0.0235, discriminator training loss: 0.0641, validation loss: 0.0197
2024-05-25 03:01:00 [INFO]: Epoch 102 - generator training loss: -0.0219, discriminator training loss: 0.0655, validation loss: 0.0191
2024-05-25 03:01:09 [INFO]: Epoch 103 - generator training loss: -0.0220, discriminator training loss: 0.0672, validation loss: 0.0196
2024-05-25 03:01:18 [INFO]: Epoch 104 - generator training loss: -0.0225, discriminator training loss: 0.0660, validation loss: 0.0199
2024-05-25 03:01:27 [INFO]: Epoch 105 - generator training loss: -0.0251, discriminator training loss: 0.0656, validation loss: 0.0199
2024-05-25 03:01:36 [INFO]: Epoch 106 - generator training loss: -0.0214, discriminator training loss: 0.0659, validation loss: 0.0192
2024-05-25 03:01:45 [INFO]: Epoch 107 - generator training loss: -0.0225, discriminator training loss: 0.0649, validation loss: 0.0193
2024-05-25 03:01:54 [INFO]: Epoch 108 - generator training loss: -0.0227, discriminator training loss: 0.0644, validation loss: 0.0193
2024-05-25 03:02:03 [INFO]: Epoch 109 - generator training loss: -0.0238, discriminator training loss: 0.0651, validation loss: 0.0191
2024-05-25 03:02:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:02:03 [INFO]: Finished training. The best model is from epoch#99.
2024-05-25 03:02:03 [INFO]: Saved the model to augmentation_saved_results/round_4/USGAN_ettm1/20240525_T024537/USGAN.pypots
2024-05-25 03:02:04 [INFO]: US-GAN on ETTm1: MAE=0.1405, MSE=0.0521
2024-05-25 03:02:04 [INFO]: Successfully saved to augmentation_saved_results/round_4/USGAN_ettm1/imputation.pkl
2024-05-25 03:02:04 [INFO]: Using the given device: cuda:0
2024-05-25 03:02:04 [INFO]: Model files will be saved to augmentation_saved_results/round_4/BRITS_ettm1/20240525_T030204
2024-05-25 03:02:04 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/BRITS_ettm1/20240525_T030204/tensorboard
2024-05-25 03:02:04 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 03:02:12 [INFO]: Epoch 001 - training loss: 1.2621, validation loss: 0.2827
2024-05-25 03:02:18 [INFO]: Epoch 002 - training loss: 0.8372, validation loss: 0.0745
2024-05-25 03:02:24 [INFO]: Epoch 003 - training loss: 0.6842, validation loss: 0.0471
2024-05-25 03:02:30 [INFO]: Epoch 004 - training loss: 0.5978, validation loss: 0.0412
2024-05-25 03:02:36 [INFO]: Epoch 005 - training loss: 0.6011, validation loss: 0.0406
2024-05-25 03:02:42 [INFO]: Epoch 006 - training loss: 0.5572, validation loss: 0.0384
2024-05-25 03:02:48 [INFO]: Epoch 007 - training loss: 0.5219, validation loss: 0.0366
2024-05-25 03:02:54 [INFO]: Epoch 008 - training loss: 0.4926, validation loss: 0.0339
2024-05-25 03:03:01 [INFO]: Epoch 009 - training loss: 0.4636, validation loss: 0.0300
2024-05-25 03:03:07 [INFO]: Epoch 010 - training loss: 0.4365, validation loss: 0.0275
2024-05-25 03:03:13 [INFO]: Epoch 011 - training loss: 0.4219, validation loss: 0.0271
2024-05-25 03:03:19 [INFO]: Epoch 012 - training loss: 0.4241, validation loss: 0.0257
2024-05-25 03:03:25 [INFO]: Epoch 013 - training loss: 0.4026, validation loss: 0.0253
2024-05-25 03:03:31 [INFO]: Epoch 014 - training loss: 0.3940, validation loss: 0.0244
2024-05-25 03:03:37 [INFO]: Epoch 015 - training loss: 0.3923, validation loss: 0.0232
2024-05-25 03:03:43 [INFO]: Epoch 016 - training loss: 0.3983, validation loss: 0.0232
2024-05-25 03:03:49 [INFO]: Epoch 017 - training loss: 0.3864, validation loss: 0.0229
2024-05-25 03:03:55 [INFO]: Epoch 018 - training loss: 0.3908, validation loss: 0.0225
2024-05-25 03:04:01 [INFO]: Epoch 019 - training loss: 0.3860, validation loss: 0.0225
2024-05-25 03:04:07 [INFO]: Epoch 020 - training loss: 0.3939, validation loss: 0.0227
2024-05-25 03:04:13 [INFO]: Epoch 021 - training loss: 0.3961, validation loss: 0.0224
2024-05-25 03:04:19 [INFO]: Epoch 022 - training loss: 0.3800, validation loss: 0.0227
2024-05-25 03:04:25 [INFO]: Epoch 023 - training loss: 0.3859, validation loss: 0.0220
2024-05-25 03:04:31 [INFO]: Epoch 024 - training loss: 0.3839, validation loss: 0.0224
2024-05-25 03:04:37 [INFO]: Epoch 025 - training loss: 0.3803, validation loss: 0.0224
2024-05-25 03:04:43 [INFO]: Epoch 026 - training loss: 0.3801, validation loss: 0.0221
2024-05-25 03:04:49 [INFO]: Epoch 027 - training loss: 0.3777, validation loss: 0.0226
2024-05-25 03:04:55 [INFO]: Epoch 028 - training loss: 0.3750, validation loss: 0.0224
2024-05-25 03:05:01 [INFO]: Epoch 029 - training loss: 0.3854, validation loss: 0.0219
2024-05-25 03:05:07 [INFO]: Epoch 030 - training loss: 0.3789, validation loss: 0.0228
2024-05-25 03:05:13 [INFO]: Epoch 031 - training loss: 0.3821, validation loss: 0.0220
2024-05-25 03:05:19 [INFO]: Epoch 032 - training loss: 0.3935, validation loss: 0.0225
2024-05-25 03:05:25 [INFO]: Epoch 033 - training loss: 0.3808, validation loss: 0.0224
2024-05-25 03:05:31 [INFO]: Epoch 034 - training loss: 0.3816, validation loss: 0.0223
2024-05-25 03:05:37 [INFO]: Epoch 035 - training loss: 0.3902, validation loss: 0.0229
2024-05-25 03:05:43 [INFO]: Epoch 036 - training loss: 0.3789, validation loss: 0.0226
2024-05-25 03:05:49 [INFO]: Epoch 037 - training loss: 0.3878, validation loss: 0.0221
2024-05-25 03:05:55 [INFO]: Epoch 038 - training loss: 0.3778, validation loss: 0.0223
2024-05-25 03:06:01 [INFO]: Epoch 039 - training loss: 0.3731, validation loss: 0.0221
2024-05-25 03:06:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:06:01 [INFO]: Finished training. The best model is from epoch#29.
2024-05-25 03:06:01 [INFO]: Saved the model to augmentation_saved_results/round_4/BRITS_ettm1/20240525_T030204/BRITS.pypots
2024-05-25 03:06:02 [INFO]: BRITS on ETTm1: MAE=0.1241, MSE=0.0455
2024-05-25 03:06:02 [INFO]: Successfully saved to augmentation_saved_results/round_4/BRITS_ettm1/imputation.pkl
2024-05-25 03:06:02 [INFO]: Using the given device: cuda:0
2024-05-25 03:06:02 [INFO]: Model files will be saved to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602
2024-05-25 03:06:02 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/tensorboard
2024-05-25 03:06:02 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 03:06:04 [INFO]: Epoch 001 - training loss: 1.5425, validation loss: 1.2947
2024-05-25 03:06:04 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch1_loss1.2947072982788086.pypots
2024-05-25 03:06:04 [INFO]: Epoch 002 - training loss: 1.1166, validation loss: 1.1671
2024-05-25 03:06:04 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch2_loss1.1670550554990768.pypots
2024-05-25 03:06:05 [INFO]: Epoch 003 - training loss: 0.9924, validation loss: 1.0992
2024-05-25 03:06:05 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch3_loss1.0992486476898193.pypots
2024-05-25 03:06:05 [INFO]: Epoch 004 - training loss: 0.9624, validation loss: 1.0678
2024-05-25 03:06:05 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch4_loss1.0678057670593262.pypots
2024-05-25 03:06:05 [INFO]: Epoch 005 - training loss: 0.9613, validation loss: 1.0487
2024-05-25 03:06:05 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch5_loss1.0487245321273804.pypots
2024-05-25 03:06:05 [INFO]: Epoch 006 - training loss: 0.9664, validation loss: 1.0309
2024-05-25 03:06:05 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch6_loss1.030906394124031.pypots
2024-05-25 03:06:05 [INFO]: Epoch 007 - training loss: 0.9720, validation loss: 1.0209
2024-05-25 03:06:05 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch7_loss1.0208747535943985.pypots
2024-05-25 03:06:06 [INFO]: Epoch 008 - training loss: 0.9146, validation loss: 1.0158
2024-05-25 03:06:06 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch8_loss1.0158427953720093.pypots
2024-05-25 03:06:06 [INFO]: Epoch 009 - training loss: 0.9289, validation loss: 1.0103
2024-05-25 03:06:06 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch9_loss1.0102573484182358.pypots
2024-05-25 03:06:06 [INFO]: Epoch 010 - training loss: 0.9018, validation loss: 1.0077
2024-05-25 03:06:06 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch10_loss1.0076696127653122.pypots
2024-05-25 03:06:06 [INFO]: Epoch 011 - training loss: 0.9269, validation loss: 1.0026
2024-05-25 03:06:06 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch11_loss1.0026284754276276.pypots
2024-05-25 03:06:06 [INFO]: Epoch 012 - training loss: 0.8863, validation loss: 1.0003
2024-05-25 03:06:06 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch12_loss1.0003293454647064.pypots
2024-05-25 03:06:06 [INFO]: Epoch 013 - training loss: 0.9087, validation loss: 0.9973
2024-05-25 03:06:06 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch13_loss0.9973316043615341.pypots
2024-05-25 03:06:07 [INFO]: Epoch 014 - training loss: 0.8877, validation loss: 0.9962
2024-05-25 03:06:07 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch14_loss0.9961719810962677.pypots
2024-05-25 03:06:07 [INFO]: Epoch 015 - training loss: 0.8936, validation loss: 0.9961
2024-05-25 03:06:07 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch15_loss0.9960803538560867.pypots
2024-05-25 03:06:07 [INFO]: Epoch 016 - training loss: 0.8908, validation loss: 0.9921
2024-05-25 03:06:07 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch16_loss0.9920950680971146.pypots
2024-05-25 03:06:07 [INFO]: Epoch 017 - training loss: 0.8779, validation loss: 0.9915
2024-05-25 03:06:07 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch17_loss0.9914724826812744.pypots
2024-05-25 03:06:07 [INFO]: Epoch 018 - training loss: 0.8829, validation loss: 0.9901
2024-05-25 03:06:07 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch18_loss0.9901484400033951.pypots
2024-05-25 03:06:08 [INFO]: Epoch 019 - training loss: 0.8700, validation loss: 0.9870
2024-05-25 03:06:08 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch19_loss0.986958771944046.pypots
2024-05-25 03:06:08 [INFO]: Epoch 020 - training loss: 0.8579, validation loss: 0.9836
2024-05-25 03:06:08 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch20_loss0.9836192727088928.pypots
2024-05-25 03:06:08 [INFO]: Epoch 021 - training loss: 0.8627, validation loss: 0.9809
2024-05-25 03:06:08 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch21_loss0.9808584898710251.pypots
2024-05-25 03:06:08 [INFO]: Epoch 022 - training loss: 0.8592, validation loss: 0.9805
2024-05-25 03:06:08 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch22_loss0.9804981350898743.pypots
2024-05-25 03:06:08 [INFO]: Epoch 023 - training loss: 0.8509, validation loss: 0.9772
2024-05-25 03:06:08 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch23_loss0.9772469401359558.pypots
2024-05-25 03:06:09 [INFO]: Epoch 024 - training loss: 0.8427, validation loss: 0.9745
2024-05-25 03:06:09 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch24_loss0.9745195955038071.pypots
2024-05-25 03:06:09 [INFO]: Epoch 025 - training loss: 0.8457, validation loss: 0.9724
2024-05-25 03:06:09 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch25_loss0.972368523478508.pypots
2024-05-25 03:06:09 [INFO]: Epoch 026 - training loss: 0.8427, validation loss: 0.9675
2024-05-25 03:06:09 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch26_loss0.9674926102161407.pypots
2024-05-25 03:06:09 [INFO]: Epoch 027 - training loss: 0.8534, validation loss: 0.9675
2024-05-25 03:06:09 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch27_loss0.9675465971231461.pypots
2024-05-25 03:06:09 [INFO]: Epoch 028 - training loss: 0.8406, validation loss: 0.9616
2024-05-25 03:06:09 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch28_loss0.9616257846355438.pypots
2024-05-25 03:06:09 [INFO]: Epoch 029 - training loss: 0.8351, validation loss: 0.9578
2024-05-25 03:06:09 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch29_loss0.957783117890358.pypots
2024-05-25 03:06:10 [INFO]: Epoch 030 - training loss: 0.8320, validation loss: 0.9561
2024-05-25 03:06:10 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch30_loss0.9561341404914856.pypots
2024-05-25 03:06:10 [INFO]: Epoch 031 - training loss: 0.8198, validation loss: 0.9559
2024-05-25 03:06:10 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch31_loss0.955893874168396.pypots
2024-05-25 03:06:10 [INFO]: Epoch 032 - training loss: 0.8289, validation loss: 0.9499
2024-05-25 03:06:10 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch32_loss0.9498994946479797.pypots
2024-05-25 03:06:10 [INFO]: Epoch 033 - training loss: 0.8243, validation loss: 0.9457
2024-05-25 03:06:10 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch33_loss0.9457487314939499.pypots
2024-05-25 03:06:10 [INFO]: Epoch 034 - training loss: 0.8268, validation loss: 0.9412
2024-05-25 03:06:10 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch34_loss0.9411576986312866.pypots
2024-05-25 03:06:11 [INFO]: Epoch 035 - training loss: 0.8188, validation loss: 0.9385
2024-05-25 03:06:11 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch35_loss0.9385218918323517.pypots
2024-05-25 03:06:11 [INFO]: Epoch 036 - training loss: 0.8270, validation loss: 0.9363
2024-05-25 03:06:11 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch36_loss0.9362920224666595.pypots
2024-05-25 03:06:11 [INFO]: Epoch 037 - training loss: 0.8145, validation loss: 0.9342
2024-05-25 03:06:11 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch37_loss0.9342237710952759.pypots
2024-05-25 03:06:11 [INFO]: Epoch 038 - training loss: 0.8157, validation loss: 0.9299
2024-05-25 03:06:11 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch38_loss0.9299207329750061.pypots
2024-05-25 03:06:11 [INFO]: Epoch 039 - training loss: 0.8326, validation loss: 0.9306
2024-05-25 03:06:11 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch39_loss0.9306459426879883.pypots
2024-05-25 03:06:12 [INFO]: Epoch 040 - training loss: 0.8135, validation loss: 0.9246
2024-05-25 03:06:12 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch40_loss0.9245775192975998.pypots
2024-05-25 03:06:12 [INFO]: Epoch 041 - training loss: 0.8230, validation loss: 0.9243
2024-05-25 03:06:12 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch41_loss0.9243212938308716.pypots
2024-05-25 03:06:12 [INFO]: Epoch 042 - training loss: 0.7999, validation loss: 0.9200
2024-05-25 03:06:12 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch42_loss0.9200278669595718.pypots
2024-05-25 03:06:12 [INFO]: Epoch 043 - training loss: 0.8119, validation loss: 0.9200
2024-05-25 03:06:12 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch43_loss0.9200455099344254.pypots
2024-05-25 03:06:12 [INFO]: Epoch 044 - training loss: 0.8003, validation loss: 0.9165
2024-05-25 03:06:12 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch44_loss0.9164929389953613.pypots
2024-05-25 03:06:13 [INFO]: Epoch 045 - training loss: 0.7856, validation loss: 0.9178
2024-05-25 03:06:13 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch45_loss0.9177700281143188.pypots
2024-05-25 03:06:13 [INFO]: Epoch 046 - training loss: 0.8103, validation loss: 0.9152
2024-05-25 03:06:13 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch46_loss0.9151623100042343.pypots
2024-05-25 03:06:13 [INFO]: Epoch 047 - training loss: 0.8110, validation loss: 0.9111
2024-05-25 03:06:13 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch47_loss0.9110894948244095.pypots
2024-05-25 03:06:13 [INFO]: Epoch 048 - training loss: 0.8142, validation loss: 0.9110
2024-05-25 03:06:13 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch48_loss0.9109593778848648.pypots
2024-05-25 03:06:13 [INFO]: Epoch 049 - training loss: 0.7908, validation loss: 0.9091
2024-05-25 03:06:13 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch49_loss0.9091283082962036.pypots
2024-05-25 03:06:14 [INFO]: Epoch 050 - training loss: 0.7964, validation loss: 0.9086
2024-05-25 03:06:14 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch50_loss0.9086320549249649.pypots
2024-05-25 03:06:14 [INFO]: Epoch 051 - training loss: 0.8227, validation loss: 0.9095
2024-05-25 03:06:14 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch51_loss0.9094664603471756.pypots
2024-05-25 03:06:14 [INFO]: Epoch 052 - training loss: 0.8109, validation loss: 0.9064
2024-05-25 03:06:14 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch52_loss0.9063887149095535.pypots
2024-05-25 03:06:14 [INFO]: Epoch 053 - training loss: 0.8246, validation loss: 0.9036
2024-05-25 03:06:14 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch53_loss0.9036122560501099.pypots
2024-05-25 03:06:14 [INFO]: Epoch 054 - training loss: 0.8169, validation loss: 0.9042
2024-05-25 03:06:14 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch54_loss0.9041891545057297.pypots
2024-05-25 03:06:15 [INFO]: Epoch 055 - training loss: 0.8157, validation loss: 0.9004
2024-05-25 03:06:15 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch55_loss0.9004038870334625.pypots
2024-05-25 03:06:15 [INFO]: Epoch 056 - training loss: 0.7900, validation loss: 0.8988
2024-05-25 03:06:15 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch56_loss0.898764967918396.pypots
2024-05-25 03:06:15 [INFO]: Epoch 057 - training loss: 0.8247, validation loss: 0.8989
2024-05-25 03:06:15 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch57_loss0.8988911211490631.pypots
2024-05-25 03:06:15 [INFO]: Epoch 058 - training loss: 0.7912, validation loss: 0.8993
2024-05-25 03:06:15 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch58_loss0.8992740213871002.pypots
2024-05-25 03:06:15 [INFO]: Epoch 059 - training loss: 0.8190, validation loss: 0.8977
2024-05-25 03:06:15 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch59_loss0.8977235853672028.pypots
2024-05-25 03:06:16 [INFO]: Epoch 060 - training loss: 0.7936, validation loss: 0.8994
2024-05-25 03:06:16 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch60_loss0.8994395583868027.pypots
2024-05-25 03:06:16 [INFO]: Epoch 061 - training loss: 0.7995, validation loss: 0.8960
2024-05-25 03:06:16 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch61_loss0.8959747701883316.pypots
2024-05-25 03:06:16 [INFO]: Epoch 062 - training loss: 0.7845, validation loss: 0.8980
2024-05-25 03:06:16 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch62_loss0.8979900926351547.pypots
2024-05-25 03:06:16 [INFO]: Epoch 063 - training loss: 0.7955, validation loss: 0.8940
2024-05-25 03:06:16 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch63_loss0.8939945697784424.pypots
2024-05-25 03:06:16 [INFO]: Epoch 064 - training loss: 0.7991, validation loss: 0.8968
2024-05-25 03:06:16 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch64_loss0.8967579454183578.pypots
2024-05-25 03:06:16 [INFO]: Epoch 065 - training loss: 0.8215, validation loss: 0.8935
2024-05-25 03:06:16 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch65_loss0.8934609442949295.pypots
2024-05-25 03:06:17 [INFO]: Epoch 066 - training loss: 0.8205, validation loss: 0.8923
2024-05-25 03:06:17 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch66_loss0.8923158198595047.pypots
2024-05-25 03:06:17 [INFO]: Epoch 067 - training loss: 0.7908, validation loss: 0.8932
2024-05-25 03:06:17 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch67_loss0.8931517750024796.pypots
2024-05-25 03:06:17 [INFO]: Epoch 068 - training loss: 0.7733, validation loss: 0.8914
2024-05-25 03:06:17 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch68_loss0.8914298415184021.pypots
2024-05-25 03:06:17 [INFO]: Epoch 069 - training loss: 0.7925, validation loss: 0.8916
2024-05-25 03:06:17 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch69_loss0.8915740698575974.pypots
2024-05-25 03:06:17 [INFO]: Epoch 070 - training loss: 0.7830, validation loss: 0.8914
2024-05-25 03:06:17 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch70_loss0.8914189338684082.pypots
2024-05-25 03:06:18 [INFO]: Epoch 071 - training loss: 0.8341, validation loss: 0.8902
2024-05-25 03:06:18 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch71_loss0.8902473002672195.pypots
2024-05-25 03:06:18 [INFO]: Epoch 072 - training loss: 0.8107, validation loss: 0.8903
2024-05-25 03:06:18 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch72_loss0.8902830630540848.pypots
2024-05-25 03:06:18 [INFO]: Epoch 073 - training loss: 0.7976, validation loss: 0.8898
2024-05-25 03:06:18 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch73_loss0.8897889852523804.pypots
2024-05-25 03:06:18 [INFO]: Epoch 074 - training loss: 0.7927, validation loss: 0.8890
2024-05-25 03:06:18 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch74_loss0.8889992833137512.pypots
2024-05-25 03:06:18 [INFO]: Epoch 075 - training loss: 0.7838, validation loss: 0.8899
2024-05-25 03:06:18 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch75_loss0.8898651003837585.pypots
2024-05-25 03:06:19 [INFO]: Epoch 076 - training loss: 0.8080, validation loss: 0.8901
2024-05-25 03:06:19 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch76_loss0.8901105672121048.pypots
2024-05-25 03:06:19 [INFO]: Epoch 077 - training loss: 0.8132, validation loss: 0.8892
2024-05-25 03:06:19 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch77_loss0.889167457818985.pypots
2024-05-25 03:06:19 [INFO]: Epoch 078 - training loss: 0.8062, validation loss: 0.8862
2024-05-25 03:06:19 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch78_loss0.8861742615699768.pypots
2024-05-25 03:06:19 [INFO]: Epoch 079 - training loss: 0.7858, validation loss: 0.8869
2024-05-25 03:06:19 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch79_loss0.8869038075208664.pypots
2024-05-25 03:06:19 [INFO]: Epoch 080 - training loss: 0.8088, validation loss: 0.8856
2024-05-25 03:06:19 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch80_loss0.8855659365653992.pypots
2024-05-25 03:06:20 [INFO]: Epoch 081 - training loss: 0.7698, validation loss: 0.8845
2024-05-25 03:06:20 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch81_loss0.8844657838344574.pypots
2024-05-25 03:06:20 [INFO]: Epoch 082 - training loss: 0.7925, validation loss: 0.8872
2024-05-25 03:06:20 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch82_loss0.8872299790382385.pypots
2024-05-25 03:06:20 [INFO]: Epoch 083 - training loss: 0.7789, validation loss: 0.8859
2024-05-25 03:06:20 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch83_loss0.885889858007431.pypots
2024-05-25 03:06:20 [INFO]: Epoch 084 - training loss: 0.7940, validation loss: 0.8860
2024-05-25 03:06:20 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch84_loss0.8859716206789017.pypots
2024-05-25 03:06:20 [INFO]: Epoch 085 - training loss: 0.7818, validation loss: 0.8845
2024-05-25 03:06:20 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch85_loss0.8845260590314865.pypots
2024-05-25 03:06:21 [INFO]: Epoch 086 - training loss: 0.7863, validation loss: 0.8837
2024-05-25 03:06:21 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch86_loss0.8837453424930573.pypots
2024-05-25 03:06:21 [INFO]: Epoch 087 - training loss: 0.8017, validation loss: 0.8919
2024-05-25 03:06:21 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch87_loss0.8919220566749573.pypots
2024-05-25 03:06:21 [INFO]: Epoch 088 - training loss: 0.8180, validation loss: 0.8851
2024-05-25 03:06:21 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch88_loss0.8850914090871811.pypots
2024-05-25 03:06:21 [INFO]: Epoch 089 - training loss: 0.8037, validation loss: 0.8866
2024-05-25 03:06:21 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch89_loss0.8865846246480942.pypots
2024-05-25 03:06:21 [INFO]: Epoch 090 - training loss: 0.7847, validation loss: 0.8826
2024-05-25 03:06:21 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch90_loss0.8825992345809937.pypots
2024-05-25 03:06:22 [INFO]: Epoch 091 - training loss: 0.7878, validation loss: 0.8831
2024-05-25 03:06:22 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch91_loss0.8831261694431305.pypots
2024-05-25 03:06:22 [INFO]: Epoch 092 - training loss: 0.7879, validation loss: 0.8825
2024-05-25 03:06:22 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch92_loss0.8825130015611649.pypots
2024-05-25 03:06:22 [INFO]: Epoch 093 - training loss: 0.7737, validation loss: 0.8798
2024-05-25 03:06:22 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch93_loss0.8797925114631653.pypots
2024-05-25 03:06:22 [INFO]: Epoch 094 - training loss: 0.8045, validation loss: 0.8843
2024-05-25 03:06:22 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch94_loss0.8843327462673187.pypots
2024-05-25 03:06:22 [INFO]: Epoch 095 - training loss: 0.7967, validation loss: 0.8792
2024-05-25 03:06:22 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch95_loss0.879239559173584.pypots
2024-05-25 03:06:23 [INFO]: Epoch 096 - training loss: 0.7776, validation loss: 0.8813
2024-05-25 03:06:23 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch96_loss0.8813102096319199.pypots
2024-05-25 03:06:23 [INFO]: Epoch 097 - training loss: 0.7798, validation loss: 0.8816
2024-05-25 03:06:23 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch97_loss0.8815693557262421.pypots
2024-05-25 03:06:23 [INFO]: Epoch 098 - training loss: 0.7810, validation loss: 0.8803
2024-05-25 03:06:23 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch98_loss0.8803135007619858.pypots
2024-05-25 03:06:23 [INFO]: Epoch 099 - training loss: 0.7842, validation loss: 0.8797
2024-05-25 03:06:23 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch99_loss0.8796945661306381.pypots
2024-05-25 03:06:23 [INFO]: Epoch 100 - training loss: 0.7892, validation loss: 0.8791
2024-05-25 03:06:23 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch100_loss0.8790739178657532.pypots
2024-05-25 03:06:23 [INFO]: Epoch 101 - training loss: 0.8044, validation loss: 0.8777
2024-05-25 03:06:23 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch101_loss0.8776539713144302.pypots
2024-05-25 03:06:24 [INFO]: Epoch 102 - training loss: 0.7867, validation loss: 0.8784
2024-05-25 03:06:24 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch102_loss0.8784008324146271.pypots
2024-05-25 03:06:24 [INFO]: Epoch 103 - training loss: 0.7919, validation loss: 0.8767
2024-05-25 03:06:24 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch103_loss0.8767445981502533.pypots
2024-05-25 03:06:24 [INFO]: Epoch 104 - training loss: 0.8065, validation loss: 0.8814
2024-05-25 03:06:24 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch104_loss0.8814244568347931.pypots
2024-05-25 03:06:24 [INFO]: Epoch 105 - training loss: 0.7729, validation loss: 0.8818
2024-05-25 03:06:24 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch105_loss0.8818246722221375.pypots
2024-05-25 03:06:24 [INFO]: Epoch 106 - training loss: 0.7756, validation loss: 0.8779
2024-05-25 03:06:24 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch106_loss0.8778913021087646.pypots
2024-05-25 03:06:25 [INFO]: Epoch 107 - training loss: 0.7978, validation loss: 0.8791
2024-05-25 03:06:25 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch107_loss0.879117026925087.pypots
2024-05-25 03:06:25 [INFO]: Epoch 108 - training loss: 0.8028, validation loss: 0.8770
2024-05-25 03:06:25 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch108_loss0.876980721950531.pypots
2024-05-25 03:06:25 [INFO]: Epoch 109 - training loss: 0.7872, validation loss: 0.8756
2024-05-25 03:06:25 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch109_loss0.8755988627672195.pypots
2024-05-25 03:06:25 [INFO]: Epoch 110 - training loss: 0.8180, validation loss: 0.8756
2024-05-25 03:06:25 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch110_loss0.8755888342857361.pypots
2024-05-25 03:06:25 [INFO]: Epoch 111 - training loss: 0.8179, validation loss: 0.8772
2024-05-25 03:06:25 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch111_loss0.8771591037511826.pypots
2024-05-25 03:06:26 [INFO]: Epoch 112 - training loss: 0.8066, validation loss: 0.8749
2024-05-25 03:06:26 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch112_loss0.8748573660850525.pypots
2024-05-25 03:06:26 [INFO]: Epoch 113 - training loss: 0.8341, validation loss: 0.8745
2024-05-25 03:06:26 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch113_loss0.8744887560606003.pypots
2024-05-25 03:06:26 [INFO]: Epoch 114 - training loss: 0.7758, validation loss: 0.8766
2024-05-25 03:06:26 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch114_loss0.8766463398933411.pypots
2024-05-25 03:06:26 [INFO]: Epoch 115 - training loss: 0.7906, validation loss: 0.8736
2024-05-25 03:06:26 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch115_loss0.8735638558864594.pypots
2024-05-25 03:06:26 [INFO]: Epoch 116 - training loss: 0.7822, validation loss: 0.8761
2024-05-25 03:06:26 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch116_loss0.8760974705219269.pypots
2024-05-25 03:06:27 [INFO]: Epoch 117 - training loss: 0.8042, validation loss: 0.8735
2024-05-25 03:06:27 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch117_loss0.8735327273607254.pypots
2024-05-25 03:06:27 [INFO]: Epoch 118 - training loss: 0.7862, validation loss: 0.8740
2024-05-25 03:06:27 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch118_loss0.874048575758934.pypots
2024-05-25 03:06:27 [INFO]: Epoch 119 - training loss: 0.7879, validation loss: 0.8751
2024-05-25 03:06:27 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch119_loss0.8751022666692734.pypots
2024-05-25 03:06:27 [INFO]: Epoch 120 - training loss: 0.8327, validation loss: 0.8747
2024-05-25 03:06:27 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch120_loss0.8747046887874603.pypots
2024-05-25 03:06:27 [INFO]: Epoch 121 - training loss: 0.8096, validation loss: 0.8728
2024-05-25 03:06:27 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch121_loss0.8727705180644989.pypots
2024-05-25 03:06:27 [INFO]: Epoch 122 - training loss: 0.7677, validation loss: 0.8760
2024-05-25 03:06:27 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch122_loss0.8760196268558502.pypots
2024-05-25 03:06:28 [INFO]: Epoch 123 - training loss: 0.7611, validation loss: 0.8743
2024-05-25 03:06:28 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch123_loss0.8742935955524445.pypots
2024-05-25 03:06:28 [INFO]: Epoch 124 - training loss: 0.7896, validation loss: 0.8744
2024-05-25 03:06:28 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch124_loss0.8743934631347656.pypots
2024-05-25 03:06:28 [INFO]: Epoch 125 - training loss: 0.7831, validation loss: 0.8746
2024-05-25 03:06:28 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch125_loss0.8745858073234558.pypots
2024-05-25 03:06:28 [INFO]: Epoch 126 - training loss: 0.7811, validation loss: 0.8702
2024-05-25 03:06:28 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch126_loss0.8701801747083664.pypots
2024-05-25 03:06:28 [INFO]: Epoch 127 - training loss: 0.7640, validation loss: 0.8719
2024-05-25 03:06:28 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch127_loss0.8718904703855515.pypots
2024-05-25 03:06:29 [INFO]: Epoch 128 - training loss: 0.7861, validation loss: 0.8717
2024-05-25 03:06:29 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch128_loss0.8717407733201981.pypots
2024-05-25 03:06:29 [INFO]: Epoch 129 - training loss: 0.7963, validation loss: 0.8715
2024-05-25 03:06:29 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch129_loss0.8715322762727737.pypots
2024-05-25 03:06:29 [INFO]: Epoch 130 - training loss: 0.7780, validation loss: 0.8730
2024-05-25 03:06:29 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch130_loss0.8729832768440247.pypots
2024-05-25 03:06:29 [INFO]: Epoch 131 - training loss: 0.7817, validation loss: 0.8697
2024-05-25 03:06:29 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch131_loss0.8697377443313599.pypots
2024-05-25 03:06:29 [INFO]: Epoch 132 - training loss: 0.7657, validation loss: 0.8704
2024-05-25 03:06:29 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch132_loss0.8703797310590744.pypots
2024-05-25 03:06:30 [INFO]: Epoch 133 - training loss: 0.7955, validation loss: 0.8688
2024-05-25 03:06:30 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch133_loss0.868792399764061.pypots
2024-05-25 03:06:30 [INFO]: Epoch 134 - training loss: 0.8024, validation loss: 0.8696
2024-05-25 03:06:30 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch134_loss0.8695637285709381.pypots
2024-05-25 03:06:30 [INFO]: Epoch 135 - training loss: 0.7917, validation loss: 0.8724
2024-05-25 03:06:30 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch135_loss0.8723741471767426.pypots
2024-05-25 03:06:30 [INFO]: Epoch 136 - training loss: 0.8035, validation loss: 0.8727
2024-05-25 03:06:30 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch136_loss0.8727179616689682.pypots
2024-05-25 03:06:30 [INFO]: Epoch 137 - training loss: 0.7664, validation loss: 0.8696
2024-05-25 03:06:30 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch137_loss0.8695904910564423.pypots
2024-05-25 03:06:31 [INFO]: Epoch 138 - training loss: 0.7779, validation loss: 0.8696
2024-05-25 03:06:31 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch138_loss0.8696484416723251.pypots
2024-05-25 03:06:31 [INFO]: Epoch 139 - training loss: 0.7835, validation loss: 0.8702
2024-05-25 03:06:31 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch139_loss0.8702263981103897.pypots
2024-05-25 03:06:31 [INFO]: Epoch 140 - training loss: 0.7888, validation loss: 0.8670
2024-05-25 03:06:31 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch140_loss0.867002934217453.pypots
2024-05-25 03:06:31 [INFO]: Epoch 141 - training loss: 0.7759, validation loss: 0.8690
2024-05-25 03:06:31 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch141_loss0.8689798414707184.pypots
2024-05-25 03:06:31 [INFO]: Epoch 142 - training loss: 0.8038, validation loss: 0.8685
2024-05-25 03:06:31 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch142_loss0.8685235530138016.pypots
2024-05-25 03:06:31 [INFO]: Epoch 143 - training loss: 0.7833, validation loss: 0.8665
2024-05-25 03:06:31 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch143_loss0.8664916008710861.pypots
2024-05-25 03:06:32 [INFO]: Epoch 144 - training loss: 0.7634, validation loss: 0.8687
2024-05-25 03:06:32 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch144_loss0.8686980605125427.pypots
2024-05-25 03:06:32 [INFO]: Epoch 145 - training loss: 0.7865, validation loss: 0.8648
2024-05-25 03:06:32 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch145_loss0.8647708147764206.pypots
2024-05-25 03:06:32 [INFO]: Epoch 146 - training loss: 0.7767, validation loss: 0.8597
2024-05-25 03:06:32 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch146_loss0.859669953584671.pypots
2024-05-25 03:06:32 [INFO]: Epoch 147 - training loss: 0.7770, validation loss: 0.8653
2024-05-25 03:06:32 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch147_loss0.8653155267238617.pypots
2024-05-25 03:06:32 [INFO]: Epoch 148 - training loss: 0.8006, validation loss: 0.8632
2024-05-25 03:06:32 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch148_loss0.8631910681724548.pypots
2024-05-25 03:06:33 [INFO]: Epoch 149 - training loss: 0.7941, validation loss: 0.8642
2024-05-25 03:06:33 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch149_loss0.8642388433218002.pypots
2024-05-25 03:06:33 [INFO]: Epoch 150 - training loss: 0.7868, validation loss: 0.8610
2024-05-25 03:06:33 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch150_loss0.8609668016433716.pypots
2024-05-25 03:06:33 [INFO]: Epoch 151 - training loss: 0.7709, validation loss: 0.8621
2024-05-25 03:06:33 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch151_loss0.8621122539043427.pypots
2024-05-25 03:06:33 [INFO]: Epoch 152 - training loss: 0.7846, validation loss: 0.8628
2024-05-25 03:06:33 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch152_loss0.8627880215644836.pypots
2024-05-25 03:06:33 [INFO]: Epoch 153 - training loss: 0.7838, validation loss: 0.8667
2024-05-25 03:06:33 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch153_loss0.8667200058698654.pypots
2024-05-25 03:06:34 [INFO]: Epoch 154 - training loss: 0.8045, validation loss: 0.8600
2024-05-25 03:06:34 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch154_loss0.8599604070186615.pypots
2024-05-25 03:06:34 [INFO]: Epoch 155 - training loss: 0.7826, validation loss: 0.8606
2024-05-25 03:06:34 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch155_loss0.8606094419956207.pypots
2024-05-25 03:06:34 [INFO]: Epoch 156 - training loss: 0.7823, validation loss: 0.8682
2024-05-25 03:06:34 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN_epoch156_loss0.8682308346033096.pypots
2024-05-25 03:06:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:06:34 [INFO]: Finished training. The best model is from epoch#146.
2024-05-25 03:06:34 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T030602/MRNN.pypots
2024-05-25 03:06:34 [INFO]: MRNN on ETTm1: MAE=0.6778, MSE=1.1015
2024-05-25 03:06:34 [INFO]: Successfully saved to augmentation_saved_results/round_4/MRNN_ettm1/imputation.pkl
2024-05-25 03:06:34 [INFO]: Using the given device: cpu
2024-05-25 03:06:34 [INFO]: LOCF on ETTm1: MAE=0.1348, MSE=0.0715
2024-05-25 03:06:34 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_ettm1".
2024-05-25 03:06:34 [INFO]: Successfully saved to augmentation_saved_results/round_4/LOCF_ettm1/imputation.pkl
2024-05-25 03:06:34 [INFO]: Median on ETTm1: MAE=0.6516, MSE=0.8223
2024-05-25 03:06:34 [INFO]: Successfully created the given path "saved_results/round_4/Median_ettm1".
2024-05-25 03:06:34 [INFO]: Successfully saved to augmentation_saved_results/round_4/Median_ettm1/imputation.pkl
2024-05-25 03:06:34 [INFO]: Mean on ETTm1: MAE=0.6566, MSE=0.8036
2024-05-25 03:06:34 [INFO]: Successfully created the given path "saved_results/round_4/Mean_ettm1".
2024-05-25 03:06:34 [INFO]: Successfully saved to augmentation_saved_results/round_4/Mean_ettm1/imputation.pkl
2024-05-25 03:06:34 [INFO]: 
SAITS on data/ettm1: MAE=0.1500.010653349972431687, MSE=0.0430.006407601636465164
Transformer on data/ettm1: MAE=0.1230.0037431213365662973, MSE=0.0290.0018101546006145531
TimesNet on data/ettm1: MAE=0.1180.007551776994706746, MSE=0.0290.0031895522981511587
CSDI on data/ettm1: MAE=0.2550.1231159764600261, MSE=1.2221.2620623977964942
GPVAE on data/ettm1: MAE=0.2820.013909736813977447, MSE=0.1670.010559024129786921
USGAN on data/ettm1: MAE=0.1400.005349636878447446, MSE=0.0490.0040885593884430384
BRITS on data/ettm1: MAE=0.1290.008912888458289124, MSE=0.0490.005788247970673942
MRNN on data/ettm1: MAE=0.7090.036224127768666216, MSE=1.1960.09372008617584926
LOCF on data/ettm1: MAE=0.1350.0, MSE=0.0710.0
Median on data/ettm1: MAE=0.6520.0, MSE=0.8220.0
Mean on data/ettm1: MAE=0.6570.0, MSE=0.8040.0

