2024-05-22 21:13:33 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-22 21:13:33 [INFO]: Using the given device: cuda:0
2024-05-22 21:13:33 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/SAITS_ettm1/20240522_T211333
2024-05-22 21:13:33 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/SAITS_ettm1/20240522_T211333/tensorboard
2024-05-22 21:13:33 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 21:13:35 [INFO]: Epoch 001 - training loss: 1.1869, validation loss: 0.2508
2024-05-22 21:13:35 [INFO]: Epoch 002 - training loss: 0.9044, validation loss: 0.1163
2024-05-22 21:13:36 [INFO]: Epoch 003 - training loss: 0.7622, validation loss: 0.1076
2024-05-22 21:13:36 [INFO]: Epoch 004 - training loss: 0.7221, validation loss: 0.0860
2024-05-22 21:13:37 [INFO]: Epoch 005 - training loss: 0.6853, validation loss: 0.0727
2024-05-22 21:13:37 [INFO]: Epoch 006 - training loss: 0.6704, validation loss: 0.0662
2024-05-22 21:13:38 [INFO]: Epoch 007 - training loss: 0.6443, validation loss: 0.0613
2024-05-22 21:13:38 [INFO]: Epoch 008 - training loss: 0.6276, validation loss: 0.0709
2024-05-22 21:13:39 [INFO]: Epoch 009 - training loss: 0.6252, validation loss: 0.0645
2024-05-22 21:13:39 [INFO]: Epoch 010 - training loss: 0.6186, validation loss: 0.0690
2024-05-22 21:13:40 [INFO]: Epoch 011 - training loss: 0.5925, validation loss: 0.0658
2024-05-22 21:13:40 [INFO]: Epoch 012 - training loss: 0.5684, validation loss: 0.0567
2024-05-22 21:13:41 [INFO]: Epoch 013 - training loss: 0.5647, validation loss: 0.0540
2024-05-22 21:13:41 [INFO]: Epoch 014 - training loss: 0.5636, validation loss: 0.0427
2024-05-22 21:13:42 [INFO]: Epoch 015 - training loss: 0.5526, validation loss: 0.0594
2024-05-22 21:13:42 [INFO]: Epoch 016 - training loss: 0.5568, validation loss: 0.0559
2024-05-22 21:13:43 [INFO]: Epoch 017 - training loss: 0.5670, validation loss: 0.0501
2024-05-22 21:13:43 [INFO]: Epoch 018 - training loss: 0.5331, validation loss: 0.0492
2024-05-22 21:13:44 [INFO]: Epoch 019 - training loss: 0.5542, validation loss: 0.0515
2024-05-22 21:13:44 [INFO]: Epoch 020 - training loss: 0.5302, validation loss: 0.0495
2024-05-22 21:13:44 [INFO]: Epoch 021 - training loss: 0.5242, validation loss: 0.0442
2024-05-22 21:13:45 [INFO]: Epoch 022 - training loss: 0.5380, validation loss: 0.0579
2024-05-22 21:13:45 [INFO]: Epoch 023 - training loss: 0.5181, validation loss: 0.0449
2024-05-22 21:13:46 [INFO]: Epoch 024 - training loss: 0.5074, validation loss: 0.0449
2024-05-22 21:13:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:13:46 [INFO]: Finished training. The best model is from epoch#14.
2024-05-22 21:13:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/SAITS_ettm1/20240522_T211333/SAITS.pypots
2024-05-22 21:13:46 [INFO]: SAITS on ETTm1: MAE=0.1849, MSE=0.0686
2024-05-22 21:13:46 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/SAITS_ettm1/imputation.pkl
2024-05-22 21:13:46 [INFO]: Using the given device: cuda:0
2024-05-22 21:13:46 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/Transformer_ettm1/20240522_T211346
2024-05-22 21:13:46 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/Transformer_ettm1/20240522_T211346/tensorboard
2024-05-22 21:13:46 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 21:13:46 [INFO]: Epoch 001 - training loss: 1.0994, validation loss: 0.3094
2024-05-22 21:13:46 [INFO]: Epoch 002 - training loss: 0.6550, validation loss: 0.1540
2024-05-22 21:13:47 [INFO]: Epoch 003 - training loss: 0.5341, validation loss: 0.1128
2024-05-22 21:13:47 [INFO]: Epoch 004 - training loss: 0.4815, validation loss: 0.0934
2024-05-22 21:13:47 [INFO]: Epoch 005 - training loss: 0.4468, validation loss: 0.0880
2024-05-22 21:13:47 [INFO]: Epoch 006 - training loss: 0.4352, validation loss: 0.0780
2024-05-22 21:13:47 [INFO]: Epoch 007 - training loss: 0.4119, validation loss: 0.0678
2024-05-22 21:13:48 [INFO]: Epoch 008 - training loss: 0.4009, validation loss: 0.0624
2024-05-22 21:13:48 [INFO]: Epoch 009 - training loss: 0.3815, validation loss: 0.0592
2024-05-22 21:13:48 [INFO]: Epoch 010 - training loss: 0.3664, validation loss: 0.0569
2024-05-22 21:13:48 [INFO]: Epoch 011 - training loss: 0.3609, validation loss: 0.0548
2024-05-22 21:13:48 [INFO]: Epoch 012 - training loss: 0.3562, validation loss: 0.0538
2024-05-22 21:13:49 [INFO]: Epoch 013 - training loss: 0.3515, validation loss: 0.0518
2024-05-22 21:13:49 [INFO]: Epoch 014 - training loss: 0.3358, validation loss: 0.0483
2024-05-22 21:13:49 [INFO]: Epoch 015 - training loss: 0.3342, validation loss: 0.0477
2024-05-22 21:13:49 [INFO]: Epoch 016 - training loss: 0.3233, validation loss: 0.0437
2024-05-22 21:13:49 [INFO]: Epoch 017 - training loss: 0.3177, validation loss: 0.0486
2024-05-22 21:13:50 [INFO]: Epoch 018 - training loss: 0.3214, validation loss: 0.0487
2024-05-22 21:13:50 [INFO]: Epoch 019 - training loss: 0.3098, validation loss: 0.0401
2024-05-22 21:13:50 [INFO]: Epoch 020 - training loss: 0.2986, validation loss: 0.0412
2024-05-22 21:13:50 [INFO]: Epoch 021 - training loss: 0.2967, validation loss: 0.0407
2024-05-22 21:13:50 [INFO]: Epoch 022 - training loss: 0.2944, validation loss: 0.0389
2024-05-22 21:13:51 [INFO]: Epoch 023 - training loss: 0.2967, validation loss: 0.0389
2024-05-22 21:13:51 [INFO]: Epoch 024 - training loss: 0.2870, validation loss: 0.0412
2024-05-22 21:13:51 [INFO]: Epoch 025 - training loss: 0.2889, validation loss: 0.0364
2024-05-22 21:13:51 [INFO]: Epoch 026 - training loss: 0.2788, validation loss: 0.0366
2024-05-22 21:13:51 [INFO]: Epoch 027 - training loss: 0.2743, validation loss: 0.0375
2024-05-22 21:13:52 [INFO]: Epoch 028 - training loss: 0.2723, validation loss: 0.0363
2024-05-22 21:13:52 [INFO]: Epoch 029 - training loss: 0.2726, validation loss: 0.0428
2024-05-22 21:13:52 [INFO]: Epoch 030 - training loss: 0.2814, validation loss: 0.0354
2024-05-22 21:13:52 [INFO]: Epoch 031 - training loss: 0.2761, validation loss: 0.0369
2024-05-22 21:13:52 [INFO]: Epoch 032 - training loss: 0.2660, validation loss: 0.0351
2024-05-22 21:13:53 [INFO]: Epoch 033 - training loss: 0.2606, validation loss: 0.0340
2024-05-22 21:13:53 [INFO]: Epoch 034 - training loss: 0.2559, validation loss: 0.0355
2024-05-22 21:13:53 [INFO]: Epoch 035 - training loss: 0.2593, validation loss: 0.0330
2024-05-22 21:13:53 [INFO]: Epoch 036 - training loss: 0.2565, validation loss: 0.0336
2024-05-22 21:13:54 [INFO]: Epoch 037 - training loss: 0.2476, validation loss: 0.0331
2024-05-22 21:13:54 [INFO]: Epoch 038 - training loss: 0.2436, validation loss: 0.0350
2024-05-22 21:13:54 [INFO]: Epoch 039 - training loss: 0.2445, validation loss: 0.0353
2024-05-22 21:13:54 [INFO]: Epoch 040 - training loss: 0.2478, validation loss: 0.0350
2024-05-22 21:13:54 [INFO]: Epoch 041 - training loss: 0.2537, validation loss: 0.0363
2024-05-22 21:13:54 [INFO]: Epoch 042 - training loss: 0.2474, validation loss: 0.0345
2024-05-22 21:13:55 [INFO]: Epoch 043 - training loss: 0.2401, validation loss: 0.0327
2024-05-22 21:13:55 [INFO]: Epoch 044 - training loss: 0.2363, validation loss: 0.0307
2024-05-22 21:13:55 [INFO]: Epoch 045 - training loss: 0.2318, validation loss: 0.0311
2024-05-22 21:13:55 [INFO]: Epoch 046 - training loss: 0.2282, validation loss: 0.0325
2024-05-22 21:13:55 [INFO]: Epoch 047 - training loss: 0.2296, validation loss: 0.0371
2024-05-22 21:13:56 [INFO]: Epoch 048 - training loss: 0.2399, validation loss: 0.0363
2024-05-22 21:13:56 [INFO]: Epoch 049 - training loss: 0.2388, validation loss: 0.0332
2024-05-22 21:13:56 [INFO]: Epoch 050 - training loss: 0.2270, validation loss: 0.0308
2024-05-22 21:13:56 [INFO]: Epoch 051 - training loss: 0.2197, validation loss: 0.0328
2024-05-22 21:13:57 [INFO]: Epoch 052 - training loss: 0.2245, validation loss: 0.0327
2024-05-22 21:13:57 [INFO]: Epoch 053 - training loss: 0.2263, validation loss: 0.0281
2024-05-22 21:13:57 [INFO]: Epoch 054 - training loss: 0.2178, validation loss: 0.0278
2024-05-22 21:13:57 [INFO]: Epoch 055 - training loss: 0.2153, validation loss: 0.0333
2024-05-22 21:13:57 [INFO]: Epoch 056 - training loss: 0.2301, validation loss: 0.0309
2024-05-22 21:13:58 [INFO]: Epoch 057 - training loss: 0.2135, validation loss: 0.0299
2024-05-22 21:13:58 [INFO]: Epoch 058 - training loss: 0.2172, validation loss: 0.0319
2024-05-22 21:13:58 [INFO]: Epoch 059 - training loss: 0.2187, validation loss: 0.0277
2024-05-22 21:13:58 [INFO]: Epoch 060 - training loss: 0.2137, validation loss: 0.0277
2024-05-22 21:13:59 [INFO]: Epoch 061 - training loss: 0.2147, validation loss: 0.0303
2024-05-22 21:13:59 [INFO]: Epoch 062 - training loss: 0.2078, validation loss: 0.0297
2024-05-22 21:13:59 [INFO]: Epoch 063 - training loss: 0.2081, validation loss: 0.0273
2024-05-22 21:13:59 [INFO]: Epoch 064 - training loss: 0.2059, validation loss: 0.0266
2024-05-22 21:13:59 [INFO]: Epoch 065 - training loss: 0.2002, validation loss: 0.0283
2024-05-22 21:14:00 [INFO]: Epoch 066 - training loss: 0.2020, validation loss: 0.0290
2024-05-22 21:14:00 [INFO]: Epoch 067 - training loss: 0.2036, validation loss: 0.0315
2024-05-22 21:14:00 [INFO]: Epoch 068 - training loss: 0.2119, validation loss: 0.0287
2024-05-22 21:14:00 [INFO]: Epoch 069 - training loss: 0.2098, validation loss: 0.0273
2024-05-22 21:14:00 [INFO]: Epoch 070 - training loss: 0.2022, validation loss: 0.0300
2024-05-22 21:14:01 [INFO]: Epoch 071 - training loss: 0.2001, validation loss: 0.0287
2024-05-22 21:14:01 [INFO]: Epoch 072 - training loss: 0.2052, validation loss: 0.0284
2024-05-22 21:14:01 [INFO]: Epoch 073 - training loss: 0.1964, validation loss: 0.0258
2024-05-22 21:14:01 [INFO]: Epoch 074 - training loss: 0.1919, validation loss: 0.0302
2024-05-22 21:14:01 [INFO]: Epoch 075 - training loss: 0.2013, validation loss: 0.0305
2024-05-22 21:14:02 [INFO]: Epoch 076 - training loss: 0.2008, validation loss: 0.0274
2024-05-22 21:14:02 [INFO]: Epoch 077 - training loss: 0.1998, validation loss: 0.0286
2024-05-22 21:14:02 [INFO]: Epoch 078 - training loss: 0.1967, validation loss: 0.0285
2024-05-22 21:14:02 [INFO]: Epoch 079 - training loss: 0.1974, validation loss: 0.0261
2024-05-22 21:14:02 [INFO]: Epoch 080 - training loss: 0.1910, validation loss: 0.0261
2024-05-22 21:14:03 [INFO]: Epoch 081 - training loss: 0.1893, validation loss: 0.0248
2024-05-22 21:14:03 [INFO]: Epoch 082 - training loss: 0.1895, validation loss: 0.0268
2024-05-22 21:14:03 [INFO]: Epoch 083 - training loss: 0.1891, validation loss: 0.0264
2024-05-22 21:14:03 [INFO]: Epoch 084 - training loss: 0.1898, validation loss: 0.0267
2024-05-22 21:14:04 [INFO]: Epoch 085 - training loss: 0.1873, validation loss: 0.0264
2024-05-22 21:14:04 [INFO]: Epoch 086 - training loss: 0.1890, validation loss: 0.0266
2024-05-22 21:14:04 [INFO]: Epoch 087 - training loss: 0.1894, validation loss: 0.0248
2024-05-22 21:14:04 [INFO]: Epoch 088 - training loss: 0.1843, validation loss: 0.0253
2024-05-22 21:14:04 [INFO]: Epoch 089 - training loss: 0.1840, validation loss: 0.0290
2024-05-22 21:14:05 [INFO]: Epoch 090 - training loss: 0.1946, validation loss: 0.0282
2024-05-22 21:14:05 [INFO]: Epoch 091 - training loss: 0.1885, validation loss: 0.0253
2024-05-22 21:14:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:14:05 [INFO]: Finished training. The best model is from epoch#81.
2024-05-22 21:14:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/Transformer_ettm1/20240522_T211346/Transformer.pypots
2024-05-22 21:14:05 [INFO]: Transformer on ETTm1: MAE=0.1251, MSE=0.0336
2024-05-22 21:14:05 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Transformer_ettm1/imputation.pkl
2024-05-22 21:14:05 [INFO]: Using the given device: cuda:0
2024-05-22 21:14:05 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/TimesNet_ettm1/20240522_T211405
2024-05-22 21:14:05 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/TimesNet_ettm1/20240522_T211405/tensorboard
2024-05-22 21:14:05 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 21:14:06 [INFO]: Epoch 001 - training loss: 0.1408, validation loss: 0.0517
2024-05-22 21:14:06 [INFO]: Epoch 002 - training loss: 0.0629, validation loss: 0.0436
2024-05-22 21:14:06 [INFO]: Epoch 003 - training loss: 0.0461, validation loss: 0.0344
2024-05-22 21:14:06 [INFO]: Epoch 004 - training loss: 0.0393, validation loss: 0.0314
2024-05-22 21:14:06 [INFO]: Epoch 005 - training loss: 0.0361, validation loss: 0.0292
2024-05-22 21:14:07 [INFO]: Epoch 006 - training loss: 0.0336, validation loss: 0.0277
2024-05-22 21:14:07 [INFO]: Epoch 007 - training loss: 0.0320, validation loss: 0.0279
2024-05-22 21:14:07 [INFO]: Epoch 008 - training loss: 0.0324, validation loss: 0.0274
2024-05-22 21:14:07 [INFO]: Epoch 009 - training loss: 0.0318, validation loss: 0.0282
2024-05-22 21:14:07 [INFO]: Epoch 010 - training loss: 0.0330, validation loss: 0.0265
2024-05-22 21:14:08 [INFO]: Epoch 011 - training loss: 0.0299, validation loss: 0.0273
2024-05-22 21:14:08 [INFO]: Epoch 012 - training loss: 0.0322, validation loss: 0.0268
2024-05-22 21:14:08 [INFO]: Epoch 013 - training loss: 0.0288, validation loss: 0.0257
2024-05-22 21:14:08 [INFO]: Epoch 014 - training loss: 0.0295, validation loss: 0.0272
2024-05-22 21:14:09 [INFO]: Epoch 015 - training loss: 0.0299, validation loss: 0.0264
2024-05-22 21:14:09 [INFO]: Epoch 016 - training loss: 0.0286, validation loss: 0.0266
2024-05-22 21:14:09 [INFO]: Epoch 017 - training loss: 0.0275, validation loss: 0.0263
2024-05-22 21:14:09 [INFO]: Epoch 018 - training loss: 0.0262, validation loss: 0.0257
2024-05-22 21:14:09 [INFO]: Epoch 019 - training loss: 0.0256, validation loss: 0.0260
2024-05-22 21:14:10 [INFO]: Epoch 020 - training loss: 0.0283, validation loss: 0.0259
2024-05-22 21:14:10 [INFO]: Epoch 021 - training loss: 0.0273, validation loss: 0.0257
2024-05-22 21:14:10 [INFO]: Epoch 022 - training loss: 0.0255, validation loss: 0.0263
2024-05-22 21:14:10 [INFO]: Epoch 023 - training loss: 0.0249, validation loss: 0.0264
2024-05-22 21:14:10 [INFO]: Epoch 024 - training loss: 0.0241, validation loss: 0.0254
2024-05-22 21:14:11 [INFO]: Epoch 025 - training loss: 0.0263, validation loss: 0.0258
2024-05-22 21:14:11 [INFO]: Epoch 026 - training loss: 0.0274, validation loss: 0.0264
2024-05-22 21:14:11 [INFO]: Epoch 027 - training loss: 0.0257, validation loss: 0.0271
2024-05-22 21:14:11 [INFO]: Epoch 028 - training loss: 0.0247, validation loss: 0.0262
2024-05-22 21:14:11 [INFO]: Epoch 029 - training loss: 0.0223, validation loss: 0.0253
2024-05-22 21:14:12 [INFO]: Epoch 030 - training loss: 0.0212, validation loss: 0.0259
2024-05-22 21:14:12 [INFO]: Epoch 031 - training loss: 0.0221, validation loss: 0.0259
2024-05-22 21:14:12 [INFO]: Epoch 032 - training loss: 0.0226, validation loss: 0.0252
2024-05-22 21:14:12 [INFO]: Epoch 033 - training loss: 0.0215, validation loss: 0.0248
2024-05-22 21:14:12 [INFO]: Epoch 034 - training loss: 0.0202, validation loss: 0.0245
2024-05-22 21:14:13 [INFO]: Epoch 035 - training loss: 0.0191, validation loss: 0.0253
2024-05-22 21:14:13 [INFO]: Epoch 036 - training loss: 0.0198, validation loss: 0.0252
2024-05-22 21:14:13 [INFO]: Epoch 037 - training loss: 0.0195, validation loss: 0.0260
2024-05-22 21:14:13 [INFO]: Epoch 038 - training loss: 0.0202, validation loss: 0.0258
2024-05-22 21:14:13 [INFO]: Epoch 039 - training loss: 0.0201, validation loss: 0.0256
2024-05-22 21:14:13 [INFO]: Epoch 040 - training loss: 0.0184, validation loss: 0.0252
2024-05-22 21:14:14 [INFO]: Epoch 041 - training loss: 0.0179, validation loss: 0.0249
2024-05-22 21:14:14 [INFO]: Epoch 042 - training loss: 0.0400, validation loss: 0.0277
2024-05-22 21:14:14 [INFO]: Epoch 043 - training loss: 0.0322, validation loss: 0.0284
2024-05-22 21:14:14 [INFO]: Epoch 044 - training loss: 0.0246, validation loss: 0.0265
2024-05-22 21:14:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:14:14 [INFO]: Finished training. The best model is from epoch#34.
2024-05-22 21:14:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/TimesNet_ettm1/20240522_T211405/TimesNet.pypots
2024-05-22 21:14:14 [INFO]: TimesNet on ETTm1: MAE=0.1121, MSE=0.0266
2024-05-22 21:14:14 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/TimesNet_ettm1/imputation.pkl
2024-05-22 21:14:14 [INFO]: Using the given device: cuda:0
2024-05-22 21:14:14 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414
2024-05-22 21:14:14 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/tensorboard
2024-05-22 21:14:14 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 21:14:17 [INFO]: Epoch 001 - training loss: 0.6696, validation loss: 0.4428
2024-05-22 21:14:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch1_loss0.44279128313064575.pypots
2024-05-22 21:14:19 [INFO]: Epoch 002 - training loss: 0.3799, validation loss: 0.3544
2024-05-22 21:14:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch2_loss0.35437409579753876.pypots
2024-05-22 21:14:21 [INFO]: Epoch 003 - training loss: 0.3320, validation loss: 0.3027
2024-05-22 21:14:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch3_loss0.30270247906446457.pypots
2024-05-22 21:14:23 [INFO]: Epoch 004 - training loss: 0.3603, validation loss: 0.3004
2024-05-22 21:14:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch4_loss0.3004450425505638.pypots
2024-05-22 21:14:25 [INFO]: Epoch 005 - training loss: 0.2797, validation loss: 0.2807
2024-05-22 21:14:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch5_loss0.2807329595088959.pypots
2024-05-22 21:14:27 [INFO]: Epoch 006 - training loss: 0.2899, validation loss: 0.2651
2024-05-22 21:14:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch6_loss0.2651248350739479.pypots
2024-05-22 21:14:29 [INFO]: Epoch 007 - training loss: 0.2223, validation loss: 0.2512
2024-05-22 21:14:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch7_loss0.2512083388864994.pypots
2024-05-22 21:14:31 [INFO]: Epoch 008 - training loss: 0.2420, validation loss: 0.2427
2024-05-22 21:14:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch8_loss0.24270294606685638.pypots
2024-05-22 21:14:33 [INFO]: Epoch 009 - training loss: 0.2887, validation loss: 0.2314
2024-05-22 21:14:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch9_loss0.23140797019004822.pypots
2024-05-22 21:14:35 [INFO]: Epoch 010 - training loss: 0.2357, validation loss: 0.2298
2024-05-22 21:14:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch10_loss0.22978812456130981.pypots
2024-05-22 21:14:37 [INFO]: Epoch 011 - training loss: 0.2090, validation loss: 0.2160
2024-05-22 21:14:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch11_loss0.2160331830382347.pypots
2024-05-22 21:14:39 [INFO]: Epoch 012 - training loss: 0.2134, validation loss: 0.2064
2024-05-22 21:14:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch12_loss0.20643405243754387.pypots
2024-05-22 21:14:41 [INFO]: Epoch 013 - training loss: 0.2617, validation loss: 0.2578
2024-05-22 21:14:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch13_loss0.2577629052102566.pypots
2024-05-22 21:14:43 [INFO]: Epoch 014 - training loss: 0.2703, validation loss: 0.2232
2024-05-22 21:14:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch14_loss0.22324225679039955.pypots
2024-05-22 21:14:45 [INFO]: Epoch 015 - training loss: 0.2285, validation loss: 0.2133
2024-05-22 21:14:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch15_loss0.2133442722260952.pypots
2024-05-22 21:14:47 [INFO]: Epoch 016 - training loss: 0.2070, validation loss: 0.2024
2024-05-22 21:14:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch16_loss0.202448058873415.pypots
2024-05-22 21:14:49 [INFO]: Epoch 017 - training loss: 0.2233, validation loss: 0.2155
2024-05-22 21:14:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch17_loss0.21550866216421127.pypots
2024-05-22 21:14:51 [INFO]: Epoch 018 - training loss: 0.2384, validation loss: 0.1987
2024-05-22 21:14:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch18_loss0.19866395741701126.pypots
2024-05-22 21:14:53 [INFO]: Epoch 019 - training loss: 0.2047, validation loss: 0.1905
2024-05-22 21:14:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch19_loss0.19051087647676468.pypots
2024-05-22 21:14:55 [INFO]: Epoch 020 - training loss: 0.2037, validation loss: 0.1833
2024-05-22 21:14:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch20_loss0.1833186037838459.pypots
2024-05-22 21:14:57 [INFO]: Epoch 021 - training loss: 0.1805, validation loss: 0.1879
2024-05-22 21:14:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch21_loss0.18790548667311668.pypots
2024-05-22 21:14:59 [INFO]: Epoch 022 - training loss: 0.2213, validation loss: 0.1901
2024-05-22 21:14:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch22_loss0.19010594114661217.pypots
2024-05-22 21:15:01 [INFO]: Epoch 023 - training loss: 0.2133, validation loss: 0.1842
2024-05-22 21:15:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch23_loss0.18421616032719612.pypots
2024-05-22 21:15:03 [INFO]: Epoch 024 - training loss: 0.2001, validation loss: 0.1726
2024-05-22 21:15:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch24_loss0.17255782335996628.pypots
2024-05-22 21:15:05 [INFO]: Epoch 025 - training loss: 0.2030, validation loss: 0.1677
2024-05-22 21:15:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch25_loss0.16770420968532562.pypots
2024-05-22 21:15:07 [INFO]: Epoch 026 - training loss: 0.1736, validation loss: 0.1660
2024-05-22 21:15:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch26_loss0.16597021371126175.pypots
2024-05-22 21:15:09 [INFO]: Epoch 027 - training loss: 0.1600, validation loss: 0.1630
2024-05-22 21:15:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch27_loss0.16300751268863678.pypots
2024-05-22 21:15:11 [INFO]: Epoch 028 - training loss: 0.1792, validation loss: 0.1601
2024-05-22 21:15:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch28_loss0.16012565791606903.pypots
2024-05-22 21:15:13 [INFO]: Epoch 029 - training loss: 0.1689, validation loss: 0.1606
2024-05-22 21:15:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch29_loss0.16058195382356644.pypots
2024-05-22 21:15:15 [INFO]: Epoch 030 - training loss: 0.1666, validation loss: 0.1575
2024-05-22 21:15:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch30_loss0.15750359743833542.pypots
2024-05-22 21:15:17 [INFO]: Epoch 031 - training loss: 0.2375, validation loss: 0.1627
2024-05-22 21:15:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch31_loss0.16269366815686226.pypots
2024-05-22 21:15:19 [INFO]: Epoch 032 - training loss: 0.1569, validation loss: 0.1535
2024-05-22 21:15:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch32_loss0.15347406640648842.pypots
2024-05-22 21:15:21 [INFO]: Epoch 033 - training loss: 0.2257, validation loss: 0.1556
2024-05-22 21:15:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch33_loss0.15557415038347244.pypots
2024-05-22 21:15:23 [INFO]: Epoch 034 - training loss: 0.1459, validation loss: 0.1658
2024-05-22 21:15:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch34_loss0.16577228903770447.pypots
2024-05-22 21:15:25 [INFO]: Epoch 035 - training loss: 0.1752, validation loss: 0.1648
2024-05-22 21:15:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch35_loss0.1647731140255928.pypots
2024-05-22 21:15:27 [INFO]: Epoch 036 - training loss: 0.1761, validation loss: 0.1580
2024-05-22 21:15:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch36_loss0.1580084227025509.pypots
2024-05-22 21:15:29 [INFO]: Epoch 037 - training loss: 0.1745, validation loss: 0.1517
2024-05-22 21:15:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch37_loss0.15172455832362175.pypots
2024-05-22 21:15:31 [INFO]: Epoch 038 - training loss: 0.1426, validation loss: 0.1540
2024-05-22 21:15:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch38_loss0.1539902649819851.pypots
2024-05-22 21:15:33 [INFO]: Epoch 039 - training loss: 0.1667, validation loss: 0.1479
2024-05-22 21:15:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch39_loss0.14793965220451355.pypots
2024-05-22 21:15:35 [INFO]: Epoch 040 - training loss: 0.1933, validation loss: 0.1525
2024-05-22 21:15:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch40_loss0.15249134972691536.pypots
2024-05-22 21:15:38 [INFO]: Epoch 041 - training loss: 0.1915, validation loss: 0.1639
2024-05-22 21:15:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch41_loss0.1638791300356388.pypots
2024-05-22 21:15:40 [INFO]: Epoch 042 - training loss: 0.2343, validation loss: 0.1520
2024-05-22 21:15:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch42_loss0.15199625864624977.pypots
2024-05-22 21:15:42 [INFO]: Epoch 043 - training loss: 0.1451, validation loss: 0.1516
2024-05-22 21:15:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch43_loss0.15160859003663063.pypots
2024-05-22 21:15:44 [INFO]: Epoch 044 - training loss: 0.1443, validation loss: 0.1514
2024-05-22 21:15:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch44_loss0.15142348781228065.pypots
2024-05-22 21:15:46 [INFO]: Epoch 045 - training loss: 0.1474, validation loss: 0.1461
2024-05-22 21:15:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch45_loss0.14612185209989548.pypots
2024-05-22 21:15:48 [INFO]: Epoch 046 - training loss: 0.1454, validation loss: 0.1560
2024-05-22 21:15:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch46_loss0.1560344062745571.pypots
2024-05-22 21:15:50 [INFO]: Epoch 047 - training loss: 0.1561, validation loss: 0.1540
2024-05-22 21:15:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch47_loss0.15399857982993126.pypots
2024-05-22 21:15:52 [INFO]: Epoch 048 - training loss: 0.1440, validation loss: 0.1480
2024-05-22 21:15:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch48_loss0.1479976885020733.pypots
2024-05-22 21:15:54 [INFO]: Epoch 049 - training loss: 0.1362, validation loss: 0.1455
2024-05-22 21:15:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch49_loss0.14550120010972023.pypots
2024-05-22 21:15:56 [INFO]: Epoch 050 - training loss: 0.1396, validation loss: 0.1460
2024-05-22 21:15:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch50_loss0.146025400608778.pypots
2024-05-22 21:15:58 [INFO]: Epoch 051 - training loss: 0.1441, validation loss: 0.1440
2024-05-22 21:15:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch51_loss0.14400164037942886.pypots
2024-05-22 21:16:00 [INFO]: Epoch 052 - training loss: 0.1694, validation loss: 0.1435
2024-05-22 21:16:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch52_loss0.14350904151797295.pypots
2024-05-22 21:16:02 [INFO]: Epoch 053 - training loss: 0.1697, validation loss: 0.1481
2024-05-22 21:16:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch53_loss0.14812003076076508.pypots
2024-05-22 21:16:04 [INFO]: Epoch 054 - training loss: 0.1367, validation loss: 0.1432
2024-05-22 21:16:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch54_loss0.14320108294487.pypots
2024-05-22 21:16:06 [INFO]: Epoch 055 - training loss: 0.1309, validation loss: 0.1436
2024-05-22 21:16:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch55_loss0.1436203233897686.pypots
2024-05-22 21:16:08 [INFO]: Epoch 056 - training loss: 0.1439, validation loss: 0.1412
2024-05-22 21:16:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch56_loss0.14124393463134766.pypots
2024-05-22 21:16:10 [INFO]: Epoch 057 - training loss: 0.1392, validation loss: 0.1461
2024-05-22 21:16:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch57_loss0.14607372507452965.pypots
2024-05-22 21:16:12 [INFO]: Epoch 058 - training loss: 0.1616, validation loss: 0.1520
2024-05-22 21:16:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch58_loss0.15202291682362556.pypots
2024-05-22 21:16:14 [INFO]: Epoch 059 - training loss: 0.1656, validation loss: 0.1434
2024-05-22 21:16:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch59_loss0.1434016339480877.pypots
2024-05-22 21:16:16 [INFO]: Epoch 060 - training loss: 0.1484, validation loss: 0.1403
2024-05-22 21:16:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch60_loss0.14033715426921844.pypots
2024-05-22 21:16:18 [INFO]: Epoch 061 - training loss: 0.1345, validation loss: 0.1426
2024-05-22 21:16:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch61_loss0.1425979547202587.pypots
2024-05-22 21:16:20 [INFO]: Epoch 062 - training loss: 0.1536, validation loss: 0.1392
2024-05-22 21:16:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch62_loss0.13924473151564598.pypots
2024-05-22 21:16:22 [INFO]: Epoch 063 - training loss: 0.1464, validation loss: 0.1340
2024-05-22 21:16:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch63_loss0.13402161374688148.pypots
2024-05-22 21:16:24 [INFO]: Epoch 064 - training loss: 0.1424, validation loss: 0.1294
2024-05-22 21:16:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch64_loss0.12938944436609745.pypots
2024-05-22 21:16:26 [INFO]: Epoch 065 - training loss: 0.1322, validation loss: 0.1325
2024-05-22 21:16:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch65_loss0.132450670003891.pypots
2024-05-22 21:16:28 [INFO]: Epoch 066 - training loss: 0.1677, validation loss: 0.1544
2024-05-22 21:16:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch66_loss0.1544402539730072.pypots
2024-05-22 21:16:30 [INFO]: Epoch 067 - training loss: 0.1630, validation loss: 0.1635
2024-05-22 21:16:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch67_loss0.16353686153888702.pypots
2024-05-22 21:16:32 [INFO]: Epoch 068 - training loss: 0.1911, validation loss: 0.1459
2024-05-22 21:16:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch68_loss0.14585918933153152.pypots
2024-05-22 21:16:34 [INFO]: Epoch 069 - training loss: 0.1444, validation loss: 0.1520
2024-05-22 21:16:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch69_loss0.15199487283825874.pypots
2024-05-22 21:16:36 [INFO]: Epoch 070 - training loss: 0.1434, validation loss: 0.1389
2024-05-22 21:16:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch70_loss0.1389448083937168.pypots
2024-05-22 21:16:38 [INFO]: Epoch 071 - training loss: 0.1307, validation loss: 0.1365
2024-05-22 21:16:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch71_loss0.13647443428635597.pypots
2024-05-22 21:16:40 [INFO]: Epoch 072 - training loss: 0.1394, validation loss: 0.1295
2024-05-22 21:16:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch72_loss0.1295214630663395.pypots
2024-05-22 21:16:42 [INFO]: Epoch 073 - training loss: 0.1266, validation loss: 0.1296
2024-05-22 21:16:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch73_loss0.12960860691964626.pypots
2024-05-22 21:16:44 [INFO]: Epoch 074 - training loss: 0.1274, validation loss: 0.1265
2024-05-22 21:16:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch74_loss0.12654410488903522.pypots
2024-05-22 21:16:46 [INFO]: Epoch 075 - training loss: 0.1171, validation loss: 0.1276
2024-05-22 21:16:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch75_loss0.12764237262308598.pypots
2024-05-22 21:16:48 [INFO]: Epoch 076 - training loss: 0.1334, validation loss: 0.1277
2024-05-22 21:16:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch76_loss0.1277086529880762.pypots
2024-05-22 21:16:50 [INFO]: Epoch 077 - training loss: 0.1689, validation loss: 0.1315
2024-05-22 21:16:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch77_loss0.13148751854896545.pypots
2024-05-22 21:16:52 [INFO]: Epoch 078 - training loss: 0.1335, validation loss: 0.1292
2024-05-22 21:16:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch78_loss0.12919372133910656.pypots
2024-05-22 21:16:54 [INFO]: Epoch 079 - training loss: 0.1765, validation loss: 0.1442
2024-05-22 21:16:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch79_loss0.14422453194856644.pypots
2024-05-22 21:16:56 [INFO]: Epoch 080 - training loss: 0.1827, validation loss: 0.1827
2024-05-22 21:16:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch80_loss0.18271466344594955.pypots
2024-05-22 21:16:58 [INFO]: Epoch 081 - training loss: 0.1590, validation loss: 0.1481
2024-05-22 21:16:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch81_loss0.14806248992681503.pypots
2024-05-22 21:17:00 [INFO]: Epoch 082 - training loss: 0.1452, validation loss: 0.1428
2024-05-22 21:17:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch82_loss0.1427806355059147.pypots
2024-05-22 21:17:02 [INFO]: Epoch 083 - training loss: 0.1221, validation loss: 0.1331
2024-05-22 21:17:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch83_loss0.13313427940011024.pypots
2024-05-22 21:17:04 [INFO]: Epoch 084 - training loss: 0.1503, validation loss: 0.1311
2024-05-22 21:17:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI_epoch84_loss0.13109778054058552.pypots
2024-05-22 21:17:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:17:04 [INFO]: Finished training. The best model is from epoch#74.
2024-05-22 21:17:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240522_T211414/CSDI.pypots
2024-05-22 21:17:20 [INFO]: CSDI on ETTm1: MAE=0.1308, MSE=0.0480
2024-05-22 21:17:20 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/CSDI_ettm1/imputation.pkl
2024-05-22 21:17:20 [INFO]: Using the given device: cuda:0
2024-05-22 21:17:20 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/GPVAE_ettm1/20240522_T211720
2024-05-22 21:17:20 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/GPVAE_ettm1/20240522_T211720/tensorboard
2024-05-22 21:17:20 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 21:17:20 [INFO]: Epoch 001 - training loss: 24139.0167, validation loss: 0.9797
2024-05-22 21:17:20 [INFO]: Epoch 002 - training loss: 21965.1672, validation loss: 0.9647
2024-05-22 21:17:21 [INFO]: Epoch 003 - training loss: 20026.9779, validation loss: 0.9455
2024-05-22 21:17:21 [INFO]: Epoch 004 - training loss: 18012.4351, validation loss: 0.9211
2024-05-22 21:17:21 [INFO]: Epoch 005 - training loss: 16077.3900, validation loss: 0.8606
2024-05-22 21:17:21 [INFO]: Epoch 006 - training loss: 14417.1074, validation loss: 0.7549
2024-05-22 21:17:21 [INFO]: Epoch 007 - training loss: 13211.0641, validation loss: 0.6295
2024-05-22 21:17:21 [INFO]: Epoch 008 - training loss: 12035.0063, validation loss: 0.5498
2024-05-22 21:17:21 [INFO]: Epoch 009 - training loss: 11504.4208, validation loss: 0.4897
2024-05-22 21:17:21 [INFO]: Epoch 010 - training loss: 11159.1709, validation loss: 0.4712
2024-05-22 21:17:21 [INFO]: Epoch 011 - training loss: 10713.4741, validation loss: 0.4457
2024-05-22 21:17:21 [INFO]: Epoch 012 - training loss: 10560.7421, validation loss: 0.4333
2024-05-22 21:17:22 [INFO]: Epoch 013 - training loss: 10350.0864, validation loss: 0.4204
2024-05-22 21:17:22 [INFO]: Epoch 014 - training loss: 10269.2501, validation loss: 0.3986
2024-05-22 21:17:22 [INFO]: Epoch 015 - training loss: 10095.8417, validation loss: 0.3810
2024-05-22 21:17:22 [INFO]: Epoch 016 - training loss: 9989.5991, validation loss: 0.3656
2024-05-22 21:17:22 [INFO]: Epoch 017 - training loss: 9930.7957, validation loss: 0.3434
2024-05-22 21:17:22 [INFO]: Epoch 018 - training loss: 9809.3511, validation loss: 0.3305
2024-05-22 21:17:22 [INFO]: Epoch 019 - training loss: 9773.6594, validation loss: 0.3166
2024-05-22 21:17:22 [INFO]: Epoch 020 - training loss: 9744.9543, validation loss: 0.3104
2024-05-22 21:17:22 [INFO]: Epoch 021 - training loss: 9696.4404, validation loss: 0.3126
2024-05-22 21:17:23 [INFO]: Epoch 022 - training loss: 9664.4407, validation loss: 0.2964
2024-05-22 21:17:23 [INFO]: Epoch 023 - training loss: 9668.6653, validation loss: 0.2872
2024-05-22 21:17:23 [INFO]: Epoch 024 - training loss: 9583.7291, validation loss: 0.2892
2024-05-22 21:17:23 [INFO]: Epoch 025 - training loss: 9558.4937, validation loss: 0.2789
2024-05-22 21:17:23 [INFO]: Epoch 026 - training loss: 9538.2523, validation loss: 0.2704
2024-05-22 21:17:23 [INFO]: Epoch 027 - training loss: 9520.9509, validation loss: 0.2668
2024-05-22 21:17:23 [INFO]: Epoch 028 - training loss: 9529.5789, validation loss: 0.2588
2024-05-22 21:17:23 [INFO]: Epoch 029 - training loss: 9491.5426, validation loss: 0.2600
2024-05-22 21:17:23 [INFO]: Epoch 030 - training loss: 9476.5264, validation loss: 0.2525
2024-05-22 21:17:24 [INFO]: Epoch 031 - training loss: 9464.1281, validation loss: 0.2466
2024-05-22 21:17:24 [INFO]: Epoch 032 - training loss: 9454.7951, validation loss: 0.2323
2024-05-22 21:17:24 [INFO]: Epoch 033 - training loss: 9453.6479, validation loss: 0.2264
2024-05-22 21:17:24 [INFO]: Epoch 034 - training loss: 9433.0563, validation loss: 0.2234
2024-05-22 21:17:24 [INFO]: Epoch 035 - training loss: 9435.7448, validation loss: 0.2186
2024-05-22 21:17:24 [INFO]: Epoch 036 - training loss: 9414.6198, validation loss: 0.2149
2024-05-22 21:17:24 [INFO]: Epoch 037 - training loss: 9419.1273, validation loss: 0.2091
2024-05-22 21:17:24 [INFO]: Epoch 038 - training loss: 9413.2971, validation loss: 0.2047
2024-05-22 21:17:24 [INFO]: Epoch 039 - training loss: 9392.5288, validation loss: 0.1998
2024-05-22 21:17:24 [INFO]: Epoch 040 - training loss: 9395.1661, validation loss: 0.1956
2024-05-22 21:17:25 [INFO]: Epoch 041 - training loss: 9384.2214, validation loss: 0.1920
2024-05-22 21:17:25 [INFO]: Epoch 042 - training loss: 9379.4113, validation loss: 0.1885
2024-05-22 21:17:25 [INFO]: Epoch 043 - training loss: 9381.0345, validation loss: 0.1783
2024-05-22 21:17:25 [INFO]: Epoch 044 - training loss: 9373.7583, validation loss: 0.1777
2024-05-22 21:17:25 [INFO]: Epoch 045 - training loss: 9394.5414, validation loss: 0.1724
2024-05-22 21:17:25 [INFO]: Epoch 046 - training loss: 9369.4598, validation loss: 0.1683
2024-05-22 21:17:25 [INFO]: Epoch 047 - training loss: 9363.1527, validation loss: 0.1642
2024-05-22 21:17:25 [INFO]: Epoch 048 - training loss: 9356.9186, validation loss: 0.1623
2024-05-22 21:17:25 [INFO]: Epoch 049 - training loss: 9353.4109, validation loss: 0.1584
2024-05-22 21:17:26 [INFO]: Epoch 050 - training loss: 9350.7648, validation loss: 0.1554
2024-05-22 21:17:26 [INFO]: Epoch 051 - training loss: 9348.6639, validation loss: 0.1525
2024-05-22 21:17:26 [INFO]: Epoch 052 - training loss: 9343.4781, validation loss: 0.1486
2024-05-22 21:17:26 [INFO]: Epoch 053 - training loss: 9341.2650, validation loss: 0.1495
2024-05-22 21:17:26 [INFO]: Epoch 054 - training loss: 9348.6958, validation loss: 0.1446
2024-05-22 21:17:26 [INFO]: Epoch 055 - training loss: 9337.2024, validation loss: 0.1435
2024-05-22 21:17:26 [INFO]: Epoch 056 - training loss: 9334.1733, validation loss: 0.1413
2024-05-22 21:17:26 [INFO]: Epoch 057 - training loss: 9332.8671, validation loss: 0.1394
2024-05-22 21:17:26 [INFO]: Epoch 058 - training loss: 9332.3603, validation loss: 0.1409
2024-05-22 21:17:26 [INFO]: Epoch 059 - training loss: 9332.6179, validation loss: 0.1367
2024-05-22 21:17:27 [INFO]: Epoch 060 - training loss: 9325.4860, validation loss: 0.1365
2024-05-22 21:17:27 [INFO]: Epoch 061 - training loss: 9328.0193, validation loss: 0.1351
2024-05-22 21:17:27 [INFO]: Epoch 062 - training loss: 9325.3503, validation loss: 0.1335
2024-05-22 21:17:27 [INFO]: Epoch 063 - training loss: 9324.3220, validation loss: 0.1315
2024-05-22 21:17:27 [INFO]: Epoch 064 - training loss: 9320.3673, validation loss: 0.1311
2024-05-22 21:17:27 [INFO]: Epoch 065 - training loss: 9320.0263, validation loss: 0.1307
2024-05-22 21:17:27 [INFO]: Epoch 066 - training loss: 9317.3056, validation loss: 0.1289
2024-05-22 21:17:27 [INFO]: Epoch 067 - training loss: 9320.2927, validation loss: 0.1289
2024-05-22 21:17:27 [INFO]: Epoch 068 - training loss: 9317.0923, validation loss: 0.1281
2024-05-22 21:17:28 [INFO]: Epoch 069 - training loss: 9315.9593, validation loss: 0.1265
2024-05-22 21:17:28 [INFO]: Epoch 070 - training loss: 9316.7305, validation loss: 0.1250
2024-05-22 21:17:28 [INFO]: Epoch 071 - training loss: 9317.2545, validation loss: 0.1250
2024-05-22 21:17:28 [INFO]: Epoch 072 - training loss: 9311.4092, validation loss: 0.1239
2024-05-22 21:17:28 [INFO]: Epoch 073 - training loss: 9313.1667, validation loss: 0.1240
2024-05-22 21:17:28 [INFO]: Epoch 074 - training loss: 9308.3496, validation loss: 0.1230
2024-05-22 21:17:28 [INFO]: Epoch 075 - training loss: 9307.7984, validation loss: 0.1225
2024-05-22 21:17:28 [INFO]: Epoch 076 - training loss: 9310.5942, validation loss: 0.1233
2024-05-22 21:17:28 [INFO]: Epoch 077 - training loss: 9308.9586, validation loss: 0.1211
2024-05-22 21:17:28 [INFO]: Epoch 078 - training loss: 9308.5067, validation loss: 0.1210
2024-05-22 21:17:29 [INFO]: Epoch 079 - training loss: 9306.9956, validation loss: 0.1198
2024-05-22 21:17:29 [INFO]: Epoch 080 - training loss: 9308.0207, validation loss: 0.1189
2024-05-22 21:17:29 [INFO]: Epoch 081 - training loss: 9303.8628, validation loss: 0.1194
2024-05-22 21:17:29 [INFO]: Epoch 082 - training loss: 9303.1887, validation loss: 0.1180
2024-05-22 21:17:29 [INFO]: Epoch 083 - training loss: 9303.1819, validation loss: 0.1176
2024-05-22 21:17:29 [INFO]: Epoch 084 - training loss: 9306.6685, validation loss: 0.1178
2024-05-22 21:17:29 [INFO]: Epoch 085 - training loss: 9299.9012, validation loss: 0.1172
2024-05-22 21:17:29 [INFO]: Epoch 086 - training loss: 9300.8328, validation loss: 0.1167
2024-05-22 21:17:29 [INFO]: Epoch 087 - training loss: 9304.3293, validation loss: 0.1160
2024-05-22 21:17:30 [INFO]: Epoch 088 - training loss: 9298.9950, validation loss: 0.1141
2024-05-22 21:17:30 [INFO]: Epoch 089 - training loss: 9299.0823, validation loss: 0.1155
2024-05-22 21:17:30 [INFO]: Epoch 090 - training loss: 9297.8859, validation loss: 0.1126
2024-05-22 21:17:30 [INFO]: Epoch 091 - training loss: 9297.6903, validation loss: 0.1114
2024-05-22 21:17:30 [INFO]: Epoch 092 - training loss: 9300.6238, validation loss: 0.1128
2024-05-22 21:17:30 [INFO]: Epoch 093 - training loss: 9294.9954, validation loss: 0.1115
2024-05-22 21:17:30 [INFO]: Epoch 094 - training loss: 9296.0776, validation loss: 0.1109
2024-05-22 21:17:30 [INFO]: Epoch 095 - training loss: 9297.1639, validation loss: 0.1114
2024-05-22 21:17:30 [INFO]: Epoch 096 - training loss: 9294.0425, validation loss: 0.1095
2024-05-22 21:17:31 [INFO]: Epoch 097 - training loss: 9294.6259, validation loss: 0.1096
2024-05-22 21:17:31 [INFO]: Epoch 098 - training loss: 9295.0828, validation loss: 0.1089
2024-05-22 21:17:31 [INFO]: Epoch 099 - training loss: 9293.6868, validation loss: 0.1086
2024-05-22 21:17:31 [INFO]: Epoch 100 - training loss: 9293.2510, validation loss: 0.1069
2024-05-22 21:17:31 [INFO]: Epoch 101 - training loss: 9293.8176, validation loss: 0.1077
2024-05-22 21:17:31 [INFO]: Epoch 102 - training loss: 9292.6798, validation loss: 0.1079
2024-05-22 21:17:31 [INFO]: Epoch 103 - training loss: 9292.9269, validation loss: 0.1058
2024-05-22 21:17:31 [INFO]: Epoch 104 - training loss: 9291.4233, validation loss: 0.1067
2024-05-22 21:17:31 [INFO]: Epoch 105 - training loss: 9293.5851, validation loss: 0.1071
2024-05-22 21:17:31 [INFO]: Epoch 106 - training loss: 9290.5806, validation loss: 0.1050
2024-05-22 21:17:32 [INFO]: Epoch 107 - training loss: 9294.9146, validation loss: 0.1044
2024-05-22 21:17:32 [INFO]: Epoch 108 - training loss: 9288.8361, validation loss: 0.1060
2024-05-22 21:17:32 [INFO]: Epoch 109 - training loss: 9289.2299, validation loss: 0.1037
2024-05-22 21:17:32 [INFO]: Epoch 110 - training loss: 9288.2186, validation loss: 0.1040
2024-05-22 21:17:32 [INFO]: Epoch 111 - training loss: 9290.1799, validation loss: 0.1033
2024-05-22 21:17:32 [INFO]: Epoch 112 - training loss: 9289.4236, validation loss: 0.1020
2024-05-22 21:17:32 [INFO]: Epoch 113 - training loss: 9288.9353, validation loss: 0.1031
2024-05-22 21:17:32 [INFO]: Epoch 114 - training loss: 9287.6384, validation loss: 0.1018
2024-05-22 21:17:32 [INFO]: Epoch 115 - training loss: 9288.9695, validation loss: 0.1021
2024-05-22 21:17:33 [INFO]: Epoch 116 - training loss: 9285.9840, validation loss: 0.1005
2024-05-22 21:17:33 [INFO]: Epoch 117 - training loss: 9285.6035, validation loss: 0.1009
2024-05-22 21:17:33 [INFO]: Epoch 118 - training loss: 9287.5682, validation loss: 0.0997
2024-05-22 21:17:33 [INFO]: Epoch 119 - training loss: 9285.2076, validation loss: 0.0993
2024-05-22 21:17:33 [INFO]: Epoch 120 - training loss: 9285.1174, validation loss: 0.1002
2024-05-22 21:17:33 [INFO]: Epoch 121 - training loss: 9285.6169, validation loss: 0.0998
2024-05-22 21:17:33 [INFO]: Epoch 122 - training loss: 9286.1653, validation loss: 0.0973
2024-05-22 21:17:33 [INFO]: Epoch 123 - training loss: 9285.9335, validation loss: 0.0993
2024-05-22 21:17:33 [INFO]: Epoch 124 - training loss: 9286.3712, validation loss: 0.0974
2024-05-22 21:17:33 [INFO]: Epoch 125 - training loss: 9284.5115, validation loss: 0.0974
2024-05-22 21:17:34 [INFO]: Epoch 126 - training loss: 9283.6436, validation loss: 0.0969
2024-05-22 21:17:34 [INFO]: Epoch 127 - training loss: 9284.0997, validation loss: 0.0965
2024-05-22 21:17:34 [INFO]: Epoch 128 - training loss: 9283.9762, validation loss: 0.0953
2024-05-22 21:17:34 [INFO]: Epoch 129 - training loss: 9283.8874, validation loss: 0.0961
2024-05-22 21:17:34 [INFO]: Epoch 130 - training loss: 9283.4707, validation loss: 0.0958
2024-05-22 21:17:34 [INFO]: Epoch 131 - training loss: 9283.1957, validation loss: 0.0955
2024-05-22 21:17:34 [INFO]: Epoch 132 - training loss: 9283.6210, validation loss: 0.0947
2024-05-22 21:17:34 [INFO]: Epoch 133 - training loss: 9282.8091, validation loss: 0.0956
2024-05-22 21:17:34 [INFO]: Epoch 134 - training loss: 9283.7903, validation loss: 0.0936
2024-05-22 21:17:35 [INFO]: Epoch 135 - training loss: 9281.5870, validation loss: 0.0944
2024-05-22 21:17:35 [INFO]: Epoch 136 - training loss: 9281.4952, validation loss: 0.0937
2024-05-22 21:17:35 [INFO]: Epoch 137 - training loss: 9281.9182, validation loss: 0.0925
2024-05-22 21:17:35 [INFO]: Epoch 138 - training loss: 9280.3730, validation loss: 0.0936
2024-05-22 21:17:35 [INFO]: Epoch 139 - training loss: 9279.9649, validation loss: 0.0919
2024-05-22 21:17:35 [INFO]: Epoch 140 - training loss: 9280.8661, validation loss: 0.0938
2024-05-22 21:17:35 [INFO]: Epoch 141 - training loss: 9280.0074, validation loss: 0.0904
2024-05-22 21:17:35 [INFO]: Epoch 142 - training loss: 9280.9857, validation loss: 0.0930
2024-05-22 21:17:35 [INFO]: Epoch 143 - training loss: 9280.7432, validation loss: 0.0916
2024-05-22 21:17:35 [INFO]: Epoch 144 - training loss: 9279.4781, validation loss: 0.0896
2024-05-22 21:17:36 [INFO]: Epoch 145 - training loss: 9281.5682, validation loss: 0.0911
2024-05-22 21:17:36 [INFO]: Epoch 146 - training loss: 9279.7366, validation loss: 0.0929
2024-05-22 21:17:36 [INFO]: Epoch 147 - training loss: 9279.7684, validation loss: 0.0892
2024-05-22 21:17:36 [INFO]: Epoch 148 - training loss: 9279.2670, validation loss: 0.0919
2024-05-22 21:17:36 [INFO]: Epoch 149 - training loss: 9279.1638, validation loss: 0.0893
2024-05-22 21:17:36 [INFO]: Epoch 150 - training loss: 9280.2145, validation loss: 0.0896
2024-05-22 21:17:36 [INFO]: Epoch 151 - training loss: 9278.8572, validation loss: 0.0879
2024-05-22 21:17:36 [INFO]: Epoch 152 - training loss: 9280.5146, validation loss: 0.0877
2024-05-22 21:17:36 [INFO]: Epoch 153 - training loss: 9278.4478, validation loss: 0.0885
2024-05-22 21:17:37 [INFO]: Epoch 154 - training loss: 9277.6329, validation loss: 0.0879
2024-05-22 21:17:37 [INFO]: Epoch 155 - training loss: 9277.9929, validation loss: 0.0895
2024-05-22 21:17:37 [INFO]: Epoch 156 - training loss: 9297.8069, validation loss: 0.0872
2024-05-22 21:17:37 [INFO]: Epoch 157 - training loss: 9278.7187, validation loss: 0.0878
2024-05-22 21:17:37 [INFO]: Epoch 158 - training loss: 9277.4926, validation loss: 0.0865
2024-05-22 21:17:37 [INFO]: Epoch 159 - training loss: 9277.2775, validation loss: 0.0876
2024-05-22 21:17:37 [INFO]: Epoch 160 - training loss: 9278.4173, validation loss: 0.0867
2024-05-22 21:17:37 [INFO]: Epoch 161 - training loss: 9277.4468, validation loss: 0.0865
2024-05-22 21:17:37 [INFO]: Epoch 162 - training loss: 9277.5300, validation loss: 0.0865
2024-05-22 21:17:37 [INFO]: Epoch 163 - training loss: 9275.8025, validation loss: 0.0855
2024-05-22 21:17:38 [INFO]: Epoch 164 - training loss: 9276.9487, validation loss: 0.0883
2024-05-22 21:17:38 [INFO]: Epoch 165 - training loss: 9277.1481, validation loss: 0.0872
2024-05-22 21:17:38 [INFO]: Epoch 166 - training loss: 9278.1271, validation loss: 0.0874
2024-05-22 21:17:38 [INFO]: Epoch 167 - training loss: 9276.4104, validation loss: 0.0882
2024-05-22 21:17:38 [INFO]: Epoch 168 - training loss: 9277.0535, validation loss: 0.0863
2024-05-22 21:17:38 [INFO]: Epoch 169 - training loss: 9278.6240, validation loss: 0.0848
2024-05-22 21:17:38 [INFO]: Epoch 170 - training loss: 9276.3385, validation loss: 0.0849
2024-05-22 21:17:38 [INFO]: Epoch 171 - training loss: 9277.6124, validation loss: 0.0851
2024-05-22 21:17:38 [INFO]: Epoch 172 - training loss: 9276.0280, validation loss: 0.0856
2024-05-22 21:17:39 [INFO]: Epoch 173 - training loss: 9275.9467, validation loss: 0.0851
2024-05-22 21:17:39 [INFO]: Epoch 174 - training loss: 9275.6746, validation loss: 0.0839
2024-05-22 21:17:39 [INFO]: Epoch 175 - training loss: 9275.1388, validation loss: 0.0849
2024-05-22 21:17:39 [INFO]: Epoch 176 - training loss: 9276.0604, validation loss: 0.0842
2024-05-22 21:17:39 [INFO]: Epoch 177 - training loss: 9275.9998, validation loss: 0.0829
2024-05-22 21:17:39 [INFO]: Epoch 178 - training loss: 9275.3445, validation loss: 0.0833
2024-05-22 21:17:39 [INFO]: Epoch 179 - training loss: 9276.6306, validation loss: 0.0839
2024-05-22 21:17:39 [INFO]: Epoch 180 - training loss: 9274.4817, validation loss: 0.0837
2024-05-22 21:17:39 [INFO]: Epoch 181 - training loss: 9275.5391, validation loss: 0.0824
2024-05-22 21:17:39 [INFO]: Epoch 182 - training loss: 9277.6868, validation loss: 0.0830
2024-05-22 21:17:40 [INFO]: Epoch 183 - training loss: 9275.6631, validation loss: 0.0815
2024-05-22 21:17:40 [INFO]: Epoch 184 - training loss: 9276.1666, validation loss: 0.0816
2024-05-22 21:17:40 [INFO]: Epoch 185 - training loss: 9274.1457, validation loss: 0.0828
2024-05-22 21:17:40 [INFO]: Epoch 186 - training loss: 9274.7804, validation loss: 0.0826
2024-05-22 21:17:40 [INFO]: Epoch 187 - training loss: 9272.9604, validation loss: 0.0818
2024-05-22 21:17:40 [INFO]: Epoch 188 - training loss: 9274.8618, validation loss: 0.0832
2024-05-22 21:17:40 [INFO]: Epoch 189 - training loss: 9274.7685, validation loss: 0.0819
2024-05-22 21:17:40 [INFO]: Epoch 190 - training loss: 9274.0928, validation loss: 0.0815
2024-05-22 21:17:40 [INFO]: Epoch 191 - training loss: 9275.1850, validation loss: 0.0808
2024-05-22 21:17:41 [INFO]: Epoch 192 - training loss: 9274.6345, validation loss: 0.0804
2024-05-22 21:17:41 [INFO]: Epoch 193 - training loss: 9274.5186, validation loss: 0.0819
2024-05-22 21:17:41 [INFO]: Epoch 194 - training loss: 9275.2307, validation loss: 0.0817
2024-05-22 21:17:41 [INFO]: Epoch 195 - training loss: 9273.8654, validation loss: 0.0796
2024-05-22 21:17:41 [INFO]: Epoch 196 - training loss: 9273.2860, validation loss: 0.0798
2024-05-22 21:17:41 [INFO]: Epoch 197 - training loss: 9272.9836, validation loss: 0.0794
2024-05-22 21:17:41 [INFO]: Epoch 198 - training loss: 9273.8424, validation loss: 0.0800
2024-05-22 21:17:41 [INFO]: Epoch 199 - training loss: 9274.8594, validation loss: 0.0811
2024-05-22 21:17:41 [INFO]: Epoch 200 - training loss: 9273.9572, validation loss: 0.0805
2024-05-22 21:17:41 [INFO]: Epoch 201 - training loss: 9274.6440, validation loss: 0.0817
2024-05-22 21:17:42 [INFO]: Epoch 202 - training loss: 9273.7592, validation loss: 0.0795
2024-05-22 21:17:42 [INFO]: Epoch 203 - training loss: 9272.6913, validation loss: 0.0803
2024-05-22 21:17:42 [INFO]: Epoch 204 - training loss: 9274.0646, validation loss: 0.0773
2024-05-22 21:17:42 [INFO]: Epoch 205 - training loss: 9277.3094, validation loss: 0.0824
2024-05-22 21:17:42 [INFO]: Epoch 206 - training loss: 9272.7719, validation loss: 0.0823
2024-05-22 21:17:42 [INFO]: Epoch 207 - training loss: 9273.8203, validation loss: 0.0783
2024-05-22 21:17:42 [INFO]: Epoch 208 - training loss: 9274.6255, validation loss: 0.0802
2024-05-22 21:17:42 [INFO]: Epoch 209 - training loss: 9272.4806, validation loss: 0.0799
2024-05-22 21:17:42 [INFO]: Epoch 210 - training loss: 9272.5068, validation loss: 0.0798
2024-05-22 21:17:43 [INFO]: Epoch 211 - training loss: 9273.8871, validation loss: 0.0800
2024-05-22 21:17:43 [INFO]: Epoch 212 - training loss: 9272.5001, validation loss: 0.0782
2024-05-22 21:17:43 [INFO]: Epoch 213 - training loss: 9272.9020, validation loss: 0.0793
2024-05-22 21:17:43 [INFO]: Epoch 214 - training loss: 9275.3568, validation loss: 0.0796
2024-05-22 21:17:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:17:43 [INFO]: Finished training. The best model is from epoch#204.
2024-05-22 21:17:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/GPVAE_ettm1/20240522_T211720/GPVAE.pypots
2024-05-22 21:17:43 [INFO]: GP-VAE on ETTm1: MAE=0.2780, MSE=0.1680
2024-05-22 21:17:43 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/GPVAE_ettm1/imputation.pkl
2024-05-22 21:17:43 [INFO]: Using the given device: cuda:0
2024-05-22 21:17:43 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/USGAN_ettm1/20240522_T211743
2024-05-22 21:17:43 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/USGAN_ettm1/20240522_T211743/tensorboard
2024-05-22 21:17:43 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 21:17:51 [INFO]: Epoch 001 - generator training loss: 0.4889, discriminator training loss: 0.4233, validation loss: 0.3079
2024-05-22 21:17:58 [INFO]: Epoch 002 - generator training loss: -0.0150, discriminator training loss: 0.3233, validation loss: 0.1004
2024-05-22 21:18:05 [INFO]: Epoch 003 - generator training loss: -0.1125, discriminator training loss: 0.3078, validation loss: 0.0597
2024-05-22 21:18:12 [INFO]: Epoch 004 - generator training loss: -0.1304, discriminator training loss: 0.2938, validation loss: 0.0580
2024-05-22 21:18:19 [INFO]: Epoch 005 - generator training loss: -0.1232, discriminator training loss: 0.2751, validation loss: 0.0446
2024-05-22 21:18:26 [INFO]: Epoch 006 - generator training loss: -0.0996, discriminator training loss: 0.2440, validation loss: 0.0433
2024-05-22 21:18:33 [INFO]: Epoch 007 - generator training loss: -0.0811, discriminator training loss: 0.2091, validation loss: 0.0413
2024-05-22 21:18:39 [INFO]: Epoch 008 - generator training loss: -0.0576, discriminator training loss: 0.1743, validation loss: 0.0390
2024-05-22 21:18:46 [INFO]: Epoch 009 - generator training loss: -0.0422, discriminator training loss: 0.1520, validation loss: 0.0376
2024-05-22 21:18:53 [INFO]: Epoch 010 - generator training loss: -0.0349, discriminator training loss: 0.1390, validation loss: 0.0369
2024-05-22 21:19:00 [INFO]: Epoch 011 - generator training loss: -0.0367, discriminator training loss: 0.1328, validation loss: 0.0353
2024-05-22 21:19:07 [INFO]: Epoch 012 - generator training loss: -0.0327, discriminator training loss: 0.1260, validation loss: 0.0352
2024-05-22 21:19:14 [INFO]: Epoch 013 - generator training loss: -0.0354, discriminator training loss: 0.1263, validation loss: 0.0345
2024-05-22 21:19:21 [INFO]: Epoch 014 - generator training loss: -0.0333, discriminator training loss: 0.1233, validation loss: 0.0340
2024-05-22 21:19:28 [INFO]: Epoch 015 - generator training loss: -0.0323, discriminator training loss: 0.1181, validation loss: 0.0339
2024-05-22 21:19:35 [INFO]: Epoch 016 - generator training loss: -0.0345, discriminator training loss: 0.1201, validation loss: 0.0332
2024-05-22 21:19:42 [INFO]: Epoch 017 - generator training loss: -0.0349, discriminator training loss: 0.1181, validation loss: 0.0334
2024-05-22 21:19:49 [INFO]: Epoch 018 - generator training loss: -0.0327, discriminator training loss: 0.1196, validation loss: 0.0322
2024-05-22 21:19:56 [INFO]: Epoch 019 - generator training loss: -0.0310, discriminator training loss: 0.1192, validation loss: 0.0324
2024-05-22 21:20:03 [INFO]: Epoch 020 - generator training loss: -0.0355, discriminator training loss: 0.1147, validation loss: 0.0313
2024-05-22 21:20:10 [INFO]: Epoch 021 - generator training loss: -0.0361, discriminator training loss: 0.1172, validation loss: 0.0312
2024-05-22 21:20:17 [INFO]: Epoch 022 - generator training loss: -0.0346, discriminator training loss: 0.1149, validation loss: 0.0305
2024-05-22 21:20:24 [INFO]: Epoch 023 - generator training loss: -0.0379, discriminator training loss: 0.1172, validation loss: 0.0306
2024-05-22 21:20:31 [INFO]: Epoch 024 - generator training loss: -0.0343, discriminator training loss: 0.1149, validation loss: 0.0299
2024-05-22 21:20:38 [INFO]: Epoch 025 - generator training loss: -0.0364, discriminator training loss: 0.1140, validation loss: 0.0302
2024-05-22 21:20:45 [INFO]: Epoch 026 - generator training loss: -0.0372, discriminator training loss: 0.1140, validation loss: 0.0289
2024-05-22 21:20:52 [INFO]: Epoch 027 - generator training loss: -0.0362, discriminator training loss: 0.1144, validation loss: 0.0292
2024-05-22 21:20:59 [INFO]: Epoch 028 - generator training loss: -0.0372, discriminator training loss: 0.1138, validation loss: 0.0287
2024-05-22 21:21:06 [INFO]: Epoch 029 - generator training loss: -0.0383, discriminator training loss: 0.1122, validation loss: 0.0288
2024-05-22 21:21:12 [INFO]: Epoch 030 - generator training loss: -0.0366, discriminator training loss: 0.1119, validation loss: 0.0280
2024-05-22 21:21:19 [INFO]: Epoch 031 - generator training loss: -0.0392, discriminator training loss: 0.1135, validation loss: 0.0287
2024-05-22 21:21:26 [INFO]: Epoch 032 - generator training loss: -0.0344, discriminator training loss: 0.1114, validation loss: 0.0290
2024-05-22 21:21:33 [INFO]: Epoch 033 - generator training loss: -0.0384, discriminator training loss: 0.1132, validation loss: 0.0276
2024-05-22 21:21:40 [INFO]: Epoch 034 - generator training loss: -0.0387, discriminator training loss: 0.1151, validation loss: 0.0283
2024-05-22 21:21:47 [INFO]: Epoch 035 - generator training loss: -0.0400, discriminator training loss: 0.1112, validation loss: 0.0273
2024-05-22 21:21:54 [INFO]: Epoch 036 - generator training loss: -0.0391, discriminator training loss: 0.1125, validation loss: 0.0270
2024-05-22 21:22:01 [INFO]: Epoch 037 - generator training loss: -0.0417, discriminator training loss: 0.1127, validation loss: 0.0275
2024-05-22 21:22:08 [INFO]: Epoch 038 - generator training loss: -0.0400, discriminator training loss: 0.1120, validation loss: 0.0267
2024-05-22 21:22:15 [INFO]: Epoch 039 - generator training loss: -0.0397, discriminator training loss: 0.1106, validation loss: 0.0276
2024-05-22 21:22:22 [INFO]: Epoch 040 - generator training loss: -0.0383, discriminator training loss: 0.1095, validation loss: 0.0277
2024-05-22 21:22:29 [INFO]: Epoch 041 - generator training loss: -0.0423, discriminator training loss: 0.1103, validation loss: 0.0270
2024-05-22 21:22:35 [INFO]: Epoch 042 - generator training loss: -0.0415, discriminator training loss: 0.1101, validation loss: 0.0265
2024-05-22 21:22:42 [INFO]: Epoch 043 - generator training loss: -0.0429, discriminator training loss: 0.1118, validation loss: 0.0263
2024-05-22 21:22:49 [INFO]: Epoch 044 - generator training loss: -0.0400, discriminator training loss: 0.1110, validation loss: 0.0268
2024-05-22 21:22:56 [INFO]: Epoch 045 - generator training loss: -0.0425, discriminator training loss: 0.1099, validation loss: 0.0263
2024-05-22 21:23:03 [INFO]: Epoch 046 - generator training loss: -0.0414, discriminator training loss: 0.1109, validation loss: 0.0267
2024-05-22 21:23:10 [INFO]: Epoch 047 - generator training loss: -0.0439, discriminator training loss: 0.1119, validation loss: 0.0267
2024-05-22 21:23:17 [INFO]: Epoch 048 - generator training loss: -0.0397, discriminator training loss: 0.1103, validation loss: 0.0267
2024-05-22 21:23:24 [INFO]: Epoch 049 - generator training loss: -0.0401, discriminator training loss: 0.1099, validation loss: 0.0264
2024-05-22 21:23:31 [INFO]: Epoch 050 - generator training loss: -0.0427, discriminator training loss: 0.1094, validation loss: 0.0264
2024-05-22 21:23:38 [INFO]: Epoch 051 - generator training loss: -0.0446, discriminator training loss: 0.1103, validation loss: 0.0260
2024-05-22 21:23:45 [INFO]: Epoch 052 - generator training loss: -0.0450, discriminator training loss: 0.1107, validation loss: 0.0259
2024-05-22 21:23:52 [INFO]: Epoch 053 - generator training loss: -0.0445, discriminator training loss: 0.1098, validation loss: 0.0268
2024-05-22 21:23:59 [INFO]: Epoch 054 - generator training loss: -0.0418, discriminator training loss: 0.1095, validation loss: 0.0257
2024-05-22 21:24:05 [INFO]: Epoch 055 - generator training loss: -0.0443, discriminator training loss: 0.1133, validation loss: 0.0261
2024-05-22 21:24:12 [INFO]: Epoch 056 - generator training loss: -0.0446, discriminator training loss: 0.1109, validation loss: 0.0257
2024-05-22 21:24:19 [INFO]: Epoch 057 - generator training loss: -0.0422, discriminator training loss: 0.1095, validation loss: 0.0267
2024-05-22 21:24:26 [INFO]: Epoch 058 - generator training loss: -0.0417, discriminator training loss: 0.1066, validation loss: 0.0260
2024-05-22 21:24:33 [INFO]: Epoch 059 - generator training loss: -0.0433, discriminator training loss: 0.1080, validation loss: 0.0266
2024-05-22 21:24:40 [INFO]: Epoch 060 - generator training loss: -0.0423, discriminator training loss: 0.1087, validation loss: 0.0265
2024-05-22 21:24:47 [INFO]: Epoch 061 - generator training loss: -0.0441, discriminator training loss: 0.1097, validation loss: 0.0250
2024-05-22 21:24:54 [INFO]: Epoch 062 - generator training loss: -0.0476, discriminator training loss: 0.1091, validation loss: 0.0250
2024-05-22 21:25:01 [INFO]: Epoch 063 - generator training loss: -0.0414, discriminator training loss: 0.1079, validation loss: 0.0251
2024-05-22 21:25:08 [INFO]: Epoch 064 - generator training loss: -0.0434, discriminator training loss: 0.1087, validation loss: 0.0254
2024-05-22 21:25:15 [INFO]: Epoch 065 - generator training loss: -0.0483, discriminator training loss: 0.1092, validation loss: 0.0246
2024-05-22 21:25:22 [INFO]: Epoch 066 - generator training loss: -0.0449, discriminator training loss: 0.1062, validation loss: 0.0258
2024-05-22 21:25:29 [INFO]: Epoch 067 - generator training loss: -0.0458, discriminator training loss: 0.1078, validation loss: 0.0246
2024-05-22 21:25:36 [INFO]: Epoch 068 - generator training loss: -0.0443, discriminator training loss: 0.1061, validation loss: 0.0255
2024-05-22 21:25:43 [INFO]: Epoch 069 - generator training loss: -0.0451, discriminator training loss: 0.1076, validation loss: 0.0245
2024-05-22 21:25:50 [INFO]: Epoch 070 - generator training loss: -0.0450, discriminator training loss: 0.1072, validation loss: 0.0254
2024-05-22 21:25:57 [INFO]: Epoch 071 - generator training loss: -0.0486, discriminator training loss: 0.1095, validation loss: 0.0239
2024-05-22 21:26:03 [INFO]: Epoch 072 - generator training loss: -0.0447, discriminator training loss: 0.1087, validation loss: 0.0244
2024-05-22 21:26:10 [INFO]: Epoch 073 - generator training loss: -0.0445, discriminator training loss: 0.1079, validation loss: 0.0244
2024-05-22 21:26:17 [INFO]: Epoch 074 - generator training loss: -0.0447, discriminator training loss: 0.1089, validation loss: 0.0239
2024-05-22 21:26:24 [INFO]: Epoch 075 - generator training loss: -0.0443, discriminator training loss: 0.1086, validation loss: 0.0243
2024-05-22 21:26:31 [INFO]: Epoch 076 - generator training loss: -0.0471, discriminator training loss: 0.1076, validation loss: 0.0240
2024-05-22 21:26:38 [INFO]: Epoch 077 - generator training loss: -0.0442, discriminator training loss: 0.1074, validation loss: 0.0244
2024-05-22 21:26:45 [INFO]: Epoch 078 - generator training loss: -0.0449, discriminator training loss: 0.1081, validation loss: 0.0236
2024-05-22 21:26:52 [INFO]: Epoch 079 - generator training loss: -0.0414, discriminator training loss: 0.1081, validation loss: 0.0245
2024-05-22 21:26:59 [INFO]: Epoch 080 - generator training loss: -0.0440, discriminator training loss: 0.1077, validation loss: 0.0230
2024-05-22 21:27:06 [INFO]: Epoch 081 - generator training loss: -0.0486, discriminator training loss: 0.1078, validation loss: 0.0236
2024-05-22 21:27:13 [INFO]: Epoch 082 - generator training loss: -0.0467, discriminator training loss: 0.1077, validation loss: 0.0236
2024-05-22 21:27:20 [INFO]: Epoch 083 - generator training loss: -0.0436, discriminator training loss: 0.1078, validation loss: 0.0241
2024-05-22 21:27:27 [INFO]: Epoch 084 - generator training loss: -0.0451, discriminator training loss: 0.1060, validation loss: 0.0233
2024-05-22 21:27:34 [INFO]: Epoch 085 - generator training loss: -0.0496, discriminator training loss: 0.1101, validation loss: 0.0238
2024-05-22 21:27:41 [INFO]: Epoch 086 - generator training loss: -0.0457, discriminator training loss: 0.1067, validation loss: 0.0249
2024-05-22 21:27:48 [INFO]: Epoch 087 - generator training loss: -0.0463, discriminator training loss: 0.1070, validation loss: 0.0240
2024-05-22 21:27:55 [INFO]: Epoch 088 - generator training loss: -0.0461, discriminator training loss: 0.1079, validation loss: 0.0236
2024-05-22 21:28:02 [INFO]: Epoch 089 - generator training loss: -0.0448, discriminator training loss: 0.1084, validation loss: 0.0233
2024-05-22 21:28:09 [INFO]: Epoch 090 - generator training loss: -0.0469, discriminator training loss: 0.1089, validation loss: 0.0234
2024-05-22 21:28:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:28:09 [INFO]: Finished training. The best model is from epoch#80.
2024-05-22 21:28:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/USGAN_ettm1/20240522_T211743/USGAN.pypots
2024-05-22 21:28:10 [INFO]: US-GAN on ETTm1: MAE=0.1548, MSE=0.0600
2024-05-22 21:28:10 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/USGAN_ettm1/imputation.pkl
2024-05-22 21:28:10 [INFO]: Using the given device: cuda:0
2024-05-22 21:28:10 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/BRITS_ettm1/20240522_T212810
2024-05-22 21:28:10 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/BRITS_ettm1/20240522_T212810/tensorboard
2024-05-22 21:28:10 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 21:28:15 [INFO]: Epoch 001 - training loss: 1.2861, validation loss: 0.3082
2024-05-22 21:28:20 [INFO]: Epoch 002 - training loss: 0.8442, validation loss: 0.0914
2024-05-22 21:28:24 [INFO]: Epoch 003 - training loss: 0.6659, validation loss: 0.0565
2024-05-22 21:28:29 [INFO]: Epoch 004 - training loss: 0.6086, validation loss: 0.0438
2024-05-22 21:28:34 [INFO]: Epoch 005 - training loss: 0.5872, validation loss: 0.0420
2024-05-22 21:28:38 [INFO]: Epoch 006 - training loss: 0.5556, validation loss: 0.0395
2024-05-22 21:28:43 [INFO]: Epoch 007 - training loss: 0.5314, validation loss: 0.0368
2024-05-22 21:28:47 [INFO]: Epoch 008 - training loss: 0.4936, validation loss: 0.0345
2024-05-22 21:28:52 [INFO]: Epoch 009 - training loss: 0.4670, validation loss: 0.0324
2024-05-22 21:28:57 [INFO]: Epoch 010 - training loss: 0.4536, validation loss: 0.0320
2024-05-22 21:29:01 [INFO]: Epoch 011 - training loss: 0.4373, validation loss: 0.0288
2024-05-22 21:29:06 [INFO]: Epoch 012 - training loss: 0.4253, validation loss: 0.0279
2024-05-22 21:29:10 [INFO]: Epoch 013 - training loss: 0.4237, validation loss: 0.0272
2024-05-22 21:29:15 [INFO]: Epoch 014 - training loss: 0.4039, validation loss: 0.0272
2024-05-22 21:29:20 [INFO]: Epoch 015 - training loss: 0.3979, validation loss: 0.0271
2024-05-22 21:29:24 [INFO]: Epoch 016 - training loss: 0.3935, validation loss: 0.0264
2024-05-22 21:29:29 [INFO]: Epoch 017 - training loss: 0.4004, validation loss: 0.0265
2024-05-22 21:29:33 [INFO]: Epoch 018 - training loss: 0.3987, validation loss: 0.0276
2024-05-22 21:29:38 [INFO]: Epoch 019 - training loss: 0.3966, validation loss: 0.0268
2024-05-22 21:29:42 [INFO]: Epoch 020 - training loss: 0.3908, validation loss: 0.0257
2024-05-22 21:29:47 [INFO]: Epoch 021 - training loss: 0.4428, validation loss: 0.0257
2024-05-22 21:29:51 [INFO]: Epoch 022 - training loss: 0.4201, validation loss: 0.0276
2024-05-22 21:29:56 [INFO]: Epoch 023 - training loss: 0.3985, validation loss: 0.0257
2024-05-22 21:30:00 [INFO]: Epoch 024 - training loss: 0.3870, validation loss: 0.0256
2024-05-22 21:30:05 [INFO]: Epoch 025 - training loss: 0.3848, validation loss: 0.0252
2024-05-22 21:30:10 [INFO]: Epoch 026 - training loss: 0.3810, validation loss: 0.0249
2024-05-22 21:30:14 [INFO]: Epoch 027 - training loss: 0.3843, validation loss: 0.0251
2024-05-22 21:30:19 [INFO]: Epoch 028 - training loss: 0.3803, validation loss: 0.0251
2024-05-22 21:30:23 [INFO]: Epoch 029 - training loss: 0.3814, validation loss: 0.0247
2024-05-22 21:30:28 [INFO]: Epoch 030 - training loss: 0.3805, validation loss: 0.0245
2024-05-22 21:30:32 [INFO]: Epoch 031 - training loss: 0.3800, validation loss: 0.0245
2024-05-22 21:30:37 [INFO]: Epoch 032 - training loss: 0.3755, validation loss: 0.0248
2024-05-22 21:30:42 [INFO]: Epoch 033 - training loss: 0.3893, validation loss: 0.0247
2024-05-22 21:30:46 [INFO]: Epoch 034 - training loss: 0.3920, validation loss: 0.0248
2024-05-22 21:30:51 [INFO]: Epoch 035 - training loss: 0.3859, validation loss: 0.0250
2024-05-22 21:30:55 [INFO]: Epoch 036 - training loss: 0.3778, validation loss: 0.0247
2024-05-22 21:31:00 [INFO]: Epoch 037 - training loss: 0.3932, validation loss: 0.0261
2024-05-22 21:31:04 [INFO]: Epoch 038 - training loss: 0.3836, validation loss: 0.0245
2024-05-22 21:31:09 [INFO]: Epoch 039 - training loss: 0.3823, validation loss: 0.0249
2024-05-22 21:31:14 [INFO]: Epoch 040 - training loss: 0.3752, validation loss: 0.0245
2024-05-22 21:31:18 [INFO]: Epoch 041 - training loss: 0.3748, validation loss: 0.0246
2024-05-22 21:31:23 [INFO]: Epoch 042 - training loss: 0.3731, validation loss: 0.0250
2024-05-22 21:31:27 [INFO]: Epoch 043 - training loss: 0.3703, validation loss: 0.0244
2024-05-22 21:31:32 [INFO]: Epoch 044 - training loss: 0.3785, validation loss: 0.0245
2024-05-22 21:31:36 [INFO]: Epoch 045 - training loss: 0.3739, validation loss: 0.0240
2024-05-22 21:31:41 [INFO]: Epoch 046 - training loss: 0.3742, validation loss: 0.0248
2024-05-22 21:31:45 [INFO]: Epoch 047 - training loss: 0.3747, validation loss: 0.0246
2024-05-22 21:31:50 [INFO]: Epoch 048 - training loss: 0.4296, validation loss: 0.0250
2024-05-22 21:31:54 [INFO]: Epoch 049 - training loss: 0.4022, validation loss: 0.0292
2024-05-22 21:31:59 [INFO]: Epoch 050 - training loss: 0.3830, validation loss: 0.0259
2024-05-22 21:32:04 [INFO]: Epoch 051 - training loss: 0.3840, validation loss: 0.0251
2024-05-22 21:32:08 [INFO]: Epoch 052 - training loss: 0.3724, validation loss: 0.0251
2024-05-22 21:32:13 [INFO]: Epoch 053 - training loss: 0.3718, validation loss: 0.0246
2024-05-22 21:32:17 [INFO]: Epoch 054 - training loss: 0.3798, validation loss: 0.0251
2024-05-22 21:32:22 [INFO]: Epoch 055 - training loss: 0.3849, validation loss: 0.0247
2024-05-22 21:32:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:32:22 [INFO]: Finished training. The best model is from epoch#45.
2024-05-22 21:32:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/BRITS_ettm1/20240522_T212810/BRITS.pypots
2024-05-22 21:32:22 [INFO]: BRITS on ETTm1: MAE=0.1405, MSE=0.0580
2024-05-22 21:32:22 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/BRITS_ettm1/imputation.pkl
2024-05-22 21:32:22 [INFO]: Using the given device: cuda:0
2024-05-22 21:32:22 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222
2024-05-22 21:32:22 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/tensorboard
2024-05-22 21:32:22 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 21:32:24 [INFO]: Epoch 001 - training loss: 1.3783, validation loss: 1.3062
2024-05-22 21:32:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch1_loss1.306246429681778.pypots
2024-05-22 21:32:24 [INFO]: Epoch 002 - training loss: 1.0354, validation loss: 1.1488
2024-05-22 21:32:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch2_loss1.1488082259893417.pypots
2024-05-22 21:32:24 [INFO]: Epoch 003 - training loss: 0.9849, validation loss: 1.0640
2024-05-22 21:32:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch3_loss1.0639891773462296.pypots
2024-05-22 21:32:24 [INFO]: Epoch 004 - training loss: 0.9390, validation loss: 1.0285
2024-05-22 21:32:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch4_loss1.028458908200264.pypots
2024-05-22 21:32:24 [INFO]: Epoch 005 - training loss: 0.9267, validation loss: 1.0107
2024-05-22 21:32:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch5_loss1.0107233673334122.pypots
2024-05-22 21:32:25 [INFO]: Epoch 006 - training loss: 0.9400, validation loss: 0.9993
2024-05-22 21:32:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch6_loss0.9993311017751694.pypots
2024-05-22 21:32:25 [INFO]: Epoch 007 - training loss: 0.9013, validation loss: 0.9884
2024-05-22 21:32:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch7_loss0.9883634448051453.pypots
2024-05-22 21:32:25 [INFO]: Epoch 008 - training loss: 0.9214, validation loss: 0.9828
2024-05-22 21:32:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch8_loss0.9828373193740845.pypots
2024-05-22 21:32:25 [INFO]: Epoch 009 - training loss: 0.8953, validation loss: 0.9785
2024-05-22 21:32:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch9_loss0.9784841984510422.pypots
2024-05-22 21:32:25 [INFO]: Epoch 010 - training loss: 0.9033, validation loss: 0.9765
2024-05-22 21:32:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch10_loss0.9764695018529892.pypots
2024-05-22 21:32:25 [INFO]: Epoch 011 - training loss: 0.9091, validation loss: 0.9712
2024-05-22 21:32:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch11_loss0.9711871147155762.pypots
2024-05-22 21:32:25 [INFO]: Epoch 012 - training loss: 0.9196, validation loss: 0.9706
2024-05-22 21:32:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch12_loss0.9705915600061417.pypots
2024-05-22 21:32:26 [INFO]: Epoch 013 - training loss: 0.8641, validation loss: 0.9704
2024-05-22 21:32:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch13_loss0.9704060703516006.pypots
2024-05-22 21:32:26 [INFO]: Epoch 014 - training loss: 0.8890, validation loss: 0.9672
2024-05-22 21:32:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch14_loss0.9672246277332306.pypots
2024-05-22 21:32:26 [INFO]: Epoch 015 - training loss: 0.8943, validation loss: 0.9640
2024-05-22 21:32:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch15_loss0.9640303403139114.pypots
2024-05-22 21:32:26 [INFO]: Epoch 016 - training loss: 0.8552, validation loss: 0.9626
2024-05-22 21:32:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch16_loss0.9626462757587433.pypots
2024-05-22 21:32:26 [INFO]: Epoch 017 - training loss: 0.8594, validation loss: 0.9590
2024-05-22 21:32:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch17_loss0.95899398624897.pypots
2024-05-22 21:32:26 [INFO]: Epoch 018 - training loss: 0.8443, validation loss: 0.9548
2024-05-22 21:32:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch18_loss0.9548132866621017.pypots
2024-05-22 21:32:27 [INFO]: Epoch 019 - training loss: 0.8350, validation loss: 0.9527
2024-05-22 21:32:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch19_loss0.9526612013578415.pypots
2024-05-22 21:32:27 [INFO]: Epoch 020 - training loss: 0.8361, validation loss: 0.9499
2024-05-22 21:32:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch20_loss0.949862077832222.pypots
2024-05-22 21:32:27 [INFO]: Epoch 021 - training loss: 0.8473, validation loss: 0.9472
2024-05-22 21:32:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch21_loss0.9471700340509415.pypots
2024-05-22 21:32:27 [INFO]: Epoch 022 - training loss: 0.8355, validation loss: 0.9430
2024-05-22 21:32:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch22_loss0.9429842233657837.pypots
2024-05-22 21:32:27 [INFO]: Epoch 023 - training loss: 0.8352, validation loss: 0.9395
2024-05-22 21:32:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch23_loss0.9394534379243851.pypots
2024-05-22 21:32:27 [INFO]: Epoch 024 - training loss: 0.8360, validation loss: 0.9365
2024-05-22 21:32:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch24_loss0.9364596754312515.pypots
2024-05-22 21:32:27 [INFO]: Epoch 025 - training loss: 0.8376, validation loss: 0.9322
2024-05-22 21:32:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch25_loss0.9322236329317093.pypots
2024-05-22 21:32:28 [INFO]: Epoch 026 - training loss: 0.8163, validation loss: 0.9286
2024-05-22 21:32:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch26_loss0.9286138564348221.pypots
2024-05-22 21:32:28 [INFO]: Epoch 027 - training loss: 0.8313, validation loss: 0.9256
2024-05-22 21:32:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch27_loss0.925630122423172.pypots
2024-05-22 21:32:28 [INFO]: Epoch 028 - training loss: 0.8199, validation loss: 0.9245
2024-05-22 21:32:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch28_loss0.9244582504034042.pypots
2024-05-22 21:32:28 [INFO]: Epoch 029 - training loss: 0.8049, validation loss: 0.9191
2024-05-22 21:32:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch29_loss0.9190960675477982.pypots
2024-05-22 21:32:28 [INFO]: Epoch 030 - training loss: 0.8122, validation loss: 0.9173
2024-05-22 21:32:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch30_loss0.9172913432121277.pypots
2024-05-22 21:32:28 [INFO]: Epoch 031 - training loss: 0.8172, validation loss: 0.9158
2024-05-22 21:32:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch31_loss0.9157991856336594.pypots
2024-05-22 21:32:29 [INFO]: Epoch 032 - training loss: 0.7995, validation loss: 0.9134
2024-05-22 21:32:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch32_loss0.9134053140878677.pypots
2024-05-22 21:32:29 [INFO]: Epoch 033 - training loss: 0.7968, validation loss: 0.9106
2024-05-22 21:32:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch33_loss0.9106378108263016.pypots
2024-05-22 21:32:29 [INFO]: Epoch 034 - training loss: 0.8132, validation loss: 0.9107
2024-05-22 21:32:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch34_loss0.9106931537389755.pypots
2024-05-22 21:32:29 [INFO]: Epoch 035 - training loss: 0.8031, validation loss: 0.9069
2024-05-22 21:32:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch35_loss0.9069283753633499.pypots
2024-05-22 21:32:29 [INFO]: Epoch 036 - training loss: 0.7967, validation loss: 0.9049
2024-05-22 21:32:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch36_loss0.9049077481031418.pypots
2024-05-22 21:32:29 [INFO]: Epoch 037 - training loss: 0.8051, validation loss: 0.9035
2024-05-22 21:32:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch37_loss0.9035044759511948.pypots
2024-05-22 21:32:30 [INFO]: Epoch 038 - training loss: 0.8092, validation loss: 0.9034
2024-05-22 21:32:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch38_loss0.9034002870321274.pypots
2024-05-22 21:32:30 [INFO]: Epoch 039 - training loss: 0.7849, validation loss: 0.9008
2024-05-22 21:32:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch39_loss0.9008089005947113.pypots
2024-05-22 21:32:30 [INFO]: Epoch 040 - training loss: 0.8109, validation loss: 0.8980
2024-05-22 21:32:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch40_loss0.8980145305395126.pypots
2024-05-22 21:32:30 [INFO]: Epoch 041 - training loss: 0.8001, validation loss: 0.8963
2024-05-22 21:32:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch41_loss0.8963070809841156.pypots
2024-05-22 21:32:30 [INFO]: Epoch 042 - training loss: 0.7894, validation loss: 0.8935
2024-05-22 21:32:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch42_loss0.8935444951057434.pypots
2024-05-22 21:32:30 [INFO]: Epoch 043 - training loss: 0.8058, validation loss: 0.8925
2024-05-22 21:32:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch43_loss0.8925135135650635.pypots
2024-05-22 21:32:30 [INFO]: Epoch 044 - training loss: 0.7796, validation loss: 0.8927
2024-05-22 21:32:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch44_loss0.8926929086446762.pypots
2024-05-22 21:32:31 [INFO]: Epoch 045 - training loss: 0.8046, validation loss: 0.8911
2024-05-22 21:32:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch45_loss0.8910669237375259.pypots
2024-05-22 21:32:31 [INFO]: Epoch 046 - training loss: 0.7914, validation loss: 0.8898
2024-05-22 21:32:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch46_loss0.8898096084594727.pypots
2024-05-22 21:32:31 [INFO]: Epoch 047 - training loss: 0.7902, validation loss: 0.8863
2024-05-22 21:32:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch47_loss0.8863072246313095.pypots
2024-05-22 21:32:31 [INFO]: Epoch 048 - training loss: 0.7958, validation loss: 0.8856
2024-05-22 21:32:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch48_loss0.8856139034032822.pypots
2024-05-22 21:32:31 [INFO]: Epoch 049 - training loss: 0.8087, validation loss: 0.8857
2024-05-22 21:32:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch49_loss0.8857265710830688.pypots
2024-05-22 21:32:31 [INFO]: Epoch 050 - training loss: 0.8152, validation loss: 0.8856
2024-05-22 21:32:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch50_loss0.8855902701616287.pypots
2024-05-22 21:32:32 [INFO]: Epoch 051 - training loss: 0.7895, validation loss: 0.8839
2024-05-22 21:32:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch51_loss0.8838550448417664.pypots
2024-05-22 21:32:32 [INFO]: Epoch 052 - training loss: 0.7871, validation loss: 0.8826
2024-05-22 21:32:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch52_loss0.8825909644365311.pypots
2024-05-22 21:32:32 [INFO]: Epoch 053 - training loss: 0.7803, validation loss: 0.8806
2024-05-22 21:32:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch53_loss0.8805905878543854.pypots
2024-05-22 21:32:32 [INFO]: Epoch 054 - training loss: 0.7581, validation loss: 0.8810
2024-05-22 21:32:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch54_loss0.8810123056173325.pypots
2024-05-22 21:32:32 [INFO]: Epoch 055 - training loss: 0.7650, validation loss: 0.8828
2024-05-22 21:32:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch55_loss0.8827714025974274.pypots
2024-05-22 21:32:32 [INFO]: Epoch 056 - training loss: 0.7734, validation loss: 0.8798
2024-05-22 21:32:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch56_loss0.8797738403081894.pypots
2024-05-22 21:32:33 [INFO]: Epoch 057 - training loss: 0.7817, validation loss: 0.8786
2024-05-22 21:32:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch57_loss0.8786108642816544.pypots
2024-05-22 21:32:33 [INFO]: Epoch 058 - training loss: 0.7827, validation loss: 0.8766
2024-05-22 21:32:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch58_loss0.8765530586242676.pypots
2024-05-22 21:32:33 [INFO]: Epoch 059 - training loss: 0.7789, validation loss: 0.8759
2024-05-22 21:32:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch59_loss0.8759321868419647.pypots
2024-05-22 21:32:33 [INFO]: Epoch 060 - training loss: 0.7605, validation loss: 0.8749
2024-05-22 21:32:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch60_loss0.8749319314956665.pypots
2024-05-22 21:32:33 [INFO]: Epoch 061 - training loss: 0.7853, validation loss: 0.8722
2024-05-22 21:32:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch61_loss0.8722374588251114.pypots
2024-05-22 21:32:33 [INFO]: Epoch 062 - training loss: 0.7749, validation loss: 0.8744
2024-05-22 21:32:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch62_loss0.8744142353534698.pypots
2024-05-22 21:32:33 [INFO]: Epoch 063 - training loss: 0.7551, validation loss: 0.8719
2024-05-22 21:32:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch63_loss0.8719089776277542.pypots
2024-05-22 21:32:34 [INFO]: Epoch 064 - training loss: 0.8137, validation loss: 0.8731
2024-05-22 21:32:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch64_loss0.8730889707803726.pypots
2024-05-22 21:32:34 [INFO]: Epoch 065 - training loss: 0.7811, validation loss: 0.8710
2024-05-22 21:32:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch65_loss0.8709714710712433.pypots
2024-05-22 21:32:34 [INFO]: Epoch 066 - training loss: 0.7822, validation loss: 0.8693
2024-05-22 21:32:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch66_loss0.8693224489688873.pypots
2024-05-22 21:32:34 [INFO]: Epoch 067 - training loss: 0.7644, validation loss: 0.8678
2024-05-22 21:32:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch67_loss0.8677826225757599.pypots
2024-05-22 21:32:34 [INFO]: Epoch 068 - training loss: 0.7857, validation loss: 0.8686
2024-05-22 21:32:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch68_loss0.868561714887619.pypots
2024-05-22 21:32:34 [INFO]: Epoch 069 - training loss: 0.7695, validation loss: 0.8681
2024-05-22 21:32:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch69_loss0.868096649646759.pypots
2024-05-22 21:32:35 [INFO]: Epoch 070 - training loss: 0.7491, validation loss: 0.8689
2024-05-22 21:32:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch70_loss0.8689150810241699.pypots
2024-05-22 21:32:35 [INFO]: Epoch 071 - training loss: 0.7625, validation loss: 0.8674
2024-05-22 21:32:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch71_loss0.8673890084028244.pypots
2024-05-22 21:32:35 [INFO]: Epoch 072 - training loss: 0.7706, validation loss: 0.8674
2024-05-22 21:32:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch72_loss0.8674192130565643.pypots
2024-05-22 21:32:35 [INFO]: Epoch 073 - training loss: 0.7850, validation loss: 0.8671
2024-05-22 21:32:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch73_loss0.8671193569898605.pypots
2024-05-22 21:32:35 [INFO]: Epoch 074 - training loss: 0.7735, validation loss: 0.8647
2024-05-22 21:32:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch74_loss0.8646513819694519.pypots
2024-05-22 21:32:35 [INFO]: Epoch 075 - training loss: 0.7821, validation loss: 0.8668
2024-05-22 21:32:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch75_loss0.8668027967214584.pypots
2024-05-22 21:32:35 [INFO]: Epoch 076 - training loss: 0.7702, validation loss: 0.8646
2024-05-22 21:32:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch76_loss0.8645761013031006.pypots
2024-05-22 21:32:36 [INFO]: Epoch 077 - training loss: 0.7712, validation loss: 0.8645
2024-05-22 21:32:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch77_loss0.864524632692337.pypots
2024-05-22 21:32:36 [INFO]: Epoch 078 - training loss: 0.7668, validation loss: 0.8627
2024-05-22 21:32:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch78_loss0.8627043217420578.pypots
2024-05-22 21:32:36 [INFO]: Epoch 079 - training loss: 0.7704, validation loss: 0.8648
2024-05-22 21:32:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch79_loss0.8648170083761215.pypots
2024-05-22 21:32:36 [INFO]: Epoch 080 - training loss: 0.7779, validation loss: 0.8626
2024-05-22 21:32:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch80_loss0.8625516891479492.pypots
2024-05-22 21:32:36 [INFO]: Epoch 081 - training loss: 0.7564, validation loss: 0.8630
2024-05-22 21:32:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch81_loss0.8630106151103973.pypots
2024-05-22 21:32:36 [INFO]: Epoch 082 - training loss: 0.7819, validation loss: 0.8630
2024-05-22 21:32:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch82_loss0.8629704266786575.pypots
2024-05-22 21:32:37 [INFO]: Epoch 083 - training loss: 0.7754, validation loss: 0.8622
2024-05-22 21:32:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch83_loss0.8622231930494308.pypots
2024-05-22 21:32:37 [INFO]: Epoch 084 - training loss: 0.7667, validation loss: 0.8617
2024-05-22 21:32:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch84_loss0.8617329895496368.pypots
2024-05-22 21:32:37 [INFO]: Epoch 085 - training loss: 0.7687, validation loss: 0.8602
2024-05-22 21:32:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch85_loss0.8601924479007721.pypots
2024-05-22 21:32:37 [INFO]: Epoch 086 - training loss: 0.7513, validation loss: 0.8596
2024-05-22 21:32:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch86_loss0.8596408516168594.pypots
2024-05-22 21:32:37 [INFO]: Epoch 087 - training loss: 0.7820, validation loss: 0.8582
2024-05-22 21:32:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch87_loss0.8581847995519638.pypots
2024-05-22 21:32:37 [INFO]: Epoch 088 - training loss: 0.7643, validation loss: 0.8578
2024-05-22 21:32:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch88_loss0.8578466922044754.pypots
2024-05-22 21:32:37 [INFO]: Epoch 089 - training loss: 0.7653, validation loss: 0.8584
2024-05-22 21:32:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch89_loss0.858354926109314.pypots
2024-05-22 21:32:38 [INFO]: Epoch 090 - training loss: 0.7778, validation loss: 0.8539
2024-05-22 21:32:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch90_loss0.8539174348115921.pypots
2024-05-22 21:32:38 [INFO]: Epoch 091 - training loss: 0.7616, validation loss: 0.8551
2024-05-22 21:32:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch91_loss0.8551499545574188.pypots
2024-05-22 21:32:38 [INFO]: Epoch 092 - training loss: 0.7830, validation loss: 0.8550
2024-05-22 21:32:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch92_loss0.8550284951925278.pypots
2024-05-22 21:32:38 [INFO]: Epoch 093 - training loss: 0.7701, validation loss: 0.8566
2024-05-22 21:32:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch93_loss0.8566110581159592.pypots
2024-05-22 21:32:38 [INFO]: Epoch 094 - training loss: 0.7492, validation loss: 0.8541
2024-05-22 21:32:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch94_loss0.8541072309017181.pypots
2024-05-22 21:32:38 [INFO]: Epoch 095 - training loss: 0.7741, validation loss: 0.8561
2024-05-22 21:32:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch95_loss0.8560920506715775.pypots
2024-05-22 21:32:39 [INFO]: Epoch 096 - training loss: 0.7652, validation loss: 0.8551
2024-05-22 21:32:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch96_loss0.855100080370903.pypots
2024-05-22 21:32:39 [INFO]: Epoch 097 - training loss: 0.7672, validation loss: 0.8575
2024-05-22 21:32:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch97_loss0.8575308918952942.pypots
2024-05-22 21:32:39 [INFO]: Epoch 098 - training loss: 0.7808, validation loss: 0.8529
2024-05-22 21:32:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch98_loss0.8529033809900284.pypots
2024-05-22 21:32:39 [INFO]: Epoch 099 - training loss: 0.7701, validation loss: 0.8536
2024-05-22 21:32:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch99_loss0.853606715798378.pypots
2024-05-22 21:32:39 [INFO]: Epoch 100 - training loss: 0.7522, validation loss: 0.8541
2024-05-22 21:32:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch100_loss0.8540941923856735.pypots
2024-05-22 21:32:39 [INFO]: Epoch 101 - training loss: 0.7930, validation loss: 0.8519
2024-05-22 21:32:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch101_loss0.8519336879253387.pypots
2024-05-22 21:32:40 [INFO]: Epoch 102 - training loss: 0.8010, validation loss: 0.8517
2024-05-22 21:32:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch102_loss0.8516938090324402.pypots
2024-05-22 21:32:40 [INFO]: Epoch 103 - training loss: 0.8060, validation loss: 0.8504
2024-05-22 21:32:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch103_loss0.8503811061382294.pypots
2024-05-22 21:32:40 [INFO]: Epoch 104 - training loss: 0.7632, validation loss: 0.8516
2024-05-22 21:32:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch104_loss0.851579412817955.pypots
2024-05-22 21:32:40 [INFO]: Epoch 105 - training loss: 0.7551, validation loss: 0.8508
2024-05-22 21:32:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch105_loss0.8508296459913254.pypots
2024-05-22 21:32:40 [INFO]: Epoch 106 - training loss: 0.7433, validation loss: 0.8474
2024-05-22 21:32:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch106_loss0.8473821729421616.pypots
2024-05-22 21:32:40 [INFO]: Epoch 107 - training loss: 0.7866, validation loss: 0.8492
2024-05-22 21:32:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch107_loss0.8491592854261398.pypots
2024-05-22 21:32:40 [INFO]: Epoch 108 - training loss: 0.7798, validation loss: 0.8468
2024-05-22 21:32:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch108_loss0.8467553555965424.pypots
2024-05-22 21:32:41 [INFO]: Epoch 109 - training loss: 0.7711, validation loss: 0.8473
2024-05-22 21:32:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch109_loss0.8473265171051025.pypots
2024-05-22 21:32:41 [INFO]: Epoch 110 - training loss: 0.7568, validation loss: 0.8461
2024-05-22 21:32:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch110_loss0.8461019396781921.pypots
2024-05-22 21:32:41 [INFO]: Epoch 111 - training loss: 0.7850, validation loss: 0.8456
2024-05-22 21:32:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch111_loss0.8455770760774612.pypots
2024-05-22 21:32:41 [INFO]: Epoch 112 - training loss: 0.7769, validation loss: 0.8499
2024-05-22 21:32:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch112_loss0.8498715162277222.pypots
2024-05-22 21:32:41 [INFO]: Epoch 113 - training loss: 0.7915, validation loss: 0.8471
2024-05-22 21:32:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch113_loss0.8470775932073593.pypots
2024-05-22 21:32:41 [INFO]: Epoch 114 - training loss: 0.7656, validation loss: 0.8451
2024-05-22 21:32:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch114_loss0.845084935426712.pypots
2024-05-22 21:32:42 [INFO]: Epoch 115 - training loss: 0.7509, validation loss: 0.8459
2024-05-22 21:32:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch115_loss0.8458802253007889.pypots
2024-05-22 21:32:42 [INFO]: Epoch 116 - training loss: 0.7731, validation loss: 0.8444
2024-05-22 21:32:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch116_loss0.8443665206432343.pypots
2024-05-22 21:32:42 [INFO]: Epoch 117 - training loss: 0.7663, validation loss: 0.8436
2024-05-22 21:32:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch117_loss0.8435584157705307.pypots
2024-05-22 21:32:42 [INFO]: Epoch 118 - training loss: 0.7695, validation loss: 0.8439
2024-05-22 21:32:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch118_loss0.8438981473445892.pypots
2024-05-22 21:32:42 [INFO]: Epoch 119 - training loss: 0.7653, validation loss: 0.8435
2024-05-22 21:32:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch119_loss0.8435463309288025.pypots
2024-05-22 21:32:42 [INFO]: Epoch 120 - training loss: 0.7609, validation loss: 0.8423
2024-05-22 21:32:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch120_loss0.842324510216713.pypots
2024-05-22 21:32:43 [INFO]: Epoch 121 - training loss: 0.7517, validation loss: 0.8409
2024-05-22 21:32:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch121_loss0.8409149795770645.pypots
2024-05-22 21:32:43 [INFO]: Epoch 122 - training loss: 0.7481, validation loss: 0.8415
2024-05-22 21:32:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch122_loss0.8414787352085114.pypots
2024-05-22 21:32:43 [INFO]: Epoch 123 - training loss: 0.7636, validation loss: 0.8419
2024-05-22 21:32:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch123_loss0.8418742120265961.pypots
2024-05-22 21:32:43 [INFO]: Epoch 124 - training loss: 0.7722, validation loss: 0.8402
2024-05-22 21:32:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch124_loss0.8401534557342529.pypots
2024-05-22 21:32:43 [INFO]: Epoch 125 - training loss: 0.7634, validation loss: 0.8419
2024-05-22 21:32:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch125_loss0.841914713382721.pypots
2024-05-22 21:32:43 [INFO]: Epoch 126 - training loss: 0.7973, validation loss: 0.8405
2024-05-22 21:32:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch126_loss0.8405245393514633.pypots
2024-05-22 21:32:43 [INFO]: Epoch 127 - training loss: 0.7528, validation loss: 0.8388
2024-05-22 21:32:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch127_loss0.8387745320796967.pypots
2024-05-22 21:32:44 [INFO]: Epoch 128 - training loss: 0.7697, validation loss: 0.8387
2024-05-22 21:32:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch128_loss0.8386559933423996.pypots
2024-05-22 21:32:44 [INFO]: Epoch 129 - training loss: 0.7585, validation loss: 0.8404
2024-05-22 21:32:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch129_loss0.8404348641633987.pypots
2024-05-22 21:32:44 [INFO]: Epoch 130 - training loss: 0.7520, validation loss: 0.8382
2024-05-22 21:32:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch130_loss0.8381617516279221.pypots
2024-05-22 21:32:44 [INFO]: Epoch 131 - training loss: 0.7630, validation loss: 0.8388
2024-05-22 21:32:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch131_loss0.8387638181447983.pypots
2024-05-22 21:32:44 [INFO]: Epoch 132 - training loss: 0.7593, validation loss: 0.8440
2024-05-22 21:32:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch132_loss0.8439810127019882.pypots
2024-05-22 21:32:44 [INFO]: Epoch 133 - training loss: 0.7615, validation loss: 0.8381
2024-05-22 21:32:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch133_loss0.8381422907114029.pypots
2024-05-22 21:32:45 [INFO]: Epoch 134 - training loss: 0.7679, validation loss: 0.8388
2024-05-22 21:32:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch134_loss0.8387815207242966.pypots
2024-05-22 21:32:45 [INFO]: Epoch 135 - training loss: 0.7803, validation loss: 0.8363
2024-05-22 21:32:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch135_loss0.8362972289323807.pypots
2024-05-22 21:32:45 [INFO]: Epoch 136 - training loss: 0.7659, validation loss: 0.8399
2024-05-22 21:32:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch136_loss0.8399095386266708.pypots
2024-05-22 21:32:45 [INFO]: Epoch 137 - training loss: 0.7731, validation loss: 0.8365
2024-05-22 21:32:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch137_loss0.836522564291954.pypots
2024-05-22 21:32:45 [INFO]: Epoch 138 - training loss: 0.7588, validation loss: 0.8370
2024-05-22 21:32:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch138_loss0.8370205610990524.pypots
2024-05-22 21:32:45 [INFO]: Epoch 139 - training loss: 0.7458, validation loss: 0.8363
2024-05-22 21:32:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch139_loss0.8362671732902527.pypots
2024-05-22 21:32:45 [INFO]: Epoch 140 - training loss: 0.7797, validation loss: 0.8361
2024-05-22 21:32:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch140_loss0.8360822647809982.pypots
2024-05-22 21:32:46 [INFO]: Epoch 141 - training loss: 0.7668, validation loss: 0.8339
2024-05-22 21:32:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch141_loss0.8338820487260818.pypots
2024-05-22 21:32:46 [INFO]: Epoch 142 - training loss: 0.7659, validation loss: 0.8341
2024-05-22 21:32:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch142_loss0.834088921546936.pypots
2024-05-22 21:32:46 [INFO]: Epoch 143 - training loss: 0.7596, validation loss: 0.8345
2024-05-22 21:32:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch143_loss0.8344927728176117.pypots
2024-05-22 21:32:46 [INFO]: Epoch 144 - training loss: 0.7683, validation loss: 0.8344
2024-05-22 21:32:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch144_loss0.834363266825676.pypots
2024-05-22 21:32:46 [INFO]: Epoch 145 - training loss: 0.7681, validation loss: 0.8331
2024-05-22 21:32:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch145_loss0.8330623209476471.pypots
2024-05-22 21:32:46 [INFO]: Epoch 146 - training loss: 0.7656, validation loss: 0.8325
2024-05-22 21:32:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch146_loss0.8324522376060486.pypots
2024-05-22 21:32:47 [INFO]: Epoch 147 - training loss: 0.8021, validation loss: 0.8327
2024-05-22 21:32:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch147_loss0.8326965272426605.pypots
2024-05-22 21:32:47 [INFO]: Epoch 148 - training loss: 0.7656, validation loss: 0.8312
2024-05-22 21:32:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch148_loss0.8311702013015747.pypots
2024-05-22 21:32:47 [INFO]: Epoch 149 - training loss: 0.7680, validation loss: 0.8313
2024-05-22 21:32:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch149_loss0.8312766849994659.pypots
2024-05-22 21:32:47 [INFO]: Epoch 150 - training loss: 0.7710, validation loss: 0.8300
2024-05-22 21:32:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch150_loss0.8300374746322632.pypots
2024-05-22 21:32:47 [INFO]: Epoch 151 - training loss: 0.7530, validation loss: 0.8324
2024-05-22 21:32:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch151_loss0.832448422908783.pypots
2024-05-22 21:32:47 [INFO]: Epoch 152 - training loss: 0.7502, validation loss: 0.8283
2024-05-22 21:32:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch152_loss0.8283113688230515.pypots
2024-05-22 21:32:48 [INFO]: Epoch 153 - training loss: 0.7874, validation loss: 0.8297
2024-05-22 21:32:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch153_loss0.8296606242656708.pypots
2024-05-22 21:32:48 [INFO]: Epoch 154 - training loss: 0.7613, validation loss: 0.8318
2024-05-22 21:32:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch154_loss0.8318151086568832.pypots
2024-05-22 21:32:48 [INFO]: Epoch 155 - training loss: 0.7542, validation loss: 0.8313
2024-05-22 21:32:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch155_loss0.8313476145267487.pypots
2024-05-22 21:32:48 [INFO]: Epoch 156 - training loss: 0.8000, validation loss: 0.8297
2024-05-22 21:32:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch156_loss0.8296567052602768.pypots
2024-05-22 21:32:48 [INFO]: Epoch 157 - training loss: 0.7841, validation loss: 0.8271
2024-05-22 21:32:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch157_loss0.82711461186409.pypots
2024-05-22 21:32:48 [INFO]: Epoch 158 - training loss: 0.7777, validation loss: 0.8301
2024-05-22 21:32:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch158_loss0.8301187604665756.pypots
2024-05-22 21:32:48 [INFO]: Epoch 159 - training loss: 0.7787, validation loss: 0.8291
2024-05-22 21:32:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch159_loss0.8290550410747528.pypots
2024-05-22 21:32:49 [INFO]: Epoch 160 - training loss: 0.7641, validation loss: 0.8267
2024-05-22 21:32:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch160_loss0.8266853988170624.pypots
2024-05-22 21:32:49 [INFO]: Epoch 161 - training loss: 0.7680, validation loss: 0.8247
2024-05-22 21:32:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch161_loss0.8247025310993195.pypots
2024-05-22 21:32:49 [INFO]: Epoch 162 - training loss: 0.7809, validation loss: 0.8301
2024-05-22 21:32:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch162_loss0.8300989717245102.pypots
2024-05-22 21:32:49 [INFO]: Epoch 163 - training loss: 0.7307, validation loss: 0.8274
2024-05-22 21:32:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch163_loss0.8273812681436539.pypots
2024-05-22 21:32:49 [INFO]: Epoch 164 - training loss: 0.7695, validation loss: 0.8277
2024-05-22 21:32:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch164_loss0.8277103453874588.pypots
2024-05-22 21:32:49 [INFO]: Epoch 165 - training loss: 0.7600, validation loss: 0.8273
2024-05-22 21:32:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch165_loss0.8273422569036484.pypots
2024-05-22 21:32:50 [INFO]: Epoch 166 - training loss: 0.7435, validation loss: 0.8251
2024-05-22 21:32:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch166_loss0.8250509947538376.pypots
2024-05-22 21:32:50 [INFO]: Epoch 167 - training loss: 0.7572, validation loss: 0.8234
2024-05-22 21:32:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch167_loss0.8234307765960693.pypots
2024-05-22 21:32:50 [INFO]: Epoch 168 - training loss: 0.7596, validation loss: 0.8237
2024-05-22 21:32:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch168_loss0.8237091302871704.pypots
2024-05-22 21:32:50 [INFO]: Epoch 169 - training loss: 0.7674, validation loss: 0.8245
2024-05-22 21:32:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch169_loss0.8244950920343399.pypots
2024-05-22 21:32:50 [INFO]: Epoch 170 - training loss: 0.7588, validation loss: 0.8240
2024-05-22 21:32:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch170_loss0.824023425579071.pypots
2024-05-22 21:32:50 [INFO]: Epoch 171 - training loss: 0.7606, validation loss: 0.8243
2024-05-22 21:32:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch171_loss0.8243088126182556.pypots
2024-05-22 21:32:50 [INFO]: Epoch 172 - training loss: 0.7688, validation loss: 0.8246
2024-05-22 21:32:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch172_loss0.8246276676654816.pypots
2024-05-22 21:32:51 [INFO]: Epoch 173 - training loss: 0.7516, validation loss: 0.8248
2024-05-22 21:32:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch173_loss0.8247687667608261.pypots
2024-05-22 21:32:51 [INFO]: Epoch 174 - training loss: 0.7571, validation loss: 0.8232
2024-05-22 21:32:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch174_loss0.8231882005929947.pypots
2024-05-22 21:32:51 [INFO]: Epoch 175 - training loss: 0.7562, validation loss: 0.8240
2024-05-22 21:32:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch175_loss0.8240271806716919.pypots
2024-05-22 21:32:51 [INFO]: Epoch 176 - training loss: 0.7368, validation loss: 0.8244
2024-05-22 21:32:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch176_loss0.8243864327669144.pypots
2024-05-22 21:32:51 [INFO]: Epoch 177 - training loss: 0.7375, validation loss: 0.8246
2024-05-22 21:32:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch177_loss0.8245673477649689.pypots
2024-05-22 21:32:51 [INFO]: Epoch 178 - training loss: 0.7547, validation loss: 0.8229
2024-05-22 21:32:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch178_loss0.8229093998670578.pypots
2024-05-22 21:32:52 [INFO]: Epoch 179 - training loss: 0.7757, validation loss: 0.8220
2024-05-22 21:32:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch179_loss0.8219713270664215.pypots
2024-05-22 21:32:52 [INFO]: Epoch 180 - training loss: 0.7492, validation loss: 0.8232
2024-05-22 21:32:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch180_loss0.8231775611639023.pypots
2024-05-22 21:32:52 [INFO]: Epoch 181 - training loss: 0.7644, validation loss: 0.8218
2024-05-22 21:32:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch181_loss0.8218106925487518.pypots
2024-05-22 21:32:52 [INFO]: Epoch 182 - training loss: 0.7759, validation loss: 0.8230
2024-05-22 21:32:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch182_loss0.8229829519987106.pypots
2024-05-22 21:32:52 [INFO]: Epoch 183 - training loss: 0.7641, validation loss: 0.8264
2024-05-22 21:32:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch183_loss0.8263539522886276.pypots
2024-05-22 21:32:52 [INFO]: Epoch 184 - training loss: 0.7610, validation loss: 0.8211
2024-05-22 21:32:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch184_loss0.8210535496473312.pypots
2024-05-22 21:32:53 [INFO]: Epoch 185 - training loss: 0.7556, validation loss: 0.8212
2024-05-22 21:32:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch185_loss0.8212475031614304.pypots
2024-05-22 21:32:53 [INFO]: Epoch 186 - training loss: 0.7507, validation loss: 0.8197
2024-05-22 21:32:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch186_loss0.819657176733017.pypots
2024-05-22 21:32:53 [INFO]: Epoch 187 - training loss: 0.7411, validation loss: 0.8249
2024-05-22 21:32:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch187_loss0.8248653262853622.pypots
2024-05-22 21:32:53 [INFO]: Epoch 188 - training loss: 0.7591, validation loss: 0.8228
2024-05-22 21:32:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch188_loss0.8227857500314713.pypots
2024-05-22 21:32:53 [INFO]: Epoch 189 - training loss: 0.7646, validation loss: 0.8196
2024-05-22 21:32:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch189_loss0.8196493834257126.pypots
2024-05-22 21:32:53 [INFO]: Epoch 190 - training loss: 0.7573, validation loss: 0.8202
2024-05-22 21:32:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch190_loss0.8201795220375061.pypots
2024-05-22 21:32:53 [INFO]: Epoch 191 - training loss: 0.7469, validation loss: 0.8214
2024-05-22 21:32:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch191_loss0.8214018642902374.pypots
2024-05-22 21:32:54 [INFO]: Epoch 192 - training loss: 0.7822, validation loss: 0.8205
2024-05-22 21:32:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch192_loss0.8205099105834961.pypots
2024-05-22 21:32:54 [INFO]: Epoch 193 - training loss: 0.7698, validation loss: 0.8163
2024-05-22 21:32:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch193_loss0.8163046836853027.pypots
2024-05-22 21:32:54 [INFO]: Epoch 194 - training loss: 0.7662, validation loss: 0.8160
2024-05-22 21:32:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch194_loss0.8159651309251785.pypots
2024-05-22 21:32:54 [INFO]: Epoch 195 - training loss: 0.7454, validation loss: 0.8175
2024-05-22 21:32:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch195_loss0.817527562379837.pypots
2024-05-22 21:32:54 [INFO]: Epoch 196 - training loss: 0.7467, validation loss: 0.8190
2024-05-22 21:32:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch196_loss0.818968266248703.pypots
2024-05-22 21:32:54 [INFO]: Epoch 197 - training loss: 0.7459, validation loss: 0.8218
2024-05-22 21:32:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch197_loss0.8217788934707642.pypots
2024-05-22 21:32:55 [INFO]: Epoch 198 - training loss: 0.7748, validation loss: 0.8220
2024-05-22 21:32:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch198_loss0.8220169395208359.pypots
2024-05-22 21:32:55 [INFO]: Epoch 199 - training loss: 0.7707, validation loss: 0.8195
2024-05-22 21:32:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch199_loss0.8194567561149597.pypots
2024-05-22 21:32:55 [INFO]: Epoch 200 - training loss: 0.7656, validation loss: 0.8207
2024-05-22 21:32:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch200_loss0.8206579089164734.pypots
2024-05-22 21:32:55 [INFO]: Epoch 201 - training loss: 0.7672, validation loss: 0.8212
2024-05-22 21:32:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch201_loss0.8211815804243088.pypots
2024-05-22 21:32:55 [INFO]: Epoch 202 - training loss: 0.7492, validation loss: 0.8177
2024-05-22 21:32:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch202_loss0.8177387714385986.pypots
2024-05-22 21:32:55 [INFO]: Epoch 203 - training loss: 0.7583, validation loss: 0.8172
2024-05-22 21:32:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch203_loss0.8171706348657608.pypots
2024-05-22 21:32:56 [INFO]: Epoch 204 - training loss: 0.7421, validation loss: 0.8219
2024-05-22 21:32:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN_epoch204_loss0.8218548595905304.pypots
2024-05-22 21:32:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:32:56 [INFO]: Finished training. The best model is from epoch#194.
2024-05-22 21:32:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240522_T213222/MRNN.pypots
2024-05-22 21:32:56 [INFO]: MRNN on ETTm1: MAE=0.6033, MSE=1.0228
2024-05-22 21:32:56 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/MRNN_ettm1/imputation.pkl
2024-05-22 21:32:56 [INFO]: Using the given device: cpu
2024-05-22 21:32:56 [INFO]: LOCF on ETTm1: MAE=0.1376, MSE=0.0773
2024-05-22 21:32:56 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_ettm1".
2024-05-22 21:32:56 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/LOCF_ettm1/imputation.pkl
2024-05-22 21:32:56 [INFO]: Median on ETTm1: MAE=0.6554, MSE=0.8235
2024-05-22 21:32:56 [INFO]: Successfully created the given path "saved_results/round_0/Median_ettm1".
2024-05-22 21:32:56 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Median_ettm1/imputation.pkl
2024-05-22 21:32:56 [INFO]: Mean on ETTm1: MAE=0.6609, MSE=0.8067
2024-05-22 21:32:56 [INFO]: Successfully created the given path "saved_results/round_0/Mean_ettm1".
2024-05-22 21:32:56 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Mean_ettm1/imputation.pkl
2024-05-22 21:32:56 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-22 21:32:56 [INFO]: Using the given device: cuda:0
2024-05-22 21:32:56 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/SAITS_ettm1/20240522_T213256
2024-05-22 21:32:56 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/SAITS_ettm1/20240522_T213256/tensorboard
2024-05-22 21:32:56 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 21:32:56 [INFO]: Epoch 001 - training loss: 1.1139, validation loss: 0.2726
2024-05-22 21:32:57 [INFO]: Epoch 002 - training loss: 0.8018, validation loss: 0.1329
2024-05-22 21:32:57 [INFO]: Epoch 003 - training loss: 0.7002, validation loss: 0.1000
2024-05-22 21:32:58 [INFO]: Epoch 004 - training loss: 0.6606, validation loss: 0.0973
2024-05-22 21:32:58 [INFO]: Epoch 005 - training loss: 0.6283, validation loss: 0.0784
2024-05-22 21:32:59 [INFO]: Epoch 006 - training loss: 0.5881, validation loss: 0.0640
2024-05-22 21:32:59 [INFO]: Epoch 007 - training loss: 0.5706, validation loss: 0.0641
2024-05-22 21:33:00 [INFO]: Epoch 008 - training loss: 0.5568, validation loss: 0.0700
2024-05-22 21:33:00 [INFO]: Epoch 009 - training loss: 0.5766, validation loss: 0.0730
2024-05-22 21:33:01 [INFO]: Epoch 010 - training loss: 0.5469, validation loss: 0.0547
2024-05-22 21:33:01 [INFO]: Epoch 011 - training loss: 0.5237, validation loss: 0.0525
2024-05-22 21:33:02 [INFO]: Epoch 012 - training loss: 0.5236, validation loss: 0.0585
2024-05-22 21:33:02 [INFO]: Epoch 013 - training loss: 0.5021, validation loss: 0.0554
2024-05-22 21:33:03 [INFO]: Epoch 014 - training loss: 0.4922, validation loss: 0.0496
2024-05-22 21:33:03 [INFO]: Epoch 015 - training loss: 0.4887, validation loss: 0.0632
2024-05-22 21:33:03 [INFO]: Epoch 016 - training loss: 0.4647, validation loss: 0.0528
2024-05-22 21:33:04 [INFO]: Epoch 017 - training loss: 0.4525, validation loss: 0.0471
2024-05-22 21:33:04 [INFO]: Epoch 018 - training loss: 0.4492, validation loss: 0.0588
2024-05-22 21:33:05 [INFO]: Epoch 019 - training loss: 0.4428, validation loss: 0.0479
2024-05-22 21:33:05 [INFO]: Epoch 020 - training loss: 0.4376, validation loss: 0.0421
2024-05-22 21:33:06 [INFO]: Epoch 021 - training loss: 0.4268, validation loss: 0.0501
2024-05-22 21:33:06 [INFO]: Epoch 022 - training loss: 0.4201, validation loss: 0.0420
2024-05-22 21:33:07 [INFO]: Epoch 023 - training loss: 0.4038, validation loss: 0.0466
2024-05-22 21:33:07 [INFO]: Epoch 024 - training loss: 0.3902, validation loss: 0.0432
2024-05-22 21:33:08 [INFO]: Epoch 025 - training loss: 0.3863, validation loss: 0.0406
2024-05-22 21:33:08 [INFO]: Epoch 026 - training loss: 0.3900, validation loss: 0.0897
2024-05-22 21:33:09 [INFO]: Epoch 027 - training loss: 0.4048, validation loss: 0.0536
2024-05-22 21:33:09 [INFO]: Epoch 028 - training loss: 0.3785, validation loss: 0.0580
2024-05-22 21:33:10 [INFO]: Epoch 029 - training loss: 0.3669, validation loss: 0.0428
2024-05-22 21:33:10 [INFO]: Epoch 030 - training loss: 0.3715, validation loss: 0.0454
2024-05-22 21:33:11 [INFO]: Epoch 031 - training loss: 0.3750, validation loss: 0.0406
2024-05-22 21:33:11 [INFO]: Epoch 032 - training loss: 0.3588, validation loss: 0.0459
2024-05-22 21:33:12 [INFO]: Epoch 033 - training loss: 0.3482, validation loss: 0.0514
2024-05-22 21:33:12 [INFO]: Epoch 034 - training loss: 0.3489, validation loss: 0.0421
2024-05-22 21:33:13 [INFO]: Epoch 035 - training loss: 0.3467, validation loss: 0.0346
2024-05-22 21:33:13 [INFO]: Epoch 036 - training loss: 0.3380, validation loss: 0.0469
2024-05-22 21:33:13 [INFO]: Epoch 037 - training loss: 0.3324, validation loss: 0.0407
2024-05-22 21:33:14 [INFO]: Epoch 038 - training loss: 0.3298, validation loss: 0.0446
2024-05-22 21:33:14 [INFO]: Epoch 039 - training loss: 0.3304, validation loss: 0.0467
2024-05-22 21:33:15 [INFO]: Epoch 040 - training loss: 0.3336, validation loss: 0.0396
2024-05-22 21:33:15 [INFO]: Epoch 041 - training loss: 0.3177, validation loss: 0.0350
2024-05-22 21:33:16 [INFO]: Epoch 042 - training loss: 0.3170, validation loss: 0.0369
2024-05-22 21:33:16 [INFO]: Epoch 043 - training loss: 0.3126, validation loss: 0.0449
2024-05-22 21:33:17 [INFO]: Epoch 044 - training loss: 0.3252, validation loss: 0.0372
2024-05-22 21:33:17 [INFO]: Epoch 045 - training loss: 0.3110, validation loss: 0.0340
2024-05-22 21:33:18 [INFO]: Epoch 046 - training loss: 0.3067, validation loss: 0.0359
2024-05-22 21:33:18 [INFO]: Epoch 047 - training loss: 0.2986, validation loss: 0.0322
2024-05-22 21:33:19 [INFO]: Epoch 048 - training loss: 0.2956, validation loss: 0.0297
2024-05-22 21:33:19 [INFO]: Epoch 049 - training loss: 0.2925, validation loss: 0.0369
2024-05-22 21:33:20 [INFO]: Epoch 050 - training loss: 0.2943, validation loss: 0.0370
2024-05-22 21:33:20 [INFO]: Epoch 051 - training loss: 0.3128, validation loss: 0.0406
2024-05-22 21:33:21 [INFO]: Epoch 052 - training loss: 0.2943, validation loss: 0.0439
2024-05-22 21:33:21 [INFO]: Epoch 053 - training loss: 0.2987, validation loss: 0.0436
2024-05-22 21:33:22 [INFO]: Epoch 054 - training loss: 0.2895, validation loss: 0.0354
2024-05-22 21:33:22 [INFO]: Epoch 055 - training loss: 0.2809, validation loss: 0.0365
2024-05-22 21:33:22 [INFO]: Epoch 056 - training loss: 0.2867, validation loss: 0.0426
2024-05-22 21:33:23 [INFO]: Epoch 057 - training loss: 0.2913, validation loss: 0.0373
2024-05-22 21:33:23 [INFO]: Epoch 058 - training loss: 0.2881, validation loss: 0.0311
2024-05-22 21:33:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:33:23 [INFO]: Finished training. The best model is from epoch#48.
2024-05-22 21:33:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/SAITS_ettm1/20240522_T213256/SAITS.pypots
2024-05-22 21:33:24 [INFO]: SAITS on ETTm1: MAE=0.1518, MSE=0.0453
2024-05-22 21:33:24 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/SAITS_ettm1/imputation.pkl
2024-05-22 21:33:24 [INFO]: Using the given device: cuda:0
2024-05-22 21:33:24 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/Transformer_ettm1/20240522_T213324
2024-05-22 21:33:24 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/Transformer_ettm1/20240522_T213324/tensorboard
2024-05-22 21:33:24 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 21:33:24 [INFO]: Epoch 001 - training loss: 1.2347, validation loss: 0.3361
2024-05-22 21:33:24 [INFO]: Epoch 002 - training loss: 0.6977, validation loss: 0.1511
2024-05-22 21:33:24 [INFO]: Epoch 003 - training loss: 0.5422, validation loss: 0.1187
2024-05-22 21:33:24 [INFO]: Epoch 004 - training loss: 0.4871, validation loss: 0.0957
2024-05-22 21:33:25 [INFO]: Epoch 005 - training loss: 0.4592, validation loss: 0.0878
2024-05-22 21:33:25 [INFO]: Epoch 006 - training loss: 0.4271, validation loss: 0.0737
2024-05-22 21:33:25 [INFO]: Epoch 007 - training loss: 0.4106, validation loss: 0.0667
2024-05-22 21:33:25 [INFO]: Epoch 008 - training loss: 0.3937, validation loss: 0.0641
2024-05-22 21:33:25 [INFO]: Epoch 009 - training loss: 0.3821, validation loss: 0.0589
2024-05-22 21:33:25 [INFO]: Epoch 010 - training loss: 0.3760, validation loss: 0.0617
2024-05-22 21:33:26 [INFO]: Epoch 011 - training loss: 0.3595, validation loss: 0.0536
2024-05-22 21:33:26 [INFO]: Epoch 012 - training loss: 0.3487, validation loss: 0.0580
2024-05-22 21:33:26 [INFO]: Epoch 013 - training loss: 0.3442, validation loss: 0.0525
2024-05-22 21:33:26 [INFO]: Epoch 014 - training loss: 0.3380, validation loss: 0.0508
2024-05-22 21:33:26 [INFO]: Epoch 015 - training loss: 0.3352, validation loss: 0.0487
2024-05-22 21:33:27 [INFO]: Epoch 016 - training loss: 0.3244, validation loss: 0.0504
2024-05-22 21:33:27 [INFO]: Epoch 017 - training loss: 0.3207, validation loss: 0.0473
2024-05-22 21:33:27 [INFO]: Epoch 018 - training loss: 0.3229, validation loss: 0.0470
2024-05-22 21:33:27 [INFO]: Epoch 019 - training loss: 0.3111, validation loss: 0.0450
2024-05-22 21:33:27 [INFO]: Epoch 020 - training loss: 0.3037, validation loss: 0.0428
2024-05-22 21:33:28 [INFO]: Epoch 021 - training loss: 0.2978, validation loss: 0.0409
2024-05-22 21:33:28 [INFO]: Epoch 022 - training loss: 0.2953, validation loss: 0.0440
2024-05-22 21:33:28 [INFO]: Epoch 023 - training loss: 0.2888, validation loss: 0.0395
2024-05-22 21:33:28 [INFO]: Epoch 024 - training loss: 0.2871, validation loss: 0.0387
2024-05-22 21:33:28 [INFO]: Epoch 025 - training loss: 0.2851, validation loss: 0.0381
2024-05-22 21:33:28 [INFO]: Epoch 026 - training loss: 0.2811, validation loss: 0.0402
2024-05-22 21:33:29 [INFO]: Epoch 027 - training loss: 0.2815, validation loss: 0.0395
2024-05-22 21:33:29 [INFO]: Epoch 028 - training loss: 0.2747, validation loss: 0.0391
2024-05-22 21:33:29 [INFO]: Epoch 029 - training loss: 0.2733, validation loss: 0.0367
2024-05-22 21:33:29 [INFO]: Epoch 030 - training loss: 0.2688, validation loss: 0.0376
2024-05-22 21:33:29 [INFO]: Epoch 031 - training loss: 0.2697, validation loss: 0.0347
2024-05-22 21:33:30 [INFO]: Epoch 032 - training loss: 0.2577, validation loss: 0.0340
2024-05-22 21:33:30 [INFO]: Epoch 033 - training loss: 0.2594, validation loss: 0.0345
2024-05-22 21:33:30 [INFO]: Epoch 034 - training loss: 0.2689, validation loss: 0.0358
2024-05-22 21:33:30 [INFO]: Epoch 035 - training loss: 0.2632, validation loss: 0.0345
2024-05-22 21:33:30 [INFO]: Epoch 036 - training loss: 0.2536, validation loss: 0.0371
2024-05-22 21:33:30 [INFO]: Epoch 037 - training loss: 0.2516, validation loss: 0.0337
2024-05-22 21:33:31 [INFO]: Epoch 038 - training loss: 0.2457, validation loss: 0.0352
2024-05-22 21:33:31 [INFO]: Epoch 039 - training loss: 0.2499, validation loss: 0.0375
2024-05-22 21:33:31 [INFO]: Epoch 040 - training loss: 0.2443, validation loss: 0.0330
2024-05-22 21:33:31 [INFO]: Epoch 041 - training loss: 0.2396, validation loss: 0.0354
2024-05-22 21:33:31 [INFO]: Epoch 042 - training loss: 0.2483, validation loss: 0.0338
2024-05-22 21:33:32 [INFO]: Epoch 043 - training loss: 0.2436, validation loss: 0.0308
2024-05-22 21:33:32 [INFO]: Epoch 044 - training loss: 0.2368, validation loss: 0.0298
2024-05-22 21:33:32 [INFO]: Epoch 045 - training loss: 0.2392, validation loss: 0.0335
2024-05-22 21:33:32 [INFO]: Epoch 046 - training loss: 0.2383, validation loss: 0.0309
2024-05-22 21:33:32 [INFO]: Epoch 047 - training loss: 0.2286, validation loss: 0.0332
2024-05-22 21:33:33 [INFO]: Epoch 048 - training loss: 0.2310, validation loss: 0.0295
2024-05-22 21:33:33 [INFO]: Epoch 049 - training loss: 0.2237, validation loss: 0.0287
2024-05-22 21:33:33 [INFO]: Epoch 050 - training loss: 0.2239, validation loss: 0.0282
2024-05-22 21:33:33 [INFO]: Epoch 051 - training loss: 0.2213, validation loss: 0.0336
2024-05-22 21:33:33 [INFO]: Epoch 052 - training loss: 0.2293, validation loss: 0.0341
2024-05-22 21:33:33 [INFO]: Epoch 053 - training loss: 0.2242, validation loss: 0.0328
2024-05-22 21:33:34 [INFO]: Epoch 054 - training loss: 0.2294, validation loss: 0.0301
2024-05-22 21:33:34 [INFO]: Epoch 055 - training loss: 0.2239, validation loss: 0.0356
2024-05-22 21:33:34 [INFO]: Epoch 056 - training loss: 0.2194, validation loss: 0.0281
2024-05-22 21:33:34 [INFO]: Epoch 057 - training loss: 0.2147, validation loss: 0.0279
2024-05-22 21:33:34 [INFO]: Epoch 058 - training loss: 0.2150, validation loss: 0.0355
2024-05-22 21:33:35 [INFO]: Epoch 059 - training loss: 0.2271, validation loss: 0.0316
2024-05-22 21:33:35 [INFO]: Epoch 060 - training loss: 0.2193, validation loss: 0.0305
2024-05-22 21:33:35 [INFO]: Epoch 061 - training loss: 0.2228, validation loss: 0.0331
2024-05-22 21:33:35 [INFO]: Epoch 062 - training loss: 0.2224, validation loss: 0.0285
2024-05-22 21:33:35 [INFO]: Epoch 063 - training loss: 0.2062, validation loss: 0.0301
2024-05-22 21:33:36 [INFO]: Epoch 064 - training loss: 0.2114, validation loss: 0.0281
2024-05-22 21:33:36 [INFO]: Epoch 065 - training loss: 0.2060, validation loss: 0.0269
2024-05-22 21:33:36 [INFO]: Epoch 066 - training loss: 0.2008, validation loss: 0.0271
2024-05-22 21:33:36 [INFO]: Epoch 067 - training loss: 0.2021, validation loss: 0.0270
2024-05-22 21:33:36 [INFO]: Epoch 068 - training loss: 0.2002, validation loss: 0.0268
2024-05-22 21:33:36 [INFO]: Epoch 069 - training loss: 0.2016, validation loss: 0.0276
2024-05-22 21:33:37 [INFO]: Epoch 070 - training loss: 0.2031, validation loss: 0.0273
2024-05-22 21:33:37 [INFO]: Epoch 071 - training loss: 0.2015, validation loss: 0.0278
2024-05-22 21:33:37 [INFO]: Epoch 072 - training loss: 0.1975, validation loss: 0.0278
2024-05-22 21:33:37 [INFO]: Epoch 073 - training loss: 0.2004, validation loss: 0.0301
2024-05-22 21:33:37 [INFO]: Epoch 074 - training loss: 0.2044, validation loss: 0.0258
2024-05-22 21:33:38 [INFO]: Epoch 075 - training loss: 0.2034, validation loss: 0.0317
2024-05-22 21:33:38 [INFO]: Epoch 076 - training loss: 0.2103, validation loss: 0.0268
2024-05-22 21:33:38 [INFO]: Epoch 077 - training loss: 0.1998, validation loss: 0.0257
2024-05-22 21:33:38 [INFO]: Epoch 078 - training loss: 0.1955, validation loss: 0.0249
2024-05-22 21:33:38 [INFO]: Epoch 079 - training loss: 0.1911, validation loss: 0.0276
2024-05-22 21:33:39 [INFO]: Epoch 080 - training loss: 0.1933, validation loss: 0.0281
2024-05-22 21:33:39 [INFO]: Epoch 081 - training loss: 0.1929, validation loss: 0.0269
2024-05-22 21:33:39 [INFO]: Epoch 082 - training loss: 0.1938, validation loss: 0.0253
2024-05-22 21:33:39 [INFO]: Epoch 083 - training loss: 0.1879, validation loss: 0.0252
2024-05-22 21:33:39 [INFO]: Epoch 084 - training loss: 0.1909, validation loss: 0.0249
2024-05-22 21:33:39 [INFO]: Epoch 085 - training loss: 0.1896, validation loss: 0.0255
2024-05-22 21:33:40 [INFO]: Epoch 086 - training loss: 0.1883, validation loss: 0.0243
2024-05-22 21:33:40 [INFO]: Epoch 087 - training loss: 0.1857, validation loss: 0.0249
2024-05-22 21:33:40 [INFO]: Epoch 088 - training loss: 0.1860, validation loss: 0.0275
2024-05-22 21:33:40 [INFO]: Epoch 089 - training loss: 0.1892, validation loss: 0.0285
2024-05-22 21:33:40 [INFO]: Epoch 090 - training loss: 0.1911, validation loss: 0.0250
2024-05-22 21:33:41 [INFO]: Epoch 091 - training loss: 0.1846, validation loss: 0.0258
2024-05-22 21:33:41 [INFO]: Epoch 092 - training loss: 0.1850, validation loss: 0.0270
2024-05-22 21:33:41 [INFO]: Epoch 093 - training loss: 0.1830, validation loss: 0.0262
2024-05-22 21:33:41 [INFO]: Epoch 094 - training loss: 0.1877, validation loss: 0.0253
2024-05-22 21:33:41 [INFO]: Epoch 095 - training loss: 0.1917, validation loss: 0.0247
2024-05-22 21:33:42 [INFO]: Epoch 096 - training loss: 0.1863, validation loss: 0.0266
2024-05-22 21:33:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:33:42 [INFO]: Finished training. The best model is from epoch#86.
2024-05-22 21:33:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/Transformer_ettm1/20240522_T213324/Transformer.pypots
2024-05-22 21:33:42 [INFO]: Transformer on ETTm1: MAE=0.1301, MSE=0.0362
2024-05-22 21:33:42 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Transformer_ettm1/imputation.pkl
2024-05-22 21:33:42 [INFO]: Using the given device: cuda:0
2024-05-22 21:33:42 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/TimesNet_ettm1/20240522_T213342
2024-05-22 21:33:42 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/TimesNet_ettm1/20240522_T213342/tensorboard
2024-05-22 21:33:42 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 21:33:42 [INFO]: Epoch 001 - training loss: 0.1720, validation loss: 0.0564
2024-05-22 21:33:42 [INFO]: Epoch 002 - training loss: 0.0714, validation loss: 0.0411
2024-05-22 21:33:42 [INFO]: Epoch 003 - training loss: 0.0540, validation loss: 0.0349
2024-05-22 21:33:42 [INFO]: Epoch 004 - training loss: 0.0410, validation loss: 0.0316
2024-05-22 21:33:43 [INFO]: Epoch 005 - training loss: 0.0374, validation loss: 0.0295
2024-05-22 21:33:43 [INFO]: Epoch 006 - training loss: 0.0390, validation loss: 0.0287
2024-05-22 21:33:43 [INFO]: Epoch 007 - training loss: 0.0402, validation loss: 0.0279
2024-05-22 21:33:43 [INFO]: Epoch 008 - training loss: 0.0352, validation loss: 0.0279
2024-05-22 21:33:43 [INFO]: Epoch 009 - training loss: 0.0340, validation loss: 0.0278
2024-05-22 21:33:44 [INFO]: Epoch 010 - training loss: 0.0314, validation loss: 0.0269
2024-05-22 21:33:44 [INFO]: Epoch 011 - training loss: 0.0294, validation loss: 0.0271
2024-05-22 21:33:44 [INFO]: Epoch 012 - training loss: 0.0294, validation loss: 0.0263
2024-05-22 21:33:44 [INFO]: Epoch 013 - training loss: 0.0311, validation loss: 0.0267
2024-05-22 21:33:44 [INFO]: Epoch 014 - training loss: 0.0295, validation loss: 0.0258
2024-05-22 21:33:44 [INFO]: Epoch 015 - training loss: 0.0290, validation loss: 0.0258
2024-05-22 21:33:45 [INFO]: Epoch 016 - training loss: 0.0287, validation loss: 0.0263
2024-05-22 21:33:45 [INFO]: Epoch 017 - training loss: 0.0280, validation loss: 0.0258
2024-05-22 21:33:45 [INFO]: Epoch 018 - training loss: 0.0294, validation loss: 0.0268
2024-05-22 21:33:45 [INFO]: Epoch 019 - training loss: 0.0311, validation loss: 0.0279
2024-05-22 21:33:45 [INFO]: Epoch 020 - training loss: 0.0301, validation loss: 0.0270
2024-05-22 21:33:45 [INFO]: Epoch 021 - training loss: 0.0278, validation loss: 0.0264
2024-05-22 21:33:46 [INFO]: Epoch 022 - training loss: 0.0282, validation loss: 0.0266
2024-05-22 21:33:46 [INFO]: Epoch 023 - training loss: 0.0280, validation loss: 0.0284
2024-05-22 21:33:46 [INFO]: Epoch 024 - training loss: 0.0296, validation loss: 0.0289
2024-05-22 21:33:46 [INFO]: Epoch 025 - training loss: 0.0273, validation loss: 0.0263
2024-05-22 21:33:46 [INFO]: Epoch 026 - training loss: 0.0232, validation loss: 0.0254
2024-05-22 21:33:47 [INFO]: Epoch 027 - training loss: 0.0241, validation loss: 0.0254
2024-05-22 21:33:47 [INFO]: Epoch 028 - training loss: 0.0254, validation loss: 0.0253
2024-05-22 21:33:47 [INFO]: Epoch 029 - training loss: 0.0236, validation loss: 0.0249
2024-05-22 21:33:47 [INFO]: Epoch 030 - training loss: 0.0245, validation loss: 0.0255
2024-05-22 21:33:47 [INFO]: Epoch 031 - training loss: 0.0236, validation loss: 0.0254
2024-05-22 21:33:47 [INFO]: Epoch 032 - training loss: 0.0232, validation loss: 0.0258
2024-05-22 21:33:48 [INFO]: Epoch 033 - training loss: 0.0225, validation loss: 0.0253
2024-05-22 21:33:48 [INFO]: Epoch 034 - training loss: 0.0207, validation loss: 0.0250
2024-05-22 21:33:48 [INFO]: Epoch 035 - training loss: 0.0214, validation loss: 0.0253
2024-05-22 21:33:48 [INFO]: Epoch 036 - training loss: 0.0223, validation loss: 0.0251
2024-05-22 21:33:48 [INFO]: Epoch 037 - training loss: 0.0206, validation loss: 0.0253
2024-05-22 21:33:48 [INFO]: Epoch 038 - training loss: 0.0227, validation loss: 0.0252
2024-05-22 21:33:49 [INFO]: Epoch 039 - training loss: 0.0215, validation loss: 0.0251
2024-05-22 21:33:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:33:49 [INFO]: Finished training. The best model is from epoch#29.
2024-05-22 21:33:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/TimesNet_ettm1/20240522_T213342/TimesNet.pypots
2024-05-22 21:33:49 [INFO]: TimesNet on ETTm1: MAE=0.1082, MSE=0.0248
2024-05-22 21:33:49 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/TimesNet_ettm1/imputation.pkl
2024-05-22 21:33:49 [INFO]: Using the given device: cuda:0
2024-05-22 21:33:49 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349
2024-05-22 21:33:49 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/tensorboard
2024-05-22 21:33:49 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 21:33:51 [INFO]: Epoch 001 - training loss: 0.7689, validation loss: 0.4348
2024-05-22 21:33:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch1_loss0.43476925045251846.pypots
2024-05-22 21:33:53 [INFO]: Epoch 002 - training loss: 0.4459, validation loss: 0.3657
2024-05-22 21:33:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch2_loss0.36571890115737915.pypots
2024-05-22 21:33:55 [INFO]: Epoch 003 - training loss: 0.3385, validation loss: 0.3618
2024-05-22 21:33:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch3_loss0.3617849722504616.pypots
2024-05-22 21:33:57 [INFO]: Epoch 004 - training loss: 0.3402, validation loss: 0.3013
2024-05-22 21:33:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch4_loss0.30128420144319534.pypots
2024-05-22 21:33:59 [INFO]: Epoch 005 - training loss: 0.3153, validation loss: 0.2888
2024-05-22 21:33:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch5_loss0.28881215304136276.pypots
2024-05-22 21:34:01 [INFO]: Epoch 006 - training loss: 0.3198, validation loss: 0.2810
2024-05-22 21:34:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch6_loss0.2810330390930176.pypots
2024-05-22 21:34:03 [INFO]: Epoch 007 - training loss: 0.2668, validation loss: 0.2608
2024-05-22 21:34:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch7_loss0.26084671169519424.pypots
2024-05-22 21:34:05 [INFO]: Epoch 008 - training loss: 0.2431, validation loss: 0.2486
2024-05-22 21:34:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch8_loss0.2486368529498577.pypots
2024-05-22 21:34:07 [INFO]: Epoch 009 - training loss: 0.2383, validation loss: 0.2370
2024-05-22 21:34:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch9_loss0.2370104193687439.pypots
2024-05-22 21:34:09 [INFO]: Epoch 010 - training loss: 0.2393, validation loss: 0.2370
2024-05-22 21:34:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch10_loss0.23699922114610672.pypots
2024-05-22 21:34:11 [INFO]: Epoch 011 - training loss: 0.2846, validation loss: 0.2414
2024-05-22 21:34:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch11_loss0.24139565229415894.pypots
2024-05-22 21:34:13 [INFO]: Epoch 012 - training loss: 0.2262, validation loss: 0.2360
2024-05-22 21:34:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch12_loss0.23599351197481155.pypots
2024-05-22 21:34:15 [INFO]: Epoch 013 - training loss: 0.2309, validation loss: 0.2186
2024-05-22 21:34:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch13_loss0.21855934336781502.pypots
2024-05-22 21:34:17 [INFO]: Epoch 014 - training loss: 0.2122, validation loss: 0.2080
2024-05-22 21:34:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch14_loss0.20799482241272926.pypots
2024-05-22 21:34:19 [INFO]: Epoch 015 - training loss: 0.1870, validation loss: 0.1942
2024-05-22 21:34:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch15_loss0.19416553527116776.pypots
2024-05-22 21:34:21 [INFO]: Epoch 016 - training loss: 0.1899, validation loss: 0.1918
2024-05-22 21:34:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch16_loss0.19181057438254356.pypots
2024-05-22 21:34:23 [INFO]: Epoch 017 - training loss: 0.2251, validation loss: 0.2172
2024-05-22 21:34:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch17_loss0.21721725910902023.pypots
2024-05-22 21:34:25 [INFO]: Epoch 018 - training loss: 0.2281, validation loss: 0.1997
2024-05-22 21:34:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch18_loss0.19971709698438644.pypots
2024-05-22 21:34:27 [INFO]: Epoch 019 - training loss: 0.2035, validation loss: 0.1865
2024-05-22 21:34:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch19_loss0.18646197766065598.pypots
2024-05-22 21:34:29 [INFO]: Epoch 020 - training loss: 0.1669, validation loss: 0.1774
2024-05-22 21:34:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch20_loss0.17735956609249115.pypots
2024-05-22 21:34:31 [INFO]: Epoch 021 - training loss: 0.1812, validation loss: 0.2068
2024-05-22 21:34:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch21_loss0.20683547481894493.pypots
2024-05-22 21:34:33 [INFO]: Epoch 022 - training loss: 0.1996, validation loss: 0.1967
2024-05-22 21:34:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch22_loss0.1966930516064167.pypots
2024-05-22 21:34:35 [INFO]: Epoch 023 - training loss: 0.1854, validation loss: 0.1736
2024-05-22 21:34:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch23_loss0.17355331405997276.pypots
2024-05-22 21:34:37 [INFO]: Epoch 024 - training loss: 0.1798, validation loss: 0.1734
2024-05-22 21:34:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch24_loss0.17341292276978493.pypots
2024-05-22 21:34:39 [INFO]: Epoch 025 - training loss: 0.2185, validation loss: 0.1774
2024-05-22 21:34:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch25_loss0.17737798020243645.pypots
2024-05-22 21:34:41 [INFO]: Epoch 026 - training loss: 0.2762, validation loss: 0.1814
2024-05-22 21:34:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch26_loss0.18139587342739105.pypots
2024-05-22 21:34:43 [INFO]: Epoch 027 - training loss: 0.1994, validation loss: 0.1734
2024-05-22 21:34:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch27_loss0.17339714616537094.pypots
2024-05-22 21:34:45 [INFO]: Epoch 028 - training loss: 0.1807, validation loss: 0.1612
2024-05-22 21:34:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch28_loss0.1611693874001503.pypots
2024-05-22 21:34:47 [INFO]: Epoch 029 - training loss: 0.1667, validation loss: 0.1534
2024-05-22 21:34:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch29_loss0.15335403010249138.pypots
2024-05-22 21:34:49 [INFO]: Epoch 030 - training loss: 0.1647, validation loss: 0.1598
2024-05-22 21:34:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch30_loss0.15982242301106453.pypots
2024-05-22 21:34:51 [INFO]: Epoch 031 - training loss: 0.1642, validation loss: 0.1584
2024-05-22 21:34:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch31_loss0.15844903513789177.pypots
2024-05-22 21:34:53 [INFO]: Epoch 032 - training loss: 0.1567, validation loss: 0.1546
2024-05-22 21:34:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch32_loss0.15460144728422165.pypots
2024-05-22 21:34:55 [INFO]: Epoch 033 - training loss: 0.1214, validation loss: 0.1511
2024-05-22 21:34:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch33_loss0.1510642021894455.pypots
2024-05-22 21:34:57 [INFO]: Epoch 034 - training loss: 0.1769, validation loss: 0.1466
2024-05-22 21:34:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch34_loss0.1465505175292492.pypots
2024-05-22 21:34:59 [INFO]: Epoch 035 - training loss: 0.1793, validation loss: 0.1533
2024-05-22 21:34:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch35_loss0.15327728167176247.pypots
2024-05-22 21:35:01 [INFO]: Epoch 036 - training loss: 0.1493, validation loss: 0.1502
2024-05-22 21:35:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch36_loss0.1502300649881363.pypots
2024-05-22 21:35:03 [INFO]: Epoch 037 - training loss: 0.1681, validation loss: 0.1455
2024-05-22 21:35:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch37_loss0.14552618190646172.pypots
2024-05-22 21:35:05 [INFO]: Epoch 038 - training loss: 0.1595, validation loss: 0.1443
2024-05-22 21:35:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch38_loss0.1443108581006527.pypots
2024-05-22 21:35:07 [INFO]: Epoch 039 - training loss: 0.1772, validation loss: 0.1570
2024-05-22 21:35:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch39_loss0.15700792893767357.pypots
2024-05-22 21:35:09 [INFO]: Epoch 040 - training loss: 0.1728, validation loss: 0.1609
2024-05-22 21:35:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch40_loss0.16093600541353226.pypots
2024-05-22 21:35:11 [INFO]: Epoch 041 - training loss: 0.1642, validation loss: 0.1514
2024-05-22 21:35:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch41_loss0.15139227733016014.pypots
2024-05-22 21:35:13 [INFO]: Epoch 042 - training loss: 0.1572, validation loss: 0.1511
2024-05-22 21:35:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch42_loss0.15113840252161026.pypots
2024-05-22 21:35:15 [INFO]: Epoch 043 - training loss: 0.1512, validation loss: 0.1488
2024-05-22 21:35:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch43_loss0.14876747131347656.pypots
2024-05-22 21:35:17 [INFO]: Epoch 044 - training loss: 0.1585, validation loss: 0.1425
2024-05-22 21:35:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch44_loss0.1425250880420208.pypots
2024-05-22 21:35:19 [INFO]: Epoch 045 - training loss: 0.1628, validation loss: 0.1401
2024-05-22 21:35:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch45_loss0.1401280052959919.pypots
2024-05-22 21:35:21 [INFO]: Epoch 046 - training loss: 0.1460, validation loss: 0.1385
2024-05-22 21:35:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch46_loss0.13853061571717262.pypots
2024-05-22 21:35:23 [INFO]: Epoch 047 - training loss: 0.1407, validation loss: 0.1389
2024-05-22 21:35:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch47_loss0.1389065980911255.pypots
2024-05-22 21:35:25 [INFO]: Epoch 048 - training loss: 0.1409, validation loss: 0.1452
2024-05-22 21:35:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch48_loss0.1451985239982605.pypots
2024-05-22 21:35:27 [INFO]: Epoch 049 - training loss: 0.1415, validation loss: 0.1419
2024-05-22 21:35:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch49_loss0.14193524047732353.pypots
2024-05-22 21:35:29 [INFO]: Epoch 050 - training loss: 0.1275, validation loss: 0.1388
2024-05-22 21:35:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch50_loss0.13879233598709106.pypots
2024-05-22 21:35:31 [INFO]: Epoch 051 - training loss: 0.1560, validation loss: 0.1403
2024-05-22 21:35:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch51_loss0.14026999101042747.pypots
2024-05-22 21:35:33 [INFO]: Epoch 052 - training loss: 0.1389, validation loss: 0.1506
2024-05-22 21:35:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch52_loss0.15064894035458565.pypots
2024-05-22 21:35:35 [INFO]: Epoch 053 - training loss: 0.1624, validation loss: 0.1401
2024-05-22 21:35:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch53_loss0.14008618891239166.pypots
2024-05-22 21:35:37 [INFO]: Epoch 054 - training loss: 0.1864, validation loss: 0.1660
2024-05-22 21:35:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch54_loss0.1660316325724125.pypots
2024-05-22 21:35:39 [INFO]: Epoch 055 - training loss: 0.1671, validation loss: 0.1539
2024-05-22 21:35:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch55_loss0.15390544012188911.pypots
2024-05-22 21:35:41 [INFO]: Epoch 056 - training loss: 0.2308, validation loss: 0.1437
2024-05-22 21:35:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI_epoch56_loss0.143681850284338.pypots
2024-05-22 21:35:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:35:41 [INFO]: Finished training. The best model is from epoch#46.
2024-05-22 21:35:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240522_T213349/CSDI.pypots
2024-05-22 21:35:57 [INFO]: CSDI on ETTm1: MAE=0.1306, MSE=0.0413
2024-05-22 21:35:57 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/CSDI_ettm1/imputation.pkl
2024-05-22 21:35:57 [INFO]: Using the given device: cuda:0
2024-05-22 21:35:57 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/GPVAE_ettm1/20240522_T213557
2024-05-22 21:35:57 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/GPVAE_ettm1/20240522_T213557/tensorboard
2024-05-22 21:35:57 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 21:35:57 [INFO]: Epoch 001 - training loss: 23670.0012, validation loss: 0.9896
2024-05-22 21:35:57 [INFO]: Epoch 002 - training loss: 21400.1354, validation loss: 0.9843
2024-05-22 21:35:57 [INFO]: Epoch 003 - training loss: 19271.5692, validation loss: 0.9779
2024-05-22 21:35:57 [INFO]: Epoch 004 - training loss: 17207.6478, validation loss: 0.9518
2024-05-22 21:35:58 [INFO]: Epoch 005 - training loss: 15329.2994, validation loss: 0.8898
2024-05-22 21:35:58 [INFO]: Epoch 006 - training loss: 13625.5358, validation loss: 0.7760
2024-05-22 21:35:58 [INFO]: Epoch 007 - training loss: 12580.7098, validation loss: 0.6702
2024-05-22 21:35:58 [INFO]: Epoch 008 - training loss: 11687.1789, validation loss: 0.6148
2024-05-22 21:35:58 [INFO]: Epoch 009 - training loss: 11214.8992, validation loss: 0.5578
2024-05-22 21:35:58 [INFO]: Epoch 010 - training loss: 10824.5939, validation loss: 0.5100
2024-05-22 21:35:58 [INFO]: Epoch 011 - training loss: 10554.9191, validation loss: 0.4895
2024-05-22 21:35:58 [INFO]: Epoch 012 - training loss: 10347.3558, validation loss: 0.4741
2024-05-22 21:35:58 [INFO]: Epoch 013 - training loss: 10227.3889, validation loss: 0.4626
2024-05-22 21:35:58 [INFO]: Epoch 014 - training loss: 10060.8260, validation loss: 0.4525
2024-05-22 21:35:59 [INFO]: Epoch 015 - training loss: 9954.1040, validation loss: 0.4358
2024-05-22 21:35:59 [INFO]: Epoch 016 - training loss: 9883.7435, validation loss: 0.4173
2024-05-22 21:35:59 [INFO]: Epoch 017 - training loss: 9835.6570, validation loss: 0.3936
2024-05-22 21:35:59 [INFO]: Epoch 018 - training loss: 9779.1104, validation loss: 0.3710
2024-05-22 21:35:59 [INFO]: Epoch 019 - training loss: 9722.2325, validation loss: 0.3457
2024-05-22 21:35:59 [INFO]: Epoch 020 - training loss: 9666.5416, validation loss: 0.3179
2024-05-22 21:35:59 [INFO]: Epoch 021 - training loss: 9634.9932, validation loss: 0.2930
2024-05-22 21:35:59 [INFO]: Epoch 022 - training loss: 9619.1656, validation loss: 0.2771
2024-05-22 21:35:59 [INFO]: Epoch 023 - training loss: 9603.5747, validation loss: 0.2644
2024-05-22 21:36:00 [INFO]: Epoch 024 - training loss: 9554.5221, validation loss: 0.2500
2024-05-22 21:36:00 [INFO]: Epoch 025 - training loss: 9528.1273, validation loss: 0.2411
2024-05-22 21:36:00 [INFO]: Epoch 026 - training loss: 9523.6880, validation loss: 0.2379
2024-05-22 21:36:00 [INFO]: Epoch 027 - training loss: 9517.6629, validation loss: 0.2302
2024-05-22 21:36:00 [INFO]: Epoch 028 - training loss: 9506.3085, validation loss: 0.2246
2024-05-22 21:36:00 [INFO]: Epoch 029 - training loss: 9513.5037, validation loss: 0.2190
2024-05-22 21:36:00 [INFO]: Epoch 030 - training loss: 9456.4785, validation loss: 0.2182
2024-05-22 21:36:00 [INFO]: Epoch 031 - training loss: 9444.2132, validation loss: 0.2144
2024-05-22 21:36:00 [INFO]: Epoch 032 - training loss: 9443.3682, validation loss: 0.2119
2024-05-22 21:36:01 [INFO]: Epoch 033 - training loss: 9432.1570, validation loss: 0.2071
2024-05-22 21:36:01 [INFO]: Epoch 034 - training loss: 9421.8503, validation loss: 0.2048
2024-05-22 21:36:01 [INFO]: Epoch 035 - training loss: 9417.7976, validation loss: 0.2014
2024-05-22 21:36:01 [INFO]: Epoch 036 - training loss: 9408.8166, validation loss: 0.1998
2024-05-22 21:36:01 [INFO]: Epoch 037 - training loss: 9404.4977, validation loss: 0.1974
2024-05-22 21:36:01 [INFO]: Epoch 038 - training loss: 9398.7742, validation loss: 0.1943
2024-05-22 21:36:01 [INFO]: Epoch 039 - training loss: 9388.7672, validation loss: 0.1917
2024-05-22 21:36:01 [INFO]: Epoch 040 - training loss: 9404.4682, validation loss: 0.1901
2024-05-22 21:36:01 [INFO]: Epoch 041 - training loss: 9382.6562, validation loss: 0.1832
2024-05-22 21:36:01 [INFO]: Epoch 042 - training loss: 9373.8109, validation loss: 0.1813
2024-05-22 21:36:02 [INFO]: Epoch 043 - training loss: 9372.1584, validation loss: 0.1803
2024-05-22 21:36:02 [INFO]: Epoch 044 - training loss: 9385.6292, validation loss: 0.1766
2024-05-22 21:36:02 [INFO]: Epoch 045 - training loss: 9364.3521, validation loss: 0.1700
2024-05-22 21:36:02 [INFO]: Epoch 046 - training loss: 9368.9031, validation loss: 0.1688
2024-05-22 21:36:02 [INFO]: Epoch 047 - training loss: 9354.7534, validation loss: 0.1706
2024-05-22 21:36:02 [INFO]: Epoch 048 - training loss: 9362.5906, validation loss: 0.1636
2024-05-22 21:36:02 [INFO]: Epoch 049 - training loss: 9353.7651, validation loss: 0.1564
2024-05-22 21:36:02 [INFO]: Epoch 050 - training loss: 9346.2686, validation loss: 0.1587
2024-05-22 21:36:02 [INFO]: Epoch 051 - training loss: 9341.3413, validation loss: 0.1563
2024-05-22 21:36:03 [INFO]: Epoch 052 - training loss: 9358.1441, validation loss: 0.1540
2024-05-22 21:36:03 [INFO]: Epoch 053 - training loss: 9335.5816, validation loss: 0.1491
2024-05-22 21:36:03 [INFO]: Epoch 054 - training loss: 9337.4152, validation loss: 0.1496
2024-05-22 21:36:03 [INFO]: Epoch 055 - training loss: 9339.0544, validation loss: 0.1464
2024-05-22 21:36:03 [INFO]: Epoch 056 - training loss: 9336.5640, validation loss: 0.1448
2024-05-22 21:36:03 [INFO]: Epoch 057 - training loss: 9329.7886, validation loss: 0.1422
2024-05-22 21:36:03 [INFO]: Epoch 058 - training loss: 9332.8527, validation loss: 0.1420
2024-05-22 21:36:03 [INFO]: Epoch 059 - training loss: 9327.0103, validation loss: 0.1417
2024-05-22 21:36:03 [INFO]: Epoch 060 - training loss: 9329.8652, validation loss: 0.1377
2024-05-22 21:36:03 [INFO]: Epoch 061 - training loss: 9324.3467, validation loss: 0.1420
2024-05-22 21:36:04 [INFO]: Epoch 062 - training loss: 9321.4373, validation loss: 0.1380
2024-05-22 21:36:04 [INFO]: Epoch 063 - training loss: 9318.3980, validation loss: 0.1360
2024-05-22 21:36:04 [INFO]: Epoch 064 - training loss: 9321.0336, validation loss: 0.1345
2024-05-22 21:36:04 [INFO]: Epoch 065 - training loss: 9319.6719, validation loss: 0.1349
2024-05-22 21:36:04 [INFO]: Epoch 066 - training loss: 9317.4999, validation loss: 0.1344
2024-05-22 21:36:04 [INFO]: Epoch 067 - training loss: 9314.6954, validation loss: 0.1317
2024-05-22 21:36:04 [INFO]: Epoch 068 - training loss: 9313.8570, validation loss: 0.1299
2024-05-22 21:36:04 [INFO]: Epoch 069 - training loss: 9313.5160, validation loss: 0.1319
2024-05-22 21:36:04 [INFO]: Epoch 070 - training loss: 9314.6790, validation loss: 0.1304
2024-05-22 21:36:05 [INFO]: Epoch 071 - training loss: 9310.8694, validation loss: 0.1282
2024-05-22 21:36:05 [INFO]: Epoch 072 - training loss: 9314.1104, validation loss: 0.1296
2024-05-22 21:36:05 [INFO]: Epoch 073 - training loss: 9310.0785, validation loss: 0.1272
2024-05-22 21:36:05 [INFO]: Epoch 074 - training loss: 9307.3903, validation loss: 0.1268
2024-05-22 21:36:05 [INFO]: Epoch 075 - training loss: 9308.0566, validation loss: 0.1255
2024-05-22 21:36:05 [INFO]: Epoch 076 - training loss: 9307.2274, validation loss: 0.1251
2024-05-22 21:36:05 [INFO]: Epoch 077 - training loss: 9306.6404, validation loss: 0.1244
2024-05-22 21:36:05 [INFO]: Epoch 078 - training loss: 9305.0823, validation loss: 0.1256
2024-05-22 21:36:05 [INFO]: Epoch 079 - training loss: 9303.6879, validation loss: 0.1241
2024-05-22 21:36:06 [INFO]: Epoch 080 - training loss: 9303.2991, validation loss: 0.1230
2024-05-22 21:36:06 [INFO]: Epoch 081 - training loss: 9304.3516, validation loss: 0.1228
2024-05-22 21:36:06 [INFO]: Epoch 082 - training loss: 9300.9631, validation loss: 0.1208
2024-05-22 21:36:06 [INFO]: Epoch 083 - training loss: 9301.5301, validation loss: 0.1192
2024-05-22 21:36:06 [INFO]: Epoch 084 - training loss: 9300.8522, validation loss: 0.1206
2024-05-22 21:36:06 [INFO]: Epoch 085 - training loss: 9302.0297, validation loss: 0.1184
2024-05-22 21:36:06 [INFO]: Epoch 086 - training loss: 9302.0963, validation loss: 0.1183
2024-05-22 21:36:06 [INFO]: Epoch 087 - training loss: 9297.5760, validation loss: 0.1190
2024-05-22 21:36:06 [INFO]: Epoch 088 - training loss: 9300.6572, validation loss: 0.1180
2024-05-22 21:36:06 [INFO]: Epoch 089 - training loss: 9297.3378, validation loss: 0.1172
2024-05-22 21:36:07 [INFO]: Epoch 090 - training loss: 9299.2484, validation loss: 0.1159
2024-05-22 21:36:07 [INFO]: Epoch 091 - training loss: 9296.0909, validation loss: 0.1142
2024-05-22 21:36:07 [INFO]: Epoch 092 - training loss: 9295.7086, validation loss: 0.1153
2024-05-22 21:36:07 [INFO]: Epoch 093 - training loss: 9295.4024, validation loss: 0.1149
2024-05-22 21:36:07 [INFO]: Epoch 094 - training loss: 9295.0768, validation loss: 0.1141
2024-05-22 21:36:07 [INFO]: Epoch 095 - training loss: 9296.2689, validation loss: 0.1147
2024-05-22 21:36:07 [INFO]: Epoch 096 - training loss: 9296.4078, validation loss: 0.1130
2024-05-22 21:36:07 [INFO]: Epoch 097 - training loss: 9293.1918, validation loss: 0.1125
2024-05-22 21:36:07 [INFO]: Epoch 098 - training loss: 9292.5533, validation loss: 0.1098
2024-05-22 21:36:08 [INFO]: Epoch 099 - training loss: 9291.5648, validation loss: 0.1111
2024-05-22 21:36:08 [INFO]: Epoch 100 - training loss: 9292.0839, validation loss: 0.1101
2024-05-22 21:36:08 [INFO]: Epoch 101 - training loss: 9298.2874, validation loss: 0.1100
2024-05-22 21:36:08 [INFO]: Epoch 102 - training loss: 9291.5233, validation loss: 0.1082
2024-05-22 21:36:08 [INFO]: Epoch 103 - training loss: 9289.6927, validation loss: 0.1105
2024-05-22 21:36:08 [INFO]: Epoch 104 - training loss: 9291.1434, validation loss: 0.1102
2024-05-22 21:36:08 [INFO]: Epoch 105 - training loss: 9290.1522, validation loss: 0.1068
2024-05-22 21:36:08 [INFO]: Epoch 106 - training loss: 9291.4276, validation loss: 0.1082
2024-05-22 21:36:08 [INFO]: Epoch 107 - training loss: 9290.4640, validation loss: 0.1071
2024-05-22 21:36:08 [INFO]: Epoch 108 - training loss: 9288.7307, validation loss: 0.1060
2024-05-22 21:36:09 [INFO]: Epoch 109 - training loss: 9290.1655, validation loss: 0.1052
2024-05-22 21:36:09 [INFO]: Epoch 110 - training loss: 9288.9597, validation loss: 0.1048
2024-05-22 21:36:09 [INFO]: Epoch 111 - training loss: 9287.7079, validation loss: 0.1057
2024-05-22 21:36:09 [INFO]: Epoch 112 - training loss: 9287.5284, validation loss: 0.1047
2024-05-22 21:36:09 [INFO]: Epoch 113 - training loss: 9286.9458, validation loss: 0.1042
2024-05-22 21:36:09 [INFO]: Epoch 114 - training loss: 9286.3741, validation loss: 0.1032
2024-05-22 21:36:09 [INFO]: Epoch 115 - training loss: 9288.7248, validation loss: 0.1040
2024-05-22 21:36:09 [INFO]: Epoch 116 - training loss: 9287.9911, validation loss: 0.1024
2024-05-22 21:36:09 [INFO]: Epoch 117 - training loss: 9285.8125, validation loss: 0.1031
2024-05-22 21:36:10 [INFO]: Epoch 118 - training loss: 9285.9352, validation loss: 0.1023
2024-05-22 21:36:10 [INFO]: Epoch 119 - training loss: 9286.8362, validation loss: 0.1003
2024-05-22 21:36:10 [INFO]: Epoch 120 - training loss: 9286.2588, validation loss: 0.1012
2024-05-22 21:36:10 [INFO]: Epoch 121 - training loss: 9284.1640, validation loss: 0.1013
2024-05-22 21:36:10 [INFO]: Epoch 122 - training loss: 9286.2680, validation loss: 0.1015
2024-05-22 21:36:10 [INFO]: Epoch 123 - training loss: 9285.6959, validation loss: 0.0986
2024-05-22 21:36:10 [INFO]: Epoch 124 - training loss: 9283.7973, validation loss: 0.1008
2024-05-22 21:36:10 [INFO]: Epoch 125 - training loss: 9284.6158, validation loss: 0.0981
2024-05-22 21:36:10 [INFO]: Epoch 126 - training loss: 9284.4581, validation loss: 0.0999
2024-05-22 21:36:11 [INFO]: Epoch 127 - training loss: 9282.9194, validation loss: 0.0979
2024-05-22 21:36:11 [INFO]: Epoch 128 - training loss: 9284.9689, validation loss: 0.0986
2024-05-22 21:36:11 [INFO]: Epoch 129 - training loss: 9283.8677, validation loss: 0.0957
2024-05-22 21:36:11 [INFO]: Epoch 130 - training loss: 9282.5827, validation loss: 0.0964
2024-05-22 21:36:11 [INFO]: Epoch 131 - training loss: 9282.8173, validation loss: 0.0981
2024-05-22 21:36:11 [INFO]: Epoch 132 - training loss: 9282.3027, validation loss: 0.0957
2024-05-22 21:36:11 [INFO]: Epoch 133 - training loss: 9281.3640, validation loss: 0.0965
2024-05-22 21:36:11 [INFO]: Epoch 134 - training loss: 9281.5530, validation loss: 0.0945
2024-05-22 21:36:11 [INFO]: Epoch 135 - training loss: 9281.5424, validation loss: 0.0943
2024-05-22 21:36:11 [INFO]: Epoch 136 - training loss: 9282.4682, validation loss: 0.0957
2024-05-22 21:36:12 [INFO]: Epoch 137 - training loss: 9280.3719, validation loss: 0.0940
2024-05-22 21:36:12 [INFO]: Epoch 138 - training loss: 9281.3564, validation loss: 0.0943
2024-05-22 21:36:12 [INFO]: Epoch 139 - training loss: 9282.3151, validation loss: 0.0931
2024-05-22 21:36:12 [INFO]: Epoch 140 - training loss: 9279.3958, validation loss: 0.0939
2024-05-22 21:36:12 [INFO]: Epoch 141 - training loss: 9280.3779, validation loss: 0.0934
2024-05-22 21:36:12 [INFO]: Epoch 142 - training loss: 9280.4006, validation loss: 0.0918
2024-05-22 21:36:12 [INFO]: Epoch 143 - training loss: 9280.5019, validation loss: 0.0926
2024-05-22 21:36:12 [INFO]: Epoch 144 - training loss: 9279.8552, validation loss: 0.0909
2024-05-22 21:36:12 [INFO]: Epoch 145 - training loss: 9280.2056, validation loss: 0.0933
2024-05-22 21:36:13 [INFO]: Epoch 146 - training loss: 9279.8937, validation loss: 0.0916
2024-05-22 21:36:13 [INFO]: Epoch 147 - training loss: 9278.4113, validation loss: 0.0908
2024-05-22 21:36:13 [INFO]: Epoch 148 - training loss: 9279.8027, validation loss: 0.0919
2024-05-22 21:36:13 [INFO]: Epoch 149 - training loss: 9279.3851, validation loss: 0.0907
2024-05-22 21:36:13 [INFO]: Epoch 150 - training loss: 9279.3497, validation loss: 0.0893
2024-05-22 21:36:13 [INFO]: Epoch 151 - training loss: 9278.3597, validation loss: 0.0907
2024-05-22 21:36:13 [INFO]: Epoch 152 - training loss: 9278.8187, validation loss: 0.0898
2024-05-22 21:36:13 [INFO]: Epoch 153 - training loss: 9278.7328, validation loss: 0.0891
2024-05-22 21:36:13 [INFO]: Epoch 154 - training loss: 9278.1166, validation loss: 0.0898
2024-05-22 21:36:14 [INFO]: Epoch 155 - training loss: 9277.5326, validation loss: 0.0905
2024-05-22 21:36:14 [INFO]: Epoch 156 - training loss: 9278.0463, validation loss: 0.0878
2024-05-22 21:36:14 [INFO]: Epoch 157 - training loss: 9278.5450, validation loss: 0.0898
2024-05-22 21:36:14 [INFO]: Epoch 158 - training loss: 9278.9551, validation loss: 0.0886
2024-05-22 21:36:14 [INFO]: Epoch 159 - training loss: 9278.1370, validation loss: 0.0876
2024-05-22 21:36:14 [INFO]: Epoch 160 - training loss: 9277.4060, validation loss: 0.0885
2024-05-22 21:36:14 [INFO]: Epoch 161 - training loss: 9276.6854, validation loss: 0.0863
2024-05-22 21:36:14 [INFO]: Epoch 162 - training loss: 9277.3393, validation loss: 0.0888
2024-05-22 21:36:14 [INFO]: Epoch 163 - training loss: 9278.5670, validation loss: 0.0869
2024-05-22 21:36:14 [INFO]: Epoch 164 - training loss: 9277.2130, validation loss: 0.0854
2024-05-22 21:36:15 [INFO]: Epoch 165 - training loss: 9277.9138, validation loss: 0.0866
2024-05-22 21:36:15 [INFO]: Epoch 166 - training loss: 9276.1674, validation loss: 0.0845
2024-05-22 21:36:15 [INFO]: Epoch 167 - training loss: 9277.0531, validation loss: 0.0848
2024-05-22 21:36:15 [INFO]: Epoch 168 - training loss: 9276.3882, validation loss: 0.0866
2024-05-22 21:36:15 [INFO]: Epoch 169 - training loss: 9275.7496, validation loss: 0.0854
2024-05-22 21:36:15 [INFO]: Epoch 170 - training loss: 9276.0087, validation loss: 0.0846
2024-05-22 21:36:15 [INFO]: Epoch 171 - training loss: 9274.9530, validation loss: 0.0848
2024-05-22 21:36:15 [INFO]: Epoch 172 - training loss: 9274.4780, validation loss: 0.0843
2024-05-22 21:36:15 [INFO]: Epoch 173 - training loss: 9275.7509, validation loss: 0.0847
2024-05-22 21:36:16 [INFO]: Epoch 174 - training loss: 9276.3729, validation loss: 0.0836
2024-05-22 21:36:16 [INFO]: Epoch 175 - training loss: 9275.2155, validation loss: 0.0829
2024-05-22 21:36:16 [INFO]: Epoch 176 - training loss: 9275.0344, validation loss: 0.0839
2024-05-22 21:36:16 [INFO]: Epoch 177 - training loss: 9276.8074, validation loss: 0.0842
2024-05-22 21:36:16 [INFO]: Epoch 178 - training loss: 9276.3402, validation loss: 0.0829
2024-05-22 21:36:16 [INFO]: Epoch 179 - training loss: 9275.2028, validation loss: 0.0837
2024-05-22 21:36:16 [INFO]: Epoch 180 - training loss: 9277.1242, validation loss: 0.0823
2024-05-22 21:36:16 [INFO]: Epoch 181 - training loss: 9275.1336, validation loss: 0.0823
2024-05-22 21:36:16 [INFO]: Epoch 182 - training loss: 9274.8892, validation loss: 0.0837
2024-05-22 21:36:17 [INFO]: Epoch 183 - training loss: 9274.4897, validation loss: 0.0848
2024-05-22 21:36:17 [INFO]: Epoch 184 - training loss: 9274.5287, validation loss: 0.0845
2024-05-22 21:36:17 [INFO]: Epoch 185 - training loss: 9276.7112, validation loss: 0.0827
2024-05-22 21:36:17 [INFO]: Epoch 186 - training loss: 9275.6796, validation loss: 0.0834
2024-05-22 21:36:17 [INFO]: Epoch 187 - training loss: 9274.7181, validation loss: 0.0833
2024-05-22 21:36:17 [INFO]: Epoch 188 - training loss: 9274.4485, validation loss: 0.0844
2024-05-22 21:36:17 [INFO]: Epoch 189 - training loss: 9273.7398, validation loss: 0.0817
2024-05-22 21:36:17 [INFO]: Epoch 190 - training loss: 9275.0903, validation loss: 0.0807
2024-05-22 21:36:17 [INFO]: Epoch 191 - training loss: 9274.5222, validation loss: 0.0813
2024-05-22 21:36:17 [INFO]: Epoch 192 - training loss: 9272.6178, validation loss: 0.0822
2024-05-22 21:36:18 [INFO]: Epoch 193 - training loss: 9274.3792, validation loss: 0.0822
2024-05-22 21:36:18 [INFO]: Epoch 194 - training loss: 9273.9236, validation loss: 0.0818
2024-05-22 21:36:18 [INFO]: Epoch 195 - training loss: 9273.7563, validation loss: 0.0799
2024-05-22 21:36:18 [INFO]: Epoch 196 - training loss: 9273.4321, validation loss: 0.0814
2024-05-22 21:36:18 [INFO]: Epoch 197 - training loss: 9274.7310, validation loss: 0.0809
2024-05-22 21:36:18 [INFO]: Epoch 198 - training loss: 9273.6528, validation loss: 0.0807
2024-05-22 21:36:18 [INFO]: Epoch 199 - training loss: 9272.9604, validation loss: 0.0803
2024-05-22 21:36:18 [INFO]: Epoch 200 - training loss: 9276.3647, validation loss: 0.0803
2024-05-22 21:36:18 [INFO]: Epoch 201 - training loss: 9274.0510, validation loss: 0.0812
2024-05-22 21:36:19 [INFO]: Epoch 202 - training loss: 9276.0036, validation loss: 0.0804
2024-05-22 21:36:19 [INFO]: Epoch 203 - training loss: 9273.4595, validation loss: 0.0775
2024-05-22 21:36:19 [INFO]: Epoch 204 - training loss: 9273.1002, validation loss: 0.0788
2024-05-22 21:36:19 [INFO]: Epoch 205 - training loss: 9272.9568, validation loss: 0.0784
2024-05-22 21:36:19 [INFO]: Epoch 206 - training loss: 9273.6457, validation loss: 0.0806
2024-05-22 21:36:19 [INFO]: Epoch 207 - training loss: 9272.7941, validation loss: 0.0794
2024-05-22 21:36:19 [INFO]: Epoch 208 - training loss: 9272.3119, validation loss: 0.0799
2024-05-22 21:36:19 [INFO]: Epoch 209 - training loss: 9272.4654, validation loss: 0.0775
2024-05-22 21:36:19 [INFO]: Epoch 210 - training loss: 9271.2204, validation loss: 0.0797
2024-05-22 21:36:20 [INFO]: Epoch 211 - training loss: 9273.9014, validation loss: 0.0787
2024-05-22 21:36:20 [INFO]: Epoch 212 - training loss: 9272.4069, validation loss: 0.0798
2024-05-22 21:36:20 [INFO]: Epoch 213 - training loss: 9272.5217, validation loss: 0.0781
2024-05-22 21:36:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:36:20 [INFO]: Finished training. The best model is from epoch#203.
2024-05-22 21:36:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/GPVAE_ettm1/20240522_T213557/GPVAE.pypots
2024-05-22 21:36:20 [INFO]: GP-VAE on ETTm1: MAE=0.2962, MSE=0.1784
2024-05-22 21:36:20 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/GPVAE_ettm1/imputation.pkl
2024-05-22 21:36:20 [INFO]: Using the given device: cuda:0
2024-05-22 21:36:20 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/USGAN_ettm1/20240522_T213620
2024-05-22 21:36:20 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/USGAN_ettm1/20240522_T213620/tensorboard
2024-05-22 21:36:20 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 21:36:28 [INFO]: Epoch 001 - generator training loss: 0.4715, discriminator training loss: 0.4333, validation loss: 0.2697
2024-05-22 21:36:35 [INFO]: Epoch 002 - generator training loss: -0.0175, discriminator training loss: 0.3245, validation loss: 0.1037
2024-05-22 21:36:42 [INFO]: Epoch 003 - generator training loss: -0.1299, discriminator training loss: 0.3123, validation loss: 0.0633
2024-05-22 21:36:48 [INFO]: Epoch 004 - generator training loss: -0.1435, discriminator training loss: 0.2994, validation loss: 0.0529
2024-05-22 21:36:55 [INFO]: Epoch 005 - generator training loss: -0.1338, discriminator training loss: 0.2836, validation loss: 0.0464
2024-05-22 21:37:02 [INFO]: Epoch 006 - generator training loss: -0.1108, discriminator training loss: 0.2528, validation loss: 0.0424
2024-05-22 21:37:09 [INFO]: Epoch 007 - generator training loss: -0.0806, discriminator training loss: 0.2139, validation loss: 0.0406
2024-05-22 21:37:16 [INFO]: Epoch 008 - generator training loss: -0.0607, discriminator training loss: 0.1799, validation loss: 0.0390
2024-05-22 21:37:23 [INFO]: Epoch 009 - generator training loss: -0.0434, discriminator training loss: 0.1571, validation loss: 0.0397
2024-05-22 21:37:30 [INFO]: Epoch 010 - generator training loss: -0.0359, discriminator training loss: 0.1415, validation loss: 0.0372
2024-05-22 21:37:37 [INFO]: Epoch 011 - generator training loss: -0.0319, discriminator training loss: 0.1313, validation loss: 0.0372
2024-05-22 21:37:44 [INFO]: Epoch 012 - generator training loss: -0.0308, discriminator training loss: 0.1270, validation loss: 0.0362
2024-05-22 21:37:51 [INFO]: Epoch 013 - generator training loss: -0.0334, discriminator training loss: 0.1272, validation loss: 0.0450
2024-05-22 21:37:58 [INFO]: Epoch 014 - generator training loss: -0.0244, discriminator training loss: 0.1224, validation loss: 0.0385
2024-05-22 21:38:04 [INFO]: Epoch 015 - generator training loss: -0.0290, discriminator training loss: 0.1204, validation loss: 0.0358
2024-05-22 21:38:11 [INFO]: Epoch 016 - generator training loss: -0.0265, discriminator training loss: 0.1182, validation loss: 0.0360
2024-05-22 21:38:18 [INFO]: Epoch 017 - generator training loss: -0.0298, discriminator training loss: 0.1180, validation loss: 0.0346
2024-05-22 21:38:25 [INFO]: Epoch 018 - generator training loss: -0.0292, discriminator training loss: 0.1180, validation loss: 0.0350
2024-05-22 21:38:32 [INFO]: Epoch 019 - generator training loss: -0.0273, discriminator training loss: 0.1171, validation loss: 0.0350
2024-05-22 21:38:39 [INFO]: Epoch 020 - generator training loss: -0.0295, discriminator training loss: 0.1158, validation loss: 0.0349
2024-05-22 21:38:46 [INFO]: Epoch 021 - generator training loss: -0.0305, discriminator training loss: 0.1136, validation loss: 0.0334
2024-05-22 21:38:53 [INFO]: Epoch 022 - generator training loss: -0.0330, discriminator training loss: 0.1136, validation loss: 0.0328
2024-05-22 21:39:00 [INFO]: Epoch 023 - generator training loss: -0.0318, discriminator training loss: 0.1148, validation loss: 0.0328
2024-05-22 21:39:06 [INFO]: Epoch 024 - generator training loss: -0.0350, discriminator training loss: 0.1149, validation loss: 0.0327
2024-05-22 21:39:13 [INFO]: Epoch 025 - generator training loss: -0.0337, discriminator training loss: 0.1128, validation loss: 0.0318
2024-05-22 21:39:20 [INFO]: Epoch 026 - generator training loss: -0.0364, discriminator training loss: 0.1146, validation loss: 0.0317
2024-05-22 21:39:27 [INFO]: Epoch 027 - generator training loss: -0.0349, discriminator training loss: 0.1138, validation loss: 0.0313
2024-05-22 21:39:35 [INFO]: Epoch 028 - generator training loss: -0.0359, discriminator training loss: 0.1147, validation loss: 0.0311
2024-05-22 21:39:42 [INFO]: Epoch 029 - generator training loss: -0.0336, discriminator training loss: 0.1127, validation loss: 0.0306
2024-05-22 21:39:49 [INFO]: Epoch 030 - generator training loss: -0.0359, discriminator training loss: 0.1135, validation loss: 0.0305
2024-05-22 21:39:56 [INFO]: Epoch 031 - generator training loss: -0.0359, discriminator training loss: 0.1124, validation loss: 0.0297
2024-05-22 21:40:02 [INFO]: Epoch 032 - generator training loss: -0.0362, discriminator training loss: 0.1121, validation loss: 0.0309
2024-05-22 21:40:09 [INFO]: Epoch 033 - generator training loss: -0.0360, discriminator training loss: 0.1108, validation loss: 0.0299
2024-05-22 21:40:16 [INFO]: Epoch 034 - generator training loss: -0.0367, discriminator training loss: 0.1110, validation loss: 0.0295
2024-05-22 21:40:23 [INFO]: Epoch 035 - generator training loss: -0.0362, discriminator training loss: 0.1102, validation loss: 0.0294
2024-05-22 21:40:30 [INFO]: Epoch 036 - generator training loss: -0.0403, discriminator training loss: 0.1127, validation loss: 0.0288
2024-05-22 21:40:37 [INFO]: Epoch 037 - generator training loss: -0.0346, discriminator training loss: 0.1115, validation loss: 0.0286
2024-05-22 21:40:44 [INFO]: Epoch 038 - generator training loss: -0.0376, discriminator training loss: 0.1113, validation loss: 0.0285
2024-05-22 21:40:51 [INFO]: Epoch 039 - generator training loss: -0.0409, discriminator training loss: 0.1124, validation loss: 0.0284
2024-05-22 21:40:58 [INFO]: Epoch 040 - generator training loss: -0.0375, discriminator training loss: 0.1088, validation loss: 0.0278
2024-05-22 21:41:05 [INFO]: Epoch 041 - generator training loss: -0.0411, discriminator training loss: 0.1112, validation loss: 0.0280
2024-05-22 21:41:12 [INFO]: Epoch 042 - generator training loss: -0.0387, discriminator training loss: 0.1114, validation loss: 0.0273
2024-05-22 21:41:19 [INFO]: Epoch 043 - generator training loss: -0.0416, discriminator training loss: 0.1096, validation loss: 0.0279
2024-05-22 21:41:25 [INFO]: Epoch 044 - generator training loss: -0.0381, discriminator training loss: 0.1093, validation loss: 0.0268
2024-05-22 21:41:32 [INFO]: Epoch 045 - generator training loss: -0.0420, discriminator training loss: 0.1111, validation loss: 0.0277
2024-05-22 21:41:39 [INFO]: Epoch 046 - generator training loss: -0.0375, discriminator training loss: 0.1081, validation loss: 0.0263
2024-05-22 21:41:46 [INFO]: Epoch 047 - generator training loss: -0.0412, discriminator training loss: 0.1121, validation loss: 0.0265
2024-05-22 21:41:53 [INFO]: Epoch 048 - generator training loss: -0.0383, discriminator training loss: 0.1092, validation loss: 0.0260
2024-05-22 21:42:00 [INFO]: Epoch 049 - generator training loss: -0.0442, discriminator training loss: 0.1110, validation loss: 0.0260
2024-05-22 21:42:07 [INFO]: Epoch 050 - generator training loss: -0.0416, discriminator training loss: 0.1091, validation loss: 0.0254
2024-05-22 21:42:14 [INFO]: Epoch 051 - generator training loss: -0.0406, discriminator training loss: 0.1093, validation loss: 0.0256
2024-05-22 21:42:21 [INFO]: Epoch 052 - generator training loss: -0.0428, discriminator training loss: 0.1092, validation loss: 0.0251
2024-05-22 21:42:28 [INFO]: Epoch 053 - generator training loss: -0.0436, discriminator training loss: 0.1092, validation loss: 0.0257
2024-05-22 21:42:34 [INFO]: Epoch 054 - generator training loss: -0.0432, discriminator training loss: 0.1100, validation loss: 0.0249
2024-05-22 21:42:41 [INFO]: Epoch 055 - generator training loss: -0.0459, discriminator training loss: 0.1112, validation loss: 0.0244
2024-05-22 21:42:48 [INFO]: Epoch 056 - generator training loss: -0.0434, discriminator training loss: 0.1087, validation loss: 0.0247
2024-05-22 21:42:55 [INFO]: Epoch 057 - generator training loss: -0.0446, discriminator training loss: 0.1092, validation loss: 0.0245
2024-05-22 21:43:02 [INFO]: Epoch 058 - generator training loss: -0.0425, discriminator training loss: 0.1078, validation loss: 0.0245
2024-05-22 21:43:09 [INFO]: Epoch 059 - generator training loss: -0.0431, discriminator training loss: 0.1067, validation loss: 0.0247
2024-05-22 21:43:16 [INFO]: Epoch 060 - generator training loss: -0.0459, discriminator training loss: 0.1095, validation loss: 0.0250
2024-05-22 21:43:23 [INFO]: Epoch 061 - generator training loss: -0.0454, discriminator training loss: 0.1104, validation loss: 0.0247
2024-05-22 21:43:30 [INFO]: Epoch 062 - generator training loss: -0.0425, discriminator training loss: 0.1091, validation loss: 0.0239
2024-05-22 21:43:37 [INFO]: Epoch 063 - generator training loss: -0.0475, discriminator training loss: 0.1070, validation loss: 0.0244
2024-05-22 21:43:44 [INFO]: Epoch 064 - generator training loss: -0.0444, discriminator training loss: 0.1084, validation loss: 0.0241
2024-05-22 21:43:51 [INFO]: Epoch 065 - generator training loss: -0.0414, discriminator training loss: 0.1072, validation loss: 0.0248
2024-05-22 21:43:57 [INFO]: Epoch 066 - generator training loss: -0.0429, discriminator training loss: 0.1108, validation loss: 0.0236
2024-05-22 21:44:04 [INFO]: Epoch 067 - generator training loss: -0.0428, discriminator training loss: 0.1100, validation loss: 0.0248
2024-05-22 21:44:11 [INFO]: Epoch 068 - generator training loss: -0.0459, discriminator training loss: 0.1058, validation loss: 0.0249
2024-05-22 21:44:18 [INFO]: Epoch 069 - generator training loss: -0.0445, discriminator training loss: 0.1059, validation loss: 0.0253
2024-05-22 21:44:25 [INFO]: Epoch 070 - generator training loss: -0.0460, discriminator training loss: 0.1065, validation loss: 0.0238
2024-05-22 21:44:32 [INFO]: Epoch 071 - generator training loss: -0.0416, discriminator training loss: 0.1072, validation loss: 0.0238
2024-05-22 21:44:39 [INFO]: Epoch 072 - generator training loss: -0.0464, discriminator training loss: 0.1074, validation loss: 0.0240
2024-05-22 21:44:46 [INFO]: Epoch 073 - generator training loss: -0.0436, discriminator training loss: 0.1070, validation loss: 0.0235
2024-05-22 21:44:53 [INFO]: Epoch 074 - generator training loss: -0.0429, discriminator training loss: 0.1073, validation loss: 0.0249
2024-05-22 21:45:00 [INFO]: Epoch 075 - generator training loss: -0.0448, discriminator training loss: 0.1081, validation loss: 0.0235
2024-05-22 21:45:06 [INFO]: Epoch 076 - generator training loss: -0.0442, discriminator training loss: 0.1078, validation loss: 0.0242
2024-05-22 21:45:13 [INFO]: Epoch 077 - generator training loss: -0.0462, discriminator training loss: 0.1068, validation loss: 0.0236
2024-05-22 21:45:20 [INFO]: Epoch 078 - generator training loss: -0.0453, discriminator training loss: 0.1090, validation loss: 0.0235
2024-05-22 21:45:27 [INFO]: Epoch 079 - generator training loss: -0.0457, discriminator training loss: 0.1076, validation loss: 0.0232
2024-05-22 21:45:34 [INFO]: Epoch 080 - generator training loss: -0.0476, discriminator training loss: 0.1058, validation loss: 0.0230
2024-05-22 21:45:41 [INFO]: Epoch 081 - generator training loss: -0.0461, discriminator training loss: 0.1047, validation loss: 0.0229
2024-05-22 21:45:48 [INFO]: Epoch 082 - generator training loss: -0.0493, discriminator training loss: 0.1065, validation loss: 0.0228
2024-05-22 21:45:55 [INFO]: Epoch 083 - generator training loss: -0.0463, discriminator training loss: 0.1071, validation loss: 0.0231
2024-05-22 21:46:02 [INFO]: Epoch 084 - generator training loss: -0.0481, discriminator training loss: 0.1052, validation loss: 0.0226
2024-05-22 21:46:09 [INFO]: Epoch 085 - generator training loss: -0.0473, discriminator training loss: 0.1042, validation loss: 0.0230
2024-05-22 21:46:16 [INFO]: Epoch 086 - generator training loss: -0.0482, discriminator training loss: 0.1053, validation loss: 0.0224
2024-05-22 21:46:23 [INFO]: Epoch 087 - generator training loss: -0.0485, discriminator training loss: 0.1032, validation loss: 0.0226
2024-05-22 21:46:29 [INFO]: Epoch 088 - generator training loss: -0.0484, discriminator training loss: 0.1063, validation loss: 0.0223
2024-05-22 21:46:36 [INFO]: Epoch 089 - generator training loss: -0.0460, discriminator training loss: 0.1038, validation loss: 0.0222
2024-05-22 21:46:43 [INFO]: Epoch 090 - generator training loss: -0.0472, discriminator training loss: 0.1073, validation loss: 0.0250
2024-05-22 21:46:50 [INFO]: Epoch 091 - generator training loss: -0.0455, discriminator training loss: 0.1055, validation loss: 0.0221
2024-05-22 21:46:57 [INFO]: Epoch 092 - generator training loss: -0.0477, discriminator training loss: 0.1064, validation loss: 0.0226
2024-05-22 21:47:04 [INFO]: Epoch 093 - generator training loss: -0.0477, discriminator training loss: 0.1060, validation loss: 0.0220
2024-05-22 21:47:11 [INFO]: Epoch 094 - generator training loss: -0.0480, discriminator training loss: 0.1061, validation loss: 0.0230
2024-05-22 21:47:18 [INFO]: Epoch 095 - generator training loss: -0.0516, discriminator training loss: 0.1070, validation loss: 0.0222
2024-05-22 21:47:25 [INFO]: Epoch 096 - generator training loss: -0.0462, discriminator training loss: 0.1057, validation loss: 0.0223
2024-05-22 21:47:32 [INFO]: Epoch 097 - generator training loss: -0.0470, discriminator training loss: 0.1051, validation loss: 0.0226
2024-05-22 21:47:39 [INFO]: Epoch 098 - generator training loss: -0.0451, discriminator training loss: 0.1042, validation loss: 0.0223
2024-05-22 21:47:45 [INFO]: Epoch 099 - generator training loss: -0.0486, discriminator training loss: 0.1039, validation loss: 0.0221
2024-05-22 21:47:52 [INFO]: Epoch 100 - generator training loss: -0.0467, discriminator training loss: 0.1040, validation loss: 0.0223
2024-05-22 21:47:59 [INFO]: Epoch 101 - generator training loss: -0.0512, discriminator training loss: 0.1053, validation loss: 0.0221
2024-05-22 21:48:06 [INFO]: Epoch 102 - generator training loss: -0.0452, discriminator training loss: 0.1066, validation loss: 0.0218
2024-05-22 21:48:13 [INFO]: Epoch 103 - generator training loss: -0.0481, discriminator training loss: 0.1076, validation loss: 0.0222
2024-05-22 21:48:20 [INFO]: Epoch 104 - generator training loss: -0.0479, discriminator training loss: 0.1034, validation loss: 0.0219
2024-05-22 21:48:27 [INFO]: Epoch 105 - generator training loss: -0.0495, discriminator training loss: 0.1063, validation loss: 0.0223
2024-05-22 21:48:34 [INFO]: Epoch 106 - generator training loss: -0.0483, discriminator training loss: 0.1032, validation loss: 0.0214
2024-05-22 21:48:41 [INFO]: Epoch 107 - generator training loss: -0.0482, discriminator training loss: 0.1041, validation loss: 0.0224
2024-05-22 21:48:48 [INFO]: Epoch 108 - generator training loss: -0.0492, discriminator training loss: 0.1063, validation loss: 0.0214
2024-05-22 21:48:54 [INFO]: Epoch 109 - generator training loss: -0.0496, discriminator training loss: 0.1054, validation loss: 0.0227
2024-05-22 21:49:01 [INFO]: Epoch 110 - generator training loss: -0.0476, discriminator training loss: 0.1048, validation loss: 0.0220
2024-05-22 21:49:08 [INFO]: Epoch 111 - generator training loss: -0.0491, discriminator training loss: 0.1039, validation loss: 0.0226
2024-05-22 21:49:15 [INFO]: Epoch 112 - generator training loss: -0.0500, discriminator training loss: 0.1035, validation loss: 0.0214
2024-05-22 21:49:22 [INFO]: Epoch 113 - generator training loss: -0.0494, discriminator training loss: 0.1046, validation loss: 0.0218
2024-05-22 21:49:29 [INFO]: Epoch 114 - generator training loss: -0.0487, discriminator training loss: 0.1056, validation loss: 0.0217
2024-05-22 21:49:36 [INFO]: Epoch 115 - generator training loss: -0.0501, discriminator training loss: 0.1046, validation loss: 0.0216
2024-05-22 21:49:43 [INFO]: Epoch 116 - generator training loss: -0.0484, discriminator training loss: 0.1049, validation loss: 0.0213
2024-05-22 21:49:50 [INFO]: Epoch 117 - generator training loss: -0.0475, discriminator training loss: 0.1042, validation loss: 0.0229
2024-05-22 21:49:57 [INFO]: Epoch 118 - generator training loss: -0.0485, discriminator training loss: 0.1039, validation loss: 0.0219
2024-05-22 21:50:04 [INFO]: Epoch 119 - generator training loss: -0.0492, discriminator training loss: 0.1046, validation loss: 0.0213
2024-05-22 21:50:10 [INFO]: Epoch 120 - generator training loss: -0.0490, discriminator training loss: 0.1061, validation loss: 0.0214
2024-05-22 21:50:17 [INFO]: Epoch 121 - generator training loss: -0.0502, discriminator training loss: 0.1047, validation loss: 0.0216
2024-05-22 21:50:24 [INFO]: Epoch 122 - generator training loss: -0.0459, discriminator training loss: 0.1058, validation loss: 0.0214
2024-05-22 21:50:31 [INFO]: Epoch 123 - generator training loss: -0.0459, discriminator training loss: 0.1053, validation loss: 0.0214
2024-05-22 21:50:38 [INFO]: Epoch 124 - generator training loss: -0.0472, discriminator training loss: 0.1042, validation loss: 0.0216
2024-05-22 21:50:45 [INFO]: Epoch 125 - generator training loss: -0.0504, discriminator training loss: 0.1028, validation loss: 0.0213
2024-05-22 21:50:52 [INFO]: Epoch 126 - generator training loss: -0.0477, discriminator training loss: 0.1055, validation loss: 0.0217
2024-05-22 21:51:00 [INFO]: Epoch 127 - generator training loss: -0.0491, discriminator training loss: 0.1043, validation loss: 0.0210
2024-05-22 21:51:07 [INFO]: Epoch 128 - generator training loss: -0.0490, discriminator training loss: 0.1043, validation loss: 0.0218
2024-05-22 21:51:14 [INFO]: Epoch 129 - generator training loss: -0.0481, discriminator training loss: 0.1066, validation loss: 0.0235
2024-05-22 21:51:21 [INFO]: Epoch 130 - generator training loss: -0.0464, discriminator training loss: 0.1038, validation loss: 0.0219
2024-05-22 21:51:28 [INFO]: Epoch 131 - generator training loss: -0.0464, discriminator training loss: 0.1052, validation loss: 0.0214
2024-05-22 21:51:35 [INFO]: Epoch 132 - generator training loss: -0.0514, discriminator training loss: 0.1042, validation loss: 0.0218
2024-05-22 21:51:42 [INFO]: Epoch 133 - generator training loss: -0.0479, discriminator training loss: 0.1019, validation loss: 0.0213
2024-05-22 21:51:49 [INFO]: Epoch 134 - generator training loss: -0.0495, discriminator training loss: 0.1050, validation loss: 0.0216
2024-05-22 21:51:55 [INFO]: Epoch 135 - generator training loss: -0.0502, discriminator training loss: 0.1050, validation loss: 0.0211
2024-05-22 21:52:02 [INFO]: Epoch 136 - generator training loss: -0.0488, discriminator training loss: 0.1017, validation loss: 0.0213
2024-05-22 21:52:09 [INFO]: Epoch 137 - generator training loss: -0.0493, discriminator training loss: 0.1037, validation loss: 0.0212
2024-05-22 21:52:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:52:09 [INFO]: Finished training. The best model is from epoch#127.
2024-05-22 21:52:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/USGAN_ettm1/20240522_T213620/USGAN.pypots
2024-05-22 21:52:10 [INFO]: US-GAN on ETTm1: MAE=0.1457, MSE=0.0537
2024-05-22 21:52:10 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/USGAN_ettm1/imputation.pkl
2024-05-22 21:52:10 [INFO]: Using the given device: cuda:0
2024-05-22 21:52:10 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/BRITS_ettm1/20240522_T215210
2024-05-22 21:52:10 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/BRITS_ettm1/20240522_T215210/tensorboard
2024-05-22 21:52:10 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 21:52:16 [INFO]: Epoch 001 - training loss: 1.3087, validation loss: 0.3381
2024-05-22 21:52:20 [INFO]: Epoch 002 - training loss: 0.8582, validation loss: 0.0978
2024-05-22 21:52:25 [INFO]: Epoch 003 - training loss: 0.7000, validation loss: 0.0520
2024-05-22 21:52:30 [INFO]: Epoch 004 - training loss: 0.6290, validation loss: 0.0453
2024-05-22 21:52:34 [INFO]: Epoch 005 - training loss: 0.6286, validation loss: 0.0383
2024-05-22 21:52:39 [INFO]: Epoch 006 - training loss: 0.5792, validation loss: 0.0401
2024-05-22 21:52:43 [INFO]: Epoch 007 - training loss: 0.5390, validation loss: 0.0368
2024-05-22 21:52:48 [INFO]: Epoch 008 - training loss: 0.5110, validation loss: 0.0369
2024-05-22 21:52:53 [INFO]: Epoch 009 - training loss: 0.4993, validation loss: 0.0339
2024-05-22 21:52:57 [INFO]: Epoch 010 - training loss: 0.4824, validation loss: 0.0318
2024-05-22 21:53:02 [INFO]: Epoch 011 - training loss: 0.4545, validation loss: 0.0311
2024-05-22 21:53:06 [INFO]: Epoch 012 - training loss: 0.4368, validation loss: 0.0293
2024-05-22 21:53:11 [INFO]: Epoch 013 - training loss: 0.4220, validation loss: 0.0285
2024-05-22 21:53:15 [INFO]: Epoch 014 - training loss: 0.4183, validation loss: 0.0278
2024-05-22 21:53:20 [INFO]: Epoch 015 - training loss: 0.4047, validation loss: 0.0266
2024-05-22 21:53:25 [INFO]: Epoch 016 - training loss: 0.3976, validation loss: 0.0265
2024-05-22 21:53:29 [INFO]: Epoch 017 - training loss: 0.3966, validation loss: 0.0260
2024-05-22 21:53:34 [INFO]: Epoch 018 - training loss: 0.3952, validation loss: 0.0258
2024-05-22 21:53:38 [INFO]: Epoch 019 - training loss: 0.3902, validation loss: 0.0258
2024-05-22 21:53:43 [INFO]: Epoch 020 - training loss: 0.3959, validation loss: 0.0256
2024-05-22 21:53:47 [INFO]: Epoch 021 - training loss: 0.3880, validation loss: 0.0252
2024-05-22 21:53:52 [INFO]: Epoch 022 - training loss: 0.3874, validation loss: 0.0253
2024-05-22 21:53:57 [INFO]: Epoch 023 - training loss: 0.3919, validation loss: 0.0254
2024-05-22 21:54:01 [INFO]: Epoch 024 - training loss: 0.3897, validation loss: 0.0257
2024-05-22 21:54:06 [INFO]: Epoch 025 - training loss: 0.3863, validation loss: 0.0250
2024-05-22 21:54:10 [INFO]: Epoch 026 - training loss: 0.3928, validation loss: 0.0252
2024-05-22 21:54:15 [INFO]: Epoch 027 - training loss: 0.3911, validation loss: 0.0253
2024-05-22 21:54:20 [INFO]: Epoch 028 - training loss: 0.3989, validation loss: 0.0251
2024-05-22 21:54:25 [INFO]: Epoch 029 - training loss: 0.4028, validation loss: 0.0253
2024-05-22 21:54:29 [INFO]: Epoch 030 - training loss: 0.3971, validation loss: 0.0256
2024-05-22 21:54:34 [INFO]: Epoch 031 - training loss: 0.3849, validation loss: 0.0251
2024-05-22 21:54:39 [INFO]: Epoch 032 - training loss: 0.3820, validation loss: 0.0248
2024-05-22 21:54:43 [INFO]: Epoch 033 - training loss: 0.3827, validation loss: 0.0247
2024-05-22 21:54:48 [INFO]: Epoch 034 - training loss: 0.3829, validation loss: 0.0249
2024-05-22 21:54:53 [INFO]: Epoch 035 - training loss: 0.3821, validation loss: 0.0253
2024-05-22 21:54:57 [INFO]: Epoch 036 - training loss: 0.3847, validation loss: 0.0252
2024-05-22 21:55:02 [INFO]: Epoch 037 - training loss: 0.3831, validation loss: 0.0263
2024-05-22 21:55:06 [INFO]: Epoch 038 - training loss: 0.3805, validation loss: 0.0245
2024-05-22 21:55:11 [INFO]: Epoch 039 - training loss: 0.3821, validation loss: 0.0250
2024-05-22 21:55:16 [INFO]: Epoch 040 - training loss: 0.3800, validation loss: 0.0254
2024-05-22 21:55:20 [INFO]: Epoch 041 - training loss: 0.3861, validation loss: 0.0244
2024-05-22 21:55:25 [INFO]: Epoch 042 - training loss: 0.3810, validation loss: 0.0258
2024-05-22 21:55:30 [INFO]: Epoch 043 - training loss: 0.3822, validation loss: 0.0251
2024-05-22 21:55:34 [INFO]: Epoch 044 - training loss: 0.3776, validation loss: 0.0258
2024-05-22 21:55:39 [INFO]: Epoch 045 - training loss: 0.3774, validation loss: 0.0258
2024-05-22 21:55:43 [INFO]: Epoch 046 - training loss: 0.3827, validation loss: 0.0260
2024-05-22 21:55:48 [INFO]: Epoch 047 - training loss: 0.3763, validation loss: 0.0245
2024-05-22 21:55:52 [INFO]: Epoch 048 - training loss: 0.3767, validation loss: 0.0247
2024-05-22 21:55:57 [INFO]: Epoch 049 - training loss: 0.3784, validation loss: 0.0255
2024-05-22 21:56:02 [INFO]: Epoch 050 - training loss: 0.4438, validation loss: 0.0258
2024-05-22 21:56:06 [INFO]: Epoch 051 - training loss: 0.4187, validation loss: 0.0287
2024-05-22 21:56:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:56:06 [INFO]: Finished training. The best model is from epoch#41.
2024-05-22 21:56:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/BRITS_ettm1/20240522_T215210/BRITS.pypots
2024-05-22 21:56:07 [INFO]: BRITS on ETTm1: MAE=0.1619, MSE=0.0708
2024-05-22 21:56:07 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/BRITS_ettm1/imputation.pkl
2024-05-22 21:56:07 [INFO]: Using the given device: cuda:0
2024-05-22 21:56:07 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607
2024-05-22 21:56:07 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/tensorboard
2024-05-22 21:56:07 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 21:56:08 [INFO]: Epoch 001 - training loss: 1.3747, validation loss: 1.2832
2024-05-22 21:56:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch1_loss1.283198133111.pypots
2024-05-22 21:56:08 [INFO]: Epoch 002 - training loss: 1.0521, validation loss: 1.1533
2024-05-22 21:56:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch2_loss1.1532504856586456.pypots
2024-05-22 21:56:08 [INFO]: Epoch 003 - training loss: 0.9822, validation loss: 1.0864
2024-05-22 21:56:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch3_loss1.0864287614822388.pypots
2024-05-22 21:56:09 [INFO]: Epoch 004 - training loss: 0.9368, validation loss: 1.0510
2024-05-22 21:56:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch4_loss1.0510066896677017.pypots
2024-05-22 21:56:09 [INFO]: Epoch 005 - training loss: 0.9162, validation loss: 1.0344
2024-05-22 21:56:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch5_loss1.0343853682279587.pypots
2024-05-22 21:56:09 [INFO]: Epoch 006 - training loss: 0.9541, validation loss: 1.0217
2024-05-22 21:56:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch6_loss1.0217022597789764.pypots
2024-05-22 21:56:09 [INFO]: Epoch 007 - training loss: 0.9619, validation loss: 1.0137
2024-05-22 21:56:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch7_loss1.0136921256780624.pypots
2024-05-22 21:56:09 [INFO]: Epoch 008 - training loss: 0.9213, validation loss: 1.0081
2024-05-22 21:56:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch8_loss1.0080662816762924.pypots
2024-05-22 21:56:09 [INFO]: Epoch 009 - training loss: 0.8959, validation loss: 1.0011
2024-05-22 21:56:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch9_loss1.0010780841112137.pypots
2024-05-22 21:56:10 [INFO]: Epoch 010 - training loss: 0.8945, validation loss: 1.0029
2024-05-22 21:56:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch10_loss1.0029105693101883.pypots
2024-05-22 21:56:10 [INFO]: Epoch 011 - training loss: 0.8706, validation loss: 1.0005
2024-05-22 21:56:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch11_loss1.0005301982164383.pypots
2024-05-22 21:56:10 [INFO]: Epoch 012 - training loss: 0.8797, validation loss: 0.9957
2024-05-22 21:56:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch12_loss0.9956517815589905.pypots
2024-05-22 21:56:10 [INFO]: Epoch 013 - training loss: 0.8976, validation loss: 0.9901
2024-05-22 21:56:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch13_loss0.9901435822248459.pypots
2024-05-22 21:56:10 [INFO]: Epoch 014 - training loss: 0.8741, validation loss: 0.9871
2024-05-22 21:56:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch14_loss0.9870524406433105.pypots
2024-05-22 21:56:10 [INFO]: Epoch 015 - training loss: 0.9159, validation loss: 0.9829
2024-05-22 21:56:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch15_loss0.9828960299491882.pypots
2024-05-22 21:56:10 [INFO]: Epoch 016 - training loss: 0.9038, validation loss: 0.9827
2024-05-22 21:56:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch16_loss0.9826685190200806.pypots
2024-05-22 21:56:11 [INFO]: Epoch 017 - training loss: 0.8447, validation loss: 0.9794
2024-05-22 21:56:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch17_loss0.9793797135353088.pypots
2024-05-22 21:56:11 [INFO]: Epoch 018 - training loss: 0.8594, validation loss: 0.9735
2024-05-22 21:56:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch18_loss0.9735369831323624.pypots
2024-05-22 21:56:11 [INFO]: Epoch 019 - training loss: 0.8438, validation loss: 0.9716
2024-05-22 21:56:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch19_loss0.9715548455715179.pypots
2024-05-22 21:56:11 [INFO]: Epoch 020 - training loss: 0.8516, validation loss: 0.9691
2024-05-22 21:56:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch20_loss0.9690848737955093.pypots
2024-05-22 21:56:11 [INFO]: Epoch 021 - training loss: 0.8120, validation loss: 0.9672
2024-05-22 21:56:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch21_loss0.967150554060936.pypots
2024-05-22 21:56:11 [INFO]: Epoch 022 - training loss: 0.8419, validation loss: 0.9609
2024-05-22 21:56:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch22_loss0.9608548879623413.pypots
2024-05-22 21:56:12 [INFO]: Epoch 023 - training loss: 0.8371, validation loss: 0.9582
2024-05-22 21:56:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch23_loss0.9582092314958572.pypots
2024-05-22 21:56:12 [INFO]: Epoch 024 - training loss: 0.8359, validation loss: 0.9567
2024-05-22 21:56:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch24_loss0.9566858559846878.pypots
2024-05-22 21:56:12 [INFO]: Epoch 025 - training loss: 0.8119, validation loss: 0.9577
2024-05-22 21:56:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch25_loss0.9576665908098221.pypots
2024-05-22 21:56:12 [INFO]: Epoch 026 - training loss: 0.8349, validation loss: 0.9571
2024-05-22 21:56:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch26_loss0.9570977091789246.pypots
2024-05-22 21:56:12 [INFO]: Epoch 027 - training loss: 0.8114, validation loss: 0.9536
2024-05-22 21:56:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch27_loss0.9536433815956116.pypots
2024-05-22 21:56:12 [INFO]: Epoch 028 - training loss: 0.8284, validation loss: 0.9540
2024-05-22 21:56:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch28_loss0.9540064930915833.pypots
2024-05-22 21:56:13 [INFO]: Epoch 029 - training loss: 0.8110, validation loss: 0.9523
2024-05-22 21:56:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch29_loss0.9522836953401566.pypots
2024-05-22 21:56:13 [INFO]: Epoch 030 - training loss: 0.8209, validation loss: 0.9507
2024-05-22 21:56:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch30_loss0.9506591409444809.pypots
2024-05-22 21:56:13 [INFO]: Epoch 031 - training loss: 0.8373, validation loss: 0.9492
2024-05-22 21:56:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch31_loss0.9491552114486694.pypots
2024-05-22 21:56:13 [INFO]: Epoch 032 - training loss: 0.7917, validation loss: 0.9489
2024-05-22 21:56:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch32_loss0.9488899260759354.pypots
2024-05-22 21:56:13 [INFO]: Epoch 033 - training loss: 0.7998, validation loss: 0.9447
2024-05-22 21:56:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch33_loss0.9446885883808136.pypots
2024-05-22 21:56:13 [INFO]: Epoch 034 - training loss: 0.8137, validation loss: 0.9424
2024-05-22 21:56:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch34_loss0.9424130171537399.pypots
2024-05-22 21:56:13 [INFO]: Epoch 035 - training loss: 0.8219, validation loss: 0.9422
2024-05-22 21:56:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch35_loss0.9422177523374557.pypots
2024-05-22 21:56:14 [INFO]: Epoch 036 - training loss: 0.7946, validation loss: 0.9375
2024-05-22 21:56:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch36_loss0.9375443309545517.pypots
2024-05-22 21:56:14 [INFO]: Epoch 037 - training loss: 0.8185, validation loss: 0.9330
2024-05-22 21:56:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch37_loss0.9330302029848099.pypots
2024-05-22 21:56:14 [INFO]: Epoch 038 - training loss: 0.8287, validation loss: 0.9312
2024-05-22 21:56:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch38_loss0.9312452524900436.pypots
2024-05-22 21:56:14 [INFO]: Epoch 039 - training loss: 0.8128, validation loss: 0.9281
2024-05-22 21:56:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch39_loss0.9281054586172104.pypots
2024-05-22 21:56:14 [INFO]: Epoch 040 - training loss: 0.8100, validation loss: 0.9249
2024-05-22 21:56:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch40_loss0.9249481558799744.pypots
2024-05-22 21:56:14 [INFO]: Epoch 041 - training loss: 0.7984, validation loss: 0.9217
2024-05-22 21:56:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch41_loss0.9216704219579697.pypots
2024-05-22 21:56:15 [INFO]: Epoch 042 - training loss: 0.7877, validation loss: 0.9170
2024-05-22 21:56:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch42_loss0.9170152693986893.pypots
2024-05-22 21:56:15 [INFO]: Epoch 043 - training loss: 0.8021, validation loss: 0.9156
2024-05-22 21:56:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch43_loss0.9156318008899689.pypots
2024-05-22 21:56:15 [INFO]: Epoch 044 - training loss: 0.8435, validation loss: 0.9129
2024-05-22 21:56:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch44_loss0.9129090458154678.pypots
2024-05-22 21:56:15 [INFO]: Epoch 045 - training loss: 0.7978, validation loss: 0.9132
2024-05-22 21:56:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch45_loss0.9131981581449509.pypots
2024-05-22 21:56:15 [INFO]: Epoch 046 - training loss: 0.7974, validation loss: 0.9101
2024-05-22 21:56:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch46_loss0.9101301282644272.pypots
2024-05-22 21:56:15 [INFO]: Epoch 047 - training loss: 0.7724, validation loss: 0.9082
2024-05-22 21:56:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch47_loss0.9082320034503937.pypots
2024-05-22 21:56:16 [INFO]: Epoch 048 - training loss: 0.7874, validation loss: 0.9066
2024-05-22 21:56:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch48_loss0.9065655767917633.pypots
2024-05-22 21:56:16 [INFO]: Epoch 049 - training loss: 0.7740, validation loss: 0.9032
2024-05-22 21:56:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch49_loss0.9032171666622162.pypots
2024-05-22 21:56:16 [INFO]: Epoch 050 - training loss: 0.7919, validation loss: 0.9019
2024-05-22 21:56:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch50_loss0.901948869228363.pypots
2024-05-22 21:56:16 [INFO]: Epoch 051 - training loss: 0.7867, validation loss: 0.9007
2024-05-22 21:56:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch51_loss0.9007342308759689.pypots
2024-05-22 21:56:16 [INFO]: Epoch 052 - training loss: 0.7782, validation loss: 0.8990
2024-05-22 21:56:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch52_loss0.8990278989076614.pypots
2024-05-22 21:56:16 [INFO]: Epoch 053 - training loss: 0.7905, validation loss: 0.8960
2024-05-22 21:56:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch53_loss0.8959703743457794.pypots
2024-05-22 21:56:17 [INFO]: Epoch 054 - training loss: 0.8079, validation loss: 0.8973
2024-05-22 21:56:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch54_loss0.8973464369773865.pypots
2024-05-22 21:56:17 [INFO]: Epoch 055 - training loss: 0.7941, validation loss: 0.8938
2024-05-22 21:56:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch55_loss0.8937520235776901.pypots
2024-05-22 21:56:17 [INFO]: Epoch 056 - training loss: 0.8170, validation loss: 0.8940
2024-05-22 21:56:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch56_loss0.8939607590436935.pypots
2024-05-22 21:56:17 [INFO]: Epoch 057 - training loss: 0.8188, validation loss: 0.8925
2024-05-22 21:56:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch57_loss0.8925377130508423.pypots
2024-05-22 21:56:17 [INFO]: Epoch 058 - training loss: 0.7688, validation loss: 0.8918
2024-05-22 21:56:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch58_loss0.8917825073003769.pypots
2024-05-22 21:56:17 [INFO]: Epoch 059 - training loss: 0.7967, validation loss: 0.8932
2024-05-22 21:56:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch59_loss0.8931940346956253.pypots
2024-05-22 21:56:17 [INFO]: Epoch 060 - training loss: 0.8134, validation loss: 0.8929
2024-05-22 21:56:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch60_loss0.8928601443767548.pypots
2024-05-22 21:56:18 [INFO]: Epoch 061 - training loss: 0.7851, validation loss: 0.8922
2024-05-22 21:56:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch61_loss0.8922018110752106.pypots
2024-05-22 21:56:18 [INFO]: Epoch 062 - training loss: 0.7674, validation loss: 0.8920
2024-05-22 21:56:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch62_loss0.8919969648122787.pypots
2024-05-22 21:56:18 [INFO]: Epoch 063 - training loss: 0.7890, validation loss: 0.8914
2024-05-22 21:56:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch63_loss0.8913526087999344.pypots
2024-05-22 21:56:18 [INFO]: Epoch 064 - training loss: 0.7923, validation loss: 0.8868
2024-05-22 21:56:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch64_loss0.8868200331926346.pypots
2024-05-22 21:56:18 [INFO]: Epoch 065 - training loss: 0.7862, validation loss: 0.8911
2024-05-22 21:56:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch65_loss0.8911418318748474.pypots
2024-05-22 21:56:18 [INFO]: Epoch 066 - training loss: 0.7697, validation loss: 0.8885
2024-05-22 21:56:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch66_loss0.8884808421134949.pypots
2024-05-22 21:56:19 [INFO]: Epoch 067 - training loss: 0.7946, validation loss: 0.8893
2024-05-22 21:56:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch67_loss0.8892809301614761.pypots
2024-05-22 21:56:19 [INFO]: Epoch 068 - training loss: 0.7976, validation loss: 0.8871
2024-05-22 21:56:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch68_loss0.8870843201875687.pypots
2024-05-22 21:56:19 [INFO]: Epoch 069 - training loss: 0.7753, validation loss: 0.8872
2024-05-22 21:56:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch69_loss0.8872493505477905.pypots
2024-05-22 21:56:19 [INFO]: Epoch 070 - training loss: 0.7949, validation loss: 0.8859
2024-05-22 21:56:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch70_loss0.8859083354473114.pypots
2024-05-22 21:56:19 [INFO]: Epoch 071 - training loss: 0.7888, validation loss: 0.8833
2024-05-22 21:56:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch71_loss0.8833163380622864.pypots
2024-05-22 21:56:19 [INFO]: Epoch 072 - training loss: 0.7592, validation loss: 0.8824
2024-05-22 21:56:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch72_loss0.8824072927236557.pypots
2024-05-22 21:56:20 [INFO]: Epoch 073 - training loss: 0.7762, validation loss: 0.8854
2024-05-22 21:56:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch73_loss0.8853547871112823.pypots
2024-05-22 21:56:20 [INFO]: Epoch 074 - training loss: 0.7731, validation loss: 0.8842
2024-05-22 21:56:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch74_loss0.884196475148201.pypots
2024-05-22 21:56:20 [INFO]: Epoch 075 - training loss: 0.7688, validation loss: 0.8835
2024-05-22 21:56:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch75_loss0.8834868371486664.pypots
2024-05-22 21:56:20 [INFO]: Epoch 076 - training loss: 0.7772, validation loss: 0.8854
2024-05-22 21:56:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch76_loss0.8853825926780701.pypots
2024-05-22 21:56:20 [INFO]: Epoch 077 - training loss: 0.7932, validation loss: 0.8811
2024-05-22 21:56:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch77_loss0.8811495155096054.pypots
2024-05-22 21:56:20 [INFO]: Epoch 078 - training loss: 0.7899, validation loss: 0.8810
2024-05-22 21:56:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch78_loss0.8809908479452133.pypots
2024-05-22 21:56:20 [INFO]: Epoch 079 - training loss: 0.7717, validation loss: 0.8802
2024-05-22 21:56:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch79_loss0.8801720142364502.pypots
2024-05-22 21:56:21 [INFO]: Epoch 080 - training loss: 0.7761, validation loss: 0.8793
2024-05-22 21:56:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch80_loss0.8792649656534195.pypots
2024-05-22 21:56:21 [INFO]: Epoch 081 - training loss: 0.7671, validation loss: 0.8828
2024-05-22 21:56:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch81_loss0.8827797919511795.pypots
2024-05-22 21:56:21 [INFO]: Epoch 082 - training loss: 0.7709, validation loss: 0.8830
2024-05-22 21:56:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch82_loss0.8829991370439529.pypots
2024-05-22 21:56:21 [INFO]: Epoch 083 - training loss: 0.8206, validation loss: 0.8822
2024-05-22 21:56:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch83_loss0.8822202086448669.pypots
2024-05-22 21:56:21 [INFO]: Epoch 084 - training loss: 0.7697, validation loss: 0.8822
2024-05-22 21:56:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch84_loss0.8821970224380493.pypots
2024-05-22 21:56:21 [INFO]: Epoch 085 - training loss: 0.7776, validation loss: 0.8783
2024-05-22 21:56:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch85_loss0.878325417637825.pypots
2024-05-22 21:56:22 [INFO]: Epoch 086 - training loss: 0.7610, validation loss: 0.8789
2024-05-22 21:56:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch86_loss0.8789398372173309.pypots
2024-05-22 21:56:22 [INFO]: Epoch 087 - training loss: 0.7911, validation loss: 0.8833
2024-05-22 21:56:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch87_loss0.8832902163267136.pypots
2024-05-22 21:56:22 [INFO]: Epoch 088 - training loss: 0.7950, validation loss: 0.8808
2024-05-22 21:56:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch88_loss0.8807874321937561.pypots
2024-05-22 21:56:22 [INFO]: Epoch 089 - training loss: 0.7661, validation loss: 0.8822
2024-05-22 21:56:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch89_loss0.8822146058082581.pypots
2024-05-22 21:56:22 [INFO]: Epoch 090 - training loss: 0.7727, validation loss: 0.8809
2024-05-22 21:56:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch90_loss0.8808537572622299.pypots
2024-05-22 21:56:22 [INFO]: Epoch 091 - training loss: 0.7786, validation loss: 0.8748
2024-05-22 21:56:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch91_loss0.8747885674238205.pypots
2024-05-22 21:56:23 [INFO]: Epoch 092 - training loss: 0.8253, validation loss: 0.8770
2024-05-22 21:56:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch92_loss0.877030998468399.pypots
2024-05-22 21:56:23 [INFO]: Epoch 093 - training loss: 0.7781, validation loss: 0.8781
2024-05-22 21:56:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch93_loss0.8781459480524063.pypots
2024-05-22 21:56:23 [INFO]: Epoch 094 - training loss: 0.7621, validation loss: 0.8748
2024-05-22 21:56:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch94_loss0.8747831135988235.pypots
2024-05-22 21:56:23 [INFO]: Epoch 095 - training loss: 0.7640, validation loss: 0.8752
2024-05-22 21:56:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch95_loss0.8751517534255981.pypots
2024-05-22 21:56:23 [INFO]: Epoch 096 - training loss: 0.7817, validation loss: 0.8783
2024-05-22 21:56:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch96_loss0.8782545030117035.pypots
2024-05-22 21:56:23 [INFO]: Epoch 097 - training loss: 0.7515, validation loss: 0.8759
2024-05-22 21:56:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch97_loss0.8759391754865646.pypots
2024-05-22 21:56:23 [INFO]: Epoch 098 - training loss: 0.7801, validation loss: 0.8772
2024-05-22 21:56:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch98_loss0.8771890848875046.pypots
2024-05-22 21:56:24 [INFO]: Epoch 099 - training loss: 0.7739, validation loss: 0.8704
2024-05-22 21:56:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch99_loss0.8703635931015015.pypots
2024-05-22 21:56:24 [INFO]: Epoch 100 - training loss: 0.7824, validation loss: 0.8729
2024-05-22 21:56:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch100_loss0.8728890866041183.pypots
2024-05-22 21:56:24 [INFO]: Epoch 101 - training loss: 0.7714, validation loss: 0.8738
2024-05-22 21:56:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch101_loss0.8737690299749374.pypots
2024-05-22 21:56:24 [INFO]: Epoch 102 - training loss: 0.7656, validation loss: 0.8724
2024-05-22 21:56:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch102_loss0.872437059879303.pypots
2024-05-22 21:56:24 [INFO]: Epoch 103 - training loss: 0.7612, validation loss: 0.8699
2024-05-22 21:56:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch103_loss0.8699442148208618.pypots
2024-05-22 21:56:24 [INFO]: Epoch 104 - training loss: 0.7638, validation loss: 0.8743
2024-05-22 21:56:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch104_loss0.8743087202310562.pypots
2024-05-22 21:56:25 [INFO]: Epoch 105 - training loss: 0.7787, validation loss: 0.8723
2024-05-22 21:56:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch105_loss0.8723238706588745.pypots
2024-05-22 21:56:25 [INFO]: Epoch 106 - training loss: 0.7753, validation loss: 0.8726
2024-05-22 21:56:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch106_loss0.8725990355014801.pypots
2024-05-22 21:56:25 [INFO]: Epoch 107 - training loss: 0.7700, validation loss: 0.8720
2024-05-22 21:56:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch107_loss0.8720261007547379.pypots
2024-05-22 21:56:25 [INFO]: Epoch 108 - training loss: 0.7453, validation loss: 0.8722
2024-05-22 21:56:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch108_loss0.8722376078367233.pypots
2024-05-22 21:56:25 [INFO]: Epoch 109 - training loss: 0.7649, validation loss: 0.8739
2024-05-22 21:56:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch109_loss0.8739454597234726.pypots
2024-05-22 21:56:25 [INFO]: Epoch 110 - training loss: 0.7611, validation loss: 0.8698
2024-05-22 21:56:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch110_loss0.869849368929863.pypots
2024-05-22 21:56:26 [INFO]: Epoch 111 - training loss: 0.7648, validation loss: 0.8699
2024-05-22 21:56:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch111_loss0.8698982894420624.pypots
2024-05-22 21:56:26 [INFO]: Epoch 112 - training loss: 0.7705, validation loss: 0.8709
2024-05-22 21:56:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch112_loss0.87087382376194.pypots
2024-05-22 21:56:26 [INFO]: Epoch 113 - training loss: 0.7768, validation loss: 0.8685
2024-05-22 21:56:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch113_loss0.8685203045606613.pypots
2024-05-22 21:56:26 [INFO]: Epoch 114 - training loss: 0.8079, validation loss: 0.8705
2024-05-22 21:56:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch114_loss0.8705249726772308.pypots
2024-05-22 21:56:26 [INFO]: Epoch 115 - training loss: 0.7695, validation loss: 0.8621
2024-05-22 21:56:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch115_loss0.8621069639921188.pypots
2024-05-22 21:56:26 [INFO]: Epoch 116 - training loss: 0.7720, validation loss: 0.8669
2024-05-22 21:56:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch116_loss0.866859182715416.pypots
2024-05-22 21:56:27 [INFO]: Epoch 117 - training loss: 0.7658, validation loss: 0.8690
2024-05-22 21:56:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch117_loss0.8690101057291031.pypots
2024-05-22 21:56:27 [INFO]: Epoch 118 - training loss: 0.7902, validation loss: 0.8650
2024-05-22 21:56:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch118_loss0.8649622350931168.pypots
2024-05-22 21:56:27 [INFO]: Epoch 119 - training loss: 0.7761, validation loss: 0.8670
2024-05-22 21:56:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch119_loss0.8670483976602554.pypots
2024-05-22 21:56:27 [INFO]: Epoch 120 - training loss: 0.7609, validation loss: 0.8632
2024-05-22 21:56:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch120_loss0.863175705075264.pypots
2024-05-22 21:56:27 [INFO]: Epoch 121 - training loss: 0.7422, validation loss: 0.8676
2024-05-22 21:56:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch121_loss0.8676493614912033.pypots
2024-05-22 21:56:27 [INFO]: Epoch 122 - training loss: 0.7802, validation loss: 0.8642
2024-05-22 21:56:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch122_loss0.8641894161701202.pypots
2024-05-22 21:56:27 [INFO]: Epoch 123 - training loss: 0.7591, validation loss: 0.8608
2024-05-22 21:56:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch123_loss0.8608013391494751.pypots
2024-05-22 21:56:28 [INFO]: Epoch 124 - training loss: 0.7536, validation loss: 0.8616
2024-05-22 21:56:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch124_loss0.8616374135017395.pypots
2024-05-22 21:56:28 [INFO]: Epoch 125 - training loss: 0.7532, validation loss: 0.8647
2024-05-22 21:56:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch125_loss0.8646537065505981.pypots
2024-05-22 21:56:28 [INFO]: Epoch 126 - training loss: 0.7694, validation loss: 0.8599
2024-05-22 21:56:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch126_loss0.8598693460226059.pypots
2024-05-22 21:56:28 [INFO]: Epoch 127 - training loss: 0.7800, validation loss: 0.8642
2024-05-22 21:56:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch127_loss0.8641667068004608.pypots
2024-05-22 21:56:28 [INFO]: Epoch 128 - training loss: 0.7615, validation loss: 0.8582
2024-05-22 21:56:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch128_loss0.8581930696964264.pypots
2024-05-22 21:56:28 [INFO]: Epoch 129 - training loss: 0.7795, validation loss: 0.8589
2024-05-22 21:56:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch129_loss0.8588849157094955.pypots
2024-05-22 21:56:29 [INFO]: Epoch 130 - training loss: 0.7645, validation loss: 0.8591
2024-05-22 21:56:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch130_loss0.8590884059667587.pypots
2024-05-22 21:56:29 [INFO]: Epoch 131 - training loss: 0.7531, validation loss: 0.8621
2024-05-22 21:56:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch131_loss0.8620880842208862.pypots
2024-05-22 21:56:29 [INFO]: Epoch 132 - training loss: 0.7524, validation loss: 0.8626
2024-05-22 21:56:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch132_loss0.862555205821991.pypots
2024-05-22 21:56:29 [INFO]: Epoch 133 - training loss: 0.7709, validation loss: 0.8578
2024-05-22 21:56:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch133_loss0.8578419238328934.pypots
2024-05-22 21:56:29 [INFO]: Epoch 134 - training loss: 0.7623, validation loss: 0.8566
2024-05-22 21:56:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch134_loss0.856594979763031.pypots
2024-05-22 21:56:29 [INFO]: Epoch 135 - training loss: 0.7683, validation loss: 0.8542
2024-05-22 21:56:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch135_loss0.8541925698518753.pypots
2024-05-22 21:56:30 [INFO]: Epoch 136 - training loss: 0.7711, validation loss: 0.8550
2024-05-22 21:56:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch136_loss0.8550053983926773.pypots
2024-05-22 21:56:30 [INFO]: Epoch 137 - training loss: 0.7642, validation loss: 0.8545
2024-05-22 21:56:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch137_loss0.8545234054327011.pypots
2024-05-22 21:56:30 [INFO]: Epoch 138 - training loss: 0.7742, validation loss: 0.8560
2024-05-22 21:56:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch138_loss0.8560499101877213.pypots
2024-05-22 21:56:30 [INFO]: Epoch 139 - training loss: 0.7804, validation loss: 0.8572
2024-05-22 21:56:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch139_loss0.857150673866272.pypots
2024-05-22 21:56:30 [INFO]: Epoch 140 - training loss: 0.7648, validation loss: 0.8505
2024-05-22 21:56:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch140_loss0.8504719138145447.pypots
2024-05-22 21:56:30 [INFO]: Epoch 141 - training loss: 0.7684, validation loss: 0.8535
2024-05-22 21:56:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch141_loss0.8535486608743668.pypots
2024-05-22 21:56:30 [INFO]: Epoch 142 - training loss: 0.7432, validation loss: 0.8511
2024-05-22 21:56:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch142_loss0.8510987609624863.pypots
2024-05-22 21:56:31 [INFO]: Epoch 143 - training loss: 0.8152, validation loss: 0.8540
2024-05-22 21:56:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch143_loss0.8539924323558807.pypots
2024-05-22 21:56:31 [INFO]: Epoch 144 - training loss: 0.7800, validation loss: 0.8466
2024-05-22 21:56:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch144_loss0.8465545475482941.pypots
2024-05-22 21:56:31 [INFO]: Epoch 145 - training loss: 0.7409, validation loss: 0.8467
2024-05-22 21:56:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch145_loss0.8466799259185791.pypots
2024-05-22 21:56:31 [INFO]: Epoch 146 - training loss: 0.7491, validation loss: 0.8529
2024-05-22 21:56:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch146_loss0.8528935015201569.pypots
2024-05-22 21:56:31 [INFO]: Epoch 147 - training loss: 0.7880, validation loss: 0.8473
2024-05-22 21:56:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch147_loss0.8473296612501144.pypots
2024-05-22 21:56:31 [INFO]: Epoch 148 - training loss: 0.7662, validation loss: 0.8480
2024-05-22 21:56:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch148_loss0.848037913441658.pypots
2024-05-22 21:56:32 [INFO]: Epoch 149 - training loss: 0.7518, validation loss: 0.8446
2024-05-22 21:56:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch149_loss0.8445994853973389.pypots
2024-05-22 21:56:32 [INFO]: Epoch 150 - training loss: 0.7551, validation loss: 0.8467
2024-05-22 21:56:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch150_loss0.8466512262821198.pypots
2024-05-22 21:56:32 [INFO]: Epoch 151 - training loss: 0.7669, validation loss: 0.8469
2024-05-22 21:56:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch151_loss0.8468929678201675.pypots
2024-05-22 21:56:32 [INFO]: Epoch 152 - training loss: 0.7436, validation loss: 0.8448
2024-05-22 21:56:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch152_loss0.8448252379894257.pypots
2024-05-22 21:56:32 [INFO]: Epoch 153 - training loss: 0.7382, validation loss: 0.8505
2024-05-22 21:56:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch153_loss0.8504696041345596.pypots
2024-05-22 21:56:32 [INFO]: Epoch 154 - training loss: 0.8022, validation loss: 0.8470
2024-05-22 21:56:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch154_loss0.8470011502504349.pypots
2024-05-22 21:56:33 [INFO]: Epoch 155 - training loss: 0.7748, validation loss: 0.8419
2024-05-22 21:56:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch155_loss0.8419010043144226.pypots
2024-05-22 21:56:33 [INFO]: Epoch 156 - training loss: 0.7397, validation loss: 0.8419
2024-05-22 21:56:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch156_loss0.8419018685817719.pypots
2024-05-22 21:56:33 [INFO]: Epoch 157 - training loss: 0.7831, validation loss: 0.8454
2024-05-22 21:56:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch157_loss0.8454134911298752.pypots
2024-05-22 21:56:33 [INFO]: Epoch 158 - training loss: 0.7614, validation loss: 0.8480
2024-05-22 21:56:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch158_loss0.8480417877435684.pypots
2024-05-22 21:56:33 [INFO]: Epoch 159 - training loss: 0.7672, validation loss: 0.8452
2024-05-22 21:56:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch159_loss0.8451767116785049.pypots
2024-05-22 21:56:33 [INFO]: Epoch 160 - training loss: 0.7571, validation loss: 0.8385
2024-05-22 21:56:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch160_loss0.8384593427181244.pypots
2024-05-22 21:56:33 [INFO]: Epoch 161 - training loss: 0.7644, validation loss: 0.8384
2024-05-22 21:56:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch161_loss0.8384087085723877.pypots
2024-05-22 21:56:34 [INFO]: Epoch 162 - training loss: 0.7735, validation loss: 0.8411
2024-05-22 21:56:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch162_loss0.8411153256893158.pypots
2024-05-22 21:56:34 [INFO]: Epoch 163 - training loss: 0.7551, validation loss: 0.8387
2024-05-22 21:56:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch163_loss0.8387470543384552.pypots
2024-05-22 21:56:34 [INFO]: Epoch 164 - training loss: 0.7783, validation loss: 0.8380
2024-05-22 21:56:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch164_loss0.8380335867404938.pypots
2024-05-22 21:56:34 [INFO]: Epoch 165 - training loss: 0.7624, validation loss: 0.8380
2024-05-22 21:56:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch165_loss0.8379795402288437.pypots
2024-05-22 21:56:34 [INFO]: Epoch 166 - training loss: 0.7580, validation loss: 0.8372
2024-05-22 21:56:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch166_loss0.8372308611869812.pypots
2024-05-22 21:56:34 [INFO]: Epoch 167 - training loss: 0.7734, validation loss: 0.8333
2024-05-22 21:56:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch167_loss0.8333108574151993.pypots
2024-05-22 21:56:35 [INFO]: Epoch 168 - training loss: 0.7636, validation loss: 0.8346
2024-05-22 21:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch168_loss0.8346094191074371.pypots
2024-05-22 21:56:35 [INFO]: Epoch 169 - training loss: 0.7574, validation loss: 0.8345
2024-05-22 21:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch169_loss0.834455594420433.pypots
2024-05-22 21:56:35 [INFO]: Epoch 170 - training loss: 0.7573, validation loss: 0.8378
2024-05-22 21:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch170_loss0.8377626836299896.pypots
2024-05-22 21:56:35 [INFO]: Epoch 171 - training loss: 0.8138, validation loss: 0.8336
2024-05-22 21:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch171_loss0.8336040079593658.pypots
2024-05-22 21:56:35 [INFO]: Epoch 172 - training loss: 0.7826, validation loss: 0.8288
2024-05-22 21:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch172_loss0.8287672102451324.pypots
2024-05-22 21:56:35 [INFO]: Epoch 173 - training loss: 0.7692, validation loss: 0.8321
2024-05-22 21:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch173_loss0.8321363031864166.pypots
2024-05-22 21:56:36 [INFO]: Epoch 174 - training loss: 0.7675, validation loss: 0.8331
2024-05-22 21:56:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch174_loss0.8330996781587601.pypots
2024-05-22 21:56:36 [INFO]: Epoch 175 - training loss: 0.7400, validation loss: 0.8350
2024-05-22 21:56:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch175_loss0.8350019454956055.pypots
2024-05-22 21:56:36 [INFO]: Epoch 176 - training loss: 0.7936, validation loss: 0.8325
2024-05-22 21:56:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch176_loss0.8325167596340179.pypots
2024-05-22 21:56:36 [INFO]: Epoch 177 - training loss: 0.7654, validation loss: 0.8287
2024-05-22 21:56:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch177_loss0.82867032289505.pypots
2024-05-22 21:56:36 [INFO]: Epoch 178 - training loss: 0.7752, validation loss: 0.8340
2024-05-22 21:56:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch178_loss0.8340030163526535.pypots
2024-05-22 21:56:36 [INFO]: Epoch 179 - training loss: 0.7703, validation loss: 0.8315
2024-05-22 21:56:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch179_loss0.8315189331769943.pypots
2024-05-22 21:56:37 [INFO]: Epoch 180 - training loss: 0.7474, validation loss: 0.8342
2024-05-22 21:56:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch180_loss0.8342089504003525.pypots
2024-05-22 21:56:37 [INFO]: Epoch 181 - training loss: 0.7604, validation loss: 0.8299
2024-05-22 21:56:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch181_loss0.8299030661582947.pypots
2024-05-22 21:56:37 [INFO]: Epoch 182 - training loss: 0.7631, validation loss: 0.8292
2024-05-22 21:56:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch182_loss0.8291977792978287.pypots
2024-05-22 21:56:37 [INFO]: Epoch 183 - training loss: 0.7756, validation loss: 0.8299
2024-05-22 21:56:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch183_loss0.8299220055341721.pypots
2024-05-22 21:56:37 [INFO]: Epoch 184 - training loss: 0.7679, validation loss: 0.8321
2024-05-22 21:56:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch184_loss0.8320939987897873.pypots
2024-05-22 21:56:37 [INFO]: Epoch 185 - training loss: 0.7600, validation loss: 0.8292
2024-05-22 21:56:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch185_loss0.8292353302240372.pypots
2024-05-22 21:56:37 [INFO]: Epoch 186 - training loss: 0.7580, validation loss: 0.8274
2024-05-22 21:56:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch186_loss0.8273768424987793.pypots
2024-05-22 21:56:38 [INFO]: Epoch 187 - training loss: 0.7415, validation loss: 0.8299
2024-05-22 21:56:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch187_loss0.8299083262681961.pypots
2024-05-22 21:56:38 [INFO]: Epoch 188 - training loss: 0.7604, validation loss: 0.8252
2024-05-22 21:56:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch188_loss0.8252189308404922.pypots
2024-05-22 21:56:38 [INFO]: Epoch 189 - training loss: 0.7777, validation loss: 0.8284
2024-05-22 21:56:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch189_loss0.8284226208925247.pypots
2024-05-22 21:56:38 [INFO]: Epoch 190 - training loss: 0.7457, validation loss: 0.8261
2024-05-22 21:56:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch190_loss0.8261326104402542.pypots
2024-05-22 21:56:38 [INFO]: Epoch 191 - training loss: 0.7679, validation loss: 0.8261
2024-05-22 21:56:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch191_loss0.8260925710201263.pypots
2024-05-22 21:56:38 [INFO]: Epoch 192 - training loss: 0.7694, validation loss: 0.8244
2024-05-22 21:56:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch192_loss0.824397474527359.pypots
2024-05-22 21:56:39 [INFO]: Epoch 193 - training loss: 0.7723, validation loss: 0.8266
2024-05-22 21:56:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch193_loss0.8266113996505737.pypots
2024-05-22 21:56:39 [INFO]: Epoch 194 - training loss: 0.7728, validation loss: 0.8220
2024-05-22 21:56:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch194_loss0.8219730257987976.pypots
2024-05-22 21:56:39 [INFO]: Epoch 195 - training loss: 0.7683, validation loss: 0.8228
2024-05-22 21:56:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch195_loss0.8227566033601761.pypots
2024-05-22 21:56:39 [INFO]: Epoch 196 - training loss: 0.7584, validation loss: 0.8233
2024-05-22 21:56:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch196_loss0.8233106136322021.pypots
2024-05-22 21:56:39 [INFO]: Epoch 197 - training loss: 0.7425, validation loss: 0.8228
2024-05-22 21:56:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch197_loss0.8228217512369156.pypots
2024-05-22 21:56:39 [INFO]: Epoch 198 - training loss: 0.7509, validation loss: 0.8235
2024-05-22 21:56:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch198_loss0.8234952986240387.pypots
2024-05-22 21:56:40 [INFO]: Epoch 199 - training loss: 0.7470, validation loss: 0.8232
2024-05-22 21:56:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch199_loss0.8232403099536896.pypots
2024-05-22 21:56:40 [INFO]: Epoch 200 - training loss: 0.7686, validation loss: 0.8257
2024-05-22 21:56:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch200_loss0.8256597965955734.pypots
2024-05-22 21:56:40 [INFO]: Epoch 201 - training loss: 0.7598, validation loss: 0.8228
2024-05-22 21:56:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch201_loss0.8227622359991074.pypots
2024-05-22 21:56:40 [INFO]: Epoch 202 - training loss: 0.7624, validation loss: 0.8260
2024-05-22 21:56:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch202_loss0.8259855359792709.pypots
2024-05-22 21:56:40 [INFO]: Epoch 203 - training loss: 0.7573, validation loss: 0.8208
2024-05-22 21:56:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch203_loss0.8207616209983826.pypots
2024-05-22 21:56:40 [INFO]: Epoch 204 - training loss: 0.7758, validation loss: 0.8225
2024-05-22 21:56:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch204_loss0.8224504590034485.pypots
2024-05-22 21:56:40 [INFO]: Epoch 205 - training loss: 0.7638, validation loss: 0.8213
2024-05-22 21:56:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch205_loss0.8212600499391556.pypots
2024-05-22 21:56:41 [INFO]: Epoch 206 - training loss: 0.7413, validation loss: 0.8197
2024-05-22 21:56:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch206_loss0.8196585327386856.pypots
2024-05-22 21:56:41 [INFO]: Epoch 207 - training loss: 0.7620, validation loss: 0.8182
2024-05-22 21:56:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch207_loss0.8182355612516403.pypots
2024-05-22 21:56:41 [INFO]: Epoch 208 - training loss: 0.7816, validation loss: 0.8192
2024-05-22 21:56:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch208_loss0.8191848546266556.pypots
2024-05-22 21:56:41 [INFO]: Epoch 209 - training loss: 0.7803, validation loss: 0.8194
2024-05-22 21:56:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch209_loss0.8193973153829575.pypots
2024-05-22 21:56:41 [INFO]: Epoch 210 - training loss: 0.7602, validation loss: 0.8193
2024-05-22 21:56:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch210_loss0.819317489862442.pypots
2024-05-22 21:56:41 [INFO]: Epoch 211 - training loss: 0.7629, validation loss: 0.8249
2024-05-22 21:56:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch211_loss0.8249181807041168.pypots
2024-05-22 21:56:42 [INFO]: Epoch 212 - training loss: 0.7667, validation loss: 0.8170
2024-05-22 21:56:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch212_loss0.8170458227396011.pypots
2024-05-22 21:56:42 [INFO]: Epoch 213 - training loss: 0.7449, validation loss: 0.8189
2024-05-22 21:56:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch213_loss0.8189467787742615.pypots
2024-05-22 21:56:42 [INFO]: Epoch 214 - training loss: 0.7792, validation loss: 0.8222
2024-05-22 21:56:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch214_loss0.822173684835434.pypots
2024-05-22 21:56:42 [INFO]: Epoch 215 - training loss: 0.7766, validation loss: 0.8193
2024-05-22 21:56:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch215_loss0.8193447887897491.pypots
2024-05-22 21:56:42 [INFO]: Epoch 216 - training loss: 0.7474, validation loss: 0.8178
2024-05-22 21:56:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch216_loss0.8178326487541199.pypots
2024-05-22 21:56:42 [INFO]: Epoch 217 - training loss: 0.7633, validation loss: 0.8198
2024-05-22 21:56:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch217_loss0.8198153227567673.pypots
2024-05-22 21:56:43 [INFO]: Epoch 218 - training loss: 0.7860, validation loss: 0.8205
2024-05-22 21:56:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch218_loss0.8204741925001144.pypots
2024-05-22 21:56:43 [INFO]: Epoch 219 - training loss: 0.7650, validation loss: 0.8185
2024-05-22 21:56:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch219_loss0.8184878826141357.pypots
2024-05-22 21:56:43 [INFO]: Epoch 220 - training loss: 0.7539, validation loss: 0.8176
2024-05-22 21:56:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch220_loss0.8175913244485855.pypots
2024-05-22 21:56:43 [INFO]: Epoch 221 - training loss: 0.8026, validation loss: 0.8208
2024-05-22 21:56:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch221_loss0.8208104074001312.pypots
2024-05-22 21:56:43 [INFO]: Epoch 222 - training loss: 0.7630, validation loss: 0.8163
2024-05-22 21:56:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch222_loss0.8162713497877121.pypots
2024-05-22 21:56:43 [INFO]: Epoch 223 - training loss: 0.8031, validation loss: 0.8144
2024-05-22 21:56:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch223_loss0.8144155889749527.pypots
2024-05-22 21:56:43 [INFO]: Epoch 224 - training loss: 0.7516, validation loss: 0.8153
2024-05-22 21:56:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch224_loss0.8152792006731033.pypots
2024-05-22 21:56:44 [INFO]: Epoch 225 - training loss: 0.7531, validation loss: 0.8186
2024-05-22 21:56:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch225_loss0.8185702264308929.pypots
2024-05-22 21:56:44 [INFO]: Epoch 226 - training loss: 0.7630, validation loss: 0.8138
2024-05-22 21:56:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch226_loss0.8137643486261368.pypots
2024-05-22 21:56:44 [INFO]: Epoch 227 - training loss: 0.7473, validation loss: 0.8148
2024-05-22 21:56:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch227_loss0.8147906959056854.pypots
2024-05-22 21:56:44 [INFO]: Epoch 228 - training loss: 0.7571, validation loss: 0.8168
2024-05-22 21:56:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch228_loss0.8167755752801895.pypots
2024-05-22 21:56:45 [INFO]: Epoch 229 - training loss: 0.7692, validation loss: 0.8157
2024-05-22 21:56:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch229_loss0.8156681954860687.pypots
2024-05-22 21:56:45 [INFO]: Epoch 230 - training loss: 0.7664, validation loss: 0.8161
2024-05-22 21:56:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch230_loss0.8161017596721649.pypots
2024-05-22 21:56:45 [INFO]: Epoch 231 - training loss: 0.7617, validation loss: 0.8189
2024-05-22 21:56:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch231_loss0.81893390417099.pypots
2024-05-22 21:56:45 [INFO]: Epoch 232 - training loss: 0.7834, validation loss: 0.8130
2024-05-22 21:56:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch232_loss0.8129591345787048.pypots
2024-05-22 21:56:45 [INFO]: Epoch 233 - training loss: 0.7733, validation loss: 0.8143
2024-05-22 21:56:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch233_loss0.814250186085701.pypots
2024-05-22 21:56:45 [INFO]: Epoch 234 - training loss: 0.7604, validation loss: 0.8164
2024-05-22 21:56:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch234_loss0.8164263665676117.pypots
2024-05-22 21:56:46 [INFO]: Epoch 235 - training loss: 0.7568, validation loss: 0.8154
2024-05-22 21:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch235_loss0.8154345899820328.pypots
2024-05-22 21:56:46 [INFO]: Epoch 236 - training loss: 0.7983, validation loss: 0.8142
2024-05-22 21:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch236_loss0.814220979809761.pypots
2024-05-22 21:56:46 [INFO]: Epoch 237 - training loss: 0.7433, validation loss: 0.8130
2024-05-22 21:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch237_loss0.813002809882164.pypots
2024-05-22 21:56:46 [INFO]: Epoch 238 - training loss: 0.7618, validation loss: 0.8136
2024-05-22 21:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch238_loss0.8136148005723953.pypots
2024-05-22 21:56:46 [INFO]: Epoch 239 - training loss: 0.7889, validation loss: 0.8132
2024-05-22 21:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch239_loss0.8131777942180634.pypots
2024-05-22 21:56:46 [INFO]: Epoch 240 - training loss: 0.7491, validation loss: 0.8157
2024-05-22 21:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch240_loss0.8156564086675644.pypots
2024-05-22 21:56:46 [INFO]: Epoch 241 - training loss: 0.7456, validation loss: 0.8150
2024-05-22 21:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch241_loss0.8149875104427338.pypots
2024-05-22 21:56:47 [INFO]: Epoch 242 - training loss: 0.7679, validation loss: 0.8115
2024-05-22 21:56:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch242_loss0.811474472284317.pypots
2024-05-22 21:56:47 [INFO]: Epoch 243 - training loss: 0.7336, validation loss: 0.8104
2024-05-22 21:56:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch243_loss0.8103650361299515.pypots
2024-05-22 21:56:47 [INFO]: Epoch 244 - training loss: 0.7524, validation loss: 0.8118
2024-05-22 21:56:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch244_loss0.8118015229701996.pypots
2024-05-22 21:56:47 [INFO]: Epoch 245 - training loss: 0.7467, validation loss: 0.8094
2024-05-22 21:56:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch245_loss0.8094401508569717.pypots
2024-05-22 21:56:47 [INFO]: Epoch 246 - training loss: 0.7667, validation loss: 0.8092
2024-05-22 21:56:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch246_loss0.8092490285634995.pypots
2024-05-22 21:56:47 [INFO]: Epoch 247 - training loss: 0.7548, validation loss: 0.8097
2024-05-22 21:56:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch247_loss0.80971659719944.pypots
2024-05-22 21:56:48 [INFO]: Epoch 248 - training loss: 0.7647, validation loss: 0.8146
2024-05-22 21:56:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch248_loss0.8146263659000397.pypots
2024-05-22 21:56:48 [INFO]: Epoch 249 - training loss: 0.7512, validation loss: 0.8145
2024-05-22 21:56:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch249_loss0.8144878298044205.pypots
2024-05-22 21:56:48 [INFO]: Epoch 250 - training loss: 0.7683, validation loss: 0.8109
2024-05-22 21:56:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch250_loss0.8109243810176849.pypots
2024-05-22 21:56:48 [INFO]: Epoch 251 - training loss: 0.7640, validation loss: 0.8113
2024-05-22 21:56:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch251_loss0.8112774044275284.pypots
2024-05-22 21:56:48 [INFO]: Epoch 252 - training loss: 0.7641, validation loss: 0.8109
2024-05-22 21:56:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch252_loss0.8109140545129776.pypots
2024-05-22 21:56:48 [INFO]: Epoch 253 - training loss: 0.7693, validation loss: 0.8103
2024-05-22 21:56:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch253_loss0.8103030771017075.pypots
2024-05-22 21:56:49 [INFO]: Epoch 254 - training loss: 0.7623, validation loss: 0.8121
2024-05-22 21:56:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch254_loss0.8121153563261032.pypots
2024-05-22 21:56:49 [INFO]: Epoch 255 - training loss: 0.7567, validation loss: 0.8115
2024-05-22 21:56:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch255_loss0.811548262834549.pypots
2024-05-22 21:56:49 [INFO]: Epoch 256 - training loss: 0.7585, validation loss: 0.8103
2024-05-22 21:56:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN_epoch256_loss0.8103463053703308.pypots
2024-05-22 21:56:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:56:49 [INFO]: Finished training. The best model is from epoch#246.
2024-05-22 21:56:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240522_T215607/MRNN.pypots
2024-05-22 21:56:49 [INFO]: MRNN on ETTm1: MAE=0.5906, MSE=0.9943
2024-05-22 21:56:49 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/MRNN_ettm1/imputation.pkl
2024-05-22 21:56:49 [INFO]: Using the given device: cpu
2024-05-22 21:56:49 [INFO]: LOCF on ETTm1: MAE=0.1376, MSE=0.0773
2024-05-22 21:56:49 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_ettm1".
2024-05-22 21:56:49 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/LOCF_ettm1/imputation.pkl
2024-05-22 21:56:49 [INFO]: Median on ETTm1: MAE=0.6554, MSE=0.8235
2024-05-22 21:56:49 [INFO]: Successfully created the given path "saved_results/round_1/Median_ettm1".
2024-05-22 21:56:49 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Median_ettm1/imputation.pkl
2024-05-22 21:56:49 [INFO]: Mean on ETTm1: MAE=0.6609, MSE=0.8067
2024-05-22 21:56:49 [INFO]: Successfully created the given path "saved_results/round_1/Mean_ettm1".
2024-05-22 21:56:49 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Mean_ettm1/imputation.pkl
2024-05-22 21:56:49 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-22 21:56:49 [INFO]: Using the given device: cuda:0
2024-05-22 21:56:49 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/SAITS_ettm1/20240522_T215649
2024-05-22 21:56:49 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/SAITS_ettm1/20240522_T215649/tensorboard
2024-05-22 21:56:49 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 21:56:50 [INFO]: Epoch 001 - training loss: 1.1464, validation loss: 0.2469
2024-05-22 21:56:50 [INFO]: Epoch 002 - training loss: 0.8112, validation loss: 0.1308
2024-05-22 21:56:51 [INFO]: Epoch 003 - training loss: 0.7124, validation loss: 0.1309
2024-05-22 21:56:51 [INFO]: Epoch 004 - training loss: 0.6578, validation loss: 0.1104
2024-05-22 21:56:52 [INFO]: Epoch 005 - training loss: 0.6173, validation loss: 0.0925
2024-05-22 21:56:52 [INFO]: Epoch 006 - training loss: 0.5794, validation loss: 0.0700
2024-05-22 21:56:53 [INFO]: Epoch 007 - training loss: 0.5539, validation loss: 0.0738
2024-05-22 21:56:53 [INFO]: Epoch 008 - training loss: 0.5364, validation loss: 0.0648
2024-05-22 21:56:54 [INFO]: Epoch 009 - training loss: 0.5288, validation loss: 0.0642
2024-05-22 21:56:54 [INFO]: Epoch 010 - training loss: 0.5152, validation loss: 0.0555
2024-05-22 21:56:54 [INFO]: Epoch 011 - training loss: 0.4891, validation loss: 0.0570
2024-05-22 21:56:55 [INFO]: Epoch 012 - training loss: 0.4902, validation loss: 0.0578
2024-05-22 21:56:55 [INFO]: Epoch 013 - training loss: 0.4821, validation loss: 0.0508
2024-05-22 21:56:56 [INFO]: Epoch 014 - training loss: 0.4629, validation loss: 0.0511
2024-05-22 21:56:56 [INFO]: Epoch 015 - training loss: 0.4761, validation loss: 0.0503
2024-05-22 21:56:57 [INFO]: Epoch 016 - training loss: 0.4486, validation loss: 0.0499
2024-05-22 21:56:57 [INFO]: Epoch 017 - training loss: 0.4858, validation loss: 0.0454
2024-05-22 21:56:58 [INFO]: Epoch 018 - training loss: 0.4463, validation loss: 0.0720
2024-05-22 21:56:58 [INFO]: Epoch 019 - training loss: 0.4348, validation loss: 0.0378
2024-05-22 21:56:59 [INFO]: Epoch 020 - training loss: 0.4123, validation loss: 0.0427
2024-05-22 21:56:59 [INFO]: Epoch 021 - training loss: 0.4371, validation loss: 0.0547
2024-05-22 21:57:00 [INFO]: Epoch 022 - training loss: 0.4283, validation loss: 0.0474
2024-05-22 21:57:00 [INFO]: Epoch 023 - training loss: 0.4069, validation loss: 0.0529
2024-05-22 21:57:01 [INFO]: Epoch 024 - training loss: 0.4131, validation loss: 0.0396
2024-05-22 21:57:01 [INFO]: Epoch 025 - training loss: 0.3980, validation loss: 0.0438
2024-05-22 21:57:02 [INFO]: Epoch 026 - training loss: 0.3914, validation loss: 0.0402
2024-05-22 21:57:02 [INFO]: Epoch 027 - training loss: 0.3864, validation loss: 0.0414
2024-05-22 21:57:03 [INFO]: Epoch 028 - training loss: 0.3798, validation loss: 0.0441
2024-05-22 21:57:03 [INFO]: Epoch 029 - training loss: 0.3934, validation loss: 0.0446
2024-05-22 21:57:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:57:03 [INFO]: Finished training. The best model is from epoch#19.
2024-05-22 21:57:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/SAITS_ettm1/20240522_T215649/SAITS.pypots
2024-05-22 21:57:03 [INFO]: SAITS on ETTm1: MAE=0.1922, MSE=0.0731
2024-05-22 21:57:03 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/SAITS_ettm1/imputation.pkl
2024-05-22 21:57:03 [INFO]: Using the given device: cuda:0
2024-05-22 21:57:03 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/Transformer_ettm1/20240522_T215703
2024-05-22 21:57:03 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/Transformer_ettm1/20240522_T215703/tensorboard
2024-05-22 21:57:03 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 21:57:03 [INFO]: Epoch 001 - training loss: 1.1709, validation loss: 0.3086
2024-05-22 21:57:04 [INFO]: Epoch 002 - training loss: 0.6691, validation loss: 0.1425
2024-05-22 21:57:04 [INFO]: Epoch 003 - training loss: 0.5522, validation loss: 0.1192
2024-05-22 21:57:04 [INFO]: Epoch 004 - training loss: 0.4954, validation loss: 0.1064
2024-05-22 21:57:04 [INFO]: Epoch 005 - training loss: 0.4581, validation loss: 0.0924
2024-05-22 21:57:04 [INFO]: Epoch 006 - training loss: 0.4269, validation loss: 0.0797
2024-05-22 21:57:05 [INFO]: Epoch 007 - training loss: 0.4136, validation loss: 0.0765
2024-05-22 21:57:05 [INFO]: Epoch 008 - training loss: 0.4036, validation loss: 0.0660
2024-05-22 21:57:05 [INFO]: Epoch 009 - training loss: 0.3861, validation loss: 0.0611
2024-05-22 21:57:05 [INFO]: Epoch 010 - training loss: 0.3717, validation loss: 0.0590
2024-05-22 21:57:05 [INFO]: Epoch 011 - training loss: 0.3667, validation loss: 0.0614
2024-05-22 21:57:05 [INFO]: Epoch 012 - training loss: 0.3538, validation loss: 0.0557
2024-05-22 21:57:06 [INFO]: Epoch 013 - training loss: 0.3592, validation loss: 0.0535
2024-05-22 21:57:06 [INFO]: Epoch 014 - training loss: 0.3358, validation loss: 0.0495
2024-05-22 21:57:06 [INFO]: Epoch 015 - training loss: 0.3293, validation loss: 0.0502
2024-05-22 21:57:06 [INFO]: Epoch 016 - training loss: 0.3286, validation loss: 0.0512
2024-05-22 21:57:06 [INFO]: Epoch 017 - training loss: 0.3165, validation loss: 0.0467
2024-05-22 21:57:07 [INFO]: Epoch 018 - training loss: 0.3213, validation loss: 0.0465
2024-05-22 21:57:07 [INFO]: Epoch 019 - training loss: 0.3117, validation loss: 0.0501
2024-05-22 21:57:07 [INFO]: Epoch 020 - training loss: 0.3212, validation loss: 0.0444
2024-05-22 21:57:07 [INFO]: Epoch 021 - training loss: 0.3051, validation loss: 0.0431
2024-05-22 21:57:07 [INFO]: Epoch 022 - training loss: 0.2968, validation loss: 0.0419
2024-05-22 21:57:08 [INFO]: Epoch 023 - training loss: 0.2901, validation loss: 0.0413
2024-05-22 21:57:08 [INFO]: Epoch 024 - training loss: 0.2920, validation loss: 0.0385
2024-05-22 21:57:08 [INFO]: Epoch 025 - training loss: 0.2792, validation loss: 0.0415
2024-05-22 21:57:08 [INFO]: Epoch 026 - training loss: 0.2817, validation loss: 0.0378
2024-05-22 21:57:08 [INFO]: Epoch 027 - training loss: 0.2796, validation loss: 0.0409
2024-05-22 21:57:08 [INFO]: Epoch 028 - training loss: 0.2838, validation loss: 0.0387
2024-05-22 21:57:09 [INFO]: Epoch 029 - training loss: 0.2729, validation loss: 0.0384
2024-05-22 21:57:09 [INFO]: Epoch 030 - training loss: 0.2696, validation loss: 0.0402
2024-05-22 21:57:09 [INFO]: Epoch 031 - training loss: 0.2670, validation loss: 0.0388
2024-05-22 21:57:09 [INFO]: Epoch 032 - training loss: 0.2679, validation loss: 0.0344
2024-05-22 21:57:09 [INFO]: Epoch 033 - training loss: 0.2600, validation loss: 0.0410
2024-05-22 21:57:10 [INFO]: Epoch 034 - training loss: 0.2730, validation loss: 0.0399
2024-05-22 21:57:10 [INFO]: Epoch 035 - training loss: 0.2699, validation loss: 0.0350
2024-05-22 21:57:10 [INFO]: Epoch 036 - training loss: 0.2640, validation loss: 0.0386
2024-05-22 21:57:10 [INFO]: Epoch 037 - training loss: 0.2598, validation loss: 0.0349
2024-05-22 21:57:10 [INFO]: Epoch 038 - training loss: 0.2537, validation loss: 0.0372
2024-05-22 21:57:11 [INFO]: Epoch 039 - training loss: 0.2623, validation loss: 0.0338
2024-05-22 21:57:11 [INFO]: Epoch 040 - training loss: 0.2521, validation loss: 0.0308
2024-05-22 21:57:11 [INFO]: Epoch 041 - training loss: 0.2417, validation loss: 0.0322
2024-05-22 21:57:11 [INFO]: Epoch 042 - training loss: 0.2416, validation loss: 0.0320
2024-05-22 21:57:11 [INFO]: Epoch 043 - training loss: 0.2337, validation loss: 0.0318
2024-05-22 21:57:12 [INFO]: Epoch 044 - training loss: 0.2371, validation loss: 0.0323
2024-05-22 21:57:12 [INFO]: Epoch 045 - training loss: 0.2317, validation loss: 0.0304
2024-05-22 21:57:12 [INFO]: Epoch 046 - training loss: 0.2345, validation loss: 0.0313
2024-05-22 21:57:12 [INFO]: Epoch 047 - training loss: 0.2327, validation loss: 0.0329
2024-05-22 21:57:12 [INFO]: Epoch 048 - training loss: 0.2328, validation loss: 0.0308
2024-05-22 21:57:12 [INFO]: Epoch 049 - training loss: 0.2298, validation loss: 0.0310
2024-05-22 21:57:13 [INFO]: Epoch 050 - training loss: 0.2279, validation loss: 0.0337
2024-05-22 21:57:13 [INFO]: Epoch 051 - training loss: 0.2333, validation loss: 0.0308
2024-05-22 21:57:13 [INFO]: Epoch 052 - training loss: 0.2250, validation loss: 0.0294
2024-05-22 21:57:13 [INFO]: Epoch 053 - training loss: 0.2214, validation loss: 0.0304
2024-05-22 21:57:13 [INFO]: Epoch 054 - training loss: 0.2199, validation loss: 0.0289
2024-05-22 21:57:14 [INFO]: Epoch 055 - training loss: 0.2165, validation loss: 0.0282
2024-05-22 21:57:14 [INFO]: Epoch 056 - training loss: 0.2130, validation loss: 0.0292
2024-05-22 21:57:14 [INFO]: Epoch 057 - training loss: 0.2182, validation loss: 0.0303
2024-05-22 21:57:14 [INFO]: Epoch 058 - training loss: 0.2225, validation loss: 0.0373
2024-05-22 21:57:14 [INFO]: Epoch 059 - training loss: 0.2238, validation loss: 0.0324
2024-05-22 21:57:15 [INFO]: Epoch 060 - training loss: 0.2171, validation loss: 0.0281
2024-05-22 21:57:15 [INFO]: Epoch 061 - training loss: 0.2093, validation loss: 0.0281
2024-05-22 21:57:15 [INFO]: Epoch 062 - training loss: 0.2115, validation loss: 0.0287
2024-05-22 21:57:15 [INFO]: Epoch 063 - training loss: 0.2132, validation loss: 0.0278
2024-05-22 21:57:15 [INFO]: Epoch 064 - training loss: 0.2099, validation loss: 0.0268
2024-05-22 21:57:15 [INFO]: Epoch 065 - training loss: 0.2057, validation loss: 0.0270
2024-05-22 21:57:16 [INFO]: Epoch 066 - training loss: 0.2016, validation loss: 0.0290
2024-05-22 21:57:16 [INFO]: Epoch 067 - training loss: 0.2070, validation loss: 0.0270
2024-05-22 21:57:16 [INFO]: Epoch 068 - training loss: 0.2044, validation loss: 0.0308
2024-05-22 21:57:16 [INFO]: Epoch 069 - training loss: 0.2052, validation loss: 0.0289
2024-05-22 21:57:16 [INFO]: Epoch 070 - training loss: 0.2084, validation loss: 0.0258
2024-05-22 21:57:17 [INFO]: Epoch 071 - training loss: 0.2037, validation loss: 0.0273
2024-05-22 21:57:17 [INFO]: Epoch 072 - training loss: 0.2006, validation loss: 0.0294
2024-05-22 21:57:17 [INFO]: Epoch 073 - training loss: 0.1979, validation loss: 0.0319
2024-05-22 21:57:17 [INFO]: Epoch 074 - training loss: 0.2028, validation loss: 0.0269
2024-05-22 21:57:17 [INFO]: Epoch 075 - training loss: 0.1950, validation loss: 0.0293
2024-05-22 21:57:18 [INFO]: Epoch 076 - training loss: 0.1990, validation loss: 0.0300
2024-05-22 21:57:18 [INFO]: Epoch 077 - training loss: 0.2043, validation loss: 0.0286
2024-05-22 21:57:18 [INFO]: Epoch 078 - training loss: 0.1972, validation loss: 0.0278
2024-05-22 21:57:18 [INFO]: Epoch 079 - training loss: 0.1954, validation loss: 0.0265
2024-05-22 21:57:18 [INFO]: Epoch 080 - training loss: 0.1913, validation loss: 0.0310
2024-05-22 21:57:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:57:18 [INFO]: Finished training. The best model is from epoch#70.
2024-05-22 21:57:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/Transformer_ettm1/20240522_T215703/Transformer.pypots
2024-05-22 21:57:18 [INFO]: Transformer on ETTm1: MAE=0.1350, MSE=0.0375
2024-05-22 21:57:18 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Transformer_ettm1/imputation.pkl
2024-05-22 21:57:18 [INFO]: Using the given device: cuda:0
2024-05-22 21:57:18 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/TimesNet_ettm1/20240522_T215718
2024-05-22 21:57:18 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/TimesNet_ettm1/20240522_T215718/tensorboard
2024-05-22 21:57:19 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 21:57:19 [INFO]: Epoch 001 - training loss: 0.1567, validation loss: 0.0574
2024-05-22 21:57:19 [INFO]: Epoch 002 - training loss: 0.0699, validation loss: 0.0435
2024-05-22 21:57:19 [INFO]: Epoch 003 - training loss: 0.0488, validation loss: 0.0364
2024-05-22 21:57:19 [INFO]: Epoch 004 - training loss: 0.0410, validation loss: 0.0318
2024-05-22 21:57:19 [INFO]: Epoch 005 - training loss: 0.0380, validation loss: 0.0305
2024-05-22 21:57:20 [INFO]: Epoch 006 - training loss: 0.0370, validation loss: 0.0294
2024-05-22 21:57:20 [INFO]: Epoch 007 - training loss: 0.0380, validation loss: 0.0288
2024-05-22 21:57:20 [INFO]: Epoch 008 - training loss: 0.0343, validation loss: 0.0282
2024-05-22 21:57:20 [INFO]: Epoch 009 - training loss: 0.0345, validation loss: 0.0296
2024-05-22 21:57:20 [INFO]: Epoch 010 - training loss: 0.0398, validation loss: 0.0291
2024-05-22 21:57:20 [INFO]: Epoch 011 - training loss: 0.0327, validation loss: 0.0276
2024-05-22 21:57:21 [INFO]: Epoch 012 - training loss: 0.0311, validation loss: 0.0273
2024-05-22 21:57:21 [INFO]: Epoch 013 - training loss: 0.0307, validation loss: 0.0275
2024-05-22 21:57:21 [INFO]: Epoch 014 - training loss: 0.0306, validation loss: 0.0264
2024-05-22 21:57:21 [INFO]: Epoch 015 - training loss: 0.0288, validation loss: 0.0267
2024-05-22 21:57:21 [INFO]: Epoch 016 - training loss: 0.0293, validation loss: 0.0272
2024-05-22 21:57:22 [INFO]: Epoch 017 - training loss: 0.0304, validation loss: 0.0267
2024-05-22 21:57:22 [INFO]: Epoch 018 - training loss: 0.0316, validation loss: 0.0270
2024-05-22 21:57:22 [INFO]: Epoch 019 - training loss: 0.0357, validation loss: 0.0272
2024-05-22 21:57:22 [INFO]: Epoch 020 - training loss: 0.0317, validation loss: 0.0266
2024-05-22 21:57:22 [INFO]: Epoch 021 - training loss: 0.0296, validation loss: 0.0269
2024-05-22 21:57:22 [INFO]: Epoch 022 - training loss: 0.0315, validation loss: 0.0282
2024-05-22 21:57:23 [INFO]: Epoch 023 - training loss: 0.0302, validation loss: 0.0269
2024-05-22 21:57:23 [INFO]: Epoch 024 - training loss: 0.0296, validation loss: 0.0266
2024-05-22 21:57:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:57:23 [INFO]: Finished training. The best model is from epoch#14.
2024-05-22 21:57:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/TimesNet_ettm1/20240522_T215718/TimesNet.pypots
2024-05-22 21:57:23 [INFO]: TimesNet on ETTm1: MAE=0.1113, MSE=0.0270
2024-05-22 21:57:23 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/TimesNet_ettm1/imputation.pkl
2024-05-22 21:57:23 [INFO]: Using the given device: cuda:0
2024-05-22 21:57:23 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723
2024-05-22 21:57:23 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/tensorboard
2024-05-22 21:57:23 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 21:57:25 [INFO]: Epoch 001 - training loss: 0.6823, validation loss: 0.4274
2024-05-22 21:57:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch1_loss0.42739085108041763.pypots
2024-05-22 21:57:27 [INFO]: Epoch 002 - training loss: 0.4124, validation loss: 0.3759
2024-05-22 21:57:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch2_loss0.37592873722314835.pypots
2024-05-22 21:57:29 [INFO]: Epoch 003 - training loss: 0.3402, validation loss: 0.3174
2024-05-22 21:57:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch3_loss0.31736042350530624.pypots
2024-05-22 21:57:31 [INFO]: Epoch 004 - training loss: 0.3103, validation loss: 0.2929
2024-05-22 21:57:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch4_loss0.29289308935403824.pypots
2024-05-22 21:57:33 [INFO]: Epoch 005 - training loss: 0.2557, validation loss: 0.2656
2024-05-22 21:57:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch5_loss0.26559029519557953.pypots
2024-05-22 21:57:35 [INFO]: Epoch 006 - training loss: 0.3150, validation loss: 0.2618
2024-05-22 21:57:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch6_loss0.2618367597460747.pypots
2024-05-22 21:57:37 [INFO]: Epoch 007 - training loss: 0.2459, validation loss: 0.2585
2024-05-22 21:57:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch7_loss0.2584894448518753.pypots
2024-05-22 21:57:39 [INFO]: Epoch 008 - training loss: 0.2830, validation loss: 0.2537
2024-05-22 21:57:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch8_loss0.25370095670223236.pypots
2024-05-22 21:57:41 [INFO]: Epoch 009 - training loss: 0.2787, validation loss: 0.2909
2024-05-22 21:57:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch9_loss0.2909480929374695.pypots
2024-05-22 21:57:43 [INFO]: Epoch 010 - training loss: 0.3105, validation loss: 0.2660
2024-05-22 21:57:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch10_loss0.2659888416528702.pypots
2024-05-22 21:57:45 [INFO]: Epoch 011 - training loss: 0.2693, validation loss: 0.2582
2024-05-22 21:57:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch11_loss0.2581961750984192.pypots
2024-05-22 21:57:47 [INFO]: Epoch 012 - training loss: 0.2235, validation loss: 0.2343
2024-05-22 21:57:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch12_loss0.23431720584630966.pypots
2024-05-22 21:57:49 [INFO]: Epoch 013 - training loss: 0.2248, validation loss: 0.2267
2024-05-22 21:57:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch13_loss0.22671114653348923.pypots
2024-05-22 21:57:51 [INFO]: Epoch 014 - training loss: 0.2243, validation loss: 0.2433
2024-05-22 21:57:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch14_loss0.2432861067354679.pypots
2024-05-22 21:57:53 [INFO]: Epoch 015 - training loss: 0.2830, validation loss: 0.2315
2024-05-22 21:57:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch15_loss0.23145291209220886.pypots
2024-05-22 21:57:55 [INFO]: Epoch 016 - training loss: 0.2228, validation loss: 0.2208
2024-05-22 21:57:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch16_loss0.22084089368581772.pypots
2024-05-22 21:57:57 [INFO]: Epoch 017 - training loss: 0.2023, validation loss: 0.2195
2024-05-22 21:57:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch17_loss0.21949229389429092.pypots
2024-05-22 21:57:59 [INFO]: Epoch 018 - training loss: 0.2053, validation loss: 0.2131
2024-05-22 21:57:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch18_loss0.21310773491859436.pypots
2024-05-22 21:58:01 [INFO]: Epoch 019 - training loss: 0.1973, validation loss: 0.2086
2024-05-22 21:58:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch19_loss0.2086443230509758.pypots
2024-05-22 21:58:03 [INFO]: Epoch 020 - training loss: 0.2757, validation loss: 0.2039
2024-05-22 21:58:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch20_loss0.203897625207901.pypots
2024-05-22 21:58:05 [INFO]: Epoch 021 - training loss: 0.1980, validation loss: 0.1983
2024-05-22 21:58:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch21_loss0.19827132672071457.pypots
2024-05-22 21:58:07 [INFO]: Epoch 022 - training loss: 0.2100, validation loss: 0.2197
2024-05-22 21:58:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch22_loss0.21967176347970963.pypots
2024-05-22 21:58:09 [INFO]: Epoch 023 - training loss: 0.2555, validation loss: 0.2136
2024-05-22 21:58:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch23_loss0.21357979997992516.pypots
2024-05-22 21:58:11 [INFO]: Epoch 024 - training loss: 0.2201, validation loss: 0.2003
2024-05-22 21:58:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch24_loss0.20034436509013176.pypots
2024-05-22 21:58:13 [INFO]: Epoch 025 - training loss: 0.2071, validation loss: 0.1885
2024-05-22 21:58:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch25_loss0.18850555270910263.pypots
2024-05-22 21:58:15 [INFO]: Epoch 026 - training loss: 0.1789, validation loss: 0.1822
2024-05-22 21:58:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch26_loss0.18222187459468842.pypots
2024-05-22 21:58:17 [INFO]: Epoch 027 - training loss: 0.2159, validation loss: 0.1746
2024-05-22 21:58:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch27_loss0.1746310293674469.pypots
2024-05-22 21:58:19 [INFO]: Epoch 028 - training loss: 0.2190, validation loss: 0.1945
2024-05-22 21:58:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch28_loss0.1944635547697544.pypots
2024-05-22 21:58:21 [INFO]: Epoch 029 - training loss: 0.1737, validation loss: 0.1765
2024-05-22 21:58:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch29_loss0.1765468418598175.pypots
2024-05-22 21:58:23 [INFO]: Epoch 030 - training loss: 0.1632, validation loss: 0.1729
2024-05-22 21:58:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch30_loss0.17292920872569084.pypots
2024-05-22 21:58:26 [INFO]: Epoch 031 - training loss: 0.2047, validation loss: 0.1704
2024-05-22 21:58:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch31_loss0.1704234927892685.pypots
2024-05-22 21:58:28 [INFO]: Epoch 032 - training loss: 0.2153, validation loss: 0.1843
2024-05-22 21:58:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch32_loss0.18429673090577126.pypots
2024-05-22 21:58:30 [INFO]: Epoch 033 - training loss: 0.2024, validation loss: 0.1820
2024-05-22 21:58:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch33_loss0.18200017884373665.pypots
2024-05-22 21:58:32 [INFO]: Epoch 034 - training loss: 0.1933, validation loss: 0.1701
2024-05-22 21:58:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch34_loss0.17011922225356102.pypots
2024-05-22 21:58:34 [INFO]: Epoch 035 - training loss: 0.1631, validation loss: 0.1609
2024-05-22 21:58:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch35_loss0.16094190999865532.pypots
2024-05-22 21:58:36 [INFO]: Epoch 036 - training loss: 0.1717, validation loss: 0.1576
2024-05-22 21:58:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch36_loss0.15758121013641357.pypots
2024-05-22 21:58:38 [INFO]: Epoch 037 - training loss: 0.1761, validation loss: 0.1559
2024-05-22 21:58:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch37_loss0.155862208455801.pypots
2024-05-22 21:58:40 [INFO]: Epoch 038 - training loss: 0.1536, validation loss: 0.1681
2024-05-22 21:58:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch38_loss0.16811879351735115.pypots
2024-05-22 21:58:42 [INFO]: Epoch 039 - training loss: 0.1781, validation loss: 0.1815
2024-05-22 21:58:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch39_loss0.18153681233525276.pypots
2024-05-22 21:58:44 [INFO]: Epoch 040 - training loss: 0.1783, validation loss: 0.1721
2024-05-22 21:58:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch40_loss0.17206091061234474.pypots
2024-05-22 21:58:46 [INFO]: Epoch 041 - training loss: 0.2033, validation loss: 0.1818
2024-05-22 21:58:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch41_loss0.18184011057019234.pypots
2024-05-22 21:58:48 [INFO]: Epoch 042 - training loss: 0.1991, validation loss: 0.1789
2024-05-22 21:58:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch42_loss0.17893557623028755.pypots
2024-05-22 21:58:50 [INFO]: Epoch 043 - training loss: 0.2107, validation loss: 0.1677
2024-05-22 21:58:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch43_loss0.16766119748353958.pypots
2024-05-22 21:58:52 [INFO]: Epoch 044 - training loss: 0.1432, validation loss: 0.1613
2024-05-22 21:58:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch44_loss0.16129716858267784.pypots
2024-05-22 21:58:54 [INFO]: Epoch 045 - training loss: 0.1796, validation loss: 0.1671
2024-05-22 21:58:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch45_loss0.16707796603441238.pypots
2024-05-22 21:58:56 [INFO]: Epoch 046 - training loss: 0.1786, validation loss: 0.1631
2024-05-22 21:58:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch46_loss0.16307800263166428.pypots
2024-05-22 21:58:58 [INFO]: Epoch 047 - training loss: 0.1520, validation loss: 0.1556
2024-05-22 21:58:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch47_loss0.1556236892938614.pypots
2024-05-22 21:59:00 [INFO]: Epoch 048 - training loss: 0.1473, validation loss: 0.1448
2024-05-22 21:59:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch48_loss0.14484019204974174.pypots
2024-05-22 21:59:02 [INFO]: Epoch 049 - training loss: 0.1368, validation loss: 0.1436
2024-05-22 21:59:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch49_loss0.14356038719415665.pypots
2024-05-22 21:59:04 [INFO]: Epoch 050 - training loss: 0.1786, validation loss: 0.1678
2024-05-22 21:59:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch50_loss0.16778146103024483.pypots
2024-05-22 21:59:06 [INFO]: Epoch 051 - training loss: 0.1697, validation loss: 0.1581
2024-05-22 21:59:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch51_loss0.15806498378515244.pypots
2024-05-22 21:59:08 [INFO]: Epoch 052 - training loss: 0.1565, validation loss: 0.1464
2024-05-22 21:59:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch52_loss0.14640604704618454.pypots
2024-05-22 21:59:10 [INFO]: Epoch 053 - training loss: 0.1372, validation loss: 0.1392
2024-05-22 21:59:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch53_loss0.139180276542902.pypots
2024-05-22 21:59:12 [INFO]: Epoch 054 - training loss: 0.1840, validation loss: 0.1561
2024-05-22 21:59:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch54_loss0.15607516467571259.pypots
2024-05-22 21:59:14 [INFO]: Epoch 055 - training loss: 0.1724, validation loss: 0.1668
2024-05-22 21:59:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch55_loss0.16675247997045517.pypots
2024-05-22 21:59:16 [INFO]: Epoch 056 - training loss: 0.1693, validation loss: 0.1485
2024-05-22 21:59:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch56_loss0.14846912771463394.pypots
2024-05-22 21:59:18 [INFO]: Epoch 057 - training loss: 0.1561, validation loss: 0.1464
2024-05-22 21:59:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch57_loss0.1463821493089199.pypots
2024-05-22 21:59:20 [INFO]: Epoch 058 - training loss: 0.1511, validation loss: 0.1530
2024-05-22 21:59:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch58_loss0.15295742079615593.pypots
2024-05-22 21:59:22 [INFO]: Epoch 059 - training loss: 0.1662, validation loss: 0.1521
2024-05-22 21:59:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch59_loss0.15212006494402885.pypots
2024-05-22 21:59:24 [INFO]: Epoch 060 - training loss: 0.1421, validation loss: 0.1389
2024-05-22 21:59:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch60_loss0.1389418989419937.pypots
2024-05-22 21:59:26 [INFO]: Epoch 061 - training loss: 0.1635, validation loss: 0.1398
2024-05-22 21:59:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch61_loss0.1398179791867733.pypots
2024-05-22 21:59:28 [INFO]: Epoch 062 - training loss: 0.1373, validation loss: 0.1377
2024-05-22 21:59:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch62_loss0.13774937391281128.pypots
2024-05-22 21:59:30 [INFO]: Epoch 063 - training loss: 0.1368, validation loss: 0.1333
2024-05-22 21:59:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch63_loss0.1332736425101757.pypots
2024-05-22 21:59:32 [INFO]: Epoch 064 - training loss: 0.1477, validation loss: 0.1334
2024-05-22 21:59:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch64_loss0.13337724655866623.pypots
2024-05-22 21:59:34 [INFO]: Epoch 065 - training loss: 0.1892, validation loss: 0.1340
2024-05-22 21:59:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch65_loss0.13403674960136414.pypots
2024-05-22 21:59:36 [INFO]: Epoch 066 - training loss: 0.1366, validation loss: 0.1326
2024-05-22 21:59:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch66_loss0.132584135979414.pypots
2024-05-22 21:59:38 [INFO]: Epoch 067 - training loss: 0.1389, validation loss: 0.1335
2024-05-22 21:59:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch67_loss0.13348188251256943.pypots
2024-05-22 21:59:40 [INFO]: Epoch 068 - training loss: 0.1357, validation loss: 0.1383
2024-05-22 21:59:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch68_loss0.13829702138900757.pypots
2024-05-22 21:59:42 [INFO]: Epoch 069 - training loss: 0.1499, validation loss: 0.1348
2024-05-22 21:59:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch69_loss0.13478555902838707.pypots
2024-05-22 21:59:44 [INFO]: Epoch 070 - training loss: 0.1641, validation loss: 0.1480
2024-05-22 21:59:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch70_loss0.1479695588350296.pypots
2024-05-22 21:59:46 [INFO]: Epoch 071 - training loss: 0.1368, validation loss: 0.1391
2024-05-22 21:59:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch71_loss0.1391199454665184.pypots
2024-05-22 21:59:48 [INFO]: Epoch 072 - training loss: 0.1360, validation loss: 0.1303
2024-05-22 21:59:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch72_loss0.1303357221186161.pypots
2024-05-22 21:59:50 [INFO]: Epoch 073 - training loss: 0.1300, validation loss: 0.1295
2024-05-22 21:59:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch73_loss0.1295423973351717.pypots
2024-05-22 21:59:52 [INFO]: Epoch 074 - training loss: 0.1198, validation loss: 0.1335
2024-05-22 21:59:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch74_loss0.13346654921770096.pypots
2024-05-22 21:59:54 [INFO]: Epoch 075 - training loss: 0.1235, validation loss: 0.1355
2024-05-22 21:59:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch75_loss0.13550616055727005.pypots
2024-05-22 21:59:56 [INFO]: Epoch 076 - training loss: 0.1176, validation loss: 0.1314
2024-05-22 21:59:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch76_loss0.13138786144554615.pypots
2024-05-22 21:59:58 [INFO]: Epoch 077 - training loss: 0.1669, validation loss: 0.1268
2024-05-22 21:59:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch77_loss0.12684925459325314.pypots
2024-05-22 22:00:00 [INFO]: Epoch 078 - training loss: 0.1248, validation loss: 0.1279
2024-05-22 22:00:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch78_loss0.1278794500976801.pypots
2024-05-22 22:00:02 [INFO]: Epoch 079 - training loss: 0.1300, validation loss: 0.1260
2024-05-22 22:00:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch79_loss0.1260407380759716.pypots
2024-05-22 22:00:04 [INFO]: Epoch 080 - training loss: 0.1650, validation loss: 0.1274
2024-05-22 22:00:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch80_loss0.1274398397654295.pypots
2024-05-22 22:00:06 [INFO]: Epoch 081 - training loss: 0.1349, validation loss: 0.1258
2024-05-22 22:00:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch81_loss0.1258073654025793.pypots
2024-05-22 22:00:09 [INFO]: Epoch 082 - training loss: 0.1171, validation loss: 0.1288
2024-05-22 22:00:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch82_loss0.12884504720568657.pypots
2024-05-22 22:00:11 [INFO]: Epoch 083 - training loss: 0.1182, validation loss: 0.1280
2024-05-22 22:00:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch83_loss0.12798493169248104.pypots
2024-05-22 22:00:13 [INFO]: Epoch 084 - training loss: 0.1494, validation loss: 0.1285
2024-05-22 22:00:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch84_loss0.1285367850214243.pypots
2024-05-22 22:00:15 [INFO]: Epoch 085 - training loss: 0.1214, validation loss: 0.1323
2024-05-22 22:00:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch85_loss0.13233991153538227.pypots
2024-05-22 22:00:17 [INFO]: Epoch 086 - training loss: 0.1284, validation loss: 0.1289
2024-05-22 22:00:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch86_loss0.1289038509130478.pypots
2024-05-22 22:00:19 [INFO]: Epoch 087 - training loss: 0.1109, validation loss: 0.1242
2024-05-22 22:00:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch87_loss0.12420783564448357.pypots
2024-05-22 22:00:21 [INFO]: Epoch 088 - training loss: 0.1333, validation loss: 0.1366
2024-05-22 22:00:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch88_loss0.13656704872846603.pypots
2024-05-22 22:00:23 [INFO]: Epoch 089 - training loss: 0.1484, validation loss: 0.1308
2024-05-22 22:00:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch89_loss0.13075239583849907.pypots
2024-05-22 22:00:25 [INFO]: Epoch 090 - training loss: 0.1238, validation loss: 0.1270
2024-05-22 22:00:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch90_loss0.12703612633049488.pypots
2024-05-22 22:00:27 [INFO]: Epoch 091 - training loss: 0.1279, validation loss: 0.1249
2024-05-22 22:00:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch91_loss0.12485280446708202.pypots
2024-05-22 22:00:29 [INFO]: Epoch 092 - training loss: 0.1816, validation loss: 0.1477
2024-05-22 22:00:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch92_loss0.14765582606196404.pypots
2024-05-22 22:00:31 [INFO]: Epoch 093 - training loss: 0.1625, validation loss: 0.1651
2024-05-22 22:00:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch93_loss0.1651047207415104.pypots
2024-05-22 22:00:33 [INFO]: Epoch 094 - training loss: 0.1530, validation loss: 0.1415
2024-05-22 22:00:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch94_loss0.1415388584136963.pypots
2024-05-22 22:00:35 [INFO]: Epoch 095 - training loss: 0.1596, validation loss: 0.1379
2024-05-22 22:00:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch95_loss0.13785042241215706.pypots
2024-05-22 22:00:37 [INFO]: Epoch 096 - training loss: 0.1246, validation loss: 0.1310
2024-05-22 22:00:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch96_loss0.13104130513966084.pypots
2024-05-22 22:00:39 [INFO]: Epoch 097 - training loss: 0.1264, validation loss: 0.1240
2024-05-22 22:00:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch97_loss0.12400816939771175.pypots
2024-05-22 22:00:41 [INFO]: Epoch 098 - training loss: 0.1684, validation loss: 0.1322
2024-05-22 22:00:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch98_loss0.1321560125797987.pypots
2024-05-22 22:00:43 [INFO]: Epoch 099 - training loss: 0.1310, validation loss: 0.1288
2024-05-22 22:00:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch99_loss0.12879124470055103.pypots
2024-05-22 22:00:45 [INFO]: Epoch 100 - training loss: 0.1424, validation loss: 0.1261
2024-05-22 22:00:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch100_loss0.12612811475992203.pypots
2024-05-22 22:00:47 [INFO]: Epoch 101 - training loss: 0.1176, validation loss: 0.1260
2024-05-22 22:00:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch101_loss0.12602956406772137.pypots
2024-05-22 22:00:49 [INFO]: Epoch 102 - training loss: 0.1365, validation loss: 0.1221
2024-05-22 22:00:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch102_loss0.12205036357045174.pypots
2024-05-22 22:00:51 [INFO]: Epoch 103 - training loss: 0.1858, validation loss: 0.1227
2024-05-22 22:00:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch103_loss0.1227359026670456.pypots
2024-05-22 22:00:53 [INFO]: Epoch 104 - training loss: 0.1319, validation loss: 0.1262
2024-05-22 22:00:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch104_loss0.12619858048856258.pypots
2024-05-22 22:00:55 [INFO]: Epoch 105 - training loss: 0.1109, validation loss: 0.1244
2024-05-22 22:00:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch105_loss0.12440388649702072.pypots
2024-05-22 22:00:57 [INFO]: Epoch 106 - training loss: 0.1332, validation loss: 0.1288
2024-05-22 22:00:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch106_loss0.1287733744829893.pypots
2024-05-22 22:00:59 [INFO]: Epoch 107 - training loss: 0.1521, validation loss: 0.1404
2024-05-22 22:00:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch107_loss0.14041206240653992.pypots
2024-05-22 22:01:01 [INFO]: Epoch 108 - training loss: 0.1574, validation loss: 0.1431
2024-05-22 22:01:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch108_loss0.143135916441679.pypots
2024-05-22 22:01:03 [INFO]: Epoch 109 - training loss: 0.1329, validation loss: 0.1271
2024-05-22 22:01:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch109_loss0.12708019651472569.pypots
2024-05-22 22:01:05 [INFO]: Epoch 110 - training loss: 0.1324, validation loss: 0.1272
2024-05-22 22:01:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch110_loss0.12723321840167046.pypots
2024-05-22 22:01:07 [INFO]: Epoch 111 - training loss: 0.1450, validation loss: 0.1334
2024-05-22 22:01:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch111_loss0.13341299071907997.pypots
2024-05-22 22:01:09 [INFO]: Epoch 112 - training loss: 0.1337, validation loss: 0.1351
2024-05-22 22:01:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI_epoch112_loss0.13512882217764854.pypots
2024-05-22 22:01:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:01:09 [INFO]: Finished training. The best model is from epoch#102.
2024-05-22 22:01:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240522_T215723/CSDI.pypots
2024-05-22 22:01:25 [INFO]: CSDI on ETTm1: MAE=0.1379, MSE=0.0494
2024-05-22 22:01:25 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/CSDI_ettm1/imputation.pkl
2024-05-22 22:01:25 [INFO]: Using the given device: cuda:0
2024-05-22 22:01:25 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/GPVAE_ettm1/20240522_T220125
2024-05-22 22:01:25 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/GPVAE_ettm1/20240522_T220125/tensorboard
2024-05-22 22:01:25 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 22:01:25 [INFO]: Epoch 001 - training loss: 24011.5065, validation loss: 0.9685
2024-05-22 22:01:25 [INFO]: Epoch 002 - training loss: 21840.6866, validation loss: 0.9683
2024-05-22 22:01:25 [INFO]: Epoch 003 - training loss: 19682.5406, validation loss: 0.9578
2024-05-22 22:01:25 [INFO]: Epoch 004 - training loss: 17755.9218, validation loss: 0.9340
2024-05-22 22:01:25 [INFO]: Epoch 005 - training loss: 15766.2486, validation loss: 0.8715
2024-05-22 22:01:25 [INFO]: Epoch 006 - training loss: 14210.8137, validation loss: 0.7518
2024-05-22 22:01:25 [INFO]: Epoch 007 - training loss: 13046.3864, validation loss: 0.6540
2024-05-22 22:01:26 [INFO]: Epoch 008 - training loss: 12337.9897, validation loss: 0.6234
2024-05-22 22:01:26 [INFO]: Epoch 009 - training loss: 11494.2215, validation loss: 0.5842
2024-05-22 22:01:26 [INFO]: Epoch 010 - training loss: 10991.3721, validation loss: 0.5450
2024-05-22 22:01:26 [INFO]: Epoch 011 - training loss: 10702.8793, validation loss: 0.5151
2024-05-22 22:01:26 [INFO]: Epoch 012 - training loss: 10495.7891, validation loss: 0.5074
2024-05-22 22:01:26 [INFO]: Epoch 013 - training loss: 10282.3423, validation loss: 0.4906
2024-05-22 22:01:26 [INFO]: Epoch 014 - training loss: 10141.7505, validation loss: 0.5064
2024-05-22 22:01:26 [INFO]: Epoch 015 - training loss: 10066.0686, validation loss: 0.4771
2024-05-22 22:01:26 [INFO]: Epoch 016 - training loss: 9965.9744, validation loss: 0.4579
2024-05-22 22:01:27 [INFO]: Epoch 017 - training loss: 9871.2552, validation loss: 0.4384
2024-05-22 22:01:27 [INFO]: Epoch 018 - training loss: 9835.0483, validation loss: 0.4210
2024-05-22 22:01:27 [INFO]: Epoch 019 - training loss: 9831.1274, validation loss: 0.3930
2024-05-22 22:01:27 [INFO]: Epoch 020 - training loss: 9753.2423, validation loss: 0.3658
2024-05-22 22:01:27 [INFO]: Epoch 021 - training loss: 9664.9546, validation loss: 0.3405
2024-05-22 22:01:27 [INFO]: Epoch 022 - training loss: 9634.5652, validation loss: 0.3203
2024-05-22 22:01:27 [INFO]: Epoch 023 - training loss: 9617.9195, validation loss: 0.3073
2024-05-22 22:01:27 [INFO]: Epoch 024 - training loss: 9578.0033, validation loss: 0.2848
2024-05-22 22:01:27 [INFO]: Epoch 025 - training loss: 9553.2377, validation loss: 0.2731
2024-05-22 22:01:28 [INFO]: Epoch 026 - training loss: 9532.3875, validation loss: 0.2604
2024-05-22 22:01:28 [INFO]: Epoch 027 - training loss: 9514.1204, validation loss: 0.2554
2024-05-22 22:01:28 [INFO]: Epoch 028 - training loss: 9585.4839, validation loss: 0.2511
2024-05-22 22:01:28 [INFO]: Epoch 029 - training loss: 9495.7849, validation loss: 0.2479
2024-05-22 22:01:28 [INFO]: Epoch 030 - training loss: 9476.6562, validation loss: 0.2412
2024-05-22 22:01:28 [INFO]: Epoch 031 - training loss: 9466.4680, validation loss: 0.2326
2024-05-22 22:01:28 [INFO]: Epoch 032 - training loss: 9451.2971, validation loss: 0.2328
2024-05-22 22:01:28 [INFO]: Epoch 033 - training loss: 9441.6048, validation loss: 0.2299
2024-05-22 22:01:28 [INFO]: Epoch 034 - training loss: 9428.4493, validation loss: 0.2281
2024-05-22 22:01:29 [INFO]: Epoch 035 - training loss: 9429.4069, validation loss: 0.2276
2024-05-22 22:01:29 [INFO]: Epoch 036 - training loss: 9420.9655, validation loss: 0.2196
2024-05-22 22:01:29 [INFO]: Epoch 037 - training loss: 9426.0024, validation loss: 0.2165
2024-05-22 22:01:29 [INFO]: Epoch 038 - training loss: 9400.4246, validation loss: 0.2109
2024-05-22 22:01:29 [INFO]: Epoch 039 - training loss: 9394.7277, validation loss: 0.2081
2024-05-22 22:01:29 [INFO]: Epoch 040 - training loss: 9395.4663, validation loss: 0.2046
2024-05-22 22:01:29 [INFO]: Epoch 041 - training loss: 9382.1993, validation loss: 0.1993
2024-05-22 22:01:29 [INFO]: Epoch 042 - training loss: 9381.6241, validation loss: 0.1964
2024-05-22 22:01:29 [INFO]: Epoch 043 - training loss: 9375.2980, validation loss: 0.1914
2024-05-22 22:01:30 [INFO]: Epoch 044 - training loss: 9379.6080, validation loss: 0.1894
2024-05-22 22:01:30 [INFO]: Epoch 045 - training loss: 9373.7564, validation loss: 0.1842
2024-05-22 22:01:30 [INFO]: Epoch 046 - training loss: 9362.5267, validation loss: 0.1816
2024-05-22 22:01:30 [INFO]: Epoch 047 - training loss: 9357.3055, validation loss: 0.1775
2024-05-22 22:01:30 [INFO]: Epoch 048 - training loss: 9359.7765, validation loss: 0.1769
2024-05-22 22:01:30 [INFO]: Epoch 049 - training loss: 9358.7130, validation loss: 0.1692
2024-05-22 22:01:30 [INFO]: Epoch 050 - training loss: 9356.9856, validation loss: 0.1675
2024-05-22 22:01:30 [INFO]: Epoch 051 - training loss: 9346.5331, validation loss: 0.1655
2024-05-22 22:01:30 [INFO]: Epoch 052 - training loss: 9344.5947, validation loss: 0.1634
2024-05-22 22:01:30 [INFO]: Epoch 053 - training loss: 9342.4658, validation loss: 0.1615
2024-05-22 22:01:31 [INFO]: Epoch 054 - training loss: 9341.3770, validation loss: 0.1594
2024-05-22 22:01:31 [INFO]: Epoch 055 - training loss: 9341.5673, validation loss: 0.1570
2024-05-22 22:01:31 [INFO]: Epoch 056 - training loss: 9333.8570, validation loss: 0.1556
2024-05-22 22:01:31 [INFO]: Epoch 057 - training loss: 9333.4683, validation loss: 0.1535
2024-05-22 22:01:31 [INFO]: Epoch 058 - training loss: 9335.0532, validation loss: 0.1516
2024-05-22 22:01:31 [INFO]: Epoch 059 - training loss: 9330.8690, validation loss: 0.1517
2024-05-22 22:01:31 [INFO]: Epoch 060 - training loss: 9330.7178, validation loss: 0.1491
2024-05-22 22:01:31 [INFO]: Epoch 061 - training loss: 9326.2704, validation loss: 0.1457
2024-05-22 22:01:31 [INFO]: Epoch 062 - training loss: 9324.1788, validation loss: 0.1491
2024-05-22 22:01:32 [INFO]: Epoch 063 - training loss: 9327.4038, validation loss: 0.1469
2024-05-22 22:01:32 [INFO]: Epoch 064 - training loss: 9322.1656, validation loss: 0.1451
2024-05-22 22:01:32 [INFO]: Epoch 065 - training loss: 9333.9171, validation loss: 0.1440
2024-05-22 22:01:32 [INFO]: Epoch 066 - training loss: 9320.2614, validation loss: 0.1422
2024-05-22 22:01:32 [INFO]: Epoch 067 - training loss: 9318.5229, validation loss: 0.1407
2024-05-22 22:01:32 [INFO]: Epoch 068 - training loss: 9314.6077, validation loss: 0.1417
2024-05-22 22:01:32 [INFO]: Epoch 069 - training loss: 9319.6572, validation loss: 0.1371
2024-05-22 22:01:32 [INFO]: Epoch 070 - training loss: 9317.6268, validation loss: 0.1392
2024-05-22 22:01:32 [INFO]: Epoch 071 - training loss: 9324.4814, validation loss: 0.1369
2024-05-22 22:01:33 [INFO]: Epoch 072 - training loss: 9311.3600, validation loss: 0.1341
2024-05-22 22:01:33 [INFO]: Epoch 073 - training loss: 9312.1616, validation loss: 0.1355
2024-05-22 22:01:33 [INFO]: Epoch 074 - training loss: 9308.0919, validation loss: 0.1349
2024-05-22 22:01:33 [INFO]: Epoch 075 - training loss: 9308.7875, validation loss: 0.1341
2024-05-22 22:01:33 [INFO]: Epoch 076 - training loss: 9309.7393, validation loss: 0.1332
2024-05-22 22:01:33 [INFO]: Epoch 077 - training loss: 9308.4333, validation loss: 0.1323
2024-05-22 22:01:33 [INFO]: Epoch 078 - training loss: 9306.7720, validation loss: 0.1365
2024-05-22 22:01:33 [INFO]: Epoch 079 - training loss: 9303.3371, validation loss: 0.1314
2024-05-22 22:01:33 [INFO]: Epoch 080 - training loss: 9304.4472, validation loss: 0.1315
2024-05-22 22:01:33 [INFO]: Epoch 081 - training loss: 9303.2027, validation loss: 0.1294
2024-05-22 22:01:34 [INFO]: Epoch 082 - training loss: 9306.0216, validation loss: 0.1313
2024-05-22 22:01:34 [INFO]: Epoch 083 - training loss: 9302.7838, validation loss: 0.1297
2024-05-22 22:01:34 [INFO]: Epoch 084 - training loss: 9301.8571, validation loss: 0.1297
2024-05-22 22:01:34 [INFO]: Epoch 085 - training loss: 9302.4009, validation loss: 0.1270
2024-05-22 22:01:34 [INFO]: Epoch 086 - training loss: 9300.2717, validation loss: 0.1273
2024-05-22 22:01:34 [INFO]: Epoch 087 - training loss: 9302.2990, validation loss: 0.1278
2024-05-22 22:01:34 [INFO]: Epoch 088 - training loss: 9299.8452, validation loss: 0.1234
2024-05-22 22:01:34 [INFO]: Epoch 089 - training loss: 9297.4074, validation loss: 0.1260
2024-05-22 22:01:34 [INFO]: Epoch 090 - training loss: 9298.3258, validation loss: 0.1231
2024-05-22 22:01:35 [INFO]: Epoch 091 - training loss: 9297.8659, validation loss: 0.1230
2024-05-22 22:01:35 [INFO]: Epoch 092 - training loss: 9297.4644, validation loss: 0.1234
2024-05-22 22:01:35 [INFO]: Epoch 093 - training loss: 9295.5859, validation loss: 0.1258
2024-05-22 22:01:35 [INFO]: Epoch 094 - training loss: 9296.5000, validation loss: 0.1188
2024-05-22 22:01:35 [INFO]: Epoch 095 - training loss: 9294.6108, validation loss: 0.1211
2024-05-22 22:01:35 [INFO]: Epoch 096 - training loss: 9295.1136, validation loss: 0.1189
2024-05-22 22:01:35 [INFO]: Epoch 097 - training loss: 9292.4379, validation loss: 0.1185
2024-05-22 22:01:35 [INFO]: Epoch 098 - training loss: 9294.0222, validation loss: 0.1182
2024-05-22 22:01:35 [INFO]: Epoch 099 - training loss: 9295.3569, validation loss: 0.1189
2024-05-22 22:01:36 [INFO]: Epoch 100 - training loss: 9292.8082, validation loss: 0.1184
2024-05-22 22:01:36 [INFO]: Epoch 101 - training loss: 9295.2590, validation loss: 0.1173
2024-05-22 22:01:36 [INFO]: Epoch 102 - training loss: 9294.2433, validation loss: 0.1169
2024-05-22 22:01:36 [INFO]: Epoch 103 - training loss: 9291.8729, validation loss: 0.1138
2024-05-22 22:01:36 [INFO]: Epoch 104 - training loss: 9291.6779, validation loss: 0.1199
2024-05-22 22:01:36 [INFO]: Epoch 105 - training loss: 9293.3589, validation loss: 0.1144
2024-05-22 22:01:36 [INFO]: Epoch 106 - training loss: 9290.8930, validation loss: 0.1153
2024-05-22 22:01:36 [INFO]: Epoch 107 - training loss: 9290.8512, validation loss: 0.1140
2024-05-22 22:01:36 [INFO]: Epoch 108 - training loss: 9289.9731, validation loss: 0.1139
2024-05-22 22:01:37 [INFO]: Epoch 109 - training loss: 9288.4971, validation loss: 0.1131
2024-05-22 22:01:37 [INFO]: Epoch 110 - training loss: 9289.8768, validation loss: 0.1128
2024-05-22 22:01:37 [INFO]: Epoch 111 - training loss: 9289.0317, validation loss: 0.1130
2024-05-22 22:01:37 [INFO]: Epoch 112 - training loss: 9288.6266, validation loss: 0.1113
2024-05-22 22:01:37 [INFO]: Epoch 113 - training loss: 9288.2064, validation loss: 0.1099
2024-05-22 22:01:37 [INFO]: Epoch 114 - training loss: 9289.2479, validation loss: 0.1082
2024-05-22 22:01:37 [INFO]: Epoch 115 - training loss: 9287.3638, validation loss: 0.1095
2024-05-22 22:01:37 [INFO]: Epoch 116 - training loss: 9289.3197, validation loss: 0.1083
2024-05-22 22:01:37 [INFO]: Epoch 117 - training loss: 9287.3436, validation loss: 0.1100
2024-05-22 22:01:37 [INFO]: Epoch 118 - training loss: 9286.4371, validation loss: 0.1067
2024-05-22 22:01:38 [INFO]: Epoch 119 - training loss: 9286.1764, validation loss: 0.1070
2024-05-22 22:01:38 [INFO]: Epoch 120 - training loss: 9285.8575, validation loss: 0.1074
2024-05-22 22:01:38 [INFO]: Epoch 121 - training loss: 9286.5816, validation loss: 0.1054
2024-05-22 22:01:38 [INFO]: Epoch 122 - training loss: 9285.4143, validation loss: 0.1054
2024-05-22 22:01:38 [INFO]: Epoch 123 - training loss: 9284.2986, validation loss: 0.1057
2024-05-22 22:01:38 [INFO]: Epoch 124 - training loss: 9284.1378, validation loss: 0.1058
2024-05-22 22:01:38 [INFO]: Epoch 125 - training loss: 9284.4216, validation loss: 0.1040
2024-05-22 22:01:38 [INFO]: Epoch 126 - training loss: 9286.1644, validation loss: 0.1036
2024-05-22 22:01:38 [INFO]: Epoch 127 - training loss: 9285.0479, validation loss: 0.1041
2024-05-22 22:01:39 [INFO]: Epoch 128 - training loss: 9283.3923, validation loss: 0.1039
2024-05-22 22:01:39 [INFO]: Epoch 129 - training loss: 9281.5024, validation loss: 0.1030
2024-05-22 22:01:39 [INFO]: Epoch 130 - training loss: 9283.4410, validation loss: 0.1015
2024-05-22 22:01:39 [INFO]: Epoch 131 - training loss: 9282.3181, validation loss: 0.1033
2024-05-22 22:01:39 [INFO]: Epoch 132 - training loss: 9283.8393, validation loss: 0.1011
2024-05-22 22:01:39 [INFO]: Epoch 133 - training loss: 9283.9800, validation loss: 0.1001
2024-05-22 22:01:39 [INFO]: Epoch 134 - training loss: 9282.7150, validation loss: 0.1005
2024-05-22 22:01:39 [INFO]: Epoch 135 - training loss: 9283.0990, validation loss: 0.0988
2024-05-22 22:01:39 [INFO]: Epoch 136 - training loss: 9281.7332, validation loss: 0.1008
2024-05-22 22:01:40 [INFO]: Epoch 137 - training loss: 9282.9976, validation loss: 0.0992
2024-05-22 22:01:40 [INFO]: Epoch 138 - training loss: 9281.6650, validation loss: 0.0986
2024-05-22 22:01:40 [INFO]: Epoch 139 - training loss: 9282.2464, validation loss: 0.0971
2024-05-22 22:01:40 [INFO]: Epoch 140 - training loss: 9281.4751, validation loss: 0.0980
2024-05-22 22:01:40 [INFO]: Epoch 141 - training loss: 9280.5630, validation loss: 0.0971
2024-05-22 22:01:40 [INFO]: Epoch 142 - training loss: 9280.4405, validation loss: 0.0966
2024-05-22 22:01:40 [INFO]: Epoch 143 - training loss: 9281.2843, validation loss: 0.0980
2024-05-22 22:01:40 [INFO]: Epoch 144 - training loss: 9282.2319, validation loss: 0.0967
2024-05-22 22:01:40 [INFO]: Epoch 145 - training loss: 9281.3633, validation loss: 0.0939
2024-05-22 22:01:41 [INFO]: Epoch 146 - training loss: 9278.8917, validation loss: 0.0960
2024-05-22 22:01:41 [INFO]: Epoch 147 - training loss: 9281.3227, validation loss: 0.0943
2024-05-22 22:01:41 [INFO]: Epoch 148 - training loss: 9279.4869, validation loss: 0.0964
2024-05-22 22:01:41 [INFO]: Epoch 149 - training loss: 9279.2026, validation loss: 0.0932
2024-05-22 22:01:41 [INFO]: Epoch 150 - training loss: 9279.2537, validation loss: 0.0930
2024-05-22 22:01:41 [INFO]: Epoch 151 - training loss: 9280.9849, validation loss: 0.0936
2024-05-22 22:01:41 [INFO]: Epoch 152 - training loss: 9278.9279, validation loss: 0.0923
2024-05-22 22:01:41 [INFO]: Epoch 153 - training loss: 9279.7717, validation loss: 0.0973
2024-05-22 22:01:41 [INFO]: Epoch 154 - training loss: 9280.7767, validation loss: 0.0952
2024-05-22 22:01:42 [INFO]: Epoch 155 - training loss: 9278.6921, validation loss: 0.0928
2024-05-22 22:01:42 [INFO]: Epoch 156 - training loss: 9280.8154, validation loss: 0.0927
2024-05-22 22:01:42 [INFO]: Epoch 157 - training loss: 9277.3281, validation loss: 0.0926
2024-05-22 22:01:42 [INFO]: Epoch 158 - training loss: 9278.3954, validation loss: 0.0906
2024-05-22 22:01:42 [INFO]: Epoch 159 - training loss: 9277.6729, validation loss: 0.0929
2024-05-22 22:01:42 [INFO]: Epoch 160 - training loss: 9278.9606, validation loss: 0.0910
2024-05-22 22:01:42 [INFO]: Epoch 161 - training loss: 9276.8671, validation loss: 0.0908
2024-05-22 22:01:42 [INFO]: Epoch 162 - training loss: 9278.6783, validation loss: 0.0904
2024-05-22 22:01:42 [INFO]: Epoch 163 - training loss: 9278.9036, validation loss: 0.0910
2024-05-22 22:01:42 [INFO]: Epoch 164 - training loss: 9278.5195, validation loss: 0.0917
2024-05-22 22:01:43 [INFO]: Epoch 165 - training loss: 9276.9794, validation loss: 0.0888
2024-05-22 22:01:43 [INFO]: Epoch 166 - training loss: 9276.7098, validation loss: 0.0887
2024-05-22 22:01:43 [INFO]: Epoch 167 - training loss: 9276.6777, validation loss: 0.0886
2024-05-22 22:01:43 [INFO]: Epoch 168 - training loss: 9277.4714, validation loss: 0.0897
2024-05-22 22:01:43 [INFO]: Epoch 169 - training loss: 9275.9561, validation loss: 0.0878
2024-05-22 22:01:43 [INFO]: Epoch 170 - training loss: 9276.8470, validation loss: 0.0884
2024-05-22 22:01:43 [INFO]: Epoch 171 - training loss: 9277.1139, validation loss: 0.0871
2024-05-22 22:01:43 [INFO]: Epoch 172 - training loss: 9275.9850, validation loss: 0.0865
2024-05-22 22:01:43 [INFO]: Epoch 173 - training loss: 9275.3933, validation loss: 0.0878
2024-05-22 22:01:44 [INFO]: Epoch 174 - training loss: 9275.9178, validation loss: 0.0873
2024-05-22 22:01:44 [INFO]: Epoch 175 - training loss: 9275.2266, validation loss: 0.0883
2024-05-22 22:01:44 [INFO]: Epoch 176 - training loss: 9277.2062, validation loss: 0.0874
2024-05-22 22:01:44 [INFO]: Epoch 177 - training loss: 9275.6150, validation loss: 0.0873
2024-05-22 22:01:44 [INFO]: Epoch 178 - training loss: 9276.7407, validation loss: 0.0865
2024-05-22 22:01:44 [INFO]: Epoch 179 - training loss: 9275.3572, validation loss: 0.0878
2024-05-22 22:01:44 [INFO]: Epoch 180 - training loss: 9275.9583, validation loss: 0.0851
2024-05-22 22:01:44 [INFO]: Epoch 181 - training loss: 9276.1275, validation loss: 0.0873
2024-05-22 22:01:44 [INFO]: Epoch 182 - training loss: 9275.4167, validation loss: 0.0846
2024-05-22 22:01:45 [INFO]: Epoch 183 - training loss: 9275.6979, validation loss: 0.0839
2024-05-22 22:01:45 [INFO]: Epoch 184 - training loss: 9275.0220, validation loss: 0.0862
2024-05-22 22:01:45 [INFO]: Epoch 185 - training loss: 9275.3102, validation loss: 0.0838
2024-05-22 22:01:45 [INFO]: Epoch 186 - training loss: 9275.4884, validation loss: 0.0843
2024-05-22 22:01:45 [INFO]: Epoch 187 - training loss: 9275.1493, validation loss: 0.0846
2024-05-22 22:01:45 [INFO]: Epoch 188 - training loss: 9275.7905, validation loss: 0.0839
2024-05-22 22:01:45 [INFO]: Epoch 189 - training loss: 9275.2345, validation loss: 0.0855
2024-05-22 22:01:45 [INFO]: Epoch 190 - training loss: 9275.0204, validation loss: 0.0826
2024-05-22 22:01:45 [INFO]: Epoch 191 - training loss: 9277.1656, validation loss: 0.0838
2024-05-22 22:01:46 [INFO]: Epoch 192 - training loss: 9274.0888, validation loss: 0.0843
2024-05-22 22:01:46 [INFO]: Epoch 193 - training loss: 9273.4800, validation loss: 0.0828
2024-05-22 22:01:46 [INFO]: Epoch 194 - training loss: 9273.8241, validation loss: 0.0836
2024-05-22 22:01:46 [INFO]: Epoch 195 - training loss: 9274.7639, validation loss: 0.0839
2024-05-22 22:01:46 [INFO]: Epoch 196 - training loss: 9273.8946, validation loss: 0.0832
2024-05-22 22:01:46 [INFO]: Epoch 197 - training loss: 9273.1468, validation loss: 0.0840
2024-05-22 22:01:46 [INFO]: Epoch 198 - training loss: 9274.3412, validation loss: 0.0832
2024-05-22 22:01:46 [INFO]: Epoch 199 - training loss: 9275.0540, validation loss: 0.0837
2024-05-22 22:01:46 [INFO]: Epoch 200 - training loss: 9273.9141, validation loss: 0.0824
2024-05-22 22:01:46 [INFO]: Epoch 201 - training loss: 9272.2073, validation loss: 0.0832
2024-05-22 22:01:47 [INFO]: Epoch 202 - training loss: 9275.0116, validation loss: 0.0826
2024-05-22 22:01:47 [INFO]: Epoch 203 - training loss: 9273.2397, validation loss: 0.0831
2024-05-22 22:01:47 [INFO]: Epoch 204 - training loss: 9272.8660, validation loss: 0.0822
2024-05-22 22:01:47 [INFO]: Epoch 205 - training loss: 9274.4059, validation loss: 0.0810
2024-05-22 22:01:47 [INFO]: Epoch 206 - training loss: 9272.7273, validation loss: 0.0817
2024-05-22 22:01:47 [INFO]: Epoch 207 - training loss: 9273.2899, validation loss: 0.0834
2024-05-22 22:01:47 [INFO]: Epoch 208 - training loss: 9272.1683, validation loss: 0.0801
2024-05-22 22:01:47 [INFO]: Epoch 209 - training loss: 9272.6765, validation loss: 0.0826
2024-05-22 22:01:47 [INFO]: Epoch 210 - training loss: 9273.2098, validation loss: 0.0828
2024-05-22 22:01:48 [INFO]: Epoch 211 - training loss: 9272.1064, validation loss: 0.0822
2024-05-22 22:01:48 [INFO]: Epoch 212 - training loss: 9272.9849, validation loss: 0.0825
2024-05-22 22:01:48 [INFO]: Epoch 213 - training loss: 9274.4108, validation loss: 0.0815
2024-05-22 22:01:48 [INFO]: Epoch 214 - training loss: 9272.7756, validation loss: 0.0819
2024-05-22 22:01:48 [INFO]: Epoch 215 - training loss: 9274.8658, validation loss: 0.0811
2024-05-22 22:01:48 [INFO]: Epoch 216 - training loss: 9272.7197, validation loss: 0.0816
2024-05-22 22:01:48 [INFO]: Epoch 217 - training loss: 9271.8995, validation loss: 0.0809
2024-05-22 22:01:48 [INFO]: Epoch 218 - training loss: 9273.9848, validation loss: 0.0799
2024-05-22 22:01:48 [INFO]: Epoch 219 - training loss: 9272.0922, validation loss: 0.0802
2024-05-22 22:01:49 [INFO]: Epoch 220 - training loss: 9273.0549, validation loss: 0.0805
2024-05-22 22:01:49 [INFO]: Epoch 221 - training loss: 9272.3318, validation loss: 0.0803
2024-05-22 22:01:49 [INFO]: Epoch 222 - training loss: 9272.4236, validation loss: 0.0798
2024-05-22 22:01:49 [INFO]: Epoch 223 - training loss: 9272.5843, validation loss: 0.0816
2024-05-22 22:01:49 [INFO]: Epoch 224 - training loss: 9272.1946, validation loss: 0.0816
2024-05-22 22:01:49 [INFO]: Epoch 225 - training loss: 9272.0035, validation loss: 0.0790
2024-05-22 22:01:49 [INFO]: Epoch 226 - training loss: 9272.1248, validation loss: 0.0787
2024-05-22 22:01:49 [INFO]: Epoch 227 - training loss: 9273.6250, validation loss: 0.0791
2024-05-22 22:01:49 [INFO]: Epoch 228 - training loss: 9272.2405, validation loss: 0.0780
2024-05-22 22:01:50 [INFO]: Epoch 229 - training loss: 9272.0508, validation loss: 0.0774
2024-05-22 22:01:50 [INFO]: Epoch 230 - training loss: 9272.0336, validation loss: 0.0793
2024-05-22 22:01:50 [INFO]: Epoch 231 - training loss: 9271.8578, validation loss: 0.0789
2024-05-22 22:01:50 [INFO]: Epoch 232 - training loss: 9271.8557, validation loss: 0.0806
2024-05-22 22:01:50 [INFO]: Epoch 233 - training loss: 9272.4942, validation loss: 0.0810
2024-05-22 22:01:50 [INFO]: Epoch 234 - training loss: 9271.9498, validation loss: 0.0804
2024-05-22 22:01:50 [INFO]: Epoch 235 - training loss: 9271.6437, validation loss: 0.0811
2024-05-22 22:01:50 [INFO]: Epoch 236 - training loss: 9271.4493, validation loss: 0.0798
2024-05-22 22:01:50 [INFO]: Epoch 237 - training loss: 9272.8615, validation loss: 0.0803
2024-05-22 22:01:50 [INFO]: Epoch 238 - training loss: 9271.2615, validation loss: 0.0795
2024-05-22 22:01:51 [INFO]: Epoch 239 - training loss: 9271.2201, validation loss: 0.0783
2024-05-22 22:01:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:01:51 [INFO]: Finished training. The best model is from epoch#229.
2024-05-22 22:01:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/GPVAE_ettm1/20240522_T220125/GPVAE.pypots
2024-05-22 22:01:51 [INFO]: GP-VAE on ETTm1: MAE=0.2700, MSE=0.1522
2024-05-22 22:01:51 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/GPVAE_ettm1/imputation.pkl
2024-05-22 22:01:51 [INFO]: Using the given device: cuda:0
2024-05-22 22:01:51 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/USGAN_ettm1/20240522_T220151
2024-05-22 22:01:51 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/USGAN_ettm1/20240522_T220151/tensorboard
2024-05-22 22:01:51 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 22:01:59 [INFO]: Epoch 001 - generator training loss: 0.4500, discriminator training loss: 0.4365, validation loss: 0.2934
2024-05-22 22:02:06 [INFO]: Epoch 002 - generator training loss: -0.0049, discriminator training loss: 0.3232, validation loss: 0.1044
2024-05-22 22:02:13 [INFO]: Epoch 003 - generator training loss: -0.1329, discriminator training loss: 0.3096, validation loss: 0.0630
2024-05-22 22:02:20 [INFO]: Epoch 004 - generator training loss: -0.1471, discriminator training loss: 0.2980, validation loss: 0.0474
2024-05-22 22:02:27 [INFO]: Epoch 005 - generator training loss: -0.1304, discriminator training loss: 0.2778, validation loss: 0.0422
2024-05-22 22:02:34 [INFO]: Epoch 006 - generator training loss: -0.1109, discriminator training loss: 0.2491, validation loss: 0.0405
2024-05-22 22:02:41 [INFO]: Epoch 007 - generator training loss: -0.0836, discriminator training loss: 0.2121, validation loss: 0.0387
2024-05-22 22:02:48 [INFO]: Epoch 008 - generator training loss: -0.0641, discriminator training loss: 0.1815, validation loss: 0.0373
2024-05-22 22:02:54 [INFO]: Epoch 009 - generator training loss: -0.0510, discriminator training loss: 0.1576, validation loss: 0.0359
2024-05-22 22:03:01 [INFO]: Epoch 010 - generator training loss: -0.0454, discriminator training loss: 0.1452, validation loss: 0.0363
2024-05-22 22:03:08 [INFO]: Epoch 011 - generator training loss: -0.0395, discriminator training loss: 0.1368, validation loss: 0.0341
2024-05-22 22:03:15 [INFO]: Epoch 012 - generator training loss: -0.0384, discriminator training loss: 0.1317, validation loss: 0.0342
2024-05-22 22:03:22 [INFO]: Epoch 013 - generator training loss: -0.0376, discriminator training loss: 0.1279, validation loss: 0.0333
2024-05-22 22:03:29 [INFO]: Epoch 014 - generator training loss: -0.0377, discriminator training loss: 0.1279, validation loss: 0.0332
2024-05-22 22:03:36 [INFO]: Epoch 015 - generator training loss: -0.0362, discriminator training loss: 0.1242, validation loss: 0.0324
2024-05-22 22:03:43 [INFO]: Epoch 016 - generator training loss: -0.0375, discriminator training loss: 0.1224, validation loss: 0.0321
2024-05-22 22:03:50 [INFO]: Epoch 017 - generator training loss: -0.0396, discriminator training loss: 0.1209, validation loss: 0.0311
2024-05-22 22:03:57 [INFO]: Epoch 018 - generator training loss: -0.0418, discriminator training loss: 0.1223, validation loss: 0.0311
2024-05-22 22:04:04 [INFO]: Epoch 019 - generator training loss: -0.0389, discriminator training loss: 0.1215, validation loss: 0.0305
2024-05-22 22:04:11 [INFO]: Epoch 020 - generator training loss: -0.0401, discriminator training loss: 0.1175, validation loss: 0.0303
2024-05-22 22:04:18 [INFO]: Epoch 021 - generator training loss: -0.0404, discriminator training loss: 0.1177, validation loss: 0.0302
2024-05-22 22:04:25 [INFO]: Epoch 022 - generator training loss: -0.0384, discriminator training loss: 0.1168, validation loss: 0.0302
2024-05-22 22:04:32 [INFO]: Epoch 023 - generator training loss: -0.0396, discriminator training loss: 0.1172, validation loss: 0.0294
2024-05-22 22:04:39 [INFO]: Epoch 024 - generator training loss: -0.0407, discriminator training loss: 0.1166, validation loss: 0.0295
2024-05-22 22:04:46 [INFO]: Epoch 025 - generator training loss: -0.0403, discriminator training loss: 0.1165, validation loss: 0.0296
2024-05-22 22:04:53 [INFO]: Epoch 026 - generator training loss: -0.0402, discriminator training loss: 0.1143, validation loss: 0.0295
2024-05-22 22:05:00 [INFO]: Epoch 027 - generator training loss: -0.0436, discriminator training loss: 0.1159, validation loss: 0.0292
2024-05-22 22:05:07 [INFO]: Epoch 028 - generator training loss: -0.0430, discriminator training loss: 0.1143, validation loss: 0.0279
2024-05-22 22:05:14 [INFO]: Epoch 029 - generator training loss: -0.0423, discriminator training loss: 0.1158, validation loss: 0.0280
2024-05-22 22:05:21 [INFO]: Epoch 030 - generator training loss: -0.0405, discriminator training loss: 0.1148, validation loss: 0.0276
2024-05-22 22:05:28 [INFO]: Epoch 031 - generator training loss: -0.0425, discriminator training loss: 0.1146, validation loss: 0.0285
2024-05-22 22:05:35 [INFO]: Epoch 032 - generator training loss: -0.0436, discriminator training loss: 0.1121, validation loss: 0.0274
2024-05-22 22:05:42 [INFO]: Epoch 033 - generator training loss: -0.0437, discriminator training loss: 0.1129, validation loss: 0.0272
2024-05-22 22:05:49 [INFO]: Epoch 034 - generator training loss: -0.0419, discriminator training loss: 0.1101, validation loss: 0.0265
2024-05-22 22:05:56 [INFO]: Epoch 035 - generator training loss: -0.0449, discriminator training loss: 0.1113, validation loss: 0.0270
2024-05-22 22:06:03 [INFO]: Epoch 036 - generator training loss: -0.0439, discriminator training loss: 0.1127, validation loss: 0.0262
2024-05-22 22:06:10 [INFO]: Epoch 037 - generator training loss: -0.0431, discriminator training loss: 0.1127, validation loss: 0.0263
2024-05-22 22:06:17 [INFO]: Epoch 038 - generator training loss: -0.0404, discriminator training loss: 0.1109, validation loss: 0.0261
2024-05-22 22:06:24 [INFO]: Epoch 039 - generator training loss: -0.0488, discriminator training loss: 0.1112, validation loss: 0.0258
2024-05-22 22:06:31 [INFO]: Epoch 040 - generator training loss: -0.0439, discriminator training loss: 0.1137, validation loss: 0.0255
2024-05-22 22:06:37 [INFO]: Epoch 041 - generator training loss: -0.0461, discriminator training loss: 0.1162, validation loss: 0.0257
2024-05-22 22:06:44 [INFO]: Epoch 042 - generator training loss: -0.0442, discriminator training loss: 0.1143, validation loss: 0.0256
2024-05-22 22:06:51 [INFO]: Epoch 043 - generator training loss: -0.0467, discriminator training loss: 0.1125, validation loss: 0.0252
2024-05-22 22:06:58 [INFO]: Epoch 044 - generator training loss: -0.0431, discriminator training loss: 0.1119, validation loss: 0.0248
2024-05-22 22:07:05 [INFO]: Epoch 045 - generator training loss: -0.0429, discriminator training loss: 0.1095, validation loss: 0.0249
2024-05-22 22:07:12 [INFO]: Epoch 046 - generator training loss: -0.0469, discriminator training loss: 0.1102, validation loss: 0.0248
2024-05-22 22:07:19 [INFO]: Epoch 047 - generator training loss: -0.0443, discriminator training loss: 0.1111, validation loss: 0.0246
2024-05-22 22:07:26 [INFO]: Epoch 048 - generator training loss: -0.0454, discriminator training loss: 0.1097, validation loss: 0.0246
2024-05-22 22:07:33 [INFO]: Epoch 049 - generator training loss: -0.0445, discriminator training loss: 0.1112, validation loss: 0.0242
2024-05-22 22:07:40 [INFO]: Epoch 050 - generator training loss: -0.0461, discriminator training loss: 0.1116, validation loss: 0.0252
2024-05-22 22:07:47 [INFO]: Epoch 051 - generator training loss: -0.0440, discriminator training loss: 0.1081, validation loss: 0.0246
2024-05-22 22:07:54 [INFO]: Epoch 052 - generator training loss: -0.0463, discriminator training loss: 0.1098, validation loss: 0.0242
2024-05-22 22:08:01 [INFO]: Epoch 053 - generator training loss: -0.0470, discriminator training loss: 0.1116, validation loss: 0.0250
2024-05-22 22:08:08 [INFO]: Epoch 054 - generator training loss: -0.0462, discriminator training loss: 0.1072, validation loss: 0.0242
2024-05-22 22:08:15 [INFO]: Epoch 055 - generator training loss: -0.0465, discriminator training loss: 0.1071, validation loss: 0.0242
2024-05-22 22:08:22 [INFO]: Epoch 056 - generator training loss: -0.0456, discriminator training loss: 0.1082, validation loss: 0.0246
2024-05-22 22:08:29 [INFO]: Epoch 057 - generator training loss: -0.0454, discriminator training loss: 0.1089, validation loss: 0.0257
2024-05-22 22:08:36 [INFO]: Epoch 058 - generator training loss: -0.0453, discriminator training loss: 0.1094, validation loss: 0.0245
2024-05-22 22:08:43 [INFO]: Epoch 059 - generator training loss: -0.0477, discriminator training loss: 0.1082, validation loss: 0.0248
2024-05-22 22:08:50 [INFO]: Epoch 060 - generator training loss: -0.0458, discriminator training loss: 0.1092, validation loss: 0.0233
2024-05-22 22:08:57 [INFO]: Epoch 061 - generator training loss: -0.0482, discriminator training loss: 0.1094, validation loss: 0.0243
2024-05-22 22:09:04 [INFO]: Epoch 062 - generator training loss: -0.0445, discriminator training loss: 0.1115, validation loss: 0.0241
2024-05-22 22:09:11 [INFO]: Epoch 063 - generator training loss: -0.0484, discriminator training loss: 0.1095, validation loss: 0.0242
2024-05-22 22:09:18 [INFO]: Epoch 064 - generator training loss: -0.0482, discriminator training loss: 0.1090, validation loss: 0.0231
2024-05-22 22:09:25 [INFO]: Epoch 065 - generator training loss: -0.0481, discriminator training loss: 0.1089, validation loss: 0.0243
2024-05-22 22:09:32 [INFO]: Epoch 066 - generator training loss: -0.0438, discriminator training loss: 0.1063, validation loss: 0.0239
2024-05-22 22:09:39 [INFO]: Epoch 067 - generator training loss: -0.0474, discriminator training loss: 0.1083, validation loss: 0.0236
2024-05-22 22:09:46 [INFO]: Epoch 068 - generator training loss: -0.0447, discriminator training loss: 0.1089, validation loss: 0.0240
2024-05-22 22:09:53 [INFO]: Epoch 069 - generator training loss: -0.0460, discriminator training loss: 0.1077, validation loss: 0.0243
2024-05-22 22:10:00 [INFO]: Epoch 070 - generator training loss: -0.0473, discriminator training loss: 0.1053, validation loss: 0.0236
2024-05-22 22:10:07 [INFO]: Epoch 071 - generator training loss: -0.0468, discriminator training loss: 0.1077, validation loss: 0.0253
2024-05-22 22:10:14 [INFO]: Epoch 072 - generator training loss: -0.0491, discriminator training loss: 0.1101, validation loss: 0.0234
2024-05-22 22:10:21 [INFO]: Epoch 073 - generator training loss: -0.0479, discriminator training loss: 0.1076, validation loss: 0.0241
2024-05-22 22:10:27 [INFO]: Epoch 074 - generator training loss: -0.0474, discriminator training loss: 0.1088, validation loss: 0.0280
2024-05-22 22:10:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:10:27 [INFO]: Finished training. The best model is from epoch#64.
2024-05-22 22:10:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/USGAN_ettm1/20240522_T220151/USGAN.pypots
2024-05-22 22:10:28 [INFO]: US-GAN on ETTm1: MAE=0.1571, MSE=0.0588
2024-05-22 22:10:28 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/USGAN_ettm1/imputation.pkl
2024-05-22 22:10:28 [INFO]: Using the given device: cuda:0
2024-05-22 22:10:28 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/BRITS_ettm1/20240522_T221028
2024-05-22 22:10:28 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/BRITS_ettm1/20240522_T221028/tensorboard
2024-05-22 22:10:28 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 22:10:34 [INFO]: Epoch 001 - training loss: 1.3114, validation loss: 0.2863
2024-05-22 22:10:38 [INFO]: Epoch 002 - training loss: 0.8581, validation loss: 0.0972
2024-05-22 22:10:43 [INFO]: Epoch 003 - training loss: 0.6850, validation loss: 0.0573
2024-05-22 22:10:48 [INFO]: Epoch 004 - training loss: 0.6190, validation loss: 0.0514
2024-05-22 22:10:52 [INFO]: Epoch 005 - training loss: 0.5951, validation loss: 0.0423
2024-05-22 22:10:57 [INFO]: Epoch 006 - training loss: 0.5587, validation loss: 0.0446
2024-05-22 22:11:02 [INFO]: Epoch 007 - training loss: 0.5165, validation loss: 0.0381
2024-05-22 22:11:06 [INFO]: Epoch 008 - training loss: 0.4955, validation loss: 0.0357
2024-05-22 22:11:11 [INFO]: Epoch 009 - training loss: 0.4649, validation loss: 0.0319
2024-05-22 22:11:15 [INFO]: Epoch 010 - training loss: 0.4450, validation loss: 0.0308
2024-05-22 22:11:20 [INFO]: Epoch 011 - training loss: 0.4421, validation loss: 0.0297
2024-05-22 22:11:24 [INFO]: Epoch 012 - training loss: 0.4232, validation loss: 0.0283
2024-05-22 22:11:29 [INFO]: Epoch 013 - training loss: 0.4277, validation loss: 0.0277
2024-05-22 22:11:34 [INFO]: Epoch 014 - training loss: 0.4268, validation loss: 0.0272
2024-05-22 22:11:38 [INFO]: Epoch 015 - training loss: 0.4069, validation loss: 0.0267
2024-05-22 22:11:43 [INFO]: Epoch 016 - training loss: 0.3992, validation loss: 0.0252
2024-05-22 22:11:48 [INFO]: Epoch 017 - training loss: 0.4029, validation loss: 0.0253
2024-05-22 22:11:52 [INFO]: Epoch 018 - training loss: 0.4015, validation loss: 0.0250
2024-05-22 22:11:57 [INFO]: Epoch 019 - training loss: 0.3864, validation loss: 0.0251
2024-05-22 22:12:01 [INFO]: Epoch 020 - training loss: 0.3864, validation loss: 0.0254
2024-05-22 22:12:06 [INFO]: Epoch 021 - training loss: 0.3865, validation loss: 0.0247
2024-05-22 22:12:11 [INFO]: Epoch 022 - training loss: 0.3861, validation loss: 0.0250
2024-05-22 22:12:15 [INFO]: Epoch 023 - training loss: 0.3986, validation loss: 0.0249
2024-05-22 22:12:20 [INFO]: Epoch 024 - training loss: 0.3756, validation loss: 0.0274
2024-05-22 22:12:24 [INFO]: Epoch 025 - training loss: 0.4200, validation loss: 0.0277
2024-05-22 22:12:29 [INFO]: Epoch 026 - training loss: 0.4155, validation loss: 0.0271
2024-05-22 22:12:34 [INFO]: Epoch 027 - training loss: 0.4034, validation loss: 0.0260
2024-05-22 22:12:38 [INFO]: Epoch 028 - training loss: 0.3926, validation loss: 0.0249
2024-05-22 22:12:43 [INFO]: Epoch 029 - training loss: 0.3929, validation loss: 0.0250
2024-05-22 22:12:47 [INFO]: Epoch 030 - training loss: 0.3904, validation loss: 0.0250
2024-05-22 22:12:52 [INFO]: Epoch 031 - training loss: 0.3886, validation loss: 0.0253
2024-05-22 22:12:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:12:52 [INFO]: Finished training. The best model is from epoch#21.
2024-05-22 22:12:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/BRITS_ettm1/20240522_T221028/BRITS.pypots
2024-05-22 22:12:53 [INFO]: BRITS on ETTm1: MAE=0.1284, MSE=0.0498
2024-05-22 22:12:53 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/BRITS_ettm1/imputation.pkl
2024-05-22 22:12:53 [INFO]: Using the given device: cuda:0
2024-05-22 22:12:53 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253
2024-05-22 22:12:53 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/tensorboard
2024-05-22 22:12:53 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 22:12:54 [INFO]: Epoch 001 - training loss: 1.3640, validation loss: 1.3217
2024-05-22 22:12:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch1_loss1.3216513693332672.pypots
2024-05-22 22:12:54 [INFO]: Epoch 002 - training loss: 1.1057, validation loss: 1.1652
2024-05-22 22:12:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch2_loss1.1652171164751053.pypots
2024-05-22 22:12:54 [INFO]: Epoch 003 - training loss: 0.9776, validation loss: 1.0703
2024-05-22 22:12:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch3_loss1.0702504813671112.pypots
2024-05-22 22:12:54 [INFO]: Epoch 004 - training loss: 0.9513, validation loss: 1.0355
2024-05-22 22:12:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch4_loss1.0354650169610977.pypots
2024-05-22 22:12:55 [INFO]: Epoch 005 - training loss: 0.9378, validation loss: 1.0194
2024-05-22 22:12:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch5_loss1.0193589180707932.pypots
2024-05-22 22:12:55 [INFO]: Epoch 006 - training loss: 0.9067, validation loss: 1.0120
2024-05-22 22:12:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch6_loss1.0119525343179703.pypots
2024-05-22 22:12:55 [INFO]: Epoch 007 - training loss: 0.9264, validation loss: 1.0053
2024-05-22 22:12:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch7_loss1.0052953213453293.pypots
2024-05-22 22:12:55 [INFO]: Epoch 008 - training loss: 0.9498, validation loss: 0.9969
2024-05-22 22:12:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch8_loss0.9969386756420135.pypots
2024-05-22 22:12:55 [INFO]: Epoch 009 - training loss: 0.9244, validation loss: 0.9952
2024-05-22 22:12:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch9_loss0.9951597601175308.pypots
2024-05-22 22:12:55 [INFO]: Epoch 010 - training loss: 0.9127, validation loss: 0.9929
2024-05-22 22:12:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch10_loss0.9928530752658844.pypots
2024-05-22 22:12:56 [INFO]: Epoch 011 - training loss: 0.8947, validation loss: 0.9912
2024-05-22 22:12:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch11_loss0.9911742955446243.pypots
2024-05-22 22:12:56 [INFO]: Epoch 012 - training loss: 0.8725, validation loss: 0.9882
2024-05-22 22:12:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch12_loss0.988226130604744.pypots
2024-05-22 22:12:56 [INFO]: Epoch 013 - training loss: 0.8877, validation loss: 0.9860
2024-05-22 22:12:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch13_loss0.9860038310289383.pypots
2024-05-22 22:12:56 [INFO]: Epoch 014 - training loss: 0.8812, validation loss: 0.9855
2024-05-22 22:12:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch14_loss0.9855280965566635.pypots
2024-05-22 22:12:56 [INFO]: Epoch 015 - training loss: 0.8489, validation loss: 0.9862
2024-05-22 22:12:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch15_loss0.986242800951004.pypots
2024-05-22 22:12:56 [INFO]: Epoch 016 - training loss: 0.8380, validation loss: 0.9835
2024-05-22 22:12:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch16_loss0.9834980070590973.pypots
2024-05-22 22:12:57 [INFO]: Epoch 017 - training loss: 0.8315, validation loss: 0.9800
2024-05-22 22:12:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch17_loss0.9800048619508743.pypots
2024-05-22 22:12:57 [INFO]: Epoch 018 - training loss: 0.8603, validation loss: 0.9763
2024-05-22 22:12:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch18_loss0.9762905985116959.pypots
2024-05-22 22:12:57 [INFO]: Epoch 019 - training loss: 0.8388, validation loss: 0.9745
2024-05-22 22:12:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch19_loss0.9744772613048553.pypots
2024-05-22 22:12:57 [INFO]: Epoch 020 - training loss: 0.8456, validation loss: 0.9706
2024-05-22 22:12:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch20_loss0.9706327468156815.pypots
2024-05-22 22:12:57 [INFO]: Epoch 021 - training loss: 0.8289, validation loss: 0.9692
2024-05-22 22:12:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch21_loss0.9691955745220184.pypots
2024-05-22 22:12:57 [INFO]: Epoch 022 - training loss: 0.8373, validation loss: 0.9636
2024-05-22 22:12:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch22_loss0.9636141061782837.pypots
2024-05-22 22:12:57 [INFO]: Epoch 023 - training loss: 0.8543, validation loss: 0.9616
2024-05-22 22:12:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch23_loss0.961595818400383.pypots
2024-05-22 22:12:58 [INFO]: Epoch 024 - training loss: 0.8350, validation loss: 0.9618
2024-05-22 22:12:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch24_loss0.9618253707885742.pypots
2024-05-22 22:12:58 [INFO]: Epoch 025 - training loss: 0.8182, validation loss: 0.9584
2024-05-22 22:12:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch25_loss0.9583788812160492.pypots
2024-05-22 22:12:58 [INFO]: Epoch 026 - training loss: 0.8094, validation loss: 0.9589
2024-05-22 22:12:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch26_loss0.9588837623596191.pypots
2024-05-22 22:12:58 [INFO]: Epoch 027 - training loss: 0.8105, validation loss: 0.9548
2024-05-22 22:12:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch27_loss0.9548059850931168.pypots
2024-05-22 22:12:58 [INFO]: Epoch 028 - training loss: 0.8005, validation loss: 0.9540
2024-05-22 22:12:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch28_loss0.9539623111486435.pypots
2024-05-22 22:12:58 [INFO]: Epoch 029 - training loss: 0.8663, validation loss: 0.9483
2024-05-22 22:12:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch29_loss0.9482873529195786.pypots
2024-05-22 22:12:59 [INFO]: Epoch 030 - training loss: 0.8155, validation loss: 0.9466
2024-05-22 22:12:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch30_loss0.946601465344429.pypots
2024-05-22 22:12:59 [INFO]: Epoch 031 - training loss: 0.7947, validation loss: 0.9415
2024-05-22 22:12:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch31_loss0.9414866119623184.pypots
2024-05-22 22:12:59 [INFO]: Epoch 032 - training loss: 0.8133, validation loss: 0.9382
2024-05-22 22:12:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch32_loss0.9381570518016815.pypots
2024-05-22 22:12:59 [INFO]: Epoch 033 - training loss: 0.8062, validation loss: 0.9353
2024-05-22 22:12:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch33_loss0.9353401213884354.pypots
2024-05-22 22:12:59 [INFO]: Epoch 034 - training loss: 0.8163, validation loss: 0.9325
2024-05-22 22:12:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch34_loss0.9324893653392792.pypots
2024-05-22 22:12:59 [INFO]: Epoch 035 - training loss: 0.7865, validation loss: 0.9298
2024-05-22 22:12:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch35_loss0.929763525724411.pypots
2024-05-22 22:13:00 [INFO]: Epoch 036 - training loss: 0.8084, validation loss: 0.9268
2024-05-22 22:13:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch36_loss0.9268259108066559.pypots
2024-05-22 22:13:00 [INFO]: Epoch 037 - training loss: 0.7954, validation loss: 0.9237
2024-05-22 22:13:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch37_loss0.9236514568328857.pypots
2024-05-22 22:13:00 [INFO]: Epoch 038 - training loss: 0.8105, validation loss: 0.9219
2024-05-22 22:13:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch38_loss0.9219170957803726.pypots
2024-05-22 22:13:00 [INFO]: Epoch 039 - training loss: 0.7995, validation loss: 0.9190
2024-05-22 22:13:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch39_loss0.9190003424882889.pypots
2024-05-22 22:13:00 [INFO]: Epoch 040 - training loss: 0.7794, validation loss: 0.9150
2024-05-22 22:13:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch40_loss0.9150227159261703.pypots
2024-05-22 22:13:00 [INFO]: Epoch 041 - training loss: 0.8006, validation loss: 0.9142
2024-05-22 22:13:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch41_loss0.914175346493721.pypots
2024-05-22 22:13:00 [INFO]: Epoch 042 - training loss: 0.8067, validation loss: 0.9103
2024-05-22 22:13:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch42_loss0.9102630019187927.pypots
2024-05-22 22:13:01 [INFO]: Epoch 043 - training loss: 0.7910, validation loss: 0.9066
2024-05-22 22:13:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch43_loss0.9066085815429688.pypots
2024-05-22 22:13:01 [INFO]: Epoch 044 - training loss: 0.7976, validation loss: 0.9039
2024-05-22 22:13:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch44_loss0.903855174779892.pypots
2024-05-22 22:13:01 [INFO]: Epoch 045 - training loss: 0.7888, validation loss: 0.9041
2024-05-22 22:13:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch45_loss0.9041469395160675.pypots
2024-05-22 22:13:01 [INFO]: Epoch 046 - training loss: 0.7849, validation loss: 0.8988
2024-05-22 22:13:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch46_loss0.8988368809223175.pypots
2024-05-22 22:13:01 [INFO]: Epoch 047 - training loss: 0.7811, validation loss: 0.8959
2024-05-22 22:13:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch47_loss0.8958886712789536.pypots
2024-05-22 22:13:01 [INFO]: Epoch 048 - training loss: 0.7969, validation loss: 0.8923
2024-05-22 22:13:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch48_loss0.8923458456993103.pypots
2024-05-22 22:13:02 [INFO]: Epoch 049 - training loss: 0.7925, validation loss: 0.8919
2024-05-22 22:13:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch49_loss0.891902431845665.pypots
2024-05-22 22:13:02 [INFO]: Epoch 050 - training loss: 0.7669, validation loss: 0.8892
2024-05-22 22:13:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch50_loss0.8891831785440445.pypots
2024-05-22 22:13:02 [INFO]: Epoch 051 - training loss: 0.7921, validation loss: 0.8896
2024-05-22 22:13:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch51_loss0.8896050602197647.pypots
2024-05-22 22:13:02 [INFO]: Epoch 052 - training loss: 0.7973, validation loss: 0.8850
2024-05-22 22:13:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch52_loss0.8849931508302689.pypots
2024-05-22 22:13:02 [INFO]: Epoch 053 - training loss: 0.7864, validation loss: 0.8833
2024-05-22 22:13:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch53_loss0.8833464682102203.pypots
2024-05-22 22:13:02 [INFO]: Epoch 054 - training loss: 0.7931, validation loss: 0.8804
2024-05-22 22:13:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch54_loss0.8804363757371902.pypots
2024-05-22 22:13:03 [INFO]: Epoch 055 - training loss: 0.8000, validation loss: 0.8796
2024-05-22 22:13:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch55_loss0.8795774430036545.pypots
2024-05-22 22:13:03 [INFO]: Epoch 056 - training loss: 0.7981, validation loss: 0.8763
2024-05-22 22:13:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch56_loss0.8763265013694763.pypots
2024-05-22 22:13:03 [INFO]: Epoch 057 - training loss: 0.7909, validation loss: 0.8758
2024-05-22 22:13:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch57_loss0.8758229613304138.pypots
2024-05-22 22:13:03 [INFO]: Epoch 058 - training loss: 0.8085, validation loss: 0.8725
2024-05-22 22:13:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch58_loss0.8724914640188217.pypots
2024-05-22 22:13:03 [INFO]: Epoch 059 - training loss: 0.8022, validation loss: 0.8720
2024-05-22 22:13:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch59_loss0.8720160871744156.pypots
2024-05-22 22:13:03 [INFO]: Epoch 060 - training loss: 0.7868, validation loss: 0.8696
2024-05-22 22:13:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch60_loss0.8696189373731613.pypots
2024-05-22 22:13:03 [INFO]: Epoch 061 - training loss: 0.7958, validation loss: 0.8694
2024-05-22 22:13:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch61_loss0.869408905506134.pypots
2024-05-22 22:13:04 [INFO]: Epoch 062 - training loss: 0.7959, validation loss: 0.8651
2024-05-22 22:13:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch62_loss0.8651157319545746.pypots
2024-05-22 22:13:04 [INFO]: Epoch 063 - training loss: 0.8290, validation loss: 0.8649
2024-05-22 22:13:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch63_loss0.8649396300315857.pypots
2024-05-22 22:13:04 [INFO]: Epoch 064 - training loss: 0.7983, validation loss: 0.8635
2024-05-22 22:13:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch64_loss0.8635081201791763.pypots
2024-05-22 22:13:05 [INFO]: Epoch 065 - training loss: 0.7981, validation loss: 0.8644
2024-05-22 22:13:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch65_loss0.8644412755966187.pypots
2024-05-22 22:13:05 [INFO]: Epoch 066 - training loss: 0.7759, validation loss: 0.8629
2024-05-22 22:13:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch66_loss0.8629101365804672.pypots
2024-05-22 22:13:05 [INFO]: Epoch 067 - training loss: 0.8024, validation loss: 0.8633
2024-05-22 22:13:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch67_loss0.8633465021848679.pypots
2024-05-22 22:13:05 [INFO]: Epoch 068 - training loss: 0.7799, validation loss: 0.8618
2024-05-22 22:13:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch68_loss0.8618007600307465.pypots
2024-05-22 22:13:05 [INFO]: Epoch 069 - training loss: 0.7727, validation loss: 0.8603
2024-05-22 22:13:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch69_loss0.860260397195816.pypots
2024-05-22 22:13:05 [INFO]: Epoch 070 - training loss: 0.7591, validation loss: 0.8606
2024-05-22 22:13:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch70_loss0.8606471121311188.pypots
2024-05-22 22:13:05 [INFO]: Epoch 071 - training loss: 0.7592, validation loss: 0.8589
2024-05-22 22:13:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch71_loss0.8588964641094208.pypots
2024-05-22 22:13:06 [INFO]: Epoch 072 - training loss: 0.7647, validation loss: 0.8576
2024-05-22 22:13:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch72_loss0.8575538247823715.pypots
2024-05-22 22:13:06 [INFO]: Epoch 073 - training loss: 0.7679, validation loss: 0.8583
2024-05-22 22:13:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch73_loss0.8583290129899979.pypots
2024-05-22 22:13:06 [INFO]: Epoch 074 - training loss: 0.8157, validation loss: 0.8582
2024-05-22 22:13:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch74_loss0.8581802695989609.pypots
2024-05-22 22:13:06 [INFO]: Epoch 075 - training loss: 0.7784, validation loss: 0.8553
2024-05-22 22:13:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch75_loss0.855251207947731.pypots
2024-05-22 22:13:06 [INFO]: Epoch 076 - training loss: 0.8092, validation loss: 0.8560
2024-05-22 22:13:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch76_loss0.8560297191143036.pypots
2024-05-22 22:13:06 [INFO]: Epoch 077 - training loss: 0.7827, validation loss: 0.8564
2024-05-22 22:13:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch77_loss0.8563668131828308.pypots
2024-05-22 22:13:07 [INFO]: Epoch 078 - training loss: 0.7759, validation loss: 0.8548
2024-05-22 22:13:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch78_loss0.8547976016998291.pypots
2024-05-22 22:13:07 [INFO]: Epoch 079 - training loss: 0.7508, validation loss: 0.8533
2024-05-22 22:13:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch79_loss0.8532750159502029.pypots
2024-05-22 22:13:07 [INFO]: Epoch 080 - training loss: 0.7633, validation loss: 0.8537
2024-05-22 22:13:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch80_loss0.8537202179431915.pypots
2024-05-22 22:13:07 [INFO]: Epoch 081 - training loss: 0.7818, validation loss: 0.8557
2024-05-22 22:13:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch81_loss0.8556814938783646.pypots
2024-05-22 22:13:07 [INFO]: Epoch 082 - training loss: 0.7673, validation loss: 0.8552
2024-05-22 22:13:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch82_loss0.8551632910966873.pypots
2024-05-22 22:13:07 [INFO]: Epoch 083 - training loss: 0.7643, validation loss: 0.8537
2024-05-22 22:13:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch83_loss0.8536500036716461.pypots
2024-05-22 22:13:08 [INFO]: Epoch 084 - training loss: 0.7768, validation loss: 0.8554
2024-05-22 22:13:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch84_loss0.8554043918848038.pypots
2024-05-22 22:13:08 [INFO]: Epoch 085 - training loss: 0.7891, validation loss: 0.8538
2024-05-22 22:13:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch85_loss0.8538380563259125.pypots
2024-05-22 22:13:08 [INFO]: Epoch 086 - training loss: 0.8032, validation loss: 0.8521
2024-05-22 22:13:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch86_loss0.8521200120449066.pypots
2024-05-22 22:13:08 [INFO]: Epoch 087 - training loss: 0.7678, validation loss: 0.8524
2024-05-22 22:13:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch87_loss0.85240139067173.pypots
2024-05-22 22:13:08 [INFO]: Epoch 088 - training loss: 0.7634, validation loss: 0.8539
2024-05-22 22:13:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch88_loss0.8538795411586761.pypots
2024-05-22 22:13:08 [INFO]: Epoch 089 - training loss: 0.7803, validation loss: 0.8506
2024-05-22 22:13:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch89_loss0.850615605711937.pypots
2024-05-22 22:13:08 [INFO]: Epoch 090 - training loss: 0.7611, validation loss: 0.8499
2024-05-22 22:13:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch90_loss0.8499063849449158.pypots
2024-05-22 22:13:09 [INFO]: Epoch 091 - training loss: 0.7591, validation loss: 0.8508
2024-05-22 22:13:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch91_loss0.8507819175720215.pypots
2024-05-22 22:13:09 [INFO]: Epoch 092 - training loss: 0.7679, validation loss: 0.8547
2024-05-22 22:13:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch92_loss0.8546874076128006.pypots
2024-05-22 22:13:09 [INFO]: Epoch 093 - training loss: 0.7770, validation loss: 0.8507
2024-05-22 22:13:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch93_loss0.8506819605827332.pypots
2024-05-22 22:13:09 [INFO]: Epoch 094 - training loss: 0.7549, validation loss: 0.8526
2024-05-22 22:13:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch94_loss0.8525502234697342.pypots
2024-05-22 22:13:09 [INFO]: Epoch 095 - training loss: 0.7718, validation loss: 0.8489
2024-05-22 22:13:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch95_loss0.8488564193248749.pypots
2024-05-22 22:13:09 [INFO]: Epoch 096 - training loss: 0.7790, validation loss: 0.8487
2024-05-22 22:13:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch96_loss0.8486519604921341.pypots
2024-05-22 22:13:10 [INFO]: Epoch 097 - training loss: 0.7665, validation loss: 0.8501
2024-05-22 22:13:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch97_loss0.8501054048538208.pypots
2024-05-22 22:13:10 [INFO]: Epoch 098 - training loss: 0.7500, validation loss: 0.8496
2024-05-22 22:13:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch98_loss0.8496088683605194.pypots
2024-05-22 22:13:10 [INFO]: Epoch 099 - training loss: 0.7808, validation loss: 0.8509
2024-05-22 22:13:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch99_loss0.8508987277746201.pypots
2024-05-22 22:13:10 [INFO]: Epoch 100 - training loss: 0.7494, validation loss: 0.8467
2024-05-22 22:13:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch100_loss0.8466785550117493.pypots
2024-05-22 22:13:10 [INFO]: Epoch 101 - training loss: 0.7681, validation loss: 0.8467
2024-05-22 22:13:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch101_loss0.8467184454202652.pypots
2024-05-22 22:13:10 [INFO]: Epoch 102 - training loss: 0.7712, validation loss: 0.8475
2024-05-22 22:13:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch102_loss0.8475198596715927.pypots
2024-05-22 22:13:11 [INFO]: Epoch 103 - training loss: 0.7679, validation loss: 0.8471
2024-05-22 22:13:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch103_loss0.8471211642026901.pypots
2024-05-22 22:13:11 [INFO]: Epoch 104 - training loss: 0.7953, validation loss: 0.8497
2024-05-22 22:13:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch104_loss0.8497062474489212.pypots
2024-05-22 22:13:11 [INFO]: Epoch 105 - training loss: 0.7723, validation loss: 0.8481
2024-05-22 22:13:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch105_loss0.8481023609638214.pypots
2024-05-22 22:13:11 [INFO]: Epoch 106 - training loss: 0.7632, validation loss: 0.8497
2024-05-22 22:13:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch106_loss0.8497080951929092.pypots
2024-05-22 22:13:11 [INFO]: Epoch 107 - training loss: 0.7676, validation loss: 0.8473
2024-05-22 22:13:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch107_loss0.8472860008478165.pypots
2024-05-22 22:13:11 [INFO]: Epoch 108 - training loss: 0.7909, validation loss: 0.8486
2024-05-22 22:13:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch108_loss0.8485656082630157.pypots
2024-05-22 22:13:11 [INFO]: Epoch 109 - training loss: 0.7714, validation loss: 0.8503
2024-05-22 22:13:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch109_loss0.8503496497869492.pypots
2024-05-22 22:13:12 [INFO]: Epoch 110 - training loss: 0.7512, validation loss: 0.8463
2024-05-22 22:13:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch110_loss0.8463291376829147.pypots
2024-05-22 22:13:12 [INFO]: Epoch 111 - training loss: 0.7595, validation loss: 0.8467
2024-05-22 22:13:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch111_loss0.8467075824737549.pypots
2024-05-22 22:13:12 [INFO]: Epoch 112 - training loss: 0.7516, validation loss: 0.8456
2024-05-22 22:13:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch112_loss0.8456459641456604.pypots
2024-05-22 22:13:12 [INFO]: Epoch 113 - training loss: 0.7576, validation loss: 0.8462
2024-05-22 22:13:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch113_loss0.8461529463529587.pypots
2024-05-22 22:13:12 [INFO]: Epoch 114 - training loss: 0.8090, validation loss: 0.8483
2024-05-22 22:13:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch114_loss0.8482516705989838.pypots
2024-05-22 22:13:12 [INFO]: Epoch 115 - training loss: 0.7797, validation loss: 0.8446
2024-05-22 22:13:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch115_loss0.8446349799633026.pypots
2024-05-22 22:13:13 [INFO]: Epoch 116 - training loss: 0.7760, validation loss: 0.8500
2024-05-22 22:13:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch116_loss0.8499938249588013.pypots
2024-05-22 22:13:13 [INFO]: Epoch 117 - training loss: 0.7689, validation loss: 0.8460
2024-05-22 22:13:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch117_loss0.8460250645875931.pypots
2024-05-22 22:13:13 [INFO]: Epoch 118 - training loss: 0.7651, validation loss: 0.8477
2024-05-22 22:13:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch118_loss0.8476792722940445.pypots
2024-05-22 22:13:13 [INFO]: Epoch 119 - training loss: 0.7629, validation loss: 0.8416
2024-05-22 22:13:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch119_loss0.8415718674659729.pypots
2024-05-22 22:13:13 [INFO]: Epoch 120 - training loss: 0.7716, validation loss: 0.8412
2024-05-22 22:13:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch120_loss0.8411687165498734.pypots
2024-05-22 22:13:13 [INFO]: Epoch 121 - training loss: 0.7678, validation loss: 0.8477
2024-05-22 22:13:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch121_loss0.8477493077516556.pypots
2024-05-22 22:13:14 [INFO]: Epoch 122 - training loss: 0.7627, validation loss: 0.8445
2024-05-22 22:13:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch122_loss0.8444741666316986.pypots
2024-05-22 22:13:14 [INFO]: Epoch 123 - training loss: 0.7776, validation loss: 0.8436
2024-05-22 22:13:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch123_loss0.8436488956212997.pypots
2024-05-22 22:13:14 [INFO]: Epoch 124 - training loss: 0.7514, validation loss: 0.8460
2024-05-22 22:13:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch124_loss0.846020832657814.pypots
2024-05-22 22:13:14 [INFO]: Epoch 125 - training loss: 0.7411, validation loss: 0.8417
2024-05-22 22:13:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch125_loss0.8416542410850525.pypots
2024-05-22 22:13:14 [INFO]: Epoch 126 - training loss: 0.7823, validation loss: 0.8394
2024-05-22 22:13:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch126_loss0.8393611013889313.pypots
2024-05-22 22:13:14 [INFO]: Epoch 127 - training loss: 0.7728, validation loss: 0.8415
2024-05-22 22:13:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch127_loss0.8415361642837524.pypots
2024-05-22 22:13:14 [INFO]: Epoch 128 - training loss: 0.7649, validation loss: 0.8428
2024-05-22 22:13:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch128_loss0.8428361415863037.pypots
2024-05-22 22:13:15 [INFO]: Epoch 129 - training loss: 0.7622, validation loss: 0.8418
2024-05-22 22:13:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch129_loss0.8418263345956802.pypots
2024-05-22 22:13:15 [INFO]: Epoch 130 - training loss: 0.7921, validation loss: 0.8443
2024-05-22 22:13:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch130_loss0.8443346619606018.pypots
2024-05-22 22:13:15 [INFO]: Epoch 131 - training loss: 0.7850, validation loss: 0.8435
2024-05-22 22:13:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch131_loss0.843522384762764.pypots
2024-05-22 22:13:15 [INFO]: Epoch 132 - training loss: 0.7599, validation loss: 0.8445
2024-05-22 22:13:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch132_loss0.8444630652666092.pypots
2024-05-22 22:13:15 [INFO]: Epoch 133 - training loss: 0.7737, validation loss: 0.8432
2024-05-22 22:13:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch133_loss0.8432428240776062.pypots
2024-05-22 22:13:15 [INFO]: Epoch 134 - training loss: 0.7443, validation loss: 0.8409
2024-05-22 22:13:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch134_loss0.840926393866539.pypots
2024-05-22 22:13:16 [INFO]: Epoch 135 - training loss: 0.7528, validation loss: 0.8422
2024-05-22 22:13:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch135_loss0.8421760648488998.pypots
2024-05-22 22:13:16 [INFO]: Epoch 136 - training loss: 0.7717, validation loss: 0.8403
2024-05-22 22:13:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN_epoch136_loss0.8402722626924515.pypots
2024-05-22 22:13:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:13:16 [INFO]: Finished training. The best model is from epoch#126.
2024-05-22 22:13:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240522_T221253/MRNN.pypots
2024-05-22 22:13:16 [INFO]: MRNN on ETTm1: MAE=0.6428, MSE=1.0780
2024-05-22 22:13:16 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/MRNN_ettm1/imputation.pkl
2024-05-22 22:13:16 [INFO]: Using the given device: cpu
2024-05-22 22:13:16 [INFO]: LOCF on ETTm1: MAE=0.1376, MSE=0.0773
2024-05-22 22:13:16 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_ettm1".
2024-05-22 22:13:16 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/LOCF_ettm1/imputation.pkl
2024-05-22 22:13:16 [INFO]: Median on ETTm1: MAE=0.6554, MSE=0.8235
2024-05-22 22:13:16 [INFO]: Successfully created the given path "saved_results/round_2/Median_ettm1".
2024-05-22 22:13:16 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Median_ettm1/imputation.pkl
2024-05-22 22:13:16 [INFO]: Mean on ETTm1: MAE=0.6609, MSE=0.8067
2024-05-22 22:13:16 [INFO]: Successfully created the given path "saved_results/round_2/Mean_ettm1".
2024-05-22 22:13:16 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Mean_ettm1/imputation.pkl
2024-05-22 22:13:16 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-22 22:13:16 [INFO]: Using the given device: cuda:0
2024-05-22 22:13:16 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/SAITS_ettm1/20240522_T221316
2024-05-22 22:13:16 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/SAITS_ettm1/20240522_T221316/tensorboard
2024-05-22 22:13:16 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 22:13:17 [INFO]: Epoch 001 - training loss: 1.1676, validation loss: 0.2569
2024-05-22 22:13:17 [INFO]: Epoch 002 - training loss: 0.8250, validation loss: 0.1630
2024-05-22 22:13:18 [INFO]: Epoch 003 - training loss: 0.7372, validation loss: 0.1076
2024-05-22 22:13:18 [INFO]: Epoch 004 - training loss: 0.6763, validation loss: 0.0956
2024-05-22 22:13:18 [INFO]: Epoch 005 - training loss: 0.6517, validation loss: 0.0912
2024-05-22 22:13:19 [INFO]: Epoch 006 - training loss: 0.6190, validation loss: 0.0770
2024-05-22 22:13:19 [INFO]: Epoch 007 - training loss: 0.6035, validation loss: 0.0858
2024-05-22 22:13:20 [INFO]: Epoch 008 - training loss: 0.5933, validation loss: 0.0735
2024-05-22 22:13:20 [INFO]: Epoch 009 - training loss: 0.5884, validation loss: 0.0889
2024-05-22 22:13:21 [INFO]: Epoch 010 - training loss: 0.5779, validation loss: 0.0553
2024-05-22 22:13:21 [INFO]: Epoch 011 - training loss: 0.5691, validation loss: 0.0622
2024-05-22 22:13:22 [INFO]: Epoch 012 - training loss: 0.5592, validation loss: 0.0493
2024-05-22 22:13:22 [INFO]: Epoch 013 - training loss: 0.5420, validation loss: 0.0502
2024-05-22 22:13:23 [INFO]: Epoch 014 - training loss: 0.5476, validation loss: 0.0655
2024-05-22 22:13:23 [INFO]: Epoch 015 - training loss: 0.5369, validation loss: 0.0491
2024-05-22 22:13:24 [INFO]: Epoch 016 - training loss: 0.5427, validation loss: 0.0485
2024-05-22 22:13:24 [INFO]: Epoch 017 - training loss: 0.5188, validation loss: 0.0434
2024-05-22 22:13:25 [INFO]: Epoch 018 - training loss: 0.5233, validation loss: 0.0454
2024-05-22 22:13:25 [INFO]: Epoch 019 - training loss: 0.5231, validation loss: 0.0436
2024-05-22 22:13:26 [INFO]: Epoch 020 - training loss: 0.5156, validation loss: 0.0524
2024-05-22 22:13:26 [INFO]: Epoch 021 - training loss: 0.4995, validation loss: 0.0488
2024-05-22 22:13:27 [INFO]: Epoch 022 - training loss: 0.4944, validation loss: 0.0427
2024-05-22 22:13:27 [INFO]: Epoch 023 - training loss: 0.4843, validation loss: 0.0440
2024-05-22 22:13:28 [INFO]: Epoch 024 - training loss: 0.4880, validation loss: 0.0503
2024-05-22 22:13:28 [INFO]: Epoch 025 - training loss: 0.4964, validation loss: 0.0520
2024-05-22 22:13:29 [INFO]: Epoch 026 - training loss: 0.4827, validation loss: 0.0417
2024-05-22 22:13:29 [INFO]: Epoch 027 - training loss: 0.4858, validation loss: 0.0431
2024-05-22 22:13:30 [INFO]: Epoch 028 - training loss: 0.4808, validation loss: 0.0620
2024-05-22 22:13:30 [INFO]: Epoch 029 - training loss: 0.4744, validation loss: 0.0401
2024-05-22 22:13:30 [INFO]: Epoch 030 - training loss: 0.4684, validation loss: 0.0430
2024-05-22 22:13:31 [INFO]: Epoch 031 - training loss: 0.4728, validation loss: 0.0479
2024-05-22 22:13:31 [INFO]: Epoch 032 - training loss: 0.4635, validation loss: 0.0438
2024-05-22 22:13:32 [INFO]: Epoch 033 - training loss: 0.4610, validation loss: 0.0434
2024-05-22 22:13:32 [INFO]: Epoch 034 - training loss: 0.4665, validation loss: 0.0413
2024-05-22 22:13:33 [INFO]: Epoch 035 - training loss: 0.4644, validation loss: 0.0446
2024-05-22 22:13:33 [INFO]: Epoch 036 - training loss: 0.4620, validation loss: 0.0459
2024-05-22 22:13:34 [INFO]: Epoch 037 - training loss: 0.4647, validation loss: 0.0381
2024-05-22 22:13:34 [INFO]: Epoch 038 - training loss: 0.4435, validation loss: 0.0425
2024-05-22 22:13:35 [INFO]: Epoch 039 - training loss: 0.4298, validation loss: 0.0390
2024-05-22 22:13:35 [INFO]: Epoch 040 - training loss: 0.4436, validation loss: 0.0343
2024-05-22 22:13:36 [INFO]: Epoch 041 - training loss: 0.4460, validation loss: 0.0354
2024-05-22 22:13:36 [INFO]: Epoch 042 - training loss: 0.4370, validation loss: 0.0344
2024-05-22 22:13:37 [INFO]: Epoch 043 - training loss: 0.4334, validation loss: 0.0502
2024-05-22 22:13:37 [INFO]: Epoch 044 - training loss: 0.4388, validation loss: 0.0430
2024-05-22 22:13:38 [INFO]: Epoch 045 - training loss: 0.4365, validation loss: 0.0340
2024-05-22 22:13:38 [INFO]: Epoch 046 - training loss: 0.4324, validation loss: 0.0427
2024-05-22 22:13:39 [INFO]: Epoch 047 - training loss: 0.4215, validation loss: 0.0396
2024-05-22 22:13:39 [INFO]: Epoch 048 - training loss: 0.4472, validation loss: 0.0427
2024-05-22 22:13:40 [INFO]: Epoch 049 - training loss: 0.4314, validation loss: 0.0352
2024-05-22 22:13:40 [INFO]: Epoch 050 - training loss: 0.4247, validation loss: 0.0359
2024-05-22 22:13:41 [INFO]: Epoch 051 - training loss: 0.4168, validation loss: 0.0365
2024-05-22 22:13:41 [INFO]: Epoch 052 - training loss: 0.4049, validation loss: 0.0445
2024-05-22 22:13:41 [INFO]: Epoch 053 - training loss: 0.4179, validation loss: 0.0349
2024-05-22 22:13:42 [INFO]: Epoch 054 - training loss: 0.4038, validation loss: 0.0351
2024-05-22 22:13:42 [INFO]: Epoch 055 - training loss: 0.4042, validation loss: 0.0309
2024-05-22 22:13:43 [INFO]: Epoch 056 - training loss: 0.4030, validation loss: 0.0380
2024-05-22 22:13:43 [INFO]: Epoch 057 - training loss: 0.4053, validation loss: 0.0427
2024-05-22 22:13:44 [INFO]: Epoch 058 - training loss: 0.3865, validation loss: 0.0426
2024-05-22 22:13:44 [INFO]: Epoch 059 - training loss: 0.3824, validation loss: 0.0331
2024-05-22 22:13:45 [INFO]: Epoch 060 - training loss: 0.3672, validation loss: 0.0329
2024-05-22 22:13:45 [INFO]: Epoch 061 - training loss: 0.3592, validation loss: 0.0369
2024-05-22 22:13:46 [INFO]: Epoch 062 - training loss: 0.3557, validation loss: 0.0323
2024-05-22 22:13:46 [INFO]: Epoch 063 - training loss: 0.3530, validation loss: 0.0354
2024-05-22 22:13:47 [INFO]: Epoch 064 - training loss: 0.3472, validation loss: 0.0321
2024-05-22 22:13:47 [INFO]: Epoch 065 - training loss: 0.3308, validation loss: 0.0359
2024-05-22 22:13:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:13:47 [INFO]: Finished training. The best model is from epoch#55.
2024-05-22 22:13:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/SAITS_ettm1/20240522_T221316/SAITS.pypots
2024-05-22 22:13:47 [INFO]: SAITS on ETTm1: MAE=0.1480, MSE=0.0451
2024-05-22 22:13:47 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/SAITS_ettm1/imputation.pkl
2024-05-22 22:13:47 [INFO]: Using the given device: cuda:0
2024-05-22 22:13:47 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/Transformer_ettm1/20240522_T221347
2024-05-22 22:13:47 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/Transformer_ettm1/20240522_T221347/tensorboard
2024-05-22 22:13:47 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 22:13:48 [INFO]: Epoch 001 - training loss: 1.1318, validation loss: 0.3161
2024-05-22 22:13:48 [INFO]: Epoch 002 - training loss: 0.6732, validation loss: 0.1550
2024-05-22 22:13:48 [INFO]: Epoch 003 - training loss: 0.5462, validation loss: 0.1208
2024-05-22 22:13:48 [INFO]: Epoch 004 - training loss: 0.4932, validation loss: 0.0981
2024-05-22 22:13:48 [INFO]: Epoch 005 - training loss: 0.4680, validation loss: 0.0857
2024-05-22 22:13:48 [INFO]: Epoch 006 - training loss: 0.4363, validation loss: 0.0764
2024-05-22 22:13:49 [INFO]: Epoch 007 - training loss: 0.4230, validation loss: 0.0708
2024-05-22 22:13:49 [INFO]: Epoch 008 - training loss: 0.4129, validation loss: 0.0674
2024-05-22 22:13:49 [INFO]: Epoch 009 - training loss: 0.3962, validation loss: 0.0693
2024-05-22 22:13:49 [INFO]: Epoch 010 - training loss: 0.3835, validation loss: 0.0599
2024-05-22 22:13:49 [INFO]: Epoch 011 - training loss: 0.3748, validation loss: 0.0561
2024-05-22 22:13:50 [INFO]: Epoch 012 - training loss: 0.3563, validation loss: 0.0523
2024-05-22 22:13:50 [INFO]: Epoch 013 - training loss: 0.3473, validation loss: 0.0559
2024-05-22 22:13:50 [INFO]: Epoch 014 - training loss: 0.3420, validation loss: 0.0511
2024-05-22 22:13:50 [INFO]: Epoch 015 - training loss: 0.3308, validation loss: 0.0514
2024-05-22 22:13:50 [INFO]: Epoch 016 - training loss: 0.3322, validation loss: 0.0481
2024-05-22 22:13:51 [INFO]: Epoch 017 - training loss: 0.3249, validation loss: 0.0519
2024-05-22 22:13:51 [INFO]: Epoch 018 - training loss: 0.3204, validation loss: 0.0452
2024-05-22 22:13:51 [INFO]: Epoch 019 - training loss: 0.3152, validation loss: 0.0462
2024-05-22 22:13:51 [INFO]: Epoch 020 - training loss: 0.3099, validation loss: 0.0439
2024-05-22 22:13:51 [INFO]: Epoch 021 - training loss: 0.3039, validation loss: 0.0406
2024-05-22 22:13:52 [INFO]: Epoch 022 - training loss: 0.3012, validation loss: 0.0424
2024-05-22 22:13:52 [INFO]: Epoch 023 - training loss: 0.2907, validation loss: 0.0462
2024-05-22 22:13:52 [INFO]: Epoch 024 - training loss: 0.2935, validation loss: 0.0408
2024-05-22 22:13:52 [INFO]: Epoch 025 - training loss: 0.2877, validation loss: 0.0398
2024-05-22 22:13:52 [INFO]: Epoch 026 - training loss: 0.2790, validation loss: 0.0376
2024-05-22 22:13:52 [INFO]: Epoch 027 - training loss: 0.2730, validation loss: 0.0392
2024-05-22 22:13:53 [INFO]: Epoch 028 - training loss: 0.2789, validation loss: 0.0372
2024-05-22 22:13:53 [INFO]: Epoch 029 - training loss: 0.2731, validation loss: 0.0409
2024-05-22 22:13:53 [INFO]: Epoch 030 - training loss: 0.2756, validation loss: 0.0412
2024-05-22 22:13:53 [INFO]: Epoch 031 - training loss: 0.2709, validation loss: 0.0371
2024-05-22 22:13:53 [INFO]: Epoch 032 - training loss: 0.2640, validation loss: 0.0367
2024-05-22 22:13:54 [INFO]: Epoch 033 - training loss: 0.2593, validation loss: 0.0359
2024-05-22 22:13:54 [INFO]: Epoch 034 - training loss: 0.2614, validation loss: 0.0352
2024-05-22 22:13:54 [INFO]: Epoch 035 - training loss: 0.2551, validation loss: 0.0335
2024-05-22 22:13:54 [INFO]: Epoch 036 - training loss: 0.2527, validation loss: 0.0370
2024-05-22 22:13:54 [INFO]: Epoch 037 - training loss: 0.2528, validation loss: 0.0350
2024-05-22 22:13:55 [INFO]: Epoch 038 - training loss: 0.2431, validation loss: 0.0326
2024-05-22 22:13:55 [INFO]: Epoch 039 - training loss: 0.2444, validation loss: 0.0347
2024-05-22 22:13:55 [INFO]: Epoch 040 - training loss: 0.2439, validation loss: 0.0340
2024-05-22 22:13:55 [INFO]: Epoch 041 - training loss: 0.2397, validation loss: 0.0314
2024-05-22 22:13:55 [INFO]: Epoch 042 - training loss: 0.2368, validation loss: 0.0331
2024-05-22 22:13:56 [INFO]: Epoch 043 - training loss: 0.2406, validation loss: 0.0341
2024-05-22 22:13:56 [INFO]: Epoch 044 - training loss: 0.2389, validation loss: 0.0343
2024-05-22 22:13:56 [INFO]: Epoch 045 - training loss: 0.2333, validation loss: 0.0312
2024-05-22 22:13:56 [INFO]: Epoch 046 - training loss: 0.2254, validation loss: 0.0306
2024-05-22 22:13:56 [INFO]: Epoch 047 - training loss: 0.2294, validation loss: 0.0301
2024-05-22 22:13:56 [INFO]: Epoch 048 - training loss: 0.2268, validation loss: 0.0303
2024-05-22 22:13:57 [INFO]: Epoch 049 - training loss: 0.2208, validation loss: 0.0333
2024-05-22 22:13:57 [INFO]: Epoch 050 - training loss: 0.2255, validation loss: 0.0313
2024-05-22 22:13:57 [INFO]: Epoch 051 - training loss: 0.2191, validation loss: 0.0307
2024-05-22 22:13:57 [INFO]: Epoch 052 - training loss: 0.2184, validation loss: 0.0330
2024-05-22 22:13:57 [INFO]: Epoch 053 - training loss: 0.2332, validation loss: 0.0287
2024-05-22 22:13:58 [INFO]: Epoch 054 - training loss: 0.2232, validation loss: 0.0301
2024-05-22 22:13:58 [INFO]: Epoch 055 - training loss: 0.2248, validation loss: 0.0280
2024-05-22 22:13:58 [INFO]: Epoch 056 - training loss: 0.2173, validation loss: 0.0310
2024-05-22 22:13:58 [INFO]: Epoch 057 - training loss: 0.2194, validation loss: 0.0277
2024-05-22 22:13:58 [INFO]: Epoch 058 - training loss: 0.2128, validation loss: 0.0266
2024-05-22 22:13:59 [INFO]: Epoch 059 - training loss: 0.2097, validation loss: 0.0270
2024-05-22 22:13:59 [INFO]: Epoch 060 - training loss: 0.2112, validation loss: 0.0292
2024-05-22 22:13:59 [INFO]: Epoch 061 - training loss: 0.2130, validation loss: 0.0284
2024-05-22 22:13:59 [INFO]: Epoch 062 - training loss: 0.2101, validation loss: 0.0281
2024-05-22 22:13:59 [INFO]: Epoch 063 - training loss: 0.2090, validation loss: 0.0289
2024-05-22 22:13:59 [INFO]: Epoch 064 - training loss: 0.2101, validation loss: 0.0294
2024-05-22 22:14:00 [INFO]: Epoch 065 - training loss: 0.2036, validation loss: 0.0311
2024-05-22 22:14:00 [INFO]: Epoch 066 - training loss: 0.2061, validation loss: 0.0299
2024-05-22 22:14:00 [INFO]: Epoch 067 - training loss: 0.2019, validation loss: 0.0260
2024-05-22 22:14:00 [INFO]: Epoch 068 - training loss: 0.2005, validation loss: 0.0290
2024-05-22 22:14:00 [INFO]: Epoch 069 - training loss: 0.2083, validation loss: 0.0284
2024-05-22 22:14:01 [INFO]: Epoch 070 - training loss: 0.2020, validation loss: 0.0287
2024-05-22 22:14:01 [INFO]: Epoch 071 - training loss: 0.2024, validation loss: 0.0258
2024-05-22 22:14:01 [INFO]: Epoch 072 - training loss: 0.1974, validation loss: 0.0267
2024-05-22 22:14:01 [INFO]: Epoch 073 - training loss: 0.2003, validation loss: 0.0300
2024-05-22 22:14:01 [INFO]: Epoch 074 - training loss: 0.2001, validation loss: 0.0264
2024-05-22 22:14:02 [INFO]: Epoch 075 - training loss: 0.1986, validation loss: 0.0252
2024-05-22 22:14:02 [INFO]: Epoch 076 - training loss: 0.1891, validation loss: 0.0294
2024-05-22 22:14:02 [INFO]: Epoch 077 - training loss: 0.1976, validation loss: 0.0260
2024-05-22 22:14:02 [INFO]: Epoch 078 - training loss: 0.1941, validation loss: 0.0282
2024-05-22 22:14:02 [INFO]: Epoch 079 - training loss: 0.1932, validation loss: 0.0264
2024-05-22 22:14:03 [INFO]: Epoch 080 - training loss: 0.1923, validation loss: 0.0252
2024-05-22 22:14:03 [INFO]: Epoch 081 - training loss: 0.1928, validation loss: 0.0257
2024-05-22 22:14:03 [INFO]: Epoch 082 - training loss: 0.1887, validation loss: 0.0311
2024-05-22 22:14:03 [INFO]: Epoch 083 - training loss: 0.2042, validation loss: 0.0284
2024-05-22 22:14:03 [INFO]: Epoch 084 - training loss: 0.1935, validation loss: 0.0262
2024-05-22 22:14:03 [INFO]: Epoch 085 - training loss: 0.1872, validation loss: 0.0257
2024-05-22 22:14:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:14:03 [INFO]: Finished training. The best model is from epoch#75.
2024-05-22 22:14:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/Transformer_ettm1/20240522_T221347/Transformer.pypots
2024-05-22 22:14:03 [INFO]: Transformer on ETTm1: MAE=0.1310, MSE=0.0372
2024-05-22 22:14:03 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Transformer_ettm1/imputation.pkl
2024-05-22 22:14:03 [INFO]: Using the given device: cuda:0
2024-05-22 22:14:03 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/TimesNet_ettm1/20240522_T221403
2024-05-22 22:14:03 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/TimesNet_ettm1/20240522_T221403/tensorboard
2024-05-22 22:14:04 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 22:14:04 [INFO]: Epoch 001 - training loss: 0.1445, validation loss: 0.0553
2024-05-22 22:14:04 [INFO]: Epoch 002 - training loss: 0.0639, validation loss: 0.0385
2024-05-22 22:14:04 [INFO]: Epoch 003 - training loss: 0.0504, validation loss: 0.0325
2024-05-22 22:14:04 [INFO]: Epoch 004 - training loss: 0.0404, validation loss: 0.0299
2024-05-22 22:14:05 [INFO]: Epoch 005 - training loss: 0.0368, validation loss: 0.0286
2024-05-22 22:14:05 [INFO]: Epoch 006 - training loss: 0.0334, validation loss: 0.0279
2024-05-22 22:14:05 [INFO]: Epoch 007 - training loss: 0.0346, validation loss: 0.0288
2024-05-22 22:14:05 [INFO]: Epoch 008 - training loss: 0.0340, validation loss: 0.0279
2024-05-22 22:14:05 [INFO]: Epoch 009 - training loss: 0.0326, validation loss: 0.0271
2024-05-22 22:14:05 [INFO]: Epoch 010 - training loss: 0.0314, validation loss: 0.0263
2024-05-22 22:14:06 [INFO]: Epoch 011 - training loss: 0.0323, validation loss: 0.0270
2024-05-22 22:14:06 [INFO]: Epoch 012 - training loss: 0.0316, validation loss: 0.0277
2024-05-22 22:14:06 [INFO]: Epoch 013 - training loss: 0.0311, validation loss: 0.0270
2024-05-22 22:14:06 [INFO]: Epoch 014 - training loss: 0.0309, validation loss: 0.0259
2024-05-22 22:14:06 [INFO]: Epoch 015 - training loss: 0.0298, validation loss: 0.0261
2024-05-22 22:14:07 [INFO]: Epoch 016 - training loss: 0.0287, validation loss: 0.0279
2024-05-22 22:14:07 [INFO]: Epoch 017 - training loss: 0.0304, validation loss: 0.0272
2024-05-22 22:14:07 [INFO]: Epoch 018 - training loss: 0.0302, validation loss: 0.0263
2024-05-22 22:14:07 [INFO]: Epoch 019 - training loss: 0.0286, validation loss: 0.0257
2024-05-22 22:14:07 [INFO]: Epoch 020 - training loss: 0.0259, validation loss: 0.0249
2024-05-22 22:14:07 [INFO]: Epoch 021 - training loss: 0.0261, validation loss: 0.0249
2024-05-22 22:14:08 [INFO]: Epoch 022 - training loss: 0.0243, validation loss: 0.0260
2024-05-22 22:14:08 [INFO]: Epoch 023 - training loss: 0.0259, validation loss: 0.0255
2024-05-22 22:14:08 [INFO]: Epoch 024 - training loss: 0.0250, validation loss: 0.0249
2024-05-22 22:14:08 [INFO]: Epoch 025 - training loss: 0.0245, validation loss: 0.0252
2024-05-22 22:14:08 [INFO]: Epoch 026 - training loss: 0.0243, validation loss: 0.0261
2024-05-22 22:14:08 [INFO]: Epoch 027 - training loss: 0.0247, validation loss: 0.0265
2024-05-22 22:14:09 [INFO]: Epoch 028 - training loss: 0.0255, validation loss: 0.0270
2024-05-22 22:14:09 [INFO]: Epoch 029 - training loss: 0.0312, validation loss: 0.0267
2024-05-22 22:14:09 [INFO]: Epoch 030 - training loss: 0.0268, validation loss: 0.0256
2024-05-22 22:14:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:14:09 [INFO]: Finished training. The best model is from epoch#20.
2024-05-22 22:14:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/TimesNet_ettm1/20240522_T221403/TimesNet.pypots
2024-05-22 22:14:10 [INFO]: TimesNet on ETTm1: MAE=0.1100, MSE=0.0259
2024-05-22 22:14:10 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/TimesNet_ettm1/imputation.pkl
2024-05-22 22:14:10 [INFO]: Using the given device: cuda:0
2024-05-22 22:14:10 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410
2024-05-22 22:14:10 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/tensorboard
2024-05-22 22:14:10 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 22:14:12 [INFO]: Epoch 001 - training loss: 0.7568, validation loss: 0.4898
2024-05-22 22:14:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch1_loss0.48977017402648926.pypots
2024-05-22 22:14:14 [INFO]: Epoch 002 - training loss: 0.4345, validation loss: 0.3795
2024-05-22 22:14:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch2_loss0.37951990962028503.pypots
2024-05-22 22:14:16 [INFO]: Epoch 003 - training loss: 0.3505, validation loss: 0.3533
2024-05-22 22:14:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch3_loss0.35332848131656647.pypots
2024-05-22 22:14:18 [INFO]: Epoch 004 - training loss: 0.3635, validation loss: 0.3009
2024-05-22 22:14:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch4_loss0.3008687272667885.pypots
2024-05-22 22:14:20 [INFO]: Epoch 005 - training loss: 0.3024, validation loss: 0.2856
2024-05-22 22:14:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch5_loss0.28556251525878906.pypots
2024-05-22 22:14:22 [INFO]: Epoch 006 - training loss: 0.3054, validation loss: 0.2687
2024-05-22 22:14:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch6_loss0.2686518356204033.pypots
2024-05-22 22:14:24 [INFO]: Epoch 007 - training loss: 0.2680, validation loss: 0.2575
2024-05-22 22:14:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch7_loss0.2574833184480667.pypots
2024-05-22 22:14:26 [INFO]: Epoch 008 - training loss: 0.2905, validation loss: 0.2597
2024-05-22 22:14:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch8_loss0.2597261965274811.pypots
2024-05-22 22:14:28 [INFO]: Epoch 009 - training loss: 0.2614, validation loss: 0.2548
2024-05-22 22:14:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch9_loss0.25481440126895905.pypots
2024-05-22 22:14:30 [INFO]: Epoch 010 - training loss: 0.2885, validation loss: 0.2350
2024-05-22 22:14:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch10_loss0.23495641723275185.pypots
2024-05-22 22:14:32 [INFO]: Epoch 011 - training loss: 0.2501, validation loss: 0.2271
2024-05-22 22:14:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch11_loss0.22706032171845436.pypots
2024-05-22 22:14:34 [INFO]: Epoch 012 - training loss: 0.2669, validation loss: 0.2258
2024-05-22 22:14:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch12_loss0.22584490850567818.pypots
2024-05-22 22:14:36 [INFO]: Epoch 013 - training loss: 0.2111, validation loss: 0.2136
2024-05-22 22:14:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch13_loss0.21361969783902168.pypots
2024-05-22 22:14:38 [INFO]: Epoch 014 - training loss: 0.2100, validation loss: 0.2072
2024-05-22 22:14:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch14_loss0.20718751475214958.pypots
2024-05-22 22:14:40 [INFO]: Epoch 015 - training loss: 0.2611, validation loss: 0.2023
2024-05-22 22:14:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch15_loss0.20230915024876595.pypots
2024-05-22 22:14:42 [INFO]: Epoch 016 - training loss: 0.2064, validation loss: 0.1904
2024-05-22 22:14:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch16_loss0.1904001720249653.pypots
2024-05-22 22:14:44 [INFO]: Epoch 017 - training loss: 0.1896, validation loss: 0.1860
2024-05-22 22:14:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch17_loss0.18598995730280876.pypots
2024-05-22 22:14:46 [INFO]: Epoch 018 - training loss: 0.1886, validation loss: 0.1890
2024-05-22 22:14:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch18_loss0.18904947489500046.pypots
2024-05-22 22:14:48 [INFO]: Epoch 019 - training loss: 0.2010, validation loss: 0.1773
2024-05-22 22:14:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch19_loss0.1772887520492077.pypots
2024-05-22 22:14:50 [INFO]: Epoch 020 - training loss: 0.2387, validation loss: 0.2667
2024-05-22 22:14:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch20_loss0.2666728049516678.pypots
2024-05-22 22:14:52 [INFO]: Epoch 021 - training loss: 0.2433, validation loss: 0.2143
2024-05-22 22:14:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch21_loss0.2143346481025219.pypots
2024-05-22 22:14:54 [INFO]: Epoch 022 - training loss: 0.2086, validation loss: 0.1918
2024-05-22 22:14:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch22_loss0.19176724553108215.pypots
2024-05-22 22:14:56 [INFO]: Epoch 023 - training loss: 0.1746, validation loss: 0.1849
2024-05-22 22:14:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch23_loss0.18485232070088387.pypots
2024-05-22 22:14:58 [INFO]: Epoch 024 - training loss: 0.1836, validation loss: 0.1766
2024-05-22 22:14:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch24_loss0.17663363739848137.pypots
2024-05-22 22:15:00 [INFO]: Epoch 025 - training loss: 0.2144, validation loss: 0.1891
2024-05-22 22:15:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch25_loss0.18905257806181908.pypots
2024-05-22 22:15:02 [INFO]: Epoch 026 - training loss: 0.2352, validation loss: 0.1943
2024-05-22 22:15:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch26_loss0.19430439174175262.pypots
2024-05-22 22:15:04 [INFO]: Epoch 027 - training loss: 0.2956, validation loss: 0.1875
2024-05-22 22:15:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch27_loss0.1875276118516922.pypots
2024-05-22 22:15:06 [INFO]: Epoch 028 - training loss: 0.2019, validation loss: 0.1731
2024-05-22 22:15:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch28_loss0.1731497086584568.pypots
2024-05-22 22:15:08 [INFO]: Epoch 029 - training loss: 0.1799, validation loss: 0.1700
2024-05-22 22:15:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch29_loss0.17002923041582108.pypots
2024-05-22 22:15:10 [INFO]: Epoch 030 - training loss: 0.1560, validation loss: 0.1613
2024-05-22 22:15:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch30_loss0.16125072166323662.pypots
2024-05-22 22:15:12 [INFO]: Epoch 031 - training loss: 0.1437, validation loss: 0.1630
2024-05-22 22:15:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch31_loss0.1630188338458538.pypots
2024-05-22 22:15:14 [INFO]: Epoch 032 - training loss: 0.1764, validation loss: 0.1662
2024-05-22 22:15:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch32_loss0.16623353958129883.pypots
2024-05-22 22:15:16 [INFO]: Epoch 033 - training loss: 0.1768, validation loss: 0.1590
2024-05-22 22:15:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch33_loss0.15902569517493248.pypots
2024-05-22 22:15:18 [INFO]: Epoch 034 - training loss: 0.1550, validation loss: 0.1542
2024-05-22 22:15:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch34_loss0.15417468175292015.pypots
2024-05-22 22:15:20 [INFO]: Epoch 035 - training loss: 0.1426, validation loss: 0.1558
2024-05-22 22:15:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch35_loss0.1558064930140972.pypots
2024-05-22 22:15:22 [INFO]: Epoch 036 - training loss: 0.1785, validation loss: 0.1567
2024-05-22 22:15:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch36_loss0.15670586749911308.pypots
2024-05-22 22:15:24 [INFO]: Epoch 037 - training loss: 0.2391, validation loss: 0.1674
2024-05-22 22:15:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch37_loss0.16737153753638268.pypots
2024-05-22 22:15:26 [INFO]: Epoch 038 - training loss: 0.1563, validation loss: 0.1535
2024-05-22 22:15:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch38_loss0.15353818982839584.pypots
2024-05-22 22:15:28 [INFO]: Epoch 039 - training loss: 0.1504, validation loss: 0.1508
2024-05-22 22:15:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch39_loss0.1508191041648388.pypots
2024-05-22 22:15:31 [INFO]: Epoch 040 - training loss: 0.2045, validation loss: 0.1603
2024-05-22 22:15:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch40_loss0.16031311079859734.pypots
2024-05-22 22:15:33 [INFO]: Epoch 041 - training loss: 0.1726, validation loss: 0.1569
2024-05-22 22:15:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch41_loss0.15685829520225525.pypots
2024-05-22 22:15:35 [INFO]: Epoch 042 - training loss: 0.1589, validation loss: 0.1568
2024-05-22 22:15:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch42_loss0.15679902583360672.pypots
2024-05-22 22:15:37 [INFO]: Epoch 043 - training loss: 0.1739, validation loss: 0.1478
2024-05-22 22:15:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch43_loss0.14784710854291916.pypots
2024-05-22 22:15:39 [INFO]: Epoch 044 - training loss: 0.1632, validation loss: 0.1535
2024-05-22 22:15:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch44_loss0.1535373330116272.pypots
2024-05-22 22:15:41 [INFO]: Epoch 045 - training loss: 0.1501, validation loss: 0.1469
2024-05-22 22:15:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch45_loss0.14694083482027054.pypots
2024-05-22 22:15:43 [INFO]: Epoch 046 - training loss: 0.1394, validation loss: 0.1432
2024-05-22 22:15:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch46_loss0.14318889379501343.pypots
2024-05-22 22:15:45 [INFO]: Epoch 047 - training loss: 0.1342, validation loss: 0.1396
2024-05-22 22:15:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch47_loss0.13955142349004745.pypots
2024-05-22 22:15:47 [INFO]: Epoch 048 - training loss: 0.1506, validation loss: 0.1374
2024-05-22 22:15:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch48_loss0.1373816840350628.pypots
2024-05-22 22:15:49 [INFO]: Epoch 049 - training loss: 0.1367, validation loss: 0.1413
2024-05-22 22:15:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch49_loss0.1412903554737568.pypots
2024-05-22 22:15:51 [INFO]: Epoch 050 - training loss: 0.1950, validation loss: 0.1487
2024-05-22 22:15:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch50_loss0.14874964952468872.pypots
2024-05-22 22:15:53 [INFO]: Epoch 051 - training loss: 0.1510, validation loss: 0.1529
2024-05-22 22:15:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch51_loss0.1528630368411541.pypots
2024-05-22 22:15:55 [INFO]: Epoch 052 - training loss: 0.1453, validation loss: 0.1406
2024-05-22 22:15:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch52_loss0.1405532993376255.pypots
2024-05-22 22:15:57 [INFO]: Epoch 053 - training loss: 0.1388, validation loss: 0.1366
2024-05-22 22:15:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch53_loss0.13658221811056137.pypots
2024-05-22 22:15:59 [INFO]: Epoch 054 - training loss: 0.1618, validation loss: 0.1464
2024-05-22 22:15:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch54_loss0.14635873213410378.pypots
2024-05-22 22:16:01 [INFO]: Epoch 055 - training loss: 0.1662, validation loss: 0.1587
2024-05-22 22:16:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch55_loss0.15874524414539337.pypots
2024-05-22 22:16:03 [INFO]: Epoch 056 - training loss: 0.1438, validation loss: 0.1435
2024-05-22 22:16:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch56_loss0.14352574571967125.pypots
2024-05-22 22:16:05 [INFO]: Epoch 057 - training loss: 0.1518, validation loss: 0.1453
2024-05-22 22:16:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch57_loss0.14531739056110382.pypots
2024-05-22 22:16:07 [INFO]: Epoch 058 - training loss: 0.1911, validation loss: 0.1520
2024-05-22 22:16:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch58_loss0.15204310789704323.pypots
2024-05-22 22:16:09 [INFO]: Epoch 059 - training loss: 0.1692, validation loss: 0.1569
2024-05-22 22:16:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch59_loss0.15692365169525146.pypots
2024-05-22 22:16:11 [INFO]: Epoch 060 - training loss: 0.1806, validation loss: 0.1596
2024-05-22 22:16:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch60_loss0.15956136211752892.pypots
2024-05-22 22:16:13 [INFO]: Epoch 061 - training loss: 0.1668, validation loss: 0.1539
2024-05-22 22:16:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch61_loss0.15389910340309143.pypots
2024-05-22 22:16:15 [INFO]: Epoch 062 - training loss: 0.1426, validation loss: 0.1436
2024-05-22 22:16:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch62_loss0.14361578598618507.pypots
2024-05-22 22:16:17 [INFO]: Epoch 063 - training loss: 0.1850, validation loss: 0.1376
2024-05-22 22:16:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI_epoch63_loss0.13762078434228897.pypots
2024-05-22 22:16:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:16:17 [INFO]: Finished training. The best model is from epoch#53.
2024-05-22 22:16:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240522_T221410/CSDI.pypots
2024-05-22 22:16:32 [INFO]: CSDI on ETTm1: MAE=0.1475, MSE=0.0516
2024-05-22 22:16:32 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/CSDI_ettm1/imputation.pkl
2024-05-22 22:16:32 [INFO]: Using the given device: cuda:0
2024-05-22 22:16:32 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/GPVAE_ettm1/20240522_T221632
2024-05-22 22:16:32 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/GPVAE_ettm1/20240522_T221632/tensorboard
2024-05-22 22:16:32 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 22:16:33 [INFO]: Epoch 001 - training loss: 22993.0681, validation loss: 0.9636
2024-05-22 22:16:33 [INFO]: Epoch 002 - training loss: 20910.7850, validation loss: 0.9557
2024-05-22 22:16:33 [INFO]: Epoch 003 - training loss: 18826.5654, validation loss: 0.9422
2024-05-22 22:16:33 [INFO]: Epoch 004 - training loss: 16700.4862, validation loss: 0.9145
2024-05-22 22:16:33 [INFO]: Epoch 005 - training loss: 14870.2386, validation loss: 0.8469
2024-05-22 22:16:33 [INFO]: Epoch 006 - training loss: 13568.1938, validation loss: 0.7380
2024-05-22 22:16:33 [INFO]: Epoch 007 - training loss: 12568.6428, validation loss: 0.6124
2024-05-22 22:16:33 [INFO]: Epoch 008 - training loss: 11704.4175, validation loss: 0.5375
2024-05-22 22:16:33 [INFO]: Epoch 009 - training loss: 11162.4010, validation loss: 0.4894
2024-05-22 22:16:34 [INFO]: Epoch 010 - training loss: 10995.6459, validation loss: 0.4712
2024-05-22 22:16:34 [INFO]: Epoch 011 - training loss: 10571.4316, validation loss: 0.4624
2024-05-22 22:16:34 [INFO]: Epoch 012 - training loss: 10359.0304, validation loss: 0.4589
2024-05-22 22:16:34 [INFO]: Epoch 013 - training loss: 10234.3306, validation loss: 0.4445
2024-05-22 22:16:34 [INFO]: Epoch 014 - training loss: 10117.4598, validation loss: 0.4264
2024-05-22 22:16:34 [INFO]: Epoch 015 - training loss: 10011.2944, validation loss: 0.4084
2024-05-22 22:16:34 [INFO]: Epoch 016 - training loss: 9941.2753, validation loss: 0.3830
2024-05-22 22:16:34 [INFO]: Epoch 017 - training loss: 9864.7131, validation loss: 0.3673
2024-05-22 22:16:34 [INFO]: Epoch 018 - training loss: 9804.9947, validation loss: 0.3430
2024-05-22 22:16:34 [INFO]: Epoch 019 - training loss: 9753.2805, validation loss: 0.3225
2024-05-22 22:16:35 [INFO]: Epoch 020 - training loss: 9694.9438, validation loss: 0.3052
2024-05-22 22:16:35 [INFO]: Epoch 021 - training loss: 9669.4551, validation loss: 0.2912
2024-05-22 22:16:35 [INFO]: Epoch 022 - training loss: 9626.4292, validation loss: 0.2767
2024-05-22 22:16:35 [INFO]: Epoch 023 - training loss: 9605.8034, validation loss: 0.2707
2024-05-22 22:16:35 [INFO]: Epoch 024 - training loss: 9576.6518, validation loss: 0.2643
2024-05-22 22:16:35 [INFO]: Epoch 025 - training loss: 9552.3513, validation loss: 0.2547
2024-05-22 22:16:35 [INFO]: Epoch 026 - training loss: 9529.1635, validation loss: 0.2467
2024-05-22 22:16:35 [INFO]: Epoch 027 - training loss: 9515.0919, validation loss: 0.2362
2024-05-22 22:16:35 [INFO]: Epoch 028 - training loss: 9496.7803, validation loss: 0.2227
2024-05-22 22:16:36 [INFO]: Epoch 029 - training loss: 9478.7416, validation loss: 0.2141
2024-05-22 22:16:36 [INFO]: Epoch 030 - training loss: 9464.5887, validation loss: 0.2080
2024-05-22 22:16:36 [INFO]: Epoch 031 - training loss: 9455.4169, validation loss: 0.1989
2024-05-22 22:16:36 [INFO]: Epoch 032 - training loss: 9439.6028, validation loss: 0.1952
2024-05-22 22:16:36 [INFO]: Epoch 033 - training loss: 9435.7411, validation loss: 0.1939
2024-05-22 22:16:36 [INFO]: Epoch 034 - training loss: 9452.6255, validation loss: 0.1831
2024-05-22 22:16:36 [INFO]: Epoch 035 - training loss: 9422.2354, validation loss: 0.1805
2024-05-22 22:16:36 [INFO]: Epoch 036 - training loss: 9410.6461, validation loss: 0.1778
2024-05-22 22:16:36 [INFO]: Epoch 037 - training loss: 9407.5457, validation loss: 0.1718
2024-05-22 22:16:36 [INFO]: Epoch 038 - training loss: 9393.2293, validation loss: 0.1704
2024-05-22 22:16:37 [INFO]: Epoch 039 - training loss: 9390.0622, validation loss: 0.1647
2024-05-22 22:16:37 [INFO]: Epoch 040 - training loss: 9386.5884, validation loss: 0.1614
2024-05-22 22:16:37 [INFO]: Epoch 041 - training loss: 9380.5083, validation loss: 0.1588
2024-05-22 22:16:37 [INFO]: Epoch 042 - training loss: 9379.0641, validation loss: 0.1552
2024-05-22 22:16:37 [INFO]: Epoch 043 - training loss: 9365.5016, validation loss: 0.1530
2024-05-22 22:16:37 [INFO]: Epoch 044 - training loss: 9368.3314, validation loss: 0.1503
2024-05-22 22:16:37 [INFO]: Epoch 045 - training loss: 9368.0992, validation loss: 0.1482
2024-05-22 22:16:37 [INFO]: Epoch 046 - training loss: 9356.7015, validation loss: 0.1456
2024-05-22 22:16:37 [INFO]: Epoch 047 - training loss: 9354.6605, validation loss: 0.1446
2024-05-22 22:16:38 [INFO]: Epoch 048 - training loss: 9350.7458, validation loss: 0.1436
2024-05-22 22:16:38 [INFO]: Epoch 049 - training loss: 9382.0267, validation loss: 0.1418
2024-05-22 22:16:38 [INFO]: Epoch 050 - training loss: 9348.5399, validation loss: 0.1399
2024-05-22 22:16:38 [INFO]: Epoch 051 - training loss: 9342.5902, validation loss: 0.1390
2024-05-22 22:16:38 [INFO]: Epoch 052 - training loss: 9342.2906, validation loss: 0.1382
2024-05-22 22:16:38 [INFO]: Epoch 053 - training loss: 9333.5921, validation loss: 0.1364
2024-05-22 22:16:38 [INFO]: Epoch 054 - training loss: 9335.1200, validation loss: 0.1368
2024-05-22 22:16:38 [INFO]: Epoch 055 - training loss: 9331.1613, validation loss: 0.1336
2024-05-22 22:16:38 [INFO]: Epoch 056 - training loss: 9331.6094, validation loss: 0.1337
2024-05-22 22:16:39 [INFO]: Epoch 057 - training loss: 9329.8983, validation loss: 0.1317
2024-05-22 22:16:39 [INFO]: Epoch 058 - training loss: 9326.9029, validation loss: 0.1340
2024-05-22 22:16:39 [INFO]: Epoch 059 - training loss: 9325.6693, validation loss: 0.1300
2024-05-22 22:16:39 [INFO]: Epoch 060 - training loss: 9326.7711, validation loss: 0.1296
2024-05-22 22:16:39 [INFO]: Epoch 061 - training loss: 9329.2773, validation loss: 0.1291
2024-05-22 22:16:39 [INFO]: Epoch 062 - training loss: 9318.5131, validation loss: 0.1290
2024-05-22 22:16:39 [INFO]: Epoch 063 - training loss: 9318.5518, validation loss: 0.1283
2024-05-22 22:16:39 [INFO]: Epoch 064 - training loss: 9315.4072, validation loss: 0.1277
2024-05-22 22:16:39 [INFO]: Epoch 065 - training loss: 9314.6218, validation loss: 0.1263
2024-05-22 22:16:39 [INFO]: Epoch 066 - training loss: 9315.1746, validation loss: 0.1255
2024-05-22 22:16:40 [INFO]: Epoch 067 - training loss: 9314.9941, validation loss: 0.1231
2024-05-22 22:16:40 [INFO]: Epoch 068 - training loss: 9313.4360, validation loss: 0.1230
2024-05-22 22:16:40 [INFO]: Epoch 069 - training loss: 9315.2619, validation loss: 0.1218
2024-05-22 22:16:40 [INFO]: Epoch 070 - training loss: 9312.2534, validation loss: 0.1201
2024-05-22 22:16:40 [INFO]: Epoch 071 - training loss: 9308.5777, validation loss: 0.1194
2024-05-22 22:16:40 [INFO]: Epoch 072 - training loss: 9307.9418, validation loss: 0.1196
2024-05-22 22:16:40 [INFO]: Epoch 073 - training loss: 9310.6821, validation loss: 0.1175
2024-05-22 22:16:40 [INFO]: Epoch 074 - training loss: 9307.3345, validation loss: 0.1182
2024-05-22 22:16:40 [INFO]: Epoch 075 - training loss: 9306.5414, validation loss: 0.1176
2024-05-22 22:16:41 [INFO]: Epoch 076 - training loss: 9304.6613, validation loss: 0.1165
2024-05-22 22:16:41 [INFO]: Epoch 077 - training loss: 9304.4561, validation loss: 0.1171
2024-05-22 22:16:41 [INFO]: Epoch 078 - training loss: 9302.3790, validation loss: 0.1146
2024-05-22 22:16:41 [INFO]: Epoch 079 - training loss: 9304.1634, validation loss: 0.1139
2024-05-22 22:16:41 [INFO]: Epoch 080 - training loss: 9302.8416, validation loss: 0.1138
2024-05-22 22:16:41 [INFO]: Epoch 081 - training loss: 9302.5091, validation loss: 0.1128
2024-05-22 22:16:41 [INFO]: Epoch 082 - training loss: 9303.8445, validation loss: 0.1128
2024-05-22 22:16:41 [INFO]: Epoch 083 - training loss: 9301.9673, validation loss: 0.1114
2024-05-22 22:16:41 [INFO]: Epoch 084 - training loss: 9300.0049, validation loss: 0.1122
2024-05-22 22:16:42 [INFO]: Epoch 085 - training loss: 9301.2950, validation loss: 0.1106
2024-05-22 22:16:42 [INFO]: Epoch 086 - training loss: 9300.6924, validation loss: 0.1101
2024-05-22 22:16:42 [INFO]: Epoch 087 - training loss: 9297.1992, validation loss: 0.1097
2024-05-22 22:16:42 [INFO]: Epoch 088 - training loss: 9296.6480, validation loss: 0.1093
2024-05-22 22:16:42 [INFO]: Epoch 089 - training loss: 9297.6999, validation loss: 0.1076
2024-05-22 22:16:42 [INFO]: Epoch 090 - training loss: 9297.9869, validation loss: 0.1082
2024-05-22 22:16:42 [INFO]: Epoch 091 - training loss: 9299.0667, validation loss: 0.1070
2024-05-22 22:16:42 [INFO]: Epoch 092 - training loss: 9294.1147, validation loss: 0.1069
2024-05-22 22:16:42 [INFO]: Epoch 093 - training loss: 9294.2822, validation loss: 0.1067
2024-05-22 22:16:43 [INFO]: Epoch 094 - training loss: 9294.3359, validation loss: 0.1054
2024-05-22 22:16:43 [INFO]: Epoch 095 - training loss: 9293.2338, validation loss: 0.1051
2024-05-22 22:16:43 [INFO]: Epoch 096 - training loss: 9292.8934, validation loss: 0.1056
2024-05-22 22:16:43 [INFO]: Epoch 097 - training loss: 9293.3749, validation loss: 0.1034
2024-05-22 22:16:43 [INFO]: Epoch 098 - training loss: 9291.9911, validation loss: 0.1040
2024-05-22 22:16:43 [INFO]: Epoch 099 - training loss: 9291.7147, validation loss: 0.1024
2024-05-22 22:16:43 [INFO]: Epoch 100 - training loss: 9290.8303, validation loss: 0.1021
2024-05-22 22:16:43 [INFO]: Epoch 101 - training loss: 9293.3871, validation loss: 0.1024
2024-05-22 22:16:43 [INFO]: Epoch 102 - training loss: 9290.5073, validation loss: 0.1012
2024-05-22 22:16:43 [INFO]: Epoch 103 - training loss: 9291.2004, validation loss: 0.1005
2024-05-22 22:16:44 [INFO]: Epoch 104 - training loss: 9291.4323, validation loss: 0.0996
2024-05-22 22:16:44 [INFO]: Epoch 105 - training loss: 9288.6382, validation loss: 0.1009
2024-05-22 22:16:44 [INFO]: Epoch 106 - training loss: 9287.6422, validation loss: 0.0991
2024-05-22 22:16:44 [INFO]: Epoch 107 - training loss: 9289.1050, validation loss: 0.0980
2024-05-22 22:16:44 [INFO]: Epoch 108 - training loss: 9288.1414, validation loss: 0.0984
2024-05-22 22:16:44 [INFO]: Epoch 109 - training loss: 9288.3976, validation loss: 0.0983
2024-05-22 22:16:44 [INFO]: Epoch 110 - training loss: 9289.3337, validation loss: 0.0964
2024-05-22 22:16:44 [INFO]: Epoch 111 - training loss: 9288.5176, validation loss: 0.0971
2024-05-22 22:16:44 [INFO]: Epoch 112 - training loss: 9288.7863, validation loss: 0.0963
2024-05-22 22:16:45 [INFO]: Epoch 113 - training loss: 9288.7745, validation loss: 0.0957
2024-05-22 22:16:45 [INFO]: Epoch 114 - training loss: 9286.8539, validation loss: 0.0964
2024-05-22 22:16:45 [INFO]: Epoch 115 - training loss: 9285.8015, validation loss: 0.0943
2024-05-22 22:16:45 [INFO]: Epoch 116 - training loss: 9285.6489, validation loss: 0.0950
2024-05-22 22:16:45 [INFO]: Epoch 117 - training loss: 9286.9066, validation loss: 0.0945
2024-05-22 22:16:45 [INFO]: Epoch 118 - training loss: 9289.8624, validation loss: 0.0939
2024-05-22 22:16:45 [INFO]: Epoch 119 - training loss: 9284.9747, validation loss: 0.0936
2024-05-22 22:16:45 [INFO]: Epoch 120 - training loss: 9283.8702, validation loss: 0.0932
2024-05-22 22:16:45 [INFO]: Epoch 121 - training loss: 9287.0176, validation loss: 0.0939
2024-05-22 22:16:46 [INFO]: Epoch 122 - training loss: 9285.4852, validation loss: 0.0929
2024-05-22 22:16:46 [INFO]: Epoch 123 - training loss: 9285.0969, validation loss: 0.0914
2024-05-22 22:16:46 [INFO]: Epoch 124 - training loss: 9285.1732, validation loss: 0.0937
2024-05-22 22:16:46 [INFO]: Epoch 125 - training loss: 9282.0142, validation loss: 0.0924
2024-05-22 22:16:46 [INFO]: Epoch 126 - training loss: 9284.4839, validation loss: 0.0903
2024-05-22 22:16:46 [INFO]: Epoch 127 - training loss: 9282.7877, validation loss: 0.0915
2024-05-22 22:16:46 [INFO]: Epoch 128 - training loss: 9283.5938, validation loss: 0.0891
2024-05-22 22:16:46 [INFO]: Epoch 129 - training loss: 9284.1885, validation loss: 0.0890
2024-05-22 22:16:46 [INFO]: Epoch 130 - training loss: 9282.0884, validation loss: 0.0907
2024-05-22 22:16:46 [INFO]: Epoch 131 - training loss: 9282.9352, validation loss: 0.0898
2024-05-22 22:16:47 [INFO]: Epoch 132 - training loss: 9281.2482, validation loss: 0.0899
2024-05-22 22:16:47 [INFO]: Epoch 133 - training loss: 9281.2240, validation loss: 0.0886
2024-05-22 22:16:47 [INFO]: Epoch 134 - training loss: 9280.5040, validation loss: 0.0883
2024-05-22 22:16:47 [INFO]: Epoch 135 - training loss: 9280.5998, validation loss: 0.0897
2024-05-22 22:16:47 [INFO]: Epoch 136 - training loss: 9281.9361, validation loss: 0.0881
2024-05-22 22:16:47 [INFO]: Epoch 137 - training loss: 9281.4190, validation loss: 0.0869
2024-05-22 22:16:47 [INFO]: Epoch 138 - training loss: 9279.0543, validation loss: 0.0877
2024-05-22 22:16:47 [INFO]: Epoch 139 - training loss: 9281.5587, validation loss: 0.0869
2024-05-22 22:16:47 [INFO]: Epoch 140 - training loss: 9279.8914, validation loss: 0.0856
2024-05-22 22:16:48 [INFO]: Epoch 141 - training loss: 9279.6416, validation loss: 0.0875
2024-05-22 22:16:48 [INFO]: Epoch 142 - training loss: 9281.1752, validation loss: 0.0861
2024-05-22 22:16:48 [INFO]: Epoch 143 - training loss: 9279.9054, validation loss: 0.0854
2024-05-22 22:16:48 [INFO]: Epoch 144 - training loss: 9279.2275, validation loss: 0.0857
2024-05-22 22:16:48 [INFO]: Epoch 145 - training loss: 9278.2944, validation loss: 0.0862
2024-05-22 22:16:48 [INFO]: Epoch 146 - training loss: 9278.6279, validation loss: 0.0862
2024-05-22 22:16:48 [INFO]: Epoch 147 - training loss: 9278.7021, validation loss: 0.0844
2024-05-22 22:16:48 [INFO]: Epoch 148 - training loss: 9279.1268, validation loss: 0.0834
2024-05-22 22:16:48 [INFO]: Epoch 149 - training loss: 9279.8339, validation loss: 0.0852
2024-05-22 22:16:49 [INFO]: Epoch 150 - training loss: 9278.5305, validation loss: 0.0838
2024-05-22 22:16:49 [INFO]: Epoch 151 - training loss: 9278.6956, validation loss: 0.0831
2024-05-22 22:16:49 [INFO]: Epoch 152 - training loss: 9278.7606, validation loss: 0.0842
2024-05-22 22:16:49 [INFO]: Epoch 153 - training loss: 9278.0220, validation loss: 0.0830
2024-05-22 22:16:49 [INFO]: Epoch 154 - training loss: 9278.4141, validation loss: 0.0835
2024-05-22 22:16:49 [INFO]: Epoch 155 - training loss: 9277.0837, validation loss: 0.0839
2024-05-22 22:16:49 [INFO]: Epoch 156 - training loss: 9276.4735, validation loss: 0.0824
2024-05-22 22:16:49 [INFO]: Epoch 157 - training loss: 9276.3062, validation loss: 0.0826
2024-05-22 22:16:49 [INFO]: Epoch 158 - training loss: 9277.1636, validation loss: 0.0816
2024-05-22 22:16:49 [INFO]: Epoch 159 - training loss: 9277.1205, validation loss: 0.0810
2024-05-22 22:16:50 [INFO]: Epoch 160 - training loss: 9277.8567, validation loss: 0.0824
2024-05-22 22:16:50 [INFO]: Epoch 161 - training loss: 9278.0483, validation loss: 0.0836
2024-05-22 22:16:50 [INFO]: Epoch 162 - training loss: 9278.4691, validation loss: 0.0812
2024-05-22 22:16:50 [INFO]: Epoch 163 - training loss: 9275.4637, validation loss: 0.0800
2024-05-22 22:16:50 [INFO]: Epoch 164 - training loss: 9275.2677, validation loss: 0.0802
2024-05-22 22:16:50 [INFO]: Epoch 165 - training loss: 9275.0328, validation loss: 0.0803
2024-05-22 22:16:50 [INFO]: Epoch 166 - training loss: 9276.7163, validation loss: 0.0813
2024-05-22 22:16:50 [INFO]: Epoch 167 - training loss: 9276.2704, validation loss: 0.0816
2024-05-22 22:16:50 [INFO]: Epoch 168 - training loss: 9276.9744, validation loss: 0.0798
2024-05-22 22:16:51 [INFO]: Epoch 169 - training loss: 9274.5808, validation loss: 0.0804
2024-05-22 22:16:51 [INFO]: Epoch 170 - training loss: 9274.8472, validation loss: 0.0806
2024-05-22 22:16:51 [INFO]: Epoch 171 - training loss: 9275.3035, validation loss: 0.0793
2024-05-22 22:16:51 [INFO]: Epoch 172 - training loss: 9276.9966, validation loss: 0.0803
2024-05-22 22:16:51 [INFO]: Epoch 173 - training loss: 9275.2527, validation loss: 0.0807
2024-05-22 22:16:51 [INFO]: Epoch 174 - training loss: 9276.3056, validation loss: 0.0808
2024-05-22 22:16:51 [INFO]: Epoch 175 - training loss: 9276.2275, validation loss: 0.0795
2024-05-22 22:16:51 [INFO]: Epoch 176 - training loss: 9276.8539, validation loss: 0.0788
2024-05-22 22:16:51 [INFO]: Epoch 177 - training loss: 9277.3682, validation loss: 0.0784
2024-05-22 22:16:52 [INFO]: Epoch 178 - training loss: 9276.0549, validation loss: 0.0770
2024-05-22 22:16:52 [INFO]: Epoch 179 - training loss: 9276.0983, validation loss: 0.0781
2024-05-22 22:16:52 [INFO]: Epoch 180 - training loss: 9273.8807, validation loss: 0.0762
2024-05-22 22:16:52 [INFO]: Epoch 181 - training loss: 9273.6957, validation loss: 0.0774
2024-05-22 22:16:52 [INFO]: Epoch 182 - training loss: 9273.8392, validation loss: 0.0779
2024-05-22 22:16:52 [INFO]: Epoch 183 - training loss: 9275.5798, validation loss: 0.0778
2024-05-22 22:16:52 [INFO]: Epoch 184 - training loss: 9274.1260, validation loss: 0.0780
2024-05-22 22:16:52 [INFO]: Epoch 185 - training loss: 9275.7736, validation loss: 0.0777
2024-05-22 22:16:52 [INFO]: Epoch 186 - training loss: 9273.6671, validation loss: 0.0783
2024-05-22 22:16:52 [INFO]: Epoch 187 - training loss: 9274.2048, validation loss: 0.0780
2024-05-22 22:16:53 [INFO]: Epoch 188 - training loss: 9275.0487, validation loss: 0.0766
2024-05-22 22:16:53 [INFO]: Epoch 189 - training loss: 9274.2231, validation loss: 0.0772
2024-05-22 22:16:53 [INFO]: Epoch 190 - training loss: 9274.0751, validation loss: 0.0767
2024-05-22 22:16:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:16:53 [INFO]: Finished training. The best model is from epoch#180.
2024-05-22 22:16:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/GPVAE_ettm1/20240522_T221632/GPVAE.pypots
2024-05-22 22:16:53 [INFO]: GP-VAE on ETTm1: MAE=0.2734, MSE=0.1558
2024-05-22 22:16:53 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/GPVAE_ettm1/imputation.pkl
2024-05-22 22:16:53 [INFO]: Using the given device: cuda:0
2024-05-22 22:16:53 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/USGAN_ettm1/20240522_T221653
2024-05-22 22:16:53 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/USGAN_ettm1/20240522_T221653/tensorboard
2024-05-22 22:16:53 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 22:17:01 [INFO]: Epoch 001 - generator training loss: 0.5028, discriminator training loss: 0.4269, validation loss: 0.3089
2024-05-22 22:17:08 [INFO]: Epoch 002 - generator training loss: 0.0076, discriminator training loss: 0.3224, validation loss: 0.1177
2024-05-22 22:17:15 [INFO]: Epoch 003 - generator training loss: -0.1166, discriminator training loss: 0.3101, validation loss: 0.0729
2024-05-22 22:17:22 [INFO]: Epoch 004 - generator training loss: -0.1363, discriminator training loss: 0.2959, validation loss: 0.0514
2024-05-22 22:17:29 [INFO]: Epoch 005 - generator training loss: -0.1255, discriminator training loss: 0.2775, validation loss: 0.0467
2024-05-22 22:17:35 [INFO]: Epoch 006 - generator training loss: -0.1089, discriminator training loss: 0.2504, validation loss: 0.0429
2024-05-22 22:17:42 [INFO]: Epoch 007 - generator training loss: -0.0821, discriminator training loss: 0.2156, validation loss: 0.0403
2024-05-22 22:17:49 [INFO]: Epoch 008 - generator training loss: -0.0615, discriminator training loss: 0.1813, validation loss: 0.0393
2024-05-22 22:17:56 [INFO]: Epoch 009 - generator training loss: -0.0437, discriminator training loss: 0.1577, validation loss: 0.0384
2024-05-22 22:18:03 [INFO]: Epoch 010 - generator training loss: -0.0374, discriminator training loss: 0.1422, validation loss: 0.0368
2024-05-22 22:18:10 [INFO]: Epoch 011 - generator training loss: -0.0345, discriminator training loss: 0.1321, validation loss: 0.0359
2024-05-22 22:18:17 [INFO]: Epoch 012 - generator training loss: -0.0311, discriminator training loss: 0.1255, validation loss: 0.0362
2024-05-22 22:18:24 [INFO]: Epoch 013 - generator training loss: -0.0324, discriminator training loss: 0.1242, validation loss: 0.0357
2024-05-22 22:18:31 [INFO]: Epoch 014 - generator training loss: -0.0312, discriminator training loss: 0.1234, validation loss: 0.0349
2024-05-22 22:18:38 [INFO]: Epoch 015 - generator training loss: -0.0324, discriminator training loss: 0.1181, validation loss: 0.0344
2024-05-22 22:18:44 [INFO]: Epoch 016 - generator training loss: -0.0322, discriminator training loss: 0.1183, validation loss: 0.0344
2024-05-22 22:18:51 [INFO]: Epoch 017 - generator training loss: -0.0337, discriminator training loss: 0.1169, validation loss: 0.0338
2024-05-22 22:18:58 [INFO]: Epoch 018 - generator training loss: -0.0278, discriminator training loss: 0.1175, validation loss: 0.0337
2024-05-22 22:19:05 [INFO]: Epoch 019 - generator training loss: -0.0334, discriminator training loss: 0.1161, validation loss: 0.0334
2024-05-22 22:19:12 [INFO]: Epoch 020 - generator training loss: -0.0302, discriminator training loss: 0.1141, validation loss: 0.0333
2024-05-22 22:19:19 [INFO]: Epoch 021 - generator training loss: -0.0340, discriminator training loss: 0.1155, validation loss: 0.0325
2024-05-22 22:19:26 [INFO]: Epoch 022 - generator training loss: -0.0343, discriminator training loss: 0.1132, validation loss: 0.0328
2024-05-22 22:19:33 [INFO]: Epoch 023 - generator training loss: -0.0316, discriminator training loss: 0.1154, validation loss: 0.0324
2024-05-22 22:19:40 [INFO]: Epoch 024 - generator training loss: -0.0300, discriminator training loss: 0.1160, validation loss: 0.0323
2024-05-22 22:19:47 [INFO]: Epoch 025 - generator training loss: -0.0336, discriminator training loss: 0.1128, validation loss: 0.0316
2024-05-22 22:19:54 [INFO]: Epoch 026 - generator training loss: -0.0330, discriminator training loss: 0.1148, validation loss: 0.0314
2024-05-22 22:20:01 [INFO]: Epoch 027 - generator training loss: -0.0332, discriminator training loss: 0.1112, validation loss: 0.0312
2024-05-22 22:20:08 [INFO]: Epoch 028 - generator training loss: -0.0360, discriminator training loss: 0.1097, validation loss: 0.0314
2024-05-22 22:20:14 [INFO]: Epoch 029 - generator training loss: -0.0344, discriminator training loss: 0.1098, validation loss: 0.0308
2024-05-22 22:20:21 [INFO]: Epoch 030 - generator training loss: -0.0379, discriminator training loss: 0.1132, validation loss: 0.0310
2024-05-22 22:20:28 [INFO]: Epoch 031 - generator training loss: -0.0345, discriminator training loss: 0.1111, validation loss: 0.0307
2024-05-22 22:20:35 [INFO]: Epoch 032 - generator training loss: -0.0387, discriminator training loss: 0.1113, validation loss: 0.0298
2024-05-22 22:20:42 [INFO]: Epoch 033 - generator training loss: -0.0330, discriminator training loss: 0.1100, validation loss: 0.0300
2024-05-22 22:20:49 [INFO]: Epoch 034 - generator training loss: -0.0362, discriminator training loss: 0.1099, validation loss: 0.0296
2024-05-22 22:20:56 [INFO]: Epoch 035 - generator training loss: -0.0376, discriminator training loss: 0.1118, validation loss: 0.0298
2024-05-22 22:21:03 [INFO]: Epoch 036 - generator training loss: -0.0357, discriminator training loss: 0.1098, validation loss: 0.0297
2024-05-22 22:21:10 [INFO]: Epoch 037 - generator training loss: -0.0354, discriminator training loss: 0.1113, validation loss: 0.0293
2024-05-22 22:21:17 [INFO]: Epoch 038 - generator training loss: -0.0382, discriminator training loss: 0.1092, validation loss: 0.0294
2024-05-22 22:21:24 [INFO]: Epoch 039 - generator training loss: -0.0387, discriminator training loss: 0.1093, validation loss: 0.0288
2024-05-22 22:21:31 [INFO]: Epoch 040 - generator training loss: -0.0366, discriminator training loss: 0.1085, validation loss: 0.0283
2024-05-22 22:21:38 [INFO]: Epoch 041 - generator training loss: -0.0386, discriminator training loss: 0.1095, validation loss: 0.0286
2024-05-22 22:21:45 [INFO]: Epoch 042 - generator training loss: -0.0372, discriminator training loss: 0.1106, validation loss: 0.0281
2024-05-22 22:21:52 [INFO]: Epoch 043 - generator training loss: -0.0389, discriminator training loss: 0.1094, validation loss: 0.0278
2024-05-22 22:21:59 [INFO]: Epoch 044 - generator training loss: -0.0379, discriminator training loss: 0.1087, validation loss: 0.0276
2024-05-22 22:22:06 [INFO]: Epoch 045 - generator training loss: -0.0412, discriminator training loss: 0.1096, validation loss: 0.0270
2024-05-22 22:22:12 [INFO]: Epoch 046 - generator training loss: -0.0416, discriminator training loss: 0.1096, validation loss: 0.0270
2024-05-22 22:22:19 [INFO]: Epoch 047 - generator training loss: -0.0402, discriminator training loss: 0.1097, validation loss: 0.0269
2024-05-22 22:22:26 [INFO]: Epoch 048 - generator training loss: -0.0416, discriminator training loss: 0.1082, validation loss: 0.0267
2024-05-22 22:22:33 [INFO]: Epoch 049 - generator training loss: -0.0410, discriminator training loss: 0.1074, validation loss: 0.0266
2024-05-22 22:22:40 [INFO]: Epoch 050 - generator training loss: -0.0450, discriminator training loss: 0.1084, validation loss: 0.0259
2024-05-22 22:22:47 [INFO]: Epoch 051 - generator training loss: -0.0424, discriminator training loss: 0.1099, validation loss: 0.0264
2024-05-22 22:22:54 [INFO]: Epoch 052 - generator training loss: -0.0398, discriminator training loss: 0.1088, validation loss: 0.0257
2024-05-22 22:23:01 [INFO]: Epoch 053 - generator training loss: -0.0427, discriminator training loss: 0.1100, validation loss: 0.0257
2024-05-22 22:23:08 [INFO]: Epoch 054 - generator training loss: -0.0408, discriminator training loss: 0.1083, validation loss: 0.0254
2024-05-22 22:23:15 [INFO]: Epoch 055 - generator training loss: -0.0416, discriminator training loss: 0.1074, validation loss: 0.0260
2024-05-22 22:23:21 [INFO]: Epoch 056 - generator training loss: -0.0408, discriminator training loss: 0.1088, validation loss: 0.0257
2024-05-22 22:23:28 [INFO]: Epoch 057 - generator training loss: -0.0437, discriminator training loss: 0.1086, validation loss: 0.0251
2024-05-22 22:23:35 [INFO]: Epoch 058 - generator training loss: -0.0423, discriminator training loss: 0.1074, validation loss: 0.0249
2024-05-22 22:23:42 [INFO]: Epoch 059 - generator training loss: -0.0438, discriminator training loss: 0.1071, validation loss: 0.0250
2024-05-22 22:23:49 [INFO]: Epoch 060 - generator training loss: -0.0438, discriminator training loss: 0.1103, validation loss: 0.0250
2024-05-22 22:23:56 [INFO]: Epoch 061 - generator training loss: -0.0436, discriminator training loss: 0.1074, validation loss: 0.0252
2024-05-22 22:24:03 [INFO]: Epoch 062 - generator training loss: -0.0419, discriminator training loss: 0.1085, validation loss: 0.0300
2024-05-22 22:24:10 [INFO]: Epoch 063 - generator training loss: -0.0391, discriminator training loss: 0.1099, validation loss: 0.0258
2024-05-22 22:24:17 [INFO]: Epoch 064 - generator training loss: -0.0421, discriminator training loss: 0.1081, validation loss: 0.0246
2024-05-22 22:24:24 [INFO]: Epoch 065 - generator training loss: -0.0481, discriminator training loss: 0.1072, validation loss: 0.0247
2024-05-22 22:24:31 [INFO]: Epoch 066 - generator training loss: -0.0460, discriminator training loss: 0.1073, validation loss: 0.0243
2024-05-22 22:24:38 [INFO]: Epoch 067 - generator training loss: -0.0435, discriminator training loss: 0.1066, validation loss: 0.0245
2024-05-22 22:24:45 [INFO]: Epoch 068 - generator training loss: -0.0477, discriminator training loss: 0.1074, validation loss: 0.0239
2024-05-22 22:24:52 [INFO]: Epoch 069 - generator training loss: -0.0461, discriminator training loss: 0.1067, validation loss: 0.0241
2024-05-22 22:24:59 [INFO]: Epoch 070 - generator training loss: -0.0444, discriminator training loss: 0.1083, validation loss: 0.0243
2024-05-22 22:25:06 [INFO]: Epoch 071 - generator training loss: -0.0436, discriminator training loss: 0.1071, validation loss: 0.0238
2024-05-22 22:25:13 [INFO]: Epoch 072 - generator training loss: -0.0444, discriminator training loss: 0.1080, validation loss: 0.0242
2024-05-22 22:25:20 [INFO]: Epoch 073 - generator training loss: -0.0462, discriminator training loss: 0.1078, validation loss: 0.0240
2024-05-22 22:25:26 [INFO]: Epoch 074 - generator training loss: -0.0470, discriminator training loss: 0.1068, validation loss: 0.0235
2024-05-22 22:25:33 [INFO]: Epoch 075 - generator training loss: -0.0458, discriminator training loss: 0.1074, validation loss: 0.0237
2024-05-22 22:25:40 [INFO]: Epoch 076 - generator training loss: -0.0464, discriminator training loss: 0.1082, validation loss: 0.0232
2024-05-22 22:25:47 [INFO]: Epoch 077 - generator training loss: -0.0441, discriminator training loss: 0.1054, validation loss: 0.0234
2024-05-22 22:25:54 [INFO]: Epoch 078 - generator training loss: -0.0478, discriminator training loss: 0.1074, validation loss: 0.0234
2024-05-22 22:26:01 [INFO]: Epoch 079 - generator training loss: -0.0433, discriminator training loss: 0.1075, validation loss: 0.0235
2024-05-22 22:26:08 [INFO]: Epoch 080 - generator training loss: -0.0444, discriminator training loss: 0.1065, validation loss: 0.0234
2024-05-22 22:26:15 [INFO]: Epoch 081 - generator training loss: -0.0464, discriminator training loss: 0.1066, validation loss: 0.0230
2024-05-22 22:26:22 [INFO]: Epoch 082 - generator training loss: -0.0458, discriminator training loss: 0.1066, validation loss: 0.0230
2024-05-22 22:26:29 [INFO]: Epoch 083 - generator training loss: -0.0482, discriminator training loss: 0.1057, validation loss: 0.0232
2024-05-22 22:26:36 [INFO]: Epoch 084 - generator training loss: -0.0468, discriminator training loss: 0.1055, validation loss: 0.0230
2024-05-22 22:26:43 [INFO]: Epoch 085 - generator training loss: -0.0467, discriminator training loss: 0.1047, validation loss: 0.0229
2024-05-22 22:26:50 [INFO]: Epoch 086 - generator training loss: -0.0494, discriminator training loss: 0.1074, validation loss: 0.0227
2024-05-22 22:26:57 [INFO]: Epoch 087 - generator training loss: -0.0440, discriminator training loss: 0.1057, validation loss: 0.0226
2024-05-22 22:27:04 [INFO]: Epoch 088 - generator training loss: -0.0529, discriminator training loss: 0.1056, validation loss: 0.0226
2024-05-22 22:27:11 [INFO]: Epoch 089 - generator training loss: -0.0452, discriminator training loss: 0.1057, validation loss: 0.0221
2024-05-22 22:27:18 [INFO]: Epoch 090 - generator training loss: -0.0467, discriminator training loss: 0.1063, validation loss: 0.0235
2024-05-22 22:27:25 [INFO]: Epoch 091 - generator training loss: -0.0495, discriminator training loss: 0.1059, validation loss: 0.0223
2024-05-22 22:27:32 [INFO]: Epoch 092 - generator training loss: -0.0473, discriminator training loss: 0.1052, validation loss: 0.0228
2024-05-22 22:27:38 [INFO]: Epoch 093 - generator training loss: -0.0512, discriminator training loss: 0.1053, validation loss: 0.0224
2024-05-22 22:27:45 [INFO]: Epoch 094 - generator training loss: -0.0500, discriminator training loss: 0.1054, validation loss: 0.0221
2024-05-22 22:27:52 [INFO]: Epoch 095 - generator training loss: -0.0468, discriminator training loss: 0.1057, validation loss: 0.0219
2024-05-22 22:27:59 [INFO]: Epoch 096 - generator training loss: -0.0500, discriminator training loss: 0.1053, validation loss: 0.0220
2024-05-22 22:28:06 [INFO]: Epoch 097 - generator training loss: -0.0504, discriminator training loss: 0.1049, validation loss: 0.0218
2024-05-22 22:28:13 [INFO]: Epoch 098 - generator training loss: -0.0491, discriminator training loss: 0.1041, validation loss: 0.0227
2024-05-22 22:28:20 [INFO]: Epoch 099 - generator training loss: -0.0509, discriminator training loss: 0.1053, validation loss: 0.0219
2024-05-22 22:28:27 [INFO]: Epoch 100 - generator training loss: -0.0473, discriminator training loss: 0.1042, validation loss: 0.0221
2024-05-22 22:28:34 [INFO]: Epoch 101 - generator training loss: -0.0501, discriminator training loss: 0.1051, validation loss: 0.0219
2024-05-22 22:28:41 [INFO]: Epoch 102 - generator training loss: -0.0483, discriminator training loss: 0.1052, validation loss: 0.0218
2024-05-22 22:28:48 [INFO]: Epoch 103 - generator training loss: -0.0475, discriminator training loss: 0.1047, validation loss: 0.0223
2024-05-22 22:28:55 [INFO]: Epoch 104 - generator training loss: -0.0494, discriminator training loss: 0.1060, validation loss: 0.0224
2024-05-22 22:29:02 [INFO]: Epoch 105 - generator training loss: -0.0476, discriminator training loss: 0.1067, validation loss: 0.0225
2024-05-22 22:29:09 [INFO]: Epoch 106 - generator training loss: -0.0488, discriminator training loss: 0.1065, validation loss: 0.0217
2024-05-22 22:29:16 [INFO]: Epoch 107 - generator training loss: -0.0468, discriminator training loss: 0.1054, validation loss: 0.0219
2024-05-22 22:29:23 [INFO]: Epoch 108 - generator training loss: -0.0481, discriminator training loss: 0.1063, validation loss: 0.0216
2024-05-22 22:29:30 [INFO]: Epoch 109 - generator training loss: -0.0473, discriminator training loss: 0.1034, validation loss: 0.0220
2024-05-22 22:29:37 [INFO]: Epoch 110 - generator training loss: -0.0482, discriminator training loss: 0.1055, validation loss: 0.0217
2024-05-22 22:29:44 [INFO]: Epoch 111 - generator training loss: -0.0465, discriminator training loss: 0.1051, validation loss: 0.0222
2024-05-22 22:29:51 [INFO]: Epoch 112 - generator training loss: -0.0510, discriminator training loss: 0.1050, validation loss: 0.0220
2024-05-22 22:29:58 [INFO]: Epoch 113 - generator training loss: -0.0488, discriminator training loss: 0.1038, validation loss: 0.0215
2024-05-22 22:30:05 [INFO]: Epoch 114 - generator training loss: -0.0503, discriminator training loss: 0.1064, validation loss: 0.0215
2024-05-22 22:30:12 [INFO]: Epoch 115 - generator training loss: -0.0473, discriminator training loss: 0.1049, validation loss: 0.0224
2024-05-22 22:30:18 [INFO]: Epoch 116 - generator training loss: -0.0474, discriminator training loss: 0.1033, validation loss: 0.0238
2024-05-22 22:30:25 [INFO]: Epoch 117 - generator training loss: -0.0506, discriminator training loss: 0.1041, validation loss: 0.0225
2024-05-22 22:30:32 [INFO]: Epoch 118 - generator training loss: -0.0478, discriminator training loss: 0.1051, validation loss: 0.0227
2024-05-22 22:30:39 [INFO]: Epoch 119 - generator training loss: -0.0470, discriminator training loss: 0.1032, validation loss: 0.0218
2024-05-22 22:30:46 [INFO]: Epoch 120 - generator training loss: -0.0491, discriminator training loss: 0.1031, validation loss: 0.0216
2024-05-22 22:30:53 [INFO]: Epoch 121 - generator training loss: -0.0494, discriminator training loss: 0.1036, validation loss: 0.0219
2024-05-22 22:31:00 [INFO]: Epoch 122 - generator training loss: -0.0479, discriminator training loss: 0.1037, validation loss: 0.0224
2024-05-22 22:31:07 [INFO]: Epoch 123 - generator training loss: -0.0507, discriminator training loss: 0.1052, validation loss: 0.0214
2024-05-22 22:31:14 [INFO]: Epoch 124 - generator training loss: -0.0480, discriminator training loss: 0.1050, validation loss: 0.0217
2024-05-22 22:31:21 [INFO]: Epoch 125 - generator training loss: -0.0501, discriminator training loss: 0.1054, validation loss: 0.0215
2024-05-22 22:31:28 [INFO]: Epoch 126 - generator training loss: -0.0480, discriminator training loss: 0.1048, validation loss: 0.0214
2024-05-22 22:31:35 [INFO]: Epoch 127 - generator training loss: -0.0460, discriminator training loss: 0.1063, validation loss: 0.0214
2024-05-22 22:31:42 [INFO]: Epoch 128 - generator training loss: -0.0490, discriminator training loss: 0.1040, validation loss: 0.0217
2024-05-22 22:31:49 [INFO]: Epoch 129 - generator training loss: -0.0488, discriminator training loss: 0.1028, validation loss: 0.0217
2024-05-22 22:31:56 [INFO]: Epoch 130 - generator training loss: -0.0496, discriminator training loss: 0.1033, validation loss: 0.0221
2024-05-22 22:32:03 [INFO]: Epoch 131 - generator training loss: -0.0475, discriminator training loss: 0.1039, validation loss: 0.0221
2024-05-22 22:32:10 [INFO]: Epoch 132 - generator training loss: -0.0482, discriminator training loss: 0.1041, validation loss: 0.0212
2024-05-22 22:32:17 [INFO]: Epoch 133 - generator training loss: -0.0487, discriminator training loss: 0.1045, validation loss: 0.0216
2024-05-22 22:32:23 [INFO]: Epoch 134 - generator training loss: -0.0498, discriminator training loss: 0.1027, validation loss: 0.0214
2024-05-22 22:32:31 [INFO]: Epoch 135 - generator training loss: -0.0489, discriminator training loss: 0.1032, validation loss: 0.0218
2024-05-22 22:32:37 [INFO]: Epoch 136 - generator training loss: -0.0503, discriminator training loss: 0.1053, validation loss: 0.0229
2024-05-22 22:32:44 [INFO]: Epoch 137 - generator training loss: -0.0478, discriminator training loss: 0.1016, validation loss: 0.0219
2024-05-22 22:32:51 [INFO]: Epoch 138 - generator training loss: -0.0464, discriminator training loss: 0.1045, validation loss: 0.0225
2024-05-22 22:32:58 [INFO]: Epoch 139 - generator training loss: -0.0461, discriminator training loss: 0.1029, validation loss: 0.0222
2024-05-22 22:33:05 [INFO]: Epoch 140 - generator training loss: -0.0487, discriminator training loss: 0.1038, validation loss: 0.0219
2024-05-22 22:33:12 [INFO]: Epoch 141 - generator training loss: -0.0482, discriminator training loss: 0.1016, validation loss: 0.0216
2024-05-22 22:33:19 [INFO]: Epoch 142 - generator training loss: -0.0510, discriminator training loss: 0.1012, validation loss: 0.0214
2024-05-22 22:33:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:33:19 [INFO]: Finished training. The best model is from epoch#132.
2024-05-22 22:33:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/USGAN_ettm1/20240522_T221653/USGAN.pypots
2024-05-22 22:33:20 [INFO]: US-GAN on ETTm1: MAE=0.1489, MSE=0.0570
2024-05-22 22:33:20 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/USGAN_ettm1/imputation.pkl
2024-05-22 22:33:20 [INFO]: Using the given device: cuda:0
2024-05-22 22:33:20 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/BRITS_ettm1/20240522_T223320
2024-05-22 22:33:20 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/BRITS_ettm1/20240522_T223320/tensorboard
2024-05-22 22:33:20 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 22:33:26 [INFO]: Epoch 001 - training loss: 1.2510, validation loss: 0.2606
2024-05-22 22:33:30 [INFO]: Epoch 002 - training loss: 0.8465, validation loss: 0.0779
2024-05-22 22:33:35 [INFO]: Epoch 003 - training loss: 0.7002, validation loss: 0.0525
2024-05-22 22:33:40 [INFO]: Epoch 004 - training loss: 0.6169, validation loss: 0.0458
2024-05-22 22:33:44 [INFO]: Epoch 005 - training loss: 0.5731, validation loss: 0.0385
2024-05-22 22:33:49 [INFO]: Epoch 006 - training loss: 0.5580, validation loss: 0.0385
2024-05-22 22:33:53 [INFO]: Epoch 007 - training loss: 0.5098, validation loss: 0.0349
2024-05-22 22:33:58 [INFO]: Epoch 008 - training loss: 0.5045, validation loss: 0.0317
2024-05-22 22:34:02 [INFO]: Epoch 009 - training loss: 0.4745, validation loss: 0.0310
2024-05-22 22:34:07 [INFO]: Epoch 010 - training loss: 0.4534, validation loss: 0.0300
2024-05-22 22:34:12 [INFO]: Epoch 011 - training loss: 0.4447, validation loss: 0.0290
2024-05-22 22:34:16 [INFO]: Epoch 012 - training loss: 0.4413, validation loss: 0.0293
2024-05-22 22:34:21 [INFO]: Epoch 013 - training loss: 0.4259, validation loss: 0.0277
2024-05-22 22:34:25 [INFO]: Epoch 014 - training loss: 0.4183, validation loss: 0.0280
2024-05-22 22:34:30 [INFO]: Epoch 015 - training loss: 0.4065, validation loss: 0.0268
2024-05-22 22:34:34 [INFO]: Epoch 016 - training loss: 0.3931, validation loss: 0.0271
2024-05-22 22:34:39 [INFO]: Epoch 017 - training loss: 0.4198, validation loss: 0.0278
2024-05-22 22:34:44 [INFO]: Epoch 018 - training loss: 0.4041, validation loss: 0.0261
2024-05-22 22:34:48 [INFO]: Epoch 019 - training loss: 0.4032, validation loss: 0.0252
2024-05-22 22:34:53 [INFO]: Epoch 020 - training loss: 0.3936, validation loss: 0.0255
2024-05-22 22:34:57 [INFO]: Epoch 021 - training loss: 0.3884, validation loss: 0.0252
2024-05-22 22:35:02 [INFO]: Epoch 022 - training loss: 0.3951, validation loss: 0.0263
2024-05-22 22:35:06 [INFO]: Epoch 023 - training loss: 0.3926, validation loss: 0.0247
2024-05-22 22:35:11 [INFO]: Epoch 024 - training loss: 0.3934, validation loss: 0.0250
2024-05-22 22:35:16 [INFO]: Epoch 025 - training loss: 0.3894, validation loss: 0.0249
2024-05-22 22:35:20 [INFO]: Epoch 026 - training loss: 0.3928, validation loss: 0.0251
2024-05-22 22:35:25 [INFO]: Epoch 027 - training loss: 0.3863, validation loss: 0.0251
2024-05-22 22:35:29 [INFO]: Epoch 028 - training loss: 0.3864, validation loss: 0.0249
2024-05-22 22:35:34 [INFO]: Epoch 029 - training loss: 0.3804, validation loss: 0.0245
2024-05-22 22:35:38 [INFO]: Epoch 030 - training loss: 0.3881, validation loss: 0.0247
2024-05-22 22:35:43 [INFO]: Epoch 031 - training loss: 0.3895, validation loss: 0.0249
2024-05-22 22:35:48 [INFO]: Epoch 032 - training loss: 0.3852, validation loss: 0.0246
2024-05-22 22:35:52 [INFO]: Epoch 033 - training loss: 0.3761, validation loss: 0.0255
2024-05-22 22:35:57 [INFO]: Epoch 034 - training loss: 0.4215, validation loss: 0.0276
2024-05-22 22:36:01 [INFO]: Epoch 035 - training loss: 0.3994, validation loss: 0.0255
2024-05-22 22:36:06 [INFO]: Epoch 036 - training loss: 0.3829, validation loss: 0.0252
2024-05-22 22:36:11 [INFO]: Epoch 037 - training loss: 0.3809, validation loss: 0.0257
2024-05-22 22:36:15 [INFO]: Epoch 038 - training loss: 0.3857, validation loss: 0.0252
2024-05-22 22:36:20 [INFO]: Epoch 039 - training loss: 0.3777, validation loss: 0.0246
2024-05-22 22:36:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:36:20 [INFO]: Finished training. The best model is from epoch#29.
2024-05-22 22:36:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/BRITS_ettm1/20240522_T223320/BRITS.pypots
2024-05-22 22:36:20 [INFO]: BRITS on ETTm1: MAE=0.1401, MSE=0.0613
2024-05-22 22:36:20 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/BRITS_ettm1/imputation.pkl
2024-05-22 22:36:20 [INFO]: Using the given device: cuda:0
2024-05-22 22:36:20 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620
2024-05-22 22:36:20 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/tensorboard
2024-05-22 22:36:20 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 22:36:22 [INFO]: Epoch 001 - training loss: 1.4544, validation loss: 1.3106
2024-05-22 22:36:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch1_loss1.3106243014335632.pypots
2024-05-22 22:36:22 [INFO]: Epoch 002 - training loss: 1.1005, validation loss: 1.1428
2024-05-22 22:36:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch2_loss1.1428000181913376.pypots
2024-05-22 22:36:22 [INFO]: Epoch 003 - training loss: 0.9717, validation loss: 1.0614
2024-05-22 22:36:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch3_loss1.061389684677124.pypots
2024-05-22 22:36:22 [INFO]: Epoch 004 - training loss: 0.9240, validation loss: 1.0315
2024-05-22 22:36:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch4_loss1.0315215587615967.pypots
2024-05-22 22:36:22 [INFO]: Epoch 005 - training loss: 0.9279, validation loss: 1.0187
2024-05-22 22:36:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch5_loss1.0187419801950455.pypots
2024-05-22 22:36:22 [INFO]: Epoch 006 - training loss: 0.9471, validation loss: 1.0081
2024-05-22 22:36:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch6_loss1.0080642104148865.pypots
2024-05-22 22:36:23 [INFO]: Epoch 007 - training loss: 0.9068, validation loss: 0.9997
2024-05-22 22:36:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch7_loss0.9997183382511139.pypots
2024-05-22 22:36:23 [INFO]: Epoch 008 - training loss: 0.8880, validation loss: 0.9940
2024-05-22 22:36:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch8_loss0.9940461218357086.pypots
2024-05-22 22:36:23 [INFO]: Epoch 009 - training loss: 0.8897, validation loss: 0.9887
2024-05-22 22:36:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch9_loss0.9886740446090698.pypots
2024-05-22 22:36:23 [INFO]: Epoch 010 - training loss: 0.8643, validation loss: 0.9842
2024-05-22 22:36:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch10_loss0.984234556555748.pypots
2024-05-22 22:36:23 [INFO]: Epoch 011 - training loss: 0.8704, validation loss: 0.9831
2024-05-22 22:36:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch11_loss0.9830725640058517.pypots
2024-05-22 22:36:23 [INFO]: Epoch 012 - training loss: 0.8855, validation loss: 0.9805
2024-05-22 22:36:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch12_loss0.9805115014314651.pypots
2024-05-22 22:36:24 [INFO]: Epoch 013 - training loss: 0.9332, validation loss: 0.9777
2024-05-22 22:36:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch13_loss0.9776510298252106.pypots
2024-05-22 22:36:24 [INFO]: Epoch 014 - training loss: 0.8703, validation loss: 0.9739
2024-05-22 22:36:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch14_loss0.9739033132791519.pypots
2024-05-22 22:36:24 [INFO]: Epoch 015 - training loss: 0.8447, validation loss: 0.9683
2024-05-22 22:36:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch15_loss0.9683369845151901.pypots
2024-05-22 22:36:24 [INFO]: Epoch 016 - training loss: 0.8639, validation loss: 0.9672
2024-05-22 22:36:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch16_loss0.9671580791473389.pypots
2024-05-22 22:36:24 [INFO]: Epoch 017 - training loss: 0.8407, validation loss: 0.9627
2024-05-22 22:36:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch17_loss0.9626543372869492.pypots
2024-05-22 22:36:24 [INFO]: Epoch 018 - training loss: 0.8288, validation loss: 0.9601
2024-05-22 22:36:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch18_loss0.9601233452558517.pypots
2024-05-22 22:36:25 [INFO]: Epoch 019 - training loss: 0.8415, validation loss: 0.9568
2024-05-22 22:36:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch19_loss0.9568064212799072.pypots
2024-05-22 22:36:25 [INFO]: Epoch 020 - training loss: 0.8271, validation loss: 0.9540
2024-05-22 22:36:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch20_loss0.954040452837944.pypots
2024-05-22 22:36:25 [INFO]: Epoch 021 - training loss: 0.8296, validation loss: 0.9523
2024-05-22 22:36:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch21_loss0.9522534161806107.pypots
2024-05-22 22:36:25 [INFO]: Epoch 022 - training loss: 0.8167, validation loss: 0.9491
2024-05-22 22:36:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch22_loss0.9491341263055801.pypots
2024-05-22 22:36:25 [INFO]: Epoch 023 - training loss: 0.8163, validation loss: 0.9461
2024-05-22 22:36:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch23_loss0.9460669308900833.pypots
2024-05-22 22:36:25 [INFO]: Epoch 024 - training loss: 0.8546, validation loss: 0.9420
2024-05-22 22:36:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch24_loss0.9419899731874466.pypots
2024-05-22 22:36:26 [INFO]: Epoch 025 - training loss: 0.8009, validation loss: 0.9391
2024-05-22 22:36:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch25_loss0.9390988796949387.pypots
2024-05-22 22:36:26 [INFO]: Epoch 026 - training loss: 0.8060, validation loss: 0.9370
2024-05-22 22:36:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch26_loss0.9370100498199463.pypots
2024-05-22 22:36:26 [INFO]: Epoch 027 - training loss: 0.8199, validation loss: 0.9363
2024-05-22 22:36:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch27_loss0.9362777173519135.pypots
2024-05-22 22:36:26 [INFO]: Epoch 028 - training loss: 0.8172, validation loss: 0.9325
2024-05-22 22:36:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch28_loss0.9325123876333237.pypots
2024-05-22 22:36:26 [INFO]: Epoch 029 - training loss: 0.8040, validation loss: 0.9282
2024-05-22 22:36:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch29_loss0.9282466769218445.pypots
2024-05-22 22:36:26 [INFO]: Epoch 030 - training loss: 0.7929, validation loss: 0.9245
2024-05-22 22:36:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch30_loss0.924500048160553.pypots
2024-05-22 22:36:26 [INFO]: Epoch 031 - training loss: 0.7948, validation loss: 0.9230
2024-05-22 22:36:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch31_loss0.9230144321918488.pypots
2024-05-22 22:36:27 [INFO]: Epoch 032 - training loss: 0.7754, validation loss: 0.9204
2024-05-22 22:36:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch32_loss0.920356273651123.pypots
2024-05-22 22:36:27 [INFO]: Epoch 033 - training loss: 0.8022, validation loss: 0.9206
2024-05-22 22:36:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch33_loss0.9206399023532867.pypots
2024-05-22 22:36:27 [INFO]: Epoch 034 - training loss: 0.7935, validation loss: 0.9167
2024-05-22 22:36:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch34_loss0.9167158901691437.pypots
2024-05-22 22:36:27 [INFO]: Epoch 035 - training loss: 0.7935, validation loss: 0.9152
2024-05-22 22:36:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch35_loss0.9152411818504333.pypots
2024-05-22 22:36:27 [INFO]: Epoch 036 - training loss: 0.8058, validation loss: 0.9109
2024-05-22 22:36:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch36_loss0.9108923226594925.pypots
2024-05-22 22:36:27 [INFO]: Epoch 037 - training loss: 0.8074, validation loss: 0.9104
2024-05-22 22:36:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch37_loss0.9104076623916626.pypots
2024-05-22 22:36:28 [INFO]: Epoch 038 - training loss: 0.7887, validation loss: 0.9068
2024-05-22 22:36:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch38_loss0.9067987948656082.pypots
2024-05-22 22:36:28 [INFO]: Epoch 039 - training loss: 0.7735, validation loss: 0.9050
2024-05-22 22:36:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch39_loss0.9049727320671082.pypots
2024-05-22 22:36:28 [INFO]: Epoch 040 - training loss: 0.7921, validation loss: 0.9027
2024-05-22 22:36:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch40_loss0.9027208834886551.pypots
2024-05-22 22:36:28 [INFO]: Epoch 041 - training loss: 0.7796, validation loss: 0.9014
2024-05-22 22:36:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch41_loss0.9014455080032349.pypots
2024-05-22 22:36:28 [INFO]: Epoch 042 - training loss: 0.7912, validation loss: 0.8997
2024-05-22 22:36:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch42_loss0.8996713161468506.pypots
2024-05-22 22:36:28 [INFO]: Epoch 043 - training loss: 0.7929, validation loss: 0.8971
2024-05-22 22:36:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch43_loss0.8971093595027924.pypots
2024-05-22 22:36:29 [INFO]: Epoch 044 - training loss: 0.8006, validation loss: 0.8951
2024-05-22 22:36:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch44_loss0.8950950056314468.pypots
2024-05-22 22:36:29 [INFO]: Epoch 045 - training loss: 0.8046, validation loss: 0.8901
2024-05-22 22:36:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch45_loss0.8901068419218063.pypots
2024-05-22 22:36:29 [INFO]: Epoch 046 - training loss: 0.7721, validation loss: 0.8879
2024-05-22 22:36:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch46_loss0.88788902759552.pypots
2024-05-22 22:36:29 [INFO]: Epoch 047 - training loss: 0.8113, validation loss: 0.8928
2024-05-22 22:36:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch47_loss0.8927711546421051.pypots
2024-05-22 22:36:29 [INFO]: Epoch 048 - training loss: 0.8134, validation loss: 0.8891
2024-05-22 22:36:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch48_loss0.889123946428299.pypots
2024-05-22 22:36:30 [INFO]: Epoch 049 - training loss: 0.7951, validation loss: 0.8863
2024-05-22 22:36:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch49_loss0.8862685859203339.pypots
2024-05-22 22:36:31 [INFO]: Epoch 050 - training loss: 0.7817, validation loss: 0.8837
2024-05-22 22:36:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch50_loss0.8837029933929443.pypots
2024-05-22 22:36:31 [INFO]: Epoch 051 - training loss: 0.7662, validation loss: 0.8855
2024-05-22 22:36:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch51_loss0.885502278804779.pypots
2024-05-22 22:36:31 [INFO]: Epoch 052 - training loss: 0.7793, validation loss: 0.8823
2024-05-22 22:36:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch52_loss0.8822849690914154.pypots
2024-05-22 22:36:31 [INFO]: Epoch 053 - training loss: 0.8119, validation loss: 0.8793
2024-05-22 22:36:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch53_loss0.8792960196733475.pypots
2024-05-22 22:36:31 [INFO]: Epoch 054 - training loss: 0.7868, validation loss: 0.8768
2024-05-22 22:36:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch54_loss0.8767909705638885.pypots
2024-05-22 22:36:31 [INFO]: Epoch 055 - training loss: 0.7905, validation loss: 0.8755
2024-05-22 22:36:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch55_loss0.8755290359258652.pypots
2024-05-22 22:36:31 [INFO]: Epoch 056 - training loss: 0.7687, validation loss: 0.8746
2024-05-22 22:36:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch56_loss0.87462018430233.pypots
2024-05-22 22:36:32 [INFO]: Epoch 057 - training loss: 0.7844, validation loss: 0.8734
2024-05-22 22:36:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch57_loss0.8733625262975693.pypots
2024-05-22 22:36:32 [INFO]: Epoch 058 - training loss: 0.7798, validation loss: 0.8721
2024-05-22 22:36:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch58_loss0.8721347451210022.pypots
2024-05-22 22:36:32 [INFO]: Epoch 059 - training loss: 0.7727, validation loss: 0.8715
2024-05-22 22:36:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch59_loss0.8714660853147507.pypots
2024-05-22 22:36:32 [INFO]: Epoch 060 - training loss: 0.7838, validation loss: 0.8674
2024-05-22 22:36:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch60_loss0.8673523366451263.pypots
2024-05-22 22:36:32 [INFO]: Epoch 061 - training loss: 0.7805, validation loss: 0.8705
2024-05-22 22:36:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch61_loss0.8704895228147507.pypots
2024-05-22 22:36:32 [INFO]: Epoch 062 - training loss: 0.7915, validation loss: 0.8694
2024-05-22 22:36:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch62_loss0.869370698928833.pypots
2024-05-22 22:36:33 [INFO]: Epoch 063 - training loss: 0.7840, validation loss: 0.8659
2024-05-22 22:36:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch63_loss0.8658937215805054.pypots
2024-05-22 22:36:33 [INFO]: Epoch 064 - training loss: 0.7647, validation loss: 0.8705
2024-05-22 22:36:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch64_loss0.8705218434333801.pypots
2024-05-22 22:36:33 [INFO]: Epoch 065 - training loss: 0.7994, validation loss: 0.8659
2024-05-22 22:36:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch65_loss0.8659282922744751.pypots
2024-05-22 22:36:33 [INFO]: Epoch 066 - training loss: 0.8102, validation loss: 0.8644
2024-05-22 22:36:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch66_loss0.8644113689661026.pypots
2024-05-22 22:36:33 [INFO]: Epoch 067 - training loss: 0.7854, validation loss: 0.8668
2024-05-22 22:36:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch67_loss0.866801843047142.pypots
2024-05-22 22:36:33 [INFO]: Epoch 068 - training loss: 0.7706, validation loss: 0.8659
2024-05-22 22:36:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch68_loss0.8658686131238937.pypots
2024-05-22 22:36:33 [INFO]: Epoch 069 - training loss: 0.7786, validation loss: 0.8652
2024-05-22 22:36:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch69_loss0.8651938587427139.pypots
2024-05-22 22:36:34 [INFO]: Epoch 070 - training loss: 0.7556, validation loss: 0.8636
2024-05-22 22:36:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch70_loss0.8635872602462769.pypots
2024-05-22 22:36:34 [INFO]: Epoch 071 - training loss: 0.7646, validation loss: 0.8622
2024-05-22 22:36:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch71_loss0.8621952086687088.pypots
2024-05-22 22:36:34 [INFO]: Epoch 072 - training loss: 0.7770, validation loss: 0.8609
2024-05-22 22:36:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch72_loss0.8609463721513748.pypots
2024-05-22 22:36:34 [INFO]: Epoch 073 - training loss: 0.7530, validation loss: 0.8620
2024-05-22 22:36:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch73_loss0.8620321750640869.pypots
2024-05-22 22:36:34 [INFO]: Epoch 074 - training loss: 0.7750, validation loss: 0.8622
2024-05-22 22:36:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch74_loss0.8621994256973267.pypots
2024-05-22 22:36:34 [INFO]: Epoch 075 - training loss: 0.7896, validation loss: 0.8612
2024-05-22 22:36:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch75_loss0.8612124472856522.pypots
2024-05-22 22:36:35 [INFO]: Epoch 076 - training loss: 0.7870, validation loss: 0.8615
2024-05-22 22:36:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch76_loss0.8614547103643417.pypots
2024-05-22 22:36:35 [INFO]: Epoch 077 - training loss: 0.7754, validation loss: 0.8565
2024-05-22 22:36:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch77_loss0.856513649225235.pypots
2024-05-22 22:36:35 [INFO]: Epoch 078 - training loss: 0.8173, validation loss: 0.8613
2024-05-22 22:36:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch78_loss0.8613429814577103.pypots
2024-05-22 22:36:35 [INFO]: Epoch 079 - training loss: 0.7835, validation loss: 0.8632
2024-05-22 22:36:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch79_loss0.863224446773529.pypots
2024-05-22 22:36:35 [INFO]: Epoch 080 - training loss: 0.7608, validation loss: 0.8599
2024-05-22 22:36:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch80_loss0.859879806637764.pypots
2024-05-22 22:36:35 [INFO]: Epoch 081 - training loss: 0.7678, validation loss: 0.8572
2024-05-22 22:36:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch81_loss0.8572379648685455.pypots
2024-05-22 22:36:36 [INFO]: Epoch 082 - training loss: 0.7592, validation loss: 0.8579
2024-05-22 22:36:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch82_loss0.8578812777996063.pypots
2024-05-22 22:36:36 [INFO]: Epoch 083 - training loss: 0.8053, validation loss: 0.8567
2024-05-22 22:36:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch83_loss0.8567357510328293.pypots
2024-05-22 22:36:36 [INFO]: Epoch 084 - training loss: 0.7737, validation loss: 0.8562
2024-05-22 22:36:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch84_loss0.8562138974666595.pypots
2024-05-22 22:36:36 [INFO]: Epoch 085 - training loss: 0.7831, validation loss: 0.8571
2024-05-22 22:36:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch85_loss0.8570602238178253.pypots
2024-05-22 22:36:36 [INFO]: Epoch 086 - training loss: 0.7535, validation loss: 0.8549
2024-05-22 22:36:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch86_loss0.8549382537603378.pypots
2024-05-22 22:36:36 [INFO]: Epoch 087 - training loss: 0.7603, validation loss: 0.8544
2024-05-22 22:36:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch87_loss0.8544429391622543.pypots
2024-05-22 22:36:37 [INFO]: Epoch 088 - training loss: 0.7735, validation loss: 0.8525
2024-05-22 22:36:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch88_loss0.852475568652153.pypots
2024-05-22 22:36:37 [INFO]: Epoch 089 - training loss: 0.7564, validation loss: 0.8550
2024-05-22 22:36:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch89_loss0.855005294084549.pypots
2024-05-22 22:36:37 [INFO]: Epoch 090 - training loss: 0.7810, validation loss: 0.8549
2024-05-22 22:36:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch90_loss0.8548528254032135.pypots
2024-05-22 22:36:37 [INFO]: Epoch 091 - training loss: 0.7688, validation loss: 0.8550
2024-05-22 22:36:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch91_loss0.8550063073635101.pypots
2024-05-22 22:36:37 [INFO]: Epoch 092 - training loss: 0.8014, validation loss: 0.8543
2024-05-22 22:36:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch92_loss0.8543425649404526.pypots
2024-05-22 22:36:37 [INFO]: Epoch 093 - training loss: 0.7627, validation loss: 0.8515
2024-05-22 22:36:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch93_loss0.8515077531337738.pypots
2024-05-22 22:36:37 [INFO]: Epoch 094 - training loss: 0.7976, validation loss: 0.8540
2024-05-22 22:36:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch94_loss0.8539620339870453.pypots
2024-05-22 22:36:38 [INFO]: Epoch 095 - training loss: 0.7633, validation loss: 0.8540
2024-05-22 22:36:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch95_loss0.8540134131908417.pypots
2024-05-22 22:36:38 [INFO]: Epoch 096 - training loss: 0.7861, validation loss: 0.8531
2024-05-22 22:36:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch96_loss0.8531170636415482.pypots
2024-05-22 22:36:38 [INFO]: Epoch 097 - training loss: 0.7805, validation loss: 0.8537
2024-05-22 22:36:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch97_loss0.8536618202924728.pypots
2024-05-22 22:36:38 [INFO]: Epoch 098 - training loss: 0.7826, validation loss: 0.8509
2024-05-22 22:36:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch98_loss0.8509176969528198.pypots
2024-05-22 22:36:38 [INFO]: Epoch 099 - training loss: 0.7620, validation loss: 0.8509
2024-05-22 22:36:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch99_loss0.850871816277504.pypots
2024-05-22 22:36:38 [INFO]: Epoch 100 - training loss: 0.7691, validation loss: 0.8496
2024-05-22 22:36:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch100_loss0.8495640307664871.pypots
2024-05-22 22:36:39 [INFO]: Epoch 101 - training loss: 0.7598, validation loss: 0.8504
2024-05-22 22:36:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch101_loss0.850444421172142.pypots
2024-05-22 22:36:39 [INFO]: Epoch 102 - training loss: 0.7759, validation loss: 0.8504
2024-05-22 22:36:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch102_loss0.85035540163517.pypots
2024-05-22 22:36:39 [INFO]: Epoch 103 - training loss: 0.7655, validation loss: 0.8523
2024-05-22 22:36:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch103_loss0.8523131012916565.pypots
2024-05-22 22:36:39 [INFO]: Epoch 104 - training loss: 0.7696, validation loss: 0.8494
2024-05-22 22:36:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch104_loss0.8493725806474686.pypots
2024-05-22 22:36:39 [INFO]: Epoch 105 - training loss: 0.7448, validation loss: 0.8486
2024-05-22 22:36:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch105_loss0.8485576510429382.pypots
2024-05-22 22:36:40 [INFO]: Epoch 106 - training loss: 0.7955, validation loss: 0.8504
2024-05-22 22:36:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch106_loss0.8504463583230972.pypots
2024-05-22 22:36:40 [INFO]: Epoch 107 - training loss: 0.7641, validation loss: 0.8481
2024-05-22 22:36:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch107_loss0.8481461256742477.pypots
2024-05-22 22:36:40 [INFO]: Epoch 108 - training loss: 0.7662, validation loss: 0.8481
2024-05-22 22:36:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch108_loss0.8480507582426071.pypots
2024-05-22 22:36:40 [INFO]: Epoch 109 - training loss: 0.8122, validation loss: 0.8486
2024-05-22 22:36:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch109_loss0.8486129641532898.pypots
2024-05-22 22:36:41 [INFO]: Epoch 110 - training loss: 0.7659, validation loss: 0.8469
2024-05-22 22:36:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch110_loss0.8469113111495972.pypots
2024-05-22 22:36:41 [INFO]: Epoch 111 - training loss: 0.7419, validation loss: 0.8452
2024-05-22 22:36:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch111_loss0.8452020436525345.pypots
2024-05-22 22:36:41 [INFO]: Epoch 112 - training loss: 0.7603, validation loss: 0.8461
2024-05-22 22:36:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch112_loss0.8460841327905655.pypots
2024-05-22 22:36:41 [INFO]: Epoch 113 - training loss: 0.8155, validation loss: 0.8466
2024-05-22 22:36:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch113_loss0.8465913534164429.pypots
2024-05-22 22:36:41 [INFO]: Epoch 114 - training loss: 0.7724, validation loss: 0.8437
2024-05-22 22:36:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch114_loss0.843679890036583.pypots
2024-05-22 22:36:42 [INFO]: Epoch 115 - training loss: 0.7516, validation loss: 0.8447
2024-05-22 22:36:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch115_loss0.8446927666664124.pypots
2024-05-22 22:36:42 [INFO]: Epoch 116 - training loss: 0.7462, validation loss: 0.8437
2024-05-22 22:36:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch116_loss0.8437282890081406.pypots
2024-05-22 22:36:42 [INFO]: Epoch 117 - training loss: 0.7672, validation loss: 0.8443
2024-05-22 22:36:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch117_loss0.8443337380886078.pypots
2024-05-22 22:36:42 [INFO]: Epoch 118 - training loss: 0.7529, validation loss: 0.8413
2024-05-22 22:36:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch118_loss0.8412939012050629.pypots
2024-05-22 22:36:42 [INFO]: Epoch 119 - training loss: 0.7567, validation loss: 0.8458
2024-05-22 22:36:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch119_loss0.8458271771669388.pypots
2024-05-22 22:36:42 [INFO]: Epoch 120 - training loss: 0.7655, validation loss: 0.8424
2024-05-22 22:36:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch120_loss0.8424438834190369.pypots
2024-05-22 22:36:42 [INFO]: Epoch 121 - training loss: 0.7745, validation loss: 0.8417
2024-05-22 22:36:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch121_loss0.8416996896266937.pypots
2024-05-22 22:36:43 [INFO]: Epoch 122 - training loss: 0.7693, validation loss: 0.8426
2024-05-22 22:36:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch122_loss0.8425871282815933.pypots
2024-05-22 22:36:43 [INFO]: Epoch 123 - training loss: 0.7654, validation loss: 0.8424
2024-05-22 22:36:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch123_loss0.8423662036657333.pypots
2024-05-22 22:36:43 [INFO]: Epoch 124 - training loss: 0.7544, validation loss: 0.8416
2024-05-22 22:36:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch124_loss0.841627836227417.pypots
2024-05-22 22:36:43 [INFO]: Epoch 125 - training loss: 0.7777, validation loss: 0.8421
2024-05-22 22:36:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch125_loss0.8420577198266983.pypots
2024-05-22 22:36:43 [INFO]: Epoch 126 - training loss: 0.7801, validation loss: 0.8397
2024-05-22 22:36:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch126_loss0.8397122174501419.pypots
2024-05-22 22:36:43 [INFO]: Epoch 127 - training loss: 0.7778, validation loss: 0.8415
2024-05-22 22:36:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch127_loss0.8414989113807678.pypots
2024-05-22 22:36:44 [INFO]: Epoch 128 - training loss: 0.7777, validation loss: 0.8366
2024-05-22 22:36:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch128_loss0.836554691195488.pypots
2024-05-22 22:36:44 [INFO]: Epoch 129 - training loss: 0.7769, validation loss: 0.8382
2024-05-22 22:36:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch129_loss0.8381974697113037.pypots
2024-05-22 22:36:44 [INFO]: Epoch 130 - training loss: 0.7648, validation loss: 0.8418
2024-05-22 22:36:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch130_loss0.8417844176292419.pypots
2024-05-22 22:36:44 [INFO]: Epoch 131 - training loss: 0.7701, validation loss: 0.8400
2024-05-22 22:36:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch131_loss0.8400306552648544.pypots
2024-05-22 22:36:44 [INFO]: Epoch 132 - training loss: 0.7423, validation loss: 0.8370
2024-05-22 22:36:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch132_loss0.8369690179824829.pypots
2024-05-22 22:36:44 [INFO]: Epoch 133 - training loss: 0.7603, validation loss: 0.8389
2024-05-22 22:36:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch133_loss0.838888868689537.pypots
2024-05-22 22:36:44 [INFO]: Epoch 134 - training loss: 0.7546, validation loss: 0.8387
2024-05-22 22:36:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch134_loss0.8387240469455719.pypots
2024-05-22 22:36:45 [INFO]: Epoch 135 - training loss: 0.7749, validation loss: 0.8389
2024-05-22 22:36:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch135_loss0.8388671427965164.pypots
2024-05-22 22:36:45 [INFO]: Epoch 136 - training loss: 0.7622, validation loss: 0.8372
2024-05-22 22:36:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch136_loss0.8371818214654922.pypots
2024-05-22 22:36:45 [INFO]: Epoch 137 - training loss: 0.7609, validation loss: 0.8379
2024-05-22 22:36:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch137_loss0.8379085063934326.pypots
2024-05-22 22:36:45 [INFO]: Epoch 138 - training loss: 0.7866, validation loss: 0.8370
2024-05-22 22:36:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN_epoch138_loss0.8369881510734558.pypots
2024-05-22 22:36:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:36:45 [INFO]: Finished training. The best model is from epoch#128.
2024-05-22 22:36:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240522_T223620/MRNN.pypots
2024-05-22 22:36:45 [INFO]: MRNN on ETTm1: MAE=0.6623, MSE=1.0911
2024-05-22 22:36:45 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/MRNN_ettm1/imputation.pkl
2024-05-22 22:36:45 [INFO]: Using the given device: cpu
2024-05-22 22:36:45 [INFO]: LOCF on ETTm1: MAE=0.1376, MSE=0.0773
2024-05-22 22:36:45 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_ettm1".
2024-05-22 22:36:45 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/LOCF_ettm1/imputation.pkl
2024-05-22 22:36:45 [INFO]: Median on ETTm1: MAE=0.6554, MSE=0.8235
2024-05-22 22:36:45 [INFO]: Successfully created the given path "saved_results/round_3/Median_ettm1".
2024-05-22 22:36:45 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Median_ettm1/imputation.pkl
2024-05-22 22:36:45 [INFO]: Mean on ETTm1: MAE=0.6609, MSE=0.8067
2024-05-22 22:36:45 [INFO]: Successfully created the given path "saved_results/round_3/Mean_ettm1".
2024-05-22 22:36:45 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Mean_ettm1/imputation.pkl
2024-05-22 22:36:45 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-22 22:36:45 [INFO]: Using the given device: cuda:0
2024-05-22 22:36:45 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/SAITS_ettm1/20240522_T223645
2024-05-22 22:36:45 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/SAITS_ettm1/20240522_T223645/tensorboard
2024-05-22 22:36:46 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 22:36:46 [INFO]: Epoch 001 - training loss: 1.1423, validation loss: 0.2389
2024-05-22 22:36:47 [INFO]: Epoch 002 - training loss: 0.8563, validation loss: 0.1628
2024-05-22 22:36:47 [INFO]: Epoch 003 - training loss: 0.7864, validation loss: 0.1026
2024-05-22 22:36:48 [INFO]: Epoch 004 - training loss: 0.7342, validation loss: 0.1100
2024-05-22 22:36:48 [INFO]: Epoch 005 - training loss: 0.7240, validation loss: 0.0814
2024-05-22 22:36:48 [INFO]: Epoch 006 - training loss: 0.6941, validation loss: 0.0802
2024-05-22 22:36:49 [INFO]: Epoch 007 - training loss: 0.6587, validation loss: 0.0715
2024-05-22 22:36:49 [INFO]: Epoch 008 - training loss: 0.6450, validation loss: 0.0663
2024-05-22 22:36:50 [INFO]: Epoch 009 - training loss: 0.6296, validation loss: 0.0654
2024-05-22 22:36:50 [INFO]: Epoch 010 - training loss: 0.6100, validation loss: 0.0553
2024-05-22 22:36:51 [INFO]: Epoch 011 - training loss: 0.6091, validation loss: 0.0608
2024-05-22 22:36:51 [INFO]: Epoch 012 - training loss: 0.6011, validation loss: 0.0658
2024-05-22 22:36:52 [INFO]: Epoch 013 - training loss: 0.5910, validation loss: 0.0649
2024-05-22 22:36:52 [INFO]: Epoch 014 - training loss: 0.5855, validation loss: 0.0469
2024-05-22 22:36:53 [INFO]: Epoch 015 - training loss: 0.6005, validation loss: 0.0516
2024-05-22 22:36:53 [INFO]: Epoch 016 - training loss: 0.5663, validation loss: 0.0493
2024-05-22 22:36:54 [INFO]: Epoch 017 - training loss: 0.5773, validation loss: 0.0588
2024-05-22 22:36:54 [INFO]: Epoch 018 - training loss: 0.5760, validation loss: 0.0541
2024-05-22 22:36:55 [INFO]: Epoch 019 - training loss: 0.5510, validation loss: 0.0565
2024-05-22 22:36:55 [INFO]: Epoch 020 - training loss: 0.5441, validation loss: 0.0588
2024-05-22 22:36:56 [INFO]: Epoch 021 - training loss: 0.5468, validation loss: 0.0447
2024-05-22 22:36:56 [INFO]: Epoch 022 - training loss: 0.5451, validation loss: 0.0459
2024-05-22 22:36:57 [INFO]: Epoch 023 - training loss: 0.5398, validation loss: 0.0544
2024-05-22 22:36:57 [INFO]: Epoch 024 - training loss: 0.5387, validation loss: 0.0403
2024-05-22 22:36:58 [INFO]: Epoch 025 - training loss: 0.5275, validation loss: 0.0449
2024-05-22 22:36:58 [INFO]: Epoch 026 - training loss: 0.5150, validation loss: 0.0566
2024-05-22 22:36:59 [INFO]: Epoch 027 - training loss: 0.5186, validation loss: 0.0415
2024-05-22 22:36:59 [INFO]: Epoch 028 - training loss: 0.5455, validation loss: 0.0416
2024-05-22 22:36:59 [INFO]: Epoch 029 - training loss: 0.5217, validation loss: 0.0442
2024-05-22 22:37:00 [INFO]: Epoch 030 - training loss: 0.5032, validation loss: 0.0428
2024-05-22 22:37:00 [INFO]: Epoch 031 - training loss: 0.4997, validation loss: 0.0500
2024-05-22 22:37:01 [INFO]: Epoch 032 - training loss: 0.4972, validation loss: 0.0486
2024-05-22 22:37:01 [INFO]: Epoch 033 - training loss: 0.5043, validation loss: 0.0469
2024-05-22 22:37:02 [INFO]: Epoch 034 - training loss: 0.5154, validation loss: 0.0423
2024-05-22 22:37:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:37:02 [INFO]: Finished training. The best model is from epoch#24.
2024-05-22 22:37:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/SAITS_ettm1/20240522_T223645/SAITS.pypots
2024-05-22 22:37:02 [INFO]: SAITS on ETTm1: MAE=0.1667, MSE=0.0579
2024-05-22 22:37:02 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/SAITS_ettm1/imputation.pkl
2024-05-22 22:37:02 [INFO]: Using the given device: cuda:0
2024-05-22 22:37:02 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/Transformer_ettm1/20240522_T223702
2024-05-22 22:37:02 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/Transformer_ettm1/20240522_T223702/tensorboard
2024-05-22 22:37:02 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 22:37:03 [INFO]: Epoch 001 - training loss: 1.1633, validation loss: 0.3036
2024-05-22 22:37:03 [INFO]: Epoch 002 - training loss: 0.6616, validation loss: 0.1434
2024-05-22 22:37:03 [INFO]: Epoch 003 - training loss: 0.5336, validation loss: 0.1119
2024-05-22 22:37:03 [INFO]: Epoch 004 - training loss: 0.4757, validation loss: 0.0923
2024-05-22 22:37:03 [INFO]: Epoch 005 - training loss: 0.4483, validation loss: 0.0782
2024-05-22 22:37:04 [INFO]: Epoch 006 - training loss: 0.4197, validation loss: 0.0747
2024-05-22 22:37:04 [INFO]: Epoch 007 - training loss: 0.4037, validation loss: 0.0659
2024-05-22 22:37:04 [INFO]: Epoch 008 - training loss: 0.3866, validation loss: 0.0668
2024-05-22 22:37:04 [INFO]: Epoch 009 - training loss: 0.3819, validation loss: 0.0626
2024-05-22 22:37:04 [INFO]: Epoch 010 - training loss: 0.3674, validation loss: 0.0562
2024-05-22 22:37:04 [INFO]: Epoch 011 - training loss: 0.3594, validation loss: 0.0569
2024-05-22 22:37:05 [INFO]: Epoch 012 - training loss: 0.3548, validation loss: 0.0574
2024-05-22 22:37:05 [INFO]: Epoch 013 - training loss: 0.3445, validation loss: 0.0529
2024-05-22 22:37:05 [INFO]: Epoch 014 - training loss: 0.3380, validation loss: 0.0536
2024-05-22 22:37:05 [INFO]: Epoch 015 - training loss: 0.3347, validation loss: 0.0482
2024-05-22 22:37:05 [INFO]: Epoch 016 - training loss: 0.3211, validation loss: 0.0455
2024-05-22 22:37:06 [INFO]: Epoch 017 - training loss: 0.3158, validation loss: 0.0455
2024-05-22 22:37:06 [INFO]: Epoch 018 - training loss: 0.3126, validation loss: 0.0440
2024-05-22 22:37:06 [INFO]: Epoch 019 - training loss: 0.3046, validation loss: 0.0468
2024-05-22 22:37:06 [INFO]: Epoch 020 - training loss: 0.3050, validation loss: 0.0436
2024-05-22 22:37:06 [INFO]: Epoch 021 - training loss: 0.3029, validation loss: 0.0423
2024-05-22 22:37:07 [INFO]: Epoch 022 - training loss: 0.2914, validation loss: 0.0442
2024-05-22 22:37:07 [INFO]: Epoch 023 - training loss: 0.3134, validation loss: 0.0404
2024-05-22 22:37:07 [INFO]: Epoch 024 - training loss: 0.2926, validation loss: 0.0416
2024-05-22 22:37:07 [INFO]: Epoch 025 - training loss: 0.2829, validation loss: 0.0394
2024-05-22 22:37:07 [INFO]: Epoch 026 - training loss: 0.2827, validation loss: 0.0381
2024-05-22 22:37:07 [INFO]: Epoch 027 - training loss: 0.2760, validation loss: 0.0373
2024-05-22 22:37:08 [INFO]: Epoch 028 - training loss: 0.2686, validation loss: 0.0367
2024-05-22 22:37:08 [INFO]: Epoch 029 - training loss: 0.2692, validation loss: 0.0390
2024-05-22 22:37:08 [INFO]: Epoch 030 - training loss: 0.2677, validation loss: 0.0370
2024-05-22 22:37:08 [INFO]: Epoch 031 - training loss: 0.2641, validation loss: 0.0354
2024-05-22 22:37:08 [INFO]: Epoch 032 - training loss: 0.2622, validation loss: 0.0352
2024-05-22 22:37:09 [INFO]: Epoch 033 - training loss: 0.2614, validation loss: 0.0383
2024-05-22 22:37:09 [INFO]: Epoch 034 - training loss: 0.2590, validation loss: 0.0341
2024-05-22 22:37:09 [INFO]: Epoch 035 - training loss: 0.2505, validation loss: 0.0344
2024-05-22 22:37:09 [INFO]: Epoch 036 - training loss: 0.2512, validation loss: 0.0326
2024-05-22 22:37:09 [INFO]: Epoch 037 - training loss: 0.2455, validation loss: 0.0371
2024-05-22 22:37:10 [INFO]: Epoch 038 - training loss: 0.2537, validation loss: 0.0337
2024-05-22 22:37:10 [INFO]: Epoch 039 - training loss: 0.2404, validation loss: 0.0326
2024-05-22 22:37:10 [INFO]: Epoch 040 - training loss: 0.2455, validation loss: 0.0352
2024-05-22 22:37:10 [INFO]: Epoch 041 - training loss: 0.2574, validation loss: 0.0363
2024-05-22 22:37:10 [INFO]: Epoch 042 - training loss: 0.2491, validation loss: 0.0313
2024-05-22 22:37:10 [INFO]: Epoch 043 - training loss: 0.2330, validation loss: 0.0309
2024-05-22 22:37:11 [INFO]: Epoch 044 - training loss: 0.2326, validation loss: 0.0319
2024-05-22 22:37:11 [INFO]: Epoch 045 - training loss: 0.2275, validation loss: 0.0316
2024-05-22 22:37:11 [INFO]: Epoch 046 - training loss: 0.2342, validation loss: 0.0306
2024-05-22 22:37:11 [INFO]: Epoch 047 - training loss: 0.2277, validation loss: 0.0313
2024-05-22 22:37:11 [INFO]: Epoch 048 - training loss: 0.2288, validation loss: 0.0316
2024-05-22 22:37:12 [INFO]: Epoch 049 - training loss: 0.2229, validation loss: 0.0308
2024-05-22 22:37:12 [INFO]: Epoch 050 - training loss: 0.2209, validation loss: 0.0325
2024-05-22 22:37:12 [INFO]: Epoch 051 - training loss: 0.2312, validation loss: 0.0348
2024-05-22 22:37:12 [INFO]: Epoch 052 - training loss: 0.2308, validation loss: 0.0300
2024-05-22 22:37:12 [INFO]: Epoch 053 - training loss: 0.2194, validation loss: 0.0292
2024-05-22 22:37:13 [INFO]: Epoch 054 - training loss: 0.2160, validation loss: 0.0283
2024-05-22 22:37:13 [INFO]: Epoch 055 - training loss: 0.2186, validation loss: 0.0285
2024-05-22 22:37:13 [INFO]: Epoch 056 - training loss: 0.2167, validation loss: 0.0306
2024-05-22 22:37:13 [INFO]: Epoch 057 - training loss: 0.2155, validation loss: 0.0283
2024-05-22 22:37:13 [INFO]: Epoch 058 - training loss: 0.2145, validation loss: 0.0291
2024-05-22 22:37:13 [INFO]: Epoch 059 - training loss: 0.2123, validation loss: 0.0293
2024-05-22 22:37:14 [INFO]: Epoch 060 - training loss: 0.2109, validation loss: 0.0281
2024-05-22 22:37:14 [INFO]: Epoch 061 - training loss: 0.2075, validation loss: 0.0311
2024-05-22 22:37:14 [INFO]: Epoch 062 - training loss: 0.2164, validation loss: 0.0296
2024-05-22 22:37:14 [INFO]: Epoch 063 - training loss: 0.2110, validation loss: 0.0315
2024-05-22 22:37:14 [INFO]: Epoch 064 - training loss: 0.2100, validation loss: 0.0268
2024-05-22 22:37:15 [INFO]: Epoch 065 - training loss: 0.2045, validation loss: 0.0270
2024-05-22 22:37:15 [INFO]: Epoch 066 - training loss: 0.2039, validation loss: 0.0265
2024-05-22 22:37:15 [INFO]: Epoch 067 - training loss: 0.2007, validation loss: 0.0277
2024-05-22 22:37:15 [INFO]: Epoch 068 - training loss: 0.2045, validation loss: 0.0288
2024-05-22 22:37:15 [INFO]: Epoch 069 - training loss: 0.2042, validation loss: 0.0263
2024-05-22 22:37:16 [INFO]: Epoch 070 - training loss: 0.1984, validation loss: 0.0301
2024-05-22 22:37:16 [INFO]: Epoch 071 - training loss: 0.2105, validation loss: 0.0274
2024-05-22 22:37:16 [INFO]: Epoch 072 - training loss: 0.1991, validation loss: 0.0258
2024-05-22 22:37:16 [INFO]: Epoch 073 - training loss: 0.1950, validation loss: 0.0274
2024-05-22 22:37:16 [INFO]: Epoch 074 - training loss: 0.1985, validation loss: 0.0270
2024-05-22 22:37:16 [INFO]: Epoch 075 - training loss: 0.1953, validation loss: 0.0276
2024-05-22 22:37:17 [INFO]: Epoch 076 - training loss: 0.1963, validation loss: 0.0263
2024-05-22 22:37:17 [INFO]: Epoch 077 - training loss: 0.1950, validation loss: 0.0266
2024-05-22 22:37:17 [INFO]: Epoch 078 - training loss: 0.1995, validation loss: 0.0299
2024-05-22 22:37:17 [INFO]: Epoch 079 - training loss: 0.1987, validation loss: 0.0254
2024-05-22 22:37:17 [INFO]: Epoch 080 - training loss: 0.1898, validation loss: 0.0282
2024-05-22 22:37:18 [INFO]: Epoch 081 - training loss: 0.1959, validation loss: 0.0249
2024-05-22 22:37:18 [INFO]: Epoch 082 - training loss: 0.1895, validation loss: 0.0261
2024-05-22 22:37:18 [INFO]: Epoch 083 - training loss: 0.1931, validation loss: 0.0248
2024-05-22 22:37:18 [INFO]: Epoch 084 - training loss: 0.1867, validation loss: 0.0249
2024-05-22 22:37:18 [INFO]: Epoch 085 - training loss: 0.1903, validation loss: 0.0243
2024-05-22 22:37:19 [INFO]: Epoch 086 - training loss: 0.1878, validation loss: 0.0252
2024-05-22 22:37:19 [INFO]: Epoch 087 - training loss: 0.1956, validation loss: 0.0302
2024-05-22 22:37:19 [INFO]: Epoch 088 - training loss: 0.2167, validation loss: 0.0249
2024-05-22 22:37:19 [INFO]: Epoch 089 - training loss: 0.1932, validation loss: 0.0251
2024-05-22 22:37:19 [INFO]: Epoch 090 - training loss: 0.1903, validation loss: 0.0247
2024-05-22 22:37:19 [INFO]: Epoch 091 - training loss: 0.1882, validation loss: 0.0248
2024-05-22 22:37:20 [INFO]: Epoch 092 - training loss: 0.1865, validation loss: 0.0235
2024-05-22 22:37:20 [INFO]: Epoch 093 - training loss: 0.1827, validation loss: 0.0245
2024-05-22 22:37:20 [INFO]: Epoch 094 - training loss: 0.1830, validation loss: 0.0275
2024-05-22 22:37:20 [INFO]: Epoch 095 - training loss: 0.1843, validation loss: 0.0230
2024-05-22 22:37:20 [INFO]: Epoch 096 - training loss: 0.1816, validation loss: 0.0226
2024-05-22 22:37:21 [INFO]: Epoch 097 - training loss: 0.1795, validation loss: 0.0266
2024-05-22 22:37:21 [INFO]: Epoch 098 - training loss: 0.1855, validation loss: 0.0237
2024-05-22 22:37:21 [INFO]: Epoch 099 - training loss: 0.1788, validation loss: 0.0227
2024-05-22 22:37:21 [INFO]: Epoch 100 - training loss: 0.1801, validation loss: 0.0231
2024-05-22 22:37:21 [INFO]: Epoch 101 - training loss: 0.1815, validation loss: 0.0242
2024-05-22 22:37:22 [INFO]: Epoch 102 - training loss: 0.1852, validation loss: 0.0242
2024-05-22 22:37:22 [INFO]: Epoch 103 - training loss: 0.1796, validation loss: 0.0256
2024-05-22 22:37:22 [INFO]: Epoch 104 - training loss: 0.1934, validation loss: 0.0273
2024-05-22 22:37:22 [INFO]: Epoch 105 - training loss: 0.1886, validation loss: 0.0265
2024-05-22 22:37:22 [INFO]: Epoch 106 - training loss: 0.1815, validation loss: 0.0235
2024-05-22 22:37:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:37:22 [INFO]: Finished training. The best model is from epoch#96.
2024-05-22 22:37:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/Transformer_ettm1/20240522_T223702/Transformer.pypots
2024-05-22 22:37:22 [INFO]: Transformer on ETTm1: MAE=0.1256, MSE=0.0340
2024-05-22 22:37:22 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Transformer_ettm1/imputation.pkl
2024-05-22 22:37:22 [INFO]: Using the given device: cuda:0
2024-05-22 22:37:22 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/TimesNet_ettm1/20240522_T223722
2024-05-22 22:37:22 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/TimesNet_ettm1/20240522_T223722/tensorboard
2024-05-22 22:37:23 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 22:37:23 [INFO]: Epoch 001 - training loss: 0.1766, validation loss: 0.0591
2024-05-22 22:37:23 [INFO]: Epoch 002 - training loss: 0.0652, validation loss: 0.0425
2024-05-22 22:37:23 [INFO]: Epoch 003 - training loss: 0.0525, validation loss: 0.0384
2024-05-22 22:37:23 [INFO]: Epoch 004 - training loss: 0.0451, validation loss: 0.0322
2024-05-22 22:37:24 [INFO]: Epoch 005 - training loss: 0.0396, validation loss: 0.0304
2024-05-22 22:37:24 [INFO]: Epoch 006 - training loss: 0.0368, validation loss: 0.0293
2024-05-22 22:37:24 [INFO]: Epoch 007 - training loss: 0.0342, validation loss: 0.0295
2024-05-22 22:37:24 [INFO]: Epoch 008 - training loss: 0.0333, validation loss: 0.0295
2024-05-22 22:37:24 [INFO]: Epoch 009 - training loss: 0.0339, validation loss: 0.0279
2024-05-22 22:37:24 [INFO]: Epoch 010 - training loss: 0.0337, validation loss: 0.0279
2024-05-22 22:37:25 [INFO]: Epoch 011 - training loss: 0.0320, validation loss: 0.0272
2024-05-22 22:37:25 [INFO]: Epoch 012 - training loss: 0.0304, validation loss: 0.0268
2024-05-22 22:37:25 [INFO]: Epoch 013 - training loss: 0.0309, validation loss: 0.0276
2024-05-22 22:37:25 [INFO]: Epoch 014 - training loss: 0.0306, validation loss: 0.0268
2024-05-22 22:37:25 [INFO]: Epoch 015 - training loss: 0.0300, validation loss: 0.0257
2024-05-22 22:37:25 [INFO]: Epoch 016 - training loss: 0.0288, validation loss: 0.0259
2024-05-22 22:37:26 [INFO]: Epoch 017 - training loss: 0.0283, validation loss: 0.0253
2024-05-22 22:37:26 [INFO]: Epoch 018 - training loss: 0.0284, validation loss: 0.0264
2024-05-22 22:37:26 [INFO]: Epoch 019 - training loss: 0.0300, validation loss: 0.0288
2024-05-22 22:37:26 [INFO]: Epoch 020 - training loss: 0.0307, validation loss: 0.0274
2024-05-22 22:37:26 [INFO]: Epoch 021 - training loss: 0.0306, validation loss: 0.0273
2024-05-22 22:37:27 [INFO]: Epoch 022 - training loss: 0.0389, validation loss: 0.0270
2024-05-22 22:37:27 [INFO]: Epoch 023 - training loss: 0.0263, validation loss: 0.0268
2024-05-22 22:37:27 [INFO]: Epoch 024 - training loss: 0.0286, validation loss: 0.0257
2024-05-22 22:37:27 [INFO]: Epoch 025 - training loss: 0.0259, validation loss: 0.0259
2024-05-22 22:37:27 [INFO]: Epoch 026 - training loss: 0.0267, validation loss: 0.0256
2024-05-22 22:37:27 [INFO]: Epoch 027 - training loss: 0.0239, validation loss: 0.0254
2024-05-22 22:37:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:37:27 [INFO]: Finished training. The best model is from epoch#17.
2024-05-22 22:37:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/TimesNet_ettm1/20240522_T223722/TimesNet.pypots
2024-05-22 22:37:28 [INFO]: TimesNet on ETTm1: MAE=0.1079, MSE=0.0253
2024-05-22 22:37:28 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/TimesNet_ettm1/imputation.pkl
2024-05-22 22:37:28 [INFO]: Using the given device: cuda:0
2024-05-22 22:37:28 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728
2024-05-22 22:37:28 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/tensorboard
2024-05-22 22:37:28 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 22:37:30 [INFO]: Epoch 001 - training loss: 0.6811, validation loss: 0.4477
2024-05-22 22:37:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch1_loss0.44765714555978775.pypots
2024-05-22 22:37:32 [INFO]: Epoch 002 - training loss: 0.3694, validation loss: 0.4639
2024-05-22 22:37:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch2_loss0.46391985565423965.pypots
2024-05-22 22:37:34 [INFO]: Epoch 003 - training loss: 0.3834, validation loss: 0.3476
2024-05-22 22:37:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch3_loss0.34763117879629135.pypots
2024-05-22 22:37:36 [INFO]: Epoch 004 - training loss: 0.3879, validation loss: 0.2926
2024-05-22 22:37:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch4_loss0.2926015108823776.pypots
2024-05-22 22:37:38 [INFO]: Epoch 005 - training loss: 0.3069, validation loss: 0.2844
2024-05-22 22:37:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch5_loss0.28444280475378036.pypots
2024-05-22 22:37:40 [INFO]: Epoch 006 - training loss: 0.2715, validation loss: 0.2743
2024-05-22 22:37:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch6_loss0.2743455842137337.pypots
2024-05-22 22:37:42 [INFO]: Epoch 007 - training loss: 0.2449, validation loss: 0.2624
2024-05-22 22:37:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch7_loss0.26241636276245117.pypots
2024-05-22 22:37:44 [INFO]: Epoch 008 - training loss: 0.2364, validation loss: 0.2506
2024-05-22 22:37:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch8_loss0.2506161071360111.pypots
2024-05-22 22:37:46 [INFO]: Epoch 009 - training loss: 0.2382, validation loss: 0.2446
2024-05-22 22:37:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch9_loss0.24460351839661598.pypots
2024-05-22 22:37:48 [INFO]: Epoch 010 - training loss: 0.3232, validation loss: 0.3128
2024-05-22 22:37:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch10_loss0.3127838149666786.pypots
2024-05-22 22:37:50 [INFO]: Epoch 011 - training loss: 0.2567, validation loss: 0.2431
2024-05-22 22:37:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch11_loss0.24311841279268265.pypots
2024-05-22 22:37:52 [INFO]: Epoch 012 - training loss: 0.3090, validation loss: 0.2324
2024-05-22 22:37:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch12_loss0.23237363621592522.pypots
2024-05-22 22:37:54 [INFO]: Epoch 013 - training loss: 0.2216, validation loss: 0.2164
2024-05-22 22:37:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch13_loss0.21636538952589035.pypots
2024-05-22 22:37:56 [INFO]: Epoch 014 - training loss: 0.2122, validation loss: 0.2050
2024-05-22 22:37:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch14_loss0.2049962505698204.pypots
2024-05-22 22:37:58 [INFO]: Epoch 015 - training loss: 0.2511, validation loss: 0.2112
2024-05-22 22:37:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch15_loss0.2111835703253746.pypots
2024-05-22 22:38:00 [INFO]: Epoch 016 - training loss: 0.2072, validation loss: 0.2171
2024-05-22 22:38:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch16_loss0.21711981669068336.pypots
2024-05-22 22:38:02 [INFO]: Epoch 017 - training loss: 0.2089, validation loss: 0.1963
2024-05-22 22:38:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch17_loss0.1962769441306591.pypots
2024-05-22 22:38:04 [INFO]: Epoch 018 - training loss: 0.2052, validation loss: 0.1960
2024-05-22 22:38:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch18_loss0.19595563784241676.pypots
2024-05-22 22:38:06 [INFO]: Epoch 019 - training loss: 0.1962, validation loss: 0.1848
2024-05-22 22:38:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch19_loss0.18475313857197762.pypots
2024-05-22 22:38:08 [INFO]: Epoch 020 - training loss: 0.2223, validation loss: 0.2120
2024-05-22 22:38:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch20_loss0.21203535795211792.pypots
2024-05-22 22:38:10 [INFO]: Epoch 021 - training loss: 0.2202, validation loss: 0.2019
2024-05-22 22:38:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch21_loss0.20190102979540825.pypots
2024-05-22 22:38:12 [INFO]: Epoch 022 - training loss: 0.1967, validation loss: 0.1917
2024-05-22 22:38:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch22_loss0.19174675270915031.pypots
2024-05-22 22:38:14 [INFO]: Epoch 023 - training loss: 0.1745, validation loss: 0.1767
2024-05-22 22:38:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch23_loss0.1766764149069786.pypots
2024-05-22 22:38:16 [INFO]: Epoch 024 - training loss: 0.1772, validation loss: 0.1835
2024-05-22 22:38:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch24_loss0.1834600418806076.pypots
2024-05-22 22:38:18 [INFO]: Epoch 025 - training loss: 0.2065, validation loss: 0.1747
2024-05-22 22:38:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch25_loss0.17466680705547333.pypots
2024-05-22 22:38:20 [INFO]: Epoch 026 - training loss: 0.1866, validation loss: 0.1699
2024-05-22 22:38:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch26_loss0.16985353082418442.pypots
2024-05-22 22:38:22 [INFO]: Epoch 027 - training loss: 0.1732, validation loss: 0.1646
2024-05-22 22:38:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch27_loss0.16456926241517067.pypots
2024-05-22 22:38:24 [INFO]: Epoch 028 - training loss: 0.1732, validation loss: 0.1616
2024-05-22 22:38:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch28_loss0.16164954379200935.pypots
2024-05-22 22:38:26 [INFO]: Epoch 029 - training loss: 0.1711, validation loss: 0.1704
2024-05-22 22:38:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch29_loss0.1703956201672554.pypots
2024-05-22 22:38:28 [INFO]: Epoch 030 - training loss: 0.2239, validation loss: 0.1687
2024-05-22 22:38:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch30_loss0.16873927414417267.pypots
2024-05-22 22:38:30 [INFO]: Epoch 031 - training loss: 0.2139, validation loss: 0.1650
2024-05-22 22:38:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch31_loss0.16496064513921738.pypots
2024-05-22 22:38:32 [INFO]: Epoch 032 - training loss: 0.2566, validation loss: 0.1837
2024-05-22 22:38:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch32_loss0.1836998499929905.pypots
2024-05-22 22:38:34 [INFO]: Epoch 033 - training loss: 0.1955, validation loss: 0.1918
2024-05-22 22:38:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch33_loss0.19179369881749153.pypots
2024-05-22 22:38:36 [INFO]: Epoch 034 - training loss: 0.2348, validation loss: 0.1755
2024-05-22 22:38:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch34_loss0.17547521740198135.pypots
2024-05-22 22:38:38 [INFO]: Epoch 035 - training loss: 0.1715, validation loss: 0.1613
2024-05-22 22:38:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch35_loss0.1613227277994156.pypots
2024-05-22 22:38:40 [INFO]: Epoch 036 - training loss: 0.1844, validation loss: 0.1532
2024-05-22 22:38:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch36_loss0.15323537588119507.pypots
2024-05-22 22:38:42 [INFO]: Epoch 037 - training loss: 0.2176, validation loss: 0.1542
2024-05-22 22:38:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch37_loss0.15421362221240997.pypots
2024-05-22 22:38:44 [INFO]: Epoch 038 - training loss: 0.1887, validation loss: 0.1664
2024-05-22 22:38:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch38_loss0.16637108847498894.pypots
2024-05-22 22:38:46 [INFO]: Epoch 039 - training loss: 0.1630, validation loss: 0.1617
2024-05-22 22:38:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch39_loss0.16174707934260368.pypots
2024-05-22 22:38:48 [INFO]: Epoch 040 - training loss: 0.1821, validation loss: 0.1548
2024-05-22 22:38:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch40_loss0.15477189421653748.pypots
2024-05-22 22:38:50 [INFO]: Epoch 041 - training loss: 0.1644, validation loss: 0.1536
2024-05-22 22:38:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch41_loss0.1536359265446663.pypots
2024-05-22 22:38:52 [INFO]: Epoch 042 - training loss: 0.1546, validation loss: 0.1459
2024-05-22 22:38:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch42_loss0.14589233323931694.pypots
2024-05-22 22:38:54 [INFO]: Epoch 043 - training loss: 0.1498, validation loss: 0.1416
2024-05-22 22:38:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch43_loss0.1415771059691906.pypots
2024-05-22 22:38:56 [INFO]: Epoch 044 - training loss: 0.1386, validation loss: 0.1441
2024-05-22 22:38:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch44_loss0.14413821697235107.pypots
2024-05-22 22:38:59 [INFO]: Epoch 045 - training loss: 0.1600, validation loss: 0.1385
2024-05-22 22:38:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch45_loss0.13847408816218376.pypots
2024-05-22 22:39:01 [INFO]: Epoch 046 - training loss: 0.1343, validation loss: 0.1381
2024-05-22 22:39:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch46_loss0.13805019855499268.pypots
2024-05-22 22:39:03 [INFO]: Epoch 047 - training loss: 0.1374, validation loss: 0.1365
2024-05-22 22:39:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch47_loss0.13649916276335716.pypots
2024-05-22 22:39:05 [INFO]: Epoch 048 - training loss: 0.1444, validation loss: 0.1358
2024-05-22 22:39:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch48_loss0.1358492337167263.pypots
2024-05-22 22:39:07 [INFO]: Epoch 049 - training loss: 0.1401, validation loss: 0.1442
2024-05-22 22:39:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch49_loss0.14423979446291924.pypots
2024-05-22 22:39:09 [INFO]: Epoch 050 - training loss: 0.1433, validation loss: 0.1353
2024-05-22 22:39:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch50_loss0.13532524928450584.pypots
2024-05-22 22:39:11 [INFO]: Epoch 051 - training loss: 0.2109, validation loss: 0.1379
2024-05-22 22:39:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch51_loss0.137863177806139.pypots
2024-05-22 22:39:13 [INFO]: Epoch 052 - training loss: 0.1834, validation loss: 0.1682
2024-05-22 22:39:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch52_loss0.16821042075753212.pypots
2024-05-22 22:39:15 [INFO]: Epoch 053 - training loss: 0.1743, validation loss: 0.1603
2024-05-22 22:39:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch53_loss0.16025856509804726.pypots
2024-05-22 22:39:17 [INFO]: Epoch 054 - training loss: 0.1842, validation loss: 0.1468
2024-05-22 22:39:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch54_loss0.14682742208242416.pypots
2024-05-22 22:39:19 [INFO]: Epoch 055 - training loss: 0.1599, validation loss: 0.1454
2024-05-22 22:39:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch55_loss0.14538121968507767.pypots
2024-05-22 22:39:21 [INFO]: Epoch 056 - training loss: 0.1810, validation loss: 0.1395
2024-05-22 22:39:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch56_loss0.13946902006864548.pypots
2024-05-22 22:39:23 [INFO]: Epoch 057 - training loss: 0.1470, validation loss: 0.1480
2024-05-22 22:39:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch57_loss0.14800183475017548.pypots
2024-05-22 22:39:25 [INFO]: Epoch 058 - training loss: 0.1478, validation loss: 0.1403
2024-05-22 22:39:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch58_loss0.14034206792712212.pypots
2024-05-22 22:39:27 [INFO]: Epoch 059 - training loss: 0.1527, validation loss: 0.1379
2024-05-22 22:39:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch59_loss0.13789064437150955.pypots
2024-05-22 22:39:29 [INFO]: Epoch 060 - training loss: 0.1822, validation loss: 0.1412
2024-05-22 22:39:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI_epoch60_loss0.1412431038916111.pypots
2024-05-22 22:39:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:39:29 [INFO]: Finished training. The best model is from epoch#50.
2024-05-22 22:39:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240522_T223728/CSDI.pypots
2024-05-22 22:39:44 [INFO]: CSDI on ETTm1: MAE=0.1336, MSE=0.0479
2024-05-22 22:39:44 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/CSDI_ettm1/imputation.pkl
2024-05-22 22:39:44 [INFO]: Using the given device: cuda:0
2024-05-22 22:39:44 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/GPVAE_ettm1/20240522_T223944
2024-05-22 22:39:44 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/GPVAE_ettm1/20240522_T223944/tensorboard
2024-05-22 22:39:44 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 22:39:44 [INFO]: Epoch 001 - training loss: 23864.1289, validation loss: 0.9875
2024-05-22 22:39:45 [INFO]: Epoch 002 - training loss: 21694.6819, validation loss: 0.9806
2024-05-22 22:39:45 [INFO]: Epoch 003 - training loss: 19582.5215, validation loss: 0.9678
2024-05-22 22:39:45 [INFO]: Epoch 004 - training loss: 17601.4698, validation loss: 0.9398
2024-05-22 22:39:45 [INFO]: Epoch 005 - training loss: 15544.2433, validation loss: 0.8813
2024-05-22 22:39:45 [INFO]: Epoch 006 - training loss: 14040.8401, validation loss: 0.7834
2024-05-22 22:39:45 [INFO]: Epoch 007 - training loss: 12989.9288, validation loss: 0.6862
2024-05-22 22:39:45 [INFO]: Epoch 008 - training loss: 11974.8190, validation loss: 0.6392
2024-05-22 22:39:45 [INFO]: Epoch 009 - training loss: 11504.1890, validation loss: 0.5681
2024-05-22 22:39:45 [INFO]: Epoch 010 - training loss: 10958.6509, validation loss: 0.4994
2024-05-22 22:39:45 [INFO]: Epoch 011 - training loss: 10648.7879, validation loss: 0.4700
2024-05-22 22:39:46 [INFO]: Epoch 012 - training loss: 10480.9311, validation loss: 0.4550
2024-05-22 22:39:46 [INFO]: Epoch 013 - training loss: 10390.2252, validation loss: 0.4408
2024-05-22 22:39:46 [INFO]: Epoch 014 - training loss: 10128.4299, validation loss: 0.4284
2024-05-22 22:39:46 [INFO]: Epoch 015 - training loss: 10010.8258, validation loss: 0.4155
2024-05-22 22:39:46 [INFO]: Epoch 016 - training loss: 10034.0494, validation loss: 0.3909
2024-05-22 22:39:46 [INFO]: Epoch 017 - training loss: 9868.4822, validation loss: 0.3738
2024-05-22 22:39:46 [INFO]: Epoch 018 - training loss: 9817.4335, validation loss: 0.3580
2024-05-22 22:39:46 [INFO]: Epoch 019 - training loss: 9767.1738, validation loss: 0.3469
2024-05-22 22:39:46 [INFO]: Epoch 020 - training loss: 9731.1583, validation loss: 0.3461
2024-05-22 22:39:47 [INFO]: Epoch 021 - training loss: 9680.1056, validation loss: 0.3364
2024-05-22 22:39:47 [INFO]: Epoch 022 - training loss: 9638.3466, validation loss: 0.3276
2024-05-22 22:39:47 [INFO]: Epoch 023 - training loss: 9614.8687, validation loss: 0.3264
2024-05-22 22:39:47 [INFO]: Epoch 024 - training loss: 9591.1940, validation loss: 0.3238
2024-05-22 22:39:47 [INFO]: Epoch 025 - training loss: 9583.1108, validation loss: 0.3225
2024-05-22 22:39:47 [INFO]: Epoch 026 - training loss: 9591.5173, validation loss: 0.3176
2024-05-22 22:39:47 [INFO]: Epoch 027 - training loss: 9531.8194, validation loss: 0.3085
2024-05-22 22:39:47 [INFO]: Epoch 028 - training loss: 9512.9400, validation loss: 0.3024
2024-05-22 22:39:47 [INFO]: Epoch 029 - training loss: 9505.6992, validation loss: 0.3014
2024-05-22 22:39:47 [INFO]: Epoch 030 - training loss: 9486.4005, validation loss: 0.2939
2024-05-22 22:39:48 [INFO]: Epoch 031 - training loss: 9478.4951, validation loss: 0.2898
2024-05-22 22:39:48 [INFO]: Epoch 032 - training loss: 9461.9418, validation loss: 0.2825
2024-05-22 22:39:48 [INFO]: Epoch 033 - training loss: 9451.0784, validation loss: 0.2724
2024-05-22 22:39:48 [INFO]: Epoch 034 - training loss: 9437.2884, validation loss: 0.2626
2024-05-22 22:39:48 [INFO]: Epoch 035 - training loss: 9440.0298, validation loss: 0.2578
2024-05-22 22:39:48 [INFO]: Epoch 036 - training loss: 9431.4000, validation loss: 0.2505
2024-05-22 22:39:48 [INFO]: Epoch 037 - training loss: 9417.0984, validation loss: 0.2440
2024-05-22 22:39:48 [INFO]: Epoch 038 - training loss: 9427.9265, validation loss: 0.2387
2024-05-22 22:39:48 [INFO]: Epoch 039 - training loss: 9400.5581, validation loss: 0.2317
2024-05-22 22:39:49 [INFO]: Epoch 040 - training loss: 9394.2883, validation loss: 0.2251
2024-05-22 22:39:49 [INFO]: Epoch 041 - training loss: 9391.6901, validation loss: 0.2193
2024-05-22 22:39:49 [INFO]: Epoch 042 - training loss: 9396.1500, validation loss: 0.2117
2024-05-22 22:39:49 [INFO]: Epoch 043 - training loss: 9386.4535, validation loss: 0.2024
2024-05-22 22:39:49 [INFO]: Epoch 044 - training loss: 9386.5327, validation loss: 0.1985
2024-05-22 22:39:49 [INFO]: Epoch 045 - training loss: 9371.3410, validation loss: 0.1997
2024-05-22 22:39:49 [INFO]: Epoch 046 - training loss: 9373.4166, validation loss: 0.1901
2024-05-22 22:39:49 [INFO]: Epoch 047 - training loss: 9363.1846, validation loss: 0.1829
2024-05-22 22:39:49 [INFO]: Epoch 048 - training loss: 9358.5858, validation loss: 0.1790
2024-05-22 22:39:50 [INFO]: Epoch 049 - training loss: 9363.5077, validation loss: 0.1741
2024-05-22 22:39:50 [INFO]: Epoch 050 - training loss: 9366.3409, validation loss: 0.1721
2024-05-22 22:39:50 [INFO]: Epoch 051 - training loss: 9352.0060, validation loss: 0.1666
2024-05-22 22:39:50 [INFO]: Epoch 052 - training loss: 9347.9529, validation loss: 0.1641
2024-05-22 22:39:50 [INFO]: Epoch 053 - training loss: 9345.4805, validation loss: 0.1589
2024-05-22 22:39:50 [INFO]: Epoch 054 - training loss: 9344.8895, validation loss: 0.1565
2024-05-22 22:39:50 [INFO]: Epoch 055 - training loss: 9344.4933, validation loss: 0.1521
2024-05-22 22:39:50 [INFO]: Epoch 056 - training loss: 9340.1246, validation loss: 0.1526
2024-05-22 22:39:50 [INFO]: Epoch 057 - training loss: 9334.1299, validation loss: 0.1499
2024-05-22 22:39:50 [INFO]: Epoch 058 - training loss: 9339.3549, validation loss: 0.1477
2024-05-22 22:39:51 [INFO]: Epoch 059 - training loss: 9332.3005, validation loss: 0.1464
2024-05-22 22:39:51 [INFO]: Epoch 060 - training loss: 9338.1887, validation loss: 0.1420
2024-05-22 22:39:51 [INFO]: Epoch 061 - training loss: 9329.5161, validation loss: 0.1393
2024-05-22 22:39:51 [INFO]: Epoch 062 - training loss: 9325.5351, validation loss: 0.1403
2024-05-22 22:39:51 [INFO]: Epoch 063 - training loss: 9325.5547, validation loss: 0.1382
2024-05-22 22:39:51 [INFO]: Epoch 064 - training loss: 9324.2734, validation loss: 0.1360
2024-05-22 22:39:51 [INFO]: Epoch 065 - training loss: 9325.4243, validation loss: 0.1387
2024-05-22 22:39:51 [INFO]: Epoch 066 - training loss: 9319.0828, validation loss: 0.1323
2024-05-22 22:39:51 [INFO]: Epoch 067 - training loss: 9320.9670, validation loss: 0.1325
2024-05-22 22:39:52 [INFO]: Epoch 068 - training loss: 9319.2557, validation loss: 0.1304
2024-05-22 22:39:52 [INFO]: Epoch 069 - training loss: 9316.8633, validation loss: 0.1382
2024-05-22 22:39:52 [INFO]: Epoch 070 - training loss: 9316.2783, validation loss: 0.1305
2024-05-22 22:39:52 [INFO]: Epoch 071 - training loss: 9313.1993, validation loss: 0.1293
2024-05-22 22:39:52 [INFO]: Epoch 072 - training loss: 9312.2167, validation loss: 0.1284
2024-05-22 22:39:52 [INFO]: Epoch 073 - training loss: 9314.3556, validation loss: 0.1271
2024-05-22 22:39:52 [INFO]: Epoch 074 - training loss: 9313.4611, validation loss: 0.1258
2024-05-22 22:39:52 [INFO]: Epoch 075 - training loss: 9310.6611, validation loss: 0.1247
2024-05-22 22:39:52 [INFO]: Epoch 076 - training loss: 9308.6753, validation loss: 0.1236
2024-05-22 22:39:52 [INFO]: Epoch 077 - training loss: 9309.8314, validation loss: 0.1231
2024-05-22 22:39:53 [INFO]: Epoch 078 - training loss: 9308.3523, validation loss: 0.1214
2024-05-22 22:39:53 [INFO]: Epoch 079 - training loss: 9308.4005, validation loss: 0.1217
2024-05-22 22:39:53 [INFO]: Epoch 080 - training loss: 9308.2337, validation loss: 0.1195
2024-05-22 22:39:53 [INFO]: Epoch 081 - training loss: 9305.5317, validation loss: 0.1202
2024-05-22 22:39:53 [INFO]: Epoch 082 - training loss: 9303.3589, validation loss: 0.1195
2024-05-22 22:39:53 [INFO]: Epoch 083 - training loss: 9303.5306, validation loss: 0.1184
2024-05-22 22:39:53 [INFO]: Epoch 084 - training loss: 9304.0981, validation loss: 0.1178
2024-05-22 22:39:53 [INFO]: Epoch 085 - training loss: 9302.3701, validation loss: 0.1172
2024-05-22 22:39:53 [INFO]: Epoch 086 - training loss: 9304.0280, validation loss: 0.1156
2024-05-22 22:39:54 [INFO]: Epoch 087 - training loss: 9302.7234, validation loss: 0.1152
2024-05-22 22:39:54 [INFO]: Epoch 088 - training loss: 9301.7173, validation loss: 0.1143
2024-05-22 22:39:54 [INFO]: Epoch 089 - training loss: 9300.2905, validation loss: 0.1139
2024-05-22 22:39:54 [INFO]: Epoch 090 - training loss: 9299.3163, validation loss: 0.1138
2024-05-22 22:39:54 [INFO]: Epoch 091 - training loss: 9297.2668, validation loss: 0.1133
2024-05-22 22:39:54 [INFO]: Epoch 092 - training loss: 9298.6705, validation loss: 0.1123
2024-05-22 22:39:54 [INFO]: Epoch 093 - training loss: 9297.2308, validation loss: 0.1122
2024-05-22 22:39:54 [INFO]: Epoch 094 - training loss: 9296.4058, validation loss: 0.1105
2024-05-22 22:39:54 [INFO]: Epoch 095 - training loss: 9293.6528, validation loss: 0.1110
2024-05-22 22:39:54 [INFO]: Epoch 096 - training loss: 9297.1440, validation loss: 0.1105
2024-05-22 22:39:55 [INFO]: Epoch 097 - training loss: 9293.9513, validation loss: 0.1088
2024-05-22 22:39:55 [INFO]: Epoch 098 - training loss: 9293.0437, validation loss: 0.1090
2024-05-22 22:39:55 [INFO]: Epoch 099 - training loss: 9293.8785, validation loss: 0.1082
2024-05-22 22:39:55 [INFO]: Epoch 100 - training loss: 9294.8998, validation loss: 0.1070
2024-05-22 22:39:55 [INFO]: Epoch 101 - training loss: 9292.6287, validation loss: 0.1066
2024-05-22 22:39:55 [INFO]: Epoch 102 - training loss: 9293.8414, validation loss: 0.1069
2024-05-22 22:39:55 [INFO]: Epoch 103 - training loss: 9292.6719, validation loss: 0.1053
2024-05-22 22:39:55 [INFO]: Epoch 104 - training loss: 9291.7355, validation loss: 0.1050
2024-05-22 22:39:55 [INFO]: Epoch 105 - training loss: 9291.7387, validation loss: 0.1053
2024-05-22 22:39:56 [INFO]: Epoch 106 - training loss: 9290.7562, validation loss: 0.1059
2024-05-22 22:39:56 [INFO]: Epoch 107 - training loss: 9291.6788, validation loss: 0.1037
2024-05-22 22:39:56 [INFO]: Epoch 108 - training loss: 9291.9139, validation loss: 0.1042
2024-05-22 22:39:56 [INFO]: Epoch 109 - training loss: 9291.7716, validation loss: 0.1040
2024-05-22 22:39:56 [INFO]: Epoch 110 - training loss: 9289.2896, validation loss: 0.1021
2024-05-22 22:39:56 [INFO]: Epoch 111 - training loss: 9291.1885, validation loss: 0.1007
2024-05-22 22:39:56 [INFO]: Epoch 112 - training loss: 9288.7960, validation loss: 0.1012
2024-05-22 22:39:56 [INFO]: Epoch 113 - training loss: 9287.9861, validation loss: 0.1020
2024-05-22 22:39:56 [INFO]: Epoch 114 - training loss: 9287.7565, validation loss: 0.1012
2024-05-22 22:39:56 [INFO]: Epoch 115 - training loss: 9287.9526, validation loss: 0.0999
2024-05-22 22:39:57 [INFO]: Epoch 116 - training loss: 9286.4732, validation loss: 0.1017
2024-05-22 22:39:57 [INFO]: Epoch 117 - training loss: 9287.6323, validation loss: 0.0985
2024-05-22 22:39:57 [INFO]: Epoch 118 - training loss: 9286.3727, validation loss: 0.0981
2024-05-22 22:39:57 [INFO]: Epoch 119 - training loss: 9286.3834, validation loss: 0.0984
2024-05-22 22:39:57 [INFO]: Epoch 120 - training loss: 9287.5444, validation loss: 0.0973
2024-05-22 22:39:57 [INFO]: Epoch 121 - training loss: 9285.9451, validation loss: 0.0979
2024-05-22 22:39:57 [INFO]: Epoch 122 - training loss: 9288.6435, validation loss: 0.0972
2024-05-22 22:39:57 [INFO]: Epoch 123 - training loss: 9285.8223, validation loss: 0.0973
2024-05-22 22:39:57 [INFO]: Epoch 124 - training loss: 9286.1052, validation loss: 0.0958
2024-05-22 22:39:58 [INFO]: Epoch 125 - training loss: 9288.2415, validation loss: 0.0952
2024-05-22 22:39:58 [INFO]: Epoch 126 - training loss: 9284.6937, validation loss: 0.0958
2024-05-22 22:39:58 [INFO]: Epoch 127 - training loss: 9284.6078, validation loss: 0.0954
2024-05-22 22:39:58 [INFO]: Epoch 128 - training loss: 9284.6666, validation loss: 0.0951
2024-05-22 22:39:58 [INFO]: Epoch 129 - training loss: 9282.7369, validation loss: 0.0935
2024-05-22 22:39:58 [INFO]: Epoch 130 - training loss: 9283.6829, validation loss: 0.0943
2024-05-22 22:39:58 [INFO]: Epoch 131 - training loss: 9282.1989, validation loss: 0.0936
2024-05-22 22:39:58 [INFO]: Epoch 132 - training loss: 9282.5159, validation loss: 0.0933
2024-05-22 22:39:58 [INFO]: Epoch 133 - training loss: 9281.8076, validation loss: 0.0942
2024-05-22 22:39:58 [INFO]: Epoch 134 - training loss: 9282.5457, validation loss: 0.0933
2024-05-22 22:39:59 [INFO]: Epoch 135 - training loss: 9282.4019, validation loss: 0.0918
2024-05-22 22:39:59 [INFO]: Epoch 136 - training loss: 9283.6580, validation loss: 0.0934
2024-05-22 22:39:59 [INFO]: Epoch 137 - training loss: 9281.1756, validation loss: 0.0916
2024-05-22 22:39:59 [INFO]: Epoch 138 - training loss: 9281.5082, validation loss: 0.0912
2024-05-22 22:39:59 [INFO]: Epoch 139 - training loss: 9281.6408, validation loss: 0.0923
2024-05-22 22:39:59 [INFO]: Epoch 140 - training loss: 9280.9124, validation loss: 0.0903
2024-05-22 22:39:59 [INFO]: Epoch 141 - training loss: 9298.5183, validation loss: 0.0906
2024-05-22 22:39:59 [INFO]: Epoch 142 - training loss: 9281.7111, validation loss: 0.0888
2024-05-22 22:39:59 [INFO]: Epoch 143 - training loss: 9280.3942, validation loss: 0.0902
2024-05-22 22:40:00 [INFO]: Epoch 144 - training loss: 9281.3346, validation loss: 0.0893
2024-05-22 22:40:00 [INFO]: Epoch 145 - training loss: 9281.5599, validation loss: 0.0892
2024-05-22 22:40:00 [INFO]: Epoch 146 - training loss: 9280.1833, validation loss: 0.0905
2024-05-22 22:40:00 [INFO]: Epoch 147 - training loss: 9281.2828, validation loss: 0.0884
2024-05-22 22:40:00 [INFO]: Epoch 148 - training loss: 9281.4026, validation loss: 0.0877
2024-05-22 22:40:00 [INFO]: Epoch 149 - training loss: 9280.8818, validation loss: 0.0893
2024-05-22 22:40:00 [INFO]: Epoch 150 - training loss: 9278.5509, validation loss: 0.0871
2024-05-22 22:40:00 [INFO]: Epoch 151 - training loss: 9279.7941, validation loss: 0.0876
2024-05-22 22:40:00 [INFO]: Epoch 152 - training loss: 9280.5670, validation loss: 0.0884
2024-05-22 22:40:00 [INFO]: Epoch 153 - training loss: 9278.3632, validation loss: 0.0880
2024-05-22 22:40:01 [INFO]: Epoch 154 - training loss: 9277.4855, validation loss: 0.0868
2024-05-22 22:40:01 [INFO]: Epoch 155 - training loss: 9280.1830, validation loss: 0.0867
2024-05-22 22:40:01 [INFO]: Epoch 156 - training loss: 9279.5937, validation loss: 0.0855
2024-05-22 22:40:01 [INFO]: Epoch 157 - training loss: 9279.0286, validation loss: 0.0839
2024-05-22 22:40:01 [INFO]: Epoch 158 - training loss: 9276.2544, validation loss: 0.0872
2024-05-22 22:40:01 [INFO]: Epoch 159 - training loss: 9276.7719, validation loss: 0.0850
2024-05-22 22:40:01 [INFO]: Epoch 160 - training loss: 9277.6866, validation loss: 0.0854
2024-05-22 22:40:01 [INFO]: Epoch 161 - training loss: 9277.3702, validation loss: 0.0854
2024-05-22 22:40:01 [INFO]: Epoch 162 - training loss: 9278.8306, validation loss: 0.0845
2024-05-22 22:40:02 [INFO]: Epoch 163 - training loss: 9276.0685, validation loss: 0.0841
2024-05-22 22:40:02 [INFO]: Epoch 164 - training loss: 9276.2297, validation loss: 0.0848
2024-05-22 22:40:02 [INFO]: Epoch 165 - training loss: 9277.8495, validation loss: 0.0839
2024-05-22 22:40:02 [INFO]: Epoch 166 - training loss: 9275.7482, validation loss: 0.0853
2024-05-22 22:40:02 [INFO]: Epoch 167 - training loss: 9275.0715, validation loss: 0.0836
2024-05-22 22:40:02 [INFO]: Epoch 168 - training loss: 9278.4706, validation loss: 0.0846
2024-05-22 22:40:02 [INFO]: Epoch 169 - training loss: 9275.9051, validation loss: 0.0835
2024-05-22 22:40:02 [INFO]: Epoch 170 - training loss: 9277.4088, validation loss: 0.0838
2024-05-22 22:40:02 [INFO]: Epoch 171 - training loss: 9276.2983, validation loss: 0.0824
2024-05-22 22:40:02 [INFO]: Epoch 172 - training loss: 9275.8607, validation loss: 0.0828
2024-05-22 22:40:03 [INFO]: Epoch 173 - training loss: 9275.3076, validation loss: 0.0847
2024-05-22 22:40:03 [INFO]: Epoch 174 - training loss: 9277.4933, validation loss: 0.0821
2024-05-22 22:40:03 [INFO]: Epoch 175 - training loss: 9275.5202, validation loss: 0.0845
2024-05-22 22:40:03 [INFO]: Epoch 176 - training loss: 9275.2581, validation loss: 0.0834
2024-05-22 22:40:03 [INFO]: Epoch 177 - training loss: 9276.5120, validation loss: 0.0834
2024-05-22 22:40:03 [INFO]: Epoch 178 - training loss: 9274.6285, validation loss: 0.0810
2024-05-22 22:40:03 [INFO]: Epoch 179 - training loss: 9276.6844, validation loss: 0.0833
2024-05-22 22:40:03 [INFO]: Epoch 180 - training loss: 9275.7325, validation loss: 0.0817
2024-05-22 22:40:03 [INFO]: Epoch 181 - training loss: 9275.5735, validation loss: 0.0825
2024-05-22 22:40:04 [INFO]: Epoch 182 - training loss: 9275.2578, validation loss: 0.0803
2024-05-22 22:40:04 [INFO]: Epoch 183 - training loss: 9275.3123, validation loss: 0.0819
2024-05-22 22:40:04 [INFO]: Epoch 184 - training loss: 9274.9576, validation loss: 0.0810
2024-05-22 22:40:04 [INFO]: Epoch 185 - training loss: 9275.4182, validation loss: 0.0803
2024-05-22 22:40:04 [INFO]: Epoch 186 - training loss: 9275.5612, validation loss: 0.0799
2024-05-22 22:40:04 [INFO]: Epoch 187 - training loss: 9275.1669, validation loss: 0.0808
2024-05-22 22:40:04 [INFO]: Epoch 188 - training loss: 9275.3633, validation loss: 0.0798
2024-05-22 22:40:04 [INFO]: Epoch 189 - training loss: 9275.9113, validation loss: 0.0798
2024-05-22 22:40:04 [INFO]: Epoch 190 - training loss: 9274.5565, validation loss: 0.0803
2024-05-22 22:40:04 [INFO]: Epoch 191 - training loss: 9273.6756, validation loss: 0.0812
2024-05-22 22:40:05 [INFO]: Epoch 192 - training loss: 9273.7086, validation loss: 0.0787
2024-05-22 22:40:05 [INFO]: Epoch 193 - training loss: 9274.3984, validation loss: 0.0795
2024-05-22 22:40:05 [INFO]: Epoch 194 - training loss: 9275.7019, validation loss: 0.0801
2024-05-22 22:40:05 [INFO]: Epoch 195 - training loss: 9273.1410, validation loss: 0.0795
2024-05-22 22:40:05 [INFO]: Epoch 196 - training loss: 9273.8279, validation loss: 0.0779
2024-05-22 22:40:05 [INFO]: Epoch 197 - training loss: 9272.9601, validation loss: 0.0794
2024-05-22 22:40:05 [INFO]: Epoch 198 - training loss: 9273.4561, validation loss: 0.0787
2024-05-22 22:40:05 [INFO]: Epoch 199 - training loss: 9274.5650, validation loss: 0.0793
2024-05-22 22:40:05 [INFO]: Epoch 200 - training loss: 9273.3201, validation loss: 0.0810
2024-05-22 22:40:06 [INFO]: Epoch 201 - training loss: 9274.3802, validation loss: 0.0822
2024-05-22 22:40:06 [INFO]: Epoch 202 - training loss: 9273.8427, validation loss: 0.0788
2024-05-22 22:40:06 [INFO]: Epoch 203 - training loss: 9274.4870, validation loss: 0.0786
2024-05-22 22:40:06 [INFO]: Epoch 204 - training loss: 9274.2742, validation loss: 0.0781
2024-05-22 22:40:06 [INFO]: Epoch 205 - training loss: 9273.3870, validation loss: 0.0765
2024-05-22 22:40:06 [INFO]: Epoch 206 - training loss: 9272.4125, validation loss: 0.0776
2024-05-22 22:40:06 [INFO]: Epoch 207 - training loss: 9272.9569, validation loss: 0.0785
2024-05-22 22:40:06 [INFO]: Epoch 208 - training loss: 9272.8974, validation loss: 0.0777
2024-05-22 22:40:06 [INFO]: Epoch 209 - training loss: 9275.1351, validation loss: 0.0804
2024-05-22 22:40:06 [INFO]: Epoch 210 - training loss: 9276.0688, validation loss: 0.0783
2024-05-22 22:40:07 [INFO]: Epoch 211 - training loss: 9273.4754, validation loss: 0.0773
2024-05-22 22:40:07 [INFO]: Epoch 212 - training loss: 9272.0526, validation loss: 0.0761
2024-05-22 22:40:07 [INFO]: Epoch 213 - training loss: 9272.1565, validation loss: 0.0774
2024-05-22 22:40:07 [INFO]: Epoch 214 - training loss: 9272.6763, validation loss: 0.0770
2024-05-22 22:40:07 [INFO]: Epoch 215 - training loss: 9272.1800, validation loss: 0.0791
2024-05-22 22:40:07 [INFO]: Epoch 216 - training loss: 9272.6260, validation loss: 0.0793
2024-05-22 22:40:07 [INFO]: Epoch 217 - training loss: 9272.6674, validation loss: 0.0774
2024-05-22 22:40:07 [INFO]: Epoch 218 - training loss: 9272.2754, validation loss: 0.0791
2024-05-22 22:40:07 [INFO]: Epoch 219 - training loss: 9271.5671, validation loss: 0.0762
2024-05-22 22:40:08 [INFO]: Epoch 220 - training loss: 9271.8318, validation loss: 0.0763
2024-05-22 22:40:08 [INFO]: Epoch 221 - training loss: 9271.4284, validation loss: 0.0757
2024-05-22 22:40:08 [INFO]: Epoch 222 - training loss: 9272.2380, validation loss: 0.0765
2024-05-22 22:40:08 [INFO]: Epoch 223 - training loss: 9272.8177, validation loss: 0.0764
2024-05-22 22:40:08 [INFO]: Epoch 224 - training loss: 9270.8054, validation loss: 0.0759
2024-05-22 22:40:08 [INFO]: Epoch 225 - training loss: 9271.8887, validation loss: 0.0753
2024-05-22 22:40:08 [INFO]: Epoch 226 - training loss: 9271.0396, validation loss: 0.0758
2024-05-22 22:40:08 [INFO]: Epoch 227 - training loss: 9272.2183, validation loss: 0.0761
2024-05-22 22:40:09 [INFO]: Epoch 228 - training loss: 9272.2950, validation loss: 0.0777
2024-05-22 22:40:09 [INFO]: Epoch 229 - training loss: 9274.0621, validation loss: 0.0768
2024-05-22 22:40:09 [INFO]: Epoch 230 - training loss: 9271.5447, validation loss: 0.0785
2024-05-22 22:40:09 [INFO]: Epoch 231 - training loss: 9271.4319, validation loss: 0.0754
2024-05-22 22:40:09 [INFO]: Epoch 232 - training loss: 9271.5869, validation loss: 0.0755
2024-05-22 22:40:09 [INFO]: Epoch 233 - training loss: 9271.6830, validation loss: 0.0766
2024-05-22 22:40:09 [INFO]: Epoch 234 - training loss: 9270.6485, validation loss: 0.0768
2024-05-22 22:40:09 [INFO]: Epoch 235 - training loss: 9272.9121, validation loss: 0.0774
2024-05-22 22:40:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:40:09 [INFO]: Finished training. The best model is from epoch#225.
2024-05-22 22:40:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/GPVAE_ettm1/20240522_T223944/GPVAE.pypots
2024-05-22 22:40:09 [INFO]: GP-VAE on ETTm1: MAE=0.2583, MSE=0.1423
2024-05-22 22:40:09 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/GPVAE_ettm1/imputation.pkl
2024-05-22 22:40:09 [INFO]: Using the given device: cuda:0
2024-05-22 22:40:09 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/USGAN_ettm1/20240522_T224009
2024-05-22 22:40:09 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/USGAN_ettm1/20240522_T224009/tensorboard
2024-05-22 22:40:09 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 22:40:17 [INFO]: Epoch 001 - generator training loss: 0.5031, discriminator training loss: 0.4145, validation loss: 0.3381
2024-05-22 22:40:24 [INFO]: Epoch 002 - generator training loss: 0.0243, discriminator training loss: 0.3207, validation loss: 0.1088
2024-05-22 22:40:31 [INFO]: Epoch 003 - generator training loss: -0.1191, discriminator training loss: 0.3087, validation loss: 0.0627
2024-05-22 22:40:38 [INFO]: Epoch 004 - generator training loss: -0.1402, discriminator training loss: 0.2977, validation loss: 0.0525
2024-05-22 22:40:45 [INFO]: Epoch 005 - generator training loss: -0.1298, discriminator training loss: 0.2798, validation loss: 0.0460
2024-05-22 22:40:52 [INFO]: Epoch 006 - generator training loss: -0.1138, discriminator training loss: 0.2557, validation loss: 0.0413
2024-05-22 22:40:59 [INFO]: Epoch 007 - generator training loss: -0.0900, discriminator training loss: 0.2208, validation loss: 0.0402
2024-05-22 22:41:06 [INFO]: Epoch 008 - generator training loss: -0.0635, discriminator training loss: 0.1852, validation loss: 0.0379
2024-05-22 22:41:13 [INFO]: Epoch 009 - generator training loss: -0.0499, discriminator training loss: 0.1575, validation loss: 0.0364
2024-05-22 22:41:20 [INFO]: Epoch 010 - generator training loss: -0.0420, discriminator training loss: 0.1420, validation loss: 0.0360
2024-05-22 22:41:26 [INFO]: Epoch 011 - generator training loss: -0.0369, discriminator training loss: 0.1324, validation loss: 0.0352
2024-05-22 22:41:33 [INFO]: Epoch 012 - generator training loss: -0.0354, discriminator training loss: 0.1240, validation loss: 0.0347
2024-05-22 22:41:40 [INFO]: Epoch 013 - generator training loss: -0.0345, discriminator training loss: 0.1254, validation loss: 0.0345
2024-05-22 22:41:47 [INFO]: Epoch 014 - generator training loss: -0.0337, discriminator training loss: 0.1201, validation loss: 0.0335
2024-05-22 22:41:54 [INFO]: Epoch 015 - generator training loss: -0.0326, discriminator training loss: 0.1189, validation loss: 0.0335
2024-05-22 22:42:01 [INFO]: Epoch 016 - generator training loss: -0.0336, discriminator training loss: 0.1184, validation loss: 0.0328
2024-05-22 22:42:08 [INFO]: Epoch 017 - generator training loss: -0.0359, discriminator training loss: 0.1175, validation loss: 0.0351
2024-05-22 22:42:15 [INFO]: Epoch 018 - generator training loss: -0.0339, discriminator training loss: 0.1148, validation loss: 0.0344
2024-05-22 22:42:22 [INFO]: Epoch 019 - generator training loss: -0.0353, discriminator training loss: 0.1167, validation loss: 0.0331
2024-05-22 22:42:29 [INFO]: Epoch 020 - generator training loss: -0.0333, discriminator training loss: 0.1156, validation loss: 0.0328
2024-05-22 22:42:35 [INFO]: Epoch 021 - generator training loss: -0.0336, discriminator training loss: 0.1136, validation loss: 0.0316
2024-05-22 22:42:42 [INFO]: Epoch 022 - generator training loss: -0.0355, discriminator training loss: 0.1140, validation loss: 0.0312
2024-05-22 22:42:49 [INFO]: Epoch 023 - generator training loss: -0.0363, discriminator training loss: 0.1133, validation loss: 0.0309
2024-05-22 22:42:56 [INFO]: Epoch 024 - generator training loss: -0.0334, discriminator training loss: 0.1148, validation loss: 0.0308
2024-05-22 22:43:03 [INFO]: Epoch 025 - generator training loss: -0.0359, discriminator training loss: 0.1121, validation loss: 0.0313
2024-05-22 22:43:10 [INFO]: Epoch 026 - generator training loss: -0.0376, discriminator training loss: 0.1142, validation loss: 0.0307
2024-05-22 22:43:17 [INFO]: Epoch 027 - generator training loss: -0.0364, discriminator training loss: 0.1121, validation loss: 0.0303
2024-05-22 22:43:24 [INFO]: Epoch 028 - generator training loss: -0.0352, discriminator training loss: 0.1114, validation loss: 0.0306
2024-05-22 22:43:31 [INFO]: Epoch 029 - generator training loss: -0.0379, discriminator training loss: 0.1105, validation loss: 0.0311
2024-05-22 22:43:38 [INFO]: Epoch 030 - generator training loss: -0.0354, discriminator training loss: 0.1100, validation loss: 0.0307
2024-05-22 22:43:45 [INFO]: Epoch 031 - generator training loss: -0.0376, discriminator training loss: 0.1123, validation loss: 0.0315
2024-05-22 22:43:51 [INFO]: Epoch 032 - generator training loss: -0.0393, discriminator training loss: 0.1123, validation loss: 0.0293
2024-05-22 22:43:58 [INFO]: Epoch 033 - generator training loss: -0.0387, discriminator training loss: 0.1121, validation loss: 0.0292
2024-05-22 22:44:05 [INFO]: Epoch 034 - generator training loss: -0.0394, discriminator training loss: 0.1101, validation loss: 0.0294
2024-05-22 22:44:12 [INFO]: Epoch 035 - generator training loss: -0.0386, discriminator training loss: 0.1114, validation loss: 0.0288
2024-05-22 22:44:19 [INFO]: Epoch 036 - generator training loss: -0.0381, discriminator training loss: 0.1112, validation loss: 0.0286
2024-05-22 22:44:26 [INFO]: Epoch 037 - generator training loss: -0.0414, discriminator training loss: 0.1103, validation loss: 0.0281
2024-05-22 22:44:33 [INFO]: Epoch 038 - generator training loss: -0.0394, discriminator training loss: 0.1101, validation loss: 0.0277
2024-05-22 22:44:40 [INFO]: Epoch 039 - generator training loss: -0.0362, discriminator training loss: 0.1114, validation loss: 0.0282
2024-05-22 22:44:47 [INFO]: Epoch 040 - generator training loss: -0.0416, discriminator training loss: 0.1113, validation loss: 0.0288
2024-05-22 22:44:54 [INFO]: Epoch 041 - generator training loss: -0.0390, discriminator training loss: 0.1104, validation loss: 0.0278
2024-05-22 22:45:01 [INFO]: Epoch 042 - generator training loss: -0.0413, discriminator training loss: 0.1101, validation loss: 0.0268
2024-05-22 22:45:08 [INFO]: Epoch 043 - generator training loss: -0.0447, discriminator training loss: 0.1124, validation loss: 0.0271
2024-05-22 22:45:16 [INFO]: Epoch 044 - generator training loss: -0.0389, discriminator training loss: 0.1088, validation loss: 0.0263
2024-05-22 22:45:23 [INFO]: Epoch 045 - generator training loss: -0.0436, discriminator training loss: 0.1097, validation loss: 0.0270
2024-05-22 22:45:30 [INFO]: Epoch 046 - generator training loss: -0.0429, discriminator training loss: 0.1102, validation loss: 0.0260
2024-05-22 22:45:37 [INFO]: Epoch 047 - generator training loss: -0.0447, discriminator training loss: 0.1103, validation loss: 0.0259
2024-05-22 22:45:44 [INFO]: Epoch 048 - generator training loss: -0.0446, discriminator training loss: 0.1127, validation loss: 0.0269
2024-05-22 22:45:51 [INFO]: Epoch 049 - generator training loss: -0.0413, discriminator training loss: 0.1091, validation loss: 0.0258
2024-05-22 22:45:58 [INFO]: Epoch 050 - generator training loss: -0.0490, discriminator training loss: 0.1102, validation loss: 0.0254
2024-05-22 22:46:04 [INFO]: Epoch 051 - generator training loss: -0.0451, discriminator training loss: 0.1105, validation loss: 0.0251
2024-05-22 22:46:11 [INFO]: Epoch 052 - generator training loss: -0.0466, discriminator training loss: 0.1087, validation loss: 0.0248
2024-05-22 22:46:18 [INFO]: Epoch 053 - generator training loss: -0.0441, discriminator training loss: 0.1112, validation loss: 0.0248
2024-05-22 22:46:25 [INFO]: Epoch 054 - generator training loss: -0.0445, discriminator training loss: 0.1073, validation loss: 0.0246
2024-05-22 22:46:32 [INFO]: Epoch 055 - generator training loss: -0.0446, discriminator training loss: 0.1080, validation loss: 0.0252
2024-05-22 22:46:39 [INFO]: Epoch 056 - generator training loss: -0.0466, discriminator training loss: 0.1080, validation loss: 0.0245
2024-05-22 22:46:46 [INFO]: Epoch 057 - generator training loss: -0.0425, discriminator training loss: 0.1084, validation loss: 0.0248
2024-05-22 22:46:53 [INFO]: Epoch 058 - generator training loss: -0.0418, discriminator training loss: 0.1106, validation loss: 0.0256
2024-05-22 22:47:00 [INFO]: Epoch 059 - generator training loss: -0.0449, discriminator training loss: 0.1071, validation loss: 0.0251
2024-05-22 22:47:07 [INFO]: Epoch 060 - generator training loss: -0.0453, discriminator training loss: 0.1068, validation loss: 0.0254
2024-05-22 22:47:14 [INFO]: Epoch 061 - generator training loss: -0.0462, discriminator training loss: 0.1086, validation loss: 0.0241
2024-05-22 22:47:20 [INFO]: Epoch 062 - generator training loss: -0.0464, discriminator training loss: 0.1075, validation loss: 0.0242
2024-05-22 22:47:27 [INFO]: Epoch 063 - generator training loss: -0.0469, discriminator training loss: 0.1078, validation loss: 0.0233
2024-05-22 22:47:34 [INFO]: Epoch 064 - generator training loss: -0.0452, discriminator training loss: 0.1075, validation loss: 0.0234
2024-05-22 22:47:41 [INFO]: Epoch 065 - generator training loss: -0.0457, discriminator training loss: 0.1066, validation loss: 0.0236
2024-05-22 22:47:48 [INFO]: Epoch 066 - generator training loss: -0.0486, discriminator training loss: 0.1084, validation loss: 0.0243
2024-05-22 22:47:55 [INFO]: Epoch 067 - generator training loss: -0.0440, discriminator training loss: 0.1093, validation loss: 0.0239
2024-05-22 22:48:02 [INFO]: Epoch 068 - generator training loss: -0.0502, discriminator training loss: 0.1078, validation loss: 0.0230
2024-05-22 22:48:09 [INFO]: Epoch 069 - generator training loss: -0.0475, discriminator training loss: 0.1083, validation loss: 0.0229
2024-05-22 22:48:16 [INFO]: Epoch 070 - generator training loss: -0.0484, discriminator training loss: 0.1076, validation loss: 0.0230
2024-05-22 22:48:23 [INFO]: Epoch 071 - generator training loss: -0.0474, discriminator training loss: 0.1107, validation loss: 0.0227
2024-05-22 22:48:30 [INFO]: Epoch 072 - generator training loss: -0.0480, discriminator training loss: 0.1072, validation loss: 0.0226
2024-05-22 22:48:37 [INFO]: Epoch 073 - generator training loss: -0.0498, discriminator training loss: 0.1060, validation loss: 0.0224
2024-05-22 22:48:44 [INFO]: Epoch 074 - generator training loss: -0.0509, discriminator training loss: 0.1073, validation loss: 0.0223
2024-05-22 22:48:51 [INFO]: Epoch 075 - generator training loss: -0.0497, discriminator training loss: 0.1060, validation loss: 0.0222
2024-05-22 22:48:58 [INFO]: Epoch 076 - generator training loss: -0.0494, discriminator training loss: 0.1055, validation loss: 0.0224
2024-05-22 22:49:05 [INFO]: Epoch 077 - generator training loss: -0.0480, discriminator training loss: 0.1071, validation loss: 0.0231
2024-05-22 22:49:12 [INFO]: Epoch 078 - generator training loss: -0.0472, discriminator training loss: 0.1050, validation loss: 0.0221
2024-05-22 22:49:19 [INFO]: Epoch 079 - generator training loss: -0.0480, discriminator training loss: 0.1063, validation loss: 0.0224
2024-05-22 22:49:26 [INFO]: Epoch 080 - generator training loss: -0.0500, discriminator training loss: 0.1067, validation loss: 0.0223
2024-05-22 22:49:33 [INFO]: Epoch 081 - generator training loss: -0.0485, discriminator training loss: 0.1077, validation loss: 0.0225
2024-05-22 22:49:40 [INFO]: Epoch 082 - generator training loss: -0.0506, discriminator training loss: 0.1068, validation loss: 0.0219
2024-05-22 22:49:47 [INFO]: Epoch 083 - generator training loss: -0.0514, discriminator training loss: 0.1086, validation loss: 0.0224
2024-05-22 22:49:54 [INFO]: Epoch 084 - generator training loss: -0.0485, discriminator training loss: 0.1061, validation loss: 0.0221
2024-05-22 22:50:01 [INFO]: Epoch 085 - generator training loss: -0.0502, discriminator training loss: 0.1083, validation loss: 0.0222
2024-05-22 22:50:08 [INFO]: Epoch 086 - generator training loss: -0.0477, discriminator training loss: 0.1072, validation loss: 0.0220
2024-05-22 22:50:15 [INFO]: Epoch 087 - generator training loss: -0.0483, discriminator training loss: 0.1074, validation loss: 0.0219
2024-05-22 22:50:22 [INFO]: Epoch 088 - generator training loss: -0.0500, discriminator training loss: 0.1066, validation loss: 0.0219
2024-05-22 22:50:29 [INFO]: Epoch 089 - generator training loss: -0.0479, discriminator training loss: 0.1074, validation loss: 0.0218
2024-05-22 22:50:36 [INFO]: Epoch 090 - generator training loss: -0.0481, discriminator training loss: 0.1071, validation loss: 0.0220
2024-05-22 22:50:43 [INFO]: Epoch 091 - generator training loss: -0.0479, discriminator training loss: 0.1052, validation loss: 0.0219
2024-05-22 22:50:50 [INFO]: Epoch 092 - generator training loss: -0.0503, discriminator training loss: 0.1055, validation loss: 0.0218
2024-05-22 22:50:57 [INFO]: Epoch 093 - generator training loss: -0.0471, discriminator training loss: 0.1074, validation loss: 0.0220
2024-05-22 22:51:04 [INFO]: Epoch 094 - generator training loss: -0.0513, discriminator training loss: 0.1045, validation loss: 0.0216
2024-05-22 22:51:11 [INFO]: Epoch 095 - generator training loss: -0.0482, discriminator training loss: 0.1058, validation loss: 0.0221
2024-05-22 22:51:18 [INFO]: Epoch 096 - generator training loss: -0.0495, discriminator training loss: 0.1033, validation loss: 0.0223
2024-05-22 22:51:25 [INFO]: Epoch 097 - generator training loss: -0.0501, discriminator training loss: 0.1072, validation loss: 0.0215
2024-05-22 22:51:32 [INFO]: Epoch 098 - generator training loss: -0.0485, discriminator training loss: 0.1047, validation loss: 0.0223
2024-05-22 22:51:39 [INFO]: Epoch 099 - generator training loss: -0.0462, discriminator training loss: 0.1057, validation loss: 0.0217
2024-05-22 22:51:46 [INFO]: Epoch 100 - generator training loss: -0.0498, discriminator training loss: 0.1064, validation loss: 0.0218
2024-05-22 22:51:53 [INFO]: Epoch 101 - generator training loss: -0.0477, discriminator training loss: 0.1074, validation loss: 0.0215
2024-05-22 22:52:00 [INFO]: Epoch 102 - generator training loss: -0.0494, discriminator training loss: 0.1040, validation loss: 0.0223
2024-05-22 22:52:07 [INFO]: Epoch 103 - generator training loss: -0.0500, discriminator training loss: 0.1050, validation loss: 0.0219
2024-05-22 22:52:14 [INFO]: Epoch 104 - generator training loss: -0.0500, discriminator training loss: 0.1069, validation loss: 0.0219
2024-05-22 22:52:21 [INFO]: Epoch 105 - generator training loss: -0.0511, discriminator training loss: 0.1055, validation loss: 0.0224
2024-05-22 22:52:28 [INFO]: Epoch 106 - generator training loss: -0.0482, discriminator training loss: 0.1061, validation loss: 0.0216
2024-05-22 22:52:35 [INFO]: Epoch 107 - generator training loss: -0.0481, discriminator training loss: 0.1061, validation loss: 0.0219
2024-05-22 22:52:42 [INFO]: Epoch 108 - generator training loss: -0.0497, discriminator training loss: 0.1052, validation loss: 0.0216
2024-05-22 22:52:49 [INFO]: Epoch 109 - generator training loss: -0.0514, discriminator training loss: 0.1060, validation loss: 0.0217
2024-05-22 22:52:56 [INFO]: Epoch 110 - generator training loss: -0.0476, discriminator training loss: 0.1051, validation loss: 0.0221
2024-05-22 22:53:03 [INFO]: Epoch 111 - generator training loss: -0.0503, discriminator training loss: 0.1064, validation loss: 0.0226
2024-05-22 22:53:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:53:03 [INFO]: Finished training. The best model is from epoch#101.
2024-05-22 22:53:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/USGAN_ettm1/20240522_T224009/USGAN.pypots
2024-05-22 22:53:03 [INFO]: US-GAN on ETTm1: MAE=0.1432, MSE=0.0567
2024-05-22 22:53:03 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/USGAN_ettm1/imputation.pkl
2024-05-22 22:53:03 [INFO]: Using the given device: cuda:0
2024-05-22 22:53:03 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/BRITS_ettm1/20240522_T225303
2024-05-22 22:53:03 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/BRITS_ettm1/20240522_T225303/tensorboard
2024-05-22 22:53:03 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 22:53:09 [INFO]: Epoch 001 - training loss: 1.3320, validation loss: 0.3088
2024-05-22 22:53:14 [INFO]: Epoch 002 - training loss: 0.8921, validation loss: 0.0885
2024-05-22 22:53:18 [INFO]: Epoch 003 - training loss: 0.7248, validation loss: 0.0571
2024-05-22 22:53:23 [INFO]: Epoch 004 - training loss: 0.6358, validation loss: 0.0479
2024-05-22 22:53:28 [INFO]: Epoch 005 - training loss: 0.5974, validation loss: 0.0405
2024-05-22 22:53:32 [INFO]: Epoch 006 - training loss: 0.5547, validation loss: 0.0379
2024-05-22 22:53:37 [INFO]: Epoch 007 - training loss: 0.5194, validation loss: 0.0377
2024-05-22 22:53:41 [INFO]: Epoch 008 - training loss: 0.5138, validation loss: 0.0340
2024-05-22 22:53:46 [INFO]: Epoch 009 - training loss: 0.4762, validation loss: 0.0339
2024-05-22 22:53:51 [INFO]: Epoch 010 - training loss: 0.4591, validation loss: 0.0330
2024-05-22 22:53:55 [INFO]: Epoch 011 - training loss: 0.4386, validation loss: 0.0306
2024-05-22 22:54:00 [INFO]: Epoch 012 - training loss: 0.4265, validation loss: 0.0302
2024-05-22 22:54:04 [INFO]: Epoch 013 - training loss: 0.4353, validation loss: 0.0277
2024-05-22 22:54:09 [INFO]: Epoch 014 - training loss: 0.4148, validation loss: 0.0268
2024-05-22 22:54:13 [INFO]: Epoch 015 - training loss: 0.4047, validation loss: 0.0264
2024-05-22 22:54:18 [INFO]: Epoch 016 - training loss: 0.4002, validation loss: 0.0261
2024-05-22 22:54:23 [INFO]: Epoch 017 - training loss: 0.4099, validation loss: 0.0256
2024-05-22 22:54:27 [INFO]: Epoch 018 - training loss: 0.4549, validation loss: 0.0255
2024-05-22 22:54:32 [INFO]: Epoch 019 - training loss: 0.4300, validation loss: 0.0273
2024-05-22 22:54:36 [INFO]: Epoch 020 - training loss: 0.4093, validation loss: 0.0264
2024-05-22 22:54:41 [INFO]: Epoch 021 - training loss: 0.4001, validation loss: 0.0256
2024-05-22 22:54:46 [INFO]: Epoch 022 - training loss: 0.3961, validation loss: 0.0257
2024-05-22 22:54:50 [INFO]: Epoch 023 - training loss: 0.3936, validation loss: 0.0251
2024-05-22 22:54:55 [INFO]: Epoch 024 - training loss: 0.3939, validation loss: 0.0258
2024-05-22 22:54:59 [INFO]: Epoch 025 - training loss: 0.3886, validation loss: 0.0249
2024-05-22 22:55:04 [INFO]: Epoch 026 - training loss: 0.3880, validation loss: 0.0248
2024-05-22 22:55:08 [INFO]: Epoch 027 - training loss: 0.3802, validation loss: 0.0250
2024-05-22 22:55:13 [INFO]: Epoch 028 - training loss: 0.3895, validation loss: 0.0245
2024-05-22 22:55:18 [INFO]: Epoch 029 - training loss: 0.3965, validation loss: 0.0258
2024-05-22 22:55:22 [INFO]: Epoch 030 - training loss: 0.3853, validation loss: 0.0264
2024-05-22 22:55:27 [INFO]: Epoch 031 - training loss: 0.4011, validation loss: 0.0260
2024-05-22 22:55:31 [INFO]: Epoch 032 - training loss: 0.4055, validation loss: 0.0258
2024-05-22 22:55:36 [INFO]: Epoch 033 - training loss: 0.3932, validation loss: 0.0252
2024-05-22 22:55:40 [INFO]: Epoch 034 - training loss: 0.3847, validation loss: 0.0249
2024-05-22 22:55:45 [INFO]: Epoch 035 - training loss: 0.3759, validation loss: 0.0244
2024-05-22 22:55:50 [INFO]: Epoch 036 - training loss: 0.3839, validation loss: 0.0246
2024-05-22 22:55:54 [INFO]: Epoch 037 - training loss: 0.3827, validation loss: 0.0249
2024-05-22 22:55:59 [INFO]: Epoch 038 - training loss: 0.3890, validation loss: 0.0247
2024-05-22 22:56:03 [INFO]: Epoch 039 - training loss: 0.3875, validation loss: 0.0248
2024-05-22 22:56:08 [INFO]: Epoch 040 - training loss: 0.3834, validation loss: 0.0246
2024-05-22 22:56:13 [INFO]: Epoch 041 - training loss: 0.3907, validation loss: 0.0252
2024-05-22 22:56:18 [INFO]: Epoch 042 - training loss: 0.3831, validation loss: 0.0246
2024-05-22 22:56:22 [INFO]: Epoch 043 - training loss: 0.3853, validation loss: 0.0258
2024-05-22 22:56:27 [INFO]: Epoch 044 - training loss: 0.3854, validation loss: 0.0246
2024-05-22 22:56:32 [INFO]: Epoch 045 - training loss: 0.3771, validation loss: 0.0253
2024-05-22 22:56:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:56:32 [INFO]: Finished training. The best model is from epoch#35.
2024-05-22 22:56:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/BRITS_ettm1/20240522_T225303/BRITS.pypots
2024-05-22 22:56:32 [INFO]: BRITS on ETTm1: MAE=0.1295, MSE=0.0487
2024-05-22 22:56:32 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/BRITS_ettm1/imputation.pkl
2024-05-22 22:56:32 [INFO]: Using the given device: cuda:0
2024-05-22 22:56:32 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632
2024-05-22 22:56:32 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/tensorboard
2024-05-22 22:56:32 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 22:56:34 [INFO]: Epoch 001 - training loss: 1.3464, validation loss: 1.2395
2024-05-22 22:56:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch1_loss1.2395453453063965.pypots
2024-05-22 22:56:34 [INFO]: Epoch 002 - training loss: 1.0484, validation loss: 1.1042
2024-05-22 22:56:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch2_loss1.1042297035455704.pypots
2024-05-22 22:56:34 [INFO]: Epoch 003 - training loss: 0.9491, validation loss: 1.0475
2024-05-22 22:56:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch3_loss1.0474564582109451.pypots
2024-05-22 22:56:34 [INFO]: Epoch 004 - training loss: 0.9689, validation loss: 1.0256
2024-05-22 22:56:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch4_loss1.0256121456623077.pypots
2024-05-22 22:56:34 [INFO]: Epoch 005 - training loss: 0.9466, validation loss: 1.0146
2024-05-22 22:56:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch5_loss1.0145826637744904.pypots
2024-05-22 22:56:34 [INFO]: Epoch 006 - training loss: 0.9516, validation loss: 1.0084
2024-05-22 22:56:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch6_loss1.0084332823753357.pypots
2024-05-22 22:56:35 [INFO]: Epoch 007 - training loss: 0.9338, validation loss: 1.0028
2024-05-22 22:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch7_loss1.0028487294912338.pypots
2024-05-22 22:56:35 [INFO]: Epoch 008 - training loss: 0.9051, validation loss: 0.9988
2024-05-22 22:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch8_loss0.9988433420658112.pypots
2024-05-22 22:56:35 [INFO]: Epoch 009 - training loss: 0.9018, validation loss: 0.9931
2024-05-22 22:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch9_loss0.9930665791034698.pypots
2024-05-22 22:56:35 [INFO]: Epoch 010 - training loss: 0.8917, validation loss: 0.9937
2024-05-22 22:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch10_loss0.993668407201767.pypots
2024-05-22 22:56:35 [INFO]: Epoch 011 - training loss: 0.9214, validation loss: 0.9900
2024-05-22 22:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch11_loss0.9900321364402771.pypots
2024-05-22 22:56:35 [INFO]: Epoch 012 - training loss: 0.8847, validation loss: 0.9896
2024-05-22 22:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch12_loss0.9896013140678406.pypots
2024-05-22 22:56:35 [INFO]: Epoch 013 - training loss: 0.8816, validation loss: 0.9884
2024-05-22 22:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch13_loss0.988417387008667.pypots
2024-05-22 22:56:36 [INFO]: Epoch 014 - training loss: 0.9148, validation loss: 0.9890
2024-05-22 22:56:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch14_loss0.9890236258506775.pypots
2024-05-22 22:56:36 [INFO]: Epoch 015 - training loss: 0.8956, validation loss: 0.9894
2024-05-22 22:56:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch15_loss0.9893972277641296.pypots
2024-05-22 22:56:36 [INFO]: Epoch 016 - training loss: 0.8655, validation loss: 0.9879
2024-05-22 22:56:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch16_loss0.9878503531217575.pypots
2024-05-22 22:56:36 [INFO]: Epoch 017 - training loss: 0.8861, validation loss: 0.9888
2024-05-22 22:56:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch17_loss0.9888277649879456.pypots
2024-05-22 22:56:36 [INFO]: Epoch 018 - training loss: 0.8631, validation loss: 0.9884
2024-05-22 22:56:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch18_loss0.9883879870176315.pypots
2024-05-22 22:56:36 [INFO]: Epoch 019 - training loss: 0.8464, validation loss: 0.9834
2024-05-22 22:56:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch19_loss0.9833904206752777.pypots
2024-05-22 22:56:37 [INFO]: Epoch 020 - training loss: 0.8469, validation loss: 0.9844
2024-05-22 22:56:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch20_loss0.9844079911708832.pypots
2024-05-22 22:56:37 [INFO]: Epoch 021 - training loss: 0.8596, validation loss: 0.9825
2024-05-22 22:56:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch21_loss0.982476070523262.pypots
2024-05-22 22:56:37 [INFO]: Epoch 022 - training loss: 0.8524, validation loss: 0.9804
2024-05-22 22:56:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch22_loss0.9803851842880249.pypots
2024-05-22 22:56:37 [INFO]: Epoch 023 - training loss: 0.8531, validation loss: 0.9775
2024-05-22 22:56:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch23_loss0.9774862974882126.pypots
2024-05-22 22:56:37 [INFO]: Epoch 024 - training loss: 0.8469, validation loss: 0.9721
2024-05-22 22:56:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch24_loss0.9721365571022034.pypots
2024-05-22 22:56:37 [INFO]: Epoch 025 - training loss: 0.8337, validation loss: 0.9684
2024-05-22 22:56:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch25_loss0.9684096127748489.pypots
2024-05-22 22:56:38 [INFO]: Epoch 026 - training loss: 0.8338, validation loss: 0.9651
2024-05-22 22:56:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch26_loss0.9651351273059845.pypots
2024-05-22 22:56:38 [INFO]: Epoch 027 - training loss: 0.8247, validation loss: 0.9604
2024-05-22 22:56:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch27_loss0.9603523463010788.pypots
2024-05-22 22:56:38 [INFO]: Epoch 028 - training loss: 0.8147, validation loss: 0.9535
2024-05-22 22:56:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch28_loss0.9534745514392853.pypots
2024-05-22 22:56:38 [INFO]: Epoch 029 - training loss: 0.8359, validation loss: 0.9528
2024-05-22 22:56:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch29_loss0.9528485536575317.pypots
2024-05-22 22:56:38 [INFO]: Epoch 030 - training loss: 0.8399, validation loss: 0.9512
2024-05-22 22:56:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch30_loss0.9512313157320023.pypots
2024-05-22 22:56:38 [INFO]: Epoch 031 - training loss: 0.8580, validation loss: 0.9467
2024-05-22 22:56:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch31_loss0.9467341899871826.pypots
2024-05-22 22:56:38 [INFO]: Epoch 032 - training loss: 0.8229, validation loss: 0.9385
2024-05-22 22:56:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch32_loss0.9384545087814331.pypots
2024-05-22 22:56:39 [INFO]: Epoch 033 - training loss: 0.8194, validation loss: 0.9394
2024-05-22 22:56:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch33_loss0.9393552392721176.pypots
2024-05-22 22:56:39 [INFO]: Epoch 034 - training loss: 0.8272, validation loss: 0.9338
2024-05-22 22:56:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch34_loss0.9337966740131378.pypots
2024-05-22 22:56:39 [INFO]: Epoch 035 - training loss: 0.8161, validation loss: 0.9299
2024-05-22 22:56:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch35_loss0.9299451261758804.pypots
2024-05-22 22:56:39 [INFO]: Epoch 036 - training loss: 0.7996, validation loss: 0.9286
2024-05-22 22:56:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch36_loss0.9285760521888733.pypots
2024-05-22 22:56:39 [INFO]: Epoch 037 - training loss: 0.7917, validation loss: 0.9257
2024-05-22 22:56:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch37_loss0.9256535321474075.pypots
2024-05-22 22:56:39 [INFO]: Epoch 038 - training loss: 0.8102, validation loss: 0.9243
2024-05-22 22:56:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch38_loss0.9243300408124924.pypots
2024-05-22 22:56:40 [INFO]: Epoch 039 - training loss: 0.8060, validation loss: 0.9213
2024-05-22 22:56:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch39_loss0.9212838709354401.pypots
2024-05-22 22:56:40 [INFO]: Epoch 040 - training loss: 0.7920, validation loss: 0.9183
2024-05-22 22:56:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch40_loss0.9183089435100555.pypots
2024-05-22 22:56:40 [INFO]: Epoch 041 - training loss: 0.8067, validation loss: 0.9167
2024-05-22 22:56:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch41_loss0.9167076796293259.pypots
2024-05-22 22:56:40 [INFO]: Epoch 042 - training loss: 0.8444, validation loss: 0.9145
2024-05-22 22:56:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch42_loss0.9144890159368515.pypots
2024-05-22 22:56:40 [INFO]: Epoch 043 - training loss: 0.7978, validation loss: 0.9116
2024-05-22 22:56:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch43_loss0.9116421788930893.pypots
2024-05-22 22:56:40 [INFO]: Epoch 044 - training loss: 0.7838, validation loss: 0.9114
2024-05-22 22:56:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch44_loss0.9114193320274353.pypots
2024-05-22 22:56:41 [INFO]: Epoch 045 - training loss: 0.8183, validation loss: 0.9083
2024-05-22 22:56:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch45_loss0.908335343003273.pypots
2024-05-22 22:56:41 [INFO]: Epoch 046 - training loss: 0.8217, validation loss: 0.9074
2024-05-22 22:56:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch46_loss0.9073501825332642.pypots
2024-05-22 22:56:41 [INFO]: Epoch 047 - training loss: 0.8387, validation loss: 0.9056
2024-05-22 22:56:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch47_loss0.905583843588829.pypots
2024-05-22 22:56:41 [INFO]: Epoch 048 - training loss: 0.7843, validation loss: 0.9021
2024-05-22 22:56:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch48_loss0.9021121114492416.pypots
2024-05-22 22:56:41 [INFO]: Epoch 049 - training loss: 0.7995, validation loss: 0.9010
2024-05-22 22:56:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch49_loss0.9009758681058884.pypots
2024-05-22 22:56:41 [INFO]: Epoch 050 - training loss: 0.8007, validation loss: 0.9009
2024-05-22 22:56:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch50_loss0.9009175002574921.pypots
2024-05-22 22:56:42 [INFO]: Epoch 051 - training loss: 0.8196, validation loss: 0.8994
2024-05-22 22:56:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch51_loss0.8994466364383698.pypots
2024-05-22 22:56:42 [INFO]: Epoch 052 - training loss: 0.7886, validation loss: 0.8976
2024-05-22 22:56:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch52_loss0.897593304514885.pypots
2024-05-22 22:56:42 [INFO]: Epoch 053 - training loss: 0.8105, validation loss: 0.8953
2024-05-22 22:56:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch53_loss0.8952947854995728.pypots
2024-05-22 22:56:42 [INFO]: Epoch 054 - training loss: 0.7984, validation loss: 0.8933
2024-05-22 22:56:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch54_loss0.8933022767305374.pypots
2024-05-22 22:56:42 [INFO]: Epoch 055 - training loss: 0.7874, validation loss: 0.8923
2024-05-22 22:56:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch55_loss0.892303854227066.pypots
2024-05-22 22:56:42 [INFO]: Epoch 056 - training loss: 0.7916, validation loss: 0.8930
2024-05-22 22:56:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch56_loss0.8929764479398727.pypots
2024-05-22 22:56:42 [INFO]: Epoch 057 - training loss: 0.7750, validation loss: 0.8919
2024-05-22 22:56:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch57_loss0.8919306397438049.pypots
2024-05-22 22:56:43 [INFO]: Epoch 058 - training loss: 0.7661, validation loss: 0.8916
2024-05-22 22:56:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch58_loss0.8916035294532776.pypots
2024-05-22 22:56:43 [INFO]: Epoch 059 - training loss: 0.7841, validation loss: 0.8895
2024-05-22 22:56:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch59_loss0.8895115703344345.pypots
2024-05-22 22:56:43 [INFO]: Epoch 060 - training loss: 0.7628, validation loss: 0.8898
2024-05-22 22:56:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch60_loss0.8897830992937088.pypots
2024-05-22 22:56:43 [INFO]: Epoch 061 - training loss: 0.7899, validation loss: 0.8883
2024-05-22 22:56:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch61_loss0.8882791548967361.pypots
2024-05-22 22:56:43 [INFO]: Epoch 062 - training loss: 0.7650, validation loss: 0.8887
2024-05-22 22:56:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch62_loss0.8886819332838058.pypots
2024-05-22 22:56:43 [INFO]: Epoch 063 - training loss: 0.8047, validation loss: 0.8845
2024-05-22 22:56:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch63_loss0.8845109194517136.pypots
2024-05-22 22:56:44 [INFO]: Epoch 064 - training loss: 0.8032, validation loss: 0.8848
2024-05-22 22:56:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch64_loss0.8848373591899872.pypots
2024-05-22 22:56:44 [INFO]: Epoch 065 - training loss: 0.7747, validation loss: 0.8852
2024-05-22 22:56:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch65_loss0.8851868361234665.pypots
2024-05-22 22:56:44 [INFO]: Epoch 066 - training loss: 0.7793, validation loss: 0.8867
2024-05-22 22:56:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch66_loss0.8866578191518784.pypots
2024-05-22 22:56:44 [INFO]: Epoch 067 - training loss: 0.7764, validation loss: 0.8814
2024-05-22 22:56:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch67_loss0.8814472705125809.pypots
2024-05-22 22:56:44 [INFO]: Epoch 068 - training loss: 0.7784, validation loss: 0.8829
2024-05-22 22:56:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch68_loss0.8829223960638046.pypots
2024-05-22 22:56:44 [INFO]: Epoch 069 - training loss: 0.7968, validation loss: 0.8838
2024-05-22 22:56:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch69_loss0.883841261267662.pypots
2024-05-22 22:56:45 [INFO]: Epoch 070 - training loss: 0.7873, validation loss: 0.8842
2024-05-22 22:56:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch70_loss0.8841730654239655.pypots
2024-05-22 22:56:45 [INFO]: Epoch 071 - training loss: 0.7566, validation loss: 0.8827
2024-05-22 22:56:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch71_loss0.8826558440923691.pypots
2024-05-22 22:56:45 [INFO]: Epoch 072 - training loss: 0.7975, validation loss: 0.8812
2024-05-22 22:56:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch72_loss0.8812317252159119.pypots
2024-05-22 22:56:45 [INFO]: Epoch 073 - training loss: 0.7587, validation loss: 0.8835
2024-05-22 22:56:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch73_loss0.8834659159183502.pypots
2024-05-22 22:56:45 [INFO]: Epoch 074 - training loss: 0.7787, validation loss: 0.8810
2024-05-22 22:56:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch74_loss0.8809859305620193.pypots
2024-05-22 22:56:45 [INFO]: Epoch 075 - training loss: 0.7700, validation loss: 0.8795
2024-05-22 22:56:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch75_loss0.879454031586647.pypots
2024-05-22 22:56:45 [INFO]: Epoch 076 - training loss: 0.7864, validation loss: 0.8819
2024-05-22 22:56:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch76_loss0.8819068372249603.pypots
2024-05-22 22:56:46 [INFO]: Epoch 077 - training loss: 0.7776, validation loss: 0.8844
2024-05-22 22:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch77_loss0.8843696117401123.pypots
2024-05-22 22:56:46 [INFO]: Epoch 078 - training loss: 0.8011, validation loss: 0.8827
2024-05-22 22:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch78_loss0.8826932311058044.pypots
2024-05-22 22:56:46 [INFO]: Epoch 079 - training loss: 0.7806, validation loss: 0.8799
2024-05-22 22:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch79_loss0.8799012750387192.pypots
2024-05-22 22:56:46 [INFO]: Epoch 080 - training loss: 0.7824, validation loss: 0.8795
2024-05-22 22:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch80_loss0.8795038014650345.pypots
2024-05-22 22:56:46 [INFO]: Epoch 081 - training loss: 0.7875, validation loss: 0.8785
2024-05-22 22:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch81_loss0.8784557729959488.pypots
2024-05-22 22:56:46 [INFO]: Epoch 082 - training loss: 0.7692, validation loss: 0.8803
2024-05-22 22:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch82_loss0.880320742726326.pypots
2024-05-22 22:56:47 [INFO]: Epoch 083 - training loss: 0.7763, validation loss: 0.8798
2024-05-22 22:56:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch83_loss0.8797951638698578.pypots
2024-05-22 22:56:47 [INFO]: Epoch 084 - training loss: 0.7574, validation loss: 0.8817
2024-05-22 22:56:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch84_loss0.8817059695720673.pypots
2024-05-22 22:56:47 [INFO]: Epoch 085 - training loss: 0.7773, validation loss: 0.8820
2024-05-22 22:56:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch85_loss0.8820348083972931.pypots
2024-05-22 22:56:47 [INFO]: Epoch 086 - training loss: 0.7538, validation loss: 0.8786
2024-05-22 22:56:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch86_loss0.8785768151283264.pypots
2024-05-22 22:56:47 [INFO]: Epoch 087 - training loss: 0.7899, validation loss: 0.8787
2024-05-22 22:56:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch87_loss0.8787004798650742.pypots
2024-05-22 22:56:47 [INFO]: Epoch 088 - training loss: 0.7810, validation loss: 0.8786
2024-05-22 22:56:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch88_loss0.8786149173974991.pypots
2024-05-22 22:56:48 [INFO]: Epoch 089 - training loss: 0.7710, validation loss: 0.8788
2024-05-22 22:56:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch89_loss0.878775492310524.pypots
2024-05-22 22:56:48 [INFO]: Epoch 090 - training loss: 0.7684, validation loss: 0.8771
2024-05-22 22:56:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch90_loss0.8771448731422424.pypots
2024-05-22 22:56:48 [INFO]: Epoch 091 - training loss: 0.7996, validation loss: 0.8780
2024-05-22 22:56:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch91_loss0.8779645562171936.pypots
2024-05-22 22:56:48 [INFO]: Epoch 092 - training loss: 0.7801, validation loss: 0.8761
2024-05-22 22:56:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch92_loss0.8761105239391327.pypots
2024-05-22 22:56:48 [INFO]: Epoch 093 - training loss: 0.7765, validation loss: 0.8761
2024-05-22 22:56:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch93_loss0.8761207610368729.pypots
2024-05-22 22:56:48 [INFO]: Epoch 094 - training loss: 0.7706, validation loss: 0.8776
2024-05-22 22:56:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch94_loss0.877596989274025.pypots
2024-05-22 22:56:48 [INFO]: Epoch 095 - training loss: 0.7681, validation loss: 0.8757
2024-05-22 22:56:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch95_loss0.8757386654615402.pypots
2024-05-22 22:56:49 [INFO]: Epoch 096 - training loss: 0.7654, validation loss: 0.8779
2024-05-22 22:56:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch96_loss0.8779321610927582.pypots
2024-05-22 22:56:49 [INFO]: Epoch 097 - training loss: 0.7635, validation loss: 0.8762
2024-05-22 22:56:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch97_loss0.8762018382549286.pypots
2024-05-22 22:56:49 [INFO]: Epoch 098 - training loss: 0.7649, validation loss: 0.8741
2024-05-22 22:56:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch98_loss0.8741375505924225.pypots
2024-05-22 22:56:49 [INFO]: Epoch 099 - training loss: 0.7814, validation loss: 0.8775
2024-05-22 22:56:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch99_loss0.877466082572937.pypots
2024-05-22 22:56:49 [INFO]: Epoch 100 - training loss: 0.7972, validation loss: 0.8767
2024-05-22 22:56:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch100_loss0.8766833394765854.pypots
2024-05-22 22:56:49 [INFO]: Epoch 101 - training loss: 0.7621, validation loss: 0.8788
2024-05-22 22:56:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch101_loss0.8787688165903091.pypots
2024-05-22 22:56:50 [INFO]: Epoch 102 - training loss: 0.7699, validation loss: 0.8748
2024-05-22 22:56:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch102_loss0.8748206794261932.pypots
2024-05-22 22:56:50 [INFO]: Epoch 103 - training loss: 0.7881, validation loss: 0.8739
2024-05-22 22:56:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch103_loss0.873874619603157.pypots
2024-05-22 22:56:50 [INFO]: Epoch 104 - training loss: 0.7743, validation loss: 0.8738
2024-05-22 22:56:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch104_loss0.8738327622413635.pypots
2024-05-22 22:56:50 [INFO]: Epoch 105 - training loss: 0.7641, validation loss: 0.8694
2024-05-22 22:56:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch105_loss0.8693639487028122.pypots
2024-05-22 22:56:50 [INFO]: Epoch 106 - training loss: 0.7752, validation loss: 0.8729
2024-05-22 22:56:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch106_loss0.8728834688663483.pypots
2024-05-22 22:56:50 [INFO]: Epoch 107 - training loss: 0.7641, validation loss: 0.8738
2024-05-22 22:56:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch107_loss0.8738240599632263.pypots
2024-05-22 22:56:51 [INFO]: Epoch 108 - training loss: 0.7434, validation loss: 0.8723
2024-05-22 22:56:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch108_loss0.8722528666257858.pypots
2024-05-22 22:56:51 [INFO]: Epoch 109 - training loss: 0.7642, validation loss: 0.8693
2024-05-22 22:56:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch109_loss0.8692826330661774.pypots
2024-05-22 22:56:51 [INFO]: Epoch 110 - training loss: 0.7710, validation loss: 0.8717
2024-05-22 22:56:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch110_loss0.8716624230146408.pypots
2024-05-22 22:56:51 [INFO]: Epoch 111 - training loss: 0.7738, validation loss: 0.8708
2024-05-22 22:56:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch111_loss0.8708209097385406.pypots
2024-05-22 22:56:51 [INFO]: Epoch 112 - training loss: 0.8080, validation loss: 0.8707
2024-05-22 22:56:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch112_loss0.8706675320863724.pypots
2024-05-22 22:56:51 [INFO]: Epoch 113 - training loss: 0.7611, validation loss: 0.8693
2024-05-22 22:56:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch113_loss0.8692801594734192.pypots
2024-05-22 22:56:51 [INFO]: Epoch 114 - training loss: 0.7614, validation loss: 0.8671
2024-05-22 22:56:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch114_loss0.8670846819877625.pypots
2024-05-22 22:56:52 [INFO]: Epoch 115 - training loss: 0.7696, validation loss: 0.8713
2024-05-22 22:56:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch115_loss0.8712804615497589.pypots
2024-05-22 22:56:52 [INFO]: Epoch 116 - training loss: 0.7408, validation loss: 0.8676
2024-05-22 22:56:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch116_loss0.8675928264856339.pypots
2024-05-22 22:56:52 [INFO]: Epoch 117 - training loss: 0.7677, validation loss: 0.8677
2024-05-22 22:56:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch117_loss0.8676593899726868.pypots
2024-05-22 22:56:52 [INFO]: Epoch 118 - training loss: 0.7737, validation loss: 0.8649
2024-05-22 22:56:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch118_loss0.8648577779531479.pypots
2024-05-22 22:56:52 [INFO]: Epoch 119 - training loss: 0.7860, validation loss: 0.8650
2024-05-22 22:56:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch119_loss0.865018904209137.pypots
2024-05-22 22:56:52 [INFO]: Epoch 120 - training loss: 0.7646, validation loss: 0.8648
2024-05-22 22:56:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch120_loss0.8648229688405991.pypots
2024-05-22 22:56:53 [INFO]: Epoch 121 - training loss: 0.7766, validation loss: 0.8622
2024-05-22 22:56:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch121_loss0.862195298075676.pypots
2024-05-22 22:56:53 [INFO]: Epoch 122 - training loss: 0.7656, validation loss: 0.8661
2024-05-22 22:56:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch122_loss0.8660634607076645.pypots
2024-05-22 22:56:53 [INFO]: Epoch 123 - training loss: 0.7634, validation loss: 0.8628
2024-05-22 22:56:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch123_loss0.8627762794494629.pypots
2024-05-22 22:56:53 [INFO]: Epoch 124 - training loss: 0.7870, validation loss: 0.8636
2024-05-22 22:56:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch124_loss0.8636153191328049.pypots
2024-05-22 22:56:53 [INFO]: Epoch 125 - training loss: 0.7663, validation loss: 0.8626
2024-05-22 22:56:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch125_loss0.8626332730054855.pypots
2024-05-22 22:56:54 [INFO]: Epoch 126 - training loss: 0.7650, validation loss: 0.8640
2024-05-22 22:56:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch126_loss0.8640012294054031.pypots
2024-05-22 22:56:54 [INFO]: Epoch 127 - training loss: 0.7617, validation loss: 0.8639
2024-05-22 22:56:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch127_loss0.8639214485883713.pypots
2024-05-22 22:56:54 [INFO]: Epoch 128 - training loss: 0.7592, validation loss: 0.8657
2024-05-22 22:56:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch128_loss0.865666463971138.pypots
2024-05-22 22:56:54 [INFO]: Epoch 129 - training loss: 0.7725, validation loss: 0.8621
2024-05-22 22:56:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch129_loss0.8621303588151932.pypots
2024-05-22 22:56:54 [INFO]: Epoch 130 - training loss: 0.7884, validation loss: 0.8632
2024-05-22 22:56:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch130_loss0.8631624132394791.pypots
2024-05-22 22:56:54 [INFO]: Epoch 131 - training loss: 0.7730, validation loss: 0.8595
2024-05-22 22:56:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch131_loss0.8594750761985779.pypots
2024-05-22 22:56:54 [INFO]: Epoch 132 - training loss: 0.7627, validation loss: 0.8607
2024-05-22 22:56:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch132_loss0.8607201427221298.pypots
2024-05-22 22:56:55 [INFO]: Epoch 133 - training loss: 0.8031, validation loss: 0.8626
2024-05-22 22:56:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch133_loss0.862581342458725.pypots
2024-05-22 22:56:55 [INFO]: Epoch 134 - training loss: 0.7689, validation loss: 0.8579
2024-05-22 22:56:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch134_loss0.8579224050045013.pypots
2024-05-22 22:56:55 [INFO]: Epoch 135 - training loss: 0.7702, validation loss: 0.8566
2024-05-22 22:56:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch135_loss0.8565798252820969.pypots
2024-05-22 22:56:55 [INFO]: Epoch 136 - training loss: 0.7532, validation loss: 0.8564
2024-05-22 22:56:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch136_loss0.8563635945320129.pypots
2024-05-22 22:56:55 [INFO]: Epoch 137 - training loss: 0.7666, validation loss: 0.8597
2024-05-22 22:56:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch137_loss0.8596707135438919.pypots
2024-05-22 22:56:55 [INFO]: Epoch 138 - training loss: 0.7703, validation loss: 0.8600
2024-05-22 22:56:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch138_loss0.859961673617363.pypots
2024-05-22 22:56:56 [INFO]: Epoch 139 - training loss: 0.7693, validation loss: 0.8599
2024-05-22 22:56:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch139_loss0.8599362820386887.pypots
2024-05-22 22:56:56 [INFO]: Epoch 140 - training loss: 0.7747, validation loss: 0.8561
2024-05-22 22:56:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch140_loss0.8560879528522491.pypots
2024-05-22 22:56:56 [INFO]: Epoch 141 - training loss: 0.7594, validation loss: 0.8554
2024-05-22 22:56:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch141_loss0.8553853929042816.pypots
2024-05-22 22:56:56 [INFO]: Epoch 142 - training loss: 0.7618, validation loss: 0.8569
2024-05-22 22:56:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch142_loss0.8568768054246902.pypots
2024-05-22 22:56:56 [INFO]: Epoch 143 - training loss: 0.7581, validation loss: 0.8561
2024-05-22 22:56:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch143_loss0.8560943454504013.pypots
2024-05-22 22:56:56 [INFO]: Epoch 144 - training loss: 0.7572, validation loss: 0.8545
2024-05-22 22:56:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch144_loss0.8544889390468597.pypots
2024-05-22 22:56:57 [INFO]: Epoch 145 - training loss: 0.7763, validation loss: 0.8562
2024-05-22 22:56:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch145_loss0.8562441170215607.pypots
2024-05-22 22:56:57 [INFO]: Epoch 146 - training loss: 0.7488, validation loss: 0.8547
2024-05-22 22:56:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch146_loss0.8546852916479111.pypots
2024-05-22 22:56:57 [INFO]: Epoch 147 - training loss: 0.7585, validation loss: 0.8548
2024-05-22 22:56:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch147_loss0.8548204153776169.pypots
2024-05-22 22:56:57 [INFO]: Epoch 148 - training loss: 0.7474, validation loss: 0.8535
2024-05-22 22:56:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch148_loss0.8535160273313522.pypots
2024-05-22 22:56:57 [INFO]: Epoch 149 - training loss: 0.7818, validation loss: 0.8511
2024-05-22 22:56:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch149_loss0.8510771095752716.pypots
2024-05-22 22:56:57 [INFO]: Epoch 150 - training loss: 0.7782, validation loss: 0.8519
2024-05-22 22:56:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch150_loss0.8518739193677902.pypots
2024-05-22 22:56:57 [INFO]: Epoch 151 - training loss: 0.7706, validation loss: 0.8498
2024-05-22 22:56:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch151_loss0.8497897982597351.pypots
2024-05-22 22:56:58 [INFO]: Epoch 152 - training loss: 0.8107, validation loss: 0.8499
2024-05-22 22:56:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch152_loss0.8498885333538055.pypots
2024-05-22 22:56:58 [INFO]: Epoch 153 - training loss: 0.7680, validation loss: 0.8530
2024-05-22 22:56:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch153_loss0.8530242443084717.pypots
2024-05-22 22:56:58 [INFO]: Epoch 154 - training loss: 0.7809, validation loss: 0.8532
2024-05-22 22:56:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch154_loss0.8531871736049652.pypots
2024-05-22 22:56:58 [INFO]: Epoch 155 - training loss: 0.7632, validation loss: 0.8515
2024-05-22 22:56:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch155_loss0.8514864593744278.pypots
2024-05-22 22:56:58 [INFO]: Epoch 156 - training loss: 0.7693, validation loss: 0.8492
2024-05-22 22:56:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch156_loss0.8492069989442825.pypots
2024-05-22 22:56:59 [INFO]: Epoch 157 - training loss: 0.7613, validation loss: 0.8512
2024-05-22 22:56:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch157_loss0.8511639535427094.pypots
2024-05-22 22:56:59 [INFO]: Epoch 158 - training loss: 0.7689, validation loss: 0.8480
2024-05-22 22:56:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch158_loss0.8480485677719116.pypots
2024-05-22 22:56:59 [INFO]: Epoch 159 - training loss: 0.7759, validation loss: 0.8472
2024-05-22 22:56:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch159_loss0.8472105860710144.pypots
2024-05-22 22:56:59 [INFO]: Epoch 160 - training loss: 0.8057, validation loss: 0.8476
2024-05-22 22:56:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch160_loss0.847633108496666.pypots
2024-05-22 22:56:59 [INFO]: Epoch 161 - training loss: 0.7659, validation loss: 0.8434
2024-05-22 22:56:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch161_loss0.8433942943811417.pypots
2024-05-22 22:56:59 [INFO]: Epoch 162 - training loss: 0.7619, validation loss: 0.8469
2024-05-22 22:56:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch162_loss0.8469300717115402.pypots
2024-05-22 22:56:59 [INFO]: Epoch 163 - training loss: 0.7699, validation loss: 0.8479
2024-05-22 22:56:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch163_loss0.8479163646697998.pypots
2024-05-22 22:57:00 [INFO]: Epoch 164 - training loss: 0.7646, validation loss: 0.8440
2024-05-22 22:57:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch164_loss0.8440367430448532.pypots
2024-05-22 22:57:00 [INFO]: Epoch 165 - training loss: 0.7741, validation loss: 0.8437
2024-05-22 22:57:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch165_loss0.8436527848243713.pypots
2024-05-22 22:57:00 [INFO]: Epoch 166 - training loss: 0.7902, validation loss: 0.8431
2024-05-22 22:57:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch166_loss0.8430906236171722.pypots
2024-05-22 22:57:00 [INFO]: Epoch 167 - training loss: 0.7642, validation loss: 0.8435
2024-05-22 22:57:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch167_loss0.843539297580719.pypots
2024-05-22 22:57:00 [INFO]: Epoch 168 - training loss: 0.8062, validation loss: 0.8426
2024-05-22 22:57:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch168_loss0.8426211923360825.pypots
2024-05-22 22:57:00 [INFO]: Epoch 169 - training loss: 0.7946, validation loss: 0.8413
2024-05-22 22:57:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch169_loss0.8413399904966354.pypots
2024-05-22 22:57:01 [INFO]: Epoch 170 - training loss: 0.7619, validation loss: 0.8414
2024-05-22 22:57:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch170_loss0.8414445221424103.pypots
2024-05-22 22:57:01 [INFO]: Epoch 171 - training loss: 0.7498, validation loss: 0.8424
2024-05-22 22:57:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch171_loss0.8423904776573181.pypots
2024-05-22 22:57:01 [INFO]: Epoch 172 - training loss: 0.7645, validation loss: 0.8419
2024-05-22 22:57:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch172_loss0.8419478386640549.pypots
2024-05-22 22:57:01 [INFO]: Epoch 173 - training loss: 0.7630, validation loss: 0.8375
2024-05-22 22:57:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch173_loss0.8374614268541336.pypots
2024-05-22 22:57:01 [INFO]: Epoch 174 - training loss: 0.7406, validation loss: 0.8450
2024-05-22 22:57:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch174_loss0.8450229614973068.pypots
2024-05-22 22:57:01 [INFO]: Epoch 175 - training loss: 0.7778, validation loss: 0.8419
2024-05-22 22:57:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch175_loss0.8418929725885391.pypots
2024-05-22 22:57:02 [INFO]: Epoch 176 - training loss: 0.7500, validation loss: 0.8398
2024-05-22 22:57:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch176_loss0.8397544622421265.pypots
2024-05-22 22:57:02 [INFO]: Epoch 177 - training loss: 0.7802, validation loss: 0.8398
2024-05-22 22:57:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch177_loss0.8397690802812576.pypots
2024-05-22 22:57:02 [INFO]: Epoch 178 - training loss: 0.7646, validation loss: 0.8400
2024-05-22 22:57:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch178_loss0.8400212228298187.pypots
2024-05-22 22:57:02 [INFO]: Epoch 179 - training loss: 0.7793, validation loss: 0.8377
2024-05-22 22:57:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch179_loss0.8377227932214737.pypots
2024-05-22 22:57:02 [INFO]: Epoch 180 - training loss: 0.7702, validation loss: 0.8396
2024-05-22 22:57:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch180_loss0.8395964205265045.pypots
2024-05-22 22:57:02 [INFO]: Epoch 181 - training loss: 0.7531, validation loss: 0.8368
2024-05-22 22:57:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch181_loss0.836756631731987.pypots
2024-05-22 22:57:03 [INFO]: Epoch 182 - training loss: 0.7757, validation loss: 0.8349
2024-05-22 22:57:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch182_loss0.8348869830369949.pypots
2024-05-22 22:57:03 [INFO]: Epoch 183 - training loss: 0.7537, validation loss: 0.8377
2024-05-22 22:57:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch183_loss0.837736651301384.pypots
2024-05-22 22:57:03 [INFO]: Epoch 184 - training loss: 0.7624, validation loss: 0.8357
2024-05-22 22:57:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch184_loss0.8357428014278412.pypots
2024-05-22 22:57:03 [INFO]: Epoch 185 - training loss: 0.7348, validation loss: 0.8334
2024-05-22 22:57:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch185_loss0.8333640545606613.pypots
2024-05-22 22:57:03 [INFO]: Epoch 186 - training loss: 0.7599, validation loss: 0.8371
2024-05-22 22:57:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch186_loss0.8370712846517563.pypots
2024-05-22 22:57:03 [INFO]: Epoch 187 - training loss: 0.7637, validation loss: 0.8347
2024-05-22 22:57:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch187_loss0.8347107470035553.pypots
2024-05-22 22:57:04 [INFO]: Epoch 188 - training loss: 0.7924, validation loss: 0.8323
2024-05-22 22:57:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch188_loss0.8322532027959824.pypots
2024-05-22 22:57:04 [INFO]: Epoch 189 - training loss: 0.7783, validation loss: 0.8307
2024-05-22 22:57:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch189_loss0.8306632488965988.pypots
2024-05-22 22:57:04 [INFO]: Epoch 190 - training loss: 0.7638, validation loss: 0.8323
2024-05-22 22:57:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch190_loss0.8322529345750809.pypots
2024-05-22 22:57:04 [INFO]: Epoch 191 - training loss: 0.7682, validation loss: 0.8309
2024-05-22 22:57:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch191_loss0.8309020698070526.pypots
2024-05-22 22:57:04 [INFO]: Epoch 192 - training loss: 0.7401, validation loss: 0.8305
2024-05-22 22:57:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch192_loss0.8304866254329681.pypots
2024-05-22 22:57:04 [INFO]: Epoch 193 - training loss: 0.7609, validation loss: 0.8361
2024-05-22 22:57:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch193_loss0.8361320197582245.pypots
2024-05-22 22:57:05 [INFO]: Epoch 194 - training loss: 0.7561, validation loss: 0.8318
2024-05-22 22:57:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch194_loss0.8317691534757614.pypots
2024-05-22 22:57:05 [INFO]: Epoch 195 - training loss: 0.7492, validation loss: 0.8289
2024-05-22 22:57:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch195_loss0.8288950622081757.pypots
2024-05-22 22:57:05 [INFO]: Epoch 196 - training loss: 0.7726, validation loss: 0.8287
2024-05-22 22:57:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch196_loss0.828741118311882.pypots
2024-05-22 22:57:05 [INFO]: Epoch 197 - training loss: 0.7797, validation loss: 0.8284
2024-05-22 22:57:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch197_loss0.8283835649490356.pypots
2024-05-22 22:57:05 [INFO]: Epoch 198 - training loss: 0.7654, validation loss: 0.8279
2024-05-22 22:57:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch198_loss0.8278770446777344.pypots
2024-05-22 22:57:05 [INFO]: Epoch 199 - training loss: 0.7570, validation loss: 0.8264
2024-05-22 22:57:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch199_loss0.8263624757528305.pypots
2024-05-22 22:57:05 [INFO]: Epoch 200 - training loss: 0.7684, validation loss: 0.8257
2024-05-22 22:57:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch200_loss0.8256774544715881.pypots
2024-05-22 22:57:06 [INFO]: Epoch 201 - training loss: 0.7711, validation loss: 0.8264
2024-05-22 22:57:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch201_loss0.8264158368110657.pypots
2024-05-22 22:57:06 [INFO]: Epoch 202 - training loss: 0.7407, validation loss: 0.8244
2024-05-22 22:57:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch202_loss0.8244101703166962.pypots
2024-05-22 22:57:06 [INFO]: Epoch 203 - training loss: 0.7684, validation loss: 0.8265
2024-05-22 22:57:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch203_loss0.8265189081430435.pypots
2024-05-22 22:57:06 [INFO]: Epoch 204 - training loss: 0.7635, validation loss: 0.8258
2024-05-22 22:57:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch204_loss0.8258245587348938.pypots
2024-05-22 22:57:06 [INFO]: Epoch 205 - training loss: 0.7614, validation loss: 0.8262
2024-05-22 22:57:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch205_loss0.8262017667293549.pypots
2024-05-22 22:57:06 [INFO]: Epoch 206 - training loss: 0.7617, validation loss: 0.8239
2024-05-22 22:57:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch206_loss0.8239310085773468.pypots
2024-05-22 22:57:07 [INFO]: Epoch 207 - training loss: 0.7668, validation loss: 0.8259
2024-05-22 22:57:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch207_loss0.8259233236312866.pypots
2024-05-22 22:57:07 [INFO]: Epoch 208 - training loss: 0.7847, validation loss: 0.8249
2024-05-22 22:57:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch208_loss0.8248925805091858.pypots
2024-05-22 22:57:07 [INFO]: Epoch 209 - training loss: 0.7550, validation loss: 0.8216
2024-05-22 22:57:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch209_loss0.8215522915124893.pypots
2024-05-22 22:57:07 [INFO]: Epoch 210 - training loss: 0.7532, validation loss: 0.8229
2024-05-22 22:57:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch210_loss0.8229264318943024.pypots
2024-05-22 22:57:07 [INFO]: Epoch 211 - training loss: 0.7403, validation loss: 0.8260
2024-05-22 22:57:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch211_loss0.8260309398174286.pypots
2024-05-22 22:57:07 [INFO]: Epoch 212 - training loss: 0.7642, validation loss: 0.8240
2024-05-22 22:57:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch212_loss0.824036717414856.pypots
2024-05-22 22:57:08 [INFO]: Epoch 213 - training loss: 0.7579, validation loss: 0.8214
2024-05-22 22:57:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch213_loss0.8214023560285568.pypots
2024-05-22 22:57:08 [INFO]: Epoch 214 - training loss: 0.7389, validation loss: 0.8221
2024-05-22 22:57:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch214_loss0.8221389204263687.pypots
2024-05-22 22:57:08 [INFO]: Epoch 215 - training loss: 0.7434, validation loss: 0.8216
2024-05-22 22:57:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch215_loss0.8216357976198196.pypots
2024-05-22 22:57:08 [INFO]: Epoch 216 - training loss: 0.7558, validation loss: 0.8201
2024-05-22 22:57:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch216_loss0.8200941830873489.pypots
2024-05-22 22:57:08 [INFO]: Epoch 217 - training loss: 0.7609, validation loss: 0.8210
2024-05-22 22:57:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch217_loss0.8209525942802429.pypots
2024-05-22 22:57:08 [INFO]: Epoch 218 - training loss: 0.7577, validation loss: 0.8184
2024-05-22 22:57:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch218_loss0.8183546662330627.pypots
2024-05-22 22:57:09 [INFO]: Epoch 219 - training loss: 0.7538, validation loss: 0.8216
2024-05-22 22:57:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch219_loss0.8215737491846085.pypots
2024-05-22 22:57:09 [INFO]: Epoch 220 - training loss: 0.7536, validation loss: 0.8190
2024-05-22 22:57:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch220_loss0.8189825117588043.pypots
2024-05-22 22:57:09 [INFO]: Epoch 221 - training loss: 0.7660, validation loss: 0.8209
2024-05-22 22:57:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch221_loss0.8209473043680191.pypots
2024-05-22 22:57:09 [INFO]: Epoch 222 - training loss: 0.7958, validation loss: 0.8221
2024-05-22 22:57:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch222_loss0.8221331089735031.pypots
2024-05-22 22:57:09 [INFO]: Epoch 223 - training loss: 0.7631, validation loss: 0.8183
2024-05-22 22:57:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch223_loss0.818301722407341.pypots
2024-05-22 22:57:09 [INFO]: Epoch 224 - training loss: 0.7475, validation loss: 0.8173
2024-05-22 22:57:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch224_loss0.8173404783010483.pypots
2024-05-22 22:57:10 [INFO]: Epoch 225 - training loss: 0.7532, validation loss: 0.8177
2024-05-22 22:57:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch225_loss0.8176622539758682.pypots
2024-05-22 22:57:10 [INFO]: Epoch 226 - training loss: 0.7546, validation loss: 0.8167
2024-05-22 22:57:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch226_loss0.8166731745004654.pypots
2024-05-22 22:57:10 [INFO]: Epoch 227 - training loss: 0.7753, validation loss: 0.8180
2024-05-22 22:57:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch227_loss0.8179669082164764.pypots
2024-05-22 22:57:10 [INFO]: Epoch 228 - training loss: 0.7517, validation loss: 0.8206
2024-05-22 22:57:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch228_loss0.820576474070549.pypots
2024-05-22 22:57:10 [INFO]: Epoch 229 - training loss: 0.7536, validation loss: 0.8194
2024-05-22 22:57:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch229_loss0.8194165974855423.pypots
2024-05-22 22:57:10 [INFO]: Epoch 230 - training loss: 0.7467, validation loss: 0.8180
2024-05-22 22:57:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch230_loss0.8180376440286636.pypots
2024-05-22 22:57:11 [INFO]: Epoch 231 - training loss: 0.7613, validation loss: 0.8184
2024-05-22 22:57:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch231_loss0.8184030652046204.pypots
2024-05-22 22:57:11 [INFO]: Epoch 232 - training loss: 0.7833, validation loss: 0.8180
2024-05-22 22:57:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch232_loss0.8180389404296875.pypots
2024-05-22 22:57:11 [INFO]: Epoch 233 - training loss: 0.7762, validation loss: 0.8162
2024-05-22 22:57:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch233_loss0.8162098228931427.pypots
2024-05-22 22:57:11 [INFO]: Epoch 234 - training loss: 0.7605, validation loss: 0.8172
2024-05-22 22:57:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch234_loss0.8172331005334854.pypots
2024-05-22 22:57:11 [INFO]: Epoch 235 - training loss: 0.7482, validation loss: 0.8156
2024-05-22 22:57:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch235_loss0.815571129322052.pypots
2024-05-22 22:57:11 [INFO]: Epoch 236 - training loss: 0.7658, validation loss: 0.8168
2024-05-22 22:57:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch236_loss0.8167838901281357.pypots
2024-05-22 22:57:12 [INFO]: Epoch 237 - training loss: 0.7475, validation loss: 0.8153
2024-05-22 22:57:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch237_loss0.8153074383735657.pypots
2024-05-22 22:57:12 [INFO]: Epoch 238 - training loss: 0.7625, validation loss: 0.8147
2024-05-22 22:57:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch238_loss0.8146962821483612.pypots
2024-05-22 22:57:12 [INFO]: Epoch 239 - training loss: 0.7649, validation loss: 0.8145
2024-05-22 22:57:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch239_loss0.8145250678062439.pypots
2024-05-22 22:57:12 [INFO]: Epoch 240 - training loss: 0.7526, validation loss: 0.8145
2024-05-22 22:57:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch240_loss0.8144921958446503.pypots
2024-05-22 22:57:12 [INFO]: Epoch 241 - training loss: 0.7651, validation loss: 0.8121
2024-05-22 22:57:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch241_loss0.8121369928121567.pypots
2024-05-22 22:57:12 [INFO]: Epoch 242 - training loss: 0.7543, validation loss: 0.8131
2024-05-22 22:57:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch242_loss0.8131237030029297.pypots
2024-05-22 22:57:13 [INFO]: Epoch 243 - training loss: 0.7794, validation loss: 0.8156
2024-05-22 22:57:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch243_loss0.8155732452869415.pypots
2024-05-22 22:57:13 [INFO]: Epoch 244 - training loss: 0.7478, validation loss: 0.8155
2024-05-22 22:57:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch244_loss0.8155390322208405.pypots
2024-05-22 22:57:13 [INFO]: Epoch 245 - training loss: 0.7675, validation loss: 0.8127
2024-05-22 22:57:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch245_loss0.8126603215932846.pypots
2024-05-22 22:57:13 [INFO]: Epoch 246 - training loss: 0.7617, validation loss: 0.8144
2024-05-22 22:57:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch246_loss0.8144255131483078.pypots
2024-05-22 22:57:13 [INFO]: Epoch 247 - training loss: 0.7624, validation loss: 0.8134
2024-05-22 22:57:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch247_loss0.8134485483169556.pypots
2024-05-22 22:57:13 [INFO]: Epoch 248 - training loss: 0.7533, validation loss: 0.8137
2024-05-22 22:57:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch248_loss0.8137083500623703.pypots
2024-05-22 22:57:14 [INFO]: Epoch 249 - training loss: 0.7497, validation loss: 0.8144
2024-05-22 22:57:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch249_loss0.8143680840730667.pypots
2024-05-22 22:57:14 [INFO]: Epoch 250 - training loss: 0.7955, validation loss: 0.8124
2024-05-22 22:57:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch250_loss0.8124419450759888.pypots
2024-05-22 22:57:14 [INFO]: Epoch 251 - training loss: 0.7571, validation loss: 0.8111
2024-05-22 22:57:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch251_loss0.8110637962818146.pypots
2024-05-22 22:57:14 [INFO]: Epoch 252 - training loss: 0.7671, validation loss: 0.8124
2024-05-22 22:57:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch252_loss0.8124474883079529.pypots
2024-05-22 22:57:14 [INFO]: Epoch 253 - training loss: 0.7395, validation loss: 0.8126
2024-05-22 22:57:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch253_loss0.8126001358032227.pypots
2024-05-22 22:57:14 [INFO]: Epoch 254 - training loss: 0.7570, validation loss: 0.8137
2024-05-22 22:57:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch254_loss0.8136716037988663.pypots
2024-05-22 22:57:15 [INFO]: Epoch 255 - training loss: 0.7628, validation loss: 0.8122
2024-05-22 22:57:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch255_loss0.8122414499521255.pypots
2024-05-22 22:57:15 [INFO]: Epoch 256 - training loss: 0.7538, validation loss: 0.8111
2024-05-22 22:57:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch256_loss0.8111018538475037.pypots
2024-05-22 22:57:15 [INFO]: Epoch 257 - training loss: 0.7588, validation loss: 0.8123
2024-05-22 22:57:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch257_loss0.8123297691345215.pypots
2024-05-22 22:57:15 [INFO]: Epoch 258 - training loss: 0.7499, validation loss: 0.8118
2024-05-22 22:57:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch258_loss0.8118124157190323.pypots
2024-05-22 22:57:15 [INFO]: Epoch 259 - training loss: 0.7642, validation loss: 0.8096
2024-05-22 22:57:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch259_loss0.8095908463001251.pypots
2024-05-22 22:57:15 [INFO]: Epoch 260 - training loss: 0.7687, validation loss: 0.8101
2024-05-22 22:57:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch260_loss0.8100791275501251.pypots
2024-05-22 22:57:15 [INFO]: Epoch 261 - training loss: 0.7449, validation loss: 0.8094
2024-05-22 22:57:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch261_loss0.8093952536582947.pypots
2024-05-22 22:57:16 [INFO]: Epoch 262 - training loss: 0.7717, validation loss: 0.8089
2024-05-22 22:57:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch262_loss0.8088647425174713.pypots
2024-05-22 22:57:16 [INFO]: Epoch 263 - training loss: 0.7494, validation loss: 0.8070
2024-05-22 22:57:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch263_loss0.8069577664136887.pypots
2024-05-22 22:57:16 [INFO]: Epoch 264 - training loss: 0.7601, validation loss: 0.8101
2024-05-22 22:57:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch264_loss0.8101390898227692.pypots
2024-05-22 22:57:16 [INFO]: Epoch 265 - training loss: 0.7898, validation loss: 0.8132
2024-05-22 22:57:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch265_loss0.8132192343473434.pypots
2024-05-22 22:57:16 [INFO]: Epoch 266 - training loss: 0.7620, validation loss: 0.8131
2024-05-22 22:57:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch266_loss0.8131274431943893.pypots
2024-05-22 22:57:17 [INFO]: Epoch 267 - training loss: 0.7330, validation loss: 0.8089
2024-05-22 22:57:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch267_loss0.8089248985052109.pypots
2024-05-22 22:57:17 [INFO]: Epoch 268 - training loss: 0.7542, validation loss: 0.8093
2024-05-22 22:57:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch268_loss0.8092769235372543.pypots
2024-05-22 22:57:17 [INFO]: Epoch 269 - training loss: 0.7573, validation loss: 0.8079
2024-05-22 22:57:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch269_loss0.807898223400116.pypots
2024-05-22 22:57:17 [INFO]: Epoch 270 - training loss: 0.7588, validation loss: 0.8086
2024-05-22 22:57:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch270_loss0.8086106777191162.pypots
2024-05-22 22:57:17 [INFO]: Epoch 271 - training loss: 0.7703, validation loss: 0.8094
2024-05-22 22:57:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch271_loss0.8094344586133957.pypots
2024-05-22 22:57:17 [INFO]: Epoch 272 - training loss: 0.7515, validation loss: 0.8073
2024-05-22 22:57:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch272_loss0.8073010444641113.pypots
2024-05-22 22:57:18 [INFO]: Epoch 273 - training loss: 0.7533, validation loss: 0.8069
2024-05-22 22:57:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch273_loss0.8069206178188324.pypots
2024-05-22 22:57:18 [INFO]: Epoch 274 - training loss: 0.7637, validation loss: 0.8080
2024-05-22 22:57:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch274_loss0.8080060631036758.pypots
2024-05-22 22:57:18 [INFO]: Epoch 275 - training loss: 0.7493, validation loss: 0.8074
2024-05-22 22:57:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch275_loss0.8073863685131073.pypots
2024-05-22 22:57:19 [INFO]: Epoch 276 - training loss: 0.7632, validation loss: 0.8066
2024-05-22 22:57:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch276_loss0.8066271394491196.pypots
2024-05-22 22:57:19 [INFO]: Epoch 277 - training loss: 0.7751, validation loss: 0.8070
2024-05-22 22:57:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch277_loss0.8069623410701752.pypots
2024-05-22 22:57:19 [INFO]: Epoch 278 - training loss: 0.7779, validation loss: 0.8110
2024-05-22 22:57:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch278_loss0.8109759092330933.pypots
2024-05-22 22:57:19 [INFO]: Epoch 279 - training loss: 0.7654, validation loss: 0.8092
2024-05-22 22:57:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch279_loss0.8092268854379654.pypots
2024-05-22 22:57:19 [INFO]: Epoch 280 - training loss: 0.7612, validation loss: 0.8077
2024-05-22 22:57:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch280_loss0.8077066987752914.pypots
2024-05-22 22:57:19 [INFO]: Epoch 281 - training loss: 0.7574, validation loss: 0.8076
2024-05-22 22:57:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch281_loss0.807551309466362.pypots
2024-05-22 22:57:19 [INFO]: Epoch 282 - training loss: 0.7751, validation loss: 0.8025
2024-05-22 22:57:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch282_loss0.8024630695581436.pypots
2024-05-22 22:57:20 [INFO]: Epoch 283 - training loss: 0.7593, validation loss: 0.8056
2024-05-22 22:57:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch283_loss0.8055869936943054.pypots
2024-05-22 22:57:20 [INFO]: Epoch 284 - training loss: 0.7548, validation loss: 0.8069
2024-05-22 22:57:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch284_loss0.8069060891866684.pypots
2024-05-22 22:57:20 [INFO]: Epoch 285 - training loss: 0.7449, validation loss: 0.8046
2024-05-22 22:57:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch285_loss0.8046280443668365.pypots
2024-05-22 22:57:20 [INFO]: Epoch 286 - training loss: 0.7598, validation loss: 0.8057
2024-05-22 22:57:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch286_loss0.8057304173707962.pypots
2024-05-22 22:57:20 [INFO]: Epoch 287 - training loss: 0.7629, validation loss: 0.8058
2024-05-22 22:57:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch287_loss0.8058201670646667.pypots
2024-05-22 22:57:20 [INFO]: Epoch 288 - training loss: 0.7531, validation loss: 0.8071
2024-05-22 22:57:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch288_loss0.8070885539054871.pypots
2024-05-22 22:57:21 [INFO]: Epoch 289 - training loss: 0.7736, validation loss: 0.8031
2024-05-22 22:57:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch289_loss0.8030911833047867.pypots
2024-05-22 22:57:21 [INFO]: Epoch 290 - training loss: 0.7688, validation loss: 0.8081
2024-05-22 22:57:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch290_loss0.8080708682537079.pypots
2024-05-22 22:57:21 [INFO]: Epoch 291 - training loss: 0.7541, validation loss: 0.8070
2024-05-22 22:57:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch291_loss0.806993842124939.pypots
2024-05-22 22:57:21 [INFO]: Epoch 292 - training loss: 0.7347, validation loss: 0.8038
2024-05-22 22:57:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN_epoch292_loss0.8038324564695358.pypots
2024-05-22 22:57:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:57:21 [INFO]: Finished training. The best model is from epoch#282.
2024-05-22 22:57:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240522_T225632/MRNN.pypots
2024-05-22 22:57:21 [INFO]: MRNN on ETTm1: MAE=0.5786, MSE=1.0045
2024-05-22 22:57:21 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/MRNN_ettm1/imputation.pkl
2024-05-22 22:57:21 [INFO]: Using the given device: cpu
2024-05-22 22:57:21 [INFO]: LOCF on ETTm1: MAE=0.1376, MSE=0.0773
2024-05-22 22:57:21 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_ettm1".
2024-05-22 22:57:21 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/LOCF_ettm1/imputation.pkl
2024-05-22 22:57:21 [INFO]: Median on ETTm1: MAE=0.6554, MSE=0.8235
2024-05-22 22:57:21 [INFO]: Successfully created the given path "saved_results/round_4/Median_ettm1".
2024-05-22 22:57:21 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Median_ettm1/imputation.pkl
2024-05-22 22:57:21 [INFO]: Mean on ETTm1: MAE=0.6609, MSE=0.8067
2024-05-22 22:57:21 [INFO]: Successfully created the given path "saved_results/round_4/Mean_ettm1".
2024-05-22 22:57:21 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Mean_ettm1/imputation.pkl
2024-05-22 22:57:21 [INFO]: 
SAITS on data/ettm1: MAE=0.1690.017510316577994088, MSE=0.0580.011550335016722884
Transformer on data/ettm1: MAE=0.1290.0036551107826676347, MSE=0.0360.0016122124130677146
TimesNet on data/ettm1: MAE=0.1100.0016385059919468586, MSE=0.0260.0008229663683556901
CSDI on data/ettm1: MAE=0.1360.006304609280536976, MSE=0.0480.003464247275488591
GPVAE on data/ettm1: MAE=0.2750.01239187287119633, MSE=0.1590.012557938440156305
USGAN on data/ettm1: MAE=0.1500.005263233557637913, MSE=0.0570.002139294431676404
BRITS on data/ettm1: MAE=0.1400.012035054945855673, MSE=0.0580.008068706969785571
MRNN on data/ettm1: MAE=0.6160.03184261546043809, MSE=1.0380.039211847430668696
LOCF on data/ettm1: MAE=0.1380.0, MSE=0.0770.0
Median on data/ettm1: MAE=0.6550.0, MSE=0.8240.0
Mean on data/ettm1: MAE=0.6610.0, MSE=0.8070.0