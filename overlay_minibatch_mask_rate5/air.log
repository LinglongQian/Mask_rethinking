2024-05-24 22:42:47 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-24 22:42:47 [INFO]: Using the given device: cuda:0
2024-05-24 22:42:47 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/SAITS_air_quality/20240524_T224247
2024-05-24 22:42:47 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/SAITS_air_quality/20240524_T224247/tensorboard
2024-05-24 22:42:47 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-24 22:42:57 [INFO]: Epoch 001 - training loss: 1.0553, validation loss: 0.5156
2024-05-24 22:42:58 [INFO]: Epoch 002 - training loss: 0.7635, validation loss: 0.3960
2024-05-24 22:42:59 [INFO]: Epoch 003 - training loss: 0.6584, validation loss: 0.3188
2024-05-24 22:42:59 [INFO]: Epoch 004 - training loss: 0.5806, validation loss: 0.2781
2024-05-24 22:43:00 [INFO]: Epoch 005 - training loss: 0.5245, validation loss: 0.2573
2024-05-24 22:43:01 [INFO]: Epoch 006 - training loss: 0.4864, validation loss: 0.2483
2024-05-24 22:43:01 [INFO]: Epoch 007 - training loss: 0.4623, validation loss: 0.2341
2024-05-24 22:43:02 [INFO]: Epoch 008 - training loss: 0.4413, validation loss: 0.2288
2024-05-24 22:43:03 [INFO]: Epoch 009 - training loss: 0.4270, validation loss: 0.2238
2024-05-24 22:43:03 [INFO]: Epoch 010 - training loss: 0.4174, validation loss: 0.2197
2024-05-24 22:43:04 [INFO]: Epoch 011 - training loss: 0.4061, validation loss: 0.2128
2024-05-24 22:43:05 [INFO]: Epoch 012 - training loss: 0.3985, validation loss: 0.2099
2024-05-24 22:43:05 [INFO]: Epoch 013 - training loss: 0.3904, validation loss: 0.2055
2024-05-24 22:43:06 [INFO]: Epoch 014 - training loss: 0.3820, validation loss: 0.2038
2024-05-24 22:43:07 [INFO]: Epoch 015 - training loss: 0.3771, validation loss: 0.2006
2024-05-24 22:43:07 [INFO]: Epoch 016 - training loss: 0.3711, validation loss: 0.1989
2024-05-24 22:43:08 [INFO]: Epoch 017 - training loss: 0.3668, validation loss: 0.1959
2024-05-24 22:43:09 [INFO]: Epoch 018 - training loss: 0.3616, validation loss: 0.1945
2024-05-24 22:43:09 [INFO]: Epoch 019 - training loss: 0.3577, validation loss: 0.1908
2024-05-24 22:43:10 [INFO]: Epoch 020 - training loss: 0.3528, validation loss: 0.1892
2024-05-24 22:43:11 [INFO]: Epoch 021 - training loss: 0.3494, validation loss: 0.1883
2024-05-24 22:43:11 [INFO]: Epoch 022 - training loss: 0.3467, validation loss: 0.1863
2024-05-24 22:43:12 [INFO]: Epoch 023 - training loss: 0.3431, validation loss: 0.1859
2024-05-24 22:43:13 [INFO]: Epoch 024 - training loss: 0.3402, validation loss: 0.1829
2024-05-24 22:43:14 [INFO]: Epoch 025 - training loss: 0.3383, validation loss: 0.1813
2024-05-24 22:43:14 [INFO]: Epoch 026 - training loss: 0.3358, validation loss: 0.1809
2024-05-24 22:43:15 [INFO]: Epoch 027 - training loss: 0.3330, validation loss: 0.1787
2024-05-24 22:43:15 [INFO]: Epoch 028 - training loss: 0.3305, validation loss: 0.1776
2024-05-24 22:43:16 [INFO]: Epoch 029 - training loss: 0.3271, validation loss: 0.1756
2024-05-24 22:43:17 [INFO]: Epoch 030 - training loss: 0.3263, validation loss: 0.1741
2024-05-24 22:43:17 [INFO]: Epoch 031 - training loss: 0.3231, validation loss: 0.1742
2024-05-24 22:43:18 [INFO]: Epoch 032 - training loss: 0.3209, validation loss: 0.1722
2024-05-24 22:43:19 [INFO]: Epoch 033 - training loss: 0.3195, validation loss: 0.1698
2024-05-24 22:43:19 [INFO]: Epoch 034 - training loss: 0.3168, validation loss: 0.1699
2024-05-24 22:43:20 [INFO]: Epoch 035 - training loss: 0.3184, validation loss: 0.1697
2024-05-24 22:43:21 [INFO]: Epoch 036 - training loss: 0.3155, validation loss: 0.1683
2024-05-24 22:43:21 [INFO]: Epoch 037 - training loss: 0.3136, validation loss: 0.1657
2024-05-24 22:43:22 [INFO]: Epoch 038 - training loss: 0.3093, validation loss: 0.1659
2024-05-24 22:43:23 [INFO]: Epoch 039 - training loss: 0.3089, validation loss: 0.1639
2024-05-24 22:43:23 [INFO]: Epoch 040 - training loss: 0.3064, validation loss: 0.1623
2024-05-24 22:43:24 [INFO]: Epoch 041 - training loss: 0.3044, validation loss: 0.1616
2024-05-24 22:43:25 [INFO]: Epoch 042 - training loss: 0.3020, validation loss: 0.1608
2024-05-24 22:43:25 [INFO]: Epoch 043 - training loss: 0.3017, validation loss: 0.1592
2024-05-24 22:43:26 [INFO]: Epoch 044 - training loss: 0.3007, validation loss: 0.1586
2024-05-24 22:43:27 [INFO]: Epoch 045 - training loss: 0.2979, validation loss: 0.1588
2024-05-24 22:43:27 [INFO]: Epoch 046 - training loss: 0.2987, validation loss: 0.1567
2024-05-24 22:43:28 [INFO]: Epoch 047 - training loss: 0.2973, validation loss: 0.1554
2024-05-24 22:43:29 [INFO]: Epoch 048 - training loss: 0.2932, validation loss: 0.1554
2024-05-24 22:43:29 [INFO]: Epoch 049 - training loss: 0.2940, validation loss: 0.1542
2024-05-24 22:43:30 [INFO]: Epoch 050 - training loss: 0.2912, validation loss: 0.1529
2024-05-24 22:43:31 [INFO]: Epoch 051 - training loss: 0.2916, validation loss: 0.1533
2024-05-24 22:43:31 [INFO]: Epoch 052 - training loss: 0.2898, validation loss: 0.1512
2024-05-24 22:43:32 [INFO]: Epoch 053 - training loss: 0.2886, validation loss: 0.1503
2024-05-24 22:43:33 [INFO]: Epoch 054 - training loss: 0.2864, validation loss: 0.1499
2024-05-24 22:43:33 [INFO]: Epoch 055 - training loss: 0.2848, validation loss: 0.1489
2024-05-24 22:43:34 [INFO]: Epoch 056 - training loss: 0.2838, validation loss: 0.1482
2024-05-24 22:43:35 [INFO]: Epoch 057 - training loss: 0.2823, validation loss: 0.1465
2024-05-24 22:43:35 [INFO]: Epoch 058 - training loss: 0.2823, validation loss: 0.1464
2024-05-24 22:43:36 [INFO]: Epoch 059 - training loss: 0.2805, validation loss: 0.1454
2024-05-24 22:43:37 [INFO]: Epoch 060 - training loss: 0.2808, validation loss: 0.1448
2024-05-24 22:43:37 [INFO]: Epoch 061 - training loss: 0.2776, validation loss: 0.1440
2024-05-24 22:43:38 [INFO]: Epoch 062 - training loss: 0.2763, validation loss: 0.1431
2024-05-24 22:43:39 [INFO]: Epoch 063 - training loss: 0.2755, validation loss: 0.1421
2024-05-24 22:43:39 [INFO]: Epoch 064 - training loss: 0.2749, validation loss: 0.1410
2024-05-24 22:43:40 [INFO]: Epoch 065 - training loss: 0.2727, validation loss: 0.1418
2024-05-24 22:43:41 [INFO]: Epoch 066 - training loss: 0.2715, validation loss: 0.1405
2024-05-24 22:43:41 [INFO]: Epoch 067 - training loss: 0.2702, validation loss: 0.1392
2024-05-24 22:43:42 [INFO]: Epoch 068 - training loss: 0.2703, validation loss: 0.1383
2024-05-24 22:43:43 [INFO]: Epoch 069 - training loss: 0.2677, validation loss: 0.1383
2024-05-24 22:43:43 [INFO]: Epoch 070 - training loss: 0.2671, validation loss: 0.1383
2024-05-24 22:43:44 [INFO]: Epoch 071 - training loss: 0.2658, validation loss: 0.1371
2024-05-24 22:43:45 [INFO]: Epoch 072 - training loss: 0.2657, validation loss: 0.1357
2024-05-24 22:43:45 [INFO]: Epoch 073 - training loss: 0.2662, validation loss: 0.1354
2024-05-24 22:43:46 [INFO]: Epoch 074 - training loss: 0.2638, validation loss: 0.1345
2024-05-24 22:43:47 [INFO]: Epoch 075 - training loss: 0.2623, validation loss: 0.1341
2024-05-24 22:43:47 [INFO]: Epoch 076 - training loss: 0.2615, validation loss: 0.1339
2024-05-24 22:43:48 [INFO]: Epoch 077 - training loss: 0.2610, validation loss: 0.1334
2024-05-24 22:43:49 [INFO]: Epoch 078 - training loss: 0.2611, validation loss: 0.1337
2024-05-24 22:43:49 [INFO]: Epoch 079 - training loss: 0.2603, validation loss: 0.1327
2024-05-24 22:43:50 [INFO]: Epoch 080 - training loss: 0.2574, validation loss: 0.1318
2024-05-24 22:43:50 [INFO]: Epoch 081 - training loss: 0.2578, validation loss: 0.1315
2024-05-24 22:43:51 [INFO]: Epoch 082 - training loss: 0.2576, validation loss: 0.1317
2024-05-24 22:43:52 [INFO]: Epoch 083 - training loss: 0.2562, validation loss: 0.1308
2024-05-24 22:43:52 [INFO]: Epoch 084 - training loss: 0.2546, validation loss: 0.1294
2024-05-24 22:43:53 [INFO]: Epoch 085 - training loss: 0.2534, validation loss: 0.1293
2024-05-24 22:43:54 [INFO]: Epoch 086 - training loss: 0.2533, validation loss: 0.1288
2024-05-24 22:43:54 [INFO]: Epoch 087 - training loss: 0.2540, validation loss: 0.1287
2024-05-24 22:43:55 [INFO]: Epoch 088 - training loss: 0.2536, validation loss: 0.1277
2024-05-24 22:43:56 [INFO]: Epoch 089 - training loss: 0.2516, validation loss: 0.1279
2024-05-24 22:43:56 [INFO]: Epoch 090 - training loss: 0.2504, validation loss: 0.1266
2024-05-24 22:43:57 [INFO]: Epoch 091 - training loss: 0.2500, validation loss: 0.1275
2024-05-24 22:43:58 [INFO]: Epoch 092 - training loss: 0.2496, validation loss: 0.1263
2024-05-24 22:43:58 [INFO]: Epoch 093 - training loss: 0.2492, validation loss: 0.1266
2024-05-24 22:43:59 [INFO]: Epoch 094 - training loss: 0.2472, validation loss: 0.1260
2024-05-24 22:44:00 [INFO]: Epoch 095 - training loss: 0.2475, validation loss: 0.1258
2024-05-24 22:44:00 [INFO]: Epoch 096 - training loss: 0.2469, validation loss: 0.1258
2024-05-24 22:44:01 [INFO]: Epoch 097 - training loss: 0.2482, validation loss: 0.1252
2024-05-24 22:44:02 [INFO]: Epoch 098 - training loss: 0.2459, validation loss: 0.1250
2024-05-24 22:44:02 [INFO]: Epoch 099 - training loss: 0.2448, validation loss: 0.1255
2024-05-24 22:44:03 [INFO]: Epoch 100 - training loss: 0.2465, validation loss: 0.1247
2024-05-24 22:44:04 [INFO]: Epoch 101 - training loss: 0.2451, validation loss: 0.1240
2024-05-24 22:44:04 [INFO]: Epoch 102 - training loss: 0.2440, validation loss: 0.1241
2024-05-24 22:44:05 [INFO]: Epoch 103 - training loss: 0.2429, validation loss: 0.1236
2024-05-24 22:44:06 [INFO]: Epoch 104 - training loss: 0.2426, validation loss: 0.1238
2024-05-24 22:44:06 [INFO]: Epoch 105 - training loss: 0.2430, validation loss: 0.1229
2024-05-24 22:44:07 [INFO]: Epoch 106 - training loss: 0.2420, validation loss: 0.1228
2024-05-24 22:44:08 [INFO]: Epoch 107 - training loss: 0.2417, validation loss: 0.1229
2024-05-24 22:44:08 [INFO]: Epoch 108 - training loss: 0.2405, validation loss: 0.1221
2024-05-24 22:44:09 [INFO]: Epoch 109 - training loss: 0.2401, validation loss: 0.1226
2024-05-24 22:44:10 [INFO]: Epoch 110 - training loss: 0.2409, validation loss: 0.1218
2024-05-24 22:44:10 [INFO]: Epoch 111 - training loss: 0.2396, validation loss: 0.1230
2024-05-24 22:44:11 [INFO]: Epoch 112 - training loss: 0.2383, validation loss: 0.1212
2024-05-24 22:44:12 [INFO]: Epoch 113 - training loss: 0.2368, validation loss: 0.1213
2024-05-24 22:44:12 [INFO]: Epoch 114 - training loss: 0.2371, validation loss: 0.1215
2024-05-24 22:44:13 [INFO]: Epoch 115 - training loss: 0.2379, validation loss: 0.1212
2024-05-24 22:44:14 [INFO]: Epoch 116 - training loss: 0.2376, validation loss: 0.1213
2024-05-24 22:44:14 [INFO]: Epoch 117 - training loss: 0.2352, validation loss: 0.1211
2024-05-24 22:44:15 [INFO]: Epoch 118 - training loss: 0.2349, validation loss: 0.1210
2024-05-24 22:44:16 [INFO]: Epoch 119 - training loss: 0.2340, validation loss: 0.1200
2024-05-24 22:44:16 [INFO]: Epoch 120 - training loss: 0.2331, validation loss: 0.1200
2024-05-24 22:44:17 [INFO]: Epoch 121 - training loss: 0.2324, validation loss: 0.1195
2024-05-24 22:44:18 [INFO]: Epoch 122 - training loss: 0.2342, validation loss: 0.1196
2024-05-24 22:44:18 [INFO]: Epoch 123 - training loss: 0.2347, validation loss: 0.1196
2024-05-24 22:44:19 [INFO]: Epoch 124 - training loss: 0.2320, validation loss: 0.1193
2024-05-24 22:44:20 [INFO]: Epoch 125 - training loss: 0.2323, validation loss: 0.1196
2024-05-24 22:44:20 [INFO]: Epoch 126 - training loss: 0.2313, validation loss: 0.1184
2024-05-24 22:44:21 [INFO]: Epoch 127 - training loss: 0.2326, validation loss: 0.1195
2024-05-24 22:44:21 [INFO]: Epoch 128 - training loss: 0.2309, validation loss: 0.1193
2024-05-24 22:44:22 [INFO]: Epoch 129 - training loss: 0.2301, validation loss: 0.1185
2024-05-24 22:44:23 [INFO]: Epoch 130 - training loss: 0.2300, validation loss: 0.1179
2024-05-24 22:44:23 [INFO]: Epoch 131 - training loss: 0.2298, validation loss: 0.1181
2024-05-24 22:44:24 [INFO]: Epoch 132 - training loss: 0.2300, validation loss: 0.1179
2024-05-24 22:44:25 [INFO]: Epoch 133 - training loss: 0.2289, validation loss: 0.1183
2024-05-24 22:44:25 [INFO]: Epoch 134 - training loss: 0.2279, validation loss: 0.1181
2024-05-24 22:44:26 [INFO]: Epoch 135 - training loss: 0.2270, validation loss: 0.1173
2024-05-24 22:44:27 [INFO]: Epoch 136 - training loss: 0.2283, validation loss: 0.1188
2024-05-24 22:44:27 [INFO]: Epoch 137 - training loss: 0.2279, validation loss: 0.1173
2024-05-24 22:44:28 [INFO]: Epoch 138 - training loss: 0.2264, validation loss: 0.1171
2024-05-24 22:44:29 [INFO]: Epoch 139 - training loss: 0.2248, validation loss: 0.1170
2024-05-24 22:44:29 [INFO]: Epoch 140 - training loss: 0.2258, validation loss: 0.1163
2024-05-24 22:44:30 [INFO]: Epoch 141 - training loss: 0.2263, validation loss: 0.1165
2024-05-24 22:44:31 [INFO]: Epoch 142 - training loss: 0.2249, validation loss: 0.1160
2024-05-24 22:44:31 [INFO]: Epoch 143 - training loss: 0.2246, validation loss: 0.1153
2024-05-24 22:44:32 [INFO]: Epoch 144 - training loss: 0.2235, validation loss: 0.1146
2024-05-24 22:44:33 [INFO]: Epoch 145 - training loss: 0.2238, validation loss: 0.1153
2024-05-24 22:44:33 [INFO]: Epoch 146 - training loss: 0.2232, validation loss: 0.1146
2024-05-24 22:44:34 [INFO]: Epoch 147 - training loss: 0.2249, validation loss: 0.1154
2024-05-24 22:44:35 [INFO]: Epoch 148 - training loss: 0.2224, validation loss: 0.1158
2024-05-24 22:44:35 [INFO]: Epoch 149 - training loss: 0.2231, validation loss: 0.1147
2024-05-24 22:44:36 [INFO]: Epoch 150 - training loss: 0.2233, validation loss: 0.1142
2024-05-24 22:44:37 [INFO]: Epoch 151 - training loss: 0.2229, validation loss: 0.1142
2024-05-24 22:44:37 [INFO]: Epoch 152 - training loss: 0.2216, validation loss: 0.1140
2024-05-24 22:44:38 [INFO]: Epoch 153 - training loss: 0.2202, validation loss: 0.1135
2024-05-24 22:44:39 [INFO]: Epoch 154 - training loss: 0.2205, validation loss: 0.1143
2024-05-24 22:44:39 [INFO]: Epoch 155 - training loss: 0.2218, validation loss: 0.1135
2024-05-24 22:44:40 [INFO]: Epoch 156 - training loss: 0.2193, validation loss: 0.1137
2024-05-24 22:44:41 [INFO]: Epoch 157 - training loss: 0.2194, validation loss: 0.1135
2024-05-24 22:44:41 [INFO]: Epoch 158 - training loss: 0.2200, validation loss: 0.1133
2024-05-24 22:44:42 [INFO]: Epoch 159 - training loss: 0.2189, validation loss: 0.1128
2024-05-24 22:44:43 [INFO]: Epoch 160 - training loss: 0.2198, validation loss: 0.1134
2024-05-24 22:44:43 [INFO]: Epoch 161 - training loss: 0.2194, validation loss: 0.1128
2024-05-24 22:44:44 [INFO]: Epoch 162 - training loss: 0.2226, validation loss: 0.1127
2024-05-24 22:44:45 [INFO]: Epoch 163 - training loss: 0.2193, validation loss: 0.1120
2024-05-24 22:44:45 [INFO]: Epoch 164 - training loss: 0.2169, validation loss: 0.1120
2024-05-24 22:44:46 [INFO]: Epoch 165 - training loss: 0.2175, validation loss: 0.1127
2024-05-24 22:44:47 [INFO]: Epoch 166 - training loss: 0.2180, validation loss: 0.1117
2024-05-24 22:44:47 [INFO]: Epoch 167 - training loss: 0.2169, validation loss: 0.1119
2024-05-24 22:44:48 [INFO]: Epoch 168 - training loss: 0.2165, validation loss: 0.1111
2024-05-24 22:44:49 [INFO]: Epoch 169 - training loss: 0.2167, validation loss: 0.1112
2024-05-24 22:44:49 [INFO]: Epoch 170 - training loss: 0.2166, validation loss: 0.1112
2024-05-24 22:44:50 [INFO]: Epoch 171 - training loss: 0.2167, validation loss: 0.1113
2024-05-24 22:44:50 [INFO]: Epoch 172 - training loss: 0.2182, validation loss: 0.1119
2024-05-24 22:44:51 [INFO]: Epoch 173 - training loss: 0.2148, validation loss: 0.1108
2024-05-24 22:44:52 [INFO]: Epoch 174 - training loss: 0.2140, validation loss: 0.1102
2024-05-24 22:44:52 [INFO]: Epoch 175 - training loss: 0.2138, validation loss: 0.1117
2024-05-24 22:44:53 [INFO]: Epoch 176 - training loss: 0.2145, validation loss: 0.1107
2024-05-24 22:44:54 [INFO]: Epoch 177 - training loss: 0.2137, validation loss: 0.1093
2024-05-24 22:44:54 [INFO]: Epoch 178 - training loss: 0.2150, validation loss: 0.1098
2024-05-24 22:44:55 [INFO]: Epoch 179 - training loss: 0.2127, validation loss: 0.1094
2024-05-24 22:44:56 [INFO]: Epoch 180 - training loss: 0.2136, validation loss: 0.1102
2024-05-24 22:44:56 [INFO]: Epoch 181 - training loss: 0.2144, validation loss: 0.1103
2024-05-24 22:44:57 [INFO]: Epoch 182 - training loss: 0.2185, validation loss: 0.1093
2024-05-24 22:44:58 [INFO]: Epoch 183 - training loss: 0.2131, validation loss: 0.1090
2024-05-24 22:44:58 [INFO]: Epoch 184 - training loss: 0.2124, validation loss: 0.1093
2024-05-24 22:44:59 [INFO]: Epoch 185 - training loss: 0.2115, validation loss: 0.1100
2024-05-24 22:45:00 [INFO]: Epoch 186 - training loss: 0.2123, validation loss: 0.1090
2024-05-24 22:45:00 [INFO]: Epoch 187 - training loss: 0.2111, validation loss: 0.1079
2024-05-24 22:45:01 [INFO]: Epoch 188 - training loss: 0.2108, validation loss: 0.1085
2024-05-24 22:45:02 [INFO]: Epoch 189 - training loss: 0.2110, validation loss: 0.1082
2024-05-24 22:45:02 [INFO]: Epoch 190 - training loss: 0.2115, validation loss: 0.1092
2024-05-24 22:45:03 [INFO]: Epoch 191 - training loss: 0.2106, validation loss: 0.1077
2024-05-24 22:45:04 [INFO]: Epoch 192 - training loss: 0.2101, validation loss: 0.1079
2024-05-24 22:45:04 [INFO]: Epoch 193 - training loss: 0.2090, validation loss: 0.1081
2024-05-24 22:45:05 [INFO]: Epoch 194 - training loss: 0.2087, validation loss: 0.1090
2024-05-24 22:45:06 [INFO]: Epoch 195 - training loss: 0.2099, validation loss: 0.1085
2024-05-24 22:45:06 [INFO]: Epoch 196 - training loss: 0.2092, validation loss: 0.1087
2024-05-24 22:45:07 [INFO]: Epoch 197 - training loss: 0.2090, validation loss: 0.1081
2024-05-24 22:45:08 [INFO]: Epoch 198 - training loss: 0.2077, validation loss: 0.1081
2024-05-24 22:45:08 [INFO]: Epoch 199 - training loss: 0.2083, validation loss: 0.1081
2024-05-24 22:45:09 [INFO]: Epoch 200 - training loss: 0.2076, validation loss: 0.1075
2024-05-24 22:45:10 [INFO]: Epoch 201 - training loss: 0.2080, validation loss: 0.1075
2024-05-24 22:45:10 [INFO]: Epoch 202 - training loss: 0.2088, validation loss: 0.1065
2024-05-24 22:45:11 [INFO]: Epoch 203 - training loss: 0.2083, validation loss: 0.1066
2024-05-24 22:45:12 [INFO]: Epoch 204 - training loss: 0.2079, validation loss: 0.1071
2024-05-24 22:45:12 [INFO]: Epoch 205 - training loss: 0.2064, validation loss: 0.1065
2024-05-24 22:45:13 [INFO]: Epoch 206 - training loss: 0.2066, validation loss: 0.1068
2024-05-24 22:45:14 [INFO]: Epoch 207 - training loss: 0.2053, validation loss: 0.1055
2024-05-24 22:45:14 [INFO]: Epoch 208 - training loss: 0.2058, validation loss: 0.1070
2024-05-24 22:45:15 [INFO]: Epoch 209 - training loss: 0.2084, validation loss: 0.1062
2024-05-24 22:45:16 [INFO]: Epoch 210 - training loss: 0.2058, validation loss: 0.1062
2024-05-24 22:45:16 [INFO]: Epoch 211 - training loss: 0.2053, validation loss: 0.1069
2024-05-24 22:45:17 [INFO]: Epoch 212 - training loss: 0.2033, validation loss: 0.1065
2024-05-24 22:45:18 [INFO]: Epoch 213 - training loss: 0.2050, validation loss: 0.1063
2024-05-24 22:45:18 [INFO]: Epoch 214 - training loss: 0.2050, validation loss: 0.1069
2024-05-24 22:45:19 [INFO]: Epoch 215 - training loss: 0.2042, validation loss: 0.1060
2024-05-24 22:45:20 [INFO]: Epoch 216 - training loss: 0.2038, validation loss: 0.1051
2024-05-24 22:45:20 [INFO]: Epoch 217 - training loss: 0.2034, validation loss: 0.1060
2024-05-24 22:45:21 [INFO]: Epoch 218 - training loss: 0.2027, validation loss: 0.1049
2024-05-24 22:45:22 [INFO]: Epoch 219 - training loss: 0.2034, validation loss: 0.1051
2024-05-24 22:45:22 [INFO]: Epoch 220 - training loss: 0.2034, validation loss: 0.1065
2024-05-24 22:45:23 [INFO]: Epoch 221 - training loss: 0.2034, validation loss: 0.1053
2024-05-24 22:45:23 [INFO]: Epoch 222 - training loss: 0.2047, validation loss: 0.1054
2024-05-24 22:45:24 [INFO]: Epoch 223 - training loss: 0.2039, validation loss: 0.1051
2024-05-24 22:45:25 [INFO]: Epoch 224 - training loss: 0.2018, validation loss: 0.1050
2024-05-24 22:45:25 [INFO]: Epoch 225 - training loss: 0.2019, validation loss: 0.1050
2024-05-24 22:45:26 [INFO]: Epoch 226 - training loss: 0.2013, validation loss: 0.1036
2024-05-24 22:45:27 [INFO]: Epoch 227 - training loss: 0.2019, validation loss: 0.1037
2024-05-24 22:45:27 [INFO]: Epoch 228 - training loss: 0.2018, validation loss: 0.1045
2024-05-24 22:45:28 [INFO]: Epoch 229 - training loss: 0.2019, validation loss: 0.1038
2024-05-24 22:45:29 [INFO]: Epoch 230 - training loss: 0.2013, validation loss: 0.1034
2024-05-24 22:45:29 [INFO]: Epoch 231 - training loss: 0.2008, validation loss: 0.1036
2024-05-24 22:45:30 [INFO]: Epoch 232 - training loss: 0.2002, validation loss: 0.1037
2024-05-24 22:45:31 [INFO]: Epoch 233 - training loss: 0.2013, validation loss: 0.1045
2024-05-24 22:45:31 [INFO]: Epoch 234 - training loss: 0.2005, validation loss: 0.1034
2024-05-24 22:45:32 [INFO]: Epoch 235 - training loss: 0.2015, validation loss: 0.1030
2024-05-24 22:45:33 [INFO]: Epoch 236 - training loss: 0.2027, validation loss: 0.1031
2024-05-24 22:45:33 [INFO]: Epoch 237 - training loss: 0.2019, validation loss: 0.1029
2024-05-24 22:45:34 [INFO]: Epoch 238 - training loss: 0.1998, validation loss: 0.1021
2024-05-24 22:45:35 [INFO]: Epoch 239 - training loss: 0.2016, validation loss: 0.1029
2024-05-24 22:45:35 [INFO]: Epoch 240 - training loss: 0.1984, validation loss: 0.1028
2024-05-24 22:45:36 [INFO]: Epoch 241 - training loss: 0.1985, validation loss: 0.1025
2024-05-24 22:45:37 [INFO]: Epoch 242 - training loss: 0.1982, validation loss: 0.1026
2024-05-24 22:45:37 [INFO]: Epoch 243 - training loss: 0.1999, validation loss: 0.1020
2024-05-24 22:45:38 [INFO]: Epoch 244 - training loss: 0.1989, validation loss: 0.1027
2024-05-24 22:45:39 [INFO]: Epoch 245 - training loss: 0.1994, validation loss: 0.1023
2024-05-24 22:45:39 [INFO]: Epoch 246 - training loss: 0.1976, validation loss: 0.1039
2024-05-24 22:45:40 [INFO]: Epoch 247 - training loss: 0.1987, validation loss: 0.1029
2024-05-24 22:45:41 [INFO]: Epoch 248 - training loss: 0.1976, validation loss: 0.1014
2024-05-24 22:45:41 [INFO]: Epoch 249 - training loss: 0.1952, validation loss: 0.1022
2024-05-24 22:45:42 [INFO]: Epoch 250 - training loss: 0.1973, validation loss: 0.1015
2024-05-24 22:45:43 [INFO]: Epoch 251 - training loss: 0.1960, validation loss: 0.1020
2024-05-24 22:45:43 [INFO]: Epoch 252 - training loss: 0.1973, validation loss: 0.1011
2024-05-24 22:45:44 [INFO]: Epoch 253 - training loss: 0.1969, validation loss: 0.1013
2024-05-24 22:45:45 [INFO]: Epoch 254 - training loss: 0.1960, validation loss: 0.1014
2024-05-24 22:45:45 [INFO]: Epoch 255 - training loss: 0.1963, validation loss: 0.1012
2024-05-24 22:45:46 [INFO]: Epoch 256 - training loss: 0.1968, validation loss: 0.1019
2024-05-24 22:45:47 [INFO]: Epoch 257 - training loss: 0.1951, validation loss: 0.1016
2024-05-24 22:45:47 [INFO]: Epoch 258 - training loss: 0.1943, validation loss: 0.1017
2024-05-24 22:45:48 [INFO]: Epoch 259 - training loss: 0.1948, validation loss: 0.1015
2024-05-24 22:45:49 [INFO]: Epoch 260 - training loss: 0.1957, validation loss: 0.1024
2024-05-24 22:45:49 [INFO]: Epoch 261 - training loss: 0.1958, validation loss: 0.1019
2024-05-24 22:45:50 [INFO]: Epoch 262 - training loss: 0.1982, validation loss: 0.1011
2024-05-24 22:45:51 [INFO]: Epoch 263 - training loss: 0.1959, validation loss: 0.1024
2024-05-24 22:45:51 [INFO]: Epoch 264 - training loss: 0.1954, validation loss: 0.1010
2024-05-24 22:45:52 [INFO]: Epoch 265 - training loss: 0.1970, validation loss: 0.1023
2024-05-24 22:45:52 [INFO]: Epoch 266 - training loss: 0.1949, validation loss: 0.1009
2024-05-24 22:45:53 [INFO]: Epoch 267 - training loss: 0.1931, validation loss: 0.1001
2024-05-24 22:45:54 [INFO]: Epoch 268 - training loss: 0.1931, validation loss: 0.1011
2024-05-24 22:45:54 [INFO]: Epoch 269 - training loss: 0.1946, validation loss: 0.1005
2024-05-24 22:45:55 [INFO]: Epoch 270 - training loss: 0.1933, validation loss: 0.1015
2024-05-24 22:45:56 [INFO]: Epoch 271 - training loss: 0.1930, validation loss: 0.1007
2024-05-24 22:45:56 [INFO]: Epoch 272 - training loss: 0.1934, validation loss: 0.1002
2024-05-24 22:45:57 [INFO]: Epoch 273 - training loss: 0.1936, validation loss: 0.1011
2024-05-24 22:45:58 [INFO]: Epoch 274 - training loss: 0.1924, validation loss: 0.1007
2024-05-24 22:45:58 [INFO]: Epoch 275 - training loss: 0.1920, validation loss: 0.1010
2024-05-24 22:45:59 [INFO]: Epoch 276 - training loss: 0.1925, validation loss: 0.1013
2024-05-24 22:46:00 [INFO]: Epoch 277 - training loss: 0.1920, validation loss: 0.1009
2024-05-24 22:46:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:46:00 [INFO]: Finished training. The best model is from epoch#267.
2024-05-24 22:46:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/SAITS_air_quality/20240524_T224247/SAITS.pypots
2024-05-24 22:46:00 [INFO]: SAITS on Air-Quality: MAE=0.1386, MSE=0.0949
2024-05-24 22:46:00 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/SAITS_air_quality/imputation.pkl
2024-05-24 22:46:00 [INFO]: Using the given device: cuda:0
2024-05-24 22:46:00 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/Transformer_air_quality/20240524_T224600
2024-05-24 22:46:00 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/Transformer_air_quality/20240524_T224600/tensorboard
2024-05-24 22:46:00 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-24 22:46:00 [INFO]: Epoch 001 - training loss: 0.9314, validation loss: 0.4721
2024-05-24 22:46:01 [INFO]: Epoch 002 - training loss: 0.5770, validation loss: 0.3529
2024-05-24 22:46:01 [INFO]: Epoch 003 - training loss: 0.4867, validation loss: 0.2931
2024-05-24 22:46:01 [INFO]: Epoch 004 - training loss: 0.4408, validation loss: 0.2673
2024-05-24 22:46:02 [INFO]: Epoch 005 - training loss: 0.4132, validation loss: 0.2524
2024-05-24 22:46:02 [INFO]: Epoch 006 - training loss: 0.3911, validation loss: 0.2395
2024-05-24 22:46:02 [INFO]: Epoch 007 - training loss: 0.3755, validation loss: 0.2328
2024-05-24 22:46:03 [INFO]: Epoch 008 - training loss: 0.3687, validation loss: 0.2268
2024-05-24 22:46:03 [INFO]: Epoch 009 - training loss: 0.3575, validation loss: 0.2233
2024-05-24 22:46:03 [INFO]: Epoch 010 - training loss: 0.3483, validation loss: 0.2176
2024-05-24 22:46:03 [INFO]: Epoch 011 - training loss: 0.3424, validation loss: 0.2125
2024-05-24 22:46:04 [INFO]: Epoch 012 - training loss: 0.3367, validation loss: 0.2075
2024-05-24 22:46:04 [INFO]: Epoch 013 - training loss: 0.3318, validation loss: 0.2034
2024-05-24 22:46:04 [INFO]: Epoch 014 - training loss: 0.3254, validation loss: 0.2007
2024-05-24 22:46:05 [INFO]: Epoch 015 - training loss: 0.3233, validation loss: 0.1971
2024-05-24 22:46:05 [INFO]: Epoch 016 - training loss: 0.3196, validation loss: 0.1918
2024-05-24 22:46:05 [INFO]: Epoch 017 - training loss: 0.3167, validation loss: 0.1882
2024-05-24 22:46:06 [INFO]: Epoch 018 - training loss: 0.3118, validation loss: 0.1866
2024-05-24 22:46:06 [INFO]: Epoch 019 - training loss: 0.3081, validation loss: 0.1835
2024-05-24 22:46:06 [INFO]: Epoch 020 - training loss: 0.3062, validation loss: 0.1809
2024-05-24 22:46:07 [INFO]: Epoch 021 - training loss: 0.3051, validation loss: 0.1776
2024-05-24 22:46:07 [INFO]: Epoch 022 - training loss: 0.3031, validation loss: 0.1776
2024-05-24 22:46:07 [INFO]: Epoch 023 - training loss: 0.3005, validation loss: 0.1760
2024-05-24 22:46:07 [INFO]: Epoch 024 - training loss: 0.2985, validation loss: 0.1731
2024-05-24 22:46:08 [INFO]: Epoch 025 - training loss: 0.2946, validation loss: 0.1745
2024-05-24 22:46:08 [INFO]: Epoch 026 - training loss: 0.2938, validation loss: 0.1718
2024-05-24 22:46:08 [INFO]: Epoch 027 - training loss: 0.2926, validation loss: 0.1705
2024-05-24 22:46:09 [INFO]: Epoch 028 - training loss: 0.2947, validation loss: 0.1716
2024-05-24 22:46:09 [INFO]: Epoch 029 - training loss: 0.2892, validation loss: 0.1707
2024-05-24 22:46:09 [INFO]: Epoch 030 - training loss: 0.2897, validation loss: 0.1685
2024-05-24 22:46:10 [INFO]: Epoch 031 - training loss: 0.2860, validation loss: 0.1671
2024-05-24 22:46:10 [INFO]: Epoch 032 - training loss: 0.2842, validation loss: 0.1670
2024-05-24 22:46:10 [INFO]: Epoch 033 - training loss: 0.2828, validation loss: 0.1655
2024-05-24 22:46:11 [INFO]: Epoch 034 - training loss: 0.2798, validation loss: 0.1645
2024-05-24 22:46:11 [INFO]: Epoch 035 - training loss: 0.2791, validation loss: 0.1648
2024-05-24 22:46:11 [INFO]: Epoch 036 - training loss: 0.2807, validation loss: 0.1640
2024-05-24 22:46:11 [INFO]: Epoch 037 - training loss: 0.2764, validation loss: 0.1635
2024-05-24 22:46:12 [INFO]: Epoch 038 - training loss: 0.2775, validation loss: 0.1628
2024-05-24 22:46:12 [INFO]: Epoch 039 - training loss: 0.2762, validation loss: 0.1647
2024-05-24 22:46:12 [INFO]: Epoch 040 - training loss: 0.2758, validation loss: 0.1632
2024-05-24 22:46:13 [INFO]: Epoch 041 - training loss: 0.2728, validation loss: 0.1628
2024-05-24 22:46:13 [INFO]: Epoch 042 - training loss: 0.2706, validation loss: 0.1617
2024-05-24 22:46:13 [INFO]: Epoch 043 - training loss: 0.2723, validation loss: 0.1619
2024-05-24 22:46:14 [INFO]: Epoch 044 - training loss: 0.2722, validation loss: 0.1629
2024-05-24 22:46:14 [INFO]: Epoch 045 - training loss: 0.2724, validation loss: 0.1618
2024-05-24 22:46:14 [INFO]: Epoch 046 - training loss: 0.2709, validation loss: 0.1656
2024-05-24 22:46:15 [INFO]: Epoch 047 - training loss: 0.2671, validation loss: 0.1602
2024-05-24 22:46:15 [INFO]: Epoch 048 - training loss: 0.2652, validation loss: 0.1583
2024-05-24 22:46:15 [INFO]: Epoch 049 - training loss: 0.2634, validation loss: 0.1593
2024-05-24 22:46:15 [INFO]: Epoch 050 - training loss: 0.2638, validation loss: 0.1587
2024-05-24 22:46:16 [INFO]: Epoch 051 - training loss: 0.2651, validation loss: 0.1616
2024-05-24 22:46:16 [INFO]: Epoch 052 - training loss: 0.2621, validation loss: 0.1576
2024-05-24 22:46:16 [INFO]: Epoch 053 - training loss: 0.2608, validation loss: 0.1596
2024-05-24 22:46:17 [INFO]: Epoch 054 - training loss: 0.2630, validation loss: 0.1569
2024-05-24 22:46:17 [INFO]: Epoch 055 - training loss: 0.2602, validation loss: 0.1603
2024-05-24 22:46:17 [INFO]: Epoch 056 - training loss: 0.2572, validation loss: 0.1574
2024-05-24 22:46:18 [INFO]: Epoch 057 - training loss: 0.2565, validation loss: 0.1566
2024-05-24 22:46:18 [INFO]: Epoch 058 - training loss: 0.2575, validation loss: 0.1582
2024-05-24 22:46:18 [INFO]: Epoch 059 - training loss: 0.2567, validation loss: 0.1557
2024-05-24 22:46:19 [INFO]: Epoch 060 - training loss: 0.2560, validation loss: 0.1570
2024-05-24 22:46:19 [INFO]: Epoch 061 - training loss: 0.2538, validation loss: 0.1557
2024-05-24 22:46:19 [INFO]: Epoch 062 - training loss: 0.2523, validation loss: 0.1569
2024-05-24 22:46:20 [INFO]: Epoch 063 - training loss: 0.2508, validation loss: 0.1560
2024-05-24 22:46:20 [INFO]: Epoch 064 - training loss: 0.2511, validation loss: 0.1555
2024-05-24 22:46:20 [INFO]: Epoch 065 - training loss: 0.2512, validation loss: 0.1554
2024-05-24 22:46:20 [INFO]: Epoch 066 - training loss: 0.2491, validation loss: 0.1545
2024-05-24 22:46:21 [INFO]: Epoch 067 - training loss: 0.2497, validation loss: 0.1560
2024-05-24 22:46:21 [INFO]: Epoch 068 - training loss: 0.2505, validation loss: 0.1562
2024-05-24 22:46:21 [INFO]: Epoch 069 - training loss: 0.2517, validation loss: 0.1542
2024-05-24 22:46:22 [INFO]: Epoch 070 - training loss: 0.2481, validation loss: 0.1541
2024-05-24 22:46:22 [INFO]: Epoch 071 - training loss: 0.2483, validation loss: 0.1550
2024-05-24 22:46:22 [INFO]: Epoch 072 - training loss: 0.2455, validation loss: 0.1531
2024-05-24 22:46:23 [INFO]: Epoch 073 - training loss: 0.2437, validation loss: 0.1528
2024-05-24 22:46:23 [INFO]: Epoch 074 - training loss: 0.2451, validation loss: 0.1521
2024-05-24 22:46:23 [INFO]: Epoch 075 - training loss: 0.2451, validation loss: 0.1538
2024-05-24 22:46:24 [INFO]: Epoch 076 - training loss: 0.2437, validation loss: 0.1531
2024-05-24 22:46:24 [INFO]: Epoch 077 - training loss: 0.2425, validation loss: 0.1530
2024-05-24 22:46:24 [INFO]: Epoch 078 - training loss: 0.2419, validation loss: 0.1524
2024-05-24 22:46:24 [INFO]: Epoch 079 - training loss: 0.2411, validation loss: 0.1509
2024-05-24 22:46:25 [INFO]: Epoch 080 - training loss: 0.2427, validation loss: 0.1513
2024-05-24 22:46:25 [INFO]: Epoch 081 - training loss: 0.2421, validation loss: 0.1531
2024-05-24 22:46:25 [INFO]: Epoch 082 - training loss: 0.2388, validation loss: 0.1500
2024-05-24 22:46:26 [INFO]: Epoch 083 - training loss: 0.2379, validation loss: 0.1508
2024-05-24 22:46:26 [INFO]: Epoch 084 - training loss: 0.2382, validation loss: 0.1508
2024-05-24 22:46:26 [INFO]: Epoch 085 - training loss: 0.2399, validation loss: 0.1501
2024-05-24 22:46:27 [INFO]: Epoch 086 - training loss: 0.2380, validation loss: 0.1503
2024-05-24 22:46:27 [INFO]: Epoch 087 - training loss: 0.2374, validation loss: 0.1494
2024-05-24 22:46:27 [INFO]: Epoch 088 - training loss: 0.2385, validation loss: 0.1518
2024-05-24 22:46:28 [INFO]: Epoch 089 - training loss: 0.2350, validation loss: 0.1484
2024-05-24 22:46:28 [INFO]: Epoch 090 - training loss: 0.2346, validation loss: 0.1518
2024-05-24 22:46:28 [INFO]: Epoch 091 - training loss: 0.2367, validation loss: 0.1487
2024-05-24 22:46:28 [INFO]: Epoch 092 - training loss: 0.2384, validation loss: 0.1498
2024-05-24 22:46:29 [INFO]: Epoch 093 - training loss: 0.2380, validation loss: 0.1494
2024-05-24 22:46:29 [INFO]: Epoch 094 - training loss: 0.2340, validation loss: 0.1501
2024-05-24 22:46:29 [INFO]: Epoch 095 - training loss: 0.2312, validation loss: 0.1481
2024-05-24 22:46:30 [INFO]: Epoch 096 - training loss: 0.2334, validation loss: 0.1483
2024-05-24 22:46:30 [INFO]: Epoch 097 - training loss: 0.2367, validation loss: 0.1490
2024-05-24 22:46:30 [INFO]: Epoch 098 - training loss: 0.2368, validation loss: 0.1507
2024-05-24 22:46:31 [INFO]: Epoch 099 - training loss: 0.2326, validation loss: 0.1469
2024-05-24 22:46:31 [INFO]: Epoch 100 - training loss: 0.2300, validation loss: 0.1477
2024-05-24 22:46:31 [INFO]: Epoch 101 - training loss: 0.2274, validation loss: 0.1455
2024-05-24 22:46:32 [INFO]: Epoch 102 - training loss: 0.2283, validation loss: 0.1482
2024-05-24 22:46:32 [INFO]: Epoch 103 - training loss: 0.2278, validation loss: 0.1451
2024-05-24 22:46:32 [INFO]: Epoch 104 - training loss: 0.2268, validation loss: 0.1461
2024-05-24 22:46:32 [INFO]: Epoch 105 - training loss: 0.2272, validation loss: 0.1453
2024-05-24 22:46:33 [INFO]: Epoch 106 - training loss: 0.2246, validation loss: 0.1455
2024-05-24 22:46:33 [INFO]: Epoch 107 - training loss: 0.2238, validation loss: 0.1463
2024-05-24 22:46:33 [INFO]: Epoch 108 - training loss: 0.2232, validation loss: 0.1461
2024-05-24 22:46:34 [INFO]: Epoch 109 - training loss: 0.2228, validation loss: 0.1440
2024-05-24 22:46:34 [INFO]: Epoch 110 - training loss: 0.2235, validation loss: 0.1467
2024-05-24 22:46:34 [INFO]: Epoch 111 - training loss: 0.2260, validation loss: 0.1441
2024-05-24 22:46:35 [INFO]: Epoch 112 - training loss: 0.2223, validation loss: 0.1436
2024-05-24 22:46:35 [INFO]: Epoch 113 - training loss: 0.2217, validation loss: 0.1437
2024-05-24 22:46:35 [INFO]: Epoch 114 - training loss: 0.2229, validation loss: 0.1432
2024-05-24 22:46:36 [INFO]: Epoch 115 - training loss: 0.2219, validation loss: 0.1442
2024-05-24 22:46:36 [INFO]: Epoch 116 - training loss: 0.2230, validation loss: 0.1425
2024-05-24 22:46:36 [INFO]: Epoch 117 - training loss: 0.2223, validation loss: 0.1445
2024-05-24 22:46:37 [INFO]: Epoch 118 - training loss: 0.2223, validation loss: 0.1447
2024-05-24 22:46:37 [INFO]: Epoch 119 - training loss: 0.2258, validation loss: 0.1410
2024-05-24 22:46:37 [INFO]: Epoch 120 - training loss: 0.2248, validation loss: 0.1435
2024-05-24 22:46:37 [INFO]: Epoch 121 - training loss: 0.2199, validation loss: 0.1423
2024-05-24 22:46:38 [INFO]: Epoch 122 - training loss: 0.2206, validation loss: 0.1427
2024-05-24 22:46:38 [INFO]: Epoch 123 - training loss: 0.2184, validation loss: 0.1429
2024-05-24 22:46:38 [INFO]: Epoch 124 - training loss: 0.2195, validation loss: 0.1438
2024-05-24 22:46:39 [INFO]: Epoch 125 - training loss: 0.2193, validation loss: 0.1432
2024-05-24 22:46:39 [INFO]: Epoch 126 - training loss: 0.2209, validation loss: 0.1422
2024-05-24 22:46:39 [INFO]: Epoch 127 - training loss: 0.2173, validation loss: 0.1421
2024-05-24 22:46:40 [INFO]: Epoch 128 - training loss: 0.2162, validation loss: 0.1412
2024-05-24 22:46:40 [INFO]: Epoch 129 - training loss: 0.2185, validation loss: 0.1419
2024-05-24 22:46:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:46:40 [INFO]: Finished training. The best model is from epoch#119.
2024-05-24 22:46:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/Transformer_air_quality/20240524_T224600/Transformer.pypots
2024-05-24 22:46:40 [INFO]: Transformer on Air-Quality: MAE=0.1657, MSE=0.1282
2024-05-24 22:46:40 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/Transformer_air_quality/imputation.pkl
2024-05-24 22:46:40 [INFO]: Using the given device: cuda:0
2024-05-24 22:46:40 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/TimesNet_air_quality/20240524_T224640
2024-05-24 22:46:40 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/TimesNet_air_quality/20240524_T224640/tensorboard
2024-05-24 22:46:40 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-24 22:46:47 [INFO]: Epoch 001 - training loss: 0.2893, validation loss: 0.2767
2024-05-24 22:46:48 [INFO]: Epoch 002 - training loss: 0.2235, validation loss: 0.2403
2024-05-24 22:46:48 [INFO]: Epoch 003 - training loss: 0.2042, validation loss: 0.2372
2024-05-24 22:46:49 [INFO]: Epoch 004 - training loss: 0.1782, validation loss: 0.2118
2024-05-24 22:46:49 [INFO]: Epoch 005 - training loss: 0.1750, validation loss: 0.1993
2024-05-24 22:46:50 [INFO]: Epoch 006 - training loss: 0.1689, validation loss: 0.1980
2024-05-24 22:46:50 [INFO]: Epoch 007 - training loss: 0.1707, validation loss: 0.1905
2024-05-24 22:46:51 [INFO]: Epoch 008 - training loss: 0.1514, validation loss: 0.1909
2024-05-24 22:46:51 [INFO]: Epoch 009 - training loss: 0.1527, validation loss: 0.1868
2024-05-24 22:46:52 [INFO]: Epoch 010 - training loss: 0.1585, validation loss: 0.1840
2024-05-24 22:46:52 [INFO]: Epoch 011 - training loss: 0.1506, validation loss: 0.1814
2024-05-24 22:46:53 [INFO]: Epoch 012 - training loss: 0.1406, validation loss: 0.1748
2024-05-24 22:46:53 [INFO]: Epoch 013 - training loss: 0.1472, validation loss: 0.1726
2024-05-24 22:46:54 [INFO]: Epoch 014 - training loss: 0.1430, validation loss: 0.1767
2024-05-24 22:46:54 [INFO]: Epoch 015 - training loss: 0.1486, validation loss: 0.1838
2024-05-24 22:46:55 [INFO]: Epoch 016 - training loss: 0.1439, validation loss: 0.1745
2024-05-24 22:46:55 [INFO]: Epoch 017 - training loss: 0.1507, validation loss: 0.1786
2024-05-24 22:46:56 [INFO]: Epoch 018 - training loss: 0.1382, validation loss: 0.1746
2024-05-24 22:46:56 [INFO]: Epoch 019 - training loss: 0.1235, validation loss: 0.1740
2024-05-24 22:46:57 [INFO]: Epoch 020 - training loss: 0.1387, validation loss: 0.1695
2024-05-24 22:46:57 [INFO]: Epoch 021 - training loss: 0.1223, validation loss: 0.1670
2024-05-24 22:46:58 [INFO]: Epoch 022 - training loss: 0.1378, validation loss: 0.1744
2024-05-24 22:46:59 [INFO]: Epoch 023 - training loss: 0.1358, validation loss: 0.1657
2024-05-24 22:46:59 [INFO]: Epoch 024 - training loss: 0.1448, validation loss: 0.1608
2024-05-24 22:47:00 [INFO]: Epoch 025 - training loss: 0.1280, validation loss: 0.1547
2024-05-24 22:47:00 [INFO]: Epoch 026 - training loss: 0.1174, validation loss: 0.1630
2024-05-24 22:47:01 [INFO]: Epoch 027 - training loss: 0.1130, validation loss: 0.1641
2024-05-24 22:47:01 [INFO]: Epoch 028 - training loss: 0.1228, validation loss: 0.1564
2024-05-24 22:47:02 [INFO]: Epoch 029 - training loss: 0.1148, validation loss: 0.1600
2024-05-24 22:47:02 [INFO]: Epoch 030 - training loss: 0.1103, validation loss: 0.1570
2024-05-24 22:47:03 [INFO]: Epoch 031 - training loss: 0.1136, validation loss: 0.1513
2024-05-24 22:47:03 [INFO]: Epoch 032 - training loss: 0.1211, validation loss: 0.1513
2024-05-24 22:47:04 [INFO]: Epoch 033 - training loss: 0.1495, validation loss: 0.1519
2024-05-24 22:47:04 [INFO]: Epoch 034 - training loss: 0.1165, validation loss: 0.1492
2024-05-24 22:47:05 [INFO]: Epoch 035 - training loss: 0.1160, validation loss: 0.1555
2024-05-24 22:47:05 [INFO]: Epoch 036 - training loss: 0.1017, validation loss: 0.1533
2024-05-24 22:47:06 [INFO]: Epoch 037 - training loss: 0.1088, validation loss: 0.1576
2024-05-24 22:47:06 [INFO]: Epoch 038 - training loss: 0.1216, validation loss: 0.1478
2024-05-24 22:47:07 [INFO]: Epoch 039 - training loss: 0.1283, validation loss: 0.1484
2024-05-24 22:47:07 [INFO]: Epoch 040 - training loss: 0.1029, validation loss: 0.1470
2024-05-24 22:47:08 [INFO]: Epoch 041 - training loss: 0.1020, validation loss: 0.1491
2024-05-24 22:47:08 [INFO]: Epoch 042 - training loss: 0.1239, validation loss: 0.1485
2024-05-24 22:47:09 [INFO]: Epoch 043 - training loss: 0.1008, validation loss: 0.1477
2024-05-24 22:47:09 [INFO]: Epoch 044 - training loss: 0.1064, validation loss: 0.1487
2024-05-24 22:47:10 [INFO]: Epoch 045 - training loss: 0.1077, validation loss: 0.1495
2024-05-24 22:47:11 [INFO]: Epoch 046 - training loss: 0.1049, validation loss: 0.1502
2024-05-24 22:47:11 [INFO]: Epoch 047 - training loss: 0.0991, validation loss: 0.1451
2024-05-24 22:47:12 [INFO]: Epoch 048 - training loss: 0.1013, validation loss: 0.1429
2024-05-24 22:47:12 [INFO]: Epoch 049 - training loss: 0.1003, validation loss: 0.1426
2024-05-24 22:47:13 [INFO]: Epoch 050 - training loss: 0.0947, validation loss: 0.1469
2024-05-24 22:47:13 [INFO]: Epoch 051 - training loss: 0.1067, validation loss: 0.1437
2024-05-24 22:47:14 [INFO]: Epoch 052 - training loss: 0.1175, validation loss: 0.1455
2024-05-24 22:47:14 [INFO]: Epoch 053 - training loss: 0.1015, validation loss: 0.1463
2024-05-24 22:47:15 [INFO]: Epoch 054 - training loss: 0.1115, validation loss: 0.1459
2024-05-24 22:47:15 [INFO]: Epoch 055 - training loss: 0.1039, validation loss: 0.1461
2024-05-24 22:47:16 [INFO]: Epoch 056 - training loss: 0.1098, validation loss: 0.1437
2024-05-24 22:47:16 [INFO]: Epoch 057 - training loss: 0.1125, validation loss: 0.1488
2024-05-24 22:47:17 [INFO]: Epoch 058 - training loss: 0.1125, validation loss: 0.1418
2024-05-24 22:47:17 [INFO]: Epoch 059 - training loss: 0.0973, validation loss: 0.1380
2024-05-24 22:47:18 [INFO]: Epoch 060 - training loss: 0.0985, validation loss: 0.1396
2024-05-24 22:47:18 [INFO]: Epoch 061 - training loss: 0.0997, validation loss: 0.1421
2024-05-24 22:47:19 [INFO]: Epoch 062 - training loss: 0.1025, validation loss: 0.1461
2024-05-24 22:47:19 [INFO]: Epoch 063 - training loss: 0.1139, validation loss: 0.1422
2024-05-24 22:47:20 [INFO]: Epoch 064 - training loss: 0.1151, validation loss: 0.1376
2024-05-24 22:47:20 [INFO]: Epoch 065 - training loss: 0.1099, validation loss: 0.1380
2024-05-24 22:47:21 [INFO]: Epoch 066 - training loss: 0.0985, validation loss: 0.1392
2024-05-24 22:47:21 [INFO]: Epoch 067 - training loss: 0.0974, validation loss: 0.1394
2024-05-24 22:47:22 [INFO]: Epoch 068 - training loss: 0.1129, validation loss: 0.1407
2024-05-24 22:47:23 [INFO]: Epoch 069 - training loss: 0.0975, validation loss: 0.1410
2024-05-24 22:47:23 [INFO]: Epoch 070 - training loss: 0.0880, validation loss: 0.1364
2024-05-24 22:47:24 [INFO]: Epoch 071 - training loss: 0.1008, validation loss: 0.1380
2024-05-24 22:47:24 [INFO]: Epoch 072 - training loss: 0.1004, validation loss: 0.1379
2024-05-24 22:47:25 [INFO]: Epoch 073 - training loss: 0.1024, validation loss: 0.1369
2024-05-24 22:47:25 [INFO]: Epoch 074 - training loss: 0.1037, validation loss: 0.1408
2024-05-24 22:47:26 [INFO]: Epoch 075 - training loss: 0.1041, validation loss: 0.1378
2024-05-24 22:47:26 [INFO]: Epoch 076 - training loss: 0.0845, validation loss: 0.1364
2024-05-24 22:47:27 [INFO]: Epoch 077 - training loss: 0.0890, validation loss: 0.1385
2024-05-24 22:47:27 [INFO]: Epoch 078 - training loss: 0.0893, validation loss: 0.1419
2024-05-24 22:47:28 [INFO]: Epoch 079 - training loss: 0.0845, validation loss: 0.1423
2024-05-24 22:47:28 [INFO]: Epoch 080 - training loss: 0.1023, validation loss: 0.1363
2024-05-24 22:47:29 [INFO]: Epoch 081 - training loss: 0.1075, validation loss: 0.1418
2024-05-24 22:47:29 [INFO]: Epoch 082 - training loss: 0.0982, validation loss: 0.1382
2024-05-24 22:47:30 [INFO]: Epoch 083 - training loss: 0.1033, validation loss: 0.1368
2024-05-24 22:47:30 [INFO]: Epoch 084 - training loss: 0.0844, validation loss: 0.1363
2024-05-24 22:47:31 [INFO]: Epoch 085 - training loss: 0.0937, validation loss: 0.1366
2024-05-24 22:47:31 [INFO]: Epoch 086 - training loss: 0.0809, validation loss: 0.1371
2024-05-24 22:47:32 [INFO]: Epoch 087 - training loss: 0.0875, validation loss: 0.1371
2024-05-24 22:47:32 [INFO]: Epoch 088 - training loss: 0.0950, validation loss: 0.1456
2024-05-24 22:47:33 [INFO]: Epoch 089 - training loss: 0.1071, validation loss: 0.1368
2024-05-24 22:47:33 [INFO]: Epoch 090 - training loss: 0.0971, validation loss: 0.1366
2024-05-24 22:47:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:47:33 [INFO]: Finished training. The best model is from epoch#80.
2024-05-24 22:47:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/TimesNet_air_quality/20240524_T224640/TimesNet.pypots
2024-05-24 22:47:34 [INFO]: TimesNet on Air-Quality: MAE=0.1502, MSE=0.1196
2024-05-24 22:47:34 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/TimesNet_air_quality/imputation.pkl
2024-05-24 22:47:34 [INFO]: Using the given device: cuda:0
2024-05-24 22:47:34 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734
2024-05-24 22:47:34 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/tensorboard
2024-05-24 22:47:34 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-24 22:47:52 [INFO]: Epoch 001 - training loss: 0.4775, validation loss: 0.3513
2024-05-24 22:47:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch1_loss0.35129258334636687.pypots
2024-05-24 22:48:08 [INFO]: Epoch 002 - training loss: 0.3118, validation loss: 0.3067
2024-05-24 22:48:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch2_loss0.3066637396812439.pypots
2024-05-24 22:48:25 [INFO]: Epoch 003 - training loss: 0.2624, validation loss: 0.2701
2024-05-24 22:48:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch3_loss0.27010051161050797.pypots
2024-05-24 22:48:42 [INFO]: Epoch 004 - training loss: 0.2625, validation loss: 0.2274
2024-05-24 22:48:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch4_loss0.22736872136592864.pypots
2024-05-24 22:48:59 [INFO]: Epoch 005 - training loss: 0.2311, validation loss: 0.1904
2024-05-24 22:48:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch5_loss0.1904368966817856.pypots
2024-05-24 22:49:15 [INFO]: Epoch 006 - training loss: 0.1875, validation loss: 0.1823
2024-05-24 22:49:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch6_loss0.18232685178518296.pypots
2024-05-24 22:49:32 [INFO]: Epoch 007 - training loss: 0.1843, validation loss: 0.1703
2024-05-24 22:49:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch7_loss0.1703450709581375.pypots
2024-05-24 22:49:49 [INFO]: Epoch 008 - training loss: 0.1967, validation loss: 0.1721
2024-05-24 22:49:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch8_loss0.17209759801626207.pypots
2024-05-24 22:50:06 [INFO]: Epoch 009 - training loss: 0.1916, validation loss: 0.1596
2024-05-24 22:50:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch9_loss0.15958703756332399.pypots
2024-05-24 22:50:22 [INFO]: Epoch 010 - training loss: 0.1841, validation loss: 0.1513
2024-05-24 22:50:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch10_loss0.15131256878376007.pypots
2024-05-24 22:50:39 [INFO]: Epoch 011 - training loss: 0.1692, validation loss: 0.1541
2024-05-24 22:50:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch11_loss0.15414209812879562.pypots
2024-05-24 22:50:56 [INFO]: Epoch 012 - training loss: 0.1807, validation loss: 0.1479
2024-05-24 22:50:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch12_loss0.14789459109306335.pypots
2024-05-24 22:51:13 [INFO]: Epoch 013 - training loss: 0.1522, validation loss: 0.1472
2024-05-24 22:51:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch13_loss0.1472125768661499.pypots
2024-05-24 22:51:29 [INFO]: Epoch 014 - training loss: 0.1921, validation loss: 0.1461
2024-05-24 22:51:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch14_loss0.1461084082722664.pypots
2024-05-24 22:51:46 [INFO]: Epoch 015 - training loss: 0.1732, validation loss: 0.1437
2024-05-24 22:51:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch15_loss0.14367559254169465.pypots
2024-05-24 22:52:03 [INFO]: Epoch 016 - training loss: 0.1953, validation loss: 0.1438
2024-05-24 22:52:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch16_loss0.14377016201615334.pypots
2024-05-24 22:52:20 [INFO]: Epoch 017 - training loss: 0.1534, validation loss: 0.1391
2024-05-24 22:52:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch17_loss0.139095950871706.pypots
2024-05-24 22:52:37 [INFO]: Epoch 018 - training loss: 0.1527, validation loss: 0.1377
2024-05-24 22:52:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch18_loss0.13768170401453972.pypots
2024-05-24 22:52:53 [INFO]: Epoch 019 - training loss: 0.1542, validation loss: 0.1353
2024-05-24 22:52:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch19_loss0.13525818586349486.pypots
2024-05-24 22:53:10 [INFO]: Epoch 020 - training loss: 0.1746, validation loss: 0.1385
2024-05-24 22:53:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch20_loss0.1384645789861679.pypots
2024-05-24 22:53:27 [INFO]: Epoch 021 - training loss: 0.1462, validation loss: 0.1335
2024-05-24 22:53:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch21_loss0.13347249031066893.pypots
2024-05-24 22:53:44 [INFO]: Epoch 022 - training loss: 0.1712, validation loss: 0.1313
2024-05-24 22:53:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch22_loss0.13132227435708047.pypots
2024-05-24 22:54:00 [INFO]: Epoch 023 - training loss: 0.1557, validation loss: 0.1318
2024-05-24 22:54:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch23_loss0.1317908562719822.pypots
2024-05-24 22:54:17 [INFO]: Epoch 024 - training loss: 0.1477, validation loss: 0.1339
2024-05-24 22:54:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch24_loss0.13385439291596413.pypots
2024-05-24 22:54:34 [INFO]: Epoch 025 - training loss: 0.1266, validation loss: 0.1283
2024-05-24 22:54:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch25_loss0.12830560952425002.pypots
2024-05-24 22:54:51 [INFO]: Epoch 026 - training loss: 0.1322, validation loss: 0.1352
2024-05-24 22:54:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch26_loss0.13519411757588387.pypots
2024-05-24 22:55:07 [INFO]: Epoch 027 - training loss: 0.1365, validation loss: 0.1305
2024-05-24 22:55:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch27_loss0.13051701784133912.pypots
2024-05-24 22:55:24 [INFO]: Epoch 028 - training loss: 0.1402, validation loss: 0.1293
2024-05-24 22:55:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch28_loss0.1293259583413601.pypots
2024-05-24 22:55:41 [INFO]: Epoch 029 - training loss: 0.1239, validation loss: 0.1282
2024-05-24 22:55:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch29_loss0.12821277529001235.pypots
2024-05-24 22:55:58 [INFO]: Epoch 030 - training loss: 0.1306, validation loss: 0.1266
2024-05-24 22:55:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch30_loss0.12664853110909463.pypots
2024-05-24 22:56:14 [INFO]: Epoch 031 - training loss: 0.1403, validation loss: 0.1289
2024-05-24 22:56:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch31_loss0.12887718454003333.pypots
2024-05-24 22:56:31 [INFO]: Epoch 032 - training loss: 0.1484, validation loss: 0.1272
2024-05-24 22:56:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch32_loss0.12722100242972373.pypots
2024-05-24 22:56:48 [INFO]: Epoch 033 - training loss: 0.1370, validation loss: 0.1199
2024-05-24 22:56:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch33_loss0.11986124441027642.pypots
2024-05-24 22:57:05 [INFO]: Epoch 034 - training loss: 0.1217, validation loss: 0.1196
2024-05-24 22:57:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch34_loss0.11963345110416412.pypots
2024-05-24 22:57:21 [INFO]: Epoch 035 - training loss: 0.1414, validation loss: 0.1233
2024-05-24 22:57:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch35_loss0.12330038174986839.pypots
2024-05-24 22:57:38 [INFO]: Epoch 036 - training loss: 0.1304, validation loss: 0.1210
2024-05-24 22:57:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch36_loss0.12098905891180038.pypots
2024-05-24 22:57:55 [INFO]: Epoch 037 - training loss: 0.1473, validation loss: 0.1232
2024-05-24 22:57:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch37_loss0.12317789793014526.pypots
2024-05-24 22:58:12 [INFO]: Epoch 038 - training loss: 0.1354, validation loss: 0.1190
2024-05-24 22:58:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch38_loss0.11901195421814918.pypots
2024-05-24 22:58:28 [INFO]: Epoch 039 - training loss: 0.1467, validation loss: 0.1200
2024-05-24 22:58:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch39_loss0.11999498903751374.pypots
2024-05-24 22:58:45 [INFO]: Epoch 040 - training loss: 0.1220, validation loss: 0.1163
2024-05-24 22:58:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch40_loss0.11627339199185371.pypots
2024-05-24 22:59:02 [INFO]: Epoch 041 - training loss: 0.1183, validation loss: 0.1142
2024-05-24 22:59:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch41_loss0.11423633471131325.pypots
2024-05-24 22:59:19 [INFO]: Epoch 042 - training loss: 0.1353, validation loss: 0.1220
2024-05-24 22:59:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch42_loss0.12203914076089858.pypots
2024-05-24 22:59:35 [INFO]: Epoch 043 - training loss: 0.1269, validation loss: 0.1131
2024-05-24 22:59:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch43_loss0.1131325788795948.pypots
2024-05-24 22:59:52 [INFO]: Epoch 044 - training loss: 0.1289, validation loss: 0.1139
2024-05-24 22:59:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch44_loss0.11391909196972846.pypots
2024-05-24 23:00:09 [INFO]: Epoch 045 - training loss: 0.1297, validation loss: 0.1139
2024-05-24 23:00:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch45_loss0.11386887803673744.pypots
2024-05-24 23:00:26 [INFO]: Epoch 046 - training loss: 0.1213, validation loss: 0.1194
2024-05-24 23:00:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch46_loss0.11940402165055275.pypots
2024-05-24 23:00:43 [INFO]: Epoch 047 - training loss: 0.1294, validation loss: 0.1139
2024-05-24 23:00:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch47_loss0.11390297189354896.pypots
2024-05-24 23:00:59 [INFO]: Epoch 048 - training loss: 0.1305, validation loss: 0.1130
2024-05-24 23:00:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch48_loss0.11302459761500358.pypots
2024-05-24 23:01:16 [INFO]: Epoch 049 - training loss: 0.1270, validation loss: 0.1124
2024-05-24 23:01:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch49_loss0.11237462013959884.pypots
2024-05-24 23:01:33 [INFO]: Epoch 050 - training loss: 0.1239, validation loss: 0.1157
2024-05-24 23:01:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch50_loss0.11573631018400192.pypots
2024-05-24 23:01:50 [INFO]: Epoch 051 - training loss: 0.1361, validation loss: 0.1128
2024-05-24 23:01:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch51_loss0.11278448849916459.pypots
2024-05-24 23:02:06 [INFO]: Epoch 052 - training loss: 0.1401, validation loss: 0.1146
2024-05-24 23:02:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch52_loss0.11462826207280159.pypots
2024-05-24 23:02:23 [INFO]: Epoch 053 - training loss: 0.1140, validation loss: 0.1106
2024-05-24 23:02:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch53_loss0.1106067143380642.pypots
2024-05-24 23:02:40 [INFO]: Epoch 054 - training loss: 0.1298, validation loss: 0.1134
2024-05-24 23:02:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch54_loss0.11341724917292595.pypots
2024-05-24 23:02:56 [INFO]: Epoch 055 - training loss: 0.1345, validation loss: 0.1089
2024-05-24 23:02:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch55_loss0.10889602303504944.pypots
2024-05-24 23:03:13 [INFO]: Epoch 056 - training loss: 0.1130, validation loss: 0.1125
2024-05-24 23:03:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch56_loss0.11253883168101311.pypots
2024-05-24 23:03:30 [INFO]: Epoch 057 - training loss: 0.1187, validation loss: 0.1095
2024-05-24 23:03:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch57_loss0.10948006734251976.pypots
2024-05-24 23:03:47 [INFO]: Epoch 058 - training loss: 0.1269, validation loss: 0.1091
2024-05-24 23:03:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch58_loss0.1090897150337696.pypots
2024-05-24 23:04:03 [INFO]: Epoch 059 - training loss: 0.1218, validation loss: 0.1139
2024-05-24 23:04:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch59_loss0.11388180255889893.pypots
2024-05-24 23:04:20 [INFO]: Epoch 060 - training loss: 0.1234, validation loss: 0.1139
2024-05-24 23:04:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch60_loss0.11385513991117477.pypots
2024-05-24 23:04:37 [INFO]: Epoch 061 - training loss: 0.1344, validation loss: 0.1092
2024-05-24 23:04:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch61_loss0.10915818884968757.pypots
2024-05-24 23:04:54 [INFO]: Epoch 062 - training loss: 0.1158, validation loss: 0.1079
2024-05-24 23:04:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch62_loss0.10789459198713303.pypots
2024-05-24 23:05:10 [INFO]: Epoch 063 - training loss: 0.1299, validation loss: 0.1079
2024-05-24 23:05:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch63_loss0.10786220878362655.pypots
2024-05-24 23:05:27 [INFO]: Epoch 064 - training loss: 0.1151, validation loss: 0.1077
2024-05-24 23:05:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch64_loss0.10765261203050613.pypots
2024-05-24 23:05:44 [INFO]: Epoch 065 - training loss: 0.1187, validation loss: 0.1107
2024-05-24 23:05:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch65_loss0.11070326045155525.pypots
2024-05-24 23:06:01 [INFO]: Epoch 066 - training loss: 0.1291, validation loss: 0.1075
2024-05-24 23:06:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch66_loss0.10753482952713966.pypots
2024-05-24 23:06:17 [INFO]: Epoch 067 - training loss: 0.1075, validation loss: 0.1084
2024-05-24 23:06:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch67_loss0.10835776701569558.pypots
2024-05-24 23:06:34 [INFO]: Epoch 068 - training loss: 0.1128, validation loss: 0.1075
2024-05-24 23:06:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch68_loss0.1074573665857315.pypots
2024-05-24 23:06:51 [INFO]: Epoch 069 - training loss: 0.1109, validation loss: 0.1070
2024-05-24 23:06:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch69_loss0.10702467933297158.pypots
2024-05-24 23:07:08 [INFO]: Epoch 070 - training loss: 0.1228, validation loss: 0.1084
2024-05-24 23:07:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch70_loss0.1083743304014206.pypots
2024-05-24 23:07:24 [INFO]: Epoch 071 - training loss: 0.1320, validation loss: 0.1078
2024-05-24 23:07:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch71_loss0.10782570168375968.pypots
2024-05-24 23:07:41 [INFO]: Epoch 072 - training loss: 0.1080, validation loss: 0.1190
2024-05-24 23:07:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch72_loss0.1189644232392311.pypots
2024-05-24 23:07:58 [INFO]: Epoch 073 - training loss: 0.1221, validation loss: 0.1067
2024-05-24 23:07:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch73_loss0.10670979991555214.pypots
2024-05-24 23:08:14 [INFO]: Epoch 074 - training loss: 0.1283, validation loss: 0.1101
2024-05-24 23:08:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch74_loss0.1101116493344307.pypots
2024-05-24 23:08:31 [INFO]: Epoch 075 - training loss: 0.1127, validation loss: 0.1118
2024-05-24 23:08:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch75_loss0.11182454079389573.pypots
2024-05-24 23:08:48 [INFO]: Epoch 076 - training loss: 0.1198, validation loss: 0.1069
2024-05-24 23:08:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch76_loss0.10694376081228256.pypots
2024-05-24 23:09:05 [INFO]: Epoch 077 - training loss: 0.1268, validation loss: 0.1062
2024-05-24 23:09:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch77_loss0.10621684789657593.pypots
2024-05-24 23:09:21 [INFO]: Epoch 078 - training loss: 0.1075, validation loss: 0.1062
2024-05-24 23:09:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch78_loss0.10615881010890008.pypots
2024-05-24 23:09:38 [INFO]: Epoch 079 - training loss: 0.1116, validation loss: 0.1080
2024-05-24 23:09:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch79_loss0.10802058652043342.pypots
2024-05-24 23:09:55 [INFO]: Epoch 080 - training loss: 0.1156, validation loss: 0.1056
2024-05-24 23:09:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch80_loss0.10562348663806916.pypots
2024-05-24 23:10:12 [INFO]: Epoch 081 - training loss: 0.1152, validation loss: 0.1048
2024-05-24 23:10:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch81_loss0.10481528639793396.pypots
2024-05-24 23:10:28 [INFO]: Epoch 082 - training loss: 0.1050, validation loss: 0.1042
2024-05-24 23:10:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch82_loss0.10423211902379989.pypots
2024-05-24 23:10:45 [INFO]: Epoch 083 - training loss: 0.1260, validation loss: 0.1024
2024-05-24 23:10:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch83_loss0.10240447670221328.pypots
2024-05-24 23:11:02 [INFO]: Epoch 084 - training loss: 0.1174, validation loss: 0.1054
2024-05-24 23:11:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch84_loss0.10540392994880676.pypots
2024-05-24 23:11:19 [INFO]: Epoch 085 - training loss: 0.1228, validation loss: 0.1074
2024-05-24 23:11:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch85_loss0.10743727535009384.pypots
2024-05-24 23:11:35 [INFO]: Epoch 086 - training loss: 0.1224, validation loss: 0.1037
2024-05-24 23:11:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch86_loss0.10372422188520432.pypots
2024-05-24 23:11:52 [INFO]: Epoch 087 - training loss: 0.1090, validation loss: 0.1044
2024-05-24 23:11:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch87_loss0.10443346351385116.pypots
2024-05-24 23:12:09 [INFO]: Epoch 088 - training loss: 0.1233, validation loss: 0.1018
2024-05-24 23:12:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch88_loss0.10179186388850212.pypots
2024-05-24 23:12:26 [INFO]: Epoch 089 - training loss: 0.1195, validation loss: 0.1038
2024-05-24 23:12:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch89_loss0.1037677675485611.pypots
2024-05-24 23:12:42 [INFO]: Epoch 090 - training loss: 0.1121, validation loss: 0.1040
2024-05-24 23:12:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch90_loss0.10396801754832267.pypots
2024-05-24 23:12:59 [INFO]: Epoch 091 - training loss: 0.1245, validation loss: 0.1074
2024-05-24 23:12:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch91_loss0.10738347172737121.pypots
2024-05-24 23:13:16 [INFO]: Epoch 092 - training loss: 0.1188, validation loss: 0.1036
2024-05-24 23:13:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch92_loss0.1036456011235714.pypots
2024-05-24 23:13:32 [INFO]: Epoch 093 - training loss: 0.1087, validation loss: 0.1042
2024-05-24 23:13:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch93_loss0.10416404232382774.pypots
2024-05-24 23:13:49 [INFO]: Epoch 094 - training loss: 0.1179, validation loss: 0.1035
2024-05-24 23:13:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch94_loss0.10354860574007034.pypots
2024-05-24 23:14:06 [INFO]: Epoch 095 - training loss: 0.1169, validation loss: 0.1043
2024-05-24 23:14:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch95_loss0.1042580969631672.pypots
2024-05-24 23:14:23 [INFO]: Epoch 096 - training loss: 0.1154, validation loss: 0.1045
2024-05-24 23:14:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch96_loss0.10453462302684784.pypots
2024-05-24 23:14:39 [INFO]: Epoch 097 - training loss: 0.1091, validation loss: 0.1057
2024-05-24 23:14:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch97_loss0.10572589635848999.pypots
2024-05-24 23:14:56 [INFO]: Epoch 098 - training loss: 0.1127, validation loss: 0.1018
2024-05-24 23:14:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch98_loss0.10176600888371468.pypots
2024-05-24 23:15:13 [INFO]: Epoch 099 - training loss: 0.1114, validation loss: 0.1034
2024-05-24 23:15:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch99_loss0.10342037454247474.pypots
2024-05-24 23:15:30 [INFO]: Epoch 100 - training loss: 0.1196, validation loss: 0.1018
2024-05-24 23:15:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch100_loss0.10177726447582244.pypots
2024-05-24 23:15:46 [INFO]: Epoch 101 - training loss: 0.1165, validation loss: 0.1095
2024-05-24 23:15:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch101_loss0.10945343375205993.pypots
2024-05-24 23:16:03 [INFO]: Epoch 102 - training loss: 0.1088, validation loss: 0.1040
2024-05-24 23:16:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch102_loss0.10395395681262017.pypots
2024-05-24 23:16:20 [INFO]: Epoch 103 - training loss: 0.1173, validation loss: 0.1024
2024-05-24 23:16:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch103_loss0.10241835042834282.pypots
2024-05-24 23:16:37 [INFO]: Epoch 104 - training loss: 0.1045, validation loss: 0.1021
2024-05-24 23:16:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch104_loss0.10205373764038086.pypots
2024-05-24 23:16:53 [INFO]: Epoch 105 - training loss: 0.1131, validation loss: 0.1015
2024-05-24 23:16:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch105_loss0.10150323137640953.pypots
2024-05-24 23:17:10 [INFO]: Epoch 106 - training loss: 0.1127, validation loss: 0.1016
2024-05-24 23:17:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch106_loss0.1015910342335701.pypots
2024-05-24 23:17:27 [INFO]: Epoch 107 - training loss: 0.1171, validation loss: 0.1031
2024-05-24 23:17:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch107_loss0.10305893272161484.pypots
2024-05-24 23:17:43 [INFO]: Epoch 108 - training loss: 0.1120, validation loss: 0.1064
2024-05-24 23:17:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch108_loss0.1063998207449913.pypots
2024-05-24 23:18:00 [INFO]: Epoch 109 - training loss: 0.1073, validation loss: 0.1035
2024-05-24 23:18:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch109_loss0.10352194607257843.pypots
2024-05-24 23:18:17 [INFO]: Epoch 110 - training loss: 0.1188, validation loss: 0.1042
2024-05-24 23:18:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch110_loss0.1041729837656021.pypots
2024-05-24 23:18:34 [INFO]: Epoch 111 - training loss: 0.1205, validation loss: 0.1020
2024-05-24 23:18:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch111_loss0.10199391171336174.pypots
2024-05-24 23:18:50 [INFO]: Epoch 112 - training loss: 0.1061, validation loss: 0.1009
2024-05-24 23:18:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch112_loss0.10089945644140244.pypots
2024-05-24 23:19:07 [INFO]: Epoch 113 - training loss: 0.1229, validation loss: 0.1035
2024-05-24 23:19:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch113_loss0.10351959019899368.pypots
2024-05-24 23:19:24 [INFO]: Epoch 114 - training loss: 0.1141, validation loss: 0.1014
2024-05-24 23:19:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch114_loss0.10142936706542968.pypots
2024-05-24 23:19:41 [INFO]: Epoch 115 - training loss: 0.1144, validation loss: 0.1043
2024-05-24 23:19:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch115_loss0.10427765250205993.pypots
2024-05-24 23:19:57 [INFO]: Epoch 116 - training loss: 0.1169, validation loss: 0.1008
2024-05-24 23:19:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch116_loss0.10077693611383438.pypots
2024-05-24 23:20:14 [INFO]: Epoch 117 - training loss: 0.1080, validation loss: 0.1006
2024-05-24 23:20:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch117_loss0.1006216675043106.pypots
2024-05-24 23:20:31 [INFO]: Epoch 118 - training loss: 0.1115, validation loss: 0.1030
2024-05-24 23:20:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch118_loss0.10298764407634735.pypots
2024-05-24 23:20:48 [INFO]: Epoch 119 - training loss: 0.1107, validation loss: 0.1057
2024-05-24 23:20:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch119_loss0.10569372028112411.pypots
2024-05-24 23:21:04 [INFO]: Epoch 120 - training loss: 0.1244, validation loss: 0.1008
2024-05-24 23:21:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch120_loss0.10078315138816833.pypots
2024-05-24 23:21:21 [INFO]: Epoch 121 - training loss: 0.1147, validation loss: 0.1007
2024-05-24 23:21:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch121_loss0.100698222219944.pypots
2024-05-24 23:21:38 [INFO]: Epoch 122 - training loss: 0.1230, validation loss: 0.1004
2024-05-24 23:21:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch122_loss0.1004412554204464.pypots
2024-05-24 23:21:54 [INFO]: Epoch 123 - training loss: 0.1182, validation loss: 0.1037
2024-05-24 23:21:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch123_loss0.10365451127290726.pypots
2024-05-24 23:22:11 [INFO]: Epoch 124 - training loss: 0.1120, validation loss: 0.1000
2024-05-24 23:22:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch124_loss0.10002762377262116.pypots
2024-05-24 23:22:28 [INFO]: Epoch 125 - training loss: 0.0995, validation loss: 0.1004
2024-05-24 23:22:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch125_loss0.1003524474799633.pypots
2024-05-24 23:22:45 [INFO]: Epoch 126 - training loss: 0.1120, validation loss: 0.0998
2024-05-24 23:22:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch126_loss0.09984087124466896.pypots
2024-05-24 23:23:01 [INFO]: Epoch 127 - training loss: 0.1086, validation loss: 0.1003
2024-05-24 23:23:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch127_loss0.10026774704456329.pypots
2024-05-24 23:23:18 [INFO]: Epoch 128 - training loss: 0.0914, validation loss: 0.1016
2024-05-24 23:23:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch128_loss0.1015687070786953.pypots
2024-05-24 23:23:35 [INFO]: Epoch 129 - training loss: 0.1227, validation loss: 0.0996
2024-05-24 23:23:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch129_loss0.09960252642631531.pypots
2024-05-24 23:23:52 [INFO]: Epoch 130 - training loss: 0.1100, validation loss: 0.1010
2024-05-24 23:23:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch130_loss0.1009815625846386.pypots
2024-05-24 23:24:08 [INFO]: Epoch 131 - training loss: 0.0978, validation loss: 0.0999
2024-05-24 23:24:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch131_loss0.09985828995704651.pypots
2024-05-24 23:24:25 [INFO]: Epoch 132 - training loss: 0.1046, validation loss: 0.0995
2024-05-24 23:24:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch132_loss0.09954160451889038.pypots
2024-05-24 23:24:42 [INFO]: Epoch 133 - training loss: 0.1175, validation loss: 0.0990
2024-05-24 23:24:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch133_loss0.0989804096519947.pypots
2024-05-24 23:24:59 [INFO]: Epoch 134 - training loss: 0.1030, validation loss: 0.0998
2024-05-24 23:24:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch134_loss0.09980034232139587.pypots
2024-05-24 23:25:15 [INFO]: Epoch 135 - training loss: 0.1110, validation loss: 0.1017
2024-05-24 23:25:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch135_loss0.10167892575263977.pypots
2024-05-24 23:25:32 [INFO]: Epoch 136 - training loss: 0.1240, validation loss: 0.1005
2024-05-24 23:25:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch136_loss0.10046838447451592.pypots
2024-05-24 23:25:49 [INFO]: Epoch 137 - training loss: 0.1130, validation loss: 0.1008
2024-05-24 23:25:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch137_loss0.10084588378667832.pypots
2024-05-24 23:26:05 [INFO]: Epoch 138 - training loss: 0.1138, validation loss: 0.0993
2024-05-24 23:26:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch138_loss0.0993288904428482.pypots
2024-05-24 23:26:22 [INFO]: Epoch 139 - training loss: 0.1037, validation loss: 0.0991
2024-05-24 23:26:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch139_loss0.09912821874022484.pypots
2024-05-24 23:26:39 [INFO]: Epoch 140 - training loss: 0.1139, validation loss: 0.0990
2024-05-24 23:26:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch140_loss0.09896437227725982.pypots
2024-05-24 23:26:56 [INFO]: Epoch 141 - training loss: 0.1050, validation loss: 0.1003
2024-05-24 23:26:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch141_loss0.10028108134865761.pypots
2024-05-24 23:27:12 [INFO]: Epoch 142 - training loss: 0.1142, validation loss: 0.1027
2024-05-24 23:27:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch142_loss0.10272538810968398.pypots
2024-05-24 23:27:29 [INFO]: Epoch 143 - training loss: 0.1345, validation loss: 0.1004
2024-05-24 23:27:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch143_loss0.10040184184908867.pypots
2024-05-24 23:27:46 [INFO]: Epoch 144 - training loss: 0.1012, validation loss: 0.0974
2024-05-24 23:27:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch144_loss0.09736754819750786.pypots
2024-05-24 23:28:03 [INFO]: Epoch 145 - training loss: 0.1123, validation loss: 0.0982
2024-05-24 23:28:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch145_loss0.0981702297925949.pypots
2024-05-24 23:28:19 [INFO]: Epoch 146 - training loss: 0.1095, validation loss: 0.0985
2024-05-24 23:28:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch146_loss0.09854673817753792.pypots
2024-05-24 23:28:36 [INFO]: Epoch 147 - training loss: 0.1052, validation loss: 0.0982
2024-05-24 23:28:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch147_loss0.09819312542676925.pypots
2024-05-24 23:28:53 [INFO]: Epoch 148 - training loss: 0.1122, validation loss: 0.0986
2024-05-24 23:28:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch148_loss0.09856606721878051.pypots
2024-05-24 23:29:10 [INFO]: Epoch 149 - training loss: 0.1133, validation loss: 0.0997
2024-05-24 23:29:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch149_loss0.09965014755725861.pypots
2024-05-24 23:29:26 [INFO]: Epoch 150 - training loss: 0.1059, validation loss: 0.1031
2024-05-24 23:29:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch150_loss0.10309956818819047.pypots
2024-05-24 23:29:43 [INFO]: Epoch 151 - training loss: 0.1123, validation loss: 0.0977
2024-05-24 23:29:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch151_loss0.09767976775765419.pypots
2024-05-24 23:30:00 [INFO]: Epoch 152 - training loss: 0.1087, validation loss: 0.0996
2024-05-24 23:30:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch152_loss0.09958696961402894.pypots
2024-05-24 23:30:16 [INFO]: Epoch 153 - training loss: 0.1012, validation loss: 0.0993
2024-05-24 23:30:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch153_loss0.09925946444272996.pypots
2024-05-24 23:30:33 [INFO]: Epoch 154 - training loss: 0.1023, validation loss: 0.1001
2024-05-24 23:30:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI_epoch154_loss0.10007597729563714.pypots
2024-05-24 23:30:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:30:33 [INFO]: Finished training. The best model is from epoch#144.
2024-05-24 23:30:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T224734/CSDI.pypots
2024-05-24 23:32:53 [INFO]: CSDI on Air-Quality: MAE=0.0970, MSE=0.0881
2024-05-24 23:32:53 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/CSDI_air_quality/imputation.pkl
2024-05-24 23:32:53 [INFO]: Using the given device: cuda:0
2024-05-24 23:32:53 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/GPVAE_air_quality/20240524_T233253
2024-05-24 23:32:53 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/GPVAE_air_quality/20240524_T233253/tensorboard
2024-05-24 23:32:53 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-24 23:32:55 [INFO]: Epoch 001 - training loss: 63785.4881, validation loss: 0.6520
2024-05-24 23:32:55 [INFO]: Epoch 002 - training loss: 42046.2962, validation loss: 0.5726
2024-05-24 23:32:56 [INFO]: Epoch 003 - training loss: 41753.4712, validation loss: 0.5217
2024-05-24 23:32:56 [INFO]: Epoch 004 - training loss: 41646.0679, validation loss: 0.4620
2024-05-24 23:32:56 [INFO]: Epoch 005 - training loss: 41544.4936, validation loss: 0.4326
2024-05-24 23:32:57 [INFO]: Epoch 006 - training loss: 41488.1657, validation loss: 0.3953
2024-05-24 23:32:57 [INFO]: Epoch 007 - training loss: 41442.6088, validation loss: 0.3700
2024-05-24 23:32:57 [INFO]: Epoch 008 - training loss: 41414.0700, validation loss: 0.3464
2024-05-24 23:32:57 [INFO]: Epoch 009 - training loss: 41382.7522, validation loss: 0.3518
2024-05-24 23:32:58 [INFO]: Epoch 010 - training loss: 41424.1264, validation loss: 0.3567
2024-05-24 23:32:58 [INFO]: Epoch 011 - training loss: 41364.9822, validation loss: 0.3123
2024-05-24 23:32:58 [INFO]: Epoch 012 - training loss: 41342.7086, validation loss: 0.3084
2024-05-24 23:32:59 [INFO]: Epoch 013 - training loss: 41318.7814, validation loss: 0.2948
2024-05-24 23:32:59 [INFO]: Epoch 014 - training loss: 41320.6619, validation loss: 0.3153
2024-05-24 23:32:59 [INFO]: Epoch 015 - training loss: 41312.2098, validation loss: 0.2956
2024-05-24 23:32:59 [INFO]: Epoch 016 - training loss: 41298.2227, validation loss: 0.2944
2024-05-24 23:33:00 [INFO]: Epoch 017 - training loss: 41293.2351, validation loss: 0.2962
2024-05-24 23:33:00 [INFO]: Epoch 018 - training loss: 41311.4437, validation loss: 0.3320
2024-05-24 23:33:00 [INFO]: Epoch 019 - training loss: 41291.6308, validation loss: 0.2722
2024-05-24 23:33:01 [INFO]: Epoch 020 - training loss: 41281.1243, validation loss: 0.2948
2024-05-24 23:33:01 [INFO]: Epoch 021 - training loss: 41264.4371, validation loss: 0.2765
2024-05-24 23:33:01 [INFO]: Epoch 022 - training loss: 41247.7302, validation loss: 0.2615
2024-05-24 23:33:01 [INFO]: Epoch 023 - training loss: 41241.9782, validation loss: 0.2666
2024-05-24 23:33:02 [INFO]: Epoch 024 - training loss: 41232.6772, validation loss: 0.2606
2024-05-24 23:33:02 [INFO]: Epoch 025 - training loss: 41230.5988, validation loss: 0.2588
2024-05-24 23:33:02 [INFO]: Epoch 026 - training loss: 41230.9942, validation loss: 0.2531
2024-05-24 23:33:03 [INFO]: Epoch 027 - training loss: 41238.7014, validation loss: 0.2564
2024-05-24 23:33:03 [INFO]: Epoch 028 - training loss: 41223.5472, validation loss: 0.2461
2024-05-24 23:33:03 [INFO]: Epoch 029 - training loss: 41210.4799, validation loss: 0.2463
2024-05-24 23:33:03 [INFO]: Epoch 030 - training loss: 41215.2001, validation loss: 0.2501
2024-05-24 23:33:04 [INFO]: Epoch 031 - training loss: 41217.0567, validation loss: 0.2497
2024-05-24 23:33:04 [INFO]: Epoch 032 - training loss: 41261.5852, validation loss: 0.2731
2024-05-24 23:33:04 [INFO]: Epoch 033 - training loss: 41253.2429, validation loss: 0.2506
2024-05-24 23:33:05 [INFO]: Epoch 034 - training loss: 41211.8194, validation loss: 0.2704
2024-05-24 23:33:05 [INFO]: Epoch 035 - training loss: 41284.8702, validation loss: 0.2578
2024-05-24 23:33:05 [INFO]: Epoch 036 - training loss: 41252.7824, validation loss: 0.2828
2024-05-24 23:33:05 [INFO]: Epoch 037 - training loss: 41222.9589, validation loss: 0.2520
2024-05-24 23:33:06 [INFO]: Epoch 038 - training loss: 41206.4071, validation loss: 0.2556
2024-05-24 23:33:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:33:06 [INFO]: Finished training. The best model is from epoch#28.
2024-05-24 23:33:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/GPVAE_air_quality/20240524_T233253/GPVAE.pypots
2024-05-24 23:33:06 [INFO]: GP-VAE on Air-Quality: MAE=0.2884, MSE=0.2416
2024-05-24 23:33:06 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/GPVAE_air_quality/imputation.pkl
2024-05-24 23:33:06 [INFO]: Using the given device: cuda:0
2024-05-24 23:33:06 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/USGAN_air_quality/20240524_T233306
2024-05-24 23:33:06 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/USGAN_air_quality/20240524_T233306/tensorboard
2024-05-24 23:33:06 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-24 23:33:12 [INFO]: Epoch 001 - generator training loss: 0.6149, discriminator training loss: 0.2903, validation loss: 0.5061
2024-05-24 23:33:16 [INFO]: Epoch 002 - generator training loss: 0.2873, discriminator training loss: 0.0672, validation loss: 0.3769
2024-05-24 23:33:19 [INFO]: Epoch 003 - generator training loss: 0.2158, discriminator training loss: 0.0630, validation loss: 0.3098
2024-05-24 23:33:23 [INFO]: Epoch 004 - generator training loss: 0.1774, discriminator training loss: 0.0621, validation loss: 0.2689
2024-05-24 23:33:27 [INFO]: Epoch 005 - generator training loss: 0.1528, discriminator training loss: 0.0618, validation loss: 0.2420
2024-05-24 23:33:31 [INFO]: Epoch 006 - generator training loss: 0.1348, discriminator training loss: 0.0613, validation loss: 0.2235
2024-05-24 23:33:35 [INFO]: Epoch 007 - generator training loss: 0.1263, discriminator training loss: 0.0606, validation loss: 0.2089
2024-05-24 23:33:39 [INFO]: Epoch 008 - generator training loss: 0.1115, discriminator training loss: 0.0600, validation loss: 0.1981
2024-05-24 23:33:43 [INFO]: Epoch 009 - generator training loss: 0.1033, discriminator training loss: 0.0593, validation loss: 0.1898
2024-05-24 23:33:47 [INFO]: Epoch 010 - generator training loss: 0.0983, discriminator training loss: 0.0588, validation loss: 0.1832
2024-05-24 23:33:51 [INFO]: Epoch 011 - generator training loss: 0.0921, discriminator training loss: 0.0578, validation loss: 0.1769
2024-05-24 23:33:55 [INFO]: Epoch 012 - generator training loss: 0.0880, discriminator training loss: 0.0568, validation loss: 0.1724
2024-05-24 23:33:59 [INFO]: Epoch 013 - generator training loss: 0.0853, discriminator training loss: 0.0547, validation loss: 0.1676
2024-05-24 23:34:03 [INFO]: Epoch 014 - generator training loss: 0.0830, discriminator training loss: 0.0533, validation loss: 0.1631
2024-05-24 23:34:07 [INFO]: Epoch 015 - generator training loss: 0.0814, discriminator training loss: 0.0509, validation loss: 0.1589
2024-05-24 23:34:11 [INFO]: Epoch 016 - generator training loss: 0.0806, discriminator training loss: 0.0492, validation loss: 0.1534
2024-05-24 23:34:15 [INFO]: Epoch 017 - generator training loss: 0.0771, discriminator training loss: 0.0475, validation loss: 0.1501
2024-05-24 23:34:19 [INFO]: Epoch 018 - generator training loss: 0.0752, discriminator training loss: 0.0466, validation loss: 0.1470
2024-05-24 23:34:23 [INFO]: Epoch 019 - generator training loss: 0.0741, discriminator training loss: 0.0457, validation loss: 0.1456
2024-05-24 23:34:27 [INFO]: Epoch 020 - generator training loss: 0.0714, discriminator training loss: 0.0454, validation loss: 0.1424
2024-05-24 23:34:31 [INFO]: Epoch 021 - generator training loss: 0.0699, discriminator training loss: 0.0447, validation loss: 0.1410
2024-05-24 23:34:35 [INFO]: Epoch 022 - generator training loss: 0.0694, discriminator training loss: 0.0436, validation loss: 0.1391
2024-05-24 23:34:39 [INFO]: Epoch 023 - generator training loss: 0.0679, discriminator training loss: 0.0434, validation loss: 0.1374
2024-05-24 23:34:43 [INFO]: Epoch 024 - generator training loss: 0.0690, discriminator training loss: 0.0421, validation loss: 0.1356
2024-05-24 23:34:46 [INFO]: Epoch 025 - generator training loss: 0.0655, discriminator training loss: 0.0419, validation loss: 0.1347
2024-05-24 23:34:50 [INFO]: Epoch 026 - generator training loss: 0.0654, discriminator training loss: 0.0408, validation loss: 0.1328
2024-05-24 23:34:54 [INFO]: Epoch 027 - generator training loss: 0.0647, discriminator training loss: 0.0401, validation loss: 0.1320
2024-05-24 23:34:58 [INFO]: Epoch 028 - generator training loss: 0.0636, discriminator training loss: 0.0391, validation loss: 0.1310
2024-05-24 23:35:02 [INFO]: Epoch 029 - generator training loss: 0.0627, discriminator training loss: 0.0380, validation loss: 0.1302
2024-05-24 23:35:06 [INFO]: Epoch 030 - generator training loss: 0.0623, discriminator training loss: 0.0374, validation loss: 0.1288
2024-05-24 23:35:10 [INFO]: Epoch 031 - generator training loss: 0.0619, discriminator training loss: 0.0366, validation loss: 0.1278
2024-05-24 23:35:14 [INFO]: Epoch 032 - generator training loss: 0.0611, discriminator training loss: 0.0357, validation loss: 0.1270
2024-05-24 23:35:18 [INFO]: Epoch 033 - generator training loss: 0.0606, discriminator training loss: 0.0352, validation loss: 0.1261
2024-05-24 23:35:22 [INFO]: Epoch 034 - generator training loss: 0.0602, discriminator training loss: 0.0345, validation loss: 0.1253
2024-05-24 23:35:26 [INFO]: Epoch 035 - generator training loss: 0.0605, discriminator training loss: 0.0330, validation loss: 0.1247
2024-05-24 23:35:30 [INFO]: Epoch 036 - generator training loss: 0.0609, discriminator training loss: 0.0325, validation loss: 0.1236
2024-05-24 23:35:34 [INFO]: Epoch 037 - generator training loss: 0.0602, discriminator training loss: 0.0316, validation loss: 0.1227
2024-05-24 23:35:38 [INFO]: Epoch 038 - generator training loss: 0.0594, discriminator training loss: 0.0313, validation loss: 0.1217
2024-05-24 23:35:42 [INFO]: Epoch 039 - generator training loss: 0.0601, discriminator training loss: 0.0305, validation loss: 0.1212
2024-05-24 23:35:46 [INFO]: Epoch 040 - generator training loss: 0.0579, discriminator training loss: 0.0300, validation loss: 0.1200
2024-05-24 23:35:50 [INFO]: Epoch 041 - generator training loss: 0.0569, discriminator training loss: 0.0297, validation loss: 0.1193
2024-05-24 23:35:54 [INFO]: Epoch 042 - generator training loss: 0.0571, discriminator training loss: 0.0291, validation loss: 0.1195
2024-05-24 23:35:58 [INFO]: Epoch 043 - generator training loss: 0.0566, discriminator training loss: 0.0287, validation loss: 0.1175
2024-05-24 23:36:02 [INFO]: Epoch 044 - generator training loss: 0.0562, discriminator training loss: 0.0280, validation loss: 0.1181
2024-05-24 23:36:06 [INFO]: Epoch 045 - generator training loss: 0.0569, discriminator training loss: 0.0276, validation loss: 0.1173
2024-05-24 23:36:10 [INFO]: Epoch 046 - generator training loss: 0.0554, discriminator training loss: 0.0269, validation loss: 0.1163
2024-05-24 23:36:14 [INFO]: Epoch 047 - generator training loss: 0.0565, discriminator training loss: 0.0265, validation loss: 0.1163
2024-05-24 23:36:17 [INFO]: Epoch 048 - generator training loss: 0.0547, discriminator training loss: 0.0260, validation loss: 0.1155
2024-05-24 23:36:21 [INFO]: Epoch 049 - generator training loss: 0.0554, discriminator training loss: 0.0256, validation loss: 0.1138
2024-05-24 23:36:25 [INFO]: Epoch 050 - generator training loss: 0.0538, discriminator training loss: 0.0254, validation loss: 0.1142
2024-05-24 23:36:29 [INFO]: Epoch 051 - generator training loss: 0.0534, discriminator training loss: 0.0248, validation loss: 0.1138
2024-05-24 23:36:33 [INFO]: Epoch 052 - generator training loss: 0.0535, discriminator training loss: 0.0244, validation loss: 0.1135
2024-05-24 23:36:37 [INFO]: Epoch 053 - generator training loss: 0.0535, discriminator training loss: 0.0239, validation loss: 0.1128
2024-05-24 23:36:41 [INFO]: Epoch 054 - generator training loss: 0.0528, discriminator training loss: 0.0237, validation loss: 0.1123
2024-05-24 23:36:45 [INFO]: Epoch 055 - generator training loss: 0.0525, discriminator training loss: 0.0232, validation loss: 0.1126
2024-05-24 23:36:49 [INFO]: Epoch 056 - generator training loss: 0.0523, discriminator training loss: 0.0229, validation loss: 0.1117
2024-05-24 23:36:53 [INFO]: Epoch 057 - generator training loss: 0.0526, discriminator training loss: 0.0224, validation loss: 0.1114
2024-05-24 23:36:57 [INFO]: Epoch 058 - generator training loss: 0.0517, discriminator training loss: 0.0222, validation loss: 0.1110
2024-05-24 23:37:01 [INFO]: Epoch 059 - generator training loss: 0.0514, discriminator training loss: 0.0219, validation loss: 0.1107
2024-05-24 23:37:05 [INFO]: Epoch 060 - generator training loss: 0.0509, discriminator training loss: 0.0215, validation loss: 0.1099
2024-05-24 23:37:09 [INFO]: Epoch 061 - generator training loss: 0.0514, discriminator training loss: 0.0216, validation loss: 0.1099
2024-05-24 23:37:13 [INFO]: Epoch 062 - generator training loss: 0.0504, discriminator training loss: 0.0211, validation loss: 0.1100
2024-05-24 23:37:17 [INFO]: Epoch 063 - generator training loss: 0.0508, discriminator training loss: 0.0207, validation loss: 0.1099
2024-05-24 23:37:21 [INFO]: Epoch 064 - generator training loss: 0.0499, discriminator training loss: 0.0206, validation loss: 0.1086
2024-05-24 23:37:25 [INFO]: Epoch 065 - generator training loss: 0.0509, discriminator training loss: 0.0203, validation loss: 0.1089
2024-05-24 23:37:29 [INFO]: Epoch 066 - generator training loss: 0.0494, discriminator training loss: 0.0201, validation loss: 0.1074
2024-05-24 23:37:33 [INFO]: Epoch 067 - generator training loss: 0.0491, discriminator training loss: 0.0197, validation loss: 0.1081
2024-05-24 23:37:37 [INFO]: Epoch 068 - generator training loss: 0.0484, discriminator training loss: 0.0198, validation loss: 0.1070
2024-05-24 23:37:41 [INFO]: Epoch 069 - generator training loss: 0.0487, discriminator training loss: 0.0195, validation loss: 0.1078
2024-05-24 23:37:45 [INFO]: Epoch 070 - generator training loss: 0.0496, discriminator training loss: 0.0190, validation loss: 0.1080
2024-05-24 23:37:49 [INFO]: Epoch 071 - generator training loss: 0.0479, discriminator training loss: 0.0191, validation loss: 0.1074
2024-05-24 23:37:52 [INFO]: Epoch 072 - generator training loss: 0.0490, discriminator training loss: 0.0189, validation loss: 0.1071
2024-05-24 23:37:56 [INFO]: Epoch 073 - generator training loss: 0.0477, discriminator training loss: 0.0186, validation loss: 0.1069
2024-05-24 23:38:00 [INFO]: Epoch 074 - generator training loss: 0.0473, discriminator training loss: 0.0185, validation loss: 0.1067
2024-05-24 23:38:04 [INFO]: Epoch 075 - generator training loss: 0.0468, discriminator training loss: 0.0181, validation loss: 0.1065
2024-05-24 23:38:08 [INFO]: Epoch 076 - generator training loss: 0.0468, discriminator training loss: 0.0185, validation loss: 0.1072
2024-05-24 23:38:12 [INFO]: Epoch 077 - generator training loss: 0.0465, discriminator training loss: 0.0182, validation loss: 0.1063
2024-05-24 23:38:16 [INFO]: Epoch 078 - generator training loss: 0.0467, discriminator training loss: 0.0178, validation loss: 0.1062
2024-05-24 23:38:20 [INFO]: Epoch 079 - generator training loss: 0.0454, discriminator training loss: 0.0178, validation loss: 0.1058
2024-05-24 23:38:24 [INFO]: Epoch 080 - generator training loss: 0.0454, discriminator training loss: 0.0174, validation loss: 0.1057
2024-05-24 23:38:28 [INFO]: Epoch 081 - generator training loss: 0.0465, discriminator training loss: 0.0173, validation loss: 0.1055
2024-05-24 23:38:32 [INFO]: Epoch 082 - generator training loss: 0.0453, discriminator training loss: 0.0174, validation loss: 0.1059
2024-05-24 23:38:36 [INFO]: Epoch 083 - generator training loss: 0.0454, discriminator training loss: 0.0172, validation loss: 0.1057
2024-05-24 23:38:40 [INFO]: Epoch 084 - generator training loss: 0.0445, discriminator training loss: 0.0170, validation loss: 0.1057
2024-05-24 23:38:44 [INFO]: Epoch 085 - generator training loss: 0.0443, discriminator training loss: 0.0168, validation loss: 0.1057
2024-05-24 23:38:48 [INFO]: Epoch 086 - generator training loss: 0.0446, discriminator training loss: 0.0167, validation loss: 0.1062
2024-05-24 23:38:52 [INFO]: Epoch 087 - generator training loss: 0.0440, discriminator training loss: 0.0166, validation loss: 0.1059
2024-05-24 23:38:56 [INFO]: Epoch 088 - generator training loss: 0.0445, discriminator training loss: 0.0166, validation loss: 0.1051
2024-05-24 23:39:00 [INFO]: Epoch 089 - generator training loss: 0.0434, discriminator training loss: 0.0164, validation loss: 0.1051
2024-05-24 23:39:04 [INFO]: Epoch 090 - generator training loss: 0.0432, discriminator training loss: 0.0164, validation loss: 0.1051
2024-05-24 23:39:08 [INFO]: Epoch 091 - generator training loss: 0.0429, discriminator training loss: 0.0163, validation loss: 0.1046
2024-05-24 23:39:12 [INFO]: Epoch 092 - generator training loss: 0.0426, discriminator training loss: 0.0159, validation loss: 0.1050
2024-05-24 23:39:15 [INFO]: Epoch 093 - generator training loss: 0.0427, discriminator training loss: 0.0160, validation loss: 0.1053
2024-05-24 23:39:19 [INFO]: Epoch 094 - generator training loss: 0.0430, discriminator training loss: 0.0159, validation loss: 0.1046
2024-05-24 23:39:23 [INFO]: Epoch 095 - generator training loss: 0.0424, discriminator training loss: 0.0159, validation loss: 0.1043
2024-05-24 23:39:27 [INFO]: Epoch 096 - generator training loss: 0.0417, discriminator training loss: 0.0156, validation loss: 0.1046
2024-05-24 23:39:31 [INFO]: Epoch 097 - generator training loss: 0.0417, discriminator training loss: 0.0156, validation loss: 0.1047
2024-05-24 23:39:35 [INFO]: Epoch 098 - generator training loss: 0.0415, discriminator training loss: 0.0154, validation loss: 0.1050
2024-05-24 23:39:39 [INFO]: Epoch 099 - generator training loss: 0.0435, discriminator training loss: 0.0155, validation loss: 0.1045
2024-05-24 23:39:43 [INFO]: Epoch 100 - generator training loss: 0.0422, discriminator training loss: 0.0154, validation loss: 0.1045
2024-05-24 23:39:47 [INFO]: Epoch 101 - generator training loss: 0.0412, discriminator training loss: 0.0155, validation loss: 0.1058
2024-05-24 23:39:51 [INFO]: Epoch 102 - generator training loss: 0.0412, discriminator training loss: 0.0152, validation loss: 0.1040
2024-05-24 23:39:55 [INFO]: Epoch 103 - generator training loss: 0.0413, discriminator training loss: 0.0152, validation loss: 0.1039
2024-05-24 23:39:59 [INFO]: Epoch 104 - generator training loss: 0.0408, discriminator training loss: 0.0149, validation loss: 0.1042
2024-05-24 23:40:03 [INFO]: Epoch 105 - generator training loss: 0.0395, discriminator training loss: 0.0151, validation loss: 0.1041
2024-05-24 23:40:07 [INFO]: Epoch 106 - generator training loss: 0.0401, discriminator training loss: 0.0149, validation loss: 0.1044
2024-05-24 23:40:11 [INFO]: Epoch 107 - generator training loss: 0.0397, discriminator training loss: 0.0149, validation loss: 0.1041
2024-05-24 23:40:15 [INFO]: Epoch 108 - generator training loss: 0.0394, discriminator training loss: 0.0147, validation loss: 0.1041
2024-05-24 23:40:19 [INFO]: Epoch 109 - generator training loss: 0.0393, discriminator training loss: 0.0149, validation loss: 0.1040
2024-05-24 23:40:23 [INFO]: Epoch 110 - generator training loss: 0.0386, discriminator training loss: 0.0150, validation loss: 0.1051
2024-05-24 23:40:27 [INFO]: Epoch 111 - generator training loss: 0.0387, discriminator training loss: 0.0146, validation loss: 0.1044
2024-05-24 23:40:31 [INFO]: Epoch 112 - generator training loss: 0.0389, discriminator training loss: 0.0144, validation loss: 0.1041
2024-05-24 23:40:35 [INFO]: Epoch 113 - generator training loss: 0.0385, discriminator training loss: 0.0144, validation loss: 0.1045
2024-05-24 23:40:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:40:35 [INFO]: Finished training. The best model is from epoch#103.
2024-05-24 23:40:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/USGAN_air_quality/20240524_T233306/USGAN.pypots
2024-05-24 23:40:35 [INFO]: US-GAN on Air-Quality: MAE=0.1587, MSE=0.1022
2024-05-24 23:40:35 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/USGAN_air_quality/imputation.pkl
2024-05-24 23:40:35 [INFO]: Using the given device: cuda:0
2024-05-24 23:40:35 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/BRITS_air_quality/20240524_T234035
2024-05-24 23:40:35 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/BRITS_air_quality/20240524_T234035/tensorboard
2024-05-24 23:40:35 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-24 23:40:39 [INFO]: Epoch 001 - training loss: 1.3828, validation loss: 0.9062
2024-05-24 23:40:42 [INFO]: Epoch 002 - training loss: 1.1130, validation loss: 0.6822
2024-05-24 23:40:44 [INFO]: Epoch 003 - training loss: 0.9298, validation loss: 0.5799
2024-05-24 23:40:47 [INFO]: Epoch 004 - training loss: 0.8259, validation loss: 0.5167
2024-05-24 23:40:50 [INFO]: Epoch 005 - training loss: 0.7522, validation loss: 0.4720
2024-05-24 23:40:52 [INFO]: Epoch 006 - training loss: 0.6976, validation loss: 0.4369
2024-05-24 23:40:55 [INFO]: Epoch 007 - training loss: 0.6534, validation loss: 0.4068
2024-05-24 23:40:58 [INFO]: Epoch 008 - training loss: 0.6219, validation loss: 0.3844
2024-05-24 23:41:01 [INFO]: Epoch 009 - training loss: 0.5936, validation loss: 0.3652
2024-05-24 23:41:03 [INFO]: Epoch 010 - training loss: 0.5739, validation loss: 0.3492
2024-05-24 23:41:06 [INFO]: Epoch 011 - training loss: 0.5584, validation loss: 0.3355
2024-05-24 23:41:09 [INFO]: Epoch 012 - training loss: 0.5407, validation loss: 0.3240
2024-05-24 23:41:11 [INFO]: Epoch 013 - training loss: 0.5273, validation loss: 0.3144
2024-05-24 23:41:14 [INFO]: Epoch 014 - training loss: 0.5165, validation loss: 0.3057
2024-05-24 23:41:17 [INFO]: Epoch 015 - training loss: 0.5053, validation loss: 0.2977
2024-05-24 23:41:20 [INFO]: Epoch 016 - training loss: 0.4959, validation loss: 0.2908
2024-05-24 23:41:22 [INFO]: Epoch 017 - training loss: 0.4874, validation loss: 0.2851
2024-05-24 23:41:25 [INFO]: Epoch 018 - training loss: 0.4789, validation loss: 0.2784
2024-05-24 23:41:28 [INFO]: Epoch 019 - training loss: 0.4724, validation loss: 0.2736
2024-05-24 23:41:30 [INFO]: Epoch 020 - training loss: 0.4637, validation loss: 0.2685
2024-05-24 23:41:33 [INFO]: Epoch 021 - training loss: 0.4572, validation loss: 0.2639
2024-05-24 23:41:36 [INFO]: Epoch 022 - training loss: 0.4501, validation loss: 0.2594
2024-05-24 23:41:39 [INFO]: Epoch 023 - training loss: 0.4451, validation loss: 0.2550
2024-05-24 23:41:41 [INFO]: Epoch 024 - training loss: 0.4372, validation loss: 0.2502
2024-05-24 23:41:44 [INFO]: Epoch 025 - training loss: 0.4315, validation loss: 0.2463
2024-05-24 23:41:47 [INFO]: Epoch 026 - training loss: 0.4264, validation loss: 0.2429
2024-05-24 23:41:49 [INFO]: Epoch 027 - training loss: 0.4212, validation loss: 0.2389
2024-05-24 23:41:52 [INFO]: Epoch 028 - training loss: 0.4159, validation loss: 0.2353
2024-05-24 23:41:55 [INFO]: Epoch 029 - training loss: 0.4125, validation loss: 0.2318
2024-05-24 23:41:58 [INFO]: Epoch 030 - training loss: 0.4068, validation loss: 0.2269
2024-05-24 23:42:00 [INFO]: Epoch 031 - training loss: 0.4023, validation loss: 0.2238
2024-05-24 23:42:03 [INFO]: Epoch 032 - training loss: 0.3971, validation loss: 0.2206
2024-05-24 23:42:06 [INFO]: Epoch 033 - training loss: 0.3931, validation loss: 0.2174
2024-05-24 23:42:08 [INFO]: Epoch 034 - training loss: 0.3895, validation loss: 0.2138
2024-05-24 23:42:11 [INFO]: Epoch 035 - training loss: 0.3857, validation loss: 0.2110
2024-05-24 23:42:14 [INFO]: Epoch 036 - training loss: 0.3823, validation loss: 0.2079
2024-05-24 23:42:17 [INFO]: Epoch 037 - training loss: 0.3787, validation loss: 0.2048
2024-05-24 23:42:19 [INFO]: Epoch 038 - training loss: 0.3743, validation loss: 0.2012
2024-05-24 23:42:22 [INFO]: Epoch 039 - training loss: 0.3719, validation loss: 0.1980
2024-05-24 23:42:25 [INFO]: Epoch 040 - training loss: 0.3692, validation loss: 0.1955
2024-05-24 23:42:28 [INFO]: Epoch 041 - training loss: 0.3653, validation loss: 0.1916
2024-05-24 23:42:31 [INFO]: Epoch 042 - training loss: 0.3618, validation loss: 0.1893
2024-05-24 23:42:33 [INFO]: Epoch 043 - training loss: 0.3591, validation loss: 0.1866
2024-05-24 23:42:36 [INFO]: Epoch 044 - training loss: 0.3561, validation loss: 0.1841
2024-05-24 23:42:39 [INFO]: Epoch 045 - training loss: 0.3534, validation loss: 0.1822
2024-05-24 23:42:42 [INFO]: Epoch 046 - training loss: 0.3511, validation loss: 0.1799
2024-05-24 23:42:44 [INFO]: Epoch 047 - training loss: 0.3480, validation loss: 0.1773
2024-05-24 23:42:47 [INFO]: Epoch 048 - training loss: 0.3450, validation loss: 0.1756
2024-05-24 23:42:50 [INFO]: Epoch 049 - training loss: 0.3429, validation loss: 0.1739
2024-05-24 23:42:53 [INFO]: Epoch 050 - training loss: 0.3410, validation loss: 0.1719
2024-05-24 23:42:55 [INFO]: Epoch 051 - training loss: 0.3389, validation loss: 0.1700
2024-05-24 23:42:58 [INFO]: Epoch 052 - training loss: 0.3358, validation loss: 0.1689
2024-05-24 23:43:01 [INFO]: Epoch 053 - training loss: 0.3340, validation loss: 0.1670
2024-05-24 23:43:03 [INFO]: Epoch 054 - training loss: 0.3323, validation loss: 0.1651
2024-05-24 23:43:06 [INFO]: Epoch 055 - training loss: 0.3294, validation loss: 0.1639
2024-05-24 23:43:09 [INFO]: Epoch 056 - training loss: 0.3284, validation loss: 0.1627
2024-05-24 23:43:12 [INFO]: Epoch 057 - training loss: 0.3265, validation loss: 0.1613
2024-05-24 23:43:14 [INFO]: Epoch 058 - training loss: 0.3252, validation loss: 0.1600
2024-05-24 23:43:17 [INFO]: Epoch 059 - training loss: 0.3226, validation loss: 0.1588
2024-05-24 23:43:20 [INFO]: Epoch 060 - training loss: 0.3207, validation loss: 0.1575
2024-05-24 23:43:22 [INFO]: Epoch 061 - training loss: 0.3189, validation loss: 0.1564
2024-05-24 23:43:25 [INFO]: Epoch 062 - training loss: 0.3171, validation loss: 0.1553
2024-05-24 23:43:28 [INFO]: Epoch 063 - training loss: 0.3167, validation loss: 0.1546
2024-05-24 23:43:31 [INFO]: Epoch 064 - training loss: 0.3148, validation loss: 0.1529
2024-05-24 23:43:33 [INFO]: Epoch 065 - training loss: 0.3137, validation loss: 0.1523
2024-05-24 23:43:36 [INFO]: Epoch 066 - training loss: 0.3118, validation loss: 0.1511
2024-05-24 23:43:39 [INFO]: Epoch 067 - training loss: 0.3106, validation loss: 0.1502
2024-05-24 23:43:42 [INFO]: Epoch 068 - training loss: 0.3088, validation loss: 0.1491
2024-05-24 23:43:44 [INFO]: Epoch 069 - training loss: 0.3072, validation loss: 0.1484
2024-05-24 23:43:47 [INFO]: Epoch 070 - training loss: 0.3063, validation loss: 0.1477
2024-05-24 23:43:50 [INFO]: Epoch 071 - training loss: 0.3048, validation loss: 0.1468
2024-05-24 23:43:52 [INFO]: Epoch 072 - training loss: 0.3037, validation loss: 0.1457
2024-05-24 23:43:55 [INFO]: Epoch 073 - training loss: 0.3025, validation loss: 0.1453
2024-05-24 23:43:58 [INFO]: Epoch 074 - training loss: 0.3015, validation loss: 0.1447
2024-05-24 23:44:01 [INFO]: Epoch 075 - training loss: 0.3015, validation loss: 0.1438
2024-05-24 23:44:03 [INFO]: Epoch 076 - training loss: 0.2994, validation loss: 0.1433
2024-05-24 23:44:06 [INFO]: Epoch 077 - training loss: 0.2981, validation loss: 0.1425
2024-05-24 23:44:09 [INFO]: Epoch 078 - training loss: 0.2976, validation loss: 0.1419
2024-05-24 23:44:11 [INFO]: Epoch 079 - training loss: 0.2965, validation loss: 0.1411
2024-05-24 23:44:14 [INFO]: Epoch 080 - training loss: 0.2960, validation loss: 0.1403
2024-05-24 23:44:17 [INFO]: Epoch 081 - training loss: 0.2945, validation loss: 0.1399
2024-05-24 23:44:20 [INFO]: Epoch 082 - training loss: 0.2937, validation loss: 0.1392
2024-05-24 23:44:22 [INFO]: Epoch 083 - training loss: 0.2927, validation loss: 0.1387
2024-05-24 23:44:25 [INFO]: Epoch 084 - training loss: 0.2918, validation loss: 0.1378
2024-05-24 23:44:28 [INFO]: Epoch 085 - training loss: 0.2910, validation loss: 0.1372
2024-05-24 23:44:30 [INFO]: Epoch 086 - training loss: 0.2899, validation loss: 0.1366
2024-05-24 23:44:33 [INFO]: Epoch 087 - training loss: 0.2894, validation loss: 0.1361
2024-05-24 23:44:36 [INFO]: Epoch 088 - training loss: 0.2889, validation loss: 0.1354
2024-05-24 23:44:39 [INFO]: Epoch 089 - training loss: 0.2875, validation loss: 0.1352
2024-05-24 23:44:41 [INFO]: Epoch 090 - training loss: 0.2868, validation loss: 0.1346
2024-05-24 23:44:44 [INFO]: Epoch 091 - training loss: 0.2867, validation loss: 0.1341
2024-05-24 23:44:47 [INFO]: Epoch 092 - training loss: 0.2856, validation loss: 0.1335
2024-05-24 23:44:49 [INFO]: Epoch 093 - training loss: 0.2846, validation loss: 0.1329
2024-05-24 23:44:52 [INFO]: Epoch 094 - training loss: 0.2845, validation loss: 0.1327
2024-05-24 23:44:55 [INFO]: Epoch 095 - training loss: 0.2833, validation loss: 0.1319
2024-05-24 23:44:58 [INFO]: Epoch 096 - training loss: 0.2828, validation loss: 0.1319
2024-05-24 23:45:00 [INFO]: Epoch 097 - training loss: 0.2824, validation loss: 0.1310
2024-05-24 23:45:03 [INFO]: Epoch 098 - training loss: 0.2820, validation loss: 0.1308
2024-05-24 23:45:06 [INFO]: Epoch 099 - training loss: 0.2810, validation loss: 0.1304
2024-05-24 23:45:09 [INFO]: Epoch 100 - training loss: 0.2803, validation loss: 0.1299
2024-05-24 23:45:11 [INFO]: Epoch 101 - training loss: 0.2787, validation loss: 0.1296
2024-05-24 23:45:14 [INFO]: Epoch 102 - training loss: 0.2788, validation loss: 0.1290
2024-05-24 23:45:17 [INFO]: Epoch 103 - training loss: 0.2779, validation loss: 0.1287
2024-05-24 23:45:19 [INFO]: Epoch 104 - training loss: 0.2777, validation loss: 0.1285
2024-05-24 23:45:22 [INFO]: Epoch 105 - training loss: 0.2774, validation loss: 0.1278
2024-05-24 23:45:25 [INFO]: Epoch 106 - training loss: 0.2762, validation loss: 0.1275
2024-05-24 23:45:28 [INFO]: Epoch 107 - training loss: 0.2759, validation loss: 0.1270
2024-05-24 23:45:30 [INFO]: Epoch 108 - training loss: 0.2746, validation loss: 0.1267
2024-05-24 23:45:33 [INFO]: Epoch 109 - training loss: 0.2746, validation loss: 0.1263
2024-05-24 23:45:36 [INFO]: Epoch 110 - training loss: 0.2741, validation loss: 0.1261
2024-05-24 23:45:38 [INFO]: Epoch 111 - training loss: 0.2736, validation loss: 0.1257
2024-05-24 23:45:41 [INFO]: Epoch 112 - training loss: 0.2734, validation loss: 0.1252
2024-05-24 23:45:44 [INFO]: Epoch 113 - training loss: 0.2724, validation loss: 0.1248
2024-05-24 23:45:47 [INFO]: Epoch 114 - training loss: 0.2725, validation loss: 0.1245
2024-05-24 23:45:49 [INFO]: Epoch 115 - training loss: 0.2712, validation loss: 0.1243
2024-05-24 23:45:52 [INFO]: Epoch 116 - training loss: 0.2712, validation loss: 0.1239
2024-05-24 23:45:55 [INFO]: Epoch 117 - training loss: 0.2704, validation loss: 0.1235
2024-05-24 23:45:58 [INFO]: Epoch 118 - training loss: 0.2698, validation loss: 0.1231
2024-05-24 23:46:00 [INFO]: Epoch 119 - training loss: 0.2690, validation loss: 0.1227
2024-05-24 23:46:03 [INFO]: Epoch 120 - training loss: 0.2693, validation loss: 0.1224
2024-05-24 23:46:06 [INFO]: Epoch 121 - training loss: 0.2683, validation loss: 0.1221
2024-05-24 23:46:08 [INFO]: Epoch 122 - training loss: 0.2678, validation loss: 0.1219
2024-05-24 23:46:11 [INFO]: Epoch 123 - training loss: 0.2668, validation loss: 0.1216
2024-05-24 23:46:14 [INFO]: Epoch 124 - training loss: 0.2673, validation loss: 0.1211
2024-05-24 23:46:17 [INFO]: Epoch 125 - training loss: 0.2665, validation loss: 0.1208
2024-05-24 23:46:19 [INFO]: Epoch 126 - training loss: 0.2662, validation loss: 0.1209
2024-05-24 23:46:22 [INFO]: Epoch 127 - training loss: 0.2660, validation loss: 0.1202
2024-05-24 23:46:25 [INFO]: Epoch 128 - training loss: 0.2647, validation loss: 0.1200
2024-05-24 23:46:27 [INFO]: Epoch 129 - training loss: 0.2649, validation loss: 0.1195
2024-05-24 23:46:30 [INFO]: Epoch 130 - training loss: 0.2645, validation loss: 0.1192
2024-05-24 23:46:33 [INFO]: Epoch 131 - training loss: 0.2640, validation loss: 0.1191
2024-05-24 23:46:36 [INFO]: Epoch 132 - training loss: 0.2638, validation loss: 0.1187
2024-05-24 23:46:38 [INFO]: Epoch 133 - training loss: 0.2628, validation loss: 0.1185
2024-05-24 23:46:41 [INFO]: Epoch 134 - training loss: 0.2631, validation loss: 0.1181
2024-05-24 23:46:44 [INFO]: Epoch 135 - training loss: 0.2628, validation loss: 0.1182
2024-05-24 23:46:46 [INFO]: Epoch 136 - training loss: 0.2620, validation loss: 0.1179
2024-05-24 23:46:49 [INFO]: Epoch 137 - training loss: 0.2617, validation loss: 0.1174
2024-05-24 23:46:52 [INFO]: Epoch 138 - training loss: 0.2613, validation loss: 0.1171
2024-05-24 23:46:55 [INFO]: Epoch 139 - training loss: 0.2608, validation loss: 0.1166
2024-05-24 23:46:57 [INFO]: Epoch 140 - training loss: 0.2602, validation loss: 0.1165
2024-05-24 23:47:00 [INFO]: Epoch 141 - training loss: 0.2599, validation loss: 0.1163
2024-05-24 23:47:03 [INFO]: Epoch 142 - training loss: 0.2600, validation loss: 0.1162
2024-05-24 23:47:05 [INFO]: Epoch 143 - training loss: 0.2593, validation loss: 0.1157
2024-05-24 23:47:08 [INFO]: Epoch 144 - training loss: 0.2593, validation loss: 0.1156
2024-05-24 23:47:11 [INFO]: Epoch 145 - training loss: 0.2586, validation loss: 0.1154
2024-05-24 23:47:14 [INFO]: Epoch 146 - training loss: 0.2578, validation loss: 0.1150
2024-05-24 23:47:16 [INFO]: Epoch 147 - training loss: 0.2579, validation loss: 0.1147
2024-05-24 23:47:19 [INFO]: Epoch 148 - training loss: 0.2572, validation loss: 0.1147
2024-05-24 23:47:22 [INFO]: Epoch 149 - training loss: 0.2575, validation loss: 0.1146
2024-05-24 23:47:24 [INFO]: Epoch 150 - training loss: 0.2566, validation loss: 0.1141
2024-05-24 23:47:27 [INFO]: Epoch 151 - training loss: 0.2566, validation loss: 0.1138
2024-05-24 23:47:30 [INFO]: Epoch 152 - training loss: 0.2565, validation loss: 0.1138
2024-05-24 23:47:33 [INFO]: Epoch 153 - training loss: 0.2557, validation loss: 0.1133
2024-05-24 23:47:35 [INFO]: Epoch 154 - training loss: 0.2559, validation loss: 0.1133
2024-05-24 23:47:38 [INFO]: Epoch 155 - training loss: 0.2555, validation loss: 0.1131
2024-05-24 23:47:41 [INFO]: Epoch 156 - training loss: 0.2548, validation loss: 0.1129
2024-05-24 23:47:44 [INFO]: Epoch 157 - training loss: 0.2547, validation loss: 0.1126
2024-05-24 23:47:46 [INFO]: Epoch 158 - training loss: 0.2542, validation loss: 0.1122
2024-05-24 23:47:49 [INFO]: Epoch 159 - training loss: 0.2539, validation loss: 0.1121
2024-05-24 23:47:52 [INFO]: Epoch 160 - training loss: 0.2541, validation loss: 0.1120
2024-05-24 23:47:54 [INFO]: Epoch 161 - training loss: 0.2537, validation loss: 0.1118
2024-05-24 23:47:57 [INFO]: Epoch 162 - training loss: 0.2537, validation loss: 0.1116
2024-05-24 23:48:00 [INFO]: Epoch 163 - training loss: 0.2533, validation loss: 0.1113
2024-05-24 23:48:03 [INFO]: Epoch 164 - training loss: 0.2526, validation loss: 0.1112
2024-05-24 23:48:05 [INFO]: Epoch 165 - training loss: 0.2522, validation loss: 0.1112
2024-05-24 23:48:08 [INFO]: Epoch 166 - training loss: 0.2519, validation loss: 0.1107
2024-05-24 23:48:11 [INFO]: Epoch 167 - training loss: 0.2519, validation loss: 0.1107
2024-05-24 23:48:14 [INFO]: Epoch 168 - training loss: 0.2516, validation loss: 0.1105
2024-05-24 23:48:16 [INFO]: Epoch 169 - training loss: 0.2511, validation loss: 0.1102
2024-05-24 23:48:19 [INFO]: Epoch 170 - training loss: 0.2517, validation loss: 0.1100
2024-05-24 23:48:22 [INFO]: Epoch 171 - training loss: 0.2512, validation loss: 0.1097
2024-05-24 23:48:24 [INFO]: Epoch 172 - training loss: 0.2503, validation loss: 0.1097
2024-05-24 23:48:27 [INFO]: Epoch 173 - training loss: 0.2500, validation loss: 0.1097
2024-05-24 23:48:30 [INFO]: Epoch 174 - training loss: 0.2496, validation loss: 0.1093
2024-05-24 23:48:33 [INFO]: Epoch 175 - training loss: 0.2497, validation loss: 0.1093
2024-05-24 23:48:35 [INFO]: Epoch 176 - training loss: 0.2496, validation loss: 0.1091
2024-05-24 23:48:38 [INFO]: Epoch 177 - training loss: 0.2494, validation loss: 0.1088
2024-05-24 23:48:41 [INFO]: Epoch 178 - training loss: 0.2493, validation loss: 0.1088
2024-05-24 23:48:43 [INFO]: Epoch 179 - training loss: 0.2483, validation loss: 0.1087
2024-05-24 23:48:46 [INFO]: Epoch 180 - training loss: 0.2485, validation loss: 0.1087
2024-05-24 23:48:49 [INFO]: Epoch 181 - training loss: 0.2482, validation loss: 0.1084
2024-05-24 23:48:52 [INFO]: Epoch 182 - training loss: 0.2481, validation loss: 0.1081
2024-05-24 23:48:54 [INFO]: Epoch 183 - training loss: 0.2478, validation loss: 0.1081
2024-05-24 23:48:57 [INFO]: Epoch 184 - training loss: 0.2474, validation loss: 0.1079
2024-05-24 23:49:00 [INFO]: Epoch 185 - training loss: 0.2472, validation loss: 0.1078
2024-05-24 23:49:02 [INFO]: Epoch 186 - training loss: 0.2465, validation loss: 0.1076
2024-05-24 23:49:05 [INFO]: Epoch 187 - training loss: 0.2467, validation loss: 0.1075
2024-05-24 23:49:08 [INFO]: Epoch 188 - training loss: 0.2465, validation loss: 0.1074
2024-05-24 23:49:11 [INFO]: Epoch 189 - training loss: 0.2460, validation loss: 0.1068
2024-05-24 23:49:13 [INFO]: Epoch 190 - training loss: 0.2462, validation loss: 0.1072
2024-05-24 23:49:16 [INFO]: Epoch 191 - training loss: 0.2459, validation loss: 0.1071
2024-05-24 23:49:19 [INFO]: Epoch 192 - training loss: 0.2460, validation loss: 0.1068
2024-05-24 23:49:21 [INFO]: Epoch 193 - training loss: 0.2458, validation loss: 0.1067
2024-05-24 23:49:24 [INFO]: Epoch 194 - training loss: 0.2456, validation loss: 0.1067
2024-05-24 23:49:27 [INFO]: Epoch 195 - training loss: 0.2456, validation loss: 0.1064
2024-05-24 23:49:30 [INFO]: Epoch 196 - training loss: 0.2453, validation loss: 0.1063
2024-05-24 23:49:32 [INFO]: Epoch 197 - training loss: 0.2440, validation loss: 0.1062
2024-05-24 23:49:35 [INFO]: Epoch 198 - training loss: 0.2443, validation loss: 0.1063
2024-05-24 23:49:38 [INFO]: Epoch 199 - training loss: 0.2444, validation loss: 0.1059
2024-05-24 23:49:41 [INFO]: Epoch 200 - training loss: 0.2438, validation loss: 0.1061
2024-05-24 23:49:43 [INFO]: Epoch 201 - training loss: 0.2439, validation loss: 0.1057
2024-05-24 23:49:46 [INFO]: Epoch 202 - training loss: 0.2439, validation loss: 0.1057
2024-05-24 23:49:49 [INFO]: Epoch 203 - training loss: 0.2436, validation loss: 0.1056
2024-05-24 23:49:51 [INFO]: Epoch 204 - training loss: 0.2433, validation loss: 0.1055
2024-05-24 23:49:54 [INFO]: Epoch 205 - training loss: 0.2431, validation loss: 0.1052
2024-05-24 23:49:57 [INFO]: Epoch 206 - training loss: 0.2429, validation loss: 0.1053
2024-05-24 23:50:00 [INFO]: Epoch 207 - training loss: 0.2431, validation loss: 0.1051
2024-05-24 23:50:02 [INFO]: Epoch 208 - training loss: 0.2427, validation loss: 0.1049
2024-05-24 23:50:05 [INFO]: Epoch 209 - training loss: 0.2428, validation loss: 0.1047
2024-05-24 23:50:08 [INFO]: Epoch 210 - training loss: 0.2419, validation loss: 0.1047
2024-05-24 23:50:10 [INFO]: Epoch 211 - training loss: 0.2420, validation loss: 0.1047
2024-05-24 23:50:13 [INFO]: Epoch 212 - training loss: 0.2423, validation loss: 0.1046
2024-05-24 23:50:16 [INFO]: Epoch 213 - training loss: 0.2418, validation loss: 0.1044
2024-05-24 23:50:19 [INFO]: Epoch 214 - training loss: 0.2416, validation loss: 0.1043
2024-05-24 23:50:21 [INFO]: Epoch 215 - training loss: 0.2411, validation loss: 0.1043
2024-05-24 23:50:24 [INFO]: Epoch 216 - training loss: 0.2411, validation loss: 0.1042
2024-05-24 23:50:27 [INFO]: Epoch 217 - training loss: 0.2410, validation loss: 0.1041
2024-05-24 23:50:29 [INFO]: Epoch 218 - training loss: 0.2406, validation loss: 0.1039
2024-05-24 23:50:32 [INFO]: Epoch 219 - training loss: 0.2403, validation loss: 0.1040
2024-05-24 23:50:35 [INFO]: Epoch 220 - training loss: 0.2408, validation loss: 0.1040
2024-05-24 23:50:38 [INFO]: Epoch 221 - training loss: 0.2403, validation loss: 0.1037
2024-05-24 23:50:40 [INFO]: Epoch 222 - training loss: 0.2403, validation loss: 0.1035
2024-05-24 23:50:43 [INFO]: Epoch 223 - training loss: 0.2395, validation loss: 0.1036
2024-05-24 23:50:46 [INFO]: Epoch 224 - training loss: 0.2399, validation loss: 0.1033
2024-05-24 23:50:49 [INFO]: Epoch 225 - training loss: 0.2394, validation loss: 0.1035
2024-05-24 23:50:51 [INFO]: Epoch 226 - training loss: 0.2392, validation loss: 0.1035
2024-05-24 23:50:54 [INFO]: Epoch 227 - training loss: 0.2393, validation loss: 0.1033
2024-05-24 23:50:57 [INFO]: Epoch 228 - training loss: 0.2391, validation loss: 0.1032
2024-05-24 23:50:59 [INFO]: Epoch 229 - training loss: 0.2394, validation loss: 0.1033
2024-05-24 23:51:02 [INFO]: Epoch 230 - training loss: 0.2386, validation loss: 0.1031
2024-05-24 23:51:05 [INFO]: Epoch 231 - training loss: 0.2381, validation loss: 0.1030
2024-05-24 23:51:08 [INFO]: Epoch 232 - training loss: 0.2387, validation loss: 0.1028
2024-05-24 23:51:10 [INFO]: Epoch 233 - training loss: 0.2384, validation loss: 0.1028
2024-05-24 23:51:13 [INFO]: Epoch 234 - training loss: 0.2387, validation loss: 0.1029
2024-05-24 23:51:16 [INFO]: Epoch 235 - training loss: 0.2382, validation loss: 0.1027
2024-05-24 23:51:18 [INFO]: Epoch 236 - training loss: 0.2381, validation loss: 0.1026
2024-05-24 23:51:21 [INFO]: Epoch 237 - training loss: 0.2380, validation loss: 0.1026
2024-05-24 23:51:24 [INFO]: Epoch 238 - training loss: 0.2376, validation loss: 0.1027
2024-05-24 23:51:27 [INFO]: Epoch 239 - training loss: 0.2373, validation loss: 0.1023
2024-05-24 23:51:29 [INFO]: Epoch 240 - training loss: 0.2370, validation loss: 0.1023
2024-05-24 23:51:32 [INFO]: Epoch 241 - training loss: 0.2377, validation loss: 0.1022
2024-05-24 23:51:35 [INFO]: Epoch 242 - training loss: 0.2368, validation loss: 0.1022
2024-05-24 23:51:38 [INFO]: Epoch 243 - training loss: 0.2365, validation loss: 0.1021
2024-05-24 23:51:40 [INFO]: Epoch 244 - training loss: 0.2365, validation loss: 0.1023
2024-05-24 23:51:43 [INFO]: Epoch 245 - training loss: 0.2363, validation loss: 0.1021
2024-05-24 23:51:46 [INFO]: Epoch 246 - training loss: 0.2361, validation loss: 0.1021
2024-05-24 23:51:48 [INFO]: Epoch 247 - training loss: 0.2362, validation loss: 0.1020
2024-05-24 23:51:51 [INFO]: Epoch 248 - training loss: 0.2354, validation loss: 0.1019
2024-05-24 23:51:54 [INFO]: Epoch 249 - training loss: 0.2356, validation loss: 0.1018
2024-05-24 23:51:57 [INFO]: Epoch 250 - training loss: 0.2355, validation loss: 0.1018
2024-05-24 23:51:59 [INFO]: Epoch 251 - training loss: 0.2351, validation loss: 0.1017
2024-05-24 23:52:02 [INFO]: Epoch 252 - training loss: 0.2350, validation loss: 0.1016
2024-05-24 23:52:05 [INFO]: Epoch 253 - training loss: 0.2350, validation loss: 0.1016
2024-05-24 23:52:07 [INFO]: Epoch 254 - training loss: 0.2348, validation loss: 0.1014
2024-05-24 23:52:10 [INFO]: Epoch 255 - training loss: 0.2352, validation loss: 0.1016
2024-05-24 23:52:13 [INFO]: Epoch 256 - training loss: 0.2347, validation loss: 0.1014
2024-05-24 23:52:16 [INFO]: Epoch 257 - training loss: 0.2346, validation loss: 0.1012
2024-05-24 23:52:18 [INFO]: Epoch 258 - training loss: 0.2345, validation loss: 0.1013
2024-05-24 23:52:21 [INFO]: Epoch 259 - training loss: 0.2340, validation loss: 0.1014
2024-05-24 23:52:24 [INFO]: Epoch 260 - training loss: 0.2342, validation loss: 0.1011
2024-05-24 23:52:26 [INFO]: Epoch 261 - training loss: 0.2337, validation loss: 0.1011
2024-05-24 23:52:29 [INFO]: Epoch 262 - training loss: 0.2338, validation loss: 0.1012
2024-05-24 23:52:32 [INFO]: Epoch 263 - training loss: 0.2337, validation loss: 0.1013
2024-05-24 23:52:35 [INFO]: Epoch 264 - training loss: 0.2335, validation loss: 0.1008
2024-05-24 23:52:37 [INFO]: Epoch 265 - training loss: 0.2334, validation loss: 0.1011
2024-05-24 23:52:40 [INFO]: Epoch 266 - training loss: 0.2339, validation loss: 0.1008
2024-05-24 23:52:43 [INFO]: Epoch 267 - training loss: 0.2328, validation loss: 0.1009
2024-05-24 23:52:45 [INFO]: Epoch 268 - training loss: 0.2332, validation loss: 0.1007
2024-05-24 23:52:48 [INFO]: Epoch 269 - training loss: 0.2334, validation loss: 0.1008
2024-05-24 23:52:51 [INFO]: Epoch 270 - training loss: 0.2329, validation loss: 0.1009
2024-05-24 23:52:54 [INFO]: Epoch 271 - training loss: 0.2327, validation loss: 0.1006
2024-05-24 23:52:56 [INFO]: Epoch 272 - training loss: 0.2326, validation loss: 0.1004
2024-05-24 23:52:59 [INFO]: Epoch 273 - training loss: 0.2323, validation loss: 0.1008
2024-05-24 23:53:02 [INFO]: Epoch 274 - training loss: 0.2320, validation loss: 0.1007
2024-05-24 23:53:04 [INFO]: Epoch 275 - training loss: 0.2323, validation loss: 0.1006
2024-05-24 23:53:07 [INFO]: Epoch 276 - training loss: 0.2327, validation loss: 0.1004
2024-05-24 23:53:10 [INFO]: Epoch 277 - training loss: 0.2323, validation loss: 0.1003
2024-05-24 23:53:13 [INFO]: Epoch 278 - training loss: 0.2322, validation loss: 0.1002
2024-05-24 23:53:15 [INFO]: Epoch 279 - training loss: 0.2317, validation loss: 0.1003
2024-05-24 23:53:18 [INFO]: Epoch 280 - training loss: 0.2319, validation loss: 0.1003
2024-05-24 23:53:21 [INFO]: Epoch 281 - training loss: 0.2320, validation loss: 0.1002
2024-05-24 23:53:23 [INFO]: Epoch 282 - training loss: 0.2317, validation loss: 0.1003
2024-05-24 23:53:26 [INFO]: Epoch 283 - training loss: 0.2312, validation loss: 0.1001
2024-05-24 23:53:29 [INFO]: Epoch 284 - training loss: 0.2310, validation loss: 0.1004
2024-05-24 23:53:32 [INFO]: Epoch 285 - training loss: 0.2312, validation loss: 0.1002
2024-05-24 23:53:34 [INFO]: Epoch 286 - training loss: 0.2307, validation loss: 0.1002
2024-05-24 23:53:37 [INFO]: Epoch 287 - training loss: 0.2311, validation loss: 0.1001
2024-05-24 23:53:40 [INFO]: Epoch 288 - training loss: 0.2313, validation loss: 0.1003
2024-05-24 23:53:43 [INFO]: Epoch 289 - training loss: 0.2311, validation loss: 0.1000
2024-05-24 23:53:45 [INFO]: Epoch 290 - training loss: 0.2306, validation loss: 0.1000
2024-05-24 23:53:48 [INFO]: Epoch 291 - training loss: 0.2302, validation loss: 0.0999
2024-05-24 23:53:51 [INFO]: Epoch 292 - training loss: 0.2303, validation loss: 0.1000
2024-05-24 23:53:53 [INFO]: Epoch 293 - training loss: 0.2303, validation loss: 0.0999
2024-05-24 23:53:56 [INFO]: Epoch 294 - training loss: 0.2303, validation loss: 0.0999
2024-05-24 23:53:59 [INFO]: Epoch 295 - training loss: 0.2301, validation loss: 0.0997
2024-05-24 23:54:02 [INFO]: Epoch 296 - training loss: 0.2297, validation loss: 0.0999
2024-05-24 23:54:04 [INFO]: Epoch 297 - training loss: 0.2302, validation loss: 0.0997
2024-05-24 23:54:07 [INFO]: Epoch 298 - training loss: 0.2299, validation loss: 0.0998
2024-05-24 23:54:10 [INFO]: Epoch 299 - training loss: 0.2301, validation loss: 0.0997
2024-05-24 23:54:12 [INFO]: Epoch 300 - training loss: 0.2300, validation loss: 0.0997
2024-05-24 23:54:12 [INFO]: Finished training. The best model is from epoch#299.
2024-05-24 23:54:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/BRITS_air_quality/20240524_T234035/BRITS.pypots
2024-05-24 23:54:13 [INFO]: BRITS on Air-Quality: MAE=0.1375, MSE=0.0961
2024-05-24 23:54:13 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/BRITS_air_quality/imputation.pkl
2024-05-24 23:54:13 [INFO]: Using the given device: cuda:0
2024-05-24 23:54:13 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413
2024-05-24 23:54:13 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/tensorboard
2024-05-24 23:54:13 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-24 23:54:18 [INFO]: Epoch 001 - training loss: 1.5280, validation loss: 0.8046
2024-05-24 23:54:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch1_loss0.8045902788639069.pypots
2024-05-24 23:54:22 [INFO]: Epoch 002 - training loss: 1.0713, validation loss: 0.7478
2024-05-24 23:54:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch2_loss0.7478272020816803.pypots
2024-05-24 23:54:25 [INFO]: Epoch 003 - training loss: 0.9838, validation loss: 0.7222
2024-05-24 23:54:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch3_loss0.7222293943166733.pypots
2024-05-24 23:54:29 [INFO]: Epoch 004 - training loss: 0.9721, validation loss: 0.7076
2024-05-24 23:54:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch4_loss0.70758758187294.pypots
2024-05-24 23:54:33 [INFO]: Epoch 005 - training loss: 0.9517, validation loss: 0.6986
2024-05-24 23:54:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch5_loss0.6986330151557922.pypots
2024-05-24 23:54:37 [INFO]: Epoch 006 - training loss: 0.9375, validation loss: 0.6919
2024-05-24 23:54:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch6_loss0.6918920367956162.pypots
2024-05-24 23:54:40 [INFO]: Epoch 007 - training loss: 0.9423, validation loss: 0.6889
2024-05-24 23:54:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch7_loss0.68890540599823.pypots
2024-05-24 23:54:44 [INFO]: Epoch 008 - training loss: 0.9473, validation loss: 0.6851
2024-05-24 23:54:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch8_loss0.6851056724786758.pypots
2024-05-24 23:54:48 [INFO]: Epoch 009 - training loss: 0.9425, validation loss: 0.6816
2024-05-24 23:54:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch9_loss0.681649026274681.pypots
2024-05-24 23:54:52 [INFO]: Epoch 010 - training loss: 0.9210, validation loss: 0.6788
2024-05-24 23:54:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch10_loss0.678824508190155.pypots
2024-05-24 23:54:55 [INFO]: Epoch 011 - training loss: 0.8995, validation loss: 0.6783
2024-05-24 23:54:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch11_loss0.6783227413892746.pypots
2024-05-24 23:54:59 [INFO]: Epoch 012 - training loss: 0.9067, validation loss: 0.6765
2024-05-24 23:54:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch12_loss0.6764960497617721.pypots
2024-05-24 23:55:03 [INFO]: Epoch 013 - training loss: 0.9233, validation loss: 0.6758
2024-05-24 23:55:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch13_loss0.6758135676383972.pypots
2024-05-24 23:55:07 [INFO]: Epoch 014 - training loss: 0.9128, validation loss: 0.6754
2024-05-24 23:55:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch14_loss0.6753759384155273.pypots
2024-05-24 23:55:10 [INFO]: Epoch 015 - training loss: 0.9048, validation loss: 0.6746
2024-05-24 23:55:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch15_loss0.6746068894863129.pypots
2024-05-24 23:55:14 [INFO]: Epoch 016 - training loss: 0.9099, validation loss: 0.6732
2024-05-24 23:55:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch16_loss0.6731738388538361.pypots
2024-05-24 23:55:18 [INFO]: Epoch 017 - training loss: 0.8879, validation loss: 0.6721
2024-05-24 23:55:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch17_loss0.6720699518918991.pypots
2024-05-24 23:55:22 [INFO]: Epoch 018 - training loss: 0.9011, validation loss: 0.6726
2024-05-24 23:55:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch18_loss0.6726167052984238.pypots
2024-05-24 23:55:26 [INFO]: Epoch 019 - training loss: 0.8909, validation loss: 0.6733
2024-05-24 23:55:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch19_loss0.673281991481781.pypots
2024-05-24 23:55:29 [INFO]: Epoch 020 - training loss: 0.8741, validation loss: 0.6723
2024-05-24 23:55:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch20_loss0.672290363907814.pypots
2024-05-24 23:55:33 [INFO]: Epoch 021 - training loss: 0.8754, validation loss: 0.6728
2024-05-24 23:55:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch21_loss0.6728269577026367.pypots
2024-05-24 23:55:37 [INFO]: Epoch 022 - training loss: 0.8891, validation loss: 0.6745
2024-05-24 23:55:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch22_loss0.6744562983512878.pypots
2024-05-24 23:55:41 [INFO]: Epoch 023 - training loss: 0.9085, validation loss: 0.6751
2024-05-24 23:55:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch23_loss0.6751441091299057.pypots
2024-05-24 23:55:44 [INFO]: Epoch 024 - training loss: 0.8837, validation loss: 0.6725
2024-05-24 23:55:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch24_loss0.6725237607955933.pypots
2024-05-24 23:55:48 [INFO]: Epoch 025 - training loss: 0.8667, validation loss: 0.6750
2024-05-24 23:55:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch25_loss0.6749629348516464.pypots
2024-05-24 23:55:52 [INFO]: Epoch 026 - training loss: 0.8648, validation loss: 0.6745
2024-05-24 23:55:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch26_loss0.674501559138298.pypots
2024-05-24 23:55:56 [INFO]: Epoch 027 - training loss: 0.8568, validation loss: 0.6766
2024-05-24 23:55:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN_epoch27_loss0.6765507161617279.pypots
2024-05-24 23:55:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:55:56 [INFO]: Finished training. The best model is from epoch#17.
2024-05-24 23:55:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240524_T235413/MRNN.pypots
2024-05-24 23:55:56 [INFO]: MRNN on Air-Quality: MAE=0.5213, MSE=0.6034
2024-05-24 23:55:56 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/MRNN_air_quality/imputation.pkl
2024-05-24 23:55:56 [INFO]: Using the given device: cpu
2024-05-24 23:55:56 [INFO]: LOCF on Air-Quality: MAE=0.1979, MSE=0.2108
2024-05-24 23:55:56 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_air_quality".
2024-05-24 23:55:56 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/LOCF_air_quality/imputation.pkl
2024-05-24 23:55:56 [INFO]: Median on Air-Quality: MAE=0.6603, MSE=0.9901
2024-05-24 23:55:56 [INFO]: Successfully created the given path "saved_results/round_0/Median_air_quality".
2024-05-24 23:55:56 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/Median_air_quality/imputation.pkl
2024-05-24 23:55:56 [INFO]: Mean on Air-Quality: MAE=0.6916, MSE=0.9314
2024-05-24 23:55:56 [INFO]: Successfully created the given path "saved_results/round_0/Mean_air_quality".
2024-05-24 23:55:56 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/Mean_air_quality/imputation.pkl
2024-05-24 23:55:56 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-24 23:55:56 [INFO]: Using the given device: cuda:0
2024-05-24 23:55:56 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/SAITS_air_quality/20240524_T235556
2024-05-24 23:55:56 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/SAITS_air_quality/20240524_T235556/tensorboard
2024-05-24 23:55:57 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-24 23:55:57 [INFO]: Epoch 001 - training loss: 1.0523, validation loss: 0.5169
2024-05-24 23:55:58 [INFO]: Epoch 002 - training loss: 0.7487, validation loss: 0.4024
2024-05-24 23:55:59 [INFO]: Epoch 003 - training loss: 0.6404, validation loss: 0.3307
2024-05-24 23:55:59 [INFO]: Epoch 004 - training loss: 0.5674, validation loss: 0.2855
2024-05-24 23:56:00 [INFO]: Epoch 005 - training loss: 0.5196, validation loss: 0.2584
2024-05-24 23:56:01 [INFO]: Epoch 006 - training loss: 0.4823, validation loss: 0.2449
2024-05-24 23:56:01 [INFO]: Epoch 007 - training loss: 0.4580, validation loss: 0.2363
2024-05-24 23:56:02 [INFO]: Epoch 008 - training loss: 0.4397, validation loss: 0.2301
2024-05-24 23:56:03 [INFO]: Epoch 009 - training loss: 0.4272, validation loss: 0.2221
2024-05-24 23:56:03 [INFO]: Epoch 010 - training loss: 0.4143, validation loss: 0.2176
2024-05-24 23:56:04 [INFO]: Epoch 011 - training loss: 0.4049, validation loss: 0.2143
2024-05-24 23:56:05 [INFO]: Epoch 012 - training loss: 0.3965, validation loss: 0.2087
2024-05-24 23:56:05 [INFO]: Epoch 013 - training loss: 0.3883, validation loss: 0.2044
2024-05-24 23:56:06 [INFO]: Epoch 014 - training loss: 0.3823, validation loss: 0.2020
2024-05-24 23:56:07 [INFO]: Epoch 015 - training loss: 0.3757, validation loss: 0.2002
2024-05-24 23:56:07 [INFO]: Epoch 016 - training loss: 0.3702, validation loss: 0.1984
2024-05-24 23:56:08 [INFO]: Epoch 017 - training loss: 0.3650, validation loss: 0.1953
2024-05-24 23:56:09 [INFO]: Epoch 018 - training loss: 0.3615, validation loss: 0.1924
2024-05-24 23:56:09 [INFO]: Epoch 019 - training loss: 0.3570, validation loss: 0.1922
2024-05-24 23:56:10 [INFO]: Epoch 020 - training loss: 0.3546, validation loss: 0.1883
2024-05-24 23:56:11 [INFO]: Epoch 021 - training loss: 0.3499, validation loss: 0.1875
2024-05-24 23:56:11 [INFO]: Epoch 022 - training loss: 0.3454, validation loss: 0.1844
2024-05-24 23:56:12 [INFO]: Epoch 023 - training loss: 0.3427, validation loss: 0.1829
2024-05-24 23:56:13 [INFO]: Epoch 024 - training loss: 0.3414, validation loss: 0.1806
2024-05-24 23:56:13 [INFO]: Epoch 025 - training loss: 0.3380, validation loss: 0.1795
2024-05-24 23:56:14 [INFO]: Epoch 026 - training loss: 0.3342, validation loss: 0.1778
2024-05-24 23:56:15 [INFO]: Epoch 027 - training loss: 0.3314, validation loss: 0.1754
2024-05-24 23:56:15 [INFO]: Epoch 028 - training loss: 0.3279, validation loss: 0.1740
2024-05-24 23:56:16 [INFO]: Epoch 029 - training loss: 0.3257, validation loss: 0.1731
2024-05-24 23:56:17 [INFO]: Epoch 030 - training loss: 0.3240, validation loss: 0.1714
2024-05-24 23:56:17 [INFO]: Epoch 031 - training loss: 0.3250, validation loss: 0.1691
2024-05-24 23:56:18 [INFO]: Epoch 032 - training loss: 0.3188, validation loss: 0.1665
2024-05-24 23:56:19 [INFO]: Epoch 033 - training loss: 0.3169, validation loss: 0.1646
2024-05-24 23:56:19 [INFO]: Epoch 034 - training loss: 0.3155, validation loss: 0.1632
2024-05-24 23:56:20 [INFO]: Epoch 035 - training loss: 0.3129, validation loss: 0.1615
2024-05-24 23:56:21 [INFO]: Epoch 036 - training loss: 0.3135, validation loss: 0.1615
2024-05-24 23:56:21 [INFO]: Epoch 037 - training loss: 0.3126, validation loss: 0.1593
2024-05-24 23:56:22 [INFO]: Epoch 038 - training loss: 0.3109, validation loss: 0.1580
2024-05-24 23:56:23 [INFO]: Epoch 039 - training loss: 0.3076, validation loss: 0.1564
2024-05-24 23:56:23 [INFO]: Epoch 040 - training loss: 0.3047, validation loss: 0.1552
2024-05-24 23:56:24 [INFO]: Epoch 041 - training loss: 0.3030, validation loss: 0.1528
2024-05-24 23:56:25 [INFO]: Epoch 042 - training loss: 0.3013, validation loss: 0.1525
2024-05-24 23:56:25 [INFO]: Epoch 043 - training loss: 0.2995, validation loss: 0.1510
2024-05-24 23:56:26 [INFO]: Epoch 044 - training loss: 0.2991, validation loss: 0.1490
2024-05-24 23:56:27 [INFO]: Epoch 045 - training loss: 0.2965, validation loss: 0.1481
2024-05-24 23:56:27 [INFO]: Epoch 046 - training loss: 0.2948, validation loss: 0.1481
2024-05-24 23:56:28 [INFO]: Epoch 047 - training loss: 0.2948, validation loss: 0.1459
2024-05-24 23:56:29 [INFO]: Epoch 048 - training loss: 0.2938, validation loss: 0.1458
2024-05-24 23:56:29 [INFO]: Epoch 049 - training loss: 0.2918, validation loss: 0.1445
2024-05-24 23:56:30 [INFO]: Epoch 050 - training loss: 0.2892, validation loss: 0.1440
2024-05-24 23:56:31 [INFO]: Epoch 051 - training loss: 0.2883, validation loss: 0.1432
2024-05-24 23:56:31 [INFO]: Epoch 052 - training loss: 0.2890, validation loss: 0.1429
2024-05-24 23:56:32 [INFO]: Epoch 053 - training loss: 0.2858, validation loss: 0.1411
2024-05-24 23:56:33 [INFO]: Epoch 054 - training loss: 0.2831, validation loss: 0.1403
2024-05-24 23:56:33 [INFO]: Epoch 055 - training loss: 0.2827, validation loss: 0.1387
2024-05-24 23:56:34 [INFO]: Epoch 056 - training loss: 0.2811, validation loss: 0.1382
2024-05-24 23:56:35 [INFO]: Epoch 057 - training loss: 0.2813, validation loss: 0.1373
2024-05-24 23:56:35 [INFO]: Epoch 058 - training loss: 0.2806, validation loss: 0.1371
2024-05-24 23:56:36 [INFO]: Epoch 059 - training loss: 0.2772, validation loss: 0.1363
2024-05-24 23:56:37 [INFO]: Epoch 060 - training loss: 0.2767, validation loss: 0.1359
2024-05-24 23:56:37 [INFO]: Epoch 061 - training loss: 0.2749, validation loss: 0.1341
2024-05-24 23:56:38 [INFO]: Epoch 062 - training loss: 0.2736, validation loss: 0.1342
2024-05-24 23:56:39 [INFO]: Epoch 063 - training loss: 0.2728, validation loss: 0.1334
2024-05-24 23:56:39 [INFO]: Epoch 064 - training loss: 0.2727, validation loss: 0.1331
2024-05-24 23:56:40 [INFO]: Epoch 065 - training loss: 0.2708, validation loss: 0.1324
2024-05-24 23:56:41 [INFO]: Epoch 066 - training loss: 0.2712, validation loss: 0.1312
2024-05-24 23:56:41 [INFO]: Epoch 067 - training loss: 0.2689, validation loss: 0.1313
2024-05-24 23:56:42 [INFO]: Epoch 068 - training loss: 0.2677, validation loss: 0.1312
2024-05-24 23:56:43 [INFO]: Epoch 069 - training loss: 0.2675, validation loss: 0.1307
2024-05-24 23:56:43 [INFO]: Epoch 070 - training loss: 0.2661, validation loss: 0.1307
2024-05-24 23:56:44 [INFO]: Epoch 071 - training loss: 0.2646, validation loss: 0.1306
2024-05-24 23:56:45 [INFO]: Epoch 072 - training loss: 0.2643, validation loss: 0.1297
2024-05-24 23:56:45 [INFO]: Epoch 073 - training loss: 0.2628, validation loss: 0.1299
2024-05-24 23:56:46 [INFO]: Epoch 074 - training loss: 0.2637, validation loss: 0.1288
2024-05-24 23:56:47 [INFO]: Epoch 075 - training loss: 0.2620, validation loss: 0.1292
2024-05-24 23:56:47 [INFO]: Epoch 076 - training loss: 0.2606, validation loss: 0.1278
2024-05-24 23:56:48 [INFO]: Epoch 077 - training loss: 0.2600, validation loss: 0.1277
2024-05-24 23:56:49 [INFO]: Epoch 078 - training loss: 0.2598, validation loss: 0.1274
2024-05-24 23:56:49 [INFO]: Epoch 079 - training loss: 0.2579, validation loss: 0.1277
2024-05-24 23:56:50 [INFO]: Epoch 080 - training loss: 0.2581, validation loss: 0.1272
2024-05-24 23:56:51 [INFO]: Epoch 081 - training loss: 0.2571, validation loss: 0.1263
2024-05-24 23:56:51 [INFO]: Epoch 082 - training loss: 0.2586, validation loss: 0.1250
2024-05-24 23:56:52 [INFO]: Epoch 083 - training loss: 0.2565, validation loss: 0.1248
2024-05-24 23:56:53 [INFO]: Epoch 084 - training loss: 0.2552, validation loss: 0.1252
2024-05-24 23:56:53 [INFO]: Epoch 085 - training loss: 0.2535, validation loss: 0.1251
2024-05-24 23:56:54 [INFO]: Epoch 086 - training loss: 0.2543, validation loss: 0.1243
2024-05-24 23:56:55 [INFO]: Epoch 087 - training loss: 0.2549, validation loss: 0.1244
2024-05-24 23:56:55 [INFO]: Epoch 088 - training loss: 0.2536, validation loss: 0.1249
2024-05-24 23:56:56 [INFO]: Epoch 089 - training loss: 0.2529, validation loss: 0.1237
2024-05-24 23:56:57 [INFO]: Epoch 090 - training loss: 0.2516, validation loss: 0.1237
2024-05-24 23:56:57 [INFO]: Epoch 091 - training loss: 0.2501, validation loss: 0.1239
2024-05-24 23:56:58 [INFO]: Epoch 092 - training loss: 0.2503, validation loss: 0.1226
2024-05-24 23:56:59 [INFO]: Epoch 093 - training loss: 0.2494, validation loss: 0.1225
2024-05-24 23:56:59 [INFO]: Epoch 094 - training loss: 0.2493, validation loss: 0.1222
2024-05-24 23:57:00 [INFO]: Epoch 095 - training loss: 0.2473, validation loss: 0.1216
2024-05-24 23:57:01 [INFO]: Epoch 096 - training loss: 0.2472, validation loss: 0.1209
2024-05-24 23:57:01 [INFO]: Epoch 097 - training loss: 0.2464, validation loss: 0.1212
2024-05-24 23:57:02 [INFO]: Epoch 098 - training loss: 0.2456, validation loss: 0.1206
2024-05-24 23:57:03 [INFO]: Epoch 099 - training loss: 0.2460, validation loss: 0.1214
2024-05-24 23:57:03 [INFO]: Epoch 100 - training loss: 0.2476, validation loss: 0.1205
2024-05-24 23:57:04 [INFO]: Epoch 101 - training loss: 0.2470, validation loss: 0.1196
2024-05-24 23:57:05 [INFO]: Epoch 102 - training loss: 0.2435, validation loss: 0.1203
2024-05-24 23:57:05 [INFO]: Epoch 103 - training loss: 0.2436, validation loss: 0.1197
2024-05-24 23:57:06 [INFO]: Epoch 104 - training loss: 0.2447, validation loss: 0.1190
2024-05-24 23:57:07 [INFO]: Epoch 105 - training loss: 0.2421, validation loss: 0.1194
2024-05-24 23:57:07 [INFO]: Epoch 106 - training loss: 0.2409, validation loss: 0.1191
2024-05-24 23:57:08 [INFO]: Epoch 107 - training loss: 0.2407, validation loss: 0.1186
2024-05-24 23:57:09 [INFO]: Epoch 108 - training loss: 0.2409, validation loss: 0.1181
2024-05-24 23:57:09 [INFO]: Epoch 109 - training loss: 0.2410, validation loss: 0.1174
2024-05-24 23:57:10 [INFO]: Epoch 110 - training loss: 0.2391, validation loss: 0.1178
2024-05-24 23:57:10 [INFO]: Epoch 111 - training loss: 0.2389, validation loss: 0.1180
2024-05-24 23:57:11 [INFO]: Epoch 112 - training loss: 0.2381, validation loss: 0.1162
2024-05-24 23:57:12 [INFO]: Epoch 113 - training loss: 0.2385, validation loss: 0.1175
2024-05-24 23:57:12 [INFO]: Epoch 114 - training loss: 0.2376, validation loss: 0.1174
2024-05-24 23:57:13 [INFO]: Epoch 115 - training loss: 0.2377, validation loss: 0.1165
2024-05-24 23:57:14 [INFO]: Epoch 116 - training loss: 0.2378, validation loss: 0.1166
2024-05-24 23:57:14 [INFO]: Epoch 117 - training loss: 0.2371, validation loss: 0.1163
2024-05-24 23:57:15 [INFO]: Epoch 118 - training loss: 0.2361, validation loss: 0.1170
2024-05-24 23:57:16 [INFO]: Epoch 119 - training loss: 0.2348, validation loss: 0.1155
2024-05-24 23:57:16 [INFO]: Epoch 120 - training loss: 0.2341, validation loss: 0.1166
2024-05-24 23:57:17 [INFO]: Epoch 121 - training loss: 0.2349, validation loss: 0.1160
2024-05-24 23:57:18 [INFO]: Epoch 122 - training loss: 0.2343, validation loss: 0.1159
2024-05-24 23:57:18 [INFO]: Epoch 123 - training loss: 0.2345, validation loss: 0.1146
2024-05-24 23:57:19 [INFO]: Epoch 124 - training loss: 0.2333, validation loss: 0.1156
2024-05-24 23:57:20 [INFO]: Epoch 125 - training loss: 0.2322, validation loss: 0.1148
2024-05-24 23:57:20 [INFO]: Epoch 126 - training loss: 0.2326, validation loss: 0.1147
2024-05-24 23:57:21 [INFO]: Epoch 127 - training loss: 0.2316, validation loss: 0.1148
2024-05-24 23:57:22 [INFO]: Epoch 128 - training loss: 0.2329, validation loss: 0.1144
2024-05-24 23:57:22 [INFO]: Epoch 129 - training loss: 0.2310, validation loss: 0.1146
2024-05-24 23:57:23 [INFO]: Epoch 130 - training loss: 0.2315, validation loss: 0.1139
2024-05-24 23:57:24 [INFO]: Epoch 131 - training loss: 0.2317, validation loss: 0.1135
2024-05-24 23:57:24 [INFO]: Epoch 132 - training loss: 0.2294, validation loss: 0.1141
2024-05-24 23:57:25 [INFO]: Epoch 133 - training loss: 0.2293, validation loss: 0.1129
2024-05-24 23:57:26 [INFO]: Epoch 134 - training loss: 0.2284, validation loss: 0.1134
2024-05-24 23:57:26 [INFO]: Epoch 135 - training loss: 0.2281, validation loss: 0.1132
2024-05-24 23:57:27 [INFO]: Epoch 136 - training loss: 0.2271, validation loss: 0.1135
2024-05-24 23:57:28 [INFO]: Epoch 137 - training loss: 0.2285, validation loss: 0.1125
2024-05-24 23:57:28 [INFO]: Epoch 138 - training loss: 0.2276, validation loss: 0.1124
2024-05-24 23:57:29 [INFO]: Epoch 139 - training loss: 0.2265, validation loss: 0.1147
2024-05-24 23:57:30 [INFO]: Epoch 140 - training loss: 0.2281, validation loss: 0.1126
2024-05-24 23:57:30 [INFO]: Epoch 141 - training loss: 0.2259, validation loss: 0.1128
2024-05-24 23:57:31 [INFO]: Epoch 142 - training loss: 0.2259, validation loss: 0.1116
2024-05-24 23:57:32 [INFO]: Epoch 143 - training loss: 0.2263, validation loss: 0.1134
2024-05-24 23:57:32 [INFO]: Epoch 144 - training loss: 0.2262, validation loss: 0.1115
2024-05-24 23:57:33 [INFO]: Epoch 145 - training loss: 0.2249, validation loss: 0.1111
2024-05-24 23:57:34 [INFO]: Epoch 146 - training loss: 0.2247, validation loss: 0.1107
2024-05-24 23:57:34 [INFO]: Epoch 147 - training loss: 0.2255, validation loss: 0.1124
2024-05-24 23:57:35 [INFO]: Epoch 148 - training loss: 0.2254, validation loss: 0.1102
2024-05-24 23:57:36 [INFO]: Epoch 149 - training loss: 0.2231, validation loss: 0.1104
2024-05-24 23:57:36 [INFO]: Epoch 150 - training loss: 0.2239, validation loss: 0.1104
2024-05-24 23:57:37 [INFO]: Epoch 151 - training loss: 0.2232, validation loss: 0.1103
2024-05-24 23:57:38 [INFO]: Epoch 152 - training loss: 0.2210, validation loss: 0.1107
2024-05-24 23:57:38 [INFO]: Epoch 153 - training loss: 0.2219, validation loss: 0.1094
2024-05-24 23:57:39 [INFO]: Epoch 154 - training loss: 0.2209, validation loss: 0.1096
2024-05-24 23:57:40 [INFO]: Epoch 155 - training loss: 0.2200, validation loss: 0.1091
2024-05-24 23:57:40 [INFO]: Epoch 156 - training loss: 0.2209, validation loss: 0.1089
2024-05-24 23:57:41 [INFO]: Epoch 157 - training loss: 0.2214, validation loss: 0.1087
2024-05-24 23:57:42 [INFO]: Epoch 158 - training loss: 0.2212, validation loss: 0.1094
2024-05-24 23:57:42 [INFO]: Epoch 159 - training loss: 0.2207, validation loss: 0.1118
2024-05-24 23:57:43 [INFO]: Epoch 160 - training loss: 0.2208, validation loss: 0.1091
2024-05-24 23:57:44 [INFO]: Epoch 161 - training loss: 0.2209, validation loss: 0.1101
2024-05-24 23:57:44 [INFO]: Epoch 162 - training loss: 0.2197, validation loss: 0.1085
2024-05-24 23:57:45 [INFO]: Epoch 163 - training loss: 0.2177, validation loss: 0.1077
2024-05-24 23:57:46 [INFO]: Epoch 164 - training loss: 0.2188, validation loss: 0.1088
2024-05-24 23:57:46 [INFO]: Epoch 165 - training loss: 0.2185, validation loss: 0.1089
2024-05-24 23:57:47 [INFO]: Epoch 166 - training loss: 0.2178, validation loss: 0.1088
2024-05-24 23:57:48 [INFO]: Epoch 167 - training loss: 0.2187, validation loss: 0.1075
2024-05-24 23:57:48 [INFO]: Epoch 168 - training loss: 0.2167, validation loss: 0.1071
2024-05-24 23:57:49 [INFO]: Epoch 169 - training loss: 0.2170, validation loss: 0.1086
2024-05-24 23:57:50 [INFO]: Epoch 170 - training loss: 0.2157, validation loss: 0.1081
2024-05-24 23:57:50 [INFO]: Epoch 171 - training loss: 0.2165, validation loss: 0.1073
2024-05-24 23:57:51 [INFO]: Epoch 172 - training loss: 0.2148, validation loss: 0.1081
2024-05-24 23:57:52 [INFO]: Epoch 173 - training loss: 0.2154, validation loss: 0.1076
2024-05-24 23:57:52 [INFO]: Epoch 174 - training loss: 0.2147, validation loss: 0.1080
2024-05-24 23:57:53 [INFO]: Epoch 175 - training loss: 0.2165, validation loss: 0.1083
2024-05-24 23:57:54 [INFO]: Epoch 176 - training loss: 0.2173, validation loss: 0.1076
2024-05-24 23:57:54 [INFO]: Epoch 177 - training loss: 0.2144, validation loss: 0.1072
2024-05-24 23:57:55 [INFO]: Epoch 178 - training loss: 0.2132, validation loss: 0.1074
2024-05-24 23:57:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:57:55 [INFO]: Finished training. The best model is from epoch#168.
2024-05-24 23:57:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/SAITS_air_quality/20240524_T235556/SAITS.pypots
2024-05-24 23:57:55 [INFO]: SAITS on Air-Quality: MAE=0.1478, MSE=0.1031
2024-05-24 23:57:55 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/SAITS_air_quality/imputation.pkl
2024-05-24 23:57:55 [INFO]: Using the given device: cuda:0
2024-05-24 23:57:55 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/Transformer_air_quality/20240524_T235755
2024-05-24 23:57:55 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/Transformer_air_quality/20240524_T235755/tensorboard
2024-05-24 23:57:55 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-24 23:57:56 [INFO]: Epoch 001 - training loss: 0.8974, validation loss: 0.4689
2024-05-24 23:57:56 [INFO]: Epoch 002 - training loss: 0.5729, validation loss: 0.3499
2024-05-24 23:57:56 [INFO]: Epoch 003 - training loss: 0.4838, validation loss: 0.2871
2024-05-24 23:57:56 [INFO]: Epoch 004 - training loss: 0.4360, validation loss: 0.2617
2024-05-24 23:57:57 [INFO]: Epoch 005 - training loss: 0.4056, validation loss: 0.2503
2024-05-24 23:57:57 [INFO]: Epoch 006 - training loss: 0.3867, validation loss: 0.2384
2024-05-24 23:57:57 [INFO]: Epoch 007 - training loss: 0.3750, validation loss: 0.2305
2024-05-24 23:57:58 [INFO]: Epoch 008 - training loss: 0.3648, validation loss: 0.2234
2024-05-24 23:57:58 [INFO]: Epoch 009 - training loss: 0.3537, validation loss: 0.2205
2024-05-24 23:57:58 [INFO]: Epoch 010 - training loss: 0.3475, validation loss: 0.2151
2024-05-24 23:57:59 [INFO]: Epoch 011 - training loss: 0.3396, validation loss: 0.2098
2024-05-24 23:57:59 [INFO]: Epoch 012 - training loss: 0.3341, validation loss: 0.2057
2024-05-24 23:57:59 [INFO]: Epoch 013 - training loss: 0.3319, validation loss: 0.2032
2024-05-24 23:58:00 [INFO]: Epoch 014 - training loss: 0.3247, validation loss: 0.1988
2024-05-24 23:58:00 [INFO]: Epoch 015 - training loss: 0.3219, validation loss: 0.1973
2024-05-24 23:58:00 [INFO]: Epoch 016 - training loss: 0.3180, validation loss: 0.1944
2024-05-24 23:58:01 [INFO]: Epoch 017 - training loss: 0.3126, validation loss: 0.1898
2024-05-24 23:58:01 [INFO]: Epoch 018 - training loss: 0.3125, validation loss: 0.1869
2024-05-24 23:58:01 [INFO]: Epoch 019 - training loss: 0.3079, validation loss: 0.1844
2024-05-24 23:58:01 [INFO]: Epoch 020 - training loss: 0.3059, validation loss: 0.1838
2024-05-24 23:58:02 [INFO]: Epoch 021 - training loss: 0.3036, validation loss: 0.1813
2024-05-24 23:58:02 [INFO]: Epoch 022 - training loss: 0.3013, validation loss: 0.1780
2024-05-24 23:58:02 [INFO]: Epoch 023 - training loss: 0.2973, validation loss: 0.1761
2024-05-24 23:58:03 [INFO]: Epoch 024 - training loss: 0.2958, validation loss: 0.1744
2024-05-24 23:58:03 [INFO]: Epoch 025 - training loss: 0.2949, validation loss: 0.1738
2024-05-24 23:58:03 [INFO]: Epoch 026 - training loss: 0.2918, validation loss: 0.1715
2024-05-24 23:58:04 [INFO]: Epoch 027 - training loss: 0.2932, validation loss: 0.1711
2024-05-24 23:58:04 [INFO]: Epoch 028 - training loss: 0.2901, validation loss: 0.1708
2024-05-24 23:58:04 [INFO]: Epoch 029 - training loss: 0.2871, validation loss: 0.1686
2024-05-24 23:58:05 [INFO]: Epoch 030 - training loss: 0.2859, validation loss: 0.1680
2024-05-24 23:58:05 [INFO]: Epoch 031 - training loss: 0.2880, validation loss: 0.1676
2024-05-24 23:58:05 [INFO]: Epoch 032 - training loss: 0.2829, validation loss: 0.1683
2024-05-24 23:58:06 [INFO]: Epoch 033 - training loss: 0.2824, validation loss: 0.1665
2024-05-24 23:58:06 [INFO]: Epoch 034 - training loss: 0.2824, validation loss: 0.1656
2024-05-24 23:58:06 [INFO]: Epoch 035 - training loss: 0.2802, validation loss: 0.1638
2024-05-24 23:58:06 [INFO]: Epoch 036 - training loss: 0.2787, validation loss: 0.1654
2024-05-24 23:58:07 [INFO]: Epoch 037 - training loss: 0.2787, validation loss: 0.1639
2024-05-24 23:58:07 [INFO]: Epoch 038 - training loss: 0.2738, validation loss: 0.1653
2024-05-24 23:58:07 [INFO]: Epoch 039 - training loss: 0.2754, validation loss: 0.1634
2024-05-24 23:58:08 [INFO]: Epoch 040 - training loss: 0.2738, validation loss: 0.1633
2024-05-24 23:58:08 [INFO]: Epoch 041 - training loss: 0.2726, validation loss: 0.1614
2024-05-24 23:58:08 [INFO]: Epoch 042 - training loss: 0.2709, validation loss: 0.1608
2024-05-24 23:58:09 [INFO]: Epoch 043 - training loss: 0.2695, validation loss: 0.1614
2024-05-24 23:58:09 [INFO]: Epoch 044 - training loss: 0.2699, validation loss: 0.1601
2024-05-24 23:58:09 [INFO]: Epoch 045 - training loss: 0.2702, validation loss: 0.1614
2024-05-24 23:58:10 [INFO]: Epoch 046 - training loss: 0.2660, validation loss: 0.1592
2024-05-24 23:58:10 [INFO]: Epoch 047 - training loss: 0.2650, validation loss: 0.1588
2024-05-24 23:58:10 [INFO]: Epoch 048 - training loss: 0.2653, validation loss: 0.1580
2024-05-24 23:58:10 [INFO]: Epoch 049 - training loss: 0.2634, validation loss: 0.1586
2024-05-24 23:58:11 [INFO]: Epoch 050 - training loss: 0.2664, validation loss: 0.1591
2024-05-24 23:58:11 [INFO]: Epoch 051 - training loss: 0.2640, validation loss: 0.1581
2024-05-24 23:58:11 [INFO]: Epoch 052 - training loss: 0.2629, validation loss: 0.1597
2024-05-24 23:58:12 [INFO]: Epoch 053 - training loss: 0.2613, validation loss: 0.1578
2024-05-24 23:58:12 [INFO]: Epoch 054 - training loss: 0.2592, validation loss: 0.1613
2024-05-24 23:58:12 [INFO]: Epoch 055 - training loss: 0.2603, validation loss: 0.1580
2024-05-24 23:58:13 [INFO]: Epoch 056 - training loss: 0.2591, validation loss: 0.1585
2024-05-24 23:58:13 [INFO]: Epoch 057 - training loss: 0.2573, validation loss: 0.1566
2024-05-24 23:58:13 [INFO]: Epoch 058 - training loss: 0.2570, validation loss: 0.1573
2024-05-24 23:58:14 [INFO]: Epoch 059 - training loss: 0.2573, validation loss: 0.1578
2024-05-24 23:58:14 [INFO]: Epoch 060 - training loss: 0.2556, validation loss: 0.1549
2024-05-24 23:58:14 [INFO]: Epoch 061 - training loss: 0.2527, validation loss: 0.1563
2024-05-24 23:58:15 [INFO]: Epoch 062 - training loss: 0.2559, validation loss: 0.1567
2024-05-24 23:58:15 [INFO]: Epoch 063 - training loss: 0.2525, validation loss: 0.1562
2024-05-24 23:58:15 [INFO]: Epoch 064 - training loss: 0.2511, validation loss: 0.1557
2024-05-24 23:58:15 [INFO]: Epoch 065 - training loss: 0.2517, validation loss: 0.1548
2024-05-24 23:58:16 [INFO]: Epoch 066 - training loss: 0.2497, validation loss: 0.1544
2024-05-24 23:58:16 [INFO]: Epoch 067 - training loss: 0.2505, validation loss: 0.1543
2024-05-24 23:58:16 [INFO]: Epoch 068 - training loss: 0.2493, validation loss: 0.1536
2024-05-24 23:58:17 [INFO]: Epoch 069 - training loss: 0.2494, validation loss: 0.1545
2024-05-24 23:58:17 [INFO]: Epoch 070 - training loss: 0.2508, validation loss: 0.1532
2024-05-24 23:58:17 [INFO]: Epoch 071 - training loss: 0.2454, validation loss: 0.1548
2024-05-24 23:58:18 [INFO]: Epoch 072 - training loss: 0.2460, validation loss: 0.1531
2024-05-24 23:58:18 [INFO]: Epoch 073 - training loss: 0.2456, validation loss: 0.1527
2024-05-24 23:58:18 [INFO]: Epoch 074 - training loss: 0.2450, validation loss: 0.1527
2024-05-24 23:58:19 [INFO]: Epoch 075 - training loss: 0.2446, validation loss: 0.1540
2024-05-24 23:58:19 [INFO]: Epoch 076 - training loss: 0.2444, validation loss: 0.1526
2024-05-24 23:58:19 [INFO]: Epoch 077 - training loss: 0.2434, validation loss: 0.1517
2024-05-24 23:58:20 [INFO]: Epoch 078 - training loss: 0.2446, validation loss: 0.1513
2024-05-24 23:58:20 [INFO]: Epoch 079 - training loss: 0.2415, validation loss: 0.1528
2024-05-24 23:58:20 [INFO]: Epoch 080 - training loss: 0.2402, validation loss: 0.1520
2024-05-24 23:58:20 [INFO]: Epoch 081 - training loss: 0.2404, validation loss: 0.1522
2024-05-24 23:58:21 [INFO]: Epoch 082 - training loss: 0.2384, validation loss: 0.1496
2024-05-24 23:58:21 [INFO]: Epoch 083 - training loss: 0.2389, validation loss: 0.1505
2024-05-24 23:58:21 [INFO]: Epoch 084 - training loss: 0.2374, validation loss: 0.1495
2024-05-24 23:58:22 [INFO]: Epoch 085 - training loss: 0.2370, validation loss: 0.1502
2024-05-24 23:58:22 [INFO]: Epoch 086 - training loss: 0.2382, validation loss: 0.1502
2024-05-24 23:58:22 [INFO]: Epoch 087 - training loss: 0.2401, validation loss: 0.1538
2024-05-24 23:58:23 [INFO]: Epoch 088 - training loss: 0.2368, validation loss: 0.1499
2024-05-24 23:58:23 [INFO]: Epoch 089 - training loss: 0.2363, validation loss: 0.1493
2024-05-24 23:58:23 [INFO]: Epoch 090 - training loss: 0.2346, validation loss: 0.1508
2024-05-24 23:58:24 [INFO]: Epoch 091 - training loss: 0.2343, validation loss: 0.1502
2024-05-24 23:58:24 [INFO]: Epoch 092 - training loss: 0.2320, validation loss: 0.1493
2024-05-24 23:58:24 [INFO]: Epoch 093 - training loss: 0.2328, validation loss: 0.1482
2024-05-24 23:58:25 [INFO]: Epoch 094 - training loss: 0.2367, validation loss: 0.1502
2024-05-24 23:58:25 [INFO]: Epoch 095 - training loss: 0.2337, validation loss: 0.1470
2024-05-24 23:58:25 [INFO]: Epoch 096 - training loss: 0.2311, validation loss: 0.1471
2024-05-24 23:58:25 [INFO]: Epoch 097 - training loss: 0.2312, validation loss: 0.1478
2024-05-24 23:58:26 [INFO]: Epoch 098 - training loss: 0.2314, validation loss: 0.1481
2024-05-24 23:58:26 [INFO]: Epoch 099 - training loss: 0.2302, validation loss: 0.1470
2024-05-24 23:58:26 [INFO]: Epoch 100 - training loss: 0.2292, validation loss: 0.1449
2024-05-24 23:58:27 [INFO]: Epoch 101 - training loss: 0.2283, validation loss: 0.1462
2024-05-24 23:58:27 [INFO]: Epoch 102 - training loss: 0.2261, validation loss: 0.1471
2024-05-24 23:58:27 [INFO]: Epoch 103 - training loss: 0.2268, validation loss: 0.1470
2024-05-24 23:58:28 [INFO]: Epoch 104 - training loss: 0.2263, validation loss: 0.1467
2024-05-24 23:58:28 [INFO]: Epoch 105 - training loss: 0.2249, validation loss: 0.1461
2024-05-24 23:58:28 [INFO]: Epoch 106 - training loss: 0.2257, validation loss: 0.1459
2024-05-24 23:58:29 [INFO]: Epoch 107 - training loss: 0.2256, validation loss: 0.1458
2024-05-24 23:58:29 [INFO]: Epoch 108 - training loss: 0.2258, validation loss: 0.1448
2024-05-24 23:58:29 [INFO]: Epoch 109 - training loss: 0.2290, validation loss: 0.1464
2024-05-24 23:58:30 [INFO]: Epoch 110 - training loss: 0.2258, validation loss: 0.1450
2024-05-24 23:58:30 [INFO]: Epoch 111 - training loss: 0.2263, validation loss: 0.1433
2024-05-24 23:58:30 [INFO]: Epoch 112 - training loss: 0.2213, validation loss: 0.1441
2024-05-24 23:58:30 [INFO]: Epoch 113 - training loss: 0.2208, validation loss: 0.1436
2024-05-24 23:58:31 [INFO]: Epoch 114 - training loss: 0.2223, validation loss: 0.1456
2024-05-24 23:58:31 [INFO]: Epoch 115 - training loss: 0.2238, validation loss: 0.1440
2024-05-24 23:58:31 [INFO]: Epoch 116 - training loss: 0.2225, validation loss: 0.1448
2024-05-24 23:58:32 [INFO]: Epoch 117 - training loss: 0.2214, validation loss: 0.1425
2024-05-24 23:58:32 [INFO]: Epoch 118 - training loss: 0.2191, validation loss: 0.1425
2024-05-24 23:58:32 [INFO]: Epoch 119 - training loss: 0.2200, validation loss: 0.1426
2024-05-24 23:58:33 [INFO]: Epoch 120 - training loss: 0.2219, validation loss: 0.1430
2024-05-24 23:58:33 [INFO]: Epoch 121 - training loss: 0.2204, validation loss: 0.1406
2024-05-24 23:58:33 [INFO]: Epoch 122 - training loss: 0.2247, validation loss: 0.1447
2024-05-24 23:58:34 [INFO]: Epoch 123 - training loss: 0.2199, validation loss: 0.1424
2024-05-24 23:58:34 [INFO]: Epoch 124 - training loss: 0.2177, validation loss: 0.1421
2024-05-24 23:58:34 [INFO]: Epoch 125 - training loss: 0.2180, validation loss: 0.1418
2024-05-24 23:58:35 [INFO]: Epoch 126 - training loss: 0.2170, validation loss: 0.1400
2024-05-24 23:58:35 [INFO]: Epoch 127 - training loss: 0.2170, validation loss: 0.1407
2024-05-24 23:58:35 [INFO]: Epoch 128 - training loss: 0.2177, validation loss: 0.1416
2024-05-24 23:58:35 [INFO]: Epoch 129 - training loss: 0.2175, validation loss: 0.1399
2024-05-24 23:58:36 [INFO]: Epoch 130 - training loss: 0.2168, validation loss: 0.1389
2024-05-24 23:58:36 [INFO]: Epoch 131 - training loss: 0.2166, validation loss: 0.1393
2024-05-24 23:58:36 [INFO]: Epoch 132 - training loss: 0.2160, validation loss: 0.1400
2024-05-24 23:58:37 [INFO]: Epoch 133 - training loss: 0.2151, validation loss: 0.1408
2024-05-24 23:58:37 [INFO]: Epoch 134 - training loss: 0.2168, validation loss: 0.1402
2024-05-24 23:58:37 [INFO]: Epoch 135 - training loss: 0.2183, validation loss: 0.1422
2024-05-24 23:58:38 [INFO]: Epoch 136 - training loss: 0.2154, validation loss: 0.1389
2024-05-24 23:58:38 [INFO]: Epoch 137 - training loss: 0.2129, validation loss: 0.1393
2024-05-24 23:58:38 [INFO]: Epoch 138 - training loss: 0.2121, validation loss: 0.1400
2024-05-24 23:58:39 [INFO]: Epoch 139 - training loss: 0.2126, validation loss: 0.1385
2024-05-24 23:58:39 [INFO]: Epoch 140 - training loss: 0.2140, validation loss: 0.1397
2024-05-24 23:58:39 [INFO]: Epoch 141 - training loss: 0.2132, validation loss: 0.1387
2024-05-24 23:58:40 [INFO]: Epoch 142 - training loss: 0.2114, validation loss: 0.1386
2024-05-24 23:58:40 [INFO]: Epoch 143 - training loss: 0.2108, validation loss: 0.1381
2024-05-24 23:58:40 [INFO]: Epoch 144 - training loss: 0.2109, validation loss: 0.1389
2024-05-24 23:58:40 [INFO]: Epoch 145 - training loss: 0.2127, validation loss: 0.1392
2024-05-24 23:58:41 [INFO]: Epoch 146 - training loss: 0.2098, validation loss: 0.1382
2024-05-24 23:58:41 [INFO]: Epoch 147 - training loss: 0.2095, validation loss: 0.1363
2024-05-24 23:58:41 [INFO]: Epoch 148 - training loss: 0.2117, validation loss: 0.1378
2024-05-24 23:58:42 [INFO]: Epoch 149 - training loss: 0.2118, validation loss: 0.1385
2024-05-24 23:58:42 [INFO]: Epoch 150 - training loss: 0.2119, validation loss: 0.1390
2024-05-24 23:58:42 [INFO]: Epoch 151 - training loss: 0.2092, validation loss: 0.1385
2024-05-24 23:58:43 [INFO]: Epoch 152 - training loss: 0.2105, validation loss: 0.1403
2024-05-24 23:58:43 [INFO]: Epoch 153 - training loss: 0.2085, validation loss: 0.1373
2024-05-24 23:58:43 [INFO]: Epoch 154 - training loss: 0.2104, validation loss: 0.1388
2024-05-24 23:58:44 [INFO]: Epoch 155 - training loss: 0.2108, validation loss: 0.1353
2024-05-24 23:58:44 [INFO]: Epoch 156 - training loss: 0.2114, validation loss: 0.1375
2024-05-24 23:58:44 [INFO]: Epoch 157 - training loss: 0.2130, validation loss: 0.1374
2024-05-24 23:58:45 [INFO]: Epoch 158 - training loss: 0.2105, validation loss: 0.1362
2024-05-24 23:58:45 [INFO]: Epoch 159 - training loss: 0.2068, validation loss: 0.1355
2024-05-24 23:58:45 [INFO]: Epoch 160 - training loss: 0.2067, validation loss: 0.1372
2024-05-24 23:58:45 [INFO]: Epoch 161 - training loss: 0.2062, validation loss: 0.1356
2024-05-24 23:58:46 [INFO]: Epoch 162 - training loss: 0.2071, validation loss: 0.1364
2024-05-24 23:58:46 [INFO]: Epoch 163 - training loss: 0.2093, validation loss: 0.1365
2024-05-24 23:58:46 [INFO]: Epoch 164 - training loss: 0.2057, validation loss: 0.1341
2024-05-24 23:58:47 [INFO]: Epoch 165 - training loss: 0.2055, validation loss: 0.1359
2024-05-24 23:58:47 [INFO]: Epoch 166 - training loss: 0.2069, validation loss: 0.1356
2024-05-24 23:58:47 [INFO]: Epoch 167 - training loss: 0.2050, validation loss: 0.1343
2024-05-24 23:58:48 [INFO]: Epoch 168 - training loss: 0.2045, validation loss: 0.1348
2024-05-24 23:58:48 [INFO]: Epoch 169 - training loss: 0.2038, validation loss: 0.1338
2024-05-24 23:58:48 [INFO]: Epoch 170 - training loss: 0.2045, validation loss: 0.1330
2024-05-24 23:58:49 [INFO]: Epoch 171 - training loss: 0.2016, validation loss: 0.1348
2024-05-24 23:58:49 [INFO]: Epoch 172 - training loss: 0.2030, validation loss: 0.1345
2024-05-24 23:58:49 [INFO]: Epoch 173 - training loss: 0.2053, validation loss: 0.1351
2024-05-24 23:58:50 [INFO]: Epoch 174 - training loss: 0.2028, validation loss: 0.1366
2024-05-24 23:58:50 [INFO]: Epoch 175 - training loss: 0.2038, validation loss: 0.1338
2024-05-24 23:58:50 [INFO]: Epoch 176 - training loss: 0.2044, validation loss: 0.1348
2024-05-24 23:58:50 [INFO]: Epoch 177 - training loss: 0.2027, validation loss: 0.1323
2024-05-24 23:58:51 [INFO]: Epoch 178 - training loss: 0.2036, validation loss: 0.1332
2024-05-24 23:58:51 [INFO]: Epoch 179 - training loss: 0.2009, validation loss: 0.1330
2024-05-24 23:58:51 [INFO]: Epoch 180 - training loss: 0.2016, validation loss: 0.1337
2024-05-24 23:58:52 [INFO]: Epoch 181 - training loss: 0.2022, validation loss: 0.1322
2024-05-24 23:58:52 [INFO]: Epoch 182 - training loss: 0.2007, validation loss: 0.1335
2024-05-24 23:58:52 [INFO]: Epoch 183 - training loss: 0.1988, validation loss: 0.1331
2024-05-24 23:58:53 [INFO]: Epoch 184 - training loss: 0.2005, validation loss: 0.1318
2024-05-24 23:58:53 [INFO]: Epoch 185 - training loss: 0.2002, validation loss: 0.1312
2024-05-24 23:58:53 [INFO]: Epoch 186 - training loss: 0.2029, validation loss: 0.1331
2024-05-24 23:58:54 [INFO]: Epoch 187 - training loss: 0.1996, validation loss: 0.1329
2024-05-24 23:58:54 [INFO]: Epoch 188 - training loss: 0.1987, validation loss: 0.1312
2024-05-24 23:58:54 [INFO]: Epoch 189 - training loss: 0.2000, validation loss: 0.1325
2024-05-24 23:58:54 [INFO]: Epoch 190 - training loss: 0.1983, validation loss: 0.1319
2024-05-24 23:58:55 [INFO]: Epoch 191 - training loss: 0.2003, validation loss: 0.1311
2024-05-24 23:58:55 [INFO]: Epoch 192 - training loss: 0.2008, validation loss: 0.1341
2024-05-24 23:58:55 [INFO]: Epoch 193 - training loss: 0.1994, validation loss: 0.1313
2024-05-24 23:58:56 [INFO]: Epoch 194 - training loss: 0.1997, validation loss: 0.1317
2024-05-24 23:58:56 [INFO]: Epoch 195 - training loss: 0.1992, validation loss: 0.1327
2024-05-24 23:58:56 [INFO]: Epoch 196 - training loss: 0.1987, validation loss: 0.1308
2024-05-24 23:58:57 [INFO]: Epoch 197 - training loss: 0.1979, validation loss: 0.1305
2024-05-24 23:58:57 [INFO]: Epoch 198 - training loss: 0.1967, validation loss: 0.1311
2024-05-24 23:58:57 [INFO]: Epoch 199 - training loss: 0.1957, validation loss: 0.1306
2024-05-24 23:58:58 [INFO]: Epoch 200 - training loss: 0.1970, validation loss: 0.1305
2024-05-24 23:58:58 [INFO]: Epoch 201 - training loss: 0.1994, validation loss: 0.1295
2024-05-24 23:58:58 [INFO]: Epoch 202 - training loss: 0.1981, validation loss: 0.1303
2024-05-24 23:58:59 [INFO]: Epoch 203 - training loss: 0.1963, validation loss: 0.1306
2024-05-24 23:58:59 [INFO]: Epoch 204 - training loss: 0.1946, validation loss: 0.1316
2024-05-24 23:58:59 [INFO]: Epoch 205 - training loss: 0.1950, validation loss: 0.1297
2024-05-24 23:58:59 [INFO]: Epoch 206 - training loss: 0.1970, validation loss: 0.1300
2024-05-24 23:59:00 [INFO]: Epoch 207 - training loss: 0.1939, validation loss: 0.1310
2024-05-24 23:59:00 [INFO]: Epoch 208 - training loss: 0.1928, validation loss: 0.1317
2024-05-24 23:59:00 [INFO]: Epoch 209 - training loss: 0.1951, validation loss: 0.1292
2024-05-24 23:59:01 [INFO]: Epoch 210 - training loss: 0.1946, validation loss: 0.1300
2024-05-24 23:59:01 [INFO]: Epoch 211 - training loss: 0.1941, validation loss: 0.1289
2024-05-24 23:59:01 [INFO]: Epoch 212 - training loss: 0.1923, validation loss: 0.1301
2024-05-24 23:59:02 [INFO]: Epoch 213 - training loss: 0.1929, validation loss: 0.1300
2024-05-24 23:59:02 [INFO]: Epoch 214 - training loss: 0.1924, validation loss: 0.1299
2024-05-24 23:59:02 [INFO]: Epoch 215 - training loss: 0.1916, validation loss: 0.1296
2024-05-24 23:59:03 [INFO]: Epoch 216 - training loss: 0.1938, validation loss: 0.1304
2024-05-24 23:59:03 [INFO]: Epoch 217 - training loss: 0.1918, validation loss: 0.1297
2024-05-24 23:59:03 [INFO]: Epoch 218 - training loss: 0.1914, validation loss: 0.1289
2024-05-24 23:59:04 [INFO]: Epoch 219 - training loss: 0.1924, validation loss: 0.1293
2024-05-24 23:59:04 [INFO]: Epoch 220 - training loss: 0.1923, validation loss: 0.1288
2024-05-24 23:59:04 [INFO]: Epoch 221 - training loss: 0.1907, validation loss: 0.1297
2024-05-24 23:59:05 [INFO]: Epoch 222 - training loss: 0.1922, validation loss: 0.1286
2024-05-24 23:59:05 [INFO]: Epoch 223 - training loss: 0.1919, validation loss: 0.1300
2024-05-24 23:59:05 [INFO]: Epoch 224 - training loss: 0.1916, validation loss: 0.1313
2024-05-24 23:59:05 [INFO]: Epoch 225 - training loss: 0.1917, validation loss: 0.1302
2024-05-24 23:59:06 [INFO]: Epoch 226 - training loss: 0.1915, validation loss: 0.1289
2024-05-24 23:59:06 [INFO]: Epoch 227 - training loss: 0.1909, validation loss: 0.1282
2024-05-24 23:59:06 [INFO]: Epoch 228 - training loss: 0.1929, validation loss: 0.1283
2024-05-24 23:59:07 [INFO]: Epoch 229 - training loss: 0.1901, validation loss: 0.1298
2024-05-24 23:59:07 [INFO]: Epoch 230 - training loss: 0.1891, validation loss: 0.1279
2024-05-24 23:59:07 [INFO]: Epoch 231 - training loss: 0.1893, validation loss: 0.1269
2024-05-24 23:59:08 [INFO]: Epoch 232 - training loss: 0.1916, validation loss: 0.1279
2024-05-24 23:59:08 [INFO]: Epoch 233 - training loss: 0.1896, validation loss: 0.1291
2024-05-24 23:59:08 [INFO]: Epoch 234 - training loss: 0.1880, validation loss: 0.1276
2024-05-24 23:59:09 [INFO]: Epoch 235 - training loss: 0.1882, validation loss: 0.1263
2024-05-24 23:59:09 [INFO]: Epoch 236 - training loss: 0.1876, validation loss: 0.1282
2024-05-24 23:59:09 [INFO]: Epoch 237 - training loss: 0.1893, validation loss: 0.1290
2024-05-24 23:59:10 [INFO]: Epoch 238 - training loss: 0.1920, validation loss: 0.1272
2024-05-24 23:59:10 [INFO]: Epoch 239 - training loss: 0.1880, validation loss: 0.1283
2024-05-24 23:59:10 [INFO]: Epoch 240 - training loss: 0.1881, validation loss: 0.1275
2024-05-24 23:59:10 [INFO]: Epoch 241 - training loss: 0.1874, validation loss: 0.1276
2024-05-24 23:59:11 [INFO]: Epoch 242 - training loss: 0.1878, validation loss: 0.1271
2024-05-24 23:59:11 [INFO]: Epoch 243 - training loss: 0.1868, validation loss: 0.1295
2024-05-24 23:59:11 [INFO]: Epoch 244 - training loss: 0.1887, validation loss: 0.1275
2024-05-24 23:59:12 [INFO]: Epoch 245 - training loss: 0.1869, validation loss: 0.1252
2024-05-24 23:59:12 [INFO]: Epoch 246 - training loss: 0.1895, validation loss: 0.1271
2024-05-24 23:59:12 [INFO]: Epoch 247 - training loss: 0.1875, validation loss: 0.1265
2024-05-24 23:59:13 [INFO]: Epoch 248 - training loss: 0.1849, validation loss: 0.1258
2024-05-24 23:59:13 [INFO]: Epoch 249 - training loss: 0.1867, validation loss: 0.1264
2024-05-24 23:59:13 [INFO]: Epoch 250 - training loss: 0.1870, validation loss: 0.1261
2024-05-24 23:59:14 [INFO]: Epoch 251 - training loss: 0.1857, validation loss: 0.1256
2024-05-24 23:59:14 [INFO]: Epoch 252 - training loss: 0.1853, validation loss: 0.1253
2024-05-24 23:59:14 [INFO]: Epoch 253 - training loss: 0.1845, validation loss: 0.1242
2024-05-24 23:59:15 [INFO]: Epoch 254 - training loss: 0.1845, validation loss: 0.1268
2024-05-24 23:59:15 [INFO]: Epoch 255 - training loss: 0.1881, validation loss: 0.1255
2024-05-24 23:59:15 [INFO]: Epoch 256 - training loss: 0.1849, validation loss: 0.1255
2024-05-24 23:59:15 [INFO]: Epoch 257 - training loss: 0.1852, validation loss: 0.1260
2024-05-24 23:59:16 [INFO]: Epoch 258 - training loss: 0.1846, validation loss: 0.1258
2024-05-24 23:59:16 [INFO]: Epoch 259 - training loss: 0.1843, validation loss: 0.1269
2024-05-24 23:59:16 [INFO]: Epoch 260 - training loss: 0.1854, validation loss: 0.1260
2024-05-24 23:59:17 [INFO]: Epoch 261 - training loss: 0.1859, validation loss: 0.1253
2024-05-24 23:59:17 [INFO]: Epoch 262 - training loss: 0.1834, validation loss: 0.1245
2024-05-24 23:59:17 [INFO]: Epoch 263 - training loss: 0.1822, validation loss: 0.1256
2024-05-24 23:59:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:59:17 [INFO]: Finished training. The best model is from epoch#253.
2024-05-24 23:59:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/Transformer_air_quality/20240524_T235755/Transformer.pypots
2024-05-24 23:59:17 [INFO]: Transformer on Air-Quality: MAE=0.1552, MSE=0.1117
2024-05-24 23:59:17 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/Transformer_air_quality/imputation.pkl
2024-05-24 23:59:17 [INFO]: Using the given device: cuda:0
2024-05-24 23:59:17 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/TimesNet_air_quality/20240524_T235917
2024-05-24 23:59:17 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/TimesNet_air_quality/20240524_T235917/tensorboard
2024-05-24 23:59:18 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-24 23:59:18 [INFO]: Epoch 001 - training loss: 0.2885, validation loss: 0.2644
2024-05-24 23:59:19 [INFO]: Epoch 002 - training loss: 0.2206, validation loss: 0.2311
2024-05-24 23:59:19 [INFO]: Epoch 003 - training loss: 0.1873, validation loss: 0.2186
2024-05-24 23:59:20 [INFO]: Epoch 004 - training loss: 0.1751, validation loss: 0.2169
2024-05-24 23:59:20 [INFO]: Epoch 005 - training loss: 0.2005, validation loss: 0.2057
2024-05-24 23:59:21 [INFO]: Epoch 006 - training loss: 0.1525, validation loss: 0.1984
2024-05-24 23:59:21 [INFO]: Epoch 007 - training loss: 0.1555, validation loss: 0.1912
2024-05-24 23:59:22 [INFO]: Epoch 008 - training loss: 0.1842, validation loss: 0.1882
2024-05-24 23:59:23 [INFO]: Epoch 009 - training loss: 0.1491, validation loss: 0.1811
2024-05-24 23:59:23 [INFO]: Epoch 010 - training loss: 0.1464, validation loss: 0.1750
2024-05-24 23:59:24 [INFO]: Epoch 011 - training loss: 0.1333, validation loss: 0.1758
2024-05-24 23:59:24 [INFO]: Epoch 012 - training loss: 0.1393, validation loss: 0.1697
2024-05-24 23:59:25 [INFO]: Epoch 013 - training loss: 0.1357, validation loss: 0.1662
2024-05-24 23:59:25 [INFO]: Epoch 014 - training loss: 0.1391, validation loss: 0.1644
2024-05-24 23:59:26 [INFO]: Epoch 015 - training loss: 0.1276, validation loss: 0.1646
2024-05-24 23:59:26 [INFO]: Epoch 016 - training loss: 0.1350, validation loss: 0.1635
2024-05-24 23:59:27 [INFO]: Epoch 017 - training loss: 0.1360, validation loss: 0.1619
2024-05-24 23:59:27 [INFO]: Epoch 018 - training loss: 0.1382, validation loss: 0.1650
2024-05-24 23:59:28 [INFO]: Epoch 019 - training loss: 0.1358, validation loss: 0.1652
2024-05-24 23:59:28 [INFO]: Epoch 020 - training loss: 0.1161, validation loss: 0.1574
2024-05-24 23:59:29 [INFO]: Epoch 021 - training loss: 0.1201, validation loss: 0.1605
2024-05-24 23:59:29 [INFO]: Epoch 022 - training loss: 0.1316, validation loss: 0.1524
2024-05-24 23:59:30 [INFO]: Epoch 023 - training loss: 0.1328, validation loss: 0.1534
2024-05-24 23:59:30 [INFO]: Epoch 024 - training loss: 0.1272, validation loss: 0.1556
2024-05-24 23:59:31 [INFO]: Epoch 025 - training loss: 0.1154, validation loss: 0.1511
2024-05-24 23:59:31 [INFO]: Epoch 026 - training loss: 0.1243, validation loss: 0.1522
2024-05-24 23:59:32 [INFO]: Epoch 027 - training loss: 0.1097, validation loss: 0.1573
2024-05-24 23:59:32 [INFO]: Epoch 028 - training loss: 0.1102, validation loss: 0.1517
2024-05-24 23:59:33 [INFO]: Epoch 029 - training loss: 0.1141, validation loss: 0.1538
2024-05-24 23:59:33 [INFO]: Epoch 030 - training loss: 0.1209, validation loss: 0.1574
2024-05-24 23:59:34 [INFO]: Epoch 031 - training loss: 0.1110, validation loss: 0.1565
2024-05-24 23:59:34 [INFO]: Epoch 032 - training loss: 0.1005, validation loss: 0.1589
2024-05-24 23:59:35 [INFO]: Epoch 033 - training loss: 0.1272, validation loss: 0.1538
2024-05-24 23:59:36 [INFO]: Epoch 034 - training loss: 0.1133, validation loss: 0.1514
2024-05-24 23:59:36 [INFO]: Epoch 035 - training loss: 0.1150, validation loss: 0.1504
2024-05-24 23:59:37 [INFO]: Epoch 036 - training loss: 0.1187, validation loss: 0.1493
2024-05-24 23:59:37 [INFO]: Epoch 037 - training loss: 0.1129, validation loss: 0.1472
2024-05-24 23:59:38 [INFO]: Epoch 038 - training loss: 0.1168, validation loss: 0.1478
2024-05-24 23:59:38 [INFO]: Epoch 039 - training loss: 0.1287, validation loss: 0.1535
2024-05-24 23:59:39 [INFO]: Epoch 040 - training loss: 0.1140, validation loss: 0.1488
2024-05-24 23:59:39 [INFO]: Epoch 041 - training loss: 0.1251, validation loss: 0.1514
2024-05-24 23:59:40 [INFO]: Epoch 042 - training loss: 0.1201, validation loss: 0.1449
2024-05-24 23:59:40 [INFO]: Epoch 043 - training loss: 0.1016, validation loss: 0.1523
2024-05-24 23:59:41 [INFO]: Epoch 044 - training loss: 0.1081, validation loss: 0.1455
2024-05-24 23:59:41 [INFO]: Epoch 045 - training loss: 0.1093, validation loss: 0.1443
2024-05-24 23:59:42 [INFO]: Epoch 046 - training loss: 0.1185, validation loss: 0.1426
2024-05-24 23:59:42 [INFO]: Epoch 047 - training loss: 0.0995, validation loss: 0.1441
2024-05-24 23:59:43 [INFO]: Epoch 048 - training loss: 0.1090, validation loss: 0.1436
2024-05-24 23:59:43 [INFO]: Epoch 049 - training loss: 0.1212, validation loss: 0.1432
2024-05-24 23:59:44 [INFO]: Epoch 050 - training loss: 0.0968, validation loss: 0.1478
2024-05-24 23:59:44 [INFO]: Epoch 051 - training loss: 0.0940, validation loss: 0.1423
2024-05-24 23:59:45 [INFO]: Epoch 052 - training loss: 0.1116, validation loss: 0.1510
2024-05-24 23:59:45 [INFO]: Epoch 053 - training loss: 0.1240, validation loss: 0.1506
2024-05-24 23:59:46 [INFO]: Epoch 054 - training loss: 0.1264, validation loss: 0.1582
2024-05-24 23:59:46 [INFO]: Epoch 055 - training loss: 0.1170, validation loss: 0.1405
2024-05-24 23:59:47 [INFO]: Epoch 056 - training loss: 0.0922, validation loss: 0.1389
2024-05-24 23:59:47 [INFO]: Epoch 057 - training loss: 0.1060, validation loss: 0.1368
2024-05-24 23:59:48 [INFO]: Epoch 058 - training loss: 0.0989, validation loss: 0.1395
2024-05-24 23:59:48 [INFO]: Epoch 059 - training loss: 0.0920, validation loss: 0.1387
2024-05-24 23:59:49 [INFO]: Epoch 060 - training loss: 0.1032, validation loss: 0.1362
2024-05-24 23:59:50 [INFO]: Epoch 061 - training loss: 0.1051, validation loss: 0.1378
2024-05-24 23:59:50 [INFO]: Epoch 062 - training loss: 0.0972, validation loss: 0.1351
2024-05-24 23:59:51 [INFO]: Epoch 063 - training loss: 0.1055, validation loss: 0.1344
2024-05-24 23:59:51 [INFO]: Epoch 064 - training loss: 0.1031, validation loss: 0.1345
2024-05-24 23:59:52 [INFO]: Epoch 065 - training loss: 0.0961, validation loss: 0.1338
2024-05-24 23:59:52 [INFO]: Epoch 066 - training loss: 0.1012, validation loss: 0.1306
2024-05-24 23:59:53 [INFO]: Epoch 067 - training loss: 0.0903, validation loss: 0.1348
2024-05-24 23:59:53 [INFO]: Epoch 068 - training loss: 0.0961, validation loss: 0.1326
2024-05-24 23:59:54 [INFO]: Epoch 069 - training loss: 0.0976, validation loss: 0.1325
2024-05-24 23:59:54 [INFO]: Epoch 070 - training loss: 0.0996, validation loss: 0.1333
2024-05-24 23:59:55 [INFO]: Epoch 071 - training loss: 0.1076, validation loss: 0.1369
2024-05-24 23:59:55 [INFO]: Epoch 072 - training loss: 0.0886, validation loss: 0.1414
2024-05-24 23:59:56 [INFO]: Epoch 073 - training loss: 0.0979, validation loss: 0.1321
2024-05-24 23:59:56 [INFO]: Epoch 074 - training loss: 0.0921, validation loss: 0.1356
2024-05-24 23:59:57 [INFO]: Epoch 075 - training loss: 0.1004, validation loss: 0.1328
2024-05-24 23:59:57 [INFO]: Epoch 076 - training loss: 0.1027, validation loss: 0.1323
2024-05-24 23:59:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:59:57 [INFO]: Finished training. The best model is from epoch#66.
2024-05-24 23:59:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/TimesNet_air_quality/20240524_T235917/TimesNet.pypots
2024-05-24 23:59:58 [INFO]: TimesNet on Air-Quality: MAE=0.1528, MSE=0.1200
2024-05-24 23:59:58 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/TimesNet_air_quality/imputation.pkl
2024-05-24 23:59:58 [INFO]: Using the given device: cuda:0
2024-05-24 23:59:58 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958
2024-05-24 23:59:58 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/tensorboard
2024-05-24 23:59:58 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 00:00:14 [INFO]: Epoch 001 - training loss: 0.4881, validation loss: 0.3627
2024-05-25 00:00:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch1_loss0.36271890699863435.pypots
2024-05-25 00:00:31 [INFO]: Epoch 002 - training loss: 0.2923, validation loss: 0.3007
2024-05-25 00:00:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch2_loss0.3007428050041199.pypots
2024-05-25 00:00:48 [INFO]: Epoch 003 - training loss: 0.2822, validation loss: 0.2667
2024-05-25 00:00:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch3_loss0.2666668012738228.pypots
2024-05-25 00:01:05 [INFO]: Epoch 004 - training loss: 0.2250, validation loss: 0.2435
2024-05-25 00:01:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch4_loss0.24347767978906631.pypots
2024-05-25 00:01:21 [INFO]: Epoch 005 - training loss: 0.2262, validation loss: 0.2161
2024-05-25 00:01:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch5_loss0.2160935953259468.pypots
2024-05-25 00:01:38 [INFO]: Epoch 006 - training loss: 0.2130, validation loss: 0.1870
2024-05-25 00:01:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch6_loss0.18700026273727416.pypots
2024-05-25 00:01:55 [INFO]: Epoch 007 - training loss: 0.2108, validation loss: 0.1907
2024-05-25 00:01:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch7_loss0.19072420299053192.pypots
2024-05-25 00:02:12 [INFO]: Epoch 008 - training loss: 0.2062, validation loss: 0.1733
2024-05-25 00:02:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch8_loss0.17328387647867202.pypots
2024-05-25 00:02:28 [INFO]: Epoch 009 - training loss: 0.1840, validation loss: 0.1719
2024-05-25 00:02:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch9_loss0.17191636115312575.pypots
2024-05-25 00:02:45 [INFO]: Epoch 010 - training loss: 0.1685, validation loss: 0.1591
2024-05-25 00:02:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch10_loss0.15907712876796723.pypots
2024-05-25 00:03:02 [INFO]: Epoch 011 - training loss: 0.1746, validation loss: 0.1565
2024-05-25 00:03:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch11_loss0.15646713376045226.pypots
2024-05-25 00:03:19 [INFO]: Epoch 012 - training loss: 0.1796, validation loss: 0.1563
2024-05-25 00:03:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch12_loss0.15633586049079895.pypots
2024-05-25 00:03:35 [INFO]: Epoch 013 - training loss: 0.1654, validation loss: 0.1541
2024-05-25 00:03:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch13_loss0.1540975421667099.pypots
2024-05-25 00:03:52 [INFO]: Epoch 014 - training loss: 0.1642, validation loss: 0.1455
2024-05-25 00:03:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch14_loss0.1454879641532898.pypots
2024-05-25 00:04:09 [INFO]: Epoch 015 - training loss: 0.1501, validation loss: 0.1447
2024-05-25 00:04:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch15_loss0.14470033794641496.pypots
2024-05-25 00:04:26 [INFO]: Epoch 016 - training loss: 0.1761, validation loss: 0.1481
2024-05-25 00:04:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch16_loss0.14808857440948486.pypots
2024-05-25 00:04:43 [INFO]: Epoch 017 - training loss: 0.1463, validation loss: 0.1406
2024-05-25 00:04:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch17_loss0.14058969020843506.pypots
2024-05-25 00:04:59 [INFO]: Epoch 018 - training loss: 0.1644, validation loss: 0.1436
2024-05-25 00:04:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch18_loss0.143632622808218.pypots
2024-05-25 00:05:16 [INFO]: Epoch 019 - training loss: 0.1557, validation loss: 0.1451
2024-05-25 00:05:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch19_loss0.1451410472393036.pypots
2024-05-25 00:05:33 [INFO]: Epoch 020 - training loss: 0.1622, validation loss: 0.1460
2024-05-25 00:05:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch20_loss0.14600010812282563.pypots
2024-05-25 00:05:50 [INFO]: Epoch 021 - training loss: 0.1687, validation loss: 0.1451
2024-05-25 00:05:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch21_loss0.14508367329835892.pypots
2024-05-25 00:06:06 [INFO]: Epoch 022 - training loss: 0.1448, validation loss: 0.1336
2024-05-25 00:06:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch22_loss0.13362717255949974.pypots
2024-05-25 00:06:23 [INFO]: Epoch 023 - training loss: 0.1522, validation loss: 0.1352
2024-05-25 00:06:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch23_loss0.13521433100104333.pypots
2024-05-25 00:06:40 [INFO]: Epoch 024 - training loss: 0.1451, validation loss: 0.1424
2024-05-25 00:06:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch24_loss0.14242181107401847.pypots
2024-05-25 00:06:57 [INFO]: Epoch 025 - training loss: 0.1497, validation loss: 0.1344
2024-05-25 00:06:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch25_loss0.134437957406044.pypots
2024-05-25 00:07:13 [INFO]: Epoch 026 - training loss: 0.1427, validation loss: 0.1380
2024-05-25 00:07:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch26_loss0.13798046708106995.pypots
2024-05-25 00:07:30 [INFO]: Epoch 027 - training loss: 0.1513, validation loss: 0.1297
2024-05-25 00:07:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch27_loss0.12969768792390823.pypots
2024-05-25 00:07:47 [INFO]: Epoch 028 - training loss: 0.1382, validation loss: 0.1299
2024-05-25 00:07:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch28_loss0.12991671934723853.pypots
2024-05-25 00:08:04 [INFO]: Epoch 029 - training loss: 0.1493, validation loss: 0.1384
2024-05-25 00:08:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch29_loss0.13844809159636498.pypots
2024-05-25 00:08:20 [INFO]: Epoch 030 - training loss: 0.1358, validation loss: 0.1277
2024-05-25 00:08:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch30_loss0.127719047665596.pypots
2024-05-25 00:08:37 [INFO]: Epoch 031 - training loss: 0.1268, validation loss: 0.1297
2024-05-25 00:08:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch31_loss0.12967221364378928.pypots
2024-05-25 00:08:54 [INFO]: Epoch 032 - training loss: 0.1499, validation loss: 0.1267
2024-05-25 00:08:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch32_loss0.12666421085596086.pypots
2024-05-25 00:09:11 [INFO]: Epoch 033 - training loss: 0.1497, validation loss: 0.1359
2024-05-25 00:09:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch33_loss0.135898170620203.pypots
2024-05-25 00:09:27 [INFO]: Epoch 034 - training loss: 0.1440, validation loss: 0.1250
2024-05-25 00:09:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch34_loss0.12501829862594604.pypots
2024-05-25 00:09:44 [INFO]: Epoch 035 - training loss: 0.1345, validation loss: 0.1217
2024-05-25 00:09:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch35_loss0.12170185446739197.pypots
2024-05-25 00:10:01 [INFO]: Epoch 036 - training loss: 0.1348, validation loss: 0.1206
2024-05-25 00:10:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch36_loss0.1205606371164322.pypots
2024-05-25 00:10:18 [INFO]: Epoch 037 - training loss: 0.1397, validation loss: 0.1215
2024-05-25 00:10:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch37_loss0.12152341231703759.pypots
2024-05-25 00:10:34 [INFO]: Epoch 038 - training loss: 0.1254, validation loss: 0.1196
2024-05-25 00:10:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch38_loss0.11964728236198426.pypots
2024-05-25 00:10:51 [INFO]: Epoch 039 - training loss: 0.1439, validation loss: 0.1206
2024-05-25 00:10:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch39_loss0.1206446148455143.pypots
2024-05-25 00:11:08 [INFO]: Epoch 040 - training loss: 0.1321, validation loss: 0.1229
2024-05-25 00:11:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch40_loss0.12290630042552948.pypots
2024-05-25 00:11:25 [INFO]: Epoch 041 - training loss: 0.1320, validation loss: 0.1233
2024-05-25 00:11:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch41_loss0.12333914935588837.pypots
2024-05-25 00:11:41 [INFO]: Epoch 042 - training loss: 0.1292, validation loss: 0.1206
2024-05-25 00:11:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch42_loss0.12055541947484016.pypots
2024-05-25 00:11:58 [INFO]: Epoch 043 - training loss: 0.1372, validation loss: 0.1159
2024-05-25 00:11:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch43_loss0.11587802469730377.pypots
2024-05-25 00:12:15 [INFO]: Epoch 044 - training loss: 0.1283, validation loss: 0.1154
2024-05-25 00:12:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch44_loss0.11540955156087876.pypots
2024-05-25 00:12:32 [INFO]: Epoch 045 - training loss: 0.1307, validation loss: 0.1133
2024-05-25 00:12:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch45_loss0.11331648603081704.pypots
2024-05-25 00:12:48 [INFO]: Epoch 046 - training loss: 0.1273, validation loss: 0.1240
2024-05-25 00:12:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch46_loss0.12404113858938218.pypots
2024-05-25 00:13:05 [INFO]: Epoch 047 - training loss: 0.1282, validation loss: 0.1163
2024-05-25 00:13:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch47_loss0.11632771417498589.pypots
2024-05-25 00:13:22 [INFO]: Epoch 048 - training loss: 0.1149, validation loss: 0.1136
2024-05-25 00:13:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch48_loss0.1136472463607788.pypots
2024-05-25 00:13:39 [INFO]: Epoch 049 - training loss: 0.1167, validation loss: 0.1146
2024-05-25 00:13:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch49_loss0.11457846611738205.pypots
2024-05-25 00:13:55 [INFO]: Epoch 050 - training loss: 0.1302, validation loss: 0.1134
2024-05-25 00:13:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch50_loss0.11339296549558639.pypots
2024-05-25 00:14:12 [INFO]: Epoch 051 - training loss: 0.1353, validation loss: 0.1166
2024-05-25 00:14:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch51_loss0.11657835841178894.pypots
2024-05-25 00:14:29 [INFO]: Epoch 052 - training loss: 0.1269, validation loss: 0.1119
2024-05-25 00:14:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch52_loss0.11194256246089936.pypots
2024-05-25 00:14:46 [INFO]: Epoch 053 - training loss: 0.1255, validation loss: 0.1177
2024-05-25 00:14:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch53_loss0.11767702102661133.pypots
2024-05-25 00:15:02 [INFO]: Epoch 054 - training loss: 0.1138, validation loss: 0.1127
2024-05-25 00:15:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch54_loss0.11269679963588715.pypots
2024-05-25 00:15:19 [INFO]: Epoch 055 - training loss: 0.1216, validation loss: 0.1110
2024-05-25 00:15:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch55_loss0.1110429547727108.pypots
2024-05-25 00:15:36 [INFO]: Epoch 056 - training loss: 0.1173, validation loss: 0.1123
2024-05-25 00:15:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch56_loss0.11230186074972152.pypots
2024-05-25 00:15:53 [INFO]: Epoch 057 - training loss: 0.1290, validation loss: 0.1084
2024-05-25 00:15:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch57_loss0.10835674032568932.pypots
2024-05-25 00:16:09 [INFO]: Epoch 058 - training loss: 0.1240, validation loss: 0.1143
2024-05-25 00:16:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch58_loss0.1142616756260395.pypots
2024-05-25 00:16:26 [INFO]: Epoch 059 - training loss: 0.1242, validation loss: 0.1122
2024-05-25 00:16:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch59_loss0.11224517226219177.pypots
2024-05-25 00:16:43 [INFO]: Epoch 060 - training loss: 0.1240, validation loss: 0.1133
2024-05-25 00:16:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch60_loss0.11329044699668885.pypots
2024-05-25 00:17:00 [INFO]: Epoch 061 - training loss: 0.1189, validation loss: 0.1085
2024-05-25 00:17:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch61_loss0.10851585045456887.pypots
2024-05-25 00:17:16 [INFO]: Epoch 062 - training loss: 0.1156, validation loss: 0.1078
2024-05-25 00:17:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch62_loss0.1077843353152275.pypots
2024-05-25 00:17:33 [INFO]: Epoch 063 - training loss: 0.1285, validation loss: 0.1078
2024-05-25 00:17:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch63_loss0.10775926858186721.pypots
2024-05-25 00:17:50 [INFO]: Epoch 064 - training loss: 0.1184, validation loss: 0.1090
2024-05-25 00:17:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch64_loss0.10897524058818817.pypots
2024-05-25 00:18:06 [INFO]: Epoch 065 - training loss: 0.1177, validation loss: 0.1103
2024-05-25 00:18:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch65_loss0.11030154898762703.pypots
2024-05-25 00:18:23 [INFO]: Epoch 066 - training loss: 0.1296, validation loss: 0.1058
2024-05-25 00:18:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch66_loss0.1058406375348568.pypots
2024-05-25 00:18:40 [INFO]: Epoch 067 - training loss: 0.1238, validation loss: 0.1126
2024-05-25 00:18:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch67_loss0.1126412533223629.pypots
2024-05-25 00:18:57 [INFO]: Epoch 068 - training loss: 0.1295, validation loss: 0.1129
2024-05-25 00:18:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch68_loss0.11286236941814423.pypots
2024-05-25 00:19:13 [INFO]: Epoch 069 - training loss: 0.1187, validation loss: 0.1085
2024-05-25 00:19:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch69_loss0.10852937698364258.pypots
2024-05-25 00:19:30 [INFO]: Epoch 070 - training loss: 0.1057, validation loss: 0.1128
2024-05-25 00:19:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch70_loss0.1128353051841259.pypots
2024-05-25 00:19:47 [INFO]: Epoch 071 - training loss: 0.1414, validation loss: 0.1065
2024-05-25 00:19:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch71_loss0.10646677389740944.pypots
2024-05-25 00:20:04 [INFO]: Epoch 072 - training loss: 0.1235, validation loss: 0.1076
2024-05-25 00:20:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch72_loss0.10756781697273254.pypots
2024-05-25 00:20:20 [INFO]: Epoch 073 - training loss: 0.1103, validation loss: 0.1073
2024-05-25 00:20:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch73_loss0.10732714235782623.pypots
2024-05-25 00:20:37 [INFO]: Epoch 074 - training loss: 0.1285, validation loss: 0.1080
2024-05-25 00:20:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch74_loss0.10797584503889084.pypots
2024-05-25 00:20:54 [INFO]: Epoch 075 - training loss: 0.1094, validation loss: 0.1067
2024-05-25 00:20:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch75_loss0.10670394748449326.pypots
2024-05-25 00:21:11 [INFO]: Epoch 076 - training loss: 0.1093, validation loss: 0.1067
2024-05-25 00:21:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI_epoch76_loss0.10669080317020416.pypots
2024-05-25 00:21:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:21:11 [INFO]: Finished training. The best model is from epoch#66.
2024-05-25 00:21:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240524_T235958/CSDI.pypots
2024-05-25 00:23:31 [INFO]: CSDI on Air-Quality: MAE=0.1087, MSE=0.2423
2024-05-25 00:23:31 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/CSDI_air_quality/imputation.pkl
2024-05-25 00:23:31 [INFO]: Using the given device: cuda:0
2024-05-25 00:23:31 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/GPVAE_air_quality/20240525_T002331
2024-05-25 00:23:31 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/GPVAE_air_quality/20240525_T002331/tensorboard
2024-05-25 00:23:31 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 00:23:31 [INFO]: Epoch 001 - training loss: 64483.0731, validation loss: 0.6617
2024-05-25 00:23:31 [INFO]: Epoch 002 - training loss: 42104.5935, validation loss: 0.5647
2024-05-25 00:23:32 [INFO]: Epoch 003 - training loss: 41736.8001, validation loss: 0.5127
2024-05-25 00:23:32 [INFO]: Epoch 004 - training loss: 41616.4891, validation loss: 0.4792
2024-05-25 00:23:32 [INFO]: Epoch 005 - training loss: 41544.0527, validation loss: 0.4916
2024-05-25 00:23:32 [INFO]: Epoch 006 - training loss: 41525.8691, validation loss: 0.4107
2024-05-25 00:23:33 [INFO]: Epoch 007 - training loss: 41465.1481, validation loss: 0.3868
2024-05-25 00:23:33 [INFO]: Epoch 008 - training loss: 41418.6227, validation loss: 0.3518
2024-05-25 00:23:33 [INFO]: Epoch 009 - training loss: 41404.1735, validation loss: 0.3384
2024-05-25 00:23:34 [INFO]: Epoch 010 - training loss: 41393.1872, validation loss: 0.3919
2024-05-25 00:23:34 [INFO]: Epoch 011 - training loss: 41378.7104, validation loss: 0.3280
2024-05-25 00:23:34 [INFO]: Epoch 012 - training loss: 41340.3817, validation loss: 0.3404
2024-05-25 00:23:35 [INFO]: Epoch 013 - training loss: 41332.0681, validation loss: 0.3061
2024-05-25 00:23:35 [INFO]: Epoch 014 - training loss: 41325.3137, validation loss: 0.3271
2024-05-25 00:23:35 [INFO]: Epoch 015 - training loss: 41321.6020, validation loss: 0.3070
2024-05-25 00:23:36 [INFO]: Epoch 016 - training loss: 41295.2092, validation loss: 0.3048
2024-05-25 00:23:36 [INFO]: Epoch 017 - training loss: 41289.5126, validation loss: 0.3095
2024-05-25 00:23:36 [INFO]: Epoch 018 - training loss: 41280.1516, validation loss: 0.2762
2024-05-25 00:23:37 [INFO]: Epoch 019 - training loss: 41262.5315, validation loss: 0.2699
2024-05-25 00:23:37 [INFO]: Epoch 020 - training loss: 41251.8290, validation loss: 0.2812
2024-05-25 00:23:37 [INFO]: Epoch 021 - training loss: 41254.2125, validation loss: 0.2809
2024-05-25 00:23:37 [INFO]: Epoch 022 - training loss: 41254.0258, validation loss: 0.2709
2024-05-25 00:23:38 [INFO]: Epoch 023 - training loss: 41242.6136, validation loss: 0.2911
2024-05-25 00:23:38 [INFO]: Epoch 024 - training loss: 41249.9540, validation loss: 0.2788
2024-05-25 00:23:38 [INFO]: Epoch 025 - training loss: 41256.8549, validation loss: 0.2745
2024-05-25 00:23:39 [INFO]: Epoch 026 - training loss: 41248.6806, validation loss: 0.2663
2024-05-25 00:23:39 [INFO]: Epoch 027 - training loss: 41239.4073, validation loss: 0.2553
2024-05-25 00:23:39 [INFO]: Epoch 028 - training loss: 41226.8520, validation loss: 0.2580
2024-05-25 00:23:40 [INFO]: Epoch 029 - training loss: 41232.6165, validation loss: 0.2703
2024-05-25 00:23:40 [INFO]: Epoch 030 - training loss: 41234.4465, validation loss: 0.2744
2024-05-25 00:23:40 [INFO]: Epoch 031 - training loss: 41245.3290, validation loss: 0.3044
2024-05-25 00:23:41 [INFO]: Epoch 032 - training loss: 41314.6515, validation loss: 0.2872
2024-05-25 00:23:41 [INFO]: Epoch 033 - training loss: 41265.0032, validation loss: 0.2836
2024-05-25 00:23:41 [INFO]: Epoch 034 - training loss: 41233.3821, validation loss: 0.2758
2024-05-25 00:23:42 [INFO]: Epoch 035 - training loss: 41213.4754, validation loss: 0.2432
2024-05-25 00:23:42 [INFO]: Epoch 036 - training loss: 41197.8764, validation loss: 0.2370
2024-05-25 00:23:42 [INFO]: Epoch 037 - training loss: 41191.7159, validation loss: 0.2368
2024-05-25 00:23:42 [INFO]: Epoch 038 - training loss: 41199.8840, validation loss: 0.2375
2024-05-25 00:23:43 [INFO]: Epoch 039 - training loss: 41214.6910, validation loss: 0.2379
2024-05-25 00:23:43 [INFO]: Epoch 040 - training loss: 41190.8150, validation loss: 0.2367
2024-05-25 00:23:43 [INFO]: Epoch 041 - training loss: 41178.1688, validation loss: 0.2309
2024-05-25 00:23:44 [INFO]: Epoch 042 - training loss: 41179.8355, validation loss: 0.2261
2024-05-25 00:23:44 [INFO]: Epoch 043 - training loss: 41171.9398, validation loss: 0.2236
2024-05-25 00:23:44 [INFO]: Epoch 044 - training loss: 41179.9148, validation loss: 0.2270
2024-05-25 00:23:45 [INFO]: Epoch 045 - training loss: 41170.5158, validation loss: 0.2310
2024-05-25 00:23:45 [INFO]: Epoch 046 - training loss: 41175.5667, validation loss: 0.2223
2024-05-25 00:23:45 [INFO]: Epoch 047 - training loss: 41173.0784, validation loss: 0.2265
2024-05-25 00:23:46 [INFO]: Epoch 048 - training loss: 41190.5817, validation loss: 0.2374
2024-05-25 00:23:46 [INFO]: Epoch 049 - training loss: 41221.8181, validation loss: 0.2598
2024-05-25 00:23:46 [INFO]: Epoch 050 - training loss: 41197.5130, validation loss: 0.2297
2024-05-25 00:23:47 [INFO]: Epoch 051 - training loss: 41191.4392, validation loss: 0.2403
2024-05-25 00:23:47 [INFO]: Epoch 052 - training loss: 41183.2674, validation loss: 0.2401
2024-05-25 00:23:47 [INFO]: Epoch 053 - training loss: 41192.0078, validation loss: 0.2408
2024-05-25 00:23:47 [INFO]: Epoch 054 - training loss: 41190.0706, validation loss: 0.2665
2024-05-25 00:23:48 [INFO]: Epoch 055 - training loss: 41241.2053, validation loss: 0.2407
2024-05-25 00:23:48 [INFO]: Epoch 056 - training loss: 41179.4897, validation loss: 0.2231
2024-05-25 00:23:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:23:48 [INFO]: Finished training. The best model is from epoch#46.
2024-05-25 00:23:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/GPVAE_air_quality/20240525_T002331/GPVAE.pypots
2024-05-25 00:23:48 [INFO]: GP-VAE on Air-Quality: MAE=0.2755, MSE=0.2145
2024-05-25 00:23:48 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/GPVAE_air_quality/imputation.pkl
2024-05-25 00:23:48 [INFO]: Using the given device: cuda:0
2024-05-25 00:23:48 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/USGAN_air_quality/20240525_T002348
2024-05-25 00:23:48 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/USGAN_air_quality/20240525_T002348/tensorboard
2024-05-25 00:23:48 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 00:23:53 [INFO]: Epoch 001 - generator training loss: 0.5977, discriminator training loss: 0.2770, validation loss: 0.5028
2024-05-25 00:23:57 [INFO]: Epoch 002 - generator training loss: 0.2853, discriminator training loss: 0.0665, validation loss: 0.3803
2024-05-25 00:24:01 [INFO]: Epoch 003 - generator training loss: 0.2122, discriminator training loss: 0.0627, validation loss: 0.3132
2024-05-25 00:24:05 [INFO]: Epoch 004 - generator training loss: 0.1742, discriminator training loss: 0.0619, validation loss: 0.2731
2024-05-25 00:24:09 [INFO]: Epoch 005 - generator training loss: 0.1503, discriminator training loss: 0.0611, validation loss: 0.2466
2024-05-25 00:24:13 [INFO]: Epoch 006 - generator training loss: 0.1347, discriminator training loss: 0.0611, validation loss: 0.2275
2024-05-25 00:24:17 [INFO]: Epoch 007 - generator training loss: 0.1203, discriminator training loss: 0.0601, validation loss: 0.2124
2024-05-25 00:24:21 [INFO]: Epoch 008 - generator training loss: 0.1099, discriminator training loss: 0.0605, validation loss: 0.2014
2024-05-25 00:24:25 [INFO]: Epoch 009 - generator training loss: 0.1037, discriminator training loss: 0.0588, validation loss: 0.1927
2024-05-25 00:24:29 [INFO]: Epoch 010 - generator training loss: 0.0975, discriminator training loss: 0.0581, validation loss: 0.1851
2024-05-25 00:24:33 [INFO]: Epoch 011 - generator training loss: 0.0895, discriminator training loss: 0.0571, validation loss: 0.1784
2024-05-25 00:24:37 [INFO]: Epoch 012 - generator training loss: 0.0867, discriminator training loss: 0.0559, validation loss: 0.1734
2024-05-25 00:24:41 [INFO]: Epoch 013 - generator training loss: 0.0849, discriminator training loss: 0.0548, validation loss: 0.1682
2024-05-25 00:24:45 [INFO]: Epoch 014 - generator training loss: 0.0796, discriminator training loss: 0.0533, validation loss: 0.1642
2024-05-25 00:24:49 [INFO]: Epoch 015 - generator training loss: 0.0777, discriminator training loss: 0.0512, validation loss: 0.1606
2024-05-25 00:24:52 [INFO]: Epoch 016 - generator training loss: 0.0748, discriminator training loss: 0.0505, validation loss: 0.1567
2024-05-25 00:24:56 [INFO]: Epoch 017 - generator training loss: 0.0741, discriminator training loss: 0.0487, validation loss: 0.1535
2024-05-25 00:25:01 [INFO]: Epoch 018 - generator training loss: 0.0734, discriminator training loss: 0.0472, validation loss: 0.1503
2024-05-25 00:25:05 [INFO]: Epoch 019 - generator training loss: 0.0703, discriminator training loss: 0.0460, validation loss: 0.1471
2024-05-25 00:25:08 [INFO]: Epoch 020 - generator training loss: 0.0682, discriminator training loss: 0.0450, validation loss: 0.1447
2024-05-25 00:25:12 [INFO]: Epoch 021 - generator training loss: 0.0668, discriminator training loss: 0.0445, validation loss: 0.1429
2024-05-25 00:25:16 [INFO]: Epoch 022 - generator training loss: 0.0647, discriminator training loss: 0.0440, validation loss: 0.1405
2024-05-25 00:25:20 [INFO]: Epoch 023 - generator training loss: 0.0636, discriminator training loss: 0.0437, validation loss: 0.1382
2024-05-25 00:25:24 [INFO]: Epoch 024 - generator training loss: 0.0625, discriminator training loss: 0.0424, validation loss: 0.1362
2024-05-25 00:25:28 [INFO]: Epoch 025 - generator training loss: 0.0611, discriminator training loss: 0.0421, validation loss: 0.1345
2024-05-25 00:25:32 [INFO]: Epoch 026 - generator training loss: 0.0626, discriminator training loss: 0.0407, validation loss: 0.1328
2024-05-25 00:25:36 [INFO]: Epoch 027 - generator training loss: 0.0606, discriminator training loss: 0.0400, validation loss: 0.1318
2024-05-25 00:25:40 [INFO]: Epoch 028 - generator training loss: 0.0594, discriminator training loss: 0.0392, validation loss: 0.1304
2024-05-25 00:25:44 [INFO]: Epoch 029 - generator training loss: 0.0588, discriminator training loss: 0.0385, validation loss: 0.1287
2024-05-25 00:25:48 [INFO]: Epoch 030 - generator training loss: 0.0576, discriminator training loss: 0.0376, validation loss: 0.1277
2024-05-25 00:25:52 [INFO]: Epoch 031 - generator training loss: 0.0570, discriminator training loss: 0.0368, validation loss: 0.1263
2024-05-25 00:25:56 [INFO]: Epoch 032 - generator training loss: 0.0567, discriminator training loss: 0.0360, validation loss: 0.1253
2024-05-25 00:26:00 [INFO]: Epoch 033 - generator training loss: 0.0567, discriminator training loss: 0.0353, validation loss: 0.1240
2024-05-25 00:26:04 [INFO]: Epoch 034 - generator training loss: 0.0570, discriminator training loss: 0.0342, validation loss: 0.1231
2024-05-25 00:26:08 [INFO]: Epoch 035 - generator training loss: 0.0554, discriminator training loss: 0.0337, validation loss: 0.1224
2024-05-25 00:26:12 [INFO]: Epoch 036 - generator training loss: 0.0546, discriminator training loss: 0.0326, validation loss: 0.1218
2024-05-25 00:26:16 [INFO]: Epoch 037 - generator training loss: 0.0540, discriminator training loss: 0.0322, validation loss: 0.1206
2024-05-25 00:26:20 [INFO]: Epoch 038 - generator training loss: 0.0531, discriminator training loss: 0.0317, validation loss: 0.1195
2024-05-25 00:26:24 [INFO]: Epoch 039 - generator training loss: 0.0532, discriminator training loss: 0.0308, validation loss: 0.1185
2024-05-25 00:26:28 [INFO]: Epoch 040 - generator training loss: 0.0522, discriminator training loss: 0.0305, validation loss: 0.1173
2024-05-25 00:26:32 [INFO]: Epoch 041 - generator training loss: 0.0516, discriminator training loss: 0.0297, validation loss: 0.1170
2024-05-25 00:26:36 [INFO]: Epoch 042 - generator training loss: 0.0517, discriminator training loss: 0.0293, validation loss: 0.1167
2024-05-25 00:26:40 [INFO]: Epoch 043 - generator training loss: 0.0509, discriminator training loss: 0.0289, validation loss: 0.1157
2024-05-25 00:26:44 [INFO]: Epoch 044 - generator training loss: 0.0507, discriminator training loss: 0.0280, validation loss: 0.1141
2024-05-25 00:26:48 [INFO]: Epoch 045 - generator training loss: 0.0508, discriminator training loss: 0.0274, validation loss: 0.1142
2024-05-25 00:26:52 [INFO]: Epoch 046 - generator training loss: 0.0517, discriminator training loss: 0.0267, validation loss: 0.1133
2024-05-25 00:26:56 [INFO]: Epoch 047 - generator training loss: 0.0495, discriminator training loss: 0.0266, validation loss: 0.1128
2024-05-25 00:27:00 [INFO]: Epoch 048 - generator training loss: 0.0487, discriminator training loss: 0.0261, validation loss: 0.1117
2024-05-25 00:27:04 [INFO]: Epoch 049 - generator training loss: 0.0490, discriminator training loss: 0.0256, validation loss: 0.1115
2024-05-25 00:27:08 [INFO]: Epoch 050 - generator training loss: 0.0481, discriminator training loss: 0.0253, validation loss: 0.1116
2024-05-25 00:27:12 [INFO]: Epoch 051 - generator training loss: 0.0475, discriminator training loss: 0.0247, validation loss: 0.1099
2024-05-25 00:27:16 [INFO]: Epoch 052 - generator training loss: 0.0471, discriminator training loss: 0.0246, validation loss: 0.1097
2024-05-25 00:27:20 [INFO]: Epoch 053 - generator training loss: 0.0463, discriminator training loss: 0.0244, validation loss: 0.1089
2024-05-25 00:27:24 [INFO]: Epoch 054 - generator training loss: 0.0461, discriminator training loss: 0.0237, validation loss: 0.1086
2024-05-25 00:27:27 [INFO]: Epoch 055 - generator training loss: 0.0463, discriminator training loss: 0.0235, validation loss: 0.1083
2024-05-25 00:27:31 [INFO]: Epoch 056 - generator training loss: 0.0460, discriminator training loss: 0.0230, validation loss: 0.1078
2024-05-25 00:27:35 [INFO]: Epoch 057 - generator training loss: 0.0446, discriminator training loss: 0.0228, validation loss: 0.1059
2024-05-25 00:27:39 [INFO]: Epoch 058 - generator training loss: 0.0435, discriminator training loss: 0.0223, validation loss: 0.1048
2024-05-25 00:27:43 [INFO]: Epoch 059 - generator training loss: 0.0432, discriminator training loss: 0.0224, validation loss: 0.1044
2024-05-25 00:27:47 [INFO]: Epoch 060 - generator training loss: 0.0430, discriminator training loss: 0.0217, validation loss: 0.1043
2024-05-25 00:27:51 [INFO]: Epoch 061 - generator training loss: 0.0424, discriminator training loss: 0.0214, validation loss: 0.1039
2024-05-25 00:27:55 [INFO]: Epoch 062 - generator training loss: 0.0425, discriminator training loss: 0.0212, validation loss: 0.1037
2024-05-25 00:28:00 [INFO]: Epoch 063 - generator training loss: 0.0416, discriminator training loss: 0.0210, validation loss: 0.1032
2024-05-25 00:28:04 [INFO]: Epoch 064 - generator training loss: 0.0413, discriminator training loss: 0.0206, validation loss: 0.1030
2024-05-25 00:28:08 [INFO]: Epoch 065 - generator training loss: 0.0410, discriminator training loss: 0.0205, validation loss: 0.1023
2024-05-25 00:28:12 [INFO]: Epoch 066 - generator training loss: 0.0407, discriminator training loss: 0.0202, validation loss: 0.1025
2024-05-25 00:28:16 [INFO]: Epoch 067 - generator training loss: 0.0405, discriminator training loss: 0.0200, validation loss: 0.1018
2024-05-25 00:28:20 [INFO]: Epoch 068 - generator training loss: 0.0405, discriminator training loss: 0.0197, validation loss: 0.1014
2024-05-25 00:28:24 [INFO]: Epoch 069 - generator training loss: 0.0400, discriminator training loss: 0.0195, validation loss: 0.1015
2024-05-25 00:28:28 [INFO]: Epoch 070 - generator training loss: 0.0398, discriminator training loss: 0.0195, validation loss: 0.1011
2024-05-25 00:28:32 [INFO]: Epoch 071 - generator training loss: 0.0397, discriminator training loss: 0.0192, validation loss: 0.1015
2024-05-25 00:28:36 [INFO]: Epoch 072 - generator training loss: 0.0394, discriminator training loss: 0.0188, validation loss: 0.1002
2024-05-25 00:28:40 [INFO]: Epoch 073 - generator training loss: 0.0388, discriminator training loss: 0.0188, validation loss: 0.1006
2024-05-25 00:28:44 [INFO]: Epoch 074 - generator training loss: 0.0390, discriminator training loss: 0.0188, validation loss: 0.1001
2024-05-25 00:28:48 [INFO]: Epoch 075 - generator training loss: 0.0386, discriminator training loss: 0.0184, validation loss: 0.1002
2024-05-25 00:28:51 [INFO]: Epoch 076 - generator training loss: 0.0382, discriminator training loss: 0.0184, validation loss: 0.0989
2024-05-25 00:28:55 [INFO]: Epoch 077 - generator training loss: 0.0403, discriminator training loss: 0.0179, validation loss: 0.1000
2024-05-25 00:28:59 [INFO]: Epoch 078 - generator training loss: 0.0383, discriminator training loss: 0.0179, validation loss: 0.0992
2024-05-25 00:29:03 [INFO]: Epoch 079 - generator training loss: 0.0378, discriminator training loss: 0.0176, validation loss: 0.0993
2024-05-25 00:29:07 [INFO]: Epoch 080 - generator training loss: 0.0381, discriminator training loss: 0.0175, validation loss: 0.0992
2024-05-25 00:29:11 [INFO]: Epoch 081 - generator training loss: 0.0375, discriminator training loss: 0.0173, validation loss: 0.0989
2024-05-25 00:29:15 [INFO]: Epoch 082 - generator training loss: 0.0376, discriminator training loss: 0.0171, validation loss: 0.0991
2024-05-25 00:29:19 [INFO]: Epoch 083 - generator training loss: 0.0381, discriminator training loss: 0.0171, validation loss: 0.0982
2024-05-25 00:29:23 [INFO]: Epoch 084 - generator training loss: 0.0368, discriminator training loss: 0.0170, validation loss: 0.0987
2024-05-25 00:29:27 [INFO]: Epoch 085 - generator training loss: 0.0362, discriminator training loss: 0.0168, validation loss: 0.0976
2024-05-25 00:29:31 [INFO]: Epoch 086 - generator training loss: 0.0365, discriminator training loss: 0.0168, validation loss: 0.0977
2024-05-25 00:29:35 [INFO]: Epoch 087 - generator training loss: 0.0360, discriminator training loss: 0.0167, validation loss: 0.0973
2024-05-25 00:29:39 [INFO]: Epoch 088 - generator training loss: 0.0357, discriminator training loss: 0.0164, validation loss: 0.0976
2024-05-25 00:29:43 [INFO]: Epoch 089 - generator training loss: 0.0355, discriminator training loss: 0.0163, validation loss: 0.0972
2024-05-25 00:29:47 [INFO]: Epoch 090 - generator training loss: 0.0363, discriminator training loss: 0.0162, validation loss: 0.0974
2024-05-25 00:29:51 [INFO]: Epoch 091 - generator training loss: 0.0356, discriminator training loss: 0.0161, validation loss: 0.0972
2024-05-25 00:29:55 [INFO]: Epoch 092 - generator training loss: 0.0359, discriminator training loss: 0.0160, validation loss: 0.0971
2024-05-25 00:29:59 [INFO]: Epoch 093 - generator training loss: 0.0346, discriminator training loss: 0.0160, validation loss: 0.0966
2024-05-25 00:30:03 [INFO]: Epoch 094 - generator training loss: 0.0352, discriminator training loss: 0.0158, validation loss: 0.0968
2024-05-25 00:30:07 [INFO]: Epoch 095 - generator training loss: 0.0342, discriminator training loss: 0.0159, validation loss: 0.0964
2024-05-25 00:30:11 [INFO]: Epoch 096 - generator training loss: 0.0342, discriminator training loss: 0.0157, validation loss: 0.0963
2024-05-25 00:30:15 [INFO]: Epoch 097 - generator training loss: 0.0342, discriminator training loss: 0.0155, validation loss: 0.0962
2024-05-25 00:30:19 [INFO]: Epoch 098 - generator training loss: 0.0338, discriminator training loss: 0.0154, validation loss: 0.0970
2024-05-25 00:30:23 [INFO]: Epoch 099 - generator training loss: 0.0343, discriminator training loss: 0.0155, validation loss: 0.0965
2024-05-25 00:30:27 [INFO]: Epoch 100 - generator training loss: 0.0333, discriminator training loss: 0.0153, validation loss: 0.0962
2024-05-25 00:30:31 [INFO]: Epoch 101 - generator training loss: 0.0335, discriminator training loss: 0.0151, validation loss: 0.0968
2024-05-25 00:30:35 [INFO]: Epoch 102 - generator training loss: 0.0329, discriminator training loss: 0.0152, validation loss: 0.0957
2024-05-25 00:30:39 [INFO]: Epoch 103 - generator training loss: 0.0331, discriminator training loss: 0.0150, validation loss: 0.0966
2024-05-25 00:30:44 [INFO]: Epoch 104 - generator training loss: 0.0330, discriminator training loss: 0.0150, validation loss: 0.0962
2024-05-25 00:30:48 [INFO]: Epoch 105 - generator training loss: 0.0335, discriminator training loss: 0.0151, validation loss: 0.0957
2024-05-25 00:30:52 [INFO]: Epoch 106 - generator training loss: 0.0326, discriminator training loss: 0.0150, validation loss: 0.0963
2024-05-25 00:30:56 [INFO]: Epoch 107 - generator training loss: 0.0324, discriminator training loss: 0.0149, validation loss: 0.0960
2024-05-25 00:31:00 [INFO]: Epoch 108 - generator training loss: 0.0323, discriminator training loss: 0.0149, validation loss: 0.0956
2024-05-25 00:31:04 [INFO]: Epoch 109 - generator training loss: 0.0323, discriminator training loss: 0.0148, validation loss: 0.0955
2024-05-25 00:31:08 [INFO]: Epoch 110 - generator training loss: 0.0330, discriminator training loss: 0.0145, validation loss: 0.0971
2024-05-25 00:31:12 [INFO]: Epoch 111 - generator training loss: 0.0327, discriminator training loss: 0.0143, validation loss: 0.0957
2024-05-25 00:31:16 [INFO]: Epoch 112 - generator training loss: 0.0316, discriminator training loss: 0.0144, validation loss: 0.0963
2024-05-25 00:31:20 [INFO]: Epoch 113 - generator training loss: 0.0313, discriminator training loss: 0.0142, validation loss: 0.0955
2024-05-25 00:31:24 [INFO]: Epoch 114 - generator training loss: 0.0315, discriminator training loss: 0.0142, validation loss: 0.0963
2024-05-25 00:31:28 [INFO]: Epoch 115 - generator training loss: 0.0307, discriminator training loss: 0.0146, validation loss: 0.0949
2024-05-25 00:31:32 [INFO]: Epoch 116 - generator training loss: 0.0305, discriminator training loss: 0.0142, validation loss: 0.0951
2024-05-25 00:31:36 [INFO]: Epoch 117 - generator training loss: 0.0307, discriminator training loss: 0.0140, validation loss: 0.0957
2024-05-25 00:31:40 [INFO]: Epoch 118 - generator training loss: 0.0307, discriminator training loss: 0.0140, validation loss: 0.0951
2024-05-25 00:31:44 [INFO]: Epoch 119 - generator training loss: 0.0306, discriminator training loss: 0.0138, validation loss: 0.0951
2024-05-25 00:31:48 [INFO]: Epoch 120 - generator training loss: 0.0306, discriminator training loss: 0.0139, validation loss: 0.0957
2024-05-25 00:31:52 [INFO]: Epoch 121 - generator training loss: 0.0308, discriminator training loss: 0.0139, validation loss: 0.0954
2024-05-25 00:31:56 [INFO]: Epoch 122 - generator training loss: 0.0301, discriminator training loss: 0.0139, validation loss: 0.0952
2024-05-25 00:32:00 [INFO]: Epoch 123 - generator training loss: 0.0301, discriminator training loss: 0.0137, validation loss: 0.0954
2024-05-25 00:32:04 [INFO]: Epoch 124 - generator training loss: 0.0296, discriminator training loss: 0.0137, validation loss: 0.0950
2024-05-25 00:32:08 [INFO]: Epoch 125 - generator training loss: 0.0296, discriminator training loss: 0.0138, validation loss: 0.0948
2024-05-25 00:32:12 [INFO]: Epoch 126 - generator training loss: 0.0297, discriminator training loss: 0.0135, validation loss: 0.0961
2024-05-25 00:32:16 [INFO]: Epoch 127 - generator training loss: 0.0297, discriminator training loss: 0.0135, validation loss: 0.0960
2024-05-25 00:32:20 [INFO]: Epoch 128 - generator training loss: 0.0300, discriminator training loss: 0.0134, validation loss: 0.0962
2024-05-25 00:32:24 [INFO]: Epoch 129 - generator training loss: 0.0298, discriminator training loss: 0.0134, validation loss: 0.0951
2024-05-25 00:32:28 [INFO]: Epoch 130 - generator training loss: 0.0292, discriminator training loss: 0.0134, validation loss: 0.0951
2024-05-25 00:32:32 [INFO]: Epoch 131 - generator training loss: 0.0291, discriminator training loss: 0.0133, validation loss: 0.0951
2024-05-25 00:32:36 [INFO]: Epoch 132 - generator training loss: 0.0294, discriminator training loss: 0.0133, validation loss: 0.0959
2024-05-25 00:32:40 [INFO]: Epoch 133 - generator training loss: 0.0289, discriminator training loss: 0.0134, validation loss: 0.0949
2024-05-25 00:32:44 [INFO]: Epoch 134 - generator training loss: 0.0287, discriminator training loss: 0.0132, validation loss: 0.0949
2024-05-25 00:32:48 [INFO]: Epoch 135 - generator training loss: 0.0307, discriminator training loss: 0.0132, validation loss: 0.0946
2024-05-25 00:32:52 [INFO]: Epoch 136 - generator training loss: 0.0304, discriminator training loss: 0.0132, validation loss: 0.0960
2024-05-25 00:32:56 [INFO]: Epoch 137 - generator training loss: 0.0295, discriminator training loss: 0.0130, validation loss: 0.0951
2024-05-25 00:33:00 [INFO]: Epoch 138 - generator training loss: 0.0293, discriminator training loss: 0.0129, validation loss: 0.0948
2024-05-25 00:33:04 [INFO]: Epoch 139 - generator training loss: 0.0286, discriminator training loss: 0.0132, validation loss: 0.0947
2024-05-25 00:33:08 [INFO]: Epoch 140 - generator training loss: 0.0283, discriminator training loss: 0.0128, validation loss: 0.0954
2024-05-25 00:33:12 [INFO]: Epoch 141 - generator training loss: 0.0281, discriminator training loss: 0.0126, validation loss: 0.0946
2024-05-25 00:33:16 [INFO]: Epoch 142 - generator training loss: 0.0278, discriminator training loss: 0.0126, validation loss: 0.0953
2024-05-25 00:33:20 [INFO]: Epoch 143 - generator training loss: 0.0278, discriminator training loss: 0.0127, validation loss: 0.0951
2024-05-25 00:33:24 [INFO]: Epoch 144 - generator training loss: 0.0277, discriminator training loss: 0.0125, validation loss: 0.0951
2024-05-25 00:33:28 [INFO]: Epoch 145 - generator training loss: 0.0279, discriminator training loss: 0.0125, validation loss: 0.0952
2024-05-25 00:33:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:33:28 [INFO]: Finished training. The best model is from epoch#135.
2024-05-25 00:33:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/USGAN_air_quality/20240525_T002348/USGAN.pypots
2024-05-25 00:33:29 [INFO]: US-GAN on Air-Quality: MAE=0.1516, MSE=0.1003
2024-05-25 00:33:29 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/USGAN_air_quality/imputation.pkl
2024-05-25 00:33:29 [INFO]: Using the given device: cuda:0
2024-05-25 00:33:29 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/BRITS_air_quality/20240525_T003329
2024-05-25 00:33:29 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/BRITS_air_quality/20240525_T003329/tensorboard
2024-05-25 00:33:29 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 00:33:32 [INFO]: Epoch 001 - training loss: 1.4046, validation loss: 0.9287
2024-05-25 00:33:35 [INFO]: Epoch 002 - training loss: 1.1271, validation loss: 0.6958
2024-05-25 00:33:38 [INFO]: Epoch 003 - training loss: 0.9408, validation loss: 0.5858
2024-05-25 00:33:40 [INFO]: Epoch 004 - training loss: 0.8334, validation loss: 0.5179
2024-05-25 00:33:43 [INFO]: Epoch 005 - training loss: 0.7610, validation loss: 0.4741
2024-05-25 00:33:46 [INFO]: Epoch 006 - training loss: 0.7038, validation loss: 0.4382
2024-05-25 00:33:49 [INFO]: Epoch 007 - training loss: 0.6626, validation loss: 0.4097
2024-05-25 00:33:51 [INFO]: Epoch 008 - training loss: 0.6263, validation loss: 0.3853
2024-05-25 00:33:54 [INFO]: Epoch 009 - training loss: 0.5993, validation loss: 0.3659
2024-05-25 00:33:57 [INFO]: Epoch 010 - training loss: 0.5765, validation loss: 0.3490
2024-05-25 00:34:00 [INFO]: Epoch 011 - training loss: 0.5597, validation loss: 0.3353
2024-05-25 00:34:02 [INFO]: Epoch 012 - training loss: 0.5444, validation loss: 0.3240
2024-05-25 00:34:05 [INFO]: Epoch 013 - training loss: 0.5288, validation loss: 0.3139
2024-05-25 00:34:08 [INFO]: Epoch 014 - training loss: 0.5181, validation loss: 0.3055
2024-05-25 00:34:11 [INFO]: Epoch 015 - training loss: 0.5061, validation loss: 0.2981
2024-05-25 00:34:13 [INFO]: Epoch 016 - training loss: 0.4960, validation loss: 0.2905
2024-05-25 00:34:16 [INFO]: Epoch 017 - training loss: 0.4871, validation loss: 0.2848
2024-05-25 00:34:19 [INFO]: Epoch 018 - training loss: 0.4793, validation loss: 0.2788
2024-05-25 00:34:22 [INFO]: Epoch 019 - training loss: 0.4710, validation loss: 0.2735
2024-05-25 00:34:24 [INFO]: Epoch 020 - training loss: 0.4637, validation loss: 0.2686
2024-05-25 00:34:27 [INFO]: Epoch 021 - training loss: 0.4577, validation loss: 0.2647
2024-05-25 00:34:30 [INFO]: Epoch 022 - training loss: 0.4496, validation loss: 0.2604
2024-05-25 00:34:33 [INFO]: Epoch 023 - training loss: 0.4434, validation loss: 0.2566
2024-05-25 00:34:35 [INFO]: Epoch 024 - training loss: 0.4373, validation loss: 0.2528
2024-05-25 00:34:38 [INFO]: Epoch 025 - training loss: 0.4317, validation loss: 0.2489
2024-05-25 00:34:41 [INFO]: Epoch 026 - training loss: 0.4278, validation loss: 0.2456
2024-05-25 00:34:43 [INFO]: Epoch 027 - training loss: 0.4209, validation loss: 0.2418
2024-05-25 00:34:46 [INFO]: Epoch 028 - training loss: 0.4158, validation loss: 0.2388
2024-05-25 00:34:49 [INFO]: Epoch 029 - training loss: 0.4116, validation loss: 0.2354
2024-05-25 00:34:52 [INFO]: Epoch 030 - training loss: 0.4067, validation loss: 0.2323
2024-05-25 00:34:54 [INFO]: Epoch 031 - training loss: 0.4018, validation loss: 0.2293
2024-05-25 00:34:57 [INFO]: Epoch 032 - training loss: 0.3974, validation loss: 0.2259
2024-05-25 00:35:00 [INFO]: Epoch 033 - training loss: 0.3930, validation loss: 0.2234
2024-05-25 00:35:03 [INFO]: Epoch 034 - training loss: 0.3893, validation loss: 0.2201
2024-05-25 00:35:05 [INFO]: Epoch 035 - training loss: 0.3853, validation loss: 0.2171
2024-05-25 00:35:08 [INFO]: Epoch 036 - training loss: 0.3819, validation loss: 0.2145
2024-05-25 00:35:11 [INFO]: Epoch 037 - training loss: 0.3783, validation loss: 0.2115
2024-05-25 00:35:14 [INFO]: Epoch 038 - training loss: 0.3743, validation loss: 0.2088
2024-05-25 00:35:16 [INFO]: Epoch 039 - training loss: 0.3722, validation loss: 0.2059
2024-05-25 00:35:19 [INFO]: Epoch 040 - training loss: 0.3679, validation loss: 0.2029
2024-05-25 00:35:22 [INFO]: Epoch 041 - training loss: 0.3650, validation loss: 0.2001
2024-05-25 00:35:25 [INFO]: Epoch 042 - training loss: 0.3623, validation loss: 0.1970
2024-05-25 00:35:27 [INFO]: Epoch 043 - training loss: 0.3594, validation loss: 0.1946
2024-05-25 00:35:30 [INFO]: Epoch 044 - training loss: 0.3564, validation loss: 0.1920
2024-05-25 00:35:33 [INFO]: Epoch 045 - training loss: 0.3534, validation loss: 0.1888
2024-05-25 00:35:35 [INFO]: Epoch 046 - training loss: 0.3505, validation loss: 0.1864
2024-05-25 00:35:38 [INFO]: Epoch 047 - training loss: 0.3481, validation loss: 0.1835
2024-05-25 00:35:41 [INFO]: Epoch 048 - training loss: 0.3456, validation loss: 0.1809
2024-05-25 00:35:44 [INFO]: Epoch 049 - training loss: 0.3432, validation loss: 0.1782
2024-05-25 00:35:46 [INFO]: Epoch 050 - training loss: 0.3410, validation loss: 0.1760
2024-05-25 00:35:49 [INFO]: Epoch 051 - training loss: 0.3391, validation loss: 0.1735
2024-05-25 00:35:52 [INFO]: Epoch 052 - training loss: 0.3367, validation loss: 0.1720
2024-05-25 00:35:55 [INFO]: Epoch 053 - training loss: 0.3343, validation loss: 0.1692
2024-05-25 00:35:57 [INFO]: Epoch 054 - training loss: 0.3318, validation loss: 0.1677
2024-05-25 00:36:00 [INFO]: Epoch 055 - training loss: 0.3302, validation loss: 0.1652
2024-05-25 00:36:03 [INFO]: Epoch 056 - training loss: 0.3283, validation loss: 0.1632
2024-05-25 00:36:06 [INFO]: Epoch 057 - training loss: 0.3260, validation loss: 0.1612
2024-05-25 00:36:08 [INFO]: Epoch 058 - training loss: 0.3249, validation loss: 0.1599
2024-05-25 00:36:11 [INFO]: Epoch 059 - training loss: 0.3230, validation loss: 0.1581
2024-05-25 00:36:14 [INFO]: Epoch 060 - training loss: 0.3204, validation loss: 0.1565
2024-05-25 00:36:17 [INFO]: Epoch 061 - training loss: 0.3186, validation loss: 0.1550
2024-05-25 00:36:19 [INFO]: Epoch 062 - training loss: 0.3178, validation loss: 0.1536
2024-05-25 00:36:22 [INFO]: Epoch 063 - training loss: 0.3157, validation loss: 0.1525
2024-05-25 00:36:25 [INFO]: Epoch 064 - training loss: 0.3151, validation loss: 0.1511
2024-05-25 00:36:28 [INFO]: Epoch 065 - training loss: 0.3135, validation loss: 0.1505
2024-05-25 00:36:30 [INFO]: Epoch 066 - training loss: 0.3115, validation loss: 0.1490
2024-05-25 00:36:33 [INFO]: Epoch 067 - training loss: 0.3106, validation loss: 0.1478
2024-05-25 00:36:36 [INFO]: Epoch 068 - training loss: 0.3091, validation loss: 0.1468
2024-05-25 00:36:39 [INFO]: Epoch 069 - training loss: 0.3079, validation loss: 0.1458
2024-05-25 00:36:41 [INFO]: Epoch 070 - training loss: 0.3064, validation loss: 0.1448
2024-05-25 00:36:44 [INFO]: Epoch 071 - training loss: 0.3051, validation loss: 0.1439
2024-05-25 00:36:47 [INFO]: Epoch 072 - training loss: 0.3043, validation loss: 0.1433
2024-05-25 00:36:49 [INFO]: Epoch 073 - training loss: 0.3029, validation loss: 0.1422
2024-05-25 00:36:52 [INFO]: Epoch 074 - training loss: 0.3019, validation loss: 0.1416
2024-05-25 00:36:55 [INFO]: Epoch 075 - training loss: 0.3016, validation loss: 0.1410
2024-05-25 00:36:58 [INFO]: Epoch 076 - training loss: 0.2997, validation loss: 0.1397
2024-05-25 00:37:00 [INFO]: Epoch 077 - training loss: 0.2988, validation loss: 0.1389
2024-05-25 00:37:03 [INFO]: Epoch 078 - training loss: 0.2980, validation loss: 0.1383
2024-05-25 00:37:06 [INFO]: Epoch 079 - training loss: 0.2974, validation loss: 0.1376
2024-05-25 00:37:09 [INFO]: Epoch 080 - training loss: 0.2957, validation loss: 0.1371
2024-05-25 00:37:11 [INFO]: Epoch 081 - training loss: 0.2953, validation loss: 0.1363
2024-05-25 00:37:14 [INFO]: Epoch 082 - training loss: 0.2941, validation loss: 0.1358
2024-05-25 00:37:17 [INFO]: Epoch 083 - training loss: 0.2932, validation loss: 0.1355
2024-05-25 00:37:20 [INFO]: Epoch 084 - training loss: 0.2925, validation loss: 0.1347
2024-05-25 00:37:22 [INFO]: Epoch 085 - training loss: 0.2911, validation loss: 0.1342
2024-05-25 00:37:25 [INFO]: Epoch 086 - training loss: 0.2907, validation loss: 0.1337
2024-05-25 00:37:28 [INFO]: Epoch 087 - training loss: 0.2897, validation loss: 0.1331
2024-05-25 00:37:31 [INFO]: Epoch 088 - training loss: 0.2889, validation loss: 0.1323
2024-05-25 00:37:33 [INFO]: Epoch 089 - training loss: 0.2884, validation loss: 0.1320
2024-05-25 00:37:36 [INFO]: Epoch 090 - training loss: 0.2869, validation loss: 0.1316
2024-05-25 00:37:39 [INFO]: Epoch 091 - training loss: 0.2874, validation loss: 0.1309
2024-05-25 00:37:42 [INFO]: Epoch 092 - training loss: 0.2855, validation loss: 0.1305
2024-05-25 00:37:44 [INFO]: Epoch 093 - training loss: 0.2854, validation loss: 0.1300
2024-05-25 00:37:47 [INFO]: Epoch 094 - training loss: 0.2845, validation loss: 0.1293
2024-05-25 00:37:50 [INFO]: Epoch 095 - training loss: 0.2840, validation loss: 0.1291
2024-05-25 00:37:52 [INFO]: Epoch 096 - training loss: 0.2828, validation loss: 0.1287
2024-05-25 00:37:55 [INFO]: Epoch 097 - training loss: 0.2828, validation loss: 0.1282
2024-05-25 00:37:58 [INFO]: Epoch 098 - training loss: 0.2814, validation loss: 0.1277
2024-05-25 00:38:01 [INFO]: Epoch 099 - training loss: 0.2810, validation loss: 0.1274
2024-05-25 00:38:03 [INFO]: Epoch 100 - training loss: 0.2810, validation loss: 0.1269
2024-05-25 00:38:06 [INFO]: Epoch 101 - training loss: 0.2802, validation loss: 0.1268
2024-05-25 00:38:09 [INFO]: Epoch 102 - training loss: 0.2795, validation loss: 0.1262
2024-05-25 00:38:12 [INFO]: Epoch 103 - training loss: 0.2787, validation loss: 0.1260
2024-05-25 00:38:14 [INFO]: Epoch 104 - training loss: 0.2778, validation loss: 0.1252
2024-05-25 00:38:17 [INFO]: Epoch 105 - training loss: 0.2771, validation loss: 0.1250
2024-05-25 00:38:20 [INFO]: Epoch 106 - training loss: 0.2771, validation loss: 0.1245
2024-05-25 00:38:23 [INFO]: Epoch 107 - training loss: 0.2770, validation loss: 0.1244
2024-05-25 00:38:25 [INFO]: Epoch 108 - training loss: 0.2754, validation loss: 0.1237
2024-05-25 00:38:28 [INFO]: Epoch 109 - training loss: 0.2747, validation loss: 0.1234
2024-05-25 00:38:31 [INFO]: Epoch 110 - training loss: 0.2746, validation loss: 0.1231
2024-05-25 00:38:34 [INFO]: Epoch 111 - training loss: 0.2739, validation loss: 0.1225
2024-05-25 00:38:36 [INFO]: Epoch 112 - training loss: 0.2734, validation loss: 0.1224
2024-05-25 00:38:39 [INFO]: Epoch 113 - training loss: 0.2726, validation loss: 0.1219
2024-05-25 00:38:42 [INFO]: Epoch 114 - training loss: 0.2725, validation loss: 0.1215
2024-05-25 00:38:45 [INFO]: Epoch 115 - training loss: 0.2717, validation loss: 0.1212
2024-05-25 00:38:47 [INFO]: Epoch 116 - training loss: 0.2718, validation loss: 0.1207
2024-05-25 00:38:50 [INFO]: Epoch 117 - training loss: 0.2713, validation loss: 0.1206
2024-05-25 00:38:53 [INFO]: Epoch 118 - training loss: 0.2706, validation loss: 0.1202
2024-05-25 00:38:56 [INFO]: Epoch 119 - training loss: 0.2698, validation loss: 0.1199
2024-05-25 00:38:59 [INFO]: Epoch 120 - training loss: 0.2693, validation loss: 0.1196
2024-05-25 00:39:01 [INFO]: Epoch 121 - training loss: 0.2687, validation loss: 0.1193
2024-05-25 00:39:04 [INFO]: Epoch 122 - training loss: 0.2681, validation loss: 0.1188
2024-05-25 00:39:07 [INFO]: Epoch 123 - training loss: 0.2680, validation loss: 0.1184
2024-05-25 00:39:10 [INFO]: Epoch 124 - training loss: 0.2675, validation loss: 0.1182
2024-05-25 00:39:12 [INFO]: Epoch 125 - training loss: 0.2670, validation loss: 0.1178
2024-05-25 00:39:15 [INFO]: Epoch 126 - training loss: 0.2663, validation loss: 0.1176
2024-05-25 00:39:18 [INFO]: Epoch 127 - training loss: 0.2659, validation loss: 0.1172
2024-05-25 00:39:21 [INFO]: Epoch 128 - training loss: 0.2656, validation loss: 0.1169
2024-05-25 00:39:23 [INFO]: Epoch 129 - training loss: 0.2652, validation loss: 0.1165
2024-05-25 00:39:26 [INFO]: Epoch 130 - training loss: 0.2651, validation loss: 0.1163
2024-05-25 00:39:29 [INFO]: Epoch 131 - training loss: 0.2641, validation loss: 0.1160
2024-05-25 00:39:32 [INFO]: Epoch 132 - training loss: 0.2639, validation loss: 0.1158
2024-05-25 00:39:34 [INFO]: Epoch 133 - training loss: 0.2642, validation loss: 0.1156
2024-05-25 00:39:37 [INFO]: Epoch 134 - training loss: 0.2635, validation loss: 0.1153
2024-05-25 00:39:40 [INFO]: Epoch 135 - training loss: 0.2623, validation loss: 0.1150
2024-05-25 00:39:43 [INFO]: Epoch 136 - training loss: 0.2620, validation loss: 0.1148
2024-05-25 00:39:45 [INFO]: Epoch 137 - training loss: 0.2617, validation loss: 0.1145
2024-05-25 00:39:48 [INFO]: Epoch 138 - training loss: 0.2618, validation loss: 0.1143
2024-05-25 00:39:51 [INFO]: Epoch 139 - training loss: 0.2613, validation loss: 0.1138
2024-05-25 00:39:54 [INFO]: Epoch 140 - training loss: 0.2607, validation loss: 0.1139
2024-05-25 00:39:56 [INFO]: Epoch 141 - training loss: 0.2603, validation loss: 0.1135
2024-05-25 00:39:59 [INFO]: Epoch 142 - training loss: 0.2602, validation loss: 0.1134
2024-05-25 00:40:02 [INFO]: Epoch 143 - training loss: 0.2597, validation loss: 0.1131
2024-05-25 00:40:05 [INFO]: Epoch 144 - training loss: 0.2594, validation loss: 0.1127
2024-05-25 00:40:07 [INFO]: Epoch 145 - training loss: 0.2590, validation loss: 0.1125
2024-05-25 00:40:10 [INFO]: Epoch 146 - training loss: 0.2584, validation loss: 0.1124
2024-05-25 00:40:13 [INFO]: Epoch 147 - training loss: 0.2584, validation loss: 0.1122
2024-05-25 00:40:16 [INFO]: Epoch 148 - training loss: 0.2579, validation loss: 0.1119
2024-05-25 00:40:18 [INFO]: Epoch 149 - training loss: 0.2573, validation loss: 0.1115
2024-05-25 00:40:21 [INFO]: Epoch 150 - training loss: 0.2577, validation loss: 0.1115
2024-05-25 00:40:24 [INFO]: Epoch 151 - training loss: 0.2570, validation loss: 0.1112
2024-05-25 00:40:27 [INFO]: Epoch 152 - training loss: 0.2559, validation loss: 0.1110
2024-05-25 00:40:29 [INFO]: Epoch 153 - training loss: 0.2558, validation loss: 0.1106
2024-05-25 00:40:32 [INFO]: Epoch 154 - training loss: 0.2558, validation loss: 0.1104
2024-05-25 00:40:35 [INFO]: Epoch 155 - training loss: 0.2553, validation loss: 0.1102
2024-05-25 00:40:38 [INFO]: Epoch 156 - training loss: 0.2560, validation loss: 0.1101
2024-05-25 00:40:40 [INFO]: Epoch 157 - training loss: 0.2549, validation loss: 0.1098
2024-05-25 00:40:43 [INFO]: Epoch 158 - training loss: 0.2547, validation loss: 0.1096
2024-05-25 00:40:46 [INFO]: Epoch 159 - training loss: 0.2539, validation loss: 0.1095
2024-05-25 00:40:49 [INFO]: Epoch 160 - training loss: 0.2542, validation loss: 0.1093
2024-05-25 00:40:51 [INFO]: Epoch 161 - training loss: 0.2537, validation loss: 0.1089
2024-05-25 00:40:54 [INFO]: Epoch 162 - training loss: 0.2533, validation loss: 0.1089
2024-05-25 00:40:57 [INFO]: Epoch 163 - training loss: 0.2530, validation loss: 0.1087
2024-05-25 00:41:00 [INFO]: Epoch 164 - training loss: 0.2529, validation loss: 0.1084
2024-05-25 00:41:02 [INFO]: Epoch 165 - training loss: 0.2530, validation loss: 0.1082
2024-05-25 00:41:05 [INFO]: Epoch 166 - training loss: 0.2523, validation loss: 0.1082
2024-05-25 00:41:08 [INFO]: Epoch 167 - training loss: 0.2522, validation loss: 0.1082
2024-05-25 00:41:11 [INFO]: Epoch 168 - training loss: 0.2515, validation loss: 0.1080
2024-05-25 00:41:14 [INFO]: Epoch 169 - training loss: 0.2514, validation loss: 0.1077
2024-05-25 00:41:16 [INFO]: Epoch 170 - training loss: 0.2512, validation loss: 0.1076
2024-05-25 00:41:19 [INFO]: Epoch 171 - training loss: 0.2509, validation loss: 0.1074
2024-05-25 00:41:22 [INFO]: Epoch 172 - training loss: 0.2508, validation loss: 0.1072
2024-05-25 00:41:25 [INFO]: Epoch 173 - training loss: 0.2504, validation loss: 0.1071
2024-05-25 00:41:28 [INFO]: Epoch 174 - training loss: 0.2498, validation loss: 0.1069
2024-05-25 00:41:30 [INFO]: Epoch 175 - training loss: 0.2495, validation loss: 0.1068
2024-05-25 00:41:33 [INFO]: Epoch 176 - training loss: 0.2496, validation loss: 0.1066
2024-05-25 00:41:36 [INFO]: Epoch 177 - training loss: 0.2498, validation loss: 0.1062
2024-05-25 00:41:39 [INFO]: Epoch 178 - training loss: 0.2491, validation loss: 0.1061
2024-05-25 00:41:42 [INFO]: Epoch 179 - training loss: 0.2490, validation loss: 0.1061
2024-05-25 00:41:45 [INFO]: Epoch 180 - training loss: 0.2484, validation loss: 0.1060
2024-05-25 00:41:47 [INFO]: Epoch 181 - training loss: 0.2482, validation loss: 0.1059
2024-05-25 00:41:50 [INFO]: Epoch 182 - training loss: 0.2478, validation loss: 0.1057
2024-05-25 00:41:53 [INFO]: Epoch 183 - training loss: 0.2480, validation loss: 0.1055
2024-05-25 00:41:56 [INFO]: Epoch 184 - training loss: 0.2474, validation loss: 0.1054
2024-05-25 00:41:59 [INFO]: Epoch 185 - training loss: 0.2469, validation loss: 0.1052
2024-05-25 00:42:02 [INFO]: Epoch 186 - training loss: 0.2471, validation loss: 0.1051
2024-05-25 00:42:04 [INFO]: Epoch 187 - training loss: 0.2470, validation loss: 0.1051
2024-05-25 00:42:07 [INFO]: Epoch 188 - training loss: 0.2465, validation loss: 0.1050
2024-05-25 00:42:10 [INFO]: Epoch 189 - training loss: 0.2461, validation loss: 0.1049
2024-05-25 00:42:13 [INFO]: Epoch 190 - training loss: 0.2460, validation loss: 0.1049
2024-05-25 00:42:16 [INFO]: Epoch 191 - training loss: 0.2454, validation loss: 0.1046
2024-05-25 00:42:19 [INFO]: Epoch 192 - training loss: 0.2462, validation loss: 0.1043
2024-05-25 00:42:22 [INFO]: Epoch 193 - training loss: 0.2461, validation loss: 0.1044
2024-05-25 00:42:24 [INFO]: Epoch 194 - training loss: 0.2453, validation loss: 0.1041
2024-05-25 00:42:27 [INFO]: Epoch 195 - training loss: 0.2454, validation loss: 0.1041
2024-05-25 00:42:30 [INFO]: Epoch 196 - training loss: 0.2447, validation loss: 0.1040
2024-05-25 00:42:33 [INFO]: Epoch 197 - training loss: 0.2447, validation loss: 0.1040
2024-05-25 00:42:35 [INFO]: Epoch 198 - training loss: 0.2443, validation loss: 0.1038
2024-05-25 00:42:38 [INFO]: Epoch 199 - training loss: 0.2452, validation loss: 0.1039
2024-05-25 00:42:41 [INFO]: Epoch 200 - training loss: 0.2448, validation loss: 0.1035
2024-05-25 00:42:44 [INFO]: Epoch 201 - training loss: 0.2440, validation loss: 0.1034
2024-05-25 00:42:47 [INFO]: Epoch 202 - training loss: 0.2439, validation loss: 0.1034
2024-05-25 00:42:49 [INFO]: Epoch 203 - training loss: 0.2439, validation loss: 0.1032
2024-05-25 00:42:52 [INFO]: Epoch 204 - training loss: 0.2433, validation loss: 0.1032
2024-05-25 00:42:55 [INFO]: Epoch 205 - training loss: 0.2432, validation loss: 0.1031
2024-05-25 00:42:58 [INFO]: Epoch 206 - training loss: 0.2438, validation loss: 0.1030
2024-05-25 00:43:01 [INFO]: Epoch 207 - training loss: 0.2427, validation loss: 0.1029
2024-05-25 00:43:04 [INFO]: Epoch 208 - training loss: 0.2424, validation loss: 0.1028
2024-05-25 00:43:06 [INFO]: Epoch 209 - training loss: 0.2427, validation loss: 0.1025
2024-05-25 00:43:09 [INFO]: Epoch 210 - training loss: 0.2420, validation loss: 0.1024
2024-05-25 00:43:12 [INFO]: Epoch 211 - training loss: 0.2426, validation loss: 0.1024
2024-05-25 00:43:15 [INFO]: Epoch 212 - training loss: 0.2418, validation loss: 0.1022
2024-05-25 00:43:18 [INFO]: Epoch 213 - training loss: 0.2419, validation loss: 0.1023
2024-05-25 00:43:21 [INFO]: Epoch 214 - training loss: 0.2416, validation loss: 0.1023
2024-05-25 00:43:23 [INFO]: Epoch 215 - training loss: 0.2416, validation loss: 0.1021
2024-05-25 00:43:26 [INFO]: Epoch 216 - training loss: 0.2409, validation loss: 0.1020
2024-05-25 00:43:29 [INFO]: Epoch 217 - training loss: 0.2412, validation loss: 0.1019
2024-05-25 00:43:32 [INFO]: Epoch 218 - training loss: 0.2412, validation loss: 0.1018
2024-05-25 00:43:35 [INFO]: Epoch 219 - training loss: 0.2407, validation loss: 0.1018
2024-05-25 00:43:37 [INFO]: Epoch 220 - training loss: 0.2404, validation loss: 0.1016
2024-05-25 00:43:40 [INFO]: Epoch 221 - training loss: 0.2403, validation loss: 0.1016
2024-05-25 00:43:43 [INFO]: Epoch 222 - training loss: 0.2399, validation loss: 0.1015
2024-05-25 00:43:46 [INFO]: Epoch 223 - training loss: 0.2396, validation loss: 0.1015
2024-05-25 00:43:48 [INFO]: Epoch 224 - training loss: 0.2396, validation loss: 0.1012
2024-05-25 00:43:51 [INFO]: Epoch 225 - training loss: 0.2395, validation loss: 0.1013
2024-05-25 00:43:54 [INFO]: Epoch 226 - training loss: 0.2394, validation loss: 0.1011
2024-05-25 00:43:57 [INFO]: Epoch 227 - training loss: 0.2394, validation loss: 0.1010
2024-05-25 00:44:00 [INFO]: Epoch 228 - training loss: 0.2389, validation loss: 0.1011
2024-05-25 00:44:03 [INFO]: Epoch 229 - training loss: 0.2390, validation loss: 0.1011
2024-05-25 00:44:06 [INFO]: Epoch 230 - training loss: 0.2383, validation loss: 0.1007
2024-05-25 00:44:08 [INFO]: Epoch 231 - training loss: 0.2387, validation loss: 0.1008
2024-05-25 00:44:11 [INFO]: Epoch 232 - training loss: 0.2380, validation loss: 0.1007
2024-05-25 00:44:14 [INFO]: Epoch 233 - training loss: 0.2381, validation loss: 0.1006
2024-05-25 00:44:17 [INFO]: Epoch 234 - training loss: 0.2376, validation loss: 0.1007
2024-05-25 00:44:20 [INFO]: Epoch 235 - training loss: 0.2382, validation loss: 0.1006
2024-05-25 00:44:23 [INFO]: Epoch 236 - training loss: 0.2374, validation loss: 0.1004
2024-05-25 00:44:25 [INFO]: Epoch 237 - training loss: 0.2375, validation loss: 0.1003
2024-05-25 00:44:28 [INFO]: Epoch 238 - training loss: 0.2375, validation loss: 0.1002
2024-05-25 00:44:31 [INFO]: Epoch 239 - training loss: 0.2370, validation loss: 0.1002
2024-05-25 00:44:34 [INFO]: Epoch 240 - training loss: 0.2371, validation loss: 0.1003
2024-05-25 00:44:37 [INFO]: Epoch 241 - training loss: 0.2371, validation loss: 0.1001
2024-05-25 00:44:39 [INFO]: Epoch 242 - training loss: 0.2368, validation loss: 0.1000
2024-05-25 00:44:42 [INFO]: Epoch 243 - training loss: 0.2366, validation loss: 0.0999
2024-05-25 00:44:45 [INFO]: Epoch 244 - training loss: 0.2365, validation loss: 0.0999
2024-05-25 00:44:48 [INFO]: Epoch 245 - training loss: 0.2364, validation loss: 0.0999
2024-05-25 00:44:51 [INFO]: Epoch 246 - training loss: 0.2359, validation loss: 0.0998
2024-05-25 00:44:53 [INFO]: Epoch 247 - training loss: 0.2363, validation loss: 0.0998
2024-05-25 00:44:56 [INFO]: Epoch 248 - training loss: 0.2357, validation loss: 0.0995
2024-05-25 00:44:59 [INFO]: Epoch 249 - training loss: 0.2359, validation loss: 0.0996
2024-05-25 00:45:02 [INFO]: Epoch 250 - training loss: 0.2357, validation loss: 0.0996
2024-05-25 00:45:05 [INFO]: Epoch 251 - training loss: 0.2354, validation loss: 0.0994
2024-05-25 00:45:08 [INFO]: Epoch 252 - training loss: 0.2352, validation loss: 0.0994
2024-05-25 00:45:10 [INFO]: Epoch 253 - training loss: 0.2350, validation loss: 0.0994
2024-05-25 00:45:13 [INFO]: Epoch 254 - training loss: 0.2353, validation loss: 0.0993
2024-05-25 00:45:16 [INFO]: Epoch 255 - training loss: 0.2350, validation loss: 0.0993
2024-05-25 00:45:19 [INFO]: Epoch 256 - training loss: 0.2349, validation loss: 0.0992
2024-05-25 00:45:22 [INFO]: Epoch 257 - training loss: 0.2350, validation loss: 0.0990
2024-05-25 00:45:25 [INFO]: Epoch 258 - training loss: 0.2350, validation loss: 0.0993
2024-05-25 00:45:27 [INFO]: Epoch 259 - training loss: 0.2338, validation loss: 0.0992
2024-05-25 00:45:30 [INFO]: Epoch 260 - training loss: 0.2340, validation loss: 0.0990
2024-05-25 00:45:33 [INFO]: Epoch 261 - training loss: 0.2339, validation loss: 0.0989
2024-05-25 00:45:36 [INFO]: Epoch 262 - training loss: 0.2338, validation loss: 0.0987
2024-05-25 00:45:39 [INFO]: Epoch 263 - training loss: 0.2338, validation loss: 0.0988
2024-05-25 00:45:41 [INFO]: Epoch 264 - training loss: 0.2338, validation loss: 0.0990
2024-05-25 00:45:44 [INFO]: Epoch 265 - training loss: 0.2333, validation loss: 0.0987
2024-05-25 00:45:47 [INFO]: Epoch 266 - training loss: 0.2333, validation loss: 0.0987
2024-05-25 00:45:50 [INFO]: Epoch 267 - training loss: 0.2336, validation loss: 0.0986
2024-05-25 00:45:52 [INFO]: Epoch 268 - training loss: 0.2330, validation loss: 0.0985
2024-05-25 00:45:55 [INFO]: Epoch 269 - training loss: 0.2330, validation loss: 0.0988
2024-05-25 00:45:58 [INFO]: Epoch 270 - training loss: 0.2328, validation loss: 0.0985
2024-05-25 00:46:01 [INFO]: Epoch 271 - training loss: 0.2328, validation loss: 0.0984
2024-05-25 00:46:03 [INFO]: Epoch 272 - training loss: 0.2328, validation loss: 0.0984
2024-05-25 00:46:06 [INFO]: Epoch 273 - training loss: 0.2326, validation loss: 0.0983
2024-05-25 00:46:09 [INFO]: Epoch 274 - training loss: 0.2320, validation loss: 0.0984
2024-05-25 00:46:12 [INFO]: Epoch 275 - training loss: 0.2321, validation loss: 0.0981
2024-05-25 00:46:14 [INFO]: Epoch 276 - training loss: 0.2325, validation loss: 0.0983
2024-05-25 00:46:17 [INFO]: Epoch 277 - training loss: 0.2321, validation loss: 0.0982
2024-05-25 00:46:20 [INFO]: Epoch 278 - training loss: 0.2321, validation loss: 0.0982
2024-05-25 00:46:23 [INFO]: Epoch 279 - training loss: 0.2317, validation loss: 0.0983
2024-05-25 00:46:25 [INFO]: Epoch 280 - training loss: 0.2315, validation loss: 0.0980
2024-05-25 00:46:28 [INFO]: Epoch 281 - training loss: 0.2316, validation loss: 0.0982
2024-05-25 00:46:31 [INFO]: Epoch 282 - training loss: 0.2318, validation loss: 0.0980
2024-05-25 00:46:33 [INFO]: Epoch 283 - training loss: 0.2317, validation loss: 0.0979
2024-05-25 00:46:36 [INFO]: Epoch 284 - training loss: 0.2309, validation loss: 0.0980
2024-05-25 00:46:39 [INFO]: Epoch 285 - training loss: 0.2308, validation loss: 0.0977
2024-05-25 00:46:42 [INFO]: Epoch 286 - training loss: 0.2310, validation loss: 0.0976
2024-05-25 00:46:44 [INFO]: Epoch 287 - training loss: 0.2307, validation loss: 0.0979
2024-05-25 00:46:47 [INFO]: Epoch 288 - training loss: 0.2306, validation loss: 0.0977
2024-05-25 00:46:50 [INFO]: Epoch 289 - training loss: 0.2308, validation loss: 0.0977
2024-05-25 00:46:53 [INFO]: Epoch 290 - training loss: 0.2307, validation loss: 0.0976
2024-05-25 00:46:55 [INFO]: Epoch 291 - training loss: 0.2305, validation loss: 0.0975
2024-05-25 00:46:58 [INFO]: Epoch 292 - training loss: 0.2302, validation loss: 0.0976
2024-05-25 00:47:01 [INFO]: Epoch 293 - training loss: 0.2309, validation loss: 0.0975
2024-05-25 00:47:03 [INFO]: Epoch 294 - training loss: 0.2303, validation loss: 0.0976
2024-05-25 00:47:06 [INFO]: Epoch 295 - training loss: 0.2299, validation loss: 0.0975
2024-05-25 00:47:09 [INFO]: Epoch 296 - training loss: 0.2299, validation loss: 0.0976
2024-05-25 00:47:12 [INFO]: Epoch 297 - training loss: 0.2298, validation loss: 0.0975
2024-05-25 00:47:14 [INFO]: Epoch 298 - training loss: 0.2296, validation loss: 0.0974
2024-05-25 00:47:17 [INFO]: Epoch 299 - training loss: 0.2294, validation loss: 0.0973
2024-05-25 00:47:20 [INFO]: Epoch 300 - training loss: 0.2296, validation loss: 0.0975
2024-05-25 00:47:20 [INFO]: Finished training. The best model is from epoch#299.
2024-05-25 00:47:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/BRITS_air_quality/20240525_T003329/BRITS.pypots
2024-05-25 00:47:20 [INFO]: BRITS on Air-Quality: MAE=0.1373, MSE=0.0949
2024-05-25 00:47:20 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/BRITS_air_quality/imputation.pkl
2024-05-25 00:47:20 [INFO]: Using the given device: cuda:0
2024-05-25 00:47:20 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720
2024-05-25 00:47:20 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/tensorboard
2024-05-25 00:47:20 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 00:47:25 [INFO]: Epoch 001 - training loss: 1.4609, validation loss: 0.8037
2024-05-25 00:47:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch1_loss0.8036759108304977.pypots
2024-05-25 00:47:29 [INFO]: Epoch 002 - training loss: 1.0598, validation loss: 0.7390
2024-05-25 00:47:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch2_loss0.7390139758586883.pypots
2024-05-25 00:47:33 [INFO]: Epoch 003 - training loss: 1.0003, validation loss: 0.7201
2024-05-25 00:47:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch3_loss0.7200939536094666.pypots
2024-05-25 00:47:36 [INFO]: Epoch 004 - training loss: 0.9785, validation loss: 0.7084
2024-05-25 00:47:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch4_loss0.7084117263555527.pypots
2024-05-25 00:47:40 [INFO]: Epoch 005 - training loss: 0.9623, validation loss: 0.6990
2024-05-25 00:47:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch5_loss0.6990347295999527.pypots
2024-05-25 00:47:44 [INFO]: Epoch 006 - training loss: 0.9458, validation loss: 0.6931
2024-05-25 00:47:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch6_loss0.693088373541832.pypots
2024-05-25 00:47:48 [INFO]: Epoch 007 - training loss: 0.9323, validation loss: 0.6889
2024-05-25 00:47:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch7_loss0.6888807952404022.pypots
2024-05-25 00:47:52 [INFO]: Epoch 008 - training loss: 0.9357, validation loss: 0.6846
2024-05-25 00:47:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch8_loss0.6845936298370361.pypots
2024-05-25 00:47:56 [INFO]: Epoch 009 - training loss: 0.9137, validation loss: 0.6813
2024-05-25 00:47:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch9_loss0.6813319623470306.pypots
2024-05-25 00:48:00 [INFO]: Epoch 010 - training loss: 0.9152, validation loss: 0.6787
2024-05-25 00:48:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch10_loss0.6787294924259186.pypots
2024-05-25 00:48:03 [INFO]: Epoch 011 - training loss: 0.8937, validation loss: 0.6792
2024-05-25 00:48:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch11_loss0.6791627466678619.pypots
2024-05-25 00:48:07 [INFO]: Epoch 012 - training loss: 0.8979, validation loss: 0.6767
2024-05-25 00:48:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch12_loss0.6766809850931168.pypots
2024-05-25 00:48:11 [INFO]: Epoch 013 - training loss: 0.9024, validation loss: 0.6754
2024-05-25 00:48:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch13_loss0.6754160702228547.pypots
2024-05-25 00:48:15 [INFO]: Epoch 014 - training loss: 0.8978, validation loss: 0.6750
2024-05-25 00:48:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch14_loss0.6749958574771882.pypots
2024-05-25 00:48:19 [INFO]: Epoch 015 - training loss: 0.8904, validation loss: 0.6748
2024-05-25 00:48:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch15_loss0.6747508347034454.pypots
2024-05-25 00:48:23 [INFO]: Epoch 016 - training loss: 0.9092, validation loss: 0.6731
2024-05-25 00:48:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch16_loss0.6731304615736008.pypots
2024-05-25 00:48:27 [INFO]: Epoch 017 - training loss: 0.8878, validation loss: 0.6721
2024-05-25 00:48:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch17_loss0.6720691233873367.pypots
2024-05-25 00:48:31 [INFO]: Epoch 018 - training loss: 0.8829, validation loss: 0.6726
2024-05-25 00:48:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch18_loss0.6726188570261001.pypots
2024-05-25 00:48:34 [INFO]: Epoch 019 - training loss: 0.8957, validation loss: 0.6733
2024-05-25 00:48:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch19_loss0.6732599198818207.pypots
2024-05-25 00:48:38 [INFO]: Epoch 020 - training loss: 0.8783, validation loss: 0.6728
2024-05-25 00:48:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch20_loss0.6728433579206466.pypots
2024-05-25 00:48:42 [INFO]: Epoch 021 - training loss: 0.8713, validation loss: 0.6730
2024-05-25 00:48:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch21_loss0.6730409950017929.pypots
2024-05-25 00:48:46 [INFO]: Epoch 022 - training loss: 0.8798, validation loss: 0.6748
2024-05-25 00:48:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch22_loss0.6748228639364242.pypots
2024-05-25 00:48:50 [INFO]: Epoch 023 - training loss: 0.8692, validation loss: 0.6749
2024-05-25 00:48:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch23_loss0.6749081432819366.pypots
2024-05-25 00:48:53 [INFO]: Epoch 024 - training loss: 0.8738, validation loss: 0.6746
2024-05-25 00:48:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch24_loss0.6745676398277283.pypots
2024-05-25 00:48:57 [INFO]: Epoch 025 - training loss: 0.8833, validation loss: 0.6725
2024-05-25 00:48:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch25_loss0.6724941462278367.pypots
2024-05-25 00:49:01 [INFO]: Epoch 026 - training loss: 0.8725, validation loss: 0.6743
2024-05-25 00:49:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch26_loss0.674336290359497.pypots
2024-05-25 00:49:05 [INFO]: Epoch 027 - training loss: 0.8500, validation loss: 0.6743
2024-05-25 00:49:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN_epoch27_loss0.6742991179227829.pypots
2024-05-25 00:49:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:49:05 [INFO]: Finished training. The best model is from epoch#17.
2024-05-25 00:49:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T004720/MRNN.pypots
2024-05-25 00:49:05 [INFO]: MRNN on Air-Quality: MAE=0.5187, MSE=0.6012
2024-05-25 00:49:05 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/MRNN_air_quality/imputation.pkl
2024-05-25 00:49:05 [INFO]: Using the given device: cpu
2024-05-25 00:49:05 [INFO]: LOCF on Air-Quality: MAE=0.1979, MSE=0.2108
2024-05-25 00:49:05 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_air_quality".
2024-05-25 00:49:05 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/LOCF_air_quality/imputation.pkl
2024-05-25 00:49:05 [INFO]: Median on Air-Quality: MAE=0.6603, MSE=0.9901
2024-05-25 00:49:05 [INFO]: Successfully created the given path "saved_results/round_1/Median_air_quality".
2024-05-25 00:49:05 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/Median_air_quality/imputation.pkl
2024-05-25 00:49:06 [INFO]: Mean on Air-Quality: MAE=0.6916, MSE=0.9314
2024-05-25 00:49:06 [INFO]: Successfully created the given path "saved_results/round_1/Mean_air_quality".
2024-05-25 00:49:06 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/Mean_air_quality/imputation.pkl
2024-05-25 00:49:06 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-25 00:49:06 [INFO]: Using the given device: cuda:0
2024-05-25 00:49:06 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/SAITS_air_quality/20240525_T004906
2024-05-25 00:49:06 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/SAITS_air_quality/20240525_T004906/tensorboard
2024-05-25 00:49:06 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 00:49:06 [INFO]: Epoch 001 - training loss: 1.0583, validation loss: 0.5236
2024-05-25 00:49:07 [INFO]: Epoch 002 - training loss: 0.7601, validation loss: 0.3938
2024-05-25 00:49:08 [INFO]: Epoch 003 - training loss: 0.6514, validation loss: 0.3173
2024-05-25 00:49:08 [INFO]: Epoch 004 - training loss: 0.5814, validation loss: 0.2788
2024-05-25 00:49:09 [INFO]: Epoch 005 - training loss: 0.5266, validation loss: 0.2566
2024-05-25 00:49:10 [INFO]: Epoch 006 - training loss: 0.4869, validation loss: 0.2416
2024-05-25 00:49:10 [INFO]: Epoch 007 - training loss: 0.4604, validation loss: 0.2316
2024-05-25 00:49:11 [INFO]: Epoch 008 - training loss: 0.4394, validation loss: 0.2250
2024-05-25 00:49:12 [INFO]: Epoch 009 - training loss: 0.4256, validation loss: 0.2191
2024-05-25 00:49:12 [INFO]: Epoch 010 - training loss: 0.4135, validation loss: 0.2142
2024-05-25 00:49:13 [INFO]: Epoch 011 - training loss: 0.4031, validation loss: 0.2115
2024-05-25 00:49:14 [INFO]: Epoch 012 - training loss: 0.3973, validation loss: 0.2065
2024-05-25 00:49:14 [INFO]: Epoch 013 - training loss: 0.3884, validation loss: 0.2048
2024-05-25 00:49:15 [INFO]: Epoch 014 - training loss: 0.3812, validation loss: 0.2015
2024-05-25 00:49:16 [INFO]: Epoch 015 - training loss: 0.3764, validation loss: 0.1986
2024-05-25 00:49:16 [INFO]: Epoch 016 - training loss: 0.3714, validation loss: 0.1965
2024-05-25 00:49:17 [INFO]: Epoch 017 - training loss: 0.3659, validation loss: 0.1965
2024-05-25 00:49:18 [INFO]: Epoch 018 - training loss: 0.3589, validation loss: 0.1937
2024-05-25 00:49:18 [INFO]: Epoch 019 - training loss: 0.3567, validation loss: 0.1913
2024-05-25 00:49:19 [INFO]: Epoch 020 - training loss: 0.3521, validation loss: 0.1900
2024-05-25 00:49:20 [INFO]: Epoch 021 - training loss: 0.3495, validation loss: 0.1896
2024-05-25 00:49:21 [INFO]: Epoch 022 - training loss: 0.3464, validation loss: 0.1867
2024-05-25 00:49:21 [INFO]: Epoch 023 - training loss: 0.3426, validation loss: 0.1856
2024-05-25 00:49:22 [INFO]: Epoch 024 - training loss: 0.3398, validation loss: 0.1838
2024-05-25 00:49:23 [INFO]: Epoch 025 - training loss: 0.3379, validation loss: 0.1820
2024-05-25 00:49:23 [INFO]: Epoch 026 - training loss: 0.3340, validation loss: 0.1802
2024-05-25 00:49:24 [INFO]: Epoch 027 - training loss: 0.3309, validation loss: 0.1803
2024-05-25 00:49:25 [INFO]: Epoch 028 - training loss: 0.3291, validation loss: 0.1783
2024-05-25 00:49:25 [INFO]: Epoch 029 - training loss: 0.3272, validation loss: 0.1780
2024-05-25 00:49:26 [INFO]: Epoch 030 - training loss: 0.3262, validation loss: 0.1760
2024-05-25 00:49:27 [INFO]: Epoch 031 - training loss: 0.3233, validation loss: 0.1746
2024-05-25 00:49:27 [INFO]: Epoch 032 - training loss: 0.3205, validation loss: 0.1729
2024-05-25 00:49:28 [INFO]: Epoch 033 - training loss: 0.3174, validation loss: 0.1720
2024-05-25 00:49:29 [INFO]: Epoch 034 - training loss: 0.3168, validation loss: 0.1710
2024-05-25 00:49:29 [INFO]: Epoch 035 - training loss: 0.3165, validation loss: 0.1695
2024-05-25 00:49:30 [INFO]: Epoch 036 - training loss: 0.3139, validation loss: 0.1682
2024-05-25 00:49:31 [INFO]: Epoch 037 - training loss: 0.3111, validation loss: 0.1679
2024-05-25 00:49:31 [INFO]: Epoch 038 - training loss: 0.3087, validation loss: 0.1670
2024-05-25 00:49:32 [INFO]: Epoch 039 - training loss: 0.3077, validation loss: 0.1654
2024-05-25 00:49:33 [INFO]: Epoch 040 - training loss: 0.3052, validation loss: 0.1634
2024-05-25 00:49:33 [INFO]: Epoch 041 - training loss: 0.3049, validation loss: 0.1626
2024-05-25 00:49:34 [INFO]: Epoch 042 - training loss: 0.3030, validation loss: 0.1625
2024-05-25 00:49:35 [INFO]: Epoch 043 - training loss: 0.2999, validation loss: 0.1604
2024-05-25 00:49:35 [INFO]: Epoch 044 - training loss: 0.2980, validation loss: 0.1603
2024-05-25 00:49:36 [INFO]: Epoch 045 - training loss: 0.2969, validation loss: 0.1592
2024-05-25 00:49:37 [INFO]: Epoch 046 - training loss: 0.2958, validation loss: 0.1584
2024-05-25 00:49:37 [INFO]: Epoch 047 - training loss: 0.2951, validation loss: 0.1569
2024-05-25 00:49:38 [INFO]: Epoch 048 - training loss: 0.2950, validation loss: 0.1558
2024-05-25 00:49:39 [INFO]: Epoch 049 - training loss: 0.2917, validation loss: 0.1537
2024-05-25 00:49:39 [INFO]: Epoch 050 - training loss: 0.2899, validation loss: 0.1539
2024-05-25 00:49:40 [INFO]: Epoch 051 - training loss: 0.2899, validation loss: 0.1536
2024-05-25 00:49:41 [INFO]: Epoch 052 - training loss: 0.2872, validation loss: 0.1524
2024-05-25 00:49:41 [INFO]: Epoch 053 - training loss: 0.2862, validation loss: 0.1511
2024-05-25 00:49:42 [INFO]: Epoch 054 - training loss: 0.2844, validation loss: 0.1502
2024-05-25 00:49:43 [INFO]: Epoch 055 - training loss: 0.2833, validation loss: 0.1489
2024-05-25 00:49:43 [INFO]: Epoch 056 - training loss: 0.2819, validation loss: 0.1483
2024-05-25 00:49:44 [INFO]: Epoch 057 - training loss: 0.2801, validation loss: 0.1473
2024-05-25 00:49:45 [INFO]: Epoch 058 - training loss: 0.2806, validation loss: 0.1460
2024-05-25 00:49:45 [INFO]: Epoch 059 - training loss: 0.2782, validation loss: 0.1457
2024-05-25 00:49:46 [INFO]: Epoch 060 - training loss: 0.2775, validation loss: 0.1437
2024-05-25 00:49:47 [INFO]: Epoch 061 - training loss: 0.2769, validation loss: 0.1447
2024-05-25 00:49:47 [INFO]: Epoch 062 - training loss: 0.2763, validation loss: 0.1443
2024-05-25 00:49:48 [INFO]: Epoch 063 - training loss: 0.2737, validation loss: 0.1424
2024-05-25 00:49:49 [INFO]: Epoch 064 - training loss: 0.2731, validation loss: 0.1420
2024-05-25 00:49:49 [INFO]: Epoch 065 - training loss: 0.2720, validation loss: 0.1416
2024-05-25 00:49:50 [INFO]: Epoch 066 - training loss: 0.2711, validation loss: 0.1407
2024-05-25 00:49:51 [INFO]: Epoch 067 - training loss: 0.2689, validation loss: 0.1396
2024-05-25 00:49:51 [INFO]: Epoch 068 - training loss: 0.2695, validation loss: 0.1395
2024-05-25 00:49:52 [INFO]: Epoch 069 - training loss: 0.2678, validation loss: 0.1376
2024-05-25 00:49:53 [INFO]: Epoch 070 - training loss: 0.2666, validation loss: 0.1375
2024-05-25 00:49:53 [INFO]: Epoch 071 - training loss: 0.2660, validation loss: 0.1372
2024-05-25 00:49:54 [INFO]: Epoch 072 - training loss: 0.2634, validation loss: 0.1371
2024-05-25 00:49:55 [INFO]: Epoch 073 - training loss: 0.2636, validation loss: 0.1353
2024-05-25 00:49:55 [INFO]: Epoch 074 - training loss: 0.2633, validation loss: 0.1361
2024-05-25 00:49:56 [INFO]: Epoch 075 - training loss: 0.2642, validation loss: 0.1348
2024-05-25 00:49:57 [INFO]: Epoch 076 - training loss: 0.2623, validation loss: 0.1348
2024-05-25 00:49:57 [INFO]: Epoch 077 - training loss: 0.2614, validation loss: 0.1333
2024-05-25 00:49:58 [INFO]: Epoch 078 - training loss: 0.2602, validation loss: 0.1335
2024-05-25 00:49:59 [INFO]: Epoch 079 - training loss: 0.2586, validation loss: 0.1322
2024-05-25 00:49:59 [INFO]: Epoch 080 - training loss: 0.2579, validation loss: 0.1326
2024-05-25 00:50:00 [INFO]: Epoch 081 - training loss: 0.2580, validation loss: 0.1326
2024-05-25 00:50:01 [INFO]: Epoch 082 - training loss: 0.2568, validation loss: 0.1319
2024-05-25 00:50:01 [INFO]: Epoch 083 - training loss: 0.2568, validation loss: 0.1314
2024-05-25 00:50:02 [INFO]: Epoch 084 - training loss: 0.2546, validation loss: 0.1312
2024-05-25 00:50:03 [INFO]: Epoch 085 - training loss: 0.2549, validation loss: 0.1310
2024-05-25 00:50:04 [INFO]: Epoch 086 - training loss: 0.2542, validation loss: 0.1300
2024-05-25 00:50:04 [INFO]: Epoch 087 - training loss: 0.2531, validation loss: 0.1302
2024-05-25 00:50:05 [INFO]: Epoch 088 - training loss: 0.2528, validation loss: 0.1293
2024-05-25 00:50:06 [INFO]: Epoch 089 - training loss: 0.2546, validation loss: 0.1296
2024-05-25 00:50:06 [INFO]: Epoch 090 - training loss: 0.2554, validation loss: 0.1293
2024-05-25 00:50:07 [INFO]: Epoch 091 - training loss: 0.2537, validation loss: 0.1288
2024-05-25 00:50:08 [INFO]: Epoch 092 - training loss: 0.2504, validation loss: 0.1278
2024-05-25 00:50:08 [INFO]: Epoch 093 - training loss: 0.2499, validation loss: 0.1275
2024-05-25 00:50:09 [INFO]: Epoch 094 - training loss: 0.2475, validation loss: 0.1271
2024-05-25 00:50:10 [INFO]: Epoch 095 - training loss: 0.2495, validation loss: 0.1270
2024-05-25 00:50:10 [INFO]: Epoch 096 - training loss: 0.2477, validation loss: 0.1271
2024-05-25 00:50:11 [INFO]: Epoch 097 - training loss: 0.2486, validation loss: 0.1267
2024-05-25 00:50:12 [INFO]: Epoch 098 - training loss: 0.2481, validation loss: 0.1263
2024-05-25 00:50:12 [INFO]: Epoch 099 - training loss: 0.2469, validation loss: 0.1266
2024-05-25 00:50:13 [INFO]: Epoch 100 - training loss: 0.2461, validation loss: 0.1263
2024-05-25 00:50:14 [INFO]: Epoch 101 - training loss: 0.2441, validation loss: 0.1257
2024-05-25 00:50:14 [INFO]: Epoch 102 - training loss: 0.2441, validation loss: 0.1248
2024-05-25 00:50:15 [INFO]: Epoch 103 - training loss: 0.2440, validation loss: 0.1251
2024-05-25 00:50:16 [INFO]: Epoch 104 - training loss: 0.2431, validation loss: 0.1249
2024-05-25 00:50:16 [INFO]: Epoch 105 - training loss: 0.2420, validation loss: 0.1246
2024-05-25 00:50:17 [INFO]: Epoch 106 - training loss: 0.2424, validation loss: 0.1240
2024-05-25 00:50:18 [INFO]: Epoch 107 - training loss: 0.2429, validation loss: 0.1239
2024-05-25 00:50:18 [INFO]: Epoch 108 - training loss: 0.2408, validation loss: 0.1237
2024-05-25 00:50:19 [INFO]: Epoch 109 - training loss: 0.2405, validation loss: 0.1237
2024-05-25 00:50:20 [INFO]: Epoch 110 - training loss: 0.2413, validation loss: 0.1231
2024-05-25 00:50:20 [INFO]: Epoch 111 - training loss: 0.2403, validation loss: 0.1233
2024-05-25 00:50:21 [INFO]: Epoch 112 - training loss: 0.2391, validation loss: 0.1227
2024-05-25 00:50:22 [INFO]: Epoch 113 - training loss: 0.2380, validation loss: 0.1225
2024-05-25 00:50:23 [INFO]: Epoch 114 - training loss: 0.2379, validation loss: 0.1222
2024-05-25 00:50:23 [INFO]: Epoch 115 - training loss: 0.2371, validation loss: 0.1221
2024-05-25 00:50:24 [INFO]: Epoch 116 - training loss: 0.2375, validation loss: 0.1222
2024-05-25 00:50:25 [INFO]: Epoch 117 - training loss: 0.2364, validation loss: 0.1221
2024-05-25 00:50:25 [INFO]: Epoch 118 - training loss: 0.2363, validation loss: 0.1217
2024-05-25 00:50:26 [INFO]: Epoch 119 - training loss: 0.2359, validation loss: 0.1225
2024-05-25 00:50:27 [INFO]: Epoch 120 - training loss: 0.2355, validation loss: 0.1216
2024-05-25 00:50:27 [INFO]: Epoch 121 - training loss: 0.2352, validation loss: 0.1215
2024-05-25 00:50:28 [INFO]: Epoch 122 - training loss: 0.2337, validation loss: 0.1214
2024-05-25 00:50:29 [INFO]: Epoch 123 - training loss: 0.2352, validation loss: 0.1200
2024-05-25 00:50:29 [INFO]: Epoch 124 - training loss: 0.2332, validation loss: 0.1206
2024-05-25 00:50:30 [INFO]: Epoch 125 - training loss: 0.2322, validation loss: 0.1205
2024-05-25 00:50:31 [INFO]: Epoch 126 - training loss: 0.2339, validation loss: 0.1209
2024-05-25 00:50:31 [INFO]: Epoch 127 - training loss: 0.2322, validation loss: 0.1198
2024-05-25 00:50:32 [INFO]: Epoch 128 - training loss: 0.2318, validation loss: 0.1196
2024-05-25 00:50:33 [INFO]: Epoch 129 - training loss: 0.2311, validation loss: 0.1197
2024-05-25 00:50:33 [INFO]: Epoch 130 - training loss: 0.2313, validation loss: 0.1197
2024-05-25 00:50:34 [INFO]: Epoch 131 - training loss: 0.2307, validation loss: 0.1189
2024-05-25 00:50:35 [INFO]: Epoch 132 - training loss: 0.2310, validation loss: 0.1204
2024-05-25 00:50:35 [INFO]: Epoch 133 - training loss: 0.2316, validation loss: 0.1187
2024-05-25 00:50:36 [INFO]: Epoch 134 - training loss: 0.2314, validation loss: 0.1190
2024-05-25 00:50:37 [INFO]: Epoch 135 - training loss: 0.2316, validation loss: 0.1188
2024-05-25 00:50:38 [INFO]: Epoch 136 - training loss: 0.2300, validation loss: 0.1183
2024-05-25 00:50:38 [INFO]: Epoch 137 - training loss: 0.2279, validation loss: 0.1181
2024-05-25 00:50:39 [INFO]: Epoch 138 - training loss: 0.2282, validation loss: 0.1179
2024-05-25 00:50:40 [INFO]: Epoch 139 - training loss: 0.2269, validation loss: 0.1174
2024-05-25 00:50:40 [INFO]: Epoch 140 - training loss: 0.2270, validation loss: 0.1174
2024-05-25 00:50:41 [INFO]: Epoch 141 - training loss: 0.2264, validation loss: 0.1171
2024-05-25 00:50:42 [INFO]: Epoch 142 - training loss: 0.2261, validation loss: 0.1172
2024-05-25 00:50:42 [INFO]: Epoch 143 - training loss: 0.2271, validation loss: 0.1168
2024-05-25 00:50:43 [INFO]: Epoch 144 - training loss: 0.2249, validation loss: 0.1164
2024-05-25 00:50:44 [INFO]: Epoch 145 - training loss: 0.2253, validation loss: 0.1169
2024-05-25 00:50:44 [INFO]: Epoch 146 - training loss: 0.2257, validation loss: 0.1165
2024-05-25 00:50:45 [INFO]: Epoch 147 - training loss: 0.2259, validation loss: 0.1156
2024-05-25 00:50:46 [INFO]: Epoch 148 - training loss: 0.2236, validation loss: 0.1153
2024-05-25 00:50:46 [INFO]: Epoch 149 - training loss: 0.2237, validation loss: 0.1153
2024-05-25 00:50:47 [INFO]: Epoch 150 - training loss: 0.2228, validation loss: 0.1148
2024-05-25 00:50:48 [INFO]: Epoch 151 - training loss: 0.2239, validation loss: 0.1157
2024-05-25 00:50:48 [INFO]: Epoch 152 - training loss: 0.2236, validation loss: 0.1159
2024-05-25 00:50:49 [INFO]: Epoch 153 - training loss: 0.2220, validation loss: 0.1152
2024-05-25 00:50:50 [INFO]: Epoch 154 - training loss: 0.2220, validation loss: 0.1147
2024-05-25 00:50:50 [INFO]: Epoch 155 - training loss: 0.2223, validation loss: 0.1152
2024-05-25 00:50:51 [INFO]: Epoch 156 - training loss: 0.2210, validation loss: 0.1153
2024-05-25 00:50:52 [INFO]: Epoch 157 - training loss: 0.2198, validation loss: 0.1141
2024-05-25 00:50:52 [INFO]: Epoch 158 - training loss: 0.2209, validation loss: 0.1148
2024-05-25 00:50:53 [INFO]: Epoch 159 - training loss: 0.2207, validation loss: 0.1163
2024-05-25 00:50:54 [INFO]: Epoch 160 - training loss: 0.2221, validation loss: 0.1134
2024-05-25 00:50:54 [INFO]: Epoch 161 - training loss: 0.2219, validation loss: 0.1143
2024-05-25 00:50:55 [INFO]: Epoch 162 - training loss: 0.2190, validation loss: 0.1138
2024-05-25 00:50:56 [INFO]: Epoch 163 - training loss: 0.2192, validation loss: 0.1137
2024-05-25 00:50:56 [INFO]: Epoch 164 - training loss: 0.2182, validation loss: 0.1128
2024-05-25 00:50:57 [INFO]: Epoch 165 - training loss: 0.2172, validation loss: 0.1136
2024-05-25 00:50:58 [INFO]: Epoch 166 - training loss: 0.2183, validation loss: 0.1123
2024-05-25 00:50:58 [INFO]: Epoch 167 - training loss: 0.2172, validation loss: 0.1123
2024-05-25 00:50:59 [INFO]: Epoch 168 - training loss: 0.2168, validation loss: 0.1124
2024-05-25 00:51:00 [INFO]: Epoch 169 - training loss: 0.2154, validation loss: 0.1123
2024-05-25 00:51:00 [INFO]: Epoch 170 - training loss: 0.2180, validation loss: 0.1132
2024-05-25 00:51:01 [INFO]: Epoch 171 - training loss: 0.2191, validation loss: 0.1133
2024-05-25 00:51:02 [INFO]: Epoch 172 - training loss: 0.2160, validation loss: 0.1122
2024-05-25 00:51:03 [INFO]: Epoch 173 - training loss: 0.2156, validation loss: 0.1122
2024-05-25 00:51:03 [INFO]: Epoch 174 - training loss: 0.2161, validation loss: 0.1120
2024-05-25 00:51:04 [INFO]: Epoch 175 - training loss: 0.2172, validation loss: 0.1124
2024-05-25 00:51:05 [INFO]: Epoch 176 - training loss: 0.2168, validation loss: 0.1115
2024-05-25 00:51:05 [INFO]: Epoch 177 - training loss: 0.2155, validation loss: 0.1121
2024-05-25 00:51:06 [INFO]: Epoch 178 - training loss: 0.2153, validation loss: 0.1105
2024-05-25 00:51:07 [INFO]: Epoch 179 - training loss: 0.2154, validation loss: 0.1107
2024-05-25 00:51:07 [INFO]: Epoch 180 - training loss: 0.2150, validation loss: 0.1107
2024-05-25 00:51:08 [INFO]: Epoch 181 - training loss: 0.2138, validation loss: 0.1110
2024-05-25 00:51:09 [INFO]: Epoch 182 - training loss: 0.2141, validation loss: 0.1103
2024-05-25 00:51:09 [INFO]: Epoch 183 - training loss: 0.2168, validation loss: 0.1110
2024-05-25 00:51:10 [INFO]: Epoch 184 - training loss: 0.2151, validation loss: 0.1100
2024-05-25 00:51:11 [INFO]: Epoch 185 - training loss: 0.2122, validation loss: 0.1110
2024-05-25 00:51:11 [INFO]: Epoch 186 - training loss: 0.2107, validation loss: 0.1099
2024-05-25 00:51:12 [INFO]: Epoch 187 - training loss: 0.2119, validation loss: 0.1103
2024-05-25 00:51:13 [INFO]: Epoch 188 - training loss: 0.2108, validation loss: 0.1099
2024-05-25 00:51:13 [INFO]: Epoch 189 - training loss: 0.2114, validation loss: 0.1093
2024-05-25 00:51:14 [INFO]: Epoch 190 - training loss: 0.2101, validation loss: 0.1100
2024-05-25 00:51:15 [INFO]: Epoch 191 - training loss: 0.2097, validation loss: 0.1086
2024-05-25 00:51:15 [INFO]: Epoch 192 - training loss: 0.2103, validation loss: 0.1083
2024-05-25 00:51:16 [INFO]: Epoch 193 - training loss: 0.2093, validation loss: 0.1092
2024-05-25 00:51:17 [INFO]: Epoch 194 - training loss: 0.2090, validation loss: 0.1087
2024-05-25 00:51:18 [INFO]: Epoch 195 - training loss: 0.2095, validation loss: 0.1078
2024-05-25 00:51:18 [INFO]: Epoch 196 - training loss: 0.2085, validation loss: 0.1081
2024-05-25 00:51:19 [INFO]: Epoch 197 - training loss: 0.2081, validation loss: 0.1089
2024-05-25 00:51:20 [INFO]: Epoch 198 - training loss: 0.2082, validation loss: 0.1081
2024-05-25 00:51:20 [INFO]: Epoch 199 - training loss: 0.2085, validation loss: 0.1094
2024-05-25 00:51:21 [INFO]: Epoch 200 - training loss: 0.2082, validation loss: 0.1074
2024-05-25 00:51:22 [INFO]: Epoch 201 - training loss: 0.2074, validation loss: 0.1074
2024-05-25 00:51:22 [INFO]: Epoch 202 - training loss: 0.2080, validation loss: 0.1094
2024-05-25 00:51:23 [INFO]: Epoch 203 - training loss: 0.2088, validation loss: 0.1075
2024-05-25 00:51:24 [INFO]: Epoch 204 - training loss: 0.2086, validation loss: 0.1079
2024-05-25 00:51:24 [INFO]: Epoch 205 - training loss: 0.2076, validation loss: 0.1067
2024-05-25 00:51:25 [INFO]: Epoch 206 - training loss: 0.2065, validation loss: 0.1071
2024-05-25 00:51:26 [INFO]: Epoch 207 - training loss: 0.2068, validation loss: 0.1064
2024-05-25 00:51:26 [INFO]: Epoch 208 - training loss: 0.2066, validation loss: 0.1058
2024-05-25 00:51:27 [INFO]: Epoch 209 - training loss: 0.2068, validation loss: 0.1071
2024-05-25 00:51:28 [INFO]: Epoch 210 - training loss: 0.2062, validation loss: 0.1074
2024-05-25 00:51:28 [INFO]: Epoch 211 - training loss: 0.2058, validation loss: 0.1063
2024-05-25 00:51:29 [INFO]: Epoch 212 - training loss: 0.2061, validation loss: 0.1070
2024-05-25 00:51:30 [INFO]: Epoch 213 - training loss: 0.2058, validation loss: 0.1065
2024-05-25 00:51:30 [INFO]: Epoch 214 - training loss: 0.2043, validation loss: 0.1064
2024-05-25 00:51:31 [INFO]: Epoch 215 - training loss: 0.2044, validation loss: 0.1068
2024-05-25 00:51:32 [INFO]: Epoch 216 - training loss: 0.2053, validation loss: 0.1057
2024-05-25 00:51:33 [INFO]: Epoch 217 - training loss: 0.2028, validation loss: 0.1066
2024-05-25 00:51:33 [INFO]: Epoch 218 - training loss: 0.2035, validation loss: 0.1061
2024-05-25 00:51:34 [INFO]: Epoch 219 - training loss: 0.2049, validation loss: 0.1074
2024-05-25 00:51:35 [INFO]: Epoch 220 - training loss: 0.2039, validation loss: 0.1065
2024-05-25 00:51:35 [INFO]: Epoch 221 - training loss: 0.2022, validation loss: 0.1055
2024-05-25 00:51:36 [INFO]: Epoch 222 - training loss: 0.2027, validation loss: 0.1058
2024-05-25 00:51:37 [INFO]: Epoch 223 - training loss: 0.2026, validation loss: 0.1060
2024-05-25 00:51:37 [INFO]: Epoch 224 - training loss: 0.2044, validation loss: 0.1051
2024-05-25 00:51:38 [INFO]: Epoch 225 - training loss: 0.2042, validation loss: 0.1056
2024-05-25 00:51:39 [INFO]: Epoch 226 - training loss: 0.2022, validation loss: 0.1041
2024-05-25 00:51:39 [INFO]: Epoch 227 - training loss: 0.2015, validation loss: 0.1052
2024-05-25 00:51:40 [INFO]: Epoch 228 - training loss: 0.2020, validation loss: 0.1051
2024-05-25 00:51:41 [INFO]: Epoch 229 - training loss: 0.2010, validation loss: 0.1046
2024-05-25 00:51:41 [INFO]: Epoch 230 - training loss: 0.2008, validation loss: 0.1047
2024-05-25 00:51:42 [INFO]: Epoch 231 - training loss: 0.2007, validation loss: 0.1044
2024-05-25 00:51:43 [INFO]: Epoch 232 - training loss: 0.2001, validation loss: 0.1040
2024-05-25 00:51:43 [INFO]: Epoch 233 - training loss: 0.2026, validation loss: 0.1046
2024-05-25 00:51:44 [INFO]: Epoch 234 - training loss: 0.2002, validation loss: 0.1043
2024-05-25 00:51:45 [INFO]: Epoch 235 - training loss: 0.2000, validation loss: 0.1032
2024-05-25 00:51:45 [INFO]: Epoch 236 - training loss: 0.1991, validation loss: 0.1043
2024-05-25 00:51:46 [INFO]: Epoch 237 - training loss: 0.1995, validation loss: 0.1047
2024-05-25 00:51:47 [INFO]: Epoch 238 - training loss: 0.1989, validation loss: 0.1040
2024-05-25 00:51:48 [INFO]: Epoch 239 - training loss: 0.1981, validation loss: 0.1047
2024-05-25 00:51:48 [INFO]: Epoch 240 - training loss: 0.1990, validation loss: 0.1046
2024-05-25 00:51:49 [INFO]: Epoch 241 - training loss: 0.2013, validation loss: 0.1043
2024-05-25 00:51:50 [INFO]: Epoch 242 - training loss: 0.2000, validation loss: 0.1030
2024-05-25 00:51:50 [INFO]: Epoch 243 - training loss: 0.1992, validation loss: 0.1046
2024-05-25 00:51:51 [INFO]: Epoch 244 - training loss: 0.1994, validation loss: 0.1051
2024-05-25 00:51:52 [INFO]: Epoch 245 - training loss: 0.1999, validation loss: 0.1046
2024-05-25 00:51:52 [INFO]: Epoch 246 - training loss: 0.2007, validation loss: 0.1038
2024-05-25 00:51:53 [INFO]: Epoch 247 - training loss: 0.1996, validation loss: 0.1055
2024-05-25 00:51:54 [INFO]: Epoch 248 - training loss: 0.2003, validation loss: 0.1035
2024-05-25 00:51:54 [INFO]: Epoch 249 - training loss: 0.1972, validation loss: 0.1031
2024-05-25 00:51:55 [INFO]: Epoch 250 - training loss: 0.1966, validation loss: 0.1035
2024-05-25 00:51:56 [INFO]: Epoch 251 - training loss: 0.1969, validation loss: 0.1032
2024-05-25 00:51:56 [INFO]: Epoch 252 - training loss: 0.1971, validation loss: 0.1031
2024-05-25 00:51:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:51:56 [INFO]: Finished training. The best model is from epoch#242.
2024-05-25 00:51:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/SAITS_air_quality/20240525_T004906/SAITS.pypots
2024-05-25 00:51:57 [INFO]: SAITS on Air-Quality: MAE=0.1397, MSE=0.0963
2024-05-25 00:51:57 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/SAITS_air_quality/imputation.pkl
2024-05-25 00:51:57 [INFO]: Using the given device: cuda:0
2024-05-25 00:51:57 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/Transformer_air_quality/20240525_T005157
2024-05-25 00:51:57 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/Transformer_air_quality/20240525_T005157/tensorboard
2024-05-25 00:51:57 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 00:51:57 [INFO]: Epoch 001 - training loss: 0.9104, validation loss: 0.4727
2024-05-25 00:51:57 [INFO]: Epoch 002 - training loss: 0.5771, validation loss: 0.3449
2024-05-25 00:51:58 [INFO]: Epoch 003 - training loss: 0.4863, validation loss: 0.2902
2024-05-25 00:51:58 [INFO]: Epoch 004 - training loss: 0.4403, validation loss: 0.2654
2024-05-25 00:51:58 [INFO]: Epoch 005 - training loss: 0.4108, validation loss: 0.2536
2024-05-25 00:51:59 [INFO]: Epoch 006 - training loss: 0.3932, validation loss: 0.2418
2024-05-25 00:51:59 [INFO]: Epoch 007 - training loss: 0.3802, validation loss: 0.2351
2024-05-25 00:51:59 [INFO]: Epoch 008 - training loss: 0.3672, validation loss: 0.2290
2024-05-25 00:52:00 [INFO]: Epoch 009 - training loss: 0.3559, validation loss: 0.2236
2024-05-25 00:52:00 [INFO]: Epoch 010 - training loss: 0.3504, validation loss: 0.2179
2024-05-25 00:52:00 [INFO]: Epoch 011 - training loss: 0.3416, validation loss: 0.2150
2024-05-25 00:52:01 [INFO]: Epoch 012 - training loss: 0.3388, validation loss: 0.2101
2024-05-25 00:52:01 [INFO]: Epoch 013 - training loss: 0.3336, validation loss: 0.2095
2024-05-25 00:52:01 [INFO]: Epoch 014 - training loss: 0.3302, validation loss: 0.2044
2024-05-25 00:52:02 [INFO]: Epoch 015 - training loss: 0.3244, validation loss: 0.2009
2024-05-25 00:52:02 [INFO]: Epoch 016 - training loss: 0.3211, validation loss: 0.1982
2024-05-25 00:52:02 [INFO]: Epoch 017 - training loss: 0.3154, validation loss: 0.1955
2024-05-25 00:52:03 [INFO]: Epoch 018 - training loss: 0.3135, validation loss: 0.1904
2024-05-25 00:52:03 [INFO]: Epoch 019 - training loss: 0.3100, validation loss: 0.1883
2024-05-25 00:52:03 [INFO]: Epoch 020 - training loss: 0.3096, validation loss: 0.1879
2024-05-25 00:52:04 [INFO]: Epoch 021 - training loss: 0.3084, validation loss: 0.1835
2024-05-25 00:52:04 [INFO]: Epoch 022 - training loss: 0.3047, validation loss: 0.1793
2024-05-25 00:52:04 [INFO]: Epoch 023 - training loss: 0.3013, validation loss: 0.1787
2024-05-25 00:52:04 [INFO]: Epoch 024 - training loss: 0.2978, validation loss: 0.1760
2024-05-25 00:52:05 [INFO]: Epoch 025 - training loss: 0.2960, validation loss: 0.1744
2024-05-25 00:52:05 [INFO]: Epoch 026 - training loss: 0.2934, validation loss: 0.1740
2024-05-25 00:52:05 [INFO]: Epoch 027 - training loss: 0.2907, validation loss: 0.1714
2024-05-25 00:52:06 [INFO]: Epoch 028 - training loss: 0.2894, validation loss: 0.1719
2024-05-25 00:52:06 [INFO]: Epoch 029 - training loss: 0.2886, validation loss: 0.1710
2024-05-25 00:52:06 [INFO]: Epoch 030 - training loss: 0.2870, validation loss: 0.1697
2024-05-25 00:52:07 [INFO]: Epoch 031 - training loss: 0.2856, validation loss: 0.1687
2024-05-25 00:52:07 [INFO]: Epoch 032 - training loss: 0.2838, validation loss: 0.1677
2024-05-25 00:52:07 [INFO]: Epoch 033 - training loss: 0.2809, validation loss: 0.1674
2024-05-25 00:52:08 [INFO]: Epoch 034 - training loss: 0.2801, validation loss: 0.1660
2024-05-25 00:52:08 [INFO]: Epoch 035 - training loss: 0.2827, validation loss: 0.1663
2024-05-25 00:52:08 [INFO]: Epoch 036 - training loss: 0.2832, validation loss: 0.1643
2024-05-25 00:52:09 [INFO]: Epoch 037 - training loss: 0.2794, validation loss: 0.1653
2024-05-25 00:52:09 [INFO]: Epoch 038 - training loss: 0.2779, validation loss: 0.1637
2024-05-25 00:52:09 [INFO]: Epoch 039 - training loss: 0.2758, validation loss: 0.1628
2024-05-25 00:52:10 [INFO]: Epoch 040 - training loss: 0.2742, validation loss: 0.1635
2024-05-25 00:52:10 [INFO]: Epoch 041 - training loss: 0.2751, validation loss: 0.1618
2024-05-25 00:52:10 [INFO]: Epoch 042 - training loss: 0.2744, validation loss: 0.1630
2024-05-25 00:52:11 [INFO]: Epoch 043 - training loss: 0.2724, validation loss: 0.1607
2024-05-25 00:52:11 [INFO]: Epoch 044 - training loss: 0.2726, validation loss: 0.1622
2024-05-25 00:52:11 [INFO]: Epoch 045 - training loss: 0.2708, validation loss: 0.1624
2024-05-25 00:52:12 [INFO]: Epoch 046 - training loss: 0.2687, validation loss: 0.1618
2024-05-25 00:52:12 [INFO]: Epoch 047 - training loss: 0.2679, validation loss: 0.1618
2024-05-25 00:52:12 [INFO]: Epoch 048 - training loss: 0.2646, validation loss: 0.1599
2024-05-25 00:52:13 [INFO]: Epoch 049 - training loss: 0.2644, validation loss: 0.1601
2024-05-25 00:52:13 [INFO]: Epoch 050 - training loss: 0.2687, validation loss: 0.1621
2024-05-25 00:52:13 [INFO]: Epoch 051 - training loss: 0.2652, validation loss: 0.1606
2024-05-25 00:52:14 [INFO]: Epoch 052 - training loss: 0.2629, validation loss: 0.1568
2024-05-25 00:52:14 [INFO]: Epoch 053 - training loss: 0.2599, validation loss: 0.1595
2024-05-25 00:52:14 [INFO]: Epoch 054 - training loss: 0.2590, validation loss: 0.1612
2024-05-25 00:52:14 [INFO]: Epoch 055 - training loss: 0.2599, validation loss: 0.1579
2024-05-25 00:52:15 [INFO]: Epoch 056 - training loss: 0.2584, validation loss: 0.1585
2024-05-25 00:52:15 [INFO]: Epoch 057 - training loss: 0.2572, validation loss: 0.1582
2024-05-25 00:52:15 [INFO]: Epoch 058 - training loss: 0.2574, validation loss: 0.1600
2024-05-25 00:52:16 [INFO]: Epoch 059 - training loss: 0.2563, validation loss: 0.1582
2024-05-25 00:52:16 [INFO]: Epoch 060 - training loss: 0.2544, validation loss: 0.1566
2024-05-25 00:52:16 [INFO]: Epoch 061 - training loss: 0.2567, validation loss: 0.1580
2024-05-25 00:52:17 [INFO]: Epoch 062 - training loss: 0.2572, validation loss: 0.1555
2024-05-25 00:52:17 [INFO]: Epoch 063 - training loss: 0.2558, validation loss: 0.1557
2024-05-25 00:52:17 [INFO]: Epoch 064 - training loss: 0.2536, validation loss: 0.1557
2024-05-25 00:52:18 [INFO]: Epoch 065 - training loss: 0.2512, validation loss: 0.1545
2024-05-25 00:52:18 [INFO]: Epoch 066 - training loss: 0.2497, validation loss: 0.1574
2024-05-25 00:52:18 [INFO]: Epoch 067 - training loss: 0.2504, validation loss: 0.1541
2024-05-25 00:52:19 [INFO]: Epoch 068 - training loss: 0.2502, validation loss: 0.1538
2024-05-25 00:52:19 [INFO]: Epoch 069 - training loss: 0.2510, validation loss: 0.1554
2024-05-25 00:52:19 [INFO]: Epoch 070 - training loss: 0.2498, validation loss: 0.1563
2024-05-25 00:52:20 [INFO]: Epoch 071 - training loss: 0.2489, validation loss: 0.1534
2024-05-25 00:52:20 [INFO]: Epoch 072 - training loss: 0.2461, validation loss: 0.1561
2024-05-25 00:52:20 [INFO]: Epoch 073 - training loss: 0.2447, validation loss: 0.1548
2024-05-25 00:52:21 [INFO]: Epoch 074 - training loss: 0.2428, validation loss: 0.1556
2024-05-25 00:52:21 [INFO]: Epoch 075 - training loss: 0.2431, validation loss: 0.1541
2024-05-25 00:52:21 [INFO]: Epoch 076 - training loss: 0.2447, validation loss: 0.1550
2024-05-25 00:52:22 [INFO]: Epoch 077 - training loss: 0.2434, validation loss: 0.1531
2024-05-25 00:52:22 [INFO]: Epoch 078 - training loss: 0.2428, validation loss: 0.1538
2024-05-25 00:52:22 [INFO]: Epoch 079 - training loss: 0.2440, validation loss: 0.1535
2024-05-25 00:52:22 [INFO]: Epoch 080 - training loss: 0.2431, validation loss: 0.1514
2024-05-25 00:52:23 [INFO]: Epoch 081 - training loss: 0.2434, validation loss: 0.1511
2024-05-25 00:52:23 [INFO]: Epoch 082 - training loss: 0.2429, validation loss: 0.1516
2024-05-25 00:52:23 [INFO]: Epoch 083 - training loss: 0.2443, validation loss: 0.1515
2024-05-25 00:52:24 [INFO]: Epoch 084 - training loss: 0.2411, validation loss: 0.1520
2024-05-25 00:52:24 [INFO]: Epoch 085 - training loss: 0.2370, validation loss: 0.1512
2024-05-25 00:52:24 [INFO]: Epoch 086 - training loss: 0.2356, validation loss: 0.1507
2024-05-25 00:52:25 [INFO]: Epoch 087 - training loss: 0.2363, validation loss: 0.1496
2024-05-25 00:52:25 [INFO]: Epoch 088 - training loss: 0.2354, validation loss: 0.1497
2024-05-25 00:52:25 [INFO]: Epoch 089 - training loss: 0.2343, validation loss: 0.1487
2024-05-25 00:52:26 [INFO]: Epoch 090 - training loss: 0.2335, validation loss: 0.1496
2024-05-25 00:52:26 [INFO]: Epoch 091 - training loss: 0.2338, validation loss: 0.1501
2024-05-25 00:52:26 [INFO]: Epoch 092 - training loss: 0.2353, validation loss: 0.1504
2024-05-25 00:52:27 [INFO]: Epoch 093 - training loss: 0.2343, validation loss: 0.1477
2024-05-25 00:52:27 [INFO]: Epoch 094 - training loss: 0.2341, validation loss: 0.1510
2024-05-25 00:52:27 [INFO]: Epoch 095 - training loss: 0.2329, validation loss: 0.1496
2024-05-25 00:52:28 [INFO]: Epoch 096 - training loss: 0.2312, validation loss: 0.1472
2024-05-25 00:52:28 [INFO]: Epoch 097 - training loss: 0.2294, validation loss: 0.1471
2024-05-25 00:52:28 [INFO]: Epoch 098 - training loss: 0.2293, validation loss: 0.1487
2024-05-25 00:52:29 [INFO]: Epoch 099 - training loss: 0.2301, validation loss: 0.1491
2024-05-25 00:52:29 [INFO]: Epoch 100 - training loss: 0.2321, validation loss: 0.1477
2024-05-25 00:52:29 [INFO]: Epoch 101 - training loss: 0.2322, validation loss: 0.1469
2024-05-25 00:52:30 [INFO]: Epoch 102 - training loss: 0.2286, validation loss: 0.1471
2024-05-25 00:52:30 [INFO]: Epoch 103 - training loss: 0.2281, validation loss: 0.1470
2024-05-25 00:52:30 [INFO]: Epoch 104 - training loss: 0.2277, validation loss: 0.1486
2024-05-25 00:52:31 [INFO]: Epoch 105 - training loss: 0.2260, validation loss: 0.1457
2024-05-25 00:52:31 [INFO]: Epoch 106 - training loss: 0.2249, validation loss: 0.1476
2024-05-25 00:52:31 [INFO]: Epoch 107 - training loss: 0.2242, validation loss: 0.1448
2024-05-25 00:52:32 [INFO]: Epoch 108 - training loss: 0.2237, validation loss: 0.1462
2024-05-25 00:52:32 [INFO]: Epoch 109 - training loss: 0.2251, validation loss: 0.1464
2024-05-25 00:52:32 [INFO]: Epoch 110 - training loss: 0.2266, validation loss: 0.1473
2024-05-25 00:52:33 [INFO]: Epoch 111 - training loss: 0.2266, validation loss: 0.1441
2024-05-25 00:52:33 [INFO]: Epoch 112 - training loss: 0.2263, validation loss: 0.1449
2024-05-25 00:52:33 [INFO]: Epoch 113 - training loss: 0.2261, validation loss: 0.1448
2024-05-25 00:52:33 [INFO]: Epoch 114 - training loss: 0.2256, validation loss: 0.1440
2024-05-25 00:52:34 [INFO]: Epoch 115 - training loss: 0.2249, validation loss: 0.1445
2024-05-25 00:52:34 [INFO]: Epoch 116 - training loss: 0.2221, validation loss: 0.1437
2024-05-25 00:52:34 [INFO]: Epoch 117 - training loss: 0.2220, validation loss: 0.1444
2024-05-25 00:52:35 [INFO]: Epoch 118 - training loss: 0.2195, validation loss: 0.1443
2024-05-25 00:52:35 [INFO]: Epoch 119 - training loss: 0.2189, validation loss: 0.1424
2024-05-25 00:52:35 [INFO]: Epoch 120 - training loss: 0.2234, validation loss: 0.1442
2024-05-25 00:52:36 [INFO]: Epoch 121 - training loss: 0.2194, validation loss: 0.1426
2024-05-25 00:52:36 [INFO]: Epoch 122 - training loss: 0.2194, validation loss: 0.1410
2024-05-25 00:52:36 [INFO]: Epoch 123 - training loss: 0.2192, validation loss: 0.1424
2024-05-25 00:52:37 [INFO]: Epoch 124 - training loss: 0.2197, validation loss: 0.1409
2024-05-25 00:52:37 [INFO]: Epoch 125 - training loss: 0.2168, validation loss: 0.1416
2024-05-25 00:52:37 [INFO]: Epoch 126 - training loss: 0.2163, validation loss: 0.1423
2024-05-25 00:52:38 [INFO]: Epoch 127 - training loss: 0.2173, validation loss: 0.1445
2024-05-25 00:52:38 [INFO]: Epoch 128 - training loss: 0.2168, validation loss: 0.1412
2024-05-25 00:52:38 [INFO]: Epoch 129 - training loss: 0.2171, validation loss: 0.1423
2024-05-25 00:52:39 [INFO]: Epoch 130 - training loss: 0.2185, validation loss: 0.1428
2024-05-25 00:52:39 [INFO]: Epoch 131 - training loss: 0.2180, validation loss: 0.1424
2024-05-25 00:52:39 [INFO]: Epoch 132 - training loss: 0.2149, validation loss: 0.1421
2024-05-25 00:52:40 [INFO]: Epoch 133 - training loss: 0.2152, validation loss: 0.1404
2024-05-25 00:52:40 [INFO]: Epoch 134 - training loss: 0.2172, validation loss: 0.1402
2024-05-25 00:52:40 [INFO]: Epoch 135 - training loss: 0.2142, validation loss: 0.1404
2024-05-25 00:52:41 [INFO]: Epoch 136 - training loss: 0.2164, validation loss: 0.1421
2024-05-25 00:52:41 [INFO]: Epoch 137 - training loss: 0.2206, validation loss: 0.1402
2024-05-25 00:52:41 [INFO]: Epoch 138 - training loss: 0.2137, validation loss: 0.1392
2024-05-25 00:52:42 [INFO]: Epoch 139 - training loss: 0.2138, validation loss: 0.1389
2024-05-25 00:52:42 [INFO]: Epoch 140 - training loss: 0.2135, validation loss: 0.1407
2024-05-25 00:52:42 [INFO]: Epoch 141 - training loss: 0.2138, validation loss: 0.1400
2024-05-25 00:52:43 [INFO]: Epoch 142 - training loss: 0.2134, validation loss: 0.1383
2024-05-25 00:52:43 [INFO]: Epoch 143 - training loss: 0.2145, validation loss: 0.1387
2024-05-25 00:52:43 [INFO]: Epoch 144 - training loss: 0.2121, validation loss: 0.1401
2024-05-25 00:52:44 [INFO]: Epoch 145 - training loss: 0.2111, validation loss: 0.1392
2024-05-25 00:52:44 [INFO]: Epoch 146 - training loss: 0.2101, validation loss: 0.1377
2024-05-25 00:52:44 [INFO]: Epoch 147 - training loss: 0.2102, validation loss: 0.1380
2024-05-25 00:52:45 [INFO]: Epoch 148 - training loss: 0.2086, validation loss: 0.1394
2024-05-25 00:52:45 [INFO]: Epoch 149 - training loss: 0.2103, validation loss: 0.1398
2024-05-25 00:52:45 [INFO]: Epoch 150 - training loss: 0.2116, validation loss: 0.1389
2024-05-25 00:52:46 [INFO]: Epoch 151 - training loss: 0.2104, validation loss: 0.1377
2024-05-25 00:52:46 [INFO]: Epoch 152 - training loss: 0.2103, validation loss: 0.1376
2024-05-25 00:52:46 [INFO]: Epoch 153 - training loss: 0.2072, validation loss: 0.1375
2024-05-25 00:52:47 [INFO]: Epoch 154 - training loss: 0.2089, validation loss: 0.1364
2024-05-25 00:52:47 [INFO]: Epoch 155 - training loss: 0.2113, validation loss: 0.1369
2024-05-25 00:52:47 [INFO]: Epoch 156 - training loss: 0.2080, validation loss: 0.1382
2024-05-25 00:52:48 [INFO]: Epoch 157 - training loss: 0.2086, validation loss: 0.1371
2024-05-25 00:52:48 [INFO]: Epoch 158 - training loss: 0.2076, validation loss: 0.1357
2024-05-25 00:52:48 [INFO]: Epoch 159 - training loss: 0.2069, validation loss: 0.1367
2024-05-25 00:52:49 [INFO]: Epoch 160 - training loss: 0.2083, validation loss: 0.1357
2024-05-25 00:52:49 [INFO]: Epoch 161 - training loss: 0.2077, validation loss: 0.1363
2024-05-25 00:52:49 [INFO]: Epoch 162 - training loss: 0.2050, validation loss: 0.1360
2024-05-25 00:52:50 [INFO]: Epoch 163 - training loss: 0.2058, validation loss: 0.1356
2024-05-25 00:52:50 [INFO]: Epoch 164 - training loss: 0.2052, validation loss: 0.1350
2024-05-25 00:52:50 [INFO]: Epoch 165 - training loss: 0.2057, validation loss: 0.1364
2024-05-25 00:52:51 [INFO]: Epoch 166 - training loss: 0.2068, validation loss: 0.1357
2024-05-25 00:52:51 [INFO]: Epoch 167 - training loss: 0.2060, validation loss: 0.1356
2024-05-25 00:52:51 [INFO]: Epoch 168 - training loss: 0.2043, validation loss: 0.1368
2024-05-25 00:52:52 [INFO]: Epoch 169 - training loss: 0.2071, validation loss: 0.1348
2024-05-25 00:52:52 [INFO]: Epoch 170 - training loss: 0.2045, validation loss: 0.1346
2024-05-25 00:52:52 [INFO]: Epoch 171 - training loss: 0.2017, validation loss: 0.1347
2024-05-25 00:52:53 [INFO]: Epoch 172 - training loss: 0.2027, validation loss: 0.1333
2024-05-25 00:52:53 [INFO]: Epoch 173 - training loss: 0.2025, validation loss: 0.1348
2024-05-25 00:52:53 [INFO]: Epoch 174 - training loss: 0.2034, validation loss: 0.1332
2024-05-25 00:52:54 [INFO]: Epoch 175 - training loss: 0.2038, validation loss: 0.1343
2024-05-25 00:52:54 [INFO]: Epoch 176 - training loss: 0.2043, validation loss: 0.1341
2024-05-25 00:52:54 [INFO]: Epoch 177 - training loss: 0.2029, validation loss: 0.1335
2024-05-25 00:52:55 [INFO]: Epoch 178 - training loss: 0.2048, validation loss: 0.1328
2024-05-25 00:52:55 [INFO]: Epoch 179 - training loss: 0.2025, validation loss: 0.1328
2024-05-25 00:52:55 [INFO]: Epoch 180 - training loss: 0.2026, validation loss: 0.1322
2024-05-25 00:52:55 [INFO]: Epoch 181 - training loss: 0.2003, validation loss: 0.1336
2024-05-25 00:52:56 [INFO]: Epoch 182 - training loss: 0.2020, validation loss: 0.1333
2024-05-25 00:52:56 [INFO]: Epoch 183 - training loss: 0.2030, validation loss: 0.1323
2024-05-25 00:52:56 [INFO]: Epoch 184 - training loss: 0.1997, validation loss: 0.1322
2024-05-25 00:52:57 [INFO]: Epoch 185 - training loss: 0.2003, validation loss: 0.1329
2024-05-25 00:52:57 [INFO]: Epoch 186 - training loss: 0.1998, validation loss: 0.1337
2024-05-25 00:52:57 [INFO]: Epoch 187 - training loss: 0.2014, validation loss: 0.1317
2024-05-25 00:52:58 [INFO]: Epoch 188 - training loss: 0.1984, validation loss: 0.1318
2024-05-25 00:52:58 [INFO]: Epoch 189 - training loss: 0.1996, validation loss: 0.1341
2024-05-25 00:52:58 [INFO]: Epoch 190 - training loss: 0.2003, validation loss: 0.1316
2024-05-25 00:52:59 [INFO]: Epoch 191 - training loss: 0.1981, validation loss: 0.1315
2024-05-25 00:52:59 [INFO]: Epoch 192 - training loss: 0.1976, validation loss: 0.1304
2024-05-25 00:52:59 [INFO]: Epoch 193 - training loss: 0.1984, validation loss: 0.1313
2024-05-25 00:53:00 [INFO]: Epoch 194 - training loss: 0.1975, validation loss: 0.1318
2024-05-25 00:53:00 [INFO]: Epoch 195 - training loss: 0.1996, validation loss: 0.1301
2024-05-25 00:53:00 [INFO]: Epoch 196 - training loss: 0.1995, validation loss: 0.1310
2024-05-25 00:53:01 [INFO]: Epoch 197 - training loss: 0.1972, validation loss: 0.1324
2024-05-25 00:53:01 [INFO]: Epoch 198 - training loss: 0.1970, validation loss: 0.1305
2024-05-25 00:53:01 [INFO]: Epoch 199 - training loss: 0.1976, validation loss: 0.1309
2024-05-25 00:53:02 [INFO]: Epoch 200 - training loss: 0.1975, validation loss: 0.1312
2024-05-25 00:53:02 [INFO]: Epoch 201 - training loss: 0.1973, validation loss: 0.1319
2024-05-25 00:53:02 [INFO]: Epoch 202 - training loss: 0.1960, validation loss: 0.1299
2024-05-25 00:53:03 [INFO]: Epoch 203 - training loss: 0.1950, validation loss: 0.1300
2024-05-25 00:53:03 [INFO]: Epoch 204 - training loss: 0.1953, validation loss: 0.1306
2024-05-25 00:53:03 [INFO]: Epoch 205 - training loss: 0.1959, validation loss: 0.1301
2024-05-25 00:53:04 [INFO]: Epoch 206 - training loss: 0.1940, validation loss: 0.1305
2024-05-25 00:53:04 [INFO]: Epoch 207 - training loss: 0.1933, validation loss: 0.1283
2024-05-25 00:53:04 [INFO]: Epoch 208 - training loss: 0.1966, validation loss: 0.1299
2024-05-25 00:53:04 [INFO]: Epoch 209 - training loss: 0.1943, validation loss: 0.1298
2024-05-25 00:53:05 [INFO]: Epoch 210 - training loss: 0.1936, validation loss: 0.1317
2024-05-25 00:53:05 [INFO]: Epoch 211 - training loss: 0.1931, validation loss: 0.1289
2024-05-25 00:53:05 [INFO]: Epoch 212 - training loss: 0.1918, validation loss: 0.1291
2024-05-25 00:53:06 [INFO]: Epoch 213 - training loss: 0.1951, validation loss: 0.1280
2024-05-25 00:53:06 [INFO]: Epoch 214 - training loss: 0.1942, validation loss: 0.1291
2024-05-25 00:53:06 [INFO]: Epoch 215 - training loss: 0.1933, validation loss: 0.1302
2024-05-25 00:53:07 [INFO]: Epoch 216 - training loss: 0.1914, validation loss: 0.1292
2024-05-25 00:53:07 [INFO]: Epoch 217 - training loss: 0.1924, validation loss: 0.1284
2024-05-25 00:53:07 [INFO]: Epoch 218 - training loss: 0.1918, validation loss: 0.1294
2024-05-25 00:53:08 [INFO]: Epoch 219 - training loss: 0.1920, validation loss: 0.1293
2024-05-25 00:53:08 [INFO]: Epoch 220 - training loss: 0.1924, validation loss: 0.1276
2024-05-25 00:53:08 [INFO]: Epoch 221 - training loss: 0.1917, validation loss: 0.1293
2024-05-25 00:53:09 [INFO]: Epoch 222 - training loss: 0.1913, validation loss: 0.1309
2024-05-25 00:53:09 [INFO]: Epoch 223 - training loss: 0.1927, validation loss: 0.1291
2024-05-25 00:53:09 [INFO]: Epoch 224 - training loss: 0.1916, validation loss: 0.1299
2024-05-25 00:53:10 [INFO]: Epoch 225 - training loss: 0.1908, validation loss: 0.1282
2024-05-25 00:53:10 [INFO]: Epoch 226 - training loss: 0.1923, validation loss: 0.1290
2024-05-25 00:53:10 [INFO]: Epoch 227 - training loss: 0.1894, validation loss: 0.1289
2024-05-25 00:53:11 [INFO]: Epoch 228 - training loss: 0.1918, validation loss: 0.1283
2024-05-25 00:53:11 [INFO]: Epoch 229 - training loss: 0.1913, validation loss: 0.1293
2024-05-25 00:53:11 [INFO]: Epoch 230 - training loss: 0.1886, validation loss: 0.1266
2024-05-25 00:53:12 [INFO]: Epoch 231 - training loss: 0.1882, validation loss: 0.1269
2024-05-25 00:53:12 [INFO]: Epoch 232 - training loss: 0.1881, validation loss: 0.1285
2024-05-25 00:53:12 [INFO]: Epoch 233 - training loss: 0.1935, validation loss: 0.1283
2024-05-25 00:53:13 [INFO]: Epoch 234 - training loss: 0.1913, validation loss: 0.1274
2024-05-25 00:53:13 [INFO]: Epoch 235 - training loss: 0.1874, validation loss: 0.1277
2024-05-25 00:53:13 [INFO]: Epoch 236 - training loss: 0.1881, validation loss: 0.1272
2024-05-25 00:53:14 [INFO]: Epoch 237 - training loss: 0.1891, validation loss: 0.1267
2024-05-25 00:53:14 [INFO]: Epoch 238 - training loss: 0.1872, validation loss: 0.1297
2024-05-25 00:53:14 [INFO]: Epoch 239 - training loss: 0.1876, validation loss: 0.1267
2024-05-25 00:53:15 [INFO]: Epoch 240 - training loss: 0.1876, validation loss: 0.1287
2024-05-25 00:53:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:53:15 [INFO]: Finished training. The best model is from epoch#230.
2024-05-25 00:53:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/Transformer_air_quality/20240525_T005157/Transformer.pypots
2024-05-25 00:53:15 [INFO]: Transformer on Air-Quality: MAE=0.1554, MSE=0.1148
2024-05-25 00:53:15 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/Transformer_air_quality/imputation.pkl
2024-05-25 00:53:15 [INFO]: Using the given device: cuda:0
2024-05-25 00:53:15 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/TimesNet_air_quality/20240525_T005315
2024-05-25 00:53:15 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/TimesNet_air_quality/20240525_T005315/tensorboard
2024-05-25 00:53:15 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 00:53:16 [INFO]: Epoch 001 - training loss: 0.2874, validation loss: 0.2607
2024-05-25 00:53:16 [INFO]: Epoch 002 - training loss: 0.2351, validation loss: 0.2408
2024-05-25 00:53:17 [INFO]: Epoch 003 - training loss: 0.1901, validation loss: 0.2163
2024-05-25 00:53:17 [INFO]: Epoch 004 - training loss: 0.1835, validation loss: 0.2069
2024-05-25 00:53:18 [INFO]: Epoch 005 - training loss: 0.1785, validation loss: 0.1990
2024-05-25 00:53:18 [INFO]: Epoch 006 - training loss: 0.1459, validation loss: 0.1823
2024-05-25 00:53:19 [INFO]: Epoch 007 - training loss: 0.1520, validation loss: 0.1890
2024-05-25 00:53:19 [INFO]: Epoch 008 - training loss: 0.1553, validation loss: 0.2000
2024-05-25 00:53:20 [INFO]: Epoch 009 - training loss: 0.1469, validation loss: 0.1827
2024-05-25 00:53:21 [INFO]: Epoch 010 - training loss: 0.1474, validation loss: 0.1785
2024-05-25 00:53:21 [INFO]: Epoch 011 - training loss: 0.1465, validation loss: 0.1701
2024-05-25 00:53:22 [INFO]: Epoch 012 - training loss: 0.1673, validation loss: 0.1715
2024-05-25 00:53:22 [INFO]: Epoch 013 - training loss: 0.1295, validation loss: 0.1667
2024-05-25 00:53:23 [INFO]: Epoch 014 - training loss: 0.1439, validation loss: 0.1640
2024-05-25 00:53:23 [INFO]: Epoch 015 - training loss: 0.1291, validation loss: 0.1658
2024-05-25 00:53:24 [INFO]: Epoch 016 - training loss: 0.1371, validation loss: 0.1613
2024-05-25 00:53:24 [INFO]: Epoch 017 - training loss: 0.1212, validation loss: 0.1622
2024-05-25 00:53:25 [INFO]: Epoch 018 - training loss: 0.1288, validation loss: 0.1637
2024-05-25 00:53:25 [INFO]: Epoch 019 - training loss: 0.1254, validation loss: 0.1608
2024-05-25 00:53:26 [INFO]: Epoch 020 - training loss: 0.1093, validation loss: 0.1581
2024-05-25 00:53:26 [INFO]: Epoch 021 - training loss: 0.1188, validation loss: 0.1564
2024-05-25 00:53:27 [INFO]: Epoch 022 - training loss: 0.1228, validation loss: 0.1610
2024-05-25 00:53:27 [INFO]: Epoch 023 - training loss: 0.1227, validation loss: 0.1608
2024-05-25 00:53:28 [INFO]: Epoch 024 - training loss: 0.1264, validation loss: 0.1554
2024-05-25 00:53:29 [INFO]: Epoch 025 - training loss: 0.1224, validation loss: 0.1560
2024-05-25 00:53:29 [INFO]: Epoch 026 - training loss: 0.1121, validation loss: 0.1557
2024-05-25 00:53:30 [INFO]: Epoch 027 - training loss: 0.1251, validation loss: 0.1549
2024-05-25 00:53:30 [INFO]: Epoch 028 - training loss: 0.1256, validation loss: 0.1552
2024-05-25 00:53:31 [INFO]: Epoch 029 - training loss: 0.1150, validation loss: 0.1502
2024-05-25 00:53:31 [INFO]: Epoch 030 - training loss: 0.1298, validation loss: 0.1529
2024-05-25 00:53:32 [INFO]: Epoch 031 - training loss: 0.1136, validation loss: 0.1468
2024-05-25 00:53:32 [INFO]: Epoch 032 - training loss: 0.1162, validation loss: 0.1486
2024-05-25 00:53:33 [INFO]: Epoch 033 - training loss: 0.1204, validation loss: 0.1445
2024-05-25 00:53:33 [INFO]: Epoch 034 - training loss: 0.1074, validation loss: 0.1511
2024-05-25 00:53:34 [INFO]: Epoch 035 - training loss: 0.1199, validation loss: 0.1463
2024-05-25 00:53:34 [INFO]: Epoch 036 - training loss: 0.1069, validation loss: 0.1451
2024-05-25 00:53:35 [INFO]: Epoch 037 - training loss: 0.1081, validation loss: 0.1515
2024-05-25 00:53:36 [INFO]: Epoch 038 - training loss: 0.1106, validation loss: 0.1473
2024-05-25 00:53:36 [INFO]: Epoch 039 - training loss: 0.1167, validation loss: 0.1478
2024-05-25 00:53:37 [INFO]: Epoch 040 - training loss: 0.1274, validation loss: 0.1503
2024-05-25 00:53:37 [INFO]: Epoch 041 - training loss: 0.1153, validation loss: 0.1542
2024-05-25 00:53:38 [INFO]: Epoch 042 - training loss: 0.1242, validation loss: 0.1490
2024-05-25 00:53:38 [INFO]: Epoch 043 - training loss: 0.1295, validation loss: 0.1449
2024-05-25 00:53:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:53:38 [INFO]: Finished training. The best model is from epoch#33.
2024-05-25 00:53:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/TimesNet_air_quality/20240525_T005315/TimesNet.pypots
2024-05-25 00:53:38 [INFO]: TimesNet on Air-Quality: MAE=0.1587, MSE=0.1272
2024-05-25 00:53:38 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/TimesNet_air_quality/imputation.pkl
2024-05-25 00:53:38 [INFO]: Using the given device: cuda:0
2024-05-25 00:53:38 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338
2024-05-25 00:53:38 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/tensorboard
2024-05-25 00:53:38 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 00:53:55 [INFO]: Epoch 001 - training loss: 0.5150, validation loss: 0.3793
2024-05-25 00:53:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch1_loss0.37928278744220734.pypots
2024-05-25 00:54:12 [INFO]: Epoch 002 - training loss: 0.3245, validation loss: 0.3144
2024-05-25 00:54:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch2_loss0.31441231071949005.pypots
2024-05-25 00:54:29 [INFO]: Epoch 003 - training loss: 0.2805, validation loss: 0.2686
2024-05-25 00:54:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch3_loss0.26856742054224014.pypots
2024-05-25 00:54:46 [INFO]: Epoch 004 - training loss: 0.2812, validation loss: 0.2385
2024-05-25 00:54:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch4_loss0.23852382898330687.pypots
2024-05-25 00:55:03 [INFO]: Epoch 005 - training loss: 0.2183, validation loss: 0.2173
2024-05-25 00:55:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch5_loss0.2172707051038742.pypots
2024-05-25 00:55:20 [INFO]: Epoch 006 - training loss: 0.2194, validation loss: 0.1963
2024-05-25 00:55:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch6_loss0.19630181193351745.pypots
2024-05-25 00:55:36 [INFO]: Epoch 007 - training loss: 0.1915, validation loss: 0.1764
2024-05-25 00:55:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch7_loss0.1764151334762573.pypots
2024-05-25 00:55:53 [INFO]: Epoch 008 - training loss: 0.1861, validation loss: 0.1723
2024-05-25 00:55:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch8_loss0.17227572649717332.pypots
2024-05-25 00:56:10 [INFO]: Epoch 009 - training loss: 0.1931, validation loss: 0.1787
2024-05-25 00:56:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch9_loss0.17872070223093034.pypots
2024-05-25 00:56:27 [INFO]: Epoch 010 - training loss: 0.1799, validation loss: 0.1778
2024-05-25 00:56:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch10_loss0.17778769880533218.pypots
2024-05-25 00:56:44 [INFO]: Epoch 011 - training loss: 0.2043, validation loss: 0.1571
2024-05-25 00:56:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch11_loss0.15711720436811447.pypots
2024-05-25 00:57:01 [INFO]: Epoch 012 - training loss: 0.1510, validation loss: 0.1515
2024-05-25 00:57:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch12_loss0.15147309899330139.pypots
2024-05-25 00:57:18 [INFO]: Epoch 013 - training loss: 0.1755, validation loss: 0.1681
2024-05-25 00:57:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch13_loss0.16813823729753494.pypots
2024-05-25 00:57:34 [INFO]: Epoch 014 - training loss: 0.1790, validation loss: 0.1546
2024-05-25 00:57:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch14_loss0.15460914969444275.pypots
2024-05-25 00:57:51 [INFO]: Epoch 015 - training loss: 0.1887, validation loss: 0.1494
2024-05-25 00:57:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch15_loss0.14936536103487014.pypots
2024-05-25 00:58:08 [INFO]: Epoch 016 - training loss: 0.1666, validation loss: 0.1446
2024-05-25 00:58:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch16_loss0.14458934217691422.pypots
2024-05-25 00:58:25 [INFO]: Epoch 017 - training loss: 0.1719, validation loss: 0.1419
2024-05-25 00:58:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch17_loss0.14190806299448014.pypots
2024-05-25 00:58:42 [INFO]: Epoch 018 - training loss: 0.1598, validation loss: 0.1435
2024-05-25 00:58:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch18_loss0.14346106946468354.pypots
2024-05-25 00:58:59 [INFO]: Epoch 019 - training loss: 0.1609, validation loss: 0.1465
2024-05-25 00:58:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch19_loss0.14649177193641663.pypots
2024-05-25 00:59:16 [INFO]: Epoch 020 - training loss: 0.1527, validation loss: 0.1525
2024-05-25 00:59:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch20_loss0.15253904908895494.pypots
2024-05-25 00:59:33 [INFO]: Epoch 021 - training loss: 0.1642, validation loss: 0.1388
2024-05-25 00:59:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch21_loss0.13877809941768646.pypots
2024-05-25 00:59:49 [INFO]: Epoch 022 - training loss: 0.1629, validation loss: 0.1353
2024-05-25 00:59:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch22_loss0.13529314771294593.pypots
2024-05-25 01:00:06 [INFO]: Epoch 023 - training loss: 0.1462, validation loss: 0.1345
2024-05-25 01:00:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch23_loss0.13445434644818305.pypots
2024-05-25 01:00:23 [INFO]: Epoch 024 - training loss: 0.1544, validation loss: 0.1357
2024-05-25 01:00:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch24_loss0.135677320510149.pypots
2024-05-25 01:00:40 [INFO]: Epoch 025 - training loss: 0.1538, validation loss: 0.1334
2024-05-25 01:00:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch25_loss0.1334259532392025.pypots
2024-05-25 01:00:57 [INFO]: Epoch 026 - training loss: 0.1595, validation loss: 0.1334
2024-05-25 01:00:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch26_loss0.1334163323044777.pypots
2024-05-25 01:01:14 [INFO]: Epoch 027 - training loss: 0.1515, validation loss: 0.1411
2024-05-25 01:01:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch27_loss0.14111695140600206.pypots
2024-05-25 01:01:31 [INFO]: Epoch 028 - training loss: 0.1503, validation loss: 0.1449
2024-05-25 01:01:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch28_loss0.1448657587170601.pypots
2024-05-25 01:01:48 [INFO]: Epoch 029 - training loss: 0.1652, validation loss: 0.1353
2024-05-25 01:01:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch29_loss0.13527414873242377.pypots
2024-05-25 01:02:05 [INFO]: Epoch 030 - training loss: 0.1524, validation loss: 0.1274
2024-05-25 01:02:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch30_loss0.1274178110063076.pypots
2024-05-25 01:02:21 [INFO]: Epoch 031 - training loss: 0.1353, validation loss: 0.1255
2024-05-25 01:02:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch31_loss0.12553420811891555.pypots
2024-05-25 01:02:38 [INFO]: Epoch 032 - training loss: 0.1330, validation loss: 0.1306
2024-05-25 01:02:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch32_loss0.13056464716792107.pypots
2024-05-25 01:02:55 [INFO]: Epoch 033 - training loss: 0.1342, validation loss: 0.1279
2024-05-25 01:02:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch33_loss0.12792264223098754.pypots
2024-05-25 01:03:12 [INFO]: Epoch 034 - training loss: 0.1343, validation loss: 0.1299
2024-05-25 01:03:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch34_loss0.129879929125309.pypots
2024-05-25 01:03:29 [INFO]: Epoch 035 - training loss: 0.1444, validation loss: 0.1278
2024-05-25 01:03:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch35_loss0.12782464697957038.pypots
2024-05-25 01:03:46 [INFO]: Epoch 036 - training loss: 0.1252, validation loss: 0.1285
2024-05-25 01:03:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch36_loss0.12851674780249595.pypots
2024-05-25 01:04:03 [INFO]: Epoch 037 - training loss: 0.1196, validation loss: 0.1223
2024-05-25 01:04:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch37_loss0.12232595980167389.pypots
2024-05-25 01:04:20 [INFO]: Epoch 038 - training loss: 0.1289, validation loss: 0.1215
2024-05-25 01:04:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch38_loss0.12146270722150802.pypots
2024-05-25 01:04:36 [INFO]: Epoch 039 - training loss: 0.1402, validation loss: 0.1221
2024-05-25 01:04:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch39_loss0.12211649566888809.pypots
2024-05-25 01:04:53 [INFO]: Epoch 040 - training loss: 0.1266, validation loss: 0.1212
2024-05-25 01:04:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch40_loss0.12118639275431634.pypots
2024-05-25 01:05:10 [INFO]: Epoch 041 - training loss: 0.1332, validation loss: 0.1198
2024-05-25 01:05:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch41_loss0.1197728879749775.pypots
2024-05-25 01:05:27 [INFO]: Epoch 042 - training loss: 0.1183, validation loss: 0.1196
2024-05-25 01:05:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch42_loss0.11956247985363007.pypots
2024-05-25 01:05:44 [INFO]: Epoch 043 - training loss: 0.1269, validation loss: 0.1180
2024-05-25 01:05:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch43_loss0.11802067458629609.pypots
2024-05-25 01:06:01 [INFO]: Epoch 044 - training loss: 0.1321, validation loss: 0.1188
2024-05-25 01:06:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch44_loss0.1187751829624176.pypots
2024-05-25 01:06:18 [INFO]: Epoch 045 - training loss: 0.1245, validation loss: 0.1185
2024-05-25 01:06:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch45_loss0.11847671642899513.pypots
2024-05-25 01:06:35 [INFO]: Epoch 046 - training loss: 0.1215, validation loss: 0.1154
2024-05-25 01:06:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch46_loss0.1153730072081089.pypots
2024-05-25 01:06:51 [INFO]: Epoch 047 - training loss: 0.1304, validation loss: 0.1173
2024-05-25 01:06:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch47_loss0.1173250287771225.pypots
2024-05-25 01:07:08 [INFO]: Epoch 048 - training loss: 0.1244, validation loss: 0.1161
2024-05-25 01:07:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch48_loss0.11606568843126297.pypots
2024-05-25 01:07:25 [INFO]: Epoch 049 - training loss: 0.1316, validation loss: 0.1200
2024-05-25 01:07:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch49_loss0.12003728002309799.pypots
2024-05-25 01:07:42 [INFO]: Epoch 050 - training loss: 0.1304, validation loss: 0.1177
2024-05-25 01:07:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch50_loss0.11774946972727776.pypots
2024-05-25 01:07:59 [INFO]: Epoch 051 - training loss: 0.1221, validation loss: 0.1169
2024-05-25 01:07:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch51_loss0.1169447883963585.pypots
2024-05-25 01:08:16 [INFO]: Epoch 052 - training loss: 0.1364, validation loss: 0.1189
2024-05-25 01:08:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch52_loss0.11890339627861976.pypots
2024-05-25 01:08:33 [INFO]: Epoch 053 - training loss: 0.1340, validation loss: 0.1130
2024-05-25 01:08:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch53_loss0.11298402547836303.pypots
2024-05-25 01:08:50 [INFO]: Epoch 054 - training loss: 0.1322, validation loss: 0.1102
2024-05-25 01:08:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch54_loss0.1101820707321167.pypots
2024-05-25 01:09:06 [INFO]: Epoch 055 - training loss: 0.1138, validation loss: 0.1153
2024-05-25 01:09:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch55_loss0.11527779400348663.pypots
2024-05-25 01:09:23 [INFO]: Epoch 056 - training loss: 0.1208, validation loss: 0.1117
2024-05-25 01:09:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch56_loss0.11171121820807457.pypots
2024-05-25 01:09:40 [INFO]: Epoch 057 - training loss: 0.1165, validation loss: 0.1148
2024-05-25 01:09:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch57_loss0.11476783975958824.pypots
2024-05-25 01:09:57 [INFO]: Epoch 058 - training loss: 0.1275, validation loss: 0.1117
2024-05-25 01:09:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch58_loss0.11174605190753936.pypots
2024-05-25 01:10:14 [INFO]: Epoch 059 - training loss: 0.1223, validation loss: 0.1116
2024-05-25 01:10:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch59_loss0.11157960966229438.pypots
2024-05-25 01:10:31 [INFO]: Epoch 060 - training loss: 0.1256, validation loss: 0.1118
2024-05-25 01:10:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch60_loss0.11175846755504608.pypots
2024-05-25 01:10:48 [INFO]: Epoch 061 - training loss: 0.1303, validation loss: 0.1090
2024-05-25 01:10:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch61_loss0.10903272926807403.pypots
2024-05-25 01:11:04 [INFO]: Epoch 062 - training loss: 0.1238, validation loss: 0.1086
2024-05-25 01:11:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch62_loss0.1086342304944992.pypots
2024-05-25 01:11:21 [INFO]: Epoch 063 - training loss: 0.1225, validation loss: 0.1104
2024-05-25 01:11:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch63_loss0.1104230284690857.pypots
2024-05-25 01:11:38 [INFO]: Epoch 064 - training loss: 0.1120, validation loss: 0.1082
2024-05-25 01:11:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch64_loss0.10822593644261361.pypots
2024-05-25 01:11:55 [INFO]: Epoch 065 - training loss: 0.1199, validation loss: 0.1116
2024-05-25 01:11:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch65_loss0.111604705452919.pypots
2024-05-25 01:12:12 [INFO]: Epoch 066 - training loss: 0.1322, validation loss: 0.1071
2024-05-25 01:12:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch66_loss0.10706511288881301.pypots
2024-05-25 01:12:29 [INFO]: Epoch 067 - training loss: 0.1250, validation loss: 0.1062
2024-05-25 01:12:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch67_loss0.10621910691261291.pypots
2024-05-25 01:12:46 [INFO]: Epoch 068 - training loss: 0.1181, validation loss: 0.1083
2024-05-25 01:12:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch68_loss0.10831602215766907.pypots
2024-05-25 01:13:03 [INFO]: Epoch 069 - training loss: 0.1308, validation loss: 0.1065
2024-05-25 01:13:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch69_loss0.10646468251943589.pypots
2024-05-25 01:13:19 [INFO]: Epoch 070 - training loss: 0.1172, validation loss: 0.1078
2024-05-25 01:13:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch70_loss0.10777197107672691.pypots
2024-05-25 01:13:36 [INFO]: Epoch 071 - training loss: 0.1290, validation loss: 0.1089
2024-05-25 01:13:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch71_loss0.10889356583356857.pypots
2024-05-25 01:13:53 [INFO]: Epoch 072 - training loss: 0.1162, validation loss: 0.1066
2024-05-25 01:13:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch72_loss0.10657113492488861.pypots
2024-05-25 01:14:10 [INFO]: Epoch 073 - training loss: 0.1340, validation loss: 0.1085
2024-05-25 01:14:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch73_loss0.1085057720541954.pypots
2024-05-25 01:14:27 [INFO]: Epoch 074 - training loss: 0.1109, validation loss: 0.1064
2024-05-25 01:14:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch74_loss0.1064450852572918.pypots
2024-05-25 01:14:44 [INFO]: Epoch 075 - training loss: 0.1218, validation loss: 0.1066
2024-05-25 01:14:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch75_loss0.10656390562653542.pypots
2024-05-25 01:15:01 [INFO]: Epoch 076 - training loss: 0.1239, validation loss: 0.1102
2024-05-25 01:15:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch76_loss0.11023368537425995.pypots
2024-05-25 01:15:18 [INFO]: Epoch 077 - training loss: 0.1249, validation loss: 0.1104
2024-05-25 01:15:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI_epoch77_loss0.11039020121097565.pypots
2024-05-25 01:15:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:15:18 [INFO]: Finished training. The best model is from epoch#67.
2024-05-25 01:15:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T005338/CSDI.pypots
2024-05-25 01:17:38 [INFO]: CSDI on Air-Quality: MAE=0.1041, MSE=0.1088
2024-05-25 01:17:38 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/CSDI_air_quality/imputation.pkl
2024-05-25 01:17:38 [INFO]: Using the given device: cuda:0
2024-05-25 01:17:38 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/GPVAE_air_quality/20240525_T011738
2024-05-25 01:17:38 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/GPVAE_air_quality/20240525_T011738/tensorboard
2024-05-25 01:17:38 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 01:17:39 [INFO]: Epoch 001 - training loss: 64254.0498, validation loss: 0.6680
2024-05-25 01:17:39 [INFO]: Epoch 002 - training loss: 42107.1137, validation loss: 0.5971
2024-05-25 01:17:39 [INFO]: Epoch 003 - training loss: 41777.8001, validation loss: 0.5493
2024-05-25 01:17:40 [INFO]: Epoch 004 - training loss: 41620.9618, validation loss: 0.4692
2024-05-25 01:17:40 [INFO]: Epoch 005 - training loss: 41608.3634, validation loss: 0.4494
2024-05-25 01:17:40 [INFO]: Epoch 006 - training loss: 41511.0204, validation loss: 0.3896
2024-05-25 01:17:41 [INFO]: Epoch 007 - training loss: 41450.7280, validation loss: 0.3817
2024-05-25 01:17:41 [INFO]: Epoch 008 - training loss: 41426.3119, validation loss: 0.3537
2024-05-25 01:17:41 [INFO]: Epoch 009 - training loss: 41379.9313, validation loss: 0.3248
2024-05-25 01:17:42 [INFO]: Epoch 010 - training loss: 41358.7650, validation loss: 0.3256
2024-05-25 01:17:42 [INFO]: Epoch 011 - training loss: 41369.0425, validation loss: 0.3205
2024-05-25 01:17:42 [INFO]: Epoch 012 - training loss: 41370.8277, validation loss: 0.3304
2024-05-25 01:17:43 [INFO]: Epoch 013 - training loss: 41342.1373, validation loss: 0.3209
2024-05-25 01:17:43 [INFO]: Epoch 014 - training loss: 41321.6259, validation loss: 0.3214
2024-05-25 01:17:44 [INFO]: Epoch 015 - training loss: 41299.4576, validation loss: 0.2952
2024-05-25 01:17:44 [INFO]: Epoch 016 - training loss: 41289.2198, validation loss: 0.3002
2024-05-25 01:17:44 [INFO]: Epoch 017 - training loss: 41289.9703, validation loss: 0.2886
2024-05-25 01:17:45 [INFO]: Epoch 018 - training loss: 41270.4621, validation loss: 0.3055
2024-05-25 01:17:45 [INFO]: Epoch 019 - training loss: 41283.2118, validation loss: 0.2998
2024-05-25 01:17:45 [INFO]: Epoch 020 - training loss: 41276.5734, validation loss: 0.2718
2024-05-25 01:17:46 [INFO]: Epoch 021 - training loss: 41255.4693, validation loss: 0.2682
2024-05-25 01:17:46 [INFO]: Epoch 022 - training loss: 41249.5692, validation loss: 0.2721
2024-05-25 01:17:46 [INFO]: Epoch 023 - training loss: 41284.2643, validation loss: 0.2863
2024-05-25 01:17:47 [INFO]: Epoch 024 - training loss: 41260.9780, validation loss: 0.2928
2024-05-25 01:17:47 [INFO]: Epoch 025 - training loss: 41259.2260, validation loss: 0.2761
2024-05-25 01:17:47 [INFO]: Epoch 026 - training loss: 41273.2852, validation loss: 0.2599
2024-05-25 01:17:48 [INFO]: Epoch 027 - training loss: 41268.7383, validation loss: 0.3089
2024-05-25 01:17:48 [INFO]: Epoch 028 - training loss: 41294.6613, validation loss: 0.2695
2024-05-25 01:17:48 [INFO]: Epoch 029 - training loss: 41243.9589, validation loss: 0.2648
2024-05-25 01:17:49 [INFO]: Epoch 030 - training loss: 41232.0305, validation loss: 0.2531
2024-05-25 01:17:49 [INFO]: Epoch 031 - training loss: 41211.6221, validation loss: 0.2462
2024-05-25 01:17:49 [INFO]: Epoch 032 - training loss: 41201.0499, validation loss: 0.2436
2024-05-25 01:17:50 [INFO]: Epoch 033 - training loss: 41195.9294, validation loss: 0.2457
2024-05-25 01:17:50 [INFO]: Epoch 034 - training loss: 41197.2567, validation loss: 0.2470
2024-05-25 01:17:51 [INFO]: Epoch 035 - training loss: 41209.1625, validation loss: 0.2518
2024-05-25 01:17:51 [INFO]: Epoch 036 - training loss: 41202.0075, validation loss: 0.2360
2024-05-25 01:17:51 [INFO]: Epoch 037 - training loss: 41195.0732, validation loss: 0.2423
2024-05-25 01:17:52 [INFO]: Epoch 038 - training loss: 41198.5939, validation loss: 0.2346
2024-05-25 01:17:52 [INFO]: Epoch 039 - training loss: 41189.4764, validation loss: 0.2396
2024-05-25 01:17:52 [INFO]: Epoch 040 - training loss: 41192.0463, validation loss: 0.2342
2024-05-25 01:17:53 [INFO]: Epoch 041 - training loss: 41177.0093, validation loss: 0.2329
2024-05-25 01:17:53 [INFO]: Epoch 042 - training loss: 41177.7821, validation loss: 0.2367
2024-05-25 01:17:53 [INFO]: Epoch 043 - training loss: 41186.0786, validation loss: 0.2286
2024-05-25 01:17:54 [INFO]: Epoch 044 - training loss: 41177.6308, validation loss: 0.2381
2024-05-25 01:17:54 [INFO]: Epoch 045 - training loss: 41188.0078, validation loss: 0.2350
2024-05-25 01:17:54 [INFO]: Epoch 046 - training loss: 41258.8785, validation loss: 0.2752
2024-05-25 01:17:55 [INFO]: Epoch 047 - training loss: 41240.7769, validation loss: 0.2533
2024-05-25 01:17:55 [INFO]: Epoch 048 - training loss: 41226.4944, validation loss: 0.2345
2024-05-25 01:17:55 [INFO]: Epoch 049 - training loss: 41176.4180, validation loss: 0.2281
2024-05-25 01:17:56 [INFO]: Epoch 050 - training loss: 41243.5437, validation loss: 0.2461
2024-05-25 01:17:56 [INFO]: Epoch 051 - training loss: 41187.4469, validation loss: 0.2263
2024-05-25 01:17:57 [INFO]: Epoch 052 - training loss: 41176.9125, validation loss: 0.2282
2024-05-25 01:17:57 [INFO]: Epoch 053 - training loss: 41163.7409, validation loss: 0.2205
2024-05-25 01:17:57 [INFO]: Epoch 054 - training loss: 41159.9300, validation loss: 0.2165
2024-05-25 01:17:58 [INFO]: Epoch 055 - training loss: 41159.8896, validation loss: 0.2241
2024-05-25 01:17:58 [INFO]: Epoch 056 - training loss: 41175.8048, validation loss: 0.2198
2024-05-25 01:17:58 [INFO]: Epoch 057 - training loss: 41165.6982, validation loss: 0.2230
2024-05-25 01:17:59 [INFO]: Epoch 058 - training loss: 41181.9495, validation loss: 0.2223
2024-05-25 01:17:59 [INFO]: Epoch 059 - training loss: 41181.0673, validation loss: 0.2410
2024-05-25 01:17:59 [INFO]: Epoch 060 - training loss: 41161.4172, validation loss: 0.2275
2024-05-25 01:18:00 [INFO]: Epoch 061 - training loss: 41157.1017, validation loss: 0.2137
2024-05-25 01:18:00 [INFO]: Epoch 062 - training loss: 41157.8707, validation loss: 0.2264
2024-05-25 01:18:00 [INFO]: Epoch 063 - training loss: 41147.1882, validation loss: 0.2114
2024-05-25 01:18:00 [INFO]: Epoch 064 - training loss: 41150.6697, validation loss: 0.2351
2024-05-25 01:18:01 [INFO]: Epoch 065 - training loss: 41163.6163, validation loss: 0.2152
2024-05-25 01:18:01 [INFO]: Epoch 066 - training loss: 41143.6306, validation loss: 0.2127
2024-05-25 01:18:01 [INFO]: Epoch 067 - training loss: 41143.2319, validation loss: 0.2243
2024-05-25 01:18:02 [INFO]: Epoch 068 - training loss: 41155.1194, validation loss: 0.2155
2024-05-25 01:18:02 [INFO]: Epoch 069 - training loss: 41153.0725, validation loss: 0.2163
2024-05-25 01:18:03 [INFO]: Epoch 070 - training loss: 41141.9486, validation loss: 0.2390
2024-05-25 01:18:03 [INFO]: Epoch 071 - training loss: 41213.4544, validation loss: 0.2637
2024-05-25 01:18:03 [INFO]: Epoch 072 - training loss: 41187.8245, validation loss: 0.2239
2024-05-25 01:18:04 [INFO]: Epoch 073 - training loss: 41165.4206, validation loss: 0.2153
2024-05-25 01:18:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:18:04 [INFO]: Finished training. The best model is from epoch#63.
2024-05-25 01:18:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/GPVAE_air_quality/20240525_T011738/GPVAE.pypots
2024-05-25 01:18:04 [INFO]: GP-VAE on Air-Quality: MAE=0.2677, MSE=0.2119
2024-05-25 01:18:04 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/GPVAE_air_quality/imputation.pkl
2024-05-25 01:18:04 [INFO]: Using the given device: cuda:0
2024-05-25 01:18:04 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/USGAN_air_quality/20240525_T011804
2024-05-25 01:18:04 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/USGAN_air_quality/20240525_T011804/tensorboard
2024-05-25 01:18:04 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 01:18:09 [INFO]: Epoch 001 - generator training loss: 0.6134, discriminator training loss: 0.3056, validation loss: 0.5038
2024-05-25 01:18:13 [INFO]: Epoch 002 - generator training loss: 0.2917, discriminator training loss: 0.0675, validation loss: 0.3860
2024-05-25 01:18:17 [INFO]: Epoch 003 - generator training loss: 0.2196, discriminator training loss: 0.0637, validation loss: 0.3268
2024-05-25 01:18:21 [INFO]: Epoch 004 - generator training loss: 0.1820, discriminator training loss: 0.0624, validation loss: 0.2833
2024-05-25 01:18:25 [INFO]: Epoch 005 - generator training loss: 0.1578, discriminator training loss: 0.0617, validation loss: 0.2558
2024-05-25 01:18:29 [INFO]: Epoch 006 - generator training loss: 0.1390, discriminator training loss: 0.0612, validation loss: 0.2351
2024-05-25 01:18:34 [INFO]: Epoch 007 - generator training loss: 0.1251, discriminator training loss: 0.0608, validation loss: 0.2177
2024-05-25 01:18:38 [INFO]: Epoch 008 - generator training loss: 0.1149, discriminator training loss: 0.0601, validation loss: 0.2059
2024-05-25 01:18:42 [INFO]: Epoch 009 - generator training loss: 0.1058, discriminator training loss: 0.0594, validation loss: 0.1962
2024-05-25 01:18:46 [INFO]: Epoch 010 - generator training loss: 0.1001, discriminator training loss: 0.0584, validation loss: 0.1887
2024-05-25 01:18:50 [INFO]: Epoch 011 - generator training loss: 0.0949, discriminator training loss: 0.0577, validation loss: 0.1825
2024-05-25 01:18:54 [INFO]: Epoch 012 - generator training loss: 0.0915, discriminator training loss: 0.0561, validation loss: 0.1766
2024-05-25 01:18:59 [INFO]: Epoch 013 - generator training loss: 0.0864, discriminator training loss: 0.0548, validation loss: 0.1714
2024-05-25 01:19:03 [INFO]: Epoch 014 - generator training loss: 0.0833, discriminator training loss: 0.0528, validation loss: 0.1672
2024-05-25 01:19:07 [INFO]: Epoch 015 - generator training loss: 0.0806, discriminator training loss: 0.0508, validation loss: 0.1623
2024-05-25 01:19:11 [INFO]: Epoch 016 - generator training loss: 0.0795, discriminator training loss: 0.0486, validation loss: 0.1588
2024-05-25 01:19:16 [INFO]: Epoch 017 - generator training loss: 0.0763, discriminator training loss: 0.0474, validation loss: 0.1557
2024-05-25 01:19:20 [INFO]: Epoch 018 - generator training loss: 0.0750, discriminator training loss: 0.0462, validation loss: 0.1534
2024-05-25 01:19:24 [INFO]: Epoch 019 - generator training loss: 0.0736, discriminator training loss: 0.0454, validation loss: 0.1499
2024-05-25 01:19:28 [INFO]: Epoch 020 - generator training loss: 0.0713, discriminator training loss: 0.0451, validation loss: 0.1480
2024-05-25 01:19:32 [INFO]: Epoch 021 - generator training loss: 0.0688, discriminator training loss: 0.0441, validation loss: 0.1459
2024-05-25 01:19:36 [INFO]: Epoch 022 - generator training loss: 0.0673, discriminator training loss: 0.0432, validation loss: 0.1432
2024-05-25 01:19:41 [INFO]: Epoch 023 - generator training loss: 0.0649, discriminator training loss: 0.0428, validation loss: 0.1409
2024-05-25 01:19:45 [INFO]: Epoch 024 - generator training loss: 0.0646, discriminator training loss: 0.0415, validation loss: 0.1397
2024-05-25 01:19:49 [INFO]: Epoch 025 - generator training loss: 0.0631, discriminator training loss: 0.0410, validation loss: 0.1376
2024-05-25 01:19:53 [INFO]: Epoch 026 - generator training loss: 0.0622, discriminator training loss: 0.0401, validation loss: 0.1360
2024-05-25 01:19:58 [INFO]: Epoch 027 - generator training loss: 0.0611, discriminator training loss: 0.0396, validation loss: 0.1347
2024-05-25 01:20:02 [INFO]: Epoch 028 - generator training loss: 0.0594, discriminator training loss: 0.0387, validation loss: 0.1337
2024-05-25 01:20:06 [INFO]: Epoch 029 - generator training loss: 0.0603, discriminator training loss: 0.0386, validation loss: 0.1320
2024-05-25 01:20:10 [INFO]: Epoch 030 - generator training loss: 0.0589, discriminator training loss: 0.0374, validation loss: 0.1304
2024-05-25 01:20:14 [INFO]: Epoch 031 - generator training loss: 0.0579, discriminator training loss: 0.0361, validation loss: 0.1288
2024-05-25 01:20:19 [INFO]: Epoch 032 - generator training loss: 0.0570, discriminator training loss: 0.0355, validation loss: 0.1277
2024-05-25 01:20:23 [INFO]: Epoch 033 - generator training loss: 0.0564, discriminator training loss: 0.0348, validation loss: 0.1265
2024-05-25 01:20:27 [INFO]: Epoch 034 - generator training loss: 0.0560, discriminator training loss: 0.0341, validation loss: 0.1247
2024-05-25 01:20:31 [INFO]: Epoch 035 - generator training loss: 0.0548, discriminator training loss: 0.0336, validation loss: 0.1240
2024-05-25 01:20:35 [INFO]: Epoch 036 - generator training loss: 0.0553, discriminator training loss: 0.0325, validation loss: 0.1227
2024-05-25 01:20:40 [INFO]: Epoch 037 - generator training loss: 0.0545, discriminator training loss: 0.0319, validation loss: 0.1223
2024-05-25 01:20:44 [INFO]: Epoch 038 - generator training loss: 0.0548, discriminator training loss: 0.0313, validation loss: 0.1211
2024-05-25 01:20:48 [INFO]: Epoch 039 - generator training loss: 0.0547, discriminator training loss: 0.0307, validation loss: 0.1200
2024-05-25 01:20:52 [INFO]: Epoch 040 - generator training loss: 0.0531, discriminator training loss: 0.0301, validation loss: 0.1195
2024-05-25 01:20:56 [INFO]: Epoch 041 - generator training loss: 0.0526, discriminator training loss: 0.0296, validation loss: 0.1191
2024-05-25 01:21:00 [INFO]: Epoch 042 - generator training loss: 0.0527, discriminator training loss: 0.0288, validation loss: 0.1178
2024-05-25 01:21:05 [INFO]: Epoch 043 - generator training loss: 0.0523, discriminator training loss: 0.0285, validation loss: 0.1170
2024-05-25 01:21:09 [INFO]: Epoch 044 - generator training loss: 0.0524, discriminator training loss: 0.0282, validation loss: 0.1167
2024-05-25 01:21:13 [INFO]: Epoch 045 - generator training loss: 0.0513, discriminator training loss: 0.0277, validation loss: 0.1155
2024-05-25 01:21:17 [INFO]: Epoch 046 - generator training loss: 0.0509, discriminator training loss: 0.0269, validation loss: 0.1154
2024-05-25 01:21:21 [INFO]: Epoch 047 - generator training loss: 0.0505, discriminator training loss: 0.0269, validation loss: 0.1153
2024-05-25 01:21:26 [INFO]: Epoch 048 - generator training loss: 0.0511, discriminator training loss: 0.0267, validation loss: 0.1144
2024-05-25 01:21:30 [INFO]: Epoch 049 - generator training loss: 0.0502, discriminator training loss: 0.0260, validation loss: 0.1137
2024-05-25 01:21:34 [INFO]: Epoch 050 - generator training loss: 0.0502, discriminator training loss: 0.0256, validation loss: 0.1132
2024-05-25 01:21:38 [INFO]: Epoch 051 - generator training loss: 0.0497, discriminator training loss: 0.0251, validation loss: 0.1122
2024-05-25 01:21:43 [INFO]: Epoch 052 - generator training loss: 0.0502, discriminator training loss: 0.0249, validation loss: 0.1123
2024-05-25 01:21:47 [INFO]: Epoch 053 - generator training loss: 0.0491, discriminator training loss: 0.0241, validation loss: 0.1114
2024-05-25 01:21:51 [INFO]: Epoch 054 - generator training loss: 0.0484, discriminator training loss: 0.0241, validation loss: 0.1108
2024-05-25 01:21:55 [INFO]: Epoch 055 - generator training loss: 0.0482, discriminator training loss: 0.0236, validation loss: 0.1106
2024-05-25 01:21:59 [INFO]: Epoch 056 - generator training loss: 0.0477, discriminator training loss: 0.0235, validation loss: 0.1106
2024-05-25 01:22:03 [INFO]: Epoch 057 - generator training loss: 0.0491, discriminator training loss: 0.0228, validation loss: 0.1102
2024-05-25 01:22:08 [INFO]: Epoch 058 - generator training loss: 0.0478, discriminator training loss: 0.0228, validation loss: 0.1090
2024-05-25 01:22:12 [INFO]: Epoch 059 - generator training loss: 0.0480, discriminator training loss: 0.0224, validation loss: 0.1092
2024-05-25 01:22:16 [INFO]: Epoch 060 - generator training loss: 0.0472, discriminator training loss: 0.0217, validation loss: 0.1087
2024-05-25 01:22:20 [INFO]: Epoch 061 - generator training loss: 0.0474, discriminator training loss: 0.0217, validation loss: 0.1085
2024-05-25 01:22:25 [INFO]: Epoch 062 - generator training loss: 0.0463, discriminator training loss: 0.0216, validation loss: 0.1079
2024-05-25 01:22:29 [INFO]: Epoch 063 - generator training loss: 0.0460, discriminator training loss: 0.0209, validation loss: 0.1078
2024-05-25 01:22:33 [INFO]: Epoch 064 - generator training loss: 0.0460, discriminator training loss: 0.0208, validation loss: 0.1076
2024-05-25 01:22:37 [INFO]: Epoch 065 - generator training loss: 0.0459, discriminator training loss: 0.0205, validation loss: 0.1073
2024-05-25 01:22:41 [INFO]: Epoch 066 - generator training loss: 0.0452, discriminator training loss: 0.0204, validation loss: 0.1073
2024-05-25 01:22:45 [INFO]: Epoch 067 - generator training loss: 0.0453, discriminator training loss: 0.0201, validation loss: 0.1067
2024-05-25 01:22:50 [INFO]: Epoch 068 - generator training loss: 0.0449, discriminator training loss: 0.0199, validation loss: 0.1067
2024-05-25 01:22:54 [INFO]: Epoch 069 - generator training loss: 0.0456, discriminator training loss: 0.0196, validation loss: 0.1067
2024-05-25 01:22:58 [INFO]: Epoch 070 - generator training loss: 0.0447, discriminator training loss: 0.0195, validation loss: 0.1066
2024-05-25 01:23:02 [INFO]: Epoch 071 - generator training loss: 0.0450, discriminator training loss: 0.0194, validation loss: 0.1065
2024-05-25 01:23:06 [INFO]: Epoch 072 - generator training loss: 0.0445, discriminator training loss: 0.0192, validation loss: 0.1062
2024-05-25 01:23:11 [INFO]: Epoch 073 - generator training loss: 0.0451, discriminator training loss: 0.0187, validation loss: 0.1059
2024-05-25 01:23:15 [INFO]: Epoch 074 - generator training loss: 0.0439, discriminator training loss: 0.0185, validation loss: 0.1055
2024-05-25 01:23:19 [INFO]: Epoch 075 - generator training loss: 0.0441, discriminator training loss: 0.0187, validation loss: 0.1051
2024-05-25 01:23:23 [INFO]: Epoch 076 - generator training loss: 0.0429, discriminator training loss: 0.0184, validation loss: 0.1051
2024-05-25 01:23:27 [INFO]: Epoch 077 - generator training loss: 0.0428, discriminator training loss: 0.0183, validation loss: 0.1052
2024-05-25 01:23:32 [INFO]: Epoch 078 - generator training loss: 0.0426, discriminator training loss: 0.0181, validation loss: 0.1056
2024-05-25 01:23:36 [INFO]: Epoch 079 - generator training loss: 0.0424, discriminator training loss: 0.0179, validation loss: 0.1047
2024-05-25 01:23:40 [INFO]: Epoch 080 - generator training loss: 0.0421, discriminator training loss: 0.0178, validation loss: 0.1042
2024-05-25 01:23:44 [INFO]: Epoch 081 - generator training loss: 0.0416, discriminator training loss: 0.0175, validation loss: 0.1048
2024-05-25 01:23:49 [INFO]: Epoch 082 - generator training loss: 0.0418, discriminator training loss: 0.0174, validation loss: 0.1045
2024-05-25 01:23:53 [INFO]: Epoch 083 - generator training loss: 0.0413, discriminator training loss: 0.0174, validation loss: 0.1045
2024-05-25 01:23:57 [INFO]: Epoch 084 - generator training loss: 0.0413, discriminator training loss: 0.0172, validation loss: 0.1039
2024-05-25 01:24:01 [INFO]: Epoch 085 - generator training loss: 0.0425, discriminator training loss: 0.0172, validation loss: 0.1035
2024-05-25 01:24:05 [INFO]: Epoch 086 - generator training loss: 0.0412, discriminator training loss: 0.0169, validation loss: 0.1040
2024-05-25 01:24:09 [INFO]: Epoch 087 - generator training loss: 0.0409, discriminator training loss: 0.0167, validation loss: 0.1043
2024-05-25 01:24:14 [INFO]: Epoch 088 - generator training loss: 0.0406, discriminator training loss: 0.0165, validation loss: 0.1031
2024-05-25 01:24:18 [INFO]: Epoch 089 - generator training loss: 0.0406, discriminator training loss: 0.0164, validation loss: 0.1033
2024-05-25 01:24:22 [INFO]: Epoch 090 - generator training loss: 0.0399, discriminator training loss: 0.0164, validation loss: 0.1035
2024-05-25 01:24:26 [INFO]: Epoch 091 - generator training loss: 0.0405, discriminator training loss: 0.0162, validation loss: 0.1033
2024-05-25 01:24:30 [INFO]: Epoch 092 - generator training loss: 0.0410, discriminator training loss: 0.0162, validation loss: 0.1037
2024-05-25 01:24:35 [INFO]: Epoch 093 - generator training loss: 0.0398, discriminator training loss: 0.0161, validation loss: 0.1030
2024-05-25 01:24:39 [INFO]: Epoch 094 - generator training loss: 0.0390, discriminator training loss: 0.0163, validation loss: 0.1034
2024-05-25 01:24:43 [INFO]: Epoch 095 - generator training loss: 0.0394, discriminator training loss: 0.0160, validation loss: 0.1029
2024-05-25 01:24:47 [INFO]: Epoch 096 - generator training loss: 0.0389, discriminator training loss: 0.0160, validation loss: 0.1034
2024-05-25 01:24:52 [INFO]: Epoch 097 - generator training loss: 0.0396, discriminator training loss: 0.0160, validation loss: 0.1031
2024-05-25 01:24:56 [INFO]: Epoch 098 - generator training loss: 0.0391, discriminator training loss: 0.0157, validation loss: 0.1036
2024-05-25 01:25:00 [INFO]: Epoch 099 - generator training loss: 0.0393, discriminator training loss: 0.0155, validation loss: 0.1036
2024-05-25 01:25:04 [INFO]: Epoch 100 - generator training loss: 0.0395, discriminator training loss: 0.0155, validation loss: 0.1029
2024-05-25 01:25:08 [INFO]: Epoch 101 - generator training loss: 0.0387, discriminator training loss: 0.0153, validation loss: 0.1026
2024-05-25 01:25:13 [INFO]: Epoch 102 - generator training loss: 0.0379, discriminator training loss: 0.0153, validation loss: 0.1027
2024-05-25 01:25:17 [INFO]: Epoch 103 - generator training loss: 0.0377, discriminator training loss: 0.0151, validation loss: 0.1028
2024-05-25 01:25:21 [INFO]: Epoch 104 - generator training loss: 0.0380, discriminator training loss: 0.0150, validation loss: 0.1033
2024-05-25 01:25:25 [INFO]: Epoch 105 - generator training loss: 0.0376, discriminator training loss: 0.0150, validation loss: 0.1032
2024-05-25 01:25:29 [INFO]: Epoch 106 - generator training loss: 0.0373, discriminator training loss: 0.0151, validation loss: 0.1028
2024-05-25 01:25:33 [INFO]: Epoch 107 - generator training loss: 0.0370, discriminator training loss: 0.0150, validation loss: 0.1025
2024-05-25 01:25:37 [INFO]: Epoch 108 - generator training loss: 0.0374, discriminator training loss: 0.0148, validation loss: 0.1034
2024-05-25 01:25:41 [INFO]: Epoch 109 - generator training loss: 0.0377, discriminator training loss: 0.0148, validation loss: 0.1036
2024-05-25 01:25:46 [INFO]: Epoch 110 - generator training loss: 0.0372, discriminator training loss: 0.0147, validation loss: 0.1029
2024-05-25 01:25:50 [INFO]: Epoch 111 - generator training loss: 0.0371, discriminator training loss: 0.0146, validation loss: 0.1049
2024-05-25 01:25:54 [INFO]: Epoch 112 - generator training loss: 0.0381, discriminator training loss: 0.0145, validation loss: 0.1037
2024-05-25 01:25:58 [INFO]: Epoch 113 - generator training loss: 0.0370, discriminator training loss: 0.0145, validation loss: 0.1031
2024-05-25 01:26:02 [INFO]: Epoch 114 - generator training loss: 0.0363, discriminator training loss: 0.0144, validation loss: 0.1022
2024-05-25 01:26:07 [INFO]: Epoch 115 - generator training loss: 0.0362, discriminator training loss: 0.0145, validation loss: 0.1027
2024-05-25 01:26:11 [INFO]: Epoch 116 - generator training loss: 0.0355, discriminator training loss: 0.0142, validation loss: 0.1023
2024-05-25 01:26:15 [INFO]: Epoch 117 - generator training loss: 0.0356, discriminator training loss: 0.0142, validation loss: 0.1029
2024-05-25 01:26:19 [INFO]: Epoch 118 - generator training loss: 0.0354, discriminator training loss: 0.0140, validation loss: 0.1028
2024-05-25 01:26:23 [INFO]: Epoch 119 - generator training loss: 0.0363, discriminator training loss: 0.0141, validation loss: 0.1025
2024-05-25 01:26:28 [INFO]: Epoch 120 - generator training loss: 0.0357, discriminator training loss: 0.0140, validation loss: 0.1035
2024-05-25 01:26:32 [INFO]: Epoch 121 - generator training loss: 0.0352, discriminator training loss: 0.0137, validation loss: 0.1035
2024-05-25 01:26:36 [INFO]: Epoch 122 - generator training loss: 0.0348, discriminator training loss: 0.0138, validation loss: 0.1033
2024-05-25 01:26:40 [INFO]: Epoch 123 - generator training loss: 0.0351, discriminator training loss: 0.0138, validation loss: 0.1033
2024-05-25 01:26:44 [INFO]: Epoch 124 - generator training loss: 0.0350, discriminator training loss: 0.0137, validation loss: 0.1027
2024-05-25 01:26:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:26:44 [INFO]: Finished training. The best model is from epoch#114.
2024-05-25 01:26:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/USGAN_air_quality/20240525_T011804/USGAN.pypots
2024-05-25 01:26:45 [INFO]: US-GAN on Air-Quality: MAE=0.1577, MSE=0.0997
2024-05-25 01:26:45 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/USGAN_air_quality/imputation.pkl
2024-05-25 01:26:45 [INFO]: Using the given device: cuda:0
2024-05-25 01:26:45 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/BRITS_air_quality/20240525_T012645
2024-05-25 01:26:45 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/BRITS_air_quality/20240525_T012645/tensorboard
2024-05-25 01:26:45 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 01:26:49 [INFO]: Epoch 001 - training loss: 1.4218, validation loss: 0.9481
2024-05-25 01:26:52 [INFO]: Epoch 002 - training loss: 1.1387, validation loss: 0.7037
2024-05-25 01:26:54 [INFO]: Epoch 003 - training loss: 0.9506, validation loss: 0.5945
2024-05-25 01:26:57 [INFO]: Epoch 004 - training loss: 0.8426, validation loss: 0.5243
2024-05-25 01:27:00 [INFO]: Epoch 005 - training loss: 0.7659, validation loss: 0.4742
2024-05-25 01:27:03 [INFO]: Epoch 006 - training loss: 0.7087, validation loss: 0.4369
2024-05-25 01:27:06 [INFO]: Epoch 007 - training loss: 0.6633, validation loss: 0.4073
2024-05-25 01:27:09 [INFO]: Epoch 008 - training loss: 0.6289, validation loss: 0.3841
2024-05-25 01:27:12 [INFO]: Epoch 009 - training loss: 0.6018, validation loss: 0.3638
2024-05-25 01:27:14 [INFO]: Epoch 010 - training loss: 0.5782, validation loss: 0.3479
2024-05-25 01:27:17 [INFO]: Epoch 011 - training loss: 0.5594, validation loss: 0.3346
2024-05-25 01:27:20 [INFO]: Epoch 012 - training loss: 0.5445, validation loss: 0.3231
2024-05-25 01:27:23 [INFO]: Epoch 013 - training loss: 0.5309, validation loss: 0.3131
2024-05-25 01:27:26 [INFO]: Epoch 014 - training loss: 0.5188, validation loss: 0.3038
2024-05-25 01:27:29 [INFO]: Epoch 015 - training loss: 0.5085, validation loss: 0.2963
2024-05-25 01:27:32 [INFO]: Epoch 016 - training loss: 0.4968, validation loss: 0.2893
2024-05-25 01:27:34 [INFO]: Epoch 017 - training loss: 0.4897, validation loss: 0.2832
2024-05-25 01:27:37 [INFO]: Epoch 018 - training loss: 0.4803, validation loss: 0.2775
2024-05-25 01:27:40 [INFO]: Epoch 019 - training loss: 0.4721, validation loss: 0.2725
2024-05-25 01:27:43 [INFO]: Epoch 020 - training loss: 0.4644, validation loss: 0.2672
2024-05-25 01:27:46 [INFO]: Epoch 021 - training loss: 0.4579, validation loss: 0.2627
2024-05-25 01:27:49 [INFO]: Epoch 022 - training loss: 0.4512, validation loss: 0.2577
2024-05-25 01:27:51 [INFO]: Epoch 023 - training loss: 0.4444, validation loss: 0.2538
2024-05-25 01:27:54 [INFO]: Epoch 024 - training loss: 0.4392, validation loss: 0.2497
2024-05-25 01:27:57 [INFO]: Epoch 025 - training loss: 0.4323, validation loss: 0.2458
2024-05-25 01:28:00 [INFO]: Epoch 026 - training loss: 0.4276, validation loss: 0.2424
2024-05-25 01:28:03 [INFO]: Epoch 027 - training loss: 0.4221, validation loss: 0.2384
2024-05-25 01:28:06 [INFO]: Epoch 028 - training loss: 0.4165, validation loss: 0.2344
2024-05-25 01:28:08 [INFO]: Epoch 029 - training loss: 0.4121, validation loss: 0.2308
2024-05-25 01:28:11 [INFO]: Epoch 030 - training loss: 0.4075, validation loss: 0.2272
2024-05-25 01:28:14 [INFO]: Epoch 031 - training loss: 0.4029, validation loss: 0.2238
2024-05-25 01:28:17 [INFO]: Epoch 032 - training loss: 0.3987, validation loss: 0.2200
2024-05-25 01:28:20 [INFO]: Epoch 033 - training loss: 0.3949, validation loss: 0.2165
2024-05-25 01:28:23 [INFO]: Epoch 034 - training loss: 0.3904, validation loss: 0.2125
2024-05-25 01:28:25 [INFO]: Epoch 035 - training loss: 0.3867, validation loss: 0.2090
2024-05-25 01:28:28 [INFO]: Epoch 036 - training loss: 0.3827, validation loss: 0.2053
2024-05-25 01:28:31 [INFO]: Epoch 037 - training loss: 0.3786, validation loss: 0.2022
2024-05-25 01:28:34 [INFO]: Epoch 038 - training loss: 0.3755, validation loss: 0.1991
2024-05-25 01:28:37 [INFO]: Epoch 039 - training loss: 0.3715, validation loss: 0.1954
2024-05-25 01:28:40 [INFO]: Epoch 040 - training loss: 0.3684, validation loss: 0.1928
2024-05-25 01:28:43 [INFO]: Epoch 041 - training loss: 0.3656, validation loss: 0.1896
2024-05-25 01:28:45 [INFO]: Epoch 042 - training loss: 0.3623, validation loss: 0.1872
2024-05-25 01:28:48 [INFO]: Epoch 043 - training loss: 0.3598, validation loss: 0.1850
2024-05-25 01:28:51 [INFO]: Epoch 044 - training loss: 0.3569, validation loss: 0.1818
2024-05-25 01:28:54 [INFO]: Epoch 045 - training loss: 0.3539, validation loss: 0.1796
2024-05-25 01:28:57 [INFO]: Epoch 046 - training loss: 0.3513, validation loss: 0.1774
2024-05-25 01:29:00 [INFO]: Epoch 047 - training loss: 0.3478, validation loss: 0.1754
2024-05-25 01:29:02 [INFO]: Epoch 048 - training loss: 0.3450, validation loss: 0.1731
2024-05-25 01:29:05 [INFO]: Epoch 049 - training loss: 0.3430, validation loss: 0.1714
2024-05-25 01:29:08 [INFO]: Epoch 050 - training loss: 0.3405, validation loss: 0.1695
2024-05-25 01:29:11 [INFO]: Epoch 051 - training loss: 0.3382, validation loss: 0.1678
2024-05-25 01:29:14 [INFO]: Epoch 052 - training loss: 0.3365, validation loss: 0.1665
2024-05-25 01:29:17 [INFO]: Epoch 053 - training loss: 0.3334, validation loss: 0.1647
2024-05-25 01:29:19 [INFO]: Epoch 054 - training loss: 0.3322, validation loss: 0.1632
2024-05-25 01:29:22 [INFO]: Epoch 055 - training loss: 0.3301, validation loss: 0.1616
2024-05-25 01:29:25 [INFO]: Epoch 056 - training loss: 0.3275, validation loss: 0.1606
2024-05-25 01:29:28 [INFO]: Epoch 057 - training loss: 0.3255, validation loss: 0.1588
2024-05-25 01:29:31 [INFO]: Epoch 058 - training loss: 0.3242, validation loss: 0.1575
2024-05-25 01:29:34 [INFO]: Epoch 059 - training loss: 0.3221, validation loss: 0.1561
2024-05-25 01:29:37 [INFO]: Epoch 060 - training loss: 0.3207, validation loss: 0.1553
2024-05-25 01:29:40 [INFO]: Epoch 061 - training loss: 0.3191, validation loss: 0.1544
2024-05-25 01:29:42 [INFO]: Epoch 062 - training loss: 0.3174, validation loss: 0.1527
2024-05-25 01:29:45 [INFO]: Epoch 063 - training loss: 0.3158, validation loss: 0.1521
2024-05-25 01:29:48 [INFO]: Epoch 064 - training loss: 0.3138, validation loss: 0.1507
2024-05-25 01:29:51 [INFO]: Epoch 065 - training loss: 0.3125, validation loss: 0.1494
2024-05-25 01:29:54 [INFO]: Epoch 066 - training loss: 0.3114, validation loss: 0.1484
2024-05-25 01:29:57 [INFO]: Epoch 067 - training loss: 0.3094, validation loss: 0.1476
2024-05-25 01:29:59 [INFO]: Epoch 068 - training loss: 0.3090, validation loss: 0.1466
2024-05-25 01:30:02 [INFO]: Epoch 069 - training loss: 0.3080, validation loss: 0.1462
2024-05-25 01:30:05 [INFO]: Epoch 070 - training loss: 0.3063, validation loss: 0.1446
2024-05-25 01:30:08 [INFO]: Epoch 071 - training loss: 0.3051, validation loss: 0.1436
2024-05-25 01:30:11 [INFO]: Epoch 072 - training loss: 0.3032, validation loss: 0.1433
2024-05-25 01:30:14 [INFO]: Epoch 073 - training loss: 0.3028, validation loss: 0.1422
2024-05-25 01:30:16 [INFO]: Epoch 074 - training loss: 0.3023, validation loss: 0.1414
2024-05-25 01:30:19 [INFO]: Epoch 075 - training loss: 0.3006, validation loss: 0.1407
2024-05-25 01:30:22 [INFO]: Epoch 076 - training loss: 0.2995, validation loss: 0.1402
2024-05-25 01:30:25 [INFO]: Epoch 077 - training loss: 0.2985, validation loss: 0.1392
2024-05-25 01:30:28 [INFO]: Epoch 078 - training loss: 0.2972, validation loss: 0.1388
2024-05-25 01:30:31 [INFO]: Epoch 079 - training loss: 0.2968, validation loss: 0.1380
2024-05-25 01:30:33 [INFO]: Epoch 080 - training loss: 0.2958, validation loss: 0.1375
2024-05-25 01:30:36 [INFO]: Epoch 081 - training loss: 0.2945, validation loss: 0.1366
2024-05-25 01:30:39 [INFO]: Epoch 082 - training loss: 0.2940, validation loss: 0.1360
2024-05-25 01:30:42 [INFO]: Epoch 083 - training loss: 0.2928, validation loss: 0.1355
2024-05-25 01:30:45 [INFO]: Epoch 084 - training loss: 0.2916, validation loss: 0.1350
2024-05-25 01:30:48 [INFO]: Epoch 085 - training loss: 0.2912, validation loss: 0.1345
2024-05-25 01:30:51 [INFO]: Epoch 086 - training loss: 0.2906, validation loss: 0.1337
2024-05-25 01:30:53 [INFO]: Epoch 087 - training loss: 0.2898, validation loss: 0.1332
2024-05-25 01:30:56 [INFO]: Epoch 088 - training loss: 0.2891, validation loss: 0.1328
2024-05-25 01:30:59 [INFO]: Epoch 089 - training loss: 0.2880, validation loss: 0.1323
2024-05-25 01:31:02 [INFO]: Epoch 090 - training loss: 0.2876, validation loss: 0.1318
2024-05-25 01:31:05 [INFO]: Epoch 091 - training loss: 0.2864, validation loss: 0.1313
2024-05-25 01:31:08 [INFO]: Epoch 092 - training loss: 0.2855, validation loss: 0.1309
2024-05-25 01:31:10 [INFO]: Epoch 093 - training loss: 0.2849, validation loss: 0.1301
2024-05-25 01:31:13 [INFO]: Epoch 094 - training loss: 0.2842, validation loss: 0.1298
2024-05-25 01:31:16 [INFO]: Epoch 095 - training loss: 0.2845, validation loss: 0.1292
2024-05-25 01:31:19 [INFO]: Epoch 096 - training loss: 0.2829, validation loss: 0.1289
2024-05-25 01:31:22 [INFO]: Epoch 097 - training loss: 0.2822, validation loss: 0.1284
2024-05-25 01:31:25 [INFO]: Epoch 098 - training loss: 0.2813, validation loss: 0.1280
2024-05-25 01:31:28 [INFO]: Epoch 099 - training loss: 0.2803, validation loss: 0.1274
2024-05-25 01:31:30 [INFO]: Epoch 100 - training loss: 0.2800, validation loss: 0.1271
2024-05-25 01:31:33 [INFO]: Epoch 101 - training loss: 0.2795, validation loss: 0.1267
2024-05-25 01:31:36 [INFO]: Epoch 102 - training loss: 0.2792, validation loss: 0.1262
2024-05-25 01:31:39 [INFO]: Epoch 103 - training loss: 0.2786, validation loss: 0.1260
2024-05-25 01:31:42 [INFO]: Epoch 104 - training loss: 0.2773, validation loss: 0.1253
2024-05-25 01:31:45 [INFO]: Epoch 105 - training loss: 0.2778, validation loss: 0.1249
2024-05-25 01:31:47 [INFO]: Epoch 106 - training loss: 0.2763, validation loss: 0.1246
2024-05-25 01:31:50 [INFO]: Epoch 107 - training loss: 0.2759, validation loss: 0.1241
2024-05-25 01:31:53 [INFO]: Epoch 108 - training loss: 0.2756, validation loss: 0.1238
2024-05-25 01:31:56 [INFO]: Epoch 109 - training loss: 0.2743, validation loss: 0.1235
2024-05-25 01:31:59 [INFO]: Epoch 110 - training loss: 0.2743, validation loss: 0.1230
2024-05-25 01:32:02 [INFO]: Epoch 111 - training loss: 0.2739, validation loss: 0.1224
2024-05-25 01:32:04 [INFO]: Epoch 112 - training loss: 0.2731, validation loss: 0.1221
2024-05-25 01:32:07 [INFO]: Epoch 113 - training loss: 0.2726, validation loss: 0.1219
2024-05-25 01:32:10 [INFO]: Epoch 114 - training loss: 0.2725, validation loss: 0.1215
2024-05-25 01:32:13 [INFO]: Epoch 115 - training loss: 0.2717, validation loss: 0.1210
2024-05-25 01:32:16 [INFO]: Epoch 116 - training loss: 0.2705, validation loss: 0.1209
2024-05-25 01:32:19 [INFO]: Epoch 117 - training loss: 0.2710, validation loss: 0.1204
2024-05-25 01:32:21 [INFO]: Epoch 118 - training loss: 0.2700, validation loss: 0.1199
2024-05-25 01:32:24 [INFO]: Epoch 119 - training loss: 0.2690, validation loss: 0.1198
2024-05-25 01:32:27 [INFO]: Epoch 120 - training loss: 0.2690, validation loss: 0.1192
2024-05-25 01:32:30 [INFO]: Epoch 121 - training loss: 0.2683, validation loss: 0.1189
2024-05-25 01:32:33 [INFO]: Epoch 122 - training loss: 0.2679, validation loss: 0.1185
2024-05-25 01:32:36 [INFO]: Epoch 123 - training loss: 0.2680, validation loss: 0.1183
2024-05-25 01:32:38 [INFO]: Epoch 124 - training loss: 0.2672, validation loss: 0.1181
2024-05-25 01:32:41 [INFO]: Epoch 125 - training loss: 0.2667, validation loss: 0.1178
2024-05-25 01:32:44 [INFO]: Epoch 126 - training loss: 0.2660, validation loss: 0.1175
2024-05-25 01:32:47 [INFO]: Epoch 127 - training loss: 0.2655, validation loss: 0.1172
2024-05-25 01:32:50 [INFO]: Epoch 128 - training loss: 0.2654, validation loss: 0.1169
2024-05-25 01:32:52 [INFO]: Epoch 129 - training loss: 0.2651, validation loss: 0.1168
2024-05-25 01:32:55 [INFO]: Epoch 130 - training loss: 0.2646, validation loss: 0.1163
2024-05-25 01:32:58 [INFO]: Epoch 131 - training loss: 0.2642, validation loss: 0.1159
2024-05-25 01:33:01 [INFO]: Epoch 132 - training loss: 0.2643, validation loss: 0.1159
2024-05-25 01:33:04 [INFO]: Epoch 133 - training loss: 0.2635, validation loss: 0.1153
2024-05-25 01:33:07 [INFO]: Epoch 134 - training loss: 0.2628, validation loss: 0.1151
2024-05-25 01:33:09 [INFO]: Epoch 135 - training loss: 0.2624, validation loss: 0.1148
2024-05-25 01:33:12 [INFO]: Epoch 136 - training loss: 0.2621, validation loss: 0.1146
2024-05-25 01:33:15 [INFO]: Epoch 137 - training loss: 0.2619, validation loss: 0.1144
2024-05-25 01:33:18 [INFO]: Epoch 138 - training loss: 0.2618, validation loss: 0.1140
2024-05-25 01:33:21 [INFO]: Epoch 139 - training loss: 0.2608, validation loss: 0.1139
2024-05-25 01:33:24 [INFO]: Epoch 140 - training loss: 0.2601, validation loss: 0.1135
2024-05-25 01:33:27 [INFO]: Epoch 141 - training loss: 0.2605, validation loss: 0.1132
2024-05-25 01:33:29 [INFO]: Epoch 142 - training loss: 0.2599, validation loss: 0.1130
2024-05-25 01:33:32 [INFO]: Epoch 143 - training loss: 0.2595, validation loss: 0.1128
2024-05-25 01:33:35 [INFO]: Epoch 144 - training loss: 0.2590, validation loss: 0.1128
2024-05-25 01:33:38 [INFO]: Epoch 145 - training loss: 0.2588, validation loss: 0.1122
2024-05-25 01:33:41 [INFO]: Epoch 146 - training loss: 0.2585, validation loss: 0.1122
2024-05-25 01:33:44 [INFO]: Epoch 147 - training loss: 0.2576, validation loss: 0.1119
2024-05-25 01:33:47 [INFO]: Epoch 148 - training loss: 0.2579, validation loss: 0.1115
2024-05-25 01:33:49 [INFO]: Epoch 149 - training loss: 0.2577, validation loss: 0.1116
2024-05-25 01:33:52 [INFO]: Epoch 150 - training loss: 0.2571, validation loss: 0.1113
2024-05-25 01:33:55 [INFO]: Epoch 151 - training loss: 0.2566, validation loss: 0.1109
2024-05-25 01:33:58 [INFO]: Epoch 152 - training loss: 0.2566, validation loss: 0.1107
2024-05-25 01:34:01 [INFO]: Epoch 153 - training loss: 0.2562, validation loss: 0.1106
2024-05-25 01:34:04 [INFO]: Epoch 154 - training loss: 0.2560, validation loss: 0.1103
2024-05-25 01:34:06 [INFO]: Epoch 155 - training loss: 0.2554, validation loss: 0.1102
2024-05-25 01:34:09 [INFO]: Epoch 156 - training loss: 0.2555, validation loss: 0.1100
2024-05-25 01:34:12 [INFO]: Epoch 157 - training loss: 0.2545, validation loss: 0.1097
2024-05-25 01:34:15 [INFO]: Epoch 158 - training loss: 0.2544, validation loss: 0.1098
2024-05-25 01:34:18 [INFO]: Epoch 159 - training loss: 0.2544, validation loss: 0.1095
2024-05-25 01:34:21 [INFO]: Epoch 160 - training loss: 0.2543, validation loss: 0.1093
2024-05-25 01:34:23 [INFO]: Epoch 161 - training loss: 0.2538, validation loss: 0.1091
2024-05-25 01:34:26 [INFO]: Epoch 162 - training loss: 0.2531, validation loss: 0.1089
2024-05-25 01:34:29 [INFO]: Epoch 163 - training loss: 0.2533, validation loss: 0.1087
2024-05-25 01:34:32 [INFO]: Epoch 164 - training loss: 0.2527, validation loss: 0.1085
2024-05-25 01:34:35 [INFO]: Epoch 165 - training loss: 0.2525, validation loss: 0.1084
2024-05-25 01:34:38 [INFO]: Epoch 166 - training loss: 0.2517, validation loss: 0.1083
2024-05-25 01:34:41 [INFO]: Epoch 167 - training loss: 0.2519, validation loss: 0.1081
2024-05-25 01:34:43 [INFO]: Epoch 168 - training loss: 0.2514, validation loss: 0.1079
2024-05-25 01:34:46 [INFO]: Epoch 169 - training loss: 0.2513, validation loss: 0.1077
2024-05-25 01:34:49 [INFO]: Epoch 170 - training loss: 0.2513, validation loss: 0.1075
2024-05-25 01:34:52 [INFO]: Epoch 171 - training loss: 0.2511, validation loss: 0.1074
2024-05-25 01:34:55 [INFO]: Epoch 172 - training loss: 0.2504, validation loss: 0.1073
2024-05-25 01:34:57 [INFO]: Epoch 173 - training loss: 0.2505, validation loss: 0.1070
2024-05-25 01:35:00 [INFO]: Epoch 174 - training loss: 0.2507, validation loss: 0.1070
2024-05-25 01:35:03 [INFO]: Epoch 175 - training loss: 0.2498, validation loss: 0.1065
2024-05-25 01:35:06 [INFO]: Epoch 176 - training loss: 0.2495, validation loss: 0.1066
2024-05-25 01:35:09 [INFO]: Epoch 177 - training loss: 0.2493, validation loss: 0.1065
2024-05-25 01:35:12 [INFO]: Epoch 178 - training loss: 0.2486, validation loss: 0.1063
2024-05-25 01:35:15 [INFO]: Epoch 179 - training loss: 0.2491, validation loss: 0.1062
2024-05-25 01:35:17 [INFO]: Epoch 180 - training loss: 0.2488, validation loss: 0.1062
2024-05-25 01:35:20 [INFO]: Epoch 181 - training loss: 0.2487, validation loss: 0.1059
2024-05-25 01:35:23 [INFO]: Epoch 182 - training loss: 0.2480, validation loss: 0.1058
2024-05-25 01:35:26 [INFO]: Epoch 183 - training loss: 0.2481, validation loss: 0.1057
2024-05-25 01:35:29 [INFO]: Epoch 184 - training loss: 0.2475, validation loss: 0.1055
2024-05-25 01:35:32 [INFO]: Epoch 185 - training loss: 0.2482, validation loss: 0.1054
2024-05-25 01:35:35 [INFO]: Epoch 186 - training loss: 0.2473, validation loss: 0.1052
2024-05-25 01:35:38 [INFO]: Epoch 187 - training loss: 0.2479, validation loss: 0.1051
2024-05-25 01:35:41 [INFO]: Epoch 188 - training loss: 0.2466, validation loss: 0.1050
2024-05-25 01:35:43 [INFO]: Epoch 189 - training loss: 0.2467, validation loss: 0.1047
2024-05-25 01:35:46 [INFO]: Epoch 190 - training loss: 0.2465, validation loss: 0.1048
2024-05-25 01:35:49 [INFO]: Epoch 191 - training loss: 0.2461, validation loss: 0.1047
2024-05-25 01:35:52 [INFO]: Epoch 192 - training loss: 0.2460, validation loss: 0.1045
2024-05-25 01:35:55 [INFO]: Epoch 193 - training loss: 0.2458, validation loss: 0.1043
2024-05-25 01:35:58 [INFO]: Epoch 194 - training loss: 0.2456, validation loss: 0.1042
2024-05-25 01:36:01 [INFO]: Epoch 195 - training loss: 0.2452, validation loss: 0.1041
2024-05-25 01:36:03 [INFO]: Epoch 196 - training loss: 0.2448, validation loss: 0.1040
2024-05-25 01:36:06 [INFO]: Epoch 197 - training loss: 0.2450, validation loss: 0.1039
2024-05-25 01:36:09 [INFO]: Epoch 198 - training loss: 0.2446, validation loss: 0.1036
2024-05-25 01:36:12 [INFO]: Epoch 199 - training loss: 0.2444, validation loss: 0.1036
2024-05-25 01:36:15 [INFO]: Epoch 200 - training loss: 0.2436, validation loss: 0.1035
2024-05-25 01:36:18 [INFO]: Epoch 201 - training loss: 0.2441, validation loss: 0.1034
2024-05-25 01:36:20 [INFO]: Epoch 202 - training loss: 0.2437, validation loss: 0.1035
2024-05-25 01:36:23 [INFO]: Epoch 203 - training loss: 0.2437, validation loss: 0.1032
2024-05-25 01:36:26 [INFO]: Epoch 204 - training loss: 0.2436, validation loss: 0.1032
2024-05-25 01:36:29 [INFO]: Epoch 205 - training loss: 0.2433, validation loss: 0.1030
2024-05-25 01:36:32 [INFO]: Epoch 206 - training loss: 0.2429, validation loss: 0.1030
2024-05-25 01:36:35 [INFO]: Epoch 207 - training loss: 0.2427, validation loss: 0.1028
2024-05-25 01:36:38 [INFO]: Epoch 208 - training loss: 0.2422, validation loss: 0.1028
2024-05-25 01:36:40 [INFO]: Epoch 209 - training loss: 0.2428, validation loss: 0.1028
2024-05-25 01:36:43 [INFO]: Epoch 210 - training loss: 0.2421, validation loss: 0.1025
2024-05-25 01:36:46 [INFO]: Epoch 211 - training loss: 0.2421, validation loss: 0.1024
2024-05-25 01:36:49 [INFO]: Epoch 212 - training loss: 0.2420, validation loss: 0.1024
2024-05-25 01:36:52 [INFO]: Epoch 213 - training loss: 0.2419, validation loss: 0.1024
2024-05-25 01:36:55 [INFO]: Epoch 214 - training loss: 0.2416, validation loss: 0.1023
2024-05-25 01:36:57 [INFO]: Epoch 215 - training loss: 0.2412, validation loss: 0.1023
2024-05-25 01:37:00 [INFO]: Epoch 216 - training loss: 0.2410, validation loss: 0.1019
2024-05-25 01:37:03 [INFO]: Epoch 217 - training loss: 0.2406, validation loss: 0.1019
2024-05-25 01:37:06 [INFO]: Epoch 218 - training loss: 0.2407, validation loss: 0.1018
2024-05-25 01:37:09 [INFO]: Epoch 219 - training loss: 0.2403, validation loss: 0.1019
2024-05-25 01:37:12 [INFO]: Epoch 220 - training loss: 0.2400, validation loss: 0.1017
2024-05-25 01:37:14 [INFO]: Epoch 221 - training loss: 0.2402, validation loss: 0.1017
2024-05-25 01:37:17 [INFO]: Epoch 222 - training loss: 0.2395, validation loss: 0.1014
2024-05-25 01:37:20 [INFO]: Epoch 223 - training loss: 0.2404, validation loss: 0.1014
2024-05-25 01:37:23 [INFO]: Epoch 224 - training loss: 0.2399, validation loss: 0.1012
2024-05-25 01:37:26 [INFO]: Epoch 225 - training loss: 0.2394, validation loss: 0.1011
2024-05-25 01:37:29 [INFO]: Epoch 226 - training loss: 0.2396, validation loss: 0.1011
2024-05-25 01:37:32 [INFO]: Epoch 227 - training loss: 0.2392, validation loss: 0.1011
2024-05-25 01:37:34 [INFO]: Epoch 228 - training loss: 0.2391, validation loss: 0.1011
2024-05-25 01:37:37 [INFO]: Epoch 229 - training loss: 0.2389, validation loss: 0.1011
2024-05-25 01:37:40 [INFO]: Epoch 230 - training loss: 0.2383, validation loss: 0.1009
2024-05-25 01:37:43 [INFO]: Epoch 231 - training loss: 0.2385, validation loss: 0.1007
2024-05-25 01:37:46 [INFO]: Epoch 232 - training loss: 0.2385, validation loss: 0.1006
2024-05-25 01:37:49 [INFO]: Epoch 233 - training loss: 0.2382, validation loss: 0.1006
2024-05-25 01:37:52 [INFO]: Epoch 234 - training loss: 0.2386, validation loss: 0.1006
2024-05-25 01:37:54 [INFO]: Epoch 235 - training loss: 0.2380, validation loss: 0.1004
2024-05-25 01:37:57 [INFO]: Epoch 236 - training loss: 0.2379, validation loss: 0.1005
2024-05-25 01:38:00 [INFO]: Epoch 237 - training loss: 0.2376, validation loss: 0.1004
2024-05-25 01:38:03 [INFO]: Epoch 238 - training loss: 0.2375, validation loss: 0.1002
2024-05-25 01:38:06 [INFO]: Epoch 239 - training loss: 0.2376, validation loss: 0.1001
2024-05-25 01:38:09 [INFO]: Epoch 240 - training loss: 0.2377, validation loss: 0.1002
2024-05-25 01:38:11 [INFO]: Epoch 241 - training loss: 0.2368, validation loss: 0.1002
2024-05-25 01:38:14 [INFO]: Epoch 242 - training loss: 0.2370, validation loss: 0.0999
2024-05-25 01:38:17 [INFO]: Epoch 243 - training loss: 0.2369, validation loss: 0.1000
2024-05-25 01:38:20 [INFO]: Epoch 244 - training loss: 0.2365, validation loss: 0.0999
2024-05-25 01:38:23 [INFO]: Epoch 245 - training loss: 0.2363, validation loss: 0.1000
2024-05-25 01:38:26 [INFO]: Epoch 246 - training loss: 0.2362, validation loss: 0.0998
2024-05-25 01:38:28 [INFO]: Epoch 247 - training loss: 0.2361, validation loss: 0.0996
2024-05-25 01:38:31 [INFO]: Epoch 248 - training loss: 0.2357, validation loss: 0.0997
2024-05-25 01:38:34 [INFO]: Epoch 249 - training loss: 0.2353, validation loss: 0.0997
2024-05-25 01:38:37 [INFO]: Epoch 250 - training loss: 0.2353, validation loss: 0.0995
2024-05-25 01:38:40 [INFO]: Epoch 251 - training loss: 0.2357, validation loss: 0.0993
2024-05-25 01:38:43 [INFO]: Epoch 252 - training loss: 0.2354, validation loss: 0.0994
2024-05-25 01:38:46 [INFO]: Epoch 253 - training loss: 0.2347, validation loss: 0.0994
2024-05-25 01:38:48 [INFO]: Epoch 254 - training loss: 0.2348, validation loss: 0.0992
2024-05-25 01:38:51 [INFO]: Epoch 255 - training loss: 0.2350, validation loss: 0.0991
2024-05-25 01:38:54 [INFO]: Epoch 256 - training loss: 0.2346, validation loss: 0.0994
2024-05-25 01:38:57 [INFO]: Epoch 257 - training loss: 0.2346, validation loss: 0.0991
2024-05-25 01:39:00 [INFO]: Epoch 258 - training loss: 0.2349, validation loss: 0.0989
2024-05-25 01:39:03 [INFO]: Epoch 259 - training loss: 0.2346, validation loss: 0.0991
2024-05-25 01:39:05 [INFO]: Epoch 260 - training loss: 0.2347, validation loss: 0.0989
2024-05-25 01:39:08 [INFO]: Epoch 261 - training loss: 0.2345, validation loss: 0.0989
2024-05-25 01:39:11 [INFO]: Epoch 262 - training loss: 0.2339, validation loss: 0.0986
2024-05-25 01:39:14 [INFO]: Epoch 263 - training loss: 0.2338, validation loss: 0.0988
2024-05-25 01:39:17 [INFO]: Epoch 264 - training loss: 0.2340, validation loss: 0.0988
2024-05-25 01:39:20 [INFO]: Epoch 265 - training loss: 0.2336, validation loss: 0.0988
2024-05-25 01:39:23 [INFO]: Epoch 266 - training loss: 0.2335, validation loss: 0.0986
2024-05-25 01:39:25 [INFO]: Epoch 267 - training loss: 0.2332, validation loss: 0.0986
2024-05-25 01:39:28 [INFO]: Epoch 268 - training loss: 0.2333, validation loss: 0.0986
2024-05-25 01:39:31 [INFO]: Epoch 269 - training loss: 0.2334, validation loss: 0.0984
2024-05-25 01:39:34 [INFO]: Epoch 270 - training loss: 0.2331, validation loss: 0.0985
2024-05-25 01:39:37 [INFO]: Epoch 271 - training loss: 0.2329, validation loss: 0.0983
2024-05-25 01:39:40 [INFO]: Epoch 272 - training loss: 0.2333, validation loss: 0.0982
2024-05-25 01:39:42 [INFO]: Epoch 273 - training loss: 0.2325, validation loss: 0.0982
2024-05-25 01:39:45 [INFO]: Epoch 274 - training loss: 0.2326, validation loss: 0.0981
2024-05-25 01:39:48 [INFO]: Epoch 275 - training loss: 0.2321, validation loss: 0.0981
2024-05-25 01:39:51 [INFO]: Epoch 276 - training loss: 0.2319, validation loss: 0.0982
2024-05-25 01:39:54 [INFO]: Epoch 277 - training loss: 0.2323, validation loss: 0.0980
2024-05-25 01:39:57 [INFO]: Epoch 278 - training loss: 0.2319, validation loss: 0.0981
2024-05-25 01:39:59 [INFO]: Epoch 279 - training loss: 0.2323, validation loss: 0.0981
2024-05-25 01:40:02 [INFO]: Epoch 280 - training loss: 0.2315, validation loss: 0.0979
2024-05-25 01:40:05 [INFO]: Epoch 281 - training loss: 0.2317, validation loss: 0.0979
2024-05-25 01:40:08 [INFO]: Epoch 282 - training loss: 0.2314, validation loss: 0.0979
2024-05-25 01:40:10 [INFO]: Epoch 283 - training loss: 0.2320, validation loss: 0.0978
2024-05-25 01:40:13 [INFO]: Epoch 284 - training loss: 0.2318, validation loss: 0.0976
2024-05-25 01:40:16 [INFO]: Epoch 285 - training loss: 0.2315, validation loss: 0.0977
2024-05-25 01:40:19 [INFO]: Epoch 286 - training loss: 0.2307, validation loss: 0.0977
2024-05-25 01:40:21 [INFO]: Epoch 287 - training loss: 0.2315, validation loss: 0.0976
2024-05-25 01:40:24 [INFO]: Epoch 288 - training loss: 0.2312, validation loss: 0.0976
2024-05-25 01:40:27 [INFO]: Epoch 289 - training loss: 0.2309, validation loss: 0.0977
2024-05-25 01:40:30 [INFO]: Epoch 290 - training loss: 0.2306, validation loss: 0.0975
2024-05-25 01:40:33 [INFO]: Epoch 291 - training loss: 0.2306, validation loss: 0.0973
2024-05-25 01:40:36 [INFO]: Epoch 292 - training loss: 0.2309, validation loss: 0.0974
2024-05-25 01:40:39 [INFO]: Epoch 293 - training loss: 0.2307, validation loss: 0.0974
2024-05-25 01:40:41 [INFO]: Epoch 294 - training loss: 0.2303, validation loss: 0.0975
2024-05-25 01:40:44 [INFO]: Epoch 295 - training loss: 0.2301, validation loss: 0.0973
2024-05-25 01:40:47 [INFO]: Epoch 296 - training loss: 0.2299, validation loss: 0.0973
2024-05-25 01:40:50 [INFO]: Epoch 297 - training loss: 0.2301, validation loss: 0.0973
2024-05-25 01:40:53 [INFO]: Epoch 298 - training loss: 0.2297, validation loss: 0.0972
2024-05-25 01:40:56 [INFO]: Epoch 299 - training loss: 0.2294, validation loss: 0.0971
2024-05-25 01:40:58 [INFO]: Epoch 300 - training loss: 0.2294, validation loss: 0.0972
2024-05-25 01:40:58 [INFO]: Finished training. The best model is from epoch#299.
2024-05-25 01:40:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/BRITS_air_quality/20240525_T012645/BRITS.pypots
2024-05-25 01:40:59 [INFO]: BRITS on Air-Quality: MAE=0.1371, MSE=0.0943
2024-05-25 01:40:59 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/BRITS_air_quality/imputation.pkl
2024-05-25 01:40:59 [INFO]: Using the given device: cuda:0
2024-05-25 01:40:59 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059
2024-05-25 01:40:59 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/tensorboard
2024-05-25 01:40:59 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 01:41:04 [INFO]: Epoch 001 - training loss: 1.5133, validation loss: 0.8045
2024-05-25 01:41:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch1_loss0.8044973909854889.pypots
2024-05-25 01:41:08 [INFO]: Epoch 002 - training loss: 1.0726, validation loss: 0.7426
2024-05-25 01:41:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch2_loss0.7425855159759521.pypots
2024-05-25 01:41:12 [INFO]: Epoch 003 - training loss: 0.9871, validation loss: 0.7199
2024-05-25 01:41:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch3_loss0.71985924243927.pypots
2024-05-25 01:41:16 [INFO]: Epoch 004 - training loss: 0.9563, validation loss: 0.7064
2024-05-25 01:41:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch4_loss0.7063961446285247.pypots
2024-05-25 01:41:20 [INFO]: Epoch 005 - training loss: 0.9491, validation loss: 0.6986
2024-05-25 01:41:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch5_loss0.698569604754448.pypots
2024-05-25 01:41:23 [INFO]: Epoch 006 - training loss: 0.9259, validation loss: 0.6938
2024-05-25 01:41:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch6_loss0.6937972605228424.pypots
2024-05-25 01:41:27 [INFO]: Epoch 007 - training loss: 0.9442, validation loss: 0.6893
2024-05-25 01:41:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch7_loss0.6893233984708786.pypots
2024-05-25 01:41:31 [INFO]: Epoch 008 - training loss: 0.9320, validation loss: 0.6850
2024-05-25 01:41:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch8_loss0.6850420802831649.pypots
2024-05-25 01:41:35 [INFO]: Epoch 009 - training loss: 0.9303, validation loss: 0.6812
2024-05-25 01:41:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch9_loss0.6812334179878234.pypots
2024-05-25 01:41:39 [INFO]: Epoch 010 - training loss: 0.9235, validation loss: 0.6796
2024-05-25 01:41:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch10_loss0.6795871913433075.pypots
2024-05-25 01:41:43 [INFO]: Epoch 011 - training loss: 0.9097, validation loss: 0.6785
2024-05-25 01:41:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch11_loss0.6784590065479279.pypots
2024-05-25 01:41:47 [INFO]: Epoch 012 - training loss: 0.8968, validation loss: 0.6759
2024-05-25 01:41:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch12_loss0.6758664935827255.pypots
2024-05-25 01:41:51 [INFO]: Epoch 013 - training loss: 0.8996, validation loss: 0.6759
2024-05-25 01:41:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch13_loss0.6758624702692032.pypots
2024-05-25 01:41:55 [INFO]: Epoch 014 - training loss: 0.8966, validation loss: 0.6747
2024-05-25 01:41:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch14_loss0.6746755123138428.pypots
2024-05-25 01:41:59 [INFO]: Epoch 015 - training loss: 0.9114, validation loss: 0.6743
2024-05-25 01:41:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch15_loss0.6743231296539307.pypots
2024-05-25 01:42:02 [INFO]: Epoch 016 - training loss: 0.8986, validation loss: 0.6738
2024-05-25 01:42:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch16_loss0.6737809240818023.pypots
2024-05-25 01:42:06 [INFO]: Epoch 017 - training loss: 0.8921, validation loss: 0.6739
2024-05-25 01:42:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch17_loss0.6738904178142547.pypots
2024-05-25 01:42:10 [INFO]: Epoch 018 - training loss: 0.8882, validation loss: 0.6744
2024-05-25 01:42:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch18_loss0.6743874460458755.pypots
2024-05-25 01:42:14 [INFO]: Epoch 019 - training loss: 0.8834, validation loss: 0.6741
2024-05-25 01:42:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch19_loss0.6741320371627808.pypots
2024-05-25 01:42:18 [INFO]: Epoch 020 - training loss: 0.8819, validation loss: 0.6735
2024-05-25 01:42:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch20_loss0.6734820425510406.pypots
2024-05-25 01:42:22 [INFO]: Epoch 021 - training loss: 0.8783, validation loss: 0.6740
2024-05-25 01:42:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch21_loss0.673983234167099.pypots
2024-05-25 01:42:26 [INFO]: Epoch 022 - training loss: 0.8735, validation loss: 0.6748
2024-05-25 01:42:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch22_loss0.6747612208127975.pypots
2024-05-25 01:42:30 [INFO]: Epoch 023 - training loss: 0.8742, validation loss: 0.6744
2024-05-25 01:42:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch23_loss0.6744143247604371.pypots
2024-05-25 01:42:34 [INFO]: Epoch 024 - training loss: 0.8861, validation loss: 0.6760
2024-05-25 01:42:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch24_loss0.6760065585374833.pypots
2024-05-25 01:42:38 [INFO]: Epoch 025 - training loss: 0.8975, validation loss: 0.6770
2024-05-25 01:42:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch25_loss0.6770451694726944.pypots
2024-05-25 01:42:42 [INFO]: Epoch 026 - training loss: 0.8568, validation loss: 0.6746
2024-05-25 01:42:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch26_loss0.6746186703443527.pypots
2024-05-25 01:42:46 [INFO]: Epoch 027 - training loss: 0.9011, validation loss: 0.6766
2024-05-25 01:42:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch27_loss0.676575556397438.pypots
2024-05-25 01:42:50 [INFO]: Epoch 028 - training loss: 0.8711, validation loss: 0.6792
2024-05-25 01:42:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch28_loss0.6791966438293457.pypots
2024-05-25 01:42:53 [INFO]: Epoch 029 - training loss: 0.8707, validation loss: 0.6797
2024-05-25 01:42:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch29_loss0.6796830981969834.pypots
2024-05-25 01:42:57 [INFO]: Epoch 030 - training loss: 0.8608, validation loss: 0.6814
2024-05-25 01:42:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN_epoch30_loss0.681371933221817.pypots
2024-05-25 01:42:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:42:57 [INFO]: Finished training. The best model is from epoch#20.
2024-05-25 01:42:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T014059/MRNN.pypots
2024-05-25 01:42:58 [INFO]: MRNN on Air-Quality: MAE=0.5227, MSE=0.6082
2024-05-25 01:42:58 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/MRNN_air_quality/imputation.pkl
2024-05-25 01:42:58 [INFO]: Using the given device: cpu
2024-05-25 01:42:58 [INFO]: LOCF on Air-Quality: MAE=0.1979, MSE=0.2108
2024-05-25 01:42:58 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_air_quality".
2024-05-25 01:42:58 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/LOCF_air_quality/imputation.pkl
2024-05-25 01:42:58 [INFO]: Median on Air-Quality: MAE=0.6603, MSE=0.9901
2024-05-25 01:42:58 [INFO]: Successfully created the given path "saved_results/round_2/Median_air_quality".
2024-05-25 01:42:58 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/Median_air_quality/imputation.pkl
2024-05-25 01:42:58 [INFO]: Mean on Air-Quality: MAE=0.6916, MSE=0.9314
2024-05-25 01:42:58 [INFO]: Successfully created the given path "saved_results/round_2/Mean_air_quality".
2024-05-25 01:42:58 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/Mean_air_quality/imputation.pkl
2024-05-25 01:42:58 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-25 01:42:58 [INFO]: Using the given device: cuda:0
2024-05-25 01:42:58 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/SAITS_air_quality/20240525_T014258
2024-05-25 01:42:58 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/SAITS_air_quality/20240525_T014258/tensorboard
2024-05-25 01:42:58 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 01:42:59 [INFO]: Epoch 001 - training loss: 1.0581, validation loss: 0.5268
2024-05-25 01:43:00 [INFO]: Epoch 002 - training loss: 0.7659, validation loss: 0.4028
2024-05-25 01:43:01 [INFO]: Epoch 003 - training loss: 0.6562, validation loss: 0.3220
2024-05-25 01:43:01 [INFO]: Epoch 004 - training loss: 0.5811, validation loss: 0.2847
2024-05-25 01:43:02 [INFO]: Epoch 005 - training loss: 0.5251, validation loss: 0.2590
2024-05-25 01:43:03 [INFO]: Epoch 006 - training loss: 0.4870, validation loss: 0.2458
2024-05-25 01:43:03 [INFO]: Epoch 007 - training loss: 0.4609, validation loss: 0.2354
2024-05-25 01:43:04 [INFO]: Epoch 008 - training loss: 0.4427, validation loss: 0.2282
2024-05-25 01:43:05 [INFO]: Epoch 009 - training loss: 0.4277, validation loss: 0.2224
2024-05-25 01:43:05 [INFO]: Epoch 010 - training loss: 0.4169, validation loss: 0.2167
2024-05-25 01:43:06 [INFO]: Epoch 011 - training loss: 0.4063, validation loss: 0.2124
2024-05-25 01:43:07 [INFO]: Epoch 012 - training loss: 0.3972, validation loss: 0.2081
2024-05-25 01:43:07 [INFO]: Epoch 013 - training loss: 0.3888, validation loss: 0.2054
2024-05-25 01:43:08 [INFO]: Epoch 014 - training loss: 0.3837, validation loss: 0.2023
2024-05-25 01:43:09 [INFO]: Epoch 015 - training loss: 0.3769, validation loss: 0.2030
2024-05-25 01:43:09 [INFO]: Epoch 016 - training loss: 0.3714, validation loss: 0.1983
2024-05-25 01:43:10 [INFO]: Epoch 017 - training loss: 0.3659, validation loss: 0.1957
2024-05-25 01:43:11 [INFO]: Epoch 018 - training loss: 0.3608, validation loss: 0.1939
2024-05-25 01:43:11 [INFO]: Epoch 019 - training loss: 0.3571, validation loss: 0.1914
2024-05-25 01:43:12 [INFO]: Epoch 020 - training loss: 0.3527, validation loss: 0.1894
2024-05-25 01:43:13 [INFO]: Epoch 021 - training loss: 0.3471, validation loss: 0.1877
2024-05-25 01:43:14 [INFO]: Epoch 022 - training loss: 0.3453, validation loss: 0.1851
2024-05-25 01:43:14 [INFO]: Epoch 023 - training loss: 0.3424, validation loss: 0.1855
2024-05-25 01:43:15 [INFO]: Epoch 024 - training loss: 0.3394, validation loss: 0.1832
2024-05-25 01:43:16 [INFO]: Epoch 025 - training loss: 0.3368, validation loss: 0.1805
2024-05-25 01:43:16 [INFO]: Epoch 026 - training loss: 0.3322, validation loss: 0.1788
2024-05-25 01:43:17 [INFO]: Epoch 027 - training loss: 0.3302, validation loss: 0.1776
2024-05-25 01:43:18 [INFO]: Epoch 028 - training loss: 0.3279, validation loss: 0.1758
2024-05-25 01:43:18 [INFO]: Epoch 029 - training loss: 0.3269, validation loss: 0.1738
2024-05-25 01:43:19 [INFO]: Epoch 030 - training loss: 0.3236, validation loss: 0.1714
2024-05-25 01:43:20 [INFO]: Epoch 031 - training loss: 0.3215, validation loss: 0.1695
2024-05-25 01:43:20 [INFO]: Epoch 032 - training loss: 0.3223, validation loss: 0.1695
2024-05-25 01:43:21 [INFO]: Epoch 033 - training loss: 0.3180, validation loss: 0.1671
2024-05-25 01:43:22 [INFO]: Epoch 034 - training loss: 0.3156, validation loss: 0.1657
2024-05-25 01:43:22 [INFO]: Epoch 035 - training loss: 0.3136, validation loss: 0.1640
2024-05-25 01:43:23 [INFO]: Epoch 036 - training loss: 0.3132, validation loss: 0.1621
2024-05-25 01:43:24 [INFO]: Epoch 037 - training loss: 0.3111, validation loss: 0.1593
2024-05-25 01:43:24 [INFO]: Epoch 038 - training loss: 0.3082, validation loss: 0.1588
2024-05-25 01:43:25 [INFO]: Epoch 039 - training loss: 0.3080, validation loss: 0.1558
2024-05-25 01:43:26 [INFO]: Epoch 040 - training loss: 0.3068, validation loss: 0.1546
2024-05-25 01:43:27 [INFO]: Epoch 041 - training loss: 0.3042, validation loss: 0.1539
2024-05-25 01:43:27 [INFO]: Epoch 042 - training loss: 0.3023, validation loss: 0.1519
2024-05-25 01:43:28 [INFO]: Epoch 043 - training loss: 0.3011, validation loss: 0.1510
2024-05-25 01:43:29 [INFO]: Epoch 044 - training loss: 0.2989, validation loss: 0.1493
2024-05-25 01:43:29 [INFO]: Epoch 045 - training loss: 0.2970, validation loss: 0.1481
2024-05-25 01:43:30 [INFO]: Epoch 046 - training loss: 0.2965, validation loss: 0.1474
2024-05-25 01:43:31 [INFO]: Epoch 047 - training loss: 0.2948, validation loss: 0.1454
2024-05-25 01:43:31 [INFO]: Epoch 048 - training loss: 0.2932, validation loss: 0.1440
2024-05-25 01:43:32 [INFO]: Epoch 049 - training loss: 0.2919, validation loss: 0.1428
2024-05-25 01:43:33 [INFO]: Epoch 050 - training loss: 0.2913, validation loss: 0.1418
2024-05-25 01:43:33 [INFO]: Epoch 051 - training loss: 0.2896, validation loss: 0.1426
2024-05-25 01:43:34 [INFO]: Epoch 052 - training loss: 0.2874, validation loss: 0.1399
2024-05-25 01:43:35 [INFO]: Epoch 053 - training loss: 0.2869, validation loss: 0.1400
2024-05-25 01:43:35 [INFO]: Epoch 054 - training loss: 0.2864, validation loss: 0.1389
2024-05-25 01:43:36 [INFO]: Epoch 055 - training loss: 0.2857, validation loss: 0.1380
2024-05-25 01:43:37 [INFO]: Epoch 056 - training loss: 0.2834, validation loss: 0.1362
2024-05-25 01:43:38 [INFO]: Epoch 057 - training loss: 0.2809, validation loss: 0.1355
2024-05-25 01:43:38 [INFO]: Epoch 058 - training loss: 0.2803, validation loss: 0.1361
2024-05-25 01:43:39 [INFO]: Epoch 059 - training loss: 0.2798, validation loss: 0.1351
2024-05-25 01:43:40 [INFO]: Epoch 060 - training loss: 0.2790, validation loss: 0.1346
2024-05-25 01:43:40 [INFO]: Epoch 061 - training loss: 0.2776, validation loss: 0.1341
2024-05-25 01:43:41 [INFO]: Epoch 062 - training loss: 0.2767, validation loss: 0.1339
2024-05-25 01:43:42 [INFO]: Epoch 063 - training loss: 0.2773, validation loss: 0.1335
2024-05-25 01:43:42 [INFO]: Epoch 064 - training loss: 0.2752, validation loss: 0.1335
2024-05-25 01:43:43 [INFO]: Epoch 065 - training loss: 0.2743, validation loss: 0.1321
2024-05-25 01:43:44 [INFO]: Epoch 066 - training loss: 0.2718, validation loss: 0.1316
2024-05-25 01:43:44 [INFO]: Epoch 067 - training loss: 0.2700, validation loss: 0.1318
2024-05-25 01:43:45 [INFO]: Epoch 068 - training loss: 0.2696, validation loss: 0.1313
2024-05-25 01:43:46 [INFO]: Epoch 069 - training loss: 0.2690, validation loss: 0.1298
2024-05-25 01:43:46 [INFO]: Epoch 070 - training loss: 0.2688, validation loss: 0.1300
2024-05-25 01:43:47 [INFO]: Epoch 071 - training loss: 0.2663, validation loss: 0.1299
2024-05-25 01:43:48 [INFO]: Epoch 072 - training loss: 0.2647, validation loss: 0.1299
2024-05-25 01:43:49 [INFO]: Epoch 073 - training loss: 0.2648, validation loss: 0.1286
2024-05-25 01:43:49 [INFO]: Epoch 074 - training loss: 0.2642, validation loss: 0.1291
2024-05-25 01:43:50 [INFO]: Epoch 075 - training loss: 0.2643, validation loss: 0.1282
2024-05-25 01:43:51 [INFO]: Epoch 076 - training loss: 0.2632, validation loss: 0.1285
2024-05-25 01:43:51 [INFO]: Epoch 077 - training loss: 0.2623, validation loss: 0.1273
2024-05-25 01:43:52 [INFO]: Epoch 078 - training loss: 0.2622, validation loss: 0.1272
2024-05-25 01:43:53 [INFO]: Epoch 079 - training loss: 0.2613, validation loss: 0.1276
2024-05-25 01:43:53 [INFO]: Epoch 080 - training loss: 0.2599, validation loss: 0.1264
2024-05-25 01:43:54 [INFO]: Epoch 081 - training loss: 0.2586, validation loss: 0.1270
2024-05-25 01:43:55 [INFO]: Epoch 082 - training loss: 0.2578, validation loss: 0.1253
2024-05-25 01:43:55 [INFO]: Epoch 083 - training loss: 0.2577, validation loss: 0.1250
2024-05-25 01:43:56 [INFO]: Epoch 084 - training loss: 0.2559, validation loss: 0.1257
2024-05-25 01:43:57 [INFO]: Epoch 085 - training loss: 0.2556, validation loss: 0.1247
2024-05-25 01:43:57 [INFO]: Epoch 086 - training loss: 0.2547, validation loss: 0.1245
2024-05-25 01:43:58 [INFO]: Epoch 087 - training loss: 0.2541, validation loss: 0.1248
2024-05-25 01:43:59 [INFO]: Epoch 088 - training loss: 0.2544, validation loss: 0.1244
2024-05-25 01:43:59 [INFO]: Epoch 089 - training loss: 0.2524, validation loss: 0.1245
2024-05-25 01:44:00 [INFO]: Epoch 090 - training loss: 0.2514, validation loss: 0.1233
2024-05-25 01:44:01 [INFO]: Epoch 091 - training loss: 0.2517, validation loss: 0.1233
2024-05-25 01:44:02 [INFO]: Epoch 092 - training loss: 0.2498, validation loss: 0.1222
2024-05-25 01:44:02 [INFO]: Epoch 093 - training loss: 0.2496, validation loss: 0.1225
2024-05-25 01:44:03 [INFO]: Epoch 094 - training loss: 0.2490, validation loss: 0.1226
2024-05-25 01:44:04 [INFO]: Epoch 095 - training loss: 0.2486, validation loss: 0.1217
2024-05-25 01:44:04 [INFO]: Epoch 096 - training loss: 0.2481, validation loss: 0.1230
2024-05-25 01:44:05 [INFO]: Epoch 097 - training loss: 0.2492, validation loss: 0.1225
2024-05-25 01:44:06 [INFO]: Epoch 098 - training loss: 0.2497, validation loss: 0.1212
2024-05-25 01:44:06 [INFO]: Epoch 099 - training loss: 0.2462, validation loss: 0.1214
2024-05-25 01:44:07 [INFO]: Epoch 100 - training loss: 0.2448, validation loss: 0.1206
2024-05-25 01:44:08 [INFO]: Epoch 101 - training loss: 0.2454, validation loss: 0.1208
2024-05-25 01:44:08 [INFO]: Epoch 102 - training loss: 0.2443, validation loss: 0.1205
2024-05-25 01:44:09 [INFO]: Epoch 103 - training loss: 0.2437, validation loss: 0.1194
2024-05-25 01:44:10 [INFO]: Epoch 104 - training loss: 0.2432, validation loss: 0.1192
2024-05-25 01:44:10 [INFO]: Epoch 105 - training loss: 0.2429, validation loss: 0.1195
2024-05-25 01:44:11 [INFO]: Epoch 106 - training loss: 0.2430, validation loss: 0.1191
2024-05-25 01:44:12 [INFO]: Epoch 107 - training loss: 0.2430, validation loss: 0.1189
2024-05-25 01:44:13 [INFO]: Epoch 108 - training loss: 0.2458, validation loss: 0.1195
2024-05-25 01:44:13 [INFO]: Epoch 109 - training loss: 0.2415, validation loss: 0.1191
2024-05-25 01:44:14 [INFO]: Epoch 110 - training loss: 0.2437, validation loss: 0.1188
2024-05-25 01:44:15 [INFO]: Epoch 111 - training loss: 0.2404, validation loss: 0.1182
2024-05-25 01:44:15 [INFO]: Epoch 112 - training loss: 0.2382, validation loss: 0.1183
2024-05-25 01:44:16 [INFO]: Epoch 113 - training loss: 0.2407, validation loss: 0.1174
2024-05-25 01:44:17 [INFO]: Epoch 114 - training loss: 0.2383, validation loss: 0.1166
2024-05-25 01:44:17 [INFO]: Epoch 115 - training loss: 0.2384, validation loss: 0.1172
2024-05-25 01:44:18 [INFO]: Epoch 116 - training loss: 0.2383, validation loss: 0.1167
2024-05-25 01:44:19 [INFO]: Epoch 117 - training loss: 0.2398, validation loss: 0.1171
2024-05-25 01:44:19 [INFO]: Epoch 118 - training loss: 0.2380, validation loss: 0.1160
2024-05-25 01:44:20 [INFO]: Epoch 119 - training loss: 0.2366, validation loss: 0.1157
2024-05-25 01:44:21 [INFO]: Epoch 120 - training loss: 0.2358, validation loss: 0.1165
2024-05-25 01:44:21 [INFO]: Epoch 121 - training loss: 0.2358, validation loss: 0.1165
2024-05-25 01:44:22 [INFO]: Epoch 122 - training loss: 0.2340, validation loss: 0.1150
2024-05-25 01:44:23 [INFO]: Epoch 123 - training loss: 0.2345, validation loss: 0.1151
2024-05-25 01:44:23 [INFO]: Epoch 124 - training loss: 0.2336, validation loss: 0.1156
2024-05-25 01:44:24 [INFO]: Epoch 125 - training loss: 0.2339, validation loss: 0.1158
2024-05-25 01:44:25 [INFO]: Epoch 126 - training loss: 0.2329, validation loss: 0.1162
2024-05-25 01:44:26 [INFO]: Epoch 127 - training loss: 0.2338, validation loss: 0.1154
2024-05-25 01:44:26 [INFO]: Epoch 128 - training loss: 0.2339, validation loss: 0.1148
2024-05-25 01:44:27 [INFO]: Epoch 129 - training loss: 0.2318, validation loss: 0.1148
2024-05-25 01:44:28 [INFO]: Epoch 130 - training loss: 0.2305, validation loss: 0.1144
2024-05-25 01:44:28 [INFO]: Epoch 131 - training loss: 0.2310, validation loss: 0.1133
2024-05-25 01:44:29 [INFO]: Epoch 132 - training loss: 0.2303, validation loss: 0.1134
2024-05-25 01:44:30 [INFO]: Epoch 133 - training loss: 0.2295, validation loss: 0.1127
2024-05-25 01:44:30 [INFO]: Epoch 134 - training loss: 0.2306, validation loss: 0.1128
2024-05-25 01:44:31 [INFO]: Epoch 135 - training loss: 0.2296, validation loss: 0.1126
2024-05-25 01:44:32 [INFO]: Epoch 136 - training loss: 0.2286, validation loss: 0.1134
2024-05-25 01:44:32 [INFO]: Epoch 137 - training loss: 0.2277, validation loss: 0.1125
2024-05-25 01:44:33 [INFO]: Epoch 138 - training loss: 0.2286, validation loss: 0.1128
2024-05-25 01:44:34 [INFO]: Epoch 139 - training loss: 0.2281, validation loss: 0.1125
2024-05-25 01:44:34 [INFO]: Epoch 140 - training loss: 0.2268, validation loss: 0.1137
2024-05-25 01:44:35 [INFO]: Epoch 141 - training loss: 0.2287, validation loss: 0.1132
2024-05-25 01:44:36 [INFO]: Epoch 142 - training loss: 0.2293, validation loss: 0.1128
2024-05-25 01:44:36 [INFO]: Epoch 143 - training loss: 0.2273, validation loss: 0.1120
2024-05-25 01:44:37 [INFO]: Epoch 144 - training loss: 0.2264, validation loss: 0.1124
2024-05-25 01:44:38 [INFO]: Epoch 145 - training loss: 0.2261, validation loss: 0.1128
2024-05-25 01:44:39 [INFO]: Epoch 146 - training loss: 0.2251, validation loss: 0.1127
2024-05-25 01:44:39 [INFO]: Epoch 147 - training loss: 0.2251, validation loss: 0.1127
2024-05-25 01:44:40 [INFO]: Epoch 148 - training loss: 0.2252, validation loss: 0.1114
2024-05-25 01:44:41 [INFO]: Epoch 149 - training loss: 0.2239, validation loss: 0.1122
2024-05-25 01:44:41 [INFO]: Epoch 150 - training loss: 0.2239, validation loss: 0.1102
2024-05-25 01:44:42 [INFO]: Epoch 151 - training loss: 0.2231, validation loss: 0.1111
2024-05-25 01:44:43 [INFO]: Epoch 152 - training loss: 0.2238, validation loss: 0.1117
2024-05-25 01:44:43 [INFO]: Epoch 153 - training loss: 0.2231, validation loss: 0.1110
2024-05-25 01:44:44 [INFO]: Epoch 154 - training loss: 0.2222, validation loss: 0.1109
2024-05-25 01:44:45 [INFO]: Epoch 155 - training loss: 0.2226, validation loss: 0.1108
2024-05-25 01:44:45 [INFO]: Epoch 156 - training loss: 0.2233, validation loss: 0.1108
2024-05-25 01:44:46 [INFO]: Epoch 157 - training loss: 0.2230, validation loss: 0.1099
2024-05-25 01:44:47 [INFO]: Epoch 158 - training loss: 0.2210, validation loss: 0.1095
2024-05-25 01:44:47 [INFO]: Epoch 159 - training loss: 0.2199, validation loss: 0.1101
2024-05-25 01:44:48 [INFO]: Epoch 160 - training loss: 0.2199, validation loss: 0.1104
2024-05-25 01:44:49 [INFO]: Epoch 161 - training loss: 0.2184, validation loss: 0.1096
2024-05-25 01:44:50 [INFO]: Epoch 162 - training loss: 0.2194, validation loss: 0.1088
2024-05-25 01:44:50 [INFO]: Epoch 163 - training loss: 0.2192, validation loss: 0.1090
2024-05-25 01:44:51 [INFO]: Epoch 164 - training loss: 0.2183, validation loss: 0.1089
2024-05-25 01:44:52 [INFO]: Epoch 165 - training loss: 0.2191, validation loss: 0.1085
2024-05-25 01:44:52 [INFO]: Epoch 166 - training loss: 0.2186, validation loss: 0.1090
2024-05-25 01:44:53 [INFO]: Epoch 167 - training loss: 0.2187, validation loss: 0.1089
2024-05-25 01:44:54 [INFO]: Epoch 168 - training loss: 0.2189, validation loss: 0.1093
2024-05-25 01:44:54 [INFO]: Epoch 169 - training loss: 0.2199, validation loss: 0.1094
2024-05-25 01:44:55 [INFO]: Epoch 170 - training loss: 0.2197, validation loss: 0.1101
2024-05-25 01:44:56 [INFO]: Epoch 171 - training loss: 0.2192, validation loss: 0.1072
2024-05-25 01:44:56 [INFO]: Epoch 172 - training loss: 0.2170, validation loss: 0.1083
2024-05-25 01:44:57 [INFO]: Epoch 173 - training loss: 0.2166, validation loss: 0.1070
2024-05-25 01:44:58 [INFO]: Epoch 174 - training loss: 0.2158, validation loss: 0.1072
2024-05-25 01:44:58 [INFO]: Epoch 175 - training loss: 0.2165, validation loss: 0.1069
2024-05-25 01:44:59 [INFO]: Epoch 176 - training loss: 0.2151, validation loss: 0.1074
2024-05-25 01:45:00 [INFO]: Epoch 177 - training loss: 0.2152, validation loss: 0.1083
2024-05-25 01:45:00 [INFO]: Epoch 178 - training loss: 0.2144, validation loss: 0.1074
2024-05-25 01:45:01 [INFO]: Epoch 179 - training loss: 0.2138, validation loss: 0.1070
2024-05-25 01:45:02 [INFO]: Epoch 180 - training loss: 0.2133, validation loss: 0.1061
2024-05-25 01:45:03 [INFO]: Epoch 181 - training loss: 0.2127, validation loss: 0.1066
2024-05-25 01:45:03 [INFO]: Epoch 182 - training loss: 0.2139, validation loss: 0.1071
2024-05-25 01:45:04 [INFO]: Epoch 183 - training loss: 0.2137, validation loss: 0.1066
2024-05-25 01:45:05 [INFO]: Epoch 184 - training loss: 0.2129, validation loss: 0.1065
2024-05-25 01:45:05 [INFO]: Epoch 185 - training loss: 0.2127, validation loss: 0.1056
2024-05-25 01:45:06 [INFO]: Epoch 186 - training loss: 0.2124, validation loss: 0.1059
2024-05-25 01:45:07 [INFO]: Epoch 187 - training loss: 0.2135, validation loss: 0.1053
2024-05-25 01:45:07 [INFO]: Epoch 188 - training loss: 0.2121, validation loss: 0.1070
2024-05-25 01:45:08 [INFO]: Epoch 189 - training loss: 0.2123, validation loss: 0.1052
2024-05-25 01:45:09 [INFO]: Epoch 190 - training loss: 0.2118, validation loss: 0.1057
2024-05-25 01:45:09 [INFO]: Epoch 191 - training loss: 0.2109, validation loss: 0.1060
2024-05-25 01:45:10 [INFO]: Epoch 192 - training loss: 0.2110, validation loss: 0.1073
2024-05-25 01:45:11 [INFO]: Epoch 193 - training loss: 0.2114, validation loss: 0.1059
2024-05-25 01:45:11 [INFO]: Epoch 194 - training loss: 0.2116, validation loss: 0.1056
2024-05-25 01:45:12 [INFO]: Epoch 195 - training loss: 0.2112, validation loss: 0.1052
2024-05-25 01:45:13 [INFO]: Epoch 196 - training loss: 0.2101, validation loss: 0.1059
2024-05-25 01:45:14 [INFO]: Epoch 197 - training loss: 0.2093, validation loss: 0.1057
2024-05-25 01:45:14 [INFO]: Epoch 198 - training loss: 0.2091, validation loss: 0.1054
2024-05-25 01:45:15 [INFO]: Epoch 199 - training loss: 0.2087, validation loss: 0.1054
2024-05-25 01:45:16 [INFO]: Epoch 200 - training loss: 0.2096, validation loss: 0.1055
2024-05-25 01:45:16 [INFO]: Epoch 201 - training loss: 0.2089, validation loss: 0.1047
2024-05-25 01:45:17 [INFO]: Epoch 202 - training loss: 0.2072, validation loss: 0.1047
2024-05-25 01:45:18 [INFO]: Epoch 203 - training loss: 0.2088, validation loss: 0.1051
2024-05-25 01:45:18 [INFO]: Epoch 204 - training loss: 0.2118, validation loss: 0.1058
2024-05-25 01:45:19 [INFO]: Epoch 205 - training loss: 0.2106, validation loss: 0.1047
2024-05-25 01:45:20 [INFO]: Epoch 206 - training loss: 0.2075, validation loss: 0.1052
2024-05-25 01:45:20 [INFO]: Epoch 207 - training loss: 0.2075, validation loss: 0.1053
2024-05-25 01:45:21 [INFO]: Epoch 208 - training loss: 0.2068, validation loss: 0.1051
2024-05-25 01:45:22 [INFO]: Epoch 209 - training loss: 0.2073, validation loss: 0.1061
2024-05-25 01:45:22 [INFO]: Epoch 210 - training loss: 0.2060, validation loss: 0.1049
2024-05-25 01:45:23 [INFO]: Epoch 211 - training loss: 0.2061, validation loss: 0.1043
2024-05-25 01:45:24 [INFO]: Epoch 212 - training loss: 0.2056, validation loss: 0.1053
2024-05-25 01:45:24 [INFO]: Epoch 213 - training loss: 0.2064, validation loss: 0.1055
2024-05-25 01:45:25 [INFO]: Epoch 214 - training loss: 0.2072, validation loss: 0.1050
2024-05-25 01:45:26 [INFO]: Epoch 215 - training loss: 0.2063, validation loss: 0.1044
2024-05-25 01:45:27 [INFO]: Epoch 216 - training loss: 0.2067, validation loss: 0.1040
2024-05-25 01:45:27 [INFO]: Epoch 217 - training loss: 0.2052, validation loss: 0.1035
2024-05-25 01:45:28 [INFO]: Epoch 218 - training loss: 0.2052, validation loss: 0.1036
2024-05-25 01:45:29 [INFO]: Epoch 219 - training loss: 0.2045, validation loss: 0.1031
2024-05-25 01:45:29 [INFO]: Epoch 220 - training loss: 0.2038, validation loss: 0.1036
2024-05-25 01:45:30 [INFO]: Epoch 221 - training loss: 0.2050, validation loss: 0.1038
2024-05-25 01:45:31 [INFO]: Epoch 222 - training loss: 0.2037, validation loss: 0.1047
2024-05-25 01:45:31 [INFO]: Epoch 223 - training loss: 0.2031, validation loss: 0.1035
2024-05-25 01:45:32 [INFO]: Epoch 224 - training loss: 0.2029, validation loss: 0.1034
2024-05-25 01:45:33 [INFO]: Epoch 225 - training loss: 0.2039, validation loss: 0.1035
2024-05-25 01:45:33 [INFO]: Epoch 226 - training loss: 0.2040, validation loss: 0.1036
2024-05-25 01:45:34 [INFO]: Epoch 227 - training loss: 0.2047, validation loss: 0.1030
2024-05-25 01:45:35 [INFO]: Epoch 228 - training loss: 0.2027, validation loss: 0.1028
2024-05-25 01:45:35 [INFO]: Epoch 229 - training loss: 0.2037, validation loss: 0.1024
2024-05-25 01:45:36 [INFO]: Epoch 230 - training loss: 0.2031, validation loss: 0.1030
2024-05-25 01:45:37 [INFO]: Epoch 231 - training loss: 0.2013, validation loss: 0.1032
2024-05-25 01:45:38 [INFO]: Epoch 232 - training loss: 0.2017, validation loss: 0.1025
2024-05-25 01:45:38 [INFO]: Epoch 233 - training loss: 0.2013, validation loss: 0.1037
2024-05-25 01:45:39 [INFO]: Epoch 234 - training loss: 0.2022, validation loss: 0.1031
2024-05-25 01:45:40 [INFO]: Epoch 235 - training loss: 0.2015, validation loss: 0.1020
2024-05-25 01:45:40 [INFO]: Epoch 236 - training loss: 0.2001, validation loss: 0.1023
2024-05-25 01:45:41 [INFO]: Epoch 237 - training loss: 0.2013, validation loss: 0.1035
2024-05-25 01:45:42 [INFO]: Epoch 238 - training loss: 0.2012, validation loss: 0.1022
2024-05-25 01:45:42 [INFO]: Epoch 239 - training loss: 0.2010, validation loss: 0.1019
2024-05-25 01:45:43 [INFO]: Epoch 240 - training loss: 0.2005, validation loss: 0.1019
2024-05-25 01:45:44 [INFO]: Epoch 241 - training loss: 0.2004, validation loss: 0.1017
2024-05-25 01:45:44 [INFO]: Epoch 242 - training loss: 0.1995, validation loss: 0.1030
2024-05-25 01:45:45 [INFO]: Epoch 243 - training loss: 0.1986, validation loss: 0.1024
2024-05-25 01:45:46 [INFO]: Epoch 244 - training loss: 0.1989, validation loss: 0.1016
2024-05-25 01:45:46 [INFO]: Epoch 245 - training loss: 0.1991, validation loss: 0.1018
2024-05-25 01:45:47 [INFO]: Epoch 246 - training loss: 0.1986, validation loss: 0.1019
2024-05-25 01:45:48 [INFO]: Epoch 247 - training loss: 0.2010, validation loss: 0.1013
2024-05-25 01:45:49 [INFO]: Epoch 248 - training loss: 0.1996, validation loss: 0.1026
2024-05-25 01:45:49 [INFO]: Epoch 249 - training loss: 0.1987, validation loss: 0.1023
2024-05-25 01:45:50 [INFO]: Epoch 250 - training loss: 0.1987, validation loss: 0.1011
2024-05-25 01:45:51 [INFO]: Epoch 251 - training loss: 0.1978, validation loss: 0.1024
2024-05-25 01:45:51 [INFO]: Epoch 252 - training loss: 0.1978, validation loss: 0.1018
2024-05-25 01:45:52 [INFO]: Epoch 253 - training loss: 0.1978, validation loss: 0.1016
2024-05-25 01:45:53 [INFO]: Epoch 254 - training loss: 0.1968, validation loss: 0.1025
2024-05-25 01:45:53 [INFO]: Epoch 255 - training loss: 0.1969, validation loss: 0.1019
2024-05-25 01:45:54 [INFO]: Epoch 256 - training loss: 0.1970, validation loss: 0.1020
2024-05-25 01:45:55 [INFO]: Epoch 257 - training loss: 0.1968, validation loss: 0.1015
2024-05-25 01:45:55 [INFO]: Epoch 258 - training loss: 0.1976, validation loss: 0.1017
2024-05-25 01:45:56 [INFO]: Epoch 259 - training loss: 0.1971, validation loss: 0.1013
2024-05-25 01:45:57 [INFO]: Epoch 260 - training loss: 0.1967, validation loss: 0.1031
2024-05-25 01:45:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:45:57 [INFO]: Finished training. The best model is from epoch#250.
2024-05-25 01:45:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/SAITS_air_quality/20240525_T014258/SAITS.pypots
2024-05-25 01:45:57 [INFO]: SAITS on Air-Quality: MAE=0.1399, MSE=0.0964
2024-05-25 01:45:57 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/SAITS_air_quality/imputation.pkl
2024-05-25 01:45:57 [INFO]: Using the given device: cuda:0
2024-05-25 01:45:57 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/Transformer_air_quality/20240525_T014557
2024-05-25 01:45:57 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/Transformer_air_quality/20240525_T014557/tensorboard
2024-05-25 01:45:57 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 01:45:57 [INFO]: Epoch 001 - training loss: 0.9112, validation loss: 0.4647
2024-05-25 01:45:58 [INFO]: Epoch 002 - training loss: 0.5725, validation loss: 0.3470
2024-05-25 01:45:58 [INFO]: Epoch 003 - training loss: 0.4839, validation loss: 0.2896
2024-05-25 01:45:58 [INFO]: Epoch 004 - training loss: 0.4369, validation loss: 0.2622
2024-05-25 01:45:59 [INFO]: Epoch 005 - training loss: 0.4074, validation loss: 0.2477
2024-05-25 01:45:59 [INFO]: Epoch 006 - training loss: 0.3928, validation loss: 0.2397
2024-05-25 01:45:59 [INFO]: Epoch 007 - training loss: 0.3754, validation loss: 0.2322
2024-05-25 01:46:00 [INFO]: Epoch 008 - training loss: 0.3648, validation loss: 0.2261
2024-05-25 01:46:00 [INFO]: Epoch 009 - training loss: 0.3535, validation loss: 0.2179
2024-05-25 01:46:00 [INFO]: Epoch 010 - training loss: 0.3454, validation loss: 0.2142
2024-05-25 01:46:01 [INFO]: Epoch 011 - training loss: 0.3397, validation loss: 0.2094
2024-05-25 01:46:01 [INFO]: Epoch 012 - training loss: 0.3348, validation loss: 0.2050
2024-05-25 01:46:01 [INFO]: Epoch 013 - training loss: 0.3311, validation loss: 0.2030
2024-05-25 01:46:01 [INFO]: Epoch 014 - training loss: 0.3277, validation loss: 0.1960
2024-05-25 01:46:02 [INFO]: Epoch 015 - training loss: 0.3235, validation loss: 0.1940
2024-05-25 01:46:02 [INFO]: Epoch 016 - training loss: 0.3189, validation loss: 0.1908
2024-05-25 01:46:02 [INFO]: Epoch 017 - training loss: 0.3133, validation loss: 0.1869
2024-05-25 01:46:03 [INFO]: Epoch 018 - training loss: 0.3106, validation loss: 0.1861
2024-05-25 01:46:03 [INFO]: Epoch 019 - training loss: 0.3087, validation loss: 0.1837
2024-05-25 01:46:03 [INFO]: Epoch 020 - training loss: 0.3059, validation loss: 0.1781
2024-05-25 01:46:04 [INFO]: Epoch 021 - training loss: 0.3025, validation loss: 0.1773
2024-05-25 01:46:04 [INFO]: Epoch 022 - training loss: 0.3037, validation loss: 0.1767
2024-05-25 01:46:04 [INFO]: Epoch 023 - training loss: 0.3006, validation loss: 0.1742
2024-05-25 01:46:05 [INFO]: Epoch 024 - training loss: 0.2971, validation loss: 0.1723
2024-05-25 01:46:05 [INFO]: Epoch 025 - training loss: 0.2957, validation loss: 0.1717
2024-05-25 01:46:05 [INFO]: Epoch 026 - training loss: 0.2940, validation loss: 0.1727
2024-05-25 01:46:06 [INFO]: Epoch 027 - training loss: 0.2897, validation loss: 0.1702
2024-05-25 01:46:06 [INFO]: Epoch 028 - training loss: 0.2883, validation loss: 0.1695
2024-05-25 01:46:06 [INFO]: Epoch 029 - training loss: 0.2915, validation loss: 0.1682
2024-05-25 01:46:07 [INFO]: Epoch 030 - training loss: 0.2855, validation loss: 0.1674
2024-05-25 01:46:07 [INFO]: Epoch 031 - training loss: 0.2843, validation loss: 0.1670
2024-05-25 01:46:07 [INFO]: Epoch 032 - training loss: 0.2844, validation loss: 0.1658
2024-05-25 01:46:08 [INFO]: Epoch 033 - training loss: 0.2798, validation loss: 0.1645
2024-05-25 01:46:08 [INFO]: Epoch 034 - training loss: 0.2818, validation loss: 0.1647
2024-05-25 01:46:08 [INFO]: Epoch 035 - training loss: 0.2793, validation loss: 0.1636
2024-05-25 01:46:09 [INFO]: Epoch 036 - training loss: 0.2770, validation loss: 0.1632
2024-05-25 01:46:09 [INFO]: Epoch 037 - training loss: 0.2750, validation loss: 0.1629
2024-05-25 01:46:09 [INFO]: Epoch 038 - training loss: 0.2746, validation loss: 0.1631
2024-05-25 01:46:10 [INFO]: Epoch 039 - training loss: 0.2740, validation loss: 0.1617
2024-05-25 01:46:10 [INFO]: Epoch 040 - training loss: 0.2735, validation loss: 0.1623
2024-05-25 01:46:10 [INFO]: Epoch 041 - training loss: 0.2738, validation loss: 0.1600
2024-05-25 01:46:11 [INFO]: Epoch 042 - training loss: 0.2715, validation loss: 0.1618
2024-05-25 01:46:11 [INFO]: Epoch 043 - training loss: 0.2708, validation loss: 0.1615
2024-05-25 01:46:11 [INFO]: Epoch 044 - training loss: 0.2732, validation loss: 0.1615
2024-05-25 01:46:12 [INFO]: Epoch 045 - training loss: 0.2679, validation loss: 0.1592
2024-05-25 01:46:12 [INFO]: Epoch 046 - training loss: 0.2647, validation loss: 0.1580
2024-05-25 01:46:12 [INFO]: Epoch 047 - training loss: 0.2639, validation loss: 0.1585
2024-05-25 01:46:13 [INFO]: Epoch 048 - training loss: 0.2646, validation loss: 0.1587
2024-05-25 01:46:13 [INFO]: Epoch 049 - training loss: 0.2666, validation loss: 0.1595
2024-05-25 01:46:13 [INFO]: Epoch 050 - training loss: 0.2625, validation loss: 0.1577
2024-05-25 01:46:13 [INFO]: Epoch 051 - training loss: 0.2622, validation loss: 0.1574
2024-05-25 01:46:14 [INFO]: Epoch 052 - training loss: 0.2622, validation loss: 0.1581
2024-05-25 01:46:14 [INFO]: Epoch 053 - training loss: 0.2586, validation loss: 0.1579
2024-05-25 01:46:14 [INFO]: Epoch 054 - training loss: 0.2588, validation loss: 0.1568
2024-05-25 01:46:15 [INFO]: Epoch 055 - training loss: 0.2588, validation loss: 0.1567
2024-05-25 01:46:15 [INFO]: Epoch 056 - training loss: 0.2573, validation loss: 0.1575
2024-05-25 01:46:15 [INFO]: Epoch 057 - training loss: 0.2568, validation loss: 0.1560
2024-05-25 01:46:16 [INFO]: Epoch 058 - training loss: 0.2618, validation loss: 0.1562
2024-05-25 01:46:16 [INFO]: Epoch 059 - training loss: 0.2565, validation loss: 0.1557
2024-05-25 01:46:16 [INFO]: Epoch 060 - training loss: 0.2545, validation loss: 0.1545
2024-05-25 01:46:17 [INFO]: Epoch 061 - training loss: 0.2535, validation loss: 0.1556
2024-05-25 01:46:17 [INFO]: Epoch 062 - training loss: 0.2521, validation loss: 0.1553
2024-05-25 01:46:17 [INFO]: Epoch 063 - training loss: 0.2523, validation loss: 0.1561
2024-05-25 01:46:18 [INFO]: Epoch 064 - training loss: 0.2516, validation loss: 0.1562
2024-05-25 01:46:18 [INFO]: Epoch 065 - training loss: 0.2529, validation loss: 0.1536
2024-05-25 01:46:18 [INFO]: Epoch 066 - training loss: 0.2518, validation loss: 0.1539
2024-05-25 01:46:19 [INFO]: Epoch 067 - training loss: 0.2524, validation loss: 0.1544
2024-05-25 01:46:19 [INFO]: Epoch 068 - training loss: 0.2495, validation loss: 0.1556
2024-05-25 01:46:19 [INFO]: Epoch 069 - training loss: 0.2501, validation loss: 0.1542
2024-05-25 01:46:20 [INFO]: Epoch 070 - training loss: 0.2469, validation loss: 0.1550
2024-05-25 01:46:20 [INFO]: Epoch 071 - training loss: 0.2454, validation loss: 0.1532
2024-05-25 01:46:20 [INFO]: Epoch 072 - training loss: 0.2461, validation loss: 0.1516
2024-05-25 01:46:21 [INFO]: Epoch 073 - training loss: 0.2458, validation loss: 0.1526
2024-05-25 01:46:21 [INFO]: Epoch 074 - training loss: 0.2451, validation loss: 0.1546
2024-05-25 01:46:21 [INFO]: Epoch 075 - training loss: 0.2454, validation loss: 0.1520
2024-05-25 01:46:22 [INFO]: Epoch 076 - training loss: 0.2426, validation loss: 0.1534
2024-05-25 01:46:22 [INFO]: Epoch 077 - training loss: 0.2412, validation loss: 0.1512
2024-05-25 01:46:22 [INFO]: Epoch 078 - training loss: 0.2406, validation loss: 0.1517
2024-05-25 01:46:23 [INFO]: Epoch 079 - training loss: 0.2403, validation loss: 0.1534
2024-05-25 01:46:23 [INFO]: Epoch 080 - training loss: 0.2418, validation loss: 0.1538
2024-05-25 01:46:23 [INFO]: Epoch 081 - training loss: 0.2422, validation loss: 0.1496
2024-05-25 01:46:24 [INFO]: Epoch 082 - training loss: 0.2421, validation loss: 0.1509
2024-05-25 01:46:24 [INFO]: Epoch 083 - training loss: 0.2395, validation loss: 0.1506
2024-05-25 01:46:24 [INFO]: Epoch 084 - training loss: 0.2387, validation loss: 0.1505
2024-05-25 01:46:25 [INFO]: Epoch 085 - training loss: 0.2367, validation loss: 0.1508
2024-05-25 01:46:25 [INFO]: Epoch 086 - training loss: 0.2367, validation loss: 0.1497
2024-05-25 01:46:25 [INFO]: Epoch 087 - training loss: 0.2355, validation loss: 0.1484
2024-05-25 01:46:25 [INFO]: Epoch 088 - training loss: 0.2340, validation loss: 0.1486
2024-05-25 01:46:26 [INFO]: Epoch 089 - training loss: 0.2337, validation loss: 0.1508
2024-05-25 01:46:26 [INFO]: Epoch 090 - training loss: 0.2355, validation loss: 0.1484
2024-05-25 01:46:26 [INFO]: Epoch 091 - training loss: 0.2339, validation loss: 0.1471
2024-05-25 01:46:27 [INFO]: Epoch 092 - training loss: 0.2330, validation loss: 0.1487
2024-05-25 01:46:27 [INFO]: Epoch 093 - training loss: 0.2324, validation loss: 0.1484
2024-05-25 01:46:27 [INFO]: Epoch 094 - training loss: 0.2325, validation loss: 0.1478
2024-05-25 01:46:28 [INFO]: Epoch 095 - training loss: 0.2310, validation loss: 0.1480
2024-05-25 01:46:28 [INFO]: Epoch 096 - training loss: 0.2316, validation loss: 0.1467
2024-05-25 01:46:28 [INFO]: Epoch 097 - training loss: 0.2305, validation loss: 0.1471
2024-05-25 01:46:29 [INFO]: Epoch 098 - training loss: 0.2304, validation loss: 0.1460
2024-05-25 01:46:29 [INFO]: Epoch 099 - training loss: 0.2312, validation loss: 0.1467
2024-05-25 01:46:29 [INFO]: Epoch 100 - training loss: 0.2305, validation loss: 0.1461
2024-05-25 01:46:30 [INFO]: Epoch 101 - training loss: 0.2281, validation loss: 0.1476
2024-05-25 01:46:30 [INFO]: Epoch 102 - training loss: 0.2286, validation loss: 0.1461
2024-05-25 01:46:30 [INFO]: Epoch 103 - training loss: 0.2273, validation loss: 0.1444
2024-05-25 01:46:31 [INFO]: Epoch 104 - training loss: 0.2277, validation loss: 0.1467
2024-05-25 01:46:31 [INFO]: Epoch 105 - training loss: 0.2269, validation loss: 0.1464
2024-05-25 01:46:31 [INFO]: Epoch 106 - training loss: 0.2265, validation loss: 0.1460
2024-05-25 01:46:32 [INFO]: Epoch 107 - training loss: 0.2269, validation loss: 0.1450
2024-05-25 01:46:32 [INFO]: Epoch 108 - training loss: 0.2249, validation loss: 0.1436
2024-05-25 01:46:32 [INFO]: Epoch 109 - training loss: 0.2246, validation loss: 0.1441
2024-05-25 01:46:33 [INFO]: Epoch 110 - training loss: 0.2256, validation loss: 0.1455
2024-05-25 01:46:33 [INFO]: Epoch 111 - training loss: 0.2251, validation loss: 0.1432
2024-05-25 01:46:33 [INFO]: Epoch 112 - training loss: 0.2240, validation loss: 0.1445
2024-05-25 01:46:34 [INFO]: Epoch 113 - training loss: 0.2220, validation loss: 0.1428
2024-05-25 01:46:34 [INFO]: Epoch 114 - training loss: 0.2253, validation loss: 0.1444
2024-05-25 01:46:34 [INFO]: Epoch 115 - training loss: 0.2235, validation loss: 0.1421
2024-05-25 01:46:35 [INFO]: Epoch 116 - training loss: 0.2291, validation loss: 0.1433
2024-05-25 01:46:35 [INFO]: Epoch 117 - training loss: 0.2243, validation loss: 0.1419
2024-05-25 01:46:35 [INFO]: Epoch 118 - training loss: 0.2246, validation loss: 0.1429
2024-05-25 01:46:36 [INFO]: Epoch 119 - training loss: 0.2215, validation loss: 0.1420
2024-05-25 01:46:36 [INFO]: Epoch 120 - training loss: 0.2196, validation loss: 0.1416
2024-05-25 01:46:36 [INFO]: Epoch 121 - training loss: 0.2199, validation loss: 0.1424
2024-05-25 01:46:36 [INFO]: Epoch 122 - training loss: 0.2219, validation loss: 0.1436
2024-05-25 01:46:37 [INFO]: Epoch 123 - training loss: 0.2210, validation loss: 0.1425
2024-05-25 01:46:37 [INFO]: Epoch 124 - training loss: 0.2186, validation loss: 0.1414
2024-05-25 01:46:37 [INFO]: Epoch 125 - training loss: 0.2199, validation loss: 0.1422
2024-05-25 01:46:38 [INFO]: Epoch 126 - training loss: 0.2185, validation loss: 0.1417
2024-05-25 01:46:38 [INFO]: Epoch 127 - training loss: 0.2159, validation loss: 0.1421
2024-05-25 01:46:38 [INFO]: Epoch 128 - training loss: 0.2151, validation loss: 0.1419
2024-05-25 01:46:39 [INFO]: Epoch 129 - training loss: 0.2168, validation loss: 0.1417
2024-05-25 01:46:39 [INFO]: Epoch 130 - training loss: 0.2164, validation loss: 0.1403
2024-05-25 01:46:39 [INFO]: Epoch 131 - training loss: 0.2143, validation loss: 0.1404
2024-05-25 01:46:40 [INFO]: Epoch 132 - training loss: 0.2211, validation loss: 0.1424
2024-05-25 01:46:40 [INFO]: Epoch 133 - training loss: 0.2198, validation loss: 0.1399
2024-05-25 01:46:40 [INFO]: Epoch 134 - training loss: 0.2157, validation loss: 0.1388
2024-05-25 01:46:41 [INFO]: Epoch 135 - training loss: 0.2165, validation loss: 0.1414
2024-05-25 01:46:41 [INFO]: Epoch 136 - training loss: 0.2154, validation loss: 0.1403
2024-05-25 01:46:41 [INFO]: Epoch 137 - training loss: 0.2141, validation loss: 0.1432
2024-05-25 01:46:42 [INFO]: Epoch 138 - training loss: 0.2179, validation loss: 0.1394
2024-05-25 01:46:42 [INFO]: Epoch 139 - training loss: 0.2173, validation loss: 0.1401
2024-05-25 01:46:42 [INFO]: Epoch 140 - training loss: 0.2125, validation loss: 0.1412
2024-05-25 01:46:43 [INFO]: Epoch 141 - training loss: 0.2116, validation loss: 0.1411
2024-05-25 01:46:43 [INFO]: Epoch 142 - training loss: 0.2115, validation loss: 0.1414
2024-05-25 01:46:43 [INFO]: Epoch 143 - training loss: 0.2157, validation loss: 0.1395
2024-05-25 01:46:44 [INFO]: Epoch 144 - training loss: 0.2135, validation loss: 0.1403
2024-05-25 01:46:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:46:44 [INFO]: Finished training. The best model is from epoch#134.
2024-05-25 01:46:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/Transformer_air_quality/20240525_T014557/Transformer.pypots
2024-05-25 01:46:44 [INFO]: Transformer on Air-Quality: MAE=0.1643, MSE=0.1262
2024-05-25 01:46:44 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/Transformer_air_quality/imputation.pkl
2024-05-25 01:46:44 [INFO]: Using the given device: cuda:0
2024-05-25 01:46:44 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/TimesNet_air_quality/20240525_T014644
2024-05-25 01:46:44 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/TimesNet_air_quality/20240525_T014644/tensorboard
2024-05-25 01:46:44 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 01:46:45 [INFO]: Epoch 001 - training loss: 0.3054, validation loss: 0.2779
2024-05-25 01:46:45 [INFO]: Epoch 002 - training loss: 0.2231, validation loss: 0.2289
2024-05-25 01:46:46 [INFO]: Epoch 003 - training loss: 0.1951, validation loss: 0.2278
2024-05-25 01:46:46 [INFO]: Epoch 004 - training loss: 0.1588, validation loss: 0.2097
2024-05-25 01:46:47 [INFO]: Epoch 005 - training loss: 0.2145, validation loss: 0.2102
2024-05-25 01:46:47 [INFO]: Epoch 006 - training loss: 0.1665, validation loss: 0.1991
2024-05-25 01:46:48 [INFO]: Epoch 007 - training loss: 0.1716, validation loss: 0.1942
2024-05-25 01:46:48 [INFO]: Epoch 008 - training loss: 0.1559, validation loss: 0.1893
2024-05-25 01:46:49 [INFO]: Epoch 009 - training loss: 0.1580, validation loss: 0.1857
2024-05-25 01:46:49 [INFO]: Epoch 010 - training loss: 0.1420, validation loss: 0.1850
2024-05-25 01:46:50 [INFO]: Epoch 011 - training loss: 0.1553, validation loss: 0.2004
2024-05-25 01:46:51 [INFO]: Epoch 012 - training loss: 0.1464, validation loss: 0.1824
2024-05-25 01:46:51 [INFO]: Epoch 013 - training loss: 0.1172, validation loss: 0.1722
2024-05-25 01:46:52 [INFO]: Epoch 014 - training loss: 0.1265, validation loss: 0.1665
2024-05-25 01:46:52 [INFO]: Epoch 015 - training loss: 0.1503, validation loss: 0.1631
2024-05-25 01:46:53 [INFO]: Epoch 016 - training loss: 0.1368, validation loss: 0.1702
2024-05-25 01:46:53 [INFO]: Epoch 017 - training loss: 0.1319, validation loss: 0.1696
2024-05-25 01:46:54 [INFO]: Epoch 018 - training loss: 0.1227, validation loss: 0.1611
2024-05-25 01:46:54 [INFO]: Epoch 019 - training loss: 0.1175, validation loss: 0.1587
2024-05-25 01:46:55 [INFO]: Epoch 020 - training loss: 0.1317, validation loss: 0.1579
2024-05-25 01:46:55 [INFO]: Epoch 021 - training loss: 0.1237, validation loss: 0.1543
2024-05-25 01:46:56 [INFO]: Epoch 022 - training loss: 0.1139, validation loss: 0.1564
2024-05-25 01:46:56 [INFO]: Epoch 023 - training loss: 0.1296, validation loss: 0.1567
2024-05-25 01:46:57 [INFO]: Epoch 024 - training loss: 0.1231, validation loss: 0.1572
2024-05-25 01:46:58 [INFO]: Epoch 025 - training loss: 0.1169, validation loss: 0.1558
2024-05-25 01:46:58 [INFO]: Epoch 026 - training loss: 0.1237, validation loss: 0.1581
2024-05-25 01:46:59 [INFO]: Epoch 027 - training loss: 0.1261, validation loss: 0.1552
2024-05-25 01:46:59 [INFO]: Epoch 028 - training loss: 0.1295, validation loss: 0.1513
2024-05-25 01:47:00 [INFO]: Epoch 029 - training loss: 0.1149, validation loss: 0.1512
2024-05-25 01:47:00 [INFO]: Epoch 030 - training loss: 0.1146, validation loss: 0.1517
2024-05-25 01:47:01 [INFO]: Epoch 031 - training loss: 0.0988, validation loss: 0.1588
2024-05-25 01:47:01 [INFO]: Epoch 032 - training loss: 0.1185, validation loss: 0.1515
2024-05-25 01:47:02 [INFO]: Epoch 033 - training loss: 0.1288, validation loss: 0.1500
2024-05-25 01:47:02 [INFO]: Epoch 034 - training loss: 0.1054, validation loss: 0.1529
2024-05-25 01:47:03 [INFO]: Epoch 035 - training loss: 0.1234, validation loss: 0.1477
2024-05-25 01:47:03 [INFO]: Epoch 036 - training loss: 0.1208, validation loss: 0.1466
2024-05-25 01:47:04 [INFO]: Epoch 037 - training loss: 0.1029, validation loss: 0.1532
2024-05-25 01:47:05 [INFO]: Epoch 038 - training loss: 0.1112, validation loss: 0.1470
2024-05-25 01:47:05 [INFO]: Epoch 039 - training loss: 0.1002, validation loss: 0.1523
2024-05-25 01:47:06 [INFO]: Epoch 040 - training loss: 0.1065, validation loss: 0.1498
2024-05-25 01:47:06 [INFO]: Epoch 041 - training loss: 0.1136, validation loss: 0.1461
2024-05-25 01:47:07 [INFO]: Epoch 042 - training loss: 0.1009, validation loss: 0.1453
2024-05-25 01:47:07 [INFO]: Epoch 043 - training loss: 0.1007, validation loss: 0.1432
2024-05-25 01:47:08 [INFO]: Epoch 044 - training loss: 0.1022, validation loss: 0.1435
2024-05-25 01:47:08 [INFO]: Epoch 045 - training loss: 0.0987, validation loss: 0.1468
2024-05-25 01:47:09 [INFO]: Epoch 046 - training loss: 0.1097, validation loss: 0.1408
2024-05-25 01:47:09 [INFO]: Epoch 047 - training loss: 0.1057, validation loss: 0.1433
2024-05-25 01:47:10 [INFO]: Epoch 048 - training loss: 0.1080, validation loss: 0.1415
2024-05-25 01:47:10 [INFO]: Epoch 049 - training loss: 0.1188, validation loss: 0.1452
2024-05-25 01:47:11 [INFO]: Epoch 050 - training loss: 0.1177, validation loss: 0.1430
2024-05-25 01:47:12 [INFO]: Epoch 051 - training loss: 0.1034, validation loss: 0.1424
2024-05-25 01:47:12 [INFO]: Epoch 052 - training loss: 0.0983, validation loss: 0.1437
2024-05-25 01:47:13 [INFO]: Epoch 053 - training loss: 0.0994, validation loss: 0.1455
2024-05-25 01:47:13 [INFO]: Epoch 054 - training loss: 0.0915, validation loss: 0.1445
2024-05-25 01:47:14 [INFO]: Epoch 055 - training loss: 0.1004, validation loss: 0.1408
2024-05-25 01:47:14 [INFO]: Epoch 056 - training loss: 0.0936, validation loss: 0.1392
2024-05-25 01:47:15 [INFO]: Epoch 057 - training loss: 0.1184, validation loss: 0.1381
2024-05-25 01:47:15 [INFO]: Epoch 058 - training loss: 0.1010, validation loss: 0.1383
2024-05-25 01:47:16 [INFO]: Epoch 059 - training loss: 0.1000, validation loss: 0.1407
2024-05-25 01:47:16 [INFO]: Epoch 060 - training loss: 0.1131, validation loss: 0.1460
2024-05-25 01:47:17 [INFO]: Epoch 061 - training loss: 0.0972, validation loss: 0.1423
2024-05-25 01:47:17 [INFO]: Epoch 062 - training loss: 0.1032, validation loss: 0.1378
2024-05-25 01:47:18 [INFO]: Epoch 063 - training loss: 0.1024, validation loss: 0.1393
2024-05-25 01:47:19 [INFO]: Epoch 064 - training loss: 0.0889, validation loss: 0.1390
2024-05-25 01:47:19 [INFO]: Epoch 065 - training loss: 0.0971, validation loss: 0.1400
2024-05-25 01:47:20 [INFO]: Epoch 066 - training loss: 0.0961, validation loss: 0.1447
2024-05-25 01:47:20 [INFO]: Epoch 067 - training loss: 0.1186, validation loss: 0.1393
2024-05-25 01:47:21 [INFO]: Epoch 068 - training loss: 0.1017, validation loss: 0.1403
2024-05-25 01:47:21 [INFO]: Epoch 069 - training loss: 0.0925, validation loss: 0.1375
2024-05-25 01:47:22 [INFO]: Epoch 070 - training loss: 0.0963, validation loss: 0.1374
2024-05-25 01:47:22 [INFO]: Epoch 071 - training loss: 0.0894, validation loss: 0.1320
2024-05-25 01:47:23 [INFO]: Epoch 072 - training loss: 0.0904, validation loss: 0.1377
2024-05-25 01:47:23 [INFO]: Epoch 073 - training loss: 0.1014, validation loss: 0.1374
2024-05-25 01:47:24 [INFO]: Epoch 074 - training loss: 0.0903, validation loss: 0.1361
2024-05-25 01:47:24 [INFO]: Epoch 075 - training loss: 0.0843, validation loss: 0.1339
2024-05-25 01:47:25 [INFO]: Epoch 076 - training loss: 0.0852, validation loss: 0.1312
2024-05-25 01:47:25 [INFO]: Epoch 077 - training loss: 0.0857, validation loss: 0.1364
2024-05-25 01:47:26 [INFO]: Epoch 078 - training loss: 0.0853, validation loss: 0.1351
2024-05-25 01:47:27 [INFO]: Epoch 079 - training loss: 0.1014, validation loss: 0.1323
2024-05-25 01:47:27 [INFO]: Epoch 080 - training loss: 0.1054, validation loss: 0.1333
2024-05-25 01:47:28 [INFO]: Epoch 081 - training loss: 0.0952, validation loss: 0.1341
2024-05-25 01:47:28 [INFO]: Epoch 082 - training loss: 0.0900, validation loss: 0.1345
2024-05-25 01:47:29 [INFO]: Epoch 083 - training loss: 0.1070, validation loss: 0.1337
2024-05-25 01:47:29 [INFO]: Epoch 084 - training loss: 0.1078, validation loss: 0.1338
2024-05-25 01:47:30 [INFO]: Epoch 085 - training loss: 0.0830, validation loss: 0.1373
2024-05-25 01:47:30 [INFO]: Epoch 086 - training loss: 0.0845, validation loss: 0.1377
2024-05-25 01:47:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:47:30 [INFO]: Finished training. The best model is from epoch#76.
2024-05-25 01:47:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/TimesNet_air_quality/20240525_T014644/TimesNet.pypots
2024-05-25 01:47:30 [INFO]: TimesNet on Air-Quality: MAE=0.1526, MSE=0.1189
2024-05-25 01:47:30 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/TimesNet_air_quality/imputation.pkl
2024-05-25 01:47:30 [INFO]: Using the given device: cuda:0
2024-05-25 01:47:30 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730
2024-05-25 01:47:30 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/tensorboard
2024-05-25 01:47:30 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 01:47:47 [INFO]: Epoch 001 - training loss: 0.5126, validation loss: 0.3820
2024-05-25 01:47:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch1_loss0.38196287453174593.pypots
2024-05-25 01:48:04 [INFO]: Epoch 002 - training loss: 0.3145, validation loss: 0.3134
2024-05-25 01:48:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch2_loss0.3133882820606232.pypots
2024-05-25 01:48:21 [INFO]: Epoch 003 - training loss: 0.2596, validation loss: 0.2636
2024-05-25 01:48:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch3_loss0.26358842849731445.pypots
2024-05-25 01:48:38 [INFO]: Epoch 004 - training loss: 0.2675, validation loss: 0.2315
2024-05-25 01:48:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch4_loss0.23150668293237686.pypots
2024-05-25 01:48:55 [INFO]: Epoch 005 - training loss: 0.2284, validation loss: 0.1985
2024-05-25 01:48:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch5_loss0.19849073141813278.pypots
2024-05-25 01:49:12 [INFO]: Epoch 006 - training loss: 0.2093, validation loss: 0.1856
2024-05-25 01:49:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch6_loss0.18559629321098328.pypots
2024-05-25 01:49:29 [INFO]: Epoch 007 - training loss: 0.2035, validation loss: 0.1800
2024-05-25 01:49:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch7_loss0.17998955994844437.pypots
2024-05-25 01:49:45 [INFO]: Epoch 008 - training loss: 0.1965, validation loss: 0.1742
2024-05-25 01:49:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch8_loss0.17424248307943344.pypots
2024-05-25 01:50:02 [INFO]: Epoch 009 - training loss: 0.1941, validation loss: 0.1770
2024-05-25 01:50:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch9_loss0.1769615277647972.pypots
2024-05-25 01:50:19 [INFO]: Epoch 010 - training loss: 0.1987, validation loss: 0.1628
2024-05-25 01:50:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch10_loss0.16276760250329972.pypots
2024-05-25 01:50:36 [INFO]: Epoch 011 - training loss: 0.1902, validation loss: 0.1637
2024-05-25 01:50:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch11_loss0.16372611820697786.pypots
2024-05-25 01:50:53 [INFO]: Epoch 012 - training loss: 0.1806, validation loss: 0.1577
2024-05-25 01:50:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch12_loss0.15773461610078812.pypots
2024-05-25 01:51:10 [INFO]: Epoch 013 - training loss: 0.1487, validation loss: 0.1568
2024-05-25 01:51:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch13_loss0.15680100321769713.pypots
2024-05-25 01:51:27 [INFO]: Epoch 014 - training loss: 0.1655, validation loss: 0.1559
2024-05-25 01:51:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch14_loss0.15588897615671157.pypots
2024-05-25 01:51:43 [INFO]: Epoch 015 - training loss: 0.1789, validation loss: 0.1548
2024-05-25 01:51:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch15_loss0.1547662600874901.pypots
2024-05-25 01:52:00 [INFO]: Epoch 016 - training loss: 0.1674, validation loss: 0.1501
2024-05-25 01:52:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch16_loss0.15009328722953796.pypots
2024-05-25 01:52:17 [INFO]: Epoch 017 - training loss: 0.1635, validation loss: 0.1569
2024-05-25 01:52:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch17_loss0.15685881972312926.pypots
2024-05-25 01:52:34 [INFO]: Epoch 018 - training loss: 0.1735, validation loss: 0.1484
2024-05-25 01:52:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch18_loss0.14840481877326966.pypots
2024-05-25 01:52:51 [INFO]: Epoch 019 - training loss: 0.1734, validation loss: 0.1479
2024-05-25 01:52:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch19_loss0.14786930233240128.pypots
2024-05-25 01:53:08 [INFO]: Epoch 020 - training loss: 0.1642, validation loss: 0.1457
2024-05-25 01:53:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch20_loss0.14569328725337982.pypots
2024-05-25 01:53:25 [INFO]: Epoch 021 - training loss: 0.1512, validation loss: 0.1452
2024-05-25 01:53:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch21_loss0.1451694115996361.pypots
2024-05-25 01:53:42 [INFO]: Epoch 022 - training loss: 0.1456, validation loss: 0.1433
2024-05-25 01:53:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch22_loss0.14326997175812722.pypots
2024-05-25 01:53:58 [INFO]: Epoch 023 - training loss: 0.1455, validation loss: 0.1413
2024-05-25 01:53:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch23_loss0.14125012382864952.pypots
2024-05-25 01:54:15 [INFO]: Epoch 024 - training loss: 0.1786, validation loss: 0.1422
2024-05-25 01:54:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch24_loss0.1421553984284401.pypots
2024-05-25 01:54:32 [INFO]: Epoch 025 - training loss: 0.1479, validation loss: 0.1460
2024-05-25 01:54:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch25_loss0.1460215061903.pypots
2024-05-25 01:54:49 [INFO]: Epoch 026 - training loss: 0.1602, validation loss: 0.1351
2024-05-25 01:54:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch26_loss0.13505593314766884.pypots
2024-05-25 01:55:06 [INFO]: Epoch 027 - training loss: 0.1405, validation loss: 0.1296
2024-05-25 01:55:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch27_loss0.1295928902924061.pypots
2024-05-25 01:55:23 [INFO]: Epoch 028 - training loss: 0.1378, validation loss: 0.1306
2024-05-25 01:55:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch28_loss0.1306060805916786.pypots
2024-05-25 01:55:40 [INFO]: Epoch 029 - training loss: 0.1268, validation loss: 0.1337
2024-05-25 01:55:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch29_loss0.13372179195284845.pypots
2024-05-25 01:55:56 [INFO]: Epoch 030 - training loss: 0.1414, validation loss: 0.1287
2024-05-25 01:55:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch30_loss0.12873739823698999.pypots
2024-05-25 01:56:13 [INFO]: Epoch 031 - training loss: 0.1409, validation loss: 0.1309
2024-05-25 01:56:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch31_loss0.13089375719428062.pypots
2024-05-25 01:56:30 [INFO]: Epoch 032 - training loss: 0.1424, validation loss: 0.1283
2024-05-25 01:56:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch32_loss0.12827008441090584.pypots
2024-05-25 01:56:47 [INFO]: Epoch 033 - training loss: 0.1515, validation loss: 0.1246
2024-05-25 01:56:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch33_loss0.12462612017989158.pypots
2024-05-25 01:57:04 [INFO]: Epoch 034 - training loss: 0.1542, validation loss: 0.1229
2024-05-25 01:57:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch34_loss0.12291476130485535.pypots
2024-05-25 01:57:21 [INFO]: Epoch 035 - training loss: 0.1396, validation loss: 0.1247
2024-05-25 01:57:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch35_loss0.12471285462379456.pypots
2024-05-25 01:57:38 [INFO]: Epoch 036 - training loss: 0.1404, validation loss: 0.1250
2024-05-25 01:57:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch36_loss0.12496946826577186.pypots
2024-05-25 01:57:55 [INFO]: Epoch 037 - training loss: 0.1310, validation loss: 0.1290
2024-05-25 01:57:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch37_loss0.12902867048978806.pypots
2024-05-25 01:58:11 [INFO]: Epoch 038 - training loss: 0.1352, validation loss: 0.1247
2024-05-25 01:58:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch38_loss0.12473956421017647.pypots
2024-05-25 01:58:28 [INFO]: Epoch 039 - training loss: 0.1322, validation loss: 0.1250
2024-05-25 01:58:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch39_loss0.12498623356223107.pypots
2024-05-25 01:58:45 [INFO]: Epoch 040 - training loss: 0.1376, validation loss: 0.1257
2024-05-25 01:58:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch40_loss0.12567765340209008.pypots
2024-05-25 01:59:02 [INFO]: Epoch 041 - training loss: 0.1310, validation loss: 0.1264
2024-05-25 01:59:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch41_loss0.12644015848636628.pypots
2024-05-25 01:59:19 [INFO]: Epoch 042 - training loss: 0.1324, validation loss: 0.1233
2024-05-25 01:59:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch42_loss0.12328383922576905.pypots
2024-05-25 01:59:36 [INFO]: Epoch 043 - training loss: 0.1371, validation loss: 0.1178
2024-05-25 01:59:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch43_loss0.11778079941868783.pypots
2024-05-25 01:59:53 [INFO]: Epoch 044 - training loss: 0.1305, validation loss: 0.1328
2024-05-25 01:59:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch44_loss0.1327924832701683.pypots
2024-05-25 02:00:10 [INFO]: Epoch 045 - training loss: 0.1274, validation loss: 0.1176
2024-05-25 02:00:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch45_loss0.11757469326257705.pypots
2024-05-25 02:00:26 [INFO]: Epoch 046 - training loss: 0.1176, validation loss: 0.1154
2024-05-25 02:00:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch46_loss0.1154498241841793.pypots
2024-05-25 02:00:43 [INFO]: Epoch 047 - training loss: 0.1398, validation loss: 0.1139
2024-05-25 02:00:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch47_loss0.11390612050890922.pypots
2024-05-25 02:01:00 [INFO]: Epoch 048 - training loss: 0.1314, validation loss: 0.1131
2024-05-25 02:01:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch48_loss0.11312052607536316.pypots
2024-05-25 02:01:17 [INFO]: Epoch 049 - training loss: 0.1281, validation loss: 0.1143
2024-05-25 02:01:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch49_loss0.1143222726881504.pypots
2024-05-25 02:01:34 [INFO]: Epoch 050 - training loss: 0.1222, validation loss: 0.1159
2024-05-25 02:01:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch50_loss0.11591162458062172.pypots
2024-05-25 02:01:51 [INFO]: Epoch 051 - training loss: 0.1330, validation loss: 0.1154
2024-05-25 02:01:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch51_loss0.11543241068720818.pypots
2024-05-25 02:02:08 [INFO]: Epoch 052 - training loss: 0.1281, validation loss: 0.1111
2024-05-25 02:02:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch52_loss0.11105510219931602.pypots
2024-05-25 02:02:24 [INFO]: Epoch 053 - training loss: 0.1147, validation loss: 0.1174
2024-05-25 02:02:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch53_loss0.11739912927150727.pypots
2024-05-25 02:02:41 [INFO]: Epoch 054 - training loss: 0.1147, validation loss: 0.1207
2024-05-25 02:02:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch54_loss0.12072314769029617.pypots
2024-05-25 02:02:58 [INFO]: Epoch 055 - training loss: 0.1117, validation loss: 0.1131
2024-05-25 02:02:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch55_loss0.11305403038859367.pypots
2024-05-25 02:03:15 [INFO]: Epoch 056 - training loss: 0.1413, validation loss: 0.1149
2024-05-25 02:03:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch56_loss0.11486597955226899.pypots
2024-05-25 02:03:32 [INFO]: Epoch 057 - training loss: 0.1345, validation loss: 0.1134
2024-05-25 02:03:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch57_loss0.11344455778598786.pypots
2024-05-25 02:03:49 [INFO]: Epoch 058 - training loss: 0.1299, validation loss: 0.1144
2024-05-25 02:03:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch58_loss0.11435613632202149.pypots
2024-05-25 02:04:06 [INFO]: Epoch 059 - training loss: 0.1225, validation loss: 0.1117
2024-05-25 02:04:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch59_loss0.11171991154551505.pypots
2024-05-25 02:04:22 [INFO]: Epoch 060 - training loss: 0.1286, validation loss: 0.1110
2024-05-25 02:04:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch60_loss0.11098519712686539.pypots
2024-05-25 02:04:39 [INFO]: Epoch 061 - training loss: 0.1231, validation loss: 0.1101
2024-05-25 02:04:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch61_loss0.11012259796261788.pypots
2024-05-25 02:04:56 [INFO]: Epoch 062 - training loss: 0.1156, validation loss: 0.1072
2024-05-25 02:04:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch62_loss0.10719452798366547.pypots
2024-05-25 02:05:13 [INFO]: Epoch 063 - training loss: 0.1307, validation loss: 0.1129
2024-05-25 02:05:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch63_loss0.11291735544800759.pypots
2024-05-25 02:05:30 [INFO]: Epoch 064 - training loss: 0.1226, validation loss: 0.1104
2024-05-25 02:05:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch64_loss0.11044399589300155.pypots
2024-05-25 02:05:47 [INFO]: Epoch 065 - training loss: 0.1458, validation loss: 0.1163
2024-05-25 02:05:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch65_loss0.1163492240011692.pypots
2024-05-25 02:06:04 [INFO]: Epoch 066 - training loss: 0.1270, validation loss: 0.1107
2024-05-25 02:06:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch66_loss0.11067055463790894.pypots
2024-05-25 02:06:20 [INFO]: Epoch 067 - training loss: 0.1243, validation loss: 0.1075
2024-05-25 02:06:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch67_loss0.10749540403485298.pypots
2024-05-25 02:06:37 [INFO]: Epoch 068 - training loss: 0.1248, validation loss: 0.1091
2024-05-25 02:06:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch68_loss0.10913981050252915.pypots
2024-05-25 02:06:54 [INFO]: Epoch 069 - training loss: 0.1080, validation loss: 0.1121
2024-05-25 02:06:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch69_loss0.11211935058236122.pypots
2024-05-25 02:07:11 [INFO]: Epoch 070 - training loss: 0.1174, validation loss: 0.1114
2024-05-25 02:07:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch70_loss0.1113505981862545.pypots
2024-05-25 02:07:28 [INFO]: Epoch 071 - training loss: 0.1171, validation loss: 0.1089
2024-05-25 02:07:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch71_loss0.10892937630414963.pypots
2024-05-25 02:07:45 [INFO]: Epoch 072 - training loss: 0.1234, validation loss: 0.1060
2024-05-25 02:07:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch72_loss0.10598823577165603.pypots
2024-05-25 02:08:02 [INFO]: Epoch 073 - training loss: 0.1158, validation loss: 0.1043
2024-05-25 02:08:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch73_loss0.10429426059126853.pypots
2024-05-25 02:08:18 [INFO]: Epoch 074 - training loss: 0.1182, validation loss: 0.1093
2024-05-25 02:08:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch74_loss0.1093402624130249.pypots
2024-05-25 02:08:35 [INFO]: Epoch 075 - training loss: 0.1158, validation loss: 0.1107
2024-05-25 02:08:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch75_loss0.11069951802492142.pypots
2024-05-25 02:08:52 [INFO]: Epoch 076 - training loss: 0.1380, validation loss: 0.1089
2024-05-25 02:08:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch76_loss0.10888100415468216.pypots
2024-05-25 02:09:09 [INFO]: Epoch 077 - training loss: 0.1370, validation loss: 0.1057
2024-05-25 02:09:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch77_loss0.10567977726459503.pypots
2024-05-25 02:09:26 [INFO]: Epoch 078 - training loss: 0.1258, validation loss: 0.1125
2024-05-25 02:09:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch78_loss0.11247678995132446.pypots
2024-05-25 02:09:43 [INFO]: Epoch 079 - training loss: 0.1209, validation loss: 0.1054
2024-05-25 02:09:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch79_loss0.10540631785988808.pypots
2024-05-25 02:10:00 [INFO]: Epoch 080 - training loss: 0.1040, validation loss: 0.1069
2024-05-25 02:10:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch80_loss0.10690430402755738.pypots
2024-05-25 02:10:16 [INFO]: Epoch 081 - training loss: 0.1103, validation loss: 0.1066
2024-05-25 02:10:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch81_loss0.10662887543439865.pypots
2024-05-25 02:10:33 [INFO]: Epoch 082 - training loss: 0.1252, validation loss: 0.1055
2024-05-25 02:10:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch82_loss0.10546567291021347.pypots
2024-05-25 02:10:50 [INFO]: Epoch 083 - training loss: 0.1165, validation loss: 0.1074
2024-05-25 02:10:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI_epoch83_loss0.10739189982414246.pypots
2024-05-25 02:10:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:10:50 [INFO]: Finished training. The best model is from epoch#73.
2024-05-25 02:10:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T014730/CSDI.pypots
2024-05-25 02:13:11 [INFO]: CSDI on Air-Quality: MAE=0.1234, MSE=0.4399
2024-05-25 02:13:11 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/CSDI_air_quality/imputation.pkl
2024-05-25 02:13:11 [INFO]: Using the given device: cuda:0
2024-05-25 02:13:11 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/GPVAE_air_quality/20240525_T021311
2024-05-25 02:13:11 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/GPVAE_air_quality/20240525_T021311/tensorboard
2024-05-25 02:13:11 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 02:13:11 [INFO]: Epoch 001 - training loss: 62834.2229, validation loss: 0.6787
2024-05-25 02:13:11 [INFO]: Epoch 002 - training loss: 42025.0648, validation loss: 0.6120
2024-05-25 02:13:12 [INFO]: Epoch 003 - training loss: 41774.2439, validation loss: 0.5520
2024-05-25 02:13:12 [INFO]: Epoch 004 - training loss: 41628.0056, validation loss: 0.4829
2024-05-25 02:13:12 [INFO]: Epoch 005 - training loss: 41549.2088, validation loss: 0.4277
2024-05-25 02:13:13 [INFO]: Epoch 006 - training loss: 41488.6936, validation loss: 0.4080
2024-05-25 02:13:13 [INFO]: Epoch 007 - training loss: 41461.0276, validation loss: 0.3940
2024-05-25 02:13:13 [INFO]: Epoch 008 - training loss: 41427.7334, validation loss: 0.3490
2024-05-25 02:13:14 [INFO]: Epoch 009 - training loss: 41418.6913, validation loss: 0.3630
2024-05-25 02:13:14 [INFO]: Epoch 010 - training loss: 41390.0859, validation loss: 0.3522
2024-05-25 02:13:14 [INFO]: Epoch 011 - training loss: 41364.4492, validation loss: 0.3755
2024-05-25 02:13:15 [INFO]: Epoch 012 - training loss: 41362.6628, validation loss: 0.3236
2024-05-25 02:13:15 [INFO]: Epoch 013 - training loss: 41347.0880, validation loss: 0.3156
2024-05-25 02:13:15 [INFO]: Epoch 014 - training loss: 41348.6451, validation loss: 0.3172
2024-05-25 02:13:16 [INFO]: Epoch 015 - training loss: 41323.7840, validation loss: 0.2938
2024-05-25 02:13:16 [INFO]: Epoch 016 - training loss: 41294.1351, validation loss: 0.2892
2024-05-25 02:13:16 [INFO]: Epoch 017 - training loss: 41289.1842, validation loss: 0.3061
2024-05-25 02:13:17 [INFO]: Epoch 018 - training loss: 41290.3660, validation loss: 0.2956
2024-05-25 02:13:17 [INFO]: Epoch 019 - training loss: 41275.2517, validation loss: 0.2819
2024-05-25 02:13:17 [INFO]: Epoch 020 - training loss: 41281.4660, validation loss: 0.2788
2024-05-25 02:13:18 [INFO]: Epoch 021 - training loss: 41271.4336, validation loss: 0.2813
2024-05-25 02:13:18 [INFO]: Epoch 022 - training loss: 41274.6769, validation loss: 0.3176
2024-05-25 02:13:18 [INFO]: Epoch 023 - training loss: 41300.1739, validation loss: 0.2740
2024-05-25 02:13:19 [INFO]: Epoch 024 - training loss: 41292.2264, validation loss: 0.2963
2024-05-25 02:13:19 [INFO]: Epoch 025 - training loss: 41301.8783, validation loss: 0.2940
2024-05-25 02:13:20 [INFO]: Epoch 026 - training loss: 41277.9048, validation loss: 0.2596
2024-05-25 02:13:20 [INFO]: Epoch 027 - training loss: 41243.0271, validation loss: 0.2852
2024-05-25 02:13:20 [INFO]: Epoch 028 - training loss: 41263.8824, validation loss: 0.2676
2024-05-25 02:13:21 [INFO]: Epoch 029 - training loss: 41245.5531, validation loss: 0.2627
2024-05-25 02:13:21 [INFO]: Epoch 030 - training loss: 41219.7789, validation loss: 0.2640
2024-05-25 02:13:21 [INFO]: Epoch 031 - training loss: 41208.0407, validation loss: 0.2480
2024-05-25 02:13:22 [INFO]: Epoch 032 - training loss: 41205.7002, validation loss: 0.2425
2024-05-25 02:13:22 [INFO]: Epoch 033 - training loss: 41197.2258, validation loss: 0.2427
2024-05-25 02:13:22 [INFO]: Epoch 034 - training loss: 41196.3235, validation loss: 0.2420
2024-05-25 02:13:23 [INFO]: Epoch 035 - training loss: 41191.2483, validation loss: 0.2494
2024-05-25 02:13:23 [INFO]: Epoch 036 - training loss: 41217.1707, validation loss: 0.2529
2024-05-25 02:13:23 [INFO]: Epoch 037 - training loss: 41197.3181, validation loss: 0.2333
2024-05-25 02:13:24 [INFO]: Epoch 038 - training loss: 41195.3414, validation loss: 0.2369
2024-05-25 02:13:24 [INFO]: Epoch 039 - training loss: 41214.6778, validation loss: 0.2455
2024-05-25 02:13:24 [INFO]: Epoch 040 - training loss: 41219.2028, validation loss: 0.2380
2024-05-25 02:13:25 [INFO]: Epoch 041 - training loss: 41213.6982, validation loss: 0.2663
2024-05-25 02:13:25 [INFO]: Epoch 042 - training loss: 41225.4463, validation loss: 0.2425
2024-05-25 02:13:26 [INFO]: Epoch 043 - training loss: 41213.1536, validation loss: 0.2306
2024-05-25 02:13:26 [INFO]: Epoch 044 - training loss: 41186.8967, validation loss: 0.2382
2024-05-25 02:13:26 [INFO]: Epoch 045 - training loss: 41177.4026, validation loss: 0.2270
2024-05-25 02:13:27 [INFO]: Epoch 046 - training loss: 41171.2425, validation loss: 0.2302
2024-05-25 02:13:27 [INFO]: Epoch 047 - training loss: 41172.1344, validation loss: 0.2250
2024-05-25 02:13:27 [INFO]: Epoch 048 - training loss: 41173.0774, validation loss: 0.2332
2024-05-25 02:13:28 [INFO]: Epoch 049 - training loss: 41173.2914, validation loss: 0.2314
2024-05-25 02:13:28 [INFO]: Epoch 050 - training loss: 41174.1713, validation loss: 0.2297
2024-05-25 02:13:28 [INFO]: Epoch 051 - training loss: 41165.9240, validation loss: 0.2230
2024-05-25 02:13:29 [INFO]: Epoch 052 - training loss: 41161.0531, validation loss: 0.2193
2024-05-25 02:13:29 [INFO]: Epoch 053 - training loss: 41162.1143, validation loss: 0.2148
2024-05-25 02:13:29 [INFO]: Epoch 054 - training loss: 41159.7904, validation loss: 0.2175
2024-05-25 02:13:30 [INFO]: Epoch 055 - training loss: 41165.0556, validation loss: 0.2169
2024-05-25 02:13:30 [INFO]: Epoch 056 - training loss: 41304.0311, validation loss: 0.2841
2024-05-25 02:13:30 [INFO]: Epoch 057 - training loss: 41308.2399, validation loss: 0.2576
2024-05-25 02:13:31 [INFO]: Epoch 058 - training loss: 41201.4372, validation loss: 0.2466
2024-05-25 02:13:31 [INFO]: Epoch 059 - training loss: 41228.7483, validation loss: 0.2330
2024-05-25 02:13:31 [INFO]: Epoch 060 - training loss: 41174.9049, validation loss: 0.2204
2024-05-25 02:13:32 [INFO]: Epoch 061 - training loss: 41162.2319, validation loss: 0.2273
2024-05-25 02:13:32 [INFO]: Epoch 062 - training loss: 41157.9242, validation loss: 0.2216
2024-05-25 02:13:33 [INFO]: Epoch 063 - training loss: 41156.6322, validation loss: 0.2332
2024-05-25 02:13:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:13:33 [INFO]: Finished training. The best model is from epoch#53.
2024-05-25 02:13:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/GPVAE_air_quality/20240525_T021311/GPVAE.pypots
2024-05-25 02:13:33 [INFO]: GP-VAE on Air-Quality: MAE=0.2708, MSE=0.2215
2024-05-25 02:13:33 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/GPVAE_air_quality/imputation.pkl
2024-05-25 02:13:33 [INFO]: Using the given device: cuda:0
2024-05-25 02:13:33 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/USGAN_air_quality/20240525_T021333
2024-05-25 02:13:33 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/USGAN_air_quality/20240525_T021333/tensorboard
2024-05-25 02:13:33 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 02:13:38 [INFO]: Epoch 001 - generator training loss: 0.6166, discriminator training loss: 0.2789, validation loss: 0.5159
2024-05-25 02:13:42 [INFO]: Epoch 002 - generator training loss: 0.2981, discriminator training loss: 0.0671, validation loss: 0.3886
2024-05-25 02:13:46 [INFO]: Epoch 003 - generator training loss: 0.2267, discriminator training loss: 0.0625, validation loss: 0.3206
2024-05-25 02:13:50 [INFO]: Epoch 004 - generator training loss: 0.1882, discriminator training loss: 0.0622, validation loss: 0.2763
2024-05-25 02:13:54 [INFO]: Epoch 005 - generator training loss: 0.1620, discriminator training loss: 0.0615, validation loss: 0.2497
2024-05-25 02:13:59 [INFO]: Epoch 006 - generator training loss: 0.1446, discriminator training loss: 0.0614, validation loss: 0.2297
2024-05-25 02:14:03 [INFO]: Epoch 007 - generator training loss: 0.1289, discriminator training loss: 0.0608, validation loss: 0.2144
2024-05-25 02:14:07 [INFO]: Epoch 008 - generator training loss: 0.1215, discriminator training loss: 0.0598, validation loss: 0.2029
2024-05-25 02:14:11 [INFO]: Epoch 009 - generator training loss: 0.1074, discriminator training loss: 0.0602, validation loss: 0.1929
2024-05-25 02:14:15 [INFO]: Epoch 010 - generator training loss: 0.1017, discriminator training loss: 0.0588, validation loss: 0.1860
2024-05-25 02:14:20 [INFO]: Epoch 011 - generator training loss: 0.0971, discriminator training loss: 0.0573, validation loss: 0.1794
2024-05-25 02:14:24 [INFO]: Epoch 012 - generator training loss: 0.0935, discriminator training loss: 0.0564, validation loss: 0.1738
2024-05-25 02:14:28 [INFO]: Epoch 013 - generator training loss: 0.0888, discriminator training loss: 0.0550, validation loss: 0.1692
2024-05-25 02:14:32 [INFO]: Epoch 014 - generator training loss: 0.0885, discriminator training loss: 0.0534, validation loss: 0.1647
2024-05-25 02:14:37 [INFO]: Epoch 015 - generator training loss: 0.0829, discriminator training loss: 0.0518, validation loss: 0.1610
2024-05-25 02:14:41 [INFO]: Epoch 016 - generator training loss: 0.0808, discriminator training loss: 0.0503, validation loss: 0.1570
2024-05-25 02:14:45 [INFO]: Epoch 017 - generator training loss: 0.0825, discriminator training loss: 0.0489, validation loss: 0.1541
2024-05-25 02:14:49 [INFO]: Epoch 018 - generator training loss: 0.0770, discriminator training loss: 0.0474, validation loss: 0.1517
2024-05-25 02:14:53 [INFO]: Epoch 019 - generator training loss: 0.0757, discriminator training loss: 0.0460, validation loss: 0.1487
2024-05-25 02:14:57 [INFO]: Epoch 020 - generator training loss: 0.0733, discriminator training loss: 0.0455, validation loss: 0.1468
2024-05-25 02:15:02 [INFO]: Epoch 021 - generator training loss: 0.0716, discriminator training loss: 0.0446, validation loss: 0.1448
2024-05-25 02:15:06 [INFO]: Epoch 022 - generator training loss: 0.0705, discriminator training loss: 0.0438, validation loss: 0.1428
2024-05-25 02:15:10 [INFO]: Epoch 023 - generator training loss: 0.0694, discriminator training loss: 0.0432, validation loss: 0.1407
2024-05-25 02:15:14 [INFO]: Epoch 024 - generator training loss: 0.0683, discriminator training loss: 0.0421, validation loss: 0.1390
2024-05-25 02:15:19 [INFO]: Epoch 025 - generator training loss: 0.0686, discriminator training loss: 0.0414, validation loss: 0.1371
2024-05-25 02:15:23 [INFO]: Epoch 026 - generator training loss: 0.0660, discriminator training loss: 0.0406, validation loss: 0.1359
2024-05-25 02:15:27 [INFO]: Epoch 027 - generator training loss: 0.0643, discriminator training loss: 0.0404, validation loss: 0.1339
2024-05-25 02:15:31 [INFO]: Epoch 028 - generator training loss: 0.0636, discriminator training loss: 0.0396, validation loss: 0.1329
2024-05-25 02:15:35 [INFO]: Epoch 029 - generator training loss: 0.0663, discriminator training loss: 0.0383, validation loss: 0.1319
2024-05-25 02:15:40 [INFO]: Epoch 030 - generator training loss: 0.0620, discriminator training loss: 0.0375, validation loss: 0.1303
2024-05-25 02:15:44 [INFO]: Epoch 031 - generator training loss: 0.0612, discriminator training loss: 0.0369, validation loss: 0.1296
2024-05-25 02:15:48 [INFO]: Epoch 032 - generator training loss: 0.0609, discriminator training loss: 0.0360, validation loss: 0.1283
2024-05-25 02:15:52 [INFO]: Epoch 033 - generator training loss: 0.0605, discriminator training loss: 0.0353, validation loss: 0.1270
2024-05-25 02:15:56 [INFO]: Epoch 034 - generator training loss: 0.0605, discriminator training loss: 0.0343, validation loss: 0.1261
2024-05-25 02:16:01 [INFO]: Epoch 035 - generator training loss: 0.0613, discriminator training loss: 0.0334, validation loss: 0.1253
2024-05-25 02:16:05 [INFO]: Epoch 036 - generator training loss: 0.0596, discriminator training loss: 0.0328, validation loss: 0.1245
2024-05-25 02:16:09 [INFO]: Epoch 037 - generator training loss: 0.0592, discriminator training loss: 0.0321, validation loss: 0.1237
2024-05-25 02:16:13 [INFO]: Epoch 038 - generator training loss: 0.0589, discriminator training loss: 0.0314, validation loss: 0.1224
2024-05-25 02:16:17 [INFO]: Epoch 039 - generator training loss: 0.0583, discriminator training loss: 0.0307, validation loss: 0.1215
2024-05-25 02:16:21 [INFO]: Epoch 040 - generator training loss: 0.0581, discriminator training loss: 0.0301, validation loss: 0.1212
2024-05-25 02:16:26 [INFO]: Epoch 041 - generator training loss: 0.0575, discriminator training loss: 0.0296, validation loss: 0.1200
2024-05-25 02:16:30 [INFO]: Epoch 042 - generator training loss: 0.0572, discriminator training loss: 0.0291, validation loss: 0.1185
2024-05-25 02:16:34 [INFO]: Epoch 043 - generator training loss: 0.0579, discriminator training loss: 0.0288, validation loss: 0.1183
2024-05-25 02:16:38 [INFO]: Epoch 044 - generator training loss: 0.0569, discriminator training loss: 0.0279, validation loss: 0.1174
2024-05-25 02:16:43 [INFO]: Epoch 045 - generator training loss: 0.0568, discriminator training loss: 0.0273, validation loss: 0.1171
2024-05-25 02:16:47 [INFO]: Epoch 046 - generator training loss: 0.0564, discriminator training loss: 0.0268, validation loss: 0.1165
2024-05-25 02:16:51 [INFO]: Epoch 047 - generator training loss: 0.0570, discriminator training loss: 0.0262, validation loss: 0.1159
2024-05-25 02:16:55 [INFO]: Epoch 048 - generator training loss: 0.0561, discriminator training loss: 0.0261, validation loss: 0.1152
2024-05-25 02:16:59 [INFO]: Epoch 049 - generator training loss: 0.0557, discriminator training loss: 0.0257, validation loss: 0.1141
2024-05-25 02:17:03 [INFO]: Epoch 050 - generator training loss: 0.0545, discriminator training loss: 0.0251, validation loss: 0.1137
2024-05-25 02:17:07 [INFO]: Epoch 051 - generator training loss: 0.0541, discriminator training loss: 0.0246, validation loss: 0.1130
2024-05-25 02:17:11 [INFO]: Epoch 052 - generator training loss: 0.0553, discriminator training loss: 0.0245, validation loss: 0.1126
2024-05-25 02:17:16 [INFO]: Epoch 053 - generator training loss: 0.0543, discriminator training loss: 0.0240, validation loss: 0.1123
2024-05-25 02:17:20 [INFO]: Epoch 054 - generator training loss: 0.0545, discriminator training loss: 0.0236, validation loss: 0.1113
2024-05-25 02:17:24 [INFO]: Epoch 055 - generator training loss: 0.0533, discriminator training loss: 0.0235, validation loss: 0.1114
2024-05-25 02:17:28 [INFO]: Epoch 056 - generator training loss: 0.0521, discriminator training loss: 0.0230, validation loss: 0.1104
2024-05-25 02:17:33 [INFO]: Epoch 057 - generator training loss: 0.0521, discriminator training loss: 0.0226, validation loss: 0.1095
2024-05-25 02:17:37 [INFO]: Epoch 058 - generator training loss: 0.0515, discriminator training loss: 0.0224, validation loss: 0.1095
2024-05-25 02:17:41 [INFO]: Epoch 059 - generator training loss: 0.0523, discriminator training loss: 0.0221, validation loss: 0.1084
2024-05-25 02:17:45 [INFO]: Epoch 060 - generator training loss: 0.0508, discriminator training loss: 0.0216, validation loss: 0.1082
2024-05-25 02:17:49 [INFO]: Epoch 061 - generator training loss: 0.0504, discriminator training loss: 0.0219, validation loss: 0.1081
2024-05-25 02:17:54 [INFO]: Epoch 062 - generator training loss: 0.0498, discriminator training loss: 0.0216, validation loss: 0.1078
2024-05-25 02:17:58 [INFO]: Epoch 063 - generator training loss: 0.0497, discriminator training loss: 0.0209, validation loss: 0.1066
2024-05-25 02:18:02 [INFO]: Epoch 064 - generator training loss: 0.0492, discriminator training loss: 0.0207, validation loss: 0.1064
2024-05-25 02:18:06 [INFO]: Epoch 065 - generator training loss: 0.0488, discriminator training loss: 0.0206, validation loss: 0.1060
2024-05-25 02:18:10 [INFO]: Epoch 066 - generator training loss: 0.0486, discriminator training loss: 0.0205, validation loss: 0.1056
2024-05-25 02:18:15 [INFO]: Epoch 067 - generator training loss: 0.0483, discriminator training loss: 0.0200, validation loss: 0.1048
2024-05-25 02:18:19 [INFO]: Epoch 068 - generator training loss: 0.0479, discriminator training loss: 0.0196, validation loss: 0.1052
2024-05-25 02:18:23 [INFO]: Epoch 069 - generator training loss: 0.0483, discriminator training loss: 0.0197, validation loss: 0.1041
2024-05-25 02:18:27 [INFO]: Epoch 070 - generator training loss: 0.0476, discriminator training loss: 0.0195, validation loss: 0.1038
2024-05-25 02:18:31 [INFO]: Epoch 071 - generator training loss: 0.0468, discriminator training loss: 0.0191, validation loss: 0.1038
2024-05-25 02:18:36 [INFO]: Epoch 072 - generator training loss: 0.0468, discriminator training loss: 0.0189, validation loss: 0.1042
2024-05-25 02:18:40 [INFO]: Epoch 073 - generator training loss: 0.0468, discriminator training loss: 0.0189, validation loss: 0.1031
2024-05-25 02:18:44 [INFO]: Epoch 074 - generator training loss: 0.0467, discriminator training loss: 0.0187, validation loss: 0.1032
2024-05-25 02:18:48 [INFO]: Epoch 075 - generator training loss: 0.0458, discriminator training loss: 0.0184, validation loss: 0.1030
2024-05-25 02:18:52 [INFO]: Epoch 076 - generator training loss: 0.0457, discriminator training loss: 0.0183, validation loss: 0.1026
2024-05-25 02:18:57 [INFO]: Epoch 077 - generator training loss: 0.0458, discriminator training loss: 0.0181, validation loss: 0.1023
2024-05-25 02:19:01 [INFO]: Epoch 078 - generator training loss: 0.0456, discriminator training loss: 0.0180, validation loss: 0.1016
2024-05-25 02:19:05 [INFO]: Epoch 079 - generator training loss: 0.0450, discriminator training loss: 0.0179, validation loss: 0.1024
2024-05-25 02:19:09 [INFO]: Epoch 080 - generator training loss: 0.0455, discriminator training loss: 0.0176, validation loss: 0.1015
2024-05-25 02:19:13 [INFO]: Epoch 081 - generator training loss: 0.0440, discriminator training loss: 0.0175, validation loss: 0.1010
2024-05-25 02:19:18 [INFO]: Epoch 082 - generator training loss: 0.0442, discriminator training loss: 0.0174, validation loss: 0.1013
2024-05-25 02:19:22 [INFO]: Epoch 083 - generator training loss: 0.0440, discriminator training loss: 0.0170, validation loss: 0.1006
2024-05-25 02:19:26 [INFO]: Epoch 084 - generator training loss: 0.0434, discriminator training loss: 0.0169, validation loss: 0.1007
2024-05-25 02:19:30 [INFO]: Epoch 085 - generator training loss: 0.0432, discriminator training loss: 0.0169, validation loss: 0.1009
2024-05-25 02:19:34 [INFO]: Epoch 086 - generator training loss: 0.0430, discriminator training loss: 0.0168, validation loss: 0.1006
2024-05-25 02:19:39 [INFO]: Epoch 087 - generator training loss: 0.0427, discriminator training loss: 0.0166, validation loss: 0.1008
2024-05-25 02:19:43 [INFO]: Epoch 088 - generator training loss: 0.0437, discriminator training loss: 0.0165, validation loss: 0.1000
2024-05-25 02:19:47 [INFO]: Epoch 089 - generator training loss: 0.0419, discriminator training loss: 0.0165, validation loss: 0.0999
2024-05-25 02:19:51 [INFO]: Epoch 090 - generator training loss: 0.0421, discriminator training loss: 0.0163, validation loss: 0.0993
2024-05-25 02:19:56 [INFO]: Epoch 091 - generator training loss: 0.0418, discriminator training loss: 0.0160, validation loss: 0.0999
2024-05-25 02:20:00 [INFO]: Epoch 092 - generator training loss: 0.0422, discriminator training loss: 0.0159, validation loss: 0.0996
2024-05-25 02:20:04 [INFO]: Epoch 093 - generator training loss: 0.0425, discriminator training loss: 0.0160, validation loss: 0.0998
2024-05-25 02:20:08 [INFO]: Epoch 094 - generator training loss: 0.0416, discriminator training loss: 0.0158, validation loss: 0.0995
2024-05-25 02:20:12 [INFO]: Epoch 095 - generator training loss: 0.0407, discriminator training loss: 0.0158, validation loss: 0.1002
2024-05-25 02:20:17 [INFO]: Epoch 096 - generator training loss: 0.0406, discriminator training loss: 0.0158, validation loss: 0.0998
2024-05-25 02:20:21 [INFO]: Epoch 097 - generator training loss: 0.0405, discriminator training loss: 0.0154, validation loss: 0.0993
2024-05-25 02:20:25 [INFO]: Epoch 098 - generator training loss: 0.0402, discriminator training loss: 0.0155, validation loss: 0.1002
2024-05-25 02:20:29 [INFO]: Epoch 099 - generator training loss: 0.0401, discriminator training loss: 0.0153, validation loss: 0.0988
2024-05-25 02:20:33 [INFO]: Epoch 100 - generator training loss: 0.0402, discriminator training loss: 0.0155, validation loss: 0.0990
2024-05-25 02:20:37 [INFO]: Epoch 101 - generator training loss: 0.0394, discriminator training loss: 0.0155, validation loss: 0.0994
2024-05-25 02:20:42 [INFO]: Epoch 102 - generator training loss: 0.0393, discriminator training loss: 0.0152, validation loss: 0.0987
2024-05-25 02:20:46 [INFO]: Epoch 103 - generator training loss: 0.0392, discriminator training loss: 0.0151, validation loss: 0.0985
2024-05-25 02:20:50 [INFO]: Epoch 104 - generator training loss: 0.0396, discriminator training loss: 0.0152, validation loss: 0.0985
2024-05-25 02:20:54 [INFO]: Epoch 105 - generator training loss: 0.0389, discriminator training loss: 0.0149, validation loss: 0.0985
2024-05-25 02:20:58 [INFO]: Epoch 106 - generator training loss: 0.0396, discriminator training loss: 0.0148, validation loss: 0.0994
2024-05-25 02:21:03 [INFO]: Epoch 107 - generator training loss: 0.0414, discriminator training loss: 0.0147, validation loss: 0.0985
2024-05-25 02:21:07 [INFO]: Epoch 108 - generator training loss: 0.0408, discriminator training loss: 0.0149, validation loss: 0.0992
2024-05-25 02:21:11 [INFO]: Epoch 109 - generator training loss: 0.0387, discriminator training loss: 0.0145, validation loss: 0.0985
2024-05-25 02:21:15 [INFO]: Epoch 110 - generator training loss: 0.0381, discriminator training loss: 0.0144, validation loss: 0.0978
2024-05-25 02:21:19 [INFO]: Epoch 111 - generator training loss: 0.0385, discriminator training loss: 0.0144, validation loss: 0.0972
2024-05-25 02:21:24 [INFO]: Epoch 112 - generator training loss: 0.0377, discriminator training loss: 0.0145, validation loss: 0.0978
2024-05-25 02:21:28 [INFO]: Epoch 113 - generator training loss: 0.0373, discriminator training loss: 0.0144, validation loss: 0.0974
2024-05-25 02:21:32 [INFO]: Epoch 114 - generator training loss: 0.0373, discriminator training loss: 0.0143, validation loss: 0.0980
2024-05-25 02:21:36 [INFO]: Epoch 115 - generator training loss: 0.0368, discriminator training loss: 0.0141, validation loss: 0.0978
2024-05-25 02:21:41 [INFO]: Epoch 116 - generator training loss: 0.0371, discriminator training loss: 0.0142, validation loss: 0.0977
2024-05-25 02:21:45 [INFO]: Epoch 117 - generator training loss: 0.0364, discriminator training loss: 0.0143, validation loss: 0.0979
2024-05-25 02:21:49 [INFO]: Epoch 118 - generator training loss: 0.0363, discriminator training loss: 0.0140, validation loss: 0.0977
2024-05-25 02:21:53 [INFO]: Epoch 119 - generator training loss: 0.0363, discriminator training loss: 0.0140, validation loss: 0.0974
2024-05-25 02:21:57 [INFO]: Epoch 120 - generator training loss: 0.0358, discriminator training loss: 0.0140, validation loss: 0.0975
2024-05-25 02:22:01 [INFO]: Epoch 121 - generator training loss: 0.0362, discriminator training loss: 0.0138, validation loss: 0.0973
2024-05-25 02:22:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:22:01 [INFO]: Finished training. The best model is from epoch#111.
2024-05-25 02:22:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/USGAN_air_quality/20240525_T021333/USGAN.pypots
2024-05-25 02:22:02 [INFO]: US-GAN on Air-Quality: MAE=0.1546, MSE=0.0970
2024-05-25 02:22:02 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/USGAN_air_quality/imputation.pkl
2024-05-25 02:22:02 [INFO]: Using the given device: cuda:0
2024-05-25 02:22:02 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/BRITS_air_quality/20240525_T022202
2024-05-25 02:22:02 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/BRITS_air_quality/20240525_T022202/tensorboard
2024-05-25 02:22:02 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 02:22:06 [INFO]: Epoch 001 - training loss: 1.4036, validation loss: 0.9476
2024-05-25 02:22:09 [INFO]: Epoch 002 - training loss: 1.1368, validation loss: 0.7022
2024-05-25 02:22:12 [INFO]: Epoch 003 - training loss: 0.9367, validation loss: 0.5890
2024-05-25 02:22:14 [INFO]: Epoch 004 - training loss: 0.8292, validation loss: 0.5201
2024-05-25 02:22:17 [INFO]: Epoch 005 - training loss: 0.7557, validation loss: 0.4749
2024-05-25 02:22:20 [INFO]: Epoch 006 - training loss: 0.6967, validation loss: 0.4362
2024-05-25 02:22:23 [INFO]: Epoch 007 - training loss: 0.6554, validation loss: 0.4059
2024-05-25 02:22:26 [INFO]: Epoch 008 - training loss: 0.6187, validation loss: 0.3822
2024-05-25 02:22:29 [INFO]: Epoch 009 - training loss: 0.5923, validation loss: 0.3620
2024-05-25 02:22:32 [INFO]: Epoch 010 - training loss: 0.5709, validation loss: 0.3465
2024-05-25 02:22:34 [INFO]: Epoch 011 - training loss: 0.5528, validation loss: 0.3328
2024-05-25 02:22:37 [INFO]: Epoch 012 - training loss: 0.5380, validation loss: 0.3220
2024-05-25 02:22:40 [INFO]: Epoch 013 - training loss: 0.5257, validation loss: 0.3121
2024-05-25 02:22:43 [INFO]: Epoch 014 - training loss: 0.5130, validation loss: 0.3036
2024-05-25 02:22:46 [INFO]: Epoch 015 - training loss: 0.5029, validation loss: 0.2961
2024-05-25 02:22:49 [INFO]: Epoch 016 - training loss: 0.4929, validation loss: 0.2889
2024-05-25 02:22:52 [INFO]: Epoch 017 - training loss: 0.4841, validation loss: 0.2830
2024-05-25 02:22:54 [INFO]: Epoch 018 - training loss: 0.4773, validation loss: 0.2778
2024-05-25 02:22:57 [INFO]: Epoch 019 - training loss: 0.4685, validation loss: 0.2728
2024-05-25 02:23:00 [INFO]: Epoch 020 - training loss: 0.4604, validation loss: 0.2678
2024-05-25 02:23:03 [INFO]: Epoch 021 - training loss: 0.4550, validation loss: 0.2635
2024-05-25 02:23:06 [INFO]: Epoch 022 - training loss: 0.4467, validation loss: 0.2593
2024-05-25 02:23:09 [INFO]: Epoch 023 - training loss: 0.4408, validation loss: 0.2551
2024-05-25 02:23:11 [INFO]: Epoch 024 - training loss: 0.4347, validation loss: 0.2515
2024-05-25 02:23:14 [INFO]: Epoch 025 - training loss: 0.4296, validation loss: 0.2479
2024-05-25 02:23:17 [INFO]: Epoch 026 - training loss: 0.4239, validation loss: 0.2448
2024-05-25 02:23:20 [INFO]: Epoch 027 - training loss: 0.4191, validation loss: 0.2413
2024-05-25 02:23:23 [INFO]: Epoch 028 - training loss: 0.4135, validation loss: 0.2378
2024-05-25 02:23:26 [INFO]: Epoch 029 - training loss: 0.4086, validation loss: 0.2347
2024-05-25 02:23:28 [INFO]: Epoch 030 - training loss: 0.4039, validation loss: 0.2319
2024-05-25 02:23:31 [INFO]: Epoch 031 - training loss: 0.3998, validation loss: 0.2288
2024-05-25 02:23:34 [INFO]: Epoch 032 - training loss: 0.3945, validation loss: 0.2258
2024-05-25 02:23:37 [INFO]: Epoch 033 - training loss: 0.3921, validation loss: 0.2228
2024-05-25 02:23:40 [INFO]: Epoch 034 - training loss: 0.3873, validation loss: 0.2201
2024-05-25 02:23:43 [INFO]: Epoch 035 - training loss: 0.3841, validation loss: 0.2172
2024-05-25 02:23:46 [INFO]: Epoch 036 - training loss: 0.3799, validation loss: 0.2147
2024-05-25 02:23:48 [INFO]: Epoch 037 - training loss: 0.3768, validation loss: 0.2125
2024-05-25 02:23:51 [INFO]: Epoch 038 - training loss: 0.3726, validation loss: 0.2095
2024-05-25 02:23:54 [INFO]: Epoch 039 - training loss: 0.3692, validation loss: 0.2070
2024-05-25 02:23:57 [INFO]: Epoch 040 - training loss: 0.3667, validation loss: 0.2041
2024-05-25 02:24:00 [INFO]: Epoch 041 - training loss: 0.3627, validation loss: 0.2019
2024-05-25 02:24:03 [INFO]: Epoch 042 - training loss: 0.3605, validation loss: 0.1994
2024-05-25 02:24:05 [INFO]: Epoch 043 - training loss: 0.3575, validation loss: 0.1970
2024-05-25 02:24:08 [INFO]: Epoch 044 - training loss: 0.3555, validation loss: 0.1946
2024-05-25 02:24:11 [INFO]: Epoch 045 - training loss: 0.3518, validation loss: 0.1920
2024-05-25 02:24:14 [INFO]: Epoch 046 - training loss: 0.3492, validation loss: 0.1892
2024-05-25 02:24:16 [INFO]: Epoch 047 - training loss: 0.3475, validation loss: 0.1873
2024-05-25 02:24:19 [INFO]: Epoch 048 - training loss: 0.3445, validation loss: 0.1849
2024-05-25 02:24:22 [INFO]: Epoch 049 - training loss: 0.3421, validation loss: 0.1826
2024-05-25 02:24:25 [INFO]: Epoch 050 - training loss: 0.3395, validation loss: 0.1810
2024-05-25 02:24:28 [INFO]: Epoch 051 - training loss: 0.3378, validation loss: 0.1785
2024-05-25 02:24:31 [INFO]: Epoch 052 - training loss: 0.3349, validation loss: 0.1765
2024-05-25 02:24:34 [INFO]: Epoch 053 - training loss: 0.3337, validation loss: 0.1743
2024-05-25 02:24:36 [INFO]: Epoch 054 - training loss: 0.3310, validation loss: 0.1721
2024-05-25 02:24:39 [INFO]: Epoch 055 - training loss: 0.3287, validation loss: 0.1702
2024-05-25 02:24:42 [INFO]: Epoch 056 - training loss: 0.3270, validation loss: 0.1682
2024-05-25 02:24:45 [INFO]: Epoch 057 - training loss: 0.3253, validation loss: 0.1665
2024-05-25 02:24:48 [INFO]: Epoch 058 - training loss: 0.3234, validation loss: 0.1649
2024-05-25 02:24:51 [INFO]: Epoch 059 - training loss: 0.3218, validation loss: 0.1631
2024-05-25 02:24:54 [INFO]: Epoch 060 - training loss: 0.3198, validation loss: 0.1618
2024-05-25 02:24:56 [INFO]: Epoch 061 - training loss: 0.3186, validation loss: 0.1601
2024-05-25 02:24:59 [INFO]: Epoch 062 - training loss: 0.3184, validation loss: 0.1588
2024-05-25 02:25:02 [INFO]: Epoch 063 - training loss: 0.3153, validation loss: 0.1564
2024-05-25 02:25:05 [INFO]: Epoch 064 - training loss: 0.3134, validation loss: 0.1547
2024-05-25 02:25:08 [INFO]: Epoch 065 - training loss: 0.3127, validation loss: 0.1538
2024-05-25 02:25:11 [INFO]: Epoch 066 - training loss: 0.3109, validation loss: 0.1523
2024-05-25 02:25:14 [INFO]: Epoch 067 - training loss: 0.3096, validation loss: 0.1512
2024-05-25 02:25:16 [INFO]: Epoch 068 - training loss: 0.3081, validation loss: 0.1501
2024-05-25 02:25:19 [INFO]: Epoch 069 - training loss: 0.3074, validation loss: 0.1491
2024-05-25 02:25:22 [INFO]: Epoch 070 - training loss: 0.3059, validation loss: 0.1480
2024-05-25 02:25:25 [INFO]: Epoch 071 - training loss: 0.3043, validation loss: 0.1469
2024-05-25 02:25:28 [INFO]: Epoch 072 - training loss: 0.3033, validation loss: 0.1460
2024-05-25 02:25:31 [INFO]: Epoch 073 - training loss: 0.3024, validation loss: 0.1456
2024-05-25 02:25:33 [INFO]: Epoch 074 - training loss: 0.3012, validation loss: 0.1446
2024-05-25 02:25:36 [INFO]: Epoch 075 - training loss: 0.3008, validation loss: 0.1438
2024-05-25 02:25:39 [INFO]: Epoch 076 - training loss: 0.2986, validation loss: 0.1430
2024-05-25 02:25:42 [INFO]: Epoch 077 - training loss: 0.2978, validation loss: 0.1420
2024-05-25 02:25:45 [INFO]: Epoch 078 - training loss: 0.2975, validation loss: 0.1413
2024-05-25 02:25:48 [INFO]: Epoch 079 - training loss: 0.2963, validation loss: 0.1405
2024-05-25 02:25:50 [INFO]: Epoch 080 - training loss: 0.2954, validation loss: 0.1403
2024-05-25 02:25:53 [INFO]: Epoch 081 - training loss: 0.2946, validation loss: 0.1394
2024-05-25 02:25:56 [INFO]: Epoch 082 - training loss: 0.2934, validation loss: 0.1386
2024-05-25 02:25:59 [INFO]: Epoch 083 - training loss: 0.2927, validation loss: 0.1381
2024-05-25 02:26:02 [INFO]: Epoch 084 - training loss: 0.2920, validation loss: 0.1377
2024-05-25 02:26:05 [INFO]: Epoch 085 - training loss: 0.2907, validation loss: 0.1370
2024-05-25 02:26:08 [INFO]: Epoch 086 - training loss: 0.2900, validation loss: 0.1365
2024-05-25 02:26:10 [INFO]: Epoch 087 - training loss: 0.2889, validation loss: 0.1359
2024-05-25 02:26:13 [INFO]: Epoch 088 - training loss: 0.2885, validation loss: 0.1352
2024-05-25 02:26:16 [INFO]: Epoch 089 - training loss: 0.2870, validation loss: 0.1347
2024-05-25 02:26:19 [INFO]: Epoch 090 - training loss: 0.2865, validation loss: 0.1343
2024-05-25 02:26:22 [INFO]: Epoch 091 - training loss: 0.2867, validation loss: 0.1337
2024-05-25 02:26:25 [INFO]: Epoch 092 - training loss: 0.2855, validation loss: 0.1333
2024-05-25 02:26:27 [INFO]: Epoch 093 - training loss: 0.2839, validation loss: 0.1327
2024-05-25 02:26:30 [INFO]: Epoch 094 - training loss: 0.2843, validation loss: 0.1324
2024-05-25 02:26:33 [INFO]: Epoch 095 - training loss: 0.2828, validation loss: 0.1318
2024-05-25 02:26:36 [INFO]: Epoch 096 - training loss: 0.2827, validation loss: 0.1315
2024-05-25 02:26:39 [INFO]: Epoch 097 - training loss: 0.2820, validation loss: 0.1310
2024-05-25 02:26:42 [INFO]: Epoch 098 - training loss: 0.2807, validation loss: 0.1305
2024-05-25 02:26:45 [INFO]: Epoch 099 - training loss: 0.2802, validation loss: 0.1302
2024-05-25 02:26:47 [INFO]: Epoch 100 - training loss: 0.2795, validation loss: 0.1298
2024-05-25 02:26:50 [INFO]: Epoch 101 - training loss: 0.2788, validation loss: 0.1293
2024-05-25 02:26:53 [INFO]: Epoch 102 - training loss: 0.2783, validation loss: 0.1289
2024-05-25 02:26:56 [INFO]: Epoch 103 - training loss: 0.2780, validation loss: 0.1285
2024-05-25 02:26:59 [INFO]: Epoch 104 - training loss: 0.2772, validation loss: 0.1282
2024-05-25 02:27:02 [INFO]: Epoch 105 - training loss: 0.2764, validation loss: 0.1278
2024-05-25 02:27:05 [INFO]: Epoch 106 - training loss: 0.2759, validation loss: 0.1273
2024-05-25 02:27:07 [INFO]: Epoch 107 - training loss: 0.2760, validation loss: 0.1271
2024-05-25 02:27:10 [INFO]: Epoch 108 - training loss: 0.2749, validation loss: 0.1264
2024-05-25 02:27:13 [INFO]: Epoch 109 - training loss: 0.2744, validation loss: 0.1263
2024-05-25 02:27:16 [INFO]: Epoch 110 - training loss: 0.2735, validation loss: 0.1260
2024-05-25 02:27:19 [INFO]: Epoch 111 - training loss: 0.2730, validation loss: 0.1255
2024-05-25 02:27:22 [INFO]: Epoch 112 - training loss: 0.2727, validation loss: 0.1252
2024-05-25 02:27:24 [INFO]: Epoch 113 - training loss: 0.2722, validation loss: 0.1250
2024-05-25 02:27:27 [INFO]: Epoch 114 - training loss: 0.2714, validation loss: 0.1246
2024-05-25 02:27:30 [INFO]: Epoch 115 - training loss: 0.2711, validation loss: 0.1241
2024-05-25 02:27:33 [INFO]: Epoch 116 - training loss: 0.2708, validation loss: 0.1239
2024-05-25 02:27:36 [INFO]: Epoch 117 - training loss: 0.2704, validation loss: 0.1236
2024-05-25 02:27:39 [INFO]: Epoch 118 - training loss: 0.2701, validation loss: 0.1231
2024-05-25 02:27:42 [INFO]: Epoch 119 - training loss: 0.2686, validation loss: 0.1230
2024-05-25 02:27:44 [INFO]: Epoch 120 - training loss: 0.2682, validation loss: 0.1225
2024-05-25 02:27:47 [INFO]: Epoch 121 - training loss: 0.2677, validation loss: 0.1222
2024-05-25 02:27:50 [INFO]: Epoch 122 - training loss: 0.2679, validation loss: 0.1221
2024-05-25 02:27:53 [INFO]: Epoch 123 - training loss: 0.2680, validation loss: 0.1215
2024-05-25 02:27:56 [INFO]: Epoch 124 - training loss: 0.2668, validation loss: 0.1212
2024-05-25 02:27:59 [INFO]: Epoch 125 - training loss: 0.2661, validation loss: 0.1211
2024-05-25 02:28:01 [INFO]: Epoch 126 - training loss: 0.2659, validation loss: 0.1206
2024-05-25 02:28:04 [INFO]: Epoch 127 - training loss: 0.2656, validation loss: 0.1205
2024-05-25 02:28:07 [INFO]: Epoch 128 - training loss: 0.2655, validation loss: 0.1201
2024-05-25 02:28:10 [INFO]: Epoch 129 - training loss: 0.2644, validation loss: 0.1200
2024-05-25 02:28:13 [INFO]: Epoch 130 - training loss: 0.2636, validation loss: 0.1196
2024-05-25 02:28:16 [INFO]: Epoch 131 - training loss: 0.2636, validation loss: 0.1193
2024-05-25 02:28:19 [INFO]: Epoch 132 - training loss: 0.2633, validation loss: 0.1189
2024-05-25 02:28:21 [INFO]: Epoch 133 - training loss: 0.2628, validation loss: 0.1187
2024-05-25 02:28:24 [INFO]: Epoch 134 - training loss: 0.2628, validation loss: 0.1183
2024-05-25 02:28:27 [INFO]: Epoch 135 - training loss: 0.2620, validation loss: 0.1182
2024-05-25 02:28:30 [INFO]: Epoch 136 - training loss: 0.2617, validation loss: 0.1178
2024-05-25 02:28:33 [INFO]: Epoch 137 - training loss: 0.2612, validation loss: 0.1176
2024-05-25 02:28:36 [INFO]: Epoch 138 - training loss: 0.2606, validation loss: 0.1174
2024-05-25 02:28:38 [INFO]: Epoch 139 - training loss: 0.2606, validation loss: 0.1172
2024-05-25 02:28:41 [INFO]: Epoch 140 - training loss: 0.2605, validation loss: 0.1170
2024-05-25 02:28:44 [INFO]: Epoch 141 - training loss: 0.2598, validation loss: 0.1166
2024-05-25 02:28:47 [INFO]: Epoch 142 - training loss: 0.2589, validation loss: 0.1163
2024-05-25 02:28:50 [INFO]: Epoch 143 - training loss: 0.2589, validation loss: 0.1161
2024-05-25 02:28:53 [INFO]: Epoch 144 - training loss: 0.2585, validation loss: 0.1158
2024-05-25 02:28:56 [INFO]: Epoch 145 - training loss: 0.2583, validation loss: 0.1156
2024-05-25 02:28:58 [INFO]: Epoch 146 - training loss: 0.2575, validation loss: 0.1156
2024-05-25 02:29:01 [INFO]: Epoch 147 - training loss: 0.2573, validation loss: 0.1151
2024-05-25 02:29:04 [INFO]: Epoch 148 - training loss: 0.2570, validation loss: 0.1149
2024-05-25 02:29:07 [INFO]: Epoch 149 - training loss: 0.2567, validation loss: 0.1148
2024-05-25 02:29:10 [INFO]: Epoch 150 - training loss: 0.2565, validation loss: 0.1145
2024-05-25 02:29:13 [INFO]: Epoch 151 - training loss: 0.2562, validation loss: 0.1144
2024-05-25 02:29:15 [INFO]: Epoch 152 - training loss: 0.2556, validation loss: 0.1142
2024-05-25 02:29:18 [INFO]: Epoch 153 - training loss: 0.2555, validation loss: 0.1139
2024-05-25 02:29:21 [INFO]: Epoch 154 - training loss: 0.2556, validation loss: 0.1138
2024-05-25 02:29:24 [INFO]: Epoch 155 - training loss: 0.2555, validation loss: 0.1135
2024-05-25 02:29:27 [INFO]: Epoch 156 - training loss: 0.2549, validation loss: 0.1132
2024-05-25 02:29:30 [INFO]: Epoch 157 - training loss: 0.2544, validation loss: 0.1131
2024-05-25 02:29:33 [INFO]: Epoch 158 - training loss: 0.2544, validation loss: 0.1128
2024-05-25 02:29:35 [INFO]: Epoch 159 - training loss: 0.2541, validation loss: 0.1127
2024-05-25 02:29:38 [INFO]: Epoch 160 - training loss: 0.2531, validation loss: 0.1122
2024-05-25 02:29:41 [INFO]: Epoch 161 - training loss: 0.2530, validation loss: 0.1123
2024-05-25 02:29:44 [INFO]: Epoch 162 - training loss: 0.2524, validation loss: 0.1121
2024-05-25 02:29:47 [INFO]: Epoch 163 - training loss: 0.2526, validation loss: 0.1119
2024-05-25 02:29:50 [INFO]: Epoch 164 - training loss: 0.2522, validation loss: 0.1116
2024-05-25 02:29:53 [INFO]: Epoch 165 - training loss: 0.2519, validation loss: 0.1116
2024-05-25 02:29:55 [INFO]: Epoch 166 - training loss: 0.2516, validation loss: 0.1114
2024-05-25 02:29:58 [INFO]: Epoch 167 - training loss: 0.2511, validation loss: 0.1112
2024-05-25 02:30:01 [INFO]: Epoch 168 - training loss: 0.2513, validation loss: 0.1110
2024-05-25 02:30:04 [INFO]: Epoch 169 - training loss: 0.2514, validation loss: 0.1108
2024-05-25 02:30:07 [INFO]: Epoch 170 - training loss: 0.2501, validation loss: 0.1106
2024-05-25 02:30:10 [INFO]: Epoch 171 - training loss: 0.2504, validation loss: 0.1105
2024-05-25 02:30:12 [INFO]: Epoch 172 - training loss: 0.2500, validation loss: 0.1104
2024-05-25 02:30:15 [INFO]: Epoch 173 - training loss: 0.2498, validation loss: 0.1103
2024-05-25 02:30:18 [INFO]: Epoch 174 - training loss: 0.2494, validation loss: 0.1101
2024-05-25 02:30:21 [INFO]: Epoch 175 - training loss: 0.2487, validation loss: 0.1100
2024-05-25 02:30:24 [INFO]: Epoch 176 - training loss: 0.2488, validation loss: 0.1097
2024-05-25 02:30:27 [INFO]: Epoch 177 - training loss: 0.2489, validation loss: 0.1095
2024-05-25 02:30:29 [INFO]: Epoch 178 - training loss: 0.2482, validation loss: 0.1095
2024-05-25 02:30:32 [INFO]: Epoch 179 - training loss: 0.2481, validation loss: 0.1093
2024-05-25 02:30:35 [INFO]: Epoch 180 - training loss: 0.2478, validation loss: 0.1092
2024-05-25 02:30:38 [INFO]: Epoch 181 - training loss: 0.2473, validation loss: 0.1091
2024-05-25 02:30:41 [INFO]: Epoch 182 - training loss: 0.2476, validation loss: 0.1088
2024-05-25 02:30:44 [INFO]: Epoch 183 - training loss: 0.2473, validation loss: 0.1086
2024-05-25 02:30:47 [INFO]: Epoch 184 - training loss: 0.2473, validation loss: 0.1085
2024-05-25 02:30:49 [INFO]: Epoch 185 - training loss: 0.2468, validation loss: 0.1085
2024-05-25 02:30:52 [INFO]: Epoch 186 - training loss: 0.2463, validation loss: 0.1085
2024-05-25 02:30:55 [INFO]: Epoch 187 - training loss: 0.2470, validation loss: 0.1081
2024-05-25 02:30:58 [INFO]: Epoch 188 - training loss: 0.2476, validation loss: 0.1081
2024-05-25 02:31:01 [INFO]: Epoch 189 - training loss: 0.2460, validation loss: 0.1079
2024-05-25 02:31:04 [INFO]: Epoch 190 - training loss: 0.2451, validation loss: 0.1078
2024-05-25 02:31:07 [INFO]: Epoch 191 - training loss: 0.2457, validation loss: 0.1075
2024-05-25 02:31:09 [INFO]: Epoch 192 - training loss: 0.2450, validation loss: 0.1075
2024-05-25 02:31:12 [INFO]: Epoch 193 - training loss: 0.2446, validation loss: 0.1073
2024-05-25 02:31:15 [INFO]: Epoch 194 - training loss: 0.2447, validation loss: 0.1073
2024-05-25 02:31:18 [INFO]: Epoch 195 - training loss: 0.2443, validation loss: 0.1072
2024-05-25 02:31:21 [INFO]: Epoch 196 - training loss: 0.2451, validation loss: 0.1071
2024-05-25 02:31:24 [INFO]: Epoch 197 - training loss: 0.2442, validation loss: 0.1070
2024-05-25 02:31:26 [INFO]: Epoch 198 - training loss: 0.2439, validation loss: 0.1068
2024-05-25 02:31:29 [INFO]: Epoch 199 - training loss: 0.2432, validation loss: 0.1067
2024-05-25 02:31:32 [INFO]: Epoch 200 - training loss: 0.2433, validation loss: 0.1065
2024-05-25 02:31:35 [INFO]: Epoch 201 - training loss: 0.2432, validation loss: 0.1063
2024-05-25 02:31:37 [INFO]: Epoch 202 - training loss: 0.2427, validation loss: 0.1064
2024-05-25 02:31:40 [INFO]: Epoch 203 - training loss: 0.2427, validation loss: 0.1061
2024-05-25 02:31:43 [INFO]: Epoch 204 - training loss: 0.2423, validation loss: 0.1061
2024-05-25 02:31:46 [INFO]: Epoch 205 - training loss: 0.2421, validation loss: 0.1059
2024-05-25 02:31:49 [INFO]: Epoch 206 - training loss: 0.2424, validation loss: 0.1060
2024-05-25 02:31:52 [INFO]: Epoch 207 - training loss: 0.2419, validation loss: 0.1059
2024-05-25 02:31:54 [INFO]: Epoch 208 - training loss: 0.2423, validation loss: 0.1057
2024-05-25 02:31:57 [INFO]: Epoch 209 - training loss: 0.2416, validation loss: 0.1055
2024-05-25 02:32:00 [INFO]: Epoch 210 - training loss: 0.2420, validation loss: 0.1056
2024-05-25 02:32:03 [INFO]: Epoch 211 - training loss: 0.2415, validation loss: 0.1054
2024-05-25 02:32:06 [INFO]: Epoch 212 - training loss: 0.2407, validation loss: 0.1052
2024-05-25 02:32:09 [INFO]: Epoch 213 - training loss: 0.2409, validation loss: 0.1053
2024-05-25 02:32:11 [INFO]: Epoch 214 - training loss: 0.2407, validation loss: 0.1052
2024-05-25 02:32:14 [INFO]: Epoch 215 - training loss: 0.2409, validation loss: 0.1049
2024-05-25 02:32:17 [INFO]: Epoch 216 - training loss: 0.2402, validation loss: 0.1049
2024-05-25 02:32:20 [INFO]: Epoch 217 - training loss: 0.2404, validation loss: 0.1049
2024-05-25 02:32:23 [INFO]: Epoch 218 - training loss: 0.2399, validation loss: 0.1049
2024-05-25 02:32:26 [INFO]: Epoch 219 - training loss: 0.2403, validation loss: 0.1046
2024-05-25 02:32:29 [INFO]: Epoch 220 - training loss: 0.2401, validation loss: 0.1045
2024-05-25 02:32:31 [INFO]: Epoch 221 - training loss: 0.2394, validation loss: 0.1045
2024-05-25 02:32:34 [INFO]: Epoch 222 - training loss: 0.2397, validation loss: 0.1044
2024-05-25 02:32:37 [INFO]: Epoch 223 - training loss: 0.2391, validation loss: 0.1044
2024-05-25 02:32:40 [INFO]: Epoch 224 - training loss: 0.2389, validation loss: 0.1044
2024-05-25 02:32:43 [INFO]: Epoch 225 - training loss: 0.2393, validation loss: 0.1042
2024-05-25 02:32:46 [INFO]: Epoch 226 - training loss: 0.2395, validation loss: 0.1041
2024-05-25 02:32:48 [INFO]: Epoch 227 - training loss: 0.2387, validation loss: 0.1041
2024-05-25 02:32:51 [INFO]: Epoch 228 - training loss: 0.2385, validation loss: 0.1041
2024-05-25 02:32:54 [INFO]: Epoch 229 - training loss: 0.2387, validation loss: 0.1039
2024-05-25 02:32:57 [INFO]: Epoch 230 - training loss: 0.2384, validation loss: 0.1038
2024-05-25 02:33:00 [INFO]: Epoch 231 - training loss: 0.2378, validation loss: 0.1038
2024-05-25 02:33:03 [INFO]: Epoch 232 - training loss: 0.2379, validation loss: 0.1037
2024-05-25 02:33:05 [INFO]: Epoch 233 - training loss: 0.2375, validation loss: 0.1036
2024-05-25 02:33:08 [INFO]: Epoch 234 - training loss: 0.2374, validation loss: 0.1035
2024-05-25 02:33:11 [INFO]: Epoch 235 - training loss: 0.2370, validation loss: 0.1034
2024-05-25 02:33:14 [INFO]: Epoch 236 - training loss: 0.2373, validation loss: 0.1032
2024-05-25 02:33:17 [INFO]: Epoch 237 - training loss: 0.2373, validation loss: 0.1033
2024-05-25 02:33:20 [INFO]: Epoch 238 - training loss: 0.2368, validation loss: 0.1032
2024-05-25 02:33:23 [INFO]: Epoch 239 - training loss: 0.2365, validation loss: 0.1030
2024-05-25 02:33:26 [INFO]: Epoch 240 - training loss: 0.2364, validation loss: 0.1031
2024-05-25 02:33:28 [INFO]: Epoch 241 - training loss: 0.2362, validation loss: 0.1029
2024-05-25 02:33:31 [INFO]: Epoch 242 - training loss: 0.2364, validation loss: 0.1029
2024-05-25 02:33:34 [INFO]: Epoch 243 - training loss: 0.2363, validation loss: 0.1031
2024-05-25 02:33:37 [INFO]: Epoch 244 - training loss: 0.2356, validation loss: 0.1028
2024-05-25 02:33:40 [INFO]: Epoch 245 - training loss: 0.2359, validation loss: 0.1030
2024-05-25 02:33:43 [INFO]: Epoch 246 - training loss: 0.2354, validation loss: 0.1027
2024-05-25 02:33:45 [INFO]: Epoch 247 - training loss: 0.2349, validation loss: 0.1026
2024-05-25 02:33:48 [INFO]: Epoch 248 - training loss: 0.2356, validation loss: 0.1026
2024-05-25 02:33:51 [INFO]: Epoch 249 - training loss: 0.2353, validation loss: 0.1024
2024-05-25 02:33:54 [INFO]: Epoch 250 - training loss: 0.2349, validation loss: 0.1023
2024-05-25 02:33:57 [INFO]: Epoch 251 - training loss: 0.2344, validation loss: 0.1023
2024-05-25 02:34:00 [INFO]: Epoch 252 - training loss: 0.2350, validation loss: 0.1022
2024-05-25 02:34:03 [INFO]: Epoch 253 - training loss: 0.2349, validation loss: 0.1023
2024-05-25 02:34:05 [INFO]: Epoch 254 - training loss: 0.2346, validation loss: 0.1023
2024-05-25 02:34:08 [INFO]: Epoch 255 - training loss: 0.2343, validation loss: 0.1020
2024-05-25 02:34:11 [INFO]: Epoch 256 - training loss: 0.2341, validation loss: 0.1023
2024-05-25 02:34:14 [INFO]: Epoch 257 - training loss: 0.2343, validation loss: 0.1021
2024-05-25 02:34:17 [INFO]: Epoch 258 - training loss: 0.2339, validation loss: 0.1020
2024-05-25 02:34:20 [INFO]: Epoch 259 - training loss: 0.2334, validation loss: 0.1019
2024-05-25 02:34:22 [INFO]: Epoch 260 - training loss: 0.2333, validation loss: 0.1019
2024-05-25 02:34:25 [INFO]: Epoch 261 - training loss: 0.2337, validation loss: 0.1019
2024-05-25 02:34:28 [INFO]: Epoch 262 - training loss: 0.2332, validation loss: 0.1019
2024-05-25 02:34:31 [INFO]: Epoch 263 - training loss: 0.2333, validation loss: 0.1017
2024-05-25 02:34:34 [INFO]: Epoch 264 - training loss: 0.2334, validation loss: 0.1017
2024-05-25 02:34:37 [INFO]: Epoch 265 - training loss: 0.2332, validation loss: 0.1017
2024-05-25 02:34:39 [INFO]: Epoch 266 - training loss: 0.2334, validation loss: 0.1016
2024-05-25 02:34:42 [INFO]: Epoch 267 - training loss: 0.2328, validation loss: 0.1018
2024-05-25 02:34:45 [INFO]: Epoch 268 - training loss: 0.2326, validation loss: 0.1015
2024-05-25 02:34:48 [INFO]: Epoch 269 - training loss: 0.2321, validation loss: 0.1015
2024-05-25 02:34:51 [INFO]: Epoch 270 - training loss: 0.2322, validation loss: 0.1013
2024-05-25 02:34:54 [INFO]: Epoch 271 - training loss: 0.2327, validation loss: 0.1013
2024-05-25 02:34:57 [INFO]: Epoch 272 - training loss: 0.2321, validation loss: 0.1012
2024-05-25 02:35:00 [INFO]: Epoch 273 - training loss: 0.2324, validation loss: 0.1014
2024-05-25 02:35:03 [INFO]: Epoch 274 - training loss: 0.2322, validation loss: 0.1011
2024-05-25 02:35:05 [INFO]: Epoch 275 - training loss: 0.2318, validation loss: 0.1012
2024-05-25 02:35:08 [INFO]: Epoch 276 - training loss: 0.2318, validation loss: 0.1012
2024-05-25 02:35:11 [INFO]: Epoch 277 - training loss: 0.2323, validation loss: 0.1010
2024-05-25 02:35:14 [INFO]: Epoch 278 - training loss: 0.2319, validation loss: 0.1009
2024-05-25 02:35:17 [INFO]: Epoch 279 - training loss: 0.2315, validation loss: 0.1009
2024-05-25 02:35:20 [INFO]: Epoch 280 - training loss: 0.2314, validation loss: 0.1010
2024-05-25 02:35:23 [INFO]: Epoch 281 - training loss: 0.2310, validation loss: 0.1010
2024-05-25 02:35:26 [INFO]: Epoch 282 - training loss: 0.2312, validation loss: 0.1010
2024-05-25 02:35:28 [INFO]: Epoch 283 - training loss: 0.2307, validation loss: 0.1009
2024-05-25 02:35:31 [INFO]: Epoch 284 - training loss: 0.2310, validation loss: 0.1008
2024-05-25 02:35:34 [INFO]: Epoch 285 - training loss: 0.2309, validation loss: 0.1008
2024-05-25 02:35:37 [INFO]: Epoch 286 - training loss: 0.2312, validation loss: 0.1007
2024-05-25 02:35:40 [INFO]: Epoch 287 - training loss: 0.2309, validation loss: 0.1007
2024-05-25 02:35:43 [INFO]: Epoch 288 - training loss: 0.2301, validation loss: 0.1006
2024-05-25 02:35:46 [INFO]: Epoch 289 - training loss: 0.2297, validation loss: 0.1004
2024-05-25 02:35:48 [INFO]: Epoch 290 - training loss: 0.2304, validation loss: 0.1007
2024-05-25 02:35:51 [INFO]: Epoch 291 - training loss: 0.2303, validation loss: 0.1006
2024-05-25 02:35:54 [INFO]: Epoch 292 - training loss: 0.2297, validation loss: 0.1006
2024-05-25 02:35:57 [INFO]: Epoch 293 - training loss: 0.2308, validation loss: 0.1006
2024-05-25 02:36:00 [INFO]: Epoch 294 - training loss: 0.2300, validation loss: 0.1002
2024-05-25 02:36:03 [INFO]: Epoch 295 - training loss: 0.2296, validation loss: 0.1004
2024-05-25 02:36:05 [INFO]: Epoch 296 - training loss: 0.2299, validation loss: 0.1003
2024-05-25 02:36:08 [INFO]: Epoch 297 - training loss: 0.2297, validation loss: 0.1002
2024-05-25 02:36:11 [INFO]: Epoch 298 - training loss: 0.2292, validation loss: 0.1002
2024-05-25 02:36:14 [INFO]: Epoch 299 - training loss: 0.2292, validation loss: 0.1003
2024-05-25 02:36:17 [INFO]: Epoch 300 - training loss: 0.2291, validation loss: 0.1003
2024-05-25 02:36:17 [INFO]: Finished training. The best model is from epoch#294.
2024-05-25 02:36:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/BRITS_air_quality/20240525_T022202/BRITS.pypots
2024-05-25 02:36:17 [INFO]: BRITS on Air-Quality: MAE=0.1357, MSE=0.0947
2024-05-25 02:36:17 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/BRITS_air_quality/imputation.pkl
2024-05-25 02:36:17 [INFO]: Using the given device: cuda:0
2024-05-25 02:36:18 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617
2024-05-25 02:36:18 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/tensorboard
2024-05-25 02:36:18 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 02:36:22 [INFO]: Epoch 001 - training loss: 1.4970, validation loss: 0.8008
2024-05-25 02:36:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch1_loss0.8008124530315399.pypots
2024-05-25 02:36:26 [INFO]: Epoch 002 - training loss: 1.0716, validation loss: 0.7418
2024-05-25 02:36:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch2_loss0.7417604595422744.pypots
2024-05-25 02:36:30 [INFO]: Epoch 003 - training loss: 0.9907, validation loss: 0.7209
2024-05-25 02:36:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch3_loss0.720889401435852.pypots
2024-05-25 02:36:34 [INFO]: Epoch 004 - training loss: 0.9766, validation loss: 0.7095
2024-05-25 02:36:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch4_loss0.7095340043306351.pypots
2024-05-25 02:36:38 [INFO]: Epoch 005 - training loss: 0.9533, validation loss: 0.6996
2024-05-25 02:36:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch5_loss0.6995916247367859.pypots
2024-05-25 02:36:42 [INFO]: Epoch 006 - training loss: 0.9509, validation loss: 0.6925
2024-05-25 02:36:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch6_loss0.6924826085567475.pypots
2024-05-25 02:36:46 [INFO]: Epoch 007 - training loss: 0.9452, validation loss: 0.6882
2024-05-25 02:36:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch7_loss0.6882495731115341.pypots
2024-05-25 02:36:50 [INFO]: Epoch 008 - training loss: 0.9357, validation loss: 0.6845
2024-05-25 02:36:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch8_loss0.6845050185918808.pypots
2024-05-25 02:36:54 [INFO]: Epoch 009 - training loss: 0.9300, validation loss: 0.6815
2024-05-25 02:36:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch9_loss0.6814663350582123.pypots
2024-05-25 02:36:57 [INFO]: Epoch 010 - training loss: 0.9311, validation loss: 0.6789
2024-05-25 02:36:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch10_loss0.6789201945066452.pypots
2024-05-25 02:37:01 [INFO]: Epoch 011 - training loss: 0.9096, validation loss: 0.6782
2024-05-25 02:37:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch11_loss0.67821164727211.pypots
2024-05-25 02:37:05 [INFO]: Epoch 012 - training loss: 0.9038, validation loss: 0.6768
2024-05-25 02:37:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch12_loss0.67679862678051.pypots
2024-05-25 02:37:09 [INFO]: Epoch 013 - training loss: 0.9066, validation loss: 0.6745
2024-05-25 02:37:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch13_loss0.6745225489139557.pypots
2024-05-25 02:37:13 [INFO]: Epoch 014 - training loss: 0.9127, validation loss: 0.6746
2024-05-25 02:37:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch14_loss0.6746195554733276.pypots
2024-05-25 02:37:17 [INFO]: Epoch 015 - training loss: 0.8955, validation loss: 0.6742
2024-05-25 02:37:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch15_loss0.6741589814424515.pypots
2024-05-25 02:37:21 [INFO]: Epoch 016 - training loss: 0.8944, validation loss: 0.6746
2024-05-25 02:37:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch16_loss0.6745965778827667.pypots
2024-05-25 02:37:25 [INFO]: Epoch 017 - training loss: 0.8929, validation loss: 0.6749
2024-05-25 02:37:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch17_loss0.6749436557292938.pypots
2024-05-25 02:37:29 [INFO]: Epoch 018 - training loss: 0.9011, validation loss: 0.6726
2024-05-25 02:37:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch18_loss0.6725971817970275.pypots
2024-05-25 02:37:33 [INFO]: Epoch 019 - training loss: 0.8941, validation loss: 0.6725
2024-05-25 02:37:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch19_loss0.6725259244441986.pypots
2024-05-25 02:37:37 [INFO]: Epoch 020 - training loss: 0.9055, validation loss: 0.6745
2024-05-25 02:37:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch20_loss0.6745499283075332.pypots
2024-05-25 02:37:41 [INFO]: Epoch 021 - training loss: 0.8853, validation loss: 0.6720
2024-05-25 02:37:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch21_loss0.6719502121210098.pypots
2024-05-25 02:37:44 [INFO]: Epoch 022 - training loss: 0.8944, validation loss: 0.6740
2024-05-25 02:37:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch22_loss0.6740152269601822.pypots
2024-05-25 02:37:48 [INFO]: Epoch 023 - training loss: 0.8975, validation loss: 0.6742
2024-05-25 02:37:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch23_loss0.6741993129253387.pypots
2024-05-25 02:37:52 [INFO]: Epoch 024 - training loss: 0.8703, validation loss: 0.6759
2024-05-25 02:37:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch24_loss0.6759200304746628.pypots
2024-05-25 02:37:56 [INFO]: Epoch 025 - training loss: 0.8763, validation loss: 0.6749
2024-05-25 02:37:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch25_loss0.6748762547969818.pypots
2024-05-25 02:38:00 [INFO]: Epoch 026 - training loss: 0.8919, validation loss: 0.6768
2024-05-25 02:38:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch26_loss0.6767566591501236.pypots
2024-05-25 02:38:04 [INFO]: Epoch 027 - training loss: 0.8934, validation loss: 0.6741
2024-05-25 02:38:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch27_loss0.6741110682487488.pypots
2024-05-25 02:38:08 [INFO]: Epoch 028 - training loss: 0.8869, validation loss: 0.6755
2024-05-25 02:38:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch28_loss0.6754948556423187.pypots
2024-05-25 02:38:12 [INFO]: Epoch 029 - training loss: 0.8869, validation loss: 0.6730
2024-05-25 02:38:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch29_loss0.6729627698659897.pypots
2024-05-25 02:38:16 [INFO]: Epoch 030 - training loss: 0.9156, validation loss: 0.6770
2024-05-25 02:38:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch30_loss0.6769729226827621.pypots
2024-05-25 02:38:20 [INFO]: Epoch 031 - training loss: 0.8846, validation loss: 0.6751
2024-05-25 02:38:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN_epoch31_loss0.6751284241676331.pypots
2024-05-25 02:38:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:38:20 [INFO]: Finished training. The best model is from epoch#21.
2024-05-25 02:38:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T023617/MRNN.pypots
2024-05-25 02:38:21 [INFO]: MRNN on Air-Quality: MAE=0.5187, MSE=0.6040
2024-05-25 02:38:21 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/MRNN_air_quality/imputation.pkl
2024-05-25 02:38:21 [INFO]: Using the given device: cpu
2024-05-25 02:38:21 [INFO]: LOCF on Air-Quality: MAE=0.1979, MSE=0.2108
2024-05-25 02:38:21 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_air_quality".
2024-05-25 02:38:21 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/LOCF_air_quality/imputation.pkl
2024-05-25 02:38:21 [INFO]: Median on Air-Quality: MAE=0.6603, MSE=0.9901
2024-05-25 02:38:21 [INFO]: Successfully created the given path "saved_results/round_3/Median_air_quality".
2024-05-25 02:38:21 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/Median_air_quality/imputation.pkl
2024-05-25 02:38:21 [INFO]: Mean on Air-Quality: MAE=0.6916, MSE=0.9314
2024-05-25 02:38:21 [INFO]: Successfully created the given path "saved_results/round_3/Mean_air_quality".
2024-05-25 02:38:21 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/Mean_air_quality/imputation.pkl
2024-05-25 02:38:21 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-25 02:38:21 [INFO]: Using the given device: cuda:0
2024-05-25 02:38:21 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/SAITS_air_quality/20240525_T023821
2024-05-25 02:38:21 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/SAITS_air_quality/20240525_T023821/tensorboard
2024-05-25 02:38:21 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 02:38:22 [INFO]: Epoch 001 - training loss: 1.0577, validation loss: 0.5082
2024-05-25 02:38:22 [INFO]: Epoch 002 - training loss: 0.7519, validation loss: 0.3932
2024-05-25 02:38:23 [INFO]: Epoch 003 - training loss: 0.6445, validation loss: 0.3174
2024-05-25 02:38:24 [INFO]: Epoch 004 - training loss: 0.5712, validation loss: 0.2777
2024-05-25 02:38:24 [INFO]: Epoch 005 - training loss: 0.5166, validation loss: 0.2592
2024-05-25 02:38:25 [INFO]: Epoch 006 - training loss: 0.4809, validation loss: 0.2428
2024-05-25 02:38:26 [INFO]: Epoch 007 - training loss: 0.4559, validation loss: 0.2338
2024-05-25 02:38:26 [INFO]: Epoch 008 - training loss: 0.4394, validation loss: 0.2247
2024-05-25 02:38:27 [INFO]: Epoch 009 - training loss: 0.4255, validation loss: 0.2199
2024-05-25 02:38:28 [INFO]: Epoch 010 - training loss: 0.4137, validation loss: 0.2138
2024-05-25 02:38:28 [INFO]: Epoch 011 - training loss: 0.4040, validation loss: 0.2112
2024-05-25 02:38:29 [INFO]: Epoch 012 - training loss: 0.3968, validation loss: 0.2076
2024-05-25 02:38:30 [INFO]: Epoch 013 - training loss: 0.3900, validation loss: 0.2052
2024-05-25 02:38:30 [INFO]: Epoch 014 - training loss: 0.3818, validation loss: 0.2016
2024-05-25 02:38:31 [INFO]: Epoch 015 - training loss: 0.3748, validation loss: 0.1997
2024-05-25 02:38:32 [INFO]: Epoch 016 - training loss: 0.3699, validation loss: 0.1965
2024-05-25 02:38:32 [INFO]: Epoch 017 - training loss: 0.3650, validation loss: 0.1937
2024-05-25 02:38:33 [INFO]: Epoch 018 - training loss: 0.3607, validation loss: 0.1920
2024-05-25 02:38:34 [INFO]: Epoch 019 - training loss: 0.3554, validation loss: 0.1891
2024-05-25 02:38:34 [INFO]: Epoch 020 - training loss: 0.3525, validation loss: 0.1890
2024-05-25 02:38:35 [INFO]: Epoch 021 - training loss: 0.3506, validation loss: 0.1860
2024-05-25 02:38:36 [INFO]: Epoch 022 - training loss: 0.3457, validation loss: 0.1839
2024-05-25 02:38:37 [INFO]: Epoch 023 - training loss: 0.3429, validation loss: 0.1842
2024-05-25 02:38:37 [INFO]: Epoch 024 - training loss: 0.3403, validation loss: 0.1818
2024-05-25 02:38:38 [INFO]: Epoch 025 - training loss: 0.3363, validation loss: 0.1800
2024-05-25 02:38:39 [INFO]: Epoch 026 - training loss: 0.3337, validation loss: 0.1771
2024-05-25 02:38:39 [INFO]: Epoch 027 - training loss: 0.3325, validation loss: 0.1761
2024-05-25 02:38:40 [INFO]: Epoch 028 - training loss: 0.3295, validation loss: 0.1749
2024-05-25 02:38:41 [INFO]: Epoch 029 - training loss: 0.3267, validation loss: 0.1730
2024-05-25 02:38:41 [INFO]: Epoch 030 - training loss: 0.3243, validation loss: 0.1708
2024-05-25 02:38:42 [INFO]: Epoch 031 - training loss: 0.3238, validation loss: 0.1706
2024-05-25 02:38:43 [INFO]: Epoch 032 - training loss: 0.3214, validation loss: 0.1686
2024-05-25 02:38:43 [INFO]: Epoch 033 - training loss: 0.3188, validation loss: 0.1662
2024-05-25 02:38:44 [INFO]: Epoch 034 - training loss: 0.3190, validation loss: 0.1662
2024-05-25 02:38:45 [INFO]: Epoch 035 - training loss: 0.3165, validation loss: 0.1639
2024-05-25 02:38:45 [INFO]: Epoch 036 - training loss: 0.3132, validation loss: 0.1619
2024-05-25 02:38:46 [INFO]: Epoch 037 - training loss: 0.3106, validation loss: 0.1611
2024-05-25 02:38:47 [INFO]: Epoch 038 - training loss: 0.3112, validation loss: 0.1592
2024-05-25 02:38:47 [INFO]: Epoch 039 - training loss: 0.3074, validation loss: 0.1576
2024-05-25 02:38:48 [INFO]: Epoch 040 - training loss: 0.3064, validation loss: 0.1561
2024-05-25 02:38:49 [INFO]: Epoch 041 - training loss: 0.3042, validation loss: 0.1555
2024-05-25 02:38:49 [INFO]: Epoch 042 - training loss: 0.3039, validation loss: 0.1545
2024-05-25 02:38:50 [INFO]: Epoch 043 - training loss: 0.3016, validation loss: 0.1528
2024-05-25 02:38:51 [INFO]: Epoch 044 - training loss: 0.3005, validation loss: 0.1514
2024-05-25 02:38:51 [INFO]: Epoch 045 - training loss: 0.2986, validation loss: 0.1506
2024-05-25 02:38:52 [INFO]: Epoch 046 - training loss: 0.2966, validation loss: 0.1494
2024-05-25 02:38:53 [INFO]: Epoch 047 - training loss: 0.2961, validation loss: 0.1490
2024-05-25 02:38:53 [INFO]: Epoch 048 - training loss: 0.2933, validation loss: 0.1479
2024-05-25 02:38:54 [INFO]: Epoch 049 - training loss: 0.2921, validation loss: 0.1471
2024-05-25 02:38:55 [INFO]: Epoch 050 - training loss: 0.2923, validation loss: 0.1457
2024-05-25 02:38:55 [INFO]: Epoch 051 - training loss: 0.2902, validation loss: 0.1451
2024-05-25 02:38:56 [INFO]: Epoch 052 - training loss: 0.2900, validation loss: 0.1430
2024-05-25 02:38:57 [INFO]: Epoch 053 - training loss: 0.2884, validation loss: 0.1434
2024-05-25 02:38:57 [INFO]: Epoch 054 - training loss: 0.2873, validation loss: 0.1436
2024-05-25 02:38:58 [INFO]: Epoch 055 - training loss: 0.2860, validation loss: 0.1420
2024-05-25 02:38:59 [INFO]: Epoch 056 - training loss: 0.2849, validation loss: 0.1415
2024-05-25 02:39:00 [INFO]: Epoch 057 - training loss: 0.2830, validation loss: 0.1401
2024-05-25 02:39:00 [INFO]: Epoch 058 - training loss: 0.2808, validation loss: 0.1404
2024-05-25 02:39:01 [INFO]: Epoch 059 - training loss: 0.2801, validation loss: 0.1395
2024-05-25 02:39:02 [INFO]: Epoch 060 - training loss: 0.2789, validation loss: 0.1384
2024-05-25 02:39:02 [INFO]: Epoch 061 - training loss: 0.2787, validation loss: 0.1375
2024-05-25 02:39:03 [INFO]: Epoch 062 - training loss: 0.2778, validation loss: 0.1370
2024-05-25 02:39:04 [INFO]: Epoch 063 - training loss: 0.2762, validation loss: 0.1361
2024-05-25 02:39:04 [INFO]: Epoch 064 - training loss: 0.2746, validation loss: 0.1359
2024-05-25 02:39:05 [INFO]: Epoch 065 - training loss: 0.2737, validation loss: 0.1349
2024-05-25 02:39:06 [INFO]: Epoch 066 - training loss: 0.2737, validation loss: 0.1352
2024-05-25 02:39:06 [INFO]: Epoch 067 - training loss: 0.2739, validation loss: 0.1350
2024-05-25 02:39:07 [INFO]: Epoch 068 - training loss: 0.2715, validation loss: 0.1333
2024-05-25 02:39:08 [INFO]: Epoch 069 - training loss: 0.2714, validation loss: 0.1329
2024-05-25 02:39:08 [INFO]: Epoch 070 - training loss: 0.2691, validation loss: 0.1331
2024-05-25 02:39:09 [INFO]: Epoch 071 - training loss: 0.2676, validation loss: 0.1315
2024-05-25 02:39:10 [INFO]: Epoch 072 - training loss: 0.2661, validation loss: 0.1314
2024-05-25 02:39:10 [INFO]: Epoch 073 - training loss: 0.2639, validation loss: 0.1312
2024-05-25 02:39:11 [INFO]: Epoch 074 - training loss: 0.2653, validation loss: 0.1306
2024-05-25 02:39:12 [INFO]: Epoch 075 - training loss: 0.2641, validation loss: 0.1304
2024-05-25 02:39:12 [INFO]: Epoch 076 - training loss: 0.2634, validation loss: 0.1299
2024-05-25 02:39:13 [INFO]: Epoch 077 - training loss: 0.2620, validation loss: 0.1301
2024-05-25 02:39:14 [INFO]: Epoch 078 - training loss: 0.2618, validation loss: 0.1293
2024-05-25 02:39:15 [INFO]: Epoch 079 - training loss: 0.2604, validation loss: 0.1295
2024-05-25 02:39:15 [INFO]: Epoch 080 - training loss: 0.2604, validation loss: 0.1287
2024-05-25 02:39:16 [INFO]: Epoch 081 - training loss: 0.2587, validation loss: 0.1281
2024-05-25 02:39:17 [INFO]: Epoch 082 - training loss: 0.2592, validation loss: 0.1275
2024-05-25 02:39:17 [INFO]: Epoch 083 - training loss: 0.2564, validation loss: 0.1268
2024-05-25 02:39:18 [INFO]: Epoch 084 - training loss: 0.2569, validation loss: 0.1266
2024-05-25 02:39:19 [INFO]: Epoch 085 - training loss: 0.2557, validation loss: 0.1275
2024-05-25 02:39:19 [INFO]: Epoch 086 - training loss: 0.2550, validation loss: 0.1268
2024-05-25 02:39:20 [INFO]: Epoch 087 - training loss: 0.2537, validation loss: 0.1262
2024-05-25 02:39:21 [INFO]: Epoch 088 - training loss: 0.2543, validation loss: 0.1262
2024-05-25 02:39:21 [INFO]: Epoch 089 - training loss: 0.2531, validation loss: 0.1255
2024-05-25 02:39:22 [INFO]: Epoch 090 - training loss: 0.2522, validation loss: 0.1249
2024-05-25 02:39:23 [INFO]: Epoch 091 - training loss: 0.2519, validation loss: 0.1256
2024-05-25 02:39:23 [INFO]: Epoch 092 - training loss: 0.2510, validation loss: 0.1242
2024-05-25 02:39:24 [INFO]: Epoch 093 - training loss: 0.2503, validation loss: 0.1249
2024-05-25 02:39:25 [INFO]: Epoch 094 - training loss: 0.2513, validation loss: 0.1245
2024-05-25 02:39:25 [INFO]: Epoch 095 - training loss: 0.2496, validation loss: 0.1243
2024-05-25 02:39:26 [INFO]: Epoch 096 - training loss: 0.2489, validation loss: 0.1239
2024-05-25 02:39:27 [INFO]: Epoch 097 - training loss: 0.2482, validation loss: 0.1236
2024-05-25 02:39:28 [INFO]: Epoch 098 - training loss: 0.2477, validation loss: 0.1225
2024-05-25 02:39:28 [INFO]: Epoch 099 - training loss: 0.2476, validation loss: 0.1230
2024-05-25 02:39:29 [INFO]: Epoch 100 - training loss: 0.2466, validation loss: 0.1225
2024-05-25 02:39:30 [INFO]: Epoch 101 - training loss: 0.2450, validation loss: 0.1222
2024-05-25 02:39:30 [INFO]: Epoch 102 - training loss: 0.2445, validation loss: 0.1223
2024-05-25 02:39:31 [INFO]: Epoch 103 - training loss: 0.2440, validation loss: 0.1222
2024-05-25 02:39:32 [INFO]: Epoch 104 - training loss: 0.2453, validation loss: 0.1219
2024-05-25 02:39:32 [INFO]: Epoch 105 - training loss: 0.2436, validation loss: 0.1209
2024-05-25 02:39:33 [INFO]: Epoch 106 - training loss: 0.2441, validation loss: 0.1213
2024-05-25 02:39:34 [INFO]: Epoch 107 - training loss: 0.2435, validation loss: 0.1221
2024-05-25 02:39:34 [INFO]: Epoch 108 - training loss: 0.2432, validation loss: 0.1204
2024-05-25 02:39:35 [INFO]: Epoch 109 - training loss: 0.2434, validation loss: 0.1202
2024-05-25 02:39:36 [INFO]: Epoch 110 - training loss: 0.2421, validation loss: 0.1206
2024-05-25 02:39:36 [INFO]: Epoch 111 - training loss: 0.2409, validation loss: 0.1201
2024-05-25 02:39:37 [INFO]: Epoch 112 - training loss: 0.2412, validation loss: 0.1204
2024-05-25 02:39:38 [INFO]: Epoch 113 - training loss: 0.2408, validation loss: 0.1192
2024-05-25 02:39:38 [INFO]: Epoch 114 - training loss: 0.2399, validation loss: 0.1185
2024-05-25 02:39:39 [INFO]: Epoch 115 - training loss: 0.2381, validation loss: 0.1191
2024-05-25 02:39:40 [INFO]: Epoch 116 - training loss: 0.2388, validation loss: 0.1186
2024-05-25 02:39:40 [INFO]: Epoch 117 - training loss: 0.2371, validation loss: 0.1186
2024-05-25 02:39:41 [INFO]: Epoch 118 - training loss: 0.2366, validation loss: 0.1186
2024-05-25 02:39:42 [INFO]: Epoch 119 - training loss: 0.2355, validation loss: 0.1187
2024-05-25 02:39:42 [INFO]: Epoch 120 - training loss: 0.2362, validation loss: 0.1182
2024-05-25 02:39:43 [INFO]: Epoch 121 - training loss: 0.2361, validation loss: 0.1181
2024-05-25 02:39:44 [INFO]: Epoch 122 - training loss: 0.2360, validation loss: 0.1183
2024-05-25 02:39:45 [INFO]: Epoch 123 - training loss: 0.2349, validation loss: 0.1185
2024-05-25 02:39:45 [INFO]: Epoch 124 - training loss: 0.2348, validation loss: 0.1170
2024-05-25 02:39:46 [INFO]: Epoch 125 - training loss: 0.2341, validation loss: 0.1184
2024-05-25 02:39:47 [INFO]: Epoch 126 - training loss: 0.2354, validation loss: 0.1169
2024-05-25 02:39:47 [INFO]: Epoch 127 - training loss: 0.2337, validation loss: 0.1167
2024-05-25 02:39:48 [INFO]: Epoch 128 - training loss: 0.2329, validation loss: 0.1169
2024-05-25 02:39:49 [INFO]: Epoch 129 - training loss: 0.2333, validation loss: 0.1169
2024-05-25 02:39:49 [INFO]: Epoch 130 - training loss: 0.2341, validation loss: 0.1162
2024-05-25 02:39:50 [INFO]: Epoch 131 - training loss: 0.2325, validation loss: 0.1160
2024-05-25 02:39:51 [INFO]: Epoch 132 - training loss: 0.2311, validation loss: 0.1152
2024-05-25 02:39:51 [INFO]: Epoch 133 - training loss: 0.2306, validation loss: 0.1156
2024-05-25 02:39:52 [INFO]: Epoch 134 - training loss: 0.2297, validation loss: 0.1157
2024-05-25 02:39:53 [INFO]: Epoch 135 - training loss: 0.2297, validation loss: 0.1159
2024-05-25 02:39:53 [INFO]: Epoch 136 - training loss: 0.2297, validation loss: 0.1153
2024-05-25 02:39:54 [INFO]: Epoch 137 - training loss: 0.2281, validation loss: 0.1151
2024-05-25 02:39:55 [INFO]: Epoch 138 - training loss: 0.2300, validation loss: 0.1141
2024-05-25 02:39:55 [INFO]: Epoch 139 - training loss: 0.2288, validation loss: 0.1142
2024-05-25 02:39:56 [INFO]: Epoch 140 - training loss: 0.2273, validation loss: 0.1141
2024-05-25 02:39:57 [INFO]: Epoch 141 - training loss: 0.2274, validation loss: 0.1136
2024-05-25 02:39:58 [INFO]: Epoch 142 - training loss: 0.2268, validation loss: 0.1131
2024-05-25 02:39:58 [INFO]: Epoch 143 - training loss: 0.2261, validation loss: 0.1133
2024-05-25 02:39:59 [INFO]: Epoch 144 - training loss: 0.2279, validation loss: 0.1128
2024-05-25 02:40:00 [INFO]: Epoch 145 - training loss: 0.2274, validation loss: 0.1130
2024-05-25 02:40:00 [INFO]: Epoch 146 - training loss: 0.2263, validation loss: 0.1131
2024-05-25 02:40:01 [INFO]: Epoch 147 - training loss: 0.2261, validation loss: 0.1129
2024-05-25 02:40:02 [INFO]: Epoch 148 - training loss: 0.2253, validation loss: 0.1121
2024-05-25 02:40:02 [INFO]: Epoch 149 - training loss: 0.2252, validation loss: 0.1128
2024-05-25 02:40:03 [INFO]: Epoch 150 - training loss: 0.2249, validation loss: 0.1119
2024-05-25 02:40:04 [INFO]: Epoch 151 - training loss: 0.2233, validation loss: 0.1122
2024-05-25 02:40:04 [INFO]: Epoch 152 - training loss: 0.2223, validation loss: 0.1122
2024-05-25 02:40:05 [INFO]: Epoch 153 - training loss: 0.2226, validation loss: 0.1116
2024-05-25 02:40:06 [INFO]: Epoch 154 - training loss: 0.2231, validation loss: 0.1120
2024-05-25 02:40:06 [INFO]: Epoch 155 - training loss: 0.2234, validation loss: 0.1114
2024-05-25 02:40:07 [INFO]: Epoch 156 - training loss: 0.2232, validation loss: 0.1109
2024-05-25 02:40:08 [INFO]: Epoch 157 - training loss: 0.2230, validation loss: 0.1110
2024-05-25 02:40:08 [INFO]: Epoch 158 - training loss: 0.2223, validation loss: 0.1112
2024-05-25 02:40:09 [INFO]: Epoch 159 - training loss: 0.2220, validation loss: 0.1113
2024-05-25 02:40:10 [INFO]: Epoch 160 - training loss: 0.2216, validation loss: 0.1107
2024-05-25 02:40:10 [INFO]: Epoch 161 - training loss: 0.2205, validation loss: 0.1109
2024-05-25 02:40:11 [INFO]: Epoch 162 - training loss: 0.2194, validation loss: 0.1107
2024-05-25 02:40:12 [INFO]: Epoch 163 - training loss: 0.2200, validation loss: 0.1106
2024-05-25 02:40:13 [INFO]: Epoch 164 - training loss: 0.2196, validation loss: 0.1109
2024-05-25 02:40:13 [INFO]: Epoch 165 - training loss: 0.2193, validation loss: 0.1104
2024-05-25 02:40:14 [INFO]: Epoch 166 - training loss: 0.2188, validation loss: 0.1100
2024-05-25 02:40:15 [INFO]: Epoch 167 - training loss: 0.2192, validation loss: 0.1104
2024-05-25 02:40:15 [INFO]: Epoch 168 - training loss: 0.2193, validation loss: 0.1090
2024-05-25 02:40:16 [INFO]: Epoch 169 - training loss: 0.2179, validation loss: 0.1090
2024-05-25 02:40:17 [INFO]: Epoch 170 - training loss: 0.2175, validation loss: 0.1084
2024-05-25 02:40:17 [INFO]: Epoch 171 - training loss: 0.2189, validation loss: 0.1084
2024-05-25 02:40:18 [INFO]: Epoch 172 - training loss: 0.2196, validation loss: 0.1088
2024-05-25 02:40:19 [INFO]: Epoch 173 - training loss: 0.2185, validation loss: 0.1086
2024-05-25 02:40:19 [INFO]: Epoch 174 - training loss: 0.2177, validation loss: 0.1078
2024-05-25 02:40:20 [INFO]: Epoch 175 - training loss: 0.2159, validation loss: 0.1089
2024-05-25 02:40:21 [INFO]: Epoch 176 - training loss: 0.2154, validation loss: 0.1090
2024-05-25 02:40:21 [INFO]: Epoch 177 - training loss: 0.2148, validation loss: 0.1079
2024-05-25 02:40:22 [INFO]: Epoch 178 - training loss: 0.2154, validation loss: 0.1083
2024-05-25 02:40:23 [INFO]: Epoch 179 - training loss: 0.2153, validation loss: 0.1079
2024-05-25 02:40:23 [INFO]: Epoch 180 - training loss: 0.2138, validation loss: 0.1083
2024-05-25 02:40:24 [INFO]: Epoch 181 - training loss: 0.2146, validation loss: 0.1075
2024-05-25 02:40:25 [INFO]: Epoch 182 - training loss: 0.2162, validation loss: 0.1078
2024-05-25 02:40:25 [INFO]: Epoch 183 - training loss: 0.2150, validation loss: 0.1074
2024-05-25 02:40:26 [INFO]: Epoch 184 - training loss: 0.2136, validation loss: 0.1074
2024-05-25 02:40:27 [INFO]: Epoch 185 - training loss: 0.2119, validation loss: 0.1072
2024-05-25 02:40:28 [INFO]: Epoch 186 - training loss: 0.2125, validation loss: 0.1076
2024-05-25 02:40:28 [INFO]: Epoch 187 - training loss: 0.2136, validation loss: 0.1072
2024-05-25 02:40:29 [INFO]: Epoch 188 - training loss: 0.2139, validation loss: 0.1069
2024-05-25 02:40:30 [INFO]: Epoch 189 - training loss: 0.2124, validation loss: 0.1065
2024-05-25 02:40:30 [INFO]: Epoch 190 - training loss: 0.2135, validation loss: 0.1070
2024-05-25 02:40:31 [INFO]: Epoch 191 - training loss: 0.2114, validation loss: 0.1060
2024-05-25 02:40:32 [INFO]: Epoch 192 - training loss: 0.2109, validation loss: 0.1055
2024-05-25 02:40:32 [INFO]: Epoch 193 - training loss: 0.2103, validation loss: 0.1057
2024-05-25 02:40:33 [INFO]: Epoch 194 - training loss: 0.2104, validation loss: 0.1062
2024-05-25 02:40:34 [INFO]: Epoch 195 - training loss: 0.2111, validation loss: 0.1057
2024-05-25 02:40:34 [INFO]: Epoch 196 - training loss: 0.2109, validation loss: 0.1062
2024-05-25 02:40:35 [INFO]: Epoch 197 - training loss: 0.2110, validation loss: 0.1055
2024-05-25 02:40:36 [INFO]: Epoch 198 - training loss: 0.2101, validation loss: 0.1067
2024-05-25 02:40:36 [INFO]: Epoch 199 - training loss: 0.2112, validation loss: 0.1055
2024-05-25 02:40:37 [INFO]: Epoch 200 - training loss: 0.2092, validation loss: 0.1050
2024-05-25 02:40:38 [INFO]: Epoch 201 - training loss: 0.2102, validation loss: 0.1053
2024-05-25 02:40:38 [INFO]: Epoch 202 - training loss: 0.2095, validation loss: 0.1054
2024-05-25 02:40:39 [INFO]: Epoch 203 - training loss: 0.2087, validation loss: 0.1049
2024-05-25 02:40:40 [INFO]: Epoch 204 - training loss: 0.2087, validation loss: 0.1056
2024-05-25 02:40:41 [INFO]: Epoch 205 - training loss: 0.2082, validation loss: 0.1052
2024-05-25 02:40:41 [INFO]: Epoch 206 - training loss: 0.2075, validation loss: 0.1048
2024-05-25 02:40:42 [INFO]: Epoch 207 - training loss: 0.2080, validation loss: 0.1046
2024-05-25 02:40:43 [INFO]: Epoch 208 - training loss: 0.2076, validation loss: 0.1052
2024-05-25 02:40:43 [INFO]: Epoch 209 - training loss: 0.2080, validation loss: 0.1038
2024-05-25 02:40:44 [INFO]: Epoch 210 - training loss: 0.2058, validation loss: 0.1040
2024-05-25 02:40:45 [INFO]: Epoch 211 - training loss: 0.2068, validation loss: 0.1040
2024-05-25 02:40:45 [INFO]: Epoch 212 - training loss: 0.2070, validation loss: 0.1039
2024-05-25 02:40:46 [INFO]: Epoch 213 - training loss: 0.2068, validation loss: 0.1036
2024-05-25 02:40:47 [INFO]: Epoch 214 - training loss: 0.2068, validation loss: 0.1033
2024-05-25 02:40:47 [INFO]: Epoch 215 - training loss: 0.2060, validation loss: 0.1039
2024-05-25 02:40:48 [INFO]: Epoch 216 - training loss: 0.2061, validation loss: 0.1032
2024-05-25 02:40:49 [INFO]: Epoch 217 - training loss: 0.2082, validation loss: 0.1039
2024-05-25 02:40:49 [INFO]: Epoch 218 - training loss: 0.2070, validation loss: 0.1035
2024-05-25 02:40:50 [INFO]: Epoch 219 - training loss: 0.2063, validation loss: 0.1026
2024-05-25 02:40:51 [INFO]: Epoch 220 - training loss: 0.2057, validation loss: 0.1031
2024-05-25 02:40:51 [INFO]: Epoch 221 - training loss: 0.2040, validation loss: 0.1030
2024-05-25 02:40:52 [INFO]: Epoch 222 - training loss: 0.2035, validation loss: 0.1015
2024-05-25 02:40:53 [INFO]: Epoch 223 - training loss: 0.2042, validation loss: 0.1026
2024-05-25 02:40:53 [INFO]: Epoch 224 - training loss: 0.2030, validation loss: 0.1035
2024-05-25 02:40:54 [INFO]: Epoch 225 - training loss: 0.2021, validation loss: 0.1021
2024-05-25 02:40:55 [INFO]: Epoch 226 - training loss: 0.2044, validation loss: 0.1018
2024-05-25 02:40:56 [INFO]: Epoch 227 - training loss: 0.2049, validation loss: 0.1026
2024-05-25 02:40:56 [INFO]: Epoch 228 - training loss: 0.2053, validation loss: 0.1029
2024-05-25 02:40:57 [INFO]: Epoch 229 - training loss: 0.2030, validation loss: 0.1019
2024-05-25 02:40:58 [INFO]: Epoch 230 - training loss: 0.2033, validation loss: 0.1020
2024-05-25 02:40:58 [INFO]: Epoch 231 - training loss: 0.2021, validation loss: 0.1017
2024-05-25 02:40:59 [INFO]: Epoch 232 - training loss: 0.2057, validation loss: 0.1027
2024-05-25 02:40:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:40:59 [INFO]: Finished training. The best model is from epoch#222.
2024-05-25 02:40:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/SAITS_air_quality/20240525_T023821/SAITS.pypots
2024-05-25 02:40:59 [INFO]: SAITS on Air-Quality: MAE=0.1432, MSE=0.0997
2024-05-25 02:40:59 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/SAITS_air_quality/imputation.pkl
2024-05-25 02:40:59 [INFO]: Using the given device: cuda:0
2024-05-25 02:40:59 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/Transformer_air_quality/20240525_T024059
2024-05-25 02:40:59 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/Transformer_air_quality/20240525_T024059/tensorboard
2024-05-25 02:40:59 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 02:41:00 [INFO]: Epoch 001 - training loss: 0.9171, validation loss: 0.4638
2024-05-25 02:41:00 [INFO]: Epoch 002 - training loss: 0.5763, validation loss: 0.3501
2024-05-25 02:41:00 [INFO]: Epoch 003 - training loss: 0.4831, validation loss: 0.2906
2024-05-25 02:41:01 [INFO]: Epoch 004 - training loss: 0.4418, validation loss: 0.2615
2024-05-25 02:41:01 [INFO]: Epoch 005 - training loss: 0.4109, validation loss: 0.2495
2024-05-25 02:41:01 [INFO]: Epoch 006 - training loss: 0.3892, validation loss: 0.2369
2024-05-25 02:41:02 [INFO]: Epoch 007 - training loss: 0.3764, validation loss: 0.2332
2024-05-25 02:41:02 [INFO]: Epoch 008 - training loss: 0.3664, validation loss: 0.2256
2024-05-25 02:41:02 [INFO]: Epoch 009 - training loss: 0.3587, validation loss: 0.2209
2024-05-25 02:41:03 [INFO]: Epoch 010 - training loss: 0.3484, validation loss: 0.2148
2024-05-25 02:41:03 [INFO]: Epoch 011 - training loss: 0.3439, validation loss: 0.2092
2024-05-25 02:41:03 [INFO]: Epoch 012 - training loss: 0.3364, validation loss: 0.2060
2024-05-25 02:41:03 [INFO]: Epoch 013 - training loss: 0.3301, validation loss: 0.2021
2024-05-25 02:41:04 [INFO]: Epoch 014 - training loss: 0.3259, validation loss: 0.1977
2024-05-25 02:41:04 [INFO]: Epoch 015 - training loss: 0.3250, validation loss: 0.1933
2024-05-25 02:41:04 [INFO]: Epoch 016 - training loss: 0.3209, validation loss: 0.1908
2024-05-25 02:41:05 [INFO]: Epoch 017 - training loss: 0.3157, validation loss: 0.1870
2024-05-25 02:41:05 [INFO]: Epoch 018 - training loss: 0.3116, validation loss: 0.1843
2024-05-25 02:41:05 [INFO]: Epoch 019 - training loss: 0.3110, validation loss: 0.1871
2024-05-25 02:41:06 [INFO]: Epoch 020 - training loss: 0.3189, validation loss: 0.1807
2024-05-25 02:41:06 [INFO]: Epoch 021 - training loss: 0.3064, validation loss: 0.1778
2024-05-25 02:41:06 [INFO]: Epoch 022 - training loss: 0.3009, validation loss: 0.1763
2024-05-25 02:41:07 [INFO]: Epoch 023 - training loss: 0.2996, validation loss: 0.1756
2024-05-25 02:41:07 [INFO]: Epoch 024 - training loss: 0.2965, validation loss: 0.1725
2024-05-25 02:41:07 [INFO]: Epoch 025 - training loss: 0.2966, validation loss: 0.1719
2024-05-25 02:41:08 [INFO]: Epoch 026 - training loss: 0.2938, validation loss: 0.1726
2024-05-25 02:41:08 [INFO]: Epoch 027 - training loss: 0.2928, validation loss: 0.1707
2024-05-25 02:41:08 [INFO]: Epoch 028 - training loss: 0.2893, validation loss: 0.1683
2024-05-25 02:41:09 [INFO]: Epoch 029 - training loss: 0.2883, validation loss: 0.1688
2024-05-25 02:41:09 [INFO]: Epoch 030 - training loss: 0.2892, validation loss: 0.1676
2024-05-25 02:41:09 [INFO]: Epoch 031 - training loss: 0.2875, validation loss: 0.1671
2024-05-25 02:41:10 [INFO]: Epoch 032 - training loss: 0.2856, validation loss: 0.1647
2024-05-25 02:41:10 [INFO]: Epoch 033 - training loss: 0.2847, validation loss: 0.1648
2024-05-25 02:41:10 [INFO]: Epoch 034 - training loss: 0.2817, validation loss: 0.1652
2024-05-25 02:41:11 [INFO]: Epoch 035 - training loss: 0.2786, validation loss: 0.1641
2024-05-25 02:41:11 [INFO]: Epoch 036 - training loss: 0.2787, validation loss: 0.1639
2024-05-25 02:41:11 [INFO]: Epoch 037 - training loss: 0.2772, validation loss: 0.1632
2024-05-25 02:41:12 [INFO]: Epoch 038 - training loss: 0.2765, validation loss: 0.1637
2024-05-25 02:41:12 [INFO]: Epoch 039 - training loss: 0.2759, validation loss: 0.1626
2024-05-25 02:41:12 [INFO]: Epoch 040 - training loss: 0.2740, validation loss: 0.1621
2024-05-25 02:41:13 [INFO]: Epoch 041 - training loss: 0.2745, validation loss: 0.1623
2024-05-25 02:41:13 [INFO]: Epoch 042 - training loss: 0.2737, validation loss: 0.1601
2024-05-25 02:41:13 [INFO]: Epoch 043 - training loss: 0.2720, validation loss: 0.1603
2024-05-25 02:41:14 [INFO]: Epoch 044 - training loss: 0.2733, validation loss: 0.1594
2024-05-25 02:41:14 [INFO]: Epoch 045 - training loss: 0.2741, validation loss: 0.1604
2024-05-25 02:41:14 [INFO]: Epoch 046 - training loss: 0.2678, validation loss: 0.1588
2024-05-25 02:41:15 [INFO]: Epoch 047 - training loss: 0.2686, validation loss: 0.1612
2024-05-25 02:41:15 [INFO]: Epoch 048 - training loss: 0.2714, validation loss: 0.1587
2024-05-25 02:41:15 [INFO]: Epoch 049 - training loss: 0.2648, validation loss: 0.1570
2024-05-25 02:41:15 [INFO]: Epoch 050 - training loss: 0.2634, validation loss: 0.1566
2024-05-25 02:41:16 [INFO]: Epoch 051 - training loss: 0.2650, validation loss: 0.1558
2024-05-25 02:41:16 [INFO]: Epoch 052 - training loss: 0.2634, validation loss: 0.1556
2024-05-25 02:41:16 [INFO]: Epoch 053 - training loss: 0.2625, validation loss: 0.1573
2024-05-25 02:41:17 [INFO]: Epoch 054 - training loss: 0.2614, validation loss: 0.1550
2024-05-25 02:41:17 [INFO]: Epoch 055 - training loss: 0.2596, validation loss: 0.1560
2024-05-25 02:41:17 [INFO]: Epoch 056 - training loss: 0.2588, validation loss: 0.1559
2024-05-25 02:41:18 [INFO]: Epoch 057 - training loss: 0.2586, validation loss: 0.1544
2024-05-25 02:41:18 [INFO]: Epoch 058 - training loss: 0.2569, validation loss: 0.1555
2024-05-25 02:41:18 [INFO]: Epoch 059 - training loss: 0.2574, validation loss: 0.1545
2024-05-25 02:41:19 [INFO]: Epoch 060 - training loss: 0.2553, validation loss: 0.1545
2024-05-25 02:41:19 [INFO]: Epoch 061 - training loss: 0.2550, validation loss: 0.1557
2024-05-25 02:41:19 [INFO]: Epoch 062 - training loss: 0.2533, validation loss: 0.1538
2024-05-25 02:41:20 [INFO]: Epoch 063 - training loss: 0.2542, validation loss: 0.1546
2024-05-25 02:41:20 [INFO]: Epoch 064 - training loss: 0.2524, validation loss: 0.1533
2024-05-25 02:41:20 [INFO]: Epoch 065 - training loss: 0.2526, validation loss: 0.1545
2024-05-25 02:41:21 [INFO]: Epoch 066 - training loss: 0.2519, validation loss: 0.1525
2024-05-25 02:41:21 [INFO]: Epoch 067 - training loss: 0.2498, validation loss: 0.1538
2024-05-25 02:41:21 [INFO]: Epoch 068 - training loss: 0.2509, validation loss: 0.1526
2024-05-25 02:41:22 [INFO]: Epoch 069 - training loss: 0.2492, validation loss: 0.1536
2024-05-25 02:41:22 [INFO]: Epoch 070 - training loss: 0.2493, validation loss: 0.1518
2024-05-25 02:41:22 [INFO]: Epoch 071 - training loss: 0.2491, validation loss: 0.1526
2024-05-25 02:41:23 [INFO]: Epoch 072 - training loss: 0.2485, validation loss: 0.1531
2024-05-25 02:41:23 [INFO]: Epoch 073 - training loss: 0.2459, validation loss: 0.1544
2024-05-25 02:41:23 [INFO]: Epoch 074 - training loss: 0.2489, validation loss: 0.1504
2024-05-25 02:41:24 [INFO]: Epoch 075 - training loss: 0.2464, validation loss: 0.1512
2024-05-25 02:41:24 [INFO]: Epoch 076 - training loss: 0.2469, validation loss: 0.1518
2024-05-25 02:41:24 [INFO]: Epoch 077 - training loss: 0.2439, validation loss: 0.1502
2024-05-25 02:41:25 [INFO]: Epoch 078 - training loss: 0.2429, validation loss: 0.1510
2024-05-25 02:41:25 [INFO]: Epoch 079 - training loss: 0.2409, validation loss: 0.1505
2024-05-25 02:41:25 [INFO]: Epoch 080 - training loss: 0.2419, validation loss: 0.1522
2024-05-25 02:41:26 [INFO]: Epoch 081 - training loss: 0.2404, validation loss: 0.1492
2024-05-25 02:41:26 [INFO]: Epoch 082 - training loss: 0.2397, validation loss: 0.1478
2024-05-25 02:41:26 [INFO]: Epoch 083 - training loss: 0.2391, validation loss: 0.1494
2024-05-25 02:41:27 [INFO]: Epoch 084 - training loss: 0.2392, validation loss: 0.1480
2024-05-25 02:41:27 [INFO]: Epoch 085 - training loss: 0.2370, validation loss: 0.1500
2024-05-25 02:41:27 [INFO]: Epoch 086 - training loss: 0.2394, validation loss: 0.1499
2024-05-25 02:41:28 [INFO]: Epoch 087 - training loss: 0.2391, validation loss: 0.1470
2024-05-25 02:41:28 [INFO]: Epoch 088 - training loss: 0.2367, validation loss: 0.1490
2024-05-25 02:41:28 [INFO]: Epoch 089 - training loss: 0.2341, validation loss: 0.1488
2024-05-25 02:41:29 [INFO]: Epoch 090 - training loss: 0.2337, validation loss: 0.1496
2024-05-25 02:41:29 [INFO]: Epoch 091 - training loss: 0.2339, validation loss: 0.1465
2024-05-25 02:41:29 [INFO]: Epoch 092 - training loss: 0.2322, validation loss: 0.1482
2024-05-25 02:41:30 [INFO]: Epoch 093 - training loss: 0.2331, validation loss: 0.1478
2024-05-25 02:41:30 [INFO]: Epoch 094 - training loss: 0.2337, validation loss: 0.1481
2024-05-25 02:41:30 [INFO]: Epoch 095 - training loss: 0.2323, validation loss: 0.1470
2024-05-25 02:41:31 [INFO]: Epoch 096 - training loss: 0.2333, validation loss: 0.1469
2024-05-25 02:41:31 [INFO]: Epoch 097 - training loss: 0.2323, validation loss: 0.1449
2024-05-25 02:41:31 [INFO]: Epoch 098 - training loss: 0.2319, validation loss: 0.1458
2024-05-25 02:41:32 [INFO]: Epoch 099 - training loss: 0.2320, validation loss: 0.1455
2024-05-25 02:41:32 [INFO]: Epoch 100 - training loss: 0.2297, validation loss: 0.1484
2024-05-25 02:41:32 [INFO]: Epoch 101 - training loss: 0.2308, validation loss: 0.1459
2024-05-25 02:41:33 [INFO]: Epoch 102 - training loss: 0.2297, validation loss: 0.1448
2024-05-25 02:41:33 [INFO]: Epoch 103 - training loss: 0.2300, validation loss: 0.1444
2024-05-25 02:41:33 [INFO]: Epoch 104 - training loss: 0.2291, validation loss: 0.1441
2024-05-25 02:41:33 [INFO]: Epoch 105 - training loss: 0.2264, validation loss: 0.1437
2024-05-25 02:41:34 [INFO]: Epoch 106 - training loss: 0.2257, validation loss: 0.1443
2024-05-25 02:41:34 [INFO]: Epoch 107 - training loss: 0.2269, validation loss: 0.1440
2024-05-25 02:41:34 [INFO]: Epoch 108 - training loss: 0.2265, validation loss: 0.1436
2024-05-25 02:41:35 [INFO]: Epoch 109 - training loss: 0.2267, validation loss: 0.1418
2024-05-25 02:41:35 [INFO]: Epoch 110 - training loss: 0.2234, validation loss: 0.1430
2024-05-25 02:41:35 [INFO]: Epoch 111 - training loss: 0.2256, validation loss: 0.1439
2024-05-25 02:41:36 [INFO]: Epoch 112 - training loss: 0.2246, validation loss: 0.1438
2024-05-25 02:41:36 [INFO]: Epoch 113 - training loss: 0.2236, validation loss: 0.1423
2024-05-25 02:41:36 [INFO]: Epoch 114 - training loss: 0.2240, validation loss: 0.1424
2024-05-25 02:41:37 [INFO]: Epoch 115 - training loss: 0.2235, validation loss: 0.1420
2024-05-25 02:41:37 [INFO]: Epoch 116 - training loss: 0.2242, validation loss: 0.1431
2024-05-25 02:41:37 [INFO]: Epoch 117 - training loss: 0.2240, validation loss: 0.1423
2024-05-25 02:41:38 [INFO]: Epoch 118 - training loss: 0.2302, validation loss: 0.1424
2024-05-25 02:41:38 [INFO]: Epoch 119 - training loss: 0.2229, validation loss: 0.1410
2024-05-25 02:41:38 [INFO]: Epoch 120 - training loss: 0.2204, validation loss: 0.1408
2024-05-25 02:41:39 [INFO]: Epoch 121 - training loss: 0.2197, validation loss: 0.1404
2024-05-25 02:41:39 [INFO]: Epoch 122 - training loss: 0.2191, validation loss: 0.1412
2024-05-25 02:41:39 [INFO]: Epoch 123 - training loss: 0.2175, validation loss: 0.1412
2024-05-25 02:41:40 [INFO]: Epoch 124 - training loss: 0.2169, validation loss: 0.1413
2024-05-25 02:41:40 [INFO]: Epoch 125 - training loss: 0.2164, validation loss: 0.1395
2024-05-25 02:41:40 [INFO]: Epoch 126 - training loss: 0.2166, validation loss: 0.1405
2024-05-25 02:41:41 [INFO]: Epoch 127 - training loss: 0.2152, validation loss: 0.1395
2024-05-25 02:41:41 [INFO]: Epoch 128 - training loss: 0.2161, validation loss: 0.1402
2024-05-25 02:41:41 [INFO]: Epoch 129 - training loss: 0.2191, validation loss: 0.1393
2024-05-25 02:41:42 [INFO]: Epoch 130 - training loss: 0.2160, validation loss: 0.1405
2024-05-25 02:41:42 [INFO]: Epoch 131 - training loss: 0.2163, validation loss: 0.1409
2024-05-25 02:41:42 [INFO]: Epoch 132 - training loss: 0.2154, validation loss: 0.1395
2024-05-25 02:41:43 [INFO]: Epoch 133 - training loss: 0.2155, validation loss: 0.1386
2024-05-25 02:41:43 [INFO]: Epoch 134 - training loss: 0.2149, validation loss: 0.1406
2024-05-25 02:41:43 [INFO]: Epoch 135 - training loss: 0.2149, validation loss: 0.1397
2024-05-25 02:41:44 [INFO]: Epoch 136 - training loss: 0.2130, validation loss: 0.1400
2024-05-25 02:41:44 [INFO]: Epoch 137 - training loss: 0.2136, validation loss: 0.1383
2024-05-25 02:41:44 [INFO]: Epoch 138 - training loss: 0.2134, validation loss: 0.1383
2024-05-25 02:41:44 [INFO]: Epoch 139 - training loss: 0.2145, validation loss: 0.1393
2024-05-25 02:41:45 [INFO]: Epoch 140 - training loss: 0.2158, validation loss: 0.1383
2024-05-25 02:41:45 [INFO]: Epoch 141 - training loss: 0.2146, validation loss: 0.1371
2024-05-25 02:41:45 [INFO]: Epoch 142 - training loss: 0.2128, validation loss: 0.1378
2024-05-25 02:41:46 [INFO]: Epoch 143 - training loss: 0.2118, validation loss: 0.1381
2024-05-25 02:41:46 [INFO]: Epoch 144 - training loss: 0.2128, validation loss: 0.1357
2024-05-25 02:41:46 [INFO]: Epoch 145 - training loss: 0.2163, validation loss: 0.1369
2024-05-25 02:41:47 [INFO]: Epoch 146 - training loss: 0.2111, validation loss: 0.1397
2024-05-25 02:41:47 [INFO]: Epoch 147 - training loss: 0.2101, validation loss: 0.1363
2024-05-25 02:41:47 [INFO]: Epoch 148 - training loss: 0.2100, validation loss: 0.1374
2024-05-25 02:41:48 [INFO]: Epoch 149 - training loss: 0.2109, validation loss: 0.1384
2024-05-25 02:41:48 [INFO]: Epoch 150 - training loss: 0.2088, validation loss: 0.1366
2024-05-25 02:41:48 [INFO]: Epoch 151 - training loss: 0.2082, validation loss: 0.1366
2024-05-25 02:41:49 [INFO]: Epoch 152 - training loss: 0.2117, validation loss: 0.1380
2024-05-25 02:41:49 [INFO]: Epoch 153 - training loss: 0.2095, validation loss: 0.1355
2024-05-25 02:41:49 [INFO]: Epoch 154 - training loss: 0.2071, validation loss: 0.1365
2024-05-25 02:41:50 [INFO]: Epoch 155 - training loss: 0.2072, validation loss: 0.1356
2024-05-25 02:41:50 [INFO]: Epoch 156 - training loss: 0.2078, validation loss: 0.1356
2024-05-25 02:41:50 [INFO]: Epoch 157 - training loss: 0.2066, validation loss: 0.1351
2024-05-25 02:41:51 [INFO]: Epoch 158 - training loss: 0.2120, validation loss: 0.1349
2024-05-25 02:41:51 [INFO]: Epoch 159 - training loss: 0.2107, validation loss: 0.1374
2024-05-25 02:41:51 [INFO]: Epoch 160 - training loss: 0.2061, validation loss: 0.1337
2024-05-25 02:41:52 [INFO]: Epoch 161 - training loss: 0.2059, validation loss: 0.1345
2024-05-25 02:41:52 [INFO]: Epoch 162 - training loss: 0.2050, validation loss: 0.1340
2024-05-25 02:41:52 [INFO]: Epoch 163 - training loss: 0.2044, validation loss: 0.1338
2024-05-25 02:41:53 [INFO]: Epoch 164 - training loss: 0.2052, validation loss: 0.1345
2024-05-25 02:41:53 [INFO]: Epoch 165 - training loss: 0.2061, validation loss: 0.1351
2024-05-25 02:41:53 [INFO]: Epoch 166 - training loss: 0.2059, validation loss: 0.1342
2024-05-25 02:41:54 [INFO]: Epoch 167 - training loss: 0.2066, validation loss: 0.1343
2024-05-25 02:41:54 [INFO]: Epoch 168 - training loss: 0.2054, validation loss: 0.1329
2024-05-25 02:41:54 [INFO]: Epoch 169 - training loss: 0.2027, validation loss: 0.1335
2024-05-25 02:41:55 [INFO]: Epoch 170 - training loss: 0.2017, validation loss: 0.1347
2024-05-25 02:41:55 [INFO]: Epoch 171 - training loss: 0.2033, validation loss: 0.1336
2024-05-25 02:41:55 [INFO]: Epoch 172 - training loss: 0.2046, validation loss: 0.1351
2024-05-25 02:41:56 [INFO]: Epoch 173 - training loss: 0.2038, validation loss: 0.1346
2024-05-25 02:41:56 [INFO]: Epoch 174 - training loss: 0.2022, validation loss: 0.1346
2024-05-25 02:41:56 [INFO]: Epoch 175 - training loss: 0.2043, validation loss: 0.1322
2024-05-25 02:41:56 [INFO]: Epoch 176 - training loss: 0.2014, validation loss: 0.1315
2024-05-25 02:41:57 [INFO]: Epoch 177 - training loss: 0.2004, validation loss: 0.1327
2024-05-25 02:41:57 [INFO]: Epoch 178 - training loss: 0.2005, validation loss: 0.1321
2024-05-25 02:41:57 [INFO]: Epoch 179 - training loss: 0.2034, validation loss: 0.1326
2024-05-25 02:41:58 [INFO]: Epoch 180 - training loss: 0.2034, validation loss: 0.1345
2024-05-25 02:41:58 [INFO]: Epoch 181 - training loss: 0.2023, validation loss: 0.1308
2024-05-25 02:41:58 [INFO]: Epoch 182 - training loss: 0.2030, validation loss: 0.1315
2024-05-25 02:41:59 [INFO]: Epoch 183 - training loss: 0.2006, validation loss: 0.1337
2024-05-25 02:41:59 [INFO]: Epoch 184 - training loss: 0.2001, validation loss: 0.1325
2024-05-25 02:41:59 [INFO]: Epoch 185 - training loss: 0.1982, validation loss: 0.1334
2024-05-25 02:42:00 [INFO]: Epoch 186 - training loss: 0.1980, validation loss: 0.1300
2024-05-25 02:42:00 [INFO]: Epoch 187 - training loss: 0.1985, validation loss: 0.1329
2024-05-25 02:42:00 [INFO]: Epoch 188 - training loss: 0.1994, validation loss: 0.1331
2024-05-25 02:42:01 [INFO]: Epoch 189 - training loss: 0.2001, validation loss: 0.1314
2024-05-25 02:42:01 [INFO]: Epoch 190 - training loss: 0.1984, validation loss: 0.1304
2024-05-25 02:42:01 [INFO]: Epoch 191 - training loss: 0.1993, validation loss: 0.1333
2024-05-25 02:42:02 [INFO]: Epoch 192 - training loss: 0.1997, validation loss: 0.1309
2024-05-25 02:42:02 [INFO]: Epoch 193 - training loss: 0.2016, validation loss: 0.1301
2024-05-25 02:42:02 [INFO]: Epoch 194 - training loss: 0.1982, validation loss: 0.1331
2024-05-25 02:42:03 [INFO]: Epoch 195 - training loss: 0.2001, validation loss: 0.1306
2024-05-25 02:42:03 [INFO]: Epoch 196 - training loss: 0.1977, validation loss: 0.1305
2024-05-25 02:42:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:42:03 [INFO]: Finished training. The best model is from epoch#186.
2024-05-25 02:42:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/Transformer_air_quality/20240525_T024059/Transformer.pypots
2024-05-25 02:42:03 [INFO]: Transformer on Air-Quality: MAE=0.1586, MSE=0.1180
2024-05-25 02:42:03 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/Transformer_air_quality/imputation.pkl
2024-05-25 02:42:03 [INFO]: Using the given device: cuda:0
2024-05-25 02:42:03 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/TimesNet_air_quality/20240525_T024203
2024-05-25 02:42:03 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/TimesNet_air_quality/20240525_T024203/tensorboard
2024-05-25 02:42:03 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 02:42:04 [INFO]: Epoch 001 - training loss: 0.2871, validation loss: 0.2634
2024-05-25 02:42:05 [INFO]: Epoch 002 - training loss: 0.2058, validation loss: 0.2289
2024-05-25 02:42:05 [INFO]: Epoch 003 - training loss: 0.1833, validation loss: 0.2193
2024-05-25 02:42:06 [INFO]: Epoch 004 - training loss: 0.1700, validation loss: 0.2032
2024-05-25 02:42:06 [INFO]: Epoch 005 - training loss: 0.1691, validation loss: 0.1945
2024-05-25 02:42:07 [INFO]: Epoch 006 - training loss: 0.1590, validation loss: 0.1921
2024-05-25 02:42:07 [INFO]: Epoch 007 - training loss: 0.1518, validation loss: 0.1891
2024-05-25 02:42:08 [INFO]: Epoch 008 - training loss: 0.1446, validation loss: 0.1807
2024-05-25 02:42:08 [INFO]: Epoch 009 - training loss: 0.1695, validation loss: 0.1799
2024-05-25 02:42:09 [INFO]: Epoch 010 - training loss: 0.1426, validation loss: 0.1727
2024-05-25 02:42:09 [INFO]: Epoch 011 - training loss: 0.1419, validation loss: 0.1726
2024-05-25 02:42:10 [INFO]: Epoch 012 - training loss: 0.1437, validation loss: 0.1675
2024-05-25 02:42:10 [INFO]: Epoch 013 - training loss: 0.1404, validation loss: 0.1791
2024-05-25 02:42:11 [INFO]: Epoch 014 - training loss: 0.1250, validation loss: 0.1676
2024-05-25 02:42:12 [INFO]: Epoch 015 - training loss: 0.1348, validation loss: 0.1713
2024-05-25 02:42:12 [INFO]: Epoch 016 - training loss: 0.1241, validation loss: 0.1635
2024-05-25 02:42:13 [INFO]: Epoch 017 - training loss: 0.1276, validation loss: 0.1686
2024-05-25 02:42:13 [INFO]: Epoch 018 - training loss: 0.1169, validation loss: 0.1646
2024-05-25 02:42:14 [INFO]: Epoch 019 - training loss: 0.1302, validation loss: 0.1576
2024-05-25 02:42:14 [INFO]: Epoch 020 - training loss: 0.1236, validation loss: 0.1593
2024-05-25 02:42:15 [INFO]: Epoch 021 - training loss: 0.1305, validation loss: 0.1564
2024-05-25 02:42:15 [INFO]: Epoch 022 - training loss: 0.1296, validation loss: 0.1612
2024-05-25 02:42:16 [INFO]: Epoch 023 - training loss: 0.1186, validation loss: 0.1560
2024-05-25 02:42:16 [INFO]: Epoch 024 - training loss: 0.1217, validation loss: 0.1519
2024-05-25 02:42:17 [INFO]: Epoch 025 - training loss: 0.1155, validation loss: 0.1517
2024-05-25 02:42:17 [INFO]: Epoch 026 - training loss: 0.1144, validation loss: 0.1552
2024-05-25 02:42:18 [INFO]: Epoch 027 - training loss: 0.1029, validation loss: 0.1498
2024-05-25 02:42:19 [INFO]: Epoch 028 - training loss: 0.1219, validation loss: 0.1551
2024-05-25 02:42:19 [INFO]: Epoch 029 - training loss: 0.1241, validation loss: 0.1522
2024-05-25 02:42:20 [INFO]: Epoch 030 - training loss: 0.1356, validation loss: 0.1511
2024-05-25 02:42:20 [INFO]: Epoch 031 - training loss: 0.1257, validation loss: 0.1545
2024-05-25 02:42:21 [INFO]: Epoch 032 - training loss: 0.1186, validation loss: 0.1585
2024-05-25 02:42:21 [INFO]: Epoch 033 - training loss: 0.1007, validation loss: 0.1522
2024-05-25 02:42:22 [INFO]: Epoch 034 - training loss: 0.1254, validation loss: 0.1494
2024-05-25 02:42:22 [INFO]: Epoch 035 - training loss: 0.0990, validation loss: 0.1490
2024-05-25 02:42:23 [INFO]: Epoch 036 - training loss: 0.1241, validation loss: 0.1522
2024-05-25 02:42:23 [INFO]: Epoch 037 - training loss: 0.1060, validation loss: 0.1516
2024-05-25 02:42:24 [INFO]: Epoch 038 - training loss: 0.1064, validation loss: 0.1487
2024-05-25 02:42:24 [INFO]: Epoch 039 - training loss: 0.1075, validation loss: 0.1504
2024-05-25 02:42:25 [INFO]: Epoch 040 - training loss: 0.1160, validation loss: 0.1468
2024-05-25 02:42:25 [INFO]: Epoch 041 - training loss: 0.0977, validation loss: 0.1466
2024-05-25 02:42:26 [INFO]: Epoch 042 - training loss: 0.1173, validation loss: 0.1441
2024-05-25 02:42:27 [INFO]: Epoch 043 - training loss: 0.1025, validation loss: 0.1458
2024-05-25 02:42:27 [INFO]: Epoch 044 - training loss: 0.1085, validation loss: 0.1492
2024-05-25 02:42:28 [INFO]: Epoch 045 - training loss: 0.1031, validation loss: 0.1466
2024-05-25 02:42:28 [INFO]: Epoch 046 - training loss: 0.0983, validation loss: 0.1481
2024-05-25 02:42:29 [INFO]: Epoch 047 - training loss: 0.1042, validation loss: 0.1468
2024-05-25 02:42:29 [INFO]: Epoch 048 - training loss: 0.1005, validation loss: 0.1452
2024-05-25 02:42:30 [INFO]: Epoch 049 - training loss: 0.1166, validation loss: 0.1436
2024-05-25 02:42:30 [INFO]: Epoch 050 - training loss: 0.1032, validation loss: 0.1419
2024-05-25 02:42:31 [INFO]: Epoch 051 - training loss: 0.0973, validation loss: 0.1434
2024-05-25 02:42:31 [INFO]: Epoch 052 - training loss: 0.1047, validation loss: 0.1407
2024-05-25 02:42:32 [INFO]: Epoch 053 - training loss: 0.1060, validation loss: 0.1418
2024-05-25 02:42:32 [INFO]: Epoch 054 - training loss: 0.1017, validation loss: 0.1373
2024-05-25 02:42:33 [INFO]: Epoch 055 - training loss: 0.1187, validation loss: 0.1375
2024-05-25 02:42:34 [INFO]: Epoch 056 - training loss: 0.1015, validation loss: 0.1393
2024-05-25 02:42:34 [INFO]: Epoch 057 - training loss: 0.1113, validation loss: 0.1401
2024-05-25 02:42:35 [INFO]: Epoch 058 - training loss: 0.1101, validation loss: 0.1424
2024-05-25 02:42:35 [INFO]: Epoch 059 - training loss: 0.1057, validation loss: 0.1416
2024-05-25 02:42:36 [INFO]: Epoch 060 - training loss: 0.1004, validation loss: 0.1440
2024-05-25 02:42:36 [INFO]: Epoch 061 - training loss: 0.1150, validation loss: 0.1375
2024-05-25 02:42:37 [INFO]: Epoch 062 - training loss: 0.0938, validation loss: 0.1403
2024-05-25 02:42:37 [INFO]: Epoch 063 - training loss: 0.0958, validation loss: 0.1418
2024-05-25 02:42:38 [INFO]: Epoch 064 - training loss: 0.0947, validation loss: 0.1404
2024-05-25 02:42:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:42:38 [INFO]: Finished training. The best model is from epoch#54.
2024-05-25 02:42:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/TimesNet_air_quality/20240525_T024203/TimesNet.pypots
2024-05-25 02:42:38 [INFO]: TimesNet on Air-Quality: MAE=0.1548, MSE=0.1251
2024-05-25 02:42:38 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/TimesNet_air_quality/imputation.pkl
2024-05-25 02:42:38 [INFO]: Using the given device: cuda:0
2024-05-25 02:42:38 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238
2024-05-25 02:42:38 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/tensorboard
2024-05-25 02:42:38 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 02:42:55 [INFO]: Epoch 001 - training loss: 0.4639, validation loss: 0.3514
2024-05-25 02:42:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch1_loss0.3514127343893051.pypots
2024-05-25 02:43:12 [INFO]: Epoch 002 - training loss: 0.2809, validation loss: 0.2902
2024-05-25 02:43:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch2_loss0.29018859267234803.pypots
2024-05-25 02:43:29 [INFO]: Epoch 003 - training loss: 0.2586, validation loss: 0.2607
2024-05-25 02:43:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch3_loss0.26067200005054475.pypots
2024-05-25 02:43:45 [INFO]: Epoch 004 - training loss: 0.2305, validation loss: 0.2312
2024-05-25 02:43:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch4_loss0.23117684721946716.pypots
2024-05-25 02:44:02 [INFO]: Epoch 005 - training loss: 0.2064, validation loss: 0.1954
2024-05-25 02:44:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch5_loss0.19536180049180984.pypots
2024-05-25 02:44:19 [INFO]: Epoch 006 - training loss: 0.2258, validation loss: 0.1826
2024-05-25 02:44:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch6_loss0.1825646609067917.pypots
2024-05-25 02:44:36 [INFO]: Epoch 007 - training loss: 0.1801, validation loss: 0.1697
2024-05-25 02:44:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch7_loss0.169698828458786.pypots
2024-05-25 02:44:53 [INFO]: Epoch 008 - training loss: 0.1704, validation loss: 0.1655
2024-05-25 02:44:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch8_loss0.16547900289297104.pypots
2024-05-25 02:45:10 [INFO]: Epoch 009 - training loss: 0.1659, validation loss: 0.1605
2024-05-25 02:45:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch9_loss0.16050693094730378.pypots
2024-05-25 02:45:27 [INFO]: Epoch 010 - training loss: 0.1881, validation loss: 0.1579
2024-05-25 02:45:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch10_loss0.15794418305158614.pypots
2024-05-25 02:45:43 [INFO]: Epoch 011 - training loss: 0.1747, validation loss: 0.1513
2024-05-25 02:45:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch11_loss0.15131274312734605.pypots
2024-05-25 02:46:00 [INFO]: Epoch 012 - training loss: 0.1552, validation loss: 0.1487
2024-05-25 02:46:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch12_loss0.1486952483654022.pypots
2024-05-25 02:46:17 [INFO]: Epoch 013 - training loss: 0.1628, validation loss: 0.1480
2024-05-25 02:46:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch13_loss0.14795674979686738.pypots
2024-05-25 02:46:34 [INFO]: Epoch 014 - training loss: 0.1470, validation loss: 0.1517
2024-05-25 02:46:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch14_loss0.15169041007757186.pypots
2024-05-25 02:46:51 [INFO]: Epoch 015 - training loss: 0.1699, validation loss: 0.1426
2024-05-25 02:46:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch15_loss0.14258086308836937.pypots
2024-05-25 02:47:08 [INFO]: Epoch 016 - training loss: 0.1480, validation loss: 0.1400
2024-05-25 02:47:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch16_loss0.14003348872065544.pypots
2024-05-25 02:47:24 [INFO]: Epoch 017 - training loss: 0.1610, validation loss: 0.1369
2024-05-25 02:47:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch17_loss0.13689245283603668.pypots
2024-05-25 02:47:41 [INFO]: Epoch 018 - training loss: 0.1575, validation loss: 0.1359
2024-05-25 02:47:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch18_loss0.13589554503560067.pypots
2024-05-25 02:47:58 [INFO]: Epoch 019 - training loss: 0.1779, validation loss: 0.1402
2024-05-25 02:47:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch19_loss0.140190689265728.pypots
2024-05-25 02:48:15 [INFO]: Epoch 020 - training loss: 0.1397, validation loss: 0.1396
2024-05-25 02:48:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch20_loss0.13963499367237092.pypots
2024-05-25 02:48:32 [INFO]: Epoch 021 - training loss: 0.1514, validation loss: 0.1363
2024-05-25 02:48:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch21_loss0.13626183271408082.pypots
2024-05-25 02:48:49 [INFO]: Epoch 022 - training loss: 0.1613, validation loss: 0.1331
2024-05-25 02:48:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch22_loss0.13308070972561836.pypots
2024-05-25 02:49:06 [INFO]: Epoch 023 - training loss: 0.1628, validation loss: 0.1352
2024-05-25 02:49:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch23_loss0.13520091623067856.pypots
2024-05-25 02:49:22 [INFO]: Epoch 024 - training loss: 0.1384, validation loss: 0.1303
2024-05-25 02:49:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch24_loss0.13029786720871925.pypots
2024-05-25 02:49:39 [INFO]: Epoch 025 - training loss: 0.1495, validation loss: 0.1311
2024-05-25 02:49:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch25_loss0.1311007931828499.pypots
2024-05-25 02:49:56 [INFO]: Epoch 026 - training loss: 0.1470, validation loss: 0.1272
2024-05-25 02:49:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch26_loss0.1271529607474804.pypots
2024-05-25 02:50:13 [INFO]: Epoch 027 - training loss: 0.1383, validation loss: 0.1385
2024-05-25 02:50:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch27_loss0.13846225664019585.pypots
2024-05-25 02:50:30 [INFO]: Epoch 028 - training loss: 0.1459, validation loss: 0.1270
2024-05-25 02:50:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch28_loss0.12701986655592917.pypots
2024-05-25 02:50:47 [INFO]: Epoch 029 - training loss: 0.1244, validation loss: 0.1258
2024-05-25 02:50:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch29_loss0.12579188346862794.pypots
2024-05-25 02:51:03 [INFO]: Epoch 030 - training loss: 0.1362, validation loss: 0.1263
2024-05-25 02:51:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch30_loss0.12634677588939666.pypots
2024-05-25 02:51:20 [INFO]: Epoch 031 - training loss: 0.1324, validation loss: 0.1256
2024-05-25 02:51:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch31_loss0.1255543015897274.pypots
2024-05-25 02:51:37 [INFO]: Epoch 032 - training loss: 0.1405, validation loss: 0.1271
2024-05-25 02:51:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch32_loss0.12714381515979767.pypots
2024-05-25 02:51:54 [INFO]: Epoch 033 - training loss: 0.1461, validation loss: 0.1230
2024-05-25 02:51:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch33_loss0.12303202375769615.pypots
2024-05-25 02:52:11 [INFO]: Epoch 034 - training loss: 0.1262, validation loss: 0.1205
2024-05-25 02:52:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch34_loss0.12046058475971222.pypots
2024-05-25 02:52:28 [INFO]: Epoch 035 - training loss: 0.1253, validation loss: 0.1257
2024-05-25 02:52:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch35_loss0.12571871057152748.pypots
2024-05-25 02:52:45 [INFO]: Epoch 036 - training loss: 0.1385, validation loss: 0.1255
2024-05-25 02:52:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch36_loss0.12551531717181205.pypots
2024-05-25 02:53:01 [INFO]: Epoch 037 - training loss: 0.1302, validation loss: 0.1241
2024-05-25 02:53:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch37_loss0.12411209866404534.pypots
2024-05-25 02:53:18 [INFO]: Epoch 038 - training loss: 0.1315, validation loss: 0.1220
2024-05-25 02:53:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch38_loss0.12197443470358849.pypots
2024-05-25 02:53:35 [INFO]: Epoch 039 - training loss: 0.1337, validation loss: 0.1196
2024-05-25 02:53:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch39_loss0.11960679590702057.pypots
2024-05-25 02:53:52 [INFO]: Epoch 040 - training loss: 0.1232, validation loss: 0.1187
2024-05-25 02:53:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch40_loss0.11871697455644607.pypots
2024-05-25 02:54:09 [INFO]: Epoch 041 - training loss: 0.1349, validation loss: 0.1200
2024-05-25 02:54:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch41_loss0.12002826035022736.pypots
2024-05-25 02:54:26 [INFO]: Epoch 042 - training loss: 0.1257, validation loss: 0.1160
2024-05-25 02:54:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch42_loss0.11601339727640152.pypots
2024-05-25 02:54:42 [INFO]: Epoch 043 - training loss: 0.1314, validation loss: 0.1267
2024-05-25 02:54:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch43_loss0.1267297960817814.pypots
2024-05-25 02:54:59 [INFO]: Epoch 044 - training loss: 0.1196, validation loss: 0.1248
2024-05-25 02:54:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch44_loss0.12479132935404777.pypots
2024-05-25 02:55:16 [INFO]: Epoch 045 - training loss: 0.1365, validation loss: 0.1195
2024-05-25 02:55:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch45_loss0.11953283473849297.pypots
2024-05-25 02:55:33 [INFO]: Epoch 046 - training loss: 0.1305, validation loss: 0.1127
2024-05-25 02:55:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch46_loss0.11274960786104202.pypots
2024-05-25 02:55:50 [INFO]: Epoch 047 - training loss: 0.1401, validation loss: 0.1181
2024-05-25 02:55:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch47_loss0.11813638806343078.pypots
2024-05-25 02:56:07 [INFO]: Epoch 048 - training loss: 0.1303, validation loss: 0.1126
2024-05-25 02:56:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch48_loss0.1126260980963707.pypots
2024-05-25 02:56:24 [INFO]: Epoch 049 - training loss: 0.1179, validation loss: 0.1121
2024-05-25 02:56:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch49_loss0.11212745681405067.pypots
2024-05-25 02:56:40 [INFO]: Epoch 050 - training loss: 0.1277, validation loss: 0.1122
2024-05-25 02:56:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch50_loss0.11222072914242745.pypots
2024-05-25 02:56:57 [INFO]: Epoch 051 - training loss: 0.1048, validation loss: 0.1115
2024-05-25 02:56:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch51_loss0.11150125786662102.pypots
2024-05-25 02:57:14 [INFO]: Epoch 052 - training loss: 0.1261, validation loss: 0.1089
2024-05-25 02:57:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch52_loss0.1089085653424263.pypots
2024-05-25 02:57:31 [INFO]: Epoch 053 - training loss: 0.1206, validation loss: 0.1176
2024-05-25 02:57:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch53_loss0.1175700657069683.pypots
2024-05-25 02:57:48 [INFO]: Epoch 054 - training loss: 0.1260, validation loss: 0.1107
2024-05-25 02:57:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch54_loss0.1107362262904644.pypots
2024-05-25 02:58:05 [INFO]: Epoch 055 - training loss: 0.1287, validation loss: 0.1114
2024-05-25 02:58:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch55_loss0.11142694503068924.pypots
2024-05-25 02:58:22 [INFO]: Epoch 056 - training loss: 0.0988, validation loss: 0.1081
2024-05-25 02:58:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch56_loss0.10807977244257927.pypots
2024-05-25 02:58:38 [INFO]: Epoch 057 - training loss: 0.1162, validation loss: 0.1103
2024-05-25 02:58:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch57_loss0.1102626271545887.pypots
2024-05-25 02:58:55 [INFO]: Epoch 058 - training loss: 0.1284, validation loss: 0.1151
2024-05-25 02:58:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch58_loss0.11506958305835724.pypots
2024-05-25 02:59:12 [INFO]: Epoch 059 - training loss: 0.1304, validation loss: 0.1093
2024-05-25 02:59:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch59_loss0.10927629172801971.pypots
2024-05-25 02:59:29 [INFO]: Epoch 060 - training loss: 0.1345, validation loss: 0.1110
2024-05-25 02:59:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch60_loss0.11104847863316536.pypots
2024-05-25 02:59:46 [INFO]: Epoch 061 - training loss: 0.1316, validation loss: 0.1093
2024-05-25 02:59:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch61_loss0.10926072522997857.pypots
2024-05-25 03:00:03 [INFO]: Epoch 062 - training loss: 0.1248, validation loss: 0.1140
2024-05-25 03:00:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch62_loss0.11403675079345703.pypots
2024-05-25 03:00:19 [INFO]: Epoch 063 - training loss: 0.1245, validation loss: 0.1119
2024-05-25 03:00:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch63_loss0.11185748279094695.pypots
2024-05-25 03:00:36 [INFO]: Epoch 064 - training loss: 0.1176, validation loss: 0.1072
2024-05-25 03:00:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch64_loss0.10723895579576492.pypots
2024-05-25 03:00:53 [INFO]: Epoch 065 - training loss: 0.1218, validation loss: 0.1089
2024-05-25 03:00:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch65_loss0.10891521945595742.pypots
2024-05-25 03:01:10 [INFO]: Epoch 066 - training loss: 0.1286, validation loss: 0.1063
2024-05-25 03:01:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch66_loss0.10632577911019325.pypots
2024-05-25 03:01:27 [INFO]: Epoch 067 - training loss: 0.1296, validation loss: 0.1065
2024-05-25 03:01:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch67_loss0.10651065781712532.pypots
2024-05-25 03:01:44 [INFO]: Epoch 068 - training loss: 0.1282, validation loss: 0.1083
2024-05-25 03:01:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch68_loss0.10825101733207702.pypots
2024-05-25 03:02:00 [INFO]: Epoch 069 - training loss: 0.1229, validation loss: 0.1076
2024-05-25 03:02:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch69_loss0.10762887448072433.pypots
2024-05-25 03:02:17 [INFO]: Epoch 070 - training loss: 0.1172, validation loss: 0.1078
2024-05-25 03:02:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch70_loss0.10782945975661277.pypots
2024-05-25 03:02:34 [INFO]: Epoch 071 - training loss: 0.1160, validation loss: 0.1088
2024-05-25 03:02:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch71_loss0.10875770449638367.pypots
2024-05-25 03:02:51 [INFO]: Epoch 072 - training loss: 0.1220, validation loss: 0.1060
2024-05-25 03:02:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch72_loss0.1060280442237854.pypots
2024-05-25 03:03:08 [INFO]: Epoch 073 - training loss: 0.1281, validation loss: 0.1073
2024-05-25 03:03:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch73_loss0.10729596838355064.pypots
2024-05-25 03:03:25 [INFO]: Epoch 074 - training loss: 0.1191, validation loss: 0.1041
2024-05-25 03:03:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch74_loss0.10406698361039161.pypots
2024-05-25 03:03:42 [INFO]: Epoch 075 - training loss: 0.1108, validation loss: 0.1034
2024-05-25 03:03:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch75_loss0.10336722731590271.pypots
2024-05-25 03:03:58 [INFO]: Epoch 076 - training loss: 0.1194, validation loss: 0.1053
2024-05-25 03:03:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch76_loss0.10529790371656418.pypots
2024-05-25 03:04:15 [INFO]: Epoch 077 - training loss: 0.1200, validation loss: 0.1050
2024-05-25 03:04:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch77_loss0.10497691407799721.pypots
2024-05-25 03:04:32 [INFO]: Epoch 078 - training loss: 0.1179, validation loss: 0.1043
2024-05-25 03:04:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch78_loss0.10434298515319824.pypots
2024-05-25 03:04:49 [INFO]: Epoch 079 - training loss: 0.0990, validation loss: 0.1021
2024-05-25 03:04:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch79_loss0.102074034512043.pypots
2024-05-25 03:05:06 [INFO]: Epoch 080 - training loss: 0.1123, validation loss: 0.1107
2024-05-25 03:05:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch80_loss0.11070411950349808.pypots
2024-05-25 03:05:23 [INFO]: Epoch 081 - training loss: 0.1132, validation loss: 0.1025
2024-05-25 03:05:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch81_loss0.10249026045203209.pypots
2024-05-25 03:05:39 [INFO]: Epoch 082 - training loss: 0.1169, validation loss: 0.1022
2024-05-25 03:05:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch82_loss0.10223097056150436.pypots
2024-05-25 03:05:56 [INFO]: Epoch 083 - training loss: 0.1158, validation loss: 0.1029
2024-05-25 03:05:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch83_loss0.10293726325035095.pypots
2024-05-25 03:06:13 [INFO]: Epoch 084 - training loss: 0.1076, validation loss: 0.1134
2024-05-25 03:06:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch84_loss0.11341628283262253.pypots
2024-05-25 03:06:30 [INFO]: Epoch 085 - training loss: 0.1292, validation loss: 0.1079
2024-05-25 03:06:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch85_loss0.10789843872189522.pypots
2024-05-25 03:06:47 [INFO]: Epoch 086 - training loss: 0.1168, validation loss: 0.1033
2024-05-25 03:06:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch86_loss0.1032729759812355.pypots
2024-05-25 03:07:04 [INFO]: Epoch 087 - training loss: 0.1181, validation loss: 0.1012
2024-05-25 03:07:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch87_loss0.10118414014577866.pypots
2024-05-25 03:07:21 [INFO]: Epoch 088 - training loss: 0.1165, validation loss: 0.1014
2024-05-25 03:07:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch88_loss0.10142396911978721.pypots
2024-05-25 03:07:37 [INFO]: Epoch 089 - training loss: 0.1183, validation loss: 0.1033
2024-05-25 03:07:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch89_loss0.10329411402344704.pypots
2024-05-25 03:07:54 [INFO]: Epoch 090 - training loss: 0.1254, validation loss: 0.1060
2024-05-25 03:07:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch90_loss0.10604751631617546.pypots
2024-05-25 03:08:11 [INFO]: Epoch 091 - training loss: 0.1334, validation loss: 0.1027
2024-05-25 03:08:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch91_loss0.10266504436731339.pypots
2024-05-25 03:08:28 [INFO]: Epoch 092 - training loss: 0.1158, validation loss: 0.1010
2024-05-25 03:08:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch92_loss0.10104394108057022.pypots
2024-05-25 03:08:45 [INFO]: Epoch 093 - training loss: 0.1162, validation loss: 0.1014
2024-05-25 03:08:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch93_loss0.1014063000679016.pypots
2024-05-25 03:09:02 [INFO]: Epoch 094 - training loss: 0.1321, validation loss: 0.1061
2024-05-25 03:09:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch94_loss0.10610443502664565.pypots
2024-05-25 03:09:18 [INFO]: Epoch 095 - training loss: 0.1249, validation loss: 0.1026
2024-05-25 03:09:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch95_loss0.10264405012130737.pypots
2024-05-25 03:09:35 [INFO]: Epoch 096 - training loss: 0.1219, validation loss: 0.1002
2024-05-25 03:09:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch96_loss0.10017911419272423.pypots
2024-05-25 03:09:52 [INFO]: Epoch 097 - training loss: 0.1211, validation loss: 0.1068
2024-05-25 03:09:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch97_loss0.1067644402384758.pypots
2024-05-25 03:10:09 [INFO]: Epoch 098 - training loss: 0.1253, validation loss: 0.1032
2024-05-25 03:10:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch98_loss0.1032341443002224.pypots
2024-05-25 03:10:26 [INFO]: Epoch 099 - training loss: 0.1069, validation loss: 0.1009
2024-05-25 03:10:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch99_loss0.10093386173248291.pypots
2024-05-25 03:10:43 [INFO]: Epoch 100 - training loss: 0.1172, validation loss: 0.1008
2024-05-25 03:10:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch100_loss0.10075565576553344.pypots
2024-05-25 03:10:59 [INFO]: Epoch 101 - training loss: 0.1112, validation loss: 0.0998
2024-05-25 03:10:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch101_loss0.09977267384529113.pypots
2024-05-25 03:11:16 [INFO]: Epoch 102 - training loss: 0.1092, validation loss: 0.1012
2024-05-25 03:11:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch102_loss0.10120640695095062.pypots
2024-05-25 03:11:33 [INFO]: Epoch 103 - training loss: 0.1155, validation loss: 0.1039
2024-05-25 03:11:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch103_loss0.10391237959265709.pypots
2024-05-25 03:11:50 [INFO]: Epoch 104 - training loss: 0.1179, validation loss: 0.1017
2024-05-25 03:11:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch104_loss0.10167171731591225.pypots
2024-05-25 03:12:07 [INFO]: Epoch 105 - training loss: 0.1036, validation loss: 0.1029
2024-05-25 03:12:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch105_loss0.10285452082753181.pypots
2024-05-25 03:12:24 [INFO]: Epoch 106 - training loss: 0.1079, validation loss: 0.1013
2024-05-25 03:12:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch106_loss0.10125109776854516.pypots
2024-05-25 03:12:41 [INFO]: Epoch 107 - training loss: 0.1178, validation loss: 0.0972
2024-05-25 03:12:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch107_loss0.0972261942923069.pypots
2024-05-25 03:12:57 [INFO]: Epoch 108 - training loss: 0.1127, validation loss: 0.0981
2024-05-25 03:12:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch108_loss0.09806049764156341.pypots
2024-05-25 03:13:14 [INFO]: Epoch 109 - training loss: 0.1263, validation loss: 0.1001
2024-05-25 03:13:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch109_loss0.10009435638785362.pypots
2024-05-25 03:13:31 [INFO]: Epoch 110 - training loss: 0.1175, validation loss: 0.1006
2024-05-25 03:13:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch110_loss0.10063221901655198.pypots
2024-05-25 03:13:48 [INFO]: Epoch 111 - training loss: 0.1016, validation loss: 0.0982
2024-05-25 03:13:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch111_loss0.09822781682014466.pypots
2024-05-25 03:14:05 [INFO]: Epoch 112 - training loss: 0.1149, validation loss: 0.0981
2024-05-25 03:14:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch112_loss0.09808786138892174.pypots
2024-05-25 03:14:22 [INFO]: Epoch 113 - training loss: 0.1016, validation loss: 0.0979
2024-05-25 03:14:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch113_loss0.09786071330308914.pypots
2024-05-25 03:14:38 [INFO]: Epoch 114 - training loss: 0.1100, validation loss: 0.0986
2024-05-25 03:14:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch114_loss0.09863895997405052.pypots
2024-05-25 03:14:55 [INFO]: Epoch 115 - training loss: 0.1137, validation loss: 0.1024
2024-05-25 03:14:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch115_loss0.10243726000189782.pypots
2024-05-25 03:15:12 [INFO]: Epoch 116 - training loss: 0.1185, validation loss: 0.0994
2024-05-25 03:15:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch116_loss0.09938719198107719.pypots
2024-05-25 03:15:29 [INFO]: Epoch 117 - training loss: 0.0987, validation loss: 0.0990
2024-05-25 03:15:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI_epoch117_loss0.09896617457270622.pypots
2024-05-25 03:15:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:15:29 [INFO]: Finished training. The best model is from epoch#107.
2024-05-25 03:15:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T024238/CSDI.pypots
2024-05-25 03:17:50 [INFO]: CSDI on Air-Quality: MAE=0.0935, MSE=0.0778
2024-05-25 03:17:50 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/CSDI_air_quality/imputation.pkl
2024-05-25 03:17:50 [INFO]: Using the given device: cuda:0
2024-05-25 03:17:50 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/GPVAE_air_quality/20240525_T031750
2024-05-25 03:17:50 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/GPVAE_air_quality/20240525_T031750/tensorboard
2024-05-25 03:17:50 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 03:17:50 [INFO]: Epoch 001 - training loss: 62996.0088, validation loss: 0.6490
2024-05-25 03:17:50 [INFO]: Epoch 002 - training loss: 42045.4135, validation loss: 0.5820
2024-05-25 03:17:51 [INFO]: Epoch 003 - training loss: 41749.5624, validation loss: 0.5184
2024-05-25 03:17:51 [INFO]: Epoch 004 - training loss: 41643.8192, validation loss: 0.4910
2024-05-25 03:17:51 [INFO]: Epoch 005 - training loss: 41571.2416, validation loss: 0.4296
2024-05-25 03:17:52 [INFO]: Epoch 006 - training loss: 41493.9935, validation loss: 0.4023
2024-05-25 03:17:52 [INFO]: Epoch 007 - training loss: 41465.3643, validation loss: 0.3668
2024-05-25 03:17:52 [INFO]: Epoch 008 - training loss: 41440.9246, validation loss: 0.4016
2024-05-25 03:17:53 [INFO]: Epoch 009 - training loss: 41436.8628, validation loss: 0.3449
2024-05-25 03:17:53 [INFO]: Epoch 010 - training loss: 41381.7122, validation loss: 0.3382
2024-05-25 03:17:53 [INFO]: Epoch 011 - training loss: 41356.1221, validation loss: 0.3257
2024-05-25 03:17:54 [INFO]: Epoch 012 - training loss: 41341.4375, validation loss: 0.3104
2024-05-25 03:17:54 [INFO]: Epoch 013 - training loss: 41338.0279, validation loss: 0.3238
2024-05-25 03:17:55 [INFO]: Epoch 014 - training loss: 41332.2431, validation loss: 0.3277
2024-05-25 03:17:55 [INFO]: Epoch 015 - training loss: 41310.0668, validation loss: 0.3528
2024-05-25 03:17:55 [INFO]: Epoch 016 - training loss: 41332.3672, validation loss: 0.2936
2024-05-25 03:17:56 [INFO]: Epoch 017 - training loss: 41286.5718, validation loss: 0.2839
2024-05-25 03:17:56 [INFO]: Epoch 018 - training loss: 41272.2208, validation loss: 0.2810
2024-05-25 03:17:56 [INFO]: Epoch 019 - training loss: 41264.5655, validation loss: 0.2798
2024-05-25 03:17:57 [INFO]: Epoch 020 - training loss: 41255.9667, validation loss: 0.2711
2024-05-25 03:17:57 [INFO]: Epoch 021 - training loss: 41253.2779, validation loss: 0.2726
2024-05-25 03:17:57 [INFO]: Epoch 022 - training loss: 41300.0122, validation loss: 0.3060
2024-05-25 03:17:58 [INFO]: Epoch 023 - training loss: 41323.8290, validation loss: 0.3086
2024-05-25 03:17:58 [INFO]: Epoch 024 - training loss: 41311.3092, validation loss: 0.2814
2024-05-25 03:17:58 [INFO]: Epoch 025 - training loss: 41255.4698, validation loss: 0.2610
2024-05-25 03:17:59 [INFO]: Epoch 026 - training loss: 41236.0405, validation loss: 0.2686
2024-05-25 03:17:59 [INFO]: Epoch 027 - training loss: 41234.5800, validation loss: 0.2492
2024-05-25 03:18:00 [INFO]: Epoch 028 - training loss: 41222.5140, validation loss: 0.2668
2024-05-25 03:18:00 [INFO]: Epoch 029 - training loss: 41222.0969, validation loss: 0.2547
2024-05-25 03:18:00 [INFO]: Epoch 030 - training loss: 41227.5820, validation loss: 0.2546
2024-05-25 03:18:01 [INFO]: Epoch 031 - training loss: 41222.6424, validation loss: 0.2720
2024-05-25 03:18:01 [INFO]: Epoch 032 - training loss: 41231.6259, validation loss: 0.2519
2024-05-25 03:18:01 [INFO]: Epoch 033 - training loss: 41211.8869, validation loss: 0.2458
2024-05-25 03:18:02 [INFO]: Epoch 034 - training loss: 41211.7121, validation loss: 0.2459
2024-05-25 03:18:02 [INFO]: Epoch 035 - training loss: 41204.7439, validation loss: 0.2411
2024-05-25 03:18:02 [INFO]: Epoch 036 - training loss: 41198.1512, validation loss: 0.2353
2024-05-25 03:18:03 [INFO]: Epoch 037 - training loss: 41196.2808, validation loss: 0.2550
2024-05-25 03:18:03 [INFO]: Epoch 038 - training loss: 41214.8341, validation loss: 0.2340
2024-05-25 03:18:03 [INFO]: Epoch 039 - training loss: 41200.7297, validation loss: 0.2428
2024-05-25 03:18:04 [INFO]: Epoch 040 - training loss: 41187.3555, validation loss: 0.2301
2024-05-25 03:18:04 [INFO]: Epoch 041 - training loss: 41175.8051, validation loss: 0.2281
2024-05-25 03:18:04 [INFO]: Epoch 042 - training loss: 41178.0541, validation loss: 0.2270
2024-05-25 03:18:05 [INFO]: Epoch 043 - training loss: 41176.9614, validation loss: 0.2291
2024-05-25 03:18:05 [INFO]: Epoch 044 - training loss: 41181.7556, validation loss: 0.2262
2024-05-25 03:18:06 [INFO]: Epoch 045 - training loss: 41192.2041, validation loss: 0.2375
2024-05-25 03:18:06 [INFO]: Epoch 046 - training loss: 41211.4405, validation loss: 0.2912
2024-05-25 03:18:06 [INFO]: Epoch 047 - training loss: 41287.7556, validation loss: 0.2653
2024-05-25 03:18:07 [INFO]: Epoch 048 - training loss: 41223.0563, validation loss: 0.2805
2024-05-25 03:18:07 [INFO]: Epoch 049 - training loss: 41209.2448, validation loss: 0.2523
2024-05-25 03:18:07 [INFO]: Epoch 050 - training loss: 41208.0485, validation loss: 0.2368
2024-05-25 03:18:08 [INFO]: Epoch 051 - training loss: 41190.1011, validation loss: 0.2305
2024-05-25 03:18:08 [INFO]: Epoch 052 - training loss: 41175.7438, validation loss: 0.2248
2024-05-25 03:18:08 [INFO]: Epoch 053 - training loss: 41175.0515, validation loss: 0.2173
2024-05-25 03:18:09 [INFO]: Epoch 054 - training loss: 41168.3958, validation loss: 0.2255
2024-05-25 03:18:09 [INFO]: Epoch 055 - training loss: 41165.6489, validation loss: 0.2252
2024-05-25 03:18:09 [INFO]: Epoch 056 - training loss: 41170.6956, validation loss: 0.2228
2024-05-25 03:18:10 [INFO]: Epoch 057 - training loss: 41173.4563, validation loss: 0.2356
2024-05-25 03:18:10 [INFO]: Epoch 058 - training loss: 41161.2623, validation loss: 0.2184
2024-05-25 03:18:10 [INFO]: Epoch 059 - training loss: 41157.3659, validation loss: 0.2122
2024-05-25 03:18:11 [INFO]: Epoch 060 - training loss: 41154.9842, validation loss: 0.2194
2024-05-25 03:18:11 [INFO]: Epoch 061 - training loss: 41160.3261, validation loss: 0.2236
2024-05-25 03:18:11 [INFO]: Epoch 062 - training loss: 41153.6236, validation loss: 0.2117
2024-05-25 03:18:12 [INFO]: Epoch 063 - training loss: 41149.5810, validation loss: 0.2108
2024-05-25 03:18:12 [INFO]: Epoch 064 - training loss: 41148.9806, validation loss: 0.2258
2024-05-25 03:18:13 [INFO]: Epoch 065 - training loss: 41148.0984, validation loss: 0.2242
2024-05-25 03:18:13 [INFO]: Epoch 066 - training loss: 41148.6626, validation loss: 0.2097
2024-05-25 03:18:13 [INFO]: Epoch 067 - training loss: 41170.5298, validation loss: 0.2607
2024-05-25 03:18:14 [INFO]: Epoch 068 - training loss: 41211.8795, validation loss: 0.2539
2024-05-25 03:18:14 [INFO]: Epoch 069 - training loss: 41163.5184, validation loss: 0.2231
2024-05-25 03:18:14 [INFO]: Epoch 070 - training loss: 41154.6531, validation loss: 0.2213
2024-05-25 03:18:15 [INFO]: Epoch 071 - training loss: 41152.7228, validation loss: 0.2201
2024-05-25 03:18:15 [INFO]: Epoch 072 - training loss: 41155.4029, validation loss: 0.2016
2024-05-25 03:18:15 [INFO]: Epoch 073 - training loss: 41149.8041, validation loss: 0.2137
2024-05-25 03:18:16 [INFO]: Epoch 074 - training loss: 41160.0192, validation loss: 0.2238
2024-05-25 03:18:16 [INFO]: Epoch 075 - training loss: 41156.6155, validation loss: 0.2261
2024-05-25 03:18:16 [INFO]: Epoch 076 - training loss: 41162.3775, validation loss: 0.2477
2024-05-25 03:18:17 [INFO]: Epoch 077 - training loss: 41203.6013, validation loss: 0.2540
2024-05-25 03:18:17 [INFO]: Epoch 078 - training loss: 41208.4342, validation loss: 0.2196
2024-05-25 03:18:17 [INFO]: Epoch 079 - training loss: 41177.0958, validation loss: 0.2191
2024-05-25 03:18:18 [INFO]: Epoch 080 - training loss: 41186.3853, validation loss: 0.2366
2024-05-25 03:18:18 [INFO]: Epoch 081 - training loss: 41171.6696, validation loss: 0.2513
2024-05-25 03:18:19 [INFO]: Epoch 082 - training loss: 41220.4239, validation loss: 0.2335
2024-05-25 03:18:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:18:19 [INFO]: Finished training. The best model is from epoch#72.
2024-05-25 03:18:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/GPVAE_air_quality/20240525_T031750/GPVAE.pypots
2024-05-25 03:18:19 [INFO]: GP-VAE on Air-Quality: MAE=0.2750, MSE=0.2152
2024-05-25 03:18:19 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/GPVAE_air_quality/imputation.pkl
2024-05-25 03:18:19 [INFO]: Using the given device: cuda:0
2024-05-25 03:18:19 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/USGAN_air_quality/20240525_T031819
2024-05-25 03:18:19 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/USGAN_air_quality/20240525_T031819/tensorboard
2024-05-25 03:18:19 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 03:18:24 [INFO]: Epoch 001 - generator training loss: 0.6042, discriminator training loss: 0.2872, validation loss: 0.5116
2024-05-25 03:18:28 [INFO]: Epoch 002 - generator training loss: 0.2857, discriminator training loss: 0.0668, validation loss: 0.3845
2024-05-25 03:18:32 [INFO]: Epoch 003 - generator training loss: 0.2118, discriminator training loss: 0.0643, validation loss: 0.3169
2024-05-25 03:18:36 [INFO]: Epoch 004 - generator training loss: 0.1770, discriminator training loss: 0.0620, validation loss: 0.2739
2024-05-25 03:18:40 [INFO]: Epoch 005 - generator training loss: 0.1532, discriminator training loss: 0.0618, validation loss: 0.2454
2024-05-25 03:18:45 [INFO]: Epoch 006 - generator training loss: 0.1365, discriminator training loss: 0.0612, validation loss: 0.2260
2024-05-25 03:18:49 [INFO]: Epoch 007 - generator training loss: 0.1220, discriminator training loss: 0.0612, validation loss: 0.2117
2024-05-25 03:18:53 [INFO]: Epoch 008 - generator training loss: 0.1136, discriminator training loss: 0.0601, validation loss: 0.2000
2024-05-25 03:18:58 [INFO]: Epoch 009 - generator training loss: 0.1045, discriminator training loss: 0.0596, validation loss: 0.1911
2024-05-25 03:19:02 [INFO]: Epoch 010 - generator training loss: 0.1005, discriminator training loss: 0.0590, validation loss: 0.1836
2024-05-25 03:19:06 [INFO]: Epoch 011 - generator training loss: 0.0932, discriminator training loss: 0.0577, validation loss: 0.1760
2024-05-25 03:19:10 [INFO]: Epoch 012 - generator training loss: 0.0875, discriminator training loss: 0.0571, validation loss: 0.1716
2024-05-25 03:19:14 [INFO]: Epoch 013 - generator training loss: 0.0855, discriminator training loss: 0.0556, validation loss: 0.1652
2024-05-25 03:19:18 [INFO]: Epoch 014 - generator training loss: 0.0828, discriminator training loss: 0.0541, validation loss: 0.1619
2024-05-25 03:19:23 [INFO]: Epoch 015 - generator training loss: 0.0786, discriminator training loss: 0.0526, validation loss: 0.1575
2024-05-25 03:19:27 [INFO]: Epoch 016 - generator training loss: 0.0763, discriminator training loss: 0.0512, validation loss: 0.1543
2024-05-25 03:19:31 [INFO]: Epoch 017 - generator training loss: 0.0754, discriminator training loss: 0.0492, validation loss: 0.1510
2024-05-25 03:19:35 [INFO]: Epoch 018 - generator training loss: 0.0736, discriminator training loss: 0.0479, validation loss: 0.1480
2024-05-25 03:19:40 [INFO]: Epoch 019 - generator training loss: 0.0726, discriminator training loss: 0.0463, validation loss: 0.1454
2024-05-25 03:19:44 [INFO]: Epoch 020 - generator training loss: 0.0702, discriminator training loss: 0.0457, validation loss: 0.1434
2024-05-25 03:19:48 [INFO]: Epoch 021 - generator training loss: 0.0687, discriminator training loss: 0.0450, validation loss: 0.1409
2024-05-25 03:19:52 [INFO]: Epoch 022 - generator training loss: 0.0685, discriminator training loss: 0.0435, validation loss: 0.1395
2024-05-25 03:19:56 [INFO]: Epoch 023 - generator training loss: 0.0678, discriminator training loss: 0.0428, validation loss: 0.1372
2024-05-25 03:20:00 [INFO]: Epoch 024 - generator training loss: 0.0663, discriminator training loss: 0.0422, validation loss: 0.1359
2024-05-25 03:20:05 [INFO]: Epoch 025 - generator training loss: 0.0647, discriminator training loss: 0.0418, validation loss: 0.1344
2024-05-25 03:20:09 [INFO]: Epoch 026 - generator training loss: 0.0637, discriminator training loss: 0.0408, validation loss: 0.1328
2024-05-25 03:20:13 [INFO]: Epoch 027 - generator training loss: 0.0625, discriminator training loss: 0.0399, validation loss: 0.1315
2024-05-25 03:20:18 [INFO]: Epoch 028 - generator training loss: 0.0635, discriminator training loss: 0.0391, validation loss: 0.1298
2024-05-25 03:20:22 [INFO]: Epoch 029 - generator training loss: 0.0609, discriminator training loss: 0.0384, validation loss: 0.1281
2024-05-25 03:20:26 [INFO]: Epoch 030 - generator training loss: 0.0604, discriminator training loss: 0.0376, validation loss: 0.1273
2024-05-25 03:20:30 [INFO]: Epoch 031 - generator training loss: 0.0594, discriminator training loss: 0.0369, validation loss: 0.1264
2024-05-25 03:20:34 [INFO]: Epoch 032 - generator training loss: 0.0608, discriminator training loss: 0.0360, validation loss: 0.1252
2024-05-25 03:20:39 [INFO]: Epoch 033 - generator training loss: 0.0597, discriminator training loss: 0.0349, validation loss: 0.1236
2024-05-25 03:20:43 [INFO]: Epoch 034 - generator training loss: 0.0577, discriminator training loss: 0.0342, validation loss: 0.1226
2024-05-25 03:20:47 [INFO]: Epoch 035 - generator training loss: 0.0570, discriminator training loss: 0.0338, validation loss: 0.1216
2024-05-25 03:20:51 [INFO]: Epoch 036 - generator training loss: 0.0572, discriminator training loss: 0.0325, validation loss: 0.1202
2024-05-25 03:20:55 [INFO]: Epoch 037 - generator training loss: 0.0562, discriminator training loss: 0.0319, validation loss: 0.1192
2024-05-25 03:21:00 [INFO]: Epoch 038 - generator training loss: 0.0560, discriminator training loss: 0.0313, validation loss: 0.1182
2024-05-25 03:21:04 [INFO]: Epoch 039 - generator training loss: 0.0566, discriminator training loss: 0.0304, validation loss: 0.1176
2024-05-25 03:21:08 [INFO]: Epoch 040 - generator training loss: 0.0551, discriminator training loss: 0.0297, validation loss: 0.1164
2024-05-25 03:21:12 [INFO]: Epoch 041 - generator training loss: 0.0547, discriminator training loss: 0.0294, validation loss: 0.1159
2024-05-25 03:21:17 [INFO]: Epoch 042 - generator training loss: 0.0540, discriminator training loss: 0.0289, validation loss: 0.1145
2024-05-25 03:21:21 [INFO]: Epoch 043 - generator training loss: 0.0545, discriminator training loss: 0.0280, validation loss: 0.1140
2024-05-25 03:21:25 [INFO]: Epoch 044 - generator training loss: 0.0536, discriminator training loss: 0.0276, validation loss: 0.1132
2024-05-25 03:21:29 [INFO]: Epoch 045 - generator training loss: 0.0530, discriminator training loss: 0.0272, validation loss: 0.1124
2024-05-25 03:21:33 [INFO]: Epoch 046 - generator training loss: 0.0529, discriminator training loss: 0.0266, validation loss: 0.1116
2024-05-25 03:21:38 [INFO]: Epoch 047 - generator training loss: 0.0532, discriminator training loss: 0.0260, validation loss: 0.1113
2024-05-25 03:21:42 [INFO]: Epoch 048 - generator training loss: 0.0521, discriminator training loss: 0.0258, validation loss: 0.1101
2024-05-25 03:21:46 [INFO]: Epoch 049 - generator training loss: 0.0517, discriminator training loss: 0.0254, validation loss: 0.1099
2024-05-25 03:21:50 [INFO]: Epoch 050 - generator training loss: 0.0515, discriminator training loss: 0.0250, validation loss: 0.1094
2024-05-25 03:21:54 [INFO]: Epoch 051 - generator training loss: 0.0511, discriminator training loss: 0.0245, validation loss: 0.1086
2024-05-25 03:21:59 [INFO]: Epoch 052 - generator training loss: 0.0513, discriminator training loss: 0.0243, validation loss: 0.1077
2024-05-25 03:22:03 [INFO]: Epoch 053 - generator training loss: 0.0506, discriminator training loss: 0.0237, validation loss: 0.1074
2024-05-25 03:22:07 [INFO]: Epoch 054 - generator training loss: 0.0501, discriminator training loss: 0.0235, validation loss: 0.1070
2024-05-25 03:22:11 [INFO]: Epoch 055 - generator training loss: 0.0501, discriminator training loss: 0.0231, validation loss: 0.1065
2024-05-25 03:22:15 [INFO]: Epoch 056 - generator training loss: 0.0507, discriminator training loss: 0.0228, validation loss: 0.1056
2024-05-25 03:22:20 [INFO]: Epoch 057 - generator training loss: 0.0484, discriminator training loss: 0.0224, validation loss: 0.1053
2024-05-25 03:22:24 [INFO]: Epoch 058 - generator training loss: 0.0477, discriminator training loss: 0.0223, validation loss: 0.1045
2024-05-25 03:22:28 [INFO]: Epoch 059 - generator training loss: 0.0473, discriminator training loss: 0.0217, validation loss: 0.1041
2024-05-25 03:22:32 [INFO]: Epoch 060 - generator training loss: 0.0479, discriminator training loss: 0.0216, validation loss: 0.1037
2024-05-25 03:22:37 [INFO]: Epoch 061 - generator training loss: 0.0468, discriminator training loss: 0.0212, validation loss: 0.1022
2024-05-25 03:22:41 [INFO]: Epoch 062 - generator training loss: 0.0470, discriminator training loss: 0.0212, validation loss: 0.1031
2024-05-25 03:22:45 [INFO]: Epoch 063 - generator training loss: 0.0461, discriminator training loss: 0.0210, validation loss: 0.1029
2024-05-25 03:22:49 [INFO]: Epoch 064 - generator training loss: 0.0457, discriminator training loss: 0.0206, validation loss: 0.1024
2024-05-25 03:22:53 [INFO]: Epoch 065 - generator training loss: 0.0457, discriminator training loss: 0.0203, validation loss: 0.1019
2024-05-25 03:22:57 [INFO]: Epoch 066 - generator training loss: 0.0464, discriminator training loss: 0.0199, validation loss: 0.1011
2024-05-25 03:23:01 [INFO]: Epoch 067 - generator training loss: 0.0449, discriminator training loss: 0.0198, validation loss: 0.1012
2024-05-25 03:23:05 [INFO]: Epoch 068 - generator training loss: 0.0454, discriminator training loss: 0.0197, validation loss: 0.1010
2024-05-25 03:23:10 [INFO]: Epoch 069 - generator training loss: 0.0449, discriminator training loss: 0.0194, validation loss: 0.1006
2024-05-25 03:23:14 [INFO]: Epoch 070 - generator training loss: 0.0441, discriminator training loss: 0.0193, validation loss: 0.1003
2024-05-25 03:23:18 [INFO]: Epoch 071 - generator training loss: 0.0439, discriminator training loss: 0.0191, validation loss: 0.1006
2024-05-25 03:23:22 [INFO]: Epoch 072 - generator training loss: 0.0441, discriminator training loss: 0.0190, validation loss: 0.0999
2024-05-25 03:23:27 [INFO]: Epoch 073 - generator training loss: 0.0440, discriminator training loss: 0.0187, validation loss: 0.0995
2024-05-25 03:23:31 [INFO]: Epoch 074 - generator training loss: 0.0435, discriminator training loss: 0.0185, validation loss: 0.0996
2024-05-25 03:23:35 [INFO]: Epoch 075 - generator training loss: 0.0437, discriminator training loss: 0.0183, validation loss: 0.0998
2024-05-25 03:23:39 [INFO]: Epoch 076 - generator training loss: 0.0452, discriminator training loss: 0.0179, validation loss: 0.0989
2024-05-25 03:23:43 [INFO]: Epoch 077 - generator training loss: 0.0428, discriminator training loss: 0.0180, validation loss: 0.0988
2024-05-25 03:23:48 [INFO]: Epoch 078 - generator training loss: 0.0428, discriminator training loss: 0.0179, validation loss: 0.0988
2024-05-25 03:23:52 [INFO]: Epoch 079 - generator training loss: 0.0417, discriminator training loss: 0.0179, validation loss: 0.0980
2024-05-25 03:23:56 [INFO]: Epoch 080 - generator training loss: 0.0415, discriminator training loss: 0.0178, validation loss: 0.0986
2024-05-25 03:24:00 [INFO]: Epoch 081 - generator training loss: 0.0415, discriminator training loss: 0.0176, validation loss: 0.0983
2024-05-25 03:24:04 [INFO]: Epoch 082 - generator training loss: 0.0422, discriminator training loss: 0.0175, validation loss: 0.0985
2024-05-25 03:24:09 [INFO]: Epoch 083 - generator training loss: 0.0414, discriminator training loss: 0.0171, validation loss: 0.0980
2024-05-25 03:24:13 [INFO]: Epoch 084 - generator training loss: 0.0413, discriminator training loss: 0.0170, validation loss: 0.0976
2024-05-25 03:24:17 [INFO]: Epoch 085 - generator training loss: 0.0411, discriminator training loss: 0.0169, validation loss: 0.0984
2024-05-25 03:24:21 [INFO]: Epoch 086 - generator training loss: 0.0405, discriminator training loss: 0.0169, validation loss: 0.0979
2024-05-25 03:24:26 [INFO]: Epoch 087 - generator training loss: 0.0405, discriminator training loss: 0.0167, validation loss: 0.0978
2024-05-25 03:24:30 [INFO]: Epoch 088 - generator training loss: 0.0406, discriminator training loss: 0.0163, validation loss: 0.0977
2024-05-25 03:24:34 [INFO]: Epoch 089 - generator training loss: 0.0405, discriminator training loss: 0.0167, validation loss: 0.0973
2024-05-25 03:24:38 [INFO]: Epoch 090 - generator training loss: 0.0402, discriminator training loss: 0.0165, validation loss: 0.0970
2024-05-25 03:24:42 [INFO]: Epoch 091 - generator training loss: 0.0394, discriminator training loss: 0.0162, validation loss: 0.0971
2024-05-25 03:24:47 [INFO]: Epoch 092 - generator training loss: 0.0395, discriminator training loss: 0.0162, validation loss: 0.0972
2024-05-25 03:24:51 [INFO]: Epoch 093 - generator training loss: 0.0395, discriminator training loss: 0.0160, validation loss: 0.0973
2024-05-25 03:24:55 [INFO]: Epoch 094 - generator training loss: 0.0392, discriminator training loss: 0.0160, validation loss: 0.0971
2024-05-25 03:24:59 [INFO]: Epoch 095 - generator training loss: 0.0400, discriminator training loss: 0.0156, validation loss: 0.0976
2024-05-25 03:25:04 [INFO]: Epoch 096 - generator training loss: 0.0400, discriminator training loss: 0.0158, validation loss: 0.0983
2024-05-25 03:25:08 [INFO]: Epoch 097 - generator training loss: 0.0393, discriminator training loss: 0.0158, validation loss: 0.0984
2024-05-25 03:25:12 [INFO]: Epoch 098 - generator training loss: 0.0391, discriminator training loss: 0.0155, validation loss: 0.0986
2024-05-25 03:25:16 [INFO]: Epoch 099 - generator training loss: 0.0383, discriminator training loss: 0.0158, validation loss: 0.0960
2024-05-25 03:25:20 [INFO]: Epoch 100 - generator training loss: 0.0382, discriminator training loss: 0.0153, validation loss: 0.0961
2024-05-25 03:25:25 [INFO]: Epoch 101 - generator training loss: 0.0380, discriminator training loss: 0.0152, validation loss: 0.0969
2024-05-25 03:25:29 [INFO]: Epoch 102 - generator training loss: 0.0381, discriminator training loss: 0.0153, validation loss: 0.0965
2024-05-25 03:25:33 [INFO]: Epoch 103 - generator training loss: 0.0376, discriminator training loss: 0.0153, validation loss: 0.0978
2024-05-25 03:25:37 [INFO]: Epoch 104 - generator training loss: 0.0392, discriminator training loss: 0.0150, validation loss: 0.0961
2024-05-25 03:25:41 [INFO]: Epoch 105 - generator training loss: 0.0378, discriminator training loss: 0.0147, validation loss: 0.0970
2024-05-25 03:25:46 [INFO]: Epoch 106 - generator training loss: 0.0371, discriminator training loss: 0.0149, validation loss: 0.0970
2024-05-25 03:25:50 [INFO]: Epoch 107 - generator training loss: 0.0377, discriminator training loss: 0.0149, validation loss: 0.0962
2024-05-25 03:25:54 [INFO]: Epoch 108 - generator training loss: 0.0376, discriminator training loss: 0.0147, validation loss: 0.0968
2024-05-25 03:25:58 [INFO]: Epoch 109 - generator training loss: 0.0371, discriminator training loss: 0.0147, validation loss: 0.0968
2024-05-25 03:25:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:25:58 [INFO]: Finished training. The best model is from epoch#99.
2024-05-25 03:25:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/USGAN_air_quality/20240525_T031819/USGAN.pypots
2024-05-25 03:25:59 [INFO]: US-GAN on Air-Quality: MAE=0.1534, MSE=0.0994
2024-05-25 03:25:59 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/USGAN_air_quality/imputation.pkl
2024-05-25 03:25:59 [INFO]: Using the given device: cuda:0
2024-05-25 03:25:59 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/BRITS_air_quality/20240525_T032559
2024-05-25 03:25:59 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/BRITS_air_quality/20240525_T032559/tensorboard
2024-05-25 03:25:59 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 03:26:03 [INFO]: Epoch 001 - training loss: 1.3987, validation loss: 0.9120
2024-05-25 03:26:06 [INFO]: Epoch 002 - training loss: 1.1270, validation loss: 0.6821
2024-05-25 03:26:08 [INFO]: Epoch 003 - training loss: 0.9377, validation loss: 0.5768
2024-05-25 03:26:11 [INFO]: Epoch 004 - training loss: 0.8303, validation loss: 0.5088
2024-05-25 03:26:14 [INFO]: Epoch 005 - training loss: 0.7564, validation loss: 0.4618
2024-05-25 03:26:17 [INFO]: Epoch 006 - training loss: 0.7007, validation loss: 0.4263
2024-05-25 03:26:20 [INFO]: Epoch 007 - training loss: 0.6576, validation loss: 0.3979
2024-05-25 03:26:23 [INFO]: Epoch 008 - training loss: 0.6218, validation loss: 0.3742
2024-05-25 03:26:25 [INFO]: Epoch 009 - training loss: 0.5954, validation loss: 0.3545
2024-05-25 03:26:28 [INFO]: Epoch 010 - training loss: 0.5718, validation loss: 0.3395
2024-05-25 03:26:31 [INFO]: Epoch 011 - training loss: 0.5552, validation loss: 0.3261
2024-05-25 03:26:34 [INFO]: Epoch 012 - training loss: 0.5395, validation loss: 0.3143
2024-05-25 03:26:37 [INFO]: Epoch 013 - training loss: 0.5251, validation loss: 0.3048
2024-05-25 03:26:40 [INFO]: Epoch 014 - training loss: 0.5137, validation loss: 0.2965
2024-05-25 03:26:42 [INFO]: Epoch 015 - training loss: 0.5036, validation loss: 0.2889
2024-05-25 03:26:45 [INFO]: Epoch 016 - training loss: 0.4932, validation loss: 0.2823
2024-05-25 03:26:48 [INFO]: Epoch 017 - training loss: 0.4846, validation loss: 0.2764
2024-05-25 03:26:51 [INFO]: Epoch 018 - training loss: 0.4759, validation loss: 0.2706
2024-05-25 03:26:54 [INFO]: Epoch 019 - training loss: 0.4692, validation loss: 0.2655
2024-05-25 03:26:57 [INFO]: Epoch 020 - training loss: 0.4613, validation loss: 0.2605
2024-05-25 03:27:00 [INFO]: Epoch 021 - training loss: 0.4549, validation loss: 0.2554
2024-05-25 03:27:02 [INFO]: Epoch 022 - training loss: 0.4479, validation loss: 0.2511
2024-05-25 03:27:05 [INFO]: Epoch 023 - training loss: 0.4422, validation loss: 0.2471
2024-05-25 03:27:08 [INFO]: Epoch 024 - training loss: 0.4362, validation loss: 0.2433
2024-05-25 03:27:11 [INFO]: Epoch 025 - training loss: 0.4305, validation loss: 0.2388
2024-05-25 03:27:14 [INFO]: Epoch 026 - training loss: 0.4250, validation loss: 0.2343
2024-05-25 03:27:17 [INFO]: Epoch 027 - training loss: 0.4213, validation loss: 0.2309
2024-05-25 03:27:19 [INFO]: Epoch 028 - training loss: 0.4148, validation loss: 0.2268
2024-05-25 03:27:22 [INFO]: Epoch 029 - training loss: 0.4108, validation loss: 0.2227
2024-05-25 03:27:25 [INFO]: Epoch 030 - training loss: 0.4054, validation loss: 0.2196
2024-05-25 03:27:28 [INFO]: Epoch 031 - training loss: 0.4009, validation loss: 0.2161
2024-05-25 03:27:31 [INFO]: Epoch 032 - training loss: 0.3967, validation loss: 0.2127
2024-05-25 03:27:34 [INFO]: Epoch 033 - training loss: 0.3924, validation loss: 0.2100
2024-05-25 03:27:36 [INFO]: Epoch 034 - training loss: 0.3882, validation loss: 0.2063
2024-05-25 03:27:39 [INFO]: Epoch 035 - training loss: 0.3844, validation loss: 0.2025
2024-05-25 03:27:42 [INFO]: Epoch 036 - training loss: 0.3807, validation loss: 0.1998
2024-05-25 03:27:45 [INFO]: Epoch 037 - training loss: 0.3775, validation loss: 0.1971
2024-05-25 03:27:48 [INFO]: Epoch 038 - training loss: 0.3736, validation loss: 0.1942
2024-05-25 03:27:51 [INFO]: Epoch 039 - training loss: 0.3698, validation loss: 0.1918
2024-05-25 03:27:54 [INFO]: Epoch 040 - training loss: 0.3672, validation loss: 0.1890
2024-05-25 03:27:56 [INFO]: Epoch 041 - training loss: 0.3638, validation loss: 0.1860
2024-05-25 03:27:59 [INFO]: Epoch 042 - training loss: 0.3610, validation loss: 0.1836
2024-05-25 03:28:02 [INFO]: Epoch 043 - training loss: 0.3583, validation loss: 0.1814
2024-05-25 03:28:05 [INFO]: Epoch 044 - training loss: 0.3555, validation loss: 0.1790
2024-05-25 03:28:08 [INFO]: Epoch 045 - training loss: 0.3520, validation loss: 0.1762
2024-05-25 03:28:11 [INFO]: Epoch 046 - training loss: 0.3497, validation loss: 0.1742
2024-05-25 03:28:14 [INFO]: Epoch 047 - training loss: 0.3468, validation loss: 0.1725
2024-05-25 03:28:16 [INFO]: Epoch 048 - training loss: 0.3446, validation loss: 0.1706
2024-05-25 03:28:19 [INFO]: Epoch 049 - training loss: 0.3425, validation loss: 0.1681
2024-05-25 03:28:22 [INFO]: Epoch 050 - training loss: 0.3400, validation loss: 0.1668
2024-05-25 03:28:25 [INFO]: Epoch 051 - training loss: 0.3375, validation loss: 0.1650
2024-05-25 03:28:28 [INFO]: Epoch 052 - training loss: 0.3346, validation loss: 0.1632
2024-05-25 03:28:31 [INFO]: Epoch 053 - training loss: 0.3338, validation loss: 0.1620
2024-05-25 03:28:33 [INFO]: Epoch 054 - training loss: 0.3309, validation loss: 0.1602
2024-05-25 03:28:36 [INFO]: Epoch 055 - training loss: 0.3288, validation loss: 0.1584
2024-05-25 03:28:39 [INFO]: Epoch 056 - training loss: 0.3267, validation loss: 0.1574
2024-05-25 03:28:42 [INFO]: Epoch 057 - training loss: 0.3255, validation loss: 0.1563
2024-05-25 03:28:45 [INFO]: Epoch 058 - training loss: 0.3228, validation loss: 0.1554
2024-05-25 03:28:48 [INFO]: Epoch 059 - training loss: 0.3216, validation loss: 0.1536
2024-05-25 03:28:50 [INFO]: Epoch 060 - training loss: 0.3199, validation loss: 0.1527
2024-05-25 03:28:53 [INFO]: Epoch 061 - training loss: 0.3182, validation loss: 0.1514
2024-05-25 03:28:56 [INFO]: Epoch 062 - training loss: 0.3160, validation loss: 0.1508
2024-05-25 03:28:59 [INFO]: Epoch 063 - training loss: 0.3145, validation loss: 0.1496
2024-05-25 03:29:02 [INFO]: Epoch 064 - training loss: 0.3135, validation loss: 0.1487
2024-05-25 03:29:05 [INFO]: Epoch 065 - training loss: 0.3120, validation loss: 0.1479
2024-05-25 03:29:08 [INFO]: Epoch 066 - training loss: 0.3102, validation loss: 0.1470
2024-05-25 03:29:10 [INFO]: Epoch 067 - training loss: 0.3109, validation loss: 0.1462
2024-05-25 03:29:13 [INFO]: Epoch 068 - training loss: 0.3080, validation loss: 0.1455
2024-05-25 03:29:16 [INFO]: Epoch 069 - training loss: 0.3068, validation loss: 0.1448
2024-05-25 03:29:19 [INFO]: Epoch 070 - training loss: 0.3053, validation loss: 0.1439
2024-05-25 03:29:22 [INFO]: Epoch 071 - training loss: 0.3041, validation loss: 0.1434
2024-05-25 03:29:25 [INFO]: Epoch 072 - training loss: 0.3035, validation loss: 0.1426
2024-05-25 03:29:27 [INFO]: Epoch 073 - training loss: 0.3020, validation loss: 0.1414
2024-05-25 03:29:30 [INFO]: Epoch 074 - training loss: 0.3003, validation loss: 0.1409
2024-05-25 03:29:33 [INFO]: Epoch 075 - training loss: 0.3002, validation loss: 0.1404
2024-05-25 03:29:36 [INFO]: Epoch 076 - training loss: 0.2983, validation loss: 0.1396
2024-05-25 03:29:39 [INFO]: Epoch 077 - training loss: 0.2975, validation loss: 0.1391
2024-05-25 03:29:42 [INFO]: Epoch 078 - training loss: 0.2965, validation loss: 0.1385
2024-05-25 03:29:44 [INFO]: Epoch 079 - training loss: 0.2958, validation loss: 0.1380
2024-05-25 03:29:47 [INFO]: Epoch 080 - training loss: 0.2945, validation loss: 0.1373
2024-05-25 03:29:50 [INFO]: Epoch 081 - training loss: 0.2937, validation loss: 0.1368
2024-05-25 03:29:53 [INFO]: Epoch 082 - training loss: 0.2932, validation loss: 0.1368
2024-05-25 03:29:56 [INFO]: Epoch 083 - training loss: 0.2921, validation loss: 0.1357
2024-05-25 03:29:59 [INFO]: Epoch 084 - training loss: 0.2908, validation loss: 0.1354
2024-05-25 03:30:02 [INFO]: Epoch 085 - training loss: 0.2906, validation loss: 0.1347
2024-05-25 03:30:04 [INFO]: Epoch 086 - training loss: 0.2892, validation loss: 0.1339
2024-05-25 03:30:07 [INFO]: Epoch 087 - training loss: 0.2883, validation loss: 0.1337
2024-05-25 03:30:10 [INFO]: Epoch 088 - training loss: 0.2875, validation loss: 0.1331
2024-05-25 03:30:13 [INFO]: Epoch 089 - training loss: 0.2869, validation loss: 0.1326
2024-05-25 03:30:16 [INFO]: Epoch 090 - training loss: 0.2863, validation loss: 0.1324
2024-05-25 03:30:18 [INFO]: Epoch 091 - training loss: 0.2853, validation loss: 0.1316
2024-05-25 03:30:21 [INFO]: Epoch 092 - training loss: 0.2847, validation loss: 0.1312
2024-05-25 03:30:24 [INFO]: Epoch 093 - training loss: 0.2841, validation loss: 0.1307
2024-05-25 03:30:27 [INFO]: Epoch 094 - training loss: 0.2840, validation loss: 0.1305
2024-05-25 03:30:29 [INFO]: Epoch 095 - training loss: 0.2832, validation loss: 0.1297
2024-05-25 03:30:32 [INFO]: Epoch 096 - training loss: 0.2820, validation loss: 0.1291
2024-05-25 03:30:35 [INFO]: Epoch 097 - training loss: 0.2814, validation loss: 0.1288
2024-05-25 03:30:38 [INFO]: Epoch 098 - training loss: 0.2804, validation loss: 0.1282
2024-05-25 03:30:40 [INFO]: Epoch 099 - training loss: 0.2801, validation loss: 0.1281
2024-05-25 03:30:43 [INFO]: Epoch 100 - training loss: 0.2798, validation loss: 0.1280
2024-05-25 03:30:46 [INFO]: Epoch 101 - training loss: 0.2789, validation loss: 0.1273
2024-05-25 03:30:49 [INFO]: Epoch 102 - training loss: 0.2788, validation loss: 0.1271
2024-05-25 03:30:52 [INFO]: Epoch 103 - training loss: 0.2778, validation loss: 0.1266
2024-05-25 03:30:55 [INFO]: Epoch 104 - training loss: 0.2772, validation loss: 0.1261
2024-05-25 03:30:58 [INFO]: Epoch 105 - training loss: 0.2768, validation loss: 0.1259
2024-05-25 03:31:00 [INFO]: Epoch 106 - training loss: 0.2760, validation loss: 0.1254
2024-05-25 03:31:03 [INFO]: Epoch 107 - training loss: 0.2749, validation loss: 0.1249
2024-05-25 03:31:06 [INFO]: Epoch 108 - training loss: 0.2748, validation loss: 0.1247
2024-05-25 03:31:09 [INFO]: Epoch 109 - training loss: 0.2737, validation loss: 0.1243
2024-05-25 03:31:12 [INFO]: Epoch 110 - training loss: 0.2738, validation loss: 0.1239
2024-05-25 03:31:15 [INFO]: Epoch 111 - training loss: 0.2735, validation loss: 0.1236
2024-05-25 03:31:17 [INFO]: Epoch 112 - training loss: 0.2722, validation loss: 0.1234
2024-05-25 03:31:20 [INFO]: Epoch 113 - training loss: 0.2722, validation loss: 0.1230
2024-05-25 03:31:23 [INFO]: Epoch 114 - training loss: 0.2714, validation loss: 0.1223
2024-05-25 03:31:26 [INFO]: Epoch 115 - training loss: 0.2714, validation loss: 0.1219
2024-05-25 03:31:29 [INFO]: Epoch 116 - training loss: 0.2701, validation loss: 0.1218
2024-05-25 03:31:32 [INFO]: Epoch 117 - training loss: 0.2697, validation loss: 0.1212
2024-05-25 03:31:34 [INFO]: Epoch 118 - training loss: 0.2697, validation loss: 0.1209
2024-05-25 03:31:37 [INFO]: Epoch 119 - training loss: 0.2686, validation loss: 0.1207
2024-05-25 03:31:40 [INFO]: Epoch 120 - training loss: 0.2682, validation loss: 0.1205
2024-05-25 03:31:43 [INFO]: Epoch 121 - training loss: 0.2680, validation loss: 0.1200
2024-05-25 03:31:46 [INFO]: Epoch 122 - training loss: 0.2682, validation loss: 0.1196
2024-05-25 03:31:49 [INFO]: Epoch 123 - training loss: 0.2672, validation loss: 0.1194
2024-05-25 03:31:52 [INFO]: Epoch 124 - training loss: 0.2671, validation loss: 0.1190
2024-05-25 03:31:54 [INFO]: Epoch 125 - training loss: 0.2662, validation loss: 0.1186
2024-05-25 03:31:57 [INFO]: Epoch 126 - training loss: 0.2658, validation loss: 0.1182
2024-05-25 03:32:00 [INFO]: Epoch 127 - training loss: 0.2657, validation loss: 0.1182
2024-05-25 03:32:03 [INFO]: Epoch 128 - training loss: 0.2650, validation loss: 0.1178
2024-05-25 03:32:06 [INFO]: Epoch 129 - training loss: 0.2638, validation loss: 0.1174
2024-05-25 03:32:09 [INFO]: Epoch 130 - training loss: 0.2643, validation loss: 0.1171
2024-05-25 03:32:12 [INFO]: Epoch 131 - training loss: 0.2635, validation loss: 0.1169
2024-05-25 03:32:14 [INFO]: Epoch 132 - training loss: 0.2633, validation loss: 0.1165
2024-05-25 03:32:17 [INFO]: Epoch 133 - training loss: 0.2629, validation loss: 0.1162
2024-05-25 03:32:20 [INFO]: Epoch 134 - training loss: 0.2627, validation loss: 0.1159
2024-05-25 03:32:23 [INFO]: Epoch 135 - training loss: 0.2620, validation loss: 0.1159
2024-05-25 03:32:26 [INFO]: Epoch 136 - training loss: 0.2611, validation loss: 0.1155
2024-05-25 03:32:29 [INFO]: Epoch 137 - training loss: 0.2612, validation loss: 0.1153
2024-05-25 03:32:31 [INFO]: Epoch 138 - training loss: 0.2613, validation loss: 0.1150
2024-05-25 03:32:34 [INFO]: Epoch 139 - training loss: 0.2601, validation loss: 0.1146
2024-05-25 03:32:37 [INFO]: Epoch 140 - training loss: 0.2602, validation loss: 0.1144
2024-05-25 03:32:40 [INFO]: Epoch 141 - training loss: 0.2603, validation loss: 0.1140
2024-05-25 03:32:43 [INFO]: Epoch 142 - training loss: 0.2599, validation loss: 0.1139
2024-05-25 03:32:46 [INFO]: Epoch 143 - training loss: 0.2592, validation loss: 0.1137
2024-05-25 03:32:48 [INFO]: Epoch 144 - training loss: 0.2586, validation loss: 0.1134
2024-05-25 03:32:51 [INFO]: Epoch 145 - training loss: 0.2582, validation loss: 0.1134
2024-05-25 03:32:54 [INFO]: Epoch 146 - training loss: 0.2578, validation loss: 0.1128
2024-05-25 03:32:57 [INFO]: Epoch 147 - training loss: 0.2577, validation loss: 0.1126
2024-05-25 03:33:00 [INFO]: Epoch 148 - training loss: 0.2571, validation loss: 0.1125
2024-05-25 03:33:03 [INFO]: Epoch 149 - training loss: 0.2568, validation loss: 0.1123
2024-05-25 03:33:06 [INFO]: Epoch 150 - training loss: 0.2570, validation loss: 0.1119
2024-05-25 03:33:08 [INFO]: Epoch 151 - training loss: 0.2562, validation loss: 0.1117
2024-05-25 03:33:11 [INFO]: Epoch 152 - training loss: 0.2563, validation loss: 0.1115
2024-05-25 03:33:14 [INFO]: Epoch 153 - training loss: 0.2555, validation loss: 0.1111
2024-05-25 03:33:17 [INFO]: Epoch 154 - training loss: 0.2549, validation loss: 0.1110
2024-05-25 03:33:20 [INFO]: Epoch 155 - training loss: 0.2547, validation loss: 0.1107
2024-05-25 03:33:23 [INFO]: Epoch 156 - training loss: 0.2540, validation loss: 0.1107
2024-05-25 03:33:25 [INFO]: Epoch 157 - training loss: 0.2548, validation loss: 0.1105
2024-05-25 03:33:28 [INFO]: Epoch 158 - training loss: 0.2538, validation loss: 0.1102
2024-05-25 03:33:31 [INFO]: Epoch 159 - training loss: 0.2541, validation loss: 0.1100
2024-05-25 03:33:34 [INFO]: Epoch 160 - training loss: 0.2528, validation loss: 0.1098
2024-05-25 03:33:37 [INFO]: Epoch 161 - training loss: 0.2531, validation loss: 0.1097
2024-05-25 03:33:40 [INFO]: Epoch 162 - training loss: 0.2524, validation loss: 0.1096
2024-05-25 03:33:42 [INFO]: Epoch 163 - training loss: 0.2523, validation loss: 0.1094
2024-05-25 03:33:45 [INFO]: Epoch 164 - training loss: 0.2522, validation loss: 0.1090
2024-05-25 03:33:48 [INFO]: Epoch 165 - training loss: 0.2520, validation loss: 0.1087
2024-05-25 03:33:51 [INFO]: Epoch 166 - training loss: 0.2516, validation loss: 0.1087
2024-05-25 03:33:54 [INFO]: Epoch 167 - training loss: 0.2516, validation loss: 0.1086
2024-05-25 03:33:57 [INFO]: Epoch 168 - training loss: 0.2508, validation loss: 0.1085
2024-05-25 03:34:00 [INFO]: Epoch 169 - training loss: 0.2510, validation loss: 0.1082
2024-05-25 03:34:02 [INFO]: Epoch 170 - training loss: 0.2511, validation loss: 0.1082
2024-05-25 03:34:05 [INFO]: Epoch 171 - training loss: 0.2505, validation loss: 0.1079
2024-05-25 03:34:08 [INFO]: Epoch 172 - training loss: 0.2505, validation loss: 0.1076
2024-05-25 03:34:11 [INFO]: Epoch 173 - training loss: 0.2497, validation loss: 0.1076
2024-05-25 03:34:14 [INFO]: Epoch 174 - training loss: 0.2495, validation loss: 0.1074
2024-05-25 03:34:17 [INFO]: Epoch 175 - training loss: 0.2496, validation loss: 0.1074
2024-05-25 03:34:20 [INFO]: Epoch 176 - training loss: 0.2490, validation loss: 0.1069
2024-05-25 03:34:23 [INFO]: Epoch 177 - training loss: 0.2490, validation loss: 0.1070
2024-05-25 03:34:26 [INFO]: Epoch 178 - training loss: 0.2483, validation loss: 0.1070
2024-05-25 03:34:28 [INFO]: Epoch 179 - training loss: 0.2484, validation loss: 0.1067
2024-05-25 03:34:31 [INFO]: Epoch 180 - training loss: 0.2471, validation loss: 0.1066
2024-05-25 03:34:34 [INFO]: Epoch 181 - training loss: 0.2482, validation loss: 0.1065
2024-05-25 03:34:37 [INFO]: Epoch 182 - training loss: 0.2478, validation loss: 0.1063
2024-05-25 03:34:40 [INFO]: Epoch 183 - training loss: 0.2471, validation loss: 0.1060
2024-05-25 03:34:43 [INFO]: Epoch 184 - training loss: 0.2472, validation loss: 0.1060
2024-05-25 03:34:46 [INFO]: Epoch 185 - training loss: 0.2462, validation loss: 0.1059
2024-05-25 03:34:48 [INFO]: Epoch 186 - training loss: 0.2464, validation loss: 0.1057
2024-05-25 03:34:51 [INFO]: Epoch 187 - training loss: 0.2462, validation loss: 0.1058
2024-05-25 03:34:54 [INFO]: Epoch 188 - training loss: 0.2456, validation loss: 0.1057
2024-05-25 03:34:57 [INFO]: Epoch 189 - training loss: 0.2463, validation loss: 0.1054
2024-05-25 03:35:00 [INFO]: Epoch 190 - training loss: 0.2459, validation loss: 0.1054
2024-05-25 03:35:03 [INFO]: Epoch 191 - training loss: 0.2453, validation loss: 0.1052
2024-05-25 03:35:05 [INFO]: Epoch 192 - training loss: 0.2451, validation loss: 0.1051
2024-05-25 03:35:08 [INFO]: Epoch 193 - training loss: 0.2454, validation loss: 0.1048
2024-05-25 03:35:11 [INFO]: Epoch 194 - training loss: 0.2447, validation loss: 0.1049
2024-05-25 03:35:14 [INFO]: Epoch 195 - training loss: 0.2446, validation loss: 0.1047
2024-05-25 03:35:17 [INFO]: Epoch 196 - training loss: 0.2441, validation loss: 0.1045
2024-05-25 03:35:20 [INFO]: Epoch 197 - training loss: 0.2438, validation loss: 0.1046
2024-05-25 03:35:22 [INFO]: Epoch 198 - training loss: 0.2441, validation loss: 0.1043
2024-05-25 03:35:25 [INFO]: Epoch 199 - training loss: 0.2438, validation loss: 0.1042
2024-05-25 03:35:28 [INFO]: Epoch 200 - training loss: 0.2435, validation loss: 0.1042
2024-05-25 03:35:31 [INFO]: Epoch 201 - training loss: 0.2437, validation loss: 0.1040
2024-05-25 03:35:34 [INFO]: Epoch 202 - training loss: 0.2428, validation loss: 0.1040
2024-05-25 03:35:37 [INFO]: Epoch 203 - training loss: 0.2434, validation loss: 0.1039
2024-05-25 03:35:40 [INFO]: Epoch 204 - training loss: 0.2427, validation loss: 0.1037
2024-05-25 03:35:42 [INFO]: Epoch 205 - training loss: 0.2427, validation loss: 0.1036
2024-05-25 03:35:45 [INFO]: Epoch 206 - training loss: 0.2426, validation loss: 0.1035
2024-05-25 03:35:48 [INFO]: Epoch 207 - training loss: 0.2417, validation loss: 0.1037
2024-05-25 03:35:51 [INFO]: Epoch 208 - training loss: 0.2422, validation loss: 0.1035
2024-05-25 03:35:54 [INFO]: Epoch 209 - training loss: 0.2415, validation loss: 0.1032
2024-05-25 03:35:57 [INFO]: Epoch 210 - training loss: 0.2418, validation loss: 0.1030
2024-05-25 03:35:59 [INFO]: Epoch 211 - training loss: 0.2415, validation loss: 0.1030
2024-05-25 03:36:02 [INFO]: Epoch 212 - training loss: 0.2413, validation loss: 0.1031
2024-05-25 03:36:05 [INFO]: Epoch 213 - training loss: 0.2409, validation loss: 0.1029
2024-05-25 03:36:08 [INFO]: Epoch 214 - training loss: 0.2413, validation loss: 0.1028
2024-05-25 03:36:11 [INFO]: Epoch 215 - training loss: 0.2408, validation loss: 0.1027
2024-05-25 03:36:14 [INFO]: Epoch 216 - training loss: 0.2406, validation loss: 0.1026
2024-05-25 03:36:17 [INFO]: Epoch 217 - training loss: 0.2401, validation loss: 0.1025
2024-05-25 03:36:19 [INFO]: Epoch 218 - training loss: 0.2402, validation loss: 0.1024
2024-05-25 03:36:22 [INFO]: Epoch 219 - training loss: 0.2399, validation loss: 0.1025
2024-05-25 03:36:25 [INFO]: Epoch 220 - training loss: 0.2398, validation loss: 0.1023
2024-05-25 03:36:28 [INFO]: Epoch 221 - training loss: 0.2398, validation loss: 0.1022
2024-05-25 03:36:31 [INFO]: Epoch 222 - training loss: 0.2396, validation loss: 0.1020
2024-05-25 03:36:34 [INFO]: Epoch 223 - training loss: 0.2400, validation loss: 0.1020
2024-05-25 03:36:37 [INFO]: Epoch 224 - training loss: 0.2391, validation loss: 0.1020
2024-05-25 03:36:39 [INFO]: Epoch 225 - training loss: 0.2391, validation loss: 0.1020
2024-05-25 03:36:42 [INFO]: Epoch 226 - training loss: 0.2391, validation loss: 0.1018
2024-05-25 03:36:45 [INFO]: Epoch 227 - training loss: 0.2388, validation loss: 0.1018
2024-05-25 03:36:48 [INFO]: Epoch 228 - training loss: 0.2383, validation loss: 0.1018
2024-05-25 03:36:51 [INFO]: Epoch 229 - training loss: 0.2381, validation loss: 0.1018
2024-05-25 03:36:54 [INFO]: Epoch 230 - training loss: 0.2387, validation loss: 0.1017
2024-05-25 03:36:56 [INFO]: Epoch 231 - training loss: 0.2377, validation loss: 0.1015
2024-05-25 03:36:59 [INFO]: Epoch 232 - training loss: 0.2375, validation loss: 0.1013
2024-05-25 03:37:02 [INFO]: Epoch 233 - training loss: 0.2380, validation loss: 0.1013
2024-05-25 03:37:05 [INFO]: Epoch 234 - training loss: 0.2373, validation loss: 0.1011
2024-05-25 03:37:08 [INFO]: Epoch 235 - training loss: 0.2374, validation loss: 0.1012
2024-05-25 03:37:11 [INFO]: Epoch 236 - training loss: 0.2374, validation loss: 0.1011
2024-05-25 03:37:14 [INFO]: Epoch 237 - training loss: 0.2374, validation loss: 0.1010
2024-05-25 03:37:16 [INFO]: Epoch 238 - training loss: 0.2372, validation loss: 0.1010
2024-05-25 03:37:19 [INFO]: Epoch 239 - training loss: 0.2368, validation loss: 0.1009
2024-05-25 03:37:22 [INFO]: Epoch 240 - training loss: 0.2366, validation loss: 0.1009
2024-05-25 03:37:25 [INFO]: Epoch 241 - training loss: 0.2367, validation loss: 0.1008
2024-05-25 03:37:28 [INFO]: Epoch 242 - training loss: 0.2364, validation loss: 0.1008
2024-05-25 03:37:31 [INFO]: Epoch 243 - training loss: 0.2363, validation loss: 0.1005
2024-05-25 03:37:33 [INFO]: Epoch 244 - training loss: 0.2364, validation loss: 0.1007
2024-05-25 03:37:36 [INFO]: Epoch 245 - training loss: 0.2355, validation loss: 0.1005
2024-05-25 03:37:39 [INFO]: Epoch 246 - training loss: 0.2355, validation loss: 0.1006
2024-05-25 03:37:42 [INFO]: Epoch 247 - training loss: 0.2356, validation loss: 0.1005
2024-05-25 03:37:45 [INFO]: Epoch 248 - training loss: 0.2357, validation loss: 0.1005
2024-05-25 03:37:48 [INFO]: Epoch 249 - training loss: 0.2356, validation loss: 0.1004
2024-05-25 03:37:50 [INFO]: Epoch 250 - training loss: 0.2348, validation loss: 0.1003
2024-05-25 03:37:53 [INFO]: Epoch 251 - training loss: 0.2351, validation loss: 0.1003
2024-05-25 03:37:56 [INFO]: Epoch 252 - training loss: 0.2351, validation loss: 0.1001
2024-05-25 03:37:59 [INFO]: Epoch 253 - training loss: 0.2349, validation loss: 0.1002
2024-05-25 03:38:01 [INFO]: Epoch 254 - training loss: 0.2347, validation loss: 0.1001
2024-05-25 03:38:04 [INFO]: Epoch 255 - training loss: 0.2342, validation loss: 0.1002
2024-05-25 03:38:07 [INFO]: Epoch 256 - training loss: 0.2344, validation loss: 0.1000
2024-05-25 03:38:10 [INFO]: Epoch 257 - training loss: 0.2344, validation loss: 0.0999
2024-05-25 03:38:13 [INFO]: Epoch 258 - training loss: 0.2343, validation loss: 0.0999
2024-05-25 03:38:16 [INFO]: Epoch 259 - training loss: 0.2339, validation loss: 0.0999
2024-05-25 03:38:19 [INFO]: Epoch 260 - training loss: 0.2339, validation loss: 0.0999
2024-05-25 03:38:21 [INFO]: Epoch 261 - training loss: 0.2336, validation loss: 0.0999
2024-05-25 03:38:24 [INFO]: Epoch 262 - training loss: 0.2338, validation loss: 0.0997
2024-05-25 03:38:27 [INFO]: Epoch 263 - training loss: 0.2332, validation loss: 0.0997
2024-05-25 03:38:30 [INFO]: Epoch 264 - training loss: 0.2332, validation loss: 0.0997
2024-05-25 03:38:33 [INFO]: Epoch 265 - training loss: 0.2330, validation loss: 0.0996
2024-05-25 03:38:36 [INFO]: Epoch 266 - training loss: 0.2329, validation loss: 0.0993
2024-05-25 03:38:39 [INFO]: Epoch 267 - training loss: 0.2328, validation loss: 0.0995
2024-05-25 03:38:41 [INFO]: Epoch 268 - training loss: 0.2329, validation loss: 0.0995
2024-05-25 03:38:44 [INFO]: Epoch 269 - training loss: 0.2325, validation loss: 0.0992
2024-05-25 03:38:47 [INFO]: Epoch 270 - training loss: 0.2325, validation loss: 0.0995
2024-05-25 03:38:50 [INFO]: Epoch 271 - training loss: 0.2324, validation loss: 0.0995
2024-05-25 03:38:53 [INFO]: Epoch 272 - training loss: 0.2322, validation loss: 0.0995
2024-05-25 03:38:56 [INFO]: Epoch 273 - training loss: 0.2320, validation loss: 0.0993
2024-05-25 03:38:58 [INFO]: Epoch 274 - training loss: 0.2317, validation loss: 0.0991
2024-05-25 03:39:01 [INFO]: Epoch 275 - training loss: 0.2322, validation loss: 0.0990
2024-05-25 03:39:04 [INFO]: Epoch 276 - training loss: 0.2323, validation loss: 0.0992
2024-05-25 03:39:07 [INFO]: Epoch 277 - training loss: 0.2320, validation loss: 0.0991
2024-05-25 03:39:10 [INFO]: Epoch 278 - training loss: 0.2316, validation loss: 0.0989
2024-05-25 03:39:13 [INFO]: Epoch 279 - training loss: 0.2316, validation loss: 0.0989
2024-05-25 03:39:16 [INFO]: Epoch 280 - training loss: 0.2314, validation loss: 0.0989
2024-05-25 03:39:18 [INFO]: Epoch 281 - training loss: 0.2311, validation loss: 0.0990
2024-05-25 03:39:21 [INFO]: Epoch 282 - training loss: 0.2313, validation loss: 0.0991
2024-05-25 03:39:24 [INFO]: Epoch 283 - training loss: 0.2310, validation loss: 0.0988
2024-05-25 03:39:27 [INFO]: Epoch 284 - training loss: 0.2313, validation loss: 0.0988
2024-05-25 03:39:30 [INFO]: Epoch 285 - training loss: 0.2307, validation loss: 0.0987
2024-05-25 03:39:33 [INFO]: Epoch 286 - training loss: 0.2306, validation loss: 0.0988
2024-05-25 03:39:35 [INFO]: Epoch 287 - training loss: 0.2310, validation loss: 0.0987
2024-05-25 03:39:38 [INFO]: Epoch 288 - training loss: 0.2305, validation loss: 0.0988
2024-05-25 03:39:41 [INFO]: Epoch 289 - training loss: 0.2305, validation loss: 0.0987
2024-05-25 03:39:44 [INFO]: Epoch 290 - training loss: 0.2304, validation loss: 0.0986
2024-05-25 03:39:47 [INFO]: Epoch 291 - training loss: 0.2306, validation loss: 0.0986
2024-05-25 03:39:50 [INFO]: Epoch 292 - training loss: 0.2301, validation loss: 0.0987
2024-05-25 03:39:53 [INFO]: Epoch 293 - training loss: 0.2303, validation loss: 0.0986
2024-05-25 03:39:55 [INFO]: Epoch 294 - training loss: 0.2303, validation loss: 0.0986
2024-05-25 03:39:58 [INFO]: Epoch 295 - training loss: 0.2293, validation loss: 0.0986
2024-05-25 03:40:01 [INFO]: Epoch 296 - training loss: 0.2300, validation loss: 0.0985
2024-05-25 03:40:04 [INFO]: Epoch 297 - training loss: 0.2302, validation loss: 0.0985
2024-05-25 03:40:07 [INFO]: Epoch 298 - training loss: 0.2295, validation loss: 0.0984
2024-05-25 03:40:10 [INFO]: Epoch 299 - training loss: 0.2291, validation loss: 0.0983
2024-05-25 03:40:12 [INFO]: Epoch 300 - training loss: 0.2293, validation loss: 0.0983
2024-05-25 03:40:12 [INFO]: Finished training. The best model is from epoch#300.
2024-05-25 03:40:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/BRITS_air_quality/20240525_T032559/BRITS.pypots
2024-05-25 03:40:13 [INFO]: BRITS on Air-Quality: MAE=0.1364, MSE=0.0956
2024-05-25 03:40:13 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/BRITS_air_quality/imputation.pkl
2024-05-25 03:40:13 [INFO]: Using the given device: cuda:0
2024-05-25 03:40:13 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013
2024-05-25 03:40:13 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/tensorboard
2024-05-25 03:40:13 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 03:40:18 [INFO]: Epoch 001 - training loss: 1.4168, validation loss: 0.7874
2024-05-25 03:40:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch1_loss0.7873849868774414.pypots
2024-05-25 03:40:22 [INFO]: Epoch 002 - training loss: 1.0597, validation loss: 0.7396
2024-05-25 03:40:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch2_loss0.7396221280097961.pypots
2024-05-25 03:40:26 [INFO]: Epoch 003 - training loss: 0.9870, validation loss: 0.7195
2024-05-25 03:40:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch3_loss0.7194537967443466.pypots
2024-05-25 03:40:30 [INFO]: Epoch 004 - training loss: 0.9729, validation loss: 0.7074
2024-05-25 03:40:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch4_loss0.7073822826147079.pypots
2024-05-25 03:40:34 [INFO]: Epoch 005 - training loss: 0.9428, validation loss: 0.6984
2024-05-25 03:40:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch5_loss0.69836066365242.pypots
2024-05-25 03:40:38 [INFO]: Epoch 006 - training loss: 0.9383, validation loss: 0.6927
2024-05-25 03:40:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch6_loss0.6927174597978591.pypots
2024-05-25 03:40:41 [INFO]: Epoch 007 - training loss: 0.9348, validation loss: 0.6878
2024-05-25 03:40:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch7_loss0.6877823531627655.pypots
2024-05-25 03:40:45 [INFO]: Epoch 008 - training loss: 0.9392, validation loss: 0.6839
2024-05-25 03:40:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch8_loss0.6839252531528472.pypots
2024-05-25 03:40:49 [INFO]: Epoch 009 - training loss: 0.9174, validation loss: 0.6818
2024-05-25 03:40:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch9_loss0.6817614525556565.pypots
2024-05-25 03:40:53 [INFO]: Epoch 010 - training loss: 0.9183, validation loss: 0.6782
2024-05-25 03:40:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch10_loss0.6782384902238846.pypots
2024-05-25 03:40:57 [INFO]: Epoch 011 - training loss: 0.9003, validation loss: 0.6766
2024-05-25 03:40:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch11_loss0.6765503644943237.pypots
2024-05-25 03:41:01 [INFO]: Epoch 012 - training loss: 0.9148, validation loss: 0.6752
2024-05-25 03:41:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch12_loss0.6752153426408768.pypots
2024-05-25 03:41:05 [INFO]: Epoch 013 - training loss: 0.9433, validation loss: 0.6738
2024-05-25 03:41:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch13_loss0.6738322019577027.pypots
2024-05-25 03:41:09 [INFO]: Epoch 014 - training loss: 0.9068, validation loss: 0.6741
2024-05-25 03:41:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch14_loss0.6740588396787643.pypots
2024-05-25 03:41:13 [INFO]: Epoch 015 - training loss: 0.9058, validation loss: 0.6728
2024-05-25 03:41:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch15_loss0.6727938562631607.pypots
2024-05-25 03:41:17 [INFO]: Epoch 016 - training loss: 0.8928, validation loss: 0.6730
2024-05-25 03:41:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch16_loss0.6730379551649094.pypots
2024-05-25 03:41:21 [INFO]: Epoch 017 - training loss: 0.8918, validation loss: 0.6730
2024-05-25 03:41:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch17_loss0.6729977935552597.pypots
2024-05-25 03:41:24 [INFO]: Epoch 018 - training loss: 0.8822, validation loss: 0.6724
2024-05-25 03:41:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch18_loss0.6723759442567825.pypots
2024-05-25 03:41:28 [INFO]: Epoch 019 - training loss: 0.8738, validation loss: 0.6715
2024-05-25 03:41:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch19_loss0.6714922070503235.pypots
2024-05-25 03:41:32 [INFO]: Epoch 020 - training loss: 0.9010, validation loss: 0.6724
2024-05-25 03:41:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch20_loss0.6724389940500259.pypots
2024-05-25 03:41:36 [INFO]: Epoch 021 - training loss: 0.9021, validation loss: 0.6731
2024-05-25 03:41:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch21_loss0.6730689734220505.pypots
2024-05-25 03:41:40 [INFO]: Epoch 022 - training loss: 0.9116, validation loss: 0.6727
2024-05-25 03:41:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch22_loss0.6727197468280792.pypots
2024-05-25 03:41:44 [INFO]: Epoch 023 - training loss: 0.9144, validation loss: 0.6715
2024-05-25 03:41:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch23_loss0.6714991897344589.pypots
2024-05-25 03:41:48 [INFO]: Epoch 024 - training loss: 0.8826, validation loss: 0.6745
2024-05-25 03:41:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch24_loss0.6745349675416946.pypots
2024-05-25 03:41:52 [INFO]: Epoch 025 - training loss: 0.8872, validation loss: 0.6737
2024-05-25 03:41:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch25_loss0.6736646682024002.pypots
2024-05-25 03:41:56 [INFO]: Epoch 026 - training loss: 0.8682, validation loss: 0.6747
2024-05-25 03:41:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch26_loss0.6747211873531341.pypots
2024-05-25 03:42:00 [INFO]: Epoch 027 - training loss: 0.8792, validation loss: 0.6741
2024-05-25 03:42:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch27_loss0.6741293519735336.pypots
2024-05-25 03:42:04 [INFO]: Epoch 028 - training loss: 0.8710, validation loss: 0.6726
2024-05-25 03:42:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch28_loss0.6725877493619918.pypots
2024-05-25 03:42:07 [INFO]: Epoch 029 - training loss: 0.8616, validation loss: 0.6785
2024-05-25 03:42:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN_epoch29_loss0.6784620314836503.pypots
2024-05-25 03:42:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:42:07 [INFO]: Finished training. The best model is from epoch#19.
2024-05-25 03:42:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T034013/MRNN.pypots
2024-05-25 03:42:08 [INFO]: MRNN on Air-Quality: MAE=0.5209, MSE=0.6059
2024-05-25 03:42:08 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/MRNN_air_quality/imputation.pkl
2024-05-25 03:42:08 [INFO]: Using the given device: cpu
2024-05-25 03:42:08 [INFO]: LOCF on Air-Quality: MAE=0.1979, MSE=0.2108
2024-05-25 03:42:08 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_air_quality".
2024-05-25 03:42:08 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/LOCF_air_quality/imputation.pkl
2024-05-25 03:42:08 [INFO]: Median on Air-Quality: MAE=0.6603, MSE=0.9901
2024-05-25 03:42:08 [INFO]: Successfully created the given path "saved_results/round_4/Median_air_quality".
2024-05-25 03:42:08 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/Median_air_quality/imputation.pkl
2024-05-25 03:42:08 [INFO]: Mean on Air-Quality: MAE=0.6916, MSE=0.9314
2024-05-25 03:42:08 [INFO]: Successfully created the given path "saved_results/round_4/Mean_air_quality".
2024-05-25 03:42:08 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/Mean_air_quality/imputation.pkl
2024-05-25 03:42:08 [INFO]: 
SAITS on data/air_quality: MAE=0.1420.0033658338602070965, MSE=0.0980.0029669163991614734
Transformer on data/air_quality: MAE=0.1600.004396997575609712, MSE=0.1200.0063885596954346945
TimesNet on data/air_quality: MAE=0.1540.002833760774203755, MSE=0.1220.0033541615548612364
CSDI on data/air_quality: MAE=0.1050.010451372032114752, MSE=0.1910.13765701922253104
GPVAE on data/air_quality: MAE=0.2750.007054507838312046, MSE=0.2210.010833853551535754
USGAN on data/air_quality: MAE=0.1550.0026264011597751597, MSE=0.1000.0016834623737570092
BRITS on data/air_quality: MAE=0.1370.0006695883351812699, MSE=0.0950.0006502559565800588
MRNN on data/air_quality: MAE=0.5200.0015446018901457378, MSE=0.6050.0023570371151997063
LOCF on data/air_quality: MAE=0.1980.0, MSE=0.2110.0
Median on data/air_quality: MAE=0.6600.0, MSE=0.9901.1102230246251565e-16
Mean on data/air_quality: MAE=0.6920.0, MSE=0.9310.0

