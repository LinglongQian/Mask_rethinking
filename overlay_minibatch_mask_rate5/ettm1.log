2024-05-24 22:45:20 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-24 22:45:20 [INFO]: Using the given device: cuda:0
2024-05-24 22:45:20 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/SAITS_ettm1/20240524_T224520
2024-05-24 22:45:20 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/SAITS_ettm1/20240524_T224520/tensorboard
2024-05-24 22:45:20 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 22:45:26 [INFO]: Epoch 001 - training loss: 1.2206, validation loss: 0.2704
2024-05-24 22:45:26 [INFO]: Epoch 002 - training loss: 0.8988, validation loss: 0.1283
2024-05-24 22:45:27 [INFO]: Epoch 003 - training loss: 0.8165, validation loss: 0.0875
2024-05-24 22:45:27 [INFO]: Epoch 004 - training loss: 0.7383, validation loss: 0.0863
2024-05-24 22:45:28 [INFO]: Epoch 005 - training loss: 0.7019, validation loss: 0.0816
2024-05-24 22:45:28 [INFO]: Epoch 006 - training loss: 0.6657, validation loss: 0.0659
2024-05-24 22:45:29 [INFO]: Epoch 007 - training loss: 0.6542, validation loss: 0.0595
2024-05-24 22:45:29 [INFO]: Epoch 008 - training loss: 0.6333, validation loss: 0.0740
2024-05-24 22:45:30 [INFO]: Epoch 009 - training loss: 0.6200, validation loss: 0.0578
2024-05-24 22:45:30 [INFO]: Epoch 010 - training loss: 0.6082, validation loss: 0.0755
2024-05-24 22:45:31 [INFO]: Epoch 011 - training loss: 0.6070, validation loss: 0.0641
2024-05-24 22:45:31 [INFO]: Epoch 012 - training loss: 0.5906, validation loss: 0.0603
2024-05-24 22:45:32 [INFO]: Epoch 013 - training loss: 0.5929, validation loss: 0.0537
2024-05-24 22:45:32 [INFO]: Epoch 014 - training loss: 0.5651, validation loss: 0.0440
2024-05-24 22:45:33 [INFO]: Epoch 015 - training loss: 0.5591, validation loss: 0.0534
2024-05-24 22:45:33 [INFO]: Epoch 016 - training loss: 0.5566, validation loss: 0.0504
2024-05-24 22:45:34 [INFO]: Epoch 017 - training loss: 0.5651, validation loss: 0.0529
2024-05-24 22:45:34 [INFO]: Epoch 018 - training loss: 0.5408, validation loss: 0.0486
2024-05-24 22:45:35 [INFO]: Epoch 019 - training loss: 0.5349, validation loss: 0.0695
2024-05-24 22:45:35 [INFO]: Epoch 020 - training loss: 0.5433, validation loss: 0.0521
2024-05-24 22:45:36 [INFO]: Epoch 021 - training loss: 0.5360, validation loss: 0.0385
2024-05-24 22:45:36 [INFO]: Epoch 022 - training loss: 0.5201, validation loss: 0.0364
2024-05-24 22:45:37 [INFO]: Epoch 023 - training loss: 0.5230, validation loss: 0.1299
2024-05-24 22:45:37 [INFO]: Epoch 024 - training loss: 0.5592, validation loss: 0.0424
2024-05-24 22:45:38 [INFO]: Epoch 025 - training loss: 0.5331, validation loss: 0.0527
2024-05-24 22:45:38 [INFO]: Epoch 026 - training loss: 0.5013, validation loss: 0.0357
2024-05-24 22:45:39 [INFO]: Epoch 027 - training loss: 0.4997, validation loss: 0.0376
2024-05-24 22:45:39 [INFO]: Epoch 028 - training loss: 0.4918, validation loss: 0.0414
2024-05-24 22:45:40 [INFO]: Epoch 029 - training loss: 0.4978, validation loss: 0.0364
2024-05-24 22:45:40 [INFO]: Epoch 030 - training loss: 0.4869, validation loss: 0.0398
2024-05-24 22:45:41 [INFO]: Epoch 031 - training loss: 0.4815, validation loss: 0.0378
2024-05-24 22:45:41 [INFO]: Epoch 032 - training loss: 0.4779, validation loss: 0.0448
2024-05-24 22:45:42 [INFO]: Epoch 033 - training loss: 0.4871, validation loss: 0.0352
2024-05-24 22:45:42 [INFO]: Epoch 034 - training loss: 0.4868, validation loss: 0.0344
2024-05-24 22:45:43 [INFO]: Epoch 035 - training loss: 0.4692, validation loss: 0.0372
2024-05-24 22:45:43 [INFO]: Epoch 036 - training loss: 0.4946, validation loss: 0.0617
2024-05-24 22:45:44 [INFO]: Epoch 037 - training loss: 0.4863, validation loss: 0.0395
2024-05-24 22:45:44 [INFO]: Epoch 038 - training loss: 0.4793, validation loss: 0.0412
2024-05-24 22:45:45 [INFO]: Epoch 039 - training loss: 0.4578, validation loss: 0.0424
2024-05-24 22:45:45 [INFO]: Epoch 040 - training loss: 0.4656, validation loss: 0.0384
2024-05-24 22:45:46 [INFO]: Epoch 041 - training loss: 0.4557, validation loss: 0.0371
2024-05-24 22:45:46 [INFO]: Epoch 042 - training loss: 0.4595, validation loss: 0.0390
2024-05-24 22:45:47 [INFO]: Epoch 043 - training loss: 0.4577, validation loss: 0.0393
2024-05-24 22:45:47 [INFO]: Epoch 044 - training loss: 0.4490, validation loss: 0.0287
2024-05-24 22:45:48 [INFO]: Epoch 045 - training loss: 0.4601, validation loss: 0.0413
2024-05-24 22:45:48 [INFO]: Epoch 046 - training loss: 0.4536, validation loss: 0.0307
2024-05-24 22:45:49 [INFO]: Epoch 047 - training loss: 0.4382, validation loss: 0.0359
2024-05-24 22:45:49 [INFO]: Epoch 048 - training loss: 0.4310, validation loss: 0.0251
2024-05-24 22:45:50 [INFO]: Epoch 049 - training loss: 0.4353, validation loss: 0.0320
2024-05-24 22:45:50 [INFO]: Epoch 050 - training loss: 0.4393, validation loss: 0.0376
2024-05-24 22:45:51 [INFO]: Epoch 051 - training loss: 0.4293, validation loss: 0.0291
2024-05-24 22:45:51 [INFO]: Epoch 052 - training loss: 0.4367, validation loss: 0.0336
2024-05-24 22:45:52 [INFO]: Epoch 053 - training loss: 0.4206, validation loss: 0.0319
2024-05-24 22:45:52 [INFO]: Epoch 054 - training loss: 0.4137, validation loss: 0.0280
2024-05-24 22:45:53 [INFO]: Epoch 055 - training loss: 0.4206, validation loss: 0.0326
2024-05-24 22:45:53 [INFO]: Epoch 056 - training loss: 0.4152, validation loss: 0.0292
2024-05-24 22:45:54 [INFO]: Epoch 057 - training loss: 0.4153, validation loss: 0.0268
2024-05-24 22:45:54 [INFO]: Epoch 058 - training loss: 0.4068, validation loss: 0.0278
2024-05-24 22:45:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:45:54 [INFO]: Finished training. The best model is from epoch#48.
2024-05-24 22:45:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/SAITS_ettm1/20240524_T224520/SAITS.pypots
2024-05-24 22:45:55 [INFO]: SAITS on ETTm1: MAE=0.1250, MSE=0.0313
2024-05-24 22:45:55 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/SAITS_ettm1/imputation.pkl
2024-05-24 22:45:55 [INFO]: Using the given device: cuda:0
2024-05-24 22:45:55 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/Transformer_ettm1/20240524_T224555
2024-05-24 22:45:55 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/Transformer_ettm1/20240524_T224555/tensorboard
2024-05-24 22:45:55 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 22:45:55 [INFO]: Epoch 001 - training loss: 1.2383, validation loss: 0.3623
2024-05-24 22:45:55 [INFO]: Epoch 002 - training loss: 0.7186, validation loss: 0.1676
2024-05-24 22:45:55 [INFO]: Epoch 003 - training loss: 0.5820, validation loss: 0.1149
2024-05-24 22:45:55 [INFO]: Epoch 004 - training loss: 0.5236, validation loss: 0.0811
2024-05-24 22:45:56 [INFO]: Epoch 005 - training loss: 0.4815, validation loss: 0.0723
2024-05-24 22:45:56 [INFO]: Epoch 006 - training loss: 0.4546, validation loss: 0.0607
2024-05-24 22:45:56 [INFO]: Epoch 007 - training loss: 0.4335, validation loss: 0.0608
2024-05-24 22:45:56 [INFO]: Epoch 008 - training loss: 0.4250, validation loss: 0.0566
2024-05-24 22:45:56 [INFO]: Epoch 009 - training loss: 0.4061, validation loss: 0.0625
2024-05-24 22:45:57 [INFO]: Epoch 010 - training loss: 0.3929, validation loss: 0.0529
2024-05-24 22:45:57 [INFO]: Epoch 011 - training loss: 0.3818, validation loss: 0.0457
2024-05-24 22:45:57 [INFO]: Epoch 012 - training loss: 0.3720, validation loss: 0.0456
2024-05-24 22:45:57 [INFO]: Epoch 013 - training loss: 0.3670, validation loss: 0.0510
2024-05-24 22:45:58 [INFO]: Epoch 014 - training loss: 0.3540, validation loss: 0.0451
2024-05-24 22:45:58 [INFO]: Epoch 015 - training loss: 0.3471, validation loss: 0.0495
2024-05-24 22:45:58 [INFO]: Epoch 016 - training loss: 0.3463, validation loss: 0.0411
2024-05-24 22:45:58 [INFO]: Epoch 017 - training loss: 0.3342, validation loss: 0.0411
2024-05-24 22:45:58 [INFO]: Epoch 018 - training loss: 0.3297, validation loss: 0.0437
2024-05-24 22:45:59 [INFO]: Epoch 019 - training loss: 0.3298, validation loss: 0.0369
2024-05-24 22:45:59 [INFO]: Epoch 020 - training loss: 0.3151, validation loss: 0.0365
2024-05-24 22:45:59 [INFO]: Epoch 021 - training loss: 0.3109, validation loss: 0.0342
2024-05-24 22:45:59 [INFO]: Epoch 022 - training loss: 0.3135, validation loss: 0.0436
2024-05-24 22:45:59 [INFO]: Epoch 023 - training loss: 0.3124, validation loss: 0.0342
2024-05-24 22:46:00 [INFO]: Epoch 024 - training loss: 0.3068, validation loss: 0.0348
2024-05-24 22:46:00 [INFO]: Epoch 025 - training loss: 0.3069, validation loss: 0.0355
2024-05-24 22:46:00 [INFO]: Epoch 026 - training loss: 0.3022, validation loss: 0.0318
2024-05-24 22:46:00 [INFO]: Epoch 027 - training loss: 0.2869, validation loss: 0.0303
2024-05-24 22:46:01 [INFO]: Epoch 028 - training loss: 0.2902, validation loss: 0.0340
2024-05-24 22:46:01 [INFO]: Epoch 029 - training loss: 0.2910, validation loss: 0.0313
2024-05-24 22:46:01 [INFO]: Epoch 030 - training loss: 0.2823, validation loss: 0.0323
2024-05-24 22:46:01 [INFO]: Epoch 031 - training loss: 0.2789, validation loss: 0.0295
2024-05-24 22:46:01 [INFO]: Epoch 032 - training loss: 0.2825, validation loss: 0.0397
2024-05-24 22:46:02 [INFO]: Epoch 033 - training loss: 0.2920, validation loss: 0.0374
2024-05-24 22:46:02 [INFO]: Epoch 034 - training loss: 0.2964, validation loss: 0.0297
2024-05-24 22:46:02 [INFO]: Epoch 035 - training loss: 0.2653, validation loss: 0.0263
2024-05-24 22:46:02 [INFO]: Epoch 036 - training loss: 0.2653, validation loss: 0.0259
2024-05-24 22:46:02 [INFO]: Epoch 037 - training loss: 0.2651, validation loss: 0.0281
2024-05-24 22:46:03 [INFO]: Epoch 038 - training loss: 0.2633, validation loss: 0.0261
2024-05-24 22:46:03 [INFO]: Epoch 039 - training loss: 0.2578, validation loss: 0.0323
2024-05-24 22:46:03 [INFO]: Epoch 040 - training loss: 0.2613, validation loss: 0.0276
2024-05-24 22:46:03 [INFO]: Epoch 041 - training loss: 0.2579, validation loss: 0.0250
2024-05-24 22:46:04 [INFO]: Epoch 042 - training loss: 0.2500, validation loss: 0.0286
2024-05-24 22:46:04 [INFO]: Epoch 043 - training loss: 0.2509, validation loss: 0.0302
2024-05-24 22:46:04 [INFO]: Epoch 044 - training loss: 0.2546, validation loss: 0.0246
2024-05-24 22:46:04 [INFO]: Epoch 045 - training loss: 0.2436, validation loss: 0.0270
2024-05-24 22:46:04 [INFO]: Epoch 046 - training loss: 0.2461, validation loss: 0.0251
2024-05-24 22:46:05 [INFO]: Epoch 047 - training loss: 0.2445, validation loss: 0.0237
2024-05-24 22:46:05 [INFO]: Epoch 048 - training loss: 0.2430, validation loss: 0.0237
2024-05-24 22:46:05 [INFO]: Epoch 049 - training loss: 0.2400, validation loss: 0.0243
2024-05-24 22:46:05 [INFO]: Epoch 050 - training loss: 0.2333, validation loss: 0.0245
2024-05-24 22:46:05 [INFO]: Epoch 051 - training loss: 0.2384, validation loss: 0.0254
2024-05-24 22:46:06 [INFO]: Epoch 052 - training loss: 0.2383, validation loss: 0.0228
2024-05-24 22:46:06 [INFO]: Epoch 053 - training loss: 0.2348, validation loss: 0.0285
2024-05-24 22:46:06 [INFO]: Epoch 054 - training loss: 0.2449, validation loss: 0.0249
2024-05-24 22:46:06 [INFO]: Epoch 055 - training loss: 0.2327, validation loss: 0.0228
2024-05-24 22:46:07 [INFO]: Epoch 056 - training loss: 0.2257, validation loss: 0.0240
2024-05-24 22:46:07 [INFO]: Epoch 057 - training loss: 0.2265, validation loss: 0.0204
2024-05-24 22:46:07 [INFO]: Epoch 058 - training loss: 0.2267, validation loss: 0.0222
2024-05-24 22:46:07 [INFO]: Epoch 059 - training loss: 0.2266, validation loss: 0.0225
2024-05-24 22:46:07 [INFO]: Epoch 060 - training loss: 0.2200, validation loss: 0.0239
2024-05-24 22:46:08 [INFO]: Epoch 061 - training loss: 0.2226, validation loss: 0.0205
2024-05-24 22:46:08 [INFO]: Epoch 062 - training loss: 0.2157, validation loss: 0.0217
2024-05-24 22:46:08 [INFO]: Epoch 063 - training loss: 0.2204, validation loss: 0.0217
2024-05-24 22:46:08 [INFO]: Epoch 064 - training loss: 0.2214, validation loss: 0.0209
2024-05-24 22:46:08 [INFO]: Epoch 065 - training loss: 0.2156, validation loss: 0.0206
2024-05-24 22:46:09 [INFO]: Epoch 066 - training loss: 0.2107, validation loss: 0.0209
2024-05-24 22:46:09 [INFO]: Epoch 067 - training loss: 0.2106, validation loss: 0.0243
2024-05-24 22:46:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:46:09 [INFO]: Finished training. The best model is from epoch#57.
2024-05-24 22:46:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/Transformer_ettm1/20240524_T224555/Transformer.pypots
2024-05-24 22:46:09 [INFO]: Transformer on ETTm1: MAE=0.1247, MSE=0.0292
2024-05-24 22:46:09 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/Transformer_ettm1/imputation.pkl
2024-05-24 22:46:09 [INFO]: Using the given device: cuda:0
2024-05-24 22:46:09 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/TimesNet_ettm1/20240524_T224609
2024-05-24 22:46:09 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/TimesNet_ettm1/20240524_T224609/tensorboard
2024-05-24 22:46:09 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 22:46:10 [INFO]: Epoch 001 - training loss: 0.1584, validation loss: 0.0476
2024-05-24 22:46:10 [INFO]: Epoch 002 - training loss: 0.0679, validation loss: 0.0414
2024-05-24 22:46:10 [INFO]: Epoch 003 - training loss: 0.0589, validation loss: 0.0365
2024-05-24 22:46:10 [INFO]: Epoch 004 - training loss: 0.0486, validation loss: 0.0328
2024-05-24 22:46:11 [INFO]: Epoch 005 - training loss: 0.0463, validation loss: 0.0292
2024-05-24 22:46:11 [INFO]: Epoch 006 - training loss: 0.0445, validation loss: 0.0311
2024-05-24 22:46:11 [INFO]: Epoch 007 - training loss: 0.0441, validation loss: 0.0332
2024-05-24 22:46:11 [INFO]: Epoch 008 - training loss: 0.0491, validation loss: 0.0327
2024-05-24 22:46:11 [INFO]: Epoch 009 - training loss: 0.0473, validation loss: 0.0292
2024-05-24 22:46:12 [INFO]: Epoch 010 - training loss: 0.0421, validation loss: 0.0319
2024-05-24 22:46:12 [INFO]: Epoch 011 - training loss: 0.0441, validation loss: 0.0321
2024-05-24 22:46:12 [INFO]: Epoch 012 - training loss: 0.0404, validation loss: 0.0270
2024-05-24 22:46:12 [INFO]: Epoch 013 - training loss: 0.0409, validation loss: 0.0290
2024-05-24 22:46:12 [INFO]: Epoch 014 - training loss: 0.0421, validation loss: 0.0339
2024-05-24 22:46:13 [INFO]: Epoch 015 - training loss: 0.0413, validation loss: 0.0285
2024-05-24 22:46:13 [INFO]: Epoch 016 - training loss: 0.0393, validation loss: 0.0278
2024-05-24 22:46:13 [INFO]: Epoch 017 - training loss: 0.0402, validation loss: 0.0261
2024-05-24 22:46:13 [INFO]: Epoch 018 - training loss: 0.0409, validation loss: 0.0278
2024-05-24 22:46:13 [INFO]: Epoch 019 - training loss: 0.0405, validation loss: 0.0277
2024-05-24 22:46:14 [INFO]: Epoch 020 - training loss: 0.0394, validation loss: 0.0280
2024-05-24 22:46:14 [INFO]: Epoch 021 - training loss: 0.0394, validation loss: 0.0264
2024-05-24 22:46:14 [INFO]: Epoch 022 - training loss: 0.0398, validation loss: 0.0265
2024-05-24 22:46:14 [INFO]: Epoch 023 - training loss: 0.0390, validation loss: 0.0281
2024-05-24 22:46:15 [INFO]: Epoch 024 - training loss: 0.0393, validation loss: 0.0266
2024-05-24 22:46:15 [INFO]: Epoch 025 - training loss: 0.0436, validation loss: 0.0317
2024-05-24 22:46:15 [INFO]: Epoch 026 - training loss: 0.0515, validation loss: 0.0340
2024-05-24 22:46:15 [INFO]: Epoch 027 - training loss: 0.0509, validation loss: 0.0317
2024-05-24 22:46:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:46:15 [INFO]: Finished training. The best model is from epoch#17.
2024-05-24 22:46:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/TimesNet_ettm1/20240524_T224609/TimesNet.pypots
2024-05-24 22:46:15 [INFO]: TimesNet on ETTm1: MAE=0.1256, MSE=0.0315
2024-05-24 22:46:15 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/TimesNet_ettm1/imputation.pkl
2024-05-24 22:46:15 [INFO]: Using the given device: cuda:0
2024-05-24 22:46:15 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615
2024-05-24 22:46:15 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/tensorboard
2024-05-24 22:46:15 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 22:46:17 [INFO]: Epoch 001 - training loss: 0.6652, validation loss: 0.4793
2024-05-24 22:46:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch1_loss0.47934920340776443.pypots
2024-05-24 22:46:20 [INFO]: Epoch 002 - training loss: 0.3565, validation loss: 0.3663
2024-05-24 22:46:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch2_loss0.36628151684999466.pypots
2024-05-24 22:46:22 [INFO]: Epoch 003 - training loss: 0.3261, validation loss: 0.3457
2024-05-24 22:46:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch3_loss0.34573354572057724.pypots
2024-05-24 22:46:24 [INFO]: Epoch 004 - training loss: 0.3327, validation loss: 0.3381
2024-05-24 22:46:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch4_loss0.3381146043539047.pypots
2024-05-24 22:46:26 [INFO]: Epoch 005 - training loss: 0.2681, validation loss: 0.3110
2024-05-24 22:46:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch5_loss0.3109651878476143.pypots
2024-05-24 22:46:28 [INFO]: Epoch 006 - training loss: 0.3224, validation loss: 0.2928
2024-05-24 22:46:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch6_loss0.29277750104665756.pypots
2024-05-24 22:46:30 [INFO]: Epoch 007 - training loss: 0.2871, validation loss: 0.2784
2024-05-24 22:46:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch7_loss0.27838144451379776.pypots
2024-05-24 22:46:32 [INFO]: Epoch 008 - training loss: 0.2869, validation loss: 0.2723
2024-05-24 22:46:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch8_loss0.27232684940099716.pypots
2024-05-24 22:46:34 [INFO]: Epoch 009 - training loss: 0.3182, validation loss: 0.2736
2024-05-24 22:46:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch9_loss0.27360495924949646.pypots
2024-05-24 22:46:36 [INFO]: Epoch 010 - training loss: 0.2854, validation loss: 0.2618
2024-05-24 22:46:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch10_loss0.2617541030049324.pypots
2024-05-24 22:46:38 [INFO]: Epoch 011 - training loss: 0.2739, validation loss: 0.2618
2024-05-24 22:46:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch11_loss0.2618097513914108.pypots
2024-05-24 22:46:40 [INFO]: Epoch 012 - training loss: 0.2328, validation loss: 0.2448
2024-05-24 22:46:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch12_loss0.24478759989142418.pypots
2024-05-24 22:46:42 [INFO]: Epoch 013 - training loss: 0.2099, validation loss: 0.2420
2024-05-24 22:46:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch13_loss0.241995457559824.pypots
2024-05-24 22:46:44 [INFO]: Epoch 014 - training loss: 0.2927, validation loss: 0.2477
2024-05-24 22:46:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch14_loss0.2476608343422413.pypots
2024-05-24 22:46:47 [INFO]: Epoch 015 - training loss: 0.2554, validation loss: 0.2594
2024-05-24 22:46:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch15_loss0.25941046327352524.pypots
2024-05-24 22:46:49 [INFO]: Epoch 016 - training loss: 0.2631, validation loss: 0.2314
2024-05-24 22:46:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch16_loss0.23139778897166252.pypots
2024-05-24 22:46:51 [INFO]: Epoch 017 - training loss: 0.2468, validation loss: 0.2300
2024-05-24 22:46:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch17_loss0.23003629222512245.pypots
2024-05-24 22:46:53 [INFO]: Epoch 018 - training loss: 0.2720, validation loss: 0.2459
2024-05-24 22:46:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch18_loss0.24592988193035126.pypots
2024-05-24 22:46:55 [INFO]: Epoch 019 - training loss: 0.3452, validation loss: 0.3199
2024-05-24 22:46:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch19_loss0.3199491500854492.pypots
2024-05-24 22:46:57 [INFO]: Epoch 020 - training loss: 0.2300, validation loss: 0.2631
2024-05-24 22:46:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch20_loss0.26309916377067566.pypots
2024-05-24 22:46:59 [INFO]: Epoch 021 - training loss: 0.2352, validation loss: 0.2435
2024-05-24 22:46:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch21_loss0.24350067973136902.pypots
2024-05-24 22:47:01 [INFO]: Epoch 022 - training loss: 0.2354, validation loss: 0.2245
2024-05-24 22:47:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch22_loss0.2245173566043377.pypots
2024-05-24 22:47:03 [INFO]: Epoch 023 - training loss: 0.2204, validation loss: 0.2217
2024-05-24 22:47:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch23_loss0.22168172150850296.pypots
2024-05-24 22:47:05 [INFO]: Epoch 024 - training loss: 0.1876, validation loss: 0.2144
2024-05-24 22:47:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch24_loss0.21435464173555374.pypots
2024-05-24 22:47:07 [INFO]: Epoch 025 - training loss: 0.2024, validation loss: 0.2096
2024-05-24 22:47:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch25_loss0.20957978814840317.pypots
2024-05-24 22:47:09 [INFO]: Epoch 026 - training loss: 0.2110, validation loss: 0.1946
2024-05-24 22:47:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch26_loss0.19456779956817627.pypots
2024-05-24 22:47:12 [INFO]: Epoch 027 - training loss: 0.2052, validation loss: 0.2017
2024-05-24 22:47:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch27_loss0.20173099264502525.pypots
2024-05-24 22:47:14 [INFO]: Epoch 028 - training loss: 0.1767, validation loss: 0.1964
2024-05-24 22:47:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch28_loss0.19642827659845352.pypots
2024-05-24 22:47:16 [INFO]: Epoch 029 - training loss: 0.2195, validation loss: 0.1887
2024-05-24 22:47:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch29_loss0.18874350562691689.pypots
2024-05-24 22:47:18 [INFO]: Epoch 030 - training loss: 0.2025, validation loss: 0.1917
2024-05-24 22:47:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch30_loss0.19165581837296486.pypots
2024-05-24 22:47:20 [INFO]: Epoch 031 - training loss: 0.1772, validation loss: 0.1773
2024-05-24 22:47:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch31_loss0.1772649697959423.pypots
2024-05-24 22:47:22 [INFO]: Epoch 032 - training loss: 0.1658, validation loss: 0.1799
2024-05-24 22:47:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch32_loss0.1799028441309929.pypots
2024-05-24 22:47:24 [INFO]: Epoch 033 - training loss: 0.2069, validation loss: 0.1706
2024-05-24 22:47:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch33_loss0.17056946083903313.pypots
2024-05-24 22:47:26 [INFO]: Epoch 034 - training loss: 0.1840, validation loss: 0.1748
2024-05-24 22:47:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch34_loss0.17479728534817696.pypots
2024-05-24 22:47:28 [INFO]: Epoch 035 - training loss: 0.1907, validation loss: 0.1790
2024-05-24 22:47:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch35_loss0.17895350977778435.pypots
2024-05-24 22:47:30 [INFO]: Epoch 036 - training loss: 0.1699, validation loss: 0.1708
2024-05-24 22:47:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch36_loss0.17079146951436996.pypots
2024-05-24 22:47:32 [INFO]: Epoch 037 - training loss: 0.1946, validation loss: 0.1617
2024-05-24 22:47:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch37_loss0.16168906167149544.pypots
2024-05-24 22:47:34 [INFO]: Epoch 038 - training loss: 0.1930, validation loss: 0.1620
2024-05-24 22:47:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch38_loss0.16200176626443863.pypots
2024-05-24 22:47:36 [INFO]: Epoch 039 - training loss: 0.1719, validation loss: 0.1615
2024-05-24 22:47:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch39_loss0.16147620975971222.pypots
2024-05-24 22:47:39 [INFO]: Epoch 040 - training loss: 0.1522, validation loss: 0.1603
2024-05-24 22:47:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch40_loss0.1603025235235691.pypots
2024-05-24 22:47:41 [INFO]: Epoch 041 - training loss: 0.1813, validation loss: 0.1579
2024-05-24 22:47:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch41_loss0.15787366777658463.pypots
2024-05-24 22:47:43 [INFO]: Epoch 042 - training loss: 0.1960, validation loss: 0.1562
2024-05-24 22:47:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch42_loss0.15618078038096428.pypots
2024-05-24 22:47:45 [INFO]: Epoch 043 - training loss: 0.1686, validation loss: 0.1609
2024-05-24 22:47:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch43_loss0.16092782467603683.pypots
2024-05-24 22:47:47 [INFO]: Epoch 044 - training loss: 0.1559, validation loss: 0.1524
2024-05-24 22:47:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch44_loss0.15238597244024277.pypots
2024-05-24 22:47:49 [INFO]: Epoch 045 - training loss: 0.1715, validation loss: 0.1550
2024-05-24 22:47:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch45_loss0.15499251708388329.pypots
2024-05-24 22:47:51 [INFO]: Epoch 046 - training loss: 0.1711, validation loss: 0.1757
2024-05-24 22:47:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch46_loss0.1756807081401348.pypots
2024-05-24 22:47:53 [INFO]: Epoch 047 - training loss: 0.1757, validation loss: 0.1624
2024-05-24 22:47:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch47_loss0.162356648594141.pypots
2024-05-24 22:47:55 [INFO]: Epoch 048 - training loss: 0.1528, validation loss: 0.1751
2024-05-24 22:47:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch48_loss0.17510496079921722.pypots
2024-05-24 22:47:57 [INFO]: Epoch 049 - training loss: 0.2051, validation loss: 0.1744
2024-05-24 22:47:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch49_loss0.17443031072616577.pypots
2024-05-24 22:47:59 [INFO]: Epoch 050 - training loss: 0.1594, validation loss: 0.1619
2024-05-24 22:47:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch50_loss0.16186019033193588.pypots
2024-05-24 22:48:01 [INFO]: Epoch 051 - training loss: 0.1652, validation loss: 0.1567
2024-05-24 22:48:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch51_loss0.15673476457595825.pypots
2024-05-24 22:48:03 [INFO]: Epoch 052 - training loss: 0.1897, validation loss: 0.1508
2024-05-24 22:48:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch52_loss0.1507922261953354.pypots
2024-05-24 22:48:06 [INFO]: Epoch 053 - training loss: 0.1703, validation loss: 0.1642
2024-05-24 22:48:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch53_loss0.16420569270849228.pypots
2024-05-24 22:48:08 [INFO]: Epoch 054 - training loss: 0.1661, validation loss: 0.1643
2024-05-24 22:48:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch54_loss0.16431373730301857.pypots
2024-05-24 22:48:10 [INFO]: Epoch 055 - training loss: 0.2332, validation loss: 0.1637
2024-05-24 22:48:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch55_loss0.16373566538095474.pypots
2024-05-24 22:48:12 [INFO]: Epoch 056 - training loss: 0.1947, validation loss: 0.1482
2024-05-24 22:48:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch56_loss0.148167185485363.pypots
2024-05-24 22:48:14 [INFO]: Epoch 057 - training loss: 0.1556, validation loss: 0.1554
2024-05-24 22:48:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch57_loss0.15537314116954803.pypots
2024-05-24 22:48:16 [INFO]: Epoch 058 - training loss: 0.1742, validation loss: 0.1489
2024-05-24 22:48:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch58_loss0.14889205247163773.pypots
2024-05-24 22:48:18 [INFO]: Epoch 059 - training loss: 0.1920, validation loss: 0.1680
2024-05-24 22:48:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch59_loss0.1680009588599205.pypots
2024-05-24 22:48:20 [INFO]: Epoch 060 - training loss: 0.2308, validation loss: 0.1651
2024-05-24 22:48:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch60_loss0.16510017961263657.pypots
2024-05-24 22:48:22 [INFO]: Epoch 061 - training loss: 0.1887, validation loss: 0.1481
2024-05-24 22:48:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch61_loss0.14811581745743752.pypots
2024-05-24 22:48:24 [INFO]: Epoch 062 - training loss: 0.1542, validation loss: 0.1477
2024-05-24 22:48:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch62_loss0.14771323278546333.pypots
2024-05-24 22:48:26 [INFO]: Epoch 063 - training loss: 0.2626, validation loss: 0.1467
2024-05-24 22:48:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch63_loss0.14670046791434288.pypots
2024-05-24 22:48:28 [INFO]: Epoch 064 - training loss: 0.1606, validation loss: 0.1546
2024-05-24 22:48:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch64_loss0.15459654107689857.pypots
2024-05-24 22:48:31 [INFO]: Epoch 065 - training loss: 0.1606, validation loss: 0.1436
2024-05-24 22:48:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch65_loss0.14360836893320084.pypots
2024-05-24 22:48:33 [INFO]: Epoch 066 - training loss: 0.1696, validation loss: 0.1479
2024-05-24 22:48:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch66_loss0.14792665094137192.pypots
2024-05-24 22:48:35 [INFO]: Epoch 067 - training loss: 0.1620, validation loss: 0.1486
2024-05-24 22:48:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch67_loss0.14858362078666687.pypots
2024-05-24 22:48:37 [INFO]: Epoch 068 - training loss: 0.1635, validation loss: 0.1408
2024-05-24 22:48:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch68_loss0.1408306434750557.pypots
2024-05-24 22:48:39 [INFO]: Epoch 069 - training loss: 0.1503, validation loss: 0.1406
2024-05-24 22:48:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch69_loss0.14058947190642357.pypots
2024-05-24 22:48:41 [INFO]: Epoch 070 - training loss: 0.1460, validation loss: 0.1498
2024-05-24 22:48:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch70_loss0.14979053661227226.pypots
2024-05-24 22:48:43 [INFO]: Epoch 071 - training loss: 0.1588, validation loss: 0.1348
2024-05-24 22:48:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch71_loss0.13478171452879906.pypots
2024-05-24 22:48:45 [INFO]: Epoch 072 - training loss: 0.1860, validation loss: 0.1408
2024-05-24 22:48:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch72_loss0.14076191931962967.pypots
2024-05-24 22:48:47 [INFO]: Epoch 073 - training loss: 0.1719, validation loss: 0.1419
2024-05-24 22:48:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch73_loss0.14186369627714157.pypots
2024-05-24 22:48:49 [INFO]: Epoch 074 - training loss: 0.1667, validation loss: 0.1372
2024-05-24 22:48:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch74_loss0.1371842436492443.pypots
2024-05-24 22:48:51 [INFO]: Epoch 075 - training loss: 0.1521, validation loss: 0.1338
2024-05-24 22:48:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch75_loss0.1338457055389881.pypots
2024-05-24 22:48:53 [INFO]: Epoch 076 - training loss: 0.1913, validation loss: 0.1410
2024-05-24 22:48:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch76_loss0.14104870706796646.pypots
2024-05-24 22:48:55 [INFO]: Epoch 077 - training loss: 0.1702, validation loss: 0.1478
2024-05-24 22:48:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch77_loss0.14784305915236473.pypots
2024-05-24 22:48:58 [INFO]: Epoch 078 - training loss: 0.2372, validation loss: 0.1494
2024-05-24 22:48:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch78_loss0.1493559591472149.pypots
2024-05-24 22:49:00 [INFO]: Epoch 079 - training loss: 0.1708, validation loss: 0.1477
2024-05-24 22:49:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch79_loss0.14768243953585625.pypots
2024-05-24 22:49:02 [INFO]: Epoch 080 - training loss: 0.1538, validation loss: 0.1413
2024-05-24 22:49:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch80_loss0.14129825308918953.pypots
2024-05-24 22:49:04 [INFO]: Epoch 081 - training loss: 0.1467, validation loss: 0.1332
2024-05-24 22:49:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch81_loss0.13317470625042915.pypots
2024-05-24 22:49:06 [INFO]: Epoch 082 - training loss: 0.1447, validation loss: 0.1333
2024-05-24 22:49:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch82_loss0.13332148641347885.pypots
2024-05-24 22:49:08 [INFO]: Epoch 083 - training loss: 0.1819, validation loss: 0.1417
2024-05-24 22:49:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch83_loss0.1416506990790367.pypots
2024-05-24 22:49:10 [INFO]: Epoch 084 - training loss: 0.1879, validation loss: 0.1554
2024-05-24 22:49:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch84_loss0.15538714081048965.pypots
2024-05-24 22:49:12 [INFO]: Epoch 085 - training loss: 0.1828, validation loss: 0.1424
2024-05-24 22:49:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch85_loss0.14236894622445107.pypots
2024-05-24 22:49:14 [INFO]: Epoch 086 - training loss: 0.1802, validation loss: 0.1390
2024-05-24 22:49:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch86_loss0.13901716843247414.pypots
2024-05-24 22:49:16 [INFO]: Epoch 087 - training loss: 0.1456, validation loss: 0.1410
2024-05-24 22:49:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch87_loss0.14099283143877983.pypots
2024-05-24 22:49:18 [INFO]: Epoch 088 - training loss: 0.1826, validation loss: 0.1399
2024-05-24 22:49:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch88_loss0.13990627601742744.pypots
2024-05-24 22:49:20 [INFO]: Epoch 089 - training loss: 0.1590, validation loss: 0.1352
2024-05-24 22:49:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch89_loss0.13523947075009346.pypots
2024-05-24 22:49:22 [INFO]: Epoch 090 - training loss: 0.1585, validation loss: 0.1322
2024-05-24 22:49:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch90_loss0.13219257816672325.pypots
2024-05-24 22:49:25 [INFO]: Epoch 091 - training loss: 0.1562, validation loss: 0.1349
2024-05-24 22:49:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch91_loss0.13485948741436005.pypots
2024-05-24 22:49:27 [INFO]: Epoch 092 - training loss: 0.1465, validation loss: 0.1328
2024-05-24 22:49:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch92_loss0.1327776238322258.pypots
2024-05-24 22:49:29 [INFO]: Epoch 093 - training loss: 0.1461, validation loss: 0.1331
2024-05-24 22:49:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch93_loss0.13309703022241592.pypots
2024-05-24 22:49:31 [INFO]: Epoch 094 - training loss: 0.1563, validation loss: 0.1311
2024-05-24 22:49:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch94_loss0.13110692240297794.pypots
2024-05-24 22:49:33 [INFO]: Epoch 095 - training loss: 0.2095, validation loss: 0.1347
2024-05-24 22:49:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch95_loss0.13473126664757729.pypots
2024-05-24 22:49:35 [INFO]: Epoch 096 - training loss: 0.1569, validation loss: 0.1333
2024-05-24 22:49:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch96_loss0.13327544555068016.pypots
2024-05-24 22:49:37 [INFO]: Epoch 097 - training loss: 0.1488, validation loss: 0.1362
2024-05-24 22:49:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch97_loss0.1362382210791111.pypots
2024-05-24 22:49:39 [INFO]: Epoch 098 - training loss: 0.1423, validation loss: 0.1346
2024-05-24 22:49:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch98_loss0.13456233963370323.pypots
2024-05-24 22:49:41 [INFO]: Epoch 099 - training loss: 0.1551, validation loss: 0.1354
2024-05-24 22:49:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch99_loss0.13542735949158669.pypots
2024-05-24 22:49:43 [INFO]: Epoch 100 - training loss: 0.1449, validation loss: 0.1276
2024-05-24 22:49:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch100_loss0.12762157060205936.pypots
2024-05-24 22:49:45 [INFO]: Epoch 101 - training loss: 0.1584, validation loss: 0.1263
2024-05-24 22:49:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch101_loss0.12630189582705498.pypots
2024-05-24 22:49:47 [INFO]: Epoch 102 - training loss: 0.1334, validation loss: 0.1270
2024-05-24 22:49:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch102_loss0.12702800892293453.pypots
2024-05-24 22:49:49 [INFO]: Epoch 103 - training loss: 0.1257, validation loss: 0.1250
2024-05-24 22:49:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch103_loss0.12495136633515358.pypots
2024-05-24 22:49:52 [INFO]: Epoch 104 - training loss: 0.1361, validation loss: 0.1252
2024-05-24 22:49:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch104_loss0.12517153471708298.pypots
2024-05-24 22:49:54 [INFO]: Epoch 105 - training loss: 0.1447, validation loss: 0.1242
2024-05-24 22:49:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch105_loss0.12417172081768513.pypots
2024-05-24 22:49:56 [INFO]: Epoch 106 - training loss: 0.1529, validation loss: 0.1265
2024-05-24 22:49:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch106_loss0.12647108174860477.pypots
2024-05-24 22:49:58 [INFO]: Epoch 107 - training loss: 0.2171, validation loss: 0.1382
2024-05-24 22:49:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch107_loss0.1382378563284874.pypots
2024-05-24 22:50:00 [INFO]: Epoch 108 - training loss: 0.1474, validation loss: 0.1291
2024-05-24 22:50:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch108_loss0.12913762778043747.pypots
2024-05-24 22:50:02 [INFO]: Epoch 109 - training loss: 0.1581, validation loss: 0.1318
2024-05-24 22:50:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch109_loss0.13178038224577904.pypots
2024-05-24 22:50:04 [INFO]: Epoch 110 - training loss: 0.1626, validation loss: 0.1293
2024-05-24 22:50:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch110_loss0.1292657945305109.pypots
2024-05-24 22:50:06 [INFO]: Epoch 111 - training loss: 0.1339, validation loss: 0.1264
2024-05-24 22:50:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch111_loss0.12641282007098198.pypots
2024-05-24 22:50:08 [INFO]: Epoch 112 - training loss: 0.1671, validation loss: 0.1303
2024-05-24 22:50:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch112_loss0.13034100271761417.pypots
2024-05-24 22:50:10 [INFO]: Epoch 113 - training loss: 0.1582, validation loss: 0.1326
2024-05-24 22:50:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch113_loss0.13262810185551643.pypots
2024-05-24 22:50:12 [INFO]: Epoch 114 - training loss: 0.1545, validation loss: 0.1290
2024-05-24 22:50:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch114_loss0.1289801374077797.pypots
2024-05-24 22:50:14 [INFO]: Epoch 115 - training loss: 0.2303, validation loss: 0.1477
2024-05-24 22:50:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI_epoch115_loss0.14765027537941933.pypots
2024-05-24 22:50:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:50:14 [INFO]: Finished training. The best model is from epoch#105.
2024-05-24 22:50:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T224615/CSDI.pypots
2024-05-24 22:50:30 [INFO]: CSDI on ETTm1: MAE=0.1768, MSE=0.3714
2024-05-24 22:50:30 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/CSDI_ettm1/imputation.pkl
2024-05-24 22:50:30 [INFO]: Using the given device: cuda:0
2024-05-24 22:50:30 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/GPVAE_ettm1/20240524_T225030
2024-05-24 22:50:30 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/GPVAE_ettm1/20240524_T225030/tensorboard
2024-05-24 22:50:30 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 22:50:30 [INFO]: Epoch 001 - training loss: 23617.5924, validation loss: 0.9494
2024-05-24 22:50:31 [INFO]: Epoch 002 - training loss: 21357.8798, validation loss: 0.9464
2024-05-24 22:50:31 [INFO]: Epoch 003 - training loss: 19087.1277, validation loss: 0.9346
2024-05-24 22:50:31 [INFO]: Epoch 004 - training loss: 16819.9669, validation loss: 0.8997
2024-05-24 22:50:31 [INFO]: Epoch 005 - training loss: 15165.2739, validation loss: 0.8301
2024-05-24 22:50:31 [INFO]: Epoch 006 - training loss: 13589.1847, validation loss: 0.7114
2024-05-24 22:50:31 [INFO]: Epoch 007 - training loss: 12772.3491, validation loss: 0.5910
2024-05-24 22:50:31 [INFO]: Epoch 008 - training loss: 11761.0955, validation loss: 0.5147
2024-05-24 22:50:31 [INFO]: Epoch 009 - training loss: 11225.3834, validation loss: 0.4723
2024-05-24 22:50:32 [INFO]: Epoch 010 - training loss: 10826.7261, validation loss: 0.4560
2024-05-24 22:50:32 [INFO]: Epoch 011 - training loss: 10533.1750, validation loss: 0.4423
2024-05-24 22:50:32 [INFO]: Epoch 012 - training loss: 10368.5828, validation loss: 0.4328
2024-05-24 22:50:32 [INFO]: Epoch 013 - training loss: 10217.8821, validation loss: 0.4088
2024-05-24 22:50:32 [INFO]: Epoch 014 - training loss: 10104.7214, validation loss: 0.3921
2024-05-24 22:50:32 [INFO]: Epoch 015 - training loss: 9980.1122, validation loss: 0.3764
2024-05-24 22:50:32 [INFO]: Epoch 016 - training loss: 9911.4018, validation loss: 0.3639
2024-05-24 22:50:32 [INFO]: Epoch 017 - training loss: 9833.4503, validation loss: 0.3530
2024-05-24 22:50:33 [INFO]: Epoch 018 - training loss: 9786.1297, validation loss: 0.3390
2024-05-24 22:50:33 [INFO]: Epoch 019 - training loss: 9755.0787, validation loss: 0.3317
2024-05-24 22:50:33 [INFO]: Epoch 020 - training loss: 9722.4911, validation loss: 0.3314
2024-05-24 22:50:33 [INFO]: Epoch 021 - training loss: 9655.9647, validation loss: 0.3274
2024-05-24 22:50:33 [INFO]: Epoch 022 - training loss: 9621.6684, validation loss: 0.3217
2024-05-24 22:50:33 [INFO]: Epoch 023 - training loss: 9605.8995, validation loss: 0.3170
2024-05-24 22:50:33 [INFO]: Epoch 024 - training loss: 9606.4167, validation loss: 0.3120
2024-05-24 22:50:34 [INFO]: Epoch 025 - training loss: 9575.1656, validation loss: 0.3065
2024-05-24 22:50:34 [INFO]: Epoch 026 - training loss: 9538.2478, validation loss: 0.2968
2024-05-24 22:50:34 [INFO]: Epoch 027 - training loss: 9528.7078, validation loss: 0.2896
2024-05-24 22:50:34 [INFO]: Epoch 028 - training loss: 9517.6359, validation loss: 0.2810
2024-05-24 22:50:34 [INFO]: Epoch 029 - training loss: 9490.1214, validation loss: 0.2654
2024-05-24 22:50:34 [INFO]: Epoch 030 - training loss: 9518.8113, validation loss: 0.2617
2024-05-24 22:50:34 [INFO]: Epoch 031 - training loss: 9472.4846, validation loss: 0.2485
2024-05-24 22:50:34 [INFO]: Epoch 032 - training loss: 9460.9649, validation loss: 0.2368
2024-05-24 22:50:34 [INFO]: Epoch 033 - training loss: 9473.8917, validation loss: 0.2267
2024-05-24 22:50:35 [INFO]: Epoch 034 - training loss: 9440.3002, validation loss: 0.2164
2024-05-24 22:50:35 [INFO]: Epoch 035 - training loss: 9435.9155, validation loss: 0.2054
2024-05-24 22:50:35 [INFO]: Epoch 036 - training loss: 9429.2053, validation loss: 0.1966
2024-05-24 22:50:35 [INFO]: Epoch 037 - training loss: 9431.0667, validation loss: 0.1869
2024-05-24 22:50:35 [INFO]: Epoch 038 - training loss: 9419.0906, validation loss: 0.1785
2024-05-24 22:50:35 [INFO]: Epoch 039 - training loss: 9409.5657, validation loss: 0.1727
2024-05-24 22:50:35 [INFO]: Epoch 040 - training loss: 9403.2338, validation loss: 0.1638
2024-05-24 22:50:36 [INFO]: Epoch 041 - training loss: 9414.2125, validation loss: 0.1554
2024-05-24 22:50:36 [INFO]: Epoch 042 - training loss: 9401.8979, validation loss: 0.1526
2024-05-24 22:50:36 [INFO]: Epoch 043 - training loss: 9392.9001, validation loss: 0.1499
2024-05-24 22:50:36 [INFO]: Epoch 044 - training loss: 9395.3306, validation loss: 0.1456
2024-05-24 22:50:36 [INFO]: Epoch 045 - training loss: 9385.8267, validation loss: 0.1421
2024-05-24 22:50:36 [INFO]: Epoch 046 - training loss: 9379.3823, validation loss: 0.1383
2024-05-24 22:50:36 [INFO]: Epoch 047 - training loss: 9377.4118, validation loss: 0.1388
2024-05-24 22:50:36 [INFO]: Epoch 048 - training loss: 9381.2150, validation loss: 0.1336
2024-05-24 22:50:36 [INFO]: Epoch 049 - training loss: 9382.1301, validation loss: 0.1302
2024-05-24 22:50:37 [INFO]: Epoch 050 - training loss: 9368.1302, validation loss: 0.1297
2024-05-24 22:50:37 [INFO]: Epoch 051 - training loss: 9367.0172, validation loss: 0.1298
2024-05-24 22:50:37 [INFO]: Epoch 052 - training loss: 9361.5714, validation loss: 0.1281
2024-05-24 22:50:37 [INFO]: Epoch 053 - training loss: 9361.3904, validation loss: 0.1270
2024-05-24 22:50:37 [INFO]: Epoch 054 - training loss: 9362.9983, validation loss: 0.1245
2024-05-24 22:50:37 [INFO]: Epoch 055 - training loss: 9358.1309, validation loss: 0.1240
2024-05-24 22:50:37 [INFO]: Epoch 056 - training loss: 9356.6265, validation loss: 0.1223
2024-05-24 22:50:37 [INFO]: Epoch 057 - training loss: 9353.4468, validation loss: 0.1211
2024-05-24 22:50:38 [INFO]: Epoch 058 - training loss: 9350.8108, validation loss: 0.1225
2024-05-24 22:50:38 [INFO]: Epoch 059 - training loss: 9351.5212, validation loss: 0.1206
2024-05-24 22:50:38 [INFO]: Epoch 060 - training loss: 9351.6180, validation loss: 0.1180
2024-05-24 22:50:38 [INFO]: Epoch 061 - training loss: 9348.3192, validation loss: 0.1189
2024-05-24 22:50:38 [INFO]: Epoch 062 - training loss: 9347.9839, validation loss: 0.1151
2024-05-24 22:50:38 [INFO]: Epoch 063 - training loss: 9346.3666, validation loss: 0.1161
2024-05-24 22:50:38 [INFO]: Epoch 064 - training loss: 9343.6044, validation loss: 0.1152
2024-05-24 22:50:38 [INFO]: Epoch 065 - training loss: 9352.8702, validation loss: 0.1143
2024-05-24 22:50:39 [INFO]: Epoch 066 - training loss: 9343.1750, validation loss: 0.1136
2024-05-24 22:50:39 [INFO]: Epoch 067 - training loss: 9341.3569, validation loss: 0.1136
2024-05-24 22:50:39 [INFO]: Epoch 068 - training loss: 9340.9313, validation loss: 0.1131
2024-05-24 22:50:39 [INFO]: Epoch 069 - training loss: 9337.8414, validation loss: 0.1117
2024-05-24 22:50:39 [INFO]: Epoch 070 - training loss: 9339.1677, validation loss: 0.1103
2024-05-24 22:50:39 [INFO]: Epoch 071 - training loss: 9336.3639, validation loss: 0.1110
2024-05-24 22:50:39 [INFO]: Epoch 072 - training loss: 9341.0972, validation loss: 0.1086
2024-05-24 22:50:39 [INFO]: Epoch 073 - training loss: 9336.2431, validation loss: 0.1077
2024-05-24 22:50:40 [INFO]: Epoch 074 - training loss: 9336.6810, validation loss: 0.1088
2024-05-24 22:50:40 [INFO]: Epoch 075 - training loss: 9333.7730, validation loss: 0.1074
2024-05-24 22:50:40 [INFO]: Epoch 076 - training loss: 9331.1622, validation loss: 0.1075
2024-05-24 22:50:40 [INFO]: Epoch 077 - training loss: 9330.2538, validation loss: 0.1061
2024-05-24 22:50:40 [INFO]: Epoch 078 - training loss: 9330.9506, validation loss: 0.1059
2024-05-24 22:50:40 [INFO]: Epoch 079 - training loss: 9332.6076, validation loss: 0.1053
2024-05-24 22:50:40 [INFO]: Epoch 080 - training loss: 9330.4475, validation loss: 0.1055
2024-05-24 22:50:41 [INFO]: Epoch 081 - training loss: 9330.3773, validation loss: 0.1024
2024-05-24 22:50:41 [INFO]: Epoch 082 - training loss: 9330.2265, validation loss: 0.1034
2024-05-24 22:50:41 [INFO]: Epoch 083 - training loss: 9326.3932, validation loss: 0.1025
2024-05-24 22:50:41 [INFO]: Epoch 084 - training loss: 9325.8619, validation loss: 0.1022
2024-05-24 22:50:41 [INFO]: Epoch 085 - training loss: 9327.0132, validation loss: 0.1015
2024-05-24 22:50:41 [INFO]: Epoch 086 - training loss: 9328.0396, validation loss: 0.0991
2024-05-24 22:50:41 [INFO]: Epoch 087 - training loss: 9324.3212, validation loss: 0.1035
2024-05-24 22:50:41 [INFO]: Epoch 088 - training loss: 9324.4415, validation loss: 0.0991
2024-05-24 22:50:42 [INFO]: Epoch 089 - training loss: 9324.9412, validation loss: 0.0999
2024-05-24 22:50:42 [INFO]: Epoch 090 - training loss: 9328.2213, validation loss: 0.0982
2024-05-24 22:50:42 [INFO]: Epoch 091 - training loss: 9327.4081, validation loss: 0.0982
2024-05-24 22:50:42 [INFO]: Epoch 092 - training loss: 9324.0988, validation loss: 0.0978
2024-05-24 22:50:42 [INFO]: Epoch 093 - training loss: 9322.0812, validation loss: 0.0971
2024-05-24 22:50:42 [INFO]: Epoch 094 - training loss: 9323.2113, validation loss: 0.0971
2024-05-24 22:50:42 [INFO]: Epoch 095 - training loss: 9320.7641, validation loss: 0.0969
2024-05-24 22:50:42 [INFO]: Epoch 096 - training loss: 9321.8684, validation loss: 0.0952
2024-05-24 22:50:43 [INFO]: Epoch 097 - training loss: 9323.4804, validation loss: 0.0951
2024-05-24 22:50:43 [INFO]: Epoch 098 - training loss: 9322.2551, validation loss: 0.0947
2024-05-24 22:50:43 [INFO]: Epoch 099 - training loss: 9320.5407, validation loss: 0.0942
2024-05-24 22:50:43 [INFO]: Epoch 100 - training loss: 9319.2255, validation loss: 0.0934
2024-05-24 22:50:43 [INFO]: Epoch 101 - training loss: 9320.9318, validation loss: 0.0925
2024-05-24 22:50:43 [INFO]: Epoch 102 - training loss: 9319.3260, validation loss: 0.0933
2024-05-24 22:50:43 [INFO]: Epoch 103 - training loss: 9317.0496, validation loss: 0.0918
2024-05-24 22:50:43 [INFO]: Epoch 104 - training loss: 9318.3741, validation loss: 0.0916
2024-05-24 22:50:44 [INFO]: Epoch 105 - training loss: 9317.4341, validation loss: 0.0910
2024-05-24 22:50:44 [INFO]: Epoch 106 - training loss: 9317.5045, validation loss: 0.0915
2024-05-24 22:50:44 [INFO]: Epoch 107 - training loss: 9317.5021, validation loss: 0.0896
2024-05-24 22:50:44 [INFO]: Epoch 108 - training loss: 9316.7343, validation loss: 0.0902
2024-05-24 22:50:44 [INFO]: Epoch 109 - training loss: 9316.0873, validation loss: 0.0896
2024-05-24 22:50:44 [INFO]: Epoch 110 - training loss: 9315.8259, validation loss: 0.0896
2024-05-24 22:50:44 [INFO]: Epoch 111 - training loss: 9316.0123, validation loss: 0.0891
2024-05-24 22:50:44 [INFO]: Epoch 112 - training loss: 9316.7580, validation loss: 0.0895
2024-05-24 22:50:45 [INFO]: Epoch 113 - training loss: 9315.1857, validation loss: 0.0881
2024-05-24 22:50:45 [INFO]: Epoch 114 - training loss: 9316.2018, validation loss: 0.0899
2024-05-24 22:50:45 [INFO]: Epoch 115 - training loss: 9315.9103, validation loss: 0.0867
2024-05-24 22:50:45 [INFO]: Epoch 116 - training loss: 9313.9317, validation loss: 0.0880
2024-05-24 22:50:45 [INFO]: Epoch 117 - training loss: 9313.8281, validation loss: 0.0860
2024-05-24 22:50:45 [INFO]: Epoch 118 - training loss: 9313.5073, validation loss: 0.0883
2024-05-24 22:50:45 [INFO]: Epoch 119 - training loss: 9319.9570, validation loss: 0.0867
2024-05-24 22:50:45 [INFO]: Epoch 120 - training loss: 9313.3347, validation loss: 0.0852
2024-05-24 22:50:46 [INFO]: Epoch 121 - training loss: 9313.9554, validation loss: 0.0852
2024-05-24 22:50:46 [INFO]: Epoch 122 - training loss: 9312.5704, validation loss: 0.0849
2024-05-24 22:50:46 [INFO]: Epoch 123 - training loss: 9313.0310, validation loss: 0.0842
2024-05-24 22:50:46 [INFO]: Epoch 124 - training loss: 9313.3708, validation loss: 0.0845
2024-05-24 22:50:46 [INFO]: Epoch 125 - training loss: 9312.3186, validation loss: 0.0831
2024-05-24 22:50:46 [INFO]: Epoch 126 - training loss: 9311.5524, validation loss: 0.0833
2024-05-24 22:50:46 [INFO]: Epoch 127 - training loss: 9311.2520, validation loss: 0.0834
2024-05-24 22:50:46 [INFO]: Epoch 128 - training loss: 9312.1278, validation loss: 0.0831
2024-05-24 22:50:47 [INFO]: Epoch 129 - training loss: 9311.8361, validation loss: 0.0826
2024-05-24 22:50:47 [INFO]: Epoch 130 - training loss: 9311.5536, validation loss: 0.0836
2024-05-24 22:50:47 [INFO]: Epoch 131 - training loss: 9311.2800, validation loss: 0.0818
2024-05-24 22:50:47 [INFO]: Epoch 132 - training loss: 9311.4864, validation loss: 0.0816
2024-05-24 22:50:47 [INFO]: Epoch 133 - training loss: 9311.6994, validation loss: 0.0821
2024-05-24 22:50:47 [INFO]: Epoch 134 - training loss: 9310.2111, validation loss: 0.0815
2024-05-24 22:50:47 [INFO]: Epoch 135 - training loss: 9310.2715, validation loss: 0.0811
2024-05-24 22:50:47 [INFO]: Epoch 136 - training loss: 9310.8817, validation loss: 0.0807
2024-05-24 22:50:48 [INFO]: Epoch 137 - training loss: 9309.8007, validation loss: 0.0814
2024-05-24 22:50:48 [INFO]: Epoch 138 - training loss: 9311.0551, validation loss: 0.0801
2024-05-24 22:50:48 [INFO]: Epoch 139 - training loss: 9309.6768, validation loss: 0.0793
2024-05-24 22:50:48 [INFO]: Epoch 140 - training loss: 9309.7413, validation loss: 0.0802
2024-05-24 22:50:48 [INFO]: Epoch 141 - training loss: 9309.7784, validation loss: 0.0805
2024-05-24 22:50:48 [INFO]: Epoch 142 - training loss: 9309.0778, validation loss: 0.0808
2024-05-24 22:50:48 [INFO]: Epoch 143 - training loss: 9308.8436, validation loss: 0.0800
2024-05-24 22:50:48 [INFO]: Epoch 144 - training loss: 9309.3667, validation loss: 0.0787
2024-05-24 22:50:49 [INFO]: Epoch 145 - training loss: 9310.1670, validation loss: 0.0789
2024-05-24 22:50:49 [INFO]: Epoch 146 - training loss: 9308.9902, validation loss: 0.0791
2024-05-24 22:50:49 [INFO]: Epoch 147 - training loss: 9310.2677, validation loss: 0.0799
2024-05-24 22:50:49 [INFO]: Epoch 148 - training loss: 9308.7437, validation loss: 0.0785
2024-05-24 22:50:49 [INFO]: Epoch 149 - training loss: 9308.4924, validation loss: 0.0784
2024-05-24 22:50:49 [INFO]: Epoch 150 - training loss: 9307.6461, validation loss: 0.0788
2024-05-24 22:50:49 [INFO]: Epoch 151 - training loss: 9306.8225, validation loss: 0.0791
2024-05-24 22:50:49 [INFO]: Epoch 152 - training loss: 9309.9388, validation loss: 0.0775
2024-05-24 22:50:50 [INFO]: Epoch 153 - training loss: 9308.4047, validation loss: 0.0767
2024-05-24 22:50:50 [INFO]: Epoch 154 - training loss: 9307.8850, validation loss: 0.0765
2024-05-24 22:50:50 [INFO]: Epoch 155 - training loss: 9307.6491, validation loss: 0.0766
2024-05-24 22:50:50 [INFO]: Epoch 156 - training loss: 9310.0003, validation loss: 0.0762
2024-05-24 22:50:50 [INFO]: Epoch 157 - training loss: 9306.5899, validation loss: 0.0778
2024-05-24 22:50:50 [INFO]: Epoch 158 - training loss: 9305.7301, validation loss: 0.0773
2024-05-24 22:50:50 [INFO]: Epoch 159 - training loss: 9307.8989, validation loss: 0.0770
2024-05-24 22:50:50 [INFO]: Epoch 160 - training loss: 9306.5671, validation loss: 0.0770
2024-05-24 22:50:51 [INFO]: Epoch 161 - training loss: 9306.1169, validation loss: 0.0760
2024-05-24 22:50:51 [INFO]: Epoch 162 - training loss: 9306.9039, validation loss: 0.0779
2024-05-24 22:50:51 [INFO]: Epoch 163 - training loss: 9306.3063, validation loss: 0.0763
2024-05-24 22:50:51 [INFO]: Epoch 164 - training loss: 9306.0090, validation loss: 0.0760
2024-05-24 22:50:51 [INFO]: Epoch 165 - training loss: 9306.8585, validation loss: 0.0766
2024-05-24 22:50:51 [INFO]: Epoch 166 - training loss: 9306.1879, validation loss: 0.0776
2024-05-24 22:50:51 [INFO]: Epoch 167 - training loss: 9306.4317, validation loss: 0.0756
2024-05-24 22:50:51 [INFO]: Epoch 168 - training loss: 9305.5687, validation loss: 0.0779
2024-05-24 22:50:52 [INFO]: Epoch 169 - training loss: 9307.8115, validation loss: 0.0770
2024-05-24 22:50:52 [INFO]: Epoch 170 - training loss: 9306.5067, validation loss: 0.0762
2024-05-24 22:50:52 [INFO]: Epoch 171 - training loss: 9305.4872, validation loss: 0.0749
2024-05-24 22:50:52 [INFO]: Epoch 172 - training loss: 9306.0001, validation loss: 0.0741
2024-05-24 22:50:52 [INFO]: Epoch 173 - training loss: 9305.4788, validation loss: 0.0756
2024-05-24 22:50:52 [INFO]: Epoch 174 - training loss: 9304.1100, validation loss: 0.0745
2024-05-24 22:50:52 [INFO]: Epoch 175 - training loss: 9305.1266, validation loss: 0.0750
2024-05-24 22:50:52 [INFO]: Epoch 176 - training loss: 9307.5641, validation loss: 0.0743
2024-05-24 22:50:53 [INFO]: Epoch 177 - training loss: 9304.8312, validation loss: 0.0750
2024-05-24 22:50:53 [INFO]: Epoch 178 - training loss: 9305.1174, validation loss: 0.0745
2024-05-24 22:50:53 [INFO]: Epoch 179 - training loss: 9304.4254, validation loss: 0.0739
2024-05-24 22:50:53 [INFO]: Epoch 180 - training loss: 9305.5457, validation loss: 0.0748
2024-05-24 22:50:53 [INFO]: Epoch 181 - training loss: 9306.7095, validation loss: 0.0742
2024-05-24 22:50:53 [INFO]: Epoch 182 - training loss: 9305.7618, validation loss: 0.0730
2024-05-24 22:50:53 [INFO]: Epoch 183 - training loss: 9304.5162, validation loss: 0.0743
2024-05-24 22:50:53 [INFO]: Epoch 184 - training loss: 9304.5843, validation loss: 0.0728
2024-05-24 22:50:54 [INFO]: Epoch 185 - training loss: 9304.5812, validation loss: 0.0729
2024-05-24 22:50:54 [INFO]: Epoch 186 - training loss: 9304.6872, validation loss: 0.0742
2024-05-24 22:50:54 [INFO]: Epoch 187 - training loss: 9304.7528, validation loss: 0.0738
2024-05-24 22:50:54 [INFO]: Epoch 188 - training loss: 9304.2551, validation loss: 0.0719
2024-05-24 22:50:54 [INFO]: Epoch 189 - training loss: 9304.7911, validation loss: 0.0733
2024-05-24 22:50:54 [INFO]: Epoch 190 - training loss: 9305.7917, validation loss: 0.0725
2024-05-24 22:50:54 [INFO]: Epoch 191 - training loss: 9304.5765, validation loss: 0.0729
2024-05-24 22:50:54 [INFO]: Epoch 192 - training loss: 9304.2192, validation loss: 0.0731
2024-05-24 22:50:55 [INFO]: Epoch 193 - training loss: 9304.6765, validation loss: 0.0717
2024-05-24 22:50:55 [INFO]: Epoch 194 - training loss: 9303.6965, validation loss: 0.0731
2024-05-24 22:50:55 [INFO]: Epoch 195 - training loss: 9303.6783, validation loss: 0.0719
2024-05-24 22:50:55 [INFO]: Epoch 196 - training loss: 9305.9189, validation loss: 0.0733
2024-05-24 22:50:55 [INFO]: Epoch 197 - training loss: 9303.0469, validation loss: 0.0724
2024-05-24 22:50:55 [INFO]: Epoch 198 - training loss: 9303.9542, validation loss: 0.0721
2024-05-24 22:50:55 [INFO]: Epoch 199 - training loss: 9304.6674, validation loss: 0.0707
2024-05-24 22:50:55 [INFO]: Epoch 200 - training loss: 9302.5881, validation loss: 0.0718
2024-05-24 22:50:56 [INFO]: Epoch 201 - training loss: 9304.1600, validation loss: 0.0711
2024-05-24 22:50:56 [INFO]: Epoch 202 - training loss: 9304.1179, validation loss: 0.0706
2024-05-24 22:50:56 [INFO]: Epoch 203 - training loss: 9303.5376, validation loss: 0.0712
2024-05-24 22:50:56 [INFO]: Epoch 204 - training loss: 9303.7048, validation loss: 0.0718
2024-05-24 22:50:56 [INFO]: Epoch 205 - training loss: 9302.8268, validation loss: 0.0718
2024-05-24 22:50:56 [INFO]: Epoch 206 - training loss: 9304.6818, validation loss: 0.0719
2024-05-24 22:50:56 [INFO]: Epoch 207 - training loss: 9303.6606, validation loss: 0.0713
2024-05-24 22:50:56 [INFO]: Epoch 208 - training loss: 9302.6073, validation loss: 0.0711
2024-05-24 22:50:57 [INFO]: Epoch 209 - training loss: 9303.5189, validation loss: 0.0720
2024-05-24 22:50:57 [INFO]: Epoch 210 - training loss: 9303.1567, validation loss: 0.0720
2024-05-24 22:50:57 [INFO]: Epoch 211 - training loss: 9303.0290, validation loss: 0.0702
2024-05-24 22:50:57 [INFO]: Epoch 212 - training loss: 9302.9744, validation loss: 0.0704
2024-05-24 22:50:57 [INFO]: Epoch 213 - training loss: 9303.0135, validation loss: 0.0717
2024-05-24 22:50:57 [INFO]: Epoch 214 - training loss: 9303.0124, validation loss: 0.0724
2024-05-24 22:50:57 [INFO]: Epoch 215 - training loss: 9302.0738, validation loss: 0.0702
2024-05-24 22:50:57 [INFO]: Epoch 216 - training loss: 9304.4067, validation loss: 0.0708
2024-05-24 22:50:58 [INFO]: Epoch 217 - training loss: 9303.6501, validation loss: 0.0712
2024-05-24 22:50:58 [INFO]: Epoch 218 - training loss: 9303.0941, validation loss: 0.0705
2024-05-24 22:50:58 [INFO]: Epoch 219 - training loss: 9301.9906, validation loss: 0.0710
2024-05-24 22:50:58 [INFO]: Epoch 220 - training loss: 9303.0998, validation loss: 0.0705
2024-05-24 22:50:58 [INFO]: Epoch 221 - training loss: 9302.4749, validation loss: 0.0700
2024-05-24 22:50:58 [INFO]: Epoch 222 - training loss: 9302.4840, validation loss: 0.0714
2024-05-24 22:50:58 [INFO]: Epoch 223 - training loss: 9302.7026, validation loss: 0.0737
2024-05-24 22:50:58 [INFO]: Epoch 224 - training loss: 9301.6099, validation loss: 0.0702
2024-05-24 22:50:59 [INFO]: Epoch 225 - training loss: 9302.2701, validation loss: 0.0699
2024-05-24 22:50:59 [INFO]: Epoch 226 - training loss: 9311.0234, validation loss: 0.0702
2024-05-24 22:50:59 [INFO]: Epoch 227 - training loss: 9303.5683, validation loss: 0.0697
2024-05-24 22:50:59 [INFO]: Epoch 228 - training loss: 9301.6728, validation loss: 0.0699
2024-05-24 22:50:59 [INFO]: Epoch 229 - training loss: 9303.0341, validation loss: 0.0702
2024-05-24 22:50:59 [INFO]: Epoch 230 - training loss: 9302.5182, validation loss: 0.0672
2024-05-24 22:50:59 [INFO]: Epoch 231 - training loss: 9303.0244, validation loss: 0.0685
2024-05-24 22:50:59 [INFO]: Epoch 232 - training loss: 9301.4569, validation loss: 0.0688
2024-05-24 22:51:00 [INFO]: Epoch 233 - training loss: 9300.8949, validation loss: 0.0706
2024-05-24 22:51:00 [INFO]: Epoch 234 - training loss: 9301.9188, validation loss: 0.0683
2024-05-24 22:51:00 [INFO]: Epoch 235 - training loss: 9302.8415, validation loss: 0.0697
2024-05-24 22:51:00 [INFO]: Epoch 236 - training loss: 9300.7878, validation loss: 0.0711
2024-05-24 22:51:00 [INFO]: Epoch 237 - training loss: 9301.6954, validation loss: 0.0694
2024-05-24 22:51:00 [INFO]: Epoch 238 - training loss: 9301.6242, validation loss: 0.0693
2024-05-24 22:51:00 [INFO]: Epoch 239 - training loss: 9302.3425, validation loss: 0.0680
2024-05-24 22:51:00 [INFO]: Epoch 240 - training loss: 9301.9204, validation loss: 0.0695
2024-05-24 22:51:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:51:00 [INFO]: Finished training. The best model is from epoch#230.
2024-05-24 22:51:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/GPVAE_ettm1/20240524_T225030/GPVAE.pypots
2024-05-24 22:51:00 [INFO]: GP-VAE on ETTm1: MAE=0.2703, MSE=0.1542
2024-05-24 22:51:00 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/GPVAE_ettm1/imputation.pkl
2024-05-24 22:51:00 [INFO]: Using the given device: cuda:0
2024-05-24 22:51:00 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/USGAN_ettm1/20240524_T225100
2024-05-24 22:51:00 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/USGAN_ettm1/20240524_T225100/tensorboard
2024-05-24 22:51:00 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 22:51:11 [INFO]: Epoch 001 - generator training loss: 0.5542, discriminator training loss: 0.3351, validation loss: 0.2464
2024-05-24 22:51:20 [INFO]: Epoch 002 - generator training loss: 0.0268, discriminator training loss: 0.2124, validation loss: 0.1058
2024-05-24 22:51:29 [INFO]: Epoch 003 - generator training loss: -0.0548, discriminator training loss: 0.1992, validation loss: 0.0617
2024-05-24 22:51:38 [INFO]: Epoch 004 - generator training loss: -0.0830, discriminator training loss: 0.1955, validation loss: 0.0466
2024-05-24 22:51:47 [INFO]: Epoch 005 - generator training loss: -0.0883, discriminator training loss: 0.1950, validation loss: 0.0417
2024-05-24 22:51:56 [INFO]: Epoch 006 - generator training loss: -0.0826, discriminator training loss: 0.1856, validation loss: 0.0380
2024-05-24 22:52:05 [INFO]: Epoch 007 - generator training loss: -0.0795, discriminator training loss: 0.1787, validation loss: 0.0379
2024-05-24 22:52:14 [INFO]: Epoch 008 - generator training loss: -0.0711, discriminator training loss: 0.1676, validation loss: 0.0362
2024-05-24 22:52:23 [INFO]: Epoch 009 - generator training loss: -0.0614, discriminator training loss: 0.1545, validation loss: 0.0348
2024-05-24 22:52:32 [INFO]: Epoch 010 - generator training loss: -0.0473, discriminator training loss: 0.1391, validation loss: 0.0352
2024-05-24 22:52:41 [INFO]: Epoch 011 - generator training loss: -0.0352, discriminator training loss: 0.1210, validation loss: 0.0338
2024-05-24 22:52:50 [INFO]: Epoch 012 - generator training loss: -0.0263, discriminator training loss: 0.1093, validation loss: 0.0329
2024-05-24 22:52:59 [INFO]: Epoch 013 - generator training loss: -0.0216, discriminator training loss: 0.1001, validation loss: 0.0323
2024-05-24 22:53:08 [INFO]: Epoch 014 - generator training loss: -0.0165, discriminator training loss: 0.0947, validation loss: 0.0320
2024-05-24 22:53:17 [INFO]: Epoch 015 - generator training loss: -0.0144, discriminator training loss: 0.0900, validation loss: 0.0318
2024-05-24 22:53:26 [INFO]: Epoch 016 - generator training loss: -0.0148, discriminator training loss: 0.0882, validation loss: 0.0313
2024-05-24 22:53:35 [INFO]: Epoch 017 - generator training loss: -0.0116, discriminator training loss: 0.0840, validation loss: 0.0315
2024-05-24 22:53:44 [INFO]: Epoch 018 - generator training loss: -0.0130, discriminator training loss: 0.0814, validation loss: 0.0307
2024-05-24 22:53:54 [INFO]: Epoch 019 - generator training loss: -0.0144, discriminator training loss: 0.0800, validation loss: 0.0308
2024-05-24 22:54:03 [INFO]: Epoch 020 - generator training loss: -0.0143, discriminator training loss: 0.0793, validation loss: 0.0295
2024-05-24 22:54:12 [INFO]: Epoch 021 - generator training loss: -0.0153, discriminator training loss: 0.0770, validation loss: 0.0296
2024-05-24 22:54:21 [INFO]: Epoch 022 - generator training loss: -0.0140, discriminator training loss: 0.0777, validation loss: 0.0295
2024-05-24 22:54:30 [INFO]: Epoch 023 - generator training loss: -0.0159, discriminator training loss: 0.0750, validation loss: 0.0284
2024-05-24 22:54:39 [INFO]: Epoch 024 - generator training loss: -0.0142, discriminator training loss: 0.0763, validation loss: 0.0282
2024-05-24 22:54:48 [INFO]: Epoch 025 - generator training loss: -0.0141, discriminator training loss: 0.0739, validation loss: 0.0284
2024-05-24 22:54:57 [INFO]: Epoch 026 - generator training loss: -0.0158, discriminator training loss: 0.0766, validation loss: 0.0278
2024-05-24 22:55:06 [INFO]: Epoch 027 - generator training loss: -0.0155, discriminator training loss: 0.0763, validation loss: 0.0279
2024-05-24 22:55:15 [INFO]: Epoch 028 - generator training loss: -0.0151, discriminator training loss: 0.0734, validation loss: 0.0266
2024-05-24 22:55:24 [INFO]: Epoch 029 - generator training loss: -0.0170, discriminator training loss: 0.0731, validation loss: 0.0274
2024-05-24 22:55:33 [INFO]: Epoch 030 - generator training loss: -0.0197, discriminator training loss: 0.0739, validation loss: 0.0260
2024-05-24 22:55:42 [INFO]: Epoch 031 - generator training loss: -0.0170, discriminator training loss: 0.0722, validation loss: 0.0261
2024-05-24 22:55:51 [INFO]: Epoch 032 - generator training loss: -0.0189, discriminator training loss: 0.0728, validation loss: 0.0253
2024-05-24 22:56:00 [INFO]: Epoch 033 - generator training loss: -0.0180, discriminator training loss: 0.0731, validation loss: 0.0249
2024-05-24 22:56:09 [INFO]: Epoch 034 - generator training loss: -0.0181, discriminator training loss: 0.0749, validation loss: 0.0250
2024-05-24 22:56:18 [INFO]: Epoch 035 - generator training loss: -0.0192, discriminator training loss: 0.0734, validation loss: 0.0249
2024-05-24 22:56:27 [INFO]: Epoch 036 - generator training loss: -0.0217, discriminator training loss: 0.0742, validation loss: 0.0241
2024-05-24 22:56:36 [INFO]: Epoch 037 - generator training loss: -0.0212, discriminator training loss: 0.0716, validation loss: 0.0238
2024-05-24 22:56:45 [INFO]: Epoch 038 - generator training loss: -0.0172, discriminator training loss: 0.0710, validation loss: 0.0237
2024-05-24 22:56:54 [INFO]: Epoch 039 - generator training loss: -0.0201, discriminator training loss: 0.0696, validation loss: 0.0235
2024-05-24 22:57:03 [INFO]: Epoch 040 - generator training loss: -0.0217, discriminator training loss: 0.0717, validation loss: 0.0230
2024-05-24 22:57:12 [INFO]: Epoch 041 - generator training loss: -0.0220, discriminator training loss: 0.0697, validation loss: 0.0227
2024-05-24 22:57:21 [INFO]: Epoch 042 - generator training loss: -0.0216, discriminator training loss: 0.0689, validation loss: 0.0226
2024-05-24 22:57:30 [INFO]: Epoch 043 - generator training loss: -0.0247, discriminator training loss: 0.0749, validation loss: 0.0231
2024-05-24 22:57:39 [INFO]: Epoch 044 - generator training loss: -0.0198, discriminator training loss: 0.0698, validation loss: 0.0225
2024-05-24 22:57:48 [INFO]: Epoch 045 - generator training loss: -0.0245, discriminator training loss: 0.0707, validation loss: 0.0222
2024-05-24 22:57:57 [INFO]: Epoch 046 - generator training loss: -0.0238, discriminator training loss: 0.0703, validation loss: 0.0222
2024-05-24 22:58:06 [INFO]: Epoch 047 - generator training loss: -0.0234, discriminator training loss: 0.0710, validation loss: 0.0217
2024-05-24 22:58:15 [INFO]: Epoch 048 - generator training loss: -0.0211, discriminator training loss: 0.0710, validation loss: 0.0218
2024-05-24 22:58:24 [INFO]: Epoch 049 - generator training loss: -0.0218, discriminator training loss: 0.0715, validation loss: 0.0215
2024-05-24 22:58:33 [INFO]: Epoch 050 - generator training loss: -0.0234, discriminator training loss: 0.0707, validation loss: 0.0211
2024-05-24 22:58:42 [INFO]: Epoch 051 - generator training loss: -0.0223, discriminator training loss: 0.0718, validation loss: 0.0211
2024-05-24 22:58:51 [INFO]: Epoch 052 - generator training loss: -0.0192, discriminator training loss: 0.0683, validation loss: 0.0212
2024-05-24 22:59:00 [INFO]: Epoch 053 - generator training loss: -0.0246, discriminator training loss: 0.0696, validation loss: 0.0210
2024-05-24 22:59:09 [INFO]: Epoch 054 - generator training loss: -0.0250, discriminator training loss: 0.0707, validation loss: 0.0206
2024-05-24 22:59:18 [INFO]: Epoch 055 - generator training loss: -0.0246, discriminator training loss: 0.0677, validation loss: 0.0205
2024-05-24 22:59:27 [INFO]: Epoch 056 - generator training loss: -0.0251, discriminator training loss: 0.0705, validation loss: 0.0203
2024-05-24 22:59:36 [INFO]: Epoch 057 - generator training loss: -0.0220, discriminator training loss: 0.0694, validation loss: 0.0205
2024-05-24 22:59:45 [INFO]: Epoch 058 - generator training loss: -0.0251, discriminator training loss: 0.0688, validation loss: 0.0208
2024-05-24 22:59:54 [INFO]: Epoch 059 - generator training loss: -0.0244, discriminator training loss: 0.0675, validation loss: 0.0199
2024-05-24 23:00:03 [INFO]: Epoch 060 - generator training loss: -0.0231, discriminator training loss: 0.0678, validation loss: 0.0206
2024-05-24 23:00:12 [INFO]: Epoch 061 - generator training loss: -0.0233, discriminator training loss: 0.0678, validation loss: 0.0201
2024-05-24 23:00:21 [INFO]: Epoch 062 - generator training loss: -0.0240, discriminator training loss: 0.0673, validation loss: 0.0199
2024-05-24 23:00:30 [INFO]: Epoch 063 - generator training loss: -0.0280, discriminator training loss: 0.0695, validation loss: 0.0199
2024-05-24 23:00:39 [INFO]: Epoch 064 - generator training loss: -0.0225, discriminator training loss: 0.0678, validation loss: 0.0202
2024-05-24 23:00:48 [INFO]: Epoch 065 - generator training loss: -0.0266, discriminator training loss: 0.0710, validation loss: 0.0200
2024-05-24 23:00:57 [INFO]: Epoch 066 - generator training loss: -0.0253, discriminator training loss: 0.0703, validation loss: 0.0207
2024-05-24 23:01:07 [INFO]: Epoch 067 - generator training loss: -0.0223, discriminator training loss: 0.0686, validation loss: 0.0203
2024-05-24 23:01:16 [INFO]: Epoch 068 - generator training loss: -0.0249, discriminator training loss: 0.0672, validation loss: 0.0201
2024-05-24 23:01:25 [INFO]: Epoch 069 - generator training loss: -0.0252, discriminator training loss: 0.0686, validation loss: 0.0200
2024-05-24 23:01:34 [INFO]: Epoch 070 - generator training loss: -0.0221, discriminator training loss: 0.0679, validation loss: 0.0198
2024-05-24 23:01:43 [INFO]: Epoch 071 - generator training loss: -0.0229, discriminator training loss: 0.0666, validation loss: 0.0199
2024-05-24 23:01:51 [INFO]: Epoch 072 - generator training loss: -0.0248, discriminator training loss: 0.0685, validation loss: 0.0196
2024-05-24 23:02:01 [INFO]: Epoch 073 - generator training loss: -0.0243, discriminator training loss: 0.0671, validation loss: 0.0202
2024-05-24 23:02:10 [INFO]: Epoch 074 - generator training loss: -0.0260, discriminator training loss: 0.0669, validation loss: 0.0193
2024-05-24 23:02:19 [INFO]: Epoch 075 - generator training loss: -0.0244, discriminator training loss: 0.0686, validation loss: 0.0197
2024-05-24 23:02:27 [INFO]: Epoch 076 - generator training loss: -0.0246, discriminator training loss: 0.0697, validation loss: 0.0204
2024-05-24 23:02:37 [INFO]: Epoch 077 - generator training loss: -0.0238, discriminator training loss: 0.0690, validation loss: 0.0196
2024-05-24 23:02:46 [INFO]: Epoch 078 - generator training loss: -0.0229, discriminator training loss: 0.0669, validation loss: 0.0193
2024-05-24 23:02:55 [INFO]: Epoch 079 - generator training loss: -0.0216, discriminator training loss: 0.0672, validation loss: 0.0199
2024-05-24 23:03:04 [INFO]: Epoch 080 - generator training loss: -0.0253, discriminator training loss: 0.0679, validation loss: 0.0198
2024-05-24 23:03:13 [INFO]: Epoch 081 - generator training loss: -0.0234, discriminator training loss: 0.0669, validation loss: 0.0198
2024-05-24 23:03:22 [INFO]: Epoch 082 - generator training loss: -0.0247, discriminator training loss: 0.0663, validation loss: 0.0194
2024-05-24 23:03:31 [INFO]: Epoch 083 - generator training loss: -0.0270, discriminator training loss: 0.0683, validation loss: 0.0193
2024-05-24 23:03:40 [INFO]: Epoch 084 - generator training loss: -0.0248, discriminator training loss: 0.0673, validation loss: 0.0195
2024-05-24 23:03:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:03:40 [INFO]: Finished training. The best model is from epoch#74.
2024-05-24 23:03:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/USGAN_ettm1/20240524_T225100/USGAN.pypots
2024-05-24 23:03:41 [INFO]: US-GAN on ETTm1: MAE=0.1249, MSE=0.0435
2024-05-24 23:03:41 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/USGAN_ettm1/imputation.pkl
2024-05-24 23:03:41 [INFO]: Using the given device: cuda:0
2024-05-24 23:03:41 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/BRITS_ettm1/20240524_T230341
2024-05-24 23:03:41 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/BRITS_ettm1/20240524_T230341/tensorboard
2024-05-24 23:03:41 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 23:03:49 [INFO]: Epoch 001 - training loss: 1.2848, validation loss: 0.2980
2024-05-24 23:03:55 [INFO]: Epoch 002 - training loss: 0.8356, validation loss: 0.0839
2024-05-24 23:04:01 [INFO]: Epoch 003 - training loss: 0.6735, validation loss: 0.0496
2024-05-24 23:04:07 [INFO]: Epoch 004 - training loss: 0.6033, validation loss: 0.0431
2024-05-24 23:04:12 [INFO]: Epoch 005 - training loss: 0.5752, validation loss: 0.0410
2024-05-24 23:04:18 [INFO]: Epoch 006 - training loss: 0.5379, validation loss: 0.0378
2024-05-24 23:04:24 [INFO]: Epoch 007 - training loss: 0.5190, validation loss: 0.0347
2024-05-24 23:04:30 [INFO]: Epoch 008 - training loss: 0.4966, validation loss: 0.0338
2024-05-24 23:04:36 [INFO]: Epoch 009 - training loss: 0.4751, validation loss: 0.0327
2024-05-24 23:04:42 [INFO]: Epoch 010 - training loss: 0.4567, validation loss: 0.0305
2024-05-24 23:04:48 [INFO]: Epoch 011 - training loss: 0.4550, validation loss: 0.0310
2024-05-24 23:04:54 [INFO]: Epoch 012 - training loss: 0.4287, validation loss: 0.0278
2024-05-24 23:05:00 [INFO]: Epoch 013 - training loss: 0.4083, validation loss: 0.0267
2024-05-24 23:05:06 [INFO]: Epoch 014 - training loss: 0.3983, validation loss: 0.0247
2024-05-24 23:05:12 [INFO]: Epoch 015 - training loss: 0.3960, validation loss: 0.0235
2024-05-24 23:05:18 [INFO]: Epoch 016 - training loss: 0.3931, validation loss: 0.0229
2024-05-24 23:05:24 [INFO]: Epoch 017 - training loss: 0.3840, validation loss: 0.0232
2024-05-24 23:05:30 [INFO]: Epoch 018 - training loss: 0.3829, validation loss: 0.0226
2024-05-24 23:05:36 [INFO]: Epoch 019 - training loss: 0.3832, validation loss: 0.0228
2024-05-24 23:05:42 [INFO]: Epoch 020 - training loss: 0.3828, validation loss: 0.0237
2024-05-24 23:05:48 [INFO]: Epoch 021 - training loss: 0.3827, validation loss: 0.0230
2024-05-24 23:05:54 [INFO]: Epoch 022 - training loss: 0.3778, validation loss: 0.0232
2024-05-24 23:06:00 [INFO]: Epoch 023 - training loss: 0.3859, validation loss: 0.0227
2024-05-24 23:06:06 [INFO]: Epoch 024 - training loss: 0.3791, validation loss: 0.0223
2024-05-24 23:06:12 [INFO]: Epoch 025 - training loss: 0.3779, validation loss: 0.0229
2024-05-24 23:06:18 [INFO]: Epoch 026 - training loss: 0.3851, validation loss: 0.0225
2024-05-24 23:06:24 [INFO]: Epoch 027 - training loss: 0.3825, validation loss: 0.0244
2024-05-24 23:06:30 [INFO]: Epoch 028 - training loss: 0.3871, validation loss: 0.0227
2024-05-24 23:06:36 [INFO]: Epoch 029 - training loss: 0.3789, validation loss: 0.0225
2024-05-24 23:06:42 [INFO]: Epoch 030 - training loss: 0.3875, validation loss: 0.0230
2024-05-24 23:06:48 [INFO]: Epoch 031 - training loss: 0.3755, validation loss: 0.0233
2024-05-24 23:06:54 [INFO]: Epoch 032 - training loss: 0.3799, validation loss: 0.0222
2024-05-24 23:07:00 [INFO]: Epoch 033 - training loss: 0.3751, validation loss: 0.0221
2024-05-24 23:07:06 [INFO]: Epoch 034 - training loss: 0.3735, validation loss: 0.0229
2024-05-24 23:07:12 [INFO]: Epoch 035 - training loss: 0.3748, validation loss: 0.0225
2024-05-24 23:07:18 [INFO]: Epoch 036 - training loss: 0.3806, validation loss: 0.0226
2024-05-24 23:07:24 [INFO]: Epoch 037 - training loss: 0.3737, validation loss: 0.0225
2024-05-24 23:07:30 [INFO]: Epoch 038 - training loss: 0.3830, validation loss: 0.0228
2024-05-24 23:07:36 [INFO]: Epoch 039 - training loss: 0.3810, validation loss: 0.0227
2024-05-24 23:07:42 [INFO]: Epoch 040 - training loss: 0.3789, validation loss: 0.0247
2024-05-24 23:07:48 [INFO]: Epoch 041 - training loss: 0.3772, validation loss: 0.0252
2024-05-24 23:07:54 [INFO]: Epoch 042 - training loss: 0.3754, validation loss: 0.0236
2024-05-24 23:08:00 [INFO]: Epoch 043 - training loss: 0.3718, validation loss: 0.0256
2024-05-24 23:08:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:08:00 [INFO]: Finished training. The best model is from epoch#33.
2024-05-24 23:08:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/BRITS_ettm1/20240524_T230341/BRITS.pypots
2024-05-24 23:08:01 [INFO]: BRITS on ETTm1: MAE=0.1238, MSE=0.0434
2024-05-24 23:08:01 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/BRITS_ettm1/imputation.pkl
2024-05-24 23:08:01 [INFO]: Using the given device: cuda:0
2024-05-24 23:08:01 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801
2024-05-24 23:08:01 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/tensorboard
2024-05-24 23:08:01 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 23:08:03 [INFO]: Epoch 001 - training loss: 1.4063, validation loss: 1.2043
2024-05-24 23:08:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch1_loss1.2042747884988785.pypots
2024-05-24 23:08:03 [INFO]: Epoch 002 - training loss: 1.0712, validation loss: 1.0864
2024-05-24 23:08:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch2_loss1.086390808224678.pypots
2024-05-24 23:08:03 [INFO]: Epoch 003 - training loss: 1.0032, validation loss: 1.0381
2024-05-24 23:08:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch3_loss1.0381057560443878.pypots
2024-05-24 23:08:03 [INFO]: Epoch 004 - training loss: 0.9545, validation loss: 1.0093
2024-05-24 23:08:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch4_loss1.0092827826738358.pypots
2024-05-24 23:08:03 [INFO]: Epoch 005 - training loss: 0.9553, validation loss: 0.9931
2024-05-24 23:08:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch5_loss0.9930938333272934.pypots
2024-05-24 23:08:04 [INFO]: Epoch 006 - training loss: 0.9346, validation loss: 0.9845
2024-05-24 23:08:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch6_loss0.984528124332428.pypots
2024-05-24 23:08:04 [INFO]: Epoch 007 - training loss: 0.9279, validation loss: 0.9769
2024-05-24 23:08:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch7_loss0.976932018995285.pypots
2024-05-24 23:08:04 [INFO]: Epoch 008 - training loss: 0.9200, validation loss: 0.9680
2024-05-24 23:08:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch8_loss0.9679627865552902.pypots
2024-05-24 23:08:04 [INFO]: Epoch 009 - training loss: 0.8901, validation loss: 0.9634
2024-05-24 23:08:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch9_loss0.9634243994951248.pypots
2024-05-24 23:08:04 [INFO]: Epoch 010 - training loss: 0.9058, validation loss: 0.9586
2024-05-24 23:08:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch10_loss0.9585688710212708.pypots
2024-05-24 23:08:05 [INFO]: Epoch 011 - training loss: 0.9097, validation loss: 0.9541
2024-05-24 23:08:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch11_loss0.9540730565786362.pypots
2024-05-24 23:08:05 [INFO]: Epoch 012 - training loss: 0.8787, validation loss: 0.9500
2024-05-24 23:08:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch12_loss0.9499561190605164.pypots
2024-05-24 23:08:05 [INFO]: Epoch 013 - training loss: 0.8974, validation loss: 0.9459
2024-05-24 23:08:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch13_loss0.94587641954422.pypots
2024-05-24 23:08:05 [INFO]: Epoch 014 - training loss: 0.8887, validation loss: 0.9432
2024-05-24 23:08:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch14_loss0.9432450532913208.pypots
2024-05-24 23:08:05 [INFO]: Epoch 015 - training loss: 0.8982, validation loss: 0.9444
2024-05-24 23:08:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch15_loss0.9444490820169449.pypots
2024-05-24 23:08:05 [INFO]: Epoch 016 - training loss: 0.8724, validation loss: 0.9441
2024-05-24 23:08:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch16_loss0.9440516829490662.pypots
2024-05-24 23:08:06 [INFO]: Epoch 017 - training loss: 0.8655, validation loss: 0.9406
2024-05-24 23:08:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch17_loss0.9406195729970932.pypots
2024-05-24 23:08:06 [INFO]: Epoch 018 - training loss: 0.8793, validation loss: 0.9398
2024-05-24 23:08:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch18_loss0.9397825747728348.pypots
2024-05-24 23:08:06 [INFO]: Epoch 019 - training loss: 0.8891, validation loss: 0.9381
2024-05-24 23:08:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch19_loss0.9380577057600021.pypots
2024-05-24 23:08:06 [INFO]: Epoch 020 - training loss: 0.8744, validation loss: 0.9389
2024-05-24 23:08:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch20_loss0.9389056116342545.pypots
2024-05-24 23:08:06 [INFO]: Epoch 021 - training loss: 0.8621, validation loss: 0.9370
2024-05-24 23:08:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch21_loss0.9370419532060623.pypots
2024-05-24 23:08:07 [INFO]: Epoch 022 - training loss: 0.8417, validation loss: 0.9333
2024-05-24 23:08:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch22_loss0.9332970231771469.pypots
2024-05-24 23:08:07 [INFO]: Epoch 023 - training loss: 0.8385, validation loss: 0.9320
2024-05-24 23:08:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch23_loss0.932039201259613.pypots
2024-05-24 23:08:07 [INFO]: Epoch 024 - training loss: 0.8220, validation loss: 0.9320
2024-05-24 23:08:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch24_loss0.9319844990968704.pypots
2024-05-24 23:08:07 [INFO]: Epoch 025 - training loss: 0.8396, validation loss: 0.9335
2024-05-24 23:08:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch25_loss0.9334697872400284.pypots
2024-05-24 23:08:07 [INFO]: Epoch 026 - training loss: 0.8367, validation loss: 0.9286
2024-05-24 23:08:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch26_loss0.9285526275634766.pypots
2024-05-24 23:08:08 [INFO]: Epoch 027 - training loss: 0.8398, validation loss: 0.9231
2024-05-24 23:08:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch27_loss0.9231320470571518.pypots
2024-05-24 23:08:08 [INFO]: Epoch 028 - training loss: 0.8429, validation loss: 0.9199
2024-05-24 23:08:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch28_loss0.9198822528123856.pypots
2024-05-24 23:08:08 [INFO]: Epoch 029 - training loss: 0.8280, validation loss: 0.9209
2024-05-24 23:08:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch29_loss0.9209307134151459.pypots
2024-05-24 23:08:08 [INFO]: Epoch 030 - training loss: 0.8467, validation loss: 0.9189
2024-05-24 23:08:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch30_loss0.9189190566539764.pypots
2024-05-24 23:08:08 [INFO]: Epoch 031 - training loss: 0.8264, validation loss: 0.9144
2024-05-24 23:08:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch31_loss0.9144162833690643.pypots
2024-05-24 23:08:08 [INFO]: Epoch 032 - training loss: 0.8325, validation loss: 0.9117
2024-05-24 23:08:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch32_loss0.9117403030395508.pypots
2024-05-24 23:08:09 [INFO]: Epoch 033 - training loss: 0.8312, validation loss: 0.9091
2024-05-24 23:08:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch33_loss0.909055158495903.pypots
2024-05-24 23:08:09 [INFO]: Epoch 034 - training loss: 0.8292, validation loss: 0.9056
2024-05-24 23:08:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch34_loss0.9055542796850204.pypots
2024-05-24 23:08:09 [INFO]: Epoch 035 - training loss: 0.8232, validation loss: 0.9053
2024-05-24 23:08:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch35_loss0.9053023010492325.pypots
2024-05-24 23:08:09 [INFO]: Epoch 036 - training loss: 0.8010, validation loss: 0.9073
2024-05-24 23:08:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch36_loss0.9073459208011627.pypots
2024-05-24 23:08:09 [INFO]: Epoch 037 - training loss: 0.8557, validation loss: 0.9014
2024-05-24 23:08:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch37_loss0.9014144837856293.pypots
2024-05-24 23:08:10 [INFO]: Epoch 038 - training loss: 0.8408, validation loss: 0.8973
2024-05-24 23:08:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch38_loss0.897264301776886.pypots
2024-05-24 23:08:10 [INFO]: Epoch 039 - training loss: 0.7891, validation loss: 0.8942
2024-05-24 23:08:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch39_loss0.8941615968942642.pypots
2024-05-24 23:08:10 [INFO]: Epoch 040 - training loss: 0.8200, validation loss: 0.8921
2024-05-24 23:08:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch40_loss0.8921337723731995.pypots
2024-05-24 23:08:10 [INFO]: Epoch 041 - training loss: 0.8258, validation loss: 0.8885
2024-05-24 23:08:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch41_loss0.8884519785642624.pypots
2024-05-24 23:08:10 [INFO]: Epoch 042 - training loss: 0.8162, validation loss: 0.8885
2024-05-24 23:08:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch42_loss0.8884628564119339.pypots
2024-05-24 23:08:11 [INFO]: Epoch 043 - training loss: 0.8162, validation loss: 0.8850
2024-05-24 23:08:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch43_loss0.8850257992744446.pypots
2024-05-24 23:08:11 [INFO]: Epoch 044 - training loss: 0.8043, validation loss: 0.8838
2024-05-24 23:08:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch44_loss0.883800745010376.pypots
2024-05-24 23:08:11 [INFO]: Epoch 045 - training loss: 0.7997, validation loss: 0.8810
2024-05-24 23:08:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch45_loss0.8809644132852554.pypots
2024-05-24 23:08:11 [INFO]: Epoch 046 - training loss: 0.7920, validation loss: 0.8790
2024-05-24 23:08:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch46_loss0.8790425062179565.pypots
2024-05-24 23:08:11 [INFO]: Epoch 047 - training loss: 0.8283, validation loss: 0.8776
2024-05-24 23:08:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch47_loss0.8776107877492905.pypots
2024-05-24 23:08:11 [INFO]: Epoch 048 - training loss: 0.8198, validation loss: 0.8773
2024-05-24 23:08:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch48_loss0.8772838264703751.pypots
2024-05-24 23:08:12 [INFO]: Epoch 049 - training loss: 0.8398, validation loss: 0.8754
2024-05-24 23:08:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch49_loss0.8753870278596878.pypots
2024-05-24 23:08:12 [INFO]: Epoch 050 - training loss: 0.8111, validation loss: 0.8738
2024-05-24 23:08:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch50_loss0.8738397657871246.pypots
2024-05-24 23:08:12 [INFO]: Epoch 051 - training loss: 0.8179, validation loss: 0.8732
2024-05-24 23:08:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch51_loss0.873174637556076.pypots
2024-05-24 23:08:12 [INFO]: Epoch 052 - training loss: 0.7913, validation loss: 0.8702
2024-05-24 23:08:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch52_loss0.8701826333999634.pypots
2024-05-24 23:08:12 [INFO]: Epoch 053 - training loss: 0.8044, validation loss: 0.8690
2024-05-24 23:08:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch53_loss0.8689517229795456.pypots
2024-05-24 23:08:13 [INFO]: Epoch 054 - training loss: 0.8081, validation loss: 0.8702
2024-05-24 23:08:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch54_loss0.8702002465724945.pypots
2024-05-24 23:08:13 [INFO]: Epoch 055 - training loss: 0.8027, validation loss: 0.8670
2024-05-24 23:08:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch55_loss0.8669686615467072.pypots
2024-05-24 23:08:13 [INFO]: Epoch 056 - training loss: 0.8055, validation loss: 0.8671
2024-05-24 23:08:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch56_loss0.8671393543481827.pypots
2024-05-24 23:08:13 [INFO]: Epoch 057 - training loss: 0.8167, validation loss: 0.8670
2024-05-24 23:08:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch57_loss0.8670064061880112.pypots
2024-05-24 23:08:13 [INFO]: Epoch 058 - training loss: 0.8109, validation loss: 0.8638
2024-05-24 23:08:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch58_loss0.8638150691986084.pypots
2024-05-24 23:08:14 [INFO]: Epoch 059 - training loss: 0.8104, validation loss: 0.8625
2024-05-24 23:08:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch59_loss0.8625361770391464.pypots
2024-05-24 23:08:14 [INFO]: Epoch 060 - training loss: 0.8174, validation loss: 0.8605
2024-05-24 23:08:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch60_loss0.8604982495307922.pypots
2024-05-24 23:08:14 [INFO]: Epoch 061 - training loss: 0.7928, validation loss: 0.8631
2024-05-24 23:08:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch61_loss0.8630528151988983.pypots
2024-05-24 23:08:14 [INFO]: Epoch 062 - training loss: 0.7966, validation loss: 0.8626
2024-05-24 23:08:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch62_loss0.8625735193490982.pypots
2024-05-24 23:08:14 [INFO]: Epoch 063 - training loss: 0.8113, validation loss: 0.8589
2024-05-24 23:08:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch63_loss0.8589178770780563.pypots
2024-05-24 23:08:14 [INFO]: Epoch 064 - training loss: 0.7748, validation loss: 0.8584
2024-05-24 23:08:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch64_loss0.8583587110042572.pypots
2024-05-24 23:08:15 [INFO]: Epoch 065 - training loss: 0.7910, validation loss: 0.8560
2024-05-24 23:08:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch65_loss0.8560138791799545.pypots
2024-05-24 23:08:15 [INFO]: Epoch 066 - training loss: 0.8408, validation loss: 0.8554
2024-05-24 23:08:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch66_loss0.8553532212972641.pypots
2024-05-24 23:08:15 [INFO]: Epoch 067 - training loss: 0.8219, validation loss: 0.8558
2024-05-24 23:08:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch67_loss0.8557912409305573.pypots
2024-05-24 23:08:15 [INFO]: Epoch 068 - training loss: 0.7845, validation loss: 0.8549
2024-05-24 23:08:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch68_loss0.8549073934555054.pypots
2024-05-24 23:08:15 [INFO]: Epoch 069 - training loss: 0.7917, validation loss: 0.8561
2024-05-24 23:08:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch69_loss0.8560653328895569.pypots
2024-05-24 23:08:16 [INFO]: Epoch 070 - training loss: 0.7920, validation loss: 0.8560
2024-05-24 23:08:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch70_loss0.8560448437929153.pypots
2024-05-24 23:08:16 [INFO]: Epoch 071 - training loss: 0.8125, validation loss: 0.8525
2024-05-24 23:08:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch71_loss0.852478489279747.pypots
2024-05-24 23:08:16 [INFO]: Epoch 072 - training loss: 0.7729, validation loss: 0.8541
2024-05-24 23:08:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch72_loss0.8541138470172882.pypots
2024-05-24 23:08:16 [INFO]: Epoch 073 - training loss: 0.8168, validation loss: 0.8530
2024-05-24 23:08:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch73_loss0.8529568463563919.pypots
2024-05-24 23:08:16 [INFO]: Epoch 074 - training loss: 0.8148, validation loss: 0.8519
2024-05-24 23:08:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch74_loss0.8519127368927002.pypots
2024-05-24 23:08:17 [INFO]: Epoch 075 - training loss: 0.8518, validation loss: 0.8514
2024-05-24 23:08:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch75_loss0.8514178395271301.pypots
2024-05-24 23:08:17 [INFO]: Epoch 076 - training loss: 0.8185, validation loss: 0.8503
2024-05-24 23:08:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch76_loss0.8502781838178635.pypots
2024-05-24 23:08:17 [INFO]: Epoch 077 - training loss: 0.8079, validation loss: 0.8502
2024-05-24 23:08:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch77_loss0.8502210825681686.pypots
2024-05-24 23:08:17 [INFO]: Epoch 078 - training loss: 0.8109, validation loss: 0.8517
2024-05-24 23:08:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch78_loss0.8516933619976044.pypots
2024-05-24 23:08:17 [INFO]: Epoch 079 - training loss: 0.8309, validation loss: 0.8507
2024-05-24 23:08:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch79_loss0.8506504893302917.pypots
2024-05-24 23:08:18 [INFO]: Epoch 080 - training loss: 0.7896, validation loss: 0.8485
2024-05-24 23:08:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch80_loss0.8484924733638763.pypots
2024-05-24 23:08:18 [INFO]: Epoch 081 - training loss: 0.8035, validation loss: 0.8489
2024-05-24 23:08:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch81_loss0.8489158600568771.pypots
2024-05-24 23:08:18 [INFO]: Epoch 082 - training loss: 0.8056, validation loss: 0.8510
2024-05-24 23:08:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch82_loss0.8509611636400223.pypots
2024-05-24 23:08:18 [INFO]: Epoch 083 - training loss: 0.8196, validation loss: 0.8493
2024-05-24 23:08:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch83_loss0.8493483662605286.pypots
2024-05-24 23:08:18 [INFO]: Epoch 084 - training loss: 0.8396, validation loss: 0.8497
2024-05-24 23:08:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch84_loss0.8496866077184677.pypots
2024-05-24 23:08:18 [INFO]: Epoch 085 - training loss: 0.8193, validation loss: 0.8431
2024-05-24 23:08:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch85_loss0.8431336283683777.pypots
2024-05-24 23:08:19 [INFO]: Epoch 086 - training loss: 0.7832, validation loss: 0.8500
2024-05-24 23:08:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch86_loss0.850044846534729.pypots
2024-05-24 23:08:19 [INFO]: Epoch 087 - training loss: 0.7898, validation loss: 0.8502
2024-05-24 23:08:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch87_loss0.8501878380775452.pypots
2024-05-24 23:08:19 [INFO]: Epoch 088 - training loss: 0.7909, validation loss: 0.8503
2024-05-24 23:08:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch88_loss0.8502833694219589.pypots
2024-05-24 23:08:19 [INFO]: Epoch 089 - training loss: 0.8064, validation loss: 0.8497
2024-05-24 23:08:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch89_loss0.8496715128421783.pypots
2024-05-24 23:08:19 [INFO]: Epoch 090 - training loss: 0.7874, validation loss: 0.8495
2024-05-24 23:08:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch90_loss0.8495431691408157.pypots
2024-05-24 23:08:20 [INFO]: Epoch 091 - training loss: 0.7872, validation loss: 0.8509
2024-05-24 23:08:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch91_loss0.8509352803230286.pypots
2024-05-24 23:08:20 [INFO]: Epoch 092 - training loss: 0.7923, validation loss: 0.8505
2024-05-24 23:08:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch92_loss0.8505143821239471.pypots
2024-05-24 23:08:20 [INFO]: Epoch 093 - training loss: 0.8053, validation loss: 0.8500
2024-05-24 23:08:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch93_loss0.8500487059354782.pypots
2024-05-24 23:08:20 [INFO]: Epoch 094 - training loss: 0.7874, validation loss: 0.8513
2024-05-24 23:08:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch94_loss0.8513285219669342.pypots
2024-05-24 23:08:20 [INFO]: Epoch 095 - training loss: 0.8256, validation loss: 0.8522
2024-05-24 23:08:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN_epoch95_loss0.8522389382123947.pypots
2024-05-24 23:08:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:08:20 [INFO]: Finished training. The best model is from epoch#85.
2024-05-24 23:08:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T230801/MRNN.pypots
2024-05-24 23:08:21 [INFO]: MRNN on ETTm1: MAE=0.7224, MSE=1.2754
2024-05-24 23:08:21 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/MRNN_ettm1/imputation.pkl
2024-05-24 23:08:21 [INFO]: Using the given device: cpu
2024-05-24 23:08:21 [INFO]: LOCF on ETTm1: MAE=0.1332, MSE=0.0720
2024-05-24 23:08:21 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_ettm1".
2024-05-24 23:08:21 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/LOCF_ettm1/imputation.pkl
2024-05-24 23:08:21 [INFO]: Median on ETTm1: MAE=0.6670, MSE=0.8617
2024-05-24 23:08:21 [INFO]: Successfully created the given path "saved_results/round_0/Median_ettm1".
2024-05-24 23:08:21 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/Median_ettm1/imputation.pkl
2024-05-24 23:08:21 [INFO]: Mean on ETTm1: MAE=0.6734, MSE=0.8444
2024-05-24 23:08:21 [INFO]: Successfully created the given path "saved_results/round_0/Mean_ettm1".
2024-05-24 23:08:21 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/Mean_ettm1/imputation.pkl
2024-05-24 23:08:21 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-24 23:08:21 [INFO]: Using the given device: cuda:0
2024-05-24 23:08:21 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/SAITS_ettm1/20240524_T230821
2024-05-24 23:08:21 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/SAITS_ettm1/20240524_T230821/tensorboard
2024-05-24 23:08:21 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 23:08:21 [INFO]: Epoch 001 - training loss: 1.1310, validation loss: 0.2742
2024-05-24 23:08:22 [INFO]: Epoch 002 - training loss: 0.8396, validation loss: 0.1368
2024-05-24 23:08:22 [INFO]: Epoch 003 - training loss: 0.7596, validation loss: 0.0927
2024-05-24 23:08:23 [INFO]: Epoch 004 - training loss: 0.6934, validation loss: 0.0742
2024-05-24 23:08:23 [INFO]: Epoch 005 - training loss: 0.6701, validation loss: 0.0691
2024-05-24 23:08:24 [INFO]: Epoch 006 - training loss: 0.6558, validation loss: 0.0639
2024-05-24 23:08:24 [INFO]: Epoch 007 - training loss: 0.6336, validation loss: 0.0697
2024-05-24 23:08:25 [INFO]: Epoch 008 - training loss: 0.6050, validation loss: 0.0683
2024-05-24 23:08:25 [INFO]: Epoch 009 - training loss: 0.5844, validation loss: 0.0633
2024-05-24 23:08:26 [INFO]: Epoch 010 - training loss: 0.5692, validation loss: 0.0708
2024-05-24 23:08:26 [INFO]: Epoch 011 - training loss: 0.5648, validation loss: 0.0461
2024-05-24 23:08:27 [INFO]: Epoch 012 - training loss: 0.5616, validation loss: 0.0515
2024-05-24 23:08:27 [INFO]: Epoch 013 - training loss: 0.5365, validation loss: 0.0556
2024-05-24 23:08:28 [INFO]: Epoch 014 - training loss: 0.5209, validation loss: 0.0509
2024-05-24 23:08:28 [INFO]: Epoch 015 - training loss: 0.5159, validation loss: 0.0523
2024-05-24 23:08:29 [INFO]: Epoch 016 - training loss: 0.5054, validation loss: 0.0603
2024-05-24 23:08:30 [INFO]: Epoch 017 - training loss: 0.5042, validation loss: 0.0556
2024-05-24 23:08:30 [INFO]: Epoch 018 - training loss: 0.4870, validation loss: 0.0540
2024-05-24 23:08:31 [INFO]: Epoch 019 - training loss: 0.4816, validation loss: 0.0438
2024-05-24 23:08:31 [INFO]: Epoch 020 - training loss: 0.4670, validation loss: 0.0495
2024-05-24 23:08:32 [INFO]: Epoch 021 - training loss: 0.4601, validation loss: 0.0379
2024-05-24 23:08:32 [INFO]: Epoch 022 - training loss: 0.4564, validation loss: 0.0416
2024-05-24 23:08:33 [INFO]: Epoch 023 - training loss: 0.4595, validation loss: 0.0452
2024-05-24 23:08:33 [INFO]: Epoch 024 - training loss: 0.4508, validation loss: 0.0667
2024-05-24 23:08:34 [INFO]: Epoch 025 - training loss: 0.4504, validation loss: 0.0432
2024-05-24 23:08:34 [INFO]: Epoch 026 - training loss: 0.4493, validation loss: 0.0389
2024-05-24 23:08:35 [INFO]: Epoch 027 - training loss: 0.4333, validation loss: 0.0405
2024-05-24 23:08:35 [INFO]: Epoch 028 - training loss: 0.4347, validation loss: 0.0442
2024-05-24 23:08:36 [INFO]: Epoch 029 - training loss: 0.4152, validation loss: 0.0351
2024-05-24 23:08:36 [INFO]: Epoch 030 - training loss: 0.4156, validation loss: 0.0322
2024-05-24 23:08:37 [INFO]: Epoch 031 - training loss: 0.4035, validation loss: 0.0428
2024-05-24 23:08:37 [INFO]: Epoch 032 - training loss: 0.3998, validation loss: 0.0347
2024-05-24 23:08:38 [INFO]: Epoch 033 - training loss: 0.3965, validation loss: 0.0453
2024-05-24 23:08:38 [INFO]: Epoch 034 - training loss: 0.3981, validation loss: 0.0362
2024-05-24 23:08:39 [INFO]: Epoch 035 - training loss: 0.3917, validation loss: 0.0362
2024-05-24 23:08:39 [INFO]: Epoch 036 - training loss: 0.3799, validation loss: 0.0410
2024-05-24 23:08:40 [INFO]: Epoch 037 - training loss: 0.3768, validation loss: 0.0380
2024-05-24 23:08:40 [INFO]: Epoch 038 - training loss: 0.3705, validation loss: 0.0353
2024-05-24 23:08:41 [INFO]: Epoch 039 - training loss: 0.3741, validation loss: 0.0404
2024-05-24 23:08:41 [INFO]: Epoch 040 - training loss: 0.3676, validation loss: 0.0336
2024-05-24 23:08:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:08:41 [INFO]: Finished training. The best model is from epoch#30.
2024-05-24 23:08:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/SAITS_ettm1/20240524_T230821/SAITS.pypots
2024-05-24 23:08:41 [INFO]: SAITS on ETTm1: MAE=0.1440, MSE=0.0364
2024-05-24 23:08:41 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/SAITS_ettm1/imputation.pkl
2024-05-24 23:08:41 [INFO]: Using the given device: cuda:0
2024-05-24 23:08:41 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/Transformer_ettm1/20240524_T230841
2024-05-24 23:08:41 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/Transformer_ettm1/20240524_T230841/tensorboard
2024-05-24 23:08:41 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 23:08:42 [INFO]: Epoch 001 - training loss: 1.1699, validation loss: 0.3462
2024-05-24 23:08:42 [INFO]: Epoch 002 - training loss: 0.7348, validation loss: 0.1496
2024-05-24 23:08:42 [INFO]: Epoch 003 - training loss: 0.6045, validation loss: 0.1135
2024-05-24 23:08:42 [INFO]: Epoch 004 - training loss: 0.5366, validation loss: 0.0904
2024-05-24 23:08:42 [INFO]: Epoch 005 - training loss: 0.4932, validation loss: 0.0707
2024-05-24 23:08:43 [INFO]: Epoch 006 - training loss: 0.4684, validation loss: 0.0641
2024-05-24 23:08:43 [INFO]: Epoch 007 - training loss: 0.4498, validation loss: 0.0716
2024-05-24 23:08:43 [INFO]: Epoch 008 - training loss: 0.4278, validation loss: 0.0601
2024-05-24 23:08:43 [INFO]: Epoch 009 - training loss: 0.4030, validation loss: 0.0513
2024-05-24 23:08:44 [INFO]: Epoch 010 - training loss: 0.3932, validation loss: 0.0598
2024-05-24 23:08:44 [INFO]: Epoch 011 - training loss: 0.3811, validation loss: 0.0504
2024-05-24 23:08:44 [INFO]: Epoch 012 - training loss: 0.3722, validation loss: 0.0509
2024-05-24 23:08:44 [INFO]: Epoch 013 - training loss: 0.3672, validation loss: 0.0561
2024-05-24 23:08:44 [INFO]: Epoch 014 - training loss: 0.3579, validation loss: 0.0477
2024-05-24 23:08:45 [INFO]: Epoch 015 - training loss: 0.3469, validation loss: 0.0421
2024-05-24 23:08:45 [INFO]: Epoch 016 - training loss: 0.3443, validation loss: 0.0393
2024-05-24 23:08:45 [INFO]: Epoch 017 - training loss: 0.3311, validation loss: 0.0412
2024-05-24 23:08:45 [INFO]: Epoch 018 - training loss: 0.3256, validation loss: 0.0417
2024-05-24 23:08:46 [INFO]: Epoch 019 - training loss: 0.3256, validation loss: 0.0367
2024-05-24 23:08:46 [INFO]: Epoch 020 - training loss: 0.3174, validation loss: 0.0378
2024-05-24 23:08:46 [INFO]: Epoch 021 - training loss: 0.3163, validation loss: 0.0349
2024-05-24 23:08:46 [INFO]: Epoch 022 - training loss: 0.3110, validation loss: 0.0315
2024-05-24 23:08:46 [INFO]: Epoch 023 - training loss: 0.3094, validation loss: 0.0418
2024-05-24 23:08:47 [INFO]: Epoch 024 - training loss: 0.3049, validation loss: 0.0404
2024-05-24 23:08:47 [INFO]: Epoch 025 - training loss: 0.3007, validation loss: 0.0340
2024-05-24 23:08:47 [INFO]: Epoch 026 - training loss: 0.2973, validation loss: 0.0305
2024-05-24 23:08:47 [INFO]: Epoch 027 - training loss: 0.2936, validation loss: 0.0318
2024-05-24 23:08:47 [INFO]: Epoch 028 - training loss: 0.2899, validation loss: 0.0336
2024-05-24 23:08:48 [INFO]: Epoch 029 - training loss: 0.2815, validation loss: 0.0304
2024-05-24 23:08:48 [INFO]: Epoch 030 - training loss: 0.2795, validation loss: 0.0320
2024-05-24 23:08:48 [INFO]: Epoch 031 - training loss: 0.2800, validation loss: 0.0310
2024-05-24 23:08:48 [INFO]: Epoch 032 - training loss: 0.2705, validation loss: 0.0295
2024-05-24 23:08:49 [INFO]: Epoch 033 - training loss: 0.2753, validation loss: 0.0295
2024-05-24 23:08:49 [INFO]: Epoch 034 - training loss: 0.2707, validation loss: 0.0286
2024-05-24 23:08:49 [INFO]: Epoch 035 - training loss: 0.2697, validation loss: 0.0277
2024-05-24 23:08:49 [INFO]: Epoch 036 - training loss: 0.2762, validation loss: 0.0275
2024-05-24 23:08:49 [INFO]: Epoch 037 - training loss: 0.2677, validation loss: 0.0249
2024-05-24 23:08:50 [INFO]: Epoch 038 - training loss: 0.2586, validation loss: 0.0316
2024-05-24 23:08:50 [INFO]: Epoch 039 - training loss: 0.2650, validation loss: 0.0278
2024-05-24 23:08:50 [INFO]: Epoch 040 - training loss: 0.2570, validation loss: 0.0315
2024-05-24 23:08:50 [INFO]: Epoch 041 - training loss: 0.2520, validation loss: 0.0289
2024-05-24 23:08:51 [INFO]: Epoch 042 - training loss: 0.2516, validation loss: 0.0308
2024-05-24 23:08:51 [INFO]: Epoch 043 - training loss: 0.2515, validation loss: 0.0291
2024-05-24 23:08:51 [INFO]: Epoch 044 - training loss: 0.2504, validation loss: 0.0248
2024-05-24 23:08:51 [INFO]: Epoch 045 - training loss: 0.2406, validation loss: 0.0237
2024-05-24 23:08:51 [INFO]: Epoch 046 - training loss: 0.2382, validation loss: 0.0284
2024-05-24 23:08:52 [INFO]: Epoch 047 - training loss: 0.2450, validation loss: 0.0264
2024-05-24 23:08:52 [INFO]: Epoch 048 - training loss: 0.2423, validation loss: 0.0230
2024-05-24 23:08:52 [INFO]: Epoch 049 - training loss: 0.2372, validation loss: 0.0246
2024-05-24 23:08:52 [INFO]: Epoch 050 - training loss: 0.2359, validation loss: 0.0249
2024-05-24 23:08:52 [INFO]: Epoch 051 - training loss: 0.2370, validation loss: 0.0231
2024-05-24 23:08:53 [INFO]: Epoch 052 - training loss: 0.2303, validation loss: 0.0251
2024-05-24 23:08:53 [INFO]: Epoch 053 - training loss: 0.2303, validation loss: 0.0224
2024-05-24 23:08:53 [INFO]: Epoch 054 - training loss: 0.2266, validation loss: 0.0230
2024-05-24 23:08:53 [INFO]: Epoch 055 - training loss: 0.2246, validation loss: 0.0253
2024-05-24 23:08:54 [INFO]: Epoch 056 - training loss: 0.2254, validation loss: 0.0243
2024-05-24 23:08:54 [INFO]: Epoch 057 - training loss: 0.2244, validation loss: 0.0236
2024-05-24 23:08:54 [INFO]: Epoch 058 - training loss: 0.2209, validation loss: 0.0217
2024-05-24 23:08:54 [INFO]: Epoch 059 - training loss: 0.2218, validation loss: 0.0232
2024-05-24 23:08:54 [INFO]: Epoch 060 - training loss: 0.2279, validation loss: 0.0237
2024-05-24 23:08:55 [INFO]: Epoch 061 - training loss: 0.2200, validation loss: 0.0218
2024-05-24 23:08:55 [INFO]: Epoch 062 - training loss: 0.2185, validation loss: 0.0223
2024-05-24 23:08:55 [INFO]: Epoch 063 - training loss: 0.2226, validation loss: 0.0247
2024-05-24 23:08:55 [INFO]: Epoch 064 - training loss: 0.2261, validation loss: 0.0208
2024-05-24 23:08:55 [INFO]: Epoch 065 - training loss: 0.2205, validation loss: 0.0258
2024-05-24 23:08:56 [INFO]: Epoch 066 - training loss: 0.2195, validation loss: 0.0209
2024-05-24 23:08:56 [INFO]: Epoch 067 - training loss: 0.2130, validation loss: 0.0202
2024-05-24 23:08:56 [INFO]: Epoch 068 - training loss: 0.2089, validation loss: 0.0264
2024-05-24 23:08:56 [INFO]: Epoch 069 - training loss: 0.2181, validation loss: 0.0247
2024-05-24 23:08:57 [INFO]: Epoch 070 - training loss: 0.2217, validation loss: 0.0223
2024-05-24 23:08:57 [INFO]: Epoch 071 - training loss: 0.2111, validation loss: 0.0227
2024-05-24 23:08:57 [INFO]: Epoch 072 - training loss: 0.2080, validation loss: 0.0215
2024-05-24 23:08:57 [INFO]: Epoch 073 - training loss: 0.2081, validation loss: 0.0246
2024-05-24 23:08:57 [INFO]: Epoch 074 - training loss: 0.2163, validation loss: 0.0224
2024-05-24 23:08:58 [INFO]: Epoch 075 - training loss: 0.2106, validation loss: 0.0208
2024-05-24 23:08:58 [INFO]: Epoch 076 - training loss: 0.2087, validation loss: 0.0217
2024-05-24 23:08:58 [INFO]: Epoch 077 - training loss: 0.2080, validation loss: 0.0202
2024-05-24 23:08:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:08:58 [INFO]: Finished training. The best model is from epoch#67.
2024-05-24 23:08:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/Transformer_ettm1/20240524_T230841/Transformer.pypots
2024-05-24 23:08:58 [INFO]: Transformer on ETTm1: MAE=0.1160, MSE=0.0266
2024-05-24 23:08:58 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/Transformer_ettm1/imputation.pkl
2024-05-24 23:08:58 [INFO]: Using the given device: cuda:0
2024-05-24 23:08:58 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/TimesNet_ettm1/20240524_T230858
2024-05-24 23:08:58 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/TimesNet_ettm1/20240524_T230858/tensorboard
2024-05-24 23:08:58 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 23:08:59 [INFO]: Epoch 001 - training loss: 0.1623, validation loss: 0.0556
2024-05-24 23:08:59 [INFO]: Epoch 002 - training loss: 0.0667, validation loss: 0.0378
2024-05-24 23:08:59 [INFO]: Epoch 003 - training loss: 0.0527, validation loss: 0.0340
2024-05-24 23:08:59 [INFO]: Epoch 004 - training loss: 0.0492, validation loss: 0.0320
2024-05-24 23:08:59 [INFO]: Epoch 005 - training loss: 0.0470, validation loss: 0.0319
2024-05-24 23:09:00 [INFO]: Epoch 006 - training loss: 0.0457, validation loss: 0.0310
2024-05-24 23:09:00 [INFO]: Epoch 007 - training loss: 0.0459, validation loss: 0.0285
2024-05-24 23:09:00 [INFO]: Epoch 008 - training loss: 0.0455, validation loss: 0.0304
2024-05-24 23:09:00 [INFO]: Epoch 009 - training loss: 0.0452, validation loss: 0.0348
2024-05-24 23:09:00 [INFO]: Epoch 010 - training loss: 0.0465, validation loss: 0.0318
2024-05-24 23:09:01 [INFO]: Epoch 011 - training loss: 0.0416, validation loss: 0.0309
2024-05-24 23:09:01 [INFO]: Epoch 012 - training loss: 0.0424, validation loss: 0.0299
2024-05-24 23:09:01 [INFO]: Epoch 013 - training loss: 0.0417, validation loss: 0.0289
2024-05-24 23:09:01 [INFO]: Epoch 014 - training loss: 0.0405, validation loss: 0.0268
2024-05-24 23:09:02 [INFO]: Epoch 015 - training loss: 0.0428, validation loss: 0.0271
2024-05-24 23:09:02 [INFO]: Epoch 016 - training loss: 0.0433, validation loss: 0.0298
2024-05-24 23:09:02 [INFO]: Epoch 017 - training loss: 0.0415, validation loss: 0.0266
2024-05-24 23:09:02 [INFO]: Epoch 018 - training loss: 0.0402, validation loss: 0.0265
2024-05-24 23:09:02 [INFO]: Epoch 019 - training loss: 0.0384, validation loss: 0.0271
2024-05-24 23:09:03 [INFO]: Epoch 020 - training loss: 0.0390, validation loss: 0.0269
2024-05-24 23:09:03 [INFO]: Epoch 021 - training loss: 0.0385, validation loss: 0.0271
2024-05-24 23:09:03 [INFO]: Epoch 022 - training loss: 0.0364, validation loss: 0.0251
2024-05-24 23:09:03 [INFO]: Epoch 023 - training loss: 0.0376, validation loss: 0.0253
2024-05-24 23:09:03 [INFO]: Epoch 024 - training loss: 0.0371, validation loss: 0.0263
2024-05-24 23:09:04 [INFO]: Epoch 025 - training loss: 0.0368, validation loss: 0.0241
2024-05-24 23:09:04 [INFO]: Epoch 026 - training loss: 0.0352, validation loss: 0.0244
2024-05-24 23:09:04 [INFO]: Epoch 027 - training loss: 0.0359, validation loss: 0.0254
2024-05-24 23:09:04 [INFO]: Epoch 028 - training loss: 0.0375, validation loss: 0.0251
2024-05-24 23:09:05 [INFO]: Epoch 029 - training loss: 0.0381, validation loss: 0.0272
2024-05-24 23:09:05 [INFO]: Epoch 030 - training loss: 0.0376, validation loss: 0.0243
2024-05-24 23:09:05 [INFO]: Epoch 031 - training loss: 0.0366, validation loss: 0.0253
2024-05-24 23:09:05 [INFO]: Epoch 032 - training loss: 0.0354, validation loss: 0.0258
2024-05-24 23:09:05 [INFO]: Epoch 033 - training loss: 0.0358, validation loss: 0.0250
2024-05-24 23:09:06 [INFO]: Epoch 034 - training loss: 0.0351, validation loss: 0.0252
2024-05-24 23:09:06 [INFO]: Epoch 035 - training loss: 0.0350, validation loss: 0.0254
2024-05-24 23:09:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:09:06 [INFO]: Finished training. The best model is from epoch#25.
2024-05-24 23:09:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/TimesNet_ettm1/20240524_T230858/TimesNet.pypots
2024-05-24 23:09:06 [INFO]: TimesNet on ETTm1: MAE=0.1113, MSE=0.0260
2024-05-24 23:09:06 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/TimesNet_ettm1/imputation.pkl
2024-05-24 23:09:06 [INFO]: Using the given device: cuda:0
2024-05-24 23:09:06 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906
2024-05-24 23:09:06 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/tensorboard
2024-05-24 23:09:06 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 23:09:08 [INFO]: Epoch 001 - training loss: 0.7113, validation loss: 0.4280
2024-05-24 23:09:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch1_loss0.4280063360929489.pypots
2024-05-24 23:09:10 [INFO]: Epoch 002 - training loss: 0.3841, validation loss: 0.3543
2024-05-24 23:09:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch2_loss0.3542556092143059.pypots
2024-05-24 23:09:12 [INFO]: Epoch 003 - training loss: 0.3776, validation loss: 0.3830
2024-05-24 23:09:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch3_loss0.38304319977760315.pypots
2024-05-24 23:09:14 [INFO]: Epoch 004 - training loss: 0.3313, validation loss: 0.3436
2024-05-24 23:09:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch4_loss0.34361784160137177.pypots
2024-05-24 23:09:16 [INFO]: Epoch 005 - training loss: 0.3072, validation loss: 0.3271
2024-05-24 23:09:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch5_loss0.32709329575300217.pypots
2024-05-24 23:09:18 [INFO]: Epoch 006 - training loss: 0.2798, validation loss: 0.3002
2024-05-24 23:09:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch6_loss0.30018283426761627.pypots
2024-05-24 23:09:21 [INFO]: Epoch 007 - training loss: 0.3133, validation loss: 0.2995
2024-05-24 23:09:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch7_loss0.299475722014904.pypots
2024-05-24 23:09:23 [INFO]: Epoch 008 - training loss: 0.2981, validation loss: 0.2953
2024-05-24 23:09:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch8_loss0.2953445538878441.pypots
2024-05-24 23:09:25 [INFO]: Epoch 009 - training loss: 0.2492, validation loss: 0.2695
2024-05-24 23:09:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch9_loss0.2695368677377701.pypots
2024-05-24 23:09:27 [INFO]: Epoch 010 - training loss: 0.3509, validation loss: 0.2650
2024-05-24 23:09:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch10_loss0.2649710029363632.pypots
2024-05-24 23:09:29 [INFO]: Epoch 011 - training loss: 0.2926, validation loss: 0.2480
2024-05-24 23:09:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch11_loss0.2479635775089264.pypots
2024-05-24 23:09:31 [INFO]: Epoch 012 - training loss: 0.2462, validation loss: 0.2479
2024-05-24 23:09:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch12_loss0.24789121374487877.pypots
2024-05-24 23:09:33 [INFO]: Epoch 013 - training loss: 0.2210, validation loss: 0.2462
2024-05-24 23:09:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch13_loss0.24622241780161858.pypots
2024-05-24 23:09:35 [INFO]: Epoch 014 - training loss: 0.2361, validation loss: 0.2374
2024-05-24 23:09:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch14_loss0.23744675517082214.pypots
2024-05-24 23:09:37 [INFO]: Epoch 015 - training loss: 0.2563, validation loss: 0.2345
2024-05-24 23:09:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch15_loss0.23449386656284332.pypots
2024-05-24 23:09:39 [INFO]: Epoch 016 - training loss: 0.2176, validation loss: 0.2353
2024-05-24 23:09:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch16_loss0.23526094108819962.pypots
2024-05-24 23:09:41 [INFO]: Epoch 017 - training loss: 0.2285, validation loss: 0.2128
2024-05-24 23:09:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch17_loss0.2127629704773426.pypots
2024-05-24 23:09:43 [INFO]: Epoch 018 - training loss: 0.1747, validation loss: 0.2142
2024-05-24 23:09:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch18_loss0.21415406838059425.pypots
2024-05-24 23:09:46 [INFO]: Epoch 019 - training loss: 0.2250, validation loss: 0.2058
2024-05-24 23:09:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch19_loss0.20580045133829117.pypots
2024-05-24 23:09:48 [INFO]: Epoch 020 - training loss: 0.2238, validation loss: 0.2025
2024-05-24 23:09:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch20_loss0.20251254364848137.pypots
2024-05-24 23:09:50 [INFO]: Epoch 021 - training loss: 0.1685, validation loss: 0.1990
2024-05-24 23:09:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch21_loss0.19899368658661842.pypots
2024-05-24 23:09:52 [INFO]: Epoch 022 - training loss: 0.1860, validation loss: 0.1947
2024-05-24 23:09:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch22_loss0.1947152502834797.pypots
2024-05-24 23:09:54 [INFO]: Epoch 023 - training loss: 0.1757, validation loss: 0.1899
2024-05-24 23:09:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch23_loss0.18994199112057686.pypots
2024-05-24 23:09:56 [INFO]: Epoch 024 - training loss: 0.1741, validation loss: 0.1839
2024-05-24 23:09:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch24_loss0.1839095801115036.pypots
2024-05-24 23:09:58 [INFO]: Epoch 025 - training loss: 0.1864, validation loss: 0.1785
2024-05-24 23:09:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch25_loss0.17845185846090317.pypots
2024-05-24 23:10:00 [INFO]: Epoch 026 - training loss: 0.2499, validation loss: 0.1762
2024-05-24 23:10:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch26_loss0.17618881911039352.pypots
2024-05-24 23:10:02 [INFO]: Epoch 027 - training loss: 0.2286, validation loss: 0.1743
2024-05-24 23:10:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch27_loss0.1743391565978527.pypots
2024-05-24 23:10:04 [INFO]: Epoch 028 - training loss: 0.2606, validation loss: 0.1832
2024-05-24 23:10:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch28_loss0.18318668007850647.pypots
2024-05-24 23:10:06 [INFO]: Epoch 029 - training loss: 0.2035, validation loss: 0.1931
2024-05-24 23:10:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch29_loss0.1930999904870987.pypots
2024-05-24 23:10:08 [INFO]: Epoch 030 - training loss: 0.1668, validation loss: 0.1691
2024-05-24 23:10:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch30_loss0.1691414937376976.pypots
2024-05-24 23:10:10 [INFO]: Epoch 031 - training loss: 0.1723, validation loss: 0.1759
2024-05-24 23:10:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch31_loss0.17585135996341705.pypots
2024-05-24 23:10:13 [INFO]: Epoch 032 - training loss: 0.1803, validation loss: 0.1792
2024-05-24 23:10:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch32_loss0.17923637852072716.pypots
2024-05-24 23:10:15 [INFO]: Epoch 033 - training loss: 0.2155, validation loss: 0.1624
2024-05-24 23:10:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch33_loss0.1624494194984436.pypots
2024-05-24 23:10:17 [INFO]: Epoch 034 - training loss: 0.1787, validation loss: 0.1643
2024-05-24 23:10:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch34_loss0.16425033658742905.pypots
2024-05-24 23:10:19 [INFO]: Epoch 035 - training loss: 0.1866, validation loss: 0.1641
2024-05-24 23:10:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch35_loss0.16410311311483383.pypots
2024-05-24 23:10:21 [INFO]: Epoch 036 - training loss: 0.1971, validation loss: 0.1637
2024-05-24 23:10:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch36_loss0.16371366754174232.pypots
2024-05-24 23:10:23 [INFO]: Epoch 037 - training loss: 0.1793, validation loss: 0.1597
2024-05-24 23:10:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch37_loss0.1596912443637848.pypots
2024-05-24 23:10:25 [INFO]: Epoch 038 - training loss: 0.2033, validation loss: 0.1601
2024-05-24 23:10:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch38_loss0.1600547507405281.pypots
2024-05-24 23:10:27 [INFO]: Epoch 039 - training loss: 0.1754, validation loss: 0.1575
2024-05-24 23:10:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch39_loss0.15746314451098442.pypots
2024-05-24 23:10:29 [INFO]: Epoch 040 - training loss: 0.1866, validation loss: 0.1601
2024-05-24 23:10:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch40_loss0.160116545855999.pypots
2024-05-24 23:10:31 [INFO]: Epoch 041 - training loss: 0.1982, validation loss: 0.1539
2024-05-24 23:10:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch41_loss0.15389328822493553.pypots
2024-05-24 23:10:33 [INFO]: Epoch 042 - training loss: 0.2052, validation loss: 0.2125
2024-05-24 23:10:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch42_loss0.21251243352890015.pypots
2024-05-24 23:10:35 [INFO]: Epoch 043 - training loss: 0.2337, validation loss: 0.2049
2024-05-24 23:10:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch43_loss0.2048804983496666.pypots
2024-05-24 23:10:37 [INFO]: Epoch 044 - training loss: 0.1928, validation loss: 0.1865
2024-05-24 23:10:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch44_loss0.18650714680552483.pypots
2024-05-24 23:10:40 [INFO]: Epoch 045 - training loss: 0.1758, validation loss: 0.1643
2024-05-24 23:10:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch45_loss0.1642925776541233.pypots
2024-05-24 23:10:42 [INFO]: Epoch 046 - training loss: 0.1741, validation loss: 0.1504
2024-05-24 23:10:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch46_loss0.15037427470088005.pypots
2024-05-24 23:10:44 [INFO]: Epoch 047 - training loss: 0.1559, validation loss: 0.1472
2024-05-24 23:10:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch47_loss0.1471875235438347.pypots
2024-05-24 23:10:46 [INFO]: Epoch 048 - training loss: 0.1704, validation loss: 0.1456
2024-05-24 23:10:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch48_loss0.14563162997364998.pypots
2024-05-24 23:10:48 [INFO]: Epoch 049 - training loss: 0.1593, validation loss: 0.1420
2024-05-24 23:10:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch49_loss0.1419820338487625.pypots
2024-05-24 23:10:50 [INFO]: Epoch 050 - training loss: 0.1575, validation loss: 0.1428
2024-05-24 23:10:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch50_loss0.1428406573832035.pypots
2024-05-24 23:10:52 [INFO]: Epoch 051 - training loss: 0.1458, validation loss: 0.1383
2024-05-24 23:10:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch51_loss0.13828576728701591.pypots
2024-05-24 23:10:54 [INFO]: Epoch 052 - training loss: 0.1750, validation loss: 0.1571
2024-05-24 23:10:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch52_loss0.15712977200746536.pypots
2024-05-24 23:10:56 [INFO]: Epoch 053 - training loss: 0.1825, validation loss: 0.1790
2024-05-24 23:10:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch53_loss0.17897165566682816.pypots
2024-05-24 23:10:58 [INFO]: Epoch 054 - training loss: 0.1576, validation loss: 0.1587
2024-05-24 23:10:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch54_loss0.1587347500026226.pypots
2024-05-24 23:11:00 [INFO]: Epoch 055 - training loss: 0.1441, validation loss: 0.1426
2024-05-24 23:11:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch55_loss0.142568189650774.pypots
2024-05-24 23:11:02 [INFO]: Epoch 056 - training loss: 0.1614, validation loss: 0.1389
2024-05-24 23:11:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch56_loss0.13890328258275986.pypots
2024-05-24 23:11:05 [INFO]: Epoch 057 - training loss: 0.1626, validation loss: 0.1380
2024-05-24 23:11:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch57_loss0.13802065700292587.pypots
2024-05-24 23:11:07 [INFO]: Epoch 058 - training loss: 0.1455, validation loss: 0.1371
2024-05-24 23:11:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch58_loss0.13712701946496964.pypots
2024-05-24 23:11:09 [INFO]: Epoch 059 - training loss: 0.1590, validation loss: 0.1355
2024-05-24 23:11:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch59_loss0.1355288401246071.pypots
2024-05-24 23:11:11 [INFO]: Epoch 060 - training loss: 0.1692, validation loss: 0.1333
2024-05-24 23:11:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch60_loss0.1332842856645584.pypots
2024-05-24 23:11:13 [INFO]: Epoch 061 - training loss: 0.2205, validation loss: 0.1340
2024-05-24 23:11:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch61_loss0.13395492732524872.pypots
2024-05-24 23:11:15 [INFO]: Epoch 062 - training loss: 0.1849, validation loss: 0.1399
2024-05-24 23:11:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch62_loss0.1399068720638752.pypots
2024-05-24 23:11:17 [INFO]: Epoch 063 - training loss: 0.1677, validation loss: 0.1422
2024-05-24 23:11:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch63_loss0.14216072484850883.pypots
2024-05-24 23:11:19 [INFO]: Epoch 064 - training loss: 0.1946, validation loss: 0.1448
2024-05-24 23:11:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch64_loss0.14479715377092361.pypots
2024-05-24 23:11:21 [INFO]: Epoch 065 - training loss: 0.1775, validation loss: 0.1453
2024-05-24 23:11:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch65_loss0.14530007168650627.pypots
2024-05-24 23:11:23 [INFO]: Epoch 066 - training loss: 0.1533, validation loss: 0.1527
2024-05-24 23:11:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch66_loss0.15273961052298546.pypots
2024-05-24 23:11:25 [INFO]: Epoch 067 - training loss: 0.1716, validation loss: 0.1396
2024-05-24 23:11:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch67_loss0.13961129263043404.pypots
2024-05-24 23:11:27 [INFO]: Epoch 068 - training loss: 0.1446, validation loss: 0.1348
2024-05-24 23:11:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch68_loss0.1348358429968357.pypots
2024-05-24 23:11:29 [INFO]: Epoch 069 - training loss: 0.1530, validation loss: 0.1396
2024-05-24 23:11:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch69_loss0.13963178172707558.pypots
2024-05-24 23:11:32 [INFO]: Epoch 070 - training loss: 0.1849, validation loss: 0.1429
2024-05-24 23:11:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI_epoch70_loss0.14286420494318008.pypots
2024-05-24 23:11:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:11:32 [INFO]: Finished training. The best model is from epoch#60.
2024-05-24 23:11:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T230906/CSDI.pypots
2024-05-24 23:11:47 [INFO]: CSDI on ETTm1: MAE=0.1459, MSE=0.1880
2024-05-24 23:11:47 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/CSDI_ettm1/imputation.pkl
2024-05-24 23:11:47 [INFO]: Using the given device: cuda:0
2024-05-24 23:11:47 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/GPVAE_ettm1/20240524_T231147
2024-05-24 23:11:47 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/GPVAE_ettm1/20240524_T231147/tensorboard
2024-05-24 23:11:48 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 23:11:48 [INFO]: Epoch 001 - training loss: 24171.4297, validation loss: 0.9653
2024-05-24 23:11:48 [INFO]: Epoch 002 - training loss: 21809.8041, validation loss: 0.9554
2024-05-24 23:11:48 [INFO]: Epoch 003 - training loss: 19928.1157, validation loss: 0.9406
2024-05-24 23:11:48 [INFO]: Epoch 004 - training loss: 17890.7661, validation loss: 0.9162
2024-05-24 23:11:48 [INFO]: Epoch 005 - training loss: 16026.2814, validation loss: 0.8669
2024-05-24 23:11:48 [INFO]: Epoch 006 - training loss: 14459.2457, validation loss: 0.7912
2024-05-24 23:11:48 [INFO]: Epoch 007 - training loss: 13093.6538, validation loss: 0.7135
2024-05-24 23:11:49 [INFO]: Epoch 008 - training loss: 12307.0189, validation loss: 0.6243
2024-05-24 23:11:49 [INFO]: Epoch 009 - training loss: 11713.4876, validation loss: 0.5373
2024-05-24 23:11:49 [INFO]: Epoch 010 - training loss: 11117.2496, validation loss: 0.4835
2024-05-24 23:11:49 [INFO]: Epoch 011 - training loss: 10814.9495, validation loss: 0.4699
2024-05-24 23:11:49 [INFO]: Epoch 012 - training loss: 10534.3126, validation loss: 0.4599
2024-05-24 23:11:49 [INFO]: Epoch 013 - training loss: 10372.4051, validation loss: 0.4383
2024-05-24 23:11:49 [INFO]: Epoch 014 - training loss: 10223.9761, validation loss: 0.4199
2024-05-24 23:11:50 [INFO]: Epoch 015 - training loss: 10130.9343, validation loss: 0.3996
2024-05-24 23:11:50 [INFO]: Epoch 016 - training loss: 10009.4102, validation loss: 0.3668
2024-05-24 23:11:50 [INFO]: Epoch 017 - training loss: 9941.1440, validation loss: 0.3578
2024-05-24 23:11:50 [INFO]: Epoch 018 - training loss: 9890.5893, validation loss: 0.3402
2024-05-24 23:11:50 [INFO]: Epoch 019 - training loss: 9804.2459, validation loss: 0.3237
2024-05-24 23:11:50 [INFO]: Epoch 020 - training loss: 9766.6632, validation loss: 0.3166
2024-05-24 23:11:50 [INFO]: Epoch 021 - training loss: 9727.9521, validation loss: 0.3050
2024-05-24 23:11:50 [INFO]: Epoch 022 - training loss: 9680.7109, validation loss: 0.2899
2024-05-24 23:11:51 [INFO]: Epoch 023 - training loss: 9668.2335, validation loss: 0.2915
2024-05-24 23:11:51 [INFO]: Epoch 024 - training loss: 9621.8560, validation loss: 0.2821
2024-05-24 23:11:51 [INFO]: Epoch 025 - training loss: 9610.2474, validation loss: 0.2714
2024-05-24 23:11:51 [INFO]: Epoch 026 - training loss: 9589.3670, validation loss: 0.2661
2024-05-24 23:11:51 [INFO]: Epoch 027 - training loss: 9571.6040, validation loss: 0.2589
2024-05-24 23:11:51 [INFO]: Epoch 028 - training loss: 9544.0068, validation loss: 0.2474
2024-05-24 23:11:51 [INFO]: Epoch 029 - training loss: 9543.8685, validation loss: 0.2417
2024-05-24 23:11:52 [INFO]: Epoch 030 - training loss: 9538.2220, validation loss: 0.2376
2024-05-24 23:11:52 [INFO]: Epoch 031 - training loss: 9504.3384, validation loss: 0.2291
2024-05-24 23:11:52 [INFO]: Epoch 032 - training loss: 9491.6804, validation loss: 0.2221
2024-05-24 23:11:52 [INFO]: Epoch 033 - training loss: 9485.1730, validation loss: 0.2191
2024-05-24 23:11:52 [INFO]: Epoch 034 - training loss: 9476.9575, validation loss: 0.2146
2024-05-24 23:11:52 [INFO]: Epoch 035 - training loss: 9463.3870, validation loss: 0.2072
2024-05-24 23:11:52 [INFO]: Epoch 036 - training loss: 9461.3304, validation loss: 0.2013
2024-05-24 23:11:52 [INFO]: Epoch 037 - training loss: 9444.1330, validation loss: 0.2001
2024-05-24 23:11:53 [INFO]: Epoch 038 - training loss: 9442.1201, validation loss: 0.1959
2024-05-24 23:11:53 [INFO]: Epoch 039 - training loss: 9443.3069, validation loss: 0.1916
2024-05-24 23:11:53 [INFO]: Epoch 040 - training loss: 9427.9453, validation loss: 0.1842
2024-05-24 23:11:53 [INFO]: Epoch 041 - training loss: 9431.3857, validation loss: 0.1827
2024-05-24 23:11:53 [INFO]: Epoch 042 - training loss: 9421.7455, validation loss: 0.1798
2024-05-24 23:11:53 [INFO]: Epoch 043 - training loss: 9412.3903, validation loss: 0.1794
2024-05-24 23:11:53 [INFO]: Epoch 044 - training loss: 9407.0820, validation loss: 0.1748
2024-05-24 23:11:53 [INFO]: Epoch 045 - training loss: 9415.7958, validation loss: 0.1741
2024-05-24 23:11:54 [INFO]: Epoch 046 - training loss: 9398.3060, validation loss: 0.1699
2024-05-24 23:11:54 [INFO]: Epoch 047 - training loss: 9395.7466, validation loss: 0.1678
2024-05-24 23:11:54 [INFO]: Epoch 048 - training loss: 9392.1414, validation loss: 0.1689
2024-05-24 23:11:54 [INFO]: Epoch 049 - training loss: 9389.8169, validation loss: 0.1636
2024-05-24 23:11:54 [INFO]: Epoch 050 - training loss: 9390.0742, validation loss: 0.1598
2024-05-24 23:11:54 [INFO]: Epoch 051 - training loss: 9381.1321, validation loss: 0.1581
2024-05-24 23:11:54 [INFO]: Epoch 052 - training loss: 9380.7250, validation loss: 0.1570
2024-05-24 23:11:55 [INFO]: Epoch 053 - training loss: 9378.9061, validation loss: 0.1546
2024-05-24 23:11:55 [INFO]: Epoch 054 - training loss: 9375.9125, validation loss: 0.1540
2024-05-24 23:11:55 [INFO]: Epoch 055 - training loss: 9372.5142, validation loss: 0.1508
2024-05-24 23:11:55 [INFO]: Epoch 056 - training loss: 9373.9877, validation loss: 0.1500
2024-05-24 23:11:55 [INFO]: Epoch 057 - training loss: 9372.0652, validation loss: 0.1482
2024-05-24 23:11:55 [INFO]: Epoch 058 - training loss: 9378.4193, validation loss: 0.1465
2024-05-24 23:11:55 [INFO]: Epoch 059 - training loss: 9364.8708, validation loss: 0.1465
2024-05-24 23:11:55 [INFO]: Epoch 060 - training loss: 9363.8422, validation loss: 0.1426
2024-05-24 23:11:56 [INFO]: Epoch 061 - training loss: 9361.6938, validation loss: 0.1448
2024-05-24 23:11:56 [INFO]: Epoch 062 - training loss: 9359.0882, validation loss: 0.1416
2024-05-24 23:11:56 [INFO]: Epoch 063 - training loss: 9359.4213, validation loss: 0.1435
2024-05-24 23:11:56 [INFO]: Epoch 064 - training loss: 9357.0004, validation loss: 0.1423
2024-05-24 23:11:56 [INFO]: Epoch 065 - training loss: 9354.6322, validation loss: 0.1367
2024-05-24 23:11:56 [INFO]: Epoch 066 - training loss: 9353.4573, validation loss: 0.1368
2024-05-24 23:11:56 [INFO]: Epoch 067 - training loss: 9354.6468, validation loss: 0.1361
2024-05-24 23:11:57 [INFO]: Epoch 068 - training loss: 9350.9767, validation loss: 0.1375
2024-05-24 23:11:57 [INFO]: Epoch 069 - training loss: 9351.2397, validation loss: 0.1351
2024-05-24 23:11:57 [INFO]: Epoch 070 - training loss: 9348.2024, validation loss: 0.1351
2024-05-24 23:11:57 [INFO]: Epoch 071 - training loss: 9348.2203, validation loss: 0.1329
2024-05-24 23:11:57 [INFO]: Epoch 072 - training loss: 9346.8825, validation loss: 0.1316
2024-05-24 23:11:57 [INFO]: Epoch 073 - training loss: 9346.7396, validation loss: 0.1288
2024-05-24 23:11:57 [INFO]: Epoch 074 - training loss: 9343.0739, validation loss: 0.1283
2024-05-24 23:11:57 [INFO]: Epoch 075 - training loss: 9348.5812, validation loss: 0.1291
2024-05-24 23:11:58 [INFO]: Epoch 076 - training loss: 9342.0627, validation loss: 0.1254
2024-05-24 23:11:58 [INFO]: Epoch 077 - training loss: 9347.2266, validation loss: 0.1249
2024-05-24 23:11:58 [INFO]: Epoch 078 - training loss: 9339.9022, validation loss: 0.1247
2024-05-24 23:11:58 [INFO]: Epoch 079 - training loss: 9341.7397, validation loss: 0.1226
2024-05-24 23:11:58 [INFO]: Epoch 080 - training loss: 9340.2348, validation loss: 0.1215
2024-05-24 23:11:58 [INFO]: Epoch 081 - training loss: 9335.3348, validation loss: 0.1216
2024-05-24 23:11:58 [INFO]: Epoch 082 - training loss: 9337.5772, validation loss: 0.1249
2024-05-24 23:11:59 [INFO]: Epoch 083 - training loss: 9336.3013, validation loss: 0.1239
2024-05-24 23:11:59 [INFO]: Epoch 084 - training loss: 9334.8726, validation loss: 0.1211
2024-05-24 23:11:59 [INFO]: Epoch 085 - training loss: 9333.5544, validation loss: 0.1187
2024-05-24 23:11:59 [INFO]: Epoch 086 - training loss: 9335.4815, validation loss: 0.1191
2024-05-24 23:11:59 [INFO]: Epoch 087 - training loss: 9333.4786, validation loss: 0.1178
2024-05-24 23:11:59 [INFO]: Epoch 088 - training loss: 9332.1547, validation loss: 0.1158
2024-05-24 23:11:59 [INFO]: Epoch 089 - training loss: 9333.2416, validation loss: 0.1153
2024-05-24 23:11:59 [INFO]: Epoch 090 - training loss: 9331.1824, validation loss: 0.1143
2024-05-24 23:12:00 [INFO]: Epoch 091 - training loss: 9330.3646, validation loss: 0.1149
2024-05-24 23:12:00 [INFO]: Epoch 092 - training loss: 9332.1696, validation loss: 0.1144
2024-05-24 23:12:00 [INFO]: Epoch 093 - training loss: 9330.4448, validation loss: 0.1131
2024-05-24 23:12:00 [INFO]: Epoch 094 - training loss: 9328.7845, validation loss: 0.1118
2024-05-24 23:12:00 [INFO]: Epoch 095 - training loss: 9329.0076, validation loss: 0.1126
2024-05-24 23:12:00 [INFO]: Epoch 096 - training loss: 9327.8220, validation loss: 0.1103
2024-05-24 23:12:00 [INFO]: Epoch 097 - training loss: 9326.5238, validation loss: 0.1087
2024-05-24 23:12:01 [INFO]: Epoch 098 - training loss: 9327.9941, validation loss: 0.1091
2024-05-24 23:12:01 [INFO]: Epoch 099 - training loss: 9326.1292, validation loss: 0.1105
2024-05-24 23:12:01 [INFO]: Epoch 100 - training loss: 9327.2650, validation loss: 0.1086
2024-05-24 23:12:01 [INFO]: Epoch 101 - training loss: 9325.8831, validation loss: 0.1084
2024-05-24 23:12:01 [INFO]: Epoch 102 - training loss: 9325.0605, validation loss: 0.1069
2024-05-24 23:12:01 [INFO]: Epoch 103 - training loss: 9324.1008, validation loss: 0.1070
2024-05-24 23:12:01 [INFO]: Epoch 104 - training loss: 9323.6542, validation loss: 0.1061
2024-05-24 23:12:01 [INFO]: Epoch 105 - training loss: 9329.0822, validation loss: 0.1047
2024-05-24 23:12:02 [INFO]: Epoch 106 - training loss: 9324.0059, validation loss: 0.1045
2024-05-24 23:12:02 [INFO]: Epoch 107 - training loss: 9323.4388, validation loss: 0.1028
2024-05-24 23:12:02 [INFO]: Epoch 108 - training loss: 9323.5362, validation loss: 0.1049
2024-05-24 23:12:02 [INFO]: Epoch 109 - training loss: 9323.3361, validation loss: 0.1034
2024-05-24 23:12:02 [INFO]: Epoch 110 - training loss: 9322.3917, validation loss: 0.1047
2024-05-24 23:12:02 [INFO]: Epoch 111 - training loss: 9322.6448, validation loss: 0.1017
2024-05-24 23:12:02 [INFO]: Epoch 112 - training loss: 9321.0121, validation loss: 0.1027
2024-05-24 23:12:03 [INFO]: Epoch 113 - training loss: 9319.6236, validation loss: 0.1001
2024-05-24 23:12:03 [INFO]: Epoch 114 - training loss: 9321.0930, validation loss: 0.1003
2024-05-24 23:12:03 [INFO]: Epoch 115 - training loss: 9318.9119, validation loss: 0.1002
2024-05-24 23:12:03 [INFO]: Epoch 116 - training loss: 9324.0107, validation loss: 0.0996
2024-05-24 23:12:03 [INFO]: Epoch 117 - training loss: 9319.0181, validation loss: 0.0974
2024-05-24 23:12:03 [INFO]: Epoch 118 - training loss: 9317.5443, validation loss: 0.0989
2024-05-24 23:12:03 [INFO]: Epoch 119 - training loss: 9318.9213, validation loss: 0.0979
2024-05-24 23:12:03 [INFO]: Epoch 120 - training loss: 9322.2297, validation loss: 0.0976
2024-05-24 23:12:04 [INFO]: Epoch 121 - training loss: 9317.8503, validation loss: 0.0958
2024-05-24 23:12:04 [INFO]: Epoch 122 - training loss: 9319.7487, validation loss: 0.0946
2024-05-24 23:12:04 [INFO]: Epoch 123 - training loss: 9318.8665, validation loss: 0.0977
2024-05-24 23:12:04 [INFO]: Epoch 124 - training loss: 9316.5234, validation loss: 0.0955
2024-05-24 23:12:04 [INFO]: Epoch 125 - training loss: 9315.5381, validation loss: 0.0960
2024-05-24 23:12:04 [INFO]: Epoch 126 - training loss: 9316.5680, validation loss: 0.0944
2024-05-24 23:12:04 [INFO]: Epoch 127 - training loss: 9317.5314, validation loss: 0.0945
2024-05-24 23:12:04 [INFO]: Epoch 128 - training loss: 9316.7343, validation loss: 0.0960
2024-05-24 23:12:05 [INFO]: Epoch 129 - training loss: 9315.2577, validation loss: 0.0935
2024-05-24 23:12:05 [INFO]: Epoch 130 - training loss: 9334.5713, validation loss: 0.0951
2024-05-24 23:12:05 [INFO]: Epoch 131 - training loss: 9315.3749, validation loss: 0.0926
2024-05-24 23:12:05 [INFO]: Epoch 132 - training loss: 9314.5425, validation loss: 0.0931
2024-05-24 23:12:05 [INFO]: Epoch 133 - training loss: 9316.0773, validation loss: 0.0936
2024-05-24 23:12:05 [INFO]: Epoch 134 - training loss: 9314.6674, validation loss: 0.0918
2024-05-24 23:12:05 [INFO]: Epoch 135 - training loss: 9313.8596, validation loss: 0.0937
2024-05-24 23:12:06 [INFO]: Epoch 136 - training loss: 9314.0075, validation loss: 0.0920
2024-05-24 23:12:06 [INFO]: Epoch 137 - training loss: 9314.3005, validation loss: 0.0912
2024-05-24 23:12:06 [INFO]: Epoch 138 - training loss: 9312.9377, validation loss: 0.0897
2024-05-24 23:12:06 [INFO]: Epoch 139 - training loss: 9313.3778, validation loss: 0.0914
2024-05-24 23:12:06 [INFO]: Epoch 140 - training loss: 9312.6859, validation loss: 0.0913
2024-05-24 23:12:06 [INFO]: Epoch 141 - training loss: 9312.9269, validation loss: 0.0902
2024-05-24 23:12:06 [INFO]: Epoch 142 - training loss: 9312.9504, validation loss: 0.0889
2024-05-24 23:12:06 [INFO]: Epoch 143 - training loss: 9313.8080, validation loss: 0.0896
2024-05-24 23:12:07 [INFO]: Epoch 144 - training loss: 9311.9193, validation loss: 0.0883
2024-05-24 23:12:07 [INFO]: Epoch 145 - training loss: 9312.8023, validation loss: 0.0893
2024-05-24 23:12:07 [INFO]: Epoch 146 - training loss: 9310.6818, validation loss: 0.0885
2024-05-24 23:12:07 [INFO]: Epoch 147 - training loss: 9312.9066, validation loss: 0.0886
2024-05-24 23:12:07 [INFO]: Epoch 148 - training loss: 9310.7783, validation loss: 0.0870
2024-05-24 23:12:07 [INFO]: Epoch 149 - training loss: 9310.9500, validation loss: 0.0881
2024-05-24 23:12:07 [INFO]: Epoch 150 - training loss: 9311.8328, validation loss: 0.0877
2024-05-24 23:12:08 [INFO]: Epoch 151 - training loss: 9311.3505, validation loss: 0.0875
2024-05-24 23:12:08 [INFO]: Epoch 152 - training loss: 9310.9661, validation loss: 0.0865
2024-05-24 23:12:08 [INFO]: Epoch 153 - training loss: 9310.3899, validation loss: 0.0860
2024-05-24 23:12:08 [INFO]: Epoch 154 - training loss: 9310.7922, validation loss: 0.0861
2024-05-24 23:12:08 [INFO]: Epoch 155 - training loss: 9310.9296, validation loss: 0.0865
2024-05-24 23:12:08 [INFO]: Epoch 156 - training loss: 9310.8788, validation loss: 0.0866
2024-05-24 23:12:08 [INFO]: Epoch 157 - training loss: 9309.4005, validation loss: 0.0847
2024-05-24 23:12:08 [INFO]: Epoch 158 - training loss: 9310.8063, validation loss: 0.0853
2024-05-24 23:12:09 [INFO]: Epoch 159 - training loss: 9309.3394, validation loss: 0.0859
2024-05-24 23:12:09 [INFO]: Epoch 160 - training loss: 9310.0132, validation loss: 0.0845
2024-05-24 23:12:09 [INFO]: Epoch 161 - training loss: 9310.8678, validation loss: 0.0847
2024-05-24 23:12:09 [INFO]: Epoch 162 - training loss: 9310.5137, validation loss: 0.0839
2024-05-24 23:12:09 [INFO]: Epoch 163 - training loss: 9307.9886, validation loss: 0.0859
2024-05-24 23:12:09 [INFO]: Epoch 164 - training loss: 9310.7185, validation loss: 0.0845
2024-05-24 23:12:09 [INFO]: Epoch 165 - training loss: 9309.5549, validation loss: 0.0838
2024-05-24 23:12:10 [INFO]: Epoch 166 - training loss: 9309.5356, validation loss: 0.0840
2024-05-24 23:12:10 [INFO]: Epoch 167 - training loss: 9309.9886, validation loss: 0.0825
2024-05-24 23:12:10 [INFO]: Epoch 168 - training loss: 9307.1747, validation loss: 0.0840
2024-05-24 23:12:10 [INFO]: Epoch 169 - training loss: 9309.7425, validation loss: 0.0821
2024-05-24 23:12:10 [INFO]: Epoch 170 - training loss: 9309.8427, validation loss: 0.0835
2024-05-24 23:12:10 [INFO]: Epoch 171 - training loss: 9307.7917, validation loss: 0.0836
2024-05-24 23:12:10 [INFO]: Epoch 172 - training loss: 9309.1115, validation loss: 0.0816
2024-05-24 23:12:10 [INFO]: Epoch 173 - training loss: 9308.1204, validation loss: 0.0813
2024-05-24 23:12:11 [INFO]: Epoch 174 - training loss: 9309.2901, validation loss: 0.0822
2024-05-24 23:12:11 [INFO]: Epoch 175 - training loss: 9308.1190, validation loss: 0.0807
2024-05-24 23:12:11 [INFO]: Epoch 176 - training loss: 9307.5105, validation loss: 0.0829
2024-05-24 23:12:11 [INFO]: Epoch 177 - training loss: 9306.9716, validation loss: 0.0823
2024-05-24 23:12:11 [INFO]: Epoch 178 - training loss: 9309.0956, validation loss: 0.0819
2024-05-24 23:12:11 [INFO]: Epoch 179 - training loss: 9307.0830, validation loss: 0.0802
2024-05-24 23:12:11 [INFO]: Epoch 180 - training loss: 9306.6235, validation loss: 0.0807
2024-05-24 23:12:12 [INFO]: Epoch 181 - training loss: 9306.8355, validation loss: 0.0812
2024-05-24 23:12:12 [INFO]: Epoch 182 - training loss: 9307.2919, validation loss: 0.0804
2024-05-24 23:12:12 [INFO]: Epoch 183 - training loss: 9306.8561, validation loss: 0.0811
2024-05-24 23:12:12 [INFO]: Epoch 184 - training loss: 9306.9199, validation loss: 0.0815
2024-05-24 23:12:12 [INFO]: Epoch 185 - training loss: 9305.1551, validation loss: 0.0806
2024-05-24 23:12:12 [INFO]: Epoch 186 - training loss: 9307.0764, validation loss: 0.0823
2024-05-24 23:12:12 [INFO]: Epoch 187 - training loss: 9307.2838, validation loss: 0.0795
2024-05-24 23:12:12 [INFO]: Epoch 188 - training loss: 9306.6556, validation loss: 0.0790
2024-05-24 23:12:13 [INFO]: Epoch 189 - training loss: 9306.5683, validation loss: 0.0782
2024-05-24 23:12:13 [INFO]: Epoch 190 - training loss: 9306.2377, validation loss: 0.0787
2024-05-24 23:12:13 [INFO]: Epoch 191 - training loss: 9307.1841, validation loss: 0.0791
2024-05-24 23:12:13 [INFO]: Epoch 192 - training loss: 9308.3369, validation loss: 0.0773
2024-05-24 23:12:13 [INFO]: Epoch 193 - training loss: 9306.0485, validation loss: 0.0792
2024-05-24 23:12:13 [INFO]: Epoch 194 - training loss: 9306.3818, validation loss: 0.0787
2024-05-24 23:12:13 [INFO]: Epoch 195 - training loss: 9306.9871, validation loss: 0.0803
2024-05-24 23:12:13 [INFO]: Epoch 196 - training loss: 9305.6321, validation loss: 0.0776
2024-05-24 23:12:14 [INFO]: Epoch 197 - training loss: 9307.1683, validation loss: 0.0779
2024-05-24 23:12:14 [INFO]: Epoch 198 - training loss: 9306.2833, validation loss: 0.0780
2024-05-24 23:12:14 [INFO]: Epoch 199 - training loss: 9305.0259, validation loss: 0.0747
2024-05-24 23:12:14 [INFO]: Epoch 200 - training loss: 9305.1451, validation loss: 0.0778
2024-05-24 23:12:14 [INFO]: Epoch 201 - training loss: 9305.1366, validation loss: 0.0769
2024-05-24 23:12:14 [INFO]: Epoch 202 - training loss: 9304.8730, validation loss: 0.0765
2024-05-24 23:12:14 [INFO]: Epoch 203 - training loss: 9306.8107, validation loss: 0.0767
2024-05-24 23:12:15 [INFO]: Epoch 204 - training loss: 9304.6806, validation loss: 0.0767
2024-05-24 23:12:15 [INFO]: Epoch 205 - training loss: 9305.0941, validation loss: 0.0781
2024-05-24 23:12:15 [INFO]: Epoch 206 - training loss: 9305.3853, validation loss: 0.0767
2024-05-24 23:12:15 [INFO]: Epoch 207 - training loss: 9304.7202, validation loss: 0.0770
2024-05-24 23:12:15 [INFO]: Epoch 208 - training loss: 9305.6976, validation loss: 0.0773
2024-05-24 23:12:15 [INFO]: Epoch 209 - training loss: 9305.5400, validation loss: 0.0761
2024-05-24 23:12:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:12:15 [INFO]: Finished training. The best model is from epoch#199.
2024-05-24 23:12:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/GPVAE_ettm1/20240524_T231147/GPVAE.pypots
2024-05-24 23:12:15 [INFO]: GP-VAE on ETTm1: MAE=0.2772, MSE=0.1532
2024-05-24 23:12:15 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/GPVAE_ettm1/imputation.pkl
2024-05-24 23:12:15 [INFO]: Using the given device: cuda:0
2024-05-24 23:12:15 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/USGAN_ettm1/20240524_T231215
2024-05-24 23:12:15 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/USGAN_ettm1/20240524_T231215/tensorboard
2024-05-24 23:12:15 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 23:12:26 [INFO]: Epoch 001 - generator training loss: 0.6370, discriminator training loss: 0.3499, validation loss: 0.3337
2024-05-24 23:12:35 [INFO]: Epoch 002 - generator training loss: 0.0598, discriminator training loss: 0.2115, validation loss: 0.0988
2024-05-24 23:12:44 [INFO]: Epoch 003 - generator training loss: -0.0485, discriminator training loss: 0.2009, validation loss: 0.0712
2024-05-24 23:12:53 [INFO]: Epoch 004 - generator training loss: -0.0774, discriminator training loss: 0.1984, validation loss: 0.0516
2024-05-24 23:13:01 [INFO]: Epoch 005 - generator training loss: -0.0805, discriminator training loss: 0.1915, validation loss: 0.0456
2024-05-24 23:13:11 [INFO]: Epoch 006 - generator training loss: -0.0794, discriminator training loss: 0.1850, validation loss: 0.0444
2024-05-24 23:13:20 [INFO]: Epoch 007 - generator training loss: -0.0790, discriminator training loss: 0.1803, validation loss: 0.0416
2024-05-24 23:13:29 [INFO]: Epoch 008 - generator training loss: -0.0704, discriminator training loss: 0.1705, validation loss: 0.0400
2024-05-24 23:13:38 [INFO]: Epoch 009 - generator training loss: -0.0568, discriminator training loss: 0.1558, validation loss: 0.0389
2024-05-24 23:13:47 [INFO]: Epoch 010 - generator training loss: -0.0459, discriminator training loss: 0.1401, validation loss: 0.0367
2024-05-24 23:13:56 [INFO]: Epoch 011 - generator training loss: -0.0348, discriminator training loss: 0.1242, validation loss: 0.0381
2024-05-24 23:14:05 [INFO]: Epoch 012 - generator training loss: -0.0265, discriminator training loss: 0.1126, validation loss: 0.0364
2024-05-24 23:14:14 [INFO]: Epoch 013 - generator training loss: -0.0176, discriminator training loss: 0.1018, validation loss: 0.0354
2024-05-24 23:14:23 [INFO]: Epoch 014 - generator training loss: -0.0145, discriminator training loss: 0.0942, validation loss: 0.0352
2024-05-24 23:14:32 [INFO]: Epoch 015 - generator training loss: -0.0107, discriminator training loss: 0.0878, validation loss: 0.0356
2024-05-24 23:14:41 [INFO]: Epoch 016 - generator training loss: -0.0107, discriminator training loss: 0.0860, validation loss: 0.0347
2024-05-24 23:14:50 [INFO]: Epoch 017 - generator training loss: -0.0098, discriminator training loss: 0.0836, validation loss: 0.0345
2024-05-24 23:14:59 [INFO]: Epoch 018 - generator training loss: -0.0096, discriminator training loss: 0.0824, validation loss: 0.0355
2024-05-24 23:15:08 [INFO]: Epoch 019 - generator training loss: -0.0097, discriminator training loss: 0.0814, validation loss: 0.0348
2024-05-24 23:15:17 [INFO]: Epoch 020 - generator training loss: -0.0091, discriminator training loss: 0.0790, validation loss: 0.0333
2024-05-24 23:15:26 [INFO]: Epoch 021 - generator training loss: -0.0083, discriminator training loss: 0.0787, validation loss: 0.0332
2024-05-24 23:15:35 [INFO]: Epoch 022 - generator training loss: -0.0064, discriminator training loss: 0.0776, validation loss: 0.0331
2024-05-24 23:15:44 [INFO]: Epoch 023 - generator training loss: -0.0085, discriminator training loss: 0.0750, validation loss: 0.0326
2024-05-24 23:15:53 [INFO]: Epoch 024 - generator training loss: -0.0053, discriminator training loss: 0.0779, validation loss: 0.0330
2024-05-24 23:16:02 [INFO]: Epoch 025 - generator training loss: -0.0058, discriminator training loss: 0.0760, validation loss: 0.0329
2024-05-24 23:16:11 [INFO]: Epoch 026 - generator training loss: -0.0062, discriminator training loss: 0.0779, validation loss: 0.0330
2024-05-24 23:16:20 [INFO]: Epoch 027 - generator training loss: -0.0068, discriminator training loss: 0.0746, validation loss: 0.0321
2024-05-24 23:16:29 [INFO]: Epoch 028 - generator training loss: -0.0075, discriminator training loss: 0.0765, validation loss: 0.0318
2024-05-24 23:16:39 [INFO]: Epoch 029 - generator training loss: -0.0090, discriminator training loss: 0.0729, validation loss: 0.0319
2024-05-24 23:16:48 [INFO]: Epoch 030 - generator training loss: -0.0084, discriminator training loss: 0.0732, validation loss: 0.0303
2024-05-24 23:16:57 [INFO]: Epoch 031 - generator training loss: -0.0112, discriminator training loss: 0.0748, validation loss: 0.0304
2024-05-24 23:17:06 [INFO]: Epoch 032 - generator training loss: -0.0092, discriminator training loss: 0.0731, validation loss: 0.0310
2024-05-24 23:17:15 [INFO]: Epoch 033 - generator training loss: -0.0080, discriminator training loss: 0.0707, validation loss: 0.0304
2024-05-24 23:17:23 [INFO]: Epoch 034 - generator training loss: -0.0122, discriminator training loss: 0.0720, validation loss: 0.0301
2024-05-24 23:17:32 [INFO]: Epoch 035 - generator training loss: -0.0109, discriminator training loss: 0.0710, validation loss: 0.0290
2024-05-24 23:17:42 [INFO]: Epoch 036 - generator training loss: -0.0126, discriminator training loss: 0.0714, validation loss: 0.0293
2024-05-24 23:17:51 [INFO]: Epoch 037 - generator training loss: -0.0138, discriminator training loss: 0.0717, validation loss: 0.0306
2024-05-24 23:17:59 [INFO]: Epoch 038 - generator training loss: -0.0102, discriminator training loss: 0.0712, validation loss: 0.0281
2024-05-24 23:18:09 [INFO]: Epoch 039 - generator training loss: -0.0055, discriminator training loss: 0.0708, validation loss: 0.0284
2024-05-24 23:18:18 [INFO]: Epoch 040 - generator training loss: -0.0121, discriminator training loss: 0.0701, validation loss: 0.0271
2024-05-24 23:18:27 [INFO]: Epoch 041 - generator training loss: -0.0145, discriminator training loss: 0.0716, validation loss: 0.0276
2024-05-24 23:18:36 [INFO]: Epoch 042 - generator training loss: -0.0136, discriminator training loss: 0.0701, validation loss: 0.0262
2024-05-24 23:18:45 [INFO]: Epoch 043 - generator training loss: -0.0137, discriminator training loss: 0.0719, validation loss: 0.0268
2024-05-24 23:18:54 [INFO]: Epoch 044 - generator training loss: -0.0118, discriminator training loss: 0.0719, validation loss: 0.0270
2024-05-24 23:19:03 [INFO]: Epoch 045 - generator training loss: -0.0132, discriminator training loss: 0.0718, validation loss: 0.0250
2024-05-24 23:19:12 [INFO]: Epoch 046 - generator training loss: -0.0146, discriminator training loss: 0.0720, validation loss: 0.0251
2024-05-24 23:19:21 [INFO]: Epoch 047 - generator training loss: -0.0132, discriminator training loss: 0.0693, validation loss: 0.0248
2024-05-24 23:19:30 [INFO]: Epoch 048 - generator training loss: -0.0198, discriminator training loss: 0.0707, validation loss: 0.0238
2024-05-24 23:19:39 [INFO]: Epoch 049 - generator training loss: -0.0169, discriminator training loss: 0.0705, validation loss: 0.0237
2024-05-24 23:19:48 [INFO]: Epoch 050 - generator training loss: -0.0174, discriminator training loss: 0.0700, validation loss: 0.0236
2024-05-24 23:19:57 [INFO]: Epoch 051 - generator training loss: -0.0146, discriminator training loss: 0.0702, validation loss: 0.0239
2024-05-24 23:20:06 [INFO]: Epoch 052 - generator training loss: -0.0187, discriminator training loss: 0.0715, validation loss: 0.0232
2024-05-24 23:20:15 [INFO]: Epoch 053 - generator training loss: -0.0192, discriminator training loss: 0.0691, validation loss: 0.0230
2024-05-24 23:20:24 [INFO]: Epoch 054 - generator training loss: -0.0191, discriminator training loss: 0.0686, validation loss: 0.0232
2024-05-24 23:20:33 [INFO]: Epoch 055 - generator training loss: -0.0164, discriminator training loss: 0.0699, validation loss: 0.0231
2024-05-24 23:20:42 [INFO]: Epoch 056 - generator training loss: -0.0179, discriminator training loss: 0.0678, validation loss: 0.0227
2024-05-24 23:20:51 [INFO]: Epoch 057 - generator training loss: -0.0167, discriminator training loss: 0.0683, validation loss: 0.0223
2024-05-24 23:21:00 [INFO]: Epoch 058 - generator training loss: -0.0203, discriminator training loss: 0.0671, validation loss: 0.0225
2024-05-24 23:21:09 [INFO]: Epoch 059 - generator training loss: -0.0190, discriminator training loss: 0.0676, validation loss: 0.0223
2024-05-24 23:21:18 [INFO]: Epoch 060 - generator training loss: -0.0171, discriminator training loss: 0.0674, validation loss: 0.0228
2024-05-24 23:21:27 [INFO]: Epoch 061 - generator training loss: -0.0180, discriminator training loss: 0.0673, validation loss: 0.0225
2024-05-24 23:21:36 [INFO]: Epoch 062 - generator training loss: -0.0200, discriminator training loss: 0.0687, validation loss: 0.0232
2024-05-24 23:21:45 [INFO]: Epoch 063 - generator training loss: -0.0198, discriminator training loss: 0.0701, validation loss: 0.0220
2024-05-24 23:21:54 [INFO]: Epoch 064 - generator training loss: -0.0181, discriminator training loss: 0.0696, validation loss: 0.0222
2024-05-24 23:22:03 [INFO]: Epoch 065 - generator training loss: -0.0186, discriminator training loss: 0.0694, validation loss: 0.0222
2024-05-24 23:22:12 [INFO]: Epoch 066 - generator training loss: -0.0209, discriminator training loss: 0.0698, validation loss: 0.0222
2024-05-24 23:22:21 [INFO]: Epoch 067 - generator training loss: -0.0188, discriminator training loss: 0.0692, validation loss: 0.0222
2024-05-24 23:22:30 [INFO]: Epoch 068 - generator training loss: -0.0162, discriminator training loss: 0.0690, validation loss: 0.0242
2024-05-24 23:22:39 [INFO]: Epoch 069 - generator training loss: -0.0169, discriminator training loss: 0.0674, validation loss: 0.0225
2024-05-24 23:22:48 [INFO]: Epoch 070 - generator training loss: -0.0184, discriminator training loss: 0.0670, validation loss: 0.0231
2024-05-24 23:22:57 [INFO]: Epoch 071 - generator training loss: -0.0185, discriminator training loss: 0.0676, validation loss: 0.0228
2024-05-24 23:23:07 [INFO]: Epoch 072 - generator training loss: -0.0189, discriminator training loss: 0.0682, validation loss: 0.0218
2024-05-24 23:23:16 [INFO]: Epoch 073 - generator training loss: -0.0208, discriminator training loss: 0.0674, validation loss: 0.0224
2024-05-24 23:23:25 [INFO]: Epoch 074 - generator training loss: -0.0216, discriminator training loss: 0.0685, validation loss: 0.0218
2024-05-24 23:23:34 [INFO]: Epoch 075 - generator training loss: -0.0211, discriminator training loss: 0.0669, validation loss: 0.0221
2024-05-24 23:23:43 [INFO]: Epoch 076 - generator training loss: -0.0190, discriminator training loss: 0.0669, validation loss: 0.0222
2024-05-24 23:23:52 [INFO]: Epoch 077 - generator training loss: -0.0184, discriminator training loss: 0.0694, validation loss: 0.0213
2024-05-24 23:24:00 [INFO]: Epoch 078 - generator training loss: -0.0196, discriminator training loss: 0.0685, validation loss: 0.0218
2024-05-24 23:24:10 [INFO]: Epoch 079 - generator training loss: -0.0204, discriminator training loss: 0.0660, validation loss: 0.0214
2024-05-24 23:24:19 [INFO]: Epoch 080 - generator training loss: -0.0233, discriminator training loss: 0.0687, validation loss: 0.0214
2024-05-24 23:24:27 [INFO]: Epoch 081 - generator training loss: -0.0220, discriminator training loss: 0.0668, validation loss: 0.0216
2024-05-24 23:24:37 [INFO]: Epoch 082 - generator training loss: -0.0219, discriminator training loss: 0.0657, validation loss: 0.0214
2024-05-24 23:24:46 [INFO]: Epoch 083 - generator training loss: -0.0243, discriminator training loss: 0.0677, validation loss: 0.0214
2024-05-24 23:24:55 [INFO]: Epoch 084 - generator training loss: -0.0205, discriminator training loss: 0.0670, validation loss: 0.0217
2024-05-24 23:25:04 [INFO]: Epoch 085 - generator training loss: -0.0208, discriminator training loss: 0.0655, validation loss: 0.0225
2024-05-24 23:25:13 [INFO]: Epoch 086 - generator training loss: -0.0217, discriminator training loss: 0.0659, validation loss: 0.0228
2024-05-24 23:25:22 [INFO]: Epoch 087 - generator training loss: -0.0191, discriminator training loss: 0.0655, validation loss: 0.0218
2024-05-24 23:25:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:25:22 [INFO]: Finished training. The best model is from epoch#77.
2024-05-24 23:25:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/USGAN_ettm1/20240524_T231215/USGAN.pypots
2024-05-24 23:25:23 [INFO]: US-GAN on ETTm1: MAE=0.1505, MSE=0.0558
2024-05-24 23:25:23 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/USGAN_ettm1/imputation.pkl
2024-05-24 23:25:23 [INFO]: Using the given device: cuda:0
2024-05-24 23:25:23 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/BRITS_ettm1/20240524_T232523
2024-05-24 23:25:23 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/BRITS_ettm1/20240524_T232523/tensorboard
2024-05-24 23:25:23 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 23:25:30 [INFO]: Epoch 001 - training loss: 1.3234, validation loss: 0.2633
2024-05-24 23:25:37 [INFO]: Epoch 002 - training loss: 0.8469, validation loss: 0.0774
2024-05-24 23:25:43 [INFO]: Epoch 003 - training loss: 0.7006, validation loss: 0.0518
2024-05-24 23:25:49 [INFO]: Epoch 004 - training loss: 0.6261, validation loss: 0.0470
2024-05-24 23:25:54 [INFO]: Epoch 005 - training loss: 0.5934, validation loss: 0.0440
2024-05-24 23:26:00 [INFO]: Epoch 006 - training loss: 0.5599, validation loss: 0.0391
2024-05-24 23:26:06 [INFO]: Epoch 007 - training loss: 0.5186, validation loss: 0.0366
2024-05-24 23:26:12 [INFO]: Epoch 008 - training loss: 0.4898, validation loss: 0.0340
2024-05-24 23:26:18 [INFO]: Epoch 009 - training loss: 0.4659, validation loss: 0.0308
2024-05-24 23:26:24 [INFO]: Epoch 010 - training loss: 0.4479, validation loss: 0.0290
2024-05-24 23:26:30 [INFO]: Epoch 011 - training loss: 0.4349, validation loss: 0.0274
2024-05-24 23:26:36 [INFO]: Epoch 012 - training loss: 0.4200, validation loss: 0.0266
2024-05-24 23:26:42 [INFO]: Epoch 013 - training loss: 0.4107, validation loss: 0.0257
2024-05-24 23:26:48 [INFO]: Epoch 014 - training loss: 0.3975, validation loss: 0.0247
2024-05-24 23:26:54 [INFO]: Epoch 015 - training loss: 0.3957, validation loss: 0.0241
2024-05-24 23:27:00 [INFO]: Epoch 016 - training loss: 0.3876, validation loss: 0.0235
2024-05-24 23:27:06 [INFO]: Epoch 017 - training loss: 0.3932, validation loss: 0.0231
2024-05-24 23:27:12 [INFO]: Epoch 018 - training loss: 0.3857, validation loss: 0.0231
2024-05-24 23:27:18 [INFO]: Epoch 019 - training loss: 0.3842, validation loss: 0.0234
2024-05-24 23:27:24 [INFO]: Epoch 020 - training loss: 0.3902, validation loss: 0.0231
2024-05-24 23:27:30 [INFO]: Epoch 021 - training loss: 0.3821, validation loss: 0.0228
2024-05-24 23:27:36 [INFO]: Epoch 022 - training loss: 0.3828, validation loss: 0.0231
2024-05-24 23:27:42 [INFO]: Epoch 023 - training loss: 0.3893, validation loss: 0.0235
2024-05-24 23:27:48 [INFO]: Epoch 024 - training loss: 0.3848, validation loss: 0.0236
2024-05-24 23:27:54 [INFO]: Epoch 025 - training loss: 0.3806, validation loss: 0.0228
2024-05-24 23:28:00 [INFO]: Epoch 026 - training loss: 0.3795, validation loss: 0.0222
2024-05-24 23:28:06 [INFO]: Epoch 027 - training loss: 0.3783, validation loss: 0.0228
2024-05-24 23:28:12 [INFO]: Epoch 028 - training loss: 0.3777, validation loss: 0.0222
2024-05-24 23:28:18 [INFO]: Epoch 029 - training loss: 0.3860, validation loss: 0.0226
2024-05-24 23:28:24 [INFO]: Epoch 030 - training loss: 0.3761, validation loss: 0.0227
2024-05-24 23:28:30 [INFO]: Epoch 031 - training loss: 0.3748, validation loss: 0.0225
2024-05-24 23:28:36 [INFO]: Epoch 032 - training loss: 0.3829, validation loss: 0.0233
2024-05-24 23:28:42 [INFO]: Epoch 033 - training loss: 0.3878, validation loss: 0.0225
2024-05-24 23:28:49 [INFO]: Epoch 034 - training loss: 0.3817, validation loss: 0.0232
2024-05-24 23:28:55 [INFO]: Epoch 035 - training loss: 0.3758, validation loss: 0.0225
2024-05-24 23:29:01 [INFO]: Epoch 036 - training loss: 0.3857, validation loss: 0.0229
2024-05-24 23:29:07 [INFO]: Epoch 037 - training loss: 0.3808, validation loss: 0.0234
2024-05-24 23:29:12 [INFO]: Epoch 038 - training loss: 0.3752, validation loss: 0.0228
2024-05-24 23:29:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:29:12 [INFO]: Finished training. The best model is from epoch#28.
2024-05-24 23:29:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/BRITS_ettm1/20240524_T232523/BRITS.pypots
2024-05-24 23:29:14 [INFO]: BRITS on ETTm1: MAE=0.1216, MSE=0.0429
2024-05-24 23:29:14 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/BRITS_ettm1/imputation.pkl
2024-05-24 23:29:14 [INFO]: Using the given device: cuda:0
2024-05-24 23:29:14 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914
2024-05-24 23:29:14 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/tensorboard
2024-05-24 23:29:14 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 23:29:15 [INFO]: Epoch 001 - training loss: 1.3674, validation loss: 1.2356
2024-05-24 23:29:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch1_loss1.235607087612152.pypots
2024-05-24 23:29:16 [INFO]: Epoch 002 - training loss: 1.0522, validation loss: 1.1002
2024-05-24 23:29:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch2_loss1.1002340912818909.pypots
2024-05-24 23:29:16 [INFO]: Epoch 003 - training loss: 1.0526, validation loss: 1.0411
2024-05-24 23:29:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch3_loss1.0411088019609451.pypots
2024-05-24 23:29:16 [INFO]: Epoch 004 - training loss: 0.9650, validation loss: 1.0149
2024-05-24 23:29:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch4_loss1.0149132162332535.pypots
2024-05-24 23:29:16 [INFO]: Epoch 005 - training loss: 0.9672, validation loss: 1.0056
2024-05-24 23:29:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch5_loss1.005587100982666.pypots
2024-05-24 23:29:16 [INFO]: Epoch 006 - training loss: 0.9493, validation loss: 0.9961
2024-05-24 23:29:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch6_loss0.9961067140102386.pypots
2024-05-24 23:29:17 [INFO]: Epoch 007 - training loss: 0.9418, validation loss: 0.9846
2024-05-24 23:29:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch7_loss0.9846342951059341.pypots
2024-05-24 23:29:17 [INFO]: Epoch 008 - training loss: 0.9135, validation loss: 0.9798
2024-05-24 23:29:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch8_loss0.9797743111848831.pypots
2024-05-24 23:29:17 [INFO]: Epoch 009 - training loss: 0.9110, validation loss: 0.9761
2024-05-24 23:29:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch9_loss0.9761271327733994.pypots
2024-05-24 23:29:17 [INFO]: Epoch 010 - training loss: 0.9181, validation loss: 0.9736
2024-05-24 23:29:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch10_loss0.9736079722642899.pypots
2024-05-24 23:29:17 [INFO]: Epoch 011 - training loss: 0.9723, validation loss: 0.9729
2024-05-24 23:29:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch11_loss0.9728670865297318.pypots
2024-05-24 23:29:18 [INFO]: Epoch 012 - training loss: 0.9270, validation loss: 0.9684
2024-05-24 23:29:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch12_loss0.9684330523014069.pypots
2024-05-24 23:29:18 [INFO]: Epoch 013 - training loss: 0.8936, validation loss: 0.9655
2024-05-24 23:29:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch13_loss0.9654736071825027.pypots
2024-05-24 23:29:18 [INFO]: Epoch 014 - training loss: 0.8886, validation loss: 0.9613
2024-05-24 23:29:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch14_loss0.9613156020641327.pypots
2024-05-24 23:29:18 [INFO]: Epoch 015 - training loss: 0.8862, validation loss: 0.9593
2024-05-24 23:29:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch15_loss0.9593026340007782.pypots
2024-05-24 23:29:18 [INFO]: Epoch 016 - training loss: 0.8766, validation loss: 0.9521
2024-05-24 23:29:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch16_loss0.9521169662475586.pypots
2024-05-24 23:29:18 [INFO]: Epoch 017 - training loss: 0.8646, validation loss: 0.9481
2024-05-24 23:29:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch17_loss0.948053777217865.pypots
2024-05-24 23:29:19 [INFO]: Epoch 018 - training loss: 0.8655, validation loss: 0.9473
2024-05-24 23:29:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch18_loss0.9472636133432388.pypots
2024-05-24 23:29:19 [INFO]: Epoch 019 - training loss: 0.8501, validation loss: 0.9428
2024-05-24 23:29:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch19_loss0.9428325444459915.pypots
2024-05-24 23:29:19 [INFO]: Epoch 020 - training loss: 0.8673, validation loss: 0.9397
2024-05-24 23:29:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch20_loss0.939700111746788.pypots
2024-05-24 23:29:19 [INFO]: Epoch 021 - training loss: 0.8625, validation loss: 0.9364
2024-05-24 23:29:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch21_loss0.9363856762647629.pypots
2024-05-24 23:29:19 [INFO]: Epoch 022 - training loss: 0.8916, validation loss: 0.9333
2024-05-24 23:29:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch22_loss0.9332765191793442.pypots
2024-05-24 23:29:20 [INFO]: Epoch 023 - training loss: 0.9107, validation loss: 0.9307
2024-05-24 23:29:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch23_loss0.9306732267141342.pypots
2024-05-24 23:29:20 [INFO]: Epoch 024 - training loss: 0.8669, validation loss: 0.9273
2024-05-24 23:29:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch24_loss0.927347794175148.pypots
2024-05-24 23:29:20 [INFO]: Epoch 025 - training loss: 0.8899, validation loss: 0.9268
2024-05-24 23:29:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch25_loss0.926797091960907.pypots
2024-05-24 23:29:20 [INFO]: Epoch 026 - training loss: 0.8292, validation loss: 0.9268
2024-05-24 23:29:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch26_loss0.9267721027135849.pypots
2024-05-24 23:29:20 [INFO]: Epoch 027 - training loss: 0.8339, validation loss: 0.9236
2024-05-24 23:29:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch27_loss0.9235585629940033.pypots
2024-05-24 23:29:21 [INFO]: Epoch 028 - training loss: 0.8433, validation loss: 0.9220
2024-05-24 23:29:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch28_loss0.9219717383384705.pypots
2024-05-24 23:29:21 [INFO]: Epoch 029 - training loss: 0.8340, validation loss: 0.9186
2024-05-24 23:29:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch29_loss0.9186377376317978.pypots
2024-05-24 23:29:21 [INFO]: Epoch 030 - training loss: 0.8706, validation loss: 0.9167
2024-05-24 23:29:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch30_loss0.9166507720947266.pypots
2024-05-24 23:29:21 [INFO]: Epoch 031 - training loss: 0.8452, validation loss: 0.9131
2024-05-24 23:29:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch31_loss0.9131372272968292.pypots
2024-05-24 23:29:21 [INFO]: Epoch 032 - training loss: 0.8350, validation loss: 0.9111
2024-05-24 23:29:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch32_loss0.9111147522926331.pypots
2024-05-24 23:29:21 [INFO]: Epoch 033 - training loss: 0.8395, validation loss: 0.9088
2024-05-24 23:29:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch33_loss0.9088005870580673.pypots
2024-05-24 23:29:22 [INFO]: Epoch 034 - training loss: 0.8360, validation loss: 0.9054
2024-05-24 23:29:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch34_loss0.905391201376915.pypots
2024-05-24 23:29:22 [INFO]: Epoch 035 - training loss: 0.8139, validation loss: 0.9052
2024-05-24 23:29:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch35_loss0.9052183628082275.pypots
2024-05-24 23:29:22 [INFO]: Epoch 036 - training loss: 0.8311, validation loss: 0.9023
2024-05-24 23:29:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch36_loss0.9022686034440994.pypots
2024-05-24 23:29:22 [INFO]: Epoch 037 - training loss: 0.8138, validation loss: 0.8986
2024-05-24 23:29:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch37_loss0.8986299186944962.pypots
2024-05-24 23:29:22 [INFO]: Epoch 038 - training loss: 0.8407, validation loss: 0.8969
2024-05-24 23:29:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch38_loss0.896921694278717.pypots
2024-05-24 23:29:23 [INFO]: Epoch 039 - training loss: 0.8674, validation loss: 0.8954
2024-05-24 23:29:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch39_loss0.8954373300075531.pypots
2024-05-24 23:29:23 [INFO]: Epoch 040 - training loss: 0.8295, validation loss: 0.8915
2024-05-24 23:29:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch40_loss0.8914881646633148.pypots
2024-05-24 23:29:23 [INFO]: Epoch 041 - training loss: 0.8222, validation loss: 0.8902
2024-05-24 23:29:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch41_loss0.8902295976877213.pypots
2024-05-24 23:29:23 [INFO]: Epoch 042 - training loss: 0.8084, validation loss: 0.8887
2024-05-24 23:29:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch42_loss0.8887069374322891.pypots
2024-05-24 23:29:23 [INFO]: Epoch 043 - training loss: 0.8181, validation loss: 0.8855
2024-05-24 23:29:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch43_loss0.8855133205652237.pypots
2024-05-24 23:29:24 [INFO]: Epoch 044 - training loss: 0.8124, validation loss: 0.8829
2024-05-24 23:29:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch44_loss0.8828797340393066.pypots
2024-05-24 23:29:24 [INFO]: Epoch 045 - training loss: 0.8172, validation loss: 0.8810
2024-05-24 23:29:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch45_loss0.8810475021600723.pypots
2024-05-24 23:29:24 [INFO]: Epoch 046 - training loss: 0.8185, validation loss: 0.8797
2024-05-24 23:29:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch46_loss0.8796925693750381.pypots
2024-05-24 23:29:24 [INFO]: Epoch 047 - training loss: 0.8151, validation loss: 0.8779
2024-05-24 23:29:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch47_loss0.877935066819191.pypots
2024-05-24 23:29:24 [INFO]: Epoch 048 - training loss: 0.7886, validation loss: 0.8746
2024-05-24 23:29:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch48_loss0.8745978623628616.pypots
2024-05-24 23:29:24 [INFO]: Epoch 049 - training loss: 0.8368, validation loss: 0.8729
2024-05-24 23:29:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch49_loss0.8729166686534882.pypots
2024-05-24 23:29:25 [INFO]: Epoch 050 - training loss: 0.8082, validation loss: 0.8719
2024-05-24 23:29:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch50_loss0.8718843013048172.pypots
2024-05-24 23:29:25 [INFO]: Epoch 051 - training loss: 0.8150, validation loss: 0.8700
2024-05-24 23:29:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch51_loss0.8700308352708817.pypots
2024-05-24 23:29:25 [INFO]: Epoch 052 - training loss: 0.8124, validation loss: 0.8682
2024-05-24 23:29:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch52_loss0.8682423830032349.pypots
2024-05-24 23:29:25 [INFO]: Epoch 053 - training loss: 0.8064, validation loss: 0.8675
2024-05-24 23:29:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch53_loss0.8675226867198944.pypots
2024-05-24 23:29:25 [INFO]: Epoch 054 - training loss: 0.7919, validation loss: 0.8662
2024-05-24 23:29:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch54_loss0.8662102073431015.pypots
2024-05-24 23:29:26 [INFO]: Epoch 055 - training loss: 0.8160, validation loss: 0.8668
2024-05-24 23:29:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch55_loss0.866777703166008.pypots
2024-05-24 23:29:26 [INFO]: Epoch 056 - training loss: 0.8093, validation loss: 0.8642
2024-05-24 23:29:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch56_loss0.8642479628324509.pypots
2024-05-24 23:29:26 [INFO]: Epoch 057 - training loss: 0.8362, validation loss: 0.8621
2024-05-24 23:29:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch57_loss0.8621183633804321.pypots
2024-05-24 23:29:26 [INFO]: Epoch 058 - training loss: 0.8116, validation loss: 0.8628
2024-05-24 23:29:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch58_loss0.8627898246049881.pypots
2024-05-24 23:29:26 [INFO]: Epoch 059 - training loss: 0.7963, validation loss: 0.8601
2024-05-24 23:29:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch59_loss0.8601170778274536.pypots
2024-05-24 23:29:27 [INFO]: Epoch 060 - training loss: 0.8125, validation loss: 0.8591
2024-05-24 23:29:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch60_loss0.8590784519910812.pypots
2024-05-24 23:29:27 [INFO]: Epoch 061 - training loss: 0.8131, validation loss: 0.8591
2024-05-24 23:29:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch61_loss0.85909004509449.pypots
2024-05-24 23:29:27 [INFO]: Epoch 062 - training loss: 0.8010, validation loss: 0.8578
2024-05-24 23:29:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch62_loss0.8578084260225296.pypots
2024-05-24 23:29:27 [INFO]: Epoch 063 - training loss: 0.7945, validation loss: 0.8580
2024-05-24 23:29:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch63_loss0.8580413609743118.pypots
2024-05-24 23:29:27 [INFO]: Epoch 064 - training loss: 0.8066, validation loss: 0.8546
2024-05-24 23:29:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch64_loss0.8546338081359863.pypots
2024-05-24 23:29:28 [INFO]: Epoch 065 - training loss: 0.7812, validation loss: 0.8548
2024-05-24 23:29:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch65_loss0.8548351675271988.pypots
2024-05-24 23:29:28 [INFO]: Epoch 066 - training loss: 0.8517, validation loss: 0.8523
2024-05-24 23:29:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch66_loss0.8523133248090744.pypots
2024-05-24 23:29:28 [INFO]: Epoch 067 - training loss: 0.8168, validation loss: 0.8552
2024-05-24 23:29:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch67_loss0.8552061319351196.pypots
2024-05-24 23:29:28 [INFO]: Epoch 068 - training loss: 0.8059, validation loss: 0.8539
2024-05-24 23:29:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch68_loss0.8539096713066101.pypots
2024-05-24 23:29:28 [INFO]: Epoch 069 - training loss: 0.8053, validation loss: 0.8528
2024-05-24 23:29:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch69_loss0.8528067022562027.pypots
2024-05-24 23:29:28 [INFO]: Epoch 070 - training loss: 0.7928, validation loss: 0.8520
2024-05-24 23:29:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch70_loss0.851958155632019.pypots
2024-05-24 23:29:29 [INFO]: Epoch 071 - training loss: 0.8056, validation loss: 0.8518
2024-05-24 23:29:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch71_loss0.8518043905496597.pypots
2024-05-24 23:29:29 [INFO]: Epoch 072 - training loss: 0.7926, validation loss: 0.8528
2024-05-24 23:29:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch72_loss0.8528088927268982.pypots
2024-05-24 23:29:29 [INFO]: Epoch 073 - training loss: 0.7993, validation loss: 0.8520
2024-05-24 23:29:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch73_loss0.8520100712776184.pypots
2024-05-24 23:29:29 [INFO]: Epoch 074 - training loss: 0.7879, validation loss: 0.8514
2024-05-24 23:29:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch74_loss0.8514297157526016.pypots
2024-05-24 23:29:29 [INFO]: Epoch 075 - training loss: 0.8121, validation loss: 0.8502
2024-05-24 23:29:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch75_loss0.8502455055713654.pypots
2024-05-24 23:29:30 [INFO]: Epoch 076 - training loss: 0.7963, validation loss: 0.8506
2024-05-24 23:29:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch76_loss0.8506314307451248.pypots
2024-05-24 23:29:30 [INFO]: Epoch 077 - training loss: 0.7927, validation loss: 0.8501
2024-05-24 23:29:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch77_loss0.8500522971153259.pypots
2024-05-24 23:29:30 [INFO]: Epoch 078 - training loss: 0.7954, validation loss: 0.8498
2024-05-24 23:29:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch78_loss0.8497658669948578.pypots
2024-05-24 23:29:30 [INFO]: Epoch 079 - training loss: 0.7925, validation loss: 0.8499
2024-05-24 23:29:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch79_loss0.8498810976743698.pypots
2024-05-24 23:29:30 [INFO]: Epoch 080 - training loss: 0.7903, validation loss: 0.8491
2024-05-24 23:29:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch80_loss0.8491110950708389.pypots
2024-05-24 23:29:31 [INFO]: Epoch 081 - training loss: 0.7818, validation loss: 0.8503
2024-05-24 23:29:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch81_loss0.8503010869026184.pypots
2024-05-24 23:29:31 [INFO]: Epoch 082 - training loss: 0.7787, validation loss: 0.8507
2024-05-24 23:29:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch82_loss0.8507313579320908.pypots
2024-05-24 23:29:31 [INFO]: Epoch 083 - training loss: 0.7932, validation loss: 0.8478
2024-05-24 23:29:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch83_loss0.8478399068117142.pypots
2024-05-24 23:29:31 [INFO]: Epoch 084 - training loss: 0.7895, validation loss: 0.8472
2024-05-24 23:29:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch84_loss0.8472032696008682.pypots
2024-05-24 23:29:31 [INFO]: Epoch 085 - training loss: 0.8087, validation loss: 0.8499
2024-05-24 23:29:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch85_loss0.8498707860708237.pypots
2024-05-24 23:29:31 [INFO]: Epoch 086 - training loss: 0.8177, validation loss: 0.8480
2024-05-24 23:29:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch86_loss0.8480473011732101.pypots
2024-05-24 23:29:32 [INFO]: Epoch 087 - training loss: 0.7880, validation loss: 0.8483
2024-05-24 23:29:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch87_loss0.8482793867588043.pypots
2024-05-24 23:29:32 [INFO]: Epoch 088 - training loss: 0.8109, validation loss: 0.8495
2024-05-24 23:29:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch88_loss0.8495104014873505.pypots
2024-05-24 23:29:32 [INFO]: Epoch 089 - training loss: 0.7929, validation loss: 0.8468
2024-05-24 23:29:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch89_loss0.8468490689992905.pypots
2024-05-24 23:29:32 [INFO]: Epoch 090 - training loss: 0.7875, validation loss: 0.8457
2024-05-24 23:29:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch90_loss0.8456842303276062.pypots
2024-05-24 23:29:32 [INFO]: Epoch 091 - training loss: 0.7969, validation loss: 0.8462
2024-05-24 23:29:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch91_loss0.8461680114269257.pypots
2024-05-24 23:29:33 [INFO]: Epoch 092 - training loss: 0.8014, validation loss: 0.8469
2024-05-24 23:29:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch92_loss0.8469056785106659.pypots
2024-05-24 23:29:33 [INFO]: Epoch 093 - training loss: 0.8030, validation loss: 0.8482
2024-05-24 23:29:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch93_loss0.8482376039028168.pypots
2024-05-24 23:29:33 [INFO]: Epoch 094 - training loss: 0.8180, validation loss: 0.8478
2024-05-24 23:29:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch94_loss0.84783074259758.pypots
2024-05-24 23:29:33 [INFO]: Epoch 095 - training loss: 0.7866, validation loss: 0.8464
2024-05-24 23:29:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch95_loss0.8464178889989853.pypots
2024-05-24 23:29:33 [INFO]: Epoch 096 - training loss: 0.7821, validation loss: 0.8494
2024-05-24 23:29:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch96_loss0.8494451940059662.pypots
2024-05-24 23:29:34 [INFO]: Epoch 097 - training loss: 0.8051, validation loss: 0.8457
2024-05-24 23:29:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch97_loss0.8457106053829193.pypots
2024-05-24 23:29:34 [INFO]: Epoch 098 - training loss: 0.7954, validation loss: 0.8463
2024-05-24 23:29:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch98_loss0.8462960124015808.pypots
2024-05-24 23:29:34 [INFO]: Epoch 099 - training loss: 0.8003, validation loss: 0.8460
2024-05-24 23:29:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch99_loss0.8459588289260864.pypots
2024-05-24 23:29:34 [INFO]: Epoch 100 - training loss: 0.8384, validation loss: 0.8437
2024-05-24 23:29:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch100_loss0.8437376469373703.pypots
2024-05-24 23:29:34 [INFO]: Epoch 101 - training loss: 0.7964, validation loss: 0.8487
2024-05-24 23:29:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch101_loss0.8487287014722824.pypots
2024-05-24 23:29:34 [INFO]: Epoch 102 - training loss: 0.7925, validation loss: 0.8496
2024-05-24 23:29:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch102_loss0.8495500981807709.pypots
2024-05-24 23:29:35 [INFO]: Epoch 103 - training loss: 0.7962, validation loss: 0.8459
2024-05-24 23:29:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch103_loss0.8458774089813232.pypots
2024-05-24 23:29:35 [INFO]: Epoch 104 - training loss: 0.7891, validation loss: 0.8507
2024-05-24 23:29:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch104_loss0.8506721258163452.pypots
2024-05-24 23:29:35 [INFO]: Epoch 105 - training loss: 0.8184, validation loss: 0.8478
2024-05-24 23:29:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch105_loss0.8478158861398697.pypots
2024-05-24 23:29:35 [INFO]: Epoch 106 - training loss: 0.8015, validation loss: 0.8477
2024-05-24 23:29:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch106_loss0.8476589769124985.pypots
2024-05-24 23:29:35 [INFO]: Epoch 107 - training loss: 0.7817, validation loss: 0.8473
2024-05-24 23:29:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch107_loss0.8473466038703918.pypots
2024-05-24 23:29:36 [INFO]: Epoch 108 - training loss: 0.7919, validation loss: 0.8428
2024-05-24 23:29:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch108_loss0.8427844047546387.pypots
2024-05-24 23:29:36 [INFO]: Epoch 109 - training loss: 0.8381, validation loss: 0.8463
2024-05-24 23:29:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch109_loss0.8462941944599152.pypots
2024-05-24 23:29:36 [INFO]: Epoch 110 - training loss: 0.8016, validation loss: 0.8494
2024-05-24 23:29:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch110_loss0.8493854403495789.pypots
2024-05-24 23:29:36 [INFO]: Epoch 111 - training loss: 0.7911, validation loss: 0.8477
2024-05-24 23:29:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch111_loss0.8477126061916351.pypots
2024-05-24 23:29:36 [INFO]: Epoch 112 - training loss: 0.8075, validation loss: 0.8473
2024-05-24 23:29:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch112_loss0.8473383784294128.pypots
2024-05-24 23:29:37 [INFO]: Epoch 113 - training loss: 0.8037, validation loss: 0.8468
2024-05-24 23:29:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch113_loss0.8467932790517807.pypots
2024-05-24 23:29:37 [INFO]: Epoch 114 - training loss: 0.8150, validation loss: 0.8455
2024-05-24 23:29:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch114_loss0.845520481467247.pypots
2024-05-24 23:29:37 [INFO]: Epoch 115 - training loss: 0.7793, validation loss: 0.8465
2024-05-24 23:29:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch115_loss0.8465107679367065.pypots
2024-05-24 23:29:37 [INFO]: Epoch 116 - training loss: 0.7707, validation loss: 0.8453
2024-05-24 23:29:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch116_loss0.8453345596790314.pypots
2024-05-24 23:29:37 [INFO]: Epoch 117 - training loss: 0.7898, validation loss: 0.8472
2024-05-24 23:29:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch117_loss0.8472020775079727.pypots
2024-05-24 23:29:37 [INFO]: Epoch 118 - training loss: 0.7901, validation loss: 0.8447
2024-05-24 23:29:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN_epoch118_loss0.844695657491684.pypots
2024-05-24 23:29:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:29:37 [INFO]: Finished training. The best model is from epoch#108.
2024-05-24 23:29:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T232914/MRNN.pypots
2024-05-24 23:29:38 [INFO]: MRNN on ETTm1: MAE=0.7260, MSE=1.3177
2024-05-24 23:29:38 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/MRNN_ettm1/imputation.pkl
2024-05-24 23:29:38 [INFO]: Using the given device: cpu
2024-05-24 23:29:38 [INFO]: LOCF on ETTm1: MAE=0.1332, MSE=0.0720
2024-05-24 23:29:38 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_ettm1".
2024-05-24 23:29:38 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/LOCF_ettm1/imputation.pkl
2024-05-24 23:29:38 [INFO]: Median on ETTm1: MAE=0.6670, MSE=0.8617
2024-05-24 23:29:38 [INFO]: Successfully created the given path "saved_results/round_1/Median_ettm1".
2024-05-24 23:29:38 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/Median_ettm1/imputation.pkl
2024-05-24 23:29:38 [INFO]: Mean on ETTm1: MAE=0.6734, MSE=0.8444
2024-05-24 23:29:38 [INFO]: Successfully created the given path "saved_results/round_1/Mean_ettm1".
2024-05-24 23:29:38 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/Mean_ettm1/imputation.pkl
2024-05-24 23:29:38 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-24 23:29:38 [INFO]: Using the given device: cuda:0
2024-05-24 23:29:38 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/SAITS_ettm1/20240524_T232938
2024-05-24 23:29:38 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/SAITS_ettm1/20240524_T232938/tensorboard
2024-05-24 23:29:38 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 23:29:39 [INFO]: Epoch 001 - training loss: 1.1742, validation loss: 0.2652
2024-05-24 23:29:39 [INFO]: Epoch 002 - training loss: 0.8291, validation loss: 0.1312
2024-05-24 23:29:40 [INFO]: Epoch 003 - training loss: 0.7198, validation loss: 0.1319
2024-05-24 23:29:40 [INFO]: Epoch 004 - training loss: 0.6560, validation loss: 0.0846
2024-05-24 23:29:41 [INFO]: Epoch 005 - training loss: 0.6322, validation loss: 0.0872
2024-05-24 23:29:41 [INFO]: Epoch 006 - training loss: 0.5784, validation loss: 0.0837
2024-05-24 23:29:42 [INFO]: Epoch 007 - training loss: 0.5643, validation loss: 0.0924
2024-05-24 23:29:42 [INFO]: Epoch 008 - training loss: 0.5458, validation loss: 0.0643
2024-05-24 23:29:43 [INFO]: Epoch 009 - training loss: 0.5513, validation loss: 0.0693
2024-05-24 23:29:43 [INFO]: Epoch 010 - training loss: 0.5375, validation loss: 0.0600
2024-05-24 23:29:44 [INFO]: Epoch 011 - training loss: 0.5148, validation loss: 0.0717
2024-05-24 23:29:44 [INFO]: Epoch 012 - training loss: 0.4964, validation loss: 0.0653
2024-05-24 23:29:45 [INFO]: Epoch 013 - training loss: 0.4921, validation loss: 0.0650
2024-05-24 23:29:45 [INFO]: Epoch 014 - training loss: 0.4757, validation loss: 0.0700
2024-05-24 23:29:46 [INFO]: Epoch 015 - training loss: 0.4891, validation loss: 0.0550
2024-05-24 23:29:46 [INFO]: Epoch 016 - training loss: 0.4648, validation loss: 0.0532
2024-05-24 23:29:47 [INFO]: Epoch 017 - training loss: 0.4609, validation loss: 0.0536
2024-05-24 23:29:47 [INFO]: Epoch 018 - training loss: 0.4590, validation loss: 0.0503
2024-05-24 23:29:48 [INFO]: Epoch 019 - training loss: 0.4342, validation loss: 0.0410
2024-05-24 23:29:48 [INFO]: Epoch 020 - training loss: 0.4258, validation loss: 0.0561
2024-05-24 23:29:49 [INFO]: Epoch 021 - training loss: 0.4454, validation loss: 0.0509
2024-05-24 23:29:49 [INFO]: Epoch 022 - training loss: 0.4295, validation loss: 0.0354
2024-05-24 23:29:50 [INFO]: Epoch 023 - training loss: 0.4273, validation loss: 0.0548
2024-05-24 23:29:50 [INFO]: Epoch 024 - training loss: 0.4102, validation loss: 0.0519
2024-05-24 23:29:51 [INFO]: Epoch 025 - training loss: 0.4014, validation loss: 0.0386
2024-05-24 23:29:51 [INFO]: Epoch 026 - training loss: 0.4225, validation loss: 0.0552
2024-05-24 23:29:52 [INFO]: Epoch 027 - training loss: 0.4033, validation loss: 0.0484
2024-05-24 23:29:52 [INFO]: Epoch 028 - training loss: 0.4060, validation loss: 0.0457
2024-05-24 23:29:53 [INFO]: Epoch 029 - training loss: 0.3901, validation loss: 0.0449
2024-05-24 23:29:53 [INFO]: Epoch 030 - training loss: 0.3922, validation loss: 0.0430
2024-05-24 23:29:54 [INFO]: Epoch 031 - training loss: 0.3750, validation loss: 0.0317
2024-05-24 23:29:54 [INFO]: Epoch 032 - training loss: 0.3762, validation loss: 0.0333
2024-05-24 23:29:55 [INFO]: Epoch 033 - training loss: 0.3688, validation loss: 0.0417
2024-05-24 23:29:55 [INFO]: Epoch 034 - training loss: 0.3559, validation loss: 0.0329
2024-05-24 23:29:56 [INFO]: Epoch 035 - training loss: 0.3570, validation loss: 0.0475
2024-05-24 23:29:56 [INFO]: Epoch 036 - training loss: 0.3531, validation loss: 0.0350
2024-05-24 23:29:57 [INFO]: Epoch 037 - training loss: 0.3601, validation loss: 0.0273
2024-05-24 23:29:57 [INFO]: Epoch 038 - training loss: 0.3791, validation loss: 0.0366
2024-05-24 23:29:58 [INFO]: Epoch 039 - training loss: 0.4013, validation loss: 0.0436
2024-05-24 23:29:58 [INFO]: Epoch 040 - training loss: 0.3707, validation loss: 0.0432
2024-05-24 23:29:59 [INFO]: Epoch 041 - training loss: 0.3660, validation loss: 0.0464
2024-05-24 23:29:59 [INFO]: Epoch 042 - training loss: 0.3553, validation loss: 0.0313
2024-05-24 23:30:00 [INFO]: Epoch 043 - training loss: 0.3452, validation loss: 0.0345
2024-05-24 23:30:00 [INFO]: Epoch 044 - training loss: 0.3362, validation loss: 0.0420
2024-05-24 23:30:01 [INFO]: Epoch 045 - training loss: 0.3382, validation loss: 0.0333
2024-05-24 23:30:01 [INFO]: Epoch 046 - training loss: 0.3260, validation loss: 0.0366
2024-05-24 23:30:02 [INFO]: Epoch 047 - training loss: 0.3328, validation loss: 0.0417
2024-05-24 23:30:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:30:02 [INFO]: Finished training. The best model is from epoch#37.
2024-05-24 23:30:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/SAITS_ettm1/20240524_T232938/SAITS.pypots
2024-05-24 23:30:02 [INFO]: SAITS on ETTm1: MAE=0.1455, MSE=0.0455
2024-05-24 23:30:02 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/SAITS_ettm1/imputation.pkl
2024-05-24 23:30:02 [INFO]: Using the given device: cuda:0
2024-05-24 23:30:02 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/Transformer_ettm1/20240524_T233002
2024-05-24 23:30:02 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/Transformer_ettm1/20240524_T233002/tensorboard
2024-05-24 23:30:02 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 23:30:02 [INFO]: Epoch 001 - training loss: 1.2560, validation loss: 0.3079
2024-05-24 23:30:03 [INFO]: Epoch 002 - training loss: 0.7475, validation loss: 0.1532
2024-05-24 23:30:03 [INFO]: Epoch 003 - training loss: 0.6016, validation loss: 0.1124
2024-05-24 23:30:03 [INFO]: Epoch 004 - training loss: 0.5305, validation loss: 0.0821
2024-05-24 23:30:03 [INFO]: Epoch 005 - training loss: 0.4880, validation loss: 0.0669
2024-05-24 23:30:03 [INFO]: Epoch 006 - training loss: 0.4633, validation loss: 0.0596
2024-05-24 23:30:04 [INFO]: Epoch 007 - training loss: 0.4422, validation loss: 0.0622
2024-05-24 23:30:04 [INFO]: Epoch 008 - training loss: 0.4176, validation loss: 0.0585
2024-05-24 23:30:04 [INFO]: Epoch 009 - training loss: 0.4064, validation loss: 0.0521
2024-05-24 23:30:04 [INFO]: Epoch 010 - training loss: 0.3857, validation loss: 0.0500
2024-05-24 23:30:05 [INFO]: Epoch 011 - training loss: 0.3821, validation loss: 0.0484
2024-05-24 23:30:05 [INFO]: Epoch 012 - training loss: 0.3744, validation loss: 0.0505
2024-05-24 23:30:05 [INFO]: Epoch 013 - training loss: 0.3603, validation loss: 0.0472
2024-05-24 23:30:05 [INFO]: Epoch 014 - training loss: 0.3535, validation loss: 0.0452
2024-05-24 23:30:05 [INFO]: Epoch 015 - training loss: 0.3502, validation loss: 0.0464
2024-05-24 23:30:06 [INFO]: Epoch 016 - training loss: 0.3471, validation loss: 0.0401
2024-05-24 23:30:06 [INFO]: Epoch 017 - training loss: 0.3363, validation loss: 0.0406
2024-05-24 23:30:06 [INFO]: Epoch 018 - training loss: 0.3279, validation loss: 0.0438
2024-05-24 23:30:06 [INFO]: Epoch 019 - training loss: 0.3295, validation loss: 0.0439
2024-05-24 23:30:06 [INFO]: Epoch 020 - training loss: 0.3305, validation loss: 0.0421
2024-05-24 23:30:07 [INFO]: Epoch 021 - training loss: 0.3194, validation loss: 0.0375
2024-05-24 23:30:07 [INFO]: Epoch 022 - training loss: 0.3087, validation loss: 0.0395
2024-05-24 23:30:07 [INFO]: Epoch 023 - training loss: 0.3082, validation loss: 0.0364
2024-05-24 23:30:07 [INFO]: Epoch 024 - training loss: 0.3091, validation loss: 0.0388
2024-05-24 23:30:08 [INFO]: Epoch 025 - training loss: 0.2996, validation loss: 0.0335
2024-05-24 23:30:08 [INFO]: Epoch 026 - training loss: 0.2936, validation loss: 0.0352
2024-05-24 23:30:08 [INFO]: Epoch 027 - training loss: 0.2932, validation loss: 0.0341
2024-05-24 23:30:08 [INFO]: Epoch 028 - training loss: 0.2838, validation loss: 0.0365
2024-05-24 23:30:08 [INFO]: Epoch 029 - training loss: 0.2828, validation loss: 0.0345
2024-05-24 23:30:09 [INFO]: Epoch 030 - training loss: 0.2832, validation loss: 0.0380
2024-05-24 23:30:09 [INFO]: Epoch 031 - training loss: 0.2802, validation loss: 0.0370
2024-05-24 23:30:09 [INFO]: Epoch 032 - training loss: 0.2767, validation loss: 0.0315
2024-05-24 23:30:09 [INFO]: Epoch 033 - training loss: 0.2719, validation loss: 0.0284
2024-05-24 23:30:10 [INFO]: Epoch 034 - training loss: 0.2706, validation loss: 0.0312
2024-05-24 23:30:10 [INFO]: Epoch 035 - training loss: 0.2670, validation loss: 0.0321
2024-05-24 23:30:10 [INFO]: Epoch 036 - training loss: 0.2736, validation loss: 0.0296
2024-05-24 23:30:10 [INFO]: Epoch 037 - training loss: 0.2662, validation loss: 0.0265
2024-05-24 23:30:10 [INFO]: Epoch 038 - training loss: 0.2539, validation loss: 0.0331
2024-05-24 23:30:11 [INFO]: Epoch 039 - training loss: 0.2605, validation loss: 0.0290
2024-05-24 23:30:11 [INFO]: Epoch 040 - training loss: 0.2576, validation loss: 0.0317
2024-05-24 23:30:11 [INFO]: Epoch 041 - training loss: 0.2581, validation loss: 0.0267
2024-05-24 23:30:11 [INFO]: Epoch 042 - training loss: 0.2541, validation loss: 0.0264
2024-05-24 23:30:11 [INFO]: Epoch 043 - training loss: 0.2460, validation loss: 0.0270
2024-05-24 23:30:12 [INFO]: Epoch 044 - training loss: 0.2493, validation loss: 0.0254
2024-05-24 23:30:12 [INFO]: Epoch 045 - training loss: 0.2436, validation loss: 0.0310
2024-05-24 23:30:12 [INFO]: Epoch 046 - training loss: 0.2447, validation loss: 0.0251
2024-05-24 23:30:12 [INFO]: Epoch 047 - training loss: 0.2413, validation loss: 0.0237
2024-05-24 23:30:13 [INFO]: Epoch 048 - training loss: 0.2371, validation loss: 0.0256
2024-05-24 23:30:13 [INFO]: Epoch 049 - training loss: 0.2338, validation loss: 0.0282
2024-05-24 23:30:13 [INFO]: Epoch 050 - training loss: 0.2331, validation loss: 0.0269
2024-05-24 23:30:13 [INFO]: Epoch 051 - training loss: 0.2351, validation loss: 0.0245
2024-05-24 23:30:13 [INFO]: Epoch 052 - training loss: 0.2353, validation loss: 0.0261
2024-05-24 23:30:14 [INFO]: Epoch 053 - training loss: 0.2358, validation loss: 0.0242
2024-05-24 23:30:14 [INFO]: Epoch 054 - training loss: 0.2364, validation loss: 0.0270
2024-05-24 23:30:14 [INFO]: Epoch 055 - training loss: 0.2291, validation loss: 0.0268
2024-05-24 23:30:14 [INFO]: Epoch 056 - training loss: 0.2319, validation loss: 0.0254
2024-05-24 23:30:15 [INFO]: Epoch 057 - training loss: 0.2374, validation loss: 0.0255
2024-05-24 23:30:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:30:15 [INFO]: Finished training. The best model is from epoch#47.
2024-05-24 23:30:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/Transformer_ettm1/20240524_T233002/Transformer.pypots
2024-05-24 23:30:15 [INFO]: Transformer on ETTm1: MAE=0.1290, MSE=0.0327
2024-05-24 23:30:15 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/Transformer_ettm1/imputation.pkl
2024-05-24 23:30:15 [INFO]: Using the given device: cuda:0
2024-05-24 23:30:15 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/TimesNet_ettm1/20240524_T233015
2024-05-24 23:30:15 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/TimesNet_ettm1/20240524_T233015/tensorboard
2024-05-24 23:30:15 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 23:30:15 [INFO]: Epoch 001 - training loss: 0.1418, validation loss: 0.0556
2024-05-24 23:30:15 [INFO]: Epoch 002 - training loss: 0.0643, validation loss: 0.0369
2024-05-24 23:30:15 [INFO]: Epoch 003 - training loss: 0.0511, validation loss: 0.0312
2024-05-24 23:30:16 [INFO]: Epoch 004 - training loss: 0.0491, validation loss: 0.0349
2024-05-24 23:30:16 [INFO]: Epoch 005 - training loss: 0.0500, validation loss: 0.0421
2024-05-24 23:30:16 [INFO]: Epoch 006 - training loss: 0.0491, validation loss: 0.0315
2024-05-24 23:30:16 [INFO]: Epoch 007 - training loss: 0.0438, validation loss: 0.0289
2024-05-24 23:30:16 [INFO]: Epoch 008 - training loss: 0.0432, validation loss: 0.0269
2024-05-24 23:30:17 [INFO]: Epoch 009 - training loss: 0.0443, validation loss: 0.0299
2024-05-24 23:30:17 [INFO]: Epoch 010 - training loss: 0.0445, validation loss: 0.0265
2024-05-24 23:30:17 [INFO]: Epoch 011 - training loss: 0.0440, validation loss: 0.0287
2024-05-24 23:30:17 [INFO]: Epoch 012 - training loss: 0.0447, validation loss: 0.0301
2024-05-24 23:30:18 [INFO]: Epoch 013 - training loss: 0.0448, validation loss: 0.0299
2024-05-24 23:30:18 [INFO]: Epoch 014 - training loss: 0.0414, validation loss: 0.0308
2024-05-24 23:30:18 [INFO]: Epoch 015 - training loss: 0.0416, validation loss: 0.0280
2024-05-24 23:30:18 [INFO]: Epoch 016 - training loss: 0.0410, validation loss: 0.0279
2024-05-24 23:30:18 [INFO]: Epoch 017 - training loss: 0.0428, validation loss: 0.0288
2024-05-24 23:30:19 [INFO]: Epoch 018 - training loss: 0.0466, validation loss: 0.0350
2024-05-24 23:30:19 [INFO]: Epoch 019 - training loss: 0.0541, validation loss: 0.0301
2024-05-24 23:30:19 [INFO]: Epoch 020 - training loss: 0.0424, validation loss: 0.0271
2024-05-24 23:30:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:30:19 [INFO]: Finished training. The best model is from epoch#10.
2024-05-24 23:30:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/TimesNet_ettm1/20240524_T233015/TimesNet.pypots
2024-05-24 23:30:19 [INFO]: TimesNet on ETTm1: MAE=0.1158, MSE=0.0278
2024-05-24 23:30:19 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/TimesNet_ettm1/imputation.pkl
2024-05-24 23:30:19 [INFO]: Using the given device: cuda:0
2024-05-24 23:30:19 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019
2024-05-24 23:30:19 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/tensorboard
2024-05-24 23:30:19 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 23:30:21 [INFO]: Epoch 001 - training loss: 0.7171, validation loss: 0.4655
2024-05-24 23:30:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch1_loss0.46553564816713333.pypots
2024-05-24 23:30:23 [INFO]: Epoch 002 - training loss: 0.4087, validation loss: 0.3786
2024-05-24 23:30:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch2_loss0.37858373671770096.pypots
2024-05-24 23:30:25 [INFO]: Epoch 003 - training loss: 0.3674, validation loss: 0.3577
2024-05-24 23:30:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch3_loss0.35767729580402374.pypots
2024-05-24 23:30:27 [INFO]: Epoch 004 - training loss: 0.3624, validation loss: 0.3461
2024-05-24 23:30:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch4_loss0.346146896481514.pypots
2024-05-24 23:30:29 [INFO]: Epoch 005 - training loss: 0.3053, validation loss: 0.3371
2024-05-24 23:30:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch5_loss0.3370773419737816.pypots
2024-05-24 23:30:32 [INFO]: Epoch 006 - training loss: 0.3107, validation loss: 0.3475
2024-05-24 23:30:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch6_loss0.34745312482118607.pypots
2024-05-24 23:30:34 [INFO]: Epoch 007 - training loss: 0.2711, validation loss: 0.2908
2024-05-24 23:30:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch7_loss0.2908225730061531.pypots
2024-05-24 23:30:36 [INFO]: Epoch 008 - training loss: 0.2349, validation loss: 0.2770
2024-05-24 23:30:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch8_loss0.2769552916288376.pypots
2024-05-24 23:30:38 [INFO]: Epoch 009 - training loss: 0.2436, validation loss: 0.2685
2024-05-24 23:30:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch9_loss0.26845143735408783.pypots
2024-05-24 23:30:40 [INFO]: Epoch 010 - training loss: 0.2412, validation loss: 0.2547
2024-05-24 23:30:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch10_loss0.25473953038454056.pypots
2024-05-24 23:30:42 [INFO]: Epoch 011 - training loss: 0.2359, validation loss: 0.2484
2024-05-24 23:30:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch11_loss0.2483588457107544.pypots
2024-05-24 23:30:44 [INFO]: Epoch 012 - training loss: 0.2507, validation loss: 0.2372
2024-05-24 23:30:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch12_loss0.23720569908618927.pypots
2024-05-24 23:30:46 [INFO]: Epoch 013 - training loss: 0.2282, validation loss: 0.2305
2024-05-24 23:30:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch13_loss0.23047994449734688.pypots
2024-05-24 23:30:48 [INFO]: Epoch 014 - training loss: 0.2126, validation loss: 0.2235
2024-05-24 23:30:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch14_loss0.2234654389321804.pypots
2024-05-24 23:30:50 [INFO]: Epoch 015 - training loss: 0.2061, validation loss: 0.2114
2024-05-24 23:30:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch15_loss0.21141619980335236.pypots
2024-05-24 23:30:52 [INFO]: Epoch 016 - training loss: 0.2157, validation loss: 0.2203
2024-05-24 23:30:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch16_loss0.22032639384269714.pypots
2024-05-24 23:30:54 [INFO]: Epoch 017 - training loss: 0.2165, validation loss: 0.2071
2024-05-24 23:30:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch17_loss0.207131490111351.pypots
2024-05-24 23:30:57 [INFO]: Epoch 018 - training loss: 0.2020, validation loss: 0.1983
2024-05-24 23:30:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch18_loss0.1983470842242241.pypots
2024-05-24 23:30:59 [INFO]: Epoch 019 - training loss: 0.1964, validation loss: 0.1981
2024-05-24 23:30:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch19_loss0.19806019589304924.pypots
2024-05-24 23:31:01 [INFO]: Epoch 020 - training loss: 0.1856, validation loss: 0.1907
2024-05-24 23:31:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch20_loss0.19065865501761436.pypots
2024-05-24 23:31:03 [INFO]: Epoch 021 - training loss: 0.2201, validation loss: 0.1960
2024-05-24 23:31:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch21_loss0.1959991715848446.pypots
2024-05-24 23:31:05 [INFO]: Epoch 022 - training loss: 0.1843, validation loss: 0.1861
2024-05-24 23:31:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch22_loss0.18605811893939972.pypots
2024-05-24 23:31:07 [INFO]: Epoch 023 - training loss: 0.1999, validation loss: 0.1811
2024-05-24 23:31:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch23_loss0.18112411350011826.pypots
2024-05-24 23:31:09 [INFO]: Epoch 024 - training loss: 0.2038, validation loss: 0.1800
2024-05-24 23:31:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch24_loss0.18003985658288002.pypots
2024-05-24 23:31:11 [INFO]: Epoch 025 - training loss: 0.2310, validation loss: 0.1771
2024-05-24 23:31:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch25_loss0.17709069326519966.pypots
2024-05-24 23:31:13 [INFO]: Epoch 026 - training loss: 0.1668, validation loss: 0.1736
2024-05-24 23:31:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch26_loss0.1736476868391037.pypots
2024-05-24 23:31:15 [INFO]: Epoch 027 - training loss: 0.1575, validation loss: 0.1694
2024-05-24 23:31:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch27_loss0.16939016059041023.pypots
2024-05-24 23:31:17 [INFO]: Epoch 028 - training loss: 0.1691, validation loss: 0.1633
2024-05-24 23:31:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch28_loss0.1632590889930725.pypots
2024-05-24 23:31:19 [INFO]: Epoch 029 - training loss: 0.1569, validation loss: 0.1653
2024-05-24 23:31:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch29_loss0.16532143205404282.pypots
2024-05-24 23:31:22 [INFO]: Epoch 030 - training loss: 0.1732, validation loss: 0.1636
2024-05-24 23:31:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch30_loss0.16364748775959015.pypots
2024-05-24 23:31:24 [INFO]: Epoch 031 - training loss: 0.1613, validation loss: 0.1567
2024-05-24 23:31:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch31_loss0.1567445993423462.pypots
2024-05-24 23:31:26 [INFO]: Epoch 032 - training loss: 0.1527, validation loss: 0.1680
2024-05-24 23:31:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch32_loss0.16801735386252403.pypots
2024-05-24 23:31:28 [INFO]: Epoch 033 - training loss: 0.1672, validation loss: 0.1617
2024-05-24 23:31:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch33_loss0.16168958693742752.pypots
2024-05-24 23:31:30 [INFO]: Epoch 034 - training loss: 0.1564, validation loss: 0.1647
2024-05-24 23:31:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch34_loss0.16474756225943565.pypots
2024-05-24 23:31:32 [INFO]: Epoch 035 - training loss: 0.1609, validation loss: 0.1507
2024-05-24 23:31:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch35_loss0.1506923772394657.pypots
2024-05-24 23:31:34 [INFO]: Epoch 036 - training loss: 0.1852, validation loss: 0.1562
2024-05-24 23:31:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch36_loss0.15622781589627266.pypots
2024-05-24 23:31:36 [INFO]: Epoch 037 - training loss: 0.2227, validation loss: 0.1723
2024-05-24 23:31:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch37_loss0.1722893938422203.pypots
2024-05-24 23:31:38 [INFO]: Epoch 038 - training loss: 0.1986, validation loss: 0.1818
2024-05-24 23:31:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch38_loss0.18182006105780602.pypots
2024-05-24 23:31:40 [INFO]: Epoch 039 - training loss: 0.1905, validation loss: 0.1593
2024-05-24 23:31:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch39_loss0.1593276970088482.pypots
2024-05-24 23:31:42 [INFO]: Epoch 040 - training loss: 0.1732, validation loss: 0.1615
2024-05-24 23:31:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch40_loss0.161454476416111.pypots
2024-05-24 23:31:44 [INFO]: Epoch 041 - training loss: 0.1747, validation loss: 0.1612
2024-05-24 23:31:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch41_loss0.16123775392770767.pypots
2024-05-24 23:31:46 [INFO]: Epoch 042 - training loss: 0.1890, validation loss: 0.1611
2024-05-24 23:31:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch42_loss0.16106858104467392.pypots
2024-05-24 23:31:49 [INFO]: Epoch 043 - training loss: 0.1837, validation loss: 0.1484
2024-05-24 23:31:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch43_loss0.148429024964571.pypots
2024-05-24 23:31:51 [INFO]: Epoch 044 - training loss: 0.1416, validation loss: 0.1481
2024-05-24 23:31:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch44_loss0.14810526371002197.pypots
2024-05-24 23:31:53 [INFO]: Epoch 045 - training loss: 0.1444, validation loss: 0.1438
2024-05-24 23:31:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch45_loss0.14380183443427086.pypots
2024-05-24 23:31:55 [INFO]: Epoch 046 - training loss: 0.1653, validation loss: 0.1486
2024-05-24 23:31:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch46_loss0.14858287200331688.pypots
2024-05-24 23:31:57 [INFO]: Epoch 047 - training loss: 0.1628, validation loss: 0.1670
2024-05-24 23:31:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch47_loss0.1669827736914158.pypots
2024-05-24 23:31:59 [INFO]: Epoch 048 - training loss: 0.1582, validation loss: 0.1528
2024-05-24 23:31:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch48_loss0.15278220549225807.pypots
2024-05-24 23:32:01 [INFO]: Epoch 049 - training loss: 0.1305, validation loss: 0.1431
2024-05-24 23:32:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch49_loss0.14312808588147163.pypots
2024-05-24 23:32:03 [INFO]: Epoch 050 - training loss: 0.1416, validation loss: 0.1429
2024-05-24 23:32:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch50_loss0.1429055780172348.pypots
2024-05-24 23:32:05 [INFO]: Epoch 051 - training loss: 0.1638, validation loss: 0.1414
2024-05-24 23:32:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch51_loss0.14140870794653893.pypots
2024-05-24 23:32:07 [INFO]: Epoch 052 - training loss: 0.1592, validation loss: 0.1498
2024-05-24 23:32:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch52_loss0.14980336651206017.pypots
2024-05-24 23:32:09 [INFO]: Epoch 053 - training loss: 0.1653, validation loss: 0.1580
2024-05-24 23:32:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch53_loss0.15804369002580643.pypots
2024-05-24 23:32:11 [INFO]: Epoch 054 - training loss: 0.1803, validation loss: 0.1500
2024-05-24 23:32:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch54_loss0.15001897513866425.pypots
2024-05-24 23:32:14 [INFO]: Epoch 055 - training loss: 0.2125, validation loss: 0.1542
2024-05-24 23:32:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch55_loss0.15418334677815437.pypots
2024-05-24 23:32:16 [INFO]: Epoch 056 - training loss: 0.1820, validation loss: 0.1539
2024-05-24 23:32:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch56_loss0.15390664339065552.pypots
2024-05-24 23:32:18 [INFO]: Epoch 057 - training loss: 0.1524, validation loss: 0.1412
2024-05-24 23:32:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch57_loss0.14124897122383118.pypots
2024-05-24 23:32:20 [INFO]: Epoch 058 - training loss: 0.1794, validation loss: 0.1386
2024-05-24 23:32:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch58_loss0.13864677771925926.pypots
2024-05-24 23:32:22 [INFO]: Epoch 059 - training loss: 0.1374, validation loss: 0.1359
2024-05-24 23:32:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch59_loss0.13592270761728287.pypots
2024-05-24 23:32:24 [INFO]: Epoch 060 - training loss: 0.1661, validation loss: 0.1364
2024-05-24 23:32:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch60_loss0.13638389110565186.pypots
2024-05-24 23:32:26 [INFO]: Epoch 061 - training loss: 0.1471, validation loss: 0.1316
2024-05-24 23:32:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch61_loss0.13158342242240906.pypots
2024-05-24 23:32:28 [INFO]: Epoch 062 - training loss: 0.1673, validation loss: 0.1360
2024-05-24 23:32:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch62_loss0.13602539524435997.pypots
2024-05-24 23:32:30 [INFO]: Epoch 063 - training loss: 0.1737, validation loss: 0.1483
2024-05-24 23:32:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch63_loss0.14829014614224434.pypots
2024-05-24 23:32:32 [INFO]: Epoch 064 - training loss: 0.1516, validation loss: 0.1344
2024-05-24 23:32:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch64_loss0.13442950695753098.pypots
2024-05-24 23:32:34 [INFO]: Epoch 065 - training loss: 0.2216, validation loss: 0.1344
2024-05-24 23:32:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch65_loss0.13442851975560188.pypots
2024-05-24 23:32:36 [INFO]: Epoch 066 - training loss: 0.1564, validation loss: 0.1329
2024-05-24 23:32:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch66_loss0.13292676955461502.pypots
2024-05-24 23:32:38 [INFO]: Epoch 067 - training loss: 0.1465, validation loss: 0.1331
2024-05-24 23:32:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch67_loss0.1330972984433174.pypots
2024-05-24 23:32:41 [INFO]: Epoch 068 - training loss: 0.1596, validation loss: 0.1389
2024-05-24 23:32:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch68_loss0.13886306062340736.pypots
2024-05-24 23:32:43 [INFO]: Epoch 069 - training loss: 0.1541, validation loss: 0.1309
2024-05-24 23:32:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch69_loss0.13093257695436478.pypots
2024-05-24 23:32:45 [INFO]: Epoch 070 - training loss: 0.1554, validation loss: 0.1306
2024-05-24 23:32:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch70_loss0.13058734312653542.pypots
2024-05-24 23:32:47 [INFO]: Epoch 071 - training loss: 0.1606, validation loss: 0.1432
2024-05-24 23:32:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch71_loss0.1431906558573246.pypots
2024-05-24 23:32:49 [INFO]: Epoch 072 - training loss: 0.1688, validation loss: 0.1384
2024-05-24 23:32:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch72_loss0.13840964436531067.pypots
2024-05-24 23:32:51 [INFO]: Epoch 073 - training loss: 0.1339, validation loss: 0.1301
2024-05-24 23:32:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch73_loss0.13007151149213314.pypots
2024-05-24 23:32:53 [INFO]: Epoch 074 - training loss: 0.1424, validation loss: 0.1270
2024-05-24 23:32:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch74_loss0.12698454223573208.pypots
2024-05-24 23:32:55 [INFO]: Epoch 075 - training loss: 0.1656, validation loss: 0.1275
2024-05-24 23:32:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch75_loss0.12749146111309528.pypots
2024-05-24 23:32:57 [INFO]: Epoch 076 - training loss: 0.1684, validation loss: 0.1289
2024-05-24 23:32:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch76_loss0.12891350127756596.pypots
2024-05-24 23:32:59 [INFO]: Epoch 077 - training loss: 0.1493, validation loss: 0.1283
2024-05-24 23:32:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch77_loss0.12833120301365852.pypots
2024-05-24 23:33:01 [INFO]: Epoch 078 - training loss: 0.1592, validation loss: 0.1301
2024-05-24 23:33:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch78_loss0.13006953708827496.pypots
2024-05-24 23:33:03 [INFO]: Epoch 079 - training loss: 0.1308, validation loss: 0.1248
2024-05-24 23:33:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch79_loss0.12481032870709896.pypots
2024-05-24 23:33:06 [INFO]: Epoch 080 - training loss: 0.1906, validation loss: 0.1254
2024-05-24 23:33:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch80_loss0.12544009275734425.pypots
2024-05-24 23:33:08 [INFO]: Epoch 081 - training loss: 0.1337, validation loss: 0.1277
2024-05-24 23:33:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch81_loss0.1277122925966978.pypots
2024-05-24 23:33:10 [INFO]: Epoch 082 - training loss: 0.1443, validation loss: 0.1243
2024-05-24 23:33:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch82_loss0.12430513650178909.pypots
2024-05-24 23:33:12 [INFO]: Epoch 083 - training loss: 0.1482, validation loss: 0.1220
2024-05-24 23:33:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch83_loss0.12196003831923008.pypots
2024-05-24 23:33:14 [INFO]: Epoch 084 - training loss: 0.1333, validation loss: 0.1221
2024-05-24 23:33:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch84_loss0.12210616655647755.pypots
2024-05-24 23:33:16 [INFO]: Epoch 085 - training loss: 0.2067, validation loss: 0.1304
2024-05-24 23:33:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch85_loss0.13035673089325428.pypots
2024-05-24 23:33:18 [INFO]: Epoch 086 - training loss: 0.1930, validation loss: 0.1323
2024-05-24 23:33:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch86_loss0.1323267351835966.pypots
2024-05-24 23:33:20 [INFO]: Epoch 087 - training loss: 0.1740, validation loss: 0.1406
2024-05-24 23:33:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch87_loss0.14060531929135323.pypots
2024-05-24 23:33:22 [INFO]: Epoch 088 - training loss: 0.1628, validation loss: 0.1286
2024-05-24 23:33:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch88_loss0.12861169502139091.pypots
2024-05-24 23:33:24 [INFO]: Epoch 089 - training loss: 0.1586, validation loss: 0.1282
2024-05-24 23:33:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch89_loss0.12821872159838676.pypots
2024-05-24 23:33:26 [INFO]: Epoch 090 - training loss: 0.1315, validation loss: 0.1230
2024-05-24 23:33:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch90_loss0.1230146735906601.pypots
2024-05-24 23:33:28 [INFO]: Epoch 091 - training loss: 0.1459, validation loss: 0.1236
2024-05-24 23:33:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch91_loss0.12360533326864243.pypots
2024-05-24 23:33:31 [INFO]: Epoch 092 - training loss: 0.1482, validation loss: 0.1235
2024-05-24 23:33:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch92_loss0.1234857551753521.pypots
2024-05-24 23:33:33 [INFO]: Epoch 093 - training loss: 0.1495, validation loss: 0.1229
2024-05-24 23:33:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI_epoch93_loss0.1229004729539156.pypots
2024-05-24 23:33:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:33:33 [INFO]: Finished training. The best model is from epoch#83.
2024-05-24 23:33:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T233019/CSDI.pypots
2024-05-24 23:33:49 [INFO]: CSDI on ETTm1: MAE=0.1188, MSE=0.0571
2024-05-24 23:33:49 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/CSDI_ettm1/imputation.pkl
2024-05-24 23:33:49 [INFO]: Using the given device: cuda:0
2024-05-24 23:33:49 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/GPVAE_ettm1/20240524_T233349
2024-05-24 23:33:49 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/GPVAE_ettm1/20240524_T233349/tensorboard
2024-05-24 23:33:49 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 23:33:49 [INFO]: Epoch 001 - training loss: 23464.3772, validation loss: 0.9232
2024-05-24 23:33:49 [INFO]: Epoch 002 - training loss: 21187.5576, validation loss: 0.9169
2024-05-24 23:33:49 [INFO]: Epoch 003 - training loss: 18949.9708, validation loss: 0.8939
2024-05-24 23:33:49 [INFO]: Epoch 004 - training loss: 16967.9259, validation loss: 0.8521
2024-05-24 23:33:49 [INFO]: Epoch 005 - training loss: 14897.6265, validation loss: 0.7662
2024-05-24 23:33:49 [INFO]: Epoch 006 - training loss: 13637.5934, validation loss: 0.6474
2024-05-24 23:33:49 [INFO]: Epoch 007 - training loss: 12683.3109, validation loss: 0.5407
2024-05-24 23:33:50 [INFO]: Epoch 008 - training loss: 11853.6185, validation loss: 0.4895
2024-05-24 23:33:50 [INFO]: Epoch 009 - training loss: 11229.8658, validation loss: 0.4629
2024-05-24 23:33:50 [INFO]: Epoch 010 - training loss: 10835.5748, validation loss: 0.4436
2024-05-24 23:33:50 [INFO]: Epoch 011 - training loss: 10594.4105, validation loss: 0.4297
2024-05-24 23:33:50 [INFO]: Epoch 012 - training loss: 10381.3351, validation loss: 0.4005
2024-05-24 23:33:50 [INFO]: Epoch 013 - training loss: 10250.6450, validation loss: 0.3824
2024-05-24 23:33:50 [INFO]: Epoch 014 - training loss: 10168.7491, validation loss: 0.3564
2024-05-24 23:33:51 [INFO]: Epoch 015 - training loss: 9998.5779, validation loss: 0.3334
2024-05-24 23:33:51 [INFO]: Epoch 016 - training loss: 9933.5861, validation loss: 0.3162
2024-05-24 23:33:51 [INFO]: Epoch 017 - training loss: 9883.4019, validation loss: 0.3051
2024-05-24 23:33:51 [INFO]: Epoch 018 - training loss: 9790.5148, validation loss: 0.2859
2024-05-24 23:33:51 [INFO]: Epoch 019 - training loss: 9764.7120, validation loss: 0.2711
2024-05-24 23:33:51 [INFO]: Epoch 020 - training loss: 9720.7169, validation loss: 0.2555
2024-05-24 23:33:51 [INFO]: Epoch 021 - training loss: 9685.0549, validation loss: 0.2457
2024-05-24 23:33:51 [INFO]: Epoch 022 - training loss: 9654.3139, validation loss: 0.2382
2024-05-24 23:33:52 [INFO]: Epoch 023 - training loss: 9613.7927, validation loss: 0.2296
2024-05-24 23:33:52 [INFO]: Epoch 024 - training loss: 9585.4123, validation loss: 0.2212
2024-05-24 23:33:52 [INFO]: Epoch 025 - training loss: 9568.3416, validation loss: 0.2102
2024-05-24 23:33:52 [INFO]: Epoch 026 - training loss: 9596.2388, validation loss: 0.2038
2024-05-24 23:33:52 [INFO]: Epoch 027 - training loss: 9536.1096, validation loss: 0.2014
2024-05-24 23:33:52 [INFO]: Epoch 028 - training loss: 9512.5049, validation loss: 0.1951
2024-05-24 23:33:52 [INFO]: Epoch 029 - training loss: 9498.4926, validation loss: 0.1935
2024-05-24 23:33:52 [INFO]: Epoch 030 - training loss: 9490.2058, validation loss: 0.1899
2024-05-24 23:33:53 [INFO]: Epoch 031 - training loss: 9481.4680, validation loss: 0.1860
2024-05-24 23:33:53 [INFO]: Epoch 032 - training loss: 9475.7866, validation loss: 0.1816
2024-05-24 23:33:53 [INFO]: Epoch 033 - training loss: 9466.0178, validation loss: 0.1770
2024-05-24 23:33:53 [INFO]: Epoch 034 - training loss: 9479.2159, validation loss: 0.1732
2024-05-24 23:33:53 [INFO]: Epoch 035 - training loss: 9442.0892, validation loss: 0.1692
2024-05-24 23:33:53 [INFO]: Epoch 036 - training loss: 9436.8121, validation loss: 0.1656
2024-05-24 23:33:53 [INFO]: Epoch 037 - training loss: 9435.5340, validation loss: 0.1643
2024-05-24 23:33:53 [INFO]: Epoch 038 - training loss: 9430.5751, validation loss: 0.1598
2024-05-24 23:33:54 [INFO]: Epoch 039 - training loss: 9414.7437, validation loss: 0.1562
2024-05-24 23:33:54 [INFO]: Epoch 040 - training loss: 9422.7707, validation loss: 0.1524
2024-05-24 23:33:54 [INFO]: Epoch 041 - training loss: 9407.0720, validation loss: 0.1477
2024-05-24 23:33:54 [INFO]: Epoch 042 - training loss: 9409.4359, validation loss: 0.1442
2024-05-24 23:33:54 [INFO]: Epoch 043 - training loss: 9401.6444, validation loss: 0.1436
2024-05-24 23:33:54 [INFO]: Epoch 044 - training loss: 9399.4438, validation loss: 0.1409
2024-05-24 23:33:54 [INFO]: Epoch 045 - training loss: 9387.4479, validation loss: 0.1395
2024-05-24 23:33:55 [INFO]: Epoch 046 - training loss: 9384.3300, validation loss: 0.1389
2024-05-24 23:33:55 [INFO]: Epoch 047 - training loss: 9389.9122, validation loss: 0.1338
2024-05-24 23:33:55 [INFO]: Epoch 048 - training loss: 9377.3101, validation loss: 0.1315
2024-05-24 23:33:55 [INFO]: Epoch 049 - training loss: 9376.2453, validation loss: 0.1308
2024-05-24 23:33:55 [INFO]: Epoch 050 - training loss: 9374.5601, validation loss: 0.1315
2024-05-24 23:33:55 [INFO]: Epoch 051 - training loss: 9371.3351, validation loss: 0.1274
2024-05-24 23:33:55 [INFO]: Epoch 052 - training loss: 9369.0968, validation loss: 0.1251
2024-05-24 23:33:55 [INFO]: Epoch 053 - training loss: 9364.6400, validation loss: 0.1252
2024-05-24 23:33:56 [INFO]: Epoch 054 - training loss: 9363.5874, validation loss: 0.1236
2024-05-24 23:33:56 [INFO]: Epoch 055 - training loss: 9363.0670, validation loss: 0.1237
2024-05-24 23:33:56 [INFO]: Epoch 056 - training loss: 9361.3605, validation loss: 0.1214
2024-05-24 23:33:56 [INFO]: Epoch 057 - training loss: 9360.7386, validation loss: 0.1192
2024-05-24 23:33:56 [INFO]: Epoch 058 - training loss: 9356.8474, validation loss: 0.1181
2024-05-24 23:33:56 [INFO]: Epoch 059 - training loss: 9354.6241, validation loss: 0.1187
2024-05-24 23:33:56 [INFO]: Epoch 060 - training loss: 9358.3184, validation loss: 0.1164
2024-05-24 23:33:56 [INFO]: Epoch 061 - training loss: 9354.0691, validation loss: 0.1186
2024-05-24 23:33:57 [INFO]: Epoch 062 - training loss: 9353.0481, validation loss: 0.1150
2024-05-24 23:33:57 [INFO]: Epoch 063 - training loss: 9349.5388, validation loss: 0.1136
2024-05-24 23:33:57 [INFO]: Epoch 064 - training loss: 9348.9031, validation loss: 0.1140
2024-05-24 23:33:57 [INFO]: Epoch 065 - training loss: 9348.0435, validation loss: 0.1132
2024-05-24 23:33:57 [INFO]: Epoch 066 - training loss: 9346.2057, validation loss: 0.1110
2024-05-24 23:33:57 [INFO]: Epoch 067 - training loss: 9344.0599, validation loss: 0.1116
2024-05-24 23:33:57 [INFO]: Epoch 068 - training loss: 9344.6779, validation loss: 0.1096
2024-05-24 23:33:58 [INFO]: Epoch 069 - training loss: 9342.7488, validation loss: 0.1115
2024-05-24 23:33:58 [INFO]: Epoch 070 - training loss: 9351.6543, validation loss: 0.1084
2024-05-24 23:33:58 [INFO]: Epoch 071 - training loss: 9339.4969, validation loss: 0.1087
2024-05-24 23:33:58 [INFO]: Epoch 072 - training loss: 9341.9606, validation loss: 0.1076
2024-05-24 23:33:58 [INFO]: Epoch 073 - training loss: 9338.5484, validation loss: 0.1055
2024-05-24 23:33:58 [INFO]: Epoch 074 - training loss: 9342.1755, validation loss: 0.1057
2024-05-24 23:33:58 [INFO]: Epoch 075 - training loss: 9335.8290, validation loss: 0.1063
2024-05-24 23:33:58 [INFO]: Epoch 076 - training loss: 9336.0125, validation loss: 0.1032
2024-05-24 23:33:59 [INFO]: Epoch 077 - training loss: 9335.2339, validation loss: 0.1033
2024-05-24 23:33:59 [INFO]: Epoch 078 - training loss: 9332.6554, validation loss: 0.1037
2024-05-24 23:33:59 [INFO]: Epoch 079 - training loss: 9335.0609, validation loss: 0.1022
2024-05-24 23:33:59 [INFO]: Epoch 080 - training loss: 9335.0095, validation loss: 0.1018
2024-05-24 23:33:59 [INFO]: Epoch 081 - training loss: 9331.6241, validation loss: 0.1009
2024-05-24 23:33:59 [INFO]: Epoch 082 - training loss: 9330.4990, validation loss: 0.1008
2024-05-24 23:33:59 [INFO]: Epoch 083 - training loss: 9331.7122, validation loss: 0.0999
2024-05-24 23:33:59 [INFO]: Epoch 084 - training loss: 9331.4742, validation loss: 0.0986
2024-05-24 23:34:00 [INFO]: Epoch 085 - training loss: 9330.4130, validation loss: 0.0986
2024-05-24 23:34:00 [INFO]: Epoch 086 - training loss: 9327.3076, validation loss: 0.0988
2024-05-24 23:34:00 [INFO]: Epoch 087 - training loss: 9328.4920, validation loss: 0.0969
2024-05-24 23:34:00 [INFO]: Epoch 088 - training loss: 9329.4014, validation loss: 0.0972
2024-05-24 23:34:00 [INFO]: Epoch 089 - training loss: 9327.1366, validation loss: 0.1039
2024-05-24 23:34:00 [INFO]: Epoch 090 - training loss: 9325.5779, validation loss: 0.0953
2024-05-24 23:34:00 [INFO]: Epoch 091 - training loss: 9328.1278, validation loss: 0.0959
2024-05-24 23:34:01 [INFO]: Epoch 092 - training loss: 9325.2595, validation loss: 0.0962
2024-05-24 23:34:01 [INFO]: Epoch 093 - training loss: 9325.5243, validation loss: 0.0950
2024-05-24 23:34:01 [INFO]: Epoch 094 - training loss: 9323.6134, validation loss: 0.0949
2024-05-24 23:34:01 [INFO]: Epoch 095 - training loss: 9327.0076, validation loss: 0.0935
2024-05-24 23:34:01 [INFO]: Epoch 096 - training loss: 9322.7726, validation loss: 0.0928
2024-05-24 23:34:01 [INFO]: Epoch 097 - training loss: 9324.0814, validation loss: 0.0927
2024-05-24 23:34:01 [INFO]: Epoch 098 - training loss: 9324.4241, validation loss: 0.0913
2024-05-24 23:34:01 [INFO]: Epoch 099 - training loss: 9322.2122, validation loss: 0.0931
2024-05-24 23:34:02 [INFO]: Epoch 100 - training loss: 9324.5616, validation loss: 0.0902
2024-05-24 23:34:02 [INFO]: Epoch 101 - training loss: 9320.9316, validation loss: 0.0905
2024-05-24 23:34:02 [INFO]: Epoch 102 - training loss: 9320.8904, validation loss: 0.0910
2024-05-24 23:34:02 [INFO]: Epoch 103 - training loss: 9319.9860, validation loss: 0.0912
2024-05-24 23:34:02 [INFO]: Epoch 104 - training loss: 9319.7078, validation loss: 0.0903
2024-05-24 23:34:02 [INFO]: Epoch 105 - training loss: 9321.7941, validation loss: 0.0902
2024-05-24 23:34:02 [INFO]: Epoch 106 - training loss: 9319.2163, validation loss: 0.0893
2024-05-24 23:34:02 [INFO]: Epoch 107 - training loss: 9318.6375, validation loss: 0.0875
2024-05-24 23:34:03 [INFO]: Epoch 108 - training loss: 9317.5703, validation loss: 0.0880
2024-05-24 23:34:03 [INFO]: Epoch 109 - training loss: 9320.4839, validation loss: 0.0869
2024-05-24 23:34:03 [INFO]: Epoch 110 - training loss: 9321.3160, validation loss: 0.0868
2024-05-24 23:34:03 [INFO]: Epoch 111 - training loss: 9317.5134, validation loss: 0.0857
2024-05-24 23:34:03 [INFO]: Epoch 112 - training loss: 9316.6952, validation loss: 0.0872
2024-05-24 23:34:03 [INFO]: Epoch 113 - training loss: 9317.3514, validation loss: 0.0856
2024-05-24 23:34:03 [INFO]: Epoch 114 - training loss: 9315.4452, validation loss: 0.0861
2024-05-24 23:34:03 [INFO]: Epoch 115 - training loss: 9315.5754, validation loss: 0.0854
2024-05-24 23:34:04 [INFO]: Epoch 116 - training loss: 9315.1713, validation loss: 0.0845
2024-05-24 23:34:04 [INFO]: Epoch 117 - training loss: 9315.1646, validation loss: 0.0852
2024-05-24 23:34:04 [INFO]: Epoch 118 - training loss: 9315.9713, validation loss: 0.0847
2024-05-24 23:34:04 [INFO]: Epoch 119 - training loss: 9316.6553, validation loss: 0.0843
2024-05-24 23:34:04 [INFO]: Epoch 120 - training loss: 9315.9788, validation loss: 0.0848
2024-05-24 23:34:04 [INFO]: Epoch 121 - training loss: 9315.5067, validation loss: 0.0828
2024-05-24 23:34:04 [INFO]: Epoch 122 - training loss: 9315.2981, validation loss: 0.0831
2024-05-24 23:34:05 [INFO]: Epoch 123 - training loss: 9312.7939, validation loss: 0.0825
2024-05-24 23:34:05 [INFO]: Epoch 124 - training loss: 9314.5020, validation loss: 0.0827
2024-05-24 23:34:05 [INFO]: Epoch 125 - training loss: 9314.6995, validation loss: 0.0820
2024-05-24 23:34:05 [INFO]: Epoch 126 - training loss: 9314.3101, validation loss: 0.0828
2024-05-24 23:34:05 [INFO]: Epoch 127 - training loss: 9313.7797, validation loss: 0.0812
2024-05-24 23:34:05 [INFO]: Epoch 128 - training loss: 9314.5046, validation loss: 0.0800
2024-05-24 23:34:05 [INFO]: Epoch 129 - training loss: 9312.8795, validation loss: 0.0822
2024-05-24 23:34:05 [INFO]: Epoch 130 - training loss: 9313.4464, validation loss: 0.0813
2024-05-24 23:34:06 [INFO]: Epoch 131 - training loss: 9311.7346, validation loss: 0.0809
2024-05-24 23:34:06 [INFO]: Epoch 132 - training loss: 9311.6672, validation loss: 0.0795
2024-05-24 23:34:06 [INFO]: Epoch 133 - training loss: 9310.4492, validation loss: 0.0809
2024-05-24 23:34:06 [INFO]: Epoch 134 - training loss: 9311.2475, validation loss: 0.0803
2024-05-24 23:34:06 [INFO]: Epoch 135 - training loss: 9311.6776, validation loss: 0.0798
2024-05-24 23:34:06 [INFO]: Epoch 136 - training loss: 9311.9760, validation loss: 0.0798
2024-05-24 23:34:06 [INFO]: Epoch 137 - training loss: 9310.8268, validation loss: 0.0794
2024-05-24 23:34:06 [INFO]: Epoch 138 - training loss: 9310.5635, validation loss: 0.0782
2024-05-24 23:34:07 [INFO]: Epoch 139 - training loss: 9314.5744, validation loss: 0.0800
2024-05-24 23:34:07 [INFO]: Epoch 140 - training loss: 9309.7001, validation loss: 0.0789
2024-05-24 23:34:07 [INFO]: Epoch 141 - training loss: 9310.1790, validation loss: 0.0785
2024-05-24 23:34:07 [INFO]: Epoch 142 - training loss: 9310.5681, validation loss: 0.0784
2024-05-24 23:34:07 [INFO]: Epoch 143 - training loss: 9311.1437, validation loss: 0.0783
2024-05-24 23:34:07 [INFO]: Epoch 144 - training loss: 9309.7048, validation loss: 0.0788
2024-05-24 23:34:07 [INFO]: Epoch 145 - training loss: 9312.1274, validation loss: 0.0782
2024-05-24 23:34:07 [INFO]: Epoch 146 - training loss: 9309.3506, validation loss: 0.0762
2024-05-24 23:34:08 [INFO]: Epoch 147 - training loss: 9309.5270, validation loss: 0.0768
2024-05-24 23:34:08 [INFO]: Epoch 148 - training loss: 9309.3455, validation loss: 0.0774
2024-05-24 23:34:08 [INFO]: Epoch 149 - training loss: 9308.4542, validation loss: 0.0767
2024-05-24 23:34:08 [INFO]: Epoch 150 - training loss: 9307.8975, validation loss: 0.0767
2024-05-24 23:34:08 [INFO]: Epoch 151 - training loss: 9307.3380, validation loss: 0.0765
2024-05-24 23:34:08 [INFO]: Epoch 152 - training loss: 9308.0888, validation loss: 0.0767
2024-05-24 23:34:08 [INFO]: Epoch 153 - training loss: 9307.9622, validation loss: 0.0764
2024-05-24 23:34:09 [INFO]: Epoch 154 - training loss: 9309.1063, validation loss: 0.0761
2024-05-24 23:34:09 [INFO]: Epoch 155 - training loss: 9309.8982, validation loss: 0.0772
2024-05-24 23:34:09 [INFO]: Epoch 156 - training loss: 9307.7103, validation loss: 0.0772
2024-05-24 23:34:09 [INFO]: Epoch 157 - training loss: 9309.8900, validation loss: 0.0760
2024-05-24 23:34:09 [INFO]: Epoch 158 - training loss: 9308.4230, validation loss: 0.0758
2024-05-24 23:34:09 [INFO]: Epoch 159 - training loss: 9308.4876, validation loss: 0.0769
2024-05-24 23:34:09 [INFO]: Epoch 160 - training loss: 9308.8076, validation loss: 0.0737
2024-05-24 23:34:09 [INFO]: Epoch 161 - training loss: 9308.1628, validation loss: 0.0752
2024-05-24 23:34:10 [INFO]: Epoch 162 - training loss: 9308.0080, validation loss: 0.0746
2024-05-24 23:34:10 [INFO]: Epoch 163 - training loss: 9306.2154, validation loss: 0.0757
2024-05-24 23:34:10 [INFO]: Epoch 164 - training loss: 9307.3754, validation loss: 0.0745
2024-05-24 23:34:10 [INFO]: Epoch 165 - training loss: 9306.7418, validation loss: 0.0743
2024-05-24 23:34:10 [INFO]: Epoch 166 - training loss: 9306.6548, validation loss: 0.0748
2024-05-24 23:34:10 [INFO]: Epoch 167 - training loss: 9307.0116, validation loss: 0.0746
2024-05-24 23:34:10 [INFO]: Epoch 168 - training loss: 9306.3105, validation loss: 0.0764
2024-05-24 23:34:10 [INFO]: Epoch 169 - training loss: 9305.5414, validation loss: 0.0724
2024-05-24 23:34:11 [INFO]: Epoch 170 - training loss: 9306.2173, validation loss: 0.0740
2024-05-24 23:34:11 [INFO]: Epoch 171 - training loss: 9306.9678, validation loss: 0.0747
2024-05-24 23:34:11 [INFO]: Epoch 172 - training loss: 9306.3788, validation loss: 0.0723
2024-05-24 23:34:11 [INFO]: Epoch 173 - training loss: 9305.7339, validation loss: 0.0737
2024-05-24 23:34:11 [INFO]: Epoch 174 - training loss: 9305.1716, validation loss: 0.0729
2024-05-24 23:34:11 [INFO]: Epoch 175 - training loss: 9306.3177, validation loss: 0.0736
2024-05-24 23:34:11 [INFO]: Epoch 176 - training loss: 9305.1509, validation loss: 0.0732
2024-05-24 23:34:12 [INFO]: Epoch 177 - training loss: 9306.3692, validation loss: 0.0724
2024-05-24 23:34:12 [INFO]: Epoch 178 - training loss: 9306.8278, validation loss: 0.0733
2024-05-24 23:34:12 [INFO]: Epoch 179 - training loss: 9305.1769, validation loss: 0.0724
2024-05-24 23:34:12 [INFO]: Epoch 180 - training loss: 9306.4936, validation loss: 0.0728
2024-05-24 23:34:12 [INFO]: Epoch 181 - training loss: 9305.3522, validation loss: 0.0714
2024-05-24 23:34:12 [INFO]: Epoch 182 - training loss: 9305.2928, validation loss: 0.0712
2024-05-24 23:34:12 [INFO]: Epoch 183 - training loss: 9304.1807, validation loss: 0.0723
2024-05-24 23:34:12 [INFO]: Epoch 184 - training loss: 9304.7756, validation loss: 0.0735
2024-05-24 23:34:13 [INFO]: Epoch 185 - training loss: 9304.7419, validation loss: 0.0733
2024-05-24 23:34:13 [INFO]: Epoch 186 - training loss: 9304.9554, validation loss: 0.0704
2024-05-24 23:34:13 [INFO]: Epoch 187 - training loss: 9305.4655, validation loss: 0.0716
2024-05-24 23:34:13 [INFO]: Epoch 188 - training loss: 9304.2430, validation loss: 0.0722
2024-05-24 23:34:13 [INFO]: Epoch 189 - training loss: 9304.1125, validation loss: 0.0718
2024-05-24 23:34:13 [INFO]: Epoch 190 - training loss: 9305.1706, validation loss: 0.0719
2024-05-24 23:34:13 [INFO]: Epoch 191 - training loss: 9303.9898, validation loss: 0.0711
2024-05-24 23:34:13 [INFO]: Epoch 192 - training loss: 9304.4118, validation loss: 0.0713
2024-05-24 23:34:14 [INFO]: Epoch 193 - training loss: 9304.9658, validation loss: 0.0706
2024-05-24 23:34:14 [INFO]: Epoch 194 - training loss: 9305.6829, validation loss: 0.0692
2024-05-24 23:34:14 [INFO]: Epoch 195 - training loss: 9305.2006, validation loss: 0.0739
2024-05-24 23:34:14 [INFO]: Epoch 196 - training loss: 9303.5998, validation loss: 0.0706
2024-05-24 23:34:14 [INFO]: Epoch 197 - training loss: 9305.3732, validation loss: 0.0703
2024-05-24 23:34:14 [INFO]: Epoch 198 - training loss: 9303.8489, validation loss: 0.0711
2024-05-24 23:34:14 [INFO]: Epoch 199 - training loss: 9302.5823, validation loss: 0.0716
2024-05-24 23:34:14 [INFO]: Epoch 200 - training loss: 9302.9803, validation loss: 0.0709
2024-05-24 23:34:15 [INFO]: Epoch 201 - training loss: 9304.1511, validation loss: 0.0702
2024-05-24 23:34:15 [INFO]: Epoch 202 - training loss: 9304.1863, validation loss: 0.0724
2024-05-24 23:34:15 [INFO]: Epoch 203 - training loss: 9304.2103, validation loss: 0.0708
2024-05-24 23:34:15 [INFO]: Epoch 204 - training loss: 9305.1774, validation loss: 0.0696
2024-05-24 23:34:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:34:15 [INFO]: Finished training. The best model is from epoch#194.
2024-05-24 23:34:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/GPVAE_ettm1/20240524_T233349/GPVAE.pypots
2024-05-24 23:34:15 [INFO]: GP-VAE on ETTm1: MAE=0.2699, MSE=0.1543
2024-05-24 23:34:15 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/GPVAE_ettm1/imputation.pkl
2024-05-24 23:34:15 [INFO]: Using the given device: cuda:0
2024-05-24 23:34:15 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/USGAN_ettm1/20240524_T233415
2024-05-24 23:34:15 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/USGAN_ettm1/20240524_T233415/tensorboard
2024-05-24 23:34:15 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 23:34:26 [INFO]: Epoch 001 - generator training loss: 0.5950, discriminator training loss: 0.3437, validation loss: 0.3403
2024-05-24 23:34:35 [INFO]: Epoch 002 - generator training loss: 0.0508, discriminator training loss: 0.2091, validation loss: 0.1002
2024-05-24 23:34:44 [INFO]: Epoch 003 - generator training loss: -0.0594, discriminator training loss: 0.1983, validation loss: 0.0579
2024-05-24 23:34:53 [INFO]: Epoch 004 - generator training loss: -0.0802, discriminator training loss: 0.1949, validation loss: 0.0495
2024-05-24 23:35:02 [INFO]: Epoch 005 - generator training loss: -0.0841, discriminator training loss: 0.1906, validation loss: 0.0416
2024-05-24 23:35:11 [INFO]: Epoch 006 - generator training loss: -0.0837, discriminator training loss: 0.1844, validation loss: 0.0395
2024-05-24 23:35:20 [INFO]: Epoch 007 - generator training loss: -0.0793, discriminator training loss: 0.1761, validation loss: 0.0376
2024-05-24 23:35:29 [INFO]: Epoch 008 - generator training loss: -0.0708, discriminator training loss: 0.1659, validation loss: 0.0363
2024-05-24 23:35:38 [INFO]: Epoch 009 - generator training loss: -0.0563, discriminator training loss: 0.1505, validation loss: 0.0356
2024-05-24 23:35:47 [INFO]: Epoch 010 - generator training loss: -0.0439, discriminator training loss: 0.1376, validation loss: 0.0359
2024-05-24 23:35:56 [INFO]: Epoch 011 - generator training loss: -0.0347, discriminator training loss: 0.1210, validation loss: 0.0353
2024-05-24 23:36:05 [INFO]: Epoch 012 - generator training loss: -0.0277, discriminator training loss: 0.1096, validation loss: 0.0329
2024-05-24 23:36:14 [INFO]: Epoch 013 - generator training loss: -0.0214, discriminator training loss: 0.1017, validation loss: 0.0331
2024-05-24 23:36:23 [INFO]: Epoch 014 - generator training loss: -0.0193, discriminator training loss: 0.0940, validation loss: 0.0325
2024-05-24 23:36:31 [INFO]: Epoch 015 - generator training loss: -0.0147, discriminator training loss: 0.0894, validation loss: 0.0316
2024-05-24 23:36:40 [INFO]: Epoch 016 - generator training loss: -0.0157, discriminator training loss: 0.0856, validation loss: 0.0315
2024-05-24 23:36:49 [INFO]: Epoch 017 - generator training loss: -0.0157, discriminator training loss: 0.0841, validation loss: 0.0309
2024-05-24 23:36:58 [INFO]: Epoch 018 - generator training loss: -0.0162, discriminator training loss: 0.0840, validation loss: 0.0305
2024-05-24 23:37:07 [INFO]: Epoch 019 - generator training loss: -0.0150, discriminator training loss: 0.0816, validation loss: 0.0301
2024-05-24 23:37:16 [INFO]: Epoch 020 - generator training loss: -0.0131, discriminator training loss: 0.0810, validation loss: 0.0301
2024-05-24 23:37:25 [INFO]: Epoch 021 - generator training loss: -0.0149, discriminator training loss: 0.0805, validation loss: 0.0300
2024-05-24 23:37:34 [INFO]: Epoch 022 - generator training loss: -0.0151, discriminator training loss: 0.0789, validation loss: 0.0299
2024-05-24 23:37:43 [INFO]: Epoch 023 - generator training loss: -0.0164, discriminator training loss: 0.0766, validation loss: 0.0289
2024-05-24 23:37:52 [INFO]: Epoch 024 - generator training loss: -0.0151, discriminator training loss: 0.0782, validation loss: 0.0288
2024-05-24 23:38:01 [INFO]: Epoch 025 - generator training loss: -0.0170, discriminator training loss: 0.0785, validation loss: 0.0285
2024-05-24 23:38:10 [INFO]: Epoch 026 - generator training loss: -0.0164, discriminator training loss: 0.0784, validation loss: 0.0279
2024-05-24 23:38:19 [INFO]: Epoch 027 - generator training loss: -0.0150, discriminator training loss: 0.0747, validation loss: 0.0281
2024-05-24 23:38:28 [INFO]: Epoch 028 - generator training loss: -0.0168, discriminator training loss: 0.0749, validation loss: 0.0276
2024-05-24 23:38:36 [INFO]: Epoch 029 - generator training loss: -0.0161, discriminator training loss: 0.0749, validation loss: 0.0278
2024-05-24 23:38:45 [INFO]: Epoch 030 - generator training loss: -0.0153, discriminator training loss: 0.0738, validation loss: 0.0271
2024-05-24 23:38:54 [INFO]: Epoch 031 - generator training loss: -0.0158, discriminator training loss: 0.0752, validation loss: 0.0270
2024-05-24 23:39:03 [INFO]: Epoch 032 - generator training loss: -0.0141, discriminator training loss: 0.0718, validation loss: 0.0271
2024-05-24 23:39:12 [INFO]: Epoch 033 - generator training loss: -0.0187, discriminator training loss: 0.0744, validation loss: 0.0266
2024-05-24 23:39:21 [INFO]: Epoch 034 - generator training loss: -0.0160, discriminator training loss: 0.0718, validation loss: 0.0264
2024-05-24 23:39:30 [INFO]: Epoch 035 - generator training loss: -0.0180, discriminator training loss: 0.0721, validation loss: 0.0265
2024-05-24 23:39:38 [INFO]: Epoch 036 - generator training loss: -0.0160, discriminator training loss: 0.0713, validation loss: 0.0260
2024-05-24 23:39:48 [INFO]: Epoch 037 - generator training loss: -0.0186, discriminator training loss: 0.0728, validation loss: 0.0265
2024-05-24 23:39:57 [INFO]: Epoch 038 - generator training loss: -0.0166, discriminator training loss: 0.0713, validation loss: 0.0261
2024-05-24 23:40:06 [INFO]: Epoch 039 - generator training loss: -0.0173, discriminator training loss: 0.0710, validation loss: 0.0259
2024-05-24 23:40:15 [INFO]: Epoch 040 - generator training loss: -0.0177, discriminator training loss: 0.0729, validation loss: 0.0258
2024-05-24 23:40:24 [INFO]: Epoch 041 - generator training loss: -0.0185, discriminator training loss: 0.0704, validation loss: 0.0260
2024-05-24 23:40:33 [INFO]: Epoch 042 - generator training loss: -0.0173, discriminator training loss: 0.0689, validation loss: 0.0257
2024-05-24 23:40:42 [INFO]: Epoch 043 - generator training loss: -0.0191, discriminator training loss: 0.0697, validation loss: 0.0254
2024-05-24 23:40:51 [INFO]: Epoch 044 - generator training loss: -0.0177, discriminator training loss: 0.0689, validation loss: 0.0252
2024-05-24 23:41:00 [INFO]: Epoch 045 - generator training loss: -0.0181, discriminator training loss: 0.0719, validation loss: 0.0261
2024-05-24 23:41:09 [INFO]: Epoch 046 - generator training loss: -0.0158, discriminator training loss: 0.0687, validation loss: 0.0266
2024-05-24 23:41:18 [INFO]: Epoch 047 - generator training loss: -0.0176, discriminator training loss: 0.0723, validation loss: 0.0262
2024-05-24 23:41:27 [INFO]: Epoch 048 - generator training loss: -0.0190, discriminator training loss: 0.0693, validation loss: 0.0252
2024-05-24 23:41:37 [INFO]: Epoch 049 - generator training loss: -0.0199, discriminator training loss: 0.0707, validation loss: 0.0255
2024-05-24 23:41:46 [INFO]: Epoch 050 - generator training loss: -0.0198, discriminator training loss: 0.0715, validation loss: 0.0275
2024-05-24 23:41:55 [INFO]: Epoch 051 - generator training loss: -0.0174, discriminator training loss: 0.0743, validation loss: 0.0248
2024-05-24 23:42:04 [INFO]: Epoch 052 - generator training loss: -0.0191, discriminator training loss: 0.0693, validation loss: 0.0260
2024-05-24 23:42:13 [INFO]: Epoch 053 - generator training loss: -0.0161, discriminator training loss: 0.0709, validation loss: 0.0249
2024-05-24 23:42:22 [INFO]: Epoch 054 - generator training loss: -0.0187, discriminator training loss: 0.0700, validation loss: 0.0254
2024-05-24 23:42:30 [INFO]: Epoch 055 - generator training loss: -0.0175, discriminator training loss: 0.0683, validation loss: 0.0247
2024-05-24 23:42:40 [INFO]: Epoch 056 - generator training loss: -0.0197, discriminator training loss: 0.0708, validation loss: 0.0253
2024-05-24 23:42:49 [INFO]: Epoch 057 - generator training loss: -0.0185, discriminator training loss: 0.0681, validation loss: 0.0254
2024-05-24 23:42:58 [INFO]: Epoch 058 - generator training loss: -0.0191, discriminator training loss: 0.0688, validation loss: 0.0248
2024-05-24 23:43:07 [INFO]: Epoch 059 - generator training loss: -0.0223, discriminator training loss: 0.0668, validation loss: 0.0251
2024-05-24 23:43:16 [INFO]: Epoch 060 - generator training loss: -0.0170, discriminator training loss: 0.0678, validation loss: 0.0249
2024-05-24 23:43:25 [INFO]: Epoch 061 - generator training loss: -0.0183, discriminator training loss: 0.0682, validation loss: 0.0241
2024-05-24 23:43:34 [INFO]: Epoch 062 - generator training loss: -0.0202, discriminator training loss: 0.0686, validation loss: 0.0257
2024-05-24 23:43:43 [INFO]: Epoch 063 - generator training loss: -0.0177, discriminator training loss: 0.0683, validation loss: 0.0251
2024-05-24 23:43:52 [INFO]: Epoch 064 - generator training loss: -0.0208, discriminator training loss: 0.0668, validation loss: 0.0244
2024-05-24 23:44:01 [INFO]: Epoch 065 - generator training loss: -0.0203, discriminator training loss: 0.0688, validation loss: 0.0255
2024-05-24 23:44:10 [INFO]: Epoch 066 - generator training loss: -0.0211, discriminator training loss: 0.0695, validation loss: 0.0243
2024-05-24 23:44:19 [INFO]: Epoch 067 - generator training loss: -0.0214, discriminator training loss: 0.0676, validation loss: 0.0258
2024-05-24 23:44:28 [INFO]: Epoch 068 - generator training loss: -0.0188, discriminator training loss: 0.0687, validation loss: 0.0247
2024-05-24 23:44:37 [INFO]: Epoch 069 - generator training loss: -0.0201, discriminator training loss: 0.0681, validation loss: 0.0251
2024-05-24 23:44:46 [INFO]: Epoch 070 - generator training loss: -0.0203, discriminator training loss: 0.0651, validation loss: 0.0256
2024-05-24 23:44:55 [INFO]: Epoch 071 - generator training loss: -0.0197, discriminator training loss: 0.0682, validation loss: 0.0242
2024-05-24 23:44:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:44:55 [INFO]: Finished training. The best model is from epoch#61.
2024-05-24 23:44:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/USGAN_ettm1/20240524_T233415/USGAN.pypots
2024-05-24 23:44:56 [INFO]: US-GAN on ETTm1: MAE=0.1392, MSE=0.0478
2024-05-24 23:44:56 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/USGAN_ettm1/imputation.pkl
2024-05-24 23:44:56 [INFO]: Using the given device: cuda:0
2024-05-24 23:44:56 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/BRITS_ettm1/20240524_T234456
2024-05-24 23:44:56 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/BRITS_ettm1/20240524_T234456/tensorboard
2024-05-24 23:44:56 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 23:45:04 [INFO]: Epoch 001 - training loss: 1.2963, validation loss: 0.2791
2024-05-24 23:45:10 [INFO]: Epoch 002 - training loss: 0.8338, validation loss: 0.0771
2024-05-24 23:45:16 [INFO]: Epoch 003 - training loss: 0.6792, validation loss: 0.0530
2024-05-24 23:45:22 [INFO]: Epoch 004 - training loss: 0.6107, validation loss: 0.0448
2024-05-24 23:45:28 [INFO]: Epoch 005 - training loss: 0.5705, validation loss: 0.0383
2024-05-24 23:45:34 [INFO]: Epoch 006 - training loss: 0.5254, validation loss: 0.0366
2024-05-24 23:45:40 [INFO]: Epoch 007 - training loss: 0.5073, validation loss: 0.0333
2024-05-24 23:45:46 [INFO]: Epoch 008 - training loss: 0.4818, validation loss: 0.0317
2024-05-24 23:45:52 [INFO]: Epoch 009 - training loss: 0.4590, validation loss: 0.0301
2024-05-24 23:45:58 [INFO]: Epoch 010 - training loss: 0.4502, validation loss: 0.0291
2024-05-24 23:46:04 [INFO]: Epoch 011 - training loss: 0.4403, validation loss: 0.0275
2024-05-24 23:46:10 [INFO]: Epoch 012 - training loss: 0.4342, validation loss: 0.0267
2024-05-24 23:46:16 [INFO]: Epoch 013 - training loss: 0.4111, validation loss: 0.0255
2024-05-24 23:46:22 [INFO]: Epoch 014 - training loss: 0.4206, validation loss: 0.0255
2024-05-24 23:46:28 [INFO]: Epoch 015 - training loss: 0.4029, validation loss: 0.0256
2024-05-24 23:46:34 [INFO]: Epoch 016 - training loss: 0.3995, validation loss: 0.0242
2024-05-24 23:46:40 [INFO]: Epoch 017 - training loss: 0.3975, validation loss: 0.0248
2024-05-24 23:46:46 [INFO]: Epoch 018 - training loss: 0.3881, validation loss: 0.0236
2024-05-24 23:46:52 [INFO]: Epoch 019 - training loss: 0.3851, validation loss: 0.0233
2024-05-24 23:46:58 [INFO]: Epoch 020 - training loss: 0.3862, validation loss: 0.0232
2024-05-24 23:47:04 [INFO]: Epoch 021 - training loss: 0.3874, validation loss: 0.0228
2024-05-24 23:47:10 [INFO]: Epoch 022 - training loss: 0.3941, validation loss: 0.0230
2024-05-24 23:47:16 [INFO]: Epoch 023 - training loss: 0.3799, validation loss: 0.0228
2024-05-24 23:47:22 [INFO]: Epoch 024 - training loss: 0.3782, validation loss: 0.0228
2024-05-24 23:47:28 [INFO]: Epoch 025 - training loss: 0.3852, validation loss: 0.0228
2024-05-24 23:47:34 [INFO]: Epoch 026 - training loss: 0.3822, validation loss: 0.0225
2024-05-24 23:47:40 [INFO]: Epoch 027 - training loss: 0.3796, validation loss: 0.0229
2024-05-24 23:47:46 [INFO]: Epoch 028 - training loss: 0.3759, validation loss: 0.0226
2024-05-24 23:47:52 [INFO]: Epoch 029 - training loss: 0.3743, validation loss: 0.0227
2024-05-24 23:47:58 [INFO]: Epoch 030 - training loss: 0.3759, validation loss: 0.0226
2024-05-24 23:48:04 [INFO]: Epoch 031 - training loss: 0.3831, validation loss: 0.0227
2024-05-24 23:48:10 [INFO]: Epoch 032 - training loss: 0.3768, validation loss: 0.0226
2024-05-24 23:48:16 [INFO]: Epoch 033 - training loss: 0.3690, validation loss: 0.0231
2024-05-24 23:48:22 [INFO]: Epoch 034 - training loss: 0.4164, validation loss: 0.0244
2024-05-24 23:48:28 [INFO]: Epoch 035 - training loss: 0.3889, validation loss: 0.0241
2024-05-24 23:48:34 [INFO]: Epoch 036 - training loss: 0.3834, validation loss: 0.0232
2024-05-24 23:48:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:48:34 [INFO]: Finished training. The best model is from epoch#26.
2024-05-24 23:48:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/BRITS_ettm1/20240524_T234456/BRITS.pypots
2024-05-24 23:48:35 [INFO]: BRITS on ETTm1: MAE=0.1347, MSE=0.0524
2024-05-24 23:48:35 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/BRITS_ettm1/imputation.pkl
2024-05-24 23:48:35 [INFO]: Using the given device: cuda:0
2024-05-24 23:48:35 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835
2024-05-24 23:48:35 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/tensorboard
2024-05-24 23:48:35 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 23:48:37 [INFO]: Epoch 001 - training loss: 1.3837, validation loss: 1.2181
2024-05-24 23:48:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch1_loss1.2180504202842712.pypots
2024-05-24 23:48:37 [INFO]: Epoch 002 - training loss: 1.0691, validation loss: 1.1020
2024-05-24 23:48:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch2_loss1.1019666641950607.pypots
2024-05-24 23:48:38 [INFO]: Epoch 003 - training loss: 1.0021, validation loss: 1.0393
2024-05-24 23:48:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch3_loss1.0393013805150986.pypots
2024-05-24 23:48:38 [INFO]: Epoch 004 - training loss: 0.9503, validation loss: 1.0208
2024-05-24 23:48:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch4_loss1.0208163559436798.pypots
2024-05-24 23:48:38 [INFO]: Epoch 005 - training loss: 0.9536, validation loss: 1.0149
2024-05-24 23:48:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch5_loss1.0149118453264236.pypots
2024-05-24 23:48:38 [INFO]: Epoch 006 - training loss: 0.9189, validation loss: 1.0089
2024-05-24 23:48:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch6_loss1.0088761746883392.pypots
2024-05-24 23:48:38 [INFO]: Epoch 007 - training loss: 0.9425, validation loss: 0.9993
2024-05-24 23:48:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch7_loss0.9992529302835464.pypots
2024-05-24 23:48:38 [INFO]: Epoch 008 - training loss: 0.9346, validation loss: 0.9953
2024-05-24 23:48:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch8_loss0.9952709078788757.pypots
2024-05-24 23:48:39 [INFO]: Epoch 009 - training loss: 0.9581, validation loss: 0.9923
2024-05-24 23:48:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch9_loss0.9922667890787125.pypots
2024-05-24 23:48:39 [INFO]: Epoch 010 - training loss: 0.9180, validation loss: 0.9852
2024-05-24 23:48:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch10_loss0.9851785004138947.pypots
2024-05-24 23:48:39 [INFO]: Epoch 011 - training loss: 0.9106, validation loss: 0.9765
2024-05-24 23:48:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch11_loss0.9764887541532516.pypots
2024-05-24 23:48:39 [INFO]: Epoch 012 - training loss: 0.8944, validation loss: 0.9676
2024-05-24 23:48:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch12_loss0.9675616472959518.pypots
2024-05-24 23:48:39 [INFO]: Epoch 013 - training loss: 0.8872, validation loss: 0.9621
2024-05-24 23:48:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch13_loss0.9620588421821594.pypots
2024-05-24 23:48:40 [INFO]: Epoch 014 - training loss: 0.8758, validation loss: 0.9543
2024-05-24 23:48:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch14_loss0.9543123692274094.pypots
2024-05-24 23:48:40 [INFO]: Epoch 015 - training loss: 0.8816, validation loss: 0.9505
2024-05-24 23:48:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch15_loss0.95054030418396.pypots
2024-05-24 23:48:40 [INFO]: Epoch 016 - training loss: 0.8641, validation loss: 0.9437
2024-05-24 23:48:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch16_loss0.9436761736869812.pypots
2024-05-24 23:48:40 [INFO]: Epoch 017 - training loss: 0.8584, validation loss: 0.9410
2024-05-24 23:48:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch17_loss0.9409587681293488.pypots
2024-05-24 23:48:40 [INFO]: Epoch 018 - training loss: 0.8419, validation loss: 0.9391
2024-05-24 23:48:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch18_loss0.9391498118638992.pypots
2024-05-24 23:48:41 [INFO]: Epoch 019 - training loss: 0.8822, validation loss: 0.9368
2024-05-24 23:48:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch19_loss0.9368224889039993.pypots
2024-05-24 23:48:41 [INFO]: Epoch 020 - training loss: 0.8672, validation loss: 0.9320
2024-05-24 23:48:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch20_loss0.9320116639137268.pypots
2024-05-24 23:48:41 [INFO]: Epoch 021 - training loss: 0.8949, validation loss: 0.9284
2024-05-24 23:48:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch21_loss0.9284359961748123.pypots
2024-05-24 23:48:41 [INFO]: Epoch 022 - training loss: 0.8785, validation loss: 0.9248
2024-05-24 23:48:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch22_loss0.924757793545723.pypots
2024-05-24 23:48:41 [INFO]: Epoch 023 - training loss: 0.8498, validation loss: 0.9171
2024-05-24 23:48:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch23_loss0.9171243906021118.pypots
2024-05-24 23:48:41 [INFO]: Epoch 024 - training loss: 0.8311, validation loss: 0.9162
2024-05-24 23:48:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch24_loss0.9161840230226517.pypots
2024-05-24 23:48:42 [INFO]: Epoch 025 - training loss: 0.8489, validation loss: 0.9130
2024-05-24 23:48:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch25_loss0.9129749536514282.pypots
2024-05-24 23:48:42 [INFO]: Epoch 026 - training loss: 0.8315, validation loss: 0.9100
2024-05-24 23:48:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch26_loss0.910002812743187.pypots
2024-05-24 23:48:42 [INFO]: Epoch 027 - training loss: 0.8440, validation loss: 0.9079
2024-05-24 23:48:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch27_loss0.9078752994537354.pypots
2024-05-24 23:48:42 [INFO]: Epoch 028 - training loss: 0.8419, validation loss: 0.9034
2024-05-24 23:48:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch28_loss0.9033782333135605.pypots
2024-05-24 23:48:42 [INFO]: Epoch 029 - training loss: 0.8159, validation loss: 0.9020
2024-05-24 23:48:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch29_loss0.902043417096138.pypots
2024-05-24 23:48:43 [INFO]: Epoch 030 - training loss: 0.8384, validation loss: 0.8999
2024-05-24 23:48:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch30_loss0.8999388217926025.pypots
2024-05-24 23:48:43 [INFO]: Epoch 031 - training loss: 0.8154, validation loss: 0.8981
2024-05-24 23:48:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch31_loss0.8980527818202972.pypots
2024-05-24 23:48:43 [INFO]: Epoch 032 - training loss: 0.8075, validation loss: 0.8968
2024-05-24 23:48:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch32_loss0.8967845886945724.pypots
2024-05-24 23:48:43 [INFO]: Epoch 033 - training loss: 0.8245, validation loss: 0.8934
2024-05-24 23:48:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch33_loss0.8934094160795212.pypots
2024-05-24 23:48:43 [INFO]: Epoch 034 - training loss: 0.8238, validation loss: 0.8906
2024-05-24 23:48:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch34_loss0.8906030803918839.pypots
2024-05-24 23:48:44 [INFO]: Epoch 035 - training loss: 0.8368, validation loss: 0.8895
2024-05-24 23:48:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch35_loss0.8894564360380173.pypots
2024-05-24 23:48:44 [INFO]: Epoch 036 - training loss: 0.8185, validation loss: 0.8858
2024-05-24 23:48:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch36_loss0.885842815041542.pypots
2024-05-24 23:48:44 [INFO]: Epoch 037 - training loss: 0.8734, validation loss: 0.8842
2024-05-24 23:48:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch37_loss0.884204626083374.pypots
2024-05-24 23:48:44 [INFO]: Epoch 038 - training loss: 0.8296, validation loss: 0.8825
2024-05-24 23:48:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch38_loss0.8825370818376541.pypots
2024-05-24 23:48:44 [INFO]: Epoch 039 - training loss: 0.8018, validation loss: 0.8825
2024-05-24 23:48:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch39_loss0.8825062811374664.pypots
2024-05-24 23:48:44 [INFO]: Epoch 040 - training loss: 0.8070, validation loss: 0.8786
2024-05-24 23:48:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch40_loss0.8786089867353439.pypots
2024-05-24 23:48:45 [INFO]: Epoch 041 - training loss: 0.8051, validation loss: 0.8779
2024-05-24 23:48:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch41_loss0.8779450356960297.pypots
2024-05-24 23:48:45 [INFO]: Epoch 042 - training loss: 0.8345, validation loss: 0.8749
2024-05-24 23:48:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch42_loss0.8748684376478195.pypots
2024-05-24 23:48:45 [INFO]: Epoch 043 - training loss: 0.8137, validation loss: 0.8745
2024-05-24 23:48:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch43_loss0.8744564205408096.pypots
2024-05-24 23:48:45 [INFO]: Epoch 044 - training loss: 0.8189, validation loss: 0.8715
2024-05-24 23:48:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch44_loss0.8715096116065979.pypots
2024-05-24 23:48:45 [INFO]: Epoch 045 - training loss: 0.8108, validation loss: 0.8691
2024-05-24 23:48:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch45_loss0.8691487014293671.pypots
2024-05-24 23:48:46 [INFO]: Epoch 046 - training loss: 0.8055, validation loss: 0.8675
2024-05-24 23:48:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch46_loss0.8675014823675156.pypots
2024-05-24 23:48:46 [INFO]: Epoch 047 - training loss: 0.8316, validation loss: 0.8636
2024-05-24 23:48:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch47_loss0.8636092096567154.pypots
2024-05-24 23:48:46 [INFO]: Epoch 048 - training loss: 0.8174, validation loss: 0.8637
2024-05-24 23:48:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch48_loss0.8636865466833115.pypots
2024-05-24 23:48:46 [INFO]: Epoch 049 - training loss: 0.8336, validation loss: 0.8615
2024-05-24 23:48:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch49_loss0.8615294098854065.pypots
2024-05-24 23:48:46 [INFO]: Epoch 050 - training loss: 0.8533, validation loss: 0.8582
2024-05-24 23:48:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch50_loss0.8582145720720291.pypots
2024-05-24 23:48:47 [INFO]: Epoch 051 - training loss: 0.8050, validation loss: 0.8580
2024-05-24 23:48:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch51_loss0.8579926192760468.pypots
2024-05-24 23:48:47 [INFO]: Epoch 052 - training loss: 0.8098, validation loss: 0.8587
2024-05-24 23:48:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch52_loss0.8586576133966446.pypots
2024-05-24 23:48:47 [INFO]: Epoch 053 - training loss: 0.8259, validation loss: 0.8570
2024-05-24 23:48:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch53_loss0.8570247739553452.pypots
2024-05-24 23:48:47 [INFO]: Epoch 054 - training loss: 0.7868, validation loss: 0.8538
2024-05-24 23:48:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch54_loss0.8538252115249634.pypots
2024-05-24 23:48:47 [INFO]: Epoch 055 - training loss: 0.8004, validation loss: 0.8540
2024-05-24 23:48:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch55_loss0.854049414396286.pypots
2024-05-24 23:48:48 [INFO]: Epoch 056 - training loss: 0.8176, validation loss: 0.8532
2024-05-24 23:48:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch56_loss0.8531522154808044.pypots
2024-05-24 23:48:48 [INFO]: Epoch 057 - training loss: 0.8231, validation loss: 0.8517
2024-05-24 23:48:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch57_loss0.8517151772975922.pypots
2024-05-24 23:48:48 [INFO]: Epoch 058 - training loss: 0.8079, validation loss: 0.8523
2024-05-24 23:48:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch58_loss0.8523032069206238.pypots
2024-05-24 23:48:48 [INFO]: Epoch 059 - training loss: 0.8006, validation loss: 0.8517
2024-05-24 23:48:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch59_loss0.8517021387815475.pypots
2024-05-24 23:48:48 [INFO]: Epoch 060 - training loss: 0.8456, validation loss: 0.8469
2024-05-24 23:48:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch60_loss0.846863642334938.pypots
2024-05-24 23:48:48 [INFO]: Epoch 061 - training loss: 0.8001, validation loss: 0.8456
2024-05-24 23:48:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch61_loss0.8455587774515152.pypots
2024-05-24 23:48:49 [INFO]: Epoch 062 - training loss: 0.8122, validation loss: 0.8480
2024-05-24 23:48:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch62_loss0.8480114489793777.pypots
2024-05-24 23:48:49 [INFO]: Epoch 063 - training loss: 0.8097, validation loss: 0.8467
2024-05-24 23:48:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch63_loss0.8467100411653519.pypots
2024-05-24 23:48:49 [INFO]: Epoch 064 - training loss: 0.7918, validation loss: 0.8451
2024-05-24 23:48:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch64_loss0.8451123833656311.pypots
2024-05-24 23:48:49 [INFO]: Epoch 065 - training loss: 0.7890, validation loss: 0.8442
2024-05-24 23:48:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch65_loss0.8442467898130417.pypots
2024-05-24 23:48:49 [INFO]: Epoch 066 - training loss: 0.7930, validation loss: 0.8436
2024-05-24 23:48:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch66_loss0.8436402827501297.pypots
2024-05-24 23:48:50 [INFO]: Epoch 067 - training loss: 0.8019, validation loss: 0.8434
2024-05-24 23:48:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch67_loss0.8434083312749863.pypots
2024-05-24 23:48:50 [INFO]: Epoch 068 - training loss: 0.7961, validation loss: 0.8439
2024-05-24 23:48:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch68_loss0.8439192771911621.pypots
2024-05-24 23:48:50 [INFO]: Epoch 069 - training loss: 0.8488, validation loss: 0.8439
2024-05-24 23:48:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch69_loss0.8438597172498703.pypots
2024-05-24 23:48:50 [INFO]: Epoch 070 - training loss: 0.8058, validation loss: 0.8438
2024-05-24 23:48:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch70_loss0.8438050895929337.pypots
2024-05-24 23:48:50 [INFO]: Epoch 071 - training loss: 0.8211, validation loss: 0.8406
2024-05-24 23:48:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch71_loss0.8405520468950272.pypots
2024-05-24 23:48:51 [INFO]: Epoch 072 - training loss: 0.7784, validation loss: 0.8423
2024-05-24 23:48:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch72_loss0.842261865735054.pypots
2024-05-24 23:48:51 [INFO]: Epoch 073 - training loss: 0.8011, validation loss: 0.8411
2024-05-24 23:48:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch73_loss0.8411303460597992.pypots
2024-05-24 23:48:51 [INFO]: Epoch 074 - training loss: 0.7943, validation loss: 0.8398
2024-05-24 23:48:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch74_loss0.8397501111030579.pypots
2024-05-24 23:48:51 [INFO]: Epoch 075 - training loss: 0.8031, validation loss: 0.8405
2024-05-24 23:48:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch75_loss0.8405441045761108.pypots
2024-05-24 23:48:51 [INFO]: Epoch 076 - training loss: 0.8064, validation loss: 0.8406
2024-05-24 23:48:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch76_loss0.840608611702919.pypots
2024-05-24 23:48:51 [INFO]: Epoch 077 - training loss: 0.8176, validation loss: 0.8381
2024-05-24 23:48:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch77_loss0.8381397426128387.pypots
2024-05-24 23:48:52 [INFO]: Epoch 078 - training loss: 0.8104, validation loss: 0.8401
2024-05-24 23:48:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch78_loss0.8400830626487732.pypots
2024-05-24 23:48:52 [INFO]: Epoch 079 - training loss: 0.7885, validation loss: 0.8399
2024-05-24 23:48:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch79_loss0.8398928195238113.pypots
2024-05-24 23:48:52 [INFO]: Epoch 080 - training loss: 0.7984, validation loss: 0.8367
2024-05-24 23:48:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch80_loss0.8367175757884979.pypots
2024-05-24 23:48:52 [INFO]: Epoch 081 - training loss: 0.7974, validation loss: 0.8383
2024-05-24 23:48:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch81_loss0.8382865935564041.pypots
2024-05-24 23:48:52 [INFO]: Epoch 082 - training loss: 0.7860, validation loss: 0.8409
2024-05-24 23:48:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch82_loss0.8408790081739426.pypots
2024-05-24 23:48:53 [INFO]: Epoch 083 - training loss: 0.7749, validation loss: 0.8392
2024-05-24 23:48:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch83_loss0.8391665071249008.pypots
2024-05-24 23:48:53 [INFO]: Epoch 084 - training loss: 0.7813, validation loss: 0.8379
2024-05-24 23:48:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch84_loss0.8378518968820572.pypots
2024-05-24 23:48:53 [INFO]: Epoch 085 - training loss: 0.7831, validation loss: 0.8385
2024-05-24 23:48:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch85_loss0.8384896963834763.pypots
2024-05-24 23:48:53 [INFO]: Epoch 086 - training loss: 0.8078, validation loss: 0.8377
2024-05-24 23:48:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch86_loss0.8377274423837662.pypots
2024-05-24 23:48:53 [INFO]: Epoch 087 - training loss: 0.7949, validation loss: 0.8395
2024-05-24 23:48:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch87_loss0.8394694924354553.pypots
2024-05-24 23:48:54 [INFO]: Epoch 088 - training loss: 0.8037, validation loss: 0.8387
2024-05-24 23:48:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch88_loss0.838678389787674.pypots
2024-05-24 23:48:54 [INFO]: Epoch 089 - training loss: 0.7859, validation loss: 0.8405
2024-05-24 23:48:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch89_loss0.8404918909072876.pypots
2024-05-24 23:48:54 [INFO]: Epoch 090 - training loss: 0.7935, validation loss: 0.8397
2024-05-24 23:48:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN_epoch90_loss0.839668869972229.pypots
2024-05-24 23:48:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:48:54 [INFO]: Finished training. The best model is from epoch#80.
2024-05-24 23:48:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240524_T234835/MRNN.pypots
2024-05-24 23:48:54 [INFO]: MRNN on ETTm1: MAE=0.7378, MSE=1.2989
2024-05-24 23:48:54 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/MRNN_ettm1/imputation.pkl
2024-05-24 23:48:54 [INFO]: Using the given device: cpu
2024-05-24 23:48:54 [INFO]: LOCF on ETTm1: MAE=0.1332, MSE=0.0720
2024-05-24 23:48:54 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_ettm1".
2024-05-24 23:48:54 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/LOCF_ettm1/imputation.pkl
2024-05-24 23:48:54 [INFO]: Median on ETTm1: MAE=0.6670, MSE=0.8617
2024-05-24 23:48:54 [INFO]: Successfully created the given path "saved_results/round_2/Median_ettm1".
2024-05-24 23:48:54 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/Median_ettm1/imputation.pkl
2024-05-24 23:48:54 [INFO]: Mean on ETTm1: MAE=0.6734, MSE=0.8444
2024-05-24 23:48:54 [INFO]: Successfully created the given path "saved_results/round_2/Mean_ettm1".
2024-05-24 23:48:54 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/Mean_ettm1/imputation.pkl
2024-05-24 23:48:54 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-24 23:48:54 [INFO]: Using the given device: cuda:0
2024-05-24 23:48:54 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/SAITS_ettm1/20240524_T234854
2024-05-24 23:48:54 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/SAITS_ettm1/20240524_T234854/tensorboard
2024-05-24 23:48:54 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 23:48:55 [INFO]: Epoch 001 - training loss: 1.1990, validation loss: 0.3005
2024-05-24 23:48:55 [INFO]: Epoch 002 - training loss: 0.8909, validation loss: 0.1407
2024-05-24 23:48:56 [INFO]: Epoch 003 - training loss: 0.7595, validation loss: 0.1030
2024-05-24 23:48:56 [INFO]: Epoch 004 - training loss: 0.7029, validation loss: 0.1149
2024-05-24 23:48:57 [INFO]: Epoch 005 - training loss: 0.6698, validation loss: 0.0709
2024-05-24 23:48:58 [INFO]: Epoch 006 - training loss: 0.6564, validation loss: 0.0858
2024-05-24 23:48:58 [INFO]: Epoch 007 - training loss: 0.6450, validation loss: 0.0885
2024-05-24 23:48:59 [INFO]: Epoch 008 - training loss: 0.6114, validation loss: 0.0743
2024-05-24 23:48:59 [INFO]: Epoch 009 - training loss: 0.6013, validation loss: 0.0753
2024-05-24 23:49:00 [INFO]: Epoch 010 - training loss: 0.5974, validation loss: 0.0960
2024-05-24 23:49:00 [INFO]: Epoch 011 - training loss: 0.5888, validation loss: 0.0831
2024-05-24 23:49:01 [INFO]: Epoch 012 - training loss: 0.5757, validation loss: 0.0709
2024-05-24 23:49:01 [INFO]: Epoch 013 - training loss: 0.5649, validation loss: 0.0494
2024-05-24 23:49:02 [INFO]: Epoch 014 - training loss: 0.5677, validation loss: 0.0979
2024-05-24 23:49:02 [INFO]: Epoch 015 - training loss: 0.5626, validation loss: 0.0520
2024-05-24 23:49:03 [INFO]: Epoch 016 - training loss: 0.5473, validation loss: 0.0597
2024-05-24 23:49:03 [INFO]: Epoch 017 - training loss: 0.5385, validation loss: 0.0564
2024-05-24 23:49:04 [INFO]: Epoch 018 - training loss: 0.5444, validation loss: 0.0597
2024-05-24 23:49:04 [INFO]: Epoch 019 - training loss: 0.5279, validation loss: 0.0489
2024-05-24 23:49:05 [INFO]: Epoch 020 - training loss: 0.5409, validation loss: 0.0578
2024-05-24 23:49:05 [INFO]: Epoch 021 - training loss: 0.5390, validation loss: 0.0658
2024-05-24 23:49:06 [INFO]: Epoch 022 - training loss: 0.5152, validation loss: 0.0500
2024-05-24 23:49:06 [INFO]: Epoch 023 - training loss: 0.5100, validation loss: 0.0514
2024-05-24 23:49:07 [INFO]: Epoch 024 - training loss: 0.5144, validation loss: 0.0414
2024-05-24 23:49:07 [INFO]: Epoch 025 - training loss: 0.4965, validation loss: 0.0529
2024-05-24 23:49:08 [INFO]: Epoch 026 - training loss: 0.4928, validation loss: 0.0463
2024-05-24 23:49:08 [INFO]: Epoch 027 - training loss: 0.4817, validation loss: 0.0374
2024-05-24 23:49:09 [INFO]: Epoch 028 - training loss: 0.4828, validation loss: 0.0500
2024-05-24 23:49:09 [INFO]: Epoch 029 - training loss: 0.4756, validation loss: 0.0381
2024-05-24 23:49:10 [INFO]: Epoch 030 - training loss: 0.4871, validation loss: 0.0388
2024-05-24 23:49:10 [INFO]: Epoch 031 - training loss: 0.4820, validation loss: 0.0416
2024-05-24 23:49:11 [INFO]: Epoch 032 - training loss: 0.4827, validation loss: 0.0381
2024-05-24 23:49:11 [INFO]: Epoch 033 - training loss: 0.4849, validation loss: 0.0412
2024-05-24 23:49:12 [INFO]: Epoch 034 - training loss: 0.4684, validation loss: 0.0355
2024-05-24 23:49:12 [INFO]: Epoch 035 - training loss: 0.4638, validation loss: 0.0418
2024-05-24 23:49:13 [INFO]: Epoch 036 - training loss: 0.4587, validation loss: 0.0323
2024-05-24 23:49:13 [INFO]: Epoch 037 - training loss: 0.4476, validation loss: 0.0495
2024-05-24 23:49:14 [INFO]: Epoch 038 - training loss: 0.4501, validation loss: 0.0428
2024-05-24 23:49:14 [INFO]: Epoch 039 - training loss: 0.4453, validation loss: 0.0388
2024-05-24 23:49:15 [INFO]: Epoch 040 - training loss: 0.4430, validation loss: 0.0461
2024-05-24 23:49:15 [INFO]: Epoch 041 - training loss: 0.4443, validation loss: 0.0437
2024-05-24 23:49:16 [INFO]: Epoch 042 - training loss: 0.4404, validation loss: 0.0327
2024-05-24 23:49:16 [INFO]: Epoch 043 - training loss: 0.4375, validation loss: 0.0479
2024-05-24 23:49:17 [INFO]: Epoch 044 - training loss: 0.4308, validation loss: 0.0415
2024-05-24 23:49:17 [INFO]: Epoch 045 - training loss: 0.4346, validation loss: 0.0345
2024-05-24 23:49:18 [INFO]: Epoch 046 - training loss: 0.4355, validation loss: 0.0430
2024-05-24 23:49:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:49:18 [INFO]: Finished training. The best model is from epoch#36.
2024-05-24 23:49:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/SAITS_ettm1/20240524_T234854/SAITS.pypots
2024-05-24 23:49:18 [INFO]: SAITS on ETTm1: MAE=0.1499, MSE=0.0420
2024-05-24 23:49:18 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/SAITS_ettm1/imputation.pkl
2024-05-24 23:49:18 [INFO]: Using the given device: cuda:0
2024-05-24 23:49:18 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/Transformer_ettm1/20240524_T234918
2024-05-24 23:49:18 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/Transformer_ettm1/20240524_T234918/tensorboard
2024-05-24 23:49:18 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 23:49:18 [INFO]: Epoch 001 - training loss: 1.1738, validation loss: 0.3669
2024-05-24 23:49:19 [INFO]: Epoch 002 - training loss: 0.7402, validation loss: 0.1850
2024-05-24 23:49:19 [INFO]: Epoch 003 - training loss: 0.6073, validation loss: 0.1128
2024-05-24 23:49:19 [INFO]: Epoch 004 - training loss: 0.5526, validation loss: 0.0802
2024-05-24 23:49:19 [INFO]: Epoch 005 - training loss: 0.4957, validation loss: 0.0713
2024-05-24 23:49:19 [INFO]: Epoch 006 - training loss: 0.4668, validation loss: 0.0647
2024-05-24 23:49:20 [INFO]: Epoch 007 - training loss: 0.4414, validation loss: 0.0622
2024-05-24 23:49:20 [INFO]: Epoch 008 - training loss: 0.4258, validation loss: 0.0593
2024-05-24 23:49:20 [INFO]: Epoch 009 - training loss: 0.4034, validation loss: 0.0526
2024-05-24 23:49:20 [INFO]: Epoch 010 - training loss: 0.3887, validation loss: 0.0551
2024-05-24 23:49:21 [INFO]: Epoch 011 - training loss: 0.3759, validation loss: 0.0567
2024-05-24 23:49:21 [INFO]: Epoch 012 - training loss: 0.3739, validation loss: 0.0495
2024-05-24 23:49:21 [INFO]: Epoch 013 - training loss: 0.3587, validation loss: 0.0426
2024-05-24 23:49:21 [INFO]: Epoch 014 - training loss: 0.3541, validation loss: 0.0466
2024-05-24 23:49:21 [INFO]: Epoch 015 - training loss: 0.3417, validation loss: 0.0399
2024-05-24 23:49:22 [INFO]: Epoch 016 - training loss: 0.3329, validation loss: 0.0450
2024-05-24 23:49:22 [INFO]: Epoch 017 - training loss: 0.3290, validation loss: 0.0355
2024-05-24 23:49:22 [INFO]: Epoch 018 - training loss: 0.3282, validation loss: 0.0437
2024-05-24 23:49:22 [INFO]: Epoch 019 - training loss: 0.3203, validation loss: 0.0419
2024-05-24 23:49:22 [INFO]: Epoch 020 - training loss: 0.3167, validation loss: 0.0408
2024-05-24 23:49:23 [INFO]: Epoch 021 - training loss: 0.3089, validation loss: 0.0404
2024-05-24 23:49:23 [INFO]: Epoch 022 - training loss: 0.3047, validation loss: 0.0368
2024-05-24 23:49:23 [INFO]: Epoch 023 - training loss: 0.3035, validation loss: 0.0298
2024-05-24 23:49:23 [INFO]: Epoch 024 - training loss: 0.2956, validation loss: 0.0332
2024-05-24 23:49:24 [INFO]: Epoch 025 - training loss: 0.2920, validation loss: 0.0349
2024-05-24 23:49:24 [INFO]: Epoch 026 - training loss: 0.2919, validation loss: 0.0342
2024-05-24 23:49:24 [INFO]: Epoch 027 - training loss: 0.2922, validation loss: 0.0420
2024-05-24 23:49:24 [INFO]: Epoch 028 - training loss: 0.3015, validation loss: 0.0335
2024-05-24 23:49:24 [INFO]: Epoch 029 - training loss: 0.2893, validation loss: 0.0309
2024-05-24 23:49:25 [INFO]: Epoch 030 - training loss: 0.2846, validation loss: 0.0338
2024-05-24 23:49:25 [INFO]: Epoch 031 - training loss: 0.2780, validation loss: 0.0325
2024-05-24 23:49:25 [INFO]: Epoch 032 - training loss: 0.2763, validation loss: 0.0289
2024-05-24 23:49:25 [INFO]: Epoch 033 - training loss: 0.2717, validation loss: 0.0329
2024-05-24 23:49:26 [INFO]: Epoch 034 - training loss: 0.2670, validation loss: 0.0257
2024-05-24 23:49:26 [INFO]: Epoch 035 - training loss: 0.2606, validation loss: 0.0301
2024-05-24 23:49:26 [INFO]: Epoch 036 - training loss: 0.2594, validation loss: 0.0314
2024-05-24 23:49:26 [INFO]: Epoch 037 - training loss: 0.2575, validation loss: 0.0273
2024-05-24 23:49:26 [INFO]: Epoch 038 - training loss: 0.2620, validation loss: 0.0319
2024-05-24 23:49:27 [INFO]: Epoch 039 - training loss: 0.2582, validation loss: 0.0271
2024-05-24 23:49:27 [INFO]: Epoch 040 - training loss: 0.2594, validation loss: 0.0274
2024-05-24 23:49:27 [INFO]: Epoch 041 - training loss: 0.2643, validation loss: 0.0281
2024-05-24 23:49:27 [INFO]: Epoch 042 - training loss: 0.2559, validation loss: 0.0262
2024-05-24 23:49:27 [INFO]: Epoch 043 - training loss: 0.2492, validation loss: 0.0248
2024-05-24 23:49:28 [INFO]: Epoch 044 - training loss: 0.2451, validation loss: 0.0241
2024-05-24 23:49:28 [INFO]: Epoch 045 - training loss: 0.2404, validation loss: 0.0274
2024-05-24 23:49:28 [INFO]: Epoch 046 - training loss: 0.2420, validation loss: 0.0243
2024-05-24 23:49:28 [INFO]: Epoch 047 - training loss: 0.2480, validation loss: 0.0242
2024-05-24 23:49:29 [INFO]: Epoch 048 - training loss: 0.2394, validation loss: 0.0238
2024-05-24 23:49:29 [INFO]: Epoch 049 - training loss: 0.2337, validation loss: 0.0230
2024-05-24 23:49:29 [INFO]: Epoch 050 - training loss: 0.2325, validation loss: 0.0303
2024-05-24 23:49:29 [INFO]: Epoch 051 - training loss: 0.2330, validation loss: 0.0262
2024-05-24 23:49:29 [INFO]: Epoch 052 - training loss: 0.2315, validation loss: 0.0250
2024-05-24 23:49:30 [INFO]: Epoch 053 - training loss: 0.2440, validation loss: 0.0289
2024-05-24 23:49:30 [INFO]: Epoch 054 - training loss: 0.2348, validation loss: 0.0214
2024-05-24 23:49:30 [INFO]: Epoch 055 - training loss: 0.2239, validation loss: 0.0221
2024-05-24 23:49:30 [INFO]: Epoch 056 - training loss: 0.2239, validation loss: 0.0237
2024-05-24 23:49:31 [INFO]: Epoch 057 - training loss: 0.2244, validation loss: 0.0202
2024-05-24 23:49:31 [INFO]: Epoch 058 - training loss: 0.2179, validation loss: 0.0204
2024-05-24 23:49:31 [INFO]: Epoch 059 - training loss: 0.2210, validation loss: 0.0232
2024-05-24 23:49:31 [INFO]: Epoch 060 - training loss: 0.2245, validation loss: 0.0216
2024-05-24 23:49:31 [INFO]: Epoch 061 - training loss: 0.2252, validation loss: 0.0228
2024-05-24 23:49:32 [INFO]: Epoch 062 - training loss: 0.2203, validation loss: 0.0210
2024-05-24 23:49:32 [INFO]: Epoch 063 - training loss: 0.2176, validation loss: 0.0217
2024-05-24 23:49:32 [INFO]: Epoch 064 - training loss: 0.2162, validation loss: 0.0211
2024-05-24 23:49:32 [INFO]: Epoch 065 - training loss: 0.2158, validation loss: 0.0243
2024-05-24 23:49:32 [INFO]: Epoch 066 - training loss: 0.2190, validation loss: 0.0242
2024-05-24 23:49:33 [INFO]: Epoch 067 - training loss: 0.2180, validation loss: 0.0206
2024-05-24 23:49:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:49:33 [INFO]: Finished training. The best model is from epoch#57.
2024-05-24 23:49:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/Transformer_ettm1/20240524_T234918/Transformer.pypots
2024-05-24 23:49:33 [INFO]: Transformer on ETTm1: MAE=0.1246, MSE=0.0300
2024-05-24 23:49:33 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/Transformer_ettm1/imputation.pkl
2024-05-24 23:49:33 [INFO]: Using the given device: cuda:0
2024-05-24 23:49:33 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/TimesNet_ettm1/20240524_T234933
2024-05-24 23:49:33 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/TimesNet_ettm1/20240524_T234933/tensorboard
2024-05-24 23:49:33 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 23:49:33 [INFO]: Epoch 001 - training loss: 0.1513, validation loss: 0.0542
2024-05-24 23:49:33 [INFO]: Epoch 002 - training loss: 0.0634, validation loss: 0.0400
2024-05-24 23:49:34 [INFO]: Epoch 003 - training loss: 0.0548, validation loss: 0.0348
2024-05-24 23:49:34 [INFO]: Epoch 004 - training loss: 0.0517, validation loss: 0.0335
2024-05-24 23:49:34 [INFO]: Epoch 005 - training loss: 0.0490, validation loss: 0.0330
2024-05-24 23:49:34 [INFO]: Epoch 006 - training loss: 0.0479, validation loss: 0.0327
2024-05-24 23:49:34 [INFO]: Epoch 007 - training loss: 0.0447, validation loss: 0.0288
2024-05-24 23:49:35 [INFO]: Epoch 008 - training loss: 0.0428, validation loss: 0.0280
2024-05-24 23:49:35 [INFO]: Epoch 009 - training loss: 0.0438, validation loss: 0.0307
2024-05-24 23:49:35 [INFO]: Epoch 010 - training loss: 0.0429, validation loss: 0.0305
2024-05-24 23:49:35 [INFO]: Epoch 011 - training loss: 0.0431, validation loss: 0.0290
2024-05-24 23:49:35 [INFO]: Epoch 012 - training loss: 0.0432, validation loss: 0.0303
2024-05-24 23:49:36 [INFO]: Epoch 013 - training loss: 0.0423, validation loss: 0.0324
2024-05-24 23:49:36 [INFO]: Epoch 014 - training loss: 0.0440, validation loss: 0.0302
2024-05-24 23:49:36 [INFO]: Epoch 015 - training loss: 0.0415, validation loss: 0.0311
2024-05-24 23:49:36 [INFO]: Epoch 016 - training loss: 0.0413, validation loss: 0.0286
2024-05-24 23:49:37 [INFO]: Epoch 017 - training loss: 0.0392, validation loss: 0.0303
2024-05-24 23:49:37 [INFO]: Epoch 018 - training loss: 0.0402, validation loss: 0.0305
2024-05-24 23:49:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:49:37 [INFO]: Finished training. The best model is from epoch#8.
2024-05-24 23:49:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/TimesNet_ettm1/20240524_T234933/TimesNet.pypots
2024-05-24 23:49:37 [INFO]: TimesNet on ETTm1: MAE=0.1187, MSE=0.0295
2024-05-24 23:49:37 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/TimesNet_ettm1/imputation.pkl
2024-05-24 23:49:37 [INFO]: Using the given device: cuda:0
2024-05-24 23:49:37 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937
2024-05-24 23:49:37 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/tensorboard
2024-05-24 23:49:37 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 23:49:39 [INFO]: Epoch 001 - training loss: 0.6855, validation loss: 0.4225
2024-05-24 23:49:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch1_loss0.42248326539993286.pypots
2024-05-24 23:49:41 [INFO]: Epoch 002 - training loss: 0.3897, validation loss: 0.3588
2024-05-24 23:49:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch2_loss0.3587837964296341.pypots
2024-05-24 23:49:43 [INFO]: Epoch 003 - training loss: 0.3350, validation loss: 0.3617
2024-05-24 23:49:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch3_loss0.36165548861026764.pypots
2024-05-24 23:49:45 [INFO]: Epoch 004 - training loss: 0.3468, validation loss: 0.3315
2024-05-24 23:49:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch4_loss0.3314978629350662.pypots
2024-05-24 23:49:47 [INFO]: Epoch 005 - training loss: 0.3313, validation loss: 0.3052
2024-05-24 23:49:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch5_loss0.3051701635122299.pypots
2024-05-24 23:49:49 [INFO]: Epoch 006 - training loss: 0.3124, validation loss: 0.2864
2024-05-24 23:49:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch6_loss0.2864353805780411.pypots
2024-05-24 23:49:51 [INFO]: Epoch 007 - training loss: 0.2823, validation loss: 0.2877
2024-05-24 23:49:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch7_loss0.28767167776823044.pypots
2024-05-24 23:49:54 [INFO]: Epoch 008 - training loss: 0.3136, validation loss: 0.2678
2024-05-24 23:49:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch8_loss0.26777105778455734.pypots
2024-05-24 23:49:56 [INFO]: Epoch 009 - training loss: 0.2740, validation loss: 0.2974
2024-05-24 23:49:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch9_loss0.2973892614245415.pypots
2024-05-24 23:49:58 [INFO]: Epoch 010 - training loss: 0.2863, validation loss: 0.3122
2024-05-24 23:49:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch10_loss0.3121892586350441.pypots
2024-05-24 23:50:00 [INFO]: Epoch 011 - training loss: 0.2590, validation loss: 0.2646
2024-05-24 23:50:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch11_loss0.26459241658449173.pypots
2024-05-24 23:50:02 [INFO]: Epoch 012 - training loss: 0.2469, validation loss: 0.2503
2024-05-24 23:50:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch12_loss0.25034669041633606.pypots
2024-05-24 23:50:04 [INFO]: Epoch 013 - training loss: 0.2067, validation loss: 0.2470
2024-05-24 23:50:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch13_loss0.2470022216439247.pypots
2024-05-24 23:50:06 [INFO]: Epoch 014 - training loss: 0.2254, validation loss: 0.2188
2024-05-24 23:50:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch14_loss0.21879661083221436.pypots
2024-05-24 23:50:08 [INFO]: Epoch 015 - training loss: 0.1985, validation loss: 0.2270
2024-05-24 23:50:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch15_loss0.22697916999459267.pypots
2024-05-24 23:50:10 [INFO]: Epoch 016 - training loss: 0.2399, validation loss: 0.2224
2024-05-24 23:50:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch16_loss0.22241707891225815.pypots
2024-05-24 23:50:12 [INFO]: Epoch 017 - training loss: 0.2024, validation loss: 0.2198
2024-05-24 23:50:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch17_loss0.21984237059950829.pypots
2024-05-24 23:50:14 [INFO]: Epoch 018 - training loss: 0.2464, validation loss: 0.2131
2024-05-24 23:50:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch18_loss0.2131086252629757.pypots
2024-05-24 23:50:16 [INFO]: Epoch 019 - training loss: 0.2224, validation loss: 0.2084
2024-05-24 23:50:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch19_loss0.20844101533293724.pypots
2024-05-24 23:50:18 [INFO]: Epoch 020 - training loss: 0.1904, validation loss: 0.1988
2024-05-24 23:50:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch20_loss0.19882022216916084.pypots
2024-05-24 23:50:21 [INFO]: Epoch 021 - training loss: 0.2693, validation loss: 0.1998
2024-05-24 23:50:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch21_loss0.19976923987269402.pypots
2024-05-24 23:50:23 [INFO]: Epoch 022 - training loss: 0.2391, validation loss: 0.2058
2024-05-24 23:50:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch22_loss0.20581669732928276.pypots
2024-05-24 23:50:25 [INFO]: Epoch 023 - training loss: 0.2564, validation loss: 0.1975
2024-05-24 23:50:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch23_loss0.19747395813465118.pypots
2024-05-24 23:50:27 [INFO]: Epoch 024 - training loss: 0.1973, validation loss: 0.2081
2024-05-24 23:50:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch24_loss0.20810726284980774.pypots
2024-05-24 23:50:29 [INFO]: Epoch 025 - training loss: 0.1710, validation loss: 0.1957
2024-05-24 23:50:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch25_loss0.19572683051228523.pypots
2024-05-24 23:50:31 [INFO]: Epoch 026 - training loss: 0.1789, validation loss: 0.1789
2024-05-24 23:50:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch26_loss0.17893880233168602.pypots
2024-05-24 23:50:33 [INFO]: Epoch 027 - training loss: 0.1890, validation loss: 0.1973
2024-05-24 23:50:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch27_loss0.19734511524438858.pypots
2024-05-24 23:50:35 [INFO]: Epoch 028 - training loss: 0.2602, validation loss: 0.1877
2024-05-24 23:50:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch28_loss0.18770373612642288.pypots
2024-05-24 23:50:37 [INFO]: Epoch 029 - training loss: 0.1886, validation loss: 0.1825
2024-05-24 23:50:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch29_loss0.1824835054576397.pypots
2024-05-24 23:50:39 [INFO]: Epoch 030 - training loss: 0.1669, validation loss: 0.1719
2024-05-24 23:50:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch30_loss0.1719200275838375.pypots
2024-05-24 23:50:41 [INFO]: Epoch 031 - training loss: 0.1905, validation loss: 0.1650
2024-05-24 23:50:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch31_loss0.1650145836174488.pypots
2024-05-24 23:50:43 [INFO]: Epoch 032 - training loss: 0.1774, validation loss: 0.1607
2024-05-24 23:50:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch32_loss0.16074210032820702.pypots
2024-05-24 23:50:46 [INFO]: Epoch 033 - training loss: 0.1644, validation loss: 0.1591
2024-05-24 23:50:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch33_loss0.15912076830863953.pypots
2024-05-24 23:50:48 [INFO]: Epoch 034 - training loss: 0.1929, validation loss: 0.1646
2024-05-24 23:50:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch34_loss0.16460837796330452.pypots
2024-05-24 23:50:50 [INFO]: Epoch 035 - training loss: 0.1742, validation loss: 0.1575
2024-05-24 23:50:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch35_loss0.15747448056936264.pypots
2024-05-24 23:50:52 [INFO]: Epoch 036 - training loss: 0.1696, validation loss: 0.1537
2024-05-24 23:50:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch36_loss0.15370512753725052.pypots
2024-05-24 23:50:54 [INFO]: Epoch 037 - training loss: 0.2480, validation loss: 0.1583
2024-05-24 23:50:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch37_loss0.15831489115953445.pypots
2024-05-24 23:50:56 [INFO]: Epoch 038 - training loss: 0.1570, validation loss: 0.1700
2024-05-24 23:50:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch38_loss0.17002081871032715.pypots
2024-05-24 23:50:58 [INFO]: Epoch 039 - training loss: 0.1662, validation loss: 0.1632
2024-05-24 23:50:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch39_loss0.16320114582777023.pypots
2024-05-24 23:51:00 [INFO]: Epoch 040 - training loss: 0.1528, validation loss: 0.1483
2024-05-24 23:51:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch40_loss0.14834193140268326.pypots
2024-05-24 23:51:02 [INFO]: Epoch 041 - training loss: 0.1860, validation loss: 0.1493
2024-05-24 23:51:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch41_loss0.14930064231157303.pypots
2024-05-24 23:51:04 [INFO]: Epoch 042 - training loss: 0.1727, validation loss: 0.1468
2024-05-24 23:51:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch42_loss0.14681947231292725.pypots
2024-05-24 23:51:06 [INFO]: Epoch 043 - training loss: 0.1605, validation loss: 0.1452
2024-05-24 23:51:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch43_loss0.14521368592977524.pypots
2024-05-24 23:51:08 [INFO]: Epoch 044 - training loss: 0.1934, validation loss: 0.1457
2024-05-24 23:51:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch44_loss0.145663533359766.pypots
2024-05-24 23:51:11 [INFO]: Epoch 045 - training loss: 0.1794, validation loss: 0.1418
2024-05-24 23:51:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch45_loss0.1418055258691311.pypots
2024-05-24 23:51:13 [INFO]: Epoch 046 - training loss: 0.1801, validation loss: 0.1386
2024-05-24 23:51:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch46_loss0.138604573905468.pypots
2024-05-24 23:51:15 [INFO]: Epoch 047 - training loss: 0.1494, validation loss: 0.1629
2024-05-24 23:51:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch47_loss0.16291286051273346.pypots
2024-05-24 23:51:17 [INFO]: Epoch 048 - training loss: 0.1790, validation loss: 0.1538
2024-05-24 23:51:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch48_loss0.1537599302828312.pypots
2024-05-24 23:51:19 [INFO]: Epoch 049 - training loss: 0.2104, validation loss: 0.1621
2024-05-24 23:51:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch49_loss0.16213302314281464.pypots
2024-05-24 23:51:21 [INFO]: Epoch 050 - training loss: 0.1555, validation loss: 0.1575
2024-05-24 23:51:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch50_loss0.1575085110962391.pypots
2024-05-24 23:51:23 [INFO]: Epoch 051 - training loss: 0.1628, validation loss: 0.1491
2024-05-24 23:51:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch51_loss0.149102583527565.pypots
2024-05-24 23:51:25 [INFO]: Epoch 052 - training loss: 0.1904, validation loss: 0.1508
2024-05-24 23:51:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch52_loss0.1508147343993187.pypots
2024-05-24 23:51:27 [INFO]: Epoch 053 - training loss: 0.1593, validation loss: 0.1391
2024-05-24 23:51:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch53_loss0.1390797235071659.pypots
2024-05-24 23:51:29 [INFO]: Epoch 054 - training loss: 0.2241, validation loss: 0.1458
2024-05-24 23:51:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch54_loss0.145778626203537.pypots
2024-05-24 23:51:31 [INFO]: Epoch 055 - training loss: 0.1486, validation loss: 0.1398
2024-05-24 23:51:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch55_loss0.1398438848555088.pypots
2024-05-24 23:51:33 [INFO]: Epoch 056 - training loss: 0.1631, validation loss: 0.1403
2024-05-24 23:51:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI_epoch56_loss0.1402789242565632.pypots
2024-05-24 23:51:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:51:33 [INFO]: Finished training. The best model is from epoch#46.
2024-05-24 23:51:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240524_T234937/CSDI.pypots
2024-05-24 23:51:49 [INFO]: CSDI on ETTm1: MAE=0.1337, MSE=0.0490
2024-05-24 23:51:49 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/CSDI_ettm1/imputation.pkl
2024-05-24 23:51:49 [INFO]: Using the given device: cuda:0
2024-05-24 23:51:49 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/GPVAE_ettm1/20240524_T235149
2024-05-24 23:51:49 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/GPVAE_ettm1/20240524_T235149/tensorboard
2024-05-24 23:51:49 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 23:51:50 [INFO]: Epoch 001 - training loss: 23454.2817, validation loss: 0.9592
2024-05-24 23:51:50 [INFO]: Epoch 002 - training loss: 21233.5240, validation loss: 0.9587
2024-05-24 23:51:50 [INFO]: Epoch 003 - training loss: 18959.9403, validation loss: 0.9394
2024-05-24 23:51:50 [INFO]: Epoch 004 - training loss: 16938.2261, validation loss: 0.8921
2024-05-24 23:51:50 [INFO]: Epoch 005 - training loss: 15011.5257, validation loss: 0.7921
2024-05-24 23:51:50 [INFO]: Epoch 006 - training loss: 13499.5513, validation loss: 0.6761
2024-05-24 23:51:50 [INFO]: Epoch 007 - training loss: 12635.5359, validation loss: 0.5843
2024-05-24 23:51:50 [INFO]: Epoch 008 - training loss: 11603.7130, validation loss: 0.4959
2024-05-24 23:51:51 [INFO]: Epoch 009 - training loss: 11261.2328, validation loss: 0.4565
2024-05-24 23:51:51 [INFO]: Epoch 010 - training loss: 10822.7977, validation loss: 0.4372
2024-05-24 23:51:51 [INFO]: Epoch 011 - training loss: 10712.0646, validation loss: 0.4216
2024-05-24 23:51:51 [INFO]: Epoch 012 - training loss: 10352.6317, validation loss: 0.4067
2024-05-24 23:51:51 [INFO]: Epoch 013 - training loss: 10173.2088, validation loss: 0.3849
2024-05-24 23:51:51 [INFO]: Epoch 014 - training loss: 10053.8568, validation loss: 0.3596
2024-05-24 23:51:51 [INFO]: Epoch 015 - training loss: 9950.7977, validation loss: 0.3407
2024-05-24 23:51:51 [INFO]: Epoch 016 - training loss: 9983.2478, validation loss: 0.3250
2024-05-24 23:51:52 [INFO]: Epoch 017 - training loss: 9852.6078, validation loss: 0.3126
2024-05-24 23:51:52 [INFO]: Epoch 018 - training loss: 9783.9487, validation loss: 0.2993
2024-05-24 23:51:52 [INFO]: Epoch 019 - training loss: 9720.7799, validation loss: 0.2842
2024-05-24 23:51:52 [INFO]: Epoch 020 - training loss: 9708.7640, validation loss: 0.2744
2024-05-24 23:51:52 [INFO]: Epoch 021 - training loss: 9654.2947, validation loss: 0.2675
2024-05-24 23:51:52 [INFO]: Epoch 022 - training loss: 9623.0634, validation loss: 0.2553
2024-05-24 23:51:52 [INFO]: Epoch 023 - training loss: 9599.8338, validation loss: 0.2490
2024-05-24 23:51:52 [INFO]: Epoch 024 - training loss: 9573.2852, validation loss: 0.2354
2024-05-24 23:51:53 [INFO]: Epoch 025 - training loss: 9562.0483, validation loss: 0.2243
2024-05-24 23:51:53 [INFO]: Epoch 026 - training loss: 9540.7723, validation loss: 0.2126
2024-05-24 23:51:53 [INFO]: Epoch 027 - training loss: 9525.3723, validation loss: 0.2043
2024-05-24 23:51:53 [INFO]: Epoch 028 - training loss: 9533.4995, validation loss: 0.1956
2024-05-24 23:51:53 [INFO]: Epoch 029 - training loss: 9527.6384, validation loss: 0.1869
2024-05-24 23:51:53 [INFO]: Epoch 030 - training loss: 9486.2955, validation loss: 0.1840
2024-05-24 23:51:53 [INFO]: Epoch 031 - training loss: 9480.3793, validation loss: 0.1737
2024-05-24 23:51:54 [INFO]: Epoch 032 - training loss: 9490.3442, validation loss: 0.1700
2024-05-24 23:51:54 [INFO]: Epoch 033 - training loss: 9458.5073, validation loss: 0.1639
2024-05-24 23:51:54 [INFO]: Epoch 034 - training loss: 9444.7763, validation loss: 0.1600
2024-05-24 23:51:54 [INFO]: Epoch 035 - training loss: 9433.2390, validation loss: 0.1591
2024-05-24 23:51:54 [INFO]: Epoch 036 - training loss: 9436.0791, validation loss: 0.1578
2024-05-24 23:51:54 [INFO]: Epoch 037 - training loss: 9421.9225, validation loss: 0.1537
2024-05-24 23:51:54 [INFO]: Epoch 038 - training loss: 9428.8433, validation loss: 0.1487
2024-05-24 23:51:54 [INFO]: Epoch 039 - training loss: 9416.5947, validation loss: 0.1484
2024-05-24 23:51:55 [INFO]: Epoch 040 - training loss: 9401.7691, validation loss: 0.1433
2024-05-24 23:51:55 [INFO]: Epoch 041 - training loss: 9399.2637, validation loss: 0.1427
2024-05-24 23:51:55 [INFO]: Epoch 042 - training loss: 9397.2784, validation loss: 0.1428
2024-05-24 23:51:55 [INFO]: Epoch 043 - training loss: 9402.2664, validation loss: 0.1415
2024-05-24 23:51:55 [INFO]: Epoch 044 - training loss: 9387.2236, validation loss: 0.1375
2024-05-24 23:51:55 [INFO]: Epoch 045 - training loss: 9389.2943, validation loss: 0.1377
2024-05-24 23:51:55 [INFO]: Epoch 046 - training loss: 9381.8642, validation loss: 0.1334
2024-05-24 23:51:55 [INFO]: Epoch 047 - training loss: 9378.8753, validation loss: 0.1347
2024-05-24 23:51:56 [INFO]: Epoch 048 - training loss: 9381.0712, validation loss: 0.1318
2024-05-24 23:51:56 [INFO]: Epoch 049 - training loss: 9373.4815, validation loss: 0.1272
2024-05-24 23:51:56 [INFO]: Epoch 050 - training loss: 9370.3806, validation loss: 0.1296
2024-05-24 23:51:56 [INFO]: Epoch 051 - training loss: 9367.2888, validation loss: 0.1260
2024-05-24 23:51:56 [INFO]: Epoch 052 - training loss: 9369.5743, validation loss: 0.1269
2024-05-24 23:51:56 [INFO]: Epoch 053 - training loss: 9363.2972, validation loss: 0.1237
2024-05-24 23:51:56 [INFO]: Epoch 054 - training loss: 9364.6531, validation loss: 0.1228
2024-05-24 23:51:56 [INFO]: Epoch 055 - training loss: 9358.4167, validation loss: 0.1223
2024-05-24 23:51:57 [INFO]: Epoch 056 - training loss: 9359.2338, validation loss: 0.1234
2024-05-24 23:51:57 [INFO]: Epoch 057 - training loss: 9355.7538, validation loss: 0.1198
2024-05-24 23:51:57 [INFO]: Epoch 058 - training loss: 9360.2683, validation loss: 0.1175
2024-05-24 23:51:57 [INFO]: Epoch 059 - training loss: 9352.2473, validation loss: 0.1185
2024-05-24 23:51:57 [INFO]: Epoch 060 - training loss: 9350.9083, validation loss: 0.1161
2024-05-24 23:51:57 [INFO]: Epoch 061 - training loss: 9353.4559, validation loss: 0.1171
2024-05-24 23:51:57 [INFO]: Epoch 062 - training loss: 9347.8438, validation loss: 0.1164
2024-05-24 23:51:58 [INFO]: Epoch 063 - training loss: 9347.6023, validation loss: 0.1153
2024-05-24 23:51:58 [INFO]: Epoch 064 - training loss: 9343.3605, validation loss: 0.1132
2024-05-24 23:51:58 [INFO]: Epoch 065 - training loss: 9344.3972, validation loss: 0.1130
2024-05-24 23:51:58 [INFO]: Epoch 066 - training loss: 9342.9645, validation loss: 0.1121
2024-05-24 23:51:58 [INFO]: Epoch 067 - training loss: 9347.4086, validation loss: 0.1123
2024-05-24 23:51:58 [INFO]: Epoch 068 - training loss: 9339.9468, validation loss: 0.1122
2024-05-24 23:51:58 [INFO]: Epoch 069 - training loss: 9338.7100, validation loss: 0.1107
2024-05-24 23:51:58 [INFO]: Epoch 070 - training loss: 9337.6256, validation loss: 0.1100
2024-05-24 23:51:59 [INFO]: Epoch 071 - training loss: 9340.5254, validation loss: 0.1088
2024-05-24 23:51:59 [INFO]: Epoch 072 - training loss: 9336.4759, validation loss: 0.1080
2024-05-24 23:51:59 [INFO]: Epoch 073 - training loss: 9335.4727, validation loss: 0.1072
2024-05-24 23:51:59 [INFO]: Epoch 074 - training loss: 9336.2469, validation loss: 0.1075
2024-05-24 23:51:59 [INFO]: Epoch 075 - training loss: 9335.6732, validation loss: 0.1061
2024-05-24 23:51:59 [INFO]: Epoch 076 - training loss: 9334.5630, validation loss: 0.1042
2024-05-24 23:51:59 [INFO]: Epoch 077 - training loss: 9332.2642, validation loss: 0.1056
2024-05-24 23:51:59 [INFO]: Epoch 078 - training loss: 9335.0856, validation loss: 0.1053
2024-05-24 23:52:00 [INFO]: Epoch 079 - training loss: 9331.6613, validation loss: 0.1039
2024-05-24 23:52:00 [INFO]: Epoch 080 - training loss: 9332.6078, validation loss: 0.1042
2024-05-24 23:52:00 [INFO]: Epoch 081 - training loss: 9331.2763, validation loss: 0.1034
2024-05-24 23:52:00 [INFO]: Epoch 082 - training loss: 9330.3996, validation loss: 0.1018
2024-05-24 23:52:00 [INFO]: Epoch 083 - training loss: 9330.9771, validation loss: 0.1023
2024-05-24 23:52:00 [INFO]: Epoch 084 - training loss: 9329.2758, validation loss: 0.1033
2024-05-24 23:52:00 [INFO]: Epoch 085 - training loss: 9330.5834, validation loss: 0.1003
2024-05-24 23:52:01 [INFO]: Epoch 086 - training loss: 9326.0832, validation loss: 0.1008
2024-05-24 23:52:01 [INFO]: Epoch 087 - training loss: 9326.5238, validation loss: 0.1001
2024-05-24 23:52:01 [INFO]: Epoch 088 - training loss: 9325.0596, validation loss: 0.1001
2024-05-24 23:52:01 [INFO]: Epoch 089 - training loss: 9327.9449, validation loss: 0.0980
2024-05-24 23:52:01 [INFO]: Epoch 090 - training loss: 9324.6118, validation loss: 0.0992
2024-05-24 23:52:01 [INFO]: Epoch 091 - training loss: 9325.0287, validation loss: 0.0995
2024-05-24 23:52:01 [INFO]: Epoch 092 - training loss: 9323.4766, validation loss: 0.0977
2024-05-24 23:52:01 [INFO]: Epoch 093 - training loss: 9322.9882, validation loss: 0.0976
2024-05-24 23:52:02 [INFO]: Epoch 094 - training loss: 9324.4658, validation loss: 0.0971
2024-05-24 23:52:02 [INFO]: Epoch 095 - training loss: 9322.6299, validation loss: 0.0967
2024-05-24 23:52:02 [INFO]: Epoch 096 - training loss: 9322.5699, validation loss: 0.0939
2024-05-24 23:52:02 [INFO]: Epoch 097 - training loss: 9324.0403, validation loss: 0.0985
2024-05-24 23:52:02 [INFO]: Epoch 098 - training loss: 9321.5480, validation loss: 0.0959
2024-05-24 23:52:02 [INFO]: Epoch 099 - training loss: 9325.8860, validation loss: 0.0959
2024-05-24 23:52:02 [INFO]: Epoch 100 - training loss: 9321.8218, validation loss: 0.0940
2024-05-24 23:52:02 [INFO]: Epoch 101 - training loss: 9319.7278, validation loss: 0.0938
2024-05-24 23:52:03 [INFO]: Epoch 102 - training loss: 9319.0952, validation loss: 0.0937
2024-05-24 23:52:03 [INFO]: Epoch 103 - training loss: 9320.7565, validation loss: 0.0927
2024-05-24 23:52:03 [INFO]: Epoch 104 - training loss: 9318.1170, validation loss: 0.0933
2024-05-24 23:52:03 [INFO]: Epoch 105 - training loss: 9318.6579, validation loss: 0.0935
2024-05-24 23:52:03 [INFO]: Epoch 106 - training loss: 9318.2417, validation loss: 0.0918
2024-05-24 23:52:03 [INFO]: Epoch 107 - training loss: 9318.5012, validation loss: 0.0920
2024-05-24 23:52:03 [INFO]: Epoch 108 - training loss: 9315.9836, validation loss: 0.0912
2024-05-24 23:52:04 [INFO]: Epoch 109 - training loss: 9316.6695, validation loss: 0.0903
2024-05-24 23:52:04 [INFO]: Epoch 110 - training loss: 9316.4760, validation loss: 0.0906
2024-05-24 23:52:04 [INFO]: Epoch 111 - training loss: 9315.5739, validation loss: 0.0886
2024-05-24 23:52:04 [INFO]: Epoch 112 - training loss: 9316.7308, validation loss: 0.0910
2024-05-24 23:52:04 [INFO]: Epoch 113 - training loss: 9316.3949, validation loss: 0.0886
2024-05-24 23:52:04 [INFO]: Epoch 114 - training loss: 9316.4800, validation loss: 0.0909
2024-05-24 23:52:04 [INFO]: Epoch 115 - training loss: 9315.0752, validation loss: 0.0921
2024-05-24 23:52:04 [INFO]: Epoch 116 - training loss: 9315.3954, validation loss: 0.0889
2024-05-24 23:52:05 [INFO]: Epoch 117 - training loss: 9314.9383, validation loss: 0.0882
2024-05-24 23:52:05 [INFO]: Epoch 118 - training loss: 9315.1678, validation loss: 0.0883
2024-05-24 23:52:05 [INFO]: Epoch 119 - training loss: 9315.1798, validation loss: 0.0877
2024-05-24 23:52:05 [INFO]: Epoch 120 - training loss: 9314.6689, validation loss: 0.0869
2024-05-24 23:52:05 [INFO]: Epoch 121 - training loss: 9314.5754, validation loss: 0.0868
2024-05-24 23:52:05 [INFO]: Epoch 122 - training loss: 9314.2292, validation loss: 0.0860
2024-05-24 23:52:05 [INFO]: Epoch 123 - training loss: 9313.1731, validation loss: 0.0870
2024-05-24 23:52:05 [INFO]: Epoch 124 - training loss: 9313.0972, validation loss: 0.0858
2024-05-24 23:52:06 [INFO]: Epoch 125 - training loss: 9314.9940, validation loss: 0.0855
2024-05-24 23:52:06 [INFO]: Epoch 126 - training loss: 9314.0730, validation loss: 0.0864
2024-05-24 23:52:06 [INFO]: Epoch 127 - training loss: 9312.2668, validation loss: 0.0835
2024-05-24 23:52:06 [INFO]: Epoch 128 - training loss: 9312.0092, validation loss: 0.0854
2024-05-24 23:52:06 [INFO]: Epoch 129 - training loss: 9311.4355, validation loss: 0.0844
2024-05-24 23:52:06 [INFO]: Epoch 130 - training loss: 9311.0661, validation loss: 0.0855
2024-05-24 23:52:06 [INFO]: Epoch 131 - training loss: 9311.5797, validation loss: 0.0843
2024-05-24 23:52:07 [INFO]: Epoch 132 - training loss: 9312.9660, validation loss: 0.0824
2024-05-24 23:52:07 [INFO]: Epoch 133 - training loss: 9312.1313, validation loss: 0.0851
2024-05-24 23:52:07 [INFO]: Epoch 134 - training loss: 9312.0917, validation loss: 0.0823
2024-05-24 23:52:07 [INFO]: Epoch 135 - training loss: 9311.5474, validation loss: 0.0848
2024-05-24 23:52:07 [INFO]: Epoch 136 - training loss: 9314.2743, validation loss: 0.0832
2024-05-24 23:52:07 [INFO]: Epoch 137 - training loss: 9310.5889, validation loss: 0.0863
2024-05-24 23:52:07 [INFO]: Epoch 138 - training loss: 9311.7331, validation loss: 0.0836
2024-05-24 23:52:07 [INFO]: Epoch 139 - training loss: 9311.2534, validation loss: 0.0819
2024-05-24 23:52:08 [INFO]: Epoch 140 - training loss: 9311.8539, validation loss: 0.0820
2024-05-24 23:52:08 [INFO]: Epoch 141 - training loss: 9312.3776, validation loss: 0.0831
2024-05-24 23:52:08 [INFO]: Epoch 142 - training loss: 9311.1902, validation loss: 0.0826
2024-05-24 23:52:08 [INFO]: Epoch 143 - training loss: 9310.3538, validation loss: 0.0803
2024-05-24 23:52:08 [INFO]: Epoch 144 - training loss: 9309.4802, validation loss: 0.0816
2024-05-24 23:52:08 [INFO]: Epoch 145 - training loss: 9311.0915, validation loss: 0.0807
2024-05-24 23:52:08 [INFO]: Epoch 146 - training loss: 9312.3104, validation loss: 0.0812
2024-05-24 23:52:08 [INFO]: Epoch 147 - training loss: 9308.8405, validation loss: 0.0814
2024-05-24 23:52:09 [INFO]: Epoch 148 - training loss: 9309.1980, validation loss: 0.0794
2024-05-24 23:52:09 [INFO]: Epoch 149 - training loss: 9309.7163, validation loss: 0.0812
2024-05-24 23:52:09 [INFO]: Epoch 150 - training loss: 9311.1202, validation loss: 0.0799
2024-05-24 23:52:09 [INFO]: Epoch 151 - training loss: 9307.3430, validation loss: 0.0791
2024-05-24 23:52:09 [INFO]: Epoch 152 - training loss: 9307.9479, validation loss: 0.0798
2024-05-24 23:52:09 [INFO]: Epoch 153 - training loss: 9308.2155, validation loss: 0.0792
2024-05-24 23:52:09 [INFO]: Epoch 154 - training loss: 9308.0673, validation loss: 0.0787
2024-05-24 23:52:09 [INFO]: Epoch 155 - training loss: 9306.8017, validation loss: 0.0789
2024-05-24 23:52:10 [INFO]: Epoch 156 - training loss: 9307.7750, validation loss: 0.0777
2024-05-24 23:52:10 [INFO]: Epoch 157 - training loss: 9307.9676, validation loss: 0.0786
2024-05-24 23:52:10 [INFO]: Epoch 158 - training loss: 9307.7913, validation loss: 0.0790
2024-05-24 23:52:10 [INFO]: Epoch 159 - training loss: 9308.2393, validation loss: 0.0803
2024-05-24 23:52:10 [INFO]: Epoch 160 - training loss: 9308.7802, validation loss: 0.0803
2024-05-24 23:52:10 [INFO]: Epoch 161 - training loss: 9307.6634, validation loss: 0.0786
2024-05-24 23:52:10 [INFO]: Epoch 162 - training loss: 9308.1719, validation loss: 0.0783
2024-05-24 23:52:11 [INFO]: Epoch 163 - training loss: 9308.0780, validation loss: 0.0770
2024-05-24 23:52:11 [INFO]: Epoch 164 - training loss: 9306.5906, validation loss: 0.0792
2024-05-24 23:52:11 [INFO]: Epoch 165 - training loss: 9306.7598, validation loss: 0.0776
2024-05-24 23:52:11 [INFO]: Epoch 166 - training loss: 9307.5486, validation loss: 0.0773
2024-05-24 23:52:11 [INFO]: Epoch 167 - training loss: 9306.6832, validation loss: 0.0772
2024-05-24 23:52:11 [INFO]: Epoch 168 - training loss: 9307.9841, validation loss: 0.0770
2024-05-24 23:52:11 [INFO]: Epoch 169 - training loss: 9306.4035, validation loss: 0.0765
2024-05-24 23:52:11 [INFO]: Epoch 170 - training loss: 9307.8095, validation loss: 0.0757
2024-05-24 23:52:12 [INFO]: Epoch 171 - training loss: 9306.9947, validation loss: 0.0773
2024-05-24 23:52:12 [INFO]: Epoch 172 - training loss: 9306.4713, validation loss: 0.0794
2024-05-24 23:52:12 [INFO]: Epoch 173 - training loss: 9306.2582, validation loss: 0.0756
2024-05-24 23:52:12 [INFO]: Epoch 174 - training loss: 9306.5596, validation loss: 0.0761
2024-05-24 23:52:12 [INFO]: Epoch 175 - training loss: 9306.2650, validation loss: 0.0769
2024-05-24 23:52:12 [INFO]: Epoch 176 - training loss: 9304.7678, validation loss: 0.0761
2024-05-24 23:52:12 [INFO]: Epoch 177 - training loss: 9307.2133, validation loss: 0.0767
2024-05-24 23:52:12 [INFO]: Epoch 178 - training loss: 9305.2960, validation loss: 0.0759
2024-05-24 23:52:13 [INFO]: Epoch 179 - training loss: 9306.0762, validation loss: 0.0745
2024-05-24 23:52:13 [INFO]: Epoch 180 - training loss: 9305.7981, validation loss: 0.0763
2024-05-24 23:52:13 [INFO]: Epoch 181 - training loss: 9305.6458, validation loss: 0.0756
2024-05-24 23:52:13 [INFO]: Epoch 182 - training loss: 9305.4023, validation loss: 0.0747
2024-05-24 23:52:13 [INFO]: Epoch 183 - training loss: 9306.4694, validation loss: 0.0762
2024-05-24 23:52:13 [INFO]: Epoch 184 - training loss: 9305.3075, validation loss: 0.0777
2024-05-24 23:52:13 [INFO]: Epoch 185 - training loss: 9305.6425, validation loss: 0.0752
2024-05-24 23:52:14 [INFO]: Epoch 186 - training loss: 9304.1978, validation loss: 0.0760
2024-05-24 23:52:14 [INFO]: Epoch 187 - training loss: 9305.2220, validation loss: 0.0748
2024-05-24 23:52:14 [INFO]: Epoch 188 - training loss: 9304.3696, validation loss: 0.0748
2024-05-24 23:52:14 [INFO]: Epoch 189 - training loss: 9304.8825, validation loss: 0.0767
2024-05-24 23:52:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:52:14 [INFO]: Finished training. The best model is from epoch#179.
2024-05-24 23:52:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/GPVAE_ettm1/20240524_T235149/GPVAE.pypots
2024-05-24 23:52:14 [INFO]: GP-VAE on ETTm1: MAE=0.2692, MSE=0.1532
2024-05-24 23:52:14 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/GPVAE_ettm1/imputation.pkl
2024-05-24 23:52:14 [INFO]: Using the given device: cuda:0
2024-05-24 23:52:14 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/USGAN_ettm1/20240524_T235214
2024-05-24 23:52:14 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/USGAN_ettm1/20240524_T235214/tensorboard
2024-05-24 23:52:14 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 23:52:25 [INFO]: Epoch 001 - generator training loss: 0.6151, discriminator training loss: 0.3388, validation loss: 0.3895
2024-05-24 23:52:34 [INFO]: Epoch 002 - generator training loss: 0.0539, discriminator training loss: 0.2114, validation loss: 0.1061
2024-05-24 23:52:43 [INFO]: Epoch 003 - generator training loss: -0.0579, discriminator training loss: 0.2016, validation loss: 0.0606
2024-05-24 23:52:52 [INFO]: Epoch 004 - generator training loss: -0.0799, discriminator training loss: 0.1971, validation loss: 0.0511
2024-05-24 23:53:01 [INFO]: Epoch 005 - generator training loss: -0.0819, discriminator training loss: 0.1937, validation loss: 0.0466
2024-05-24 23:53:10 [INFO]: Epoch 006 - generator training loss: -0.0832, discriminator training loss: 0.1896, validation loss: 0.0430
2024-05-24 23:53:19 [INFO]: Epoch 007 - generator training loss: -0.0783, discriminator training loss: 0.1815, validation loss: 0.0405
2024-05-24 23:53:28 [INFO]: Epoch 008 - generator training loss: -0.0712, discriminator training loss: 0.1711, validation loss: 0.0394
2024-05-24 23:53:36 [INFO]: Epoch 009 - generator training loss: -0.0624, discriminator training loss: 0.1595, validation loss: 0.0383
2024-05-24 23:53:46 [INFO]: Epoch 010 - generator training loss: -0.0449, discriminator training loss: 0.1409, validation loss: 0.0374
2024-05-24 23:53:54 [INFO]: Epoch 011 - generator training loss: -0.0343, discriminator training loss: 0.1239, validation loss: 0.0365
2024-05-24 23:54:03 [INFO]: Epoch 012 - generator training loss: -0.0248, discriminator training loss: 0.1106, validation loss: 0.0361
2024-05-24 23:54:12 [INFO]: Epoch 013 - generator training loss: -0.0173, discriminator training loss: 0.1015, validation loss: 0.0354
2024-05-24 23:54:21 [INFO]: Epoch 014 - generator training loss: -0.0195, discriminator training loss: 0.0963, validation loss: 0.0347
2024-05-24 23:54:30 [INFO]: Epoch 015 - generator training loss: -0.0140, discriminator training loss: 0.0907, validation loss: 0.0349
2024-05-24 23:54:39 [INFO]: Epoch 016 - generator training loss: -0.0117, discriminator training loss: 0.0873, validation loss: 0.0342
2024-05-24 23:54:48 [INFO]: Epoch 017 - generator training loss: -0.0077, discriminator training loss: 0.0848, validation loss: 0.0368
2024-05-24 23:54:57 [INFO]: Epoch 018 - generator training loss: -0.0124, discriminator training loss: 0.0841, validation loss: 0.0342
2024-05-24 23:55:07 [INFO]: Epoch 019 - generator training loss: -0.0086, discriminator training loss: 0.0783, validation loss: 0.0336
2024-05-24 23:55:16 [INFO]: Epoch 020 - generator training loss: -0.0104, discriminator training loss: 0.0783, validation loss: 0.0331
2024-05-24 23:55:25 [INFO]: Epoch 021 - generator training loss: -0.0102, discriminator training loss: 0.0774, validation loss: 0.0327
2024-05-24 23:55:34 [INFO]: Epoch 022 - generator training loss: -0.0106, discriminator training loss: 0.0759, validation loss: 0.0324
2024-05-24 23:55:43 [INFO]: Epoch 023 - generator training loss: -0.0114, discriminator training loss: 0.0759, validation loss: 0.0319
2024-05-24 23:55:52 [INFO]: Epoch 024 - generator training loss: -0.0110, discriminator training loss: 0.0751, validation loss: 0.0323
2024-05-24 23:56:01 [INFO]: Epoch 025 - generator training loss: -0.0112, discriminator training loss: 0.0749, validation loss: 0.0318
2024-05-24 23:56:09 [INFO]: Epoch 026 - generator training loss: -0.0149, discriminator training loss: 0.0769, validation loss: 0.0315
2024-05-24 23:56:18 [INFO]: Epoch 027 - generator training loss: -0.0090, discriminator training loss: 0.0734, validation loss: 0.0312
2024-05-24 23:56:27 [INFO]: Epoch 028 - generator training loss: -0.0114, discriminator training loss: 0.0757, validation loss: 0.0308
2024-05-24 23:56:36 [INFO]: Epoch 029 - generator training loss: -0.0137, discriminator training loss: 0.0743, validation loss: 0.0309
2024-05-24 23:56:45 [INFO]: Epoch 030 - generator training loss: -0.0144, discriminator training loss: 0.0742, validation loss: 0.0303
2024-05-24 23:56:54 [INFO]: Epoch 031 - generator training loss: -0.0104, discriminator training loss: 0.0726, validation loss: 0.0301
2024-05-24 23:57:03 [INFO]: Epoch 032 - generator training loss: -0.0129, discriminator training loss: 0.0730, validation loss: 0.0301
2024-05-24 23:57:12 [INFO]: Epoch 033 - generator training loss: -0.0114, discriminator training loss: 0.0733, validation loss: 0.0302
2024-05-24 23:57:21 [INFO]: Epoch 034 - generator training loss: -0.0134, discriminator training loss: 0.0729, validation loss: 0.0296
2024-05-24 23:57:30 [INFO]: Epoch 035 - generator training loss: -0.0181, discriminator training loss: 0.0744, validation loss: 0.0296
2024-05-24 23:57:39 [INFO]: Epoch 036 - generator training loss: -0.0121, discriminator training loss: 0.0713, validation loss: 0.0289
2024-05-24 23:57:48 [INFO]: Epoch 037 - generator training loss: -0.0147, discriminator training loss: 0.0709, validation loss: 0.0291
2024-05-24 23:57:57 [INFO]: Epoch 038 - generator training loss: -0.0149, discriminator training loss: 0.0717, validation loss: 0.0295
2024-05-24 23:58:06 [INFO]: Epoch 039 - generator training loss: -0.0160, discriminator training loss: 0.0737, validation loss: 0.0291
2024-05-24 23:58:15 [INFO]: Epoch 040 - generator training loss: -0.0147, discriminator training loss: 0.0718, validation loss: 0.0285
2024-05-24 23:58:24 [INFO]: Epoch 041 - generator training loss: -0.0177, discriminator training loss: 0.0722, validation loss: 0.0279
2024-05-24 23:58:33 [INFO]: Epoch 042 - generator training loss: -0.0120, discriminator training loss: 0.0716, validation loss: 0.0289
2024-05-24 23:58:42 [INFO]: Epoch 043 - generator training loss: -0.0183, discriminator training loss: 0.0711, validation loss: 0.0282
2024-05-24 23:58:51 [INFO]: Epoch 044 - generator training loss: -0.0172, discriminator training loss: 0.0705, validation loss: 0.0282
2024-05-24 23:59:00 [INFO]: Epoch 045 - generator training loss: -0.0162, discriminator training loss: 0.0707, validation loss: 0.0284
2024-05-24 23:59:08 [INFO]: Epoch 046 - generator training loss: -0.0201, discriminator training loss: 0.0712, validation loss: 0.0270
2024-05-24 23:59:17 [INFO]: Epoch 047 - generator training loss: -0.0183, discriminator training loss: 0.0705, validation loss: 0.0264
2024-05-24 23:59:26 [INFO]: Epoch 048 - generator training loss: -0.0182, discriminator training loss: 0.0712, validation loss: 0.0267
2024-05-24 23:59:35 [INFO]: Epoch 049 - generator training loss: -0.0184, discriminator training loss: 0.0691, validation loss: 0.0258
2024-05-24 23:59:44 [INFO]: Epoch 050 - generator training loss: -0.0180, discriminator training loss: 0.0699, validation loss: 0.0265
2024-05-24 23:59:53 [INFO]: Epoch 051 - generator training loss: -0.0181, discriminator training loss: 0.0697, validation loss: 0.0257
2024-05-25 00:00:02 [INFO]: Epoch 052 - generator training loss: -0.0175, discriminator training loss: 0.0684, validation loss: 0.0262
2024-05-25 00:00:10 [INFO]: Epoch 053 - generator training loss: -0.0165, discriminator training loss: 0.0686, validation loss: 0.0257
2024-05-25 00:00:19 [INFO]: Epoch 054 - generator training loss: -0.0207, discriminator training loss: 0.0692, validation loss: 0.0254
2024-05-25 00:00:28 [INFO]: Epoch 055 - generator training loss: -0.0173, discriminator training loss: 0.0692, validation loss: 0.0245
2024-05-25 00:00:37 [INFO]: Epoch 056 - generator training loss: -0.0180, discriminator training loss: 0.0681, validation loss: 0.0255
2024-05-25 00:00:46 [INFO]: Epoch 057 - generator training loss: -0.0201, discriminator training loss: 0.0702, validation loss: 0.0253
2024-05-25 00:00:55 [INFO]: Epoch 058 - generator training loss: -0.0190, discriminator training loss: 0.0699, validation loss: 0.0242
2024-05-25 00:01:04 [INFO]: Epoch 059 - generator training loss: -0.0200, discriminator training loss: 0.0688, validation loss: 0.0255
2024-05-25 00:01:13 [INFO]: Epoch 060 - generator training loss: -0.0179, discriminator training loss: 0.0666, validation loss: 0.0241
2024-05-25 00:01:22 [INFO]: Epoch 061 - generator training loss: -0.0210, discriminator training loss: 0.0714, validation loss: 0.0239
2024-05-25 00:01:31 [INFO]: Epoch 062 - generator training loss: -0.0176, discriminator training loss: 0.0690, validation loss: 0.0238
2024-05-25 00:01:40 [INFO]: Epoch 063 - generator training loss: -0.0213, discriminator training loss: 0.0682, validation loss: 0.0239
2024-05-25 00:01:49 [INFO]: Epoch 064 - generator training loss: -0.0206, discriminator training loss: 0.0672, validation loss: 0.0233
2024-05-25 00:01:58 [INFO]: Epoch 065 - generator training loss: -0.0199, discriminator training loss: 0.0680, validation loss: 0.0236
2024-05-25 00:02:08 [INFO]: Epoch 066 - generator training loss: -0.0207, discriminator training loss: 0.0694, validation loss: 0.0237
2024-05-25 00:02:16 [INFO]: Epoch 067 - generator training loss: -0.0205, discriminator training loss: 0.0672, validation loss: 0.0234
2024-05-25 00:02:25 [INFO]: Epoch 068 - generator training loss: -0.0213, discriminator training loss: 0.0665, validation loss: 0.0229
2024-05-25 00:02:34 [INFO]: Epoch 069 - generator training loss: -0.0200, discriminator training loss: 0.0684, validation loss: 0.0231
2024-05-25 00:02:43 [INFO]: Epoch 070 - generator training loss: -0.0203, discriminator training loss: 0.0700, validation loss: 0.0239
2024-05-25 00:02:53 [INFO]: Epoch 071 - generator training loss: -0.0220, discriminator training loss: 0.0709, validation loss: 0.0230
2024-05-25 00:03:02 [INFO]: Epoch 072 - generator training loss: -0.0200, discriminator training loss: 0.0679, validation loss: 0.0229
2024-05-25 00:03:10 [INFO]: Epoch 073 - generator training loss: -0.0222, discriminator training loss: 0.0687, validation loss: 0.0246
2024-05-25 00:03:19 [INFO]: Epoch 074 - generator training loss: -0.0204, discriminator training loss: 0.0681, validation loss: 0.0234
2024-05-25 00:03:29 [INFO]: Epoch 075 - generator training loss: -0.0223, discriminator training loss: 0.0665, validation loss: 0.0229
2024-05-25 00:03:38 [INFO]: Epoch 076 - generator training loss: -0.0213, discriminator training loss: 0.0687, validation loss: 0.0231
2024-05-25 00:03:47 [INFO]: Epoch 077 - generator training loss: -0.0232, discriminator training loss: 0.0694, validation loss: 0.0225
2024-05-25 00:03:56 [INFO]: Epoch 078 - generator training loss: -0.0198, discriminator training loss: 0.0690, validation loss: 0.0224
2024-05-25 00:04:05 [INFO]: Epoch 079 - generator training loss: -0.0207, discriminator training loss: 0.0679, validation loss: 0.0230
2024-05-25 00:04:14 [INFO]: Epoch 080 - generator training loss: -0.0216, discriminator training loss: 0.0661, validation loss: 0.0224
2024-05-25 00:04:23 [INFO]: Epoch 081 - generator training loss: -0.0226, discriminator training loss: 0.0684, validation loss: 0.0221
2024-05-25 00:04:32 [INFO]: Epoch 082 - generator training loss: -0.0231, discriminator training loss: 0.0684, validation loss: 0.0223
2024-05-25 00:04:41 [INFO]: Epoch 083 - generator training loss: -0.0230, discriminator training loss: 0.0669, validation loss: 0.0221
2024-05-25 00:04:50 [INFO]: Epoch 084 - generator training loss: -0.0232, discriminator training loss: 0.0662, validation loss: 0.0257
2024-05-25 00:04:59 [INFO]: Epoch 085 - generator training loss: -0.0168, discriminator training loss: 0.0665, validation loss: 0.0230
2024-05-25 00:05:08 [INFO]: Epoch 086 - generator training loss: -0.0214, discriminator training loss: 0.0675, validation loss: 0.0227
2024-05-25 00:05:17 [INFO]: Epoch 087 - generator training loss: -0.0206, discriminator training loss: 0.0670, validation loss: 0.0220
2024-05-25 00:05:26 [INFO]: Epoch 088 - generator training loss: -0.0229, discriminator training loss: 0.0661, validation loss: 0.0223
2024-05-25 00:05:35 [INFO]: Epoch 089 - generator training loss: -0.0243, discriminator training loss: 0.0667, validation loss: 0.0215
2024-05-25 00:05:44 [INFO]: Epoch 090 - generator training loss: -0.0242, discriminator training loss: 0.0674, validation loss: 0.0213
2024-05-25 00:05:53 [INFO]: Epoch 091 - generator training loss: -0.0240, discriminator training loss: 0.0658, validation loss: 0.0215
2024-05-25 00:06:02 [INFO]: Epoch 092 - generator training loss: -0.0240, discriminator training loss: 0.0683, validation loss: 0.0214
2024-05-25 00:06:11 [INFO]: Epoch 093 - generator training loss: -0.0226, discriminator training loss: 0.0675, validation loss: 0.0211
2024-05-25 00:06:20 [INFO]: Epoch 094 - generator training loss: -0.0228, discriminator training loss: 0.0674, validation loss: 0.0215
2024-05-25 00:06:29 [INFO]: Epoch 095 - generator training loss: -0.0251, discriminator training loss: 0.0669, validation loss: 0.0214
2024-05-25 00:06:38 [INFO]: Epoch 096 - generator training loss: -0.0240, discriminator training loss: 0.0668, validation loss: 0.0211
2024-05-25 00:06:47 [INFO]: Epoch 097 - generator training loss: -0.0251, discriminator training loss: 0.0673, validation loss: 0.0211
2024-05-25 00:06:56 [INFO]: Epoch 098 - generator training loss: -0.0238, discriminator training loss: 0.0694, validation loss: 0.0214
2024-05-25 00:07:05 [INFO]: Epoch 099 - generator training loss: -0.0238, discriminator training loss: 0.0668, validation loss: 0.0211
2024-05-25 00:07:14 [INFO]: Epoch 100 - generator training loss: -0.0260, discriminator training loss: 0.0665, validation loss: 0.0210
2024-05-25 00:07:23 [INFO]: Epoch 101 - generator training loss: -0.0249, discriminator training loss: 0.0664, validation loss: 0.0220
2024-05-25 00:07:32 [INFO]: Epoch 102 - generator training loss: -0.0258, discriminator training loss: 0.0653, validation loss: 0.0209
2024-05-25 00:07:41 [INFO]: Epoch 103 - generator training loss: -0.0233, discriminator training loss: 0.0658, validation loss: 0.0212
2024-05-25 00:07:50 [INFO]: Epoch 104 - generator training loss: -0.0235, discriminator training loss: 0.0653, validation loss: 0.0214
2024-05-25 00:08:00 [INFO]: Epoch 105 - generator training loss: -0.0250, discriminator training loss: 0.0665, validation loss: 0.0208
2024-05-25 00:08:09 [INFO]: Epoch 106 - generator training loss: -0.0242, discriminator training loss: 0.0656, validation loss: 0.0208
2024-05-25 00:08:18 [INFO]: Epoch 107 - generator training loss: -0.0234, discriminator training loss: 0.0654, validation loss: 0.0209
2024-05-25 00:08:27 [INFO]: Epoch 108 - generator training loss: -0.0230, discriminator training loss: 0.0660, validation loss: 0.0209
2024-05-25 00:08:36 [INFO]: Epoch 109 - generator training loss: -0.0262, discriminator training loss: 0.0652, validation loss: 0.0206
2024-05-25 00:08:45 [INFO]: Epoch 110 - generator training loss: -0.0265, discriminator training loss: 0.0677, validation loss: 0.0209
2024-05-25 00:08:54 [INFO]: Epoch 111 - generator training loss: -0.0243, discriminator training loss: 0.0664, validation loss: 0.0209
2024-05-25 00:09:03 [INFO]: Epoch 112 - generator training loss: -0.0247, discriminator training loss: 0.0644, validation loss: 0.0210
2024-05-25 00:09:12 [INFO]: Epoch 113 - generator training loss: -0.0261, discriminator training loss: 0.0667, validation loss: 0.0210
2024-05-25 00:09:21 [INFO]: Epoch 114 - generator training loss: -0.0242, discriminator training loss: 0.0659, validation loss: 0.0208
2024-05-25 00:09:30 [INFO]: Epoch 115 - generator training loss: -0.0253, discriminator training loss: 0.0653, validation loss: 0.0207
2024-05-25 00:09:39 [INFO]: Epoch 116 - generator training loss: -0.0242, discriminator training loss: 0.0648, validation loss: 0.0208
2024-05-25 00:09:48 [INFO]: Epoch 117 - generator training loss: -0.0251, discriminator training loss: 0.0641, validation loss: 0.0204
2024-05-25 00:09:57 [INFO]: Epoch 118 - generator training loss: -0.0266, discriminator training loss: 0.0661, validation loss: 0.0203
2024-05-25 00:10:06 [INFO]: Epoch 119 - generator training loss: -0.0249, discriminator training loss: 0.0665, validation loss: 0.0203
2024-05-25 00:10:15 [INFO]: Epoch 120 - generator training loss: -0.0262, discriminator training loss: 0.0648, validation loss: 0.0204
2024-05-25 00:10:24 [INFO]: Epoch 121 - generator training loss: -0.0256, discriminator training loss: 0.0658, validation loss: 0.0201
2024-05-25 00:10:33 [INFO]: Epoch 122 - generator training loss: -0.0231, discriminator training loss: 0.0647, validation loss: 0.0204
2024-05-25 00:10:42 [INFO]: Epoch 123 - generator training loss: -0.0251, discriminator training loss: 0.0659, validation loss: 0.0202
2024-05-25 00:10:51 [INFO]: Epoch 124 - generator training loss: -0.0269, discriminator training loss: 0.0674, validation loss: 0.0198
2024-05-25 00:11:00 [INFO]: Epoch 125 - generator training loss: -0.0279, discriminator training loss: 0.0667, validation loss: 0.0199
2024-05-25 00:11:09 [INFO]: Epoch 126 - generator training loss: -0.0251, discriminator training loss: 0.0642, validation loss: 0.0196
2024-05-25 00:11:18 [INFO]: Epoch 127 - generator training loss: -0.0254, discriminator training loss: 0.0651, validation loss: 0.0196
2024-05-25 00:11:27 [INFO]: Epoch 128 - generator training loss: -0.0253, discriminator training loss: 0.0654, validation loss: 0.0194
2024-05-25 00:11:36 [INFO]: Epoch 129 - generator training loss: -0.0249, discriminator training loss: 0.0652, validation loss: 0.0194
2024-05-25 00:11:45 [INFO]: Epoch 130 - generator training loss: -0.0249, discriminator training loss: 0.0664, validation loss: 0.0194
2024-05-25 00:11:54 [INFO]: Epoch 131 - generator training loss: -0.0255, discriminator training loss: 0.0649, validation loss: 0.0204
2024-05-25 00:12:03 [INFO]: Epoch 132 - generator training loss: -0.0230, discriminator training loss: 0.0674, validation loss: 0.0193
2024-05-25 00:12:12 [INFO]: Epoch 133 - generator training loss: -0.0246, discriminator training loss: 0.0659, validation loss: 0.0186
2024-05-25 00:12:21 [INFO]: Epoch 134 - generator training loss: -0.0259, discriminator training loss: 0.0659, validation loss: 0.0194
2024-05-25 00:12:30 [INFO]: Epoch 135 - generator training loss: -0.0242, discriminator training loss: 0.0635, validation loss: 0.0188
2024-05-25 00:12:39 [INFO]: Epoch 136 - generator training loss: -0.0263, discriminator training loss: 0.0661, validation loss: 0.0189
2024-05-25 00:12:48 [INFO]: Epoch 137 - generator training loss: -0.0233, discriminator training loss: 0.0637, validation loss: 0.0180
2024-05-25 00:12:57 [INFO]: Epoch 138 - generator training loss: -0.0264, discriminator training loss: 0.0660, validation loss: 0.0190
2024-05-25 00:13:06 [INFO]: Epoch 139 - generator training loss: -0.0264, discriminator training loss: 0.0679, validation loss: 0.0186
2024-05-25 00:13:15 [INFO]: Epoch 140 - generator training loss: -0.0255, discriminator training loss: 0.0661, validation loss: 0.0184
2024-05-25 00:13:25 [INFO]: Epoch 141 - generator training loss: -0.0267, discriminator training loss: 0.0656, validation loss: 0.0182
2024-05-25 00:13:33 [INFO]: Epoch 142 - generator training loss: -0.0275, discriminator training loss: 0.0665, validation loss: 0.0181
2024-05-25 00:13:43 [INFO]: Epoch 143 - generator training loss: -0.0266, discriminator training loss: 0.0647, validation loss: 0.0181
2024-05-25 00:13:52 [INFO]: Epoch 144 - generator training loss: -0.0264, discriminator training loss: 0.0659, validation loss: 0.0188
2024-05-25 00:14:01 [INFO]: Epoch 145 - generator training loss: -0.0176, discriminator training loss: 0.0645, validation loss: 0.0216
2024-05-25 00:14:10 [INFO]: Epoch 146 - generator training loss: -0.0229, discriminator training loss: 0.0653, validation loss: 0.0195
2024-05-25 00:14:19 [INFO]: Epoch 147 - generator training loss: -0.0259, discriminator training loss: 0.0659, validation loss: 0.0188
2024-05-25 00:14:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:14:19 [INFO]: Finished training. The best model is from epoch#137.
2024-05-25 00:14:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/USGAN_ettm1/20240524_T235214/USGAN.pypots
2024-05-25 00:14:20 [INFO]: US-GAN on ETTm1: MAE=0.1406, MSE=0.0558
2024-05-25 00:14:20 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/USGAN_ettm1/imputation.pkl
2024-05-25 00:14:20 [INFO]: Using the given device: cuda:0
2024-05-25 00:14:20 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/BRITS_ettm1/20240525_T001420
2024-05-25 00:14:20 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/BRITS_ettm1/20240525_T001420/tensorboard
2024-05-25 00:14:20 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 00:14:28 [INFO]: Epoch 001 - training loss: 1.2740, validation loss: 0.2496
2024-05-25 00:14:34 [INFO]: Epoch 002 - training loss: 0.8395, validation loss: 0.0802
2024-05-25 00:14:40 [INFO]: Epoch 003 - training loss: 0.6826, validation loss: 0.0520
2024-05-25 00:14:46 [INFO]: Epoch 004 - training loss: 0.6178, validation loss: 0.0450
2024-05-25 00:14:52 [INFO]: Epoch 005 - training loss: 0.5772, validation loss: 0.0415
2024-05-25 00:14:58 [INFO]: Epoch 006 - training loss: 0.5516, validation loss: 0.0375
2024-05-25 00:15:04 [INFO]: Epoch 007 - training loss: 0.5190, validation loss: 0.0373
2024-05-25 00:15:10 [INFO]: Epoch 008 - training loss: 0.4998, validation loss: 0.0356
2024-05-25 00:15:16 [INFO]: Epoch 009 - training loss: 0.4800, validation loss: 0.0351
2024-05-25 00:15:22 [INFO]: Epoch 010 - training loss: 0.4490, validation loss: 0.0315
2024-05-25 00:15:28 [INFO]: Epoch 011 - training loss: 0.4369, validation loss: 0.0302
2024-05-25 00:15:34 [INFO]: Epoch 012 - training loss: 0.4273, validation loss: 0.0286
2024-05-25 00:15:40 [INFO]: Epoch 013 - training loss: 0.4073, validation loss: 0.0271
2024-05-25 00:15:46 [INFO]: Epoch 014 - training loss: 0.4022, validation loss: 0.0255
2024-05-25 00:15:52 [INFO]: Epoch 015 - training loss: 0.3947, validation loss: 0.0242
2024-05-25 00:15:58 [INFO]: Epoch 016 - training loss: 0.3882, validation loss: 0.0238
2024-05-25 00:16:04 [INFO]: Epoch 017 - training loss: 0.3936, validation loss: 0.0238
2024-05-25 00:16:10 [INFO]: Epoch 018 - training loss: 0.3848, validation loss: 0.0237
2024-05-25 00:16:16 [INFO]: Epoch 019 - training loss: 0.3822, validation loss: 0.0236
2024-05-25 00:16:22 [INFO]: Epoch 020 - training loss: 0.3827, validation loss: 0.0232
2024-05-25 00:16:28 [INFO]: Epoch 021 - training loss: 0.3830, validation loss: 0.0232
2024-05-25 00:16:34 [INFO]: Epoch 022 - training loss: 0.3908, validation loss: 0.0231
2024-05-25 00:16:40 [INFO]: Epoch 023 - training loss: 0.3933, validation loss: 0.0234
2024-05-25 00:16:46 [INFO]: Epoch 024 - training loss: 0.3966, validation loss: 0.0241
2024-05-25 00:16:51 [INFO]: Epoch 025 - training loss: 0.3852, validation loss: 0.0243
2024-05-25 00:16:57 [INFO]: Epoch 026 - training loss: 0.3863, validation loss: 0.0235
2024-05-25 00:17:04 [INFO]: Epoch 027 - training loss: 0.3782, validation loss: 0.0229
2024-05-25 00:17:09 [INFO]: Epoch 028 - training loss: 0.3756, validation loss: 0.0225
2024-05-25 00:17:15 [INFO]: Epoch 029 - training loss: 0.3749, validation loss: 0.0224
2024-05-25 00:17:21 [INFO]: Epoch 030 - training loss: 0.3755, validation loss: 0.0228
2024-05-25 00:17:27 [INFO]: Epoch 031 - training loss: 0.3741, validation loss: 0.0224
2024-05-25 00:17:33 [INFO]: Epoch 032 - training loss: 0.3719, validation loss: 0.0225
2024-05-25 00:17:39 [INFO]: Epoch 033 - training loss: 0.3745, validation loss: 0.0229
2024-05-25 00:17:45 [INFO]: Epoch 034 - training loss: 0.3723, validation loss: 0.0225
2024-05-25 00:17:51 [INFO]: Epoch 035 - training loss: 0.3687, validation loss: 0.0231
2024-05-25 00:17:57 [INFO]: Epoch 036 - training loss: 0.3690, validation loss: 0.0229
2024-05-25 00:18:03 [INFO]: Epoch 037 - training loss: 0.3802, validation loss: 0.0230
2024-05-25 00:18:09 [INFO]: Epoch 038 - training loss: 0.3806, validation loss: 0.0227
2024-05-25 00:18:15 [INFO]: Epoch 039 - training loss: 0.3756, validation loss: 0.0225
2024-05-25 00:18:21 [INFO]: Epoch 040 - training loss: 0.3696, validation loss: 0.0305
2024-05-25 00:18:27 [INFO]: Epoch 041 - training loss: 0.4058, validation loss: 0.0231
2024-05-25 00:18:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:18:27 [INFO]: Finished training. The best model is from epoch#31.
2024-05-25 00:18:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/BRITS_ettm1/20240525_T001420/BRITS.pypots
2024-05-25 00:18:28 [INFO]: BRITS on ETTm1: MAE=0.1289, MSE=0.0475
2024-05-25 00:18:28 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/BRITS_ettm1/imputation.pkl
2024-05-25 00:18:28 [INFO]: Using the given device: cuda:0
2024-05-25 00:18:28 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828
2024-05-25 00:18:28 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/tensorboard
2024-05-25 00:18:28 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 00:18:30 [INFO]: Epoch 001 - training loss: 1.4113, validation loss: 1.3116
2024-05-25 00:18:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch1_loss1.3116154372692108.pypots
2024-05-25 00:18:30 [INFO]: Epoch 002 - training loss: 1.0623, validation loss: 1.1640
2024-05-25 00:18:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch2_loss1.164021834731102.pypots
2024-05-25 00:18:31 [INFO]: Epoch 003 - training loss: 0.9986, validation loss: 1.0676
2024-05-25 00:18:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch3_loss1.0675934851169586.pypots
2024-05-25 00:18:31 [INFO]: Epoch 004 - training loss: 0.9870, validation loss: 1.0323
2024-05-25 00:18:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch4_loss1.0323355048894882.pypots
2024-05-25 00:18:31 [INFO]: Epoch 005 - training loss: 0.9604, validation loss: 1.0191
2024-05-25 00:18:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch5_loss1.0191260129213333.pypots
2024-05-25 00:18:31 [INFO]: Epoch 006 - training loss: 0.9351, validation loss: 1.0118
2024-05-25 00:18:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch6_loss1.0117833316326141.pypots
2024-05-25 00:18:31 [INFO]: Epoch 007 - training loss: 0.9938, validation loss: 1.0086
2024-05-25 00:18:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch7_loss1.0085682272911072.pypots
2024-05-25 00:18:32 [INFO]: Epoch 008 - training loss: 0.9372, validation loss: 1.0055
2024-05-25 00:18:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch8_loss1.005493938922882.pypots
2024-05-25 00:18:32 [INFO]: Epoch 009 - training loss: 0.9179, validation loss: 0.9983
2024-05-25 00:18:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch9_loss0.9983313679695129.pypots
2024-05-25 00:18:32 [INFO]: Epoch 010 - training loss: 0.9447, validation loss: 0.9947
2024-05-25 00:18:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch10_loss0.9946781098842621.pypots
2024-05-25 00:18:32 [INFO]: Epoch 011 - training loss: 0.9179, validation loss: 0.9965
2024-05-25 00:18:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch11_loss0.9964738488197327.pypots
2024-05-25 00:18:32 [INFO]: Epoch 012 - training loss: 0.9146, validation loss: 0.9962
2024-05-25 00:18:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch12_loss0.9961996674537659.pypots
2024-05-25 00:18:33 [INFO]: Epoch 013 - training loss: 0.8995, validation loss: 0.9922
2024-05-25 00:18:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch13_loss0.9922493696212769.pypots
2024-05-25 00:18:33 [INFO]: Epoch 014 - training loss: 0.8902, validation loss: 0.9860
2024-05-25 00:18:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch14_loss0.9859692305326462.pypots
2024-05-25 00:18:33 [INFO]: Epoch 015 - training loss: 0.8951, validation loss: 0.9844
2024-05-25 00:18:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch15_loss0.9844250380992889.pypots
2024-05-25 00:18:33 [INFO]: Epoch 016 - training loss: 0.9032, validation loss: 0.9805
2024-05-25 00:18:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch16_loss0.9804811626672745.pypots
2024-05-25 00:18:33 [INFO]: Epoch 017 - training loss: 0.8706, validation loss: 0.9810
2024-05-25 00:18:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch17_loss0.9810211658477783.pypots
2024-05-25 00:18:34 [INFO]: Epoch 018 - training loss: 0.8595, validation loss: 0.9773
2024-05-25 00:18:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch18_loss0.9772590696811676.pypots
2024-05-25 00:18:34 [INFO]: Epoch 019 - training loss: 0.8732, validation loss: 0.9724
2024-05-25 00:18:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch19_loss0.9724208563566208.pypots
2024-05-25 00:18:34 [INFO]: Epoch 020 - training loss: 0.8805, validation loss: 0.9694
2024-05-25 00:18:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch20_loss0.9694403409957886.pypots
2024-05-25 00:18:34 [INFO]: Epoch 021 - training loss: 0.8641, validation loss: 0.9637
2024-05-25 00:18:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch21_loss0.9636901468038559.pypots
2024-05-25 00:18:34 [INFO]: Epoch 022 - training loss: 0.8424, validation loss: 0.9634
2024-05-25 00:18:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch22_loss0.9633820801973343.pypots
2024-05-25 00:18:34 [INFO]: Epoch 023 - training loss: 0.8847, validation loss: 0.9598
2024-05-25 00:18:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch23_loss0.9597842991352081.pypots
2024-05-25 00:18:35 [INFO]: Epoch 024 - training loss: 0.8430, validation loss: 0.9562
2024-05-25 00:18:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch24_loss0.9561629146337509.pypots
2024-05-25 00:18:35 [INFO]: Epoch 025 - training loss: 0.8428, validation loss: 0.9523
2024-05-25 00:18:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch25_loss0.952349454164505.pypots
2024-05-25 00:18:35 [INFO]: Epoch 026 - training loss: 0.8415, validation loss: 0.9501
2024-05-25 00:18:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch26_loss0.9500578492879868.pypots
2024-05-25 00:18:35 [INFO]: Epoch 027 - training loss: 0.8282, validation loss: 0.9455
2024-05-25 00:18:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch27_loss0.9455478936433792.pypots
2024-05-25 00:18:35 [INFO]: Epoch 028 - training loss: 0.8774, validation loss: 0.9416
2024-05-25 00:18:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch28_loss0.9415784925222397.pypots
2024-05-25 00:18:36 [INFO]: Epoch 029 - training loss: 0.8363, validation loss: 0.9349
2024-05-25 00:18:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch29_loss0.9348815977573395.pypots
2024-05-25 00:18:36 [INFO]: Epoch 030 - training loss: 0.8408, validation loss: 0.9307
2024-05-25 00:18:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch30_loss0.9307301640510559.pypots
2024-05-25 00:18:36 [INFO]: Epoch 031 - training loss: 0.8136, validation loss: 0.9330
2024-05-25 00:18:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch31_loss0.9329947084188461.pypots
2024-05-25 00:18:36 [INFO]: Epoch 032 - training loss: 0.8250, validation loss: 0.9251
2024-05-25 00:18:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch32_loss0.9251261055469513.pypots
2024-05-25 00:18:36 [INFO]: Epoch 033 - training loss: 0.8276, validation loss: 0.9236
2024-05-25 00:18:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch33_loss0.9236431568861008.pypots
2024-05-25 00:18:37 [INFO]: Epoch 034 - training loss: 0.8073, validation loss: 0.9189
2024-05-25 00:18:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch34_loss0.9189001470804214.pypots
2024-05-25 00:18:37 [INFO]: Epoch 035 - training loss: 0.8358, validation loss: 0.9150
2024-05-25 00:18:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch35_loss0.9150010943412781.pypots
2024-05-25 00:18:37 [INFO]: Epoch 036 - training loss: 0.8216, validation loss: 0.9133
2024-05-25 00:18:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch36_loss0.9132743030786514.pypots
2024-05-25 00:18:37 [INFO]: Epoch 037 - training loss: 0.8037, validation loss: 0.9104
2024-05-25 00:18:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch37_loss0.9103813320398331.pypots
2024-05-25 00:18:37 [INFO]: Epoch 038 - training loss: 0.8158, validation loss: 0.9075
2024-05-25 00:18:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch38_loss0.9074788838624954.pypots
2024-05-25 00:18:37 [INFO]: Epoch 039 - training loss: 0.8115, validation loss: 0.9069
2024-05-25 00:18:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch39_loss0.9069321155548096.pypots
2024-05-25 00:18:38 [INFO]: Epoch 040 - training loss: 0.7878, validation loss: 0.9015
2024-05-25 00:18:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch40_loss0.9015294462442398.pypots
2024-05-25 00:18:38 [INFO]: Epoch 041 - training loss: 0.8108, validation loss: 0.8994
2024-05-25 00:18:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch41_loss0.8993909060955048.pypots
2024-05-25 00:18:38 [INFO]: Epoch 042 - training loss: 0.8169, validation loss: 0.8979
2024-05-25 00:18:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch42_loss0.8978904038667679.pypots
2024-05-25 00:18:38 [INFO]: Epoch 043 - training loss: 0.8210, validation loss: 0.8953
2024-05-25 00:18:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch43_loss0.8953443616628647.pypots
2024-05-25 00:18:38 [INFO]: Epoch 044 - training loss: 0.8070, validation loss: 0.8911
2024-05-25 00:18:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch44_loss0.8910583257675171.pypots
2024-05-25 00:18:39 [INFO]: Epoch 045 - training loss: 0.8056, validation loss: 0.8882
2024-05-25 00:18:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch45_loss0.8881949484348297.pypots
2024-05-25 00:18:39 [INFO]: Epoch 046 - training loss: 0.8468, validation loss: 0.8881
2024-05-25 00:18:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch46_loss0.8881131112575531.pypots
2024-05-25 00:18:39 [INFO]: Epoch 047 - training loss: 0.8137, validation loss: 0.8860
2024-05-25 00:18:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch47_loss0.8860386908054352.pypots
2024-05-25 00:18:39 [INFO]: Epoch 048 - training loss: 0.8240, validation loss: 0.8809
2024-05-25 00:18:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch48_loss0.8808590620756149.pypots
2024-05-25 00:18:39 [INFO]: Epoch 049 - training loss: 0.8263, validation loss: 0.8823
2024-05-25 00:18:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch49_loss0.8823384940624237.pypots
2024-05-25 00:18:40 [INFO]: Epoch 050 - training loss: 0.8210, validation loss: 0.8802
2024-05-25 00:18:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch50_loss0.880198672413826.pypots
2024-05-25 00:18:40 [INFO]: Epoch 051 - training loss: 0.8607, validation loss: 0.8784
2024-05-25 00:18:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch51_loss0.878415122628212.pypots
2024-05-25 00:18:40 [INFO]: Epoch 052 - training loss: 0.8513, validation loss: 0.8702
2024-05-25 00:18:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch52_loss0.8702079951763153.pypots
2024-05-25 00:18:40 [INFO]: Epoch 053 - training loss: 0.8166, validation loss: 0.8745
2024-05-25 00:18:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch53_loss0.8744715303182602.pypots
2024-05-25 00:18:40 [INFO]: Epoch 054 - training loss: 0.8275, validation loss: 0.8696
2024-05-25 00:18:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch54_loss0.8696493059396744.pypots
2024-05-25 00:18:41 [INFO]: Epoch 055 - training loss: 0.8206, validation loss: 0.8733
2024-05-25 00:18:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch55_loss0.8732872903347015.pypots
2024-05-25 00:18:41 [INFO]: Epoch 056 - training loss: 0.7936, validation loss: 0.8720
2024-05-25 00:18:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch56_loss0.8719501793384552.pypots
2024-05-25 00:18:41 [INFO]: Epoch 057 - training loss: 0.7893, validation loss: 0.8686
2024-05-25 00:18:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch57_loss0.8685666620731354.pypots
2024-05-25 00:18:41 [INFO]: Epoch 058 - training loss: 0.7985, validation loss: 0.8715
2024-05-25 00:18:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch58_loss0.8715287446975708.pypots
2024-05-25 00:18:41 [INFO]: Epoch 059 - training loss: 0.8017, validation loss: 0.8685
2024-05-25 00:18:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch59_loss0.8685002028942108.pypots
2024-05-25 00:18:41 [INFO]: Epoch 060 - training loss: 0.7864, validation loss: 0.8688
2024-05-25 00:18:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch60_loss0.8688075691461563.pypots
2024-05-25 00:18:42 [INFO]: Epoch 061 - training loss: 0.8012, validation loss: 0.8674
2024-05-25 00:18:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch61_loss0.8674185425043106.pypots
2024-05-25 00:18:42 [INFO]: Epoch 062 - training loss: 0.7917, validation loss: 0.8653
2024-05-25 00:18:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch62_loss0.8653067797422409.pypots
2024-05-25 00:18:42 [INFO]: Epoch 063 - training loss: 0.7890, validation loss: 0.8658
2024-05-25 00:18:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch63_loss0.865846574306488.pypots
2024-05-25 00:18:42 [INFO]: Epoch 064 - training loss: 0.8030, validation loss: 0.8655
2024-05-25 00:18:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch64_loss0.865514799952507.pypots
2024-05-25 00:18:42 [INFO]: Epoch 065 - training loss: 0.7909, validation loss: 0.8627
2024-05-25 00:18:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch65_loss0.8626724779605865.pypots
2024-05-25 00:18:43 [INFO]: Epoch 066 - training loss: 0.8113, validation loss: 0.8665
2024-05-25 00:18:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch66_loss0.8665037900209427.pypots
2024-05-25 00:18:43 [INFO]: Epoch 067 - training loss: 0.8114, validation loss: 0.8615
2024-05-25 00:18:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch67_loss0.8615436553955078.pypots
2024-05-25 00:18:43 [INFO]: Epoch 068 - training loss: 0.8151, validation loss: 0.8644
2024-05-25 00:18:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch68_loss0.86443991959095.pypots
2024-05-25 00:18:43 [INFO]: Epoch 069 - training loss: 0.7939, validation loss: 0.8610
2024-05-25 00:18:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch69_loss0.8610015213489532.pypots
2024-05-25 00:18:43 [INFO]: Epoch 070 - training loss: 0.7778, validation loss: 0.8619
2024-05-25 00:18:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch70_loss0.861919030547142.pypots
2024-05-25 00:18:44 [INFO]: Epoch 071 - training loss: 0.8023, validation loss: 0.8634
2024-05-25 00:18:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch71_loss0.8634431809186935.pypots
2024-05-25 00:18:44 [INFO]: Epoch 072 - training loss: 0.8014, validation loss: 0.8613
2024-05-25 00:18:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch72_loss0.8612979650497437.pypots
2024-05-25 00:18:44 [INFO]: Epoch 073 - training loss: 0.7976, validation loss: 0.8572
2024-05-25 00:18:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch73_loss0.8572089374065399.pypots
2024-05-25 00:18:44 [INFO]: Epoch 074 - training loss: 0.8269, validation loss: 0.8602
2024-05-25 00:18:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch74_loss0.8601906448602676.pypots
2024-05-25 00:18:44 [INFO]: Epoch 075 - training loss: 0.8531, validation loss: 0.8594
2024-05-25 00:18:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch75_loss0.8594248741865158.pypots
2024-05-25 00:18:44 [INFO]: Epoch 076 - training loss: 0.7877, validation loss: 0.8561
2024-05-25 00:18:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch76_loss0.8560508042573929.pypots
2024-05-25 00:18:45 [INFO]: Epoch 077 - training loss: 0.7965, validation loss: 0.8546
2024-05-25 00:18:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch77_loss0.8545586168766022.pypots
2024-05-25 00:18:45 [INFO]: Epoch 078 - training loss: 0.8427, validation loss: 0.8557
2024-05-25 00:18:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch78_loss0.8556776195764542.pypots
2024-05-25 00:18:45 [INFO]: Epoch 079 - training loss: 0.7813, validation loss: 0.8584
2024-05-25 00:18:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch79_loss0.8584151118993759.pypots
2024-05-25 00:18:45 [INFO]: Epoch 080 - training loss: 0.8002, validation loss: 0.8567
2024-05-25 00:18:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch80_loss0.8567349165678024.pypots
2024-05-25 00:18:45 [INFO]: Epoch 081 - training loss: 0.7945, validation loss: 0.8548
2024-05-25 00:18:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch81_loss0.8548064231872559.pypots
2024-05-25 00:18:46 [INFO]: Epoch 082 - training loss: 0.7825, validation loss: 0.8542
2024-05-25 00:18:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch82_loss0.8542391806840897.pypots
2024-05-25 00:18:46 [INFO]: Epoch 083 - training loss: 0.7828, validation loss: 0.8547
2024-05-25 00:18:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch83_loss0.8547113686800003.pypots
2024-05-25 00:18:46 [INFO]: Epoch 084 - training loss: 0.7857, validation loss: 0.8523
2024-05-25 00:18:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch84_loss0.8522654175758362.pypots
2024-05-25 00:18:46 [INFO]: Epoch 085 - training loss: 0.7890, validation loss: 0.8523
2024-05-25 00:18:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch85_loss0.8522566109895706.pypots
2024-05-25 00:18:46 [INFO]: Epoch 086 - training loss: 0.7959, validation loss: 0.8522
2024-05-25 00:18:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch86_loss0.8521882444620132.pypots
2024-05-25 00:18:47 [INFO]: Epoch 087 - training loss: 0.7835, validation loss: 0.8524
2024-05-25 00:18:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch87_loss0.8523858934640884.pypots
2024-05-25 00:18:47 [INFO]: Epoch 088 - training loss: 0.7858, validation loss: 0.8510
2024-05-25 00:18:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch88_loss0.8509816825389862.pypots
2024-05-25 00:18:47 [INFO]: Epoch 089 - training loss: 0.7824, validation loss: 0.8493
2024-05-25 00:18:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch89_loss0.8493430614471436.pypots
2024-05-25 00:18:47 [INFO]: Epoch 090 - training loss: 0.8223, validation loss: 0.8484
2024-05-25 00:18:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch90_loss0.8483706563711166.pypots
2024-05-25 00:18:47 [INFO]: Epoch 091 - training loss: 0.7849, validation loss: 0.8499
2024-05-25 00:18:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch91_loss0.8498841673135757.pypots
2024-05-25 00:18:47 [INFO]: Epoch 092 - training loss: 0.7891, validation loss: 0.8519
2024-05-25 00:18:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch92_loss0.8519019186496735.pypots
2024-05-25 00:18:48 [INFO]: Epoch 093 - training loss: 0.7654, validation loss: 0.8489
2024-05-25 00:18:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch93_loss0.8488838374614716.pypots
2024-05-25 00:18:48 [INFO]: Epoch 094 - training loss: 0.7873, validation loss: 0.8488
2024-05-25 00:18:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch94_loss0.8487708270549774.pypots
2024-05-25 00:18:48 [INFO]: Epoch 095 - training loss: 0.7632, validation loss: 0.8486
2024-05-25 00:18:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch95_loss0.8485556542873383.pypots
2024-05-25 00:18:48 [INFO]: Epoch 096 - training loss: 0.8012, validation loss: 0.8500
2024-05-25 00:18:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch96_loss0.8500025123357773.pypots
2024-05-25 00:18:48 [INFO]: Epoch 097 - training loss: 0.7803, validation loss: 0.8440
2024-05-25 00:18:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch97_loss0.8439655303955078.pypots
2024-05-25 00:18:49 [INFO]: Epoch 098 - training loss: 0.7907, validation loss: 0.8462
2024-05-25 00:18:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch98_loss0.8462294489145279.pypots
2024-05-25 00:18:49 [INFO]: Epoch 099 - training loss: 0.7816, validation loss: 0.8452
2024-05-25 00:18:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch99_loss0.8452163338661194.pypots
2024-05-25 00:18:49 [INFO]: Epoch 100 - training loss: 0.7878, validation loss: 0.8438
2024-05-25 00:18:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch100_loss0.8437717854976654.pypots
2024-05-25 00:18:49 [INFO]: Epoch 101 - training loss: 0.7768, validation loss: 0.8440
2024-05-25 00:18:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch101_loss0.8440222293138504.pypots
2024-05-25 00:18:49 [INFO]: Epoch 102 - training loss: 0.8144, validation loss: 0.8439
2024-05-25 00:18:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch102_loss0.8438783437013626.pypots
2024-05-25 00:18:50 [INFO]: Epoch 103 - training loss: 0.7829, validation loss: 0.8408
2024-05-25 00:18:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch103_loss0.8407677561044693.pypots
2024-05-25 00:18:50 [INFO]: Epoch 104 - training loss: 0.7676, validation loss: 0.8429
2024-05-25 00:18:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch104_loss0.8428865969181061.pypots
2024-05-25 00:18:50 [INFO]: Epoch 105 - training loss: 0.7699, validation loss: 0.8401
2024-05-25 00:18:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch105_loss0.8400760442018509.pypots
2024-05-25 00:18:50 [INFO]: Epoch 106 - training loss: 0.8002, validation loss: 0.8416
2024-05-25 00:18:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch106_loss0.8416261523962021.pypots
2024-05-25 00:18:50 [INFO]: Epoch 107 - training loss: 0.7946, validation loss: 0.8410
2024-05-25 00:18:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch107_loss0.8410101532936096.pypots
2024-05-25 00:18:50 [INFO]: Epoch 108 - training loss: 0.7800, validation loss: 0.8394
2024-05-25 00:18:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch108_loss0.8394091725349426.pypots
2024-05-25 00:18:51 [INFO]: Epoch 109 - training loss: 0.7767, validation loss: 0.8409
2024-05-25 00:18:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch109_loss0.8409426808357239.pypots
2024-05-25 00:18:51 [INFO]: Epoch 110 - training loss: 0.7633, validation loss: 0.8378
2024-05-25 00:18:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch110_loss0.8377839922904968.pypots
2024-05-25 00:18:51 [INFO]: Epoch 111 - training loss: 0.7874, validation loss: 0.8382
2024-05-25 00:18:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch111_loss0.8382045030593872.pypots
2024-05-25 00:18:51 [INFO]: Epoch 112 - training loss: 0.7956, validation loss: 0.8401
2024-05-25 00:18:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch112_loss0.8401092439889908.pypots
2024-05-25 00:18:51 [INFO]: Epoch 113 - training loss: 0.7899, validation loss: 0.8403
2024-05-25 00:18:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch113_loss0.8403075337409973.pypots
2024-05-25 00:18:52 [INFO]: Epoch 114 - training loss: 0.8108, validation loss: 0.8372
2024-05-25 00:18:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch114_loss0.8372071534395218.pypots
2024-05-25 00:18:52 [INFO]: Epoch 115 - training loss: 0.7815, validation loss: 0.8343
2024-05-25 00:18:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch115_loss0.8343355059623718.pypots
2024-05-25 00:18:52 [INFO]: Epoch 116 - training loss: 0.7818, validation loss: 0.8374
2024-05-25 00:18:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch116_loss0.8373588919639587.pypots
2024-05-25 00:18:52 [INFO]: Epoch 117 - training loss: 0.7639, validation loss: 0.8337
2024-05-25 00:18:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch117_loss0.8337496370077133.pypots
2024-05-25 00:18:52 [INFO]: Epoch 118 - training loss: 0.7723, validation loss: 0.8331
2024-05-25 00:18:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch118_loss0.8330789506435394.pypots
2024-05-25 00:18:53 [INFO]: Epoch 119 - training loss: 0.7957, validation loss: 0.8405
2024-05-25 00:18:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch119_loss0.8405429124832153.pypots
2024-05-25 00:18:53 [INFO]: Epoch 120 - training loss: 0.7696, validation loss: 0.8329
2024-05-25 00:18:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch120_loss0.8329318761825562.pypots
2024-05-25 00:18:53 [INFO]: Epoch 121 - training loss: 0.7799, validation loss: 0.8345
2024-05-25 00:18:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch121_loss0.8344578742980957.pypots
2024-05-25 00:18:53 [INFO]: Epoch 122 - training loss: 0.7835, validation loss: 0.8331
2024-05-25 00:18:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch122_loss0.833120197057724.pypots
2024-05-25 00:18:53 [INFO]: Epoch 123 - training loss: 0.7954, validation loss: 0.8339
2024-05-25 00:18:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch123_loss0.8339322805404663.pypots
2024-05-25 00:18:54 [INFO]: Epoch 124 - training loss: 0.7803, validation loss: 0.8318
2024-05-25 00:18:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch124_loss0.8318018317222595.pypots
2024-05-25 00:18:54 [INFO]: Epoch 125 - training loss: 0.7705, validation loss: 0.8321
2024-05-25 00:18:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch125_loss0.8320975601673126.pypots
2024-05-25 00:18:54 [INFO]: Epoch 126 - training loss: 0.7901, validation loss: 0.8280
2024-05-25 00:18:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch126_loss0.827976331114769.pypots
2024-05-25 00:18:54 [INFO]: Epoch 127 - training loss: 0.7769, validation loss: 0.8338
2024-05-25 00:18:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch127_loss0.8338351398706436.pypots
2024-05-25 00:18:54 [INFO]: Epoch 128 - training loss: 0.7867, validation loss: 0.8275
2024-05-25 00:18:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch128_loss0.8275217115879059.pypots
2024-05-25 00:18:54 [INFO]: Epoch 129 - training loss: 0.7767, validation loss: 0.8270
2024-05-25 00:18:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch129_loss0.8269682824611664.pypots
2024-05-25 00:18:55 [INFO]: Epoch 130 - training loss: 0.7952, validation loss: 0.8327
2024-05-25 00:18:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch130_loss0.83269864320755.pypots
2024-05-25 00:18:55 [INFO]: Epoch 131 - training loss: 0.7771, validation loss: 0.8277
2024-05-25 00:18:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch131_loss0.8277095407247543.pypots
2024-05-25 00:18:55 [INFO]: Epoch 132 - training loss: 0.7731, validation loss: 0.8273
2024-05-25 00:18:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch132_loss0.8272560089826584.pypots
2024-05-25 00:18:55 [INFO]: Epoch 133 - training loss: 0.7995, validation loss: 0.8259
2024-05-25 00:18:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch133_loss0.8259243667125702.pypots
2024-05-25 00:18:55 [INFO]: Epoch 134 - training loss: 0.7953, validation loss: 0.8239
2024-05-25 00:18:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch134_loss0.8239191323518753.pypots
2024-05-25 00:18:56 [INFO]: Epoch 135 - training loss: 0.8390, validation loss: 0.8329
2024-05-25 00:18:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch135_loss0.8328916430473328.pypots
2024-05-25 00:18:56 [INFO]: Epoch 136 - training loss: 0.8074, validation loss: 0.8303
2024-05-25 00:18:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch136_loss0.830343946814537.pypots
2024-05-25 00:18:56 [INFO]: Epoch 137 - training loss: 0.7806, validation loss: 0.8304
2024-05-25 00:18:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch137_loss0.8303866237401962.pypots
2024-05-25 00:18:56 [INFO]: Epoch 138 - training loss: 0.7893, validation loss: 0.8291
2024-05-25 00:18:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch138_loss0.8290574997663498.pypots
2024-05-25 00:18:56 [INFO]: Epoch 139 - training loss: 0.7738, validation loss: 0.8265
2024-05-25 00:18:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch139_loss0.8264710903167725.pypots
2024-05-25 00:18:57 [INFO]: Epoch 140 - training loss: 0.7691, validation loss: 0.8236
2024-05-25 00:18:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch140_loss0.823630154132843.pypots
2024-05-25 00:18:57 [INFO]: Epoch 141 - training loss: 0.7881, validation loss: 0.8293
2024-05-25 00:18:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch141_loss0.8292705416679382.pypots
2024-05-25 00:18:57 [INFO]: Epoch 142 - training loss: 0.7807, validation loss: 0.8274
2024-05-25 00:18:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch142_loss0.8274030983448029.pypots
2024-05-25 00:18:57 [INFO]: Epoch 143 - training loss: 0.7880, validation loss: 0.8261
2024-05-25 00:18:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch143_loss0.8260584324598312.pypots
2024-05-25 00:18:57 [INFO]: Epoch 144 - training loss: 0.7678, validation loss: 0.8287
2024-05-25 00:18:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch144_loss0.8287409096956253.pypots
2024-05-25 00:18:57 [INFO]: Epoch 145 - training loss: 0.7727, validation loss: 0.8265
2024-05-25 00:18:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch145_loss0.8264807164669037.pypots
2024-05-25 00:18:58 [INFO]: Epoch 146 - training loss: 0.7664, validation loss: 0.8243
2024-05-25 00:18:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch146_loss0.8242739289999008.pypots
2024-05-25 00:18:58 [INFO]: Epoch 147 - training loss: 0.7780, validation loss: 0.8268
2024-05-25 00:18:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch147_loss0.826788455247879.pypots
2024-05-25 00:18:58 [INFO]: Epoch 148 - training loss: 0.7729, validation loss: 0.8264
2024-05-25 00:18:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch148_loss0.8264222145080566.pypots
2024-05-25 00:18:58 [INFO]: Epoch 149 - training loss: 0.7870, validation loss: 0.8258
2024-05-25 00:18:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch149_loss0.8258174508810043.pypots
2024-05-25 00:18:58 [INFO]: Epoch 150 - training loss: 0.7607, validation loss: 0.8253
2024-05-25 00:18:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN_epoch150_loss0.8253046423196793.pypots
2024-05-25 00:18:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:18:58 [INFO]: Finished training. The best model is from epoch#140.
2024-05-25 00:18:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T001828/MRNN.pypots
2024-05-25 00:18:59 [INFO]: MRNN on ETTm1: MAE=0.6785, MSE=1.0782
2024-05-25 00:18:59 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/MRNN_ettm1/imputation.pkl
2024-05-25 00:18:59 [INFO]: Using the given device: cpu
2024-05-25 00:18:59 [INFO]: LOCF on ETTm1: MAE=0.1332, MSE=0.0720
2024-05-25 00:18:59 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_ettm1".
2024-05-25 00:18:59 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/LOCF_ettm1/imputation.pkl
2024-05-25 00:18:59 [INFO]: Median on ETTm1: MAE=0.6670, MSE=0.8617
2024-05-25 00:18:59 [INFO]: Successfully created the given path "saved_results/round_3/Median_ettm1".
2024-05-25 00:18:59 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/Median_ettm1/imputation.pkl
2024-05-25 00:18:59 [INFO]: Mean on ETTm1: MAE=0.6734, MSE=0.8444
2024-05-25 00:18:59 [INFO]: Successfully created the given path "saved_results/round_3/Mean_ettm1".
2024-05-25 00:18:59 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/Mean_ettm1/imputation.pkl
2024-05-25 00:18:59 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-25 00:18:59 [INFO]: Using the given device: cuda:0
2024-05-25 00:18:59 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/SAITS_ettm1/20240525_T001859
2024-05-25 00:18:59 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/SAITS_ettm1/20240525_T001859/tensorboard
2024-05-25 00:18:59 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 00:18:59 [INFO]: Epoch 001 - training loss: 1.1701, validation loss: 0.2460
2024-05-25 00:19:00 [INFO]: Epoch 002 - training loss: 0.9060, validation loss: 0.1160
2024-05-25 00:19:00 [INFO]: Epoch 003 - training loss: 0.8029, validation loss: 0.0903
2024-05-25 00:19:01 [INFO]: Epoch 004 - training loss: 0.7542, validation loss: 0.0793
2024-05-25 00:19:01 [INFO]: Epoch 005 - training loss: 0.7130, validation loss: 0.0827
2024-05-25 00:19:02 [INFO]: Epoch 006 - training loss: 0.6969, validation loss: 0.0652
2024-05-25 00:19:03 [INFO]: Epoch 007 - training loss: 0.6669, validation loss: 0.0603
2024-05-25 00:19:03 [INFO]: Epoch 008 - training loss: 0.6603, validation loss: 0.0815
2024-05-25 00:19:04 [INFO]: Epoch 009 - training loss: 0.6432, validation loss: 0.0707
2024-05-25 00:19:04 [INFO]: Epoch 010 - training loss: 0.6319, validation loss: 0.0662
2024-05-25 00:19:05 [INFO]: Epoch 011 - training loss: 0.6236, validation loss: 0.0585
2024-05-25 00:19:05 [INFO]: Epoch 012 - training loss: 0.6230, validation loss: 0.0694
2024-05-25 00:19:06 [INFO]: Epoch 013 - training loss: 0.6064, validation loss: 0.0532
2024-05-25 00:19:06 [INFO]: Epoch 014 - training loss: 0.5926, validation loss: 0.0597
2024-05-25 00:19:07 [INFO]: Epoch 015 - training loss: 0.6059, validation loss: 0.0657
2024-05-25 00:19:07 [INFO]: Epoch 016 - training loss: 0.5858, validation loss: 0.0573
2024-05-25 00:19:08 [INFO]: Epoch 017 - training loss: 0.5657, validation loss: 0.0527
2024-05-25 00:19:08 [INFO]: Epoch 018 - training loss: 0.5676, validation loss: 0.0519
2024-05-25 00:19:09 [INFO]: Epoch 019 - training loss: 0.5837, validation loss: 0.0636
2024-05-25 00:19:09 [INFO]: Epoch 020 - training loss: 0.5693, validation loss: 0.0520
2024-05-25 00:19:10 [INFO]: Epoch 021 - training loss: 0.5536, validation loss: 0.0417
2024-05-25 00:19:10 [INFO]: Epoch 022 - training loss: 0.5415, validation loss: 0.0454
2024-05-25 00:19:11 [INFO]: Epoch 023 - training loss: 0.5658, validation loss: 0.0423
2024-05-25 00:19:11 [INFO]: Epoch 024 - training loss: 0.5354, validation loss: 0.0522
2024-05-25 00:19:12 [INFO]: Epoch 025 - training loss: 0.5481, validation loss: 0.0533
2024-05-25 00:19:12 [INFO]: Epoch 026 - training loss: 0.5485, validation loss: 0.0595
2024-05-25 00:19:13 [INFO]: Epoch 027 - training loss: 0.5252, validation loss: 0.0519
2024-05-25 00:19:13 [INFO]: Epoch 028 - training loss: 0.5331, validation loss: 0.0359
2024-05-25 00:19:14 [INFO]: Epoch 029 - training loss: 0.5173, validation loss: 0.0455
2024-05-25 00:19:14 [INFO]: Epoch 030 - training loss: 0.5299, validation loss: 0.0400
2024-05-25 00:19:15 [INFO]: Epoch 031 - training loss: 0.5133, validation loss: 0.0408
2024-05-25 00:19:15 [INFO]: Epoch 032 - training loss: 0.4939, validation loss: 0.0353
2024-05-25 00:19:16 [INFO]: Epoch 033 - training loss: 0.4959, validation loss: 0.0352
2024-05-25 00:19:16 [INFO]: Epoch 034 - training loss: 0.4875, validation loss: 0.0277
2024-05-25 00:19:17 [INFO]: Epoch 035 - training loss: 0.4857, validation loss: 0.0359
2024-05-25 00:19:17 [INFO]: Epoch 036 - training loss: 0.4877, validation loss: 0.0447
2024-05-25 00:19:18 [INFO]: Epoch 037 - training loss: 0.4842, validation loss: 0.0358
2024-05-25 00:19:18 [INFO]: Epoch 038 - training loss: 0.4804, validation loss: 0.0340
2024-05-25 00:19:19 [INFO]: Epoch 039 - training loss: 0.4854, validation loss: 0.0429
2024-05-25 00:19:19 [INFO]: Epoch 040 - training loss: 0.5006, validation loss: 0.0406
2024-05-25 00:19:20 [INFO]: Epoch 041 - training loss: 0.5023, validation loss: 0.0596
2024-05-25 00:19:20 [INFO]: Epoch 042 - training loss: 0.4737, validation loss: 0.0314
2024-05-25 00:19:21 [INFO]: Epoch 043 - training loss: 0.4831, validation loss: 0.0354
2024-05-25 00:19:21 [INFO]: Epoch 044 - training loss: 0.4743, validation loss: 0.0357
2024-05-25 00:19:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:19:21 [INFO]: Finished training. The best model is from epoch#34.
2024-05-25 00:19:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/SAITS_ettm1/20240525_T001859/SAITS.pypots
2024-05-25 00:19:22 [INFO]: SAITS on ETTm1: MAE=0.1392, MSE=0.0386
2024-05-25 00:19:22 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/SAITS_ettm1/imputation.pkl
2024-05-25 00:19:22 [INFO]: Using the given device: cuda:0
2024-05-25 00:19:22 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/Transformer_ettm1/20240525_T001922
2024-05-25 00:19:22 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/Transformer_ettm1/20240525_T001922/tensorboard
2024-05-25 00:19:22 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 00:19:22 [INFO]: Epoch 001 - training loss: 1.1695, validation loss: 0.3295
2024-05-25 00:19:22 [INFO]: Epoch 002 - training loss: 0.7318, validation loss: 0.1681
2024-05-25 00:19:22 [INFO]: Epoch 003 - training loss: 0.6011, validation loss: 0.1053
2024-05-25 00:19:22 [INFO]: Epoch 004 - training loss: 0.5326, validation loss: 0.0815
2024-05-25 00:19:23 [INFO]: Epoch 005 - training loss: 0.4883, validation loss: 0.0692
2024-05-25 00:19:23 [INFO]: Epoch 006 - training loss: 0.4618, validation loss: 0.0640
2024-05-25 00:19:23 [INFO]: Epoch 007 - training loss: 0.4303, validation loss: 0.0560
2024-05-25 00:19:23 [INFO]: Epoch 008 - training loss: 0.4138, validation loss: 0.0559
2024-05-25 00:19:24 [INFO]: Epoch 009 - training loss: 0.3996, validation loss: 0.0500
2024-05-25 00:19:24 [INFO]: Epoch 010 - training loss: 0.3838, validation loss: 0.0491
2024-05-25 00:19:24 [INFO]: Epoch 011 - training loss: 0.3724, validation loss: 0.0458
2024-05-25 00:19:24 [INFO]: Epoch 012 - training loss: 0.3652, validation loss: 0.0569
2024-05-25 00:19:24 [INFO]: Epoch 013 - training loss: 0.3547, validation loss: 0.0431
2024-05-25 00:19:25 [INFO]: Epoch 014 - training loss: 0.3515, validation loss: 0.0492
2024-05-25 00:19:25 [INFO]: Epoch 015 - training loss: 0.3527, validation loss: 0.0389
2024-05-25 00:19:25 [INFO]: Epoch 016 - training loss: 0.3447, validation loss: 0.0445
2024-05-25 00:19:25 [INFO]: Epoch 017 - training loss: 0.3290, validation loss: 0.0371
2024-05-25 00:19:25 [INFO]: Epoch 018 - training loss: 0.3288, validation loss: 0.0382
2024-05-25 00:19:26 [INFO]: Epoch 019 - training loss: 0.3256, validation loss: 0.0588
2024-05-25 00:19:26 [INFO]: Epoch 020 - training loss: 0.3282, validation loss: 0.0371
2024-05-25 00:19:26 [INFO]: Epoch 021 - training loss: 0.3176, validation loss: 0.0388
2024-05-25 00:19:26 [INFO]: Epoch 022 - training loss: 0.3068, validation loss: 0.0358
2024-05-25 00:19:27 [INFO]: Epoch 023 - training loss: 0.3085, validation loss: 0.0353
2024-05-25 00:19:27 [INFO]: Epoch 024 - training loss: 0.2952, validation loss: 0.0335
2024-05-25 00:19:27 [INFO]: Epoch 025 - training loss: 0.2987, validation loss: 0.0360
2024-05-25 00:19:27 [INFO]: Epoch 026 - training loss: 0.3034, validation loss: 0.0343
2024-05-25 00:19:27 [INFO]: Epoch 027 - training loss: 0.3021, validation loss: 0.0323
2024-05-25 00:19:28 [INFO]: Epoch 028 - training loss: 0.2938, validation loss: 0.0319
2024-05-25 00:19:28 [INFO]: Epoch 029 - training loss: 0.2853, validation loss: 0.0312
2024-05-25 00:19:28 [INFO]: Epoch 030 - training loss: 0.2796, validation loss: 0.0288
2024-05-25 00:19:28 [INFO]: Epoch 031 - training loss: 0.2740, validation loss: 0.0315
2024-05-25 00:19:29 [INFO]: Epoch 032 - training loss: 0.2762, validation loss: 0.0384
2024-05-25 00:19:29 [INFO]: Epoch 033 - training loss: 0.2750, validation loss: 0.0341
2024-05-25 00:19:29 [INFO]: Epoch 034 - training loss: 0.2677, validation loss: 0.0324
2024-05-25 00:19:29 [INFO]: Epoch 035 - training loss: 0.2673, validation loss: 0.0315
2024-05-25 00:19:29 [INFO]: Epoch 036 - training loss: 0.2611, validation loss: 0.0302
2024-05-25 00:19:30 [INFO]: Epoch 037 - training loss: 0.2578, validation loss: 0.0296
2024-05-25 00:19:30 [INFO]: Epoch 038 - training loss: 0.2585, validation loss: 0.0277
2024-05-25 00:19:30 [INFO]: Epoch 039 - training loss: 0.2545, validation loss: 0.0284
2024-05-25 00:19:30 [INFO]: Epoch 040 - training loss: 0.2575, validation loss: 0.0256
2024-05-25 00:19:30 [INFO]: Epoch 041 - training loss: 0.2489, validation loss: 0.0253
2024-05-25 00:19:31 [INFO]: Epoch 042 - training loss: 0.2531, validation loss: 0.0251
2024-05-25 00:19:31 [INFO]: Epoch 043 - training loss: 0.2464, validation loss: 0.0246
2024-05-25 00:19:31 [INFO]: Epoch 044 - training loss: 0.2470, validation loss: 0.0295
2024-05-25 00:19:31 [INFO]: Epoch 045 - training loss: 0.2514, validation loss: 0.0283
2024-05-25 00:19:32 [INFO]: Epoch 046 - training loss: 0.2501, validation loss: 0.0253
2024-05-25 00:19:32 [INFO]: Epoch 047 - training loss: 0.2437, validation loss: 0.0261
2024-05-25 00:19:32 [INFO]: Epoch 048 - training loss: 0.2413, validation loss: 0.0244
2024-05-25 00:19:32 [INFO]: Epoch 049 - training loss: 0.2363, validation loss: 0.0265
2024-05-25 00:19:32 [INFO]: Epoch 050 - training loss: 0.2353, validation loss: 0.0256
2024-05-25 00:19:33 [INFO]: Epoch 051 - training loss: 0.2362, validation loss: 0.0323
2024-05-25 00:19:33 [INFO]: Epoch 052 - training loss: 0.2475, validation loss: 0.0292
2024-05-25 00:19:33 [INFO]: Epoch 053 - training loss: 0.2460, validation loss: 0.0298
2024-05-25 00:19:33 [INFO]: Epoch 054 - training loss: 0.2405, validation loss: 0.0254
2024-05-25 00:19:34 [INFO]: Epoch 055 - training loss: 0.2295, validation loss: 0.0216
2024-05-25 00:19:34 [INFO]: Epoch 056 - training loss: 0.2212, validation loss: 0.0227
2024-05-25 00:19:34 [INFO]: Epoch 057 - training loss: 0.2233, validation loss: 0.0253
2024-05-25 00:19:34 [INFO]: Epoch 058 - training loss: 0.2327, validation loss: 0.0266
2024-05-25 00:19:34 [INFO]: Epoch 059 - training loss: 0.2269, validation loss: 0.0216
2024-05-25 00:19:35 [INFO]: Epoch 060 - training loss: 0.2243, validation loss: 0.0232
2024-05-25 00:19:35 [INFO]: Epoch 061 - training loss: 0.2217, validation loss: 0.0238
2024-05-25 00:19:35 [INFO]: Epoch 062 - training loss: 0.2167, validation loss: 0.0222
2024-05-25 00:19:35 [INFO]: Epoch 063 - training loss: 0.2176, validation loss: 0.0261
2024-05-25 00:19:35 [INFO]: Epoch 064 - training loss: 0.2164, validation loss: 0.0222
2024-05-25 00:19:36 [INFO]: Epoch 065 - training loss: 0.2094, validation loss: 0.0235
2024-05-25 00:19:36 [INFO]: Epoch 066 - training loss: 0.2222, validation loss: 0.0242
2024-05-25 00:19:36 [INFO]: Epoch 067 - training loss: 0.2181, validation loss: 0.0214
2024-05-25 00:19:36 [INFO]: Epoch 068 - training loss: 0.2165, validation loss: 0.0247
2024-05-25 00:19:37 [INFO]: Epoch 069 - training loss: 0.2139, validation loss: 0.0218
2024-05-25 00:19:37 [INFO]: Epoch 070 - training loss: 0.2105, validation loss: 0.0248
2024-05-25 00:19:37 [INFO]: Epoch 071 - training loss: 0.2089, validation loss: 0.0204
2024-05-25 00:19:37 [INFO]: Epoch 072 - training loss: 0.2100, validation loss: 0.0213
2024-05-25 00:19:37 [INFO]: Epoch 073 - training loss: 0.2048, validation loss: 0.0201
2024-05-25 00:19:38 [INFO]: Epoch 074 - training loss: 0.2061, validation loss: 0.0212
2024-05-25 00:19:38 [INFO]: Epoch 075 - training loss: 0.2018, validation loss: 0.0207
2024-05-25 00:19:38 [INFO]: Epoch 076 - training loss: 0.2023, validation loss: 0.0208
2024-05-25 00:19:38 [INFO]: Epoch 077 - training loss: 0.2030, validation loss: 0.0213
2024-05-25 00:19:38 [INFO]: Epoch 078 - training loss: 0.2052, validation loss: 0.0222
2024-05-25 00:19:39 [INFO]: Epoch 079 - training loss: 0.2096, validation loss: 0.0223
2024-05-25 00:19:39 [INFO]: Epoch 080 - training loss: 0.2095, validation loss: 0.0211
2024-05-25 00:19:39 [INFO]: Epoch 081 - training loss: 0.2014, validation loss: 0.0219
2024-05-25 00:19:39 [INFO]: Epoch 082 - training loss: 0.2014, validation loss: 0.0191
2024-05-25 00:19:40 [INFO]: Epoch 083 - training loss: 0.2030, validation loss: 0.0230
2024-05-25 00:19:40 [INFO]: Epoch 084 - training loss: 0.2026, validation loss: 0.0248
2024-05-25 00:19:40 [INFO]: Epoch 085 - training loss: 0.2014, validation loss: 0.0213
2024-05-25 00:19:40 [INFO]: Epoch 086 - training loss: 0.2007, validation loss: 0.0222
2024-05-25 00:19:40 [INFO]: Epoch 087 - training loss: 0.2012, validation loss: 0.0223
2024-05-25 00:19:41 [INFO]: Epoch 088 - training loss: 0.2100, validation loss: 0.0209
2024-05-25 00:19:41 [INFO]: Epoch 089 - training loss: 0.1995, validation loss: 0.0237
2024-05-25 00:19:41 [INFO]: Epoch 090 - training loss: 0.1984, validation loss: 0.0212
2024-05-25 00:19:41 [INFO]: Epoch 091 - training loss: 0.2013, validation loss: 0.0214
2024-05-25 00:19:42 [INFO]: Epoch 092 - training loss: 0.2019, validation loss: 0.0203
2024-05-25 00:19:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:19:42 [INFO]: Finished training. The best model is from epoch#82.
2024-05-25 00:19:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/Transformer_ettm1/20240525_T001922/Transformer.pypots
2024-05-25 00:19:42 [INFO]: Transformer on ETTm1: MAE=0.1140, MSE=0.0265
2024-05-25 00:19:42 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/Transformer_ettm1/imputation.pkl
2024-05-25 00:19:42 [INFO]: Using the given device: cuda:0
2024-05-25 00:19:42 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/TimesNet_ettm1/20240525_T001942
2024-05-25 00:19:42 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/TimesNet_ettm1/20240525_T001942/tensorboard
2024-05-25 00:19:42 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 00:19:42 [INFO]: Epoch 001 - training loss: 0.1579, validation loss: 0.0469
2024-05-25 00:19:42 [INFO]: Epoch 002 - training loss: 0.0704, validation loss: 0.0374
2024-05-25 00:19:42 [INFO]: Epoch 003 - training loss: 0.0531, validation loss: 0.0353
2024-05-25 00:19:43 [INFO]: Epoch 004 - training loss: 0.0483, validation loss: 0.0318
2024-05-25 00:19:43 [INFO]: Epoch 005 - training loss: 0.0464, validation loss: 0.0318
2024-05-25 00:19:43 [INFO]: Epoch 006 - training loss: 0.0471, validation loss: 0.0311
2024-05-25 00:19:43 [INFO]: Epoch 007 - training loss: 0.0466, validation loss: 0.0314
2024-05-25 00:19:43 [INFO]: Epoch 008 - training loss: 0.0477, validation loss: 0.0325
2024-05-25 00:19:44 [INFO]: Epoch 009 - training loss: 0.0481, validation loss: 0.0307
2024-05-25 00:19:44 [INFO]: Epoch 010 - training loss: 0.0444, validation loss: 0.0298
2024-05-25 00:19:44 [INFO]: Epoch 011 - training loss: 0.0480, validation loss: 0.0305
2024-05-25 00:19:44 [INFO]: Epoch 012 - training loss: 0.0445, validation loss: 0.0307
2024-05-25 00:19:45 [INFO]: Epoch 013 - training loss: 0.0458, validation loss: 0.0308
2024-05-25 00:19:45 [INFO]: Epoch 014 - training loss: 0.0404, validation loss: 0.0283
2024-05-25 00:19:45 [INFO]: Epoch 015 - training loss: 0.0407, validation loss: 0.0300
2024-05-25 00:19:45 [INFO]: Epoch 016 - training loss: 0.0401, validation loss: 0.0272
2024-05-25 00:19:45 [INFO]: Epoch 017 - training loss: 0.0434, validation loss: 0.0287
2024-05-25 00:19:46 [INFO]: Epoch 018 - training loss: 0.0415, validation loss: 0.0310
2024-05-25 00:19:46 [INFO]: Epoch 019 - training loss: 0.0445, validation loss: 0.0318
2024-05-25 00:19:46 [INFO]: Epoch 020 - training loss: 0.0429, validation loss: 0.0286
2024-05-25 00:19:46 [INFO]: Epoch 021 - training loss: 0.0389, validation loss: 0.0296
2024-05-25 00:19:46 [INFO]: Epoch 022 - training loss: 0.0408, validation loss: 0.0284
2024-05-25 00:19:47 [INFO]: Epoch 023 - training loss: 0.0425, validation loss: 0.0308
2024-05-25 00:19:47 [INFO]: Epoch 024 - training loss: 0.0407, validation loss: 0.0250
2024-05-25 00:19:47 [INFO]: Epoch 025 - training loss: 0.0404, validation loss: 0.0268
2024-05-25 00:19:47 [INFO]: Epoch 026 - training loss: 0.0384, validation loss: 0.0254
2024-05-25 00:19:47 [INFO]: Epoch 027 - training loss: 0.0390, validation loss: 0.0316
2024-05-25 00:19:48 [INFO]: Epoch 028 - training loss: 0.0441, validation loss: 0.0332
2024-05-25 00:19:48 [INFO]: Epoch 029 - training loss: 0.0593, validation loss: 0.0326
2024-05-25 00:19:48 [INFO]: Epoch 030 - training loss: 0.0413, validation loss: 0.0271
2024-05-25 00:19:48 [INFO]: Epoch 031 - training loss: 0.0395, validation loss: 0.0267
2024-05-25 00:19:49 [INFO]: Epoch 032 - training loss: 0.0409, validation loss: 0.0266
2024-05-25 00:19:49 [INFO]: Epoch 033 - training loss: 0.0388, validation loss: 0.0268
2024-05-25 00:19:49 [INFO]: Epoch 034 - training loss: 0.0383, validation loss: 0.0258
2024-05-25 00:19:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:19:49 [INFO]: Finished training. The best model is from epoch#24.
2024-05-25 00:19:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/TimesNet_ettm1/20240525_T001942/TimesNet.pypots
2024-05-25 00:19:49 [INFO]: TimesNet on ETTm1: MAE=0.1131, MSE=0.0274
2024-05-25 00:19:49 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/TimesNet_ettm1/imputation.pkl
2024-05-25 00:19:49 [INFO]: Using the given device: cuda:0
2024-05-25 00:19:49 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949
2024-05-25 00:19:49 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/tensorboard
2024-05-25 00:19:49 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 00:19:51 [INFO]: Epoch 001 - training loss: 0.7263, validation loss: 0.4241
2024-05-25 00:19:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch1_loss0.42413316667079926.pypots
2024-05-25 00:19:53 [INFO]: Epoch 002 - training loss: 0.3988, validation loss: 0.3970
2024-05-25 00:19:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch2_loss0.3969667851924896.pypots
2024-05-25 00:19:55 [INFO]: Epoch 003 - training loss: 0.3154, validation loss: 0.3621
2024-05-25 00:19:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch3_loss0.36206064373254776.pypots
2024-05-25 00:19:57 [INFO]: Epoch 004 - training loss: 0.3953, validation loss: 0.3302
2024-05-25 00:19:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch4_loss0.33023229986429214.pypots
2024-05-25 00:19:59 [INFO]: Epoch 005 - training loss: 0.3301, validation loss: 0.3032
2024-05-25 00:19:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch5_loss0.3032025471329689.pypots
2024-05-25 00:20:02 [INFO]: Epoch 006 - training loss: 0.2771, validation loss: 0.3097
2024-05-25 00:20:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch6_loss0.30970627814531326.pypots
2024-05-25 00:20:04 [INFO]: Epoch 007 - training loss: 0.2600, validation loss: 0.2889
2024-05-25 00:20:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch7_loss0.28886815160512924.pypots
2024-05-25 00:20:06 [INFO]: Epoch 008 - training loss: 0.2876, validation loss: 0.2777
2024-05-25 00:20:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch8_loss0.27773912996053696.pypots
2024-05-25 00:20:08 [INFO]: Epoch 009 - training loss: 0.2823, validation loss: 0.2855
2024-05-25 00:20:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch9_loss0.28549545258283615.pypots
2024-05-25 00:20:10 [INFO]: Epoch 010 - training loss: 0.2544, validation loss: 0.2562
2024-05-25 00:20:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch10_loss0.2562270238995552.pypots
2024-05-25 00:20:12 [INFO]: Epoch 011 - training loss: 0.2673, validation loss: 0.2541
2024-05-25 00:20:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch11_loss0.2541181109845638.pypots
2024-05-25 00:20:14 [INFO]: Epoch 012 - training loss: 0.2305, validation loss: 0.2606
2024-05-25 00:20:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch12_loss0.26064806431531906.pypots
2024-05-25 00:20:16 [INFO]: Epoch 013 - training loss: 0.2503, validation loss: 0.2243
2024-05-25 00:20:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch13_loss0.224275141954422.pypots
2024-05-25 00:20:18 [INFO]: Epoch 014 - training loss: 0.2113, validation loss: 0.2210
2024-05-25 00:20:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch14_loss0.22101648896932602.pypots
2024-05-25 00:20:20 [INFO]: Epoch 015 - training loss: 0.2588, validation loss: 0.2190
2024-05-25 00:20:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch15_loss0.21901042759418488.pypots
2024-05-25 00:20:22 [INFO]: Epoch 016 - training loss: 0.2167, validation loss: 0.2133
2024-05-25 00:20:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch16_loss0.21325604245066643.pypots
2024-05-25 00:20:24 [INFO]: Epoch 017 - training loss: 0.2050, validation loss: 0.2124
2024-05-25 00:20:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch17_loss0.2124325968325138.pypots
2024-05-25 00:20:27 [INFO]: Epoch 018 - training loss: 0.2179, validation loss: 0.2134
2024-05-25 00:20:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch18_loss0.2133890949189663.pypots
2024-05-25 00:20:29 [INFO]: Epoch 019 - training loss: 0.2193, validation loss: 0.2293
2024-05-25 00:20:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch19_loss0.2293415665626526.pypots
2024-05-25 00:20:31 [INFO]: Epoch 020 - training loss: 0.2175, validation loss: 0.1952
2024-05-25 00:20:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch20_loss0.1951523758471012.pypots
2024-05-25 00:20:33 [INFO]: Epoch 021 - training loss: 0.2101, validation loss: 0.1891
2024-05-25 00:20:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch21_loss0.18906068801879883.pypots
2024-05-25 00:20:35 [INFO]: Epoch 022 - training loss: 0.2408, validation loss: 0.1976
2024-05-25 00:20:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch22_loss0.19764814525842667.pypots
2024-05-25 00:20:37 [INFO]: Epoch 023 - training loss: 0.2387, validation loss: 0.1892
2024-05-25 00:20:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch23_loss0.18919771537184715.pypots
2024-05-25 00:20:39 [INFO]: Epoch 024 - training loss: 0.2084, validation loss: 0.1862
2024-05-25 00:20:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch24_loss0.1861768625676632.pypots
2024-05-25 00:20:41 [INFO]: Epoch 025 - training loss: 0.2042, validation loss: 0.1800
2024-05-25 00:20:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch25_loss0.1800452284514904.pypots
2024-05-25 00:20:43 [INFO]: Epoch 026 - training loss: 0.1697, validation loss: 0.1974
2024-05-25 00:20:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch26_loss0.1973949633538723.pypots
2024-05-25 00:20:45 [INFO]: Epoch 027 - training loss: 0.2319, validation loss: 0.1775
2024-05-25 00:20:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch27_loss0.17747238278388977.pypots
2024-05-25 00:20:47 [INFO]: Epoch 028 - training loss: 0.1943, validation loss: 0.1720
2024-05-25 00:20:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch28_loss0.17204581573605537.pypots
2024-05-25 00:20:49 [INFO]: Epoch 029 - training loss: 0.1872, validation loss: 0.1645
2024-05-25 00:20:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch29_loss0.1644916981458664.pypots
2024-05-25 00:20:51 [INFO]: Epoch 030 - training loss: 0.1707, validation loss: 0.1642
2024-05-25 00:20:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch30_loss0.16420809924602509.pypots
2024-05-25 00:20:54 [INFO]: Epoch 031 - training loss: 0.1850, validation loss: 0.1619
2024-05-25 00:20:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch31_loss0.161942046135664.pypots
2024-05-25 00:20:56 [INFO]: Epoch 032 - training loss: 0.1858, validation loss: 0.1556
2024-05-25 00:20:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch32_loss0.15562478825449944.pypots
2024-05-25 00:20:58 [INFO]: Epoch 033 - training loss: 0.2050, validation loss: 0.1536
2024-05-25 00:20:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch33_loss0.15360556542873383.pypots
2024-05-25 00:21:00 [INFO]: Epoch 034 - training loss: 0.1594, validation loss: 0.1625
2024-05-25 00:21:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch34_loss0.16251958906650543.pypots
2024-05-25 00:21:02 [INFO]: Epoch 035 - training loss: 0.2109, validation loss: 0.1850
2024-05-25 00:21:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch35_loss0.18502403050661087.pypots
2024-05-25 00:21:04 [INFO]: Epoch 036 - training loss: 0.2031, validation loss: 0.2278
2024-05-25 00:21:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch36_loss0.22777091339230537.pypots
2024-05-25 00:21:06 [INFO]: Epoch 037 - training loss: 0.1984, validation loss: 0.1991
2024-05-25 00:21:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch37_loss0.19912758097052574.pypots
2024-05-25 00:21:08 [INFO]: Epoch 038 - training loss: 0.1695, validation loss: 0.1802
2024-05-25 00:21:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch38_loss0.18018632009625435.pypots
2024-05-25 00:21:10 [INFO]: Epoch 039 - training loss: 0.1896, validation loss: 0.1772
2024-05-25 00:21:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch39_loss0.17721706628799438.pypots
2024-05-25 00:21:12 [INFO]: Epoch 040 - training loss: 0.1852, validation loss: 0.1741
2024-05-25 00:21:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch40_loss0.17411722987890244.pypots
2024-05-25 00:21:14 [INFO]: Epoch 041 - training loss: 0.1535, validation loss: 0.1652
2024-05-25 00:21:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch41_loss0.16521498188376427.pypots
2024-05-25 00:21:16 [INFO]: Epoch 042 - training loss: 0.1536, validation loss: 0.1607
2024-05-25 00:21:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch42_loss0.16073698550462723.pypots
2024-05-25 00:21:19 [INFO]: Epoch 043 - training loss: 0.1737, validation loss: 0.1570
2024-05-25 00:21:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI_epoch43_loss0.1570090539753437.pypots
2024-05-25 00:21:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:21:19 [INFO]: Finished training. The best model is from epoch#33.
2024-05-25 00:21:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T001949/CSDI.pypots
2024-05-25 00:21:34 [INFO]: CSDI on ETTm1: MAE=0.1681, MSE=0.0614
2024-05-25 00:21:34 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/CSDI_ettm1/imputation.pkl
2024-05-25 00:21:34 [INFO]: Using the given device: cuda:0
2024-05-25 00:21:34 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/GPVAE_ettm1/20240525_T002134
2024-05-25 00:21:34 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/GPVAE_ettm1/20240525_T002134/tensorboard
2024-05-25 00:21:34 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 00:21:35 [INFO]: Epoch 001 - training loss: 23672.3661, validation loss: 0.9966
2024-05-25 00:21:35 [INFO]: Epoch 002 - training loss: 21470.2850, validation loss: 0.9767
2024-05-25 00:21:35 [INFO]: Epoch 003 - training loss: 19460.2046, validation loss: 0.9578
2024-05-25 00:21:35 [INFO]: Epoch 004 - training loss: 17405.2745, validation loss: 0.9236
2024-05-25 00:21:35 [INFO]: Epoch 005 - training loss: 15547.9075, validation loss: 0.8529
2024-05-25 00:21:35 [INFO]: Epoch 006 - training loss: 13886.8311, validation loss: 0.7424
2024-05-25 00:21:35 [INFO]: Epoch 007 - training loss: 12740.0509, validation loss: 0.6261
2024-05-25 00:21:35 [INFO]: Epoch 008 - training loss: 12113.2700, validation loss: 0.5335
2024-05-25 00:21:36 [INFO]: Epoch 009 - training loss: 11355.6136, validation loss: 0.4891
2024-05-25 00:21:36 [INFO]: Epoch 010 - training loss: 10882.1111, validation loss: 0.4720
2024-05-25 00:21:36 [INFO]: Epoch 011 - training loss: 10643.5270, validation loss: 0.4665
2024-05-25 00:21:36 [INFO]: Epoch 012 - training loss: 10501.4794, validation loss: 0.4606
2024-05-25 00:21:36 [INFO]: Epoch 013 - training loss: 10265.1394, validation loss: 0.4529
2024-05-25 00:21:36 [INFO]: Epoch 014 - training loss: 10113.2881, validation loss: 0.4341
2024-05-25 00:21:36 [INFO]: Epoch 015 - training loss: 10142.0425, validation loss: 0.4167
2024-05-25 00:21:36 [INFO]: Epoch 016 - training loss: 10016.5994, validation loss: 0.4083
2024-05-25 00:21:37 [INFO]: Epoch 017 - training loss: 9864.1393, validation loss: 0.3912
2024-05-25 00:21:37 [INFO]: Epoch 018 - training loss: 9844.4334, validation loss: 0.3714
2024-05-25 00:21:37 [INFO]: Epoch 019 - training loss: 9737.5688, validation loss: 0.3463
2024-05-25 00:21:37 [INFO]: Epoch 020 - training loss: 9715.7094, validation loss: 0.3253
2024-05-25 00:21:37 [INFO]: Epoch 021 - training loss: 9664.0972, validation loss: 0.3047
2024-05-25 00:21:37 [INFO]: Epoch 022 - training loss: 9625.8895, validation loss: 0.2845
2024-05-25 00:21:37 [INFO]: Epoch 023 - training loss: 9599.5450, validation loss: 0.2660
2024-05-25 00:21:37 [INFO]: Epoch 024 - training loss: 9592.0588, validation loss: 0.2495
2024-05-25 00:21:38 [INFO]: Epoch 025 - training loss: 9596.8525, validation loss: 0.2319
2024-05-25 00:21:38 [INFO]: Epoch 026 - training loss: 9539.0412, validation loss: 0.2267
2024-05-25 00:21:38 [INFO]: Epoch 027 - training loss: 9526.0435, validation loss: 0.2145
2024-05-25 00:21:38 [INFO]: Epoch 028 - training loss: 9505.8523, validation loss: 0.2037
2024-05-25 00:21:38 [INFO]: Epoch 029 - training loss: 9507.9357, validation loss: 0.1939
2024-05-25 00:21:38 [INFO]: Epoch 030 - training loss: 9488.3787, validation loss: 0.1840
2024-05-25 00:21:38 [INFO]: Epoch 031 - training loss: 9468.2266, validation loss: 0.1734
2024-05-25 00:21:38 [INFO]: Epoch 032 - training loss: 9460.2913, validation loss: 0.1709
2024-05-25 00:21:38 [INFO]: Epoch 033 - training loss: 9455.0849, validation loss: 0.1630
2024-05-25 00:21:39 [INFO]: Epoch 034 - training loss: 9449.4026, validation loss: 0.1562
2024-05-25 00:21:39 [INFO]: Epoch 035 - training loss: 9433.6338, validation loss: 0.1515
2024-05-25 00:21:39 [INFO]: Epoch 036 - training loss: 9428.1408, validation loss: 0.1488
2024-05-25 00:21:39 [INFO]: Epoch 037 - training loss: 9422.9810, validation loss: 0.1435
2024-05-25 00:21:39 [INFO]: Epoch 038 - training loss: 9417.0421, validation loss: 0.1408
2024-05-25 00:21:39 [INFO]: Epoch 039 - training loss: 9410.2354, validation loss: 0.1371
2024-05-25 00:21:39 [INFO]: Epoch 040 - training loss: 9420.8539, validation loss: 0.1337
2024-05-25 00:21:39 [INFO]: Epoch 041 - training loss: 9418.8041, validation loss: 0.1320
2024-05-25 00:21:40 [INFO]: Epoch 042 - training loss: 9398.4363, validation loss: 0.1302
2024-05-25 00:21:40 [INFO]: Epoch 043 - training loss: 9404.6014, validation loss: 0.1287
2024-05-25 00:21:40 [INFO]: Epoch 044 - training loss: 9389.6497, validation loss: 0.1261
2024-05-25 00:21:40 [INFO]: Epoch 045 - training loss: 9387.5029, validation loss: 0.1240
2024-05-25 00:21:40 [INFO]: Epoch 046 - training loss: 9390.5544, validation loss: 0.1234
2024-05-25 00:21:40 [INFO]: Epoch 047 - training loss: 9378.1913, validation loss: 0.1242
2024-05-25 00:21:40 [INFO]: Epoch 048 - training loss: 9381.4286, validation loss: 0.1211
2024-05-25 00:21:40 [INFO]: Epoch 049 - training loss: 9378.3350, validation loss: 0.1201
2024-05-25 00:21:41 [INFO]: Epoch 050 - training loss: 9371.4807, validation loss: 0.1183
2024-05-25 00:21:41 [INFO]: Epoch 051 - training loss: 9371.5692, validation loss: 0.1179
2024-05-25 00:21:41 [INFO]: Epoch 052 - training loss: 9366.6437, validation loss: 0.1159
2024-05-25 00:21:41 [INFO]: Epoch 053 - training loss: 9370.4270, validation loss: 0.1172
2024-05-25 00:21:41 [INFO]: Epoch 054 - training loss: 9375.3516, validation loss: 0.1158
2024-05-25 00:21:41 [INFO]: Epoch 055 - training loss: 9357.8149, validation loss: 0.1135
2024-05-25 00:21:41 [INFO]: Epoch 056 - training loss: 9358.8575, validation loss: 0.1140
2024-05-25 00:21:41 [INFO]: Epoch 057 - training loss: 9354.9701, validation loss: 0.1122
2024-05-25 00:21:42 [INFO]: Epoch 058 - training loss: 9356.5670, validation loss: 0.1110
2024-05-25 00:21:42 [INFO]: Epoch 059 - training loss: 9354.6284, validation loss: 0.1111
2024-05-25 00:21:42 [INFO]: Epoch 060 - training loss: 9352.5312, validation loss: 0.1112
2024-05-25 00:21:42 [INFO]: Epoch 061 - training loss: 9358.0208, validation loss: 0.1092
2024-05-25 00:21:42 [INFO]: Epoch 062 - training loss: 9348.8217, validation loss: 0.1092
2024-05-25 00:21:42 [INFO]: Epoch 063 - training loss: 9347.5190, validation loss: 0.1086
2024-05-25 00:21:42 [INFO]: Epoch 064 - training loss: 9344.8463, validation loss: 0.1083
2024-05-25 00:21:42 [INFO]: Epoch 065 - training loss: 9344.9474, validation loss: 0.1074
2024-05-25 00:21:43 [INFO]: Epoch 066 - training loss: 9345.0798, validation loss: 0.1080
2024-05-25 00:21:43 [INFO]: Epoch 067 - training loss: 9342.5525, validation loss: 0.1061
2024-05-25 00:21:43 [INFO]: Epoch 068 - training loss: 9341.7377, validation loss: 0.1035
2024-05-25 00:21:43 [INFO]: Epoch 069 - training loss: 9346.6250, validation loss: 0.1038
2024-05-25 00:21:43 [INFO]: Epoch 070 - training loss: 9340.4930, validation loss: 0.1044
2024-05-25 00:21:43 [INFO]: Epoch 071 - training loss: 9336.7072, validation loss: 0.1043
2024-05-25 00:21:43 [INFO]: Epoch 072 - training loss: 9337.6180, validation loss: 0.1024
2024-05-25 00:21:43 [INFO]: Epoch 073 - training loss: 9339.8970, validation loss: 0.1023
2024-05-25 00:21:44 [INFO]: Epoch 074 - training loss: 9336.7095, validation loss: 0.1030
2024-05-25 00:21:44 [INFO]: Epoch 075 - training loss: 9334.8522, validation loss: 0.1020
2024-05-25 00:21:44 [INFO]: Epoch 076 - training loss: 9335.2468, validation loss: 0.1014
2024-05-25 00:21:44 [INFO]: Epoch 077 - training loss: 9333.3229, validation loss: 0.1009
2024-05-25 00:21:44 [INFO]: Epoch 078 - training loss: 9331.8727, validation loss: 0.1008
2024-05-25 00:21:44 [INFO]: Epoch 079 - training loss: 9331.6199, validation loss: 0.1006
2024-05-25 00:21:44 [INFO]: Epoch 080 - training loss: 9331.1027, validation loss: 0.1008
2024-05-25 00:21:44 [INFO]: Epoch 081 - training loss: 9331.4001, validation loss: 0.0979
2024-05-25 00:21:45 [INFO]: Epoch 082 - training loss: 9330.5406, validation loss: 0.1020
2024-05-25 00:21:45 [INFO]: Epoch 083 - training loss: 9330.8173, validation loss: 0.0973
2024-05-25 00:21:45 [INFO]: Epoch 084 - training loss: 9330.9324, validation loss: 0.0982
2024-05-25 00:21:45 [INFO]: Epoch 085 - training loss: 9327.1567, validation loss: 0.0968
2024-05-25 00:21:45 [INFO]: Epoch 086 - training loss: 9327.1126, validation loss: 0.0967
2024-05-25 00:21:45 [INFO]: Epoch 087 - training loss: 9326.2953, validation loss: 0.0965
2024-05-25 00:21:45 [INFO]: Epoch 088 - training loss: 9325.7910, validation loss: 0.0957
2024-05-25 00:21:45 [INFO]: Epoch 089 - training loss: 9327.2747, validation loss: 0.0965
2024-05-25 00:21:45 [INFO]: Epoch 090 - training loss: 9327.3605, validation loss: 0.0951
2024-05-25 00:21:46 [INFO]: Epoch 091 - training loss: 9323.5315, validation loss: 0.0941
2024-05-25 00:21:46 [INFO]: Epoch 092 - training loss: 9324.6982, validation loss: 0.0946
2024-05-25 00:21:46 [INFO]: Epoch 093 - training loss: 9325.1323, validation loss: 0.0942
2024-05-25 00:21:46 [INFO]: Epoch 094 - training loss: 9323.7685, validation loss: 0.0924
2024-05-25 00:21:46 [INFO]: Epoch 095 - training loss: 9322.7760, validation loss: 0.0930
2024-05-25 00:21:46 [INFO]: Epoch 096 - training loss: 9324.4949, validation loss: 0.0941
2024-05-25 00:21:46 [INFO]: Epoch 097 - training loss: 9324.4887, validation loss: 0.0925
2024-05-25 00:21:46 [INFO]: Epoch 098 - training loss: 9321.9901, validation loss: 0.0947
2024-05-25 00:21:47 [INFO]: Epoch 099 - training loss: 9321.4340, validation loss: 0.0916
2024-05-25 00:21:47 [INFO]: Epoch 100 - training loss: 9321.3635, validation loss: 0.0925
2024-05-25 00:21:47 [INFO]: Epoch 101 - training loss: 9328.7853, validation loss: 0.0921
2024-05-25 00:21:47 [INFO]: Epoch 102 - training loss: 9319.3604, validation loss: 0.0903
2024-05-25 00:21:47 [INFO]: Epoch 103 - training loss: 9318.5161, validation loss: 0.0910
2024-05-25 00:21:47 [INFO]: Epoch 104 - training loss: 9319.3284, validation loss: 0.0905
2024-05-25 00:21:47 [INFO]: Epoch 105 - training loss: 9318.8077, validation loss: 0.0900
2024-05-25 00:21:47 [INFO]: Epoch 106 - training loss: 9320.0541, validation loss: 0.0903
2024-05-25 00:21:48 [INFO]: Epoch 107 - training loss: 9319.9517, validation loss: 0.0904
2024-05-25 00:21:48 [INFO]: Epoch 108 - training loss: 9319.2501, validation loss: 0.0891
2024-05-25 00:21:48 [INFO]: Epoch 109 - training loss: 9317.9916, validation loss: 0.0875
2024-05-25 00:21:48 [INFO]: Epoch 110 - training loss: 9316.5447, validation loss: 0.0888
2024-05-25 00:21:48 [INFO]: Epoch 111 - training loss: 9317.1494, validation loss: 0.0887
2024-05-25 00:21:48 [INFO]: Epoch 112 - training loss: 9317.7830, validation loss: 0.0876
2024-05-25 00:21:48 [INFO]: Epoch 113 - training loss: 9316.0834, validation loss: 0.0860
2024-05-25 00:21:48 [INFO]: Epoch 114 - training loss: 9316.6282, validation loss: 0.0880
2024-05-25 00:21:49 [INFO]: Epoch 115 - training loss: 9319.0674, validation loss: 0.0865
2024-05-25 00:21:49 [INFO]: Epoch 116 - training loss: 9314.7883, validation loss: 0.0882
2024-05-25 00:21:49 [INFO]: Epoch 117 - training loss: 9316.6075, validation loss: 0.0867
2024-05-25 00:21:49 [INFO]: Epoch 118 - training loss: 9314.6432, validation loss: 0.0857
2024-05-25 00:21:49 [INFO]: Epoch 119 - training loss: 9315.9579, validation loss: 0.0862
2024-05-25 00:21:49 [INFO]: Epoch 120 - training loss: 9316.1107, validation loss: 0.0851
2024-05-25 00:21:49 [INFO]: Epoch 121 - training loss: 9316.3259, validation loss: 0.0844
2024-05-25 00:21:49 [INFO]: Epoch 122 - training loss: 9313.8276, validation loss: 0.0856
2024-05-25 00:21:50 [INFO]: Epoch 123 - training loss: 9313.0541, validation loss: 0.0846
2024-05-25 00:21:50 [INFO]: Epoch 124 - training loss: 9314.2415, validation loss: 0.0842
2024-05-25 00:21:50 [INFO]: Epoch 125 - training loss: 9313.7456, validation loss: 0.0839
2024-05-25 00:21:50 [INFO]: Epoch 126 - training loss: 9313.8470, validation loss: 0.0840
2024-05-25 00:21:50 [INFO]: Epoch 127 - training loss: 9313.4304, validation loss: 0.0837
2024-05-25 00:21:50 [INFO]: Epoch 128 - training loss: 9312.8293, validation loss: 0.0837
2024-05-25 00:21:50 [INFO]: Epoch 129 - training loss: 9313.0148, validation loss: 0.0841
2024-05-25 00:21:50 [INFO]: Epoch 130 - training loss: 9313.0589, validation loss: 0.0825
2024-05-25 00:21:51 [INFO]: Epoch 131 - training loss: 9311.9581, validation loss: 0.0834
2024-05-25 00:21:51 [INFO]: Epoch 132 - training loss: 9311.6024, validation loss: 0.0830
2024-05-25 00:21:51 [INFO]: Epoch 133 - training loss: 9311.9376, validation loss: 0.0815
2024-05-25 00:21:51 [INFO]: Epoch 134 - training loss: 9311.6905, validation loss: 0.0839
2024-05-25 00:21:51 [INFO]: Epoch 135 - training loss: 9312.7621, validation loss: 0.0813
2024-05-25 00:21:51 [INFO]: Epoch 136 - training loss: 9311.7793, validation loss: 0.0826
2024-05-25 00:21:51 [INFO]: Epoch 137 - training loss: 9311.1719, validation loss: 0.0816
2024-05-25 00:21:51 [INFO]: Epoch 138 - training loss: 9310.9338, validation loss: 0.0800
2024-05-25 00:21:52 [INFO]: Epoch 139 - training loss: 9311.1500, validation loss: 0.0802
2024-05-25 00:21:52 [INFO]: Epoch 140 - training loss: 9310.7013, validation loss: 0.0821
2024-05-25 00:21:52 [INFO]: Epoch 141 - training loss: 9313.5682, validation loss: 0.0815
2024-05-25 00:21:52 [INFO]: Epoch 142 - training loss: 9309.8651, validation loss: 0.0798
2024-05-25 00:21:52 [INFO]: Epoch 143 - training loss: 9310.3591, validation loss: 0.0801
2024-05-25 00:21:52 [INFO]: Epoch 144 - training loss: 9310.2843, validation loss: 0.0808
2024-05-25 00:21:52 [INFO]: Epoch 145 - training loss: 9310.3613, validation loss: 0.0800
2024-05-25 00:21:52 [INFO]: Epoch 146 - training loss: 9309.3281, validation loss: 0.0809
2024-05-25 00:21:53 [INFO]: Epoch 147 - training loss: 9308.8518, validation loss: 0.0791
2024-05-25 00:21:53 [INFO]: Epoch 148 - training loss: 9308.8420, validation loss: 0.0795
2024-05-25 00:21:53 [INFO]: Epoch 149 - training loss: 9309.8999, validation loss: 0.0800
2024-05-25 00:21:53 [INFO]: Epoch 150 - training loss: 9308.3529, validation loss: 0.0800
2024-05-25 00:21:53 [INFO]: Epoch 151 - training loss: 9309.7029, validation loss: 0.0805
2024-05-25 00:21:53 [INFO]: Epoch 152 - training loss: 9308.9358, validation loss: 0.0807
2024-05-25 00:21:53 [INFO]: Epoch 153 - training loss: 9309.3622, validation loss: 0.0790
2024-05-25 00:21:53 [INFO]: Epoch 154 - training loss: 9309.7410, validation loss: 0.0785
2024-05-25 00:21:53 [INFO]: Epoch 155 - training loss: 9308.2112, validation loss: 0.0792
2024-05-25 00:21:54 [INFO]: Epoch 156 - training loss: 9307.4067, validation loss: 0.0785
2024-05-25 00:21:54 [INFO]: Epoch 157 - training loss: 9308.1529, validation loss: 0.0791
2024-05-25 00:21:54 [INFO]: Epoch 158 - training loss: 9308.6693, validation loss: 0.0781
2024-05-25 00:21:54 [INFO]: Epoch 159 - training loss: 9307.7185, validation loss: 0.0790
2024-05-25 00:21:54 [INFO]: Epoch 160 - training loss: 9307.2114, validation loss: 0.0792
2024-05-25 00:21:54 [INFO]: Epoch 161 - training loss: 9309.0283, validation loss: 0.0784
2024-05-25 00:21:54 [INFO]: Epoch 162 - training loss: 9307.3333, validation loss: 0.0786
2024-05-25 00:21:54 [INFO]: Epoch 163 - training loss: 9307.3601, validation loss: 0.0780
2024-05-25 00:21:55 [INFO]: Epoch 164 - training loss: 9306.8037, validation loss: 0.0781
2024-05-25 00:21:55 [INFO]: Epoch 165 - training loss: 9307.2571, validation loss: 0.0786
2024-05-25 00:21:55 [INFO]: Epoch 166 - training loss: 9307.3636, validation loss: 0.0772
2024-05-25 00:21:55 [INFO]: Epoch 167 - training loss: 9307.2943, validation loss: 0.0786
2024-05-25 00:21:55 [INFO]: Epoch 168 - training loss: 9306.5776, validation loss: 0.0770
2024-05-25 00:21:55 [INFO]: Epoch 169 - training loss: 9307.0178, validation loss: 0.0779
2024-05-25 00:21:55 [INFO]: Epoch 170 - training loss: 9306.5098, validation loss: 0.0770
2024-05-25 00:21:55 [INFO]: Epoch 171 - training loss: 9306.4698, validation loss: 0.0755
2024-05-25 00:21:56 [INFO]: Epoch 172 - training loss: 9306.8718, validation loss: 0.0765
2024-05-25 00:21:56 [INFO]: Epoch 173 - training loss: 9305.8291, validation loss: 0.0760
2024-05-25 00:21:56 [INFO]: Epoch 174 - training loss: 9304.9544, validation loss: 0.0754
2024-05-25 00:21:56 [INFO]: Epoch 175 - training loss: 9306.8065, validation loss: 0.0753
2024-05-25 00:21:56 [INFO]: Epoch 176 - training loss: 9307.0421, validation loss: 0.0756
2024-05-25 00:21:56 [INFO]: Epoch 177 - training loss: 9306.7100, validation loss: 0.0754
2024-05-25 00:21:56 [INFO]: Epoch 178 - training loss: 9306.8702, validation loss: 0.0751
2024-05-25 00:21:56 [INFO]: Epoch 179 - training loss: 9305.3389, validation loss: 0.0760
2024-05-25 00:21:57 [INFO]: Epoch 180 - training loss: 9307.6264, validation loss: 0.0754
2024-05-25 00:21:57 [INFO]: Epoch 181 - training loss: 9305.4651, validation loss: 0.0744
2024-05-25 00:21:57 [INFO]: Epoch 182 - training loss: 9305.4020, validation loss: 0.0758
2024-05-25 00:21:57 [INFO]: Epoch 183 - training loss: 9305.4237, validation loss: 0.0746
2024-05-25 00:21:57 [INFO]: Epoch 184 - training loss: 9305.3862, validation loss: 0.0739
2024-05-25 00:21:57 [INFO]: Epoch 185 - training loss: 9305.2946, validation loss: 0.0756
2024-05-25 00:21:57 [INFO]: Epoch 186 - training loss: 9305.6439, validation loss: 0.0740
2024-05-25 00:21:57 [INFO]: Epoch 187 - training loss: 9307.6333, validation loss: 0.0753
2024-05-25 00:21:58 [INFO]: Epoch 188 - training loss: 9304.8825, validation loss: 0.0766
2024-05-25 00:21:58 [INFO]: Epoch 189 - training loss: 9305.9099, validation loss: 0.0737
2024-05-25 00:21:58 [INFO]: Epoch 190 - training loss: 9304.6018, validation loss: 0.0745
2024-05-25 00:21:58 [INFO]: Epoch 191 - training loss: 9304.3516, validation loss: 0.0753
2024-05-25 00:21:58 [INFO]: Epoch 192 - training loss: 9304.2919, validation loss: 0.0738
2024-05-25 00:21:58 [INFO]: Epoch 193 - training loss: 9304.1682, validation loss: 0.0730
2024-05-25 00:21:58 [INFO]: Epoch 194 - training loss: 9304.4233, validation loss: 0.0738
2024-05-25 00:21:58 [INFO]: Epoch 195 - training loss: 9303.7722, validation loss: 0.0737
2024-05-25 00:21:59 [INFO]: Epoch 196 - training loss: 9303.9178, validation loss: 0.0736
2024-05-25 00:21:59 [INFO]: Epoch 197 - training loss: 9303.7780, validation loss: 0.0747
2024-05-25 00:21:59 [INFO]: Epoch 198 - training loss: 9303.9204, validation loss: 0.0722
2024-05-25 00:21:59 [INFO]: Epoch 199 - training loss: 9304.4437, validation loss: 0.0726
2024-05-25 00:21:59 [INFO]: Epoch 200 - training loss: 9304.9959, validation loss: 0.0722
2024-05-25 00:21:59 [INFO]: Epoch 201 - training loss: 9306.2343, validation loss: 0.0726
2024-05-25 00:21:59 [INFO]: Epoch 202 - training loss: 9304.1207, validation loss: 0.0768
2024-05-25 00:21:59 [INFO]: Epoch 203 - training loss: 9304.0790, validation loss: 0.0723
2024-05-25 00:22:00 [INFO]: Epoch 204 - training loss: 9303.0627, validation loss: 0.0712
2024-05-25 00:22:00 [INFO]: Epoch 205 - training loss: 9303.5217, validation loss: 0.0732
2024-05-25 00:22:00 [INFO]: Epoch 206 - training loss: 9304.8226, validation loss: 0.0736
2024-05-25 00:22:00 [INFO]: Epoch 207 - training loss: 9303.3950, validation loss: 0.0753
2024-05-25 00:22:00 [INFO]: Epoch 208 - training loss: 9303.3597, validation loss: 0.0732
2024-05-25 00:22:00 [INFO]: Epoch 209 - training loss: 9303.3093, validation loss: 0.0723
2024-05-25 00:22:00 [INFO]: Epoch 210 - training loss: 9303.6728, validation loss: 0.0722
2024-05-25 00:22:00 [INFO]: Epoch 211 - training loss: 9303.4255, validation loss: 0.0721
2024-05-25 00:22:01 [INFO]: Epoch 212 - training loss: 9303.2349, validation loss: 0.0709
2024-05-25 00:22:01 [INFO]: Epoch 213 - training loss: 9302.2457, validation loss: 0.0723
2024-05-25 00:22:01 [INFO]: Epoch 214 - training loss: 9305.4073, validation loss: 0.0708
2024-05-25 00:22:01 [INFO]: Epoch 215 - training loss: 9303.0233, validation loss: 0.0726
2024-05-25 00:22:01 [INFO]: Epoch 216 - training loss: 9303.6959, validation loss: 0.0713
2024-05-25 00:22:01 [INFO]: Epoch 217 - training loss: 9302.9230, validation loss: 0.0724
2024-05-25 00:22:01 [INFO]: Epoch 218 - training loss: 9304.8375, validation loss: 0.0710
2024-05-25 00:22:01 [INFO]: Epoch 219 - training loss: 9302.7186, validation loss: 0.0721
2024-05-25 00:22:01 [INFO]: Epoch 220 - training loss: 9302.5425, validation loss: 0.0716
2024-05-25 00:22:02 [INFO]: Epoch 221 - training loss: 9302.5626, validation loss: 0.0704
2024-05-25 00:22:02 [INFO]: Epoch 222 - training loss: 9303.1091, validation loss: 0.0719
2024-05-25 00:22:02 [INFO]: Epoch 223 - training loss: 9302.9960, validation loss: 0.0717
2024-05-25 00:22:02 [INFO]: Epoch 224 - training loss: 9303.9336, validation loss: 0.0703
2024-05-25 00:22:02 [INFO]: Epoch 225 - training loss: 9303.1470, validation loss: 0.0734
2024-05-25 00:22:02 [INFO]: Epoch 226 - training loss: 9304.7495, validation loss: 0.0697
2024-05-25 00:22:02 [INFO]: Epoch 227 - training loss: 9302.4408, validation loss: 0.0692
2024-05-25 00:22:02 [INFO]: Epoch 228 - training loss: 9302.5761, validation loss: 0.0718
2024-05-25 00:22:03 [INFO]: Epoch 229 - training loss: 9304.2075, validation loss: 0.0719
2024-05-25 00:22:03 [INFO]: Epoch 230 - training loss: 9302.2042, validation loss: 0.0709
2024-05-25 00:22:03 [INFO]: Epoch 231 - training loss: 9301.9278, validation loss: 0.0694
2024-05-25 00:22:03 [INFO]: Epoch 232 - training loss: 9301.2687, validation loss: 0.0696
2024-05-25 00:22:03 [INFO]: Epoch 233 - training loss: 9301.6260, validation loss: 0.0701
2024-05-25 00:22:03 [INFO]: Epoch 234 - training loss: 9301.2523, validation loss: 0.0709
2024-05-25 00:22:03 [INFO]: Epoch 235 - training loss: 9302.5953, validation loss: 0.0691
2024-05-25 00:22:04 [INFO]: Epoch 236 - training loss: 9302.5355, validation loss: 0.0702
2024-05-25 00:22:04 [INFO]: Epoch 237 - training loss: 9302.3542, validation loss: 0.0687
2024-05-25 00:22:04 [INFO]: Epoch 238 - training loss: 9300.8002, validation loss: 0.0706
2024-05-25 00:22:04 [INFO]: Epoch 239 - training loss: 9302.5101, validation loss: 0.0711
2024-05-25 00:22:04 [INFO]: Epoch 240 - training loss: 9301.6980, validation loss: 0.0708
2024-05-25 00:22:04 [INFO]: Epoch 241 - training loss: 9302.8422, validation loss: 0.0705
2024-05-25 00:22:04 [INFO]: Epoch 242 - training loss: 9301.7928, validation loss: 0.0697
2024-05-25 00:22:04 [INFO]: Epoch 243 - training loss: 9303.0650, validation loss: 0.0687
2024-05-25 00:22:05 [INFO]: Epoch 244 - training loss: 9301.7214, validation loss: 0.0685
2024-05-25 00:22:05 [INFO]: Epoch 245 - training loss: 9301.9512, validation loss: 0.0685
2024-05-25 00:22:05 [INFO]: Epoch 246 - training loss: 9302.4676, validation loss: 0.0692
2024-05-25 00:22:05 [INFO]: Epoch 247 - training loss: 9301.8732, validation loss: 0.0687
2024-05-25 00:22:05 [INFO]: Epoch 248 - training loss: 9303.3149, validation loss: 0.0716
2024-05-25 00:22:05 [INFO]: Epoch 249 - training loss: 9301.6139, validation loss: 0.0686
2024-05-25 00:22:05 [INFO]: Epoch 250 - training loss: 9300.4441, validation loss: 0.0705
2024-05-25 00:22:05 [INFO]: Epoch 251 - training loss: 9302.1409, validation loss: 0.0690
2024-05-25 00:22:06 [INFO]: Epoch 252 - training loss: 9301.4409, validation loss: 0.0701
2024-05-25 00:22:06 [INFO]: Epoch 253 - training loss: 9302.3198, validation loss: 0.0689
2024-05-25 00:22:06 [INFO]: Epoch 254 - training loss: 9301.6197, validation loss: 0.0685
2024-05-25 00:22:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:22:06 [INFO]: Finished training. The best model is from epoch#244.
2024-05-25 00:22:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/GPVAE_ettm1/20240525_T002134/GPVAE.pypots
2024-05-25 00:22:06 [INFO]: GP-VAE on ETTm1: MAE=0.2619, MSE=0.1444
2024-05-25 00:22:06 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/GPVAE_ettm1/imputation.pkl
2024-05-25 00:22:06 [INFO]: Using the given device: cuda:0
2024-05-25 00:22:06 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/USGAN_ettm1/20240525_T002206
2024-05-25 00:22:06 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/USGAN_ettm1/20240525_T002206/tensorboard
2024-05-25 00:22:06 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 00:22:16 [INFO]: Epoch 001 - generator training loss: 0.6099, discriminator training loss: 0.3342, validation loss: 0.3461
2024-05-25 00:22:25 [INFO]: Epoch 002 - generator training loss: 0.0373, discriminator training loss: 0.2134, validation loss: 0.0950
2024-05-25 00:22:34 [INFO]: Epoch 003 - generator training loss: -0.0583, discriminator training loss: 0.1994, validation loss: 0.0577
2024-05-25 00:22:43 [INFO]: Epoch 004 - generator training loss: -0.0839, discriminator training loss: 0.1962, validation loss: 0.0473
2024-05-25 00:22:52 [INFO]: Epoch 005 - generator training loss: -0.0843, discriminator training loss: 0.1912, validation loss: 0.0425
2024-05-25 00:23:01 [INFO]: Epoch 006 - generator training loss: -0.0864, discriminator training loss: 0.1878, validation loss: 0.0401
2024-05-25 00:23:10 [INFO]: Epoch 007 - generator training loss: -0.0824, discriminator training loss: 0.1818, validation loss: 0.0376
2024-05-25 00:23:19 [INFO]: Epoch 008 - generator training loss: -0.0697, discriminator training loss: 0.1688, validation loss: 0.0370
2024-05-25 00:23:28 [INFO]: Epoch 009 - generator training loss: -0.0589, discriminator training loss: 0.1556, validation loss: 0.0356
2024-05-25 00:23:37 [INFO]: Epoch 010 - generator training loss: -0.0476, discriminator training loss: 0.1402, validation loss: 0.0351
2024-05-25 00:23:45 [INFO]: Epoch 011 - generator training loss: -0.0341, discriminator training loss: 0.1232, validation loss: 0.0342
2024-05-25 00:23:54 [INFO]: Epoch 012 - generator training loss: -0.0252, discriminator training loss: 0.1094, validation loss: 0.0337
2024-05-25 00:24:03 [INFO]: Epoch 013 - generator training loss: -0.0221, discriminator training loss: 0.1013, validation loss: 0.0338
2024-05-25 00:24:12 [INFO]: Epoch 014 - generator training loss: -0.0152, discriminator training loss: 0.0954, validation loss: 0.0327
2024-05-25 00:24:21 [INFO]: Epoch 015 - generator training loss: -0.0163, discriminator training loss: 0.0906, validation loss: 0.0324
2024-05-25 00:24:30 [INFO]: Epoch 016 - generator training loss: -0.0131, discriminator training loss: 0.0869, validation loss: 0.0320
2024-05-25 00:24:39 [INFO]: Epoch 017 - generator training loss: -0.0128, discriminator training loss: 0.0846, validation loss: 0.0313
2024-05-25 00:24:48 [INFO]: Epoch 018 - generator training loss: -0.0126, discriminator training loss: 0.0835, validation loss: 0.0314
2024-05-25 00:24:57 [INFO]: Epoch 019 - generator training loss: -0.0101, discriminator training loss: 0.0820, validation loss: 0.0319
2024-05-25 00:25:06 [INFO]: Epoch 020 - generator training loss: -0.0118, discriminator training loss: 0.0806, validation loss: 0.0307
2024-05-25 00:25:14 [INFO]: Epoch 021 - generator training loss: -0.0102, discriminator training loss: 0.0802, validation loss: 0.0300
2024-05-25 00:25:23 [INFO]: Epoch 022 - generator training loss: -0.0103, discriminator training loss: 0.0793, validation loss: 0.0297
2024-05-25 00:25:32 [INFO]: Epoch 023 - generator training loss: -0.0098, discriminator training loss: 0.0781, validation loss: 0.0301
2024-05-25 00:25:41 [INFO]: Epoch 024 - generator training loss: -0.0103, discriminator training loss: 0.0773, validation loss: 0.0300
2024-05-25 00:25:51 [INFO]: Epoch 025 - generator training loss: -0.0116, discriminator training loss: 0.0781, validation loss: 0.0292
2024-05-25 00:26:00 [INFO]: Epoch 026 - generator training loss: -0.0123, discriminator training loss: 0.0781, validation loss: 0.0293
2024-05-25 00:26:09 [INFO]: Epoch 027 - generator training loss: -0.0116, discriminator training loss: 0.0746, validation loss: 0.0289
2024-05-25 00:26:18 [INFO]: Epoch 028 - generator training loss: -0.0136, discriminator training loss: 0.0728, validation loss: 0.0287
2024-05-25 00:26:27 [INFO]: Epoch 029 - generator training loss: -0.0127, discriminator training loss: 0.0739, validation loss: 0.0289
2024-05-25 00:26:36 [INFO]: Epoch 030 - generator training loss: -0.0154, discriminator training loss: 0.0745, validation loss: 0.0284
2024-05-25 00:26:45 [INFO]: Epoch 031 - generator training loss: -0.0103, discriminator training loss: 0.0733, validation loss: 0.0290
2024-05-25 00:26:54 [INFO]: Epoch 032 - generator training loss: -0.0136, discriminator training loss: 0.0719, validation loss: 0.0277
2024-05-25 00:27:03 [INFO]: Epoch 033 - generator training loss: -0.0161, discriminator training loss: 0.0727, validation loss: 0.0276
2024-05-25 00:27:12 [INFO]: Epoch 034 - generator training loss: -0.0147, discriminator training loss: 0.0756, validation loss: 0.0277
2024-05-25 00:27:21 [INFO]: Epoch 035 - generator training loss: -0.0131, discriminator training loss: 0.0752, validation loss: 0.0287
2024-05-25 00:27:30 [INFO]: Epoch 036 - generator training loss: -0.0150, discriminator training loss: 0.0724, validation loss: 0.0281
2024-05-25 00:27:39 [INFO]: Epoch 037 - generator training loss: -0.0152, discriminator training loss: 0.0726, validation loss: 0.0280
2024-05-25 00:27:48 [INFO]: Epoch 038 - generator training loss: -0.0164, discriminator training loss: 0.0717, validation loss: 0.0267
2024-05-25 00:27:57 [INFO]: Epoch 039 - generator training loss: -0.0144, discriminator training loss: 0.0726, validation loss: 0.0271
2024-05-25 00:28:06 [INFO]: Epoch 040 - generator training loss: -0.0151, discriminator training loss: 0.0713, validation loss: 0.0260
2024-05-25 00:28:15 [INFO]: Epoch 041 - generator training loss: -0.0163, discriminator training loss: 0.0709, validation loss: 0.0255
2024-05-25 00:28:24 [INFO]: Epoch 042 - generator training loss: -0.0213, discriminator training loss: 0.0705, validation loss: 0.0259
2024-05-25 00:28:33 [INFO]: Epoch 043 - generator training loss: -0.0184, discriminator training loss: 0.0711, validation loss: 0.0251
2024-05-25 00:28:43 [INFO]: Epoch 044 - generator training loss: -0.0188, discriminator training loss: 0.0716, validation loss: 0.0251
2024-05-25 00:28:52 [INFO]: Epoch 045 - generator training loss: -0.0192, discriminator training loss: 0.0710, validation loss: 0.0254
2024-05-25 00:29:01 [INFO]: Epoch 046 - generator training loss: -0.0193, discriminator training loss: 0.0691, validation loss: 0.0246
2024-05-25 00:29:10 [INFO]: Epoch 047 - generator training loss: -0.0181, discriminator training loss: 0.0709, validation loss: 0.0243
2024-05-25 00:29:19 [INFO]: Epoch 048 - generator training loss: -0.0192, discriminator training loss: 0.0698, validation loss: 0.0247
2024-05-25 00:29:28 [INFO]: Epoch 049 - generator training loss: -0.0177, discriminator training loss: 0.0699, validation loss: 0.0237
2024-05-25 00:29:37 [INFO]: Epoch 050 - generator training loss: -0.0195, discriminator training loss: 0.0702, validation loss: 0.0236
2024-05-25 00:29:46 [INFO]: Epoch 051 - generator training loss: -0.0174, discriminator training loss: 0.0692, validation loss: 0.0232
2024-05-25 00:29:55 [INFO]: Epoch 052 - generator training loss: -0.0204, discriminator training loss: 0.0694, validation loss: 0.0233
2024-05-25 00:30:04 [INFO]: Epoch 053 - generator training loss: -0.0209, discriminator training loss: 0.0708, validation loss: 0.0229
2024-05-25 00:30:13 [INFO]: Epoch 054 - generator training loss: -0.0191, discriminator training loss: 0.0711, validation loss: 0.0232
2024-05-25 00:30:22 [INFO]: Epoch 055 - generator training loss: -0.0194, discriminator training loss: 0.0717, validation loss: 0.0228
2024-05-25 00:30:31 [INFO]: Epoch 056 - generator training loss: -0.0203, discriminator training loss: 0.0684, validation loss: 0.0229
2024-05-25 00:30:40 [INFO]: Epoch 057 - generator training loss: -0.0205, discriminator training loss: 0.0683, validation loss: 0.0228
2024-05-25 00:30:49 [INFO]: Epoch 058 - generator training loss: -0.0216, discriminator training loss: 0.0705, validation loss: 0.0229
2024-05-25 00:30:58 [INFO]: Epoch 059 - generator training loss: -0.0191, discriminator training loss: 0.0687, validation loss: 0.0218
2024-05-25 00:31:07 [INFO]: Epoch 060 - generator training loss: -0.0224, discriminator training loss: 0.0702, validation loss: 0.0220
2024-05-25 00:31:16 [INFO]: Epoch 061 - generator training loss: -0.0208, discriminator training loss: 0.0701, validation loss: 0.0221
2024-05-25 00:31:25 [INFO]: Epoch 062 - generator training loss: -0.0198, discriminator training loss: 0.0693, validation loss: 0.0215
2024-05-25 00:31:34 [INFO]: Epoch 063 - generator training loss: -0.0249, discriminator training loss: 0.0699, validation loss: 0.0212
2024-05-25 00:31:43 [INFO]: Epoch 064 - generator training loss: -0.0185, discriminator training loss: 0.0694, validation loss: 0.0214
2024-05-25 00:31:52 [INFO]: Epoch 065 - generator training loss: -0.0193, discriminator training loss: 0.0704, validation loss: 0.0212
2024-05-25 00:32:01 [INFO]: Epoch 066 - generator training loss: -0.0204, discriminator training loss: 0.0692, validation loss: 0.0211
2024-05-25 00:32:10 [INFO]: Epoch 067 - generator training loss: -0.0196, discriminator training loss: 0.0689, validation loss: 0.0209
2024-05-25 00:32:20 [INFO]: Epoch 068 - generator training loss: -0.0238, discriminator training loss: 0.0702, validation loss: 0.0208
2024-05-25 00:32:29 [INFO]: Epoch 069 - generator training loss: -0.0214, discriminator training loss: 0.0686, validation loss: 0.0207
2024-05-25 00:32:37 [INFO]: Epoch 070 - generator training loss: -0.0241, discriminator training loss: 0.0706, validation loss: 0.0204
2024-05-25 00:32:46 [INFO]: Epoch 071 - generator training loss: -0.0207, discriminator training loss: 0.0694, validation loss: 0.0207
2024-05-25 00:32:55 [INFO]: Epoch 072 - generator training loss: -0.0226, discriminator training loss: 0.0668, validation loss: 0.0206
2024-05-25 00:33:04 [INFO]: Epoch 073 - generator training loss: -0.0223, discriminator training loss: 0.0686, validation loss: 0.0203
2024-05-25 00:33:14 [INFO]: Epoch 074 - generator training loss: -0.0220, discriminator training loss: 0.0679, validation loss: 0.0205
2024-05-25 00:33:22 [INFO]: Epoch 075 - generator training loss: -0.0210, discriminator training loss: 0.0684, validation loss: 0.0205
2024-05-25 00:33:31 [INFO]: Epoch 076 - generator training loss: -0.0252, discriminator training loss: 0.0684, validation loss: 0.0202
2024-05-25 00:33:41 [INFO]: Epoch 077 - generator training loss: -0.0205, discriminator training loss: 0.0652, validation loss: 0.0206
2024-05-25 00:33:50 [INFO]: Epoch 078 - generator training loss: -0.0232, discriminator training loss: 0.0687, validation loss: 0.0208
2024-05-25 00:33:59 [INFO]: Epoch 079 - generator training loss: -0.0263, discriminator training loss: 0.0689, validation loss: 0.0205
2024-05-25 00:34:08 [INFO]: Epoch 080 - generator training loss: -0.0230, discriminator training loss: 0.0671, validation loss: 0.0203
2024-05-25 00:34:17 [INFO]: Epoch 081 - generator training loss: -0.0223, discriminator training loss: 0.0692, validation loss: 0.0205
2024-05-25 00:34:26 [INFO]: Epoch 082 - generator training loss: -0.0208, discriminator training loss: 0.0686, validation loss: 0.0207
2024-05-25 00:34:35 [INFO]: Epoch 083 - generator training loss: -0.0192, discriminator training loss: 0.0671, validation loss: 0.0201
2024-05-25 00:34:44 [INFO]: Epoch 084 - generator training loss: -0.0232, discriminator training loss: 0.0675, validation loss: 0.0199
2024-05-25 00:34:53 [INFO]: Epoch 085 - generator training loss: -0.0209, discriminator training loss: 0.0686, validation loss: 0.0202
2024-05-25 00:35:02 [INFO]: Epoch 086 - generator training loss: -0.0236, discriminator training loss: 0.0687, validation loss: 0.0200
2024-05-25 00:35:11 [INFO]: Epoch 087 - generator training loss: -0.0218, discriminator training loss: 0.0688, validation loss: 0.0204
2024-05-25 00:35:20 [INFO]: Epoch 088 - generator training loss: -0.0230, discriminator training loss: 0.0684, validation loss: 0.0199
2024-05-25 00:35:29 [INFO]: Epoch 089 - generator training loss: -0.0233, discriminator training loss: 0.0674, validation loss: 0.0207
2024-05-25 00:35:38 [INFO]: Epoch 090 - generator training loss: -0.0238, discriminator training loss: 0.0696, validation loss: 0.0205
2024-05-25 00:35:47 [INFO]: Epoch 091 - generator training loss: -0.0223, discriminator training loss: 0.0686, validation loss: 0.0206
2024-05-25 00:35:56 [INFO]: Epoch 092 - generator training loss: -0.0264, discriminator training loss: 0.0692, validation loss: 0.0202
2024-05-25 00:36:05 [INFO]: Epoch 093 - generator training loss: -0.0227, discriminator training loss: 0.0660, validation loss: 0.0195
2024-05-25 00:36:14 [INFO]: Epoch 094 - generator training loss: -0.0233, discriminator training loss: 0.0660, validation loss: 0.0202
2024-05-25 00:36:23 [INFO]: Epoch 095 - generator training loss: -0.0226, discriminator training loss: 0.0658, validation loss: 0.0196
2024-05-25 00:36:32 [INFO]: Epoch 096 - generator training loss: -0.0221, discriminator training loss: 0.0660, validation loss: 0.0197
2024-05-25 00:36:41 [INFO]: Epoch 097 - generator training loss: -0.0236, discriminator training loss: 0.0674, validation loss: 0.0198
2024-05-25 00:36:50 [INFO]: Epoch 098 - generator training loss: -0.0229, discriminator training loss: 0.0677, validation loss: 0.0205
2024-05-25 00:36:59 [INFO]: Epoch 099 - generator training loss: -0.0224, discriminator training loss: 0.0667, validation loss: 0.0200
2024-05-25 00:37:08 [INFO]: Epoch 100 - generator training loss: -0.0219, discriminator training loss: 0.0677, validation loss: 0.0198
2024-05-25 00:37:17 [INFO]: Epoch 101 - generator training loss: -0.0213, discriminator training loss: 0.0665, validation loss: 0.0201
2024-05-25 00:37:26 [INFO]: Epoch 102 - generator training loss: -0.0221, discriminator training loss: 0.0659, validation loss: 0.0199
2024-05-25 00:37:35 [INFO]: Epoch 103 - generator training loss: -0.0238, discriminator training loss: 0.0678, validation loss: 0.0204
2024-05-25 00:37:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:37:35 [INFO]: Finished training. The best model is from epoch#93.
2024-05-25 00:37:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/USGAN_ettm1/20240525_T002206/USGAN.pypots
2024-05-25 00:37:36 [INFO]: US-GAN on ETTm1: MAE=0.1499, MSE=0.0533
2024-05-25 00:37:36 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/USGAN_ettm1/imputation.pkl
2024-05-25 00:37:36 [INFO]: Using the given device: cuda:0
2024-05-25 00:37:36 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/BRITS_ettm1/20240525_T003736
2024-05-25 00:37:36 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/BRITS_ettm1/20240525_T003736/tensorboard
2024-05-25 00:37:36 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 00:37:44 [INFO]: Epoch 001 - training loss: 1.3596, validation loss: 0.2782
2024-05-25 00:37:50 [INFO]: Epoch 002 - training loss: 0.8994, validation loss: 0.0876
2024-05-25 00:37:56 [INFO]: Epoch 003 - training loss: 0.7231, validation loss: 0.0520
2024-05-25 00:38:02 [INFO]: Epoch 004 - training loss: 0.6655, validation loss: 0.0444
2024-05-25 00:38:08 [INFO]: Epoch 005 - training loss: 0.6191, validation loss: 0.0432
2024-05-25 00:38:14 [INFO]: Epoch 006 - training loss: 0.5911, validation loss: 0.0389
2024-05-25 00:38:20 [INFO]: Epoch 007 - training loss: 0.5534, validation loss: 0.0360
2024-05-25 00:38:26 [INFO]: Epoch 008 - training loss: 0.5271, validation loss: 0.0358
2024-05-25 00:38:32 [INFO]: Epoch 009 - training loss: 0.5155, validation loss: 0.0329
2024-05-25 00:38:38 [INFO]: Epoch 010 - training loss: 0.4902, validation loss: 0.0318
2024-05-25 00:38:44 [INFO]: Epoch 011 - training loss: 0.4790, validation loss: 0.0295
2024-05-25 00:38:50 [INFO]: Epoch 012 - training loss: 0.4700, validation loss: 0.0282
2024-05-25 00:38:56 [INFO]: Epoch 013 - training loss: 0.4439, validation loss: 0.0271
2024-05-25 00:39:02 [INFO]: Epoch 014 - training loss: 0.4238, validation loss: 0.0258
2024-05-25 00:39:08 [INFO]: Epoch 015 - training loss: 0.4154, validation loss: 0.0251
2024-05-25 00:39:14 [INFO]: Epoch 016 - training loss: 0.4129, validation loss: 0.0245
2024-05-25 00:39:20 [INFO]: Epoch 017 - training loss: 0.3985, validation loss: 0.0246
2024-05-25 00:39:26 [INFO]: Epoch 018 - training loss: 0.4012, validation loss: 0.0234
2024-05-25 00:39:32 [INFO]: Epoch 019 - training loss: 0.3866, validation loss: 0.0235
2024-05-25 00:39:38 [INFO]: Epoch 020 - training loss: 0.3834, validation loss: 0.0223
2024-05-25 00:39:44 [INFO]: Epoch 021 - training loss: 0.3856, validation loss: 0.0227
2024-05-25 00:39:50 [INFO]: Epoch 022 - training loss: 0.3827, validation loss: 0.0223
2024-05-25 00:39:56 [INFO]: Epoch 023 - training loss: 0.3846, validation loss: 0.0228
2024-05-25 00:40:02 [INFO]: Epoch 024 - training loss: 0.3819, validation loss: 0.0223
2024-05-25 00:40:08 [INFO]: Epoch 025 - training loss: 0.3796, validation loss: 0.0223
2024-05-25 00:40:14 [INFO]: Epoch 026 - training loss: 0.3850, validation loss: 0.0227
2024-05-25 00:40:20 [INFO]: Epoch 027 - training loss: 0.3934, validation loss: 0.0231
2024-05-25 00:40:26 [INFO]: Epoch 028 - training loss: 0.3868, validation loss: 0.0227
2024-05-25 00:40:32 [INFO]: Epoch 029 - training loss: 0.3783, validation loss: 0.0224
2024-05-25 00:40:38 [INFO]: Epoch 030 - training loss: 0.3770, validation loss: 0.0223
2024-05-25 00:40:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:40:38 [INFO]: Finished training. The best model is from epoch#20.
2024-05-25 00:40:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/BRITS_ettm1/20240525_T003736/BRITS.pypots
2024-05-25 00:40:40 [INFO]: BRITS on ETTm1: MAE=0.1181, MSE=0.0427
2024-05-25 00:40:40 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/BRITS_ettm1/imputation.pkl
2024-05-25 00:40:40 [INFO]: Using the given device: cuda:0
2024-05-25 00:40:40 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040
2024-05-25 00:40:40 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/tensorboard
2024-05-25 00:40:40 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 00:40:41 [INFO]: Epoch 001 - training loss: 1.4133, validation loss: 1.2106
2024-05-25 00:40:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch1_loss1.2105521112680435.pypots
2024-05-25 00:40:42 [INFO]: Epoch 002 - training loss: 1.1052, validation loss: 1.1041
2024-05-25 00:40:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch2_loss1.1041017025709152.pypots
2024-05-25 00:40:42 [INFO]: Epoch 003 - training loss: 1.0032, validation loss: 1.0516
2024-05-25 00:40:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch3_loss1.051592692732811.pypots
2024-05-25 00:40:42 [INFO]: Epoch 004 - training loss: 1.0039, validation loss: 1.0224
2024-05-25 00:40:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch4_loss1.0223865360021591.pypots
2024-05-25 00:40:42 [INFO]: Epoch 005 - training loss: 0.9529, validation loss: 1.0077
2024-05-25 00:40:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch5_loss1.0077140927314758.pypots
2024-05-25 00:40:42 [INFO]: Epoch 006 - training loss: 0.9522, validation loss: 0.9982
2024-05-25 00:40:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch6_loss0.9981619417667389.pypots
2024-05-25 00:40:43 [INFO]: Epoch 007 - training loss: 0.9452, validation loss: 0.9910
2024-05-25 00:40:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch7_loss0.9909940809011459.pypots
2024-05-25 00:40:43 [INFO]: Epoch 008 - training loss: 0.9260, validation loss: 0.9846
2024-05-25 00:40:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch8_loss0.9846245646476746.pypots
2024-05-25 00:40:43 [INFO]: Epoch 009 - training loss: 0.9257, validation loss: 0.9782
2024-05-25 00:40:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch9_loss0.9782287329435349.pypots
2024-05-25 00:40:43 [INFO]: Epoch 010 - training loss: 0.9159, validation loss: 0.9745
2024-05-25 00:40:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch10_loss0.9744724333286285.pypots
2024-05-25 00:40:43 [INFO]: Epoch 011 - training loss: 0.9081, validation loss: 0.9666
2024-05-25 00:40:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch11_loss0.9665964841842651.pypots
2024-05-25 00:40:44 [INFO]: Epoch 012 - training loss: 0.9130, validation loss: 0.9642
2024-05-25 00:40:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch12_loss0.964190274477005.pypots
2024-05-25 00:40:44 [INFO]: Epoch 013 - training loss: 0.8888, validation loss: 0.9620
2024-05-25 00:40:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch13_loss0.9620176255702972.pypots
2024-05-25 00:40:44 [INFO]: Epoch 014 - training loss: 0.8963, validation loss: 0.9599
2024-05-25 00:40:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch14_loss0.9599284529685974.pypots
2024-05-25 00:40:44 [INFO]: Epoch 015 - training loss: 0.9016, validation loss: 0.9586
2024-05-25 00:40:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch15_loss0.9585982412099838.pypots
2024-05-25 00:40:44 [INFO]: Epoch 016 - training loss: 0.8981, validation loss: 0.9571
2024-05-25 00:40:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch16_loss0.9570624679327011.pypots
2024-05-25 00:40:44 [INFO]: Epoch 017 - training loss: 0.8920, validation loss: 0.9575
2024-05-25 00:40:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch17_loss0.9574660509824753.pypots
2024-05-25 00:40:45 [INFO]: Epoch 018 - training loss: 0.9149, validation loss: 0.9549
2024-05-25 00:40:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch18_loss0.9549244940280914.pypots
2024-05-25 00:40:45 [INFO]: Epoch 019 - training loss: 0.8732, validation loss: 0.9540
2024-05-25 00:40:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch19_loss0.9539659023284912.pypots
2024-05-25 00:40:45 [INFO]: Epoch 020 - training loss: 0.8703, validation loss: 0.9529
2024-05-25 00:40:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch20_loss0.9529493898153305.pypots
2024-05-25 00:40:45 [INFO]: Epoch 021 - training loss: 0.8680, validation loss: 0.9512
2024-05-25 00:40:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch21_loss0.9511672407388687.pypots
2024-05-25 00:40:45 [INFO]: Epoch 022 - training loss: 0.8441, validation loss: 0.9527
2024-05-25 00:40:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch22_loss0.9526957273483276.pypots
2024-05-25 00:40:46 [INFO]: Epoch 023 - training loss: 0.8328, validation loss: 0.9537
2024-05-25 00:40:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch23_loss0.9537017494440079.pypots
2024-05-25 00:40:46 [INFO]: Epoch 024 - training loss: 0.8869, validation loss: 0.9512
2024-05-25 00:40:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch24_loss0.9511709958314896.pypots
2024-05-25 00:40:46 [INFO]: Epoch 025 - training loss: 0.8439, validation loss: 0.9522
2024-05-25 00:40:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch25_loss0.9521844834089279.pypots
2024-05-25 00:40:46 [INFO]: Epoch 026 - training loss: 0.8427, validation loss: 0.9478
2024-05-25 00:40:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch26_loss0.9478355646133423.pypots
2024-05-25 00:40:46 [INFO]: Epoch 027 - training loss: 0.8559, validation loss: 0.9454
2024-05-25 00:40:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch27_loss0.9454495906829834.pypots
2024-05-25 00:40:47 [INFO]: Epoch 028 - training loss: 0.8391, validation loss: 0.9429
2024-05-25 00:40:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch28_loss0.9429217129945755.pypots
2024-05-25 00:40:47 [INFO]: Epoch 029 - training loss: 0.8369, validation loss: 0.9417
2024-05-25 00:40:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch29_loss0.9417072832584381.pypots
2024-05-25 00:40:47 [INFO]: Epoch 030 - training loss: 0.8213, validation loss: 0.9392
2024-05-25 00:40:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch30_loss0.9391729831695557.pypots
2024-05-25 00:40:47 [INFO]: Epoch 031 - training loss: 0.8315, validation loss: 0.9342
2024-05-25 00:40:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch31_loss0.934155210852623.pypots
2024-05-25 00:40:47 [INFO]: Epoch 032 - training loss: 0.8149, validation loss: 0.9323
2024-05-25 00:40:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch32_loss0.9322913140058517.pypots
2024-05-25 00:40:47 [INFO]: Epoch 033 - training loss: 0.8227, validation loss: 0.9295
2024-05-25 00:40:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch33_loss0.9294672608375549.pypots
2024-05-25 00:40:48 [INFO]: Epoch 034 - training loss: 0.8361, validation loss: 0.9261
2024-05-25 00:40:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch34_loss0.9261111170053482.pypots
2024-05-25 00:40:48 [INFO]: Epoch 035 - training loss: 0.8204, validation loss: 0.9233
2024-05-25 00:40:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch35_loss0.9233129173517227.pypots
2024-05-25 00:40:48 [INFO]: Epoch 036 - training loss: 0.8706, validation loss: 0.9199
2024-05-25 00:40:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch36_loss0.9198509007692337.pypots
2024-05-25 00:40:48 [INFO]: Epoch 037 - training loss: 0.8366, validation loss: 0.9131
2024-05-25 00:40:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch37_loss0.9130558669567108.pypots
2024-05-25 00:40:48 [INFO]: Epoch 038 - training loss: 0.8145, validation loss: 0.9152
2024-05-25 00:40:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch38_loss0.9152491688728333.pypots
2024-05-25 00:40:49 [INFO]: Epoch 039 - training loss: 0.7981, validation loss: 0.9111
2024-05-25 00:40:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch39_loss0.9110837131738663.pypots
2024-05-25 00:40:49 [INFO]: Epoch 040 - training loss: 0.8540, validation loss: 0.9085
2024-05-25 00:40:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch40_loss0.9085153788328171.pypots
2024-05-25 00:40:49 [INFO]: Epoch 041 - training loss: 0.8198, validation loss: 0.9063
2024-05-25 00:40:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch41_loss0.9062785059213638.pypots
2024-05-25 00:40:49 [INFO]: Epoch 042 - training loss: 0.8224, validation loss: 0.9034
2024-05-25 00:40:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch42_loss0.9033757448196411.pypots
2024-05-25 00:40:49 [INFO]: Epoch 043 - training loss: 0.8170, validation loss: 0.9004
2024-05-25 00:40:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch43_loss0.9004105925559998.pypots
2024-05-25 00:40:50 [INFO]: Epoch 044 - training loss: 0.7991, validation loss: 0.8989
2024-05-25 00:40:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch44_loss0.8988972306251526.pypots
2024-05-25 00:40:50 [INFO]: Epoch 045 - training loss: 0.7999, validation loss: 0.8951
2024-05-25 00:40:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch45_loss0.8950923830270767.pypots
2024-05-25 00:40:50 [INFO]: Epoch 046 - training loss: 0.8226, validation loss: 0.8935
2024-05-25 00:40:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch46_loss0.8935164660215378.pypots
2024-05-25 00:40:50 [INFO]: Epoch 047 - training loss: 0.8300, validation loss: 0.8885
2024-05-25 00:40:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch47_loss0.8884626477956772.pypots
2024-05-25 00:40:50 [INFO]: Epoch 048 - training loss: 0.8136, validation loss: 0.8897
2024-05-25 00:40:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch48_loss0.8896983712911606.pypots
2024-05-25 00:40:51 [INFO]: Epoch 049 - training loss: 0.8053, validation loss: 0.8875
2024-05-25 00:40:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch49_loss0.8874586522579193.pypots
2024-05-25 00:40:51 [INFO]: Epoch 050 - training loss: 0.7934, validation loss: 0.8859
2024-05-25 00:40:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch50_loss0.8859420120716095.pypots
2024-05-25 00:40:51 [INFO]: Epoch 051 - training loss: 0.8511, validation loss: 0.8831
2024-05-25 00:40:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch51_loss0.8831256031990051.pypots
2024-05-25 00:40:51 [INFO]: Epoch 052 - training loss: 0.7848, validation loss: 0.8820
2024-05-25 00:40:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch52_loss0.8819860219955444.pypots
2024-05-25 00:40:51 [INFO]: Epoch 053 - training loss: 0.7951, validation loss: 0.8814
2024-05-25 00:40:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch53_loss0.8814120292663574.pypots
2024-05-25 00:40:51 [INFO]: Epoch 054 - training loss: 0.8369, validation loss: 0.8810
2024-05-25 00:40:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch54_loss0.8809995204210281.pypots
2024-05-25 00:40:52 [INFO]: Epoch 055 - training loss: 0.8162, validation loss: 0.8777
2024-05-25 00:40:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch55_loss0.8776813894510269.pypots
2024-05-25 00:40:52 [INFO]: Epoch 056 - training loss: 0.8381, validation loss: 0.8772
2024-05-25 00:40:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch56_loss0.8771713972091675.pypots
2024-05-25 00:40:52 [INFO]: Epoch 057 - training loss: 0.8048, validation loss: 0.8749
2024-05-25 00:40:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch57_loss0.8749186247587204.pypots
2024-05-25 00:40:52 [INFO]: Epoch 058 - training loss: 0.8208, validation loss: 0.8718
2024-05-25 00:40:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch58_loss0.8717932552099228.pypots
2024-05-25 00:40:52 [INFO]: Epoch 059 - training loss: 0.7922, validation loss: 0.8726
2024-05-25 00:40:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch59_loss0.8725748062133789.pypots
2024-05-25 00:40:53 [INFO]: Epoch 060 - training loss: 0.8219, validation loss: 0.8732
2024-05-25 00:40:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch60_loss0.8732076436281204.pypots
2024-05-25 00:40:53 [INFO]: Epoch 061 - training loss: 0.7862, validation loss: 0.8705
2024-05-25 00:40:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch61_loss0.8705180287361145.pypots
2024-05-25 00:40:53 [INFO]: Epoch 062 - training loss: 0.7998, validation loss: 0.8727
2024-05-25 00:40:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch62_loss0.8726896345615387.pypots
2024-05-25 00:40:53 [INFO]: Epoch 063 - training loss: 0.8130, validation loss: 0.8697
2024-05-25 00:40:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch63_loss0.8697401434183121.pypots
2024-05-25 00:40:53 [INFO]: Epoch 064 - training loss: 0.8142, validation loss: 0.8680
2024-05-25 00:40:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch64_loss0.8679535537958145.pypots
2024-05-25 00:40:54 [INFO]: Epoch 065 - training loss: 0.8063, validation loss: 0.8660
2024-05-25 00:40:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch65_loss0.8659946620464325.pypots
2024-05-25 00:40:54 [INFO]: Epoch 066 - training loss: 0.8140, validation loss: 0.8667
2024-05-25 00:40:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch66_loss0.866749107837677.pypots
2024-05-25 00:40:54 [INFO]: Epoch 067 - training loss: 0.8007, validation loss: 0.8689
2024-05-25 00:40:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch67_loss0.8688661009073257.pypots
2024-05-25 00:40:54 [INFO]: Epoch 068 - training loss: 0.8076, validation loss: 0.8628
2024-05-25 00:40:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch68_loss0.8628057241439819.pypots
2024-05-25 00:40:54 [INFO]: Epoch 069 - training loss: 0.7999, validation loss: 0.8622
2024-05-25 00:40:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch69_loss0.8621831685304642.pypots
2024-05-25 00:40:54 [INFO]: Epoch 070 - training loss: 0.7843, validation loss: 0.8631
2024-05-25 00:40:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch70_loss0.8630662262439728.pypots
2024-05-25 00:40:55 [INFO]: Epoch 071 - training loss: 0.7923, validation loss: 0.8630
2024-05-25 00:40:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch71_loss0.8630439788103104.pypots
2024-05-25 00:40:55 [INFO]: Epoch 072 - training loss: 0.7985, validation loss: 0.8602
2024-05-25 00:40:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch72_loss0.8602448403835297.pypots
2024-05-25 00:40:55 [INFO]: Epoch 073 - training loss: 0.7854, validation loss: 0.8585
2024-05-25 00:40:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch73_loss0.8585014492273331.pypots
2024-05-25 00:40:55 [INFO]: Epoch 074 - training loss: 0.8245, validation loss: 0.8596
2024-05-25 00:40:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch74_loss0.8596134781837463.pypots
2024-05-25 00:40:55 [INFO]: Epoch 075 - training loss: 0.8007, validation loss: 0.8580
2024-05-25 00:40:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch75_loss0.8580238670110703.pypots
2024-05-25 00:40:56 [INFO]: Epoch 076 - training loss: 0.7946, validation loss: 0.8585
2024-05-25 00:40:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch76_loss0.8585340082645416.pypots
2024-05-25 00:40:56 [INFO]: Epoch 077 - training loss: 0.7702, validation loss: 0.8578
2024-05-25 00:40:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch77_loss0.857758179306984.pypots
2024-05-25 00:40:56 [INFO]: Epoch 078 - training loss: 0.8219, validation loss: 0.8578
2024-05-25 00:40:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch78_loss0.8578237444162369.pypots
2024-05-25 00:40:56 [INFO]: Epoch 079 - training loss: 0.7827, validation loss: 0.8556
2024-05-25 00:40:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch79_loss0.8555672019720078.pypots
2024-05-25 00:40:56 [INFO]: Epoch 080 - training loss: 0.8000, validation loss: 0.8546
2024-05-25 00:40:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch80_loss0.8545884490013123.pypots
2024-05-25 00:40:57 [INFO]: Epoch 081 - training loss: 0.7966, validation loss: 0.8587
2024-05-25 00:40:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch81_loss0.8587323725223541.pypots
2024-05-25 00:40:57 [INFO]: Epoch 082 - training loss: 0.7898, validation loss: 0.8554
2024-05-25 00:40:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch82_loss0.8554348200559616.pypots
2024-05-25 00:40:57 [INFO]: Epoch 083 - training loss: 0.7919, validation loss: 0.8523
2024-05-25 00:40:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch83_loss0.8523120433092117.pypots
2024-05-25 00:40:57 [INFO]: Epoch 084 - training loss: 0.7918, validation loss: 0.8512
2024-05-25 00:40:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch84_loss0.8512185215950012.pypots
2024-05-25 00:40:57 [INFO]: Epoch 085 - training loss: 0.7845, validation loss: 0.8535
2024-05-25 00:40:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch85_loss0.8535185009241104.pypots
2024-05-25 00:40:57 [INFO]: Epoch 086 - training loss: 0.7884, validation loss: 0.8528
2024-05-25 00:40:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch86_loss0.852841779589653.pypots
2024-05-25 00:40:58 [INFO]: Epoch 087 - training loss: 0.8242, validation loss: 0.8511
2024-05-25 00:40:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch87_loss0.8510814905166626.pypots
2024-05-25 00:40:58 [INFO]: Epoch 088 - training loss: 0.8023, validation loss: 0.8501
2024-05-25 00:40:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch88_loss0.85006383061409.pypots
2024-05-25 00:40:58 [INFO]: Epoch 089 - training loss: 0.7880, validation loss: 0.8501
2024-05-25 00:40:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch89_loss0.8500872850418091.pypots
2024-05-25 00:40:58 [INFO]: Epoch 090 - training loss: 0.8066, validation loss: 0.8503
2024-05-25 00:40:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch90_loss0.8502714484930038.pypots
2024-05-25 00:40:58 [INFO]: Epoch 091 - training loss: 0.7638, validation loss: 0.8481
2024-05-25 00:40:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch91_loss0.8481059223413467.pypots
2024-05-25 00:40:59 [INFO]: Epoch 092 - training loss: 0.7682, validation loss: 0.8535
2024-05-25 00:40:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch92_loss0.8535391390323639.pypots
2024-05-25 00:40:59 [INFO]: Epoch 093 - training loss: 0.7959, validation loss: 0.8493
2024-05-25 00:40:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch93_loss0.8493475019931793.pypots
2024-05-25 00:40:59 [INFO]: Epoch 094 - training loss: 0.7702, validation loss: 0.8499
2024-05-25 00:40:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch94_loss0.8499070703983307.pypots
2024-05-25 00:40:59 [INFO]: Epoch 095 - training loss: 0.7813, validation loss: 0.8500
2024-05-25 00:40:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch95_loss0.8500388562679291.pypots
2024-05-25 00:40:59 [INFO]: Epoch 096 - training loss: 0.8070, validation loss: 0.8483
2024-05-25 00:40:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch96_loss0.8483278155326843.pypots
2024-05-25 00:41:00 [INFO]: Epoch 097 - training loss: 0.7921, validation loss: 0.8490
2024-05-25 00:41:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch97_loss0.8490303009748459.pypots
2024-05-25 00:41:00 [INFO]: Epoch 098 - training loss: 0.7918, validation loss: 0.8501
2024-05-25 00:41:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch98_loss0.8500946015119553.pypots
2024-05-25 00:41:00 [INFO]: Epoch 099 - training loss: 0.7788, validation loss: 0.8488
2024-05-25 00:41:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch99_loss0.8488373309373856.pypots
2024-05-25 00:41:00 [INFO]: Epoch 100 - training loss: 0.7835, validation loss: 0.8487
2024-05-25 00:41:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch100_loss0.8487110435962677.pypots
2024-05-25 00:41:00 [INFO]: Epoch 101 - training loss: 0.7916, validation loss: 0.8449
2024-05-25 00:41:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch101_loss0.8449386060237885.pypots
2024-05-25 00:41:01 [INFO]: Epoch 102 - training loss: 0.8276, validation loss: 0.8460
2024-05-25 00:41:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch102_loss0.8459904491901398.pypots
2024-05-25 00:41:01 [INFO]: Epoch 103 - training loss: 0.7913, validation loss: 0.8458
2024-05-25 00:41:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch103_loss0.8458045423030853.pypots
2024-05-25 00:41:01 [INFO]: Epoch 104 - training loss: 0.7738, validation loss: 0.8468
2024-05-25 00:41:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch104_loss0.8467664867639542.pypots
2024-05-25 00:41:01 [INFO]: Epoch 105 - training loss: 0.7780, validation loss: 0.8484
2024-05-25 00:41:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch105_loss0.8484227359294891.pypots
2024-05-25 00:41:01 [INFO]: Epoch 106 - training loss: 0.8235, validation loss: 0.8458
2024-05-25 00:41:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch106_loss0.8457583039999008.pypots
2024-05-25 00:41:01 [INFO]: Epoch 107 - training loss: 0.8039, validation loss: 0.8448
2024-05-25 00:41:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch107_loss0.8448158800601959.pypots
2024-05-25 00:41:02 [INFO]: Epoch 108 - training loss: 0.7732, validation loss: 0.8434
2024-05-25 00:41:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch108_loss0.8434088230133057.pypots
2024-05-25 00:41:02 [INFO]: Epoch 109 - training loss: 0.7819, validation loss: 0.8460
2024-05-25 00:41:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch109_loss0.8460371792316437.pypots
2024-05-25 00:41:02 [INFO]: Epoch 110 - training loss: 0.7975, validation loss: 0.8439
2024-05-25 00:41:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch110_loss0.843881368637085.pypots
2024-05-25 00:41:02 [INFO]: Epoch 111 - training loss: 0.7841, validation loss: 0.8430
2024-05-25 00:41:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch111_loss0.8429852575063705.pypots
2024-05-25 00:41:02 [INFO]: Epoch 112 - training loss: 0.7976, validation loss: 0.8437
2024-05-25 00:41:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch112_loss0.8436805903911591.pypots
2024-05-25 00:41:03 [INFO]: Epoch 113 - training loss: 0.7709, validation loss: 0.8440
2024-05-25 00:41:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch113_loss0.843996062874794.pypots
2024-05-25 00:41:03 [INFO]: Epoch 114 - training loss: 0.7999, validation loss: 0.8454
2024-05-25 00:41:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch114_loss0.8454485088586807.pypots
2024-05-25 00:41:03 [INFO]: Epoch 115 - training loss: 0.8019, validation loss: 0.8397
2024-05-25 00:41:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch115_loss0.8396533131599426.pypots
2024-05-25 00:41:03 [INFO]: Epoch 116 - training loss: 0.7916, validation loss: 0.8429
2024-05-25 00:41:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch116_loss0.8429462760686874.pypots
2024-05-25 00:41:03 [INFO]: Epoch 117 - training loss: 0.7928, validation loss: 0.8425
2024-05-25 00:41:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch117_loss0.842543289065361.pypots
2024-05-25 00:41:04 [INFO]: Epoch 118 - training loss: 0.7985, validation loss: 0.8436
2024-05-25 00:41:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch118_loss0.8436355143785477.pypots
2024-05-25 00:41:04 [INFO]: Epoch 119 - training loss: 0.7721, validation loss: 0.8448
2024-05-25 00:41:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch119_loss0.8447651267051697.pypots
2024-05-25 00:41:04 [INFO]: Epoch 120 - training loss: 0.7832, validation loss: 0.8422
2024-05-25 00:41:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch120_loss0.8421706110239029.pypots
2024-05-25 00:41:04 [INFO]: Epoch 121 - training loss: 0.7691, validation loss: 0.8410
2024-05-25 00:41:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch121_loss0.8410029113292694.pypots
2024-05-25 00:41:04 [INFO]: Epoch 122 - training loss: 0.7732, validation loss: 0.8413
2024-05-25 00:41:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch122_loss0.8412719517946243.pypots
2024-05-25 00:41:04 [INFO]: Epoch 123 - training loss: 0.7956, validation loss: 0.8380
2024-05-25 00:41:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch123_loss0.8379559069871902.pypots
2024-05-25 00:41:05 [INFO]: Epoch 124 - training loss: 0.8385, validation loss: 0.8386
2024-05-25 00:41:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch124_loss0.8385523706674576.pypots
2024-05-25 00:41:05 [INFO]: Epoch 125 - training loss: 0.8190, validation loss: 0.8399
2024-05-25 00:41:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch125_loss0.8399112075567245.pypots
2024-05-25 00:41:05 [INFO]: Epoch 126 - training loss: 0.8019, validation loss: 0.8414
2024-05-25 00:41:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch126_loss0.8413888514041901.pypots
2024-05-25 00:41:05 [INFO]: Epoch 127 - training loss: 0.7870, validation loss: 0.8403
2024-05-25 00:41:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch127_loss0.840342327952385.pypots
2024-05-25 00:41:05 [INFO]: Epoch 128 - training loss: 0.7612, validation loss: 0.8420
2024-05-25 00:41:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch128_loss0.8419949561357498.pypots
2024-05-25 00:41:06 [INFO]: Epoch 129 - training loss: 0.7810, validation loss: 0.8419
2024-05-25 00:41:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch129_loss0.8419228494167328.pypots
2024-05-25 00:41:06 [INFO]: Epoch 130 - training loss: 0.7822, validation loss: 0.8424
2024-05-25 00:41:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch130_loss0.8423801511526108.pypots
2024-05-25 00:41:06 [INFO]: Epoch 131 - training loss: 0.8204, validation loss: 0.8365
2024-05-25 00:41:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch131_loss0.8364989012479782.pypots
2024-05-25 00:41:06 [INFO]: Epoch 132 - training loss: 0.7877, validation loss: 0.8381
2024-05-25 00:41:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch132_loss0.8380875289440155.pypots
2024-05-25 00:41:06 [INFO]: Epoch 133 - training loss: 0.7873, validation loss: 0.8381
2024-05-25 00:41:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch133_loss0.8380690515041351.pypots
2024-05-25 00:41:07 [INFO]: Epoch 134 - training loss: 0.7801, validation loss: 0.8371
2024-05-25 00:41:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch134_loss0.8370516002178192.pypots
2024-05-25 00:41:07 [INFO]: Epoch 135 - training loss: 0.7829, validation loss: 0.8378
2024-05-25 00:41:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch135_loss0.8378493040800095.pypots
2024-05-25 00:41:07 [INFO]: Epoch 136 - training loss: 0.8045, validation loss: 0.8363
2024-05-25 00:41:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch136_loss0.8363186120986938.pypots
2024-05-25 00:41:07 [INFO]: Epoch 137 - training loss: 0.8211, validation loss: 0.8341
2024-05-25 00:41:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch137_loss0.834132969379425.pypots
2024-05-25 00:41:07 [INFO]: Epoch 138 - training loss: 0.7658, validation loss: 0.8328
2024-05-25 00:41:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch138_loss0.8327706009149551.pypots
2024-05-25 00:41:07 [INFO]: Epoch 139 - training loss: 0.7642, validation loss: 0.8359
2024-05-25 00:41:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch139_loss0.8358748406171799.pypots
2024-05-25 00:41:08 [INFO]: Epoch 140 - training loss: 0.7879, validation loss: 0.8345
2024-05-25 00:41:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch140_loss0.834491416811943.pypots
2024-05-25 00:41:08 [INFO]: Epoch 141 - training loss: 0.7745, validation loss: 0.8336
2024-05-25 00:41:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch141_loss0.8335553109645844.pypots
2024-05-25 00:41:08 [INFO]: Epoch 142 - training loss: 0.7808, validation loss: 0.8308
2024-05-25 00:41:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch142_loss0.8308328837156296.pypots
2024-05-25 00:41:08 [INFO]: Epoch 143 - training loss: 0.7863, validation loss: 0.8340
2024-05-25 00:41:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch143_loss0.8340329229831696.pypots
2024-05-25 00:41:08 [INFO]: Epoch 144 - training loss: 0.7865, validation loss: 0.8316
2024-05-25 00:41:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch144_loss0.8315955400466919.pypots
2024-05-25 00:41:09 [INFO]: Epoch 145 - training loss: 0.7903, validation loss: 0.8334
2024-05-25 00:41:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch145_loss0.8333768546581268.pypots
2024-05-25 00:41:09 [INFO]: Epoch 146 - training loss: 0.7985, validation loss: 0.8333
2024-05-25 00:41:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch146_loss0.833309143781662.pypots
2024-05-25 00:41:09 [INFO]: Epoch 147 - training loss: 0.7766, validation loss: 0.8345
2024-05-25 00:41:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch147_loss0.8344545811414719.pypots
2024-05-25 00:41:09 [INFO]: Epoch 148 - training loss: 0.7669, validation loss: 0.8320
2024-05-25 00:41:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch148_loss0.8320229351520538.pypots
2024-05-25 00:41:09 [INFO]: Epoch 149 - training loss: 0.7765, validation loss: 0.8325
2024-05-25 00:41:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch149_loss0.8324721455574036.pypots
2024-05-25 00:41:10 [INFO]: Epoch 150 - training loss: 0.7632, validation loss: 0.8308
2024-05-25 00:41:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch150_loss0.830776110291481.pypots
2024-05-25 00:41:10 [INFO]: Epoch 151 - training loss: 0.7779, validation loss: 0.8333
2024-05-25 00:41:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch151_loss0.8332725167274475.pypots
2024-05-25 00:41:10 [INFO]: Epoch 152 - training loss: 0.7719, validation loss: 0.8320
2024-05-25 00:41:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch152_loss0.8319887071847916.pypots
2024-05-25 00:41:10 [INFO]: Epoch 153 - training loss: 0.7661, validation loss: 0.8298
2024-05-25 00:41:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch153_loss0.8298414051532745.pypots
2024-05-25 00:41:10 [INFO]: Epoch 154 - training loss: 0.7674, validation loss: 0.8290
2024-05-25 00:41:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch154_loss0.8289770781993866.pypots
2024-05-25 00:41:11 [INFO]: Epoch 155 - training loss: 0.8166, validation loss: 0.8297
2024-05-25 00:41:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch155_loss0.8296710103750229.pypots
2024-05-25 00:41:11 [INFO]: Epoch 156 - training loss: 0.7729, validation loss: 0.8327
2024-05-25 00:41:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch156_loss0.832665741443634.pypots
2024-05-25 00:41:11 [INFO]: Epoch 157 - training loss: 0.7870, validation loss: 0.8285
2024-05-25 00:41:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch157_loss0.8284576684236526.pypots
2024-05-25 00:41:11 [INFO]: Epoch 158 - training loss: 0.8256, validation loss: 0.8281
2024-05-25 00:41:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch158_loss0.8280619531869888.pypots
2024-05-25 00:41:11 [INFO]: Epoch 159 - training loss: 0.7879, validation loss: 0.8292
2024-05-25 00:41:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch159_loss0.8291566371917725.pypots
2024-05-25 00:41:11 [INFO]: Epoch 160 - training loss: 0.7970, validation loss: 0.8257
2024-05-25 00:41:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch160_loss0.8257414847612381.pypots
2024-05-25 00:41:12 [INFO]: Epoch 161 - training loss: 0.7724, validation loss: 0.8271
2024-05-25 00:41:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch161_loss0.8270903825759888.pypots
2024-05-25 00:41:12 [INFO]: Epoch 162 - training loss: 0.8115, validation loss: 0.8262
2024-05-25 00:41:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch162_loss0.8262114971876144.pypots
2024-05-25 00:41:12 [INFO]: Epoch 163 - training loss: 0.8127, validation loss: 0.8260
2024-05-25 00:41:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch163_loss0.8259841948747635.pypots
2024-05-25 00:41:12 [INFO]: Epoch 164 - training loss: 0.7621, validation loss: 0.8266
2024-05-25 00:41:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch164_loss0.8266194462776184.pypots
2024-05-25 00:41:12 [INFO]: Epoch 165 - training loss: 0.7897, validation loss: 0.8324
2024-05-25 00:41:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch165_loss0.832411140203476.pypots
2024-05-25 00:41:13 [INFO]: Epoch 166 - training loss: 0.7964, validation loss: 0.8255
2024-05-25 00:41:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch166_loss0.8255407810211182.pypots
2024-05-25 00:41:13 [INFO]: Epoch 167 - training loss: 0.7975, validation loss: 0.8222
2024-05-25 00:41:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch167_loss0.8221944719552994.pypots
2024-05-25 00:41:13 [INFO]: Epoch 168 - training loss: 0.7877, validation loss: 0.8259
2024-05-25 00:41:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch168_loss0.8258571475744247.pypots
2024-05-25 00:41:13 [INFO]: Epoch 169 - training loss: 0.7897, validation loss: 0.8293
2024-05-25 00:41:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch169_loss0.8293140232563019.pypots
2024-05-25 00:41:13 [INFO]: Epoch 170 - training loss: 0.7791, validation loss: 0.8257
2024-05-25 00:41:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch170_loss0.8257011920213699.pypots
2024-05-25 00:41:14 [INFO]: Epoch 171 - training loss: 0.7639, validation loss: 0.8221
2024-05-25 00:41:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch171_loss0.8220706582069397.pypots
2024-05-25 00:41:14 [INFO]: Epoch 172 - training loss: 0.7744, validation loss: 0.8203
2024-05-25 00:41:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch172_loss0.8203122913837433.pypots
2024-05-25 00:41:14 [INFO]: Epoch 173 - training loss: 0.7906, validation loss: 0.8242
2024-05-25 00:41:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch173_loss0.8241687566041946.pypots
2024-05-25 00:41:14 [INFO]: Epoch 174 - training loss: 0.8169, validation loss: 0.8205
2024-05-25 00:41:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch174_loss0.8204915225505829.pypots
2024-05-25 00:41:14 [INFO]: Epoch 175 - training loss: 0.7893, validation loss: 0.8242
2024-05-25 00:41:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch175_loss0.8242292106151581.pypots
2024-05-25 00:41:14 [INFO]: Epoch 176 - training loss: 0.7922, validation loss: 0.8190
2024-05-25 00:41:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch176_loss0.8189721703529358.pypots
2024-05-25 00:41:15 [INFO]: Epoch 177 - training loss: 0.7921, validation loss: 0.8209
2024-05-25 00:41:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch177_loss0.8208974152803421.pypots
2024-05-25 00:41:15 [INFO]: Epoch 178 - training loss: 0.7920, validation loss: 0.8197
2024-05-25 00:41:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch178_loss0.8196841180324554.pypots
2024-05-25 00:41:15 [INFO]: Epoch 179 - training loss: 0.7863, validation loss: 0.8213
2024-05-25 00:41:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch179_loss0.8213049918413162.pypots
2024-05-25 00:41:15 [INFO]: Epoch 180 - training loss: 0.7892, validation loss: 0.8231
2024-05-25 00:41:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch180_loss0.8230762630701065.pypots
2024-05-25 00:41:15 [INFO]: Epoch 181 - training loss: 0.7597, validation loss: 0.8217
2024-05-25 00:41:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch181_loss0.8217255175113678.pypots
2024-05-25 00:41:16 [INFO]: Epoch 182 - training loss: 0.7874, validation loss: 0.8214
2024-05-25 00:41:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch182_loss0.8214061260223389.pypots
2024-05-25 00:41:16 [INFO]: Epoch 183 - training loss: 0.7738, validation loss: 0.8224
2024-05-25 00:41:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch183_loss0.8223765790462494.pypots
2024-05-25 00:41:16 [INFO]: Epoch 184 - training loss: 0.7647, validation loss: 0.8213
2024-05-25 00:41:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch184_loss0.8212855607271194.pypots
2024-05-25 00:41:16 [INFO]: Epoch 185 - training loss: 0.7844, validation loss: 0.8211
2024-05-25 00:41:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch185_loss0.8210995197296143.pypots
2024-05-25 00:41:16 [INFO]: Epoch 186 - training loss: 0.7980, validation loss: 0.8188
2024-05-25 00:41:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch186_loss0.8187538534402847.pypots
2024-05-25 00:41:17 [INFO]: Epoch 187 - training loss: 0.7886, validation loss: 0.8223
2024-05-25 00:41:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch187_loss0.8222603499889374.pypots
2024-05-25 00:41:17 [INFO]: Epoch 188 - training loss: 0.7936, validation loss: 0.8213
2024-05-25 00:41:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch188_loss0.8213304281234741.pypots
2024-05-25 00:41:17 [INFO]: Epoch 189 - training loss: 0.8224, validation loss: 0.8169
2024-05-25 00:41:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch189_loss0.8169206827878952.pypots
2024-05-25 00:41:17 [INFO]: Epoch 190 - training loss: 0.7769, validation loss: 0.8185
2024-05-25 00:41:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch190_loss0.8184745609760284.pypots
2024-05-25 00:41:17 [INFO]: Epoch 191 - training loss: 0.7692, validation loss: 0.8143
2024-05-25 00:41:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch191_loss0.8143273293972015.pypots
2024-05-25 00:41:18 [INFO]: Epoch 192 - training loss: 0.7561, validation loss: 0.8156
2024-05-25 00:41:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch192_loss0.8156419396400452.pypots
2024-05-25 00:41:18 [INFO]: Epoch 193 - training loss: 0.7827, validation loss: 0.8180
2024-05-25 00:41:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch193_loss0.8180050104856491.pypots
2024-05-25 00:41:18 [INFO]: Epoch 194 - training loss: 0.7998, validation loss: 0.8172
2024-05-25 00:41:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch194_loss0.81721630692482.pypots
2024-05-25 00:41:18 [INFO]: Epoch 195 - training loss: 0.7706, validation loss: 0.8150
2024-05-25 00:41:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch195_loss0.8150056153535843.pypots
2024-05-25 00:41:18 [INFO]: Epoch 196 - training loss: 0.7581, validation loss: 0.8181
2024-05-25 00:41:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch196_loss0.8180747926235199.pypots
2024-05-25 00:41:18 [INFO]: Epoch 197 - training loss: 0.8062, validation loss: 0.8139
2024-05-25 00:41:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch197_loss0.8139283359050751.pypots
2024-05-25 00:41:19 [INFO]: Epoch 198 - training loss: 0.7761, validation loss: 0.8097
2024-05-25 00:41:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch198_loss0.8097114861011505.pypots
2024-05-25 00:41:19 [INFO]: Epoch 199 - training loss: 0.7839, validation loss: 0.8127
2024-05-25 00:41:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch199_loss0.8126632273197174.pypots
2024-05-25 00:41:19 [INFO]: Epoch 200 - training loss: 0.7869, validation loss: 0.8150
2024-05-25 00:41:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch200_loss0.8149599432945251.pypots
2024-05-25 00:41:19 [INFO]: Epoch 201 - training loss: 0.7689, validation loss: 0.8127
2024-05-25 00:41:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch201_loss0.8127263188362122.pypots
2024-05-25 00:41:19 [INFO]: Epoch 202 - training loss: 0.7933, validation loss: 0.8140
2024-05-25 00:41:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch202_loss0.8139848113059998.pypots
2024-05-25 00:41:20 [INFO]: Epoch 203 - training loss: 0.8156, validation loss: 0.8145
2024-05-25 00:41:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch203_loss0.814451277256012.pypots
2024-05-25 00:41:20 [INFO]: Epoch 204 - training loss: 0.8001, validation loss: 0.8119
2024-05-25 00:41:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch204_loss0.8119201362133026.pypots
2024-05-25 00:41:20 [INFO]: Epoch 205 - training loss: 0.7703, validation loss: 0.8169
2024-05-25 00:41:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch205_loss0.8169497549533844.pypots
2024-05-25 00:41:20 [INFO]: Epoch 206 - training loss: 0.7593, validation loss: 0.8125
2024-05-25 00:41:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch206_loss0.8124508708715439.pypots
2024-05-25 00:41:20 [INFO]: Epoch 207 - training loss: 0.7533, validation loss: 0.8123
2024-05-25 00:41:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch207_loss0.8122592866420746.pypots
2024-05-25 00:41:21 [INFO]: Epoch 208 - training loss: 0.7848, validation loss: 0.8153
2024-05-25 00:41:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN_epoch208_loss0.8153144270181656.pypots
2024-05-25 00:41:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:41:21 [INFO]: Finished training. The best model is from epoch#198.
2024-05-25 00:41:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T004040/MRNN.pypots
2024-05-25 00:41:21 [INFO]: MRNN on ETTm1: MAE=0.6456, MSE=1.0749
2024-05-25 00:41:21 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/MRNN_ettm1/imputation.pkl
2024-05-25 00:41:21 [INFO]: Using the given device: cpu
2024-05-25 00:41:21 [INFO]: LOCF on ETTm1: MAE=0.1332, MSE=0.0720
2024-05-25 00:41:21 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_ettm1".
2024-05-25 00:41:21 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/LOCF_ettm1/imputation.pkl
2024-05-25 00:41:21 [INFO]: Median on ETTm1: MAE=0.6670, MSE=0.8617
2024-05-25 00:41:21 [INFO]: Successfully created the given path "saved_results/round_4/Median_ettm1".
2024-05-25 00:41:21 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/Median_ettm1/imputation.pkl
2024-05-25 00:41:21 [INFO]: Mean on ETTm1: MAE=0.6734, MSE=0.8444
2024-05-25 00:41:21 [INFO]: Successfully created the given path "saved_results/round_4/Mean_ettm1".
2024-05-25 00:41:21 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/Mean_ettm1/imputation.pkl
2024-05-25 00:41:21 [INFO]: 
SAITS on data/ettm1: MAE=0.1410.0085693616091542, MSE=0.0390.0048407766663935686
Transformer on data/ettm1: MAE=0.1220.005684795656079254, MSE=0.0290.002307386119880283
TimesNet on data/ettm1: MAE=0.1170.005027875473732814, MSE=0.0280.0019028067283858913
CSDI on data/ettm1: MAE=0.1490.021410215606826034, MSE=0.1450.12412908685663918
GPVAE on data/ettm1: MAE=0.2700.004844905804244658, MSE=0.1520.003743147887600285
USGAN on data/ettm1: MAE=0.1410.00927504962974551, MSE=0.0510.004842097393982538
BRITS on data/ettm1: MAE=0.1250.005838972319001225, MSE=0.0460.0037627276186566593
MRNN on data/ettm1: MAE=0.7020.03467462396356325, MSE=1.2090.10900294191045348
LOCF on data/ettm1: MAE=0.1330.0, MSE=0.0720.0
Median on data/ettm1: MAE=0.6670.0, MSE=0.8620.0
Mean on data/ettm1: MAE=0.6730.0, MSE=0.8441.1102230246251565e-16

