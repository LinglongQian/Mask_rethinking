2024-05-25 03:06:59 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-25 03:06:59 [INFO]: Using the given device: cuda:0
2024-05-25 03:06:59 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/SAITS_air_quality/20240525_T030659
2024-05-25 03:06:59 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/SAITS_air_quality/20240525_T030659/tensorboard
2024-05-25 03:07:00 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 03:07:01 [INFO]: Epoch 001 - training loss: 1.0559, validation loss: 0.5053
2024-05-25 03:07:02 [INFO]: Epoch 002 - training loss: 0.7601, validation loss: 0.3831
2024-05-25 03:07:02 [INFO]: Epoch 003 - training loss: 0.6541, validation loss: 0.3075
2024-05-25 03:07:03 [INFO]: Epoch 004 - training loss: 0.5752, validation loss: 0.2638
2024-05-25 03:07:04 [INFO]: Epoch 005 - training loss: 0.5212, validation loss: 0.2409
2024-05-25 03:07:04 [INFO]: Epoch 006 - training loss: 0.4812, validation loss: 0.2284
2024-05-25 03:07:05 [INFO]: Epoch 007 - training loss: 0.4551, validation loss: 0.2180
2024-05-25 03:07:05 [INFO]: Epoch 008 - training loss: 0.4361, validation loss: 0.2128
2024-05-25 03:07:06 [INFO]: Epoch 009 - training loss: 0.4232, validation loss: 0.2054
2024-05-25 03:07:07 [INFO]: Epoch 010 - training loss: 0.4121, validation loss: 0.2024
2024-05-25 03:07:07 [INFO]: Epoch 011 - training loss: 0.4012, validation loss: 0.1980
2024-05-25 03:07:08 [INFO]: Epoch 012 - training loss: 0.3927, validation loss: 0.1951
2024-05-25 03:07:08 [INFO]: Epoch 013 - training loss: 0.3861, validation loss: 0.1913
2024-05-25 03:07:09 [INFO]: Epoch 014 - training loss: 0.3791, validation loss: 0.1885
2024-05-25 03:07:10 [INFO]: Epoch 015 - training loss: 0.3735, validation loss: 0.1852
2024-05-25 03:07:10 [INFO]: Epoch 016 - training loss: 0.3669, validation loss: 0.1835
2024-05-25 03:07:11 [INFO]: Epoch 017 - training loss: 0.3622, validation loss: 0.1808
2024-05-25 03:07:11 [INFO]: Epoch 018 - training loss: 0.3598, validation loss: 0.1806
2024-05-25 03:07:12 [INFO]: Epoch 019 - training loss: 0.3584, validation loss: 0.1770
2024-05-25 03:07:13 [INFO]: Epoch 020 - training loss: 0.3517, validation loss: 0.1742
2024-05-25 03:07:13 [INFO]: Epoch 021 - training loss: 0.3458, validation loss: 0.1719
2024-05-25 03:07:14 [INFO]: Epoch 022 - training loss: 0.3416, validation loss: 0.1725
2024-05-25 03:07:14 [INFO]: Epoch 023 - training loss: 0.3392, validation loss: 0.1691
2024-05-25 03:07:15 [INFO]: Epoch 024 - training loss: 0.3355, validation loss: 0.1674
2024-05-25 03:07:16 [INFO]: Epoch 025 - training loss: 0.3348, validation loss: 0.1679
2024-05-25 03:07:16 [INFO]: Epoch 026 - training loss: 0.3310, validation loss: 0.1650
2024-05-25 03:07:17 [INFO]: Epoch 027 - training loss: 0.3282, validation loss: 0.1634
2024-05-25 03:07:17 [INFO]: Epoch 028 - training loss: 0.3246, validation loss: 0.1626
2024-05-25 03:07:18 [INFO]: Epoch 029 - training loss: 0.3222, validation loss: 0.1613
2024-05-25 03:07:19 [INFO]: Epoch 030 - training loss: 0.3196, validation loss: 0.1596
2024-05-25 03:07:19 [INFO]: Epoch 031 - training loss: 0.3173, validation loss: 0.1583
2024-05-25 03:07:20 [INFO]: Epoch 032 - training loss: 0.3153, validation loss: 0.1572
2024-05-25 03:07:20 [INFO]: Epoch 033 - training loss: 0.3139, validation loss: 0.1558
2024-05-25 03:07:21 [INFO]: Epoch 034 - training loss: 0.3113, validation loss: 0.1556
2024-05-25 03:07:22 [INFO]: Epoch 035 - training loss: 0.3090, validation loss: 0.1542
2024-05-25 03:07:22 [INFO]: Epoch 036 - training loss: 0.3072, validation loss: 0.1527
2024-05-25 03:07:23 [INFO]: Epoch 037 - training loss: 0.3061, validation loss: 0.1511
2024-05-25 03:07:23 [INFO]: Epoch 038 - training loss: 0.3077, validation loss: 0.1521
2024-05-25 03:07:24 [INFO]: Epoch 039 - training loss: 0.3037, validation loss: 0.1510
2024-05-25 03:07:25 [INFO]: Epoch 040 - training loss: 0.2992, validation loss: 0.1491
2024-05-25 03:07:25 [INFO]: Epoch 041 - training loss: 0.2971, validation loss: 0.1480
2024-05-25 03:07:26 [INFO]: Epoch 042 - training loss: 0.2953, validation loss: 0.1478
2024-05-25 03:07:26 [INFO]: Epoch 043 - training loss: 0.2952, validation loss: 0.1459
2024-05-25 03:07:27 [INFO]: Epoch 044 - training loss: 0.2935, validation loss: 0.1455
2024-05-25 03:07:28 [INFO]: Epoch 045 - training loss: 0.2911, validation loss: 0.1446
2024-05-25 03:07:28 [INFO]: Epoch 046 - training loss: 0.2902, validation loss: 0.1439
2024-05-25 03:07:29 [INFO]: Epoch 047 - training loss: 0.2880, validation loss: 0.1431
2024-05-25 03:07:29 [INFO]: Epoch 048 - training loss: 0.2860, validation loss: 0.1416
2024-05-25 03:07:30 [INFO]: Epoch 049 - training loss: 0.2845, validation loss: 0.1407
2024-05-25 03:07:31 [INFO]: Epoch 050 - training loss: 0.2830, validation loss: 0.1402
2024-05-25 03:07:31 [INFO]: Epoch 051 - training loss: 0.2816, validation loss: 0.1404
2024-05-25 03:07:32 [INFO]: Epoch 052 - training loss: 0.2808, validation loss: 0.1387
2024-05-25 03:07:32 [INFO]: Epoch 053 - training loss: 0.2785, validation loss: 0.1387
2024-05-25 03:07:33 [INFO]: Epoch 054 - training loss: 0.2770, validation loss: 0.1380
2024-05-25 03:07:34 [INFO]: Epoch 055 - training loss: 0.2772, validation loss: 0.1374
2024-05-25 03:07:34 [INFO]: Epoch 056 - training loss: 0.2757, validation loss: 0.1375
2024-05-25 03:07:35 [INFO]: Epoch 057 - training loss: 0.2747, validation loss: 0.1380
2024-05-25 03:07:35 [INFO]: Epoch 058 - training loss: 0.2741, validation loss: 0.1358
2024-05-25 03:07:36 [INFO]: Epoch 059 - training loss: 0.2750, validation loss: 0.1357
2024-05-25 03:07:37 [INFO]: Epoch 060 - training loss: 0.2714, validation loss: 0.1350
2024-05-25 03:07:37 [INFO]: Epoch 061 - training loss: 0.2675, validation loss: 0.1343
2024-05-25 03:07:38 [INFO]: Epoch 062 - training loss: 0.2665, validation loss: 0.1345
2024-05-25 03:07:38 [INFO]: Epoch 063 - training loss: 0.2653, validation loss: 0.1338
2024-05-25 03:07:39 [INFO]: Epoch 064 - training loss: 0.2630, validation loss: 0.1324
2024-05-25 03:07:39 [INFO]: Epoch 065 - training loss: 0.2624, validation loss: 0.1328
2024-05-25 03:07:40 [INFO]: Epoch 066 - training loss: 0.2615, validation loss: 0.1324
2024-05-25 03:07:41 [INFO]: Epoch 067 - training loss: 0.2607, validation loss: 0.1314
2024-05-25 03:07:41 [INFO]: Epoch 068 - training loss: 0.2596, validation loss: 0.1314
2024-05-25 03:07:42 [INFO]: Epoch 069 - training loss: 0.2580, validation loss: 0.1311
2024-05-25 03:07:42 [INFO]: Epoch 070 - training loss: 0.2577, validation loss: 0.1306
2024-05-25 03:07:43 [INFO]: Epoch 071 - training loss: 0.2581, validation loss: 0.1318
2024-05-25 03:07:44 [INFO]: Epoch 072 - training loss: 0.2582, validation loss: 0.1312
2024-05-25 03:07:44 [INFO]: Epoch 073 - training loss: 0.2562, validation loss: 0.1305
2024-05-25 03:07:45 [INFO]: Epoch 074 - training loss: 0.2535, validation loss: 0.1298
2024-05-25 03:07:46 [INFO]: Epoch 075 - training loss: 0.2532, validation loss: 0.1300
2024-05-25 03:07:46 [INFO]: Epoch 076 - training loss: 0.2513, validation loss: 0.1287
2024-05-25 03:07:47 [INFO]: Epoch 077 - training loss: 0.2503, validation loss: 0.1294
2024-05-25 03:07:47 [INFO]: Epoch 078 - training loss: 0.2498, validation loss: 0.1285
2024-05-25 03:07:48 [INFO]: Epoch 079 - training loss: 0.2488, validation loss: 0.1294
2024-05-25 03:07:49 [INFO]: Epoch 080 - training loss: 0.2482, validation loss: 0.1284
2024-05-25 03:07:49 [INFO]: Epoch 081 - training loss: 0.2478, validation loss: 0.1281
2024-05-25 03:07:50 [INFO]: Epoch 082 - training loss: 0.2474, validation loss: 0.1276
2024-05-25 03:07:50 [INFO]: Epoch 083 - training loss: 0.2456, validation loss: 0.1282
2024-05-25 03:07:51 [INFO]: Epoch 084 - training loss: 0.2443, validation loss: 0.1276
2024-05-25 03:07:52 [INFO]: Epoch 085 - training loss: 0.2438, validation loss: 0.1267
2024-05-25 03:07:52 [INFO]: Epoch 086 - training loss: 0.2430, validation loss: 0.1262
2024-05-25 03:07:53 [INFO]: Epoch 087 - training loss: 0.2426, validation loss: 0.1275
2024-05-25 03:07:53 [INFO]: Epoch 088 - training loss: 0.2420, validation loss: 0.1264
2024-05-25 03:07:54 [INFO]: Epoch 089 - training loss: 0.2408, validation loss: 0.1262
2024-05-25 03:07:55 [INFO]: Epoch 090 - training loss: 0.2399, validation loss: 0.1259
2024-05-25 03:07:55 [INFO]: Epoch 091 - training loss: 0.2410, validation loss: 0.1252
2024-05-25 03:07:56 [INFO]: Epoch 092 - training loss: 0.2384, validation loss: 0.1247
2024-05-25 03:07:56 [INFO]: Epoch 093 - training loss: 0.2377, validation loss: 0.1247
2024-05-25 03:07:57 [INFO]: Epoch 094 - training loss: 0.2367, validation loss: 0.1240
2024-05-25 03:07:57 [INFO]: Epoch 095 - training loss: 0.2362, validation loss: 0.1236
2024-05-25 03:07:58 [INFO]: Epoch 096 - training loss: 0.2353, validation loss: 0.1241
2024-05-25 03:07:59 [INFO]: Epoch 097 - training loss: 0.2348, validation loss: 0.1241
2024-05-25 03:07:59 [INFO]: Epoch 098 - training loss: 0.2347, validation loss: 0.1244
2024-05-25 03:08:00 [INFO]: Epoch 099 - training loss: 0.2351, validation loss: 0.1231
2024-05-25 03:08:00 [INFO]: Epoch 100 - training loss: 0.2354, validation loss: 0.1232
2024-05-25 03:08:01 [INFO]: Epoch 101 - training loss: 0.2334, validation loss: 0.1232
2024-05-25 03:08:02 [INFO]: Epoch 102 - training loss: 0.2327, validation loss: 0.1222
2024-05-25 03:08:02 [INFO]: Epoch 103 - training loss: 0.2311, validation loss: 0.1228
2024-05-25 03:08:03 [INFO]: Epoch 104 - training loss: 0.2308, validation loss: 0.1224
2024-05-25 03:08:03 [INFO]: Epoch 105 - training loss: 0.2304, validation loss: 0.1223
2024-05-25 03:08:04 [INFO]: Epoch 106 - training loss: 0.2290, validation loss: 0.1227
2024-05-25 03:08:05 [INFO]: Epoch 107 - training loss: 0.2290, validation loss: 0.1216
2024-05-25 03:08:05 [INFO]: Epoch 108 - training loss: 0.2288, validation loss: 0.1207
2024-05-25 03:08:06 [INFO]: Epoch 109 - training loss: 0.2267, validation loss: 0.1216
2024-05-25 03:08:06 [INFO]: Epoch 110 - training loss: 0.2261, validation loss: 0.1209
2024-05-25 03:08:07 [INFO]: Epoch 111 - training loss: 0.2260, validation loss: 0.1212
2024-05-25 03:08:08 [INFO]: Epoch 112 - training loss: 0.2261, validation loss: 0.1208
2024-05-25 03:08:08 [INFO]: Epoch 113 - training loss: 0.2244, validation loss: 0.1201
2024-05-25 03:08:09 [INFO]: Epoch 114 - training loss: 0.2243, validation loss: 0.1206
2024-05-25 03:08:09 [INFO]: Epoch 115 - training loss: 0.2242, validation loss: 0.1199
2024-05-25 03:08:10 [INFO]: Epoch 116 - training loss: 0.2240, validation loss: 0.1199
2024-05-25 03:08:11 [INFO]: Epoch 117 - training loss: 0.2235, validation loss: 0.1201
2024-05-25 03:08:11 [INFO]: Epoch 118 - training loss: 0.2219, validation loss: 0.1198
2024-05-25 03:08:12 [INFO]: Epoch 119 - training loss: 0.2230, validation loss: 0.1193
2024-05-25 03:08:12 [INFO]: Epoch 120 - training loss: 0.2217, validation loss: 0.1195
2024-05-25 03:08:13 [INFO]: Epoch 121 - training loss: 0.2203, validation loss: 0.1191
2024-05-25 03:08:14 [INFO]: Epoch 122 - training loss: 0.2196, validation loss: 0.1189
2024-05-25 03:08:14 [INFO]: Epoch 123 - training loss: 0.2198, validation loss: 0.1191
2024-05-25 03:08:15 [INFO]: Epoch 124 - training loss: 0.2209, validation loss: 0.1178
2024-05-25 03:08:15 [INFO]: Epoch 125 - training loss: 0.2204, validation loss: 0.1181
2024-05-25 03:08:16 [INFO]: Epoch 126 - training loss: 0.2191, validation loss: 0.1207
2024-05-25 03:08:17 [INFO]: Epoch 127 - training loss: 0.2192, validation loss: 0.1185
2024-05-25 03:08:17 [INFO]: Epoch 128 - training loss: 0.2173, validation loss: 0.1193
2024-05-25 03:08:18 [INFO]: Epoch 129 - training loss: 0.2163, validation loss: 0.1176
2024-05-25 03:08:18 [INFO]: Epoch 130 - training loss: 0.2161, validation loss: 0.1174
2024-05-25 03:08:19 [INFO]: Epoch 131 - training loss: 0.2151, validation loss: 0.1170
2024-05-25 03:08:20 [INFO]: Epoch 132 - training loss: 0.2161, validation loss: 0.1180
2024-05-25 03:08:20 [INFO]: Epoch 133 - training loss: 0.2138, validation loss: 0.1170
2024-05-25 03:08:21 [INFO]: Epoch 134 - training loss: 0.2138, validation loss: 0.1174
2024-05-25 03:08:21 [INFO]: Epoch 135 - training loss: 0.2132, validation loss: 0.1175
2024-05-25 03:08:22 [INFO]: Epoch 136 - training loss: 0.2122, validation loss: 0.1162
2024-05-25 03:08:23 [INFO]: Epoch 137 - training loss: 0.2129, validation loss: 0.1176
2024-05-25 03:08:23 [INFO]: Epoch 138 - training loss: 0.2129, validation loss: 0.1165
2024-05-25 03:08:24 [INFO]: Epoch 139 - training loss: 0.2117, validation loss: 0.1159
2024-05-25 03:08:24 [INFO]: Epoch 140 - training loss: 0.2117, validation loss: 0.1161
2024-05-25 03:08:25 [INFO]: Epoch 141 - training loss: 0.2117, validation loss: 0.1167
2024-05-25 03:08:26 [INFO]: Epoch 142 - training loss: 0.2105, validation loss: 0.1155
2024-05-25 03:08:26 [INFO]: Epoch 143 - training loss: 0.2104, validation loss: 0.1175
2024-05-25 03:08:27 [INFO]: Epoch 144 - training loss: 0.2110, validation loss: 0.1161
2024-05-25 03:08:27 [INFO]: Epoch 145 - training loss: 0.2089, validation loss: 0.1153
2024-05-25 03:08:28 [INFO]: Epoch 146 - training loss: 0.2087, validation loss: 0.1153
2024-05-25 03:08:29 [INFO]: Epoch 147 - training loss: 0.2081, validation loss: 0.1154
2024-05-25 03:08:29 [INFO]: Epoch 148 - training loss: 0.2069, validation loss: 0.1154
2024-05-25 03:08:30 [INFO]: Epoch 149 - training loss: 0.2067, validation loss: 0.1152
2024-05-25 03:08:30 [INFO]: Epoch 150 - training loss: 0.2062, validation loss: 0.1152
2024-05-25 03:08:31 [INFO]: Epoch 151 - training loss: 0.2058, validation loss: 0.1155
2024-05-25 03:08:32 [INFO]: Epoch 152 - training loss: 0.2054, validation loss: 0.1140
2024-05-25 03:08:32 [INFO]: Epoch 153 - training loss: 0.2053, validation loss: 0.1150
2024-05-25 03:08:33 [INFO]: Epoch 154 - training loss: 0.2063, validation loss: 0.1150
2024-05-25 03:08:33 [INFO]: Epoch 155 - training loss: 0.2050, validation loss: 0.1140
2024-05-25 03:08:34 [INFO]: Epoch 156 - training loss: 0.2042, validation loss: 0.1151
2024-05-25 03:08:35 [INFO]: Epoch 157 - training loss: 0.2034, validation loss: 0.1138
2024-05-25 03:08:35 [INFO]: Epoch 158 - training loss: 0.2038, validation loss: 0.1148
2024-05-25 03:08:36 [INFO]: Epoch 159 - training loss: 0.2035, validation loss: 0.1147
2024-05-25 03:08:36 [INFO]: Epoch 160 - training loss: 0.2028, validation loss: 0.1153
2024-05-25 03:08:37 [INFO]: Epoch 161 - training loss: 0.2018, validation loss: 0.1149
2024-05-25 03:08:38 [INFO]: Epoch 162 - training loss: 0.2024, validation loss: 0.1147
2024-05-25 03:08:38 [INFO]: Epoch 163 - training loss: 0.2058, validation loss: 0.1153
2024-05-25 03:08:39 [INFO]: Epoch 164 - training loss: 0.2031, validation loss: 0.1138
2024-05-25 03:08:39 [INFO]: Epoch 165 - training loss: 0.2005, validation loss: 0.1146
2024-05-25 03:08:40 [INFO]: Epoch 166 - training loss: 0.1999, validation loss: 0.1148
2024-05-25 03:08:41 [INFO]: Epoch 167 - training loss: 0.2013, validation loss: 0.1140
2024-05-25 03:08:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:08:41 [INFO]: Finished training. The best model is from epoch#157.
2024-05-25 03:08:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/SAITS_air_quality/20240525_T030659/SAITS.pypots
2024-05-25 03:08:41 [INFO]: SAITS on Air-Quality: MAE=0.1625, MSE=0.1577
2024-05-25 03:08:41 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/SAITS_air_quality/imputation.pkl
2024-05-25 03:08:41 [INFO]: Using the given device: cuda:0
2024-05-25 03:08:41 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/Transformer_air_quality/20240525_T030841
2024-05-25 03:08:41 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/Transformer_air_quality/20240525_T030841/tensorboard
2024-05-25 03:08:41 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 03:08:41 [INFO]: Epoch 001 - training loss: 0.9048, validation loss: 0.4475
2024-05-25 03:08:41 [INFO]: Epoch 002 - training loss: 0.5714, validation loss: 0.3303
2024-05-25 03:08:42 [INFO]: Epoch 003 - training loss: 0.4820, validation loss: 0.2733
2024-05-25 03:08:42 [INFO]: Epoch 004 - training loss: 0.4336, validation loss: 0.2457
2024-05-25 03:08:42 [INFO]: Epoch 005 - training loss: 0.4043, validation loss: 0.2337
2024-05-25 03:08:42 [INFO]: Epoch 006 - training loss: 0.3860, validation loss: 0.2245
2024-05-25 03:08:43 [INFO]: Epoch 007 - training loss: 0.3733, validation loss: 0.2170
2024-05-25 03:08:43 [INFO]: Epoch 008 - training loss: 0.3617, validation loss: 0.2144
2024-05-25 03:08:43 [INFO]: Epoch 009 - training loss: 0.3514, validation loss: 0.2057
2024-05-25 03:08:43 [INFO]: Epoch 010 - training loss: 0.3446, validation loss: 0.2030
2024-05-25 03:08:44 [INFO]: Epoch 011 - training loss: 0.3369, validation loss: 0.1964
2024-05-25 03:08:44 [INFO]: Epoch 012 - training loss: 0.3288, validation loss: 0.1944
2024-05-25 03:08:44 [INFO]: Epoch 013 - training loss: 0.3246, validation loss: 0.1912
2024-05-25 03:08:44 [INFO]: Epoch 014 - training loss: 0.3197, validation loss: 0.1879
2024-05-25 03:08:45 [INFO]: Epoch 015 - training loss: 0.3137, validation loss: 0.1841
2024-05-25 03:08:45 [INFO]: Epoch 016 - training loss: 0.3120, validation loss: 0.1833
2024-05-25 03:08:45 [INFO]: Epoch 017 - training loss: 0.3111, validation loss: 0.1820
2024-05-25 03:08:45 [INFO]: Epoch 018 - training loss: 0.3071, validation loss: 0.1746
2024-05-25 03:08:46 [INFO]: Epoch 019 - training loss: 0.3020, validation loss: 0.1769
2024-05-25 03:08:46 [INFO]: Epoch 020 - training loss: 0.3009, validation loss: 0.1745
2024-05-25 03:08:46 [INFO]: Epoch 021 - training loss: 0.2986, validation loss: 0.1726
2024-05-25 03:08:46 [INFO]: Epoch 022 - training loss: 0.2927, validation loss: 0.1736
2024-05-25 03:08:46 [INFO]: Epoch 023 - training loss: 0.2914, validation loss: 0.1729
2024-05-25 03:08:47 [INFO]: Epoch 024 - training loss: 0.2944, validation loss: 0.1722
2024-05-25 03:08:47 [INFO]: Epoch 025 - training loss: 0.2855, validation loss: 0.1681
2024-05-25 03:08:47 [INFO]: Epoch 026 - training loss: 0.2826, validation loss: 0.1681
2024-05-25 03:08:47 [INFO]: Epoch 027 - training loss: 0.2800, validation loss: 0.1669
2024-05-25 03:08:48 [INFO]: Epoch 028 - training loss: 0.2776, validation loss: 0.1650
2024-05-25 03:08:48 [INFO]: Epoch 029 - training loss: 0.2773, validation loss: 0.1657
2024-05-25 03:08:48 [INFO]: Epoch 030 - training loss: 0.2764, validation loss: 0.1645
2024-05-25 03:08:48 [INFO]: Epoch 031 - training loss: 0.2743, validation loss: 0.1641
2024-05-25 03:08:49 [INFO]: Epoch 032 - training loss: 0.2705, validation loss: 0.1632
2024-05-25 03:08:49 [INFO]: Epoch 033 - training loss: 0.2677, validation loss: 0.1635
2024-05-25 03:08:49 [INFO]: Epoch 034 - training loss: 0.2658, validation loss: 0.1617
2024-05-25 03:08:49 [INFO]: Epoch 035 - training loss: 0.2653, validation loss: 0.1639
2024-05-25 03:08:50 [INFO]: Epoch 036 - training loss: 0.2640, validation loss: 0.1622
2024-05-25 03:08:50 [INFO]: Epoch 037 - training loss: 0.2627, validation loss: 0.1625
2024-05-25 03:08:50 [INFO]: Epoch 038 - training loss: 0.2592, validation loss: 0.1593
2024-05-25 03:08:50 [INFO]: Epoch 039 - training loss: 0.2590, validation loss: 0.1605
2024-05-25 03:08:51 [INFO]: Epoch 040 - training loss: 0.2607, validation loss: 0.1594
2024-05-25 03:08:51 [INFO]: Epoch 041 - training loss: 0.2568, validation loss: 0.1604
2024-05-25 03:08:51 [INFO]: Epoch 042 - training loss: 0.2554, validation loss: 0.1591
2024-05-25 03:08:51 [INFO]: Epoch 043 - training loss: 0.2525, validation loss: 0.1585
2024-05-25 03:08:52 [INFO]: Epoch 044 - training loss: 0.2500, validation loss: 0.1593
2024-05-25 03:08:52 [INFO]: Epoch 045 - training loss: 0.2518, validation loss: 0.1592
2024-05-25 03:08:52 [INFO]: Epoch 046 - training loss: 0.2542, validation loss: 0.1579
2024-05-25 03:08:52 [INFO]: Epoch 047 - training loss: 0.2509, validation loss: 0.1577
2024-05-25 03:08:53 [INFO]: Epoch 048 - training loss: 0.2487, validation loss: 0.1551
2024-05-25 03:08:53 [INFO]: Epoch 049 - training loss: 0.2503, validation loss: 0.1614
2024-05-25 03:08:53 [INFO]: Epoch 050 - training loss: 0.2471, validation loss: 0.1556
2024-05-25 03:08:53 [INFO]: Epoch 051 - training loss: 0.2439, validation loss: 0.1560
2024-05-25 03:08:54 [INFO]: Epoch 052 - training loss: 0.2435, validation loss: 0.1586
2024-05-25 03:08:54 [INFO]: Epoch 053 - training loss: 0.2422, validation loss: 0.1559
2024-05-25 03:08:54 [INFO]: Epoch 054 - training loss: 0.2402, validation loss: 0.1548
2024-05-25 03:08:54 [INFO]: Epoch 055 - training loss: 0.2376, validation loss: 0.1530
2024-05-25 03:08:55 [INFO]: Epoch 056 - training loss: 0.2367, validation loss: 0.1558
2024-05-25 03:08:55 [INFO]: Epoch 057 - training loss: 0.2374, validation loss: 0.1543
2024-05-25 03:08:55 [INFO]: Epoch 058 - training loss: 0.2367, validation loss: 0.1532
2024-05-25 03:08:55 [INFO]: Epoch 059 - training loss: 0.2356, validation loss: 0.1544
2024-05-25 03:08:56 [INFO]: Epoch 060 - training loss: 0.2342, validation loss: 0.1520
2024-05-25 03:08:56 [INFO]: Epoch 061 - training loss: 0.2347, validation loss: 0.1543
2024-05-25 03:08:56 [INFO]: Epoch 062 - training loss: 0.2335, validation loss: 0.1525
2024-05-25 03:08:56 [INFO]: Epoch 063 - training loss: 0.2300, validation loss: 0.1538
2024-05-25 03:08:57 [INFO]: Epoch 064 - training loss: 0.2293, validation loss: 0.1495
2024-05-25 03:08:57 [INFO]: Epoch 065 - training loss: 0.2271, validation loss: 0.1515
2024-05-25 03:08:57 [INFO]: Epoch 066 - training loss: 0.2273, validation loss: 0.1500
2024-05-25 03:08:57 [INFO]: Epoch 067 - training loss: 0.2246, validation loss: 0.1488
2024-05-25 03:08:58 [INFO]: Epoch 068 - training loss: 0.2252, validation loss: 0.1493
2024-05-25 03:08:58 [INFO]: Epoch 069 - training loss: 0.2247, validation loss: 0.1505
2024-05-25 03:08:58 [INFO]: Epoch 070 - training loss: 0.2266, validation loss: 0.1502
2024-05-25 03:08:58 [INFO]: Epoch 071 - training loss: 0.2240, validation loss: 0.1476
2024-05-25 03:08:59 [INFO]: Epoch 072 - training loss: 0.2209, validation loss: 0.1495
2024-05-25 03:08:59 [INFO]: Epoch 073 - training loss: 0.2189, validation loss: 0.1501
2024-05-25 03:08:59 [INFO]: Epoch 074 - training loss: 0.2198, validation loss: 0.1472
2024-05-25 03:08:59 [INFO]: Epoch 075 - training loss: 0.2172, validation loss: 0.1491
2024-05-25 03:08:59 [INFO]: Epoch 076 - training loss: 0.2177, validation loss: 0.1480
2024-05-25 03:09:00 [INFO]: Epoch 077 - training loss: 0.2143, validation loss: 0.1474
2024-05-25 03:09:00 [INFO]: Epoch 078 - training loss: 0.2148, validation loss: 0.1493
2024-05-25 03:09:00 [INFO]: Epoch 079 - training loss: 0.2186, validation loss: 0.1476
2024-05-25 03:09:00 [INFO]: Epoch 080 - training loss: 0.2167, validation loss: 0.1473
2024-05-25 03:09:01 [INFO]: Epoch 081 - training loss: 0.2147, validation loss: 0.1467
2024-05-25 03:09:01 [INFO]: Epoch 082 - training loss: 0.2134, validation loss: 0.1493
2024-05-25 03:09:01 [INFO]: Epoch 083 - training loss: 0.2115, validation loss: 0.1475
2024-05-25 03:09:01 [INFO]: Epoch 084 - training loss: 0.2095, validation loss: 0.1480
2024-05-25 03:09:02 [INFO]: Epoch 085 - training loss: 0.2121, validation loss: 0.1504
2024-05-25 03:09:02 [INFO]: Epoch 086 - training loss: 0.2123, validation loss: 0.1467
2024-05-25 03:09:02 [INFO]: Epoch 087 - training loss: 0.2081, validation loss: 0.1472
2024-05-25 03:09:02 [INFO]: Epoch 088 - training loss: 0.2066, validation loss: 0.1466
2024-05-25 03:09:03 [INFO]: Epoch 089 - training loss: 0.2100, validation loss: 0.1438
2024-05-25 03:09:03 [INFO]: Epoch 090 - training loss: 0.2089, validation loss: 0.1447
2024-05-25 03:09:03 [INFO]: Epoch 091 - training loss: 0.2050, validation loss: 0.1460
2024-05-25 03:09:03 [INFO]: Epoch 092 - training loss: 0.2036, validation loss: 0.1453
2024-05-25 03:09:04 [INFO]: Epoch 093 - training loss: 0.2047, validation loss: 0.1455
2024-05-25 03:09:04 [INFO]: Epoch 094 - training loss: 0.2041, validation loss: 0.1448
2024-05-25 03:09:04 [INFO]: Epoch 095 - training loss: 0.2035, validation loss: 0.1443
2024-05-25 03:09:04 [INFO]: Epoch 096 - training loss: 0.2015, validation loss: 0.1442
2024-05-25 03:09:05 [INFO]: Epoch 097 - training loss: 0.2051, validation loss: 0.1439
2024-05-25 03:09:05 [INFO]: Epoch 098 - training loss: 0.2068, validation loss: 0.1432
2024-05-25 03:09:05 [INFO]: Epoch 099 - training loss: 0.2041, validation loss: 0.1444
2024-05-25 03:09:05 [INFO]: Epoch 100 - training loss: 0.1982, validation loss: 0.1428
2024-05-25 03:09:06 [INFO]: Epoch 101 - training loss: 0.1977, validation loss: 0.1441
2024-05-25 03:09:06 [INFO]: Epoch 102 - training loss: 0.1958, validation loss: 0.1436
2024-05-25 03:09:06 [INFO]: Epoch 103 - training loss: 0.1947, validation loss: 0.1426
2024-05-25 03:09:06 [INFO]: Epoch 104 - training loss: 0.1939, validation loss: 0.1425
2024-05-25 03:09:07 [INFO]: Epoch 105 - training loss: 0.1932, validation loss: 0.1440
2024-05-25 03:09:07 [INFO]: Epoch 106 - training loss: 0.1934, validation loss: 0.1443
2024-05-25 03:09:07 [INFO]: Epoch 107 - training loss: 0.1920, validation loss: 0.1423
2024-05-25 03:09:07 [INFO]: Epoch 108 - training loss: 0.1911, validation loss: 0.1445
2024-05-25 03:09:08 [INFO]: Epoch 109 - training loss: 0.1928, validation loss: 0.1422
2024-05-25 03:09:08 [INFO]: Epoch 110 - training loss: 0.1908, validation loss: 0.1420
2024-05-25 03:09:08 [INFO]: Epoch 111 - training loss: 0.1912, validation loss: 0.1421
2024-05-25 03:09:08 [INFO]: Epoch 112 - training loss: 0.1915, validation loss: 0.1424
2024-05-25 03:09:09 [INFO]: Epoch 113 - training loss: 0.1910, validation loss: 0.1411
2024-05-25 03:09:09 [INFO]: Epoch 114 - training loss: 0.1908, validation loss: 0.1396
2024-05-25 03:09:09 [INFO]: Epoch 115 - training loss: 0.1910, validation loss: 0.1415
2024-05-25 03:09:09 [INFO]: Epoch 116 - training loss: 0.1891, validation loss: 0.1437
2024-05-25 03:09:10 [INFO]: Epoch 117 - training loss: 0.1882, validation loss: 0.1406
2024-05-25 03:09:10 [INFO]: Epoch 118 - training loss: 0.1867, validation loss: 0.1424
2024-05-25 03:09:10 [INFO]: Epoch 119 - training loss: 0.1870, validation loss: 0.1409
2024-05-25 03:09:10 [INFO]: Epoch 120 - training loss: 0.1849, validation loss: 0.1413
2024-05-25 03:09:11 [INFO]: Epoch 121 - training loss: 0.1846, validation loss: 0.1393
2024-05-25 03:09:11 [INFO]: Epoch 122 - training loss: 0.1853, validation loss: 0.1406
2024-05-25 03:09:11 [INFO]: Epoch 123 - training loss: 0.1825, validation loss: 0.1410
2024-05-25 03:09:11 [INFO]: Epoch 124 - training loss: 0.1834, validation loss: 0.1447
2024-05-25 03:09:12 [INFO]: Epoch 125 - training loss: 0.1838, validation loss: 0.1412
2024-05-25 03:09:12 [INFO]: Epoch 126 - training loss: 0.1840, validation loss: 0.1410
2024-05-25 03:09:12 [INFO]: Epoch 127 - training loss: 0.1848, validation loss: 0.1394
2024-05-25 03:09:12 [INFO]: Epoch 128 - training loss: 0.1817, validation loss: 0.1388
2024-05-25 03:09:13 [INFO]: Epoch 129 - training loss: 0.1824, validation loss: 0.1405
2024-05-25 03:09:13 [INFO]: Epoch 130 - training loss: 0.1812, validation loss: 0.1393
2024-05-25 03:09:13 [INFO]: Epoch 131 - training loss: 0.1785, validation loss: 0.1391
2024-05-25 03:09:13 [INFO]: Epoch 132 - training loss: 0.1780, validation loss: 0.1404
2024-05-25 03:09:14 [INFO]: Epoch 133 - training loss: 0.1775, validation loss: 0.1386
2024-05-25 03:09:14 [INFO]: Epoch 134 - training loss: 0.1797, validation loss: 0.1394
2024-05-25 03:09:14 [INFO]: Epoch 135 - training loss: 0.1784, validation loss: 0.1394
2024-05-25 03:09:14 [INFO]: Epoch 136 - training loss: 0.1787, validation loss: 0.1384
2024-05-25 03:09:14 [INFO]: Epoch 137 - training loss: 0.1774, validation loss: 0.1400
2024-05-25 03:09:15 [INFO]: Epoch 138 - training loss: 0.1781, validation loss: 0.1399
2024-05-25 03:09:15 [INFO]: Epoch 139 - training loss: 0.1781, validation loss: 0.1382
2024-05-25 03:09:15 [INFO]: Epoch 140 - training loss: 0.1766, validation loss: 0.1414
2024-05-25 03:09:15 [INFO]: Epoch 141 - training loss: 0.1762, validation loss: 0.1381
2024-05-25 03:09:16 [INFO]: Epoch 142 - training loss: 0.1760, validation loss: 0.1402
2024-05-25 03:09:16 [INFO]: Epoch 143 - training loss: 0.1763, validation loss: 0.1402
2024-05-25 03:09:16 [INFO]: Epoch 144 - training loss: 0.1755, validation loss: 0.1377
2024-05-25 03:09:16 [INFO]: Epoch 145 - training loss: 0.1744, validation loss: 0.1382
2024-05-25 03:09:17 [INFO]: Epoch 146 - training loss: 0.1725, validation loss: 0.1366
2024-05-25 03:09:17 [INFO]: Epoch 147 - training loss: 0.1726, validation loss: 0.1376
2024-05-25 03:09:17 [INFO]: Epoch 148 - training loss: 0.1700, validation loss: 0.1370
2024-05-25 03:09:17 [INFO]: Epoch 149 - training loss: 0.1691, validation loss: 0.1392
2024-05-25 03:09:18 [INFO]: Epoch 150 - training loss: 0.1701, validation loss: 0.1391
2024-05-25 03:09:18 [INFO]: Epoch 151 - training loss: 0.1709, validation loss: 0.1378
2024-05-25 03:09:18 [INFO]: Epoch 152 - training loss: 0.1706, validation loss: 0.1382
2024-05-25 03:09:18 [INFO]: Epoch 153 - training loss: 0.1713, validation loss: 0.1377
2024-05-25 03:09:19 [INFO]: Epoch 154 - training loss: 0.1716, validation loss: 0.1368
2024-05-25 03:09:19 [INFO]: Epoch 155 - training loss: 0.1721, validation loss: 0.1396
2024-05-25 03:09:19 [INFO]: Epoch 156 - training loss: 0.1681, validation loss: 0.1378
2024-05-25 03:09:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:09:19 [INFO]: Finished training. The best model is from epoch#146.
2024-05-25 03:09:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/Transformer_air_quality/20240525_T030841/Transformer.pypots
2024-05-25 03:09:19 [INFO]: Transformer on Air-Quality: MAE=0.1817, MSE=0.1843
2024-05-25 03:09:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Transformer_air_quality/imputation.pkl
2024-05-25 03:09:19 [INFO]: Using the given device: cuda:0
2024-05-25 03:09:19 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/TimesNet_air_quality/20240525_T030919
2024-05-25 03:09:19 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/TimesNet_air_quality/20240525_T030919/tensorboard
2024-05-25 03:09:20 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 03:09:20 [INFO]: Epoch 001 - training loss: 0.3120, validation loss: 0.2466
2024-05-25 03:09:21 [INFO]: Epoch 002 - training loss: 0.2268, validation loss: 0.2204
2024-05-25 03:09:21 [INFO]: Epoch 003 - training loss: 0.1952, validation loss: 0.1990
2024-05-25 03:09:22 [INFO]: Epoch 004 - training loss: 0.1754, validation loss: 0.1835
2024-05-25 03:09:22 [INFO]: Epoch 005 - training loss: 0.1622, validation loss: 0.1791
2024-05-25 03:09:23 [INFO]: Epoch 006 - training loss: 0.1616, validation loss: 0.1777
2024-05-25 03:09:23 [INFO]: Epoch 007 - training loss: 0.1537, validation loss: 0.1782
2024-05-25 03:09:24 [INFO]: Epoch 008 - training loss: 0.1405, validation loss: 0.1723
2024-05-25 03:09:24 [INFO]: Epoch 009 - training loss: 0.1345, validation loss: 0.1718
2024-05-25 03:09:25 [INFO]: Epoch 010 - training loss: 0.1326, validation loss: 0.1716
2024-05-25 03:09:25 [INFO]: Epoch 011 - training loss: 0.1301, validation loss: 0.1714
2024-05-25 03:09:25 [INFO]: Epoch 012 - training loss: 0.1199, validation loss: 0.1629
2024-05-25 03:09:26 [INFO]: Epoch 013 - training loss: 0.1174, validation loss: 0.1666
2024-05-25 03:09:26 [INFO]: Epoch 014 - training loss: 0.1131, validation loss: 0.1656
2024-05-25 03:09:27 [INFO]: Epoch 015 - training loss: 0.1146, validation loss: 0.1656
2024-05-25 03:09:27 [INFO]: Epoch 016 - training loss: 0.1116, validation loss: 0.1688
2024-05-25 03:09:28 [INFO]: Epoch 017 - training loss: 0.1086, validation loss: 0.1643
2024-05-25 03:09:28 [INFO]: Epoch 018 - training loss: 0.1153, validation loss: 0.1694
2024-05-25 03:09:29 [INFO]: Epoch 019 - training loss: 0.1084, validation loss: 0.1772
2024-05-25 03:09:29 [INFO]: Epoch 020 - training loss: 0.1102, validation loss: 0.1709
2024-05-25 03:09:30 [INFO]: Epoch 021 - training loss: 0.1068, validation loss: 0.1634
2024-05-25 03:09:30 [INFO]: Epoch 022 - training loss: 0.1033, validation loss: 0.1618
2024-05-25 03:09:30 [INFO]: Epoch 023 - training loss: 0.0997, validation loss: 0.1573
2024-05-25 03:09:31 [INFO]: Epoch 024 - training loss: 0.0989, validation loss: 0.1579
2024-05-25 03:09:31 [INFO]: Epoch 025 - training loss: 0.0955, validation loss: 0.1573
2024-05-25 03:09:32 [INFO]: Epoch 026 - training loss: 0.0915, validation loss: 0.1602
2024-05-25 03:09:32 [INFO]: Epoch 027 - training loss: 0.0948, validation loss: 0.1600
2024-05-25 03:09:33 [INFO]: Epoch 028 - training loss: 0.0940, validation loss: 0.1561
2024-05-25 03:09:33 [INFO]: Epoch 029 - training loss: 0.1008, validation loss: 0.1579
2024-05-25 03:09:34 [INFO]: Epoch 030 - training loss: 0.0962, validation loss: 0.1606
2024-05-25 03:09:34 [INFO]: Epoch 031 - training loss: 0.0929, validation loss: 0.1572
2024-05-25 03:09:35 [INFO]: Epoch 032 - training loss: 0.0871, validation loss: 0.1565
2024-05-25 03:09:35 [INFO]: Epoch 033 - training loss: 0.0868, validation loss: 0.1548
2024-05-25 03:09:35 [INFO]: Epoch 034 - training loss: 0.0843, validation loss: 0.1553
2024-05-25 03:09:36 [INFO]: Epoch 035 - training loss: 0.0817, validation loss: 0.1583
2024-05-25 03:09:36 [INFO]: Epoch 036 - training loss: 0.0812, validation loss: 0.1553
2024-05-25 03:09:37 [INFO]: Epoch 037 - training loss: 0.0802, validation loss: 0.1585
2024-05-25 03:09:37 [INFO]: Epoch 038 - training loss: 0.0807, validation loss: 0.1563
2024-05-25 03:09:38 [INFO]: Epoch 039 - training loss: 0.0804, validation loss: 0.1581
2024-05-25 03:09:38 [INFO]: Epoch 040 - training loss: 0.0810, validation loss: 0.1585
2024-05-25 03:09:39 [INFO]: Epoch 041 - training loss: 0.0791, validation loss: 0.1543
2024-05-25 03:09:39 [INFO]: Epoch 042 - training loss: 0.0774, validation loss: 0.1568
2024-05-25 03:09:40 [INFO]: Epoch 043 - training loss: 0.0734, validation loss: 0.1583
2024-05-25 03:09:40 [INFO]: Epoch 044 - training loss: 0.0729, validation loss: 0.1567
2024-05-25 03:09:40 [INFO]: Epoch 045 - training loss: 0.0739, validation loss: 0.1574
2024-05-25 03:09:41 [INFO]: Epoch 046 - training loss: 0.0785, validation loss: 0.1593
2024-05-25 03:09:41 [INFO]: Epoch 047 - training loss: 0.0762, validation loss: 0.1596
2024-05-25 03:09:42 [INFO]: Epoch 048 - training loss: 0.0777, validation loss: 0.1639
2024-05-25 03:09:42 [INFO]: Epoch 049 - training loss: 0.0786, validation loss: 0.1663
2024-05-25 03:09:43 [INFO]: Epoch 050 - training loss: 0.0741, validation loss: 0.1494
2024-05-25 03:09:43 [INFO]: Epoch 051 - training loss: 0.0751, validation loss: 0.1579
2024-05-25 03:09:44 [INFO]: Epoch 052 - training loss: 0.0716, validation loss: 0.1523
2024-05-25 03:09:44 [INFO]: Epoch 053 - training loss: 0.0682, validation loss: 0.1545
2024-05-25 03:09:45 [INFO]: Epoch 054 - training loss: 0.0672, validation loss: 0.1524
2024-05-25 03:09:45 [INFO]: Epoch 055 - training loss: 0.0671, validation loss: 0.1547
2024-05-25 03:09:45 [INFO]: Epoch 056 - training loss: 0.0671, validation loss: 0.1538
2024-05-25 03:09:46 [INFO]: Epoch 057 - training loss: 0.0668, validation loss: 0.1610
2024-05-25 03:09:46 [INFO]: Epoch 058 - training loss: 0.0671, validation loss: 0.1571
2024-05-25 03:09:47 [INFO]: Epoch 059 - training loss: 0.0646, validation loss: 0.1546
2024-05-25 03:09:47 [INFO]: Epoch 060 - training loss: 0.0640, validation loss: 0.1545
2024-05-25 03:09:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:09:47 [INFO]: Finished training. The best model is from epoch#50.
2024-05-25 03:09:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/TimesNet_air_quality/20240525_T030919/TimesNet.pypots
2024-05-25 03:09:47 [INFO]: TimesNet on Air-Quality: MAE=0.1696, MSE=0.2690
2024-05-25 03:09:47 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/TimesNet_air_quality/imputation.pkl
2024-05-25 03:09:47 [INFO]: Using the given device: cuda:0
2024-05-25 03:09:47 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947
2024-05-25 03:09:47 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/tensorboard
2024-05-25 03:09:47 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 03:10:04 [INFO]: Epoch 001 - training loss: 0.5494, validation loss: 0.3529
2024-05-25 03:10:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch1_loss0.35287071466445924.pypots
2024-05-25 03:10:21 [INFO]: Epoch 002 - training loss: 0.2977, validation loss: 0.2749
2024-05-25 03:10:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch2_loss0.2749381422996521.pypots
2024-05-25 03:10:38 [INFO]: Epoch 003 - training loss: 0.2551, validation loss: 0.2407
2024-05-25 03:10:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch3_loss0.24072506427764892.pypots
2024-05-25 03:10:54 [INFO]: Epoch 004 - training loss: 0.2310, validation loss: 0.2057
2024-05-25 03:10:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch4_loss0.20568243712186812.pypots
2024-05-25 03:11:11 [INFO]: Epoch 005 - training loss: 0.2105, validation loss: 0.1866
2024-05-25 03:11:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch5_loss0.18655555993318557.pypots
2024-05-25 03:11:28 [INFO]: Epoch 006 - training loss: 0.1627, validation loss: 0.1707
2024-05-25 03:11:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch6_loss0.17068892121315002.pypots
2024-05-25 03:11:44 [INFO]: Epoch 007 - training loss: 0.1653, validation loss: 0.1627
2024-05-25 03:11:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch7_loss0.162717504799366.pypots
2024-05-25 03:12:01 [INFO]: Epoch 008 - training loss: 0.1666, validation loss: 0.1592
2024-05-25 03:12:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch8_loss0.15924002826213837.pypots
2024-05-25 03:12:18 [INFO]: Epoch 009 - training loss: 0.1676, validation loss: 0.1599
2024-05-25 03:12:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch9_loss0.15985608249902725.pypots
2024-05-25 03:12:34 [INFO]: Epoch 010 - training loss: 0.1519, validation loss: 0.1549
2024-05-25 03:12:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch10_loss0.15493438988924027.pypots
2024-05-25 03:12:51 [INFO]: Epoch 011 - training loss: 0.1417, validation loss: 0.1470
2024-05-25 03:12:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch11_loss0.14700100421905518.pypots
2024-05-25 03:13:08 [INFO]: Epoch 012 - training loss: 0.1584, validation loss: 0.1477
2024-05-25 03:13:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch12_loss0.1477128580212593.pypots
2024-05-25 03:13:24 [INFO]: Epoch 013 - training loss: 0.1529, validation loss: 0.1430
2024-05-25 03:13:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch13_loss0.14304805397987366.pypots
2024-05-25 03:13:41 [INFO]: Epoch 014 - training loss: 0.1632, validation loss: 0.1494
2024-05-25 03:13:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch14_loss0.14942684918642044.pypots
2024-05-25 03:13:58 [INFO]: Epoch 015 - training loss: 0.1585, validation loss: 0.1456
2024-05-25 03:13:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch15_loss0.14559332132339478.pypots
2024-05-25 03:14:14 [INFO]: Epoch 016 - training loss: 0.1512, validation loss: 0.1423
2024-05-25 03:14:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch16_loss0.1422699809074402.pypots
2024-05-25 03:14:31 [INFO]: Epoch 017 - training loss: 0.1651, validation loss: 0.1389
2024-05-25 03:14:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch17_loss0.13888897150754928.pypots
2024-05-25 03:14:48 [INFO]: Epoch 018 - training loss: 0.1422, validation loss: 0.1364
2024-05-25 03:14:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch18_loss0.13637102618813515.pypots
2024-05-25 03:15:04 [INFO]: Epoch 019 - training loss: 0.1421, validation loss: 0.1373
2024-05-25 03:15:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch19_loss0.13731788992881774.pypots
2024-05-25 03:15:21 [INFO]: Epoch 020 - training loss: 0.1214, validation loss: 0.1344
2024-05-25 03:15:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch20_loss0.13442377820611.pypots
2024-05-25 03:15:38 [INFO]: Epoch 021 - training loss: 0.1443, validation loss: 0.1353
2024-05-25 03:15:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch21_loss0.13533424362540245.pypots
2024-05-25 03:15:54 [INFO]: Epoch 022 - training loss: 0.1374, validation loss: 0.1350
2024-05-25 03:15:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch22_loss0.13502958416938782.pypots
2024-05-25 03:16:11 [INFO]: Epoch 023 - training loss: 0.1424, validation loss: 0.1358
2024-05-25 03:16:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch23_loss0.13579628020524978.pypots
2024-05-25 03:16:28 [INFO]: Epoch 024 - training loss: 0.1388, validation loss: 0.1366
2024-05-25 03:16:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch24_loss0.1365957297384739.pypots
2024-05-25 03:16:45 [INFO]: Epoch 025 - training loss: 0.1333, validation loss: 0.1362
2024-05-25 03:16:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch25_loss0.13616763576865196.pypots
2024-05-25 03:17:01 [INFO]: Epoch 026 - training loss: 0.1396, validation loss: 0.1320
2024-05-25 03:17:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch26_loss0.1320110596716404.pypots
2024-05-25 03:17:18 [INFO]: Epoch 027 - training loss: 0.1482, validation loss: 0.1310
2024-05-25 03:17:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch27_loss0.13095140904188157.pypots
2024-05-25 03:17:35 [INFO]: Epoch 028 - training loss: 0.1425, validation loss: 0.1281
2024-05-25 03:17:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch28_loss0.12806217297911643.pypots
2024-05-25 03:17:51 [INFO]: Epoch 029 - training loss: 0.1175, validation loss: 0.1294
2024-05-25 03:17:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch29_loss0.1294122315943241.pypots
2024-05-25 03:18:08 [INFO]: Epoch 030 - training loss: 0.1242, validation loss: 0.1282
2024-05-25 03:18:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch30_loss0.1281961604952812.pypots
2024-05-25 03:18:25 [INFO]: Epoch 031 - training loss: 0.1284, validation loss: 0.1264
2024-05-25 03:18:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch31_loss0.12635040879249573.pypots
2024-05-25 03:18:41 [INFO]: Epoch 032 - training loss: 0.1350, validation loss: 0.1271
2024-05-25 03:18:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch32_loss0.12713063955307008.pypots
2024-05-25 03:18:58 [INFO]: Epoch 033 - training loss: 0.1163, validation loss: 0.1313
2024-05-25 03:18:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch33_loss0.13127342313528062.pypots
2024-05-25 03:19:15 [INFO]: Epoch 034 - training loss: 0.1306, validation loss: 0.1308
2024-05-25 03:19:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch34_loss0.1307962156832218.pypots
2024-05-25 03:19:31 [INFO]: Epoch 035 - training loss: 0.1223, validation loss: 0.1231
2024-05-25 03:19:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch35_loss0.12311785146594048.pypots
2024-05-25 03:19:48 [INFO]: Epoch 036 - training loss: 0.1205, validation loss: 0.1268
2024-05-25 03:19:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch36_loss0.1267794318497181.pypots
2024-05-25 03:20:05 [INFO]: Epoch 037 - training loss: 0.1260, validation loss: 0.1233
2024-05-25 03:20:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch37_loss0.12333746626973152.pypots
2024-05-25 03:20:21 [INFO]: Epoch 038 - training loss: 0.1300, validation loss: 0.1202
2024-05-25 03:20:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch38_loss0.12018621116876602.pypots
2024-05-25 03:20:38 [INFO]: Epoch 039 - training loss: 0.1259, validation loss: 0.1277
2024-05-25 03:20:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch39_loss0.1277201771736145.pypots
2024-05-25 03:20:55 [INFO]: Epoch 040 - training loss: 0.1286, validation loss: 0.1263
2024-05-25 03:20:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch40_loss0.12630515173077583.pypots
2024-05-25 03:21:11 [INFO]: Epoch 041 - training loss: 0.1259, validation loss: 0.1213
2024-05-25 03:21:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch41_loss0.12134032845497131.pypots
2024-05-25 03:21:28 [INFO]: Epoch 042 - training loss: 0.1117, validation loss: 0.1187
2024-05-25 03:21:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch42_loss0.11870191767811775.pypots
2024-05-25 03:21:45 [INFO]: Epoch 043 - training loss: 0.1208, validation loss: 0.1189
2024-05-25 03:21:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch43_loss0.11885530576109886.pypots
2024-05-25 03:22:01 [INFO]: Epoch 044 - training loss: 0.1196, validation loss: 0.1179
2024-05-25 03:22:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch44_loss0.11794747337698937.pypots
2024-05-25 03:22:18 [INFO]: Epoch 045 - training loss: 0.1124, validation loss: 0.1178
2024-05-25 03:22:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch45_loss0.11782143265008926.pypots
2024-05-25 03:22:35 [INFO]: Epoch 046 - training loss: 0.1322, validation loss: 0.1217
2024-05-25 03:22:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch46_loss0.12168375924229621.pypots
2024-05-25 03:22:51 [INFO]: Epoch 047 - training loss: 0.1126, validation loss: 0.1173
2024-05-25 03:22:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch47_loss0.11725551411509513.pypots
2024-05-25 03:23:08 [INFO]: Epoch 048 - training loss: 0.1163, validation loss: 0.1169
2024-05-25 03:23:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch48_loss0.11688250526785851.pypots
2024-05-25 03:23:25 [INFO]: Epoch 049 - training loss: 0.1209, validation loss: 0.1248
2024-05-25 03:23:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch49_loss0.1247673898935318.pypots
2024-05-25 03:23:41 [INFO]: Epoch 050 - training loss: 0.1112, validation loss: 0.1164
2024-05-25 03:23:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch50_loss0.11639022603631019.pypots
2024-05-25 03:23:58 [INFO]: Epoch 051 - training loss: 0.1115, validation loss: 0.1154
2024-05-25 03:23:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch51_loss0.11541130170226097.pypots
2024-05-25 03:24:15 [INFO]: Epoch 052 - training loss: 0.1071, validation loss: 0.1167
2024-05-25 03:24:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch52_loss0.11672349274158478.pypots
2024-05-25 03:24:31 [INFO]: Epoch 053 - training loss: 0.1122, validation loss: 0.1174
2024-05-25 03:24:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch53_loss0.11738804802298546.pypots
2024-05-25 03:24:48 [INFO]: Epoch 054 - training loss: 0.1298, validation loss: 0.1153
2024-05-25 03:24:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch54_loss0.11526606902480126.pypots
2024-05-25 03:25:05 [INFO]: Epoch 055 - training loss: 0.1138, validation loss: 0.1157
2024-05-25 03:25:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch55_loss0.11573089733719825.pypots
2024-05-25 03:25:21 [INFO]: Epoch 056 - training loss: 0.1026, validation loss: 0.1157
2024-05-25 03:25:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch56_loss0.1157108873128891.pypots
2024-05-25 03:25:38 [INFO]: Epoch 057 - training loss: 0.0976, validation loss: 0.1157
2024-05-25 03:25:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch57_loss0.11567835733294488.pypots
2024-05-25 03:25:55 [INFO]: Epoch 058 - training loss: 0.1224, validation loss: 0.1127
2024-05-25 03:25:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch58_loss0.11272347122430801.pypots
2024-05-25 03:26:11 [INFO]: Epoch 059 - training loss: 0.1139, validation loss: 0.1138
2024-05-25 03:26:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch59_loss0.1138337604701519.pypots
2024-05-25 03:26:28 [INFO]: Epoch 060 - training loss: 0.1095, validation loss: 0.1120
2024-05-25 03:26:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch60_loss0.11196637153625488.pypots
2024-05-25 03:26:45 [INFO]: Epoch 061 - training loss: 0.1075, validation loss: 0.1127
2024-05-25 03:26:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch61_loss0.11267734840512275.pypots
2024-05-25 03:27:01 [INFO]: Epoch 062 - training loss: 0.1076, validation loss: 0.1125
2024-05-25 03:27:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch62_loss0.11247582957148552.pypots
2024-05-25 03:27:18 [INFO]: Epoch 063 - training loss: 0.1054, validation loss: 0.1135
2024-05-25 03:27:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch63_loss0.11351920515298844.pypots
2024-05-25 03:27:35 [INFO]: Epoch 064 - training loss: 0.0935, validation loss: 0.1158
2024-05-25 03:27:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch64_loss0.11579044237732887.pypots
2024-05-25 03:27:51 [INFO]: Epoch 065 - training loss: 0.1180, validation loss: 0.1129
2024-05-25 03:27:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch65_loss0.11291946768760681.pypots
2024-05-25 03:28:08 [INFO]: Epoch 066 - training loss: 0.1005, validation loss: 0.1134
2024-05-25 03:28:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch66_loss0.11344809904694557.pypots
2024-05-25 03:28:25 [INFO]: Epoch 067 - training loss: 0.1089, validation loss: 0.1135
2024-05-25 03:28:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch67_loss0.11354920491576195.pypots
2024-05-25 03:28:41 [INFO]: Epoch 068 - training loss: 0.1067, validation loss: 0.1105
2024-05-25 03:28:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch68_loss0.11048670262098312.pypots
2024-05-25 03:28:58 [INFO]: Epoch 069 - training loss: 0.1062, validation loss: 0.1114
2024-05-25 03:28:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch69_loss0.111398746073246.pypots
2024-05-25 03:29:15 [INFO]: Epoch 070 - training loss: 0.1031, validation loss: 0.1105
2024-05-25 03:29:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch70_loss0.1104627288877964.pypots
2024-05-25 03:29:31 [INFO]: Epoch 071 - training loss: 0.1113, validation loss: 0.1106
2024-05-25 03:29:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch71_loss0.1106419399380684.pypots
2024-05-25 03:29:48 [INFO]: Epoch 072 - training loss: 0.1174, validation loss: 0.1131
2024-05-25 03:29:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch72_loss0.11309065148234368.pypots
2024-05-25 03:30:05 [INFO]: Epoch 073 - training loss: 0.0996, validation loss: 0.1118
2024-05-25 03:30:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch73_loss0.11180254742503166.pypots
2024-05-25 03:30:21 [INFO]: Epoch 074 - training loss: 0.1080, validation loss: 0.1110
2024-05-25 03:30:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch74_loss0.11097881123423577.pypots
2024-05-25 03:30:38 [INFO]: Epoch 075 - training loss: 0.1096, validation loss: 0.1135
2024-05-25 03:30:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch75_loss0.11353380009531974.pypots
2024-05-25 03:30:55 [INFO]: Epoch 076 - training loss: 0.1161, validation loss: 0.1248
2024-05-25 03:30:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch76_loss0.12480200305581093.pypots
2024-05-25 03:31:11 [INFO]: Epoch 077 - training loss: 0.1131, validation loss: 0.1136
2024-05-25 03:31:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch77_loss0.11356734409928322.pypots
2024-05-25 03:31:28 [INFO]: Epoch 078 - training loss: 0.1015, validation loss: 0.1089
2024-05-25 03:31:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch78_loss0.10890621170401574.pypots
2024-05-25 03:31:45 [INFO]: Epoch 079 - training loss: 0.1067, validation loss: 0.1137
2024-05-25 03:31:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch79_loss0.11365024894475936.pypots
2024-05-25 03:32:01 [INFO]: Epoch 080 - training loss: 0.1098, validation loss: 0.1084
2024-05-25 03:32:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch80_loss0.10844994410872459.pypots
2024-05-25 03:32:18 [INFO]: Epoch 081 - training loss: 0.1024, validation loss: 0.1081
2024-05-25 03:32:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch81_loss0.10805425718426705.pypots
2024-05-25 03:32:35 [INFO]: Epoch 082 - training loss: 0.1045, validation loss: 0.1079
2024-05-25 03:32:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch82_loss0.10785500630736351.pypots
2024-05-25 03:32:51 [INFO]: Epoch 083 - training loss: 0.1122, validation loss: 0.1070
2024-05-25 03:32:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch83_loss0.10704493671655654.pypots
2024-05-25 03:33:08 [INFO]: Epoch 084 - training loss: 0.0985, validation loss: 0.1078
2024-05-25 03:33:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch84_loss0.10780669152736663.pypots
2024-05-25 03:33:25 [INFO]: Epoch 085 - training loss: 0.0987, validation loss: 0.1066
2024-05-25 03:33:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch85_loss0.10657818093895913.pypots
2024-05-25 03:33:41 [INFO]: Epoch 086 - training loss: 0.0999, validation loss: 0.1067
2024-05-25 03:33:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch86_loss0.10666148662567139.pypots
2024-05-25 03:33:58 [INFO]: Epoch 087 - training loss: 0.0965, validation loss: 0.1067
2024-05-25 03:33:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch87_loss0.10671959817409515.pypots
2024-05-25 03:34:15 [INFO]: Epoch 088 - training loss: 0.1058, validation loss: 0.1111
2024-05-25 03:34:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch88_loss0.11112380251288415.pypots
2024-05-25 03:34:31 [INFO]: Epoch 089 - training loss: 0.1060, validation loss: 0.1088
2024-05-25 03:34:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch89_loss0.10883674845099449.pypots
2024-05-25 03:34:48 [INFO]: Epoch 090 - training loss: 0.1100, validation loss: 0.1065
2024-05-25 03:34:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch90_loss0.10652282983064651.pypots
2024-05-25 03:35:05 [INFO]: Epoch 091 - training loss: 0.1077, validation loss: 0.1085
2024-05-25 03:35:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch91_loss0.1084849089384079.pypots
2024-05-25 03:35:21 [INFO]: Epoch 092 - training loss: 0.1061, validation loss: 0.1059
2024-05-25 03:35:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch92_loss0.10587938576936722.pypots
2024-05-25 03:35:38 [INFO]: Epoch 093 - training loss: 0.0892, validation loss: 0.1051
2024-05-25 03:35:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch93_loss0.10508129447698593.pypots
2024-05-25 03:35:55 [INFO]: Epoch 094 - training loss: 0.0949, validation loss: 0.1046
2024-05-25 03:35:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch94_loss0.10460318624973297.pypots
2024-05-25 03:36:11 [INFO]: Epoch 095 - training loss: 0.1173, validation loss: 0.1102
2024-05-25 03:36:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch95_loss0.11022895276546478.pypots
2024-05-25 03:36:28 [INFO]: Epoch 096 - training loss: 0.0902, validation loss: 0.1075
2024-05-25 03:36:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch96_loss0.10753940567374229.pypots
2024-05-25 03:36:45 [INFO]: Epoch 097 - training loss: 0.1046, validation loss: 0.1040
2024-05-25 03:36:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch97_loss0.10395195335149765.pypots
2024-05-25 03:37:01 [INFO]: Epoch 098 - training loss: 0.1123, validation loss: 0.1082
2024-05-25 03:37:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch98_loss0.10820828750729561.pypots
2024-05-25 03:37:18 [INFO]: Epoch 099 - training loss: 0.0971, validation loss: 0.1061
2024-05-25 03:37:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch99_loss0.10611817985773087.pypots
2024-05-25 03:37:35 [INFO]: Epoch 100 - training loss: 0.1010, validation loss: 0.1059
2024-05-25 03:37:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch100_loss0.10593004822731018.pypots
2024-05-25 03:37:51 [INFO]: Epoch 101 - training loss: 0.0985, validation loss: 0.1056
2024-05-25 03:37:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch101_loss0.10562334433197976.pypots
2024-05-25 03:38:08 [INFO]: Epoch 102 - training loss: 0.0951, validation loss: 0.1041
2024-05-25 03:38:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch102_loss0.10408084765076638.pypots
2024-05-25 03:38:25 [INFO]: Epoch 103 - training loss: 0.1212, validation loss: 0.1050
2024-05-25 03:38:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch103_loss0.10504872277379036.pypots
2024-05-25 03:38:41 [INFO]: Epoch 104 - training loss: 0.0986, validation loss: 0.1055
2024-05-25 03:38:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch104_loss0.10546222478151321.pypots
2024-05-25 03:38:58 [INFO]: Epoch 105 - training loss: 0.1029, validation loss: 0.1031
2024-05-25 03:38:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch105_loss0.10306970924139022.pypots
2024-05-25 03:39:15 [INFO]: Epoch 106 - training loss: 0.1015, validation loss: 0.1024
2024-05-25 03:39:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch106_loss0.10239267349243164.pypots
2024-05-25 03:39:31 [INFO]: Epoch 107 - training loss: 0.1111, validation loss: 0.1040
2024-05-25 03:39:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch107_loss0.10396865159273147.pypots
2024-05-25 03:39:48 [INFO]: Epoch 108 - training loss: 0.0931, validation loss: 0.1039
2024-05-25 03:39:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch108_loss0.10388836711645126.pypots
2024-05-25 03:40:05 [INFO]: Epoch 109 - training loss: 0.0985, validation loss: 0.1025
2024-05-25 03:40:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch109_loss0.1025254063308239.pypots
2024-05-25 03:40:21 [INFO]: Epoch 110 - training loss: 0.1009, validation loss: 0.1039
2024-05-25 03:40:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch110_loss0.10386315882205963.pypots
2024-05-25 03:40:38 [INFO]: Epoch 111 - training loss: 0.1060, validation loss: 0.1027
2024-05-25 03:40:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch111_loss0.10268593579530716.pypots
2024-05-25 03:40:55 [INFO]: Epoch 112 - training loss: 0.1003, validation loss: 0.1058
2024-05-25 03:40:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch112_loss0.10582649037241935.pypots
2024-05-25 03:41:11 [INFO]: Epoch 113 - training loss: 0.0946, validation loss: 0.1035
2024-05-25 03:41:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch113_loss0.10349313616752624.pypots
2024-05-25 03:41:28 [INFO]: Epoch 114 - training loss: 0.0988, validation loss: 0.1028
2024-05-25 03:41:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch114_loss0.10275074616074562.pypots
2024-05-25 03:41:45 [INFO]: Epoch 115 - training loss: 0.0924, validation loss: 0.1028
2024-05-25 03:41:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch115_loss0.10281557664275169.pypots
2024-05-25 03:42:01 [INFO]: Epoch 116 - training loss: 0.0870, validation loss: 0.1044
2024-05-25 03:42:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI_epoch116_loss0.10435918346047401.pypots
2024-05-25 03:42:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:42:01 [INFO]: Finished training. The best model is from epoch#106.
2024-05-25 03:42:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T030947/CSDI.pypots
2024-05-25 03:44:22 [INFO]: CSDI on Air-Quality: MAE=0.1086, MSE=0.1816
2024-05-25 03:44:22 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/CSDI_air_quality/imputation.pkl
2024-05-25 03:44:22 [INFO]: Using the given device: cuda:0
2024-05-25 03:44:22 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/GPVAE_air_quality/20240525_T034422
2024-05-25 03:44:22 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/GPVAE_air_quality/20240525_T034422/tensorboard
2024-05-25 03:44:22 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 03:44:22 [INFO]: Epoch 001 - training loss: 65583.4209, validation loss: 0.6255
2024-05-25 03:44:23 [INFO]: Epoch 002 - training loss: 41621.8591, validation loss: 0.5619
2024-05-25 03:44:23 [INFO]: Epoch 003 - training loss: 41218.7470, validation loss: 0.5260
2024-05-25 03:44:23 [INFO]: Epoch 004 - training loss: 41070.3244, validation loss: 0.4663
2024-05-25 03:44:24 [INFO]: Epoch 005 - training loss: 40985.3999, validation loss: 0.4917
2024-05-25 03:44:24 [INFO]: Epoch 006 - training loss: 40948.3183, validation loss: 0.4221
2024-05-25 03:44:24 [INFO]: Epoch 007 - training loss: 40868.4889, validation loss: 0.3977
2024-05-25 03:44:25 [INFO]: Epoch 008 - training loss: 40835.7724, validation loss: 0.3721
2024-05-25 03:44:25 [INFO]: Epoch 009 - training loss: 40812.1251, validation loss: 0.3771
2024-05-25 03:44:25 [INFO]: Epoch 010 - training loss: 40794.4115, validation loss: 0.3662
2024-05-25 03:44:26 [INFO]: Epoch 011 - training loss: 40759.5791, validation loss: 0.3186
2024-05-25 03:44:26 [INFO]: Epoch 012 - training loss: 40730.6994, validation loss: 0.3123
2024-05-25 03:44:26 [INFO]: Epoch 013 - training loss: 40708.3838, validation loss: 0.2996
2024-05-25 03:44:26 [INFO]: Epoch 014 - training loss: 40693.1037, validation loss: 0.3163
2024-05-25 03:44:27 [INFO]: Epoch 015 - training loss: 40694.3585, validation loss: 0.3681
2024-05-25 03:44:27 [INFO]: Epoch 016 - training loss: 40715.1017, validation loss: 0.3054
2024-05-25 03:44:27 [INFO]: Epoch 017 - training loss: 40682.0339, validation loss: 0.2882
2024-05-25 03:44:28 [INFO]: Epoch 018 - training loss: 40671.7010, validation loss: 0.2870
2024-05-25 03:44:28 [INFO]: Epoch 019 - training loss: 40658.5851, validation loss: 0.2756
2024-05-25 03:44:28 [INFO]: Epoch 020 - training loss: 40651.6907, validation loss: 0.2745
2024-05-25 03:44:29 [INFO]: Epoch 021 - training loss: 40647.3073, validation loss: 0.2774
2024-05-25 03:44:29 [INFO]: Epoch 022 - training loss: 40661.4829, validation loss: 0.2937
2024-05-25 03:44:29 [INFO]: Epoch 023 - training loss: 40634.9102, validation loss: 0.2665
2024-05-25 03:44:30 [INFO]: Epoch 024 - training loss: 40632.0718, validation loss: 0.2707
2024-05-25 03:44:30 [INFO]: Epoch 025 - training loss: 40620.2907, validation loss: 0.2580
2024-05-25 03:44:30 [INFO]: Epoch 026 - training loss: 40615.4783, validation loss: 0.2699
2024-05-25 03:44:30 [INFO]: Epoch 027 - training loss: 40645.6940, validation loss: 0.2904
2024-05-25 03:44:31 [INFO]: Epoch 028 - training loss: 40677.3974, validation loss: 0.3022
2024-05-25 03:44:31 [INFO]: Epoch 029 - training loss: 40650.2244, validation loss: 0.3167
2024-05-25 03:44:31 [INFO]: Epoch 030 - training loss: 40645.2305, validation loss: 0.2762
2024-05-25 03:44:32 [INFO]: Epoch 031 - training loss: 40640.1755, validation loss: 0.2665
2024-05-25 03:44:32 [INFO]: Epoch 032 - training loss: 40604.1474, validation loss: 0.2604
2024-05-25 03:44:32 [INFO]: Epoch 033 - training loss: 40588.5268, validation loss: 0.2446
2024-05-25 03:44:33 [INFO]: Epoch 034 - training loss: 40585.6661, validation loss: 0.2454
2024-05-25 03:44:33 [INFO]: Epoch 035 - training loss: 40593.1413, validation loss: 0.2422
2024-05-25 03:44:33 [INFO]: Epoch 036 - training loss: 40580.9907, validation loss: 0.2413
2024-05-25 03:44:34 [INFO]: Epoch 037 - training loss: 40578.8883, validation loss: 0.2426
2024-05-25 03:44:34 [INFO]: Epoch 038 - training loss: 40580.7459, validation loss: 0.2430
2024-05-25 03:44:34 [INFO]: Epoch 039 - training loss: 40582.1519, validation loss: 0.2410
2024-05-25 03:44:34 [INFO]: Epoch 040 - training loss: 40574.6029, validation loss: 0.2358
2024-05-25 03:44:35 [INFO]: Epoch 041 - training loss: 40567.3183, validation loss: 0.2334
2024-05-25 03:44:35 [INFO]: Epoch 042 - training loss: 40565.5642, validation loss: 0.2324
2024-05-25 03:44:35 [INFO]: Epoch 043 - training loss: 40563.7497, validation loss: 0.2361
2024-05-25 03:44:36 [INFO]: Epoch 044 - training loss: 40568.1141, validation loss: 0.2363
2024-05-25 03:44:36 [INFO]: Epoch 045 - training loss: 40564.1013, validation loss: 0.2400
2024-05-25 03:44:36 [INFO]: Epoch 046 - training loss: 40561.6233, validation loss: 0.2314
2024-05-25 03:44:37 [INFO]: Epoch 047 - training loss: 40558.7038, validation loss: 0.2313
2024-05-25 03:44:37 [INFO]: Epoch 048 - training loss: 40567.0773, validation loss: 0.2421
2024-05-25 03:44:37 [INFO]: Epoch 049 - training loss: 40603.9285, validation loss: 0.2452
2024-05-25 03:44:38 [INFO]: Epoch 050 - training loss: 40583.9858, validation loss: 0.2450
2024-05-25 03:44:38 [INFO]: Epoch 051 - training loss: 40569.5907, validation loss: 0.2423
2024-05-25 03:44:38 [INFO]: Epoch 052 - training loss: 40569.5427, validation loss: 0.2270
2024-05-25 03:44:39 [INFO]: Epoch 053 - training loss: 40555.2792, validation loss: 0.2199
2024-05-25 03:44:39 [INFO]: Epoch 054 - training loss: 40551.5938, validation loss: 0.2243
2024-05-25 03:44:39 [INFO]: Epoch 055 - training loss: 40553.5389, validation loss: 0.2233
2024-05-25 03:44:39 [INFO]: Epoch 056 - training loss: 40547.2189, validation loss: 0.2235
2024-05-25 03:44:40 [INFO]: Epoch 057 - training loss: 40543.4468, validation loss: 0.2182
2024-05-25 03:44:40 [INFO]: Epoch 058 - training loss: 40547.0012, validation loss: 0.2255
2024-05-25 03:44:40 [INFO]: Epoch 059 - training loss: 40557.5490, validation loss: 0.2217
2024-05-25 03:44:41 [INFO]: Epoch 060 - training loss: 40553.0071, validation loss: 0.2169
2024-05-25 03:44:41 [INFO]: Epoch 061 - training loss: 40543.2137, validation loss: 0.2206
2024-05-25 03:44:41 [INFO]: Epoch 062 - training loss: 40539.4346, validation loss: 0.2161
2024-05-25 03:44:42 [INFO]: Epoch 063 - training loss: 40533.6091, validation loss: 0.2150
2024-05-25 03:44:42 [INFO]: Epoch 064 - training loss: 40534.9178, validation loss: 0.2173
2024-05-25 03:44:42 [INFO]: Epoch 065 - training loss: 40543.3762, validation loss: 0.2213
2024-05-25 03:44:43 [INFO]: Epoch 066 - training loss: 40563.9796, validation loss: 0.2459
2024-05-25 03:44:43 [INFO]: Epoch 067 - training loss: 40594.8296, validation loss: 0.2215
2024-05-25 03:44:43 [INFO]: Epoch 068 - training loss: 40558.7795, validation loss: 0.2272
2024-05-25 03:44:44 [INFO]: Epoch 069 - training loss: 40563.6029, validation loss: 0.2224
2024-05-25 03:44:44 [INFO]: Epoch 070 - training loss: 40545.2705, validation loss: 0.2268
2024-05-25 03:44:44 [INFO]: Epoch 071 - training loss: 40562.6609, validation loss: 0.2218
2024-05-25 03:44:44 [INFO]: Epoch 072 - training loss: 40541.3442, validation loss: 0.2096
2024-05-25 03:44:45 [INFO]: Epoch 073 - training loss: 40536.0496, validation loss: 0.2150
2024-05-25 03:44:45 [INFO]: Epoch 074 - training loss: 40533.4767, validation loss: 0.2127
2024-05-25 03:44:45 [INFO]: Epoch 075 - training loss: 40528.5213, validation loss: 0.2143
2024-05-25 03:44:46 [INFO]: Epoch 076 - training loss: 40531.6052, validation loss: 0.2244
2024-05-25 03:44:46 [INFO]: Epoch 077 - training loss: 40527.1920, validation loss: 0.2095
2024-05-25 03:44:46 [INFO]: Epoch 078 - training loss: 40534.2205, validation loss: 0.2154
2024-05-25 03:44:47 [INFO]: Epoch 079 - training loss: 40520.8873, validation loss: 0.2058
2024-05-25 03:44:47 [INFO]: Epoch 080 - training loss: 40516.7957, validation loss: 0.2046
2024-05-25 03:44:47 [INFO]: Epoch 081 - training loss: 40520.4217, validation loss: 0.2069
2024-05-25 03:44:48 [INFO]: Epoch 082 - training loss: 40521.8174, validation loss: 0.2065
2024-05-25 03:44:48 [INFO]: Epoch 083 - training loss: 40523.8183, validation loss: 0.2238
2024-05-25 03:44:48 [INFO]: Epoch 084 - training loss: 40537.3951, validation loss: 0.2188
2024-05-25 03:44:48 [INFO]: Epoch 085 - training loss: 40527.3414, validation loss: 0.2152
2024-05-25 03:44:49 [INFO]: Epoch 086 - training loss: 40520.3885, validation loss: 0.2111
2024-05-25 03:44:49 [INFO]: Epoch 087 - training loss: 40517.1286, validation loss: 0.2042
2024-05-25 03:44:49 [INFO]: Epoch 088 - training loss: 40527.5632, validation loss: 0.2136
2024-05-25 03:44:50 [INFO]: Epoch 089 - training loss: 40529.4666, validation loss: 0.2151
2024-05-25 03:44:50 [INFO]: Epoch 090 - training loss: 40523.7138, validation loss: 0.2404
2024-05-25 03:44:50 [INFO]: Epoch 091 - training loss: 40599.5356, validation loss: 0.2185
2024-05-25 03:44:51 [INFO]: Epoch 092 - training loss: 40555.4282, validation loss: 0.2110
2024-05-25 03:44:51 [INFO]: Epoch 093 - training loss: 40537.1746, validation loss: 0.2076
2024-05-25 03:44:51 [INFO]: Epoch 094 - training loss: 40528.1607, validation loss: 0.2021
2024-05-25 03:44:52 [INFO]: Epoch 095 - training loss: 40522.5284, validation loss: 0.2058
2024-05-25 03:44:52 [INFO]: Epoch 096 - training loss: 40521.6586, validation loss: 0.2043
2024-05-25 03:44:52 [INFO]: Epoch 097 - training loss: 40516.1655, validation loss: 0.2006
2024-05-25 03:44:52 [INFO]: Epoch 098 - training loss: 40514.5645, validation loss: 0.2045
2024-05-25 03:44:53 [INFO]: Epoch 099 - training loss: 40507.1869, validation loss: 0.1995
2024-05-25 03:44:53 [INFO]: Epoch 100 - training loss: 40509.1894, validation loss: 0.2042
2024-05-25 03:44:53 [INFO]: Epoch 101 - training loss: 40508.6816, validation loss: 0.2006
2024-05-25 03:44:54 [INFO]: Epoch 102 - training loss: 40504.3419, validation loss: 0.2005
2024-05-25 03:44:54 [INFO]: Epoch 103 - training loss: 40511.9706, validation loss: 0.2020
2024-05-25 03:44:54 [INFO]: Epoch 104 - training loss: 40525.8705, validation loss: 0.2099
2024-05-25 03:44:55 [INFO]: Epoch 105 - training loss: 40533.3889, validation loss: 0.2127
2024-05-25 03:44:55 [INFO]: Epoch 106 - training loss: 40510.8223, validation loss: 0.2002
2024-05-25 03:44:55 [INFO]: Epoch 107 - training loss: 40504.1952, validation loss: 0.2006
2024-05-25 03:44:56 [INFO]: Epoch 108 - training loss: 40510.9938, validation loss: 0.2093
2024-05-25 03:44:56 [INFO]: Epoch 109 - training loss: 40536.8769, validation loss: 0.2102
2024-05-25 03:44:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:44:56 [INFO]: Finished training. The best model is from epoch#99.
2024-05-25 03:44:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/GPVAE_air_quality/20240525_T034422/GPVAE.pypots
2024-05-25 03:44:56 [INFO]: GP-VAE on Air-Quality: MAE=0.2727, MSE=0.2664
2024-05-25 03:44:56 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/GPVAE_air_quality/imputation.pkl
2024-05-25 03:44:56 [INFO]: Using the given device: cuda:0
2024-05-25 03:44:56 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/USGAN_air_quality/20240525_T034456
2024-05-25 03:44:56 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/USGAN_air_quality/20240525_T034456/tensorboard
2024-05-25 03:44:56 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 03:45:01 [INFO]: Epoch 001 - generator training loss: 0.3410, discriminator training loss: 0.5715, validation loss: 0.4977
2024-05-25 03:45:05 [INFO]: Epoch 002 - generator training loss: 0.0277, discriminator training loss: 0.5240, validation loss: 0.3726
2024-05-25 03:45:09 [INFO]: Epoch 003 - generator training loss: -0.0442, discriminator training loss: 0.5184, validation loss: 0.3053
2024-05-25 03:45:13 [INFO]: Epoch 004 - generator training loss: -0.0771, discriminator training loss: 0.5138, validation loss: 0.2665
2024-05-25 03:45:17 [INFO]: Epoch 005 - generator training loss: -0.1028, discriminator training loss: 0.5089, validation loss: 0.2392
2024-05-25 03:45:21 [INFO]: Epoch 006 - generator training loss: -0.1158, discriminator training loss: 0.5034, validation loss: 0.2211
2024-05-25 03:45:25 [INFO]: Epoch 007 - generator training loss: -0.1277, discriminator training loss: 0.4967, validation loss: 0.2072
2024-05-25 03:45:29 [INFO]: Epoch 008 - generator training loss: -0.1325, discriminator training loss: 0.4891, validation loss: 0.1979
2024-05-25 03:45:33 [INFO]: Epoch 009 - generator training loss: -0.1354, discriminator training loss: 0.4809, validation loss: 0.1901
2024-05-25 03:45:37 [INFO]: Epoch 010 - generator training loss: -0.1322, discriminator training loss: 0.4715, validation loss: 0.1839
2024-05-25 03:45:42 [INFO]: Epoch 011 - generator training loss: -0.1342, discriminator training loss: 0.4614, validation loss: 0.1787
2024-05-25 03:45:46 [INFO]: Epoch 012 - generator training loss: -0.1316, discriminator training loss: 0.4512, validation loss: 0.1734
2024-05-25 03:45:50 [INFO]: Epoch 013 - generator training loss: -0.1280, discriminator training loss: 0.4408, validation loss: 0.1688
2024-05-25 03:45:54 [INFO]: Epoch 014 - generator training loss: -0.1225, discriminator training loss: 0.4302, validation loss: 0.1660
2024-05-25 03:45:59 [INFO]: Epoch 015 - generator training loss: -0.1234, discriminator training loss: 0.4198, validation loss: 0.1619
2024-05-25 03:46:03 [INFO]: Epoch 016 - generator training loss: -0.1201, discriminator training loss: 0.4104, validation loss: 0.1592
2024-05-25 03:46:07 [INFO]: Epoch 017 - generator training loss: -0.1153, discriminator training loss: 0.4010, validation loss: 0.1570
2024-05-25 03:46:11 [INFO]: Epoch 018 - generator training loss: -0.1102, discriminator training loss: 0.3927, validation loss: 0.1547
2024-05-25 03:46:15 [INFO]: Epoch 019 - generator training loss: -0.1115, discriminator training loss: 0.3851, validation loss: 0.1518
2024-05-25 03:46:19 [INFO]: Epoch 020 - generator training loss: -0.1088, discriminator training loss: 0.3778, validation loss: 0.1492
2024-05-25 03:46:23 [INFO]: Epoch 021 - generator training loss: -0.1066, discriminator training loss: 0.3711, validation loss: 0.1479
2024-05-25 03:46:27 [INFO]: Epoch 022 - generator training loss: -0.1052, discriminator training loss: 0.3653, validation loss: 0.1449
2024-05-25 03:46:31 [INFO]: Epoch 023 - generator training loss: -0.1027, discriminator training loss: 0.3597, validation loss: 0.1437
2024-05-25 03:46:35 [INFO]: Epoch 024 - generator training loss: -0.1029, discriminator training loss: 0.3557, validation loss: 0.1419
2024-05-25 03:46:40 [INFO]: Epoch 025 - generator training loss: -0.1012, discriminator training loss: 0.3512, validation loss: 0.1403
2024-05-25 03:46:44 [INFO]: Epoch 026 - generator training loss: -0.1004, discriminator training loss: 0.3470, validation loss: 0.1388
2024-05-25 03:46:48 [INFO]: Epoch 027 - generator training loss: -0.0996, discriminator training loss: 0.3439, validation loss: 0.1373
2024-05-25 03:46:52 [INFO]: Epoch 028 - generator training loss: -0.0992, discriminator training loss: 0.3406, validation loss: 0.1354
2024-05-25 03:46:56 [INFO]: Epoch 029 - generator training loss: -0.0992, discriminator training loss: 0.3377, validation loss: 0.1343
2024-05-25 03:47:00 [INFO]: Epoch 030 - generator training loss: -0.0986, discriminator training loss: 0.3352, validation loss: 0.1324
2024-05-25 03:47:04 [INFO]: Epoch 031 - generator training loss: -0.0981, discriminator training loss: 0.3326, validation loss: 0.1314
2024-05-25 03:47:08 [INFO]: Epoch 032 - generator training loss: -0.0988, discriminator training loss: 0.3305, validation loss: 0.1297
2024-05-25 03:47:12 [INFO]: Epoch 033 - generator training loss: -0.0994, discriminator training loss: 0.3290, validation loss: 0.1292
2024-05-25 03:47:17 [INFO]: Epoch 034 - generator training loss: -0.0996, discriminator training loss: 0.3269, validation loss: 0.1278
2024-05-25 03:47:21 [INFO]: Epoch 035 - generator training loss: -0.0988, discriminator training loss: 0.3259, validation loss: 0.1271
2024-05-25 03:47:25 [INFO]: Epoch 036 - generator training loss: -0.0994, discriminator training loss: 0.3239, validation loss: 0.1266
2024-05-25 03:47:29 [INFO]: Epoch 037 - generator training loss: -0.1005, discriminator training loss: 0.3220, validation loss: 0.1249
2024-05-25 03:47:33 [INFO]: Epoch 038 - generator training loss: -0.1003, discriminator training loss: 0.3210, validation loss: 0.1239
2024-05-25 03:47:37 [INFO]: Epoch 039 - generator training loss: -0.0987, discriminator training loss: 0.3199, validation loss: 0.1232
2024-05-25 03:47:41 [INFO]: Epoch 040 - generator training loss: -0.1001, discriminator training loss: 0.3187, validation loss: 0.1222
2024-05-25 03:47:45 [INFO]: Epoch 041 - generator training loss: -0.1002, discriminator training loss: 0.3179, validation loss: 0.1219
2024-05-25 03:47:49 [INFO]: Epoch 042 - generator training loss: -0.1009, discriminator training loss: 0.3172, validation loss: 0.1213
2024-05-25 03:47:53 [INFO]: Epoch 043 - generator training loss: -0.1011, discriminator training loss: 0.3161, validation loss: 0.1207
2024-05-25 03:47:57 [INFO]: Epoch 044 - generator training loss: -0.1018, discriminator training loss: 0.3154, validation loss: 0.1194
2024-05-25 03:48:01 [INFO]: Epoch 045 - generator training loss: -0.1016, discriminator training loss: 0.3142, validation loss: 0.1190
2024-05-25 03:48:06 [INFO]: Epoch 046 - generator training loss: -0.1020, discriminator training loss: 0.3147, validation loss: 0.1182
2024-05-25 03:48:10 [INFO]: Epoch 047 - generator training loss: -0.1025, discriminator training loss: 0.3135, validation loss: 0.1177
2024-05-25 03:48:14 [INFO]: Epoch 048 - generator training loss: -0.1029, discriminator training loss: 0.3127, validation loss: 0.1175
2024-05-25 03:48:18 [INFO]: Epoch 049 - generator training loss: -0.1033, discriminator training loss: 0.3126, validation loss: 0.1169
2024-05-25 03:48:22 [INFO]: Epoch 050 - generator training loss: -0.1048, discriminator training loss: 0.3116, validation loss: 0.1163
2024-05-25 03:48:26 [INFO]: Epoch 051 - generator training loss: -0.1036, discriminator training loss: 0.3112, validation loss: 0.1162
2024-05-25 03:48:30 [INFO]: Epoch 052 - generator training loss: -0.1054, discriminator training loss: 0.3111, validation loss: 0.1153
2024-05-25 03:48:34 [INFO]: Epoch 053 - generator training loss: -0.1029, discriminator training loss: 0.3105, validation loss: 0.1148
2024-05-25 03:48:38 [INFO]: Epoch 054 - generator training loss: -0.1038, discriminator training loss: 0.3105, validation loss: 0.1151
2024-05-25 03:48:42 [INFO]: Epoch 055 - generator training loss: -0.1042, discriminator training loss: 0.3098, validation loss: 0.1141
2024-05-25 03:48:46 [INFO]: Epoch 056 - generator training loss: -0.1060, discriminator training loss: 0.3095, validation loss: 0.1137
2024-05-25 03:48:51 [INFO]: Epoch 057 - generator training loss: -0.1080, discriminator training loss: 0.3090, validation loss: 0.1137
2024-05-25 03:48:55 [INFO]: Epoch 058 - generator training loss: -0.1073, discriminator training loss: 0.3085, validation loss: 0.1126
2024-05-25 03:48:59 [INFO]: Epoch 059 - generator training loss: -0.1068, discriminator training loss: 0.3082, validation loss: 0.1126
2024-05-25 03:49:03 [INFO]: Epoch 060 - generator training loss: -0.1076, discriminator training loss: 0.3082, validation loss: 0.1117
2024-05-25 03:49:07 [INFO]: Epoch 061 - generator training loss: -0.1081, discriminator training loss: 0.3084, validation loss: 0.1117
2024-05-25 03:49:11 [INFO]: Epoch 062 - generator training loss: -0.1094, discriminator training loss: 0.3070, validation loss: 0.1114
2024-05-25 03:49:15 [INFO]: Epoch 063 - generator training loss: -0.1091, discriminator training loss: 0.3076, validation loss: 0.1112
2024-05-25 03:49:19 [INFO]: Epoch 064 - generator training loss: -0.1095, discriminator training loss: 0.3070, validation loss: 0.1113
2024-05-25 03:49:23 [INFO]: Epoch 065 - generator training loss: -0.1102, discriminator training loss: 0.3074, validation loss: 0.1111
2024-05-25 03:49:27 [INFO]: Epoch 066 - generator training loss: -0.1097, discriminator training loss: 0.3062, validation loss: 0.1104
2024-05-25 03:49:31 [INFO]: Epoch 067 - generator training loss: -0.1106, discriminator training loss: 0.3061, validation loss: 0.1102
2024-05-25 03:49:35 [INFO]: Epoch 068 - generator training loss: -0.1107, discriminator training loss: 0.3063, validation loss: 0.1100
2024-05-25 03:49:39 [INFO]: Epoch 069 - generator training loss: -0.1101, discriminator training loss: 0.3063, validation loss: 0.1098
2024-05-25 03:49:44 [INFO]: Epoch 070 - generator training loss: -0.1101, discriminator training loss: 0.3060, validation loss: 0.1098
2024-05-25 03:49:48 [INFO]: Epoch 071 - generator training loss: -0.1120, discriminator training loss: 0.3047, validation loss: 0.1094
2024-05-25 03:49:52 [INFO]: Epoch 072 - generator training loss: -0.1119, discriminator training loss: 0.3055, validation loss: 0.1094
2024-05-25 03:49:56 [INFO]: Epoch 073 - generator training loss: -0.1128, discriminator training loss: 0.3048, validation loss: 0.1097
2024-05-25 03:50:00 [INFO]: Epoch 074 - generator training loss: -0.1122, discriminator training loss: 0.3050, validation loss: 0.1086
2024-05-25 03:50:04 [INFO]: Epoch 075 - generator training loss: -0.1129, discriminator training loss: 0.3050, validation loss: 0.1088
2024-05-25 03:50:08 [INFO]: Epoch 076 - generator training loss: -0.1113, discriminator training loss: 0.3046, validation loss: 0.1083
2024-05-25 03:50:12 [INFO]: Epoch 077 - generator training loss: -0.1140, discriminator training loss: 0.3046, validation loss: 0.1085
2024-05-25 03:50:16 [INFO]: Epoch 078 - generator training loss: -0.1126, discriminator training loss: 0.3045, validation loss: 0.1086
2024-05-25 03:50:20 [INFO]: Epoch 079 - generator training loss: -0.1130, discriminator training loss: 0.3042, validation loss: 0.1083
2024-05-25 03:50:24 [INFO]: Epoch 080 - generator training loss: -0.1146, discriminator training loss: 0.3039, validation loss: 0.1079
2024-05-25 03:50:29 [INFO]: Epoch 081 - generator training loss: -0.1142, discriminator training loss: 0.3043, validation loss: 0.1079
2024-05-25 03:50:33 [INFO]: Epoch 082 - generator training loss: -0.1151, discriminator training loss: 0.3037, validation loss: 0.1075
2024-05-25 03:50:37 [INFO]: Epoch 083 - generator training loss: -0.1155, discriminator training loss: 0.3036, validation loss: 0.1076
2024-05-25 03:50:41 [INFO]: Epoch 084 - generator training loss: -0.1155, discriminator training loss: 0.3032, validation loss: 0.1075
2024-05-25 03:50:45 [INFO]: Epoch 085 - generator training loss: -0.1151, discriminator training loss: 0.3034, validation loss: 0.1077
2024-05-25 03:50:49 [INFO]: Epoch 086 - generator training loss: -0.1156, discriminator training loss: 0.3029, validation loss: 0.1071
2024-05-25 03:50:53 [INFO]: Epoch 087 - generator training loss: -0.1157, discriminator training loss: 0.3035, validation loss: 0.1070
2024-05-25 03:50:57 [INFO]: Epoch 088 - generator training loss: -0.1145, discriminator training loss: 0.3033, validation loss: 0.1067
2024-05-25 03:51:01 [INFO]: Epoch 089 - generator training loss: -0.1160, discriminator training loss: 0.3028, validation loss: 0.1070
2024-05-25 03:51:05 [INFO]: Epoch 090 - generator training loss: -0.1165, discriminator training loss: 0.3024, validation loss: 0.1065
2024-05-25 03:51:09 [INFO]: Epoch 091 - generator training loss: -0.1171, discriminator training loss: 0.3028, validation loss: 0.1069
2024-05-25 03:51:13 [INFO]: Epoch 092 - generator training loss: -0.1172, discriminator training loss: 0.3022, validation loss: 0.1061
2024-05-25 03:51:17 [INFO]: Epoch 093 - generator training loss: -0.1185, discriminator training loss: 0.3020, validation loss: 0.1062
2024-05-25 03:51:22 [INFO]: Epoch 094 - generator training loss: -0.1171, discriminator training loss: 0.3015, validation loss: 0.1064
2024-05-25 03:51:26 [INFO]: Epoch 095 - generator training loss: -0.1170, discriminator training loss: 0.3022, validation loss: 0.1064
2024-05-25 03:51:30 [INFO]: Epoch 096 - generator training loss: -0.1190, discriminator training loss: 0.3018, validation loss: 0.1062
2024-05-25 03:51:34 [INFO]: Epoch 097 - generator training loss: -0.1177, discriminator training loss: 0.3013, validation loss: 0.1060
2024-05-25 03:51:38 [INFO]: Epoch 098 - generator training loss: -0.1184, discriminator training loss: 0.3020, validation loss: 0.1058
2024-05-25 03:51:42 [INFO]: Epoch 099 - generator training loss: -0.1196, discriminator training loss: 0.3014, validation loss: 0.1061
2024-05-25 03:51:46 [INFO]: Epoch 100 - generator training loss: -0.1189, discriminator training loss: 0.3018, validation loss: 0.1061
2024-05-25 03:51:50 [INFO]: Epoch 101 - generator training loss: -0.1193, discriminator training loss: 0.3011, validation loss: 0.1057
2024-05-25 03:51:54 [INFO]: Epoch 102 - generator training loss: -0.1199, discriminator training loss: 0.3008, validation loss: 0.1058
2024-05-25 03:51:58 [INFO]: Epoch 103 - generator training loss: -0.1199, discriminator training loss: 0.3010, validation loss: 0.1060
2024-05-25 03:52:02 [INFO]: Epoch 104 - generator training loss: -0.1205, discriminator training loss: 0.3009, validation loss: 0.1053
2024-05-25 03:52:06 [INFO]: Epoch 105 - generator training loss: -0.1203, discriminator training loss: 0.3004, validation loss: 0.1057
2024-05-25 03:52:11 [INFO]: Epoch 106 - generator training loss: -0.1207, discriminator training loss: 0.3009, validation loss: 0.1058
2024-05-25 03:52:15 [INFO]: Epoch 107 - generator training loss: -0.1197, discriminator training loss: 0.3010, validation loss: 0.1056
2024-05-25 03:52:19 [INFO]: Epoch 108 - generator training loss: -0.1208, discriminator training loss: 0.3000, validation loss: 0.1048
2024-05-25 03:52:23 [INFO]: Epoch 109 - generator training loss: -0.1201, discriminator training loss: 0.3002, validation loss: 0.1056
2024-05-25 03:52:27 [INFO]: Epoch 110 - generator training loss: -0.1207, discriminator training loss: 0.2999, validation loss: 0.1052
2024-05-25 03:52:31 [INFO]: Epoch 111 - generator training loss: -0.1216, discriminator training loss: 0.3003, validation loss: 0.1051
2024-05-25 03:52:35 [INFO]: Epoch 112 - generator training loss: -0.1219, discriminator training loss: 0.2999, validation loss: 0.1052
2024-05-25 03:52:39 [INFO]: Epoch 113 - generator training loss: -0.1222, discriminator training loss: 0.2998, validation loss: 0.1057
2024-05-25 03:52:43 [INFO]: Epoch 114 - generator training loss: -0.1209, discriminator training loss: 0.2999, validation loss: 0.1052
2024-05-25 03:52:47 [INFO]: Epoch 115 - generator training loss: -0.1213, discriminator training loss: 0.2994, validation loss: 0.1051
2024-05-25 03:52:51 [INFO]: Epoch 116 - generator training loss: -0.1222, discriminator training loss: 0.2998, validation loss: 0.1058
2024-05-25 03:52:55 [INFO]: Epoch 117 - generator training loss: -0.1221, discriminator training loss: 0.2994, validation loss: 0.1056
2024-05-25 03:53:00 [INFO]: Epoch 118 - generator training loss: -0.1235, discriminator training loss: 0.2990, validation loss: 0.1052
2024-05-25 03:53:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:53:00 [INFO]: Finished training. The best model is from epoch#108.
2024-05-25 03:53:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/USGAN_air_quality/20240525_T034456/USGAN.pypots
2024-05-25 03:53:00 [INFO]: US-GAN on Air-Quality: MAE=0.1685, MSE=0.1422
2024-05-25 03:53:00 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/USGAN_air_quality/imputation.pkl
2024-05-25 03:53:00 [INFO]: Using the given device: cuda:0
2024-05-25 03:53:00 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/BRITS_air_quality/20240525_T035300
2024-05-25 03:53:00 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/BRITS_air_quality/20240525_T035300/tensorboard
2024-05-25 03:53:00 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 03:53:04 [INFO]: Epoch 001 - training loss: 1.4210, validation loss: 0.9562
2024-05-25 03:53:07 [INFO]: Epoch 002 - training loss: 1.1602, validation loss: 0.6928
2024-05-25 03:53:09 [INFO]: Epoch 003 - training loss: 0.9659, validation loss: 0.5817
2024-05-25 03:53:12 [INFO]: Epoch 004 - training loss: 0.8565, validation loss: 0.5121
2024-05-25 03:53:15 [INFO]: Epoch 005 - training loss: 0.7865, validation loss: 0.4668
2024-05-25 03:53:18 [INFO]: Epoch 006 - training loss: 0.7324, validation loss: 0.4299
2024-05-25 03:53:20 [INFO]: Epoch 007 - training loss: 0.6906, validation loss: 0.4001
2024-05-25 03:53:23 [INFO]: Epoch 008 - training loss: 0.6550, validation loss: 0.3751
2024-05-25 03:53:26 [INFO]: Epoch 009 - training loss: 0.6292, validation loss: 0.3551
2024-05-25 03:53:29 [INFO]: Epoch 010 - training loss: 0.6050, validation loss: 0.3390
2024-05-25 03:53:31 [INFO]: Epoch 011 - training loss: 0.5869, validation loss: 0.3254
2024-05-25 03:53:34 [INFO]: Epoch 012 - training loss: 0.5724, validation loss: 0.3131
2024-05-25 03:53:37 [INFO]: Epoch 013 - training loss: 0.5582, validation loss: 0.3023
2024-05-25 03:53:40 [INFO]: Epoch 014 - training loss: 0.5460, validation loss: 0.2935
2024-05-25 03:53:42 [INFO]: Epoch 015 - training loss: 0.5356, validation loss: 0.2857
2024-05-25 03:53:45 [INFO]: Epoch 016 - training loss: 0.5239, validation loss: 0.2783
2024-05-25 03:53:48 [INFO]: Epoch 017 - training loss: 0.5154, validation loss: 0.2718
2024-05-25 03:53:51 [INFO]: Epoch 018 - training loss: 0.5070, validation loss: 0.2659
2024-05-25 03:53:53 [INFO]: Epoch 019 - training loss: 0.4984, validation loss: 0.2604
2024-05-25 03:53:56 [INFO]: Epoch 020 - training loss: 0.4899, validation loss: 0.2555
2024-05-25 03:53:59 [INFO]: Epoch 021 - training loss: 0.4846, validation loss: 0.2507
2024-05-25 03:54:02 [INFO]: Epoch 022 - training loss: 0.4759, validation loss: 0.2458
2024-05-25 03:54:04 [INFO]: Epoch 023 - training loss: 0.4707, validation loss: 0.2418
2024-05-25 03:54:07 [INFO]: Epoch 024 - training loss: 0.4637, validation loss: 0.2378
2024-05-25 03:54:10 [INFO]: Epoch 025 - training loss: 0.4578, validation loss: 0.2338
2024-05-25 03:54:13 [INFO]: Epoch 026 - training loss: 0.4527, validation loss: 0.2305
2024-05-25 03:54:15 [INFO]: Epoch 027 - training loss: 0.4461, validation loss: 0.2270
2024-05-25 03:54:18 [INFO]: Epoch 028 - training loss: 0.4413, validation loss: 0.2238
2024-05-25 03:54:21 [INFO]: Epoch 029 - training loss: 0.4366, validation loss: 0.2201
2024-05-25 03:54:24 [INFO]: Epoch 030 - training loss: 0.4320, validation loss: 0.2173
2024-05-25 03:54:26 [INFO]: Epoch 031 - training loss: 0.4261, validation loss: 0.2143
2024-05-25 03:54:29 [INFO]: Epoch 032 - training loss: 0.4220, validation loss: 0.2114
2024-05-25 03:54:32 [INFO]: Epoch 033 - training loss: 0.4176, validation loss: 0.2092
2024-05-25 03:54:35 [INFO]: Epoch 034 - training loss: 0.4144, validation loss: 0.2061
2024-05-25 03:54:38 [INFO]: Epoch 035 - training loss: 0.4100, validation loss: 0.2037
2024-05-25 03:54:40 [INFO]: Epoch 036 - training loss: 0.4055, validation loss: 0.2014
2024-05-25 03:54:43 [INFO]: Epoch 037 - training loss: 0.4020, validation loss: 0.1986
2024-05-25 03:54:46 [INFO]: Epoch 038 - training loss: 0.4005, validation loss: 0.1964
2024-05-25 03:54:49 [INFO]: Epoch 039 - training loss: 0.3962, validation loss: 0.1942
2024-05-25 03:54:51 [INFO]: Epoch 040 - training loss: 0.3920, validation loss: 0.1922
2024-05-25 03:54:54 [INFO]: Epoch 041 - training loss: 0.3893, validation loss: 0.1901
2024-05-25 03:54:57 [INFO]: Epoch 042 - training loss: 0.3868, validation loss: 0.1880
2024-05-25 03:55:00 [INFO]: Epoch 043 - training loss: 0.3836, validation loss: 0.1860
2024-05-25 03:55:02 [INFO]: Epoch 044 - training loss: 0.3802, validation loss: 0.1839
2024-05-25 03:55:05 [INFO]: Epoch 045 - training loss: 0.3774, validation loss: 0.1821
2024-05-25 03:55:08 [INFO]: Epoch 046 - training loss: 0.3753, validation loss: 0.1803
2024-05-25 03:55:11 [INFO]: Epoch 047 - training loss: 0.3731, validation loss: 0.1786
2024-05-25 03:55:13 [INFO]: Epoch 048 - training loss: 0.3703, validation loss: 0.1770
2024-05-25 03:55:16 [INFO]: Epoch 049 - training loss: 0.3667, validation loss: 0.1751
2024-05-25 03:55:19 [INFO]: Epoch 050 - training loss: 0.3649, validation loss: 0.1735
2024-05-25 03:55:22 [INFO]: Epoch 051 - training loss: 0.3624, validation loss: 0.1724
2024-05-25 03:55:24 [INFO]: Epoch 052 - training loss: 0.3603, validation loss: 0.1706
2024-05-25 03:55:27 [INFO]: Epoch 053 - training loss: 0.3589, validation loss: 0.1691
2024-05-25 03:55:30 [INFO]: Epoch 054 - training loss: 0.3565, validation loss: 0.1678
2024-05-25 03:55:33 [INFO]: Epoch 055 - training loss: 0.3550, validation loss: 0.1663
2024-05-25 03:55:35 [INFO]: Epoch 056 - training loss: 0.3525, validation loss: 0.1653
2024-05-25 03:55:38 [INFO]: Epoch 057 - training loss: 0.3502, validation loss: 0.1639
2024-05-25 03:55:41 [INFO]: Epoch 058 - training loss: 0.3494, validation loss: 0.1628
2024-05-25 03:55:44 [INFO]: Epoch 059 - training loss: 0.3469, validation loss: 0.1619
2024-05-25 03:55:46 [INFO]: Epoch 060 - training loss: 0.3453, validation loss: 0.1604
2024-05-25 03:55:49 [INFO]: Epoch 061 - training loss: 0.3436, validation loss: 0.1596
2024-05-25 03:55:52 [INFO]: Epoch 062 - training loss: 0.3433, validation loss: 0.1584
2024-05-25 03:55:55 [INFO]: Epoch 063 - training loss: 0.3410, validation loss: 0.1575
2024-05-25 03:55:57 [INFO]: Epoch 064 - training loss: 0.3403, validation loss: 0.1568
2024-05-25 03:56:00 [INFO]: Epoch 065 - training loss: 0.3376, validation loss: 0.1558
2024-05-25 03:56:03 [INFO]: Epoch 066 - training loss: 0.3357, validation loss: 0.1550
2024-05-25 03:56:06 [INFO]: Epoch 067 - training loss: 0.3348, validation loss: 0.1542
2024-05-25 03:56:08 [INFO]: Epoch 068 - training loss: 0.3336, validation loss: 0.1534
2024-05-25 03:56:11 [INFO]: Epoch 069 - training loss: 0.3326, validation loss: 0.1527
2024-05-25 03:56:14 [INFO]: Epoch 070 - training loss: 0.3317, validation loss: 0.1520
2024-05-25 03:56:17 [INFO]: Epoch 071 - training loss: 0.3302, validation loss: 0.1514
2024-05-25 03:56:19 [INFO]: Epoch 072 - training loss: 0.3289, validation loss: 0.1506
2024-05-25 03:56:22 [INFO]: Epoch 073 - training loss: 0.3281, validation loss: 0.1500
2024-05-25 03:56:25 [INFO]: Epoch 074 - training loss: 0.3266, validation loss: 0.1497
2024-05-25 03:56:28 [INFO]: Epoch 075 - training loss: 0.3252, validation loss: 0.1490
2024-05-25 03:56:30 [INFO]: Epoch 076 - training loss: 0.3241, validation loss: 0.1484
2024-05-25 03:56:33 [INFO]: Epoch 077 - training loss: 0.3225, validation loss: 0.1476
2024-05-25 03:56:36 [INFO]: Epoch 078 - training loss: 0.3219, validation loss: 0.1472
2024-05-25 03:56:39 [INFO]: Epoch 079 - training loss: 0.3215, validation loss: 0.1467
2024-05-25 03:56:41 [INFO]: Epoch 080 - training loss: 0.3201, validation loss: 0.1461
2024-05-25 03:56:44 [INFO]: Epoch 081 - training loss: 0.3190, validation loss: 0.1456
2024-05-25 03:56:47 [INFO]: Epoch 082 - training loss: 0.3181, validation loss: 0.1451
2024-05-25 03:56:50 [INFO]: Epoch 083 - training loss: 0.3174, validation loss: 0.1447
2024-05-25 03:56:52 [INFO]: Epoch 084 - training loss: 0.3167, validation loss: 0.1442
2024-05-25 03:56:55 [INFO]: Epoch 085 - training loss: 0.3163, validation loss: 0.1439
2024-05-25 03:56:58 [INFO]: Epoch 086 - training loss: 0.3146, validation loss: 0.1433
2024-05-25 03:57:01 [INFO]: Epoch 087 - training loss: 0.3147, validation loss: 0.1430
2024-05-25 03:57:04 [INFO]: Epoch 088 - training loss: 0.3137, validation loss: 0.1424
2024-05-25 03:57:06 [INFO]: Epoch 089 - training loss: 0.3127, validation loss: 0.1420
2024-05-25 03:57:09 [INFO]: Epoch 090 - training loss: 0.3114, validation loss: 0.1417
2024-05-25 03:57:12 [INFO]: Epoch 091 - training loss: 0.3104, validation loss: 0.1412
2024-05-25 03:57:15 [INFO]: Epoch 092 - training loss: 0.3108, validation loss: 0.1409
2024-05-25 03:57:17 [INFO]: Epoch 093 - training loss: 0.3087, validation loss: 0.1406
2024-05-25 03:57:20 [INFO]: Epoch 094 - training loss: 0.3091, validation loss: 0.1402
2024-05-25 03:57:23 [INFO]: Epoch 095 - training loss: 0.3079, validation loss: 0.1399
2024-05-25 03:57:26 [INFO]: Epoch 096 - training loss: 0.3076, validation loss: 0.1394
2024-05-25 03:57:28 [INFO]: Epoch 097 - training loss: 0.3074, validation loss: 0.1391
2024-05-25 03:57:31 [INFO]: Epoch 098 - training loss: 0.3057, validation loss: 0.1389
2024-05-25 03:57:34 [INFO]: Epoch 099 - training loss: 0.3052, validation loss: 0.1386
2024-05-25 03:57:37 [INFO]: Epoch 100 - training loss: 0.3044, validation loss: 0.1380
2024-05-25 03:57:39 [INFO]: Epoch 101 - training loss: 0.3046, validation loss: 0.1380
2024-05-25 03:57:42 [INFO]: Epoch 102 - training loss: 0.3033, validation loss: 0.1375
2024-05-25 03:57:45 [INFO]: Epoch 103 - training loss: 0.3030, validation loss: 0.1372
2024-05-25 03:57:48 [INFO]: Epoch 104 - training loss: 0.3024, validation loss: 0.1370
2024-05-25 03:57:50 [INFO]: Epoch 105 - training loss: 0.3019, validation loss: 0.1367
2024-05-25 03:57:53 [INFO]: Epoch 106 - training loss: 0.3016, validation loss: 0.1364
2024-05-25 03:57:56 [INFO]: Epoch 107 - training loss: 0.3003, validation loss: 0.1362
2024-05-25 03:57:59 [INFO]: Epoch 108 - training loss: 0.3001, validation loss: 0.1358
2024-05-25 03:58:01 [INFO]: Epoch 109 - training loss: 0.3000, validation loss: 0.1355
2024-05-25 03:58:04 [INFO]: Epoch 110 - training loss: 0.2991, validation loss: 0.1353
2024-05-25 03:58:07 [INFO]: Epoch 111 - training loss: 0.2986, validation loss: 0.1349
2024-05-25 03:58:10 [INFO]: Epoch 112 - training loss: 0.2979, validation loss: 0.1347
2024-05-25 03:58:12 [INFO]: Epoch 113 - training loss: 0.2972, validation loss: 0.1345
2024-05-25 03:58:15 [INFO]: Epoch 114 - training loss: 0.2963, validation loss: 0.1340
2024-05-25 03:58:18 [INFO]: Epoch 115 - training loss: 0.2967, validation loss: 0.1338
2024-05-25 03:58:21 [INFO]: Epoch 116 - training loss: 0.2959, validation loss: 0.1335
2024-05-25 03:58:23 [INFO]: Epoch 117 - training loss: 0.2947, validation loss: 0.1333
2024-05-25 03:58:26 [INFO]: Epoch 118 - training loss: 0.2947, validation loss: 0.1330
2024-05-25 03:58:29 [INFO]: Epoch 119 - training loss: 0.2941, validation loss: 0.1327
2024-05-25 03:58:32 [INFO]: Epoch 120 - training loss: 0.2942, validation loss: 0.1326
2024-05-25 03:58:34 [INFO]: Epoch 121 - training loss: 0.2931, validation loss: 0.1321
2024-05-25 03:58:37 [INFO]: Epoch 122 - training loss: 0.2934, validation loss: 0.1318
2024-05-25 03:58:40 [INFO]: Epoch 123 - training loss: 0.2925, validation loss: 0.1317
2024-05-25 03:58:43 [INFO]: Epoch 124 - training loss: 0.2918, validation loss: 0.1316
2024-05-25 03:58:45 [INFO]: Epoch 125 - training loss: 0.2913, validation loss: 0.1313
2024-05-25 03:58:48 [INFO]: Epoch 126 - training loss: 0.2907, validation loss: 0.1310
2024-05-25 03:58:51 [INFO]: Epoch 127 - training loss: 0.2912, validation loss: 0.1306
2024-05-25 03:58:54 [INFO]: Epoch 128 - training loss: 0.2900, validation loss: 0.1304
2024-05-25 03:58:57 [INFO]: Epoch 129 - training loss: 0.2891, validation loss: 0.1301
2024-05-25 03:58:59 [INFO]: Epoch 130 - training loss: 0.2889, validation loss: 0.1298
2024-05-25 03:59:02 [INFO]: Epoch 131 - training loss: 0.2888, validation loss: 0.1295
2024-05-25 03:59:05 [INFO]: Epoch 132 - training loss: 0.2884, validation loss: 0.1294
2024-05-25 03:59:08 [INFO]: Epoch 133 - training loss: 0.2882, validation loss: 0.1293
2024-05-25 03:59:10 [INFO]: Epoch 134 - training loss: 0.2876, validation loss: 0.1289
2024-05-25 03:59:13 [INFO]: Epoch 135 - training loss: 0.2870, validation loss: 0.1287
2024-05-25 03:59:16 [INFO]: Epoch 136 - training loss: 0.2867, validation loss: 0.1285
2024-05-25 03:59:19 [INFO]: Epoch 137 - training loss: 0.2870, validation loss: 0.1284
2024-05-25 03:59:21 [INFO]: Epoch 138 - training loss: 0.2862, validation loss: 0.1281
2024-05-25 03:59:24 [INFO]: Epoch 139 - training loss: 0.2861, validation loss: 0.1278
2024-05-25 03:59:27 [INFO]: Epoch 140 - training loss: 0.2855, validation loss: 0.1275
2024-05-25 03:59:30 [INFO]: Epoch 141 - training loss: 0.2849, validation loss: 0.1272
2024-05-25 03:59:32 [INFO]: Epoch 142 - training loss: 0.2845, validation loss: 0.1272
2024-05-25 03:59:35 [INFO]: Epoch 143 - training loss: 0.2838, validation loss: 0.1267
2024-05-25 03:59:38 [INFO]: Epoch 144 - training loss: 0.2837, validation loss: 0.1268
2024-05-25 03:59:41 [INFO]: Epoch 145 - training loss: 0.2830, validation loss: 0.1267
2024-05-25 03:59:43 [INFO]: Epoch 146 - training loss: 0.2828, validation loss: 0.1264
2024-05-25 03:59:46 [INFO]: Epoch 147 - training loss: 0.2830, validation loss: 0.1261
2024-05-25 03:59:49 [INFO]: Epoch 148 - training loss: 0.2832, validation loss: 0.1261
2024-05-25 03:59:52 [INFO]: Epoch 149 - training loss: 0.2822, validation loss: 0.1255
2024-05-25 03:59:54 [INFO]: Epoch 150 - training loss: 0.2816, validation loss: 0.1257
2024-05-25 03:59:57 [INFO]: Epoch 151 - training loss: 0.2810, validation loss: 0.1252
2024-05-25 04:00:00 [INFO]: Epoch 152 - training loss: 0.2809, validation loss: 0.1250
2024-05-25 04:00:03 [INFO]: Epoch 153 - training loss: 0.2804, validation loss: 0.1248
2024-05-25 04:00:05 [INFO]: Epoch 154 - training loss: 0.2806, validation loss: 0.1247
2024-05-25 04:00:08 [INFO]: Epoch 155 - training loss: 0.2803, validation loss: 0.1246
2024-05-25 04:00:11 [INFO]: Epoch 156 - training loss: 0.2792, validation loss: 0.1244
2024-05-25 04:00:14 [INFO]: Epoch 157 - training loss: 0.2796, validation loss: 0.1242
2024-05-25 04:00:16 [INFO]: Epoch 158 - training loss: 0.2792, validation loss: 0.1240
2024-05-25 04:00:19 [INFO]: Epoch 159 - training loss: 0.2789, validation loss: 0.1236
2024-05-25 04:00:22 [INFO]: Epoch 160 - training loss: 0.2781, validation loss: 0.1236
2024-05-25 04:00:25 [INFO]: Epoch 161 - training loss: 0.2781, validation loss: 0.1235
2024-05-25 04:00:27 [INFO]: Epoch 162 - training loss: 0.2781, validation loss: 0.1232
2024-05-25 04:00:30 [INFO]: Epoch 163 - training loss: 0.2780, validation loss: 0.1229
2024-05-25 04:00:33 [INFO]: Epoch 164 - training loss: 0.2770, validation loss: 0.1231
2024-05-25 04:00:36 [INFO]: Epoch 165 - training loss: 0.2770, validation loss: 0.1226
2024-05-25 04:00:38 [INFO]: Epoch 166 - training loss: 0.2770, validation loss: 0.1225
2024-05-25 04:00:41 [INFO]: Epoch 167 - training loss: 0.2768, validation loss: 0.1224
2024-05-25 04:00:44 [INFO]: Epoch 168 - training loss: 0.2762, validation loss: 0.1222
2024-05-25 04:00:47 [INFO]: Epoch 169 - training loss: 0.2763, validation loss: 0.1221
2024-05-25 04:00:50 [INFO]: Epoch 170 - training loss: 0.2760, validation loss: 0.1219
2024-05-25 04:00:52 [INFO]: Epoch 171 - training loss: 0.2753, validation loss: 0.1218
2024-05-25 04:00:55 [INFO]: Epoch 172 - training loss: 0.2748, validation loss: 0.1217
2024-05-25 04:00:58 [INFO]: Epoch 173 - training loss: 0.2745, validation loss: 0.1215
2024-05-25 04:01:01 [INFO]: Epoch 174 - training loss: 0.2744, validation loss: 0.1212
2024-05-25 04:01:03 [INFO]: Epoch 175 - training loss: 0.2744, validation loss: 0.1211
2024-05-25 04:01:06 [INFO]: Epoch 176 - training loss: 0.2741, validation loss: 0.1210
2024-05-25 04:01:09 [INFO]: Epoch 177 - training loss: 0.2738, validation loss: 0.1209
2024-05-25 04:01:12 [INFO]: Epoch 178 - training loss: 0.2737, validation loss: 0.1209
2024-05-25 04:01:14 [INFO]: Epoch 179 - training loss: 0.2730, validation loss: 0.1206
2024-05-25 04:01:17 [INFO]: Epoch 180 - training loss: 0.2733, validation loss: 0.1205
2024-05-25 04:01:20 [INFO]: Epoch 181 - training loss: 0.2729, validation loss: 0.1202
2024-05-25 04:01:23 [INFO]: Epoch 182 - training loss: 0.2724, validation loss: 0.1203
2024-05-25 04:01:25 [INFO]: Epoch 183 - training loss: 0.2720, validation loss: 0.1200
2024-05-25 04:01:28 [INFO]: Epoch 184 - training loss: 0.2719, validation loss: 0.1200
2024-05-25 04:01:31 [INFO]: Epoch 185 - training loss: 0.2719, validation loss: 0.1199
2024-05-25 04:01:34 [INFO]: Epoch 186 - training loss: 0.2721, validation loss: 0.1197
2024-05-25 04:01:36 [INFO]: Epoch 187 - training loss: 0.2709, validation loss: 0.1194
2024-05-25 04:01:39 [INFO]: Epoch 188 - training loss: 0.2711, validation loss: 0.1195
2024-05-25 04:01:42 [INFO]: Epoch 189 - training loss: 0.2711, validation loss: 0.1192
2024-05-25 04:01:45 [INFO]: Epoch 190 - training loss: 0.2702, validation loss: 0.1191
2024-05-25 04:01:47 [INFO]: Epoch 191 - training loss: 0.2700, validation loss: 0.1190
2024-05-25 04:01:50 [INFO]: Epoch 192 - training loss: 0.2706, validation loss: 0.1186
2024-05-25 04:01:53 [INFO]: Epoch 193 - training loss: 0.2696, validation loss: 0.1186
2024-05-25 04:01:56 [INFO]: Epoch 194 - training loss: 0.2697, validation loss: 0.1184
2024-05-25 04:01:58 [INFO]: Epoch 195 - training loss: 0.2692, validation loss: 0.1185
2024-05-25 04:02:01 [INFO]: Epoch 196 - training loss: 0.2690, validation loss: 0.1184
2024-05-25 04:02:04 [INFO]: Epoch 197 - training loss: 0.2691, validation loss: 0.1181
2024-05-25 04:02:07 [INFO]: Epoch 198 - training loss: 0.2685, validation loss: 0.1180
2024-05-25 04:02:09 [INFO]: Epoch 199 - training loss: 0.2686, validation loss: 0.1181
2024-05-25 04:02:12 [INFO]: Epoch 200 - training loss: 0.2682, validation loss: 0.1179
2024-05-25 04:02:15 [INFO]: Epoch 201 - training loss: 0.2679, validation loss: 0.1177
2024-05-25 04:02:18 [INFO]: Epoch 202 - training loss: 0.2683, validation loss: 0.1175
2024-05-25 04:02:20 [INFO]: Epoch 203 - training loss: 0.2675, validation loss: 0.1173
2024-05-25 04:02:23 [INFO]: Epoch 204 - training loss: 0.2680, validation loss: 0.1171
2024-05-25 04:02:26 [INFO]: Epoch 205 - training loss: 0.2670, validation loss: 0.1172
2024-05-25 04:02:29 [INFO]: Epoch 206 - training loss: 0.2669, validation loss: 0.1171
2024-05-25 04:02:31 [INFO]: Epoch 207 - training loss: 0.2671, validation loss: 0.1168
2024-05-25 04:02:34 [INFO]: Epoch 208 - training loss: 0.2664, validation loss: 0.1169
2024-05-25 04:02:37 [INFO]: Epoch 209 - training loss: 0.2667, validation loss: 0.1167
2024-05-25 04:02:40 [INFO]: Epoch 210 - training loss: 0.2667, validation loss: 0.1165
2024-05-25 04:02:42 [INFO]: Epoch 211 - training loss: 0.2660, validation loss: 0.1167
2024-05-25 04:02:45 [INFO]: Epoch 212 - training loss: 0.2657, validation loss: 0.1166
2024-05-25 04:02:48 [INFO]: Epoch 213 - training loss: 0.2658, validation loss: 0.1165
2024-05-25 04:02:51 [INFO]: Epoch 214 - training loss: 0.2653, validation loss: 0.1162
2024-05-25 04:02:53 [INFO]: Epoch 215 - training loss: 0.2655, validation loss: 0.1160
2024-05-25 04:02:56 [INFO]: Epoch 216 - training loss: 0.2652, validation loss: 0.1161
2024-05-25 04:02:59 [INFO]: Epoch 217 - training loss: 0.2643, validation loss: 0.1159
2024-05-25 04:03:02 [INFO]: Epoch 218 - training loss: 0.2650, validation loss: 0.1159
2024-05-25 04:03:04 [INFO]: Epoch 219 - training loss: 0.2650, validation loss: 0.1158
2024-05-25 04:03:07 [INFO]: Epoch 220 - training loss: 0.2643, validation loss: 0.1155
2024-05-25 04:03:10 [INFO]: Epoch 221 - training loss: 0.2636, validation loss: 0.1157
2024-05-25 04:03:13 [INFO]: Epoch 222 - training loss: 0.2636, validation loss: 0.1155
2024-05-25 04:03:15 [INFO]: Epoch 223 - training loss: 0.2635, validation loss: 0.1154
2024-05-25 04:03:18 [INFO]: Epoch 224 - training loss: 0.2634, validation loss: 0.1151
2024-05-25 04:03:21 [INFO]: Epoch 225 - training loss: 0.2633, validation loss: 0.1154
2024-05-25 04:03:24 [INFO]: Epoch 226 - training loss: 0.2629, validation loss: 0.1152
2024-05-25 04:03:26 [INFO]: Epoch 227 - training loss: 0.2625, validation loss: 0.1150
2024-05-25 04:03:29 [INFO]: Epoch 228 - training loss: 0.2629, validation loss: 0.1148
2024-05-25 04:03:32 [INFO]: Epoch 229 - training loss: 0.2625, validation loss: 0.1147
2024-05-25 04:03:35 [INFO]: Epoch 230 - training loss: 0.2623, validation loss: 0.1146
2024-05-25 04:03:38 [INFO]: Epoch 231 - training loss: 0.2621, validation loss: 0.1144
2024-05-25 04:03:40 [INFO]: Epoch 232 - training loss: 0.2616, validation loss: 0.1147
2024-05-25 04:03:43 [INFO]: Epoch 233 - training loss: 0.2619, validation loss: 0.1147
2024-05-25 04:03:46 [INFO]: Epoch 234 - training loss: 0.2622, validation loss: 0.1147
2024-05-25 04:03:49 [INFO]: Epoch 235 - training loss: 0.2618, validation loss: 0.1142
2024-05-25 04:03:51 [INFO]: Epoch 236 - training loss: 0.2611, validation loss: 0.1144
2024-05-25 04:03:54 [INFO]: Epoch 237 - training loss: 0.2607, validation loss: 0.1141
2024-05-25 04:03:57 [INFO]: Epoch 238 - training loss: 0.2609, validation loss: 0.1141
2024-05-25 04:04:00 [INFO]: Epoch 239 - training loss: 0.2607, validation loss: 0.1139
2024-05-25 04:04:02 [INFO]: Epoch 240 - training loss: 0.2606, validation loss: 0.1141
2024-05-25 04:04:05 [INFO]: Epoch 241 - training loss: 0.2597, validation loss: 0.1139
2024-05-25 04:04:08 [INFO]: Epoch 242 - training loss: 0.2603, validation loss: 0.1139
2024-05-25 04:04:11 [INFO]: Epoch 243 - training loss: 0.2604, validation loss: 0.1138
2024-05-25 04:04:13 [INFO]: Epoch 244 - training loss: 0.2594, validation loss: 0.1137
2024-05-25 04:04:16 [INFO]: Epoch 245 - training loss: 0.2601, validation loss: 0.1137
2024-05-25 04:04:19 [INFO]: Epoch 246 - training loss: 0.2598, validation loss: 0.1136
2024-05-25 04:04:22 [INFO]: Epoch 247 - training loss: 0.2594, validation loss: 0.1136
2024-05-25 04:04:24 [INFO]: Epoch 248 - training loss: 0.2592, validation loss: 0.1136
2024-05-25 04:04:27 [INFO]: Epoch 249 - training loss: 0.2592, validation loss: 0.1133
2024-05-25 04:04:30 [INFO]: Epoch 250 - training loss: 0.2588, validation loss: 0.1135
2024-05-25 04:04:33 [INFO]: Epoch 251 - training loss: 0.2588, validation loss: 0.1135
2024-05-25 04:04:35 [INFO]: Epoch 252 - training loss: 0.2589, validation loss: 0.1134
2024-05-25 04:04:38 [INFO]: Epoch 253 - training loss: 0.2582, validation loss: 0.1134
2024-05-25 04:04:41 [INFO]: Epoch 254 - training loss: 0.2585, validation loss: 0.1132
2024-05-25 04:04:44 [INFO]: Epoch 255 - training loss: 0.2579, validation loss: 0.1132
2024-05-25 04:04:46 [INFO]: Epoch 256 - training loss: 0.2577, validation loss: 0.1131
2024-05-25 04:04:49 [INFO]: Epoch 257 - training loss: 0.2576, validation loss: 0.1129
2024-05-25 04:04:52 [INFO]: Epoch 258 - training loss: 0.2578, validation loss: 0.1131
2024-05-25 04:04:55 [INFO]: Epoch 259 - training loss: 0.2576, validation loss: 0.1130
2024-05-25 04:04:57 [INFO]: Epoch 260 - training loss: 0.2572, validation loss: 0.1131
2024-05-25 04:05:00 [INFO]: Epoch 261 - training loss: 0.2567, validation loss: 0.1128
2024-05-25 04:05:03 [INFO]: Epoch 262 - training loss: 0.2571, validation loss: 0.1128
2024-05-25 04:05:06 [INFO]: Epoch 263 - training loss: 0.2571, validation loss: 0.1127
2024-05-25 04:05:08 [INFO]: Epoch 264 - training loss: 0.2569, validation loss: 0.1128
2024-05-25 04:05:11 [INFO]: Epoch 265 - training loss: 0.2568, validation loss: 0.1126
2024-05-25 04:05:14 [INFO]: Epoch 266 - training loss: 0.2564, validation loss: 0.1123
2024-05-25 04:05:17 [INFO]: Epoch 267 - training loss: 0.2559, validation loss: 0.1126
2024-05-25 04:05:19 [INFO]: Epoch 268 - training loss: 0.2562, validation loss: 0.1125
2024-05-25 04:05:22 [INFO]: Epoch 269 - training loss: 0.2567, validation loss: 0.1124
2024-05-25 04:05:25 [INFO]: Epoch 270 - training loss: 0.2558, validation loss: 0.1124
2024-05-25 04:05:28 [INFO]: Epoch 271 - training loss: 0.2555, validation loss: 0.1122
2024-05-25 04:05:30 [INFO]: Epoch 272 - training loss: 0.2551, validation loss: 0.1124
2024-05-25 04:05:33 [INFO]: Epoch 273 - training loss: 0.2551, validation loss: 0.1122
2024-05-25 04:05:36 [INFO]: Epoch 274 - training loss: 0.2552, validation loss: 0.1123
2024-05-25 04:05:39 [INFO]: Epoch 275 - training loss: 0.2549, validation loss: 0.1121
2024-05-25 04:05:41 [INFO]: Epoch 276 - training loss: 0.2552, validation loss: 0.1120
2024-05-25 04:05:44 [INFO]: Epoch 277 - training loss: 0.2548, validation loss: 0.1121
2024-05-25 04:05:47 [INFO]: Epoch 278 - training loss: 0.2542, validation loss: 0.1121
2024-05-25 04:05:50 [INFO]: Epoch 279 - training loss: 0.2542, validation loss: 0.1120
2024-05-25 04:05:52 [INFO]: Epoch 280 - training loss: 0.2543, validation loss: 0.1120
2024-05-25 04:05:55 [INFO]: Epoch 281 - training loss: 0.2543, validation loss: 0.1118
2024-05-25 04:05:58 [INFO]: Epoch 282 - training loss: 0.2545, validation loss: 0.1121
2024-05-25 04:06:01 [INFO]: Epoch 283 - training loss: 0.2541, validation loss: 0.1119
2024-05-25 04:06:03 [INFO]: Epoch 284 - training loss: 0.2539, validation loss: 0.1117
2024-05-25 04:06:06 [INFO]: Epoch 285 - training loss: 0.2537, validation loss: 0.1121
2024-05-25 04:06:09 [INFO]: Epoch 286 - training loss: 0.2539, validation loss: 0.1118
2024-05-25 04:06:12 [INFO]: Epoch 287 - training loss: 0.2535, validation loss: 0.1117
2024-05-25 04:06:15 [INFO]: Epoch 288 - training loss: 0.2542, validation loss: 0.1116
2024-05-25 04:06:18 [INFO]: Epoch 289 - training loss: 0.2535, validation loss: 0.1116
2024-05-25 04:06:20 [INFO]: Epoch 290 - training loss: 0.2534, validation loss: 0.1117
2024-05-25 04:06:23 [INFO]: Epoch 291 - training loss: 0.2532, validation loss: 0.1116
2024-05-25 04:06:26 [INFO]: Epoch 292 - training loss: 0.2529, validation loss: 0.1114
2024-05-25 04:06:29 [INFO]: Epoch 293 - training loss: 0.2528, validation loss: 0.1115
2024-05-25 04:06:32 [INFO]: Epoch 294 - training loss: 0.2523, validation loss: 0.1113
2024-05-25 04:06:35 [INFO]: Epoch 295 - training loss: 0.2532, validation loss: 0.1114
2024-05-25 04:06:37 [INFO]: Epoch 296 - training loss: 0.2528, validation loss: 0.1114
2024-05-25 04:06:40 [INFO]: Epoch 297 - training loss: 0.2522, validation loss: 0.1114
2024-05-25 04:06:43 [INFO]: Epoch 298 - training loss: 0.2523, validation loss: 0.1114
2024-05-25 04:06:46 [INFO]: Epoch 299 - training loss: 0.2523, validation loss: 0.1115
2024-05-25 04:06:48 [INFO]: Epoch 300 - training loss: 0.2521, validation loss: 0.1115
2024-05-25 04:06:48 [INFO]: Finished training. The best model is from epoch#294.
2024-05-25 04:06:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/BRITS_air_quality/20240525_T035300/BRITS.pypots
2024-05-25 04:06:49 [INFO]: BRITS on Air-Quality: MAE=0.1537, MSE=0.1504
2024-05-25 04:06:49 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/BRITS_air_quality/imputation.pkl
2024-05-25 04:06:49 [INFO]: Using the given device: cuda:0
2024-05-25 04:06:49 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649
2024-05-25 04:06:49 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/tensorboard
2024-05-25 04:06:49 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 04:06:54 [INFO]: Epoch 001 - training loss: 1.4111, validation loss: 0.7944
2024-05-25 04:06:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch1_loss0.7944089859724045.pypots
2024-05-25 04:06:58 [INFO]: Epoch 002 - training loss: 1.0004, validation loss: 0.7300
2024-05-25 04:06:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch2_loss0.730012121796608.pypots
2024-05-25 04:07:01 [INFO]: Epoch 003 - training loss: 0.9227, validation loss: 0.7101
2024-05-25 04:07:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch3_loss0.7101143270730972.pypots
2024-05-25 04:07:05 [INFO]: Epoch 004 - training loss: 0.8838, validation loss: 0.6977
2024-05-25 04:07:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch4_loss0.6976825594902039.pypots
2024-05-25 04:07:09 [INFO]: Epoch 005 - training loss: 0.8760, validation loss: 0.6880
2024-05-25 04:07:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch5_loss0.688042289018631.pypots
2024-05-25 04:07:13 [INFO]: Epoch 006 - training loss: 0.8648, validation loss: 0.6815
2024-05-25 04:07:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch6_loss0.6814534068107605.pypots
2024-05-25 04:07:17 [INFO]: Epoch 007 - training loss: 0.8531, validation loss: 0.6775
2024-05-25 04:07:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch7_loss0.6775142103433609.pypots
2024-05-25 04:07:20 [INFO]: Epoch 008 - training loss: 0.8479, validation loss: 0.6731
2024-05-25 04:07:20 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch8_loss0.6730705797672272.pypots
2024-05-25 04:07:24 [INFO]: Epoch 009 - training loss: 0.8426, validation loss: 0.6683
2024-05-25 04:07:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch9_loss0.6682539999485015.pypots
2024-05-25 04:07:28 [INFO]: Epoch 010 - training loss: 0.8414, validation loss: 0.6664
2024-05-25 04:07:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch10_loss0.6664343565702439.pypots
2024-05-25 04:07:32 [INFO]: Epoch 011 - training loss: 0.8377, validation loss: 0.6644
2024-05-25 04:07:32 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch11_loss0.6644073903560639.pypots
2024-05-25 04:07:36 [INFO]: Epoch 012 - training loss: 0.8175, validation loss: 0.6635
2024-05-25 04:07:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch12_loss0.6634668737649918.pypots
2024-05-25 04:07:39 [INFO]: Epoch 013 - training loss: 0.8225, validation loss: 0.6622
2024-05-25 04:07:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch13_loss0.6621759295463562.pypots
2024-05-25 04:07:43 [INFO]: Epoch 014 - training loss: 0.8230, validation loss: 0.6614
2024-05-25 04:07:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch14_loss0.6613681137561798.pypots
2024-05-25 04:07:47 [INFO]: Epoch 015 - training loss: 0.8255, validation loss: 0.6615
2024-05-25 04:07:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch15_loss0.6615186214447022.pypots
2024-05-25 04:07:51 [INFO]: Epoch 016 - training loss: 0.8190, validation loss: 0.6615
2024-05-25 04:07:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch16_loss0.6614822834730149.pypots
2024-05-25 04:07:55 [INFO]: Epoch 017 - training loss: 0.8125, validation loss: 0.6603
2024-05-25 04:07:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch17_loss0.6602664232254029.pypots
2024-05-25 04:07:58 [INFO]: Epoch 018 - training loss: 0.8106, validation loss: 0.6599
2024-05-25 04:07:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch18_loss0.6599074989557266.pypots
2024-05-25 04:08:02 [INFO]: Epoch 019 - training loss: 0.8003, validation loss: 0.6573
2024-05-25 04:08:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch19_loss0.6573394805192947.pypots
2024-05-25 04:08:06 [INFO]: Epoch 020 - training loss: 0.7849, validation loss: 0.6590
2024-05-25 04:08:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch20_loss0.6590311169624329.pypots
2024-05-25 04:08:10 [INFO]: Epoch 021 - training loss: 0.8060, validation loss: 0.6578
2024-05-25 04:08:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch21_loss0.6578221797943116.pypots
2024-05-25 04:08:14 [INFO]: Epoch 022 - training loss: 0.7853, validation loss: 0.6575
2024-05-25 04:08:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch22_loss0.6575376898050308.pypots
2024-05-25 04:08:17 [INFO]: Epoch 023 - training loss: 0.7907, validation loss: 0.6586
2024-05-25 04:08:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch23_loss0.6585602968931198.pypots
2024-05-25 04:08:21 [INFO]: Epoch 024 - training loss: 0.7950, validation loss: 0.6581
2024-05-25 04:08:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch24_loss0.6580745100975036.pypots
2024-05-25 04:08:25 [INFO]: Epoch 025 - training loss: 0.7879, validation loss: 0.6569
2024-05-25 04:08:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch25_loss0.6568775743246078.pypots
2024-05-25 04:08:29 [INFO]: Epoch 026 - training loss: 0.7757, validation loss: 0.6571
2024-05-25 04:08:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch26_loss0.657118234038353.pypots
2024-05-25 04:08:33 [INFO]: Epoch 027 - training loss: 0.7866, validation loss: 0.6600
2024-05-25 04:08:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch27_loss0.6600028038024902.pypots
2024-05-25 04:08:37 [INFO]: Epoch 028 - training loss: 0.7939, validation loss: 0.6585
2024-05-25 04:08:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch28_loss0.6585224390029907.pypots
2024-05-25 04:08:40 [INFO]: Epoch 029 - training loss: 0.7792, validation loss: 0.6578
2024-05-25 04:08:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch29_loss0.6578200995922089.pypots
2024-05-25 04:08:44 [INFO]: Epoch 030 - training loss: 0.7790, validation loss: 0.6595
2024-05-25 04:08:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch30_loss0.6595337271690369.pypots
2024-05-25 04:08:48 [INFO]: Epoch 031 - training loss: 0.7656, validation loss: 0.6579
2024-05-25 04:08:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch31_loss0.6579464554786683.pypots
2024-05-25 04:08:52 [INFO]: Epoch 032 - training loss: 0.7669, validation loss: 0.6603
2024-05-25 04:08:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch32_loss0.6602968573570251.pypots
2024-05-25 04:08:56 [INFO]: Epoch 033 - training loss: 0.7667, validation loss: 0.6611
2024-05-25 04:08:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch33_loss0.6611206412315369.pypots
2024-05-25 04:08:59 [INFO]: Epoch 034 - training loss: 0.7685, validation loss: 0.6596
2024-05-25 04:08:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch34_loss0.6595660954713821.pypots
2024-05-25 04:09:03 [INFO]: Epoch 035 - training loss: 0.7588, validation loss: 0.6591
2024-05-25 04:09:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN_epoch35_loss0.6591397285461426.pypots
2024-05-25 04:09:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:09:03 [INFO]: Finished training. The best model is from epoch#25.
2024-05-25 04:09:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T040649/MRNN.pypots
2024-05-25 04:09:04 [INFO]: MRNN on Air-Quality: MAE=0.5217, MSE=0.6572
2024-05-25 04:09:04 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/MRNN_air_quality/imputation.pkl
2024-05-25 04:09:04 [INFO]: Using the given device: cpu
2024-05-25 04:09:04 [INFO]: LOCF on Air-Quality: MAE=0.2220, MSE=0.3375
2024-05-25 04:09:04 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_air_quality".
2024-05-25 04:09:04 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/LOCF_air_quality/imputation.pkl
2024-05-25 04:09:04 [INFO]: Median on Air-Quality: MAE=0.6640, MSE=1.0523
2024-05-25 04:09:04 [INFO]: Successfully created the given path "saved_results/round_0/Median_air_quality".
2024-05-25 04:09:04 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Median_air_quality/imputation.pkl
2024-05-25 04:09:04 [INFO]: Mean on Air-Quality: MAE=0.6951, MSE=0.9927
2024-05-25 04:09:04 [INFO]: Successfully created the given path "saved_results/round_0/Mean_air_quality".
2024-05-25 04:09:04 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Mean_air_quality/imputation.pkl
2024-05-25 04:09:04 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-25 04:09:04 [INFO]: Using the given device: cuda:0
2024-05-25 04:09:04 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/SAITS_air_quality/20240525_T040904
2024-05-25 04:09:04 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/SAITS_air_quality/20240525_T040904/tensorboard
2024-05-25 04:09:04 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 04:09:05 [INFO]: Epoch 001 - training loss: 1.0520, validation loss: 0.5022
2024-05-25 04:09:06 [INFO]: Epoch 002 - training loss: 0.7481, validation loss: 0.3871
2024-05-25 04:09:06 [INFO]: Epoch 003 - training loss: 0.6374, validation loss: 0.3120
2024-05-25 04:09:07 [INFO]: Epoch 004 - training loss: 0.5637, validation loss: 0.2715
2024-05-25 04:09:07 [INFO]: Epoch 005 - training loss: 0.5136, validation loss: 0.2463
2024-05-25 04:09:08 [INFO]: Epoch 006 - training loss: 0.4799, validation loss: 0.2310
2024-05-25 04:09:09 [INFO]: Epoch 007 - training loss: 0.4563, validation loss: 0.2219
2024-05-25 04:09:09 [INFO]: Epoch 008 - training loss: 0.4385, validation loss: 0.2136
2024-05-25 04:09:10 [INFO]: Epoch 009 - training loss: 0.4236, validation loss: 0.2081
2024-05-25 04:09:10 [INFO]: Epoch 010 - training loss: 0.4129, validation loss: 0.2024
2024-05-25 04:09:11 [INFO]: Epoch 011 - training loss: 0.4019, validation loss: 0.1983
2024-05-25 04:09:12 [INFO]: Epoch 012 - training loss: 0.3948, validation loss: 0.1926
2024-05-25 04:09:12 [INFO]: Epoch 013 - training loss: 0.3870, validation loss: 0.1920
2024-05-25 04:09:13 [INFO]: Epoch 014 - training loss: 0.3794, validation loss: 0.1873
2024-05-25 04:09:13 [INFO]: Epoch 015 - training loss: 0.3733, validation loss: 0.1862
2024-05-25 04:09:14 [INFO]: Epoch 016 - training loss: 0.3690, validation loss: 0.1829
2024-05-25 04:09:15 [INFO]: Epoch 017 - training loss: 0.3619, validation loss: 0.1799
2024-05-25 04:09:15 [INFO]: Epoch 018 - training loss: 0.3576, validation loss: 0.1776
2024-05-25 04:09:16 [INFO]: Epoch 019 - training loss: 0.3541, validation loss: 0.1764
2024-05-25 04:09:16 [INFO]: Epoch 020 - training loss: 0.3495, validation loss: 0.1734
2024-05-25 04:09:17 [INFO]: Epoch 021 - training loss: 0.3446, validation loss: 0.1716
2024-05-25 04:09:18 [INFO]: Epoch 022 - training loss: 0.3423, validation loss: 0.1706
2024-05-25 04:09:18 [INFO]: Epoch 023 - training loss: 0.3386, validation loss: 0.1680
2024-05-25 04:09:19 [INFO]: Epoch 024 - training loss: 0.3339, validation loss: 0.1674
2024-05-25 04:09:19 [INFO]: Epoch 025 - training loss: 0.3306, validation loss: 0.1645
2024-05-25 04:09:20 [INFO]: Epoch 026 - training loss: 0.3298, validation loss: 0.1639
2024-05-25 04:09:21 [INFO]: Epoch 027 - training loss: 0.3267, validation loss: 0.1626
2024-05-25 04:09:21 [INFO]: Epoch 028 - training loss: 0.3248, validation loss: 0.1594
2024-05-25 04:09:22 [INFO]: Epoch 029 - training loss: 0.3200, validation loss: 0.1605
2024-05-25 04:09:22 [INFO]: Epoch 030 - training loss: 0.3184, validation loss: 0.1559
2024-05-25 04:09:23 [INFO]: Epoch 031 - training loss: 0.3151, validation loss: 0.1551
2024-05-25 04:09:24 [INFO]: Epoch 032 - training loss: 0.3141, validation loss: 0.1530
2024-05-25 04:09:24 [INFO]: Epoch 033 - training loss: 0.3118, validation loss: 0.1529
2024-05-25 04:09:25 [INFO]: Epoch 034 - training loss: 0.3087, validation loss: 0.1514
2024-05-25 04:09:25 [INFO]: Epoch 035 - training loss: 0.3071, validation loss: 0.1503
2024-05-25 04:09:26 [INFO]: Epoch 036 - training loss: 0.3063, validation loss: 0.1486
2024-05-25 04:09:27 [INFO]: Epoch 037 - training loss: 0.3026, validation loss: 0.1485
2024-05-25 04:09:27 [INFO]: Epoch 038 - training loss: 0.3015, validation loss: 0.1466
2024-05-25 04:09:28 [INFO]: Epoch 039 - training loss: 0.2988, validation loss: 0.1459
2024-05-25 04:09:28 [INFO]: Epoch 040 - training loss: 0.2969, validation loss: 0.1466
2024-05-25 04:09:29 [INFO]: Epoch 041 - training loss: 0.2956, validation loss: 0.1448
2024-05-25 04:09:30 [INFO]: Epoch 042 - training loss: 0.2930, validation loss: 0.1444
2024-05-25 04:09:30 [INFO]: Epoch 043 - training loss: 0.2916, validation loss: 0.1437
2024-05-25 04:09:31 [INFO]: Epoch 044 - training loss: 0.2917, validation loss: 0.1424
2024-05-25 04:09:31 [INFO]: Epoch 045 - training loss: 0.2896, validation loss: 0.1434
2024-05-25 04:09:32 [INFO]: Epoch 046 - training loss: 0.2890, validation loss: 0.1415
2024-05-25 04:09:33 [INFO]: Epoch 047 - training loss: 0.2874, validation loss: 0.1411
2024-05-25 04:09:33 [INFO]: Epoch 048 - training loss: 0.2839, validation loss: 0.1414
2024-05-25 04:09:34 [INFO]: Epoch 049 - training loss: 0.2827, validation loss: 0.1395
2024-05-25 04:09:34 [INFO]: Epoch 050 - training loss: 0.2803, validation loss: 0.1397
2024-05-25 04:09:35 [INFO]: Epoch 051 - training loss: 0.2795, validation loss: 0.1384
2024-05-25 04:09:36 [INFO]: Epoch 052 - training loss: 0.2781, validation loss: 0.1382
2024-05-25 04:09:36 [INFO]: Epoch 053 - training loss: 0.2768, validation loss: 0.1374
2024-05-25 04:09:37 [INFO]: Epoch 054 - training loss: 0.2759, validation loss: 0.1376
2024-05-25 04:09:37 [INFO]: Epoch 055 - training loss: 0.2741, validation loss: 0.1368
2024-05-25 04:09:38 [INFO]: Epoch 056 - training loss: 0.2719, validation loss: 0.1369
2024-05-25 04:09:39 [INFO]: Epoch 057 - training loss: 0.2705, validation loss: 0.1376
2024-05-25 04:09:39 [INFO]: Epoch 058 - training loss: 0.2712, validation loss: 0.1359
2024-05-25 04:09:40 [INFO]: Epoch 059 - training loss: 0.2682, validation loss: 0.1355
2024-05-25 04:09:40 [INFO]: Epoch 060 - training loss: 0.2681, validation loss: 0.1348
2024-05-25 04:09:41 [INFO]: Epoch 061 - training loss: 0.2663, validation loss: 0.1346
2024-05-25 04:09:42 [INFO]: Epoch 062 - training loss: 0.2665, validation loss: 0.1339
2024-05-25 04:09:42 [INFO]: Epoch 063 - training loss: 0.2650, validation loss: 0.1335
2024-05-25 04:09:43 [INFO]: Epoch 064 - training loss: 0.2622, validation loss: 0.1321
2024-05-25 04:09:43 [INFO]: Epoch 065 - training loss: 0.2607, validation loss: 0.1324
2024-05-25 04:09:44 [INFO]: Epoch 066 - training loss: 0.2604, validation loss: 0.1315
2024-05-25 04:09:45 [INFO]: Epoch 067 - training loss: 0.2585, validation loss: 0.1315
2024-05-25 04:09:45 [INFO]: Epoch 068 - training loss: 0.2572, validation loss: 0.1306
2024-05-25 04:09:46 [INFO]: Epoch 069 - training loss: 0.2569, validation loss: 0.1318
2024-05-25 04:09:46 [INFO]: Epoch 070 - training loss: 0.2553, validation loss: 0.1312
2024-05-25 04:09:47 [INFO]: Epoch 071 - training loss: 0.2558, validation loss: 0.1311
2024-05-25 04:09:48 [INFO]: Epoch 072 - training loss: 0.2545, validation loss: 0.1299
2024-05-25 04:09:48 [INFO]: Epoch 073 - training loss: 0.2545, validation loss: 0.1303
2024-05-25 04:09:49 [INFO]: Epoch 074 - training loss: 0.2519, validation loss: 0.1301
2024-05-25 04:09:49 [INFO]: Epoch 075 - training loss: 0.2509, validation loss: 0.1299
2024-05-25 04:09:50 [INFO]: Epoch 076 - training loss: 0.2491, validation loss: 0.1286
2024-05-25 04:09:51 [INFO]: Epoch 077 - training loss: 0.2481, validation loss: 0.1287
2024-05-25 04:09:51 [INFO]: Epoch 078 - training loss: 0.2480, validation loss: 0.1286
2024-05-25 04:09:52 [INFO]: Epoch 079 - training loss: 0.2480, validation loss: 0.1288
2024-05-25 04:09:52 [INFO]: Epoch 080 - training loss: 0.2468, validation loss: 0.1275
2024-05-25 04:09:53 [INFO]: Epoch 081 - training loss: 0.2455, validation loss: 0.1270
2024-05-25 04:09:54 [INFO]: Epoch 082 - training loss: 0.2439, validation loss: 0.1269
2024-05-25 04:09:54 [INFO]: Epoch 083 - training loss: 0.2430, validation loss: 0.1264
2024-05-25 04:09:55 [INFO]: Epoch 084 - training loss: 0.2441, validation loss: 0.1270
2024-05-25 04:09:55 [INFO]: Epoch 085 - training loss: 0.2426, validation loss: 0.1268
2024-05-25 04:09:56 [INFO]: Epoch 086 - training loss: 0.2425, validation loss: 0.1262
2024-05-25 04:09:57 [INFO]: Epoch 087 - training loss: 0.2411, validation loss: 0.1251
2024-05-25 04:09:57 [INFO]: Epoch 088 - training loss: 0.2400, validation loss: 0.1250
2024-05-25 04:09:58 [INFO]: Epoch 089 - training loss: 0.2400, validation loss: 0.1253
2024-05-25 04:09:58 [INFO]: Epoch 090 - training loss: 0.2388, validation loss: 0.1249
2024-05-25 04:09:59 [INFO]: Epoch 091 - training loss: 0.2378, validation loss: 0.1251
2024-05-25 04:10:00 [INFO]: Epoch 092 - training loss: 0.2387, validation loss: 0.1253
2024-05-25 04:10:00 [INFO]: Epoch 093 - training loss: 0.2385, validation loss: 0.1257
2024-05-25 04:10:01 [INFO]: Epoch 094 - training loss: 0.2359, validation loss: 0.1242
2024-05-25 04:10:01 [INFO]: Epoch 095 - training loss: 0.2353, validation loss: 0.1244
2024-05-25 04:10:02 [INFO]: Epoch 096 - training loss: 0.2344, validation loss: 0.1238
2024-05-25 04:10:03 [INFO]: Epoch 097 - training loss: 0.2356, validation loss: 0.1236
2024-05-25 04:10:03 [INFO]: Epoch 098 - training loss: 0.2343, validation loss: 0.1231
2024-05-25 04:10:04 [INFO]: Epoch 099 - training loss: 0.2325, validation loss: 0.1238
2024-05-25 04:10:04 [INFO]: Epoch 100 - training loss: 0.2329, validation loss: 0.1233
2024-05-25 04:10:05 [INFO]: Epoch 101 - training loss: 0.2319, validation loss: 0.1225
2024-05-25 04:10:06 [INFO]: Epoch 102 - training loss: 0.2315, validation loss: 0.1232
2024-05-25 04:10:06 [INFO]: Epoch 103 - training loss: 0.2308, validation loss: 0.1229
2024-05-25 04:10:07 [INFO]: Epoch 104 - training loss: 0.2296, validation loss: 0.1217
2024-05-25 04:10:07 [INFO]: Epoch 105 - training loss: 0.2294, validation loss: 0.1231
2024-05-25 04:10:08 [INFO]: Epoch 106 - training loss: 0.2277, validation loss: 0.1214
2024-05-25 04:10:09 [INFO]: Epoch 107 - training loss: 0.2264, validation loss: 0.1223
2024-05-25 04:10:09 [INFO]: Epoch 108 - training loss: 0.2264, validation loss: 0.1220
2024-05-25 04:10:10 [INFO]: Epoch 109 - training loss: 0.2264, validation loss: 0.1211
2024-05-25 04:10:10 [INFO]: Epoch 110 - training loss: 0.2261, validation loss: 0.1212
2024-05-25 04:10:11 [INFO]: Epoch 111 - training loss: 0.2259, validation loss: 0.1210
2024-05-25 04:10:12 [INFO]: Epoch 112 - training loss: 0.2251, validation loss: 0.1223
2024-05-25 04:10:12 [INFO]: Epoch 113 - training loss: 0.2244, validation loss: 0.1210
2024-05-25 04:10:13 [INFO]: Epoch 114 - training loss: 0.2241, validation loss: 0.1214
2024-05-25 04:10:13 [INFO]: Epoch 115 - training loss: 0.2226, validation loss: 0.1207
2024-05-25 04:10:14 [INFO]: Epoch 116 - training loss: 0.2228, validation loss: 0.1203
2024-05-25 04:10:15 [INFO]: Epoch 117 - training loss: 0.2213, validation loss: 0.1208
2024-05-25 04:10:15 [INFO]: Epoch 118 - training loss: 0.2211, validation loss: 0.1198
2024-05-25 04:10:16 [INFO]: Epoch 119 - training loss: 0.2203, validation loss: 0.1198
2024-05-25 04:10:16 [INFO]: Epoch 120 - training loss: 0.2194, validation loss: 0.1192
2024-05-25 04:10:17 [INFO]: Epoch 121 - training loss: 0.2194, validation loss: 0.1211
2024-05-25 04:10:18 [INFO]: Epoch 122 - training loss: 0.2199, validation loss: 0.1190
2024-05-25 04:10:18 [INFO]: Epoch 123 - training loss: 0.2186, validation loss: 0.1185
2024-05-25 04:10:19 [INFO]: Epoch 124 - training loss: 0.2171, validation loss: 0.1185
2024-05-25 04:10:19 [INFO]: Epoch 125 - training loss: 0.2171, validation loss: 0.1204
2024-05-25 04:10:20 [INFO]: Epoch 126 - training loss: 0.2175, validation loss: 0.1189
2024-05-25 04:10:21 [INFO]: Epoch 127 - training loss: 0.2155, validation loss: 0.1192
2024-05-25 04:10:21 [INFO]: Epoch 128 - training loss: 0.2155, validation loss: 0.1191
2024-05-25 04:10:22 [INFO]: Epoch 129 - training loss: 0.2168, validation loss: 0.1188
2024-05-25 04:10:22 [INFO]: Epoch 130 - training loss: 0.2177, validation loss: 0.1186
2024-05-25 04:10:23 [INFO]: Epoch 131 - training loss: 0.2169, validation loss: 0.1186
2024-05-25 04:10:24 [INFO]: Epoch 132 - training loss: 0.2139, validation loss: 0.1190
2024-05-25 04:10:24 [INFO]: Epoch 133 - training loss: 0.2137, validation loss: 0.1181
2024-05-25 04:10:25 [INFO]: Epoch 134 - training loss: 0.2123, validation loss: 0.1175
2024-05-25 04:10:25 [INFO]: Epoch 135 - training loss: 0.2116, validation loss: 0.1194
2024-05-25 04:10:26 [INFO]: Epoch 136 - training loss: 0.2115, validation loss: 0.1178
2024-05-25 04:10:27 [INFO]: Epoch 137 - training loss: 0.2114, validation loss: 0.1175
2024-05-25 04:10:27 [INFO]: Epoch 138 - training loss: 0.2115, validation loss: 0.1184
2024-05-25 04:10:28 [INFO]: Epoch 139 - training loss: 0.2110, validation loss: 0.1179
2024-05-25 04:10:28 [INFO]: Epoch 140 - training loss: 0.2121, validation loss: 0.1183
2024-05-25 04:10:29 [INFO]: Epoch 141 - training loss: 0.2141, validation loss: 0.1184
2024-05-25 04:10:30 [INFO]: Epoch 142 - training loss: 0.2105, validation loss: 0.1184
2024-05-25 04:10:30 [INFO]: Epoch 143 - training loss: 0.2081, validation loss: 0.1187
2024-05-25 04:10:31 [INFO]: Epoch 144 - training loss: 0.2082, validation loss: 0.1190
2024-05-25 04:10:31 [INFO]: Epoch 145 - training loss: 0.2087, validation loss: 0.1180
2024-05-25 04:10:32 [INFO]: Epoch 146 - training loss: 0.2071, validation loss: 0.1182
2024-05-25 04:10:33 [INFO]: Epoch 147 - training loss: 0.2060, validation loss: 0.1167
2024-05-25 04:10:33 [INFO]: Epoch 148 - training loss: 0.2063, validation loss: 0.1177
2024-05-25 04:10:34 [INFO]: Epoch 149 - training loss: 0.2058, validation loss: 0.1169
2024-05-25 04:10:34 [INFO]: Epoch 150 - training loss: 0.2056, validation loss: 0.1173
2024-05-25 04:10:35 [INFO]: Epoch 151 - training loss: 0.2049, validation loss: 0.1167
2024-05-25 04:10:36 [INFO]: Epoch 152 - training loss: 0.2050, validation loss: 0.1175
2024-05-25 04:10:36 [INFO]: Epoch 153 - training loss: 0.2065, validation loss: 0.1174
2024-05-25 04:10:37 [INFO]: Epoch 154 - training loss: 0.2045, validation loss: 0.1163
2024-05-25 04:10:37 [INFO]: Epoch 155 - training loss: 0.2028, validation loss: 0.1171
2024-05-25 04:10:38 [INFO]: Epoch 156 - training loss: 0.2026, validation loss: 0.1169
2024-05-25 04:10:39 [INFO]: Epoch 157 - training loss: 0.2019, validation loss: 0.1177
2024-05-25 04:10:39 [INFO]: Epoch 158 - training loss: 0.2027, validation loss: 0.1181
2024-05-25 04:10:40 [INFO]: Epoch 159 - training loss: 0.2017, validation loss: 0.1162
2024-05-25 04:10:40 [INFO]: Epoch 160 - training loss: 0.2005, validation loss: 0.1164
2024-05-25 04:10:41 [INFO]: Epoch 161 - training loss: 0.2003, validation loss: 0.1167
2024-05-25 04:10:42 [INFO]: Epoch 162 - training loss: 0.2012, validation loss: 0.1174
2024-05-25 04:10:42 [INFO]: Epoch 163 - training loss: 0.1994, validation loss: 0.1160
2024-05-25 04:10:43 [INFO]: Epoch 164 - training loss: 0.1990, validation loss: 0.1166
2024-05-25 04:10:43 [INFO]: Epoch 165 - training loss: 0.1993, validation loss: 0.1166
2024-05-25 04:10:44 [INFO]: Epoch 166 - training loss: 0.2005, validation loss: 0.1161
2024-05-25 04:10:45 [INFO]: Epoch 167 - training loss: 0.2039, validation loss: 0.1170
2024-05-25 04:10:45 [INFO]: Epoch 168 - training loss: 0.2001, validation loss: 0.1153
2024-05-25 04:10:46 [INFO]: Epoch 169 - training loss: 0.1989, validation loss: 0.1170
2024-05-25 04:10:46 [INFO]: Epoch 170 - training loss: 0.1984, validation loss: 0.1157
2024-05-25 04:10:47 [INFO]: Epoch 171 - training loss: 0.1979, validation loss: 0.1164
2024-05-25 04:10:48 [INFO]: Epoch 172 - training loss: 0.1971, validation loss: 0.1153
2024-05-25 04:10:48 [INFO]: Epoch 173 - training loss: 0.1980, validation loss: 0.1150
2024-05-25 04:10:49 [INFO]: Epoch 174 - training loss: 0.2007, validation loss: 0.1160
2024-05-25 04:10:49 [INFO]: Epoch 175 - training loss: 0.1984, validation loss: 0.1159
2024-05-25 04:10:50 [INFO]: Epoch 176 - training loss: 0.1961, validation loss: 0.1163
2024-05-25 04:10:51 [INFO]: Epoch 177 - training loss: 0.1949, validation loss: 0.1158
2024-05-25 04:10:51 [INFO]: Epoch 178 - training loss: 0.1952, validation loss: 0.1164
2024-05-25 04:10:52 [INFO]: Epoch 179 - training loss: 0.2005, validation loss: 0.1153
2024-05-25 04:10:52 [INFO]: Epoch 180 - training loss: 0.1979, validation loss: 0.1154
2024-05-25 04:10:53 [INFO]: Epoch 181 - training loss: 0.1937, validation loss: 0.1144
2024-05-25 04:10:54 [INFO]: Epoch 182 - training loss: 0.1931, validation loss: 0.1154
2024-05-25 04:10:54 [INFO]: Epoch 183 - training loss: 0.1937, validation loss: 0.1148
2024-05-25 04:10:55 [INFO]: Epoch 184 - training loss: 0.1919, validation loss: 0.1156
2024-05-25 04:10:55 [INFO]: Epoch 185 - training loss: 0.1928, validation loss: 0.1159
2024-05-25 04:10:56 [INFO]: Epoch 186 - training loss: 0.1930, validation loss: 0.1167
2024-05-25 04:10:57 [INFO]: Epoch 187 - training loss: 0.1927, validation loss: 0.1153
2024-05-25 04:10:57 [INFO]: Epoch 188 - training loss: 0.1911, validation loss: 0.1143
2024-05-25 04:10:58 [INFO]: Epoch 189 - training loss: 0.1902, validation loss: 0.1145
2024-05-25 04:10:58 [INFO]: Epoch 190 - training loss: 0.1906, validation loss: 0.1146
2024-05-25 04:10:59 [INFO]: Epoch 191 - training loss: 0.1900, validation loss: 0.1144
2024-05-25 04:11:00 [INFO]: Epoch 192 - training loss: 0.1897, validation loss: 0.1153
2024-05-25 04:11:00 [INFO]: Epoch 193 - training loss: 0.1898, validation loss: 0.1139
2024-05-25 04:11:01 [INFO]: Epoch 194 - training loss: 0.1911, validation loss: 0.1193
2024-05-25 04:11:02 [INFO]: Epoch 195 - training loss: 0.1910, validation loss: 0.1145
2024-05-25 04:11:02 [INFO]: Epoch 196 - training loss: 0.1916, validation loss: 0.1150
2024-05-25 04:11:03 [INFO]: Epoch 197 - training loss: 0.1921, validation loss: 0.1157
2024-05-25 04:11:03 [INFO]: Epoch 198 - training loss: 0.1895, validation loss: 0.1151
2024-05-25 04:11:04 [INFO]: Epoch 199 - training loss: 0.1891, validation loss: 0.1152
2024-05-25 04:11:05 [INFO]: Epoch 200 - training loss: 0.1874, validation loss: 0.1144
2024-05-25 04:11:05 [INFO]: Epoch 201 - training loss: 0.1866, validation loss: 0.1141
2024-05-25 04:11:06 [INFO]: Epoch 202 - training loss: 0.1869, validation loss: 0.1145
2024-05-25 04:11:06 [INFO]: Epoch 203 - training loss: 0.1863, validation loss: 0.1152
2024-05-25 04:11:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:11:06 [INFO]: Finished training. The best model is from epoch#193.
2024-05-25 04:11:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/SAITS_air_quality/20240525_T040904/SAITS.pypots
2024-05-25 04:11:07 [INFO]: SAITS on Air-Quality: MAE=0.1590, MSE=0.1563
2024-05-25 04:11:07 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/SAITS_air_quality/imputation.pkl
2024-05-25 04:11:07 [INFO]: Using the given device: cuda:0
2024-05-25 04:11:07 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/Transformer_air_quality/20240525_T041107
2024-05-25 04:11:07 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/Transformer_air_quality/20240525_T041107/tensorboard
2024-05-25 04:11:07 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 04:11:07 [INFO]: Epoch 001 - training loss: 0.9203, validation loss: 0.4480
2024-05-25 04:11:07 [INFO]: Epoch 002 - training loss: 0.5790, validation loss: 0.3440
2024-05-25 04:11:07 [INFO]: Epoch 003 - training loss: 0.4876, validation loss: 0.2783
2024-05-25 04:11:08 [INFO]: Epoch 004 - training loss: 0.4372, validation loss: 0.2541
2024-05-25 04:11:08 [INFO]: Epoch 005 - training loss: 0.4070, validation loss: 0.2384
2024-05-25 04:11:08 [INFO]: Epoch 006 - training loss: 0.3853, validation loss: 0.2283
2024-05-25 04:11:08 [INFO]: Epoch 007 - training loss: 0.3756, validation loss: 0.2236
2024-05-25 04:11:09 [INFO]: Epoch 008 - training loss: 0.3655, validation loss: 0.2142
2024-05-25 04:11:09 [INFO]: Epoch 009 - training loss: 0.3546, validation loss: 0.2091
2024-05-25 04:11:09 [INFO]: Epoch 010 - training loss: 0.3431, validation loss: 0.2045
2024-05-25 04:11:09 [INFO]: Epoch 011 - training loss: 0.3358, validation loss: 0.2011
2024-05-25 04:11:10 [INFO]: Epoch 012 - training loss: 0.3326, validation loss: 0.1951
2024-05-25 04:11:10 [INFO]: Epoch 013 - training loss: 0.3251, validation loss: 0.1930
2024-05-25 04:11:10 [INFO]: Epoch 014 - training loss: 0.3209, validation loss: 0.1885
2024-05-25 04:11:10 [INFO]: Epoch 015 - training loss: 0.3159, validation loss: 0.1848
2024-05-25 04:11:11 [INFO]: Epoch 016 - training loss: 0.3114, validation loss: 0.1852
2024-05-25 04:11:11 [INFO]: Epoch 017 - training loss: 0.3082, validation loss: 0.1818
2024-05-25 04:11:11 [INFO]: Epoch 018 - training loss: 0.3043, validation loss: 0.1768
2024-05-25 04:11:11 [INFO]: Epoch 019 - training loss: 0.3030, validation loss: 0.1770
2024-05-25 04:11:12 [INFO]: Epoch 020 - training loss: 0.2996, validation loss: 0.1759
2024-05-25 04:11:12 [INFO]: Epoch 021 - training loss: 0.2965, validation loss: 0.1722
2024-05-25 04:11:12 [INFO]: Epoch 022 - training loss: 0.2948, validation loss: 0.1737
2024-05-25 04:11:12 [INFO]: Epoch 023 - training loss: 0.2898, validation loss: 0.1728
2024-05-25 04:11:13 [INFO]: Epoch 024 - training loss: 0.2872, validation loss: 0.1694
2024-05-25 04:11:13 [INFO]: Epoch 025 - training loss: 0.2845, validation loss: 0.1701
2024-05-25 04:11:13 [INFO]: Epoch 026 - training loss: 0.2831, validation loss: 0.1681
2024-05-25 04:11:13 [INFO]: Epoch 027 - training loss: 0.2786, validation loss: 0.1660
2024-05-25 04:11:14 [INFO]: Epoch 028 - training loss: 0.2784, validation loss: 0.1685
2024-05-25 04:11:14 [INFO]: Epoch 029 - training loss: 0.2773, validation loss: 0.1672
2024-05-25 04:11:14 [INFO]: Epoch 030 - training loss: 0.2746, validation loss: 0.1654
2024-05-25 04:11:14 [INFO]: Epoch 031 - training loss: 0.2706, validation loss: 0.1637
2024-05-25 04:11:15 [INFO]: Epoch 032 - training loss: 0.2696, validation loss: 0.1644
2024-05-25 04:11:15 [INFO]: Epoch 033 - training loss: 0.2677, validation loss: 0.1661
2024-05-25 04:11:15 [INFO]: Epoch 034 - training loss: 0.2671, validation loss: 0.1609
2024-05-25 04:11:15 [INFO]: Epoch 035 - training loss: 0.2654, validation loss: 0.1629
2024-05-25 04:11:16 [INFO]: Epoch 036 - training loss: 0.2621, validation loss: 0.1618
2024-05-25 04:11:16 [INFO]: Epoch 037 - training loss: 0.2628, validation loss: 0.1615
2024-05-25 04:11:16 [INFO]: Epoch 038 - training loss: 0.2606, validation loss: 0.1605
2024-05-25 04:11:16 [INFO]: Epoch 039 - training loss: 0.2601, validation loss: 0.1606
2024-05-25 04:11:17 [INFO]: Epoch 040 - training loss: 0.2570, validation loss: 0.1596
2024-05-25 04:11:17 [INFO]: Epoch 041 - training loss: 0.2558, validation loss: 0.1597
2024-05-25 04:11:17 [INFO]: Epoch 042 - training loss: 0.2544, validation loss: 0.1585
2024-05-25 04:11:17 [INFO]: Epoch 043 - training loss: 0.2518, validation loss: 0.1591
2024-05-25 04:11:18 [INFO]: Epoch 044 - training loss: 0.2506, validation loss: 0.1595
2024-05-25 04:11:18 [INFO]: Epoch 045 - training loss: 0.2507, validation loss: 0.1587
2024-05-25 04:11:18 [INFO]: Epoch 046 - training loss: 0.2527, validation loss: 0.1577
2024-05-25 04:11:18 [INFO]: Epoch 047 - training loss: 0.2524, validation loss: 0.1582
2024-05-25 04:11:19 [INFO]: Epoch 048 - training loss: 0.2497, validation loss: 0.1573
2024-05-25 04:11:19 [INFO]: Epoch 049 - training loss: 0.2449, validation loss: 0.1562
2024-05-25 04:11:19 [INFO]: Epoch 050 - training loss: 0.2439, validation loss: 0.1545
2024-05-25 04:11:19 [INFO]: Epoch 051 - training loss: 0.2438, validation loss: 0.1546
2024-05-25 04:11:20 [INFO]: Epoch 052 - training loss: 0.2445, validation loss: 0.1559
2024-05-25 04:11:20 [INFO]: Epoch 053 - training loss: 0.2387, validation loss: 0.1538
2024-05-25 04:11:20 [INFO]: Epoch 054 - training loss: 0.2385, validation loss: 0.1539
2024-05-25 04:11:20 [INFO]: Epoch 055 - training loss: 0.2379, validation loss: 0.1550
2024-05-25 04:11:21 [INFO]: Epoch 056 - training loss: 0.2366, validation loss: 0.1520
2024-05-25 04:11:21 [INFO]: Epoch 057 - training loss: 0.2370, validation loss: 0.1546
2024-05-25 04:11:21 [INFO]: Epoch 058 - training loss: 0.2411, validation loss: 0.1534
2024-05-25 04:11:21 [INFO]: Epoch 059 - training loss: 0.2359, validation loss: 0.1528
2024-05-25 04:11:22 [INFO]: Epoch 060 - training loss: 0.2324, validation loss: 0.1518
2024-05-25 04:11:22 [INFO]: Epoch 061 - training loss: 0.2311, validation loss: 0.1506
2024-05-25 04:11:22 [INFO]: Epoch 062 - training loss: 0.2354, validation loss: 0.1513
2024-05-25 04:11:22 [INFO]: Epoch 063 - training loss: 0.2302, validation loss: 0.1533
2024-05-25 04:11:23 [INFO]: Epoch 064 - training loss: 0.2314, validation loss: 0.1510
2024-05-25 04:11:23 [INFO]: Epoch 065 - training loss: 0.2253, validation loss: 0.1507
2024-05-25 04:11:23 [INFO]: Epoch 066 - training loss: 0.2248, validation loss: 0.1508
2024-05-25 04:11:23 [INFO]: Epoch 067 - training loss: 0.2252, validation loss: 0.1501
2024-05-25 04:11:24 [INFO]: Epoch 068 - training loss: 0.2257, validation loss: 0.1494
2024-05-25 04:11:24 [INFO]: Epoch 069 - training loss: 0.2219, validation loss: 0.1487
2024-05-25 04:11:24 [INFO]: Epoch 070 - training loss: 0.2211, validation loss: 0.1484
2024-05-25 04:11:24 [INFO]: Epoch 071 - training loss: 0.2205, validation loss: 0.1505
2024-05-25 04:11:25 [INFO]: Epoch 072 - training loss: 0.2192, validation loss: 0.1490
2024-05-25 04:11:25 [INFO]: Epoch 073 - training loss: 0.2174, validation loss: 0.1487
2024-05-25 04:11:25 [INFO]: Epoch 074 - training loss: 0.2173, validation loss: 0.1474
2024-05-25 04:11:25 [INFO]: Epoch 075 - training loss: 0.2168, validation loss: 0.1479
2024-05-25 04:11:26 [INFO]: Epoch 076 - training loss: 0.2187, validation loss: 0.1455
2024-05-25 04:11:26 [INFO]: Epoch 077 - training loss: 0.2208, validation loss: 0.1468
2024-05-25 04:11:26 [INFO]: Epoch 078 - training loss: 0.2168, validation loss: 0.1468
2024-05-25 04:11:26 [INFO]: Epoch 079 - training loss: 0.2178, validation loss: 0.1491
2024-05-25 04:11:27 [INFO]: Epoch 080 - training loss: 0.2192, validation loss: 0.1476
2024-05-25 04:11:27 [INFO]: Epoch 081 - training loss: 0.2135, validation loss: 0.1462
2024-05-25 04:11:27 [INFO]: Epoch 082 - training loss: 0.2111, validation loss: 0.1464
2024-05-25 04:11:27 [INFO]: Epoch 083 - training loss: 0.2093, validation loss: 0.1470
2024-05-25 04:11:28 [INFO]: Epoch 084 - training loss: 0.2086, validation loss: 0.1453
2024-05-25 04:11:28 [INFO]: Epoch 085 - training loss: 0.2085, validation loss: 0.1468
2024-05-25 04:11:28 [INFO]: Epoch 086 - training loss: 0.2075, validation loss: 0.1453
2024-05-25 04:11:28 [INFO]: Epoch 087 - training loss: 0.2068, validation loss: 0.1446
2024-05-25 04:11:29 [INFO]: Epoch 088 - training loss: 0.2064, validation loss: 0.1434
2024-05-25 04:11:29 [INFO]: Epoch 089 - training loss: 0.2061, validation loss: 0.1449
2024-05-25 04:11:29 [INFO]: Epoch 090 - training loss: 0.2046, validation loss: 0.1431
2024-05-25 04:11:29 [INFO]: Epoch 091 - training loss: 0.2086, validation loss: 0.1457
2024-05-25 04:11:30 [INFO]: Epoch 092 - training loss: 0.2048, validation loss: 0.1426
2024-05-25 04:11:30 [INFO]: Epoch 093 - training loss: 0.2024, validation loss: 0.1466
2024-05-25 04:11:30 [INFO]: Epoch 094 - training loss: 0.2069, validation loss: 0.1436
2024-05-25 04:11:30 [INFO]: Epoch 095 - training loss: 0.2038, validation loss: 0.1447
2024-05-25 04:11:31 [INFO]: Epoch 096 - training loss: 0.2056, validation loss: 0.1440
2024-05-25 04:11:31 [INFO]: Epoch 097 - training loss: 0.2056, validation loss: 0.1428
2024-05-25 04:11:31 [INFO]: Epoch 098 - training loss: 0.2028, validation loss: 0.1447
2024-05-25 04:11:31 [INFO]: Epoch 099 - training loss: 0.2032, validation loss: 0.1433
2024-05-25 04:11:32 [INFO]: Epoch 100 - training loss: 0.1969, validation loss: 0.1434
2024-05-25 04:11:32 [INFO]: Epoch 101 - training loss: 0.1958, validation loss: 0.1405
2024-05-25 04:11:32 [INFO]: Epoch 102 - training loss: 0.1961, validation loss: 0.1430
2024-05-25 04:11:32 [INFO]: Epoch 103 - training loss: 0.1956, validation loss: 0.1430
2024-05-25 04:11:33 [INFO]: Epoch 104 - training loss: 0.1965, validation loss: 0.1434
2024-05-25 04:11:33 [INFO]: Epoch 105 - training loss: 0.1969, validation loss: 0.1415
2024-05-25 04:11:33 [INFO]: Epoch 106 - training loss: 0.1948, validation loss: 0.1409
2024-05-25 04:11:33 [INFO]: Epoch 107 - training loss: 0.1926, validation loss: 0.1427
2024-05-25 04:11:34 [INFO]: Epoch 108 - training loss: 0.1910, validation loss: 0.1410
2024-05-25 04:11:34 [INFO]: Epoch 109 - training loss: 0.1913, validation loss: 0.1406
2024-05-25 04:11:34 [INFO]: Epoch 110 - training loss: 0.1905, validation loss: 0.1418
2024-05-25 04:11:34 [INFO]: Epoch 111 - training loss: 0.1916, validation loss: 0.1420
2024-05-25 04:11:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:11:34 [INFO]: Finished training. The best model is from epoch#101.
2024-05-25 04:11:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/Transformer_air_quality/20240525_T041107/Transformer.pypots
2024-05-25 04:11:34 [INFO]: Transformer on Air-Quality: MAE=0.1853, MSE=0.1904
2024-05-25 04:11:34 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Transformer_air_quality/imputation.pkl
2024-05-25 04:11:34 [INFO]: Using the given device: cuda:0
2024-05-25 04:11:34 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/TimesNet_air_quality/20240525_T041134
2024-05-25 04:11:34 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/TimesNet_air_quality/20240525_T041134/tensorboard
2024-05-25 04:11:35 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 04:11:35 [INFO]: Epoch 001 - training loss: 0.3030, validation loss: 0.2482
2024-05-25 04:11:36 [INFO]: Epoch 002 - training loss: 0.2295, validation loss: 0.2196
2024-05-25 04:11:36 [INFO]: Epoch 003 - training loss: 0.1960, validation loss: 0.1968
2024-05-25 04:11:37 [INFO]: Epoch 004 - training loss: 0.1729, validation loss: 0.1880
2024-05-25 04:11:37 [INFO]: Epoch 005 - training loss: 0.1661, validation loss: 0.1808
2024-05-25 04:11:38 [INFO]: Epoch 006 - training loss: 0.1548, validation loss: 0.1749
2024-05-25 04:11:38 [INFO]: Epoch 007 - training loss: 0.1489, validation loss: 0.1729
2024-05-25 04:11:39 [INFO]: Epoch 008 - training loss: 0.1402, validation loss: 0.1727
2024-05-25 04:11:39 [INFO]: Epoch 009 - training loss: 0.1344, validation loss: 0.1696
2024-05-25 04:11:39 [INFO]: Epoch 010 - training loss: 0.1377, validation loss: 0.1684
2024-05-25 04:11:40 [INFO]: Epoch 011 - training loss: 0.1354, validation loss: 0.1656
2024-05-25 04:11:40 [INFO]: Epoch 012 - training loss: 0.1296, validation loss: 0.1737
2024-05-25 04:11:41 [INFO]: Epoch 013 - training loss: 0.1221, validation loss: 0.1675
2024-05-25 04:11:41 [INFO]: Epoch 014 - training loss: 0.1195, validation loss: 0.1632
2024-05-25 04:11:42 [INFO]: Epoch 015 - training loss: 0.1133, validation loss: 0.1660
2024-05-25 04:11:42 [INFO]: Epoch 016 - training loss: 0.1095, validation loss: 0.1618
2024-05-25 04:11:43 [INFO]: Epoch 017 - training loss: 0.1094, validation loss: 0.1673
2024-05-25 04:11:43 [INFO]: Epoch 018 - training loss: 0.1154, validation loss: 0.1597
2024-05-25 04:11:44 [INFO]: Epoch 019 - training loss: 0.1095, validation loss: 0.1572
2024-05-25 04:11:44 [INFO]: Epoch 020 - training loss: 0.1029, validation loss: 0.1612
2024-05-25 04:11:44 [INFO]: Epoch 021 - training loss: 0.0977, validation loss: 0.1607
2024-05-25 04:11:45 [INFO]: Epoch 022 - training loss: 0.0960, validation loss: 0.1597
2024-05-25 04:11:45 [INFO]: Epoch 023 - training loss: 0.0947, validation loss: 0.1578
2024-05-25 04:11:46 [INFO]: Epoch 024 - training loss: 0.0956, validation loss: 0.1597
2024-05-25 04:11:46 [INFO]: Epoch 025 - training loss: 0.0973, validation loss: 0.1626
2024-05-25 04:11:47 [INFO]: Epoch 026 - training loss: 0.0947, validation loss: 0.1626
2024-05-25 04:11:47 [INFO]: Epoch 027 - training loss: 0.0990, validation loss: 0.1591
2024-05-25 04:11:48 [INFO]: Epoch 028 - training loss: 0.1002, validation loss: 0.1767
2024-05-25 04:11:48 [INFO]: Epoch 029 - training loss: 0.0973, validation loss: 0.1593
2024-05-25 04:11:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:11:48 [INFO]: Finished training. The best model is from epoch#19.
2024-05-25 04:11:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/TimesNet_air_quality/20240525_T041134/TimesNet.pypots
2024-05-25 04:11:48 [INFO]: TimesNet on Air-Quality: MAE=0.1768, MSE=0.2619
2024-05-25 04:11:48 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/TimesNet_air_quality/imputation.pkl
2024-05-25 04:11:48 [INFO]: Using the given device: cuda:0
2024-05-25 04:11:48 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148
2024-05-25 04:11:48 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/tensorboard
2024-05-25 04:11:48 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 04:12:05 [INFO]: Epoch 001 - training loss: 0.4996, validation loss: 0.3265
2024-05-25 04:12:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch1_loss0.3264512151479721.pypots
2024-05-25 04:12:22 [INFO]: Epoch 002 - training loss: 0.2893, validation loss: 0.2567
2024-05-25 04:12:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch2_loss0.2567315325140953.pypots
2024-05-25 04:12:38 [INFO]: Epoch 003 - training loss: 0.2424, validation loss: 0.2193
2024-05-25 04:12:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch3_loss0.21928795874118806.pypots
2024-05-25 04:12:55 [INFO]: Epoch 004 - training loss: 0.2206, validation loss: 0.2021
2024-05-25 04:12:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch4_loss0.20207389444112778.pypots
2024-05-25 04:13:12 [INFO]: Epoch 005 - training loss: 0.1962, validation loss: 0.1884
2024-05-25 04:13:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch5_loss0.18836371451616288.pypots
2024-05-25 04:13:28 [INFO]: Epoch 006 - training loss: 0.1964, validation loss: 0.1704
2024-05-25 04:13:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch6_loss0.17037390768527985.pypots
2024-05-25 04:13:45 [INFO]: Epoch 007 - training loss: 0.1670, validation loss: 0.1653
2024-05-25 04:13:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch7_loss0.165297269821167.pypots
2024-05-25 04:14:02 [INFO]: Epoch 008 - training loss: 0.1663, validation loss: 0.1570
2024-05-25 04:14:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch8_loss0.15699736028909683.pypots
2024-05-25 04:14:18 [INFO]: Epoch 009 - training loss: 0.1559, validation loss: 0.1501
2024-05-25 04:14:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch9_loss0.15010145157575608.pypots
2024-05-25 04:14:35 [INFO]: Epoch 010 - training loss: 0.1579, validation loss: 0.1547
2024-05-25 04:14:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch10_loss0.1547189712524414.pypots
2024-05-25 04:14:52 [INFO]: Epoch 011 - training loss: 0.1707, validation loss: 0.1452
2024-05-25 04:14:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch11_loss0.14523355066776275.pypots
2024-05-25 04:15:08 [INFO]: Epoch 012 - training loss: 0.1464, validation loss: 0.1432
2024-05-25 04:15:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch12_loss0.14322477281093599.pypots
2024-05-25 04:15:25 [INFO]: Epoch 013 - training loss: 0.1481, validation loss: 0.1417
2024-05-25 04:15:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch13_loss0.1416788548231125.pypots
2024-05-25 04:15:42 [INFO]: Epoch 014 - training loss: 0.1492, validation loss: 0.1428
2024-05-25 04:15:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch14_loss0.14277815222740173.pypots
2024-05-25 04:15:58 [INFO]: Epoch 015 - training loss: 0.1603, validation loss: 0.1374
2024-05-25 04:15:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch15_loss0.13738941103219987.pypots
2024-05-25 04:16:15 [INFO]: Epoch 016 - training loss: 0.1527, validation loss: 0.1393
2024-05-25 04:16:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch16_loss0.13928614556789398.pypots
2024-05-25 04:16:32 [INFO]: Epoch 017 - training loss: 0.1654, validation loss: 0.1381
2024-05-25 04:16:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch17_loss0.1380963869392872.pypots
2024-05-25 04:16:48 [INFO]: Epoch 018 - training loss: 0.1319, validation loss: 0.1351
2024-05-25 04:16:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch18_loss0.1350575491786003.pypots
2024-05-25 04:17:05 [INFO]: Epoch 019 - training loss: 0.1412, validation loss: 0.1329
2024-05-25 04:17:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch19_loss0.13289026990532876.pypots
2024-05-25 04:17:22 [INFO]: Epoch 020 - training loss: 0.1285, validation loss: 0.1334
2024-05-25 04:17:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch20_loss0.13341657519340516.pypots
2024-05-25 04:17:38 [INFO]: Epoch 021 - training loss: 0.1309, validation loss: 0.1312
2024-05-25 04:17:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch21_loss0.1311538964509964.pypots
2024-05-25 04:17:55 [INFO]: Epoch 022 - training loss: 0.1313, validation loss: 0.1337
2024-05-25 04:17:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch22_loss0.13367175608873366.pypots
2024-05-25 04:18:12 [INFO]: Epoch 023 - training loss: 0.1276, validation loss: 0.1299
2024-05-25 04:18:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch23_loss0.12991528064012528.pypots
2024-05-25 04:18:28 [INFO]: Epoch 024 - training loss: 0.1230, validation loss: 0.1298
2024-05-25 04:18:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch24_loss0.1297789193689823.pypots
2024-05-25 04:18:45 [INFO]: Epoch 025 - training loss: 0.1267, validation loss: 0.1304
2024-05-25 04:18:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch25_loss0.1303587056696415.pypots
2024-05-25 04:19:02 [INFO]: Epoch 026 - training loss: 0.1318, validation loss: 0.1274
2024-05-25 04:19:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch26_loss0.12743451222777366.pypots
2024-05-25 04:19:18 [INFO]: Epoch 027 - training loss: 0.1218, validation loss: 0.1272
2024-05-25 04:19:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch27_loss0.12716400176286696.pypots
2024-05-25 04:19:35 [INFO]: Epoch 028 - training loss: 0.1220, validation loss: 0.1278
2024-05-25 04:19:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch28_loss0.12780646309256555.pypots
2024-05-25 04:19:52 [INFO]: Epoch 029 - training loss: 0.1222, validation loss: 0.1235
2024-05-25 04:19:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch29_loss0.12354419082403183.pypots
2024-05-25 04:20:08 [INFO]: Epoch 030 - training loss: 0.1135, validation loss: 0.1248
2024-05-25 04:20:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch30_loss0.12476202920079231.pypots
2024-05-25 04:20:25 [INFO]: Epoch 031 - training loss: 0.1110, validation loss: 0.1242
2024-05-25 04:20:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch31_loss0.12417126372456551.pypots
2024-05-25 04:20:42 [INFO]: Epoch 032 - training loss: 0.1222, validation loss: 0.1241
2024-05-25 04:20:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch32_loss0.1241340734064579.pypots
2024-05-25 04:20:58 [INFO]: Epoch 033 - training loss: 0.1288, validation loss: 0.1246
2024-05-25 04:20:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch33_loss0.12464657425880432.pypots
2024-05-25 04:21:15 [INFO]: Epoch 034 - training loss: 0.1227, validation loss: 0.1210
2024-05-25 04:21:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch34_loss0.1209915541112423.pypots
2024-05-25 04:21:32 [INFO]: Epoch 035 - training loss: 0.1195, validation loss: 0.1197
2024-05-25 04:21:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch35_loss0.11971866488456726.pypots
2024-05-25 04:21:48 [INFO]: Epoch 036 - training loss: 0.1152, validation loss: 0.1175
2024-05-25 04:21:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch36_loss0.11746275797486305.pypots
2024-05-25 04:22:05 [INFO]: Epoch 037 - training loss: 0.1200, validation loss: 0.1222
2024-05-25 04:22:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch37_loss0.12220727801322936.pypots
2024-05-25 04:22:22 [INFO]: Epoch 038 - training loss: 0.1242, validation loss: 0.1265
2024-05-25 04:22:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch38_loss0.12653035297989845.pypots
2024-05-25 04:22:38 [INFO]: Epoch 039 - training loss: 0.1242, validation loss: 0.1191
2024-05-25 04:22:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch39_loss0.11911245509982109.pypots
2024-05-25 04:22:55 [INFO]: Epoch 040 - training loss: 0.1085, validation loss: 0.1196
2024-05-25 04:22:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch40_loss0.11960512846708297.pypots
2024-05-25 04:23:12 [INFO]: Epoch 041 - training loss: 0.1247, validation loss: 0.1190
2024-05-25 04:23:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch41_loss0.1190027192234993.pypots
2024-05-25 04:23:28 [INFO]: Epoch 042 - training loss: 0.1130, validation loss: 0.1154
2024-05-25 04:23:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch42_loss0.11540242061018943.pypots
2024-05-25 04:23:45 [INFO]: Epoch 043 - training loss: 0.1012, validation loss: 0.1165
2024-05-25 04:23:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch43_loss0.1165010690689087.pypots
2024-05-25 04:24:02 [INFO]: Epoch 044 - training loss: 0.1079, validation loss: 0.1234
2024-05-25 04:24:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch44_loss0.12342506870627404.pypots
2024-05-25 04:24:18 [INFO]: Epoch 045 - training loss: 0.1112, validation loss: 0.1165
2024-05-25 04:24:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch45_loss0.1165105126798153.pypots
2024-05-25 04:24:35 [INFO]: Epoch 046 - training loss: 0.1135, validation loss: 0.1145
2024-05-25 04:24:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch46_loss0.11450985819101334.pypots
2024-05-25 04:24:52 [INFO]: Epoch 047 - training loss: 0.1237, validation loss: 0.1140
2024-05-25 04:24:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch47_loss0.11399087011814117.pypots
2024-05-25 04:25:08 [INFO]: Epoch 048 - training loss: 0.1126, validation loss: 0.1122
2024-05-25 04:25:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch48_loss0.11224564388394356.pypots
2024-05-25 04:25:25 [INFO]: Epoch 049 - training loss: 0.1298, validation loss: 0.1147
2024-05-25 04:25:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch49_loss0.1146838754415512.pypots
2024-05-25 04:25:42 [INFO]: Epoch 050 - training loss: 0.1196, validation loss: 0.1143
2024-05-25 04:25:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch50_loss0.11425373330712318.pypots
2024-05-25 04:25:58 [INFO]: Epoch 051 - training loss: 0.1063, validation loss: 0.1128
2024-05-25 04:25:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch51_loss0.11281757801771164.pypots
2024-05-25 04:26:15 [INFO]: Epoch 052 - training loss: 0.1035, validation loss: 0.1149
2024-05-25 04:26:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch52_loss0.11488929241895676.pypots
2024-05-25 04:26:32 [INFO]: Epoch 053 - training loss: 0.1201, validation loss: 0.1119
2024-05-25 04:26:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch53_loss0.111931811273098.pypots
2024-05-25 04:26:48 [INFO]: Epoch 054 - training loss: 0.1125, validation loss: 0.1137
2024-05-25 04:26:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch54_loss0.1137242116034031.pypots
2024-05-25 04:27:05 [INFO]: Epoch 055 - training loss: 0.1078, validation loss: 0.1093
2024-05-25 04:27:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch55_loss0.10927450060844421.pypots
2024-05-25 04:27:22 [INFO]: Epoch 056 - training loss: 0.1098, validation loss: 0.1091
2024-05-25 04:27:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch56_loss0.10906885340809822.pypots
2024-05-25 04:27:38 [INFO]: Epoch 057 - training loss: 0.1108, validation loss: 0.1093
2024-05-25 04:27:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch57_loss0.10926231816411018.pypots
2024-05-25 04:27:55 [INFO]: Epoch 058 - training loss: 0.1014, validation loss: 0.1097
2024-05-25 04:27:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch58_loss0.10971271470189095.pypots
2024-05-25 04:28:12 [INFO]: Epoch 059 - training loss: 0.1064, validation loss: 0.1139
2024-05-25 04:28:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch59_loss0.11390556991100312.pypots
2024-05-25 04:28:28 [INFO]: Epoch 060 - training loss: 0.1174, validation loss: 0.1093
2024-05-25 04:28:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch60_loss0.109299036860466.pypots
2024-05-25 04:28:45 [INFO]: Epoch 061 - training loss: 0.1070, validation loss: 0.1094
2024-05-25 04:28:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch61_loss0.10943925902247428.pypots
2024-05-25 04:29:02 [INFO]: Epoch 062 - training loss: 0.1104, validation loss: 0.1101
2024-05-25 04:29:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch62_loss0.11010055541992188.pypots
2024-05-25 04:29:18 [INFO]: Epoch 063 - training loss: 0.1090, validation loss: 0.1103
2024-05-25 04:29:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch63_loss0.11027028188109397.pypots
2024-05-25 04:29:35 [INFO]: Epoch 064 - training loss: 0.0948, validation loss: 0.1108
2024-05-25 04:29:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch64_loss0.11083208471536636.pypots
2024-05-25 04:29:52 [INFO]: Epoch 065 - training loss: 0.1074, validation loss: 0.1068
2024-05-25 04:29:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch65_loss0.10684063658118248.pypots
2024-05-25 04:30:08 [INFO]: Epoch 066 - training loss: 0.1056, validation loss: 0.1076
2024-05-25 04:30:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch66_loss0.10756880715489388.pypots
2024-05-25 04:30:25 [INFO]: Epoch 067 - training loss: 0.1154, validation loss: 0.1078
2024-05-25 04:30:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch67_loss0.10782363265752792.pypots
2024-05-25 04:30:42 [INFO]: Epoch 068 - training loss: 0.0996, validation loss: 0.1070
2024-05-25 04:30:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch68_loss0.1069749154150486.pypots
2024-05-25 04:30:58 [INFO]: Epoch 069 - training loss: 0.1031, validation loss: 0.1059
2024-05-25 04:30:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch69_loss0.10587893575429916.pypots
2024-05-25 04:31:15 [INFO]: Epoch 070 - training loss: 0.1118, validation loss: 0.1097
2024-05-25 04:31:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch70_loss0.10970187708735465.pypots
2024-05-25 04:31:32 [INFO]: Epoch 071 - training loss: 0.1163, validation loss: 0.1079
2024-05-25 04:31:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch71_loss0.1079190194606781.pypots
2024-05-25 04:31:48 [INFO]: Epoch 072 - training loss: 0.1065, validation loss: 0.1109
2024-05-25 04:31:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch72_loss0.1109018363058567.pypots
2024-05-25 04:32:05 [INFO]: Epoch 073 - training loss: 0.1059, validation loss: 0.1067
2024-05-25 04:32:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch73_loss0.10669346377253533.pypots
2024-05-25 04:32:21 [INFO]: Epoch 074 - training loss: 0.1136, validation loss: 0.1060
2024-05-25 04:32:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch74_loss0.10599836334586143.pypots
2024-05-25 04:32:38 [INFO]: Epoch 075 - training loss: 0.0987, validation loss: 0.1061
2024-05-25 04:32:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch75_loss0.10605600774288178.pypots
2024-05-25 04:32:55 [INFO]: Epoch 076 - training loss: 0.1018, validation loss: 0.1072
2024-05-25 04:32:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch76_loss0.10718211382627488.pypots
2024-05-25 04:33:11 [INFO]: Epoch 077 - training loss: 0.1101, validation loss: 0.1085
2024-05-25 04:33:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch77_loss0.10852715075016021.pypots
2024-05-25 04:33:28 [INFO]: Epoch 078 - training loss: 0.1171, validation loss: 0.1061
2024-05-25 04:33:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch78_loss0.1061317577958107.pypots
2024-05-25 04:33:45 [INFO]: Epoch 079 - training loss: 0.1091, validation loss: 0.1075
2024-05-25 04:33:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI_epoch79_loss0.10749881342053413.pypots
2024-05-25 04:33:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:33:45 [INFO]: Finished training. The best model is from epoch#69.
2024-05-25 04:33:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T041148/CSDI.pypots
2024-05-25 04:36:05 [INFO]: CSDI on Air-Quality: MAE=0.1149, MSE=0.2007
2024-05-25 04:36:05 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/CSDI_air_quality/imputation.pkl
2024-05-25 04:36:05 [INFO]: Using the given device: cuda:0
2024-05-25 04:36:05 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/GPVAE_air_quality/20240525_T043605
2024-05-25 04:36:05 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/GPVAE_air_quality/20240525_T043605/tensorboard
2024-05-25 04:36:05 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 04:36:06 [INFO]: Epoch 001 - training loss: 63652.0250, validation loss: 0.6428
2024-05-25 04:36:06 [INFO]: Epoch 002 - training loss: 41554.7948, validation loss: 0.5621
2024-05-25 04:36:06 [INFO]: Epoch 003 - training loss: 41203.7020, validation loss: 0.5374
2024-05-25 04:36:06 [INFO]: Epoch 004 - training loss: 41071.1999, validation loss: 0.4673
2024-05-25 04:36:07 [INFO]: Epoch 005 - training loss: 40964.2371, validation loss: 0.4423
2024-05-25 04:36:07 [INFO]: Epoch 006 - training loss: 40987.7739, validation loss: 0.4643
2024-05-25 04:36:07 [INFO]: Epoch 007 - training loss: 40910.3080, validation loss: 0.4085
2024-05-25 04:36:08 [INFO]: Epoch 008 - training loss: 40835.9280, validation loss: 0.3605
2024-05-25 04:36:08 [INFO]: Epoch 009 - training loss: 40803.6234, validation loss: 0.3418
2024-05-25 04:36:08 [INFO]: Epoch 010 - training loss: 40801.5770, validation loss: 0.3490
2024-05-25 04:36:09 [INFO]: Epoch 011 - training loss: 40765.0317, validation loss: 0.3247
2024-05-25 04:36:09 [INFO]: Epoch 012 - training loss: 40735.1227, validation loss: 0.3048
2024-05-25 04:36:09 [INFO]: Epoch 013 - training loss: 40710.7614, validation loss: 0.3025
2024-05-25 04:36:10 [INFO]: Epoch 014 - training loss: 40698.8038, validation loss: 0.3047
2024-05-25 04:36:10 [INFO]: Epoch 015 - training loss: 40702.8218, validation loss: 0.3051
2024-05-25 04:36:10 [INFO]: Epoch 016 - training loss: 40690.0683, validation loss: 0.2945
2024-05-25 04:36:11 [INFO]: Epoch 017 - training loss: 40677.8251, validation loss: 0.2999
2024-05-25 04:36:11 [INFO]: Epoch 018 - training loss: 40660.6725, validation loss: 0.2773
2024-05-25 04:36:11 [INFO]: Epoch 019 - training loss: 40649.6777, validation loss: 0.2952
2024-05-25 04:36:12 [INFO]: Epoch 020 - training loss: 40661.5249, validation loss: 0.2864
2024-05-25 04:36:12 [INFO]: Epoch 021 - training loss: 40663.5058, validation loss: 0.3013
2024-05-25 04:36:12 [INFO]: Epoch 022 - training loss: 40654.5213, validation loss: 0.2732
2024-05-25 04:36:13 [INFO]: Epoch 023 - training loss: 40661.9223, validation loss: 0.2855
2024-05-25 04:36:13 [INFO]: Epoch 024 - training loss: 40635.7303, validation loss: 0.2697
2024-05-25 04:36:13 [INFO]: Epoch 025 - training loss: 40625.1963, validation loss: 0.2681
2024-05-25 04:36:14 [INFO]: Epoch 026 - training loss: 40619.0172, validation loss: 0.2517
2024-05-25 04:36:14 [INFO]: Epoch 027 - training loss: 40610.2964, validation loss: 0.2573
2024-05-25 04:36:14 [INFO]: Epoch 028 - training loss: 40614.3992, validation loss: 0.2535
2024-05-25 04:36:15 [INFO]: Epoch 029 - training loss: 40610.4530, validation loss: 0.2679
2024-05-25 04:36:15 [INFO]: Epoch 030 - training loss: 40605.7912, validation loss: 0.2537
2024-05-25 04:36:15 [INFO]: Epoch 031 - training loss: 40596.2711, validation loss: 0.2532
2024-05-25 04:36:16 [INFO]: Epoch 032 - training loss: 40591.2257, validation loss: 0.2476
2024-05-25 04:36:16 [INFO]: Epoch 033 - training loss: 40603.9745, validation loss: 0.2480
2024-05-25 04:36:16 [INFO]: Epoch 034 - training loss: 40587.9064, validation loss: 0.2515
2024-05-25 04:36:17 [INFO]: Epoch 035 - training loss: 40583.6457, validation loss: 0.2354
2024-05-25 04:36:17 [INFO]: Epoch 036 - training loss: 40575.4809, validation loss: 0.2423
2024-05-25 04:36:17 [INFO]: Epoch 037 - training loss: 40581.7297, validation loss: 0.2796
2024-05-25 04:36:17 [INFO]: Epoch 038 - training loss: 40600.6427, validation loss: 0.2552
2024-05-25 04:36:18 [INFO]: Epoch 039 - training loss: 40590.1421, validation loss: 0.3140
2024-05-25 04:36:18 [INFO]: Epoch 040 - training loss: 40600.5398, validation loss: 0.2443
2024-05-25 04:36:18 [INFO]: Epoch 041 - training loss: 40601.3192, validation loss: 0.2479
2024-05-25 04:36:19 [INFO]: Epoch 042 - training loss: 40593.6852, validation loss: 0.2580
2024-05-25 04:36:19 [INFO]: Epoch 043 - training loss: 40588.9922, validation loss: 0.2493
2024-05-25 04:36:19 [INFO]: Epoch 044 - training loss: 40577.6509, validation loss: 0.2412
2024-05-25 04:36:20 [INFO]: Epoch 045 - training loss: 40580.7797, validation loss: 0.2444
2024-05-25 04:36:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:36:20 [INFO]: Finished training. The best model is from epoch#35.
2024-05-25 04:36:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/GPVAE_air_quality/20240525_T043605/GPVAE.pypots
2024-05-25 04:36:20 [INFO]: GP-VAE on Air-Quality: MAE=0.2944, MSE=0.3104
2024-05-25 04:36:20 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/GPVAE_air_quality/imputation.pkl
2024-05-25 04:36:20 [INFO]: Using the given device: cuda:0
2024-05-25 04:36:20 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/USGAN_air_quality/20240525_T043620
2024-05-25 04:36:20 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/USGAN_air_quality/20240525_T043620/tensorboard
2024-05-25 04:36:20 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 04:36:25 [INFO]: Epoch 001 - generator training loss: 0.3558, discriminator training loss: 0.5694, validation loss: 0.5014
2024-05-25 04:36:29 [INFO]: Epoch 002 - generator training loss: 0.0311, discriminator training loss: 0.5238, validation loss: 0.3774
2024-05-25 04:36:33 [INFO]: Epoch 003 - generator training loss: -0.0406, discriminator training loss: 0.5185, validation loss: 0.3135
2024-05-25 04:36:37 [INFO]: Epoch 004 - generator training loss: -0.0780, discriminator training loss: 0.5138, validation loss: 0.2694
2024-05-25 04:36:41 [INFO]: Epoch 005 - generator training loss: -0.1003, discriminator training loss: 0.5090, validation loss: 0.2434
2024-05-25 04:36:45 [INFO]: Epoch 006 - generator training loss: -0.1122, discriminator training loss: 0.5032, validation loss: 0.2244
2024-05-25 04:36:49 [INFO]: Epoch 007 - generator training loss: -0.1234, discriminator training loss: 0.4966, validation loss: 0.2128
2024-05-25 04:36:53 [INFO]: Epoch 008 - generator training loss: -0.1292, discriminator training loss: 0.4892, validation loss: 0.2020
2024-05-25 04:36:57 [INFO]: Epoch 009 - generator training loss: -0.1304, discriminator training loss: 0.4805, validation loss: 0.1934
2024-05-25 04:37:01 [INFO]: Epoch 010 - generator training loss: -0.1314, discriminator training loss: 0.4708, validation loss: 0.1869
2024-05-25 04:37:05 [INFO]: Epoch 011 - generator training loss: -0.1299, discriminator training loss: 0.4610, validation loss: 0.1809
2024-05-25 04:37:10 [INFO]: Epoch 012 - generator training loss: -0.1304, discriminator training loss: 0.4507, validation loss: 0.1752
2024-05-25 04:37:14 [INFO]: Epoch 013 - generator training loss: -0.1285, discriminator training loss: 0.4403, validation loss: 0.1702
2024-05-25 04:37:18 [INFO]: Epoch 014 - generator training loss: -0.1257, discriminator training loss: 0.4303, validation loss: 0.1663
2024-05-25 04:37:22 [INFO]: Epoch 015 - generator training loss: -0.1228, discriminator training loss: 0.4201, validation loss: 0.1635
2024-05-25 04:37:26 [INFO]: Epoch 016 - generator training loss: -0.1194, discriminator training loss: 0.4106, validation loss: 0.1605
2024-05-25 04:37:30 [INFO]: Epoch 017 - generator training loss: -0.1163, discriminator training loss: 0.4021, validation loss: 0.1575
2024-05-25 04:37:34 [INFO]: Epoch 018 - generator training loss: -0.1102, discriminator training loss: 0.3935, validation loss: 0.1547
2024-05-25 04:37:38 [INFO]: Epoch 019 - generator training loss: -0.1114, discriminator training loss: 0.3858, validation loss: 0.1529
2024-05-25 04:37:42 [INFO]: Epoch 020 - generator training loss: -0.1088, discriminator training loss: 0.3789, validation loss: 0.1511
2024-05-25 04:37:46 [INFO]: Epoch 021 - generator training loss: -0.1061, discriminator training loss: 0.3723, validation loss: 0.1492
2024-05-25 04:37:50 [INFO]: Epoch 022 - generator training loss: -0.1036, discriminator training loss: 0.3669, validation loss: 0.1469
2024-05-25 04:37:54 [INFO]: Epoch 023 - generator training loss: -0.1035, discriminator training loss: 0.3611, validation loss: 0.1449
2024-05-25 04:37:58 [INFO]: Epoch 024 - generator training loss: -0.1018, discriminator training loss: 0.3565, validation loss: 0.1431
2024-05-25 04:38:02 [INFO]: Epoch 025 - generator training loss: -0.0993, discriminator training loss: 0.3519, validation loss: 0.1416
2024-05-25 04:38:06 [INFO]: Epoch 026 - generator training loss: -0.0997, discriminator training loss: 0.3481, validation loss: 0.1407
2024-05-25 04:38:10 [INFO]: Epoch 027 - generator training loss: -0.0984, discriminator training loss: 0.3445, validation loss: 0.1387
2024-05-25 04:38:15 [INFO]: Epoch 028 - generator training loss: -0.0984, discriminator training loss: 0.3411, validation loss: 0.1373
2024-05-25 04:38:19 [INFO]: Epoch 029 - generator training loss: -0.0977, discriminator training loss: 0.3382, validation loss: 0.1362
2024-05-25 04:38:23 [INFO]: Epoch 030 - generator training loss: -0.0968, discriminator training loss: 0.3353, validation loss: 0.1348
2024-05-25 04:38:27 [INFO]: Epoch 031 - generator training loss: -0.0973, discriminator training loss: 0.3326, validation loss: 0.1337
2024-05-25 04:38:31 [INFO]: Epoch 032 - generator training loss: -0.0973, discriminator training loss: 0.3307, validation loss: 0.1327
2024-05-25 04:38:35 [INFO]: Epoch 033 - generator training loss: -0.0958, discriminator training loss: 0.3279, validation loss: 0.1316
2024-05-25 04:38:39 [INFO]: Epoch 034 - generator training loss: -0.0978, discriminator training loss: 0.3265, validation loss: 0.1306
2024-05-25 04:38:43 [INFO]: Epoch 035 - generator training loss: -0.0957, discriminator training loss: 0.3244, validation loss: 0.1291
2024-05-25 04:38:47 [INFO]: Epoch 036 - generator training loss: -0.0979, discriminator training loss: 0.3228, validation loss: 0.1279
2024-05-25 04:38:51 [INFO]: Epoch 037 - generator training loss: -0.0973, discriminator training loss: 0.3213, validation loss: 0.1272
2024-05-25 04:38:55 [INFO]: Epoch 038 - generator training loss: -0.0973, discriminator training loss: 0.3203, validation loss: 0.1266
2024-05-25 04:38:59 [INFO]: Epoch 039 - generator training loss: -0.0977, discriminator training loss: 0.3191, validation loss: 0.1252
2024-05-25 04:39:04 [INFO]: Epoch 040 - generator training loss: -0.0984, discriminator training loss: 0.3178, validation loss: 0.1250
2024-05-25 04:39:08 [INFO]: Epoch 041 - generator training loss: -0.0988, discriminator training loss: 0.3171, validation loss: 0.1239
2024-05-25 04:39:12 [INFO]: Epoch 042 - generator training loss: -0.0994, discriminator training loss: 0.3169, validation loss: 0.1231
2024-05-25 04:39:16 [INFO]: Epoch 043 - generator training loss: -0.0993, discriminator training loss: 0.3153, validation loss: 0.1225
2024-05-25 04:39:21 [INFO]: Epoch 044 - generator training loss: -0.0998, discriminator training loss: 0.3143, validation loss: 0.1221
2024-05-25 04:39:25 [INFO]: Epoch 045 - generator training loss: -0.0996, discriminator training loss: 0.3137, validation loss: 0.1210
2024-05-25 04:39:29 [INFO]: Epoch 046 - generator training loss: -0.0997, discriminator training loss: 0.3129, validation loss: 0.1200
2024-05-25 04:39:33 [INFO]: Epoch 047 - generator training loss: -0.1016, discriminator training loss: 0.3122, validation loss: 0.1193
2024-05-25 04:39:37 [INFO]: Epoch 048 - generator training loss: -0.1022, discriminator training loss: 0.3116, validation loss: 0.1188
2024-05-25 04:39:41 [INFO]: Epoch 049 - generator training loss: -0.1023, discriminator training loss: 0.3115, validation loss: 0.1184
2024-05-25 04:39:45 [INFO]: Epoch 050 - generator training loss: -0.1024, discriminator training loss: 0.3105, validation loss: 0.1177
2024-05-25 04:39:49 [INFO]: Epoch 051 - generator training loss: -0.1020, discriminator training loss: 0.3104, validation loss: 0.1171
2024-05-25 04:39:53 [INFO]: Epoch 052 - generator training loss: -0.1034, discriminator training loss: 0.3099, validation loss: 0.1167
2024-05-25 04:39:58 [INFO]: Epoch 053 - generator training loss: -0.1023, discriminator training loss: 0.3095, validation loss: 0.1162
2024-05-25 04:40:02 [INFO]: Epoch 054 - generator training loss: -0.1048, discriminator training loss: 0.3091, validation loss: 0.1161
2024-05-25 04:40:06 [INFO]: Epoch 055 - generator training loss: -0.1029, discriminator training loss: 0.3090, validation loss: 0.1152
2024-05-25 04:40:10 [INFO]: Epoch 056 - generator training loss: -0.1050, discriminator training loss: 0.3087, validation loss: 0.1151
2024-05-25 04:40:14 [INFO]: Epoch 057 - generator training loss: -0.1050, discriminator training loss: 0.3078, validation loss: 0.1147
2024-05-25 04:40:18 [INFO]: Epoch 058 - generator training loss: -0.1058, discriminator training loss: 0.3076, validation loss: 0.1142
2024-05-25 04:40:22 [INFO]: Epoch 059 - generator training loss: -0.1051, discriminator training loss: 0.3074, validation loss: 0.1142
2024-05-25 04:40:26 [INFO]: Epoch 060 - generator training loss: -0.1064, discriminator training loss: 0.3075, validation loss: 0.1132
2024-05-25 04:40:30 [INFO]: Epoch 061 - generator training loss: -0.1070, discriminator training loss: 0.3068, validation loss: 0.1130
2024-05-25 04:40:34 [INFO]: Epoch 062 - generator training loss: -0.1082, discriminator training loss: 0.3067, validation loss: 0.1129
2024-05-25 04:40:38 [INFO]: Epoch 063 - generator training loss: -0.1072, discriminator training loss: 0.3063, validation loss: 0.1122
2024-05-25 04:40:43 [INFO]: Epoch 064 - generator training loss: -0.1081, discriminator training loss: 0.3068, validation loss: 0.1114
2024-05-25 04:40:47 [INFO]: Epoch 065 - generator training loss: -0.1085, discriminator training loss: 0.3060, validation loss: 0.1116
2024-05-25 04:40:51 [INFO]: Epoch 066 - generator training loss: -0.1096, discriminator training loss: 0.3061, validation loss: 0.1113
2024-05-25 04:40:55 [INFO]: Epoch 067 - generator training loss: -0.1093, discriminator training loss: 0.3053, validation loss: 0.1108
2024-05-25 04:40:59 [INFO]: Epoch 068 - generator training loss: -0.1100, discriminator training loss: 0.3051, validation loss: 0.1107
2024-05-25 04:41:03 [INFO]: Epoch 069 - generator training loss: -0.1102, discriminator training loss: 0.3054, validation loss: 0.1113
2024-05-25 04:41:07 [INFO]: Epoch 070 - generator training loss: -0.1103, discriminator training loss: 0.3052, validation loss: 0.1103
2024-05-25 04:41:11 [INFO]: Epoch 071 - generator training loss: -0.1101, discriminator training loss: 0.3045, validation loss: 0.1104
2024-05-25 04:41:15 [INFO]: Epoch 072 - generator training loss: -0.1094, discriminator training loss: 0.3050, validation loss: 0.1102
2024-05-25 04:41:19 [INFO]: Epoch 073 - generator training loss: -0.1112, discriminator training loss: 0.3043, validation loss: 0.1099
2024-05-25 04:41:24 [INFO]: Epoch 074 - generator training loss: -0.1115, discriminator training loss: 0.3039, validation loss: 0.1097
2024-05-25 04:41:28 [INFO]: Epoch 075 - generator training loss: -0.1118, discriminator training loss: 0.3042, validation loss: 0.1100
2024-05-25 04:41:32 [INFO]: Epoch 076 - generator training loss: -0.1123, discriminator training loss: 0.3038, validation loss: 0.1089
2024-05-25 04:41:36 [INFO]: Epoch 077 - generator training loss: -0.1127, discriminator training loss: 0.3036, validation loss: 0.1094
2024-05-25 04:41:40 [INFO]: Epoch 078 - generator training loss: -0.1125, discriminator training loss: 0.3040, validation loss: 0.1091
2024-05-25 04:41:44 [INFO]: Epoch 079 - generator training loss: -0.1145, discriminator training loss: 0.3033, validation loss: 0.1080
2024-05-25 04:41:48 [INFO]: Epoch 080 - generator training loss: -0.1145, discriminator training loss: 0.3030, validation loss: 0.1084
2024-05-25 04:41:52 [INFO]: Epoch 081 - generator training loss: -0.1149, discriminator training loss: 0.3030, validation loss: 0.1086
2024-05-25 04:41:56 [INFO]: Epoch 082 - generator training loss: -0.1146, discriminator training loss: 0.3030, validation loss: 0.1081
2024-05-25 04:42:00 [INFO]: Epoch 083 - generator training loss: -0.1147, discriminator training loss: 0.3032, validation loss: 0.1079
2024-05-25 04:42:04 [INFO]: Epoch 084 - generator training loss: -0.1152, discriminator training loss: 0.3028, validation loss: 0.1081
2024-05-25 04:42:09 [INFO]: Epoch 085 - generator training loss: -0.1148, discriminator training loss: 0.3025, validation loss: 0.1083
2024-05-25 04:42:13 [INFO]: Epoch 086 - generator training loss: -0.1155, discriminator training loss: 0.3027, validation loss: 0.1073
2024-05-25 04:42:17 [INFO]: Epoch 087 - generator training loss: -0.1158, discriminator training loss: 0.3024, validation loss: 0.1075
2024-05-25 04:42:21 [INFO]: Epoch 088 - generator training loss: -0.1166, discriminator training loss: 0.3024, validation loss: 0.1071
2024-05-25 04:42:25 [INFO]: Epoch 089 - generator training loss: -0.1164, discriminator training loss: 0.3018, validation loss: 0.1076
2024-05-25 04:42:29 [INFO]: Epoch 090 - generator training loss: -0.1175, discriminator training loss: 0.3020, validation loss: 0.1071
2024-05-25 04:42:33 [INFO]: Epoch 091 - generator training loss: -0.1177, discriminator training loss: 0.3019, validation loss: 0.1075
2024-05-25 04:42:37 [INFO]: Epoch 092 - generator training loss: -0.1171, discriminator training loss: 0.3016, validation loss: 0.1074
2024-05-25 04:42:41 [INFO]: Epoch 093 - generator training loss: -0.1175, discriminator training loss: 0.3017, validation loss: 0.1074
2024-05-25 04:42:45 [INFO]: Epoch 094 - generator training loss: -0.1184, discriminator training loss: 0.3015, validation loss: 0.1065
2024-05-25 04:42:49 [INFO]: Epoch 095 - generator training loss: -0.1189, discriminator training loss: 0.3013, validation loss: 0.1069
2024-05-25 04:42:54 [INFO]: Epoch 096 - generator training loss: -0.1183, discriminator training loss: 0.3015, validation loss: 0.1064
2024-05-25 04:42:58 [INFO]: Epoch 097 - generator training loss: -0.1185, discriminator training loss: 0.3009, validation loss: 0.1061
2024-05-25 04:43:02 [INFO]: Epoch 098 - generator training loss: -0.1200, discriminator training loss: 0.3010, validation loss: 0.1070
2024-05-25 04:43:06 [INFO]: Epoch 099 - generator training loss: -0.1194, discriminator training loss: 0.3012, validation loss: 0.1067
2024-05-25 04:43:10 [INFO]: Epoch 100 - generator training loss: -0.1203, discriminator training loss: 0.3005, validation loss: 0.1062
2024-05-25 04:43:14 [INFO]: Epoch 101 - generator training loss: -0.1203, discriminator training loss: 0.3006, validation loss: 0.1070
2024-05-25 04:43:18 [INFO]: Epoch 102 - generator training loss: -0.1197, discriminator training loss: 0.3008, validation loss: 0.1066
2024-05-25 04:43:22 [INFO]: Epoch 103 - generator training loss: -0.1210, discriminator training loss: 0.3006, validation loss: 0.1066
2024-05-25 04:43:26 [INFO]: Epoch 104 - generator training loss: -0.1208, discriminator training loss: 0.3005, validation loss: 0.1064
2024-05-25 04:43:30 [INFO]: Epoch 105 - generator training loss: -0.1210, discriminator training loss: 0.3004, validation loss: 0.1064
2024-05-25 04:43:35 [INFO]: Epoch 106 - generator training loss: -0.1203, discriminator training loss: 0.3002, validation loss: 0.1063
2024-05-25 04:43:39 [INFO]: Epoch 107 - generator training loss: -0.1220, discriminator training loss: 0.2999, validation loss: 0.1065
2024-05-25 04:43:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:43:39 [INFO]: Finished training. The best model is from epoch#97.
2024-05-25 04:43:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/USGAN_air_quality/20240525_T043620/USGAN.pypots
2024-05-25 04:43:39 [INFO]: US-GAN on Air-Quality: MAE=0.1684, MSE=0.1426
2024-05-25 04:43:39 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/USGAN_air_quality/imputation.pkl
2024-05-25 04:43:39 [INFO]: Using the given device: cuda:0
2024-05-25 04:43:39 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/BRITS_air_quality/20240525_T044339
2024-05-25 04:43:39 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/BRITS_air_quality/20240525_T044339/tensorboard
2024-05-25 04:43:39 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 04:43:43 [INFO]: Epoch 001 - training loss: 1.4307, validation loss: 0.9537
2024-05-25 04:43:46 [INFO]: Epoch 002 - training loss: 1.1650, validation loss: 0.6923
2024-05-25 04:43:48 [INFO]: Epoch 003 - training loss: 0.9698, validation loss: 0.5824
2024-05-25 04:43:51 [INFO]: Epoch 004 - training loss: 0.8613, validation loss: 0.5136
2024-05-25 04:43:54 [INFO]: Epoch 005 - training loss: 0.7869, validation loss: 0.4659
2024-05-25 04:43:57 [INFO]: Epoch 006 - training loss: 0.7307, validation loss: 0.4294
2024-05-25 04:44:00 [INFO]: Epoch 007 - training loss: 0.6888, validation loss: 0.4012
2024-05-25 04:44:02 [INFO]: Epoch 008 - training loss: 0.6549, validation loss: 0.3775
2024-05-25 04:44:05 [INFO]: Epoch 009 - training loss: 0.6280, validation loss: 0.3586
2024-05-25 04:44:08 [INFO]: Epoch 010 - training loss: 0.6072, validation loss: 0.3426
2024-05-25 04:44:11 [INFO]: Epoch 011 - training loss: 0.5918, validation loss: 0.3284
2024-05-25 04:44:13 [INFO]: Epoch 012 - training loss: 0.5749, validation loss: 0.3160
2024-05-25 04:44:16 [INFO]: Epoch 013 - training loss: 0.5600, validation loss: 0.3056
2024-05-25 04:44:19 [INFO]: Epoch 014 - training loss: 0.5488, validation loss: 0.2972
2024-05-25 04:44:22 [INFO]: Epoch 015 - training loss: 0.5380, validation loss: 0.2878
2024-05-25 04:44:24 [INFO]: Epoch 016 - training loss: 0.5274, validation loss: 0.2810
2024-05-25 04:44:27 [INFO]: Epoch 017 - training loss: 0.5185, validation loss: 0.2739
2024-05-25 04:44:30 [INFO]: Epoch 018 - training loss: 0.5094, validation loss: 0.2682
2024-05-25 04:44:33 [INFO]: Epoch 019 - training loss: 0.5016, validation loss: 0.2622
2024-05-25 04:44:35 [INFO]: Epoch 020 - training loss: 0.4938, validation loss: 0.2567
2024-05-25 04:44:38 [INFO]: Epoch 021 - training loss: 0.4857, validation loss: 0.2517
2024-05-25 04:44:41 [INFO]: Epoch 022 - training loss: 0.4797, validation loss: 0.2472
2024-05-25 04:44:44 [INFO]: Epoch 023 - training loss: 0.4726, validation loss: 0.2427
2024-05-25 04:44:46 [INFO]: Epoch 024 - training loss: 0.4671, validation loss: 0.2385
2024-05-25 04:44:49 [INFO]: Epoch 025 - training loss: 0.4609, validation loss: 0.2349
2024-05-25 04:44:52 [INFO]: Epoch 026 - training loss: 0.4546, validation loss: 0.2310
2024-05-25 04:44:55 [INFO]: Epoch 027 - training loss: 0.4495, validation loss: 0.2275
2024-05-25 04:44:57 [INFO]: Epoch 028 - training loss: 0.4434, validation loss: 0.2245
2024-05-25 04:45:00 [INFO]: Epoch 029 - training loss: 0.4388, validation loss: 0.2208
2024-05-25 04:45:03 [INFO]: Epoch 030 - training loss: 0.4346, validation loss: 0.2177
2024-05-25 04:45:06 [INFO]: Epoch 031 - training loss: 0.4290, validation loss: 0.2146
2024-05-25 04:45:08 [INFO]: Epoch 032 - training loss: 0.4251, validation loss: 0.2116
2024-05-25 04:45:11 [INFO]: Epoch 033 - training loss: 0.4197, validation loss: 0.2092
2024-05-25 04:45:14 [INFO]: Epoch 034 - training loss: 0.4163, validation loss: 0.2064
2024-05-25 04:45:17 [INFO]: Epoch 035 - training loss: 0.4124, validation loss: 0.2039
2024-05-25 04:45:19 [INFO]: Epoch 036 - training loss: 0.4089, validation loss: 0.2010
2024-05-25 04:45:22 [INFO]: Epoch 037 - training loss: 0.4040, validation loss: 0.1987
2024-05-25 04:45:25 [INFO]: Epoch 038 - training loss: 0.4005, validation loss: 0.1963
2024-05-25 04:45:28 [INFO]: Epoch 039 - training loss: 0.3969, validation loss: 0.1942
2024-05-25 04:45:31 [INFO]: Epoch 040 - training loss: 0.3937, validation loss: 0.1921
2024-05-25 04:45:33 [INFO]: Epoch 041 - training loss: 0.3910, validation loss: 0.1898
2024-05-25 04:45:36 [INFO]: Epoch 042 - training loss: 0.3868, validation loss: 0.1877
2024-05-25 04:45:39 [INFO]: Epoch 043 - training loss: 0.3842, validation loss: 0.1858
2024-05-25 04:45:42 [INFO]: Epoch 044 - training loss: 0.3818, validation loss: 0.1841
2024-05-25 04:45:44 [INFO]: Epoch 045 - training loss: 0.3789, validation loss: 0.1823
2024-05-25 04:45:47 [INFO]: Epoch 046 - training loss: 0.3761, validation loss: 0.1801
2024-05-25 04:45:50 [INFO]: Epoch 047 - training loss: 0.3732, validation loss: 0.1785
2024-05-25 04:45:53 [INFO]: Epoch 048 - training loss: 0.3724, validation loss: 0.1768
2024-05-25 04:45:55 [INFO]: Epoch 049 - training loss: 0.3684, validation loss: 0.1753
2024-05-25 04:45:58 [INFO]: Epoch 050 - training loss: 0.3661, validation loss: 0.1736
2024-05-25 04:46:01 [INFO]: Epoch 051 - training loss: 0.3641, validation loss: 0.1721
2024-05-25 04:46:04 [INFO]: Epoch 052 - training loss: 0.3616, validation loss: 0.1710
2024-05-25 04:46:06 [INFO]: Epoch 053 - training loss: 0.3596, validation loss: 0.1695
2024-05-25 04:46:09 [INFO]: Epoch 054 - training loss: 0.3572, validation loss: 0.1681
2024-05-25 04:46:12 [INFO]: Epoch 055 - training loss: 0.3551, validation loss: 0.1669
2024-05-25 04:46:15 [INFO]: Epoch 056 - training loss: 0.3529, validation loss: 0.1657
2024-05-25 04:46:17 [INFO]: Epoch 057 - training loss: 0.3513, validation loss: 0.1645
2024-05-25 04:46:20 [INFO]: Epoch 058 - training loss: 0.3496, validation loss: 0.1637
2024-05-25 04:46:23 [INFO]: Epoch 059 - training loss: 0.3477, validation loss: 0.1628
2024-05-25 04:46:26 [INFO]: Epoch 060 - training loss: 0.3456, validation loss: 0.1616
2024-05-25 04:46:28 [INFO]: Epoch 061 - training loss: 0.3439, validation loss: 0.1607
2024-05-25 04:46:31 [INFO]: Epoch 062 - training loss: 0.3424, validation loss: 0.1597
2024-05-25 04:46:34 [INFO]: Epoch 063 - training loss: 0.3412, validation loss: 0.1588
2024-05-25 04:46:37 [INFO]: Epoch 064 - training loss: 0.3399, validation loss: 0.1581
2024-05-25 04:46:39 [INFO]: Epoch 065 - training loss: 0.3383, validation loss: 0.1574
2024-05-25 04:46:42 [INFO]: Epoch 066 - training loss: 0.3368, validation loss: 0.1563
2024-05-25 04:46:45 [INFO]: Epoch 067 - training loss: 0.3353, validation loss: 0.1558
2024-05-25 04:46:48 [INFO]: Epoch 068 - training loss: 0.3331, validation loss: 0.1551
2024-05-25 04:46:50 [INFO]: Epoch 069 - training loss: 0.3329, validation loss: 0.1544
2024-05-25 04:46:53 [INFO]: Epoch 070 - training loss: 0.3319, validation loss: 0.1536
2024-05-25 04:46:56 [INFO]: Epoch 071 - training loss: 0.3301, validation loss: 0.1531
2024-05-25 04:46:59 [INFO]: Epoch 072 - training loss: 0.3294, validation loss: 0.1524
2024-05-25 04:47:01 [INFO]: Epoch 073 - training loss: 0.3275, validation loss: 0.1517
2024-05-25 04:47:04 [INFO]: Epoch 074 - training loss: 0.3263, validation loss: 0.1511
2024-05-25 04:47:07 [INFO]: Epoch 075 - training loss: 0.3264, validation loss: 0.1507
2024-05-25 04:47:10 [INFO]: Epoch 076 - training loss: 0.3248, validation loss: 0.1500
2024-05-25 04:47:12 [INFO]: Epoch 077 - training loss: 0.3232, validation loss: 0.1495
2024-05-25 04:47:15 [INFO]: Epoch 078 - training loss: 0.3227, validation loss: 0.1490
2024-05-25 04:47:18 [INFO]: Epoch 079 - training loss: 0.3215, validation loss: 0.1486
2024-05-25 04:47:21 [INFO]: Epoch 080 - training loss: 0.3208, validation loss: 0.1483
2024-05-25 04:47:24 [INFO]: Epoch 081 - training loss: 0.3188, validation loss: 0.1476
2024-05-25 04:47:26 [INFO]: Epoch 082 - training loss: 0.3186, validation loss: 0.1471
2024-05-25 04:47:29 [INFO]: Epoch 083 - training loss: 0.3178, validation loss: 0.1466
2024-05-25 04:47:32 [INFO]: Epoch 084 - training loss: 0.3169, validation loss: 0.1463
2024-05-25 04:47:35 [INFO]: Epoch 085 - training loss: 0.3159, validation loss: 0.1458
2024-05-25 04:47:37 [INFO]: Epoch 086 - training loss: 0.3156, validation loss: 0.1452
2024-05-25 04:47:40 [INFO]: Epoch 087 - training loss: 0.3147, validation loss: 0.1449
2024-05-25 04:47:43 [INFO]: Epoch 088 - training loss: 0.3143, validation loss: 0.1444
2024-05-25 04:47:46 [INFO]: Epoch 089 - training loss: 0.3127, validation loss: 0.1441
2024-05-25 04:47:48 [INFO]: Epoch 090 - training loss: 0.3116, validation loss: 0.1439
2024-05-25 04:47:51 [INFO]: Epoch 091 - training loss: 0.3117, validation loss: 0.1433
2024-05-25 04:47:54 [INFO]: Epoch 092 - training loss: 0.3106, validation loss: 0.1431
2024-05-25 04:47:57 [INFO]: Epoch 093 - training loss: 0.3103, validation loss: 0.1428
2024-05-25 04:47:59 [INFO]: Epoch 094 - training loss: 0.3094, validation loss: 0.1424
2024-05-25 04:48:02 [INFO]: Epoch 095 - training loss: 0.3081, validation loss: 0.1421
2024-05-25 04:48:05 [INFO]: Epoch 096 - training loss: 0.3076, validation loss: 0.1414
2024-05-25 04:48:08 [INFO]: Epoch 097 - training loss: 0.3077, validation loss: 0.1412
2024-05-25 04:48:10 [INFO]: Epoch 098 - training loss: 0.3070, validation loss: 0.1411
2024-05-25 04:48:13 [INFO]: Epoch 099 - training loss: 0.3062, validation loss: 0.1407
2024-05-25 04:48:16 [INFO]: Epoch 100 - training loss: 0.3049, validation loss: 0.1403
2024-05-25 04:48:19 [INFO]: Epoch 101 - training loss: 0.3045, validation loss: 0.1401
2024-05-25 04:48:21 [INFO]: Epoch 102 - training loss: 0.3035, validation loss: 0.1396
2024-05-25 04:48:24 [INFO]: Epoch 103 - training loss: 0.3032, validation loss: 0.1395
2024-05-25 04:48:27 [INFO]: Epoch 104 - training loss: 0.3024, validation loss: 0.1390
2024-05-25 04:48:30 [INFO]: Epoch 105 - training loss: 0.3018, validation loss: 0.1385
2024-05-25 04:48:32 [INFO]: Epoch 106 - training loss: 0.3012, validation loss: 0.1385
2024-05-25 04:48:35 [INFO]: Epoch 107 - training loss: 0.3013, validation loss: 0.1382
2024-05-25 04:48:38 [INFO]: Epoch 108 - training loss: 0.3004, validation loss: 0.1378
2024-05-25 04:48:41 [INFO]: Epoch 109 - training loss: 0.3000, validation loss: 0.1377
2024-05-25 04:48:44 [INFO]: Epoch 110 - training loss: 0.2987, validation loss: 0.1374
2024-05-25 04:48:46 [INFO]: Epoch 111 - training loss: 0.2997, validation loss: 0.1368
2024-05-25 04:48:49 [INFO]: Epoch 112 - training loss: 0.2979, validation loss: 0.1367
2024-05-25 04:48:52 [INFO]: Epoch 113 - training loss: 0.2974, validation loss: 0.1364
2024-05-25 04:48:55 [INFO]: Epoch 114 - training loss: 0.2973, validation loss: 0.1362
2024-05-25 04:48:57 [INFO]: Epoch 115 - training loss: 0.2963, validation loss: 0.1359
2024-05-25 04:49:00 [INFO]: Epoch 116 - training loss: 0.2959, validation loss: 0.1357
2024-05-25 04:49:03 [INFO]: Epoch 117 - training loss: 0.2954, validation loss: 0.1354
2024-05-25 04:49:06 [INFO]: Epoch 118 - training loss: 0.2952, validation loss: 0.1350
2024-05-25 04:49:08 [INFO]: Epoch 119 - training loss: 0.2952, validation loss: 0.1346
2024-05-25 04:49:11 [INFO]: Epoch 120 - training loss: 0.2943, validation loss: 0.1348
2024-05-25 04:49:14 [INFO]: Epoch 121 - training loss: 0.2938, validation loss: 0.1341
2024-05-25 04:49:17 [INFO]: Epoch 122 - training loss: 0.2935, validation loss: 0.1339
2024-05-25 04:49:19 [INFO]: Epoch 123 - training loss: 0.2926, validation loss: 0.1337
2024-05-25 04:49:22 [INFO]: Epoch 124 - training loss: 0.2926, validation loss: 0.1336
2024-05-25 04:49:25 [INFO]: Epoch 125 - training loss: 0.2925, validation loss: 0.1331
2024-05-25 04:49:28 [INFO]: Epoch 126 - training loss: 0.2918, validation loss: 0.1329
2024-05-25 04:49:30 [INFO]: Epoch 127 - training loss: 0.2909, validation loss: 0.1329
2024-05-25 04:49:33 [INFO]: Epoch 128 - training loss: 0.2905, validation loss: 0.1324
2024-05-25 04:49:36 [INFO]: Epoch 129 - training loss: 0.2903, validation loss: 0.1322
2024-05-25 04:49:39 [INFO]: Epoch 130 - training loss: 0.2894, validation loss: 0.1319
2024-05-25 04:49:41 [INFO]: Epoch 131 - training loss: 0.2889, validation loss: 0.1316
2024-05-25 04:49:44 [INFO]: Epoch 132 - training loss: 0.2893, validation loss: 0.1314
2024-05-25 04:49:47 [INFO]: Epoch 133 - training loss: 0.2885, validation loss: 0.1312
2024-05-25 04:49:50 [INFO]: Epoch 134 - training loss: 0.2879, validation loss: 0.1310
2024-05-25 04:49:52 [INFO]: Epoch 135 - training loss: 0.2874, validation loss: 0.1309
2024-05-25 04:49:55 [INFO]: Epoch 136 - training loss: 0.2874, validation loss: 0.1306
2024-05-25 04:49:58 [INFO]: Epoch 137 - training loss: 0.2867, validation loss: 0.1302
2024-05-25 04:50:01 [INFO]: Epoch 138 - training loss: 0.2864, validation loss: 0.1302
2024-05-25 04:50:03 [INFO]: Epoch 139 - training loss: 0.2871, validation loss: 0.1299
2024-05-25 04:50:06 [INFO]: Epoch 140 - training loss: 0.2861, validation loss: 0.1296
2024-05-25 04:50:09 [INFO]: Epoch 141 - training loss: 0.2854, validation loss: 0.1295
2024-05-25 04:50:12 [INFO]: Epoch 142 - training loss: 0.2851, validation loss: 0.1293
2024-05-25 04:50:14 [INFO]: Epoch 143 - training loss: 0.2856, validation loss: 0.1291
2024-05-25 04:50:17 [INFO]: Epoch 144 - training loss: 0.2840, validation loss: 0.1289
2024-05-25 04:50:20 [INFO]: Epoch 145 - training loss: 0.2842, validation loss: 0.1288
2024-05-25 04:50:23 [INFO]: Epoch 146 - training loss: 0.2832, validation loss: 0.1285
2024-05-25 04:50:25 [INFO]: Epoch 147 - training loss: 0.2828, validation loss: 0.1283
2024-05-25 04:50:28 [INFO]: Epoch 148 - training loss: 0.2823, validation loss: 0.1282
2024-05-25 04:50:31 [INFO]: Epoch 149 - training loss: 0.2827, validation loss: 0.1278
2024-05-25 04:50:34 [INFO]: Epoch 150 - training loss: 0.2820, validation loss: 0.1275
2024-05-25 04:50:37 [INFO]: Epoch 151 - training loss: 0.2823, validation loss: 0.1274
2024-05-25 04:50:39 [INFO]: Epoch 152 - training loss: 0.2813, validation loss: 0.1273
2024-05-25 04:50:42 [INFO]: Epoch 153 - training loss: 0.2814, validation loss: 0.1270
2024-05-25 04:50:45 [INFO]: Epoch 154 - training loss: 0.2810, validation loss: 0.1270
2024-05-25 04:50:48 [INFO]: Epoch 155 - training loss: 0.2809, validation loss: 0.1266
2024-05-25 04:50:50 [INFO]: Epoch 156 - training loss: 0.2800, validation loss: 0.1266
2024-05-25 04:50:53 [INFO]: Epoch 157 - training loss: 0.2805, validation loss: 0.1265
2024-05-25 04:50:56 [INFO]: Epoch 158 - training loss: 0.2797, validation loss: 0.1261
2024-05-25 04:50:59 [INFO]: Epoch 159 - training loss: 0.2788, validation loss: 0.1260
2024-05-25 04:51:01 [INFO]: Epoch 160 - training loss: 0.2789, validation loss: 0.1258
2024-05-25 04:51:04 [INFO]: Epoch 161 - training loss: 0.2784, validation loss: 0.1256
2024-05-25 04:51:07 [INFO]: Epoch 162 - training loss: 0.2792, validation loss: 0.1253
2024-05-25 04:51:10 [INFO]: Epoch 163 - training loss: 0.2781, validation loss: 0.1252
2024-05-25 04:51:12 [INFO]: Epoch 164 - training loss: 0.2780, validation loss: 0.1249
2024-05-25 04:51:15 [INFO]: Epoch 165 - training loss: 0.2777, validation loss: 0.1249
2024-05-25 04:51:18 [INFO]: Epoch 166 - training loss: 0.2770, validation loss: 0.1248
2024-05-25 04:51:21 [INFO]: Epoch 167 - training loss: 0.2773, validation loss: 0.1245
2024-05-25 04:51:23 [INFO]: Epoch 168 - training loss: 0.2767, validation loss: 0.1244
2024-05-25 04:51:26 [INFO]: Epoch 169 - training loss: 0.2763, validation loss: 0.1243
2024-05-25 04:51:29 [INFO]: Epoch 170 - training loss: 0.2763, validation loss: 0.1241
2024-05-25 04:51:32 [INFO]: Epoch 171 - training loss: 0.2753, validation loss: 0.1239
2024-05-25 04:51:34 [INFO]: Epoch 172 - training loss: 0.2754, validation loss: 0.1237
2024-05-25 04:51:37 [INFO]: Epoch 173 - training loss: 0.2755, validation loss: 0.1236
2024-05-25 04:51:40 [INFO]: Epoch 174 - training loss: 0.2750, validation loss: 0.1233
2024-05-25 04:51:43 [INFO]: Epoch 175 - training loss: 0.2739, validation loss: 0.1235
2024-05-25 04:51:45 [INFO]: Epoch 176 - training loss: 0.2739, validation loss: 0.1231
2024-05-25 04:51:48 [INFO]: Epoch 177 - training loss: 0.2743, validation loss: 0.1230
2024-05-25 04:51:51 [INFO]: Epoch 178 - training loss: 0.2742, validation loss: 0.1229
2024-05-25 04:51:54 [INFO]: Epoch 179 - training loss: 0.2738, validation loss: 0.1226
2024-05-25 04:51:56 [INFO]: Epoch 180 - training loss: 0.2732, validation loss: 0.1226
2024-05-25 04:51:59 [INFO]: Epoch 181 - training loss: 0.2726, validation loss: 0.1225
2024-05-25 04:52:02 [INFO]: Epoch 182 - training loss: 0.2726, validation loss: 0.1224
2024-05-25 04:52:05 [INFO]: Epoch 183 - training loss: 0.2728, validation loss: 0.1222
2024-05-25 04:52:07 [INFO]: Epoch 184 - training loss: 0.2726, validation loss: 0.1220
2024-05-25 04:52:10 [INFO]: Epoch 185 - training loss: 0.2728, validation loss: 0.1218
2024-05-25 04:52:13 [INFO]: Epoch 186 - training loss: 0.2718, validation loss: 0.1217
2024-05-25 04:52:16 [INFO]: Epoch 187 - training loss: 0.2716, validation loss: 0.1217
2024-05-25 04:52:18 [INFO]: Epoch 188 - training loss: 0.2711, validation loss: 0.1214
2024-05-25 04:52:21 [INFO]: Epoch 189 - training loss: 0.2713, validation loss: 0.1213
2024-05-25 04:52:24 [INFO]: Epoch 190 - training loss: 0.2712, validation loss: 0.1211
2024-05-25 04:52:27 [INFO]: Epoch 191 - training loss: 0.2703, validation loss: 0.1210
2024-05-25 04:52:29 [INFO]: Epoch 192 - training loss: 0.2705, validation loss: 0.1209
2024-05-25 04:52:32 [INFO]: Epoch 193 - training loss: 0.2703, validation loss: 0.1208
2024-05-25 04:52:35 [INFO]: Epoch 194 - training loss: 0.2699, validation loss: 0.1206
2024-05-25 04:52:38 [INFO]: Epoch 195 - training loss: 0.2695, validation loss: 0.1205
2024-05-25 04:52:40 [INFO]: Epoch 196 - training loss: 0.2691, validation loss: 0.1204
2024-05-25 04:52:43 [INFO]: Epoch 197 - training loss: 0.2693, validation loss: 0.1203
2024-05-25 04:52:46 [INFO]: Epoch 198 - training loss: 0.2685, validation loss: 0.1201
2024-05-25 04:52:49 [INFO]: Epoch 199 - training loss: 0.2692, validation loss: 0.1200
2024-05-25 04:52:51 [INFO]: Epoch 200 - training loss: 0.2684, validation loss: 0.1200
2024-05-25 04:52:54 [INFO]: Epoch 201 - training loss: 0.2681, validation loss: 0.1199
2024-05-25 04:52:57 [INFO]: Epoch 202 - training loss: 0.2678, validation loss: 0.1198
2024-05-25 04:53:00 [INFO]: Epoch 203 - training loss: 0.2688, validation loss: 0.1197
2024-05-25 04:53:02 [INFO]: Epoch 204 - training loss: 0.2682, validation loss: 0.1195
2024-05-25 04:53:05 [INFO]: Epoch 205 - training loss: 0.2676, validation loss: 0.1194
2024-05-25 04:53:08 [INFO]: Epoch 206 - training loss: 0.2670, validation loss: 0.1193
2024-05-25 04:53:11 [INFO]: Epoch 207 - training loss: 0.2667, validation loss: 0.1193
2024-05-25 04:53:13 [INFO]: Epoch 208 - training loss: 0.2667, validation loss: 0.1190
2024-05-25 04:53:16 [INFO]: Epoch 209 - training loss: 0.2667, validation loss: 0.1190
2024-05-25 04:53:19 [INFO]: Epoch 210 - training loss: 0.2662, validation loss: 0.1188
2024-05-25 04:53:22 [INFO]: Epoch 211 - training loss: 0.2658, validation loss: 0.1187
2024-05-25 04:53:25 [INFO]: Epoch 212 - training loss: 0.2654, validation loss: 0.1186
2024-05-25 04:53:27 [INFO]: Epoch 213 - training loss: 0.2655, validation loss: 0.1184
2024-05-25 04:53:30 [INFO]: Epoch 214 - training loss: 0.2652, validation loss: 0.1184
2024-05-25 04:53:33 [INFO]: Epoch 215 - training loss: 0.2654, validation loss: 0.1182
2024-05-25 04:53:36 [INFO]: Epoch 216 - training loss: 0.2652, validation loss: 0.1182
2024-05-25 04:53:38 [INFO]: Epoch 217 - training loss: 0.2648, validation loss: 0.1181
2024-05-25 04:53:41 [INFO]: Epoch 218 - training loss: 0.2651, validation loss: 0.1183
2024-05-25 04:53:44 [INFO]: Epoch 219 - training loss: 0.2648, validation loss: 0.1179
2024-05-25 04:53:47 [INFO]: Epoch 220 - training loss: 0.2645, validation loss: 0.1178
2024-05-25 04:53:49 [INFO]: Epoch 221 - training loss: 0.2638, validation loss: 0.1177
2024-05-25 04:53:52 [INFO]: Epoch 222 - training loss: 0.2640, validation loss: 0.1176
2024-05-25 04:53:55 [INFO]: Epoch 223 - training loss: 0.2637, validation loss: 0.1174
2024-05-25 04:53:58 [INFO]: Epoch 224 - training loss: 0.2635, validation loss: 0.1175
2024-05-25 04:54:00 [INFO]: Epoch 225 - training loss: 0.2632, validation loss: 0.1174
2024-05-25 04:54:03 [INFO]: Epoch 226 - training loss: 0.2634, validation loss: 0.1174
2024-05-25 04:54:06 [INFO]: Epoch 227 - training loss: 0.2628, validation loss: 0.1172
2024-05-25 04:54:09 [INFO]: Epoch 228 - training loss: 0.2631, validation loss: 0.1171
2024-05-25 04:54:11 [INFO]: Epoch 229 - training loss: 0.2629, validation loss: 0.1171
2024-05-25 04:54:14 [INFO]: Epoch 230 - training loss: 0.2622, validation loss: 0.1169
2024-05-25 04:54:17 [INFO]: Epoch 231 - training loss: 0.2622, validation loss: 0.1168
2024-05-25 04:54:20 [INFO]: Epoch 232 - training loss: 0.2631, validation loss: 0.1166
2024-05-25 04:54:22 [INFO]: Epoch 233 - training loss: 0.2621, validation loss: 0.1168
2024-05-25 04:54:25 [INFO]: Epoch 234 - training loss: 0.2620, validation loss: 0.1167
2024-05-25 04:54:28 [INFO]: Epoch 235 - training loss: 0.2615, validation loss: 0.1165
2024-05-25 04:54:31 [INFO]: Epoch 236 - training loss: 0.2614, validation loss: 0.1164
2024-05-25 04:54:33 [INFO]: Epoch 237 - training loss: 0.2611, validation loss: 0.1164
2024-05-25 04:54:36 [INFO]: Epoch 238 - training loss: 0.2611, validation loss: 0.1165
2024-05-25 04:54:39 [INFO]: Epoch 239 - training loss: 0.2608, validation loss: 0.1162
2024-05-25 04:54:42 [INFO]: Epoch 240 - training loss: 0.2605, validation loss: 0.1161
2024-05-25 04:54:44 [INFO]: Epoch 241 - training loss: 0.2606, validation loss: 0.1163
2024-05-25 04:54:47 [INFO]: Epoch 242 - training loss: 0.2601, validation loss: 0.1160
2024-05-25 04:54:50 [INFO]: Epoch 243 - training loss: 0.2604, validation loss: 0.1160
2024-05-25 04:54:53 [INFO]: Epoch 244 - training loss: 0.2596, validation loss: 0.1159
2024-05-25 04:54:55 [INFO]: Epoch 245 - training loss: 0.2598, validation loss: 0.1160
2024-05-25 04:54:58 [INFO]: Epoch 246 - training loss: 0.2601, validation loss: 0.1157
2024-05-25 04:55:01 [INFO]: Epoch 247 - training loss: 0.2595, validation loss: 0.1157
2024-05-25 04:55:04 [INFO]: Epoch 248 - training loss: 0.2590, validation loss: 0.1157
2024-05-25 04:55:06 [INFO]: Epoch 249 - training loss: 0.2590, validation loss: 0.1156
2024-05-25 04:55:09 [INFO]: Epoch 250 - training loss: 0.2593, validation loss: 0.1155
2024-05-25 04:55:12 [INFO]: Epoch 251 - training loss: 0.2589, validation loss: 0.1153
2024-05-25 04:55:15 [INFO]: Epoch 252 - training loss: 0.2584, validation loss: 0.1153
2024-05-25 04:55:17 [INFO]: Epoch 253 - training loss: 0.2591, validation loss: 0.1153
2024-05-25 04:55:20 [INFO]: Epoch 254 - training loss: 0.2590, validation loss: 0.1152
2024-05-25 04:55:23 [INFO]: Epoch 255 - training loss: 0.2585, validation loss: 0.1152
2024-05-25 04:55:26 [INFO]: Epoch 256 - training loss: 0.2580, validation loss: 0.1151
2024-05-25 04:55:28 [INFO]: Epoch 257 - training loss: 0.2582, validation loss: 0.1149
2024-05-25 04:55:31 [INFO]: Epoch 258 - training loss: 0.2576, validation loss: 0.1148
2024-05-25 04:55:34 [INFO]: Epoch 259 - training loss: 0.2574, validation loss: 0.1148
2024-05-25 04:55:37 [INFO]: Epoch 260 - training loss: 0.2571, validation loss: 0.1150
2024-05-25 04:55:39 [INFO]: Epoch 261 - training loss: 0.2575, validation loss: 0.1147
2024-05-25 04:55:42 [INFO]: Epoch 262 - training loss: 0.2571, validation loss: 0.1148
2024-05-25 04:55:45 [INFO]: Epoch 263 - training loss: 0.2572, validation loss: 0.1147
2024-05-25 04:55:48 [INFO]: Epoch 264 - training loss: 0.2574, validation loss: 0.1146
2024-05-25 04:55:50 [INFO]: Epoch 265 - training loss: 0.2569, validation loss: 0.1145
2024-05-25 04:55:53 [INFO]: Epoch 266 - training loss: 0.2564, validation loss: 0.1147
2024-05-25 04:55:56 [INFO]: Epoch 267 - training loss: 0.2564, validation loss: 0.1146
2024-05-25 04:55:59 [INFO]: Epoch 268 - training loss: 0.2562, validation loss: 0.1145
2024-05-25 04:56:01 [INFO]: Epoch 269 - training loss: 0.2566, validation loss: 0.1145
2024-05-25 04:56:04 [INFO]: Epoch 270 - training loss: 0.2561, validation loss: 0.1143
2024-05-25 04:56:07 [INFO]: Epoch 271 - training loss: 0.2560, validation loss: 0.1143
2024-05-25 04:56:10 [INFO]: Epoch 272 - training loss: 0.2559, validation loss: 0.1143
2024-05-25 04:56:12 [INFO]: Epoch 273 - training loss: 0.2555, validation loss: 0.1142
2024-05-25 04:56:15 [INFO]: Epoch 274 - training loss: 0.2553, validation loss: 0.1143
2024-05-25 04:56:18 [INFO]: Epoch 275 - training loss: 0.2556, validation loss: 0.1140
2024-05-25 04:56:21 [INFO]: Epoch 276 - training loss: 0.2548, validation loss: 0.1139
2024-05-25 04:56:23 [INFO]: Epoch 277 - training loss: 0.2553, validation loss: 0.1140
2024-05-25 04:56:26 [INFO]: Epoch 278 - training loss: 0.2546, validation loss: 0.1139
2024-05-25 04:56:29 [INFO]: Epoch 279 - training loss: 0.2546, validation loss: 0.1140
2024-05-25 04:56:32 [INFO]: Epoch 280 - training loss: 0.2540, validation loss: 0.1139
2024-05-25 04:56:35 [INFO]: Epoch 281 - training loss: 0.2540, validation loss: 0.1139
2024-05-25 04:56:37 [INFO]: Epoch 282 - training loss: 0.2541, validation loss: 0.1137
2024-05-25 04:56:40 [INFO]: Epoch 283 - training loss: 0.2545, validation loss: 0.1138
2024-05-25 04:56:43 [INFO]: Epoch 284 - training loss: 0.2540, validation loss: 0.1136
2024-05-25 04:56:46 [INFO]: Epoch 285 - training loss: 0.2539, validation loss: 0.1134
2024-05-25 04:56:48 [INFO]: Epoch 286 - training loss: 0.2536, validation loss: 0.1137
2024-05-25 04:56:51 [INFO]: Epoch 287 - training loss: 0.2535, validation loss: 0.1137
2024-05-25 04:56:54 [INFO]: Epoch 288 - training loss: 0.2541, validation loss: 0.1136
2024-05-25 04:56:57 [INFO]: Epoch 289 - training loss: 0.2531, validation loss: 0.1137
2024-05-25 04:56:59 [INFO]: Epoch 290 - training loss: 0.2528, validation loss: 0.1133
2024-05-25 04:57:02 [INFO]: Epoch 291 - training loss: 0.2529, validation loss: 0.1134
2024-05-25 04:57:05 [INFO]: Epoch 292 - training loss: 0.2527, validation loss: 0.1134
2024-05-25 04:57:08 [INFO]: Epoch 293 - training loss: 0.2530, validation loss: 0.1135
2024-05-25 04:57:10 [INFO]: Epoch 294 - training loss: 0.2527, validation loss: 0.1131
2024-05-25 04:57:13 [INFO]: Epoch 295 - training loss: 0.2526, validation loss: 0.1133
2024-05-25 04:57:16 [INFO]: Epoch 296 - training loss: 0.2525, validation loss: 0.1132
2024-05-25 04:57:18 [INFO]: Epoch 297 - training loss: 0.2523, validation loss: 0.1132
2024-05-25 04:57:21 [INFO]: Epoch 298 - training loss: 0.2528, validation loss: 0.1131
2024-05-25 04:57:24 [INFO]: Epoch 299 - training loss: 0.2520, validation loss: 0.1131
2024-05-25 04:57:27 [INFO]: Epoch 300 - training loss: 0.2521, validation loss: 0.1132
2024-05-25 04:57:27 [INFO]: Finished training. The best model is from epoch#298.
2024-05-25 04:57:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/BRITS_air_quality/20240525_T044339/BRITS.pypots
2024-05-25 04:57:27 [INFO]: BRITS on Air-Quality: MAE=0.1531, MSE=0.1502
2024-05-25 04:57:27 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/BRITS_air_quality/imputation.pkl
2024-05-25 04:57:27 [INFO]: Using the given device: cuda:0
2024-05-25 04:57:27 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727
2024-05-25 04:57:27 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/tensorboard
2024-05-25 04:57:27 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 04:57:32 [INFO]: Epoch 001 - training loss: 1.3883, validation loss: 0.8086
2024-05-25 04:57:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch1_loss0.808632081747055.pypots
2024-05-25 04:57:36 [INFO]: Epoch 002 - training loss: 1.0120, validation loss: 0.7446
2024-05-25 04:57:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch2_loss0.744614553451538.pypots
2024-05-25 04:57:40 [INFO]: Epoch 003 - training loss: 0.9357, validation loss: 0.7183
2024-05-25 04:57:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch3_loss0.718318110704422.pypots
2024-05-25 04:57:43 [INFO]: Epoch 004 - training loss: 0.9008, validation loss: 0.7040
2024-05-25 04:57:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch4_loss0.7040316790342331.pypots
2024-05-25 04:57:47 [INFO]: Epoch 005 - training loss: 0.8843, validation loss: 0.6929
2024-05-25 04:57:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch5_loss0.6929194957017899.pypots
2024-05-25 04:57:51 [INFO]: Epoch 006 - training loss: 0.8753, validation loss: 0.6849
2024-05-25 04:57:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch6_loss0.6848669677972794.pypots
2024-05-25 04:57:55 [INFO]: Epoch 007 - training loss: 0.8599, validation loss: 0.6791
2024-05-25 04:57:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch7_loss0.6791102796792984.pypots
2024-05-25 04:57:59 [INFO]: Epoch 008 - training loss: 0.8411, validation loss: 0.6744
2024-05-25 04:57:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch8_loss0.6743836969137191.pypots
2024-05-25 04:58:02 [INFO]: Epoch 009 - training loss: 0.8514, validation loss: 0.6708
2024-05-25 04:58:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch9_loss0.6708461076021195.pypots
2024-05-25 04:58:06 [INFO]: Epoch 010 - training loss: 0.8461, validation loss: 0.6679
2024-05-25 04:58:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch10_loss0.6678751081228256.pypots
2024-05-25 04:58:10 [INFO]: Epoch 011 - training loss: 0.8391, validation loss: 0.6665
2024-05-25 04:58:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch11_loss0.6664718747138977.pypots
2024-05-25 04:58:14 [INFO]: Epoch 012 - training loss: 0.8322, validation loss: 0.6635
2024-05-25 04:58:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch12_loss0.6634515672922134.pypots
2024-05-25 04:58:18 [INFO]: Epoch 013 - training loss: 0.8286, validation loss: 0.6625
2024-05-25 04:58:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch13_loss0.6624652534723282.pypots
2024-05-25 04:58:21 [INFO]: Epoch 014 - training loss: 0.8248, validation loss: 0.6634
2024-05-25 04:58:21 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch14_loss0.663406154513359.pypots
2024-05-25 04:58:25 [INFO]: Epoch 015 - training loss: 0.8212, validation loss: 0.6614
2024-05-25 04:58:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch15_loss0.6614117443561554.pypots
2024-05-25 04:58:29 [INFO]: Epoch 016 - training loss: 0.8144, validation loss: 0.6614
2024-05-25 04:58:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch16_loss0.6613718956708908.pypots
2024-05-25 04:58:33 [INFO]: Epoch 017 - training loss: 0.8224, validation loss: 0.6602
2024-05-25 04:58:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch17_loss0.6602460443973541.pypots
2024-05-25 04:58:37 [INFO]: Epoch 018 - training loss: 0.8114, validation loss: 0.6600
2024-05-25 04:58:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch18_loss0.6600186824798584.pypots
2024-05-25 04:58:40 [INFO]: Epoch 019 - training loss: 0.8130, validation loss: 0.6595
2024-05-25 04:58:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch19_loss0.6594505816698074.pypots
2024-05-25 04:58:44 [INFO]: Epoch 020 - training loss: 0.8141, validation loss: 0.6591
2024-05-25 04:58:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch20_loss0.6590940117835998.pypots
2024-05-25 04:58:48 [INFO]: Epoch 021 - training loss: 0.8011, validation loss: 0.6589
2024-05-25 04:58:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch21_loss0.658852270245552.pypots
2024-05-25 04:58:52 [INFO]: Epoch 022 - training loss: 0.8035, validation loss: 0.6594
2024-05-25 04:58:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch22_loss0.6593740254640579.pypots
2024-05-25 04:58:55 [INFO]: Epoch 023 - training loss: 0.8096, validation loss: 0.6591
2024-05-25 04:58:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch23_loss0.6590729981660843.pypots
2024-05-25 04:58:59 [INFO]: Epoch 024 - training loss: 0.7985, validation loss: 0.6613
2024-05-25 04:58:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch24_loss0.6613013327121735.pypots
2024-05-25 04:59:03 [INFO]: Epoch 025 - training loss: 0.8355, validation loss: 0.6607
2024-05-25 04:59:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch25_loss0.6606832444667816.pypots
2024-05-25 04:59:07 [INFO]: Epoch 026 - training loss: 0.8188, validation loss: 0.6574
2024-05-25 04:59:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch26_loss0.65738165974617.pypots
2024-05-25 04:59:11 [INFO]: Epoch 027 - training loss: 0.8034, validation loss: 0.6572
2024-05-25 04:59:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch27_loss0.6571619749069214.pypots
2024-05-25 04:59:15 [INFO]: Epoch 028 - training loss: 0.8003, validation loss: 0.6589
2024-05-25 04:59:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch28_loss0.6589159190654754.pypots
2024-05-25 04:59:18 [INFO]: Epoch 029 - training loss: 0.7959, validation loss: 0.6584
2024-05-25 04:59:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch29_loss0.6583697170019149.pypots
2024-05-25 04:59:22 [INFO]: Epoch 030 - training loss: 0.7838, validation loss: 0.6588
2024-05-25 04:59:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch30_loss0.658809432387352.pypots
2024-05-25 04:59:26 [INFO]: Epoch 031 - training loss: 0.7853, validation loss: 0.6593
2024-05-25 04:59:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch31_loss0.659287565946579.pypots
2024-05-25 04:59:30 [INFO]: Epoch 032 - training loss: 0.7980, validation loss: 0.6610
2024-05-25 04:59:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch32_loss0.661006411910057.pypots
2024-05-25 04:59:33 [INFO]: Epoch 033 - training loss: 0.7775, validation loss: 0.6596
2024-05-25 04:59:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch33_loss0.6595540374517441.pypots
2024-05-25 04:59:37 [INFO]: Epoch 034 - training loss: 0.7865, validation loss: 0.6631
2024-05-25 04:59:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch34_loss0.6630975604057312.pypots
2024-05-25 04:59:41 [INFO]: Epoch 035 - training loss: 0.8046, validation loss: 0.6612
2024-05-25 04:59:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch35_loss0.661202684044838.pypots
2024-05-25 04:59:45 [INFO]: Epoch 036 - training loss: 0.7924, validation loss: 0.6583
2024-05-25 04:59:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch36_loss0.6583170711994171.pypots
2024-05-25 04:59:49 [INFO]: Epoch 037 - training loss: 0.7783, validation loss: 0.6618
2024-05-25 04:59:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN_epoch37_loss0.6618223249912262.pypots
2024-05-25 04:59:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:59:49 [INFO]: Finished training. The best model is from epoch#27.
2024-05-25 04:59:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T045727/MRNN.pypots
2024-05-25 04:59:49 [INFO]: MRNN on Air-Quality: MAE=0.5221, MSE=0.6592
2024-05-25 04:59:49 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/MRNN_air_quality/imputation.pkl
2024-05-25 04:59:49 [INFO]: Using the given device: cpu
2024-05-25 04:59:49 [INFO]: LOCF on Air-Quality: MAE=0.2220, MSE=0.3375
2024-05-25 04:59:49 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_air_quality".
2024-05-25 04:59:49 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/LOCF_air_quality/imputation.pkl
2024-05-25 04:59:49 [INFO]: Median on Air-Quality: MAE=0.6640, MSE=1.0523
2024-05-25 04:59:49 [INFO]: Successfully created the given path "saved_results/round_1/Median_air_quality".
2024-05-25 04:59:49 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Median_air_quality/imputation.pkl
2024-05-25 04:59:49 [INFO]: Mean on Air-Quality: MAE=0.6951, MSE=0.9927
2024-05-25 04:59:49 [INFO]: Successfully created the given path "saved_results/round_1/Mean_air_quality".
2024-05-25 04:59:49 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Mean_air_quality/imputation.pkl
2024-05-25 04:59:49 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-25 04:59:49 [INFO]: Using the given device: cuda:0
2024-05-25 04:59:49 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/SAITS_air_quality/20240525_T045949
2024-05-25 04:59:49 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/SAITS_air_quality/20240525_T045949/tensorboard
2024-05-25 04:59:50 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 04:59:50 [INFO]: Epoch 001 - training loss: 1.0570, validation loss: 0.5138
2024-05-25 04:59:51 [INFO]: Epoch 002 - training loss: 0.7587, validation loss: 0.3832
2024-05-25 04:59:52 [INFO]: Epoch 003 - training loss: 0.6545, validation loss: 0.3093
2024-05-25 04:59:52 [INFO]: Epoch 004 - training loss: 0.5759, validation loss: 0.2679
2024-05-25 04:59:53 [INFO]: Epoch 005 - training loss: 0.5200, validation loss: 0.2450
2024-05-25 04:59:53 [INFO]: Epoch 006 - training loss: 0.4827, validation loss: 0.2306
2024-05-25 04:59:54 [INFO]: Epoch 007 - training loss: 0.4564, validation loss: 0.2194
2024-05-25 04:59:55 [INFO]: Epoch 008 - training loss: 0.4373, validation loss: 0.2115
2024-05-25 04:59:55 [INFO]: Epoch 009 - training loss: 0.4229, validation loss: 0.2048
2024-05-25 04:59:56 [INFO]: Epoch 010 - training loss: 0.4110, validation loss: 0.2021
2024-05-25 04:59:56 [INFO]: Epoch 011 - training loss: 0.4018, validation loss: 0.1971
2024-05-25 04:59:57 [INFO]: Epoch 012 - training loss: 0.3920, validation loss: 0.1925
2024-05-25 04:59:58 [INFO]: Epoch 013 - training loss: 0.3857, validation loss: 0.1894
2024-05-25 04:59:58 [INFO]: Epoch 014 - training loss: 0.3780, validation loss: 0.1881
2024-05-25 04:59:59 [INFO]: Epoch 015 - training loss: 0.3711, validation loss: 0.1848
2024-05-25 04:59:59 [INFO]: Epoch 016 - training loss: 0.3661, validation loss: 0.1825
2024-05-25 05:00:00 [INFO]: Epoch 017 - training loss: 0.3596, validation loss: 0.1797
2024-05-25 05:00:01 [INFO]: Epoch 018 - training loss: 0.3561, validation loss: 0.1781
2024-05-25 05:00:01 [INFO]: Epoch 019 - training loss: 0.3520, validation loss: 0.1769
2024-05-25 05:00:02 [INFO]: Epoch 020 - training loss: 0.3496, validation loss: 0.1756
2024-05-25 05:00:02 [INFO]: Epoch 021 - training loss: 0.3449, validation loss: 0.1739
2024-05-25 05:00:03 [INFO]: Epoch 022 - training loss: 0.3412, validation loss: 0.1725
2024-05-25 05:00:04 [INFO]: Epoch 023 - training loss: 0.3370, validation loss: 0.1697
2024-05-25 05:00:04 [INFO]: Epoch 024 - training loss: 0.3342, validation loss: 0.1690
2024-05-25 05:00:05 [INFO]: Epoch 025 - training loss: 0.3315, validation loss: 0.1677
2024-05-25 05:00:05 [INFO]: Epoch 026 - training loss: 0.3300, validation loss: 0.1661
2024-05-25 05:00:06 [INFO]: Epoch 027 - training loss: 0.3254, validation loss: 0.1638
2024-05-25 05:00:07 [INFO]: Epoch 028 - training loss: 0.3227, validation loss: 0.1641
2024-05-25 05:00:07 [INFO]: Epoch 029 - training loss: 0.3215, validation loss: 0.1633
2024-05-25 05:00:08 [INFO]: Epoch 030 - training loss: 0.3192, validation loss: 0.1620
2024-05-25 05:00:08 [INFO]: Epoch 031 - training loss: 0.3164, validation loss: 0.1599
2024-05-25 05:00:09 [INFO]: Epoch 032 - training loss: 0.3144, validation loss: 0.1589
2024-05-25 05:00:10 [INFO]: Epoch 033 - training loss: 0.3119, validation loss: 0.1567
2024-05-25 05:00:10 [INFO]: Epoch 034 - training loss: 0.3103, validation loss: 0.1573
2024-05-25 05:00:11 [INFO]: Epoch 035 - training loss: 0.3083, validation loss: 0.1550
2024-05-25 05:00:11 [INFO]: Epoch 036 - training loss: 0.3060, validation loss: 0.1546
2024-05-25 05:00:12 [INFO]: Epoch 037 - training loss: 0.3037, validation loss: 0.1532
2024-05-25 05:00:13 [INFO]: Epoch 038 - training loss: 0.3027, validation loss: 0.1533
2024-05-25 05:00:13 [INFO]: Epoch 039 - training loss: 0.2999, validation loss: 0.1513
2024-05-25 05:00:14 [INFO]: Epoch 040 - training loss: 0.2977, validation loss: 0.1516
2024-05-25 05:00:14 [INFO]: Epoch 041 - training loss: 0.2971, validation loss: 0.1502
2024-05-25 05:00:15 [INFO]: Epoch 042 - training loss: 0.2956, validation loss: 0.1481
2024-05-25 05:00:16 [INFO]: Epoch 043 - training loss: 0.2931, validation loss: 0.1471
2024-05-25 05:00:16 [INFO]: Epoch 044 - training loss: 0.2909, validation loss: 0.1476
2024-05-25 05:00:17 [INFO]: Epoch 045 - training loss: 0.2897, validation loss: 0.1475
2024-05-25 05:00:17 [INFO]: Epoch 046 - training loss: 0.2872, validation loss: 0.1455
2024-05-25 05:00:18 [INFO]: Epoch 047 - training loss: 0.2873, validation loss: 0.1444
2024-05-25 05:00:19 [INFO]: Epoch 048 - training loss: 0.2859, validation loss: 0.1434
2024-05-25 05:00:19 [INFO]: Epoch 049 - training loss: 0.2841, validation loss: 0.1427
2024-05-25 05:00:20 [INFO]: Epoch 050 - training loss: 0.2844, validation loss: 0.1409
2024-05-25 05:00:20 [INFO]: Epoch 051 - training loss: 0.2810, validation loss: 0.1411
2024-05-25 05:00:21 [INFO]: Epoch 052 - training loss: 0.2778, validation loss: 0.1403
2024-05-25 05:00:22 [INFO]: Epoch 053 - training loss: 0.2760, validation loss: 0.1395
2024-05-25 05:00:22 [INFO]: Epoch 054 - training loss: 0.2759, validation loss: 0.1394
2024-05-25 05:00:23 [INFO]: Epoch 055 - training loss: 0.2740, validation loss: 0.1390
2024-05-25 05:00:24 [INFO]: Epoch 056 - training loss: 0.2718, validation loss: 0.1380
2024-05-25 05:00:24 [INFO]: Epoch 057 - training loss: 0.2725, validation loss: 0.1393
2024-05-25 05:00:25 [INFO]: Epoch 058 - training loss: 0.2705, validation loss: 0.1369
2024-05-25 05:00:25 [INFO]: Epoch 059 - training loss: 0.2697, validation loss: 0.1356
2024-05-25 05:00:26 [INFO]: Epoch 060 - training loss: 0.2677, validation loss: 0.1350
2024-05-25 05:00:27 [INFO]: Epoch 061 - training loss: 0.2659, validation loss: 0.1339
2024-05-25 05:00:27 [INFO]: Epoch 062 - training loss: 0.2646, validation loss: 0.1341
2024-05-25 05:00:28 [INFO]: Epoch 063 - training loss: 0.2637, validation loss: 0.1338
2024-05-25 05:00:28 [INFO]: Epoch 064 - training loss: 0.2617, validation loss: 0.1335
2024-05-25 05:00:29 [INFO]: Epoch 065 - training loss: 0.2603, validation loss: 0.1329
2024-05-25 05:00:30 [INFO]: Epoch 066 - training loss: 0.2595, validation loss: 0.1330
2024-05-25 05:00:30 [INFO]: Epoch 067 - training loss: 0.2592, validation loss: 0.1321
2024-05-25 05:00:31 [INFO]: Epoch 068 - training loss: 0.2573, validation loss: 0.1314
2024-05-25 05:00:31 [INFO]: Epoch 069 - training loss: 0.2563, validation loss: 0.1321
2024-05-25 05:00:32 [INFO]: Epoch 070 - training loss: 0.2550, validation loss: 0.1316
2024-05-25 05:00:33 [INFO]: Epoch 071 - training loss: 0.2548, validation loss: 0.1306
2024-05-25 05:00:33 [INFO]: Epoch 072 - training loss: 0.2542, validation loss: 0.1310
2024-05-25 05:00:34 [INFO]: Epoch 073 - training loss: 0.2524, validation loss: 0.1302
2024-05-25 05:00:34 [INFO]: Epoch 074 - training loss: 0.2508, validation loss: 0.1297
2024-05-25 05:00:35 [INFO]: Epoch 075 - training loss: 0.2501, validation loss: 0.1294
2024-05-25 05:00:36 [INFO]: Epoch 076 - training loss: 0.2490, validation loss: 0.1286
2024-05-25 05:00:36 [INFO]: Epoch 077 - training loss: 0.2497, validation loss: 0.1295
2024-05-25 05:00:37 [INFO]: Epoch 078 - training loss: 0.2475, validation loss: 0.1300
2024-05-25 05:00:37 [INFO]: Epoch 079 - training loss: 0.2466, validation loss: 0.1279
2024-05-25 05:00:38 [INFO]: Epoch 080 - training loss: 0.2465, validation loss: 0.1293
2024-05-25 05:00:39 [INFO]: Epoch 081 - training loss: 0.2451, validation loss: 0.1276
2024-05-25 05:00:39 [INFO]: Epoch 082 - training loss: 0.2441, validation loss: 0.1267
2024-05-25 05:00:40 [INFO]: Epoch 083 - training loss: 0.2450, validation loss: 0.1277
2024-05-25 05:00:40 [INFO]: Epoch 084 - training loss: 0.2447, validation loss: 0.1266
2024-05-25 05:00:41 [INFO]: Epoch 085 - training loss: 0.2434, validation loss: 0.1264
2024-05-25 05:00:42 [INFO]: Epoch 086 - training loss: 0.2414, validation loss: 0.1261
2024-05-25 05:00:42 [INFO]: Epoch 087 - training loss: 0.2411, validation loss: 0.1263
2024-05-25 05:00:43 [INFO]: Epoch 088 - training loss: 0.2394, validation loss: 0.1259
2024-05-25 05:00:43 [INFO]: Epoch 089 - training loss: 0.2390, validation loss: 0.1259
2024-05-25 05:00:44 [INFO]: Epoch 090 - training loss: 0.2372, validation loss: 0.1248
2024-05-25 05:00:45 [INFO]: Epoch 091 - training loss: 0.2375, validation loss: 0.1249
2024-05-25 05:00:45 [INFO]: Epoch 092 - training loss: 0.2362, validation loss: 0.1246
2024-05-25 05:00:46 [INFO]: Epoch 093 - training loss: 0.2363, validation loss: 0.1288
2024-05-25 05:00:46 [INFO]: Epoch 094 - training loss: 0.2369, validation loss: 0.1246
2024-05-25 05:00:47 [INFO]: Epoch 095 - training loss: 0.2366, validation loss: 0.1235
2024-05-25 05:00:47 [INFO]: Epoch 096 - training loss: 0.2339, validation loss: 0.1234
2024-05-25 05:00:48 [INFO]: Epoch 097 - training loss: 0.2335, validation loss: 0.1231
2024-05-25 05:00:49 [INFO]: Epoch 098 - training loss: 0.2324, validation loss: 0.1230
2024-05-25 05:00:49 [INFO]: Epoch 099 - training loss: 0.2323, validation loss: 0.1237
2024-05-25 05:00:50 [INFO]: Epoch 100 - training loss: 0.2322, validation loss: 0.1223
2024-05-25 05:00:50 [INFO]: Epoch 101 - training loss: 0.2306, validation loss: 0.1219
2024-05-25 05:00:51 [INFO]: Epoch 102 - training loss: 0.2303, validation loss: 0.1221
2024-05-25 05:00:52 [INFO]: Epoch 103 - training loss: 0.2297, validation loss: 0.1220
2024-05-25 05:00:52 [INFO]: Epoch 104 - training loss: 0.2283, validation loss: 0.1223
2024-05-25 05:00:53 [INFO]: Epoch 105 - training loss: 0.2286, validation loss: 0.1230
2024-05-25 05:00:53 [INFO]: Epoch 106 - training loss: 0.2270, validation loss: 0.1209
2024-05-25 05:00:54 [INFO]: Epoch 107 - training loss: 0.2262, validation loss: 0.1218
2024-05-25 05:00:55 [INFO]: Epoch 108 - training loss: 0.2255, validation loss: 0.1209
2024-05-25 05:00:55 [INFO]: Epoch 109 - training loss: 0.2260, validation loss: 0.1211
2024-05-25 05:00:56 [INFO]: Epoch 110 - training loss: 0.2260, validation loss: 0.1219
2024-05-25 05:00:56 [INFO]: Epoch 111 - training loss: 0.2246, validation loss: 0.1213
2024-05-25 05:00:57 [INFO]: Epoch 112 - training loss: 0.2241, validation loss: 0.1201
2024-05-25 05:00:58 [INFO]: Epoch 113 - training loss: 0.2234, validation loss: 0.1202
2024-05-25 05:00:58 [INFO]: Epoch 114 - training loss: 0.2225, validation loss: 0.1210
2024-05-25 05:00:59 [INFO]: Epoch 115 - training loss: 0.2215, validation loss: 0.1203
2024-05-25 05:00:59 [INFO]: Epoch 116 - training loss: 0.2214, validation loss: 0.1190
2024-05-25 05:01:00 [INFO]: Epoch 117 - training loss: 0.2215, validation loss: 0.1212
2024-05-25 05:01:01 [INFO]: Epoch 118 - training loss: 0.2200, validation loss: 0.1196
2024-05-25 05:01:01 [INFO]: Epoch 119 - training loss: 0.2199, validation loss: 0.1189
2024-05-25 05:01:02 [INFO]: Epoch 120 - training loss: 0.2198, validation loss: 0.1196
2024-05-25 05:01:03 [INFO]: Epoch 121 - training loss: 0.2191, validation loss: 0.1192
2024-05-25 05:01:03 [INFO]: Epoch 122 - training loss: 0.2188, validation loss: 0.1180
2024-05-25 05:01:04 [INFO]: Epoch 123 - training loss: 0.2194, validation loss: 0.1191
2024-05-25 05:01:04 [INFO]: Epoch 124 - training loss: 0.2185, validation loss: 0.1185
2024-05-25 05:01:05 [INFO]: Epoch 125 - training loss: 0.2183, validation loss: 0.1186
2024-05-25 05:01:06 [INFO]: Epoch 126 - training loss: 0.2193, validation loss: 0.1177
2024-05-25 05:01:06 [INFO]: Epoch 127 - training loss: 0.2178, validation loss: 0.1185
2024-05-25 05:01:07 [INFO]: Epoch 128 - training loss: 0.2157, validation loss: 0.1184
2024-05-25 05:01:07 [INFO]: Epoch 129 - training loss: 0.2148, validation loss: 0.1184
2024-05-25 05:01:08 [INFO]: Epoch 130 - training loss: 0.2155, validation loss: 0.1175
2024-05-25 05:01:09 [INFO]: Epoch 131 - training loss: 0.2166, validation loss: 0.1177
2024-05-25 05:01:09 [INFO]: Epoch 132 - training loss: 0.2156, validation loss: 0.1167
2024-05-25 05:01:10 [INFO]: Epoch 133 - training loss: 0.2146, validation loss: 0.1170
2024-05-25 05:01:10 [INFO]: Epoch 134 - training loss: 0.2137, validation loss: 0.1170
2024-05-25 05:01:11 [INFO]: Epoch 135 - training loss: 0.2122, validation loss: 0.1161
2024-05-25 05:01:12 [INFO]: Epoch 136 - training loss: 0.2107, validation loss: 0.1160
2024-05-25 05:01:12 [INFO]: Epoch 137 - training loss: 0.2128, validation loss: 0.1180
2024-05-25 05:01:13 [INFO]: Epoch 138 - training loss: 0.2127, validation loss: 0.1152
2024-05-25 05:01:13 [INFO]: Epoch 139 - training loss: 0.2129, validation loss: 0.1160
2024-05-25 05:01:14 [INFO]: Epoch 140 - training loss: 0.2102, validation loss: 0.1157
2024-05-25 05:01:15 [INFO]: Epoch 141 - training loss: 0.2089, validation loss: 0.1157
2024-05-25 05:01:15 [INFO]: Epoch 142 - training loss: 0.2090, validation loss: 0.1158
2024-05-25 05:01:16 [INFO]: Epoch 143 - training loss: 0.2078, validation loss: 0.1154
2024-05-25 05:01:16 [INFO]: Epoch 144 - training loss: 0.2080, validation loss: 0.1158
2024-05-25 05:01:17 [INFO]: Epoch 145 - training loss: 0.2087, validation loss: 0.1160
2024-05-25 05:01:18 [INFO]: Epoch 146 - training loss: 0.2082, validation loss: 0.1166
2024-05-25 05:01:18 [INFO]: Epoch 147 - training loss: 0.2063, validation loss: 0.1159
2024-05-25 05:01:19 [INFO]: Epoch 148 - training loss: 0.2060, validation loss: 0.1162
2024-05-25 05:01:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:01:19 [INFO]: Finished training. The best model is from epoch#138.
2024-05-25 05:01:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/SAITS_air_quality/20240525_T045949/SAITS.pypots
2024-05-25 05:01:19 [INFO]: SAITS on Air-Quality: MAE=0.1646, MSE=0.1593
2024-05-25 05:01:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/SAITS_air_quality/imputation.pkl
2024-05-25 05:01:19 [INFO]: Using the given device: cuda:0
2024-05-25 05:01:19 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/Transformer_air_quality/20240525_T050119
2024-05-25 05:01:19 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/Transformer_air_quality/20240525_T050119/tensorboard
2024-05-25 05:01:19 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 05:01:19 [INFO]: Epoch 001 - training loss: 0.9150, validation loss: 0.4526
2024-05-25 05:01:20 [INFO]: Epoch 002 - training loss: 0.5816, validation loss: 0.3290
2024-05-25 05:01:20 [INFO]: Epoch 003 - training loss: 0.4870, validation loss: 0.2784
2024-05-25 05:01:20 [INFO]: Epoch 004 - training loss: 0.4391, validation loss: 0.2519
2024-05-25 05:01:20 [INFO]: Epoch 005 - training loss: 0.4115, validation loss: 0.2352
2024-05-25 05:01:21 [INFO]: Epoch 006 - training loss: 0.3904, validation loss: 0.2272
2024-05-25 05:01:21 [INFO]: Epoch 007 - training loss: 0.3750, validation loss: 0.2178
2024-05-25 05:01:21 [INFO]: Epoch 008 - training loss: 0.3645, validation loss: 0.2138
2024-05-25 05:01:21 [INFO]: Epoch 009 - training loss: 0.3527, validation loss: 0.2105
2024-05-25 05:01:22 [INFO]: Epoch 010 - training loss: 0.3438, validation loss: 0.2033
2024-05-25 05:01:22 [INFO]: Epoch 011 - training loss: 0.3365, validation loss: 0.2000
2024-05-25 05:01:22 [INFO]: Epoch 012 - training loss: 0.3299, validation loss: 0.1969
2024-05-25 05:01:22 [INFO]: Epoch 013 - training loss: 0.3257, validation loss: 0.1909
2024-05-25 05:01:23 [INFO]: Epoch 014 - training loss: 0.3213, validation loss: 0.1887
2024-05-25 05:01:23 [INFO]: Epoch 015 - training loss: 0.3168, validation loss: 0.1871
2024-05-25 05:01:23 [INFO]: Epoch 016 - training loss: 0.3138, validation loss: 0.1843
2024-05-25 05:01:23 [INFO]: Epoch 017 - training loss: 0.3097, validation loss: 0.1810
2024-05-25 05:01:24 [INFO]: Epoch 018 - training loss: 0.3050, validation loss: 0.1785
2024-05-25 05:01:24 [INFO]: Epoch 019 - training loss: 0.3026, validation loss: 0.1751
2024-05-25 05:01:24 [INFO]: Epoch 020 - training loss: 0.2990, validation loss: 0.1748
2024-05-25 05:01:24 [INFO]: Epoch 021 - training loss: 0.2974, validation loss: 0.1716
2024-05-25 05:01:25 [INFO]: Epoch 022 - training loss: 0.2946, validation loss: 0.1729
2024-05-25 05:01:25 [INFO]: Epoch 023 - training loss: 0.2911, validation loss: 0.1710
2024-05-25 05:01:25 [INFO]: Epoch 024 - training loss: 0.2874, validation loss: 0.1679
2024-05-25 05:01:25 [INFO]: Epoch 025 - training loss: 0.2833, validation loss: 0.1719
2024-05-25 05:01:25 [INFO]: Epoch 026 - training loss: 0.2824, validation loss: 0.1673
2024-05-25 05:01:26 [INFO]: Epoch 027 - training loss: 0.2818, validation loss: 0.1682
2024-05-25 05:01:26 [INFO]: Epoch 028 - training loss: 0.2798, validation loss: 0.1675
2024-05-25 05:01:26 [INFO]: Epoch 029 - training loss: 0.2786, validation loss: 0.1654
2024-05-25 05:01:26 [INFO]: Epoch 030 - training loss: 0.2780, validation loss: 0.1675
2024-05-25 05:01:27 [INFO]: Epoch 031 - training loss: 0.2790, validation loss: 0.1661
2024-05-25 05:01:27 [INFO]: Epoch 032 - training loss: 0.2728, validation loss: 0.1629
2024-05-25 05:01:27 [INFO]: Epoch 033 - training loss: 0.2706, validation loss: 0.1623
2024-05-25 05:01:27 [INFO]: Epoch 034 - training loss: 0.2679, validation loss: 0.1634
2024-05-25 05:01:28 [INFO]: Epoch 035 - training loss: 0.2664, validation loss: 0.1646
2024-05-25 05:01:28 [INFO]: Epoch 036 - training loss: 0.2631, validation loss: 0.1612
2024-05-25 05:01:28 [INFO]: Epoch 037 - training loss: 0.2610, validation loss: 0.1613
2024-05-25 05:01:28 [INFO]: Epoch 038 - training loss: 0.2605, validation loss: 0.1619
2024-05-25 05:01:29 [INFO]: Epoch 039 - training loss: 0.2577, validation loss: 0.1585
2024-05-25 05:01:29 [INFO]: Epoch 040 - training loss: 0.2577, validation loss: 0.1602
2024-05-25 05:01:29 [INFO]: Epoch 041 - training loss: 0.2575, validation loss: 0.1582
2024-05-25 05:01:29 [INFO]: Epoch 042 - training loss: 0.2573, validation loss: 0.1594
2024-05-25 05:01:30 [INFO]: Epoch 043 - training loss: 0.2581, validation loss: 0.1579
2024-05-25 05:01:30 [INFO]: Epoch 044 - training loss: 0.2538, validation loss: 0.1568
2024-05-25 05:01:30 [INFO]: Epoch 045 - training loss: 0.2530, validation loss: 0.1582
2024-05-25 05:01:30 [INFO]: Epoch 046 - training loss: 0.2494, validation loss: 0.1560
2024-05-25 05:01:31 [INFO]: Epoch 047 - training loss: 0.2479, validation loss: 0.1566
2024-05-25 05:01:31 [INFO]: Epoch 048 - training loss: 0.2473, validation loss: 0.1577
2024-05-25 05:01:31 [INFO]: Epoch 049 - training loss: 0.2453, validation loss: 0.1548
2024-05-25 05:01:31 [INFO]: Epoch 050 - training loss: 0.2469, validation loss: 0.1566
2024-05-25 05:01:32 [INFO]: Epoch 051 - training loss: 0.2443, validation loss: 0.1562
2024-05-25 05:01:32 [INFO]: Epoch 052 - training loss: 0.2408, validation loss: 0.1541
2024-05-25 05:01:32 [INFO]: Epoch 053 - training loss: 0.2421, validation loss: 0.1530
2024-05-25 05:01:32 [INFO]: Epoch 054 - training loss: 0.2412, validation loss: 0.1541
2024-05-25 05:01:33 [INFO]: Epoch 055 - training loss: 0.2419, validation loss: 0.1543
2024-05-25 05:01:33 [INFO]: Epoch 056 - training loss: 0.2379, validation loss: 0.1540
2024-05-25 05:01:33 [INFO]: Epoch 057 - training loss: 0.2363, validation loss: 0.1545
2024-05-25 05:01:33 [INFO]: Epoch 058 - training loss: 0.2368, validation loss: 0.1527
2024-05-25 05:01:34 [INFO]: Epoch 059 - training loss: 0.2358, validation loss: 0.1533
2024-05-25 05:01:34 [INFO]: Epoch 060 - training loss: 0.2381, validation loss: 0.1547
2024-05-25 05:01:34 [INFO]: Epoch 061 - training loss: 0.2332, validation loss: 0.1537
2024-05-25 05:01:34 [INFO]: Epoch 062 - training loss: 0.2319, validation loss: 0.1520
2024-05-25 05:01:35 [INFO]: Epoch 063 - training loss: 0.2294, validation loss: 0.1511
2024-05-25 05:01:35 [INFO]: Epoch 064 - training loss: 0.2283, validation loss: 0.1510
2024-05-25 05:01:35 [INFO]: Epoch 065 - training loss: 0.2291, validation loss: 0.1514
2024-05-25 05:01:35 [INFO]: Epoch 066 - training loss: 0.2275, validation loss: 0.1484
2024-05-25 05:01:36 [INFO]: Epoch 067 - training loss: 0.2315, validation loss: 0.1525
2024-05-25 05:01:36 [INFO]: Epoch 068 - training loss: 0.2253, validation loss: 0.1498
2024-05-25 05:01:36 [INFO]: Epoch 069 - training loss: 0.2250, validation loss: 0.1507
2024-05-25 05:01:36 [INFO]: Epoch 070 - training loss: 0.2240, validation loss: 0.1481
2024-05-25 05:01:37 [INFO]: Epoch 071 - training loss: 0.2222, validation loss: 0.1501
2024-05-25 05:01:37 [INFO]: Epoch 072 - training loss: 0.2227, validation loss: 0.1490
2024-05-25 05:01:37 [INFO]: Epoch 073 - training loss: 0.2224, validation loss: 0.1482
2024-05-25 05:01:37 [INFO]: Epoch 074 - training loss: 0.2231, validation loss: 0.1504
2024-05-25 05:01:38 [INFO]: Epoch 075 - training loss: 0.2208, validation loss: 0.1480
2024-05-25 05:01:38 [INFO]: Epoch 076 - training loss: 0.2157, validation loss: 0.1480
2024-05-25 05:01:38 [INFO]: Epoch 077 - training loss: 0.2210, validation loss: 0.1468
2024-05-25 05:01:38 [INFO]: Epoch 078 - training loss: 0.2187, validation loss: 0.1486
2024-05-25 05:01:39 [INFO]: Epoch 079 - training loss: 0.2159, validation loss: 0.1480
2024-05-25 05:01:39 [INFO]: Epoch 080 - training loss: 0.2134, validation loss: 0.1476
2024-05-25 05:01:39 [INFO]: Epoch 081 - training loss: 0.2113, validation loss: 0.1463
2024-05-25 05:01:39 [INFO]: Epoch 082 - training loss: 0.2113, validation loss: 0.1466
2024-05-25 05:01:40 [INFO]: Epoch 083 - training loss: 0.2123, validation loss: 0.1470
2024-05-25 05:01:40 [INFO]: Epoch 084 - training loss: 0.2137, validation loss: 0.1444
2024-05-25 05:01:40 [INFO]: Epoch 085 - training loss: 0.2104, validation loss: 0.1478
2024-05-25 05:01:40 [INFO]: Epoch 086 - training loss: 0.2125, validation loss: 0.1491
2024-05-25 05:01:41 [INFO]: Epoch 087 - training loss: 0.2161, validation loss: 0.1475
2024-05-25 05:01:41 [INFO]: Epoch 088 - training loss: 0.2141, validation loss: 0.1458
2024-05-25 05:01:41 [INFO]: Epoch 089 - training loss: 0.2113, validation loss: 0.1432
2024-05-25 05:01:41 [INFO]: Epoch 090 - training loss: 0.2090, validation loss: 0.1481
2024-05-25 05:01:42 [INFO]: Epoch 091 - training loss: 0.2059, validation loss: 0.1466
2024-05-25 05:01:42 [INFO]: Epoch 092 - training loss: 0.2081, validation loss: 0.1440
2024-05-25 05:01:42 [INFO]: Epoch 093 - training loss: 0.2030, validation loss: 0.1447
2024-05-25 05:01:42 [INFO]: Epoch 094 - training loss: 0.2018, validation loss: 0.1449
2024-05-25 05:01:43 [INFO]: Epoch 095 - training loss: 0.2040, validation loss: 0.1458
2024-05-25 05:01:43 [INFO]: Epoch 096 - training loss: 0.2025, validation loss: 0.1444
2024-05-25 05:01:43 [INFO]: Epoch 097 - training loss: 0.2017, validation loss: 0.1453
2024-05-25 05:01:43 [INFO]: Epoch 098 - training loss: 0.1998, validation loss: 0.1430
2024-05-25 05:01:44 [INFO]: Epoch 099 - training loss: 0.2006, validation loss: 0.1453
2024-05-25 05:01:44 [INFO]: Epoch 100 - training loss: 0.2007, validation loss: 0.1411
2024-05-25 05:01:44 [INFO]: Epoch 101 - training loss: 0.2017, validation loss: 0.1415
2024-05-25 05:01:44 [INFO]: Epoch 102 - training loss: 0.2009, validation loss: 0.1437
2024-05-25 05:01:45 [INFO]: Epoch 103 - training loss: 0.1987, validation loss: 0.1424
2024-05-25 05:01:45 [INFO]: Epoch 104 - training loss: 0.1978, validation loss: 0.1446
2024-05-25 05:01:45 [INFO]: Epoch 105 - training loss: 0.1964, validation loss: 0.1434
2024-05-25 05:01:45 [INFO]: Epoch 106 - training loss: 0.1962, validation loss: 0.1416
2024-05-25 05:01:46 [INFO]: Epoch 107 - training loss: 0.1955, validation loss: 0.1410
2024-05-25 05:01:46 [INFO]: Epoch 108 - training loss: 0.1980, validation loss: 0.1432
2024-05-25 05:01:46 [INFO]: Epoch 109 - training loss: 0.1940, validation loss: 0.1407
2024-05-25 05:01:46 [INFO]: Epoch 110 - training loss: 0.1922, validation loss: 0.1417
2024-05-25 05:01:47 [INFO]: Epoch 111 - training loss: 0.1905, validation loss: 0.1419
2024-05-25 05:01:47 [INFO]: Epoch 112 - training loss: 0.1911, validation loss: 0.1423
2024-05-25 05:01:47 [INFO]: Epoch 113 - training loss: 0.1905, validation loss: 0.1417
2024-05-25 05:01:47 [INFO]: Epoch 114 - training loss: 0.1909, validation loss: 0.1413
2024-05-25 05:01:48 [INFO]: Epoch 115 - training loss: 0.1903, validation loss: 0.1429
2024-05-25 05:01:48 [INFO]: Epoch 116 - training loss: 0.1884, validation loss: 0.1402
2024-05-25 05:01:48 [INFO]: Epoch 117 - training loss: 0.1881, validation loss: 0.1393
2024-05-25 05:01:48 [INFO]: Epoch 118 - training loss: 0.1897, validation loss: 0.1396
2024-05-25 05:01:49 [INFO]: Epoch 119 - training loss: 0.1891, validation loss: 0.1397
2024-05-25 05:01:49 [INFO]: Epoch 120 - training loss: 0.1889, validation loss: 0.1396
2024-05-25 05:01:49 [INFO]: Epoch 121 - training loss: 0.1867, validation loss: 0.1401
2024-05-25 05:01:49 [INFO]: Epoch 122 - training loss: 0.1861, validation loss: 0.1420
2024-05-25 05:01:50 [INFO]: Epoch 123 - training loss: 0.1864, validation loss: 0.1414
2024-05-25 05:01:50 [INFO]: Epoch 124 - training loss: 0.1882, validation loss: 0.1414
2024-05-25 05:01:50 [INFO]: Epoch 125 - training loss: 0.1859, validation loss: 0.1414
2024-05-25 05:01:50 [INFO]: Epoch 126 - training loss: 0.1865, validation loss: 0.1409
2024-05-25 05:01:51 [INFO]: Epoch 127 - training loss: 0.1827, validation loss: 0.1399
2024-05-25 05:01:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:01:51 [INFO]: Finished training. The best model is from epoch#117.
2024-05-25 05:01:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/Transformer_air_quality/20240525_T050119/Transformer.pypots
2024-05-25 05:01:51 [INFO]: Transformer on Air-Quality: MAE=0.1835, MSE=0.1873
2024-05-25 05:01:51 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Transformer_air_quality/imputation.pkl
2024-05-25 05:01:51 [INFO]: Using the given device: cuda:0
2024-05-25 05:01:51 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/TimesNet_air_quality/20240525_T050151
2024-05-25 05:01:51 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/TimesNet_air_quality/20240525_T050151/tensorboard
2024-05-25 05:01:51 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 05:01:52 [INFO]: Epoch 001 - training loss: 0.3000, validation loss: 0.2852
2024-05-25 05:01:52 [INFO]: Epoch 002 - training loss: 0.2293, validation loss: 0.2149
2024-05-25 05:01:52 [INFO]: Epoch 003 - training loss: 0.1955, validation loss: 0.1968
2024-05-25 05:01:53 [INFO]: Epoch 004 - training loss: 0.1880, validation loss: 0.1880
2024-05-25 05:01:53 [INFO]: Epoch 005 - training loss: 0.1722, validation loss: 0.1812
2024-05-25 05:01:54 [INFO]: Epoch 006 - training loss: 0.1593, validation loss: 0.1771
2024-05-25 05:01:54 [INFO]: Epoch 007 - training loss: 0.1525, validation loss: 0.1702
2024-05-25 05:01:55 [INFO]: Epoch 008 - training loss: 0.1396, validation loss: 0.1689
2024-05-25 05:01:55 [INFO]: Epoch 009 - training loss: 0.1329, validation loss: 0.1674
2024-05-25 05:01:56 [INFO]: Epoch 010 - training loss: 0.1280, validation loss: 0.1665
2024-05-25 05:01:56 [INFO]: Epoch 011 - training loss: 0.1253, validation loss: 0.1615
2024-05-25 05:01:57 [INFO]: Epoch 012 - training loss: 0.1305, validation loss: 0.1680
2024-05-25 05:01:57 [INFO]: Epoch 013 - training loss: 0.1197, validation loss: 0.1591
2024-05-25 05:01:57 [INFO]: Epoch 014 - training loss: 0.1151, validation loss: 0.1605
2024-05-25 05:01:58 [INFO]: Epoch 015 - training loss: 0.1166, validation loss: 0.1636
2024-05-25 05:01:58 [INFO]: Epoch 016 - training loss: 0.1135, validation loss: 0.1614
2024-05-25 05:01:59 [INFO]: Epoch 017 - training loss: 0.1169, validation loss: 0.1589
2024-05-25 05:01:59 [INFO]: Epoch 018 - training loss: 0.1094, validation loss: 0.1568
2024-05-25 05:02:00 [INFO]: Epoch 019 - training loss: 0.1043, validation loss: 0.1568
2024-05-25 05:02:00 [INFO]: Epoch 020 - training loss: 0.1011, validation loss: 0.1683
2024-05-25 05:02:01 [INFO]: Epoch 021 - training loss: 0.1036, validation loss: 0.1582
2024-05-25 05:02:01 [INFO]: Epoch 022 - training loss: 0.1050, validation loss: 0.1621
2024-05-25 05:02:02 [INFO]: Epoch 023 - training loss: 0.0993, validation loss: 0.1590
2024-05-25 05:02:02 [INFO]: Epoch 024 - training loss: 0.0964, validation loss: 0.1575
2024-05-25 05:02:02 [INFO]: Epoch 025 - training loss: 0.0960, validation loss: 0.1575
2024-05-25 05:02:03 [INFO]: Epoch 026 - training loss: 0.0969, validation loss: 0.1598
2024-05-25 05:02:03 [INFO]: Epoch 027 - training loss: 0.0992, validation loss: 0.1565
2024-05-25 05:02:04 [INFO]: Epoch 028 - training loss: 0.0912, validation loss: 0.1561
2024-05-25 05:02:04 [INFO]: Epoch 029 - training loss: 0.0886, validation loss: 0.1591
2024-05-25 05:02:05 [INFO]: Epoch 030 - training loss: 0.0870, validation loss: 0.1553
2024-05-25 05:02:05 [INFO]: Epoch 031 - training loss: 0.0863, validation loss: 0.1564
2024-05-25 05:02:06 [INFO]: Epoch 032 - training loss: 0.0856, validation loss: 0.1589
2024-05-25 05:02:06 [INFO]: Epoch 033 - training loss: 0.0845, validation loss: 0.1558
2024-05-25 05:02:07 [INFO]: Epoch 034 - training loss: 0.0849, validation loss: 0.1501
2024-05-25 05:02:07 [INFO]: Epoch 035 - training loss: 0.0834, validation loss: 0.1568
2024-05-25 05:02:07 [INFO]: Epoch 036 - training loss: 0.0833, validation loss: 0.1552
2024-05-25 05:02:08 [INFO]: Epoch 037 - training loss: 0.0836, validation loss: 0.1539
2024-05-25 05:02:08 [INFO]: Epoch 038 - training loss: 0.0835, validation loss: 0.1577
2024-05-25 05:02:09 [INFO]: Epoch 039 - training loss: 0.0832, validation loss: 0.1531
2024-05-25 05:02:09 [INFO]: Epoch 040 - training loss: 0.0820, validation loss: 0.1564
2024-05-25 05:02:10 [INFO]: Epoch 041 - training loss: 0.0815, validation loss: 0.1542
2024-05-25 05:02:10 [INFO]: Epoch 042 - training loss: 0.0769, validation loss: 0.1531
2024-05-25 05:02:11 [INFO]: Epoch 043 - training loss: 0.0751, validation loss: 0.1537
2024-05-25 05:02:11 [INFO]: Epoch 044 - training loss: 0.0727, validation loss: 0.1560
2024-05-25 05:02:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:02:11 [INFO]: Finished training. The best model is from epoch#34.
2024-05-25 05:02:11 [INFO]: Saved the model to overlay_premask_saved_results/round_2/TimesNet_air_quality/20240525_T050151/TimesNet.pypots
2024-05-25 05:02:11 [INFO]: TimesNet on Air-Quality: MAE=0.1719, MSE=0.2653
2024-05-25 05:02:11 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/TimesNet_air_quality/imputation.pkl
2024-05-25 05:02:11 [INFO]: Using the given device: cuda:0
2024-05-25 05:02:11 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211
2024-05-25 05:02:11 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/tensorboard
2024-05-25 05:02:11 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 05:02:28 [INFO]: Epoch 001 - training loss: 0.4904, validation loss: 0.3250
2024-05-25 05:02:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch1_loss0.32500347793102263.pypots
2024-05-25 05:02:45 [INFO]: Epoch 002 - training loss: 0.2864, validation loss: 0.2662
2024-05-25 05:02:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch2_loss0.2662052810192108.pypots
2024-05-25 05:03:01 [INFO]: Epoch 003 - training loss: 0.2421, validation loss: 0.2396
2024-05-25 05:03:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch3_loss0.2396483913064003.pypots
2024-05-25 05:03:18 [INFO]: Epoch 004 - training loss: 0.2501, validation loss: 0.2203
2024-05-25 05:03:18 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch4_loss0.22030517905950547.pypots
2024-05-25 05:03:35 [INFO]: Epoch 005 - training loss: 0.2225, validation loss: 0.1977
2024-05-25 05:03:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch5_loss0.19770224243402482.pypots
2024-05-25 05:03:51 [INFO]: Epoch 006 - training loss: 0.1941, validation loss: 0.1780
2024-05-25 05:03:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch6_loss0.1779513880610466.pypots
2024-05-25 05:04:08 [INFO]: Epoch 007 - training loss: 0.1704, validation loss: 0.1649
2024-05-25 05:04:08 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch7_loss0.1649048686027527.pypots
2024-05-25 05:04:25 [INFO]: Epoch 008 - training loss: 0.1632, validation loss: 0.1627
2024-05-25 05:04:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch8_loss0.1626844361424446.pypots
2024-05-25 05:04:41 [INFO]: Epoch 009 - training loss: 0.1635, validation loss: 0.1682
2024-05-25 05:04:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch9_loss0.1682378202676773.pypots
2024-05-25 05:04:58 [INFO]: Epoch 010 - training loss: 0.1571, validation loss: 0.1534
2024-05-25 05:04:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch10_loss0.15337247401475906.pypots
2024-05-25 05:05:15 [INFO]: Epoch 011 - training loss: 0.1640, validation loss: 0.1642
2024-05-25 05:05:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch11_loss0.16420894861221313.pypots
2024-05-25 05:05:31 [INFO]: Epoch 012 - training loss: 0.1523, validation loss: 0.1477
2024-05-25 05:05:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch12_loss0.14768341630697251.pypots
2024-05-25 05:05:48 [INFO]: Epoch 013 - training loss: 0.1534, validation loss: 0.1463
2024-05-25 05:05:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch13_loss0.1463155373930931.pypots
2024-05-25 05:06:05 [INFO]: Epoch 014 - training loss: 0.1588, validation loss: 0.1424
2024-05-25 05:06:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch14_loss0.14240459799766542.pypots
2024-05-25 05:06:22 [INFO]: Epoch 015 - training loss: 0.1474, validation loss: 0.1438
2024-05-25 05:06:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch15_loss0.14380692541599274.pypots
2024-05-25 05:06:38 [INFO]: Epoch 016 - training loss: 0.1532, validation loss: 0.1447
2024-05-25 05:06:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch16_loss0.14472129195928574.pypots
2024-05-25 05:06:55 [INFO]: Epoch 017 - training loss: 0.1547, validation loss: 0.1468
2024-05-25 05:06:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch17_loss0.14677949845790864.pypots
2024-05-25 05:07:12 [INFO]: Epoch 018 - training loss: 0.1518, validation loss: 0.1372
2024-05-25 05:07:12 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch18_loss0.13723275065422058.pypots
2024-05-25 05:07:28 [INFO]: Epoch 019 - training loss: 0.1402, validation loss: 0.1332
2024-05-25 05:07:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch19_loss0.1331886164844036.pypots
2024-05-25 05:07:45 [INFO]: Epoch 020 - training loss: 0.1317, validation loss: 0.1342
2024-05-25 05:07:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch20_loss0.13416711762547492.pypots
2024-05-25 05:08:02 [INFO]: Epoch 021 - training loss: 0.1440, validation loss: 0.1341
2024-05-25 05:08:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch21_loss0.13407454118132592.pypots
2024-05-25 05:08:19 [INFO]: Epoch 022 - training loss: 0.1246, validation loss: 0.1321
2024-05-25 05:08:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch22_loss0.1320766791701317.pypots
2024-05-25 05:08:35 [INFO]: Epoch 023 - training loss: 0.1298, validation loss: 0.1327
2024-05-25 05:08:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch23_loss0.1326963871717453.pypots
2024-05-25 05:08:52 [INFO]: Epoch 024 - training loss: 0.1397, validation loss: 0.1330
2024-05-25 05:08:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch24_loss0.13300047367811202.pypots
2024-05-25 05:09:09 [INFO]: Epoch 025 - training loss: 0.1393, validation loss: 0.1296
2024-05-25 05:09:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch25_loss0.12961161509156227.pypots
2024-05-25 05:09:25 [INFO]: Epoch 026 - training loss: 0.1269, validation loss: 0.1285
2024-05-25 05:09:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch26_loss0.12848397493362426.pypots
2024-05-25 05:09:42 [INFO]: Epoch 027 - training loss: 0.1186, validation loss: 0.1309
2024-05-25 05:09:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch27_loss0.13086064979434014.pypots
2024-05-25 05:09:59 [INFO]: Epoch 028 - training loss: 0.1381, validation loss: 0.1325
2024-05-25 05:09:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch28_loss0.13250139653682708.pypots
2024-05-25 05:10:15 [INFO]: Epoch 029 - training loss: 0.1343, validation loss: 0.1362
2024-05-25 05:10:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch29_loss0.13620799407362938.pypots
2024-05-25 05:10:32 [INFO]: Epoch 030 - training loss: 0.1224, validation loss: 0.1268
2024-05-25 05:10:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch30_loss0.1268249161541462.pypots
2024-05-25 05:10:49 [INFO]: Epoch 031 - training loss: 0.1255, validation loss: 0.1304
2024-05-25 05:10:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch31_loss0.1304425247013569.pypots
2024-05-25 05:11:05 [INFO]: Epoch 032 - training loss: 0.1198, validation loss: 0.1258
2024-05-25 05:11:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch32_loss0.12583405748009682.pypots
2024-05-25 05:11:22 [INFO]: Epoch 033 - training loss: 0.1105, validation loss: 0.1251
2024-05-25 05:11:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch33_loss0.12509270757436752.pypots
2024-05-25 05:11:39 [INFO]: Epoch 034 - training loss: 0.1152, validation loss: 0.1233
2024-05-25 05:11:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch34_loss0.12332561388611793.pypots
2024-05-25 05:11:55 [INFO]: Epoch 035 - training loss: 0.1162, validation loss: 0.1226
2024-05-25 05:11:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch35_loss0.1226189099252224.pypots
2024-05-25 05:12:12 [INFO]: Epoch 036 - training loss: 0.1144, validation loss: 0.1205
2024-05-25 05:12:12 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch36_loss0.12050427794456482.pypots
2024-05-25 05:12:29 [INFO]: Epoch 037 - training loss: 0.1288, validation loss: 0.1221
2024-05-25 05:12:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch37_loss0.12207423374056817.pypots
2024-05-25 05:12:45 [INFO]: Epoch 038 - training loss: 0.1140, validation loss: 0.1212
2024-05-25 05:12:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch38_loss0.12120554968714714.pypots
2024-05-25 05:13:02 [INFO]: Epoch 039 - training loss: 0.1287, validation loss: 0.1205
2024-05-25 05:13:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch39_loss0.12045826911926269.pypots
2024-05-25 05:13:19 [INFO]: Epoch 040 - training loss: 0.1107, validation loss: 0.1173
2024-05-25 05:13:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch40_loss0.11732827797532082.pypots
2024-05-25 05:13:35 [INFO]: Epoch 041 - training loss: 0.1177, validation loss: 0.1221
2024-05-25 05:13:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch41_loss0.12206022366881371.pypots
2024-05-25 05:13:52 [INFO]: Epoch 042 - training loss: 0.1140, validation loss: 0.1203
2024-05-25 05:13:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch42_loss0.1203127533197403.pypots
2024-05-25 05:14:09 [INFO]: Epoch 043 - training loss: 0.1219, validation loss: 0.1171
2024-05-25 05:14:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch43_loss0.11709647849202157.pypots
2024-05-25 05:14:25 [INFO]: Epoch 044 - training loss: 0.1141, validation loss: 0.1157
2024-05-25 05:14:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch44_loss0.11570107936859131.pypots
2024-05-25 05:14:42 [INFO]: Epoch 045 - training loss: 0.1166, validation loss: 0.1158
2024-05-25 05:14:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch45_loss0.11582911983132363.pypots
2024-05-25 05:14:59 [INFO]: Epoch 046 - training loss: 0.1246, validation loss: 0.1193
2024-05-25 05:14:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch46_loss0.11926515474915504.pypots
2024-05-25 05:15:16 [INFO]: Epoch 047 - training loss: 0.1115, validation loss: 0.1151
2024-05-25 05:15:16 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch47_loss0.1150543212890625.pypots
2024-05-25 05:15:32 [INFO]: Epoch 048 - training loss: 0.1092, validation loss: 0.1158
2024-05-25 05:15:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch48_loss0.11576771885156631.pypots
2024-05-25 05:15:49 [INFO]: Epoch 049 - training loss: 0.1053, validation loss: 0.1137
2024-05-25 05:15:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch49_loss0.11373505368828773.pypots
2024-05-25 05:16:06 [INFO]: Epoch 050 - training loss: 0.1282, validation loss: 0.1187
2024-05-25 05:16:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch50_loss0.11867519542574882.pypots
2024-05-25 05:16:22 [INFO]: Epoch 051 - training loss: 0.1034, validation loss: 0.1131
2024-05-25 05:16:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch51_loss0.11314572393894196.pypots
2024-05-25 05:16:39 [INFO]: Epoch 052 - training loss: 0.1131, validation loss: 0.1110
2024-05-25 05:16:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch52_loss0.11097006723284722.pypots
2024-05-25 05:16:56 [INFO]: Epoch 053 - training loss: 0.1219, validation loss: 0.1128
2024-05-25 05:16:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch53_loss0.11280856281518936.pypots
2024-05-25 05:17:12 [INFO]: Epoch 054 - training loss: 0.1179, validation loss: 0.1145
2024-05-25 05:17:12 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch54_loss0.11452845856547356.pypots
2024-05-25 05:17:29 [INFO]: Epoch 055 - training loss: 0.1130, validation loss: 0.1153
2024-05-25 05:17:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch55_loss0.11532498449087143.pypots
2024-05-25 05:17:46 [INFO]: Epoch 056 - training loss: 0.1091, validation loss: 0.1124
2024-05-25 05:17:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch56_loss0.11238851845264435.pypots
2024-05-25 05:18:02 [INFO]: Epoch 057 - training loss: 0.1039, validation loss: 0.1107
2024-05-25 05:18:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch57_loss0.11070571914315223.pypots
2024-05-25 05:18:19 [INFO]: Epoch 058 - training loss: 0.1122, validation loss: 0.1154
2024-05-25 05:18:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch58_loss0.11535669043660164.pypots
2024-05-25 05:18:36 [INFO]: Epoch 059 - training loss: 0.1120, validation loss: 0.1098
2024-05-25 05:18:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch59_loss0.10978801399469376.pypots
2024-05-25 05:18:52 [INFO]: Epoch 060 - training loss: 0.1012, validation loss: 0.1123
2024-05-25 05:18:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch60_loss0.11228943765163421.pypots
2024-05-25 05:19:09 [INFO]: Epoch 061 - training loss: 0.1048, validation loss: 0.1115
2024-05-25 05:19:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch61_loss0.11145895794034004.pypots
2024-05-25 05:19:26 [INFO]: Epoch 062 - training loss: 0.1025, validation loss: 0.1109
2024-05-25 05:19:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch62_loss0.11088738068938256.pypots
2024-05-25 05:19:42 [INFO]: Epoch 063 - training loss: 0.1132, validation loss: 0.1093
2024-05-25 05:19:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch63_loss0.10932553410530091.pypots
2024-05-25 05:19:59 [INFO]: Epoch 064 - training loss: 0.1072, validation loss: 0.1111
2024-05-25 05:19:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch64_loss0.11110104396939277.pypots
2024-05-25 05:20:16 [INFO]: Epoch 065 - training loss: 0.1222, validation loss: 0.1106
2024-05-25 05:20:16 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch65_loss0.11056614890694619.pypots
2024-05-25 05:20:32 [INFO]: Epoch 066 - training loss: 0.1060, validation loss: 0.1083
2024-05-25 05:20:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch66_loss0.10830626785755157.pypots
2024-05-25 05:20:49 [INFO]: Epoch 067 - training loss: 0.1134, validation loss: 0.1086
2024-05-25 05:20:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch67_loss0.10861948505043983.pypots
2024-05-25 05:21:06 [INFO]: Epoch 068 - training loss: 0.1020, validation loss: 0.1096
2024-05-25 05:21:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch68_loss0.10955672338604927.pypots
2024-05-25 05:21:23 [INFO]: Epoch 069 - training loss: 0.0991, validation loss: 0.1087
2024-05-25 05:21:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch69_loss0.10871523097157479.pypots
2024-05-25 05:21:39 [INFO]: Epoch 070 - training loss: 0.1150, validation loss: 0.1103
2024-05-25 05:21:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch70_loss0.11032595038414002.pypots
2024-05-25 05:21:56 [INFO]: Epoch 071 - training loss: 0.1008, validation loss: 0.1063
2024-05-25 05:21:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch71_loss0.1063100479543209.pypots
2024-05-25 05:22:13 [INFO]: Epoch 072 - training loss: 0.1081, validation loss: 0.1079
2024-05-25 05:22:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch72_loss0.10785042271018028.pypots
2024-05-25 05:22:29 [INFO]: Epoch 073 - training loss: 0.1003, validation loss: 0.1120
2024-05-25 05:22:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch73_loss0.11199249625205994.pypots
2024-05-25 05:22:46 [INFO]: Epoch 074 - training loss: 0.1115, validation loss: 0.1079
2024-05-25 05:22:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch74_loss0.10789624005556106.pypots
2024-05-25 05:23:03 [INFO]: Epoch 075 - training loss: 0.1006, validation loss: 0.1108
2024-05-25 05:23:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch75_loss0.11084406524896621.pypots
2024-05-25 05:23:19 [INFO]: Epoch 076 - training loss: 0.1075, validation loss: 0.1128
2024-05-25 05:23:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch76_loss0.1128129243850708.pypots
2024-05-25 05:23:36 [INFO]: Epoch 077 - training loss: 0.1077, validation loss: 0.1103
2024-05-25 05:23:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch77_loss0.11026562452316284.pypots
2024-05-25 05:23:53 [INFO]: Epoch 078 - training loss: 0.1197, validation loss: 0.1082
2024-05-25 05:23:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch78_loss0.10819116905331612.pypots
2024-05-25 05:24:09 [INFO]: Epoch 079 - training loss: 0.1117, validation loss: 0.1055
2024-05-25 05:24:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch79_loss0.10553754940629005.pypots
2024-05-25 05:24:26 [INFO]: Epoch 080 - training loss: 0.0996, validation loss: 0.1068
2024-05-25 05:24:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch80_loss0.10680163130164147.pypots
2024-05-25 05:24:43 [INFO]: Epoch 081 - training loss: 0.1007, validation loss: 0.1062
2024-05-25 05:24:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch81_loss0.10617870986461639.pypots
2024-05-25 05:24:59 [INFO]: Epoch 082 - training loss: 0.1070, validation loss: 0.1049
2024-05-25 05:24:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch82_loss0.10489775836467743.pypots
2024-05-25 05:25:16 [INFO]: Epoch 083 - training loss: 0.1001, validation loss: 0.1058
2024-05-25 05:25:16 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch83_loss0.10582010820508003.pypots
2024-05-25 05:25:33 [INFO]: Epoch 084 - training loss: 0.1122, validation loss: 0.1062
2024-05-25 05:25:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch84_loss0.10615846589207649.pypots
2024-05-25 05:25:49 [INFO]: Epoch 085 - training loss: 0.1008, validation loss: 0.1057
2024-05-25 05:25:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch85_loss0.1056963287293911.pypots
2024-05-25 05:26:06 [INFO]: Epoch 086 - training loss: 0.1084, validation loss: 0.1044
2024-05-25 05:26:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch86_loss0.10439683720469475.pypots
2024-05-25 05:26:23 [INFO]: Epoch 087 - training loss: 0.0964, validation loss: 0.1048
2024-05-25 05:26:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch87_loss0.10482161492109299.pypots
2024-05-25 05:26:39 [INFO]: Epoch 088 - training loss: 0.1095, validation loss: 0.1036
2024-05-25 05:26:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch88_loss0.10357855781912803.pypots
2024-05-25 05:26:56 [INFO]: Epoch 089 - training loss: 0.0959, validation loss: 0.1039
2024-05-25 05:26:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch89_loss0.10392610803246498.pypots
2024-05-25 05:27:13 [INFO]: Epoch 090 - training loss: 0.1016, validation loss: 0.1057
2024-05-25 05:27:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch90_loss0.10570778995752335.pypots
2024-05-25 05:27:30 [INFO]: Epoch 091 - training loss: 0.1111, validation loss: 0.1035
2024-05-25 05:27:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch91_loss0.10351003855466842.pypots
2024-05-25 05:27:46 [INFO]: Epoch 092 - training loss: 0.0957, validation loss: 0.1027
2024-05-25 05:27:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch92_loss0.10273915007710457.pypots
2024-05-25 05:28:03 [INFO]: Epoch 093 - training loss: 0.1072, validation loss: 0.1029
2024-05-25 05:28:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch93_loss0.10291474312543869.pypots
2024-05-25 05:28:20 [INFO]: Epoch 094 - training loss: 0.0964, validation loss: 0.1029
2024-05-25 05:28:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch94_loss0.10288721770048141.pypots
2024-05-25 05:28:36 [INFO]: Epoch 095 - training loss: 0.1089, validation loss: 0.1074
2024-05-25 05:28:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch95_loss0.1073820248246193.pypots
2024-05-25 05:28:53 [INFO]: Epoch 096 - training loss: 0.0956, validation loss: 0.1065
2024-05-25 05:28:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch96_loss0.10648979321122169.pypots
2024-05-25 05:29:10 [INFO]: Epoch 097 - training loss: 0.1119, validation loss: 0.1058
2024-05-25 05:29:10 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch97_loss0.10580508485436439.pypots
2024-05-25 05:29:26 [INFO]: Epoch 098 - training loss: 0.1010, validation loss: 0.1026
2024-05-25 05:29:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch98_loss0.10264423787593842.pypots
2024-05-25 05:29:43 [INFO]: Epoch 099 - training loss: 0.1055, validation loss: 0.1034
2024-05-25 05:29:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch99_loss0.10343118980526925.pypots
2024-05-25 05:30:00 [INFO]: Epoch 100 - training loss: 0.1008, validation loss: 0.1068
2024-05-25 05:30:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch100_loss0.10678405463695526.pypots
2024-05-25 05:30:16 [INFO]: Epoch 101 - training loss: 0.1050, validation loss: 0.1035
2024-05-25 05:30:16 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch101_loss0.10354125797748566.pypots
2024-05-25 05:30:33 [INFO]: Epoch 102 - training loss: 0.0969, validation loss: 0.1026
2024-05-25 05:30:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch102_loss0.10264398381114007.pypots
2024-05-25 05:30:50 [INFO]: Epoch 103 - training loss: 0.0904, validation loss: 0.1030
2024-05-25 05:30:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch103_loss0.10302645340561867.pypots
2024-05-25 05:31:07 [INFO]: Epoch 104 - training loss: 0.0996, validation loss: 0.1010
2024-05-25 05:31:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch104_loss0.10103966146707535.pypots
2024-05-25 05:31:23 [INFO]: Epoch 105 - training loss: 0.1095, validation loss: 0.1016
2024-05-25 05:31:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch105_loss0.101558768004179.pypots
2024-05-25 05:31:40 [INFO]: Epoch 106 - training loss: 0.0976, validation loss: 0.1032
2024-05-25 05:31:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch106_loss0.10323294028639793.pypots
2024-05-25 05:31:57 [INFO]: Epoch 107 - training loss: 0.0954, validation loss: 0.1034
2024-05-25 05:31:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch107_loss0.10336571708321571.pypots
2024-05-25 05:32:13 [INFO]: Epoch 108 - training loss: 0.1042, validation loss: 0.1009
2024-05-25 05:32:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch108_loss0.10086359158158302.pypots
2024-05-25 05:32:30 [INFO]: Epoch 109 - training loss: 0.1020, validation loss: 0.1027
2024-05-25 05:32:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch109_loss0.10274143666028976.pypots
2024-05-25 05:32:47 [INFO]: Epoch 110 - training loss: 0.0957, validation loss: 0.1008
2024-05-25 05:32:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch110_loss0.10077044889330863.pypots
2024-05-25 05:33:03 [INFO]: Epoch 111 - training loss: 0.1072, validation loss: 0.1013
2024-05-25 05:33:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch111_loss0.10132942348718643.pypots
2024-05-25 05:33:20 [INFO]: Epoch 112 - training loss: 0.0946, validation loss: 0.1010
2024-05-25 05:33:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch112_loss0.10102710276842117.pypots
2024-05-25 05:33:37 [INFO]: Epoch 113 - training loss: 0.1031, validation loss: 0.1007
2024-05-25 05:33:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch113_loss0.10070513635873794.pypots
2024-05-25 05:33:53 [INFO]: Epoch 114 - training loss: 0.0983, validation loss: 0.1053
2024-05-25 05:33:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch114_loss0.10530492141842843.pypots
2024-05-25 05:34:10 [INFO]: Epoch 115 - training loss: 0.0968, validation loss: 0.1017
2024-05-25 05:34:10 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch115_loss0.10169399827718735.pypots
2024-05-25 05:34:27 [INFO]: Epoch 116 - training loss: 0.0910, validation loss: 0.1007
2024-05-25 05:34:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch116_loss0.10068035796284676.pypots
2024-05-25 05:34:43 [INFO]: Epoch 117 - training loss: 0.1026, validation loss: 0.1019
2024-05-25 05:34:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch117_loss0.1018544889986515.pypots
2024-05-25 05:35:00 [INFO]: Epoch 118 - training loss: 0.0959, validation loss: 0.1010
2024-05-25 05:35:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch118_loss0.10104107037186623.pypots
2024-05-25 05:35:17 [INFO]: Epoch 119 - training loss: 0.1039, validation loss: 0.1026
2024-05-25 05:35:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch119_loss0.10261488556861878.pypots
2024-05-25 05:35:33 [INFO]: Epoch 120 - training loss: 0.0994, validation loss: 0.1012
2024-05-25 05:35:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch120_loss0.10117713883519172.pypots
2024-05-25 05:35:50 [INFO]: Epoch 121 - training loss: 0.0979, validation loss: 0.1028
2024-05-25 05:35:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch121_loss0.10276947841048241.pypots
2024-05-25 05:36:07 [INFO]: Epoch 122 - training loss: 0.0940, validation loss: 0.1007
2024-05-25 05:36:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch122_loss0.1006817176938057.pypots
2024-05-25 05:36:23 [INFO]: Epoch 123 - training loss: 0.0901, validation loss: 0.1037
2024-05-25 05:36:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch123_loss0.10365015640854836.pypots
2024-05-25 05:36:40 [INFO]: Epoch 124 - training loss: 0.1028, validation loss: 0.1003
2024-05-25 05:36:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch124_loss0.10032682344317437.pypots
2024-05-25 05:36:57 [INFO]: Epoch 125 - training loss: 0.1022, validation loss: 0.1046
2024-05-25 05:36:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch125_loss0.10458160191774368.pypots
2024-05-25 05:37:13 [INFO]: Epoch 126 - training loss: 0.0921, validation loss: 0.0995
2024-05-25 05:37:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch126_loss0.09954659119248391.pypots
2024-05-25 05:37:30 [INFO]: Epoch 127 - training loss: 0.0962, validation loss: 0.1001
2024-05-25 05:37:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch127_loss0.10006868466734886.pypots
2024-05-25 05:37:47 [INFO]: Epoch 128 - training loss: 0.0985, validation loss: 0.0993
2024-05-25 05:37:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch128_loss0.09927853271365165.pypots
2024-05-25 05:38:03 [INFO]: Epoch 129 - training loss: 0.1014, validation loss: 0.0992
2024-05-25 05:38:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch129_loss0.09922520965337753.pypots
2024-05-25 05:38:20 [INFO]: Epoch 130 - training loss: 0.1023, validation loss: 0.1014
2024-05-25 05:38:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch130_loss0.1013798899948597.pypots
2024-05-25 05:38:37 [INFO]: Epoch 131 - training loss: 0.0947, validation loss: 0.0987
2024-05-25 05:38:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch131_loss0.09866681843996047.pypots
2024-05-25 05:38:53 [INFO]: Epoch 132 - training loss: 0.0912, validation loss: 0.0994
2024-05-25 05:38:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch132_loss0.09940162226557732.pypots
2024-05-25 05:39:10 [INFO]: Epoch 133 - training loss: 0.1046, validation loss: 0.1000
2024-05-25 05:39:10 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch133_loss0.1000477485358715.pypots
2024-05-25 05:39:27 [INFO]: Epoch 134 - training loss: 0.1108, validation loss: 0.1000
2024-05-25 05:39:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch134_loss0.09998397752642632.pypots
2024-05-25 05:39:44 [INFO]: Epoch 135 - training loss: 0.1039, validation loss: 0.1015
2024-05-25 05:39:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch135_loss0.10153912007808685.pypots
2024-05-25 05:40:00 [INFO]: Epoch 136 - training loss: 0.0913, validation loss: 0.1006
2024-05-25 05:40:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch136_loss0.10062896460294724.pypots
2024-05-25 05:40:17 [INFO]: Epoch 137 - training loss: 0.0989, validation loss: 0.0998
2024-05-25 05:40:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch137_loss0.0998425155878067.pypots
2024-05-25 05:40:34 [INFO]: Epoch 138 - training loss: 0.0910, validation loss: 0.0984
2024-05-25 05:40:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch138_loss0.09839132577180862.pypots
2024-05-25 05:40:50 [INFO]: Epoch 139 - training loss: 0.0969, validation loss: 0.0981
2024-05-25 05:40:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch139_loss0.09809359684586524.pypots
2024-05-25 05:41:07 [INFO]: Epoch 140 - training loss: 0.0980, validation loss: 0.0981
2024-05-25 05:41:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch140_loss0.09805840030312538.pypots
2024-05-25 05:41:24 [INFO]: Epoch 141 - training loss: 0.0891, validation loss: 0.0990
2024-05-25 05:41:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch141_loss0.09895215779542924.pypots
2024-05-25 05:41:40 [INFO]: Epoch 142 - training loss: 0.1014, validation loss: 0.0994
2024-05-25 05:41:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch142_loss0.0993659496307373.pypots
2024-05-25 05:41:57 [INFO]: Epoch 143 - training loss: 0.1003, validation loss: 0.0987
2024-05-25 05:41:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch143_loss0.09872934147715569.pypots
2024-05-25 05:42:14 [INFO]: Epoch 144 - training loss: 0.0877, validation loss: 0.0975
2024-05-25 05:42:14 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch144_loss0.09753096699714661.pypots
2024-05-25 05:42:30 [INFO]: Epoch 145 - training loss: 0.0882, validation loss: 0.1020
2024-05-25 05:42:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch145_loss0.10198503360152245.pypots
2024-05-25 05:42:47 [INFO]: Epoch 146 - training loss: 0.0933, validation loss: 0.1033
2024-05-25 05:42:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch146_loss0.10325233414769172.pypots
2024-05-25 05:43:04 [INFO]: Epoch 147 - training loss: 0.1039, validation loss: 0.1016
2024-05-25 05:43:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch147_loss0.10162502452731133.pypots
2024-05-25 05:43:20 [INFO]: Epoch 148 - training loss: 0.0999, validation loss: 0.1014
2024-05-25 05:43:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch148_loss0.10136391147971154.pypots
2024-05-25 05:43:37 [INFO]: Epoch 149 - training loss: 0.0984, validation loss: 0.0983
2024-05-25 05:43:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch149_loss0.0983186975121498.pypots
2024-05-25 05:43:54 [INFO]: Epoch 150 - training loss: 0.0988, validation loss: 0.1011
2024-05-25 05:43:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch150_loss0.10106171146035195.pypots
2024-05-25 05:44:10 [INFO]: Epoch 151 - training loss: 0.0963, validation loss: 0.1070
2024-05-25 05:44:10 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch151_loss0.106955286860466.pypots
2024-05-25 05:44:27 [INFO]: Epoch 152 - training loss: 0.0930, validation loss: 0.0984
2024-05-25 05:44:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch152_loss0.09844327047467231.pypots
2024-05-25 05:44:44 [INFO]: Epoch 153 - training loss: 0.0965, validation loss: 0.0986
2024-05-25 05:44:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch153_loss0.0985718123614788.pypots
2024-05-25 05:45:00 [INFO]: Epoch 154 - training loss: 0.0974, validation loss: 0.1013
2024-05-25 05:45:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI_epoch154_loss0.1013073056936264.pypots
2024-05-25 05:45:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:45:00 [INFO]: Finished training. The best model is from epoch#144.
2024-05-25 05:45:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T050211/CSDI.pypots
2024-05-25 05:47:21 [INFO]: CSDI on Air-Quality: MAE=0.1066, MSE=0.2329
2024-05-25 05:47:21 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/CSDI_air_quality/imputation.pkl
2024-05-25 05:47:21 [INFO]: Using the given device: cuda:0
2024-05-25 05:47:21 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/GPVAE_air_quality/20240525_T054721
2024-05-25 05:47:21 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/GPVAE_air_quality/20240525_T054721/tensorboard
2024-05-25 05:47:21 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 05:47:21 [INFO]: Epoch 001 - training loss: 64452.4753, validation loss: 0.6493
2024-05-25 05:47:22 [INFO]: Epoch 002 - training loss: 41546.5223, validation loss: 0.5537
2024-05-25 05:47:22 [INFO]: Epoch 003 - training loss: 41208.6467, validation loss: 0.5570
2024-05-25 05:47:22 [INFO]: Epoch 004 - training loss: 41060.2157, validation loss: 0.4734
2024-05-25 05:47:23 [INFO]: Epoch 005 - training loss: 40958.4168, validation loss: 0.4415
2024-05-25 05:47:23 [INFO]: Epoch 006 - training loss: 40907.5226, validation loss: 0.4048
2024-05-25 05:47:23 [INFO]: Epoch 007 - training loss: 40851.0803, validation loss: 0.3659
2024-05-25 05:47:24 [INFO]: Epoch 008 - training loss: 40830.5091, validation loss: 0.3763
2024-05-25 05:47:24 [INFO]: Epoch 009 - training loss: 40808.3659, validation loss: 0.3847
2024-05-25 05:47:24 [INFO]: Epoch 010 - training loss: 40785.6538, validation loss: 0.3353
2024-05-25 05:47:25 [INFO]: Epoch 011 - training loss: 40760.4782, validation loss: 0.3177
2024-05-25 05:47:25 [INFO]: Epoch 012 - training loss: 40736.5294, validation loss: 0.3029
2024-05-25 05:47:25 [INFO]: Epoch 013 - training loss: 40716.8913, validation loss: 0.3036
2024-05-25 05:47:26 [INFO]: Epoch 014 - training loss: 40711.8354, validation loss: 0.3089
2024-05-25 05:47:26 [INFO]: Epoch 015 - training loss: 40689.8837, validation loss: 0.2944
2024-05-25 05:47:26 [INFO]: Epoch 016 - training loss: 40690.4311, validation loss: 0.2929
2024-05-25 05:47:27 [INFO]: Epoch 017 - training loss: 40673.1166, validation loss: 0.3097
2024-05-25 05:47:27 [INFO]: Epoch 018 - training loss: 40674.7944, validation loss: 0.2842
2024-05-25 05:47:27 [INFO]: Epoch 019 - training loss: 40661.9682, validation loss: 0.2944
2024-05-25 05:47:28 [INFO]: Epoch 020 - training loss: 40657.7694, validation loss: 0.2784
2024-05-25 05:47:28 [INFO]: Epoch 021 - training loss: 40637.5312, validation loss: 0.2945
2024-05-25 05:47:28 [INFO]: Epoch 022 - training loss: 40644.3346, validation loss: 0.2711
2024-05-25 05:47:29 [INFO]: Epoch 023 - training loss: 40631.8093, validation loss: 0.2820
2024-05-25 05:47:29 [INFO]: Epoch 024 - training loss: 40624.9446, validation loss: 0.2667
2024-05-25 05:47:29 [INFO]: Epoch 025 - training loss: 40618.8160, validation loss: 0.2804
2024-05-25 05:47:30 [INFO]: Epoch 026 - training loss: 40616.3702, validation loss: 0.2634
2024-05-25 05:47:30 [INFO]: Epoch 027 - training loss: 40621.9702, validation loss: 0.2782
2024-05-25 05:47:30 [INFO]: Epoch 028 - training loss: 40608.0974, validation loss: 0.2508
2024-05-25 05:47:31 [INFO]: Epoch 029 - training loss: 40607.0389, validation loss: 0.2567
2024-05-25 05:47:31 [INFO]: Epoch 030 - training loss: 40600.2951, validation loss: 0.2553
2024-05-25 05:47:31 [INFO]: Epoch 031 - training loss: 40595.3909, validation loss: 0.2608
2024-05-25 05:47:32 [INFO]: Epoch 032 - training loss: 40595.4049, validation loss: 0.2494
2024-05-25 05:47:32 [INFO]: Epoch 033 - training loss: 40637.3762, validation loss: 0.2632
2024-05-25 05:47:32 [INFO]: Epoch 034 - training loss: 40641.4200, validation loss: 0.2775
2024-05-25 05:47:33 [INFO]: Epoch 035 - training loss: 40621.2812, validation loss: 0.2680
2024-05-25 05:47:33 [INFO]: Epoch 036 - training loss: 40608.7273, validation loss: 0.2742
2024-05-25 05:47:33 [INFO]: Epoch 037 - training loss: 40603.7850, validation loss: 0.2621
2024-05-25 05:47:34 [INFO]: Epoch 038 - training loss: 40588.2784, validation loss: 0.2358
2024-05-25 05:47:34 [INFO]: Epoch 039 - training loss: 40575.2669, validation loss: 0.2381
2024-05-25 05:47:34 [INFO]: Epoch 040 - training loss: 40572.8927, validation loss: 0.2330
2024-05-25 05:47:35 [INFO]: Epoch 041 - training loss: 40571.9955, validation loss: 0.2278
2024-05-25 05:47:35 [INFO]: Epoch 042 - training loss: 40568.8343, validation loss: 0.2286
2024-05-25 05:47:36 [INFO]: Epoch 043 - training loss: 40562.1895, validation loss: 0.2264
2024-05-25 05:47:36 [INFO]: Epoch 044 - training loss: 40557.3440, validation loss: 0.2239
2024-05-25 05:47:36 [INFO]: Epoch 045 - training loss: 40554.6578, validation loss: 0.2241
2024-05-25 05:47:37 [INFO]: Epoch 046 - training loss: 40557.3315, validation loss: 0.2209
2024-05-25 05:47:37 [INFO]: Epoch 047 - training loss: 40557.8465, validation loss: 0.2211
2024-05-25 05:47:37 [INFO]: Epoch 048 - training loss: 40551.1778, validation loss: 0.2248
2024-05-25 05:47:38 [INFO]: Epoch 049 - training loss: 40549.7348, validation loss: 0.2205
2024-05-25 05:47:38 [INFO]: Epoch 050 - training loss: 40551.8281, validation loss: 0.2245
2024-05-25 05:47:38 [INFO]: Epoch 051 - training loss: 40547.5883, validation loss: 0.2158
2024-05-25 05:47:39 [INFO]: Epoch 052 - training loss: 40545.2121, validation loss: 0.2149
2024-05-25 05:47:39 [INFO]: Epoch 053 - training loss: 40547.4170, validation loss: 0.2195
2024-05-25 05:47:39 [INFO]: Epoch 054 - training loss: 40546.6282, validation loss: 0.2163
2024-05-25 05:47:40 [INFO]: Epoch 055 - training loss: 40553.0298, validation loss: 0.2390
2024-05-25 05:47:40 [INFO]: Epoch 056 - training loss: 40563.4767, validation loss: 0.2315
2024-05-25 05:47:40 [INFO]: Epoch 057 - training loss: 40552.2206, validation loss: 0.2214
2024-05-25 05:47:41 [INFO]: Epoch 058 - training loss: 40560.5246, validation loss: 0.2236
2024-05-25 05:47:41 [INFO]: Epoch 059 - training loss: 40583.7093, validation loss: 0.2166
2024-05-25 05:47:41 [INFO]: Epoch 060 - training loss: 40561.2070, validation loss: 0.2387
2024-05-25 05:47:42 [INFO]: Epoch 061 - training loss: 40575.8783, validation loss: 0.2335
2024-05-25 05:47:42 [INFO]: Epoch 062 - training loss: 40580.5456, validation loss: 0.2152
2024-05-25 05:47:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:47:42 [INFO]: Finished training. The best model is from epoch#52.
2024-05-25 05:47:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/GPVAE_air_quality/20240525_T054721/GPVAE.pypots
2024-05-25 05:47:42 [INFO]: GP-VAE on Air-Quality: MAE=0.2787, MSE=0.2717
2024-05-25 05:47:42 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/GPVAE_air_quality/imputation.pkl
2024-05-25 05:47:42 [INFO]: Using the given device: cuda:0
2024-05-25 05:47:42 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/USGAN_air_quality/20240525_T054742
2024-05-25 05:47:42 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/USGAN_air_quality/20240525_T054742/tensorboard
2024-05-25 05:47:42 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 05:47:47 [INFO]: Epoch 001 - generator training loss: 0.3410, discriminator training loss: 0.5655, validation loss: 0.5017
2024-05-25 05:47:51 [INFO]: Epoch 002 - generator training loss: 0.0304, discriminator training loss: 0.5235, validation loss: 0.3794
2024-05-25 05:47:55 [INFO]: Epoch 003 - generator training loss: -0.0414, discriminator training loss: 0.5181, validation loss: 0.3135
2024-05-25 05:47:59 [INFO]: Epoch 004 - generator training loss: -0.0797, discriminator training loss: 0.5137, validation loss: 0.2717
2024-05-25 05:48:04 [INFO]: Epoch 005 - generator training loss: -0.1033, discriminator training loss: 0.5088, validation loss: 0.2421
2024-05-25 05:48:08 [INFO]: Epoch 006 - generator training loss: -0.1183, discriminator training loss: 0.5032, validation loss: 0.2224
2024-05-25 05:48:12 [INFO]: Epoch 007 - generator training loss: -0.1286, discriminator training loss: 0.4965, validation loss: 0.2084
2024-05-25 05:48:16 [INFO]: Epoch 008 - generator training loss: -0.1345, discriminator training loss: 0.4889, validation loss: 0.1977
2024-05-25 05:48:20 [INFO]: Epoch 009 - generator training loss: -0.1371, discriminator training loss: 0.4802, validation loss: 0.1897
2024-05-25 05:48:24 [INFO]: Epoch 010 - generator training loss: -0.1370, discriminator training loss: 0.4706, validation loss: 0.1837
2024-05-25 05:48:28 [INFO]: Epoch 011 - generator training loss: -0.1374, discriminator training loss: 0.4600, validation loss: 0.1779
2024-05-25 05:48:33 [INFO]: Epoch 012 - generator training loss: -0.1328, discriminator training loss: 0.4494, validation loss: 0.1728
2024-05-25 05:48:37 [INFO]: Epoch 013 - generator training loss: -0.1324, discriminator training loss: 0.4383, validation loss: 0.1688
2024-05-25 05:48:41 [INFO]: Epoch 014 - generator training loss: -0.1292, discriminator training loss: 0.4277, validation loss: 0.1652
2024-05-25 05:48:45 [INFO]: Epoch 015 - generator training loss: -0.1231, discriminator training loss: 0.4173, validation loss: 0.1612
2024-05-25 05:48:49 [INFO]: Epoch 016 - generator training loss: -0.1221, discriminator training loss: 0.4077, validation loss: 0.1588
2024-05-25 05:48:53 [INFO]: Epoch 017 - generator training loss: -0.1184, discriminator training loss: 0.3984, validation loss: 0.1564
2024-05-25 05:48:57 [INFO]: Epoch 018 - generator training loss: -0.1169, discriminator training loss: 0.3902, validation loss: 0.1539
2024-05-25 05:49:02 [INFO]: Epoch 019 - generator training loss: -0.1144, discriminator training loss: 0.3829, validation loss: 0.1511
2024-05-25 05:49:06 [INFO]: Epoch 020 - generator training loss: -0.1114, discriminator training loss: 0.3760, validation loss: 0.1493
2024-05-25 05:49:10 [INFO]: Epoch 021 - generator training loss: -0.1097, discriminator training loss: 0.3695, validation loss: 0.1469
2024-05-25 05:49:14 [INFO]: Epoch 022 - generator training loss: -0.1073, discriminator training loss: 0.3642, validation loss: 0.1452
2024-05-25 05:49:18 [INFO]: Epoch 023 - generator training loss: -0.1076, discriminator training loss: 0.3588, validation loss: 0.1432
2024-05-25 05:49:22 [INFO]: Epoch 024 - generator training loss: -0.1051, discriminator training loss: 0.3542, validation loss: 0.1412
2024-05-25 05:49:26 [INFO]: Epoch 025 - generator training loss: -0.1044, discriminator training loss: 0.3502, validation loss: 0.1402
2024-05-25 05:49:30 [INFO]: Epoch 026 - generator training loss: -0.1035, discriminator training loss: 0.3467, validation loss: 0.1380
2024-05-25 05:49:35 [INFO]: Epoch 027 - generator training loss: -0.1027, discriminator training loss: 0.3430, validation loss: 0.1366
2024-05-25 05:49:39 [INFO]: Epoch 028 - generator training loss: -0.1009, discriminator training loss: 0.3402, validation loss: 0.1349
2024-05-25 05:49:43 [INFO]: Epoch 029 - generator training loss: -0.1026, discriminator training loss: 0.3369, validation loss: 0.1333
2024-05-25 05:49:47 [INFO]: Epoch 030 - generator training loss: -0.1016, discriminator training loss: 0.3348, validation loss: 0.1330
2024-05-25 05:49:51 [INFO]: Epoch 031 - generator training loss: -0.0997, discriminator training loss: 0.3322, validation loss: 0.1316
2024-05-25 05:49:55 [INFO]: Epoch 032 - generator training loss: -0.1019, discriminator training loss: 0.3299, validation loss: 0.1302
2024-05-25 05:49:59 [INFO]: Epoch 033 - generator training loss: -0.1012, discriminator training loss: 0.3285, validation loss: 0.1286
2024-05-25 05:50:03 [INFO]: Epoch 034 - generator training loss: -0.1007, discriminator training loss: 0.3269, validation loss: 0.1275
2024-05-25 05:50:07 [INFO]: Epoch 035 - generator training loss: -0.1017, discriminator training loss: 0.3246, validation loss: 0.1265
2024-05-25 05:50:12 [INFO]: Epoch 036 - generator training loss: -0.1027, discriminator training loss: 0.3230, validation loss: 0.1252
2024-05-25 05:50:16 [INFO]: Epoch 037 - generator training loss: -0.1012, discriminator training loss: 0.3216, validation loss: 0.1245
2024-05-25 05:50:20 [INFO]: Epoch 038 - generator training loss: -0.1029, discriminator training loss: 0.3210, validation loss: 0.1238
2024-05-25 05:50:24 [INFO]: Epoch 039 - generator training loss: -0.1018, discriminator training loss: 0.3194, validation loss: 0.1227
2024-05-25 05:50:28 [INFO]: Epoch 040 - generator training loss: -0.1024, discriminator training loss: 0.3185, validation loss: 0.1221
2024-05-25 05:50:32 [INFO]: Epoch 041 - generator training loss: -0.1041, discriminator training loss: 0.3173, validation loss: 0.1211
2024-05-25 05:50:36 [INFO]: Epoch 042 - generator training loss: -0.1039, discriminator training loss: 0.3167, validation loss: 0.1204
2024-05-25 05:50:41 [INFO]: Epoch 043 - generator training loss: -0.1022, discriminator training loss: 0.3155, validation loss: 0.1193
2024-05-25 05:50:45 [INFO]: Epoch 044 - generator training loss: -0.1040, discriminator training loss: 0.3149, validation loss: 0.1180
2024-05-25 05:50:49 [INFO]: Epoch 045 - generator training loss: -0.1052, discriminator training loss: 0.3146, validation loss: 0.1178
2024-05-25 05:50:53 [INFO]: Epoch 046 - generator training loss: -0.1054, discriminator training loss: 0.3131, validation loss: 0.1175
2024-05-25 05:50:57 [INFO]: Epoch 047 - generator training loss: -0.1047, discriminator training loss: 0.3127, validation loss: 0.1168
2024-05-25 05:51:01 [INFO]: Epoch 048 - generator training loss: -0.1062, discriminator training loss: 0.3122, validation loss: 0.1163
2024-05-25 05:51:05 [INFO]: Epoch 049 - generator training loss: -0.1060, discriminator training loss: 0.3120, validation loss: 0.1158
2024-05-25 05:51:09 [INFO]: Epoch 050 - generator training loss: -0.1069, discriminator training loss: 0.3106, validation loss: 0.1145
2024-05-25 05:51:14 [INFO]: Epoch 051 - generator training loss: -0.1069, discriminator training loss: 0.3103, validation loss: 0.1150
2024-05-25 05:51:18 [INFO]: Epoch 052 - generator training loss: -0.1078, discriminator training loss: 0.3103, validation loss: 0.1134
2024-05-25 05:51:22 [INFO]: Epoch 053 - generator training loss: -0.1079, discriminator training loss: 0.3101, validation loss: 0.1139
2024-05-25 05:51:26 [INFO]: Epoch 054 - generator training loss: -0.1086, discriminator training loss: 0.3093, validation loss: 0.1129
2024-05-25 05:51:30 [INFO]: Epoch 055 - generator training loss: -0.1086, discriminator training loss: 0.3090, validation loss: 0.1119
2024-05-25 05:51:34 [INFO]: Epoch 056 - generator training loss: -0.1104, discriminator training loss: 0.3091, validation loss: 0.1121
2024-05-25 05:51:38 [INFO]: Epoch 057 - generator training loss: -0.1098, discriminator training loss: 0.3084, validation loss: 0.1118
2024-05-25 05:51:42 [INFO]: Epoch 058 - generator training loss: -0.1114, discriminator training loss: 0.3077, validation loss: 0.1112
2024-05-25 05:51:47 [INFO]: Epoch 059 - generator training loss: -0.1107, discriminator training loss: 0.3082, validation loss: 0.1107
2024-05-25 05:51:51 [INFO]: Epoch 060 - generator training loss: -0.1090, discriminator training loss: 0.3082, validation loss: 0.1105
2024-05-25 05:51:55 [INFO]: Epoch 061 - generator training loss: -0.1107, discriminator training loss: 0.3076, validation loss: 0.1097
2024-05-25 05:51:59 [INFO]: Epoch 062 - generator training loss: -0.1113, discriminator training loss: 0.3073, validation loss: 0.1100
2024-05-25 05:52:03 [INFO]: Epoch 063 - generator training loss: -0.1121, discriminator training loss: 0.3067, validation loss: 0.1091
2024-05-25 05:52:07 [INFO]: Epoch 064 - generator training loss: -0.1124, discriminator training loss: 0.3062, validation loss: 0.1089
2024-05-25 05:52:11 [INFO]: Epoch 065 - generator training loss: -0.1118, discriminator training loss: 0.3067, validation loss: 0.1085
2024-05-25 05:52:15 [INFO]: Epoch 066 - generator training loss: -0.1126, discriminator training loss: 0.3063, validation loss: 0.1091
2024-05-25 05:52:19 [INFO]: Epoch 067 - generator training loss: -0.1137, discriminator training loss: 0.3063, validation loss: 0.1077
2024-05-25 05:52:24 [INFO]: Epoch 068 - generator training loss: -0.1140, discriminator training loss: 0.3058, validation loss: 0.1076
2024-05-25 05:52:28 [INFO]: Epoch 069 - generator training loss: -0.1138, discriminator training loss: 0.3055, validation loss: 0.1080
2024-05-25 05:52:32 [INFO]: Epoch 070 - generator training loss: -0.1148, discriminator training loss: 0.3052, validation loss: 0.1072
2024-05-25 05:52:36 [INFO]: Epoch 071 - generator training loss: -0.1153, discriminator training loss: 0.3050, validation loss: 0.1077
2024-05-25 05:52:40 [INFO]: Epoch 072 - generator training loss: -0.1154, discriminator training loss: 0.3046, validation loss: 0.1072
2024-05-25 05:52:44 [INFO]: Epoch 073 - generator training loss: -0.1155, discriminator training loss: 0.3046, validation loss: 0.1069
2024-05-25 05:52:49 [INFO]: Epoch 074 - generator training loss: -0.1158, discriminator training loss: 0.3045, validation loss: 0.1061
2024-05-25 05:52:53 [INFO]: Epoch 075 - generator training loss: -0.1153, discriminator training loss: 0.3041, validation loss: 0.1068
2024-05-25 05:52:57 [INFO]: Epoch 076 - generator training loss: -0.1162, discriminator training loss: 0.3045, validation loss: 0.1061
2024-05-25 05:53:01 [INFO]: Epoch 077 - generator training loss: -0.1157, discriminator training loss: 0.3043, validation loss: 0.1061
2024-05-25 05:53:05 [INFO]: Epoch 078 - generator training loss: -0.1168, discriminator training loss: 0.3044, validation loss: 0.1053
2024-05-25 05:53:09 [INFO]: Epoch 079 - generator training loss: -0.1158, discriminator training loss: 0.3038, validation loss: 0.1057
2024-05-25 05:53:13 [INFO]: Epoch 080 - generator training loss: -0.1179, discriminator training loss: 0.3038, validation loss: 0.1054
2024-05-25 05:53:17 [INFO]: Epoch 081 - generator training loss: -0.1174, discriminator training loss: 0.3032, validation loss: 0.1047
2024-05-25 05:53:21 [INFO]: Epoch 082 - generator training loss: -0.1189, discriminator training loss: 0.3037, validation loss: 0.1049
2024-05-25 05:53:26 [INFO]: Epoch 083 - generator training loss: -0.1188, discriminator training loss: 0.3029, validation loss: 0.1047
2024-05-25 05:53:30 [INFO]: Epoch 084 - generator training loss: -0.1182, discriminator training loss: 0.3029, validation loss: 0.1044
2024-05-25 05:53:34 [INFO]: Epoch 085 - generator training loss: -0.1195, discriminator training loss: 0.3026, validation loss: 0.1045
2024-05-25 05:53:38 [INFO]: Epoch 086 - generator training loss: -0.1188, discriminator training loss: 0.3034, validation loss: 0.1049
2024-05-25 05:53:42 [INFO]: Epoch 087 - generator training loss: -0.1200, discriminator training loss: 0.3027, validation loss: 0.1039
2024-05-25 05:53:46 [INFO]: Epoch 088 - generator training loss: -0.1195, discriminator training loss: 0.3025, validation loss: 0.1046
2024-05-25 05:53:50 [INFO]: Epoch 089 - generator training loss: -0.1199, discriminator training loss: 0.3023, validation loss: 0.1038
2024-05-25 05:53:55 [INFO]: Epoch 090 - generator training loss: -0.1196, discriminator training loss: 0.3022, validation loss: 0.1041
2024-05-25 05:53:59 [INFO]: Epoch 091 - generator training loss: -0.1207, discriminator training loss: 0.3021, validation loss: 0.1041
2024-05-25 05:54:03 [INFO]: Epoch 092 - generator training loss: -0.1214, discriminator training loss: 0.3022, validation loss: 0.1039
2024-05-25 05:54:07 [INFO]: Epoch 093 - generator training loss: -0.1202, discriminator training loss: 0.3020, validation loss: 0.1035
2024-05-25 05:54:11 [INFO]: Epoch 094 - generator training loss: -0.1211, discriminator training loss: 0.3015, validation loss: 0.1037
2024-05-25 05:54:15 [INFO]: Epoch 095 - generator training loss: -0.1213, discriminator training loss: 0.3017, validation loss: 0.1040
2024-05-25 05:54:19 [INFO]: Epoch 096 - generator training loss: -0.1212, discriminator training loss: 0.3023, validation loss: 0.1037
2024-05-25 05:54:23 [INFO]: Epoch 097 - generator training loss: -0.1210, discriminator training loss: 0.3017, validation loss: 0.1035
2024-05-25 05:54:28 [INFO]: Epoch 098 - generator training loss: -0.1215, discriminator training loss: 0.3013, validation loss: 0.1040
2024-05-25 05:54:32 [INFO]: Epoch 099 - generator training loss: -0.1226, discriminator training loss: 0.3014, validation loss: 0.1035
2024-05-25 05:54:36 [INFO]: Epoch 100 - generator training loss: -0.1226, discriminator training loss: 0.3013, validation loss: 0.1033
2024-05-25 05:54:40 [INFO]: Epoch 101 - generator training loss: -0.1231, discriminator training loss: 0.3010, validation loss: 0.1036
2024-05-25 05:54:44 [INFO]: Epoch 102 - generator training loss: -0.1236, discriminator training loss: 0.3007, validation loss: 0.1035
2024-05-25 05:54:48 [INFO]: Epoch 103 - generator training loss: -0.1235, discriminator training loss: 0.3008, validation loss: 0.1030
2024-05-25 05:54:52 [INFO]: Epoch 104 - generator training loss: -0.1233, discriminator training loss: 0.3009, validation loss: 0.1039
2024-05-25 05:54:56 [INFO]: Epoch 105 - generator training loss: -0.1236, discriminator training loss: 0.3005, validation loss: 0.1034
2024-05-25 05:55:01 [INFO]: Epoch 106 - generator training loss: -0.1236, discriminator training loss: 0.2999, validation loss: 0.1030
2024-05-25 05:55:05 [INFO]: Epoch 107 - generator training loss: -0.1233, discriminator training loss: 0.3002, validation loss: 0.1029
2024-05-25 05:55:09 [INFO]: Epoch 108 - generator training loss: -0.1232, discriminator training loss: 0.3000, validation loss: 0.1033
2024-05-25 05:55:13 [INFO]: Epoch 109 - generator training loss: -0.1239, discriminator training loss: 0.3004, validation loss: 0.1038
2024-05-25 05:55:17 [INFO]: Epoch 110 - generator training loss: -0.1237, discriminator training loss: 0.2997, validation loss: 0.1028
2024-05-25 05:55:21 [INFO]: Epoch 111 - generator training loss: -0.1244, discriminator training loss: 0.2998, validation loss: 0.1022
2024-05-25 05:55:25 [INFO]: Epoch 112 - generator training loss: -0.1254, discriminator training loss: 0.2997, validation loss: 0.1030
2024-05-25 05:55:29 [INFO]: Epoch 113 - generator training loss: -0.1242, discriminator training loss: 0.2995, validation loss: 0.1031
2024-05-25 05:55:33 [INFO]: Epoch 114 - generator training loss: -0.1252, discriminator training loss: 0.2995, validation loss: 0.1030
2024-05-25 05:55:38 [INFO]: Epoch 115 - generator training loss: -0.1251, discriminator training loss: 0.2996, validation loss: 0.1055
2024-05-25 05:55:42 [INFO]: Epoch 116 - generator training loss: -0.1240, discriminator training loss: 0.2993, validation loss: 0.1029
2024-05-25 05:55:46 [INFO]: Epoch 117 - generator training loss: -0.1251, discriminator training loss: 0.2995, validation loss: 0.1027
2024-05-25 05:55:50 [INFO]: Epoch 118 - generator training loss: -0.1250, discriminator training loss: 0.2991, validation loss: 0.1027
2024-05-25 05:55:54 [INFO]: Epoch 119 - generator training loss: -0.1260, discriminator training loss: 0.2995, validation loss: 0.1026
2024-05-25 05:55:58 [INFO]: Epoch 120 - generator training loss: -0.1262, discriminator training loss: 0.2988, validation loss: 0.1025
2024-05-25 05:56:02 [INFO]: Epoch 121 - generator training loss: -0.1265, discriminator training loss: 0.2990, validation loss: 0.1026
2024-05-25 05:56:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:56:02 [INFO]: Finished training. The best model is from epoch#111.
2024-05-25 05:56:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/USGAN_air_quality/20240525_T054742/USGAN.pypots
2024-05-25 05:56:03 [INFO]: US-GAN on Air-Quality: MAE=0.1659, MSE=0.1383
2024-05-25 05:56:03 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/USGAN_air_quality/imputation.pkl
2024-05-25 05:56:03 [INFO]: Using the given device: cuda:0
2024-05-25 05:56:03 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/BRITS_air_quality/20240525_T055603
2024-05-25 05:56:03 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/BRITS_air_quality/20240525_T055603/tensorboard
2024-05-25 05:56:03 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 05:56:07 [INFO]: Epoch 001 - training loss: 1.4224, validation loss: 0.9439
2024-05-25 05:56:10 [INFO]: Epoch 002 - training loss: 1.1640, validation loss: 0.6948
2024-05-25 05:56:12 [INFO]: Epoch 003 - training loss: 0.9685, validation loss: 0.5845
2024-05-25 05:56:15 [INFO]: Epoch 004 - training loss: 0.8569, validation loss: 0.5135
2024-05-25 05:56:18 [INFO]: Epoch 005 - training loss: 0.7792, validation loss: 0.4662
2024-05-25 05:56:21 [INFO]: Epoch 006 - training loss: 0.7239, validation loss: 0.4308
2024-05-25 05:56:23 [INFO]: Epoch 007 - training loss: 0.6799, validation loss: 0.4017
2024-05-25 05:56:26 [INFO]: Epoch 008 - training loss: 0.6466, validation loss: 0.3775
2024-05-25 05:56:29 [INFO]: Epoch 009 - training loss: 0.6197, validation loss: 0.3566
2024-05-25 05:56:32 [INFO]: Epoch 010 - training loss: 0.5992, validation loss: 0.3411
2024-05-25 05:56:35 [INFO]: Epoch 011 - training loss: 0.5817, validation loss: 0.3266
2024-05-25 05:56:37 [INFO]: Epoch 012 - training loss: 0.5658, validation loss: 0.3136
2024-05-25 05:56:40 [INFO]: Epoch 013 - training loss: 0.5543, validation loss: 0.3026
2024-05-25 05:56:43 [INFO]: Epoch 014 - training loss: 0.5424, validation loss: 0.2932
2024-05-25 05:56:46 [INFO]: Epoch 015 - training loss: 0.5313, validation loss: 0.2850
2024-05-25 05:56:49 [INFO]: Epoch 016 - training loss: 0.5203, validation loss: 0.2777
2024-05-25 05:56:51 [INFO]: Epoch 017 - training loss: 0.5117, validation loss: 0.2703
2024-05-25 05:56:54 [INFO]: Epoch 018 - training loss: 0.5026, validation loss: 0.2640
2024-05-25 05:56:57 [INFO]: Epoch 019 - training loss: 0.4955, validation loss: 0.2581
2024-05-25 05:57:00 [INFO]: Epoch 020 - training loss: 0.4871, validation loss: 0.2526
2024-05-25 05:57:02 [INFO]: Epoch 021 - training loss: 0.4809, validation loss: 0.2482
2024-05-25 05:57:05 [INFO]: Epoch 022 - training loss: 0.4726, validation loss: 0.2426
2024-05-25 05:57:08 [INFO]: Epoch 023 - training loss: 0.4675, validation loss: 0.2384
2024-05-25 05:57:11 [INFO]: Epoch 024 - training loss: 0.4604, validation loss: 0.2342
2024-05-25 05:57:14 [INFO]: Epoch 025 - training loss: 0.4545, validation loss: 0.2299
2024-05-25 05:57:16 [INFO]: Epoch 026 - training loss: 0.4495, validation loss: 0.2260
2024-05-25 05:57:19 [INFO]: Epoch 027 - training loss: 0.4433, validation loss: 0.2227
2024-05-25 05:57:22 [INFO]: Epoch 028 - training loss: 0.4390, validation loss: 0.2191
2024-05-25 05:57:25 [INFO]: Epoch 029 - training loss: 0.4343, validation loss: 0.2159
2024-05-25 05:57:27 [INFO]: Epoch 030 - training loss: 0.4287, validation loss: 0.2122
2024-05-25 05:57:30 [INFO]: Epoch 031 - training loss: 0.4251, validation loss: 0.2096
2024-05-25 05:57:33 [INFO]: Epoch 032 - training loss: 0.4200, validation loss: 0.2066
2024-05-25 05:57:36 [INFO]: Epoch 033 - training loss: 0.4159, validation loss: 0.2043
2024-05-25 05:57:39 [INFO]: Epoch 034 - training loss: 0.4130, validation loss: 0.2017
2024-05-25 05:57:41 [INFO]: Epoch 035 - training loss: 0.4083, validation loss: 0.1988
2024-05-25 05:57:44 [INFO]: Epoch 036 - training loss: 0.4052, validation loss: 0.1964
2024-05-25 05:57:47 [INFO]: Epoch 037 - training loss: 0.4021, validation loss: 0.1938
2024-05-25 05:57:50 [INFO]: Epoch 038 - training loss: 0.3977, validation loss: 0.1919
2024-05-25 05:57:53 [INFO]: Epoch 039 - training loss: 0.3944, validation loss: 0.1897
2024-05-25 05:57:55 [INFO]: Epoch 040 - training loss: 0.3912, validation loss: 0.1875
2024-05-25 05:57:58 [INFO]: Epoch 041 - training loss: 0.3893, validation loss: 0.1853
2024-05-25 05:58:01 [INFO]: Epoch 042 - training loss: 0.3854, validation loss: 0.1836
2024-05-25 05:58:04 [INFO]: Epoch 043 - training loss: 0.3825, validation loss: 0.1815
2024-05-25 05:58:07 [INFO]: Epoch 044 - training loss: 0.3799, validation loss: 0.1800
2024-05-25 05:58:09 [INFO]: Epoch 045 - training loss: 0.3769, validation loss: 0.1782
2024-05-25 05:58:12 [INFO]: Epoch 046 - training loss: 0.3760, validation loss: 0.1767
2024-05-25 05:58:15 [INFO]: Epoch 047 - training loss: 0.3706, validation loss: 0.1748
2024-05-25 05:58:18 [INFO]: Epoch 048 - training loss: 0.3689, validation loss: 0.1734
2024-05-25 05:58:20 [INFO]: Epoch 049 - training loss: 0.3674, validation loss: 0.1719
2024-05-25 05:58:23 [INFO]: Epoch 050 - training loss: 0.3645, validation loss: 0.1703
2024-05-25 05:58:26 [INFO]: Epoch 051 - training loss: 0.3623, validation loss: 0.1692
2024-05-25 05:58:29 [INFO]: Epoch 052 - training loss: 0.3596, validation loss: 0.1681
2024-05-25 05:58:32 [INFO]: Epoch 053 - training loss: 0.3575, validation loss: 0.1667
2024-05-25 05:58:34 [INFO]: Epoch 054 - training loss: 0.3558, validation loss: 0.1656
2024-05-25 05:58:37 [INFO]: Epoch 055 - training loss: 0.3542, validation loss: 0.1646
2024-05-25 05:58:40 [INFO]: Epoch 056 - training loss: 0.3526, validation loss: 0.1634
2024-05-25 05:58:43 [INFO]: Epoch 057 - training loss: 0.3505, validation loss: 0.1625
2024-05-25 05:58:45 [INFO]: Epoch 058 - training loss: 0.3480, validation loss: 0.1614
2024-05-25 05:58:48 [INFO]: Epoch 059 - training loss: 0.3461, validation loss: 0.1605
2024-05-25 05:58:51 [INFO]: Epoch 060 - training loss: 0.3449, validation loss: 0.1597
2024-05-25 05:58:54 [INFO]: Epoch 061 - training loss: 0.3429, validation loss: 0.1587
2024-05-25 05:58:57 [INFO]: Epoch 062 - training loss: 0.3417, validation loss: 0.1577
2024-05-25 05:58:59 [INFO]: Epoch 063 - training loss: 0.3395, validation loss: 0.1571
2024-05-25 05:59:02 [INFO]: Epoch 064 - training loss: 0.3388, validation loss: 0.1565
2024-05-25 05:59:05 [INFO]: Epoch 065 - training loss: 0.3371, validation loss: 0.1556
2024-05-25 05:59:08 [INFO]: Epoch 066 - training loss: 0.3356, validation loss: 0.1548
2024-05-25 05:59:11 [INFO]: Epoch 067 - training loss: 0.3341, validation loss: 0.1543
2024-05-25 05:59:13 [INFO]: Epoch 068 - training loss: 0.3335, validation loss: 0.1535
2024-05-25 05:59:16 [INFO]: Epoch 069 - training loss: 0.3320, validation loss: 0.1529
2024-05-25 05:59:19 [INFO]: Epoch 070 - training loss: 0.3304, validation loss: 0.1523
2024-05-25 05:59:22 [INFO]: Epoch 071 - training loss: 0.3291, validation loss: 0.1517
2024-05-25 05:59:24 [INFO]: Epoch 072 - training loss: 0.3283, validation loss: 0.1512
2024-05-25 05:59:27 [INFO]: Epoch 073 - training loss: 0.3270, validation loss: 0.1504
2024-05-25 05:59:30 [INFO]: Epoch 074 - training loss: 0.3261, validation loss: 0.1501
2024-05-25 05:59:33 [INFO]: Epoch 075 - training loss: 0.3247, validation loss: 0.1495
2024-05-25 05:59:36 [INFO]: Epoch 076 - training loss: 0.3241, validation loss: 0.1489
2024-05-25 05:59:38 [INFO]: Epoch 077 - training loss: 0.3234, validation loss: 0.1485
2024-05-25 05:59:41 [INFO]: Epoch 078 - training loss: 0.3220, validation loss: 0.1479
2024-05-25 05:59:44 [INFO]: Epoch 079 - training loss: 0.3215, validation loss: 0.1476
2024-05-25 05:59:47 [INFO]: Epoch 080 - training loss: 0.3201, validation loss: 0.1469
2024-05-25 05:59:49 [INFO]: Epoch 081 - training loss: 0.3188, validation loss: 0.1466
2024-05-25 05:59:52 [INFO]: Epoch 082 - training loss: 0.3180, validation loss: 0.1461
2024-05-25 05:59:55 [INFO]: Epoch 083 - training loss: 0.3174, validation loss: 0.1458
2024-05-25 05:59:58 [INFO]: Epoch 084 - training loss: 0.3163, validation loss: 0.1452
2024-05-25 06:00:01 [INFO]: Epoch 085 - training loss: 0.3151, validation loss: 0.1449
2024-05-25 06:00:03 [INFO]: Epoch 086 - training loss: 0.3147, validation loss: 0.1445
2024-05-25 06:00:06 [INFO]: Epoch 087 - training loss: 0.3141, validation loss: 0.1440
2024-05-25 06:00:09 [INFO]: Epoch 088 - training loss: 0.3134, validation loss: 0.1437
2024-05-25 06:00:12 [INFO]: Epoch 089 - training loss: 0.3122, validation loss: 0.1430
2024-05-25 06:00:15 [INFO]: Epoch 090 - training loss: 0.3115, validation loss: 0.1427
2024-05-25 06:00:17 [INFO]: Epoch 091 - training loss: 0.3114, validation loss: 0.1425
2024-05-25 06:00:20 [INFO]: Epoch 092 - training loss: 0.3105, validation loss: 0.1419
2024-05-25 06:00:23 [INFO]: Epoch 093 - training loss: 0.3095, validation loss: 0.1415
2024-05-25 06:00:26 [INFO]: Epoch 094 - training loss: 0.3082, validation loss: 0.1413
2024-05-25 06:00:28 [INFO]: Epoch 095 - training loss: 0.3083, validation loss: 0.1409
2024-05-25 06:00:31 [INFO]: Epoch 096 - training loss: 0.3074, validation loss: 0.1405
2024-05-25 06:00:34 [INFO]: Epoch 097 - training loss: 0.3063, validation loss: 0.1402
2024-05-25 06:00:37 [INFO]: Epoch 098 - training loss: 0.3062, validation loss: 0.1400
2024-05-25 06:00:40 [INFO]: Epoch 099 - training loss: 0.3054, validation loss: 0.1396
2024-05-25 06:00:42 [INFO]: Epoch 100 - training loss: 0.3059, validation loss: 0.1392
2024-05-25 06:00:45 [INFO]: Epoch 101 - training loss: 0.3042, validation loss: 0.1387
2024-05-25 06:00:48 [INFO]: Epoch 102 - training loss: 0.3043, validation loss: 0.1385
2024-05-25 06:00:51 [INFO]: Epoch 103 - training loss: 0.3032, validation loss: 0.1381
2024-05-25 06:00:53 [INFO]: Epoch 104 - training loss: 0.3024, validation loss: 0.1378
2024-05-25 06:00:56 [INFO]: Epoch 105 - training loss: 0.3018, validation loss: 0.1376
2024-05-25 06:00:59 [INFO]: Epoch 106 - training loss: 0.3014, validation loss: 0.1372
2024-05-25 06:01:02 [INFO]: Epoch 107 - training loss: 0.3011, validation loss: 0.1369
2024-05-25 06:01:05 [INFO]: Epoch 108 - training loss: 0.3014, validation loss: 0.1365
2024-05-25 06:01:07 [INFO]: Epoch 109 - training loss: 0.2989, validation loss: 0.1365
2024-05-25 06:01:10 [INFO]: Epoch 110 - training loss: 0.2993, validation loss: 0.1360
2024-05-25 06:01:13 [INFO]: Epoch 111 - training loss: 0.2990, validation loss: 0.1357
2024-05-25 06:01:16 [INFO]: Epoch 112 - training loss: 0.2981, validation loss: 0.1355
2024-05-25 06:01:19 [INFO]: Epoch 113 - training loss: 0.2973, validation loss: 0.1353
2024-05-25 06:01:21 [INFO]: Epoch 114 - training loss: 0.2972, validation loss: 0.1348
2024-05-25 06:01:24 [INFO]: Epoch 115 - training loss: 0.2965, validation loss: 0.1347
2024-05-25 06:01:27 [INFO]: Epoch 116 - training loss: 0.2960, validation loss: 0.1343
2024-05-25 06:01:30 [INFO]: Epoch 117 - training loss: 0.2953, validation loss: 0.1341
2024-05-25 06:01:33 [INFO]: Epoch 118 - training loss: 0.2950, validation loss: 0.1338
2024-05-25 06:01:36 [INFO]: Epoch 119 - training loss: 0.2946, validation loss: 0.1336
2024-05-25 06:01:39 [INFO]: Epoch 120 - training loss: 0.2939, validation loss: 0.1332
2024-05-25 06:01:41 [INFO]: Epoch 121 - training loss: 0.2936, validation loss: 0.1330
2024-05-25 06:01:44 [INFO]: Epoch 122 - training loss: 0.2930, validation loss: 0.1328
2024-05-25 06:01:47 [INFO]: Epoch 123 - training loss: 0.2928, validation loss: 0.1325
2024-05-25 06:01:50 [INFO]: Epoch 124 - training loss: 0.2921, validation loss: 0.1322
2024-05-25 06:01:53 [INFO]: Epoch 125 - training loss: 0.2922, validation loss: 0.1319
2024-05-25 06:01:56 [INFO]: Epoch 126 - training loss: 0.2917, validation loss: 0.1317
2024-05-25 06:01:59 [INFO]: Epoch 127 - training loss: 0.2912, validation loss: 0.1314
2024-05-25 06:02:02 [INFO]: Epoch 128 - training loss: 0.2908, validation loss: 0.1312
2024-05-25 06:02:04 [INFO]: Epoch 129 - training loss: 0.2904, validation loss: 0.1308
2024-05-25 06:02:07 [INFO]: Epoch 130 - training loss: 0.2897, validation loss: 0.1308
2024-05-25 06:02:10 [INFO]: Epoch 131 - training loss: 0.2897, validation loss: 0.1304
2024-05-25 06:02:13 [INFO]: Epoch 132 - training loss: 0.2889, validation loss: 0.1302
2024-05-25 06:02:15 [INFO]: Epoch 133 - training loss: 0.2889, validation loss: 0.1298
2024-05-25 06:02:18 [INFO]: Epoch 134 - training loss: 0.2882, validation loss: 0.1296
2024-05-25 06:02:21 [INFO]: Epoch 135 - training loss: 0.2875, validation loss: 0.1295
2024-05-25 06:02:24 [INFO]: Epoch 136 - training loss: 0.2875, validation loss: 0.1294
2024-05-25 06:02:27 [INFO]: Epoch 137 - training loss: 0.2865, validation loss: 0.1291
2024-05-25 06:02:30 [INFO]: Epoch 138 - training loss: 0.2869, validation loss: 0.1289
2024-05-25 06:02:32 [INFO]: Epoch 139 - training loss: 0.2868, validation loss: 0.1286
2024-05-25 06:02:35 [INFO]: Epoch 140 - training loss: 0.2854, validation loss: 0.1282
2024-05-25 06:02:38 [INFO]: Epoch 141 - training loss: 0.2854, validation loss: 0.1280
2024-05-25 06:02:41 [INFO]: Epoch 142 - training loss: 0.2845, validation loss: 0.1278
2024-05-25 06:02:43 [INFO]: Epoch 143 - training loss: 0.2845, validation loss: 0.1277
2024-05-25 06:02:46 [INFO]: Epoch 144 - training loss: 0.2846, validation loss: 0.1273
2024-05-25 06:02:49 [INFO]: Epoch 145 - training loss: 0.2849, validation loss: 0.1271
2024-05-25 06:02:52 [INFO]: Epoch 146 - training loss: 0.2839, validation loss: 0.1271
2024-05-25 06:02:55 [INFO]: Epoch 147 - training loss: 0.2830, validation loss: 0.1266
2024-05-25 06:02:57 [INFO]: Epoch 148 - training loss: 0.2830, validation loss: 0.1266
2024-05-25 06:03:00 [INFO]: Epoch 149 - training loss: 0.2825, validation loss: 0.1262
2024-05-25 06:03:03 [INFO]: Epoch 150 - training loss: 0.2820, validation loss: 0.1263
2024-05-25 06:03:06 [INFO]: Epoch 151 - training loss: 0.2818, validation loss: 0.1262
2024-05-25 06:03:09 [INFO]: Epoch 152 - training loss: 0.2816, validation loss: 0.1257
2024-05-25 06:03:11 [INFO]: Epoch 153 - training loss: 0.2814, validation loss: 0.1256
2024-05-25 06:03:14 [INFO]: Epoch 154 - training loss: 0.2811, validation loss: 0.1254
2024-05-25 06:03:17 [INFO]: Epoch 155 - training loss: 0.2805, validation loss: 0.1252
2024-05-25 06:03:20 [INFO]: Epoch 156 - training loss: 0.2801, validation loss: 0.1253
2024-05-25 06:03:23 [INFO]: Epoch 157 - training loss: 0.2793, validation loss: 0.1247
2024-05-25 06:03:25 [INFO]: Epoch 158 - training loss: 0.2799, validation loss: 0.1246
2024-05-25 06:03:28 [INFO]: Epoch 159 - training loss: 0.2799, validation loss: 0.1247
2024-05-25 06:03:31 [INFO]: Epoch 160 - training loss: 0.2790, validation loss: 0.1243
2024-05-25 06:03:34 [INFO]: Epoch 161 - training loss: 0.2778, validation loss: 0.1241
2024-05-25 06:03:37 [INFO]: Epoch 162 - training loss: 0.2784, validation loss: 0.1238
2024-05-25 06:03:39 [INFO]: Epoch 163 - training loss: 0.2782, validation loss: 0.1237
2024-05-25 06:03:42 [INFO]: Epoch 164 - training loss: 0.2785, validation loss: 0.1234
2024-05-25 06:03:45 [INFO]: Epoch 165 - training loss: 0.2778, validation loss: 0.1233
2024-05-25 06:03:48 [INFO]: Epoch 166 - training loss: 0.2772, validation loss: 0.1234
2024-05-25 06:03:51 [INFO]: Epoch 167 - training loss: 0.2773, validation loss: 0.1230
2024-05-25 06:03:53 [INFO]: Epoch 168 - training loss: 0.2763, validation loss: 0.1229
2024-05-25 06:03:56 [INFO]: Epoch 169 - training loss: 0.2761, validation loss: 0.1227
2024-05-25 06:03:59 [INFO]: Epoch 170 - training loss: 0.2764, validation loss: 0.1226
2024-05-25 06:04:02 [INFO]: Epoch 171 - training loss: 0.2761, validation loss: 0.1222
2024-05-25 06:04:05 [INFO]: Epoch 172 - training loss: 0.2752, validation loss: 0.1221
2024-05-25 06:04:08 [INFO]: Epoch 173 - training loss: 0.2759, validation loss: 0.1219
2024-05-25 06:04:10 [INFO]: Epoch 174 - training loss: 0.2749, validation loss: 0.1219
2024-05-25 06:04:13 [INFO]: Epoch 175 - training loss: 0.2744, validation loss: 0.1219
2024-05-25 06:04:16 [INFO]: Epoch 176 - training loss: 0.2744, validation loss: 0.1218
2024-05-25 06:04:19 [INFO]: Epoch 177 - training loss: 0.2743, validation loss: 0.1213
2024-05-25 06:04:22 [INFO]: Epoch 178 - training loss: 0.2736, validation loss: 0.1214
2024-05-25 06:04:24 [INFO]: Epoch 179 - training loss: 0.2734, validation loss: 0.1211
2024-05-25 06:04:27 [INFO]: Epoch 180 - training loss: 0.2745, validation loss: 0.1211
2024-05-25 06:04:30 [INFO]: Epoch 181 - training loss: 0.2727, validation loss: 0.1209
2024-05-25 06:04:33 [INFO]: Epoch 182 - training loss: 0.2727, validation loss: 0.1207
2024-05-25 06:04:36 [INFO]: Epoch 183 - training loss: 0.2730, validation loss: 0.1207
2024-05-25 06:04:38 [INFO]: Epoch 184 - training loss: 0.2730, validation loss: 0.1203
2024-05-25 06:04:41 [INFO]: Epoch 185 - training loss: 0.2727, validation loss: 0.1204
2024-05-25 06:04:44 [INFO]: Epoch 186 - training loss: 0.2717, validation loss: 0.1202
2024-05-25 06:04:47 [INFO]: Epoch 187 - training loss: 0.2716, validation loss: 0.1200
2024-05-25 06:04:50 [INFO]: Epoch 188 - training loss: 0.2719, validation loss: 0.1197
2024-05-25 06:04:52 [INFO]: Epoch 189 - training loss: 0.2708, validation loss: 0.1197
2024-05-25 06:04:55 [INFO]: Epoch 190 - training loss: 0.2712, validation loss: 0.1196
2024-05-25 06:04:58 [INFO]: Epoch 191 - training loss: 0.2714, validation loss: 0.1193
2024-05-25 06:05:01 [INFO]: Epoch 192 - training loss: 0.2709, validation loss: 0.1191
2024-05-25 06:05:04 [INFO]: Epoch 193 - training loss: 0.2702, validation loss: 0.1192
2024-05-25 06:05:06 [INFO]: Epoch 194 - training loss: 0.2700, validation loss: 0.1190
2024-05-25 06:05:09 [INFO]: Epoch 195 - training loss: 0.2693, validation loss: 0.1189
2024-05-25 06:05:12 [INFO]: Epoch 196 - training loss: 0.2695, validation loss: 0.1189
2024-05-25 06:05:15 [INFO]: Epoch 197 - training loss: 0.2691, validation loss: 0.1188
2024-05-25 06:05:18 [INFO]: Epoch 198 - training loss: 0.2690, validation loss: 0.1185
2024-05-25 06:05:20 [INFO]: Epoch 199 - training loss: 0.2694, validation loss: 0.1184
2024-05-25 06:05:23 [INFO]: Epoch 200 - training loss: 0.2688, validation loss: 0.1185
2024-05-25 06:05:26 [INFO]: Epoch 201 - training loss: 0.2681, validation loss: 0.1182
2024-05-25 06:05:29 [INFO]: Epoch 202 - training loss: 0.2688, validation loss: 0.1180
2024-05-25 06:05:32 [INFO]: Epoch 203 - training loss: 0.2677, validation loss: 0.1180
2024-05-25 06:05:34 [INFO]: Epoch 204 - training loss: 0.2673, validation loss: 0.1179
2024-05-25 06:05:37 [INFO]: Epoch 205 - training loss: 0.2674, validation loss: 0.1179
2024-05-25 06:05:40 [INFO]: Epoch 206 - training loss: 0.2673, validation loss: 0.1177
2024-05-25 06:05:43 [INFO]: Epoch 207 - training loss: 0.2670, validation loss: 0.1174
2024-05-25 06:05:46 [INFO]: Epoch 208 - training loss: 0.2670, validation loss: 0.1173
2024-05-25 06:05:48 [INFO]: Epoch 209 - training loss: 0.2667, validation loss: 0.1174
2024-05-25 06:05:51 [INFO]: Epoch 210 - training loss: 0.2666, validation loss: 0.1172
2024-05-25 06:05:54 [INFO]: Epoch 211 - training loss: 0.2659, validation loss: 0.1170
2024-05-25 06:05:57 [INFO]: Epoch 212 - training loss: 0.2656, validation loss: 0.1169
2024-05-25 06:06:00 [INFO]: Epoch 213 - training loss: 0.2660, validation loss: 0.1169
2024-05-25 06:06:02 [INFO]: Epoch 214 - training loss: 0.2658, validation loss: 0.1168
2024-05-25 06:06:05 [INFO]: Epoch 215 - training loss: 0.2654, validation loss: 0.1168
2024-05-25 06:06:08 [INFO]: Epoch 216 - training loss: 0.2650, validation loss: 0.1164
2024-05-25 06:06:11 [INFO]: Epoch 217 - training loss: 0.2647, validation loss: 0.1165
2024-05-25 06:06:14 [INFO]: Epoch 218 - training loss: 0.2644, validation loss: 0.1163
2024-05-25 06:06:17 [INFO]: Epoch 219 - training loss: 0.2643, validation loss: 0.1162
2024-05-25 06:06:19 [INFO]: Epoch 220 - training loss: 0.2642, validation loss: 0.1161
2024-05-25 06:06:22 [INFO]: Epoch 221 - training loss: 0.2643, validation loss: 0.1164
2024-05-25 06:06:25 [INFO]: Epoch 222 - training loss: 0.2640, validation loss: 0.1160
2024-05-25 06:06:28 [INFO]: Epoch 223 - training loss: 0.2641, validation loss: 0.1160
2024-05-25 06:06:31 [INFO]: Epoch 224 - training loss: 0.2639, validation loss: 0.1158
2024-05-25 06:06:33 [INFO]: Epoch 225 - training loss: 0.2633, validation loss: 0.1158
2024-05-25 06:06:36 [INFO]: Epoch 226 - training loss: 0.2635, validation loss: 0.1155
2024-05-25 06:06:39 [INFO]: Epoch 227 - training loss: 0.2630, validation loss: 0.1154
2024-05-25 06:06:42 [INFO]: Epoch 228 - training loss: 0.2626, validation loss: 0.1156
2024-05-25 06:06:45 [INFO]: Epoch 229 - training loss: 0.2626, validation loss: 0.1153
2024-05-25 06:06:47 [INFO]: Epoch 230 - training loss: 0.2626, validation loss: 0.1152
2024-05-25 06:06:50 [INFO]: Epoch 231 - training loss: 0.2622, validation loss: 0.1150
2024-05-25 06:06:53 [INFO]: Epoch 232 - training loss: 0.2622, validation loss: 0.1150
2024-05-25 06:06:56 [INFO]: Epoch 233 - training loss: 0.2624, validation loss: 0.1148
2024-05-25 06:06:59 [INFO]: Epoch 234 - training loss: 0.2617, validation loss: 0.1148
2024-05-25 06:07:01 [INFO]: Epoch 235 - training loss: 0.2619, validation loss: 0.1148
2024-05-25 06:07:04 [INFO]: Epoch 236 - training loss: 0.2614, validation loss: 0.1148
2024-05-25 06:07:07 [INFO]: Epoch 237 - training loss: 0.2614, validation loss: 0.1146
2024-05-25 06:07:10 [INFO]: Epoch 238 - training loss: 0.2613, validation loss: 0.1148
2024-05-25 06:07:13 [INFO]: Epoch 239 - training loss: 0.2610, validation loss: 0.1145
2024-05-25 06:07:15 [INFO]: Epoch 240 - training loss: 0.2603, validation loss: 0.1143
2024-05-25 06:07:18 [INFO]: Epoch 241 - training loss: 0.2608, validation loss: 0.1143
2024-05-25 06:07:21 [INFO]: Epoch 242 - training loss: 0.2608, validation loss: 0.1143
2024-05-25 06:07:24 [INFO]: Epoch 243 - training loss: 0.2603, validation loss: 0.1143
2024-05-25 06:07:27 [INFO]: Epoch 244 - training loss: 0.2599, validation loss: 0.1141
2024-05-25 06:07:29 [INFO]: Epoch 245 - training loss: 0.2602, validation loss: 0.1140
2024-05-25 06:07:32 [INFO]: Epoch 246 - training loss: 0.2604, validation loss: 0.1141
2024-05-25 06:07:35 [INFO]: Epoch 247 - training loss: 0.2597, validation loss: 0.1138
2024-05-25 06:07:38 [INFO]: Epoch 248 - training loss: 0.2593, validation loss: 0.1139
2024-05-25 06:07:41 [INFO]: Epoch 249 - training loss: 0.2591, validation loss: 0.1137
2024-05-25 06:07:43 [INFO]: Epoch 250 - training loss: 0.2596, validation loss: 0.1137
2024-05-25 06:07:46 [INFO]: Epoch 251 - training loss: 0.2588, validation loss: 0.1138
2024-05-25 06:07:49 [INFO]: Epoch 252 - training loss: 0.2584, validation loss: 0.1136
2024-05-25 06:07:52 [INFO]: Epoch 253 - training loss: 0.2586, validation loss: 0.1136
2024-05-25 06:07:55 [INFO]: Epoch 254 - training loss: 0.2582, validation loss: 0.1135
2024-05-25 06:07:57 [INFO]: Epoch 255 - training loss: 0.2581, validation loss: 0.1134
2024-05-25 06:08:00 [INFO]: Epoch 256 - training loss: 0.2581, validation loss: 0.1133
2024-05-25 06:08:03 [INFO]: Epoch 257 - training loss: 0.2579, validation loss: 0.1134
2024-05-25 06:08:06 [INFO]: Epoch 258 - training loss: 0.2586, validation loss: 0.1132
2024-05-25 06:08:09 [INFO]: Epoch 259 - training loss: 0.2576, validation loss: 0.1132
2024-05-25 06:08:11 [INFO]: Epoch 260 - training loss: 0.2575, validation loss: 0.1133
2024-05-25 06:08:14 [INFO]: Epoch 261 - training loss: 0.2574, validation loss: 0.1131
2024-05-25 06:08:17 [INFO]: Epoch 262 - training loss: 0.2570, validation loss: 0.1130
2024-05-25 06:08:20 [INFO]: Epoch 263 - training loss: 0.2569, validation loss: 0.1129
2024-05-25 06:08:23 [INFO]: Epoch 264 - training loss: 0.2570, validation loss: 0.1128
2024-05-25 06:08:25 [INFO]: Epoch 265 - training loss: 0.2567, validation loss: 0.1128
2024-05-25 06:08:28 [INFO]: Epoch 266 - training loss: 0.2568, validation loss: 0.1128
2024-05-25 06:08:31 [INFO]: Epoch 267 - training loss: 0.2563, validation loss: 0.1128
2024-05-25 06:08:34 [INFO]: Epoch 268 - training loss: 0.2563, validation loss: 0.1128
2024-05-25 06:08:37 [INFO]: Epoch 269 - training loss: 0.2563, validation loss: 0.1127
2024-05-25 06:08:39 [INFO]: Epoch 270 - training loss: 0.2557, validation loss: 0.1125
2024-05-25 06:08:42 [INFO]: Epoch 271 - training loss: 0.2557, validation loss: 0.1126
2024-05-25 06:08:45 [INFO]: Epoch 272 - training loss: 0.2552, validation loss: 0.1125
2024-05-25 06:08:48 [INFO]: Epoch 273 - training loss: 0.2551, validation loss: 0.1124
2024-05-25 06:08:51 [INFO]: Epoch 274 - training loss: 0.2554, validation loss: 0.1126
2024-05-25 06:08:53 [INFO]: Epoch 275 - training loss: 0.2553, validation loss: 0.1124
2024-05-25 06:08:56 [INFO]: Epoch 276 - training loss: 0.2549, validation loss: 0.1123
2024-05-25 06:08:59 [INFO]: Epoch 277 - training loss: 0.2548, validation loss: 0.1122
2024-05-25 06:09:02 [INFO]: Epoch 278 - training loss: 0.2548, validation loss: 0.1123
2024-05-25 06:09:05 [INFO]: Epoch 279 - training loss: 0.2546, validation loss: 0.1121
2024-05-25 06:09:07 [INFO]: Epoch 280 - training loss: 0.2548, validation loss: 0.1122
2024-05-25 06:09:10 [INFO]: Epoch 281 - training loss: 0.2543, validation loss: 0.1119
2024-05-25 06:09:13 [INFO]: Epoch 282 - training loss: 0.2544, validation loss: 0.1122
2024-05-25 06:09:16 [INFO]: Epoch 283 - training loss: 0.2542, validation loss: 0.1121
2024-05-25 06:09:19 [INFO]: Epoch 284 - training loss: 0.2540, validation loss: 0.1118
2024-05-25 06:09:21 [INFO]: Epoch 285 - training loss: 0.2536, validation loss: 0.1120
2024-05-25 06:09:24 [INFO]: Epoch 286 - training loss: 0.2537, validation loss: 0.1120
2024-05-25 06:09:27 [INFO]: Epoch 287 - training loss: 0.2531, validation loss: 0.1118
2024-05-25 06:09:30 [INFO]: Epoch 288 - training loss: 0.2531, validation loss: 0.1117
2024-05-25 06:09:33 [INFO]: Epoch 289 - training loss: 0.2532, validation loss: 0.1117
2024-05-25 06:09:35 [INFO]: Epoch 290 - training loss: 0.2530, validation loss: 0.1119
2024-05-25 06:09:38 [INFO]: Epoch 291 - training loss: 0.2530, validation loss: 0.1117
2024-05-25 06:09:41 [INFO]: Epoch 292 - training loss: 0.2533, validation loss: 0.1118
2024-05-25 06:09:44 [INFO]: Epoch 293 - training loss: 0.2527, validation loss: 0.1117
2024-05-25 06:09:47 [INFO]: Epoch 294 - training loss: 0.2529, validation loss: 0.1117
2024-05-25 06:09:49 [INFO]: Epoch 295 - training loss: 0.2528, validation loss: 0.1117
2024-05-25 06:09:52 [INFO]: Epoch 296 - training loss: 0.2525, validation loss: 0.1117
2024-05-25 06:09:55 [INFO]: Epoch 297 - training loss: 0.2523, validation loss: 0.1116
2024-05-25 06:09:58 [INFO]: Epoch 298 - training loss: 0.2521, validation loss: 0.1115
2024-05-25 06:10:01 [INFO]: Epoch 299 - training loss: 0.2519, validation loss: 0.1115
2024-05-25 06:10:03 [INFO]: Epoch 300 - training loss: 0.2521, validation loss: 0.1113
2024-05-25 06:10:03 [INFO]: Finished training. The best model is from epoch#300.
2024-05-25 06:10:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/BRITS_air_quality/20240525_T055603/BRITS.pypots
2024-05-25 06:10:04 [INFO]: BRITS on Air-Quality: MAE=0.1538, MSE=0.1503
2024-05-25 06:10:04 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/BRITS_air_quality/imputation.pkl
2024-05-25 06:10:04 [INFO]: Using the given device: cuda:0
2024-05-25 06:10:04 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004
2024-05-25 06:10:04 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/tensorboard
2024-05-25 06:10:04 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 06:10:09 [INFO]: Epoch 001 - training loss: 1.4865, validation loss: 0.7983
2024-05-25 06:10:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch1_loss0.7983348727226257.pypots
2024-05-25 06:10:13 [INFO]: Epoch 002 - training loss: 1.0143, validation loss: 0.7422
2024-05-25 06:10:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch2_loss0.7422293931245804.pypots
2024-05-25 06:10:17 [INFO]: Epoch 003 - training loss: 0.9400, validation loss: 0.7137
2024-05-25 06:10:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch3_loss0.7137154519557953.pypots
2024-05-25 06:10:20 [INFO]: Epoch 004 - training loss: 0.8992, validation loss: 0.6993
2024-05-25 06:10:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch4_loss0.6993245482444763.pypots
2024-05-25 06:10:24 [INFO]: Epoch 005 - training loss: 0.8731, validation loss: 0.6891
2024-05-25 06:10:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch5_loss0.6890869826078415.pypots
2024-05-25 06:10:28 [INFO]: Epoch 006 - training loss: 0.9067, validation loss: 0.6846
2024-05-25 06:10:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch6_loss0.6845790058374405.pypots
2024-05-25 06:10:32 [INFO]: Epoch 007 - training loss: 0.8716, validation loss: 0.6768
2024-05-25 06:10:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch7_loss0.676834124326706.pypots
2024-05-25 06:10:36 [INFO]: Epoch 008 - training loss: 0.8492, validation loss: 0.6732
2024-05-25 06:10:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch8_loss0.6731930434703827.pypots
2024-05-25 06:10:40 [INFO]: Epoch 009 - training loss: 0.8352, validation loss: 0.6700
2024-05-25 06:10:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch9_loss0.6699641138315201.pypots
2024-05-25 06:10:44 [INFO]: Epoch 010 - training loss: 0.8410, validation loss: 0.6676
2024-05-25 06:10:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch10_loss0.6676134973764419.pypots
2024-05-25 06:10:47 [INFO]: Epoch 011 - training loss: 0.8501, validation loss: 0.6644
2024-05-25 06:10:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch11_loss0.6643629312515259.pypots
2024-05-25 06:10:51 [INFO]: Epoch 012 - training loss: 0.8502, validation loss: 0.6642
2024-05-25 06:10:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch12_loss0.6642261147499084.pypots
2024-05-25 06:10:55 [INFO]: Epoch 013 - training loss: 0.8332, validation loss: 0.6625
2024-05-25 06:10:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch13_loss0.662471479177475.pypots
2024-05-25 06:10:59 [INFO]: Epoch 014 - training loss: 0.8224, validation loss: 0.6630
2024-05-25 06:10:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch14_loss0.6629585564136505.pypots
2024-05-25 06:11:03 [INFO]: Epoch 015 - training loss: 0.8178, validation loss: 0.6604
2024-05-25 06:11:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch15_loss0.6604137688875198.pypots
2024-05-25 06:11:07 [INFO]: Epoch 016 - training loss: 0.8277, validation loss: 0.6627
2024-05-25 06:11:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch16_loss0.6627372026443481.pypots
2024-05-25 06:11:10 [INFO]: Epoch 017 - training loss: 0.8044, validation loss: 0.6596
2024-05-25 06:11:10 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch17_loss0.6596067726612092.pypots
2024-05-25 06:11:14 [INFO]: Epoch 018 - training loss: 0.8068, validation loss: 0.6593
2024-05-25 06:11:14 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch18_loss0.6593290597200394.pypots
2024-05-25 06:11:18 [INFO]: Epoch 019 - training loss: 0.8171, validation loss: 0.6642
2024-05-25 06:11:18 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch19_loss0.6641694784164429.pypots
2024-05-25 06:11:22 [INFO]: Epoch 020 - training loss: 0.8216, validation loss: 0.6589
2024-05-25 06:11:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch20_loss0.6589124292135239.pypots
2024-05-25 06:11:26 [INFO]: Epoch 021 - training loss: 0.8004, validation loss: 0.6583
2024-05-25 06:11:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch21_loss0.6582912325859069.pypots
2024-05-25 06:11:30 [INFO]: Epoch 022 - training loss: 0.8157, validation loss: 0.6604
2024-05-25 06:11:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch22_loss0.6604243278503418.pypots
2024-05-25 06:11:33 [INFO]: Epoch 023 - training loss: 0.7965, validation loss: 0.6577
2024-05-25 06:11:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch23_loss0.6576718479394913.pypots
2024-05-25 06:11:37 [INFO]: Epoch 024 - training loss: 0.7926, validation loss: 0.6561
2024-05-25 06:11:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch24_loss0.6560663461685181.pypots
2024-05-25 06:11:41 [INFO]: Epoch 025 - training loss: 0.8104, validation loss: 0.6588
2024-05-25 06:11:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch25_loss0.6587665766477585.pypots
2024-05-25 06:11:45 [INFO]: Epoch 026 - training loss: 0.8008, validation loss: 0.6567
2024-05-25 06:11:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch26_loss0.6566652715206146.pypots
2024-05-25 06:11:49 [INFO]: Epoch 027 - training loss: 0.8006, validation loss: 0.6577
2024-05-25 06:11:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch27_loss0.6576917797327042.pypots
2024-05-25 06:11:53 [INFO]: Epoch 028 - training loss: 0.7803, validation loss: 0.6594
2024-05-25 06:11:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch28_loss0.6594414174556732.pypots
2024-05-25 06:11:57 [INFO]: Epoch 029 - training loss: 0.7789, validation loss: 0.6592
2024-05-25 06:11:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch29_loss0.659249022603035.pypots
2024-05-25 06:12:00 [INFO]: Epoch 030 - training loss: 0.7868, validation loss: 0.6598
2024-05-25 06:12:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch30_loss0.6598206371068954.pypots
2024-05-25 06:12:04 [INFO]: Epoch 031 - training loss: 0.7778, validation loss: 0.6574
2024-05-25 06:12:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch31_loss0.6573712259531022.pypots
2024-05-25 06:12:08 [INFO]: Epoch 032 - training loss: 0.7845, validation loss: 0.6564
2024-05-25 06:12:08 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch32_loss0.656433978676796.pypots
2024-05-25 06:12:12 [INFO]: Epoch 033 - training loss: 0.7903, validation loss: 0.6577
2024-05-25 06:12:12 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch33_loss0.6576802998781204.pypots
2024-05-25 06:12:16 [INFO]: Epoch 034 - training loss: 0.7876, validation loss: 0.6590
2024-05-25 06:12:16 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN_epoch34_loss0.6590362668037415.pypots
2024-05-25 06:12:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:12:16 [INFO]: Finished training. The best model is from epoch#24.
2024-05-25 06:12:16 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T061004/MRNN.pypots
2024-05-25 06:12:16 [INFO]: MRNN on Air-Quality: MAE=0.5219, MSE=0.6580
2024-05-25 06:12:16 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/MRNN_air_quality/imputation.pkl
2024-05-25 06:12:16 [INFO]: Using the given device: cpu
2024-05-25 06:12:16 [INFO]: LOCF on Air-Quality: MAE=0.2220, MSE=0.3375
2024-05-25 06:12:16 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_air_quality".
2024-05-25 06:12:16 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/LOCF_air_quality/imputation.pkl
2024-05-25 06:12:16 [INFO]: Median on Air-Quality: MAE=0.6640, MSE=1.0523
2024-05-25 06:12:16 [INFO]: Successfully created the given path "saved_results/round_2/Median_air_quality".
2024-05-25 06:12:17 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Median_air_quality/imputation.pkl
2024-05-25 06:12:17 [INFO]: Mean on Air-Quality: MAE=0.6951, MSE=0.9927
2024-05-25 06:12:17 [INFO]: Successfully created the given path "saved_results/round_2/Mean_air_quality".
2024-05-25 06:12:17 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Mean_air_quality/imputation.pkl
2024-05-25 06:12:17 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-25 06:12:17 [INFO]: Using the given device: cuda:0
2024-05-25 06:12:17 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/SAITS_air_quality/20240525_T061217
2024-05-25 06:12:17 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/SAITS_air_quality/20240525_T061217/tensorboard
2024-05-25 06:12:17 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 06:12:17 [INFO]: Epoch 001 - training loss: 1.0605, validation loss: 0.5173
2024-05-25 06:12:18 [INFO]: Epoch 002 - training loss: 0.7659, validation loss: 0.3921
2024-05-25 06:12:19 [INFO]: Epoch 003 - training loss: 0.6557, validation loss: 0.3174
2024-05-25 06:12:19 [INFO]: Epoch 004 - training loss: 0.5791, validation loss: 0.2723
2024-05-25 06:12:20 [INFO]: Epoch 005 - training loss: 0.5233, validation loss: 0.2495
2024-05-25 06:12:20 [INFO]: Epoch 006 - training loss: 0.4862, validation loss: 0.2335
2024-05-25 06:12:21 [INFO]: Epoch 007 - training loss: 0.4581, validation loss: 0.2212
2024-05-25 06:12:22 [INFO]: Epoch 008 - training loss: 0.4401, validation loss: 0.2144
2024-05-25 06:12:22 [INFO]: Epoch 009 - training loss: 0.4270, validation loss: 0.2085
2024-05-25 06:12:23 [INFO]: Epoch 010 - training loss: 0.4136, validation loss: 0.2022
2024-05-25 06:12:23 [INFO]: Epoch 011 - training loss: 0.4048, validation loss: 0.1988
2024-05-25 06:12:24 [INFO]: Epoch 012 - training loss: 0.3956, validation loss: 0.1948
2024-05-25 06:12:25 [INFO]: Epoch 013 - training loss: 0.3869, validation loss: 0.1908
2024-05-25 06:12:25 [INFO]: Epoch 014 - training loss: 0.3787, validation loss: 0.1880
2024-05-25 06:12:26 [INFO]: Epoch 015 - training loss: 0.3743, validation loss: 0.1849
2024-05-25 06:12:26 [INFO]: Epoch 016 - training loss: 0.3686, validation loss: 0.1827
2024-05-25 06:12:27 [INFO]: Epoch 017 - training loss: 0.3611, validation loss: 0.1810
2024-05-25 06:12:28 [INFO]: Epoch 018 - training loss: 0.3562, validation loss: 0.1775
2024-05-25 06:12:28 [INFO]: Epoch 019 - training loss: 0.3526, validation loss: 0.1755
2024-05-25 06:12:29 [INFO]: Epoch 020 - training loss: 0.3507, validation loss: 0.1757
2024-05-25 06:12:29 [INFO]: Epoch 021 - training loss: 0.3472, validation loss: 0.1719
2024-05-25 06:12:30 [INFO]: Epoch 022 - training loss: 0.3403, validation loss: 0.1703
2024-05-25 06:12:31 [INFO]: Epoch 023 - training loss: 0.3378, validation loss: 0.1688
2024-05-25 06:12:31 [INFO]: Epoch 024 - training loss: 0.3368, validation loss: 0.1671
2024-05-25 06:12:32 [INFO]: Epoch 025 - training loss: 0.3315, validation loss: 0.1658
2024-05-25 06:12:33 [INFO]: Epoch 026 - training loss: 0.3291, validation loss: 0.1648
2024-05-25 06:12:33 [INFO]: Epoch 027 - training loss: 0.3268, validation loss: 0.1620
2024-05-25 06:12:34 [INFO]: Epoch 028 - training loss: 0.3226, validation loss: 0.1611
2024-05-25 06:12:34 [INFO]: Epoch 029 - training loss: 0.3200, validation loss: 0.1583
2024-05-25 06:12:35 [INFO]: Epoch 030 - training loss: 0.3186, validation loss: 0.1584
2024-05-25 06:12:36 [INFO]: Epoch 031 - training loss: 0.3166, validation loss: 0.1559
2024-05-25 06:12:36 [INFO]: Epoch 032 - training loss: 0.3136, validation loss: 0.1557
2024-05-25 06:12:37 [INFO]: Epoch 033 - training loss: 0.3117, validation loss: 0.1541
2024-05-25 06:12:37 [INFO]: Epoch 034 - training loss: 0.3101, validation loss: 0.1533
2024-05-25 06:12:38 [INFO]: Epoch 035 - training loss: 0.3079, validation loss: 0.1520
2024-05-25 06:12:39 [INFO]: Epoch 036 - training loss: 0.3055, validation loss: 0.1512
2024-05-25 06:12:39 [INFO]: Epoch 037 - training loss: 0.3027, validation loss: 0.1497
2024-05-25 06:12:40 [INFO]: Epoch 038 - training loss: 0.3014, validation loss: 0.1484
2024-05-25 06:12:40 [INFO]: Epoch 039 - training loss: 0.3006, validation loss: 0.1474
2024-05-25 06:12:41 [INFO]: Epoch 040 - training loss: 0.2993, validation loss: 0.1461
2024-05-25 06:12:42 [INFO]: Epoch 041 - training loss: 0.2964, validation loss: 0.1458
2024-05-25 06:12:42 [INFO]: Epoch 042 - training loss: 0.2944, validation loss: 0.1436
2024-05-25 06:12:43 [INFO]: Epoch 043 - training loss: 0.2940, validation loss: 0.1432
2024-05-25 06:12:43 [INFO]: Epoch 044 - training loss: 0.2938, validation loss: 0.1427
2024-05-25 06:12:44 [INFO]: Epoch 045 - training loss: 0.2905, validation loss: 0.1428
2024-05-25 06:12:45 [INFO]: Epoch 046 - training loss: 0.2892, validation loss: 0.1424
2024-05-25 06:12:45 [INFO]: Epoch 047 - training loss: 0.2871, validation loss: 0.1415
2024-05-25 06:12:46 [INFO]: Epoch 048 - training loss: 0.2871, validation loss: 0.1408
2024-05-25 06:12:46 [INFO]: Epoch 049 - training loss: 0.2881, validation loss: 0.1408
2024-05-25 06:12:47 [INFO]: Epoch 050 - training loss: 0.2831, validation loss: 0.1393
2024-05-25 06:12:48 [INFO]: Epoch 051 - training loss: 0.2811, validation loss: 0.1394
2024-05-25 06:12:48 [INFO]: Epoch 052 - training loss: 0.2805, validation loss: 0.1380
2024-05-25 06:12:49 [INFO]: Epoch 053 - training loss: 0.2795, validation loss: 0.1374
2024-05-25 06:12:49 [INFO]: Epoch 054 - training loss: 0.2777, validation loss: 0.1368
2024-05-25 06:12:50 [INFO]: Epoch 055 - training loss: 0.2765, validation loss: 0.1378
2024-05-25 06:12:51 [INFO]: Epoch 056 - training loss: 0.2750, validation loss: 0.1370
2024-05-25 06:12:51 [INFO]: Epoch 057 - training loss: 0.2730, validation loss: 0.1358
2024-05-25 06:12:52 [INFO]: Epoch 058 - training loss: 0.2724, validation loss: 0.1359
2024-05-25 06:12:52 [INFO]: Epoch 059 - training loss: 0.2707, validation loss: 0.1349
2024-05-25 06:12:53 [INFO]: Epoch 060 - training loss: 0.2687, validation loss: 0.1358
2024-05-25 06:12:54 [INFO]: Epoch 061 - training loss: 0.2681, validation loss: 0.1355
2024-05-25 06:12:54 [INFO]: Epoch 062 - training loss: 0.2666, validation loss: 0.1350
2024-05-25 06:12:55 [INFO]: Epoch 063 - training loss: 0.2653, validation loss: 0.1353
2024-05-25 06:12:55 [INFO]: Epoch 064 - training loss: 0.2658, validation loss: 0.1333
2024-05-25 06:12:56 [INFO]: Epoch 065 - training loss: 0.2640, validation loss: 0.1338
2024-05-25 06:12:57 [INFO]: Epoch 066 - training loss: 0.2625, validation loss: 0.1342
2024-05-25 06:12:57 [INFO]: Epoch 067 - training loss: 0.2612, validation loss: 0.1320
2024-05-25 06:12:58 [INFO]: Epoch 068 - training loss: 0.2604, validation loss: 0.1324
2024-05-25 06:12:58 [INFO]: Epoch 069 - training loss: 0.2585, validation loss: 0.1318
2024-05-25 06:12:59 [INFO]: Epoch 070 - training loss: 0.2579, validation loss: 0.1324
2024-05-25 06:13:00 [INFO]: Epoch 071 - training loss: 0.2573, validation loss: 0.1309
2024-05-25 06:13:00 [INFO]: Epoch 072 - training loss: 0.2550, validation loss: 0.1310
2024-05-25 06:13:01 [INFO]: Epoch 073 - training loss: 0.2550, validation loss: 0.1311
2024-05-25 06:13:01 [INFO]: Epoch 074 - training loss: 0.2546, validation loss: 0.1325
2024-05-25 06:13:02 [INFO]: Epoch 075 - training loss: 0.2535, validation loss: 0.1296
2024-05-25 06:13:03 [INFO]: Epoch 076 - training loss: 0.2521, validation loss: 0.1292
2024-05-25 06:13:03 [INFO]: Epoch 077 - training loss: 0.2505, validation loss: 0.1293
2024-05-25 06:13:04 [INFO]: Epoch 078 - training loss: 0.2500, validation loss: 0.1286
2024-05-25 06:13:05 [INFO]: Epoch 079 - training loss: 0.2484, validation loss: 0.1281
2024-05-25 06:13:05 [INFO]: Epoch 080 - training loss: 0.2480, validation loss: 0.1288
2024-05-25 06:13:06 [INFO]: Epoch 081 - training loss: 0.2474, validation loss: 0.1279
2024-05-25 06:13:06 [INFO]: Epoch 082 - training loss: 0.2460, validation loss: 0.1280
2024-05-25 06:13:07 [INFO]: Epoch 083 - training loss: 0.2450, validation loss: 0.1282
2024-05-25 06:13:08 [INFO]: Epoch 084 - training loss: 0.2458, validation loss: 0.1272
2024-05-25 06:13:08 [INFO]: Epoch 085 - training loss: 0.2434, validation loss: 0.1281
2024-05-25 06:13:09 [INFO]: Epoch 086 - training loss: 0.2422, validation loss: 0.1256
2024-05-25 06:13:09 [INFO]: Epoch 087 - training loss: 0.2418, validation loss: 0.1260
2024-05-25 06:13:10 [INFO]: Epoch 088 - training loss: 0.2409, validation loss: 0.1257
2024-05-25 06:13:11 [INFO]: Epoch 089 - training loss: 0.2404, validation loss: 0.1254
2024-05-25 06:13:11 [INFO]: Epoch 090 - training loss: 0.2389, validation loss: 0.1252
2024-05-25 06:13:12 [INFO]: Epoch 091 - training loss: 0.2400, validation loss: 0.1257
2024-05-25 06:13:12 [INFO]: Epoch 092 - training loss: 0.2377, validation loss: 0.1263
2024-05-25 06:13:13 [INFO]: Epoch 093 - training loss: 0.2373, validation loss: 0.1249
2024-05-25 06:13:14 [INFO]: Epoch 094 - training loss: 0.2379, validation loss: 0.1259
2024-05-25 06:13:14 [INFO]: Epoch 095 - training loss: 0.2369, validation loss: 0.1252
2024-05-25 06:13:15 [INFO]: Epoch 096 - training loss: 0.2350, validation loss: 0.1246
2024-05-25 06:13:15 [INFO]: Epoch 097 - training loss: 0.2341, validation loss: 0.1247
2024-05-25 06:13:16 [INFO]: Epoch 098 - training loss: 0.2328, validation loss: 0.1237
2024-05-25 06:13:17 [INFO]: Epoch 099 - training loss: 0.2320, validation loss: 0.1228
2024-05-25 06:13:17 [INFO]: Epoch 100 - training loss: 0.2312, validation loss: 0.1231
2024-05-25 06:13:18 [INFO]: Epoch 101 - training loss: 0.2328, validation loss: 0.1235
2024-05-25 06:13:18 [INFO]: Epoch 102 - training loss: 0.2317, validation loss: 0.1232
2024-05-25 06:13:19 [INFO]: Epoch 103 - training loss: 0.2301, validation loss: 0.1226
2024-05-25 06:13:20 [INFO]: Epoch 104 - training loss: 0.2293, validation loss: 0.1223
2024-05-25 06:13:20 [INFO]: Epoch 105 - training loss: 0.2308, validation loss: 0.1229
2024-05-25 06:13:21 [INFO]: Epoch 106 - training loss: 0.2292, validation loss: 0.1219
2024-05-25 06:13:21 [INFO]: Epoch 107 - training loss: 0.2272, validation loss: 0.1225
2024-05-25 06:13:22 [INFO]: Epoch 108 - training loss: 0.2268, validation loss: 0.1218
2024-05-25 06:13:23 [INFO]: Epoch 109 - training loss: 0.2268, validation loss: 0.1230
2024-05-25 06:13:23 [INFO]: Epoch 110 - training loss: 0.2277, validation loss: 0.1220
2024-05-25 06:13:24 [INFO]: Epoch 111 - training loss: 0.2261, validation loss: 0.1216
2024-05-25 06:13:24 [INFO]: Epoch 112 - training loss: 0.2243, validation loss: 0.1205
2024-05-25 06:13:25 [INFO]: Epoch 113 - training loss: 0.2251, validation loss: 0.1200
2024-05-25 06:13:26 [INFO]: Epoch 114 - training loss: 0.2247, validation loss: 0.1205
2024-05-25 06:13:26 [INFO]: Epoch 115 - training loss: 0.2225, validation loss: 0.1201
2024-05-25 06:13:27 [INFO]: Epoch 116 - training loss: 0.2222, validation loss: 0.1198
2024-05-25 06:13:27 [INFO]: Epoch 117 - training loss: 0.2214, validation loss: 0.1203
2024-05-25 06:13:28 [INFO]: Epoch 118 - training loss: 0.2245, validation loss: 0.1206
2024-05-25 06:13:29 [INFO]: Epoch 119 - training loss: 0.2210, validation loss: 0.1187
2024-05-25 06:13:29 [INFO]: Epoch 120 - training loss: 0.2212, validation loss: 0.1208
2024-05-25 06:13:30 [INFO]: Epoch 121 - training loss: 0.2207, validation loss: 0.1188
2024-05-25 06:13:30 [INFO]: Epoch 122 - training loss: 0.2190, validation loss: 0.1185
2024-05-25 06:13:31 [INFO]: Epoch 123 - training loss: 0.2188, validation loss: 0.1207
2024-05-25 06:13:32 [INFO]: Epoch 124 - training loss: 0.2179, validation loss: 0.1189
2024-05-25 06:13:32 [INFO]: Epoch 125 - training loss: 0.2169, validation loss: 0.1181
2024-05-25 06:13:33 [INFO]: Epoch 126 - training loss: 0.2174, validation loss: 0.1193
2024-05-25 06:13:33 [INFO]: Epoch 127 - training loss: 0.2172, validation loss: 0.1197
2024-05-25 06:13:34 [INFO]: Epoch 128 - training loss: 0.2166, validation loss: 0.1189
2024-05-25 06:13:35 [INFO]: Epoch 129 - training loss: 0.2154, validation loss: 0.1188
2024-05-25 06:13:35 [INFO]: Epoch 130 - training loss: 0.2155, validation loss: 0.1182
2024-05-25 06:13:36 [INFO]: Epoch 131 - training loss: 0.2144, validation loss: 0.1187
2024-05-25 06:13:37 [INFO]: Epoch 132 - training loss: 0.2147, validation loss: 0.1192
2024-05-25 06:13:37 [INFO]: Epoch 133 - training loss: 0.2163, validation loss: 0.1176
2024-05-25 06:13:38 [INFO]: Epoch 134 - training loss: 0.2134, validation loss: 0.1186
2024-05-25 06:13:38 [INFO]: Epoch 135 - training loss: 0.2119, validation loss: 0.1176
2024-05-25 06:13:39 [INFO]: Epoch 136 - training loss: 0.2116, validation loss: 0.1175
2024-05-25 06:13:40 [INFO]: Epoch 137 - training loss: 0.2120, validation loss: 0.1179
2024-05-25 06:13:40 [INFO]: Epoch 138 - training loss: 0.2115, validation loss: 0.1177
2024-05-25 06:13:41 [INFO]: Epoch 139 - training loss: 0.2127, validation loss: 0.1185
2024-05-25 06:13:41 [INFO]: Epoch 140 - training loss: 0.2124, validation loss: 0.1180
2024-05-25 06:13:42 [INFO]: Epoch 141 - training loss: 0.2109, validation loss: 0.1175
2024-05-25 06:13:43 [INFO]: Epoch 142 - training loss: 0.2090, validation loss: 0.1179
2024-05-25 06:13:43 [INFO]: Epoch 143 - training loss: 0.2088, validation loss: 0.1182
2024-05-25 06:13:44 [INFO]: Epoch 144 - training loss: 0.2084, validation loss: 0.1173
2024-05-25 06:13:44 [INFO]: Epoch 145 - training loss: 0.2089, validation loss: 0.1178
2024-05-25 06:13:45 [INFO]: Epoch 146 - training loss: 0.2082, validation loss: 0.1173
2024-05-25 06:13:46 [INFO]: Epoch 147 - training loss: 0.2080, validation loss: 0.1169
2024-05-25 06:13:46 [INFO]: Epoch 148 - training loss: 0.2075, validation loss: 0.1169
2024-05-25 06:13:47 [INFO]: Epoch 149 - training loss: 0.2067, validation loss: 0.1169
2024-05-25 06:13:47 [INFO]: Epoch 150 - training loss: 0.2078, validation loss: 0.1169
2024-05-25 06:13:48 [INFO]: Epoch 151 - training loss: 0.2065, validation loss: 0.1172
2024-05-25 06:13:49 [INFO]: Epoch 152 - training loss: 0.2059, validation loss: 0.1173
2024-05-25 06:13:49 [INFO]: Epoch 153 - training loss: 0.2054, validation loss: 0.1169
2024-05-25 06:13:50 [INFO]: Epoch 154 - training loss: 0.2055, validation loss: 0.1171
2024-05-25 06:13:50 [INFO]: Epoch 155 - training loss: 0.2049, validation loss: 0.1161
2024-05-25 06:13:51 [INFO]: Epoch 156 - training loss: 0.2035, validation loss: 0.1164
2024-05-25 06:13:52 [INFO]: Epoch 157 - training loss: 0.2031, validation loss: 0.1163
2024-05-25 06:13:52 [INFO]: Epoch 158 - training loss: 0.2024, validation loss: 0.1169
2024-05-25 06:13:53 [INFO]: Epoch 159 - training loss: 0.2026, validation loss: 0.1161
2024-05-25 06:13:53 [INFO]: Epoch 160 - training loss: 0.2020, validation loss: 0.1165
2024-05-25 06:13:54 [INFO]: Epoch 161 - training loss: 0.2023, validation loss: 0.1165
2024-05-25 06:13:55 [INFO]: Epoch 162 - training loss: 0.2012, validation loss: 0.1160
2024-05-25 06:13:55 [INFO]: Epoch 163 - training loss: 0.2015, validation loss: 0.1168
2024-05-25 06:13:56 [INFO]: Epoch 164 - training loss: 0.2026, validation loss: 0.1163
2024-05-25 06:13:56 [INFO]: Epoch 165 - training loss: 0.2015, validation loss: 0.1163
2024-05-25 06:13:57 [INFO]: Epoch 166 - training loss: 0.2008, validation loss: 0.1157
2024-05-25 06:13:58 [INFO]: Epoch 167 - training loss: 0.1996, validation loss: 0.1159
2024-05-25 06:13:58 [INFO]: Epoch 168 - training loss: 0.1983, validation loss: 0.1160
2024-05-25 06:13:59 [INFO]: Epoch 169 - training loss: 0.1985, validation loss: 0.1159
2024-05-25 06:13:59 [INFO]: Epoch 170 - training loss: 0.1980, validation loss: 0.1154
2024-05-25 06:14:00 [INFO]: Epoch 171 - training loss: 0.1973, validation loss: 0.1148
2024-05-25 06:14:01 [INFO]: Epoch 172 - training loss: 0.1975, validation loss: 0.1157
2024-05-25 06:14:01 [INFO]: Epoch 173 - training loss: 0.1972, validation loss: 0.1169
2024-05-25 06:14:02 [INFO]: Epoch 174 - training loss: 0.2001, validation loss: 0.1159
2024-05-25 06:14:02 [INFO]: Epoch 175 - training loss: 0.2007, validation loss: 0.1151
2024-05-25 06:14:03 [INFO]: Epoch 176 - training loss: 0.2020, validation loss: 0.1169
2024-05-25 06:14:04 [INFO]: Epoch 177 - training loss: 0.2042, validation loss: 0.1170
2024-05-25 06:14:04 [INFO]: Epoch 178 - training loss: 0.1981, validation loss: 0.1160
2024-05-25 06:14:05 [INFO]: Epoch 179 - training loss: 0.1956, validation loss: 0.1152
2024-05-25 06:14:05 [INFO]: Epoch 180 - training loss: 0.1948, validation loss: 0.1150
2024-05-25 06:14:06 [INFO]: Epoch 181 - training loss: 0.1952, validation loss: 0.1152
2024-05-25 06:14:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:14:06 [INFO]: Finished training. The best model is from epoch#171.
2024-05-25 06:14:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/SAITS_air_quality/20240525_T061217/SAITS.pypots
2024-05-25 06:14:06 [INFO]: SAITS on Air-Quality: MAE=0.1615, MSE=0.1567
2024-05-25 06:14:06 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/SAITS_air_quality/imputation.pkl
2024-05-25 06:14:06 [INFO]: Using the given device: cuda:0
2024-05-25 06:14:06 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/Transformer_air_quality/20240525_T061406
2024-05-25 06:14:06 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/Transformer_air_quality/20240525_T061406/tensorboard
2024-05-25 06:14:06 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 06:14:07 [INFO]: Epoch 001 - training loss: 0.9014, validation loss: 0.4603
2024-05-25 06:14:07 [INFO]: Epoch 002 - training loss: 0.5771, validation loss: 0.3417
2024-05-25 06:14:07 [INFO]: Epoch 003 - training loss: 0.4842, validation loss: 0.2802
2024-05-25 06:14:07 [INFO]: Epoch 004 - training loss: 0.4379, validation loss: 0.2506
2024-05-25 06:14:08 [INFO]: Epoch 005 - training loss: 0.4077, validation loss: 0.2371
2024-05-25 06:14:08 [INFO]: Epoch 006 - training loss: 0.3887, validation loss: 0.2286
2024-05-25 06:14:08 [INFO]: Epoch 007 - training loss: 0.3752, validation loss: 0.2210
2024-05-25 06:14:08 [INFO]: Epoch 008 - training loss: 0.3662, validation loss: 0.2143
2024-05-25 06:14:09 [INFO]: Epoch 009 - training loss: 0.3522, validation loss: 0.2111
2024-05-25 06:14:09 [INFO]: Epoch 010 - training loss: 0.3425, validation loss: 0.2051
2024-05-25 06:14:09 [INFO]: Epoch 011 - training loss: 0.3349, validation loss: 0.1990
2024-05-25 06:14:09 [INFO]: Epoch 012 - training loss: 0.3294, validation loss: 0.1960
2024-05-25 06:14:10 [INFO]: Epoch 013 - training loss: 0.3251, validation loss: 0.1959
2024-05-25 06:14:10 [INFO]: Epoch 014 - training loss: 0.3237, validation loss: 0.1903
2024-05-25 06:14:10 [INFO]: Epoch 015 - training loss: 0.3168, validation loss: 0.1924
2024-05-25 06:14:11 [INFO]: Epoch 016 - training loss: 0.3120, validation loss: 0.1848
2024-05-25 06:14:11 [INFO]: Epoch 017 - training loss: 0.3100, validation loss: 0.1850
2024-05-25 06:14:11 [INFO]: Epoch 018 - training loss: 0.3078, validation loss: 0.1832
2024-05-25 06:14:11 [INFO]: Epoch 019 - training loss: 0.3044, validation loss: 0.1785
2024-05-25 06:14:12 [INFO]: Epoch 020 - training loss: 0.3005, validation loss: 0.1767
2024-05-25 06:14:12 [INFO]: Epoch 021 - training loss: 0.2960, validation loss: 0.1753
2024-05-25 06:14:12 [INFO]: Epoch 022 - training loss: 0.2934, validation loss: 0.1730
2024-05-25 06:14:12 [INFO]: Epoch 023 - training loss: 0.2910, validation loss: 0.1727
2024-05-25 06:14:13 [INFO]: Epoch 024 - training loss: 0.2895, validation loss: 0.1702
2024-05-25 06:14:13 [INFO]: Epoch 025 - training loss: 0.2847, validation loss: 0.1700
2024-05-25 06:14:13 [INFO]: Epoch 026 - training loss: 0.2827, validation loss: 0.1717
2024-05-25 06:14:13 [INFO]: Epoch 027 - training loss: 0.2815, validation loss: 0.1698
2024-05-25 06:14:14 [INFO]: Epoch 028 - training loss: 0.2790, validation loss: 0.1679
2024-05-25 06:14:14 [INFO]: Epoch 029 - training loss: 0.2759, validation loss: 0.1669
2024-05-25 06:14:14 [INFO]: Epoch 030 - training loss: 0.2755, validation loss: 0.1655
2024-05-25 06:14:14 [INFO]: Epoch 031 - training loss: 0.2737, validation loss: 0.1679
2024-05-25 06:14:15 [INFO]: Epoch 032 - training loss: 0.2723, validation loss: 0.1639
2024-05-25 06:14:15 [INFO]: Epoch 033 - training loss: 0.2692, validation loss: 0.1661
2024-05-25 06:14:15 [INFO]: Epoch 034 - training loss: 0.2705, validation loss: 0.1685
2024-05-25 06:14:15 [INFO]: Epoch 035 - training loss: 0.2710, validation loss: 0.1640
2024-05-25 06:14:16 [INFO]: Epoch 036 - training loss: 0.2649, validation loss: 0.1626
2024-05-25 06:14:16 [INFO]: Epoch 037 - training loss: 0.2631, validation loss: 0.1619
2024-05-25 06:14:16 [INFO]: Epoch 038 - training loss: 0.2595, validation loss: 0.1618
2024-05-25 06:14:16 [INFO]: Epoch 039 - training loss: 0.2572, validation loss: 0.1610
2024-05-25 06:14:17 [INFO]: Epoch 040 - training loss: 0.2630, validation loss: 0.1628
2024-05-25 06:14:17 [INFO]: Epoch 041 - training loss: 0.2637, validation loss: 0.1618
2024-05-25 06:14:17 [INFO]: Epoch 042 - training loss: 0.2590, validation loss: 0.1583
2024-05-25 06:14:17 [INFO]: Epoch 043 - training loss: 0.2544, validation loss: 0.1592
2024-05-25 06:14:18 [INFO]: Epoch 044 - training loss: 0.2518, validation loss: 0.1591
2024-05-25 06:14:18 [INFO]: Epoch 045 - training loss: 0.2496, validation loss: 0.1594
2024-05-25 06:14:18 [INFO]: Epoch 046 - training loss: 0.2478, validation loss: 0.1576
2024-05-25 06:14:18 [INFO]: Epoch 047 - training loss: 0.2476, validation loss: 0.1558
2024-05-25 06:14:18 [INFO]: Epoch 048 - training loss: 0.2470, validation loss: 0.1575
2024-05-25 06:14:19 [INFO]: Epoch 049 - training loss: 0.2447, validation loss: 0.1579
2024-05-25 06:14:19 [INFO]: Epoch 050 - training loss: 0.2447, validation loss: 0.1563
2024-05-25 06:14:19 [INFO]: Epoch 051 - training loss: 0.2443, validation loss: 0.1578
2024-05-25 06:14:19 [INFO]: Epoch 052 - training loss: 0.2484, validation loss: 0.1543
2024-05-25 06:14:20 [INFO]: Epoch 053 - training loss: 0.2442, validation loss: 0.1538
2024-05-25 06:14:20 [INFO]: Epoch 054 - training loss: 0.2403, validation loss: 0.1527
2024-05-25 06:14:20 [INFO]: Epoch 055 - training loss: 0.2401, validation loss: 0.1549
2024-05-25 06:14:20 [INFO]: Epoch 056 - training loss: 0.2367, validation loss: 0.1546
2024-05-25 06:14:21 [INFO]: Epoch 057 - training loss: 0.2367, validation loss: 0.1528
2024-05-25 06:14:21 [INFO]: Epoch 058 - training loss: 0.2342, validation loss: 0.1552
2024-05-25 06:14:21 [INFO]: Epoch 059 - training loss: 0.2353, validation loss: 0.1528
2024-05-25 06:14:21 [INFO]: Epoch 060 - training loss: 0.2346, validation loss: 0.1560
2024-05-25 06:14:22 [INFO]: Epoch 061 - training loss: 0.2321, validation loss: 0.1517
2024-05-25 06:14:22 [INFO]: Epoch 062 - training loss: 0.2302, validation loss: 0.1538
2024-05-25 06:14:22 [INFO]: Epoch 063 - training loss: 0.2304, validation loss: 0.1530
2024-05-25 06:14:22 [INFO]: Epoch 064 - training loss: 0.2307, validation loss: 0.1506
2024-05-25 06:14:23 [INFO]: Epoch 065 - training loss: 0.2310, validation loss: 0.1529
2024-05-25 06:14:23 [INFO]: Epoch 066 - training loss: 0.2319, validation loss: 0.1529
2024-05-25 06:14:23 [INFO]: Epoch 067 - training loss: 0.2268, validation loss: 0.1484
2024-05-25 06:14:23 [INFO]: Epoch 068 - training loss: 0.2263, validation loss: 0.1517
2024-05-25 06:14:24 [INFO]: Epoch 069 - training loss: 0.2294, validation loss: 0.1475
2024-05-25 06:14:24 [INFO]: Epoch 070 - training loss: 0.2254, validation loss: 0.1524
2024-05-25 06:14:24 [INFO]: Epoch 071 - training loss: 0.2227, validation loss: 0.1489
2024-05-25 06:14:24 [INFO]: Epoch 072 - training loss: 0.2222, validation loss: 0.1506
2024-05-25 06:14:25 [INFO]: Epoch 073 - training loss: 0.2208, validation loss: 0.1478
2024-05-25 06:14:25 [INFO]: Epoch 074 - training loss: 0.2194, validation loss: 0.1482
2024-05-25 06:14:25 [INFO]: Epoch 075 - training loss: 0.2210, validation loss: 0.1498
2024-05-25 06:14:25 [INFO]: Epoch 076 - training loss: 0.2196, validation loss: 0.1478
2024-05-25 06:14:26 [INFO]: Epoch 077 - training loss: 0.2168, validation loss: 0.1470
2024-05-25 06:14:26 [INFO]: Epoch 078 - training loss: 0.2200, validation loss: 0.1485
2024-05-25 06:14:26 [INFO]: Epoch 079 - training loss: 0.2155, validation loss: 0.1480
2024-05-25 06:14:26 [INFO]: Epoch 080 - training loss: 0.2140, validation loss: 0.1479
2024-05-25 06:14:27 [INFO]: Epoch 081 - training loss: 0.2126, validation loss: 0.1465
2024-05-25 06:14:27 [INFO]: Epoch 082 - training loss: 0.2126, validation loss: 0.1473
2024-05-25 06:14:27 [INFO]: Epoch 083 - training loss: 0.2126, validation loss: 0.1474
2024-05-25 06:14:27 [INFO]: Epoch 084 - training loss: 0.2126, validation loss: 0.1494
2024-05-25 06:14:28 [INFO]: Epoch 085 - training loss: 0.2119, validation loss: 0.1470
2024-05-25 06:14:28 [INFO]: Epoch 086 - training loss: 0.2123, validation loss: 0.1493
2024-05-25 06:14:28 [INFO]: Epoch 087 - training loss: 0.2095, validation loss: 0.1471
2024-05-25 06:14:28 [INFO]: Epoch 088 - training loss: 0.2066, validation loss: 0.1462
2024-05-25 06:14:29 [INFO]: Epoch 089 - training loss: 0.2061, validation loss: 0.1476
2024-05-25 06:14:29 [INFO]: Epoch 090 - training loss: 0.2059, validation loss: 0.1471
2024-05-25 06:14:29 [INFO]: Epoch 091 - training loss: 0.2041, validation loss: 0.1466
2024-05-25 06:14:29 [INFO]: Epoch 092 - training loss: 0.2021, validation loss: 0.1445
2024-05-25 06:14:30 [INFO]: Epoch 093 - training loss: 0.2034, validation loss: 0.1436
2024-05-25 06:14:30 [INFO]: Epoch 094 - training loss: 0.2044, validation loss: 0.1450
2024-05-25 06:14:30 [INFO]: Epoch 095 - training loss: 0.2020, validation loss: 0.1446
2024-05-25 06:14:30 [INFO]: Epoch 096 - training loss: 0.2007, validation loss: 0.1456
2024-05-25 06:14:31 [INFO]: Epoch 097 - training loss: 0.2011, validation loss: 0.1451
2024-05-25 06:14:31 [INFO]: Epoch 098 - training loss: 0.1996, validation loss: 0.1447
2024-05-25 06:14:31 [INFO]: Epoch 099 - training loss: 0.1989, validation loss: 0.1433
2024-05-25 06:14:31 [INFO]: Epoch 100 - training loss: 0.2021, validation loss: 0.1442
2024-05-25 06:14:32 [INFO]: Epoch 101 - training loss: 0.1999, validation loss: 0.1432
2024-05-25 06:14:32 [INFO]: Epoch 102 - training loss: 0.1976, validation loss: 0.1443
2024-05-25 06:14:32 [INFO]: Epoch 103 - training loss: 0.1959, validation loss: 0.1448
2024-05-25 06:14:32 [INFO]: Epoch 104 - training loss: 0.1955, validation loss: 0.1427
2024-05-25 06:14:33 [INFO]: Epoch 105 - training loss: 0.1958, validation loss: 0.1429
2024-05-25 06:14:33 [INFO]: Epoch 106 - training loss: 0.1965, validation loss: 0.1439
2024-05-25 06:14:33 [INFO]: Epoch 107 - training loss: 0.1961, validation loss: 0.1435
2024-05-25 06:14:33 [INFO]: Epoch 108 - training loss: 0.1975, validation loss: 0.1434
2024-05-25 06:14:34 [INFO]: Epoch 109 - training loss: 0.1974, validation loss: 0.1426
2024-05-25 06:14:34 [INFO]: Epoch 110 - training loss: 0.1930, validation loss: 0.1435
2024-05-25 06:14:34 [INFO]: Epoch 111 - training loss: 0.1913, validation loss: 0.1422
2024-05-25 06:14:34 [INFO]: Epoch 112 - training loss: 0.1906, validation loss: 0.1412
2024-05-25 06:14:35 [INFO]: Epoch 113 - training loss: 0.1895, validation loss: 0.1412
2024-05-25 06:14:35 [INFO]: Epoch 114 - training loss: 0.1918, validation loss: 0.1415
2024-05-25 06:14:35 [INFO]: Epoch 115 - training loss: 0.1906, validation loss: 0.1432
2024-05-25 06:14:35 [INFO]: Epoch 116 - training loss: 0.1878, validation loss: 0.1418
2024-05-25 06:14:36 [INFO]: Epoch 117 - training loss: 0.1877, validation loss: 0.1413
2024-05-25 06:14:36 [INFO]: Epoch 118 - training loss: 0.1872, validation loss: 0.1387
2024-05-25 06:14:36 [INFO]: Epoch 119 - training loss: 0.1866, validation loss: 0.1419
2024-05-25 06:14:36 [INFO]: Epoch 120 - training loss: 0.1866, validation loss: 0.1410
2024-05-25 06:14:37 [INFO]: Epoch 121 - training loss: 0.1880, validation loss: 0.1408
2024-05-25 06:14:37 [INFO]: Epoch 122 - training loss: 0.1905, validation loss: 0.1398
2024-05-25 06:14:37 [INFO]: Epoch 123 - training loss: 0.1880, validation loss: 0.1409
2024-05-25 06:14:37 [INFO]: Epoch 124 - training loss: 0.1853, validation loss: 0.1416
2024-05-25 06:14:38 [INFO]: Epoch 125 - training loss: 0.1846, validation loss: 0.1410
2024-05-25 06:14:38 [INFO]: Epoch 126 - training loss: 0.1843, validation loss: 0.1403
2024-05-25 06:14:38 [INFO]: Epoch 127 - training loss: 0.1893, validation loss: 0.1406
2024-05-25 06:14:38 [INFO]: Epoch 128 - training loss: 0.1842, validation loss: 0.1408
2024-05-25 06:14:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:14:38 [INFO]: Finished training. The best model is from epoch#118.
2024-05-25 06:14:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/Transformer_air_quality/20240525_T061406/Transformer.pypots
2024-05-25 06:14:39 [INFO]: Transformer on Air-Quality: MAE=0.1833, MSE=0.1882
2024-05-25 06:14:39 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Transformer_air_quality/imputation.pkl
2024-05-25 06:14:39 [INFO]: Using the given device: cuda:0
2024-05-25 06:14:39 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/TimesNet_air_quality/20240525_T061439
2024-05-25 06:14:39 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/TimesNet_air_quality/20240525_T061439/tensorboard
2024-05-25 06:14:39 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 06:14:39 [INFO]: Epoch 001 - training loss: 0.3089, validation loss: 0.2608
2024-05-25 06:14:40 [INFO]: Epoch 002 - training loss: 0.2386, validation loss: 0.2167
2024-05-25 06:14:40 [INFO]: Epoch 003 - training loss: 0.2126, validation loss: 0.2079
2024-05-25 06:14:41 [INFO]: Epoch 004 - training loss: 0.1806, validation loss: 0.1908
2024-05-25 06:14:41 [INFO]: Epoch 005 - training loss: 0.1641, validation loss: 0.1826
2024-05-25 06:14:42 [INFO]: Epoch 006 - training loss: 0.1506, validation loss: 0.1801
2024-05-25 06:14:42 [INFO]: Epoch 007 - training loss: 0.1446, validation loss: 0.1718
2024-05-25 06:14:43 [INFO]: Epoch 008 - training loss: 0.1468, validation loss: 0.1748
2024-05-25 06:14:43 [INFO]: Epoch 009 - training loss: 0.1382, validation loss: 0.1711
2024-05-25 06:14:44 [INFO]: Epoch 010 - training loss: 0.1313, validation loss: 0.1706
2024-05-25 06:14:44 [INFO]: Epoch 011 - training loss: 0.1397, validation loss: 0.1896
2024-05-25 06:14:45 [INFO]: Epoch 012 - training loss: 0.1379, validation loss: 0.1687
2024-05-25 06:14:45 [INFO]: Epoch 013 - training loss: 0.1231, validation loss: 0.1737
2024-05-25 06:14:45 [INFO]: Epoch 014 - training loss: 0.1201, validation loss: 0.1665
2024-05-25 06:14:46 [INFO]: Epoch 015 - training loss: 0.1144, validation loss: 0.1691
2024-05-25 06:14:46 [INFO]: Epoch 016 - training loss: 0.1105, validation loss: 0.1624
2024-05-25 06:14:47 [INFO]: Epoch 017 - training loss: 0.1087, validation loss: 0.1666
2024-05-25 06:14:47 [INFO]: Epoch 018 - training loss: 0.1071, validation loss: 0.1669
2024-05-25 06:14:48 [INFO]: Epoch 019 - training loss: 0.1032, validation loss: 0.1632
2024-05-25 06:14:48 [INFO]: Epoch 020 - training loss: 0.1039, validation loss: 0.1656
2024-05-25 06:14:49 [INFO]: Epoch 021 - training loss: 0.1007, validation loss: 0.1619
2024-05-25 06:14:49 [INFO]: Epoch 022 - training loss: 0.0989, validation loss: 0.1641
2024-05-25 06:14:50 [INFO]: Epoch 023 - training loss: 0.1001, validation loss: 0.1575
2024-05-25 06:14:50 [INFO]: Epoch 024 - training loss: 0.0946, validation loss: 0.1639
2024-05-25 06:14:50 [INFO]: Epoch 025 - training loss: 0.0977, validation loss: 0.1606
2024-05-25 06:14:51 [INFO]: Epoch 026 - training loss: 0.1027, validation loss: 0.1619
2024-05-25 06:14:51 [INFO]: Epoch 027 - training loss: 0.0990, validation loss: 0.1603
2024-05-25 06:14:52 [INFO]: Epoch 028 - training loss: 0.0942, validation loss: 0.1642
2024-05-25 06:14:52 [INFO]: Epoch 029 - training loss: 0.0933, validation loss: 0.1585
2024-05-25 06:14:53 [INFO]: Epoch 030 - training loss: 0.0860, validation loss: 0.1587
2024-05-25 06:14:53 [INFO]: Epoch 031 - training loss: 0.0837, validation loss: 0.1579
2024-05-25 06:14:54 [INFO]: Epoch 032 - training loss: 0.0845, validation loss: 0.1686
2024-05-25 06:14:54 [INFO]: Epoch 033 - training loss: 0.0862, validation loss: 0.1584
2024-05-25 06:14:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:14:54 [INFO]: Finished training. The best model is from epoch#23.
2024-05-25 06:14:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/TimesNet_air_quality/20240525_T061439/TimesNet.pypots
2024-05-25 06:14:54 [INFO]: TimesNet on Air-Quality: MAE=0.1745, MSE=0.2477
2024-05-25 06:14:54 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/TimesNet_air_quality/imputation.pkl
2024-05-25 06:14:54 [INFO]: Using the given device: cuda:0
2024-05-25 06:14:54 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454
2024-05-25 06:14:54 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/tensorboard
2024-05-25 06:14:54 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 06:15:11 [INFO]: Epoch 001 - training loss: 0.4739, validation loss: 0.3120
2024-05-25 06:15:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch1_loss0.3120022535324097.pypots
2024-05-25 06:15:28 [INFO]: Epoch 002 - training loss: 0.2789, validation loss: 0.2619
2024-05-25 06:15:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch2_loss0.261850668489933.pypots
2024-05-25 06:15:44 [INFO]: Epoch 003 - training loss: 0.2373, validation loss: 0.2266
2024-05-25 06:15:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch3_loss0.2265844613313675.pypots
2024-05-25 06:16:01 [INFO]: Epoch 004 - training loss: 0.2303, validation loss: 0.2059
2024-05-25 06:16:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch4_loss0.20593899488449097.pypots
2024-05-25 06:16:18 [INFO]: Epoch 005 - training loss: 0.1909, validation loss: 0.1796
2024-05-25 06:16:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch5_loss0.1796397015452385.pypots
2024-05-25 06:16:34 [INFO]: Epoch 006 - training loss: 0.1834, validation loss: 0.1688
2024-05-25 06:16:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch6_loss0.1688401371240616.pypots
2024-05-25 06:16:51 [INFO]: Epoch 007 - training loss: 0.1683, validation loss: 0.1681
2024-05-25 06:16:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch7_loss0.16814872175455092.pypots
2024-05-25 06:17:08 [INFO]: Epoch 008 - training loss: 0.1664, validation loss: 0.1570
2024-05-25 06:17:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch8_loss0.1570052906870842.pypots
2024-05-25 06:17:24 [INFO]: Epoch 009 - training loss: 0.1681, validation loss: 0.1511
2024-05-25 06:17:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch9_loss0.1511290490627289.pypots
2024-05-25 06:17:41 [INFO]: Epoch 010 - training loss: 0.1500, validation loss: 0.1499
2024-05-25 06:17:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch10_loss0.1499394044280052.pypots
2024-05-25 06:17:58 [INFO]: Epoch 011 - training loss: 0.1573, validation loss: 0.1472
2024-05-25 06:17:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch11_loss0.14720751196146012.pypots
2024-05-25 06:18:14 [INFO]: Epoch 012 - training loss: 0.1525, validation loss: 0.1519
2024-05-25 06:18:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch12_loss0.15189023911952973.pypots
2024-05-25 06:18:31 [INFO]: Epoch 013 - training loss: 0.1441, validation loss: 0.1453
2024-05-25 06:18:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch13_loss0.1453264147043228.pypots
2024-05-25 06:18:48 [INFO]: Epoch 014 - training loss: 0.1457, validation loss: 0.1482
2024-05-25 06:18:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch14_loss0.14820404052734376.pypots
2024-05-25 06:19:04 [INFO]: Epoch 015 - training loss: 0.1480, validation loss: 0.1387
2024-05-25 06:19:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch15_loss0.13873762786388397.pypots
2024-05-25 06:19:21 [INFO]: Epoch 016 - training loss: 0.1430, validation loss: 0.1368
2024-05-25 06:19:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch16_loss0.13682066202163695.pypots
2024-05-25 06:19:38 [INFO]: Epoch 017 - training loss: 0.1495, validation loss: 0.1395
2024-05-25 06:19:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch17_loss0.13945628926157952.pypots
2024-05-25 06:19:54 [INFO]: Epoch 018 - training loss: 0.1472, validation loss: 0.1371
2024-05-25 06:19:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch18_loss0.13711467906832694.pypots
2024-05-25 06:20:11 [INFO]: Epoch 019 - training loss: 0.1335, validation loss: 0.1361
2024-05-25 06:20:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch19_loss0.13612818568944932.pypots
2024-05-25 06:20:28 [INFO]: Epoch 020 - training loss: 0.1342, validation loss: 0.1359
2024-05-25 06:20:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch20_loss0.13590492010116578.pypots
2024-05-25 06:20:44 [INFO]: Epoch 021 - training loss: 0.1420, validation loss: 0.1335
2024-05-25 06:20:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch21_loss0.1335219107568264.pypots
2024-05-25 06:21:01 [INFO]: Epoch 022 - training loss: 0.1406, validation loss: 0.1305
2024-05-25 06:21:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch22_loss0.13053308576345443.pypots
2024-05-25 06:21:18 [INFO]: Epoch 023 - training loss: 0.1529, validation loss: 0.1288
2024-05-25 06:21:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch23_loss0.1288139969110489.pypots
2024-05-25 06:21:34 [INFO]: Epoch 024 - training loss: 0.1283, validation loss: 0.1265
2024-05-25 06:21:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch24_loss0.1265176683664322.pypots
2024-05-25 06:21:51 [INFO]: Epoch 025 - training loss: 0.1400, validation loss: 0.1292
2024-05-25 06:21:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch25_loss0.12920866012573243.pypots
2024-05-25 06:22:08 [INFO]: Epoch 026 - training loss: 0.1333, validation loss: 0.1263
2024-05-25 06:22:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch26_loss0.12625644579529763.pypots
2024-05-25 06:22:24 [INFO]: Epoch 027 - training loss: 0.1343, validation loss: 0.1299
2024-05-25 06:22:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch27_loss0.1299462527036667.pypots
2024-05-25 06:22:41 [INFO]: Epoch 028 - training loss: 0.1231, validation loss: 0.1276
2024-05-25 06:22:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch28_loss0.12764844223856925.pypots
2024-05-25 06:22:57 [INFO]: Epoch 029 - training loss: 0.1193, validation loss: 0.1236
2024-05-25 06:22:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch29_loss0.12359591573476791.pypots
2024-05-25 06:23:14 [INFO]: Epoch 030 - training loss: 0.1136, validation loss: 0.1245
2024-05-25 06:23:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch30_loss0.12445780411362647.pypots
2024-05-25 06:23:31 [INFO]: Epoch 031 - training loss: 0.1153, validation loss: 0.1243
2024-05-25 06:23:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch31_loss0.12425405830144882.pypots
2024-05-25 06:23:47 [INFO]: Epoch 032 - training loss: 0.1271, validation loss: 0.1229
2024-05-25 06:23:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch32_loss0.12294110432267188.pypots
2024-05-25 06:24:04 [INFO]: Epoch 033 - training loss: 0.1234, validation loss: 0.1239
2024-05-25 06:24:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch33_loss0.12389840632677078.pypots
2024-05-25 06:24:21 [INFO]: Epoch 034 - training loss: 0.1137, validation loss: 0.1208
2024-05-25 06:24:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch34_loss0.12080433592200279.pypots
2024-05-25 06:24:37 [INFO]: Epoch 035 - training loss: 0.1155, validation loss: 0.1222
2024-05-25 06:24:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch35_loss0.12219286784529686.pypots
2024-05-25 06:24:54 [INFO]: Epoch 036 - training loss: 0.1148, validation loss: 0.1177
2024-05-25 06:24:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch36_loss0.11770558580756188.pypots
2024-05-25 06:25:11 [INFO]: Epoch 037 - training loss: 0.1236, validation loss: 0.1172
2024-05-25 06:25:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch37_loss0.11715696454048156.pypots
2024-05-25 06:25:27 [INFO]: Epoch 038 - training loss: 0.1209, validation loss: 0.1226
2024-05-25 06:25:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch38_loss0.12264401912689209.pypots
2024-05-25 06:25:44 [INFO]: Epoch 039 - training loss: 0.1244, validation loss: 0.1222
2024-05-25 06:25:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch39_loss0.12220354750752449.pypots
2024-05-25 06:26:01 [INFO]: Epoch 040 - training loss: 0.1232, validation loss: 0.1180
2024-05-25 06:26:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch40_loss0.11797157078981399.pypots
2024-05-25 06:26:17 [INFO]: Epoch 041 - training loss: 0.1181, validation loss: 0.1215
2024-05-25 06:26:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch41_loss0.12153933048248292.pypots
2024-05-25 06:26:34 [INFO]: Epoch 042 - training loss: 0.1223, validation loss: 0.1156
2024-05-25 06:26:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch42_loss0.1156204029917717.pypots
2024-05-25 06:26:51 [INFO]: Epoch 043 - training loss: 0.1292, validation loss: 0.1171
2024-05-25 06:26:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch43_loss0.11709411293268204.pypots
2024-05-25 06:27:07 [INFO]: Epoch 044 - training loss: 0.1120, validation loss: 0.1152
2024-05-25 06:27:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch44_loss0.11517042443156242.pypots
2024-05-25 06:27:24 [INFO]: Epoch 045 - training loss: 0.1241, validation loss: 0.1146
2024-05-25 06:27:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch45_loss0.11461213007569312.pypots
2024-05-25 06:27:41 [INFO]: Epoch 046 - training loss: 0.1186, validation loss: 0.1178
2024-05-25 06:27:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch46_loss0.11779359430074691.pypots
2024-05-25 06:27:58 [INFO]: Epoch 047 - training loss: 0.1093, validation loss: 0.1152
2024-05-25 06:27:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch47_loss0.11520109102129936.pypots
2024-05-25 06:28:14 [INFO]: Epoch 048 - training loss: 0.1098, validation loss: 0.1161
2024-05-25 06:28:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch48_loss0.11606123372912407.pypots
2024-05-25 06:28:31 [INFO]: Epoch 049 - training loss: 0.1064, validation loss: 0.1140
2024-05-25 06:28:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch49_loss0.11396479681134224.pypots
2024-05-25 06:28:48 [INFO]: Epoch 050 - training loss: 0.1169, validation loss: 0.1224
2024-05-25 06:28:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch50_loss0.1224407896399498.pypots
2024-05-25 06:29:04 [INFO]: Epoch 051 - training loss: 0.1260, validation loss: 0.1156
2024-05-25 06:29:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch51_loss0.11561872735619545.pypots
2024-05-25 06:29:21 [INFO]: Epoch 052 - training loss: 0.1095, validation loss: 0.1127
2024-05-25 06:29:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch52_loss0.11271711066365242.pypots
2024-05-25 06:29:38 [INFO]: Epoch 053 - training loss: 0.1148, validation loss: 0.1129
2024-05-25 06:29:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch53_loss0.11293938681483269.pypots
2024-05-25 06:29:54 [INFO]: Epoch 054 - training loss: 0.1135, validation loss: 0.1124
2024-05-25 06:29:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch54_loss0.11242740228772163.pypots
2024-05-25 06:30:11 [INFO]: Epoch 055 - training loss: 0.1192, validation loss: 0.1137
2024-05-25 06:30:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch55_loss0.11371129900217056.pypots
2024-05-25 06:30:28 [INFO]: Epoch 056 - training loss: 0.0967, validation loss: 0.1107
2024-05-25 06:30:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch56_loss0.11071905046701432.pypots
2024-05-25 06:30:44 [INFO]: Epoch 057 - training loss: 0.1047, validation loss: 0.1128
2024-05-25 06:30:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch57_loss0.11278968676924706.pypots
2024-05-25 06:31:01 [INFO]: Epoch 058 - training loss: 0.0997, validation loss: 0.1106
2024-05-25 06:31:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch58_loss0.11055530682206154.pypots
2024-05-25 06:31:18 [INFO]: Epoch 059 - training loss: 0.1049, validation loss: 0.1111
2024-05-25 06:31:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch59_loss0.11106058210134506.pypots
2024-05-25 06:31:34 [INFO]: Epoch 060 - training loss: 0.1198, validation loss: 0.1118
2024-05-25 06:31:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch60_loss0.11178355515003205.pypots
2024-05-25 06:31:51 [INFO]: Epoch 061 - training loss: 0.0967, validation loss: 0.1115
2024-05-25 06:31:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch61_loss0.1114643320441246.pypots
2024-05-25 06:32:08 [INFO]: Epoch 062 - training loss: 0.1060, validation loss: 0.1088
2024-05-25 06:32:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch62_loss0.10883454456925393.pypots
2024-05-25 06:32:24 [INFO]: Epoch 063 - training loss: 0.1158, validation loss: 0.1093
2024-05-25 06:32:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch63_loss0.10932034999132156.pypots
2024-05-25 06:32:41 [INFO]: Epoch 064 - training loss: 0.1184, validation loss: 0.1156
2024-05-25 06:32:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch64_loss0.11556665748357772.pypots
2024-05-25 06:32:58 [INFO]: Epoch 065 - training loss: 0.1056, validation loss: 0.1099
2024-05-25 06:32:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch65_loss0.10993922725319863.pypots
2024-05-25 06:33:14 [INFO]: Epoch 066 - training loss: 0.1059, validation loss: 0.1081
2024-05-25 06:33:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch66_loss0.10812027603387833.pypots
2024-05-25 06:33:31 [INFO]: Epoch 067 - training loss: 0.1116, validation loss: 0.1089
2024-05-25 06:33:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch67_loss0.1088927760720253.pypots
2024-05-25 06:33:48 [INFO]: Epoch 068 - training loss: 0.1022, validation loss: 0.1089
2024-05-25 06:33:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch68_loss0.10888645350933075.pypots
2024-05-25 06:34:04 [INFO]: Epoch 069 - training loss: 0.1045, validation loss: 0.1083
2024-05-25 06:34:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch69_loss0.10830715596675873.pypots
2024-05-25 06:34:21 [INFO]: Epoch 070 - training loss: 0.1139, validation loss: 0.1085
2024-05-25 06:34:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch70_loss0.10851282700896263.pypots
2024-05-25 06:34:38 [INFO]: Epoch 071 - training loss: 0.1027, validation loss: 0.1087
2024-05-25 06:34:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch71_loss0.10871261432766914.pypots
2024-05-25 06:34:54 [INFO]: Epoch 072 - training loss: 0.1182, validation loss: 0.1082
2024-05-25 06:34:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch72_loss0.10823312178254127.pypots
2024-05-25 06:35:11 [INFO]: Epoch 073 - training loss: 0.1068, validation loss: 0.1077
2024-05-25 06:35:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch73_loss0.10768771767616273.pypots
2024-05-25 06:35:28 [INFO]: Epoch 074 - training loss: 0.1058, validation loss: 0.1105
2024-05-25 06:35:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch74_loss0.11046088933944702.pypots
2024-05-25 06:35:44 [INFO]: Epoch 075 - training loss: 0.1009, validation loss: 0.1128
2024-05-25 06:35:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch75_loss0.11277252435684204.pypots
2024-05-25 06:36:01 [INFO]: Epoch 076 - training loss: 0.1021, validation loss: 0.1117
2024-05-25 06:36:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch76_loss0.11172183379530906.pypots
2024-05-25 06:36:18 [INFO]: Epoch 077 - training loss: 0.1040, validation loss: 0.1092
2024-05-25 06:36:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch77_loss0.10924549847841263.pypots
2024-05-25 06:36:34 [INFO]: Epoch 078 - training loss: 0.1139, validation loss: 0.1076
2024-05-25 06:36:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch78_loss0.10757266655564308.pypots
2024-05-25 06:36:51 [INFO]: Epoch 079 - training loss: 0.1019, validation loss: 0.1069
2024-05-25 06:36:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch79_loss0.10689349323511124.pypots
2024-05-25 06:37:08 [INFO]: Epoch 080 - training loss: 0.1141, validation loss: 0.1064
2024-05-25 06:37:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch80_loss0.10639115124940872.pypots
2024-05-25 06:37:24 [INFO]: Epoch 081 - training loss: 0.1149, validation loss: 0.1062
2024-05-25 06:37:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch81_loss0.10617989599704743.pypots
2024-05-25 06:37:41 [INFO]: Epoch 082 - training loss: 0.0972, validation loss: 0.1061
2024-05-25 06:37:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch82_loss0.10605600029230118.pypots
2024-05-25 06:37:58 [INFO]: Epoch 083 - training loss: 0.1082, validation loss: 0.1076
2024-05-25 06:37:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch83_loss0.10756335854530334.pypots
2024-05-25 06:38:14 [INFO]: Epoch 084 - training loss: 0.1100, validation loss: 0.1092
2024-05-25 06:38:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch84_loss0.10915006622672081.pypots
2024-05-25 06:38:31 [INFO]: Epoch 085 - training loss: 0.0998, validation loss: 0.1050
2024-05-25 06:38:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch85_loss0.10496415644884109.pypots
2024-05-25 06:38:48 [INFO]: Epoch 086 - training loss: 0.1188, validation loss: 0.1083
2024-05-25 06:38:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch86_loss0.1082906298339367.pypots
2024-05-25 06:39:04 [INFO]: Epoch 087 - training loss: 0.1044, validation loss: 0.1059
2024-05-25 06:39:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch87_loss0.10594325438141823.pypots
2024-05-25 06:39:21 [INFO]: Epoch 088 - training loss: 0.0950, validation loss: 0.1085
2024-05-25 06:39:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch88_loss0.10847153142094612.pypots
2024-05-25 06:39:38 [INFO]: Epoch 089 - training loss: 0.1072, validation loss: 0.1045
2024-05-25 06:39:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch89_loss0.1045380875468254.pypots
2024-05-25 06:39:54 [INFO]: Epoch 090 - training loss: 0.1003, validation loss: 0.1050
2024-05-25 06:39:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch90_loss0.10504616573452949.pypots
2024-05-25 06:40:11 [INFO]: Epoch 091 - training loss: 0.1023, validation loss: 0.1074
2024-05-25 06:40:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch91_loss0.10738019794225692.pypots
2024-05-25 06:40:28 [INFO]: Epoch 092 - training loss: 0.0934, validation loss: 0.1041
2024-05-25 06:40:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch92_loss0.1040547713637352.pypots
2024-05-25 06:40:44 [INFO]: Epoch 093 - training loss: 0.1076, validation loss: 0.1054
2024-05-25 06:40:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch93_loss0.1053724929690361.pypots
2024-05-25 06:41:01 [INFO]: Epoch 094 - training loss: 0.1036, validation loss: 0.1060
2024-05-25 06:41:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch94_loss0.10603283792734146.pypots
2024-05-25 06:41:18 [INFO]: Epoch 095 - training loss: 0.0979, validation loss: 0.1041
2024-05-25 06:41:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch95_loss0.10411035120487214.pypots
2024-05-25 06:41:34 [INFO]: Epoch 096 - training loss: 0.0939, validation loss: 0.1061
2024-05-25 06:41:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch96_loss0.10612670481204986.pypots
2024-05-25 06:41:51 [INFO]: Epoch 097 - training loss: 0.0983, validation loss: 0.1066
2024-05-25 06:41:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch97_loss0.10659550502896309.pypots
2024-05-25 06:42:08 [INFO]: Epoch 098 - training loss: 0.1184, validation loss: 0.1051
2024-05-25 06:42:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch98_loss0.10507341474294662.pypots
2024-05-25 06:42:24 [INFO]: Epoch 099 - training loss: 0.1095, validation loss: 0.1043
2024-05-25 06:42:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch99_loss0.10430625602602958.pypots
2024-05-25 06:42:41 [INFO]: Epoch 100 - training loss: 0.1138, validation loss: 0.1054
2024-05-25 06:42:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch100_loss0.10540486499667168.pypots
2024-05-25 06:42:58 [INFO]: Epoch 101 - training loss: 0.1170, validation loss: 0.1042
2024-05-25 06:42:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch101_loss0.10419645458459854.pypots
2024-05-25 06:43:15 [INFO]: Epoch 102 - training loss: 0.1009, validation loss: 0.1069
2024-05-25 06:43:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI_epoch102_loss0.1068949468433857.pypots
2024-05-25 06:43:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:43:15 [INFO]: Finished training. The best model is from epoch#92.
2024-05-25 06:43:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T061454/CSDI.pypots
2024-05-25 06:45:35 [INFO]: CSDI on Air-Quality: MAE=0.1156, MSE=0.2439
2024-05-25 06:45:35 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/CSDI_air_quality/imputation.pkl
2024-05-25 06:45:35 [INFO]: Using the given device: cuda:0
2024-05-25 06:45:35 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/GPVAE_air_quality/20240525_T064535
2024-05-25 06:45:35 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/GPVAE_air_quality/20240525_T064535/tensorboard
2024-05-25 06:45:35 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 06:45:36 [INFO]: Epoch 001 - training loss: 65313.2730, validation loss: 0.6617
2024-05-25 06:45:36 [INFO]: Epoch 002 - training loss: 41567.0072, validation loss: 0.5548
2024-05-25 06:45:36 [INFO]: Epoch 003 - training loss: 41201.0595, validation loss: 0.5290
2024-05-25 06:45:37 [INFO]: Epoch 004 - training loss: 41057.4359, validation loss: 0.4619
2024-05-25 06:45:37 [INFO]: Epoch 005 - training loss: 40962.4929, validation loss: 0.4486
2024-05-25 06:45:37 [INFO]: Epoch 006 - training loss: 40902.0835, validation loss: 0.3956
2024-05-25 06:45:38 [INFO]: Epoch 007 - training loss: 40876.5427, validation loss: 0.4151
2024-05-25 06:45:38 [INFO]: Epoch 008 - training loss: 40845.4939, validation loss: 0.3620
2024-05-25 06:45:38 [INFO]: Epoch 009 - training loss: 40792.5010, validation loss: 0.3312
2024-05-25 06:45:39 [INFO]: Epoch 010 - training loss: 40770.1895, validation loss: 0.3182
2024-05-25 06:45:39 [INFO]: Epoch 011 - training loss: 40750.6267, validation loss: 0.3495
2024-05-25 06:45:39 [INFO]: Epoch 012 - training loss: 40739.3979, validation loss: 0.3120
2024-05-25 06:45:40 [INFO]: Epoch 013 - training loss: 40713.0323, validation loss: 0.3010
2024-05-25 06:45:40 [INFO]: Epoch 014 - training loss: 40697.8242, validation loss: 0.3330
2024-05-25 06:45:40 [INFO]: Epoch 015 - training loss: 40716.3226, validation loss: 0.3200
2024-05-25 06:45:41 [INFO]: Epoch 016 - training loss: 40690.5774, validation loss: 0.3109
2024-05-25 06:45:41 [INFO]: Epoch 017 - training loss: 40665.4711, validation loss: 0.2819
2024-05-25 06:45:41 [INFO]: Epoch 018 - training loss: 40659.6327, validation loss: 0.3239
2024-05-25 06:45:42 [INFO]: Epoch 019 - training loss: 40660.9615, validation loss: 0.2816
2024-05-25 06:45:42 [INFO]: Epoch 020 - training loss: 40642.9389, validation loss: 0.2724
2024-05-25 06:45:42 [INFO]: Epoch 021 - training loss: 40649.9602, validation loss: 0.3027
2024-05-25 06:45:43 [INFO]: Epoch 022 - training loss: 40692.3900, validation loss: 0.2868
2024-05-25 06:45:43 [INFO]: Epoch 023 - training loss: 40644.3205, validation loss: 0.2984
2024-05-25 06:45:43 [INFO]: Epoch 024 - training loss: 40643.2554, validation loss: 0.2735
2024-05-25 06:45:44 [INFO]: Epoch 025 - training loss: 40653.3352, validation loss: 0.2988
2024-05-25 06:45:44 [INFO]: Epoch 026 - training loss: 40661.4789, validation loss: 0.2958
2024-05-25 06:45:44 [INFO]: Epoch 027 - training loss: 40664.6000, validation loss: 0.2823
2024-05-25 06:45:45 [INFO]: Epoch 028 - training loss: 40630.4784, validation loss: 0.2637
2024-05-25 06:45:45 [INFO]: Epoch 029 - training loss: 40604.5563, validation loss: 0.2510
2024-05-25 06:45:46 [INFO]: Epoch 030 - training loss: 40604.3108, validation loss: 0.2480
2024-05-25 06:45:46 [INFO]: Epoch 031 - training loss: 40593.4015, validation loss: 0.2436
2024-05-25 06:45:46 [INFO]: Epoch 032 - training loss: 40589.0757, validation loss: 0.2453
2024-05-25 06:45:47 [INFO]: Epoch 033 - training loss: 40594.7435, validation loss: 0.2660
2024-05-25 06:45:47 [INFO]: Epoch 034 - training loss: 40587.8199, validation loss: 0.2367
2024-05-25 06:45:47 [INFO]: Epoch 035 - training loss: 40581.0700, validation loss: 0.2402
2024-05-25 06:45:48 [INFO]: Epoch 036 - training loss: 40578.2763, validation loss: 0.2427
2024-05-25 06:45:48 [INFO]: Epoch 037 - training loss: 40576.2565, validation loss: 0.2331
2024-05-25 06:45:48 [INFO]: Epoch 038 - training loss: 40574.7543, validation loss: 0.2342
2024-05-25 06:45:49 [INFO]: Epoch 039 - training loss: 40582.4261, validation loss: 0.2467
2024-05-25 06:45:49 [INFO]: Epoch 040 - training loss: 40587.5074, validation loss: 0.2548
2024-05-25 06:45:49 [INFO]: Epoch 041 - training loss: 40597.4129, validation loss: 0.2306
2024-05-25 06:45:50 [INFO]: Epoch 042 - training loss: 40568.8539, validation loss: 0.2292
2024-05-25 06:45:50 [INFO]: Epoch 043 - training loss: 40568.3854, validation loss: 0.2367
2024-05-25 06:45:50 [INFO]: Epoch 044 - training loss: 40559.4294, validation loss: 0.2234
2024-05-25 06:45:51 [INFO]: Epoch 045 - training loss: 40558.4650, validation loss: 0.2288
2024-05-25 06:45:51 [INFO]: Epoch 046 - training loss: 40556.7105, validation loss: 0.2360
2024-05-25 06:45:51 [INFO]: Epoch 047 - training loss: 40559.0757, validation loss: 0.2283
2024-05-25 06:45:52 [INFO]: Epoch 048 - training loss: 40564.6826, validation loss: 0.2298
2024-05-25 06:45:52 [INFO]: Epoch 049 - training loss: 40553.5684, validation loss: 0.2220
2024-05-25 06:45:52 [INFO]: Epoch 050 - training loss: 40545.9388, validation loss: 0.2206
2024-05-25 06:45:53 [INFO]: Epoch 051 - training loss: 40544.8443, validation loss: 0.2199
2024-05-25 06:45:53 [INFO]: Epoch 052 - training loss: 40542.6117, validation loss: 0.2192
2024-05-25 06:45:53 [INFO]: Epoch 053 - training loss: 40547.6683, validation loss: 0.3196
2024-05-25 06:45:54 [INFO]: Epoch 054 - training loss: 40749.3103, validation loss: 0.2590
2024-05-25 06:45:54 [INFO]: Epoch 055 - training loss: 40622.2457, validation loss: 0.2488
2024-05-25 06:45:55 [INFO]: Epoch 056 - training loss: 40581.8294, validation loss: 0.2244
2024-05-25 06:45:55 [INFO]: Epoch 057 - training loss: 40560.8598, validation loss: 0.2221
2024-05-25 06:45:55 [INFO]: Epoch 058 - training loss: 40551.1976, validation loss: 0.2183
2024-05-25 06:45:56 [INFO]: Epoch 059 - training loss: 40544.9505, validation loss: 0.2291
2024-05-25 06:45:56 [INFO]: Epoch 060 - training loss: 40551.4104, validation loss: 0.2148
2024-05-25 06:45:56 [INFO]: Epoch 061 - training loss: 40539.4145, validation loss: 0.2110
2024-05-25 06:45:57 [INFO]: Epoch 062 - training loss: 40535.6049, validation loss: 0.2117
2024-05-25 06:45:57 [INFO]: Epoch 063 - training loss: 40536.6357, validation loss: 0.2155
2024-05-25 06:45:57 [INFO]: Epoch 064 - training loss: 40539.1616, validation loss: 0.2174
2024-05-25 06:45:58 [INFO]: Epoch 065 - training loss: 40533.6079, validation loss: 0.2110
2024-05-25 06:45:58 [INFO]: Epoch 066 - training loss: 40537.1497, validation loss: 0.2095
2024-05-25 06:45:58 [INFO]: Epoch 067 - training loss: 40530.1217, validation loss: 0.2096
2024-05-25 06:45:59 [INFO]: Epoch 068 - training loss: 40556.3193, validation loss: 0.2214
2024-05-25 06:45:59 [INFO]: Epoch 069 - training loss: 40559.1463, validation loss: 0.2233
2024-05-25 06:46:00 [INFO]: Epoch 070 - training loss: 40574.4317, validation loss: 0.2426
2024-05-25 06:46:00 [INFO]: Epoch 071 - training loss: 40606.9039, validation loss: 0.2379
2024-05-25 06:46:00 [INFO]: Epoch 072 - training loss: 40575.1981, validation loss: 0.2243
2024-05-25 06:46:01 [INFO]: Epoch 073 - training loss: 40552.1836, validation loss: 0.2093
2024-05-25 06:46:01 [INFO]: Epoch 074 - training loss: 40539.9225, validation loss: 0.2085
2024-05-25 06:46:01 [INFO]: Epoch 075 - training loss: 40539.5929, validation loss: 0.2072
2024-05-25 06:46:02 [INFO]: Epoch 076 - training loss: 40532.2661, validation loss: 0.2041
2024-05-25 06:46:02 [INFO]: Epoch 077 - training loss: 40533.7397, validation loss: 0.2028
2024-05-25 06:46:02 [INFO]: Epoch 078 - training loss: 40529.7687, validation loss: 0.2032
2024-05-25 06:46:03 [INFO]: Epoch 079 - training loss: 40527.2244, validation loss: 0.2057
2024-05-25 06:46:03 [INFO]: Epoch 080 - training loss: 40527.3877, validation loss: 0.2110
2024-05-25 06:46:03 [INFO]: Epoch 081 - training loss: 40536.7189, validation loss: 0.2062
2024-05-25 06:46:04 [INFO]: Epoch 082 - training loss: 40531.7593, validation loss: 0.2187
2024-05-25 06:46:04 [INFO]: Epoch 083 - training loss: 40544.6766, validation loss: 0.2105
2024-05-25 06:46:04 [INFO]: Epoch 084 - training loss: 40531.6383, validation loss: 0.2042
2024-05-25 06:46:05 [INFO]: Epoch 085 - training loss: 40529.8655, validation loss: 0.2051
2024-05-25 06:46:05 [INFO]: Epoch 086 - training loss: 40529.7293, validation loss: 0.2067
2024-05-25 06:46:05 [INFO]: Epoch 087 - training loss: 40526.7378, validation loss: 0.2038
2024-05-25 06:46:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:46:05 [INFO]: Finished training. The best model is from epoch#77.
2024-05-25 06:46:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/GPVAE_air_quality/20240525_T064535/GPVAE.pypots
2024-05-25 06:46:06 [INFO]: GP-VAE on Air-Quality: MAE=0.2650, MSE=0.2561
2024-05-25 06:46:06 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/GPVAE_air_quality/imputation.pkl
2024-05-25 06:46:06 [INFO]: Using the given device: cuda:0
2024-05-25 06:46:06 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/USGAN_air_quality/20240525_T064606
2024-05-25 06:46:06 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/USGAN_air_quality/20240525_T064606/tensorboard
2024-05-25 06:46:06 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 06:46:11 [INFO]: Epoch 001 - generator training loss: 0.3625, discriminator training loss: 0.5701, validation loss: 0.4989
2024-05-25 06:46:15 [INFO]: Epoch 002 - generator training loss: 0.0326, discriminator training loss: 0.5237, validation loss: 0.3817
2024-05-25 06:46:19 [INFO]: Epoch 003 - generator training loss: -0.0260, discriminator training loss: 0.5182, validation loss: 0.3113
2024-05-25 06:46:23 [INFO]: Epoch 004 - generator training loss: -0.0744, discriminator training loss: 0.5141, validation loss: 0.2698
2024-05-25 06:46:27 [INFO]: Epoch 005 - generator training loss: -0.1000, discriminator training loss: 0.5096, validation loss: 0.2447
2024-05-25 06:46:32 [INFO]: Epoch 006 - generator training loss: -0.1132, discriminator training loss: 0.5040, validation loss: 0.2250
2024-05-25 06:46:36 [INFO]: Epoch 007 - generator training loss: -0.1219, discriminator training loss: 0.4975, validation loss: 0.2108
2024-05-25 06:46:40 [INFO]: Epoch 008 - generator training loss: -0.1292, discriminator training loss: 0.4897, validation loss: 0.2011
2024-05-25 06:46:44 [INFO]: Epoch 009 - generator training loss: -0.1321, discriminator training loss: 0.4811, validation loss: 0.1935
2024-05-25 06:46:48 [INFO]: Epoch 010 - generator training loss: -0.1323, discriminator training loss: 0.4712, validation loss: 0.1863
2024-05-25 06:46:52 [INFO]: Epoch 011 - generator training loss: -0.1308, discriminator training loss: 0.4606, validation loss: 0.1805
2024-05-25 06:46:57 [INFO]: Epoch 012 - generator training loss: -0.1292, discriminator training loss: 0.4497, validation loss: 0.1758
2024-05-25 06:47:01 [INFO]: Epoch 013 - generator training loss: -0.1257, discriminator training loss: 0.4387, validation loss: 0.1719
2024-05-25 06:47:05 [INFO]: Epoch 014 - generator training loss: -0.1225, discriminator training loss: 0.4275, validation loss: 0.1680
2024-05-25 06:47:09 [INFO]: Epoch 015 - generator training loss: -0.1186, discriminator training loss: 0.4170, validation loss: 0.1651
2024-05-25 06:47:13 [INFO]: Epoch 016 - generator training loss: -0.1145, discriminator training loss: 0.4071, validation loss: 0.1623
2024-05-25 06:47:17 [INFO]: Epoch 017 - generator training loss: -0.1120, discriminator training loss: 0.3977, validation loss: 0.1591
2024-05-25 06:47:22 [INFO]: Epoch 018 - generator training loss: -0.1077, discriminator training loss: 0.3889, validation loss: 0.1572
2024-05-25 06:47:26 [INFO]: Epoch 019 - generator training loss: -0.1054, discriminator training loss: 0.3809, validation loss: 0.1543
2024-05-25 06:47:30 [INFO]: Epoch 020 - generator training loss: -0.1026, discriminator training loss: 0.3737, validation loss: 0.1531
2024-05-25 06:47:34 [INFO]: Epoch 021 - generator training loss: -0.1009, discriminator training loss: 0.3673, validation loss: 0.1509
2024-05-25 06:47:38 [INFO]: Epoch 022 - generator training loss: -0.0980, discriminator training loss: 0.3617, validation loss: 0.1491
2024-05-25 06:47:43 [INFO]: Epoch 023 - generator training loss: -0.0984, discriminator training loss: 0.3558, validation loss: 0.1473
2024-05-25 06:47:47 [INFO]: Epoch 024 - generator training loss: -0.0960, discriminator training loss: 0.3512, validation loss: 0.1456
2024-05-25 06:47:51 [INFO]: Epoch 025 - generator training loss: -0.0958, discriminator training loss: 0.3472, validation loss: 0.1440
2024-05-25 06:47:55 [INFO]: Epoch 026 - generator training loss: -0.0938, discriminator training loss: 0.3432, validation loss: 0.1425
2024-05-25 06:47:59 [INFO]: Epoch 027 - generator training loss: -0.0935, discriminator training loss: 0.3404, validation loss: 0.1404
2024-05-25 06:48:03 [INFO]: Epoch 028 - generator training loss: -0.0922, discriminator training loss: 0.3371, validation loss: 0.1394
2024-05-25 06:48:08 [INFO]: Epoch 029 - generator training loss: -0.0934, discriminator training loss: 0.3340, validation loss: 0.1377
2024-05-25 06:48:12 [INFO]: Epoch 030 - generator training loss: -0.0935, discriminator training loss: 0.3319, validation loss: 0.1367
2024-05-25 06:48:16 [INFO]: Epoch 031 - generator training loss: -0.0940, discriminator training loss: 0.3294, validation loss: 0.1352
2024-05-25 06:48:20 [INFO]: Epoch 032 - generator training loss: -0.0932, discriminator training loss: 0.3275, validation loss: 0.1341
2024-05-25 06:48:24 [INFO]: Epoch 033 - generator training loss: -0.0944, discriminator training loss: 0.3256, validation loss: 0.1335
2024-05-25 06:48:29 [INFO]: Epoch 034 - generator training loss: -0.0932, discriminator training loss: 0.3236, validation loss: 0.1319
2024-05-25 06:48:33 [INFO]: Epoch 035 - generator training loss: -0.0938, discriminator training loss: 0.3222, validation loss: 0.1307
2024-05-25 06:48:37 [INFO]: Epoch 036 - generator training loss: -0.0948, discriminator training loss: 0.3209, validation loss: 0.1303
2024-05-25 06:48:41 [INFO]: Epoch 037 - generator training loss: -0.0938, discriminator training loss: 0.3196, validation loss: 0.1289
2024-05-25 06:48:45 [INFO]: Epoch 038 - generator training loss: -0.0948, discriminator training loss: 0.3184, validation loss: 0.1278
2024-05-25 06:48:49 [INFO]: Epoch 039 - generator training loss: -0.0952, discriminator training loss: 0.3171, validation loss: 0.1272
2024-05-25 06:48:54 [INFO]: Epoch 040 - generator training loss: -0.0952, discriminator training loss: 0.3165, validation loss: 0.1264
2024-05-25 06:48:58 [INFO]: Epoch 041 - generator training loss: -0.0954, discriminator training loss: 0.3159, validation loss: 0.1252
2024-05-25 06:49:02 [INFO]: Epoch 042 - generator training loss: -0.0969, discriminator training loss: 0.3149, validation loss: 0.1247
2024-05-25 06:49:06 [INFO]: Epoch 043 - generator training loss: -0.0967, discriminator training loss: 0.3140, validation loss: 0.1238
2024-05-25 06:49:10 [INFO]: Epoch 044 - generator training loss: -0.0980, discriminator training loss: 0.3133, validation loss: 0.1234
2024-05-25 06:49:14 [INFO]: Epoch 045 - generator training loss: -0.0970, discriminator training loss: 0.3132, validation loss: 0.1226
2024-05-25 06:49:19 [INFO]: Epoch 046 - generator training loss: -0.0984, discriminator training loss: 0.3120, validation loss: 0.1215
2024-05-25 06:49:23 [INFO]: Epoch 047 - generator training loss: -0.0986, discriminator training loss: 0.3121, validation loss: 0.1211
2024-05-25 06:49:27 [INFO]: Epoch 048 - generator training loss: -0.0994, discriminator training loss: 0.3111, validation loss: 0.1205
2024-05-25 06:49:31 [INFO]: Epoch 049 - generator training loss: -0.0996, discriminator training loss: 0.3109, validation loss: 0.1200
2024-05-25 06:49:35 [INFO]: Epoch 050 - generator training loss: -0.1002, discriminator training loss: 0.3102, validation loss: 0.1195
2024-05-25 06:49:39 [INFO]: Epoch 051 - generator training loss: -0.1011, discriminator training loss: 0.3092, validation loss: 0.1190
2024-05-25 06:49:44 [INFO]: Epoch 052 - generator training loss: -0.1006, discriminator training loss: 0.3091, validation loss: 0.1178
2024-05-25 06:49:48 [INFO]: Epoch 053 - generator training loss: -0.1015, discriminator training loss: 0.3088, validation loss: 0.1184
2024-05-25 06:49:52 [INFO]: Epoch 054 - generator training loss: -0.1028, discriminator training loss: 0.3088, validation loss: 0.1172
2024-05-25 06:49:56 [INFO]: Epoch 055 - generator training loss: -0.1025, discriminator training loss: 0.3088, validation loss: 0.1167
2024-05-25 06:50:00 [INFO]: Epoch 056 - generator training loss: -0.1031, discriminator training loss: 0.3076, validation loss: 0.1169
2024-05-25 06:50:05 [INFO]: Epoch 057 - generator training loss: -0.1031, discriminator training loss: 0.3076, validation loss: 0.1153
2024-05-25 06:50:09 [INFO]: Epoch 058 - generator training loss: -0.1045, discriminator training loss: 0.3072, validation loss: 0.1148
2024-05-25 06:50:13 [INFO]: Epoch 059 - generator training loss: -0.1058, discriminator training loss: 0.3078, validation loss: 0.1140
2024-05-25 06:50:17 [INFO]: Epoch 060 - generator training loss: -0.1067, discriminator training loss: 0.3069, validation loss: 0.1145
2024-05-25 06:50:21 [INFO]: Epoch 061 - generator training loss: -0.1074, discriminator training loss: 0.3063, validation loss: 0.1137
2024-05-25 06:50:25 [INFO]: Epoch 062 - generator training loss: -0.1066, discriminator training loss: 0.3066, validation loss: 0.1135
2024-05-25 06:50:29 [INFO]: Epoch 063 - generator training loss: -0.1080, discriminator training loss: 0.3062, validation loss: 0.1130
2024-05-25 06:50:34 [INFO]: Epoch 064 - generator training loss: -0.1082, discriminator training loss: 0.3061, validation loss: 0.1125
2024-05-25 06:50:38 [INFO]: Epoch 065 - generator training loss: -0.1089, discriminator training loss: 0.3051, validation loss: 0.1124
2024-05-25 06:50:42 [INFO]: Epoch 066 - generator training loss: -0.1084, discriminator training loss: 0.3050, validation loss: 0.1121
2024-05-25 06:50:46 [INFO]: Epoch 067 - generator training loss: -0.1098, discriminator training loss: 0.3050, validation loss: 0.1120
2024-05-25 06:50:50 [INFO]: Epoch 068 - generator training loss: -0.1070, discriminator training loss: 0.3044, validation loss: 0.1118
2024-05-25 06:50:55 [INFO]: Epoch 069 - generator training loss: -0.1094, discriminator training loss: 0.3051, validation loss: 0.1117
2024-05-25 06:50:59 [INFO]: Epoch 070 - generator training loss: -0.1106, discriminator training loss: 0.3044, validation loss: 0.1123
2024-05-25 06:51:03 [INFO]: Epoch 071 - generator training loss: -0.1112, discriminator training loss: 0.3046, validation loss: 0.1113
2024-05-25 06:51:07 [INFO]: Epoch 072 - generator training loss: -0.1101, discriminator training loss: 0.3035, validation loss: 0.1101
2024-05-25 06:51:11 [INFO]: Epoch 073 - generator training loss: -0.1121, discriminator training loss: 0.3046, validation loss: 0.1101
2024-05-25 06:51:15 [INFO]: Epoch 074 - generator training loss: -0.1125, discriminator training loss: 0.3038, validation loss: 0.1106
2024-05-25 06:51:20 [INFO]: Epoch 075 - generator training loss: -0.1121, discriminator training loss: 0.3043, validation loss: 0.1108
2024-05-25 06:51:24 [INFO]: Epoch 076 - generator training loss: -0.1114, discriminator training loss: 0.3035, validation loss: 0.1102
2024-05-25 06:51:28 [INFO]: Epoch 077 - generator training loss: -0.1131, discriminator training loss: 0.3036, validation loss: 0.1099
2024-05-25 06:51:32 [INFO]: Epoch 078 - generator training loss: -0.1131, discriminator training loss: 0.3036, validation loss: 0.1091
2024-05-25 06:51:36 [INFO]: Epoch 079 - generator training loss: -0.1129, discriminator training loss: 0.3036, validation loss: 0.1095
2024-05-25 06:51:40 [INFO]: Epoch 080 - generator training loss: -0.1141, discriminator training loss: 0.3033, validation loss: 0.1089
2024-05-25 06:51:45 [INFO]: Epoch 081 - generator training loss: -0.1143, discriminator training loss: 0.3028, validation loss: 0.1088
2024-05-25 06:51:49 [INFO]: Epoch 082 - generator training loss: -0.1143, discriminator training loss: 0.3030, validation loss: 0.1089
2024-05-25 06:51:53 [INFO]: Epoch 083 - generator training loss: -0.1152, discriminator training loss: 0.3031, validation loss: 0.1086
2024-05-25 06:51:57 [INFO]: Epoch 084 - generator training loss: -0.1154, discriminator training loss: 0.3026, validation loss: 0.1091
2024-05-25 06:52:01 [INFO]: Epoch 085 - generator training loss: -0.1152, discriminator training loss: 0.3027, validation loss: 0.1097
2024-05-25 06:52:05 [INFO]: Epoch 086 - generator training loss: -0.1156, discriminator training loss: 0.3025, validation loss: 0.1085
2024-05-25 06:52:10 [INFO]: Epoch 087 - generator training loss: -0.1144, discriminator training loss: 0.3018, validation loss: 0.1090
2024-05-25 06:52:14 [INFO]: Epoch 088 - generator training loss: -0.1163, discriminator training loss: 0.3022, validation loss: 0.1081
2024-05-25 06:52:18 [INFO]: Epoch 089 - generator training loss: -0.1171, discriminator training loss: 0.3017, validation loss: 0.1077
2024-05-25 06:52:22 [INFO]: Epoch 090 - generator training loss: -0.1169, discriminator training loss: 0.3014, validation loss: 0.1074
2024-05-25 06:52:26 [INFO]: Epoch 091 - generator training loss: -0.1177, discriminator training loss: 0.3016, validation loss: 0.1073
2024-05-25 06:52:30 [INFO]: Epoch 092 - generator training loss: -0.1173, discriminator training loss: 0.3015, validation loss: 0.1072
2024-05-25 06:52:35 [INFO]: Epoch 093 - generator training loss: -0.1179, discriminator training loss: 0.3012, validation loss: 0.1072
2024-05-25 06:52:39 [INFO]: Epoch 094 - generator training loss: -0.1186, discriminator training loss: 0.3013, validation loss: 0.1074
2024-05-25 06:52:43 [INFO]: Epoch 095 - generator training loss: -0.1188, discriminator training loss: 0.3021, validation loss: 0.1069
2024-05-25 06:52:47 [INFO]: Epoch 096 - generator training loss: -0.1184, discriminator training loss: 0.3014, validation loss: 0.1068
2024-05-25 06:52:51 [INFO]: Epoch 097 - generator training loss: -0.1194, discriminator training loss: 0.3012, validation loss: 0.1069
2024-05-25 06:52:55 [INFO]: Epoch 098 - generator training loss: -0.1189, discriminator training loss: 0.3013, validation loss: 0.1069
2024-05-25 06:53:00 [INFO]: Epoch 099 - generator training loss: -0.1191, discriminator training loss: 0.3012, validation loss: 0.1066
2024-05-25 06:53:04 [INFO]: Epoch 100 - generator training loss: -0.1195, discriminator training loss: 0.3011, validation loss: 0.1071
2024-05-25 06:53:08 [INFO]: Epoch 101 - generator training loss: -0.1195, discriminator training loss: 0.3004, validation loss: 0.1061
2024-05-25 06:53:12 [INFO]: Epoch 102 - generator training loss: -0.1197, discriminator training loss: 0.3003, validation loss: 0.1070
2024-05-25 06:53:16 [INFO]: Epoch 103 - generator training loss: -0.1198, discriminator training loss: 0.3001, validation loss: 0.1071
2024-05-25 06:53:21 [INFO]: Epoch 104 - generator training loss: -0.1194, discriminator training loss: 0.2997, validation loss: 0.1063
2024-05-25 06:53:25 [INFO]: Epoch 105 - generator training loss: -0.1214, discriminator training loss: 0.2995, validation loss: 0.1056
2024-05-25 06:53:29 [INFO]: Epoch 106 - generator training loss: -0.1216, discriminator training loss: 0.2999, validation loss: 0.1063
2024-05-25 06:53:33 [INFO]: Epoch 107 - generator training loss: -0.1210, discriminator training loss: 0.3000, validation loss: 0.1063
2024-05-25 06:53:37 [INFO]: Epoch 108 - generator training loss: -0.1218, discriminator training loss: 0.2993, validation loss: 0.1061
2024-05-25 06:53:41 [INFO]: Epoch 109 - generator training loss: -0.1204, discriminator training loss: 0.3002, validation loss: 0.1065
2024-05-25 06:53:46 [INFO]: Epoch 110 - generator training loss: -0.1209, discriminator training loss: 0.2996, validation loss: 0.1061
2024-05-25 06:53:50 [INFO]: Epoch 111 - generator training loss: -0.1222, discriminator training loss: 0.2998, validation loss: 0.1063
2024-05-25 06:53:54 [INFO]: Epoch 112 - generator training loss: -0.1221, discriminator training loss: 0.2998, validation loss: 0.1066
2024-05-25 06:53:58 [INFO]: Epoch 113 - generator training loss: -0.1218, discriminator training loss: 0.2991, validation loss: 0.1058
2024-05-25 06:54:02 [INFO]: Epoch 114 - generator training loss: -0.1221, discriminator training loss: 0.2993, validation loss: 0.1058
2024-05-25 06:54:07 [INFO]: Epoch 115 - generator training loss: -0.1232, discriminator training loss: 0.2988, validation loss: 0.1060
2024-05-25 06:54:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:54:07 [INFO]: Finished training. The best model is from epoch#105.
2024-05-25 06:54:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/USGAN_air_quality/20240525_T064606/USGAN.pypots
2024-05-25 06:54:07 [INFO]: US-GAN on Air-Quality: MAE=0.1664, MSE=0.1398
2024-05-25 06:54:07 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/USGAN_air_quality/imputation.pkl
2024-05-25 06:54:07 [INFO]: Using the given device: cuda:0
2024-05-25 06:54:07 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/BRITS_air_quality/20240525_T065407
2024-05-25 06:54:07 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/BRITS_air_quality/20240525_T065407/tensorboard
2024-05-25 06:54:07 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 06:54:11 [INFO]: Epoch 001 - training loss: 1.4224, validation loss: 0.9455
2024-05-25 06:54:14 [INFO]: Epoch 002 - training loss: 1.1723, validation loss: 0.6999
2024-05-25 06:54:17 [INFO]: Epoch 003 - training loss: 0.9724, validation loss: 0.5820
2024-05-25 06:54:19 [INFO]: Epoch 004 - training loss: 0.8556, validation loss: 0.5095
2024-05-25 06:54:22 [INFO]: Epoch 005 - training loss: 0.7804, validation loss: 0.4621
2024-05-25 06:54:25 [INFO]: Epoch 006 - training loss: 0.7275, validation loss: 0.4260
2024-05-25 06:54:28 [INFO]: Epoch 007 - training loss: 0.6847, validation loss: 0.3965
2024-05-25 06:54:31 [INFO]: Epoch 008 - training loss: 0.6496, validation loss: 0.3725
2024-05-25 06:54:33 [INFO]: Epoch 009 - training loss: 0.6237, validation loss: 0.3527
2024-05-25 06:54:36 [INFO]: Epoch 010 - training loss: 0.6042, validation loss: 0.3376
2024-05-25 06:54:39 [INFO]: Epoch 011 - training loss: 0.5864, validation loss: 0.3229
2024-05-25 06:54:42 [INFO]: Epoch 012 - training loss: 0.5720, validation loss: 0.3112
2024-05-25 06:54:45 [INFO]: Epoch 013 - training loss: 0.5573, validation loss: 0.3006
2024-05-25 06:54:48 [INFO]: Epoch 014 - training loss: 0.5450, validation loss: 0.2910
2024-05-25 06:54:50 [INFO]: Epoch 015 - training loss: 0.5343, validation loss: 0.2839
2024-05-25 06:54:53 [INFO]: Epoch 016 - training loss: 0.5244, validation loss: 0.2763
2024-05-25 06:54:56 [INFO]: Epoch 017 - training loss: 0.5151, validation loss: 0.2697
2024-05-25 06:54:59 [INFO]: Epoch 018 - training loss: 0.5071, validation loss: 0.2635
2024-05-25 06:55:02 [INFO]: Epoch 019 - training loss: 0.4984, validation loss: 0.2578
2024-05-25 06:55:04 [INFO]: Epoch 020 - training loss: 0.4920, validation loss: 0.2528
2024-05-25 06:55:07 [INFO]: Epoch 021 - training loss: 0.4834, validation loss: 0.2481
2024-05-25 06:55:10 [INFO]: Epoch 022 - training loss: 0.4783, validation loss: 0.2426
2024-05-25 06:55:13 [INFO]: Epoch 023 - training loss: 0.4698, validation loss: 0.2379
2024-05-25 06:55:16 [INFO]: Epoch 024 - training loss: 0.4641, validation loss: 0.2345
2024-05-25 06:55:19 [INFO]: Epoch 025 - training loss: 0.4572, validation loss: 0.2300
2024-05-25 06:55:21 [INFO]: Epoch 026 - training loss: 0.4517, validation loss: 0.2263
2024-05-25 06:55:24 [INFO]: Epoch 027 - training loss: 0.4467, validation loss: 0.2224
2024-05-25 06:55:27 [INFO]: Epoch 028 - training loss: 0.4413, validation loss: 0.2195
2024-05-25 06:55:30 [INFO]: Epoch 029 - training loss: 0.4360, validation loss: 0.2161
2024-05-25 06:55:33 [INFO]: Epoch 030 - training loss: 0.4312, validation loss: 0.2128
2024-05-25 06:55:35 [INFO]: Epoch 031 - training loss: 0.4268, validation loss: 0.2097
2024-05-25 06:55:38 [INFO]: Epoch 032 - training loss: 0.4219, validation loss: 0.2069
2024-05-25 06:55:41 [INFO]: Epoch 033 - training loss: 0.4179, validation loss: 0.2039
2024-05-25 06:55:44 [INFO]: Epoch 034 - training loss: 0.4136, validation loss: 0.2014
2024-05-25 06:55:47 [INFO]: Epoch 035 - training loss: 0.4102, validation loss: 0.1984
2024-05-25 06:55:50 [INFO]: Epoch 036 - training loss: 0.4062, validation loss: 0.1960
2024-05-25 06:55:52 [INFO]: Epoch 037 - training loss: 0.4020, validation loss: 0.1939
2024-05-25 06:55:55 [INFO]: Epoch 038 - training loss: 0.3985, validation loss: 0.1916
2024-05-25 06:55:58 [INFO]: Epoch 039 - training loss: 0.3952, validation loss: 0.1896
2024-05-25 06:56:01 [INFO]: Epoch 040 - training loss: 0.3924, validation loss: 0.1874
2024-05-25 06:56:04 [INFO]: Epoch 041 - training loss: 0.3887, validation loss: 0.1852
2024-05-25 06:56:06 [INFO]: Epoch 042 - training loss: 0.3868, validation loss: 0.1835
2024-05-25 06:56:09 [INFO]: Epoch 043 - training loss: 0.3834, validation loss: 0.1813
2024-05-25 06:56:12 [INFO]: Epoch 044 - training loss: 0.3793, validation loss: 0.1797
2024-05-25 06:56:15 [INFO]: Epoch 045 - training loss: 0.3785, validation loss: 0.1783
2024-05-25 06:56:18 [INFO]: Epoch 046 - training loss: 0.3749, validation loss: 0.1762
2024-05-25 06:56:20 [INFO]: Epoch 047 - training loss: 0.3725, validation loss: 0.1746
2024-05-25 06:56:23 [INFO]: Epoch 048 - training loss: 0.3701, validation loss: 0.1730
2024-05-25 06:56:26 [INFO]: Epoch 049 - training loss: 0.3677, validation loss: 0.1716
2024-05-25 06:56:29 [INFO]: Epoch 050 - training loss: 0.3656, validation loss: 0.1703
2024-05-25 06:56:32 [INFO]: Epoch 051 - training loss: 0.3635, validation loss: 0.1689
2024-05-25 06:56:35 [INFO]: Epoch 052 - training loss: 0.3602, validation loss: 0.1678
2024-05-25 06:56:37 [INFO]: Epoch 053 - training loss: 0.3586, validation loss: 0.1665
2024-05-25 06:56:40 [INFO]: Epoch 054 - training loss: 0.3565, validation loss: 0.1653
2024-05-25 06:56:43 [INFO]: Epoch 055 - training loss: 0.3549, validation loss: 0.1640
2024-05-25 06:56:46 [INFO]: Epoch 056 - training loss: 0.3527, validation loss: 0.1629
2024-05-25 06:56:49 [INFO]: Epoch 057 - training loss: 0.3505, validation loss: 0.1620
2024-05-25 06:56:51 [INFO]: Epoch 058 - training loss: 0.3499, validation loss: 0.1607
2024-05-25 06:56:54 [INFO]: Epoch 059 - training loss: 0.3469, validation loss: 0.1598
2024-05-25 06:56:57 [INFO]: Epoch 060 - training loss: 0.3452, validation loss: 0.1590
2024-05-25 06:57:00 [INFO]: Epoch 061 - training loss: 0.3438, validation loss: 0.1578
2024-05-25 06:57:03 [INFO]: Epoch 062 - training loss: 0.3419, validation loss: 0.1572
2024-05-25 06:57:06 [INFO]: Epoch 063 - training loss: 0.3408, validation loss: 0.1562
2024-05-25 06:57:08 [INFO]: Epoch 064 - training loss: 0.3388, validation loss: 0.1553
2024-05-25 06:57:11 [INFO]: Epoch 065 - training loss: 0.3373, validation loss: 0.1546
2024-05-25 06:57:14 [INFO]: Epoch 066 - training loss: 0.3358, validation loss: 0.1539
2024-05-25 06:57:17 [INFO]: Epoch 067 - training loss: 0.3343, validation loss: 0.1531
2024-05-25 06:57:20 [INFO]: Epoch 068 - training loss: 0.3332, validation loss: 0.1523
2024-05-25 06:57:22 [INFO]: Epoch 069 - training loss: 0.3320, validation loss: 0.1514
2024-05-25 06:57:25 [INFO]: Epoch 070 - training loss: 0.3305, validation loss: 0.1510
2024-05-25 06:57:28 [INFO]: Epoch 071 - training loss: 0.3303, validation loss: 0.1502
2024-05-25 06:57:31 [INFO]: Epoch 072 - training loss: 0.3285, validation loss: 0.1496
2024-05-25 06:57:34 [INFO]: Epoch 073 - training loss: 0.3269, validation loss: 0.1491
2024-05-25 06:57:36 [INFO]: Epoch 074 - training loss: 0.3269, validation loss: 0.1485
2024-05-25 06:57:39 [INFO]: Epoch 075 - training loss: 0.3255, validation loss: 0.1480
2024-05-25 06:57:42 [INFO]: Epoch 076 - training loss: 0.3240, validation loss: 0.1476
2024-05-25 06:57:45 [INFO]: Epoch 077 - training loss: 0.3226, validation loss: 0.1468
2024-05-25 06:57:48 [INFO]: Epoch 078 - training loss: 0.3223, validation loss: 0.1462
2024-05-25 06:57:51 [INFO]: Epoch 079 - training loss: 0.3210, validation loss: 0.1457
2024-05-25 06:57:53 [INFO]: Epoch 080 - training loss: 0.3201, validation loss: 0.1452
2024-05-25 06:57:56 [INFO]: Epoch 081 - training loss: 0.3192, validation loss: 0.1447
2024-05-25 06:57:59 [INFO]: Epoch 082 - training loss: 0.3184, validation loss: 0.1445
2024-05-25 06:58:02 [INFO]: Epoch 083 - training loss: 0.3176, validation loss: 0.1440
2024-05-25 06:58:05 [INFO]: Epoch 084 - training loss: 0.3165, validation loss: 0.1435
2024-05-25 06:58:07 [INFO]: Epoch 085 - training loss: 0.3157, validation loss: 0.1430
2024-05-25 06:58:10 [INFO]: Epoch 086 - training loss: 0.3148, validation loss: 0.1424
2024-05-25 06:58:13 [INFO]: Epoch 087 - training loss: 0.3139, validation loss: 0.1422
2024-05-25 06:58:16 [INFO]: Epoch 088 - training loss: 0.3135, validation loss: 0.1416
2024-05-25 06:58:19 [INFO]: Epoch 089 - training loss: 0.3126, validation loss: 0.1413
2024-05-25 06:58:21 [INFO]: Epoch 090 - training loss: 0.3124, validation loss: 0.1410
2024-05-25 06:58:24 [INFO]: Epoch 091 - training loss: 0.3115, validation loss: 0.1404
2024-05-25 06:58:27 [INFO]: Epoch 092 - training loss: 0.3104, validation loss: 0.1402
2024-05-25 06:58:30 [INFO]: Epoch 093 - training loss: 0.3094, validation loss: 0.1398
2024-05-25 06:58:33 [INFO]: Epoch 094 - training loss: 0.3090, validation loss: 0.1397
2024-05-25 06:58:36 [INFO]: Epoch 095 - training loss: 0.3078, validation loss: 0.1392
2024-05-25 06:58:38 [INFO]: Epoch 096 - training loss: 0.3071, validation loss: 0.1388
2024-05-25 06:58:41 [INFO]: Epoch 097 - training loss: 0.3071, validation loss: 0.1385
2024-05-25 06:58:44 [INFO]: Epoch 098 - training loss: 0.3064, validation loss: 0.1381
2024-05-25 06:58:47 [INFO]: Epoch 099 - training loss: 0.3051, validation loss: 0.1379
2024-05-25 06:58:50 [INFO]: Epoch 100 - training loss: 0.3046, validation loss: 0.1375
2024-05-25 06:58:52 [INFO]: Epoch 101 - training loss: 0.3039, validation loss: 0.1374
2024-05-25 06:58:55 [INFO]: Epoch 102 - training loss: 0.3036, validation loss: 0.1368
2024-05-25 06:58:58 [INFO]: Epoch 103 - training loss: 0.3025, validation loss: 0.1367
2024-05-25 06:59:01 [INFO]: Epoch 104 - training loss: 0.3021, validation loss: 0.1363
2024-05-25 06:59:04 [INFO]: Epoch 105 - training loss: 0.3023, validation loss: 0.1361
2024-05-25 06:59:07 [INFO]: Epoch 106 - training loss: 0.3010, validation loss: 0.1358
2024-05-25 06:59:09 [INFO]: Epoch 107 - training loss: 0.3005, validation loss: 0.1355
2024-05-25 06:59:12 [INFO]: Epoch 108 - training loss: 0.2998, validation loss: 0.1352
2024-05-25 06:59:15 [INFO]: Epoch 109 - training loss: 0.2995, validation loss: 0.1347
2024-05-25 06:59:18 [INFO]: Epoch 110 - training loss: 0.2997, validation loss: 0.1346
2024-05-25 06:59:21 [INFO]: Epoch 111 - training loss: 0.2983, validation loss: 0.1344
2024-05-25 06:59:23 [INFO]: Epoch 112 - training loss: 0.2978, validation loss: 0.1342
2024-05-25 06:59:26 [INFO]: Epoch 113 - training loss: 0.2974, validation loss: 0.1339
2024-05-25 06:59:29 [INFO]: Epoch 114 - training loss: 0.2971, validation loss: 0.1335
2024-05-25 06:59:32 [INFO]: Epoch 115 - training loss: 0.2961, validation loss: 0.1333
2024-05-25 06:59:35 [INFO]: Epoch 116 - training loss: 0.2965, validation loss: 0.1329
2024-05-25 06:59:37 [INFO]: Epoch 117 - training loss: 0.2959, validation loss: 0.1330
2024-05-25 06:59:40 [INFO]: Epoch 118 - training loss: 0.2951, validation loss: 0.1325
2024-05-25 06:59:43 [INFO]: Epoch 119 - training loss: 0.2941, validation loss: 0.1322
2024-05-25 06:59:46 [INFO]: Epoch 120 - training loss: 0.2944, validation loss: 0.1322
2024-05-25 06:59:49 [INFO]: Epoch 121 - training loss: 0.2932, validation loss: 0.1319
2024-05-25 06:59:52 [INFO]: Epoch 122 - training loss: 0.2926, validation loss: 0.1317
2024-05-25 06:59:54 [INFO]: Epoch 123 - training loss: 0.2927, validation loss: 0.1314
2024-05-25 06:59:57 [INFO]: Epoch 124 - training loss: 0.2918, validation loss: 0.1314
2024-05-25 07:00:00 [INFO]: Epoch 125 - training loss: 0.2916, validation loss: 0.1307
2024-05-25 07:00:03 [INFO]: Epoch 126 - training loss: 0.2915, validation loss: 0.1305
2024-05-25 07:00:06 [INFO]: Epoch 127 - training loss: 0.2908, validation loss: 0.1304
2024-05-25 07:00:08 [INFO]: Epoch 128 - training loss: 0.2898, validation loss: 0.1302
2024-05-25 07:00:11 [INFO]: Epoch 129 - training loss: 0.2898, validation loss: 0.1299
2024-05-25 07:00:14 [INFO]: Epoch 130 - training loss: 0.2893, validation loss: 0.1298
2024-05-25 07:00:17 [INFO]: Epoch 131 - training loss: 0.2886, validation loss: 0.1293
2024-05-25 07:00:20 [INFO]: Epoch 132 - training loss: 0.2880, validation loss: 0.1291
2024-05-25 07:00:22 [INFO]: Epoch 133 - training loss: 0.2883, validation loss: 0.1289
2024-05-25 07:00:25 [INFO]: Epoch 134 - training loss: 0.2876, validation loss: 0.1287
2024-05-25 07:00:28 [INFO]: Epoch 135 - training loss: 0.2868, validation loss: 0.1285
2024-05-25 07:00:31 [INFO]: Epoch 136 - training loss: 0.2865, validation loss: 0.1283
2024-05-25 07:00:34 [INFO]: Epoch 137 - training loss: 0.2867, validation loss: 0.1281
2024-05-25 07:00:37 [INFO]: Epoch 138 - training loss: 0.2861, validation loss: 0.1276
2024-05-25 07:00:39 [INFO]: Epoch 139 - training loss: 0.2857, validation loss: 0.1278
2024-05-25 07:00:42 [INFO]: Epoch 140 - training loss: 0.2854, validation loss: 0.1275
2024-05-25 07:00:45 [INFO]: Epoch 141 - training loss: 0.2857, validation loss: 0.1273
2024-05-25 07:00:48 [INFO]: Epoch 142 - training loss: 0.2844, validation loss: 0.1273
2024-05-25 07:00:51 [INFO]: Epoch 143 - training loss: 0.2838, validation loss: 0.1269
2024-05-25 07:00:53 [INFO]: Epoch 144 - training loss: 0.2846, validation loss: 0.1266
2024-05-25 07:00:56 [INFO]: Epoch 145 - training loss: 0.2834, validation loss: 0.1266
2024-05-25 07:00:59 [INFO]: Epoch 146 - training loss: 0.2833, validation loss: 0.1261
2024-05-25 07:01:02 [INFO]: Epoch 147 - training loss: 0.2831, validation loss: 0.1262
2024-05-25 07:01:05 [INFO]: Epoch 148 - training loss: 0.2824, validation loss: 0.1258
2024-05-25 07:01:08 [INFO]: Epoch 149 - training loss: 0.2821, validation loss: 0.1256
2024-05-25 07:01:10 [INFO]: Epoch 150 - training loss: 0.2818, validation loss: 0.1255
2024-05-25 07:01:13 [INFO]: Epoch 151 - training loss: 0.2814, validation loss: 0.1254
2024-05-25 07:01:16 [INFO]: Epoch 152 - training loss: 0.2813, validation loss: 0.1250
2024-05-25 07:01:19 [INFO]: Epoch 153 - training loss: 0.2807, validation loss: 0.1251
2024-05-25 07:01:22 [INFO]: Epoch 154 - training loss: 0.2801, validation loss: 0.1247
2024-05-25 07:01:24 [INFO]: Epoch 155 - training loss: 0.2795, validation loss: 0.1247
2024-05-25 07:01:27 [INFO]: Epoch 156 - training loss: 0.2797, validation loss: 0.1245
2024-05-25 07:01:30 [INFO]: Epoch 157 - training loss: 0.2793, validation loss: 0.1242
2024-05-25 07:01:33 [INFO]: Epoch 158 - training loss: 0.2791, validation loss: 0.1241
2024-05-25 07:01:36 [INFO]: Epoch 159 - training loss: 0.2786, validation loss: 0.1240
2024-05-25 07:01:38 [INFO]: Epoch 160 - training loss: 0.2790, validation loss: 0.1239
2024-05-25 07:01:41 [INFO]: Epoch 161 - training loss: 0.2784, validation loss: 0.1235
2024-05-25 07:01:44 [INFO]: Epoch 162 - training loss: 0.2780, validation loss: 0.1235
2024-05-25 07:01:47 [INFO]: Epoch 163 - training loss: 0.2779, validation loss: 0.1234
2024-05-25 07:01:50 [INFO]: Epoch 164 - training loss: 0.2770, validation loss: 0.1230
2024-05-25 07:01:52 [INFO]: Epoch 165 - training loss: 0.2765, validation loss: 0.1230
2024-05-25 07:01:55 [INFO]: Epoch 166 - training loss: 0.2774, validation loss: 0.1229
2024-05-25 07:01:58 [INFO]: Epoch 167 - training loss: 0.2765, validation loss: 0.1226
2024-05-25 07:02:01 [INFO]: Epoch 168 - training loss: 0.2758, validation loss: 0.1226
2024-05-25 07:02:04 [INFO]: Epoch 169 - training loss: 0.2759, validation loss: 0.1223
2024-05-25 07:02:07 [INFO]: Epoch 170 - training loss: 0.2758, validation loss: 0.1223
2024-05-25 07:02:09 [INFO]: Epoch 171 - training loss: 0.2752, validation loss: 0.1221
2024-05-25 07:02:12 [INFO]: Epoch 172 - training loss: 0.2752, validation loss: 0.1220
2024-05-25 07:02:15 [INFO]: Epoch 173 - training loss: 0.2749, validation loss: 0.1220
2024-05-25 07:02:18 [INFO]: Epoch 174 - training loss: 0.2743, validation loss: 0.1217
2024-05-25 07:02:21 [INFO]: Epoch 175 - training loss: 0.2747, validation loss: 0.1215
2024-05-25 07:02:23 [INFO]: Epoch 176 - training loss: 0.2741, validation loss: 0.1215
2024-05-25 07:02:26 [INFO]: Epoch 177 - training loss: 0.2741, validation loss: 0.1213
2024-05-25 07:02:29 [INFO]: Epoch 178 - training loss: 0.2739, validation loss: 0.1213
2024-05-25 07:02:32 [INFO]: Epoch 179 - training loss: 0.2734, validation loss: 0.1211
2024-05-25 07:02:35 [INFO]: Epoch 180 - training loss: 0.2733, validation loss: 0.1209
2024-05-25 07:02:37 [INFO]: Epoch 181 - training loss: 0.2731, validation loss: 0.1205
2024-05-25 07:02:40 [INFO]: Epoch 182 - training loss: 0.2727, validation loss: 0.1206
2024-05-25 07:02:43 [INFO]: Epoch 183 - training loss: 0.2720, validation loss: 0.1207
2024-05-25 07:02:46 [INFO]: Epoch 184 - training loss: 0.2720, validation loss: 0.1202
2024-05-25 07:02:49 [INFO]: Epoch 185 - training loss: 0.2720, validation loss: 0.1202
2024-05-25 07:02:52 [INFO]: Epoch 186 - training loss: 0.2712, validation loss: 0.1201
2024-05-25 07:02:54 [INFO]: Epoch 187 - training loss: 0.2711, validation loss: 0.1199
2024-05-25 07:02:57 [INFO]: Epoch 188 - training loss: 0.2713, validation loss: 0.1198
2024-05-25 07:03:00 [INFO]: Epoch 189 - training loss: 0.2707, validation loss: 0.1198
2024-05-25 07:03:03 [INFO]: Epoch 190 - training loss: 0.2709, validation loss: 0.1195
2024-05-25 07:03:06 [INFO]: Epoch 191 - training loss: 0.2702, validation loss: 0.1195
2024-05-25 07:03:09 [INFO]: Epoch 192 - training loss: 0.2700, validation loss: 0.1194
2024-05-25 07:03:11 [INFO]: Epoch 193 - training loss: 0.2703, validation loss: 0.1192
2024-05-25 07:03:14 [INFO]: Epoch 194 - training loss: 0.2697, validation loss: 0.1190
2024-05-25 07:03:17 [INFO]: Epoch 195 - training loss: 0.2696, validation loss: 0.1190
2024-05-25 07:03:20 [INFO]: Epoch 196 - training loss: 0.2688, validation loss: 0.1188
2024-05-25 07:03:23 [INFO]: Epoch 197 - training loss: 0.2687, validation loss: 0.1190
2024-05-25 07:03:25 [INFO]: Epoch 198 - training loss: 0.2686, validation loss: 0.1186
2024-05-25 07:03:28 [INFO]: Epoch 199 - training loss: 0.2690, validation loss: 0.1183
2024-05-25 07:03:31 [INFO]: Epoch 200 - training loss: 0.2681, validation loss: 0.1187
2024-05-25 07:03:34 [INFO]: Epoch 201 - training loss: 0.2680, validation loss: 0.1181
2024-05-25 07:03:37 [INFO]: Epoch 202 - training loss: 0.2675, validation loss: 0.1183
2024-05-25 07:03:39 [INFO]: Epoch 203 - training loss: 0.2674, validation loss: 0.1181
2024-05-25 07:03:42 [INFO]: Epoch 204 - training loss: 0.2672, validation loss: 0.1180
2024-05-25 07:03:45 [INFO]: Epoch 205 - training loss: 0.2671, validation loss: 0.1180
2024-05-25 07:03:48 [INFO]: Epoch 206 - training loss: 0.2678, validation loss: 0.1178
2024-05-25 07:03:51 [INFO]: Epoch 207 - training loss: 0.2667, validation loss: 0.1177
2024-05-25 07:03:54 [INFO]: Epoch 208 - training loss: 0.2665, validation loss: 0.1175
2024-05-25 07:03:56 [INFO]: Epoch 209 - training loss: 0.2663, validation loss: 0.1174
2024-05-25 07:03:59 [INFO]: Epoch 210 - training loss: 0.2656, validation loss: 0.1176
2024-05-25 07:04:02 [INFO]: Epoch 211 - training loss: 0.2661, validation loss: 0.1173
2024-05-25 07:04:05 [INFO]: Epoch 212 - training loss: 0.2666, validation loss: 0.1172
2024-05-25 07:04:08 [INFO]: Epoch 213 - training loss: 0.2654, validation loss: 0.1173
2024-05-25 07:04:10 [INFO]: Epoch 214 - training loss: 0.2658, validation loss: 0.1170
2024-05-25 07:04:13 [INFO]: Epoch 215 - training loss: 0.2652, validation loss: 0.1170
2024-05-25 07:04:16 [INFO]: Epoch 216 - training loss: 0.2649, validation loss: 0.1168
2024-05-25 07:04:19 [INFO]: Epoch 217 - training loss: 0.2644, validation loss: 0.1169
2024-05-25 07:04:22 [INFO]: Epoch 218 - training loss: 0.2643, validation loss: 0.1169
2024-05-25 07:04:24 [INFO]: Epoch 219 - training loss: 0.2645, validation loss: 0.1167
2024-05-25 07:04:27 [INFO]: Epoch 220 - training loss: 0.2643, validation loss: 0.1164
2024-05-25 07:04:30 [INFO]: Epoch 221 - training loss: 0.2637, validation loss: 0.1163
2024-05-25 07:04:33 [INFO]: Epoch 222 - training loss: 0.2638, validation loss: 0.1165
2024-05-25 07:04:36 [INFO]: Epoch 223 - training loss: 0.2637, validation loss: 0.1163
2024-05-25 07:04:39 [INFO]: Epoch 224 - training loss: 0.2640, validation loss: 0.1161
2024-05-25 07:04:41 [INFO]: Epoch 225 - training loss: 0.2632, validation loss: 0.1161
2024-05-25 07:04:44 [INFO]: Epoch 226 - training loss: 0.2629, validation loss: 0.1160
2024-05-25 07:04:47 [INFO]: Epoch 227 - training loss: 0.2630, validation loss: 0.1160
2024-05-25 07:04:50 [INFO]: Epoch 228 - training loss: 0.2628, validation loss: 0.1160
2024-05-25 07:04:53 [INFO]: Epoch 229 - training loss: 0.2626, validation loss: 0.1156
2024-05-25 07:04:55 [INFO]: Epoch 230 - training loss: 0.2624, validation loss: 0.1158
2024-05-25 07:04:58 [INFO]: Epoch 231 - training loss: 0.2623, validation loss: 0.1156
2024-05-25 07:05:01 [INFO]: Epoch 232 - training loss: 0.2616, validation loss: 0.1155
2024-05-25 07:05:04 [INFO]: Epoch 233 - training loss: 0.2615, validation loss: 0.1154
2024-05-25 07:05:07 [INFO]: Epoch 234 - training loss: 0.2612, validation loss: 0.1155
2024-05-25 07:05:10 [INFO]: Epoch 235 - training loss: 0.2617, validation loss: 0.1153
2024-05-25 07:05:12 [INFO]: Epoch 236 - training loss: 0.2613, validation loss: 0.1153
2024-05-25 07:05:15 [INFO]: Epoch 237 - training loss: 0.2611, validation loss: 0.1152
2024-05-25 07:05:18 [INFO]: Epoch 238 - training loss: 0.2607, validation loss: 0.1151
2024-05-25 07:05:21 [INFO]: Epoch 239 - training loss: 0.2610, validation loss: 0.1151
2024-05-25 07:05:24 [INFO]: Epoch 240 - training loss: 0.2605, validation loss: 0.1150
2024-05-25 07:05:26 [INFO]: Epoch 241 - training loss: 0.2611, validation loss: 0.1150
2024-05-25 07:05:29 [INFO]: Epoch 242 - training loss: 0.2603, validation loss: 0.1147
2024-05-25 07:05:32 [INFO]: Epoch 243 - training loss: 0.2606, validation loss: 0.1148
2024-05-25 07:05:35 [INFO]: Epoch 244 - training loss: 0.2602, validation loss: 0.1148
2024-05-25 07:05:38 [INFO]: Epoch 245 - training loss: 0.2597, validation loss: 0.1145
2024-05-25 07:05:41 [INFO]: Epoch 246 - training loss: 0.2592, validation loss: 0.1144
2024-05-25 07:05:43 [INFO]: Epoch 247 - training loss: 0.2593, validation loss: 0.1146
2024-05-25 07:05:46 [INFO]: Epoch 248 - training loss: 0.2590, validation loss: 0.1144
2024-05-25 07:05:49 [INFO]: Epoch 249 - training loss: 0.2588, validation loss: 0.1143
2024-05-25 07:05:52 [INFO]: Epoch 250 - training loss: 0.2599, validation loss: 0.1146
2024-05-25 07:05:55 [INFO]: Epoch 251 - training loss: 0.2588, validation loss: 0.1144
2024-05-25 07:05:57 [INFO]: Epoch 252 - training loss: 0.2585, validation loss: 0.1141
2024-05-25 07:06:00 [INFO]: Epoch 253 - training loss: 0.2583, validation loss: 0.1143
2024-05-25 07:06:03 [INFO]: Epoch 254 - training loss: 0.2583, validation loss: 0.1141
2024-05-25 07:06:06 [INFO]: Epoch 255 - training loss: 0.2588, validation loss: 0.1141
2024-05-25 07:06:09 [INFO]: Epoch 256 - training loss: 0.2579, validation loss: 0.1141
2024-05-25 07:06:11 [INFO]: Epoch 257 - training loss: 0.2579, validation loss: 0.1141
2024-05-25 07:06:14 [INFO]: Epoch 258 - training loss: 0.2575, validation loss: 0.1140
2024-05-25 07:06:17 [INFO]: Epoch 259 - training loss: 0.2572, validation loss: 0.1141
2024-05-25 07:06:20 [INFO]: Epoch 260 - training loss: 0.2569, validation loss: 0.1139
2024-05-25 07:06:23 [INFO]: Epoch 261 - training loss: 0.2571, validation loss: 0.1138
2024-05-25 07:06:26 [INFO]: Epoch 262 - training loss: 0.2578, validation loss: 0.1138
2024-05-25 07:06:28 [INFO]: Epoch 263 - training loss: 0.2564, validation loss: 0.1139
2024-05-25 07:06:31 [INFO]: Epoch 264 - training loss: 0.2568, validation loss: 0.1137
2024-05-25 07:06:34 [INFO]: Epoch 265 - training loss: 0.2566, validation loss: 0.1137
2024-05-25 07:06:37 [INFO]: Epoch 266 - training loss: 0.2565, validation loss: 0.1135
2024-05-25 07:06:40 [INFO]: Epoch 267 - training loss: 0.2562, validation loss: 0.1135
2024-05-25 07:06:42 [INFO]: Epoch 268 - training loss: 0.2565, validation loss: 0.1134
2024-05-25 07:06:45 [INFO]: Epoch 269 - training loss: 0.2560, validation loss: 0.1133
2024-05-25 07:06:48 [INFO]: Epoch 270 - training loss: 0.2558, validation loss: 0.1134
2024-05-25 07:06:51 [INFO]: Epoch 271 - training loss: 0.2560, validation loss: 0.1134
2024-05-25 07:06:54 [INFO]: Epoch 272 - training loss: 0.2555, validation loss: 0.1134
2024-05-25 07:06:56 [INFO]: Epoch 273 - training loss: 0.2556, validation loss: 0.1133
2024-05-25 07:06:59 [INFO]: Epoch 274 - training loss: 0.2556, validation loss: 0.1131
2024-05-25 07:07:02 [INFO]: Epoch 275 - training loss: 0.2549, validation loss: 0.1133
2024-05-25 07:07:05 [INFO]: Epoch 276 - training loss: 0.2552, validation loss: 0.1132
2024-05-25 07:07:08 [INFO]: Epoch 277 - training loss: 0.2551, validation loss: 0.1130
2024-05-25 07:07:11 [INFO]: Epoch 278 - training loss: 0.2548, validation loss: 0.1131
2024-05-25 07:07:13 [INFO]: Epoch 279 - training loss: 0.2545, validation loss: 0.1130
2024-05-25 07:07:16 [INFO]: Epoch 280 - training loss: 0.2543, validation loss: 0.1129
2024-05-25 07:07:19 [INFO]: Epoch 281 - training loss: 0.2546, validation loss: 0.1130
2024-05-25 07:07:22 [INFO]: Epoch 282 - training loss: 0.2543, validation loss: 0.1129
2024-05-25 07:07:25 [INFO]: Epoch 283 - training loss: 0.2543, validation loss: 0.1128
2024-05-25 07:07:28 [INFO]: Epoch 284 - training loss: 0.2540, validation loss: 0.1130
2024-05-25 07:07:30 [INFO]: Epoch 285 - training loss: 0.2538, validation loss: 0.1129
2024-05-25 07:07:33 [INFO]: Epoch 286 - training loss: 0.2535, validation loss: 0.1128
2024-05-25 07:07:36 [INFO]: Epoch 287 - training loss: 0.2539, validation loss: 0.1127
2024-05-25 07:07:39 [INFO]: Epoch 288 - training loss: 0.2529, validation loss: 0.1125
2024-05-25 07:07:42 [INFO]: Epoch 289 - training loss: 0.2531, validation loss: 0.1125
2024-05-25 07:07:44 [INFO]: Epoch 290 - training loss: 0.2532, validation loss: 0.1127
2024-05-25 07:07:47 [INFO]: Epoch 291 - training loss: 0.2533, validation loss: 0.1125
2024-05-25 07:07:50 [INFO]: Epoch 292 - training loss: 0.2532, validation loss: 0.1125
2024-05-25 07:07:53 [INFO]: Epoch 293 - training loss: 0.2530, validation loss: 0.1124
2024-05-25 07:07:56 [INFO]: Epoch 294 - training loss: 0.2527, validation loss: 0.1124
2024-05-25 07:07:58 [INFO]: Epoch 295 - training loss: 0.2532, validation loss: 0.1123
2024-05-25 07:08:01 [INFO]: Epoch 296 - training loss: 0.2527, validation loss: 0.1123
2024-05-25 07:08:04 [INFO]: Epoch 297 - training loss: 0.2522, validation loss: 0.1126
2024-05-25 07:08:07 [INFO]: Epoch 298 - training loss: 0.2521, validation loss: 0.1125
2024-05-25 07:08:10 [INFO]: Epoch 299 - training loss: 0.2523, validation loss: 0.1125
2024-05-25 07:08:13 [INFO]: Epoch 300 - training loss: 0.2517, validation loss: 0.1122
2024-05-25 07:08:13 [INFO]: Finished training. The best model is from epoch#300.
2024-05-25 07:08:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/BRITS_air_quality/20240525_T065407/BRITS.pypots
2024-05-25 07:08:13 [INFO]: BRITS on Air-Quality: MAE=0.1534, MSE=0.1513
2024-05-25 07:08:13 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/BRITS_air_quality/imputation.pkl
2024-05-25 07:08:13 [INFO]: Using the given device: cuda:0
2024-05-25 07:08:13 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813
2024-05-25 07:08:13 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/tensorboard
2024-05-25 07:08:13 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 07:08:18 [INFO]: Epoch 001 - training loss: 1.3865, validation loss: 0.8059
2024-05-25 07:08:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch1_loss0.805923581123352.pypots
2024-05-25 07:08:22 [INFO]: Epoch 002 - training loss: 1.0101, validation loss: 0.7475
2024-05-25 07:08:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch2_loss0.7475132316350936.pypots
2024-05-25 07:08:26 [INFO]: Epoch 003 - training loss: 0.9300, validation loss: 0.7186
2024-05-25 07:08:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch3_loss0.7186466366052627.pypots
2024-05-25 07:08:30 [INFO]: Epoch 004 - training loss: 0.8940, validation loss: 0.7035
2024-05-25 07:08:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch4_loss0.7035212546586991.pypots
2024-05-25 07:08:33 [INFO]: Epoch 005 - training loss: 0.8786, validation loss: 0.6922
2024-05-25 07:08:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch5_loss0.6922194063663483.pypots
2024-05-25 07:08:37 [INFO]: Epoch 006 - training loss: 0.8643, validation loss: 0.6847
2024-05-25 07:08:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch6_loss0.6846934258937836.pypots
2024-05-25 07:08:41 [INFO]: Epoch 007 - training loss: 0.8592, validation loss: 0.6783
2024-05-25 07:08:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch7_loss0.6782755106687546.pypots
2024-05-25 07:08:45 [INFO]: Epoch 008 - training loss: 0.8486, validation loss: 0.6747
2024-05-25 07:08:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch8_loss0.6747050911188126.pypots
2024-05-25 07:08:49 [INFO]: Epoch 009 - training loss: 0.8609, validation loss: 0.6709
2024-05-25 07:08:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch9_loss0.6709378182888031.pypots
2024-05-25 07:08:53 [INFO]: Epoch 010 - training loss: 0.8350, validation loss: 0.6667
2024-05-25 07:08:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch10_loss0.6667456865310669.pypots
2024-05-25 07:08:57 [INFO]: Epoch 011 - training loss: 0.8463, validation loss: 0.6648
2024-05-25 07:08:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch11_loss0.664849603176117.pypots
2024-05-25 07:09:00 [INFO]: Epoch 012 - training loss: 0.8252, validation loss: 0.6634
2024-05-25 07:09:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch12_loss0.6634168148040771.pypots
2024-05-25 07:09:04 [INFO]: Epoch 013 - training loss: 0.8201, validation loss: 0.6624
2024-05-25 07:09:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch13_loss0.6624033838510514.pypots
2024-05-25 07:09:08 [INFO]: Epoch 014 - training loss: 0.8313, validation loss: 0.6610
2024-05-25 07:09:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch14_loss0.6610188484191895.pypots
2024-05-25 07:09:12 [INFO]: Epoch 015 - training loss: 0.8138, validation loss: 0.6612
2024-05-25 07:09:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch15_loss0.6611816018819809.pypots
2024-05-25 07:09:16 [INFO]: Epoch 016 - training loss: 0.8144, validation loss: 0.6595
2024-05-25 07:09:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch16_loss0.6595092296600342.pypots
2024-05-25 07:09:20 [INFO]: Epoch 017 - training loss: 0.8043, validation loss: 0.6593
2024-05-25 07:09:20 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch17_loss0.6592706263065338.pypots
2024-05-25 07:09:24 [INFO]: Epoch 018 - training loss: 0.8103, validation loss: 0.6595
2024-05-25 07:09:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch18_loss0.6595336526632309.pypots
2024-05-25 07:09:27 [INFO]: Epoch 019 - training loss: 0.8075, validation loss: 0.6600
2024-05-25 07:09:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch19_loss0.6599796921014786.pypots
2024-05-25 07:09:31 [INFO]: Epoch 020 - training loss: 0.8062, validation loss: 0.6600
2024-05-25 07:09:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch20_loss0.66000294983387.pypots
2024-05-25 07:09:35 [INFO]: Epoch 021 - training loss: 0.8114, validation loss: 0.6605
2024-05-25 07:09:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch21_loss0.6605470955371857.pypots
2024-05-25 07:09:39 [INFO]: Epoch 022 - training loss: 0.7905, validation loss: 0.6574
2024-05-25 07:09:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch22_loss0.6574081540107727.pypots
2024-05-25 07:09:43 [INFO]: Epoch 023 - training loss: 0.7932, validation loss: 0.6567
2024-05-25 07:09:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch23_loss0.656734225153923.pypots
2024-05-25 07:09:47 [INFO]: Epoch 024 - training loss: 0.7929, validation loss: 0.6588
2024-05-25 07:09:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch24_loss0.6588431835174561.pypots
2024-05-25 07:09:51 [INFO]: Epoch 025 - training loss: 0.7847, validation loss: 0.6594
2024-05-25 07:09:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch25_loss0.6593585431575775.pypots
2024-05-25 07:09:55 [INFO]: Epoch 026 - training loss: 0.7733, validation loss: 0.6585
2024-05-25 07:09:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch26_loss0.6585382610559464.pypots
2024-05-25 07:09:58 [INFO]: Epoch 027 - training loss: 0.7848, validation loss: 0.6586
2024-05-25 07:09:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch27_loss0.6585986346006394.pypots
2024-05-25 07:10:02 [INFO]: Epoch 028 - training loss: 0.7759, validation loss: 0.6608
2024-05-25 07:10:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch28_loss0.6608494311571121.pypots
2024-05-25 07:10:06 [INFO]: Epoch 029 - training loss: 0.7769, validation loss: 0.6592
2024-05-25 07:10:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch29_loss0.6592224925756455.pypots
2024-05-25 07:10:10 [INFO]: Epoch 030 - training loss: 0.7910, validation loss: 0.6606
2024-05-25 07:10:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch30_loss0.6606439888477326.pypots
2024-05-25 07:10:14 [INFO]: Epoch 031 - training loss: 0.7671, validation loss: 0.6573
2024-05-25 07:10:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch31_loss0.6573343575000763.pypots
2024-05-25 07:10:18 [INFO]: Epoch 032 - training loss: 0.7723, validation loss: 0.6617
2024-05-25 07:10:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch32_loss0.6617053300142288.pypots
2024-05-25 07:10:22 [INFO]: Epoch 033 - training loss: 0.7690, validation loss: 0.6573
2024-05-25 07:10:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN_epoch33_loss0.6572799772024155.pypots
2024-05-25 07:10:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:10:22 [INFO]: Finished training. The best model is from epoch#23.
2024-05-25 07:10:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T070813/MRNN.pypots
2024-05-25 07:10:22 [INFO]: MRNN on Air-Quality: MAE=0.5208, MSE=0.6559
2024-05-25 07:10:22 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/MRNN_air_quality/imputation.pkl
2024-05-25 07:10:22 [INFO]: Using the given device: cpu
2024-05-25 07:10:22 [INFO]: LOCF on Air-Quality: MAE=0.2220, MSE=0.3375
2024-05-25 07:10:22 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_air_quality".
2024-05-25 07:10:22 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/LOCF_air_quality/imputation.pkl
2024-05-25 07:10:22 [INFO]: Median on Air-Quality: MAE=0.6640, MSE=1.0523
2024-05-25 07:10:22 [INFO]: Successfully created the given path "saved_results/round_3/Median_air_quality".
2024-05-25 07:10:22 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Median_air_quality/imputation.pkl
2024-05-25 07:10:22 [INFO]: Mean on Air-Quality: MAE=0.6951, MSE=0.9927
2024-05-25 07:10:22 [INFO]: Successfully created the given path "saved_results/round_3/Mean_air_quality".
2024-05-25 07:10:22 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Mean_air_quality/imputation.pkl
2024-05-25 07:10:22 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-25 07:10:23 [INFO]: Using the given device: cuda:0
2024-05-25 07:10:23 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/SAITS_air_quality/20240525_T071023
2024-05-25 07:10:23 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/SAITS_air_quality/20240525_T071023/tensorboard
2024-05-25 07:10:23 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 07:10:24 [INFO]: Epoch 001 - training loss: 1.0574, validation loss: 0.4951
2024-05-25 07:10:25 [INFO]: Epoch 002 - training loss: 0.7532, validation loss: 0.3826
2024-05-25 07:10:25 [INFO]: Epoch 003 - training loss: 0.6472, validation loss: 0.3054
2024-05-25 07:10:26 [INFO]: Epoch 004 - training loss: 0.5717, validation loss: 0.2663
2024-05-25 07:10:26 [INFO]: Epoch 005 - training loss: 0.5168, validation loss: 0.2422
2024-05-25 07:10:27 [INFO]: Epoch 006 - training loss: 0.4792, validation loss: 0.2295
2024-05-25 07:10:28 [INFO]: Epoch 007 - training loss: 0.4550, validation loss: 0.2204
2024-05-25 07:10:28 [INFO]: Epoch 008 - training loss: 0.4359, validation loss: 0.2128
2024-05-25 07:10:29 [INFO]: Epoch 009 - training loss: 0.4213, validation loss: 0.2077
2024-05-25 07:10:29 [INFO]: Epoch 010 - training loss: 0.4093, validation loss: 0.2015
2024-05-25 07:10:30 [INFO]: Epoch 011 - training loss: 0.4005, validation loss: 0.1965
2024-05-25 07:10:31 [INFO]: Epoch 012 - training loss: 0.3939, validation loss: 0.1942
2024-05-25 07:10:31 [INFO]: Epoch 013 - training loss: 0.3834, validation loss: 0.1897
2024-05-25 07:10:32 [INFO]: Epoch 014 - training loss: 0.3763, validation loss: 0.1890
2024-05-25 07:10:32 [INFO]: Epoch 015 - training loss: 0.3731, validation loss: 0.1848
2024-05-25 07:10:33 [INFO]: Epoch 016 - training loss: 0.3657, validation loss: 0.1813
2024-05-25 07:10:34 [INFO]: Epoch 017 - training loss: 0.3623, validation loss: 0.1812
2024-05-25 07:10:34 [INFO]: Epoch 018 - training loss: 0.3569, validation loss: 0.1769
2024-05-25 07:10:35 [INFO]: Epoch 019 - training loss: 0.3521, validation loss: 0.1750
2024-05-25 07:10:35 [INFO]: Epoch 020 - training loss: 0.3485, validation loss: 0.1739
2024-05-25 07:10:36 [INFO]: Epoch 021 - training loss: 0.3431, validation loss: 0.1715
2024-05-25 07:10:37 [INFO]: Epoch 022 - training loss: 0.3421, validation loss: 0.1701
2024-05-25 07:10:37 [INFO]: Epoch 023 - training loss: 0.3380, validation loss: 0.1675
2024-05-25 07:10:38 [INFO]: Epoch 024 - training loss: 0.3337, validation loss: 0.1676
2024-05-25 07:10:38 [INFO]: Epoch 025 - training loss: 0.3326, validation loss: 0.1657
2024-05-25 07:10:39 [INFO]: Epoch 026 - training loss: 0.3288, validation loss: 0.1641
2024-05-25 07:10:40 [INFO]: Epoch 027 - training loss: 0.3253, validation loss: 0.1625
2024-05-25 07:10:40 [INFO]: Epoch 028 - training loss: 0.3228, validation loss: 0.1612
2024-05-25 07:10:41 [INFO]: Epoch 029 - training loss: 0.3226, validation loss: 0.1612
2024-05-25 07:10:42 [INFO]: Epoch 030 - training loss: 0.3187, validation loss: 0.1598
2024-05-25 07:10:42 [INFO]: Epoch 031 - training loss: 0.3174, validation loss: 0.1576
2024-05-25 07:10:43 [INFO]: Epoch 032 - training loss: 0.3150, validation loss: 0.1570
2024-05-25 07:10:43 [INFO]: Epoch 033 - training loss: 0.3123, validation loss: 0.1572
2024-05-25 07:10:44 [INFO]: Epoch 034 - training loss: 0.3105, validation loss: 0.1540
2024-05-25 07:10:45 [INFO]: Epoch 035 - training loss: 0.3077, validation loss: 0.1542
2024-05-25 07:10:45 [INFO]: Epoch 036 - training loss: 0.3061, validation loss: 0.1526
2024-05-25 07:10:46 [INFO]: Epoch 037 - training loss: 0.3042, validation loss: 0.1527
2024-05-25 07:10:46 [INFO]: Epoch 038 - training loss: 0.3029, validation loss: 0.1511
2024-05-25 07:10:47 [INFO]: Epoch 039 - training loss: 0.3029, validation loss: 0.1505
2024-05-25 07:10:48 [INFO]: Epoch 040 - training loss: 0.2993, validation loss: 0.1490
2024-05-25 07:10:48 [INFO]: Epoch 041 - training loss: 0.2975, validation loss: 0.1484
2024-05-25 07:10:49 [INFO]: Epoch 042 - training loss: 0.2955, validation loss: 0.1483
2024-05-25 07:10:49 [INFO]: Epoch 043 - training loss: 0.2942, validation loss: 0.1463
2024-05-25 07:10:50 [INFO]: Epoch 044 - training loss: 0.2936, validation loss: 0.1457
2024-05-25 07:10:51 [INFO]: Epoch 045 - training loss: 0.2913, validation loss: 0.1449
2024-05-25 07:10:51 [INFO]: Epoch 046 - training loss: 0.2902, validation loss: 0.1439
2024-05-25 07:10:52 [INFO]: Epoch 047 - training loss: 0.2878, validation loss: 0.1432
2024-05-25 07:10:52 [INFO]: Epoch 048 - training loss: 0.2874, validation loss: 0.1433
2024-05-25 07:10:53 [INFO]: Epoch 049 - training loss: 0.2858, validation loss: 0.1419
2024-05-25 07:10:54 [INFO]: Epoch 050 - training loss: 0.2842, validation loss: 0.1406
2024-05-25 07:10:54 [INFO]: Epoch 051 - training loss: 0.2824, validation loss: 0.1413
2024-05-25 07:10:55 [INFO]: Epoch 052 - training loss: 0.2829, validation loss: 0.1400
2024-05-25 07:10:55 [INFO]: Epoch 053 - training loss: 0.2796, validation loss: 0.1396
2024-05-25 07:10:56 [INFO]: Epoch 054 - training loss: 0.2782, validation loss: 0.1388
2024-05-25 07:10:57 [INFO]: Epoch 055 - training loss: 0.2763, validation loss: 0.1391
2024-05-25 07:10:57 [INFO]: Epoch 056 - training loss: 0.2749, validation loss: 0.1389
2024-05-25 07:10:58 [INFO]: Epoch 057 - training loss: 0.2729, validation loss: 0.1379
2024-05-25 07:10:58 [INFO]: Epoch 058 - training loss: 0.2719, validation loss: 0.1373
2024-05-25 07:10:59 [INFO]: Epoch 059 - training loss: 0.2710, validation loss: 0.1373
2024-05-25 07:11:00 [INFO]: Epoch 060 - training loss: 0.2702, validation loss: 0.1369
2024-05-25 07:11:00 [INFO]: Epoch 061 - training loss: 0.2686, validation loss: 0.1361
2024-05-25 07:11:01 [INFO]: Epoch 062 - training loss: 0.2672, validation loss: 0.1358
2024-05-25 07:11:02 [INFO]: Epoch 063 - training loss: 0.2651, validation loss: 0.1345
2024-05-25 07:11:02 [INFO]: Epoch 064 - training loss: 0.2640, validation loss: 0.1345
2024-05-25 07:11:03 [INFO]: Epoch 065 - training loss: 0.2637, validation loss: 0.1348
2024-05-25 07:11:03 [INFO]: Epoch 066 - training loss: 0.2631, validation loss: 0.1338
2024-05-25 07:11:04 [INFO]: Epoch 067 - training loss: 0.2613, validation loss: 0.1329
2024-05-25 07:11:05 [INFO]: Epoch 068 - training loss: 0.2599, validation loss: 0.1317
2024-05-25 07:11:05 [INFO]: Epoch 069 - training loss: 0.2595, validation loss: 0.1325
2024-05-25 07:11:06 [INFO]: Epoch 070 - training loss: 0.2589, validation loss: 0.1314
2024-05-25 07:11:06 [INFO]: Epoch 071 - training loss: 0.2569, validation loss: 0.1314
2024-05-25 07:11:07 [INFO]: Epoch 072 - training loss: 0.2558, validation loss: 0.1318
2024-05-25 07:11:08 [INFO]: Epoch 073 - training loss: 0.2548, validation loss: 0.1319
2024-05-25 07:11:08 [INFO]: Epoch 074 - training loss: 0.2532, validation loss: 0.1309
2024-05-25 07:11:09 [INFO]: Epoch 075 - training loss: 0.2541, validation loss: 0.1305
2024-05-25 07:11:09 [INFO]: Epoch 076 - training loss: 0.2526, validation loss: 0.1305
2024-05-25 07:11:10 [INFO]: Epoch 077 - training loss: 0.2511, validation loss: 0.1294
2024-05-25 07:11:11 [INFO]: Epoch 078 - training loss: 0.2500, validation loss: 0.1289
2024-05-25 07:11:11 [INFO]: Epoch 079 - training loss: 0.2492, validation loss: 0.1282
2024-05-25 07:11:12 [INFO]: Epoch 080 - training loss: 0.2482, validation loss: 0.1284
2024-05-25 07:11:12 [INFO]: Epoch 081 - training loss: 0.2467, validation loss: 0.1295
2024-05-25 07:11:13 [INFO]: Epoch 082 - training loss: 0.2468, validation loss: 0.1280
2024-05-25 07:11:14 [INFO]: Epoch 083 - training loss: 0.2463, validation loss: 0.1278
2024-05-25 07:11:14 [INFO]: Epoch 084 - training loss: 0.2443, validation loss: 0.1281
2024-05-25 07:11:15 [INFO]: Epoch 085 - training loss: 0.2456, validation loss: 0.1277
2024-05-25 07:11:15 [INFO]: Epoch 086 - training loss: 0.2441, validation loss: 0.1277
2024-05-25 07:11:16 [INFO]: Epoch 087 - training loss: 0.2436, validation loss: 0.1270
2024-05-25 07:11:17 [INFO]: Epoch 088 - training loss: 0.2422, validation loss: 0.1276
2024-05-25 07:11:17 [INFO]: Epoch 089 - training loss: 0.2411, validation loss: 0.1263
2024-05-25 07:11:18 [INFO]: Epoch 090 - training loss: 0.2404, validation loss: 0.1256
2024-05-25 07:11:18 [INFO]: Epoch 091 - training loss: 0.2400, validation loss: 0.1258
2024-05-25 07:11:19 [INFO]: Epoch 092 - training loss: 0.2389, validation loss: 0.1261
2024-05-25 07:11:20 [INFO]: Epoch 093 - training loss: 0.2384, validation loss: 0.1250
2024-05-25 07:11:20 [INFO]: Epoch 094 - training loss: 0.2384, validation loss: 0.1266
2024-05-25 07:11:21 [INFO]: Epoch 095 - training loss: 0.2390, validation loss: 0.1260
2024-05-25 07:11:21 [INFO]: Epoch 096 - training loss: 0.2378, validation loss: 0.1261
2024-05-25 07:11:22 [INFO]: Epoch 097 - training loss: 0.2386, validation loss: 0.1253
2024-05-25 07:11:23 [INFO]: Epoch 098 - training loss: 0.2358, validation loss: 0.1246
2024-05-25 07:11:23 [INFO]: Epoch 099 - training loss: 0.2351, validation loss: 0.1233
2024-05-25 07:11:24 [INFO]: Epoch 100 - training loss: 0.2335, validation loss: 0.1240
2024-05-25 07:11:24 [INFO]: Epoch 101 - training loss: 0.2325, validation loss: 0.1246
2024-05-25 07:11:25 [INFO]: Epoch 102 - training loss: 0.2341, validation loss: 0.1254
2024-05-25 07:11:26 [INFO]: Epoch 103 - training loss: 0.2326, validation loss: 0.1241
2024-05-25 07:11:26 [INFO]: Epoch 104 - training loss: 0.2315, validation loss: 0.1243
2024-05-25 07:11:27 [INFO]: Epoch 105 - training loss: 0.2310, validation loss: 0.1227
2024-05-25 07:11:28 [INFO]: Epoch 106 - training loss: 0.2305, validation loss: 0.1230
2024-05-25 07:11:28 [INFO]: Epoch 107 - training loss: 0.2291, validation loss: 0.1237
2024-05-25 07:11:29 [INFO]: Epoch 108 - training loss: 0.2286, validation loss: 0.1229
2024-05-25 07:11:29 [INFO]: Epoch 109 - training loss: 0.2287, validation loss: 0.1217
2024-05-25 07:11:30 [INFO]: Epoch 110 - training loss: 0.2281, validation loss: 0.1214
2024-05-25 07:11:31 [INFO]: Epoch 111 - training loss: 0.2275, validation loss: 0.1225
2024-05-25 07:11:31 [INFO]: Epoch 112 - training loss: 0.2266, validation loss: 0.1224
2024-05-25 07:11:32 [INFO]: Epoch 113 - training loss: 0.2260, validation loss: 0.1220
2024-05-25 07:11:32 [INFO]: Epoch 114 - training loss: 0.2248, validation loss: 0.1215
2024-05-25 07:11:33 [INFO]: Epoch 115 - training loss: 0.2248, validation loss: 0.1206
2024-05-25 07:11:34 [INFO]: Epoch 116 - training loss: 0.2241, validation loss: 0.1218
2024-05-25 07:11:34 [INFO]: Epoch 117 - training loss: 0.2233, validation loss: 0.1212
2024-05-25 07:11:35 [INFO]: Epoch 118 - training loss: 0.2234, validation loss: 0.1206
2024-05-25 07:11:35 [INFO]: Epoch 119 - training loss: 0.2239, validation loss: 0.1208
2024-05-25 07:11:36 [INFO]: Epoch 120 - training loss: 0.2222, validation loss: 0.1210
2024-05-25 07:11:37 [INFO]: Epoch 121 - training loss: 0.2210, validation loss: 0.1206
2024-05-25 07:11:37 [INFO]: Epoch 122 - training loss: 0.2199, validation loss: 0.1198
2024-05-25 07:11:38 [INFO]: Epoch 123 - training loss: 0.2204, validation loss: 0.1204
2024-05-25 07:11:38 [INFO]: Epoch 124 - training loss: 0.2195, validation loss: 0.1199
2024-05-25 07:11:39 [INFO]: Epoch 125 - training loss: 0.2193, validation loss: 0.1197
2024-05-25 07:11:40 [INFO]: Epoch 126 - training loss: 0.2201, validation loss: 0.1190
2024-05-25 07:11:40 [INFO]: Epoch 127 - training loss: 0.2191, validation loss: 0.1202
2024-05-25 07:11:41 [INFO]: Epoch 128 - training loss: 0.2185, validation loss: 0.1197
2024-05-25 07:11:41 [INFO]: Epoch 129 - training loss: 0.2176, validation loss: 0.1184
2024-05-25 07:11:42 [INFO]: Epoch 130 - training loss: 0.2163, validation loss: 0.1188
2024-05-25 07:11:43 [INFO]: Epoch 131 - training loss: 0.2170, validation loss: 0.1198
2024-05-25 07:11:43 [INFO]: Epoch 132 - training loss: 0.2197, validation loss: 0.1183
2024-05-25 07:11:44 [INFO]: Epoch 133 - training loss: 0.2178, validation loss: 0.1189
2024-05-25 07:11:44 [INFO]: Epoch 134 - training loss: 0.2161, validation loss: 0.1189
2024-05-25 07:11:45 [INFO]: Epoch 135 - training loss: 0.2156, validation loss: 0.1183
2024-05-25 07:11:46 [INFO]: Epoch 136 - training loss: 0.2148, validation loss: 0.1176
2024-05-25 07:11:46 [INFO]: Epoch 137 - training loss: 0.2139, validation loss: 0.1179
2024-05-25 07:11:47 [INFO]: Epoch 138 - training loss: 0.2132, validation loss: 0.1189
2024-05-25 07:11:47 [INFO]: Epoch 139 - training loss: 0.2125, validation loss: 0.1178
2024-05-25 07:11:48 [INFO]: Epoch 140 - training loss: 0.2121, validation loss: 0.1180
2024-05-25 07:11:49 [INFO]: Epoch 141 - training loss: 0.2117, validation loss: 0.1181
2024-05-25 07:11:49 [INFO]: Epoch 142 - training loss: 0.2148, validation loss: 0.1190
2024-05-25 07:11:50 [INFO]: Epoch 143 - training loss: 0.2138, validation loss: 0.1179
2024-05-25 07:11:50 [INFO]: Epoch 144 - training loss: 0.2115, validation loss: 0.1176
2024-05-25 07:11:51 [INFO]: Epoch 145 - training loss: 0.2103, validation loss: 0.1174
2024-05-25 07:11:52 [INFO]: Epoch 146 - training loss: 0.2093, validation loss: 0.1166
2024-05-25 07:11:52 [INFO]: Epoch 147 - training loss: 0.2092, validation loss: 0.1168
2024-05-25 07:11:53 [INFO]: Epoch 148 - training loss: 0.2090, validation loss: 0.1162
2024-05-25 07:11:53 [INFO]: Epoch 149 - training loss: 0.2107, validation loss: 0.1173
2024-05-25 07:11:54 [INFO]: Epoch 150 - training loss: 0.2094, validation loss: 0.1168
2024-05-25 07:11:55 [INFO]: Epoch 151 - training loss: 0.2085, validation loss: 0.1159
2024-05-25 07:11:55 [INFO]: Epoch 152 - training loss: 0.2081, validation loss: 0.1165
2024-05-25 07:11:56 [INFO]: Epoch 153 - training loss: 0.2070, validation loss: 0.1149
2024-05-25 07:11:57 [INFO]: Epoch 154 - training loss: 0.2080, validation loss: 0.1173
2024-05-25 07:11:57 [INFO]: Epoch 155 - training loss: 0.2074, validation loss: 0.1171
2024-05-25 07:11:58 [INFO]: Epoch 156 - training loss: 0.2073, validation loss: 0.1172
2024-05-25 07:11:58 [INFO]: Epoch 157 - training loss: 0.2056, validation loss: 0.1156
2024-05-25 07:11:59 [INFO]: Epoch 158 - training loss: 0.2044, validation loss: 0.1151
2024-05-25 07:12:00 [INFO]: Epoch 159 - training loss: 0.2034, validation loss: 0.1159
2024-05-25 07:12:00 [INFO]: Epoch 160 - training loss: 0.2044, validation loss: 0.1149
2024-05-25 07:12:01 [INFO]: Epoch 161 - training loss: 0.2032, validation loss: 0.1151
2024-05-25 07:12:01 [INFO]: Epoch 162 - training loss: 0.2028, validation loss: 0.1147
2024-05-25 07:12:02 [INFO]: Epoch 163 - training loss: 0.2027, validation loss: 0.1152
2024-05-25 07:12:03 [INFO]: Epoch 164 - training loss: 0.2035, validation loss: 0.1159
2024-05-25 07:12:03 [INFO]: Epoch 165 - training loss: 0.2033, validation loss: 0.1145
2024-05-25 07:12:04 [INFO]: Epoch 166 - training loss: 0.2068, validation loss: 0.1172
2024-05-25 07:12:04 [INFO]: Epoch 167 - training loss: 0.2064, validation loss: 0.1147
2024-05-25 07:12:05 [INFO]: Epoch 168 - training loss: 0.2030, validation loss: 0.1146
2024-05-25 07:12:06 [INFO]: Epoch 169 - training loss: 0.2009, validation loss: 0.1151
2024-05-25 07:12:06 [INFO]: Epoch 170 - training loss: 0.2002, validation loss: 0.1148
2024-05-25 07:12:07 [INFO]: Epoch 171 - training loss: 0.1994, validation loss: 0.1137
2024-05-25 07:12:07 [INFO]: Epoch 172 - training loss: 0.1995, validation loss: 0.1152
2024-05-25 07:12:08 [INFO]: Epoch 173 - training loss: 0.1996, validation loss: 0.1144
2024-05-25 07:12:09 [INFO]: Epoch 174 - training loss: 0.2001, validation loss: 0.1148
2024-05-25 07:12:09 [INFO]: Epoch 175 - training loss: 0.1993, validation loss: 0.1141
2024-05-25 07:12:10 [INFO]: Epoch 176 - training loss: 0.1980, validation loss: 0.1139
2024-05-25 07:12:10 [INFO]: Epoch 177 - training loss: 0.1972, validation loss: 0.1139
2024-05-25 07:12:11 [INFO]: Epoch 178 - training loss: 0.1974, validation loss: 0.1133
2024-05-25 07:12:12 [INFO]: Epoch 179 - training loss: 0.1973, validation loss: 0.1144
2024-05-25 07:12:12 [INFO]: Epoch 180 - training loss: 0.1967, validation loss: 0.1130
2024-05-25 07:12:13 [INFO]: Epoch 181 - training loss: 0.1964, validation loss: 0.1137
2024-05-25 07:12:13 [INFO]: Epoch 182 - training loss: 0.1959, validation loss: 0.1142
2024-05-25 07:12:14 [INFO]: Epoch 183 - training loss: 0.1975, validation loss: 0.1148
2024-05-25 07:12:15 [INFO]: Epoch 184 - training loss: 0.1977, validation loss: 0.1135
2024-05-25 07:12:15 [INFO]: Epoch 185 - training loss: 0.1981, validation loss: 0.1136
2024-05-25 07:12:16 [INFO]: Epoch 186 - training loss: 0.1971, validation loss: 0.1135
2024-05-25 07:12:16 [INFO]: Epoch 187 - training loss: 0.1966, validation loss: 0.1140
2024-05-25 07:12:17 [INFO]: Epoch 188 - training loss: 0.1952, validation loss: 0.1129
2024-05-25 07:12:18 [INFO]: Epoch 189 - training loss: 0.1948, validation loss: 0.1135
2024-05-25 07:12:18 [INFO]: Epoch 190 - training loss: 0.1942, validation loss: 0.1140
2024-05-25 07:12:19 [INFO]: Epoch 191 - training loss: 0.1929, validation loss: 0.1130
2024-05-25 07:12:19 [INFO]: Epoch 192 - training loss: 0.1928, validation loss: 0.1135
2024-05-25 07:12:20 [INFO]: Epoch 193 - training loss: 0.1927, validation loss: 0.1129
2024-05-25 07:12:21 [INFO]: Epoch 194 - training loss: 0.1915, validation loss: 0.1130
2024-05-25 07:12:21 [INFO]: Epoch 195 - training loss: 0.1909, validation loss: 0.1131
2024-05-25 07:12:22 [INFO]: Epoch 196 - training loss: 0.1910, validation loss: 0.1136
2024-05-25 07:12:22 [INFO]: Epoch 197 - training loss: 0.1915, validation loss: 0.1142
2024-05-25 07:12:23 [INFO]: Epoch 198 - training loss: 0.1923, validation loss: 0.1156
2024-05-25 07:12:24 [INFO]: Epoch 199 - training loss: 0.1916, validation loss: 0.1130
2024-05-25 07:12:24 [INFO]: Epoch 200 - training loss: 0.1911, validation loss: 0.1125
2024-05-25 07:12:25 [INFO]: Epoch 201 - training loss: 0.1925, validation loss: 0.1141
2024-05-25 07:12:26 [INFO]: Epoch 202 - training loss: 0.1905, validation loss: 0.1128
2024-05-25 07:12:26 [INFO]: Epoch 203 - training loss: 0.1904, validation loss: 0.1124
2024-05-25 07:12:27 [INFO]: Epoch 204 - training loss: 0.1890, validation loss: 0.1131
2024-05-25 07:12:27 [INFO]: Epoch 205 - training loss: 0.1890, validation loss: 0.1135
2024-05-25 07:12:28 [INFO]: Epoch 206 - training loss: 0.1889, validation loss: 0.1137
2024-05-25 07:12:29 [INFO]: Epoch 207 - training loss: 0.1881, validation loss: 0.1124
2024-05-25 07:12:29 [INFO]: Epoch 208 - training loss: 0.1881, validation loss: 0.1124
2024-05-25 07:12:30 [INFO]: Epoch 209 - training loss: 0.1886, validation loss: 0.1128
2024-05-25 07:12:30 [INFO]: Epoch 210 - training loss: 0.1875, validation loss: 0.1119
2024-05-25 07:12:31 [INFO]: Epoch 211 - training loss: 0.1871, validation loss: 0.1123
2024-05-25 07:12:32 [INFO]: Epoch 212 - training loss: 0.1866, validation loss: 0.1138
2024-05-25 07:12:32 [INFO]: Epoch 213 - training loss: 0.1871, validation loss: 0.1129
2024-05-25 07:12:33 [INFO]: Epoch 214 - training loss: 0.1867, validation loss: 0.1133
2024-05-25 07:12:33 [INFO]: Epoch 215 - training loss: 0.1860, validation loss: 0.1118
2024-05-25 07:12:34 [INFO]: Epoch 216 - training loss: 0.1856, validation loss: 0.1120
2024-05-25 07:12:35 [INFO]: Epoch 217 - training loss: 0.1861, validation loss: 0.1133
2024-05-25 07:12:35 [INFO]: Epoch 218 - training loss: 0.1861, validation loss: 0.1129
2024-05-25 07:12:36 [INFO]: Epoch 219 - training loss: 0.1851, validation loss: 0.1129
2024-05-25 07:12:36 [INFO]: Epoch 220 - training loss: 0.1845, validation loss: 0.1125
2024-05-25 07:12:37 [INFO]: Epoch 221 - training loss: 0.1837, validation loss: 0.1121
2024-05-25 07:12:38 [INFO]: Epoch 222 - training loss: 0.1843, validation loss: 0.1118
2024-05-25 07:12:38 [INFO]: Epoch 223 - training loss: 0.1835, validation loss: 0.1120
2024-05-25 07:12:39 [INFO]: Epoch 224 - training loss: 0.1841, validation loss: 0.1125
2024-05-25 07:12:39 [INFO]: Epoch 225 - training loss: 0.1840, validation loss: 0.1120
2024-05-25 07:12:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:12:39 [INFO]: Finished training. The best model is from epoch#215.
2024-05-25 07:12:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/SAITS_air_quality/20240525_T071023/SAITS.pypots
2024-05-25 07:12:40 [INFO]: SAITS on Air-Quality: MAE=0.1611, MSE=0.1555
2024-05-25 07:12:40 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/SAITS_air_quality/imputation.pkl
2024-05-25 07:12:40 [INFO]: Using the given device: cuda:0
2024-05-25 07:12:40 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/Transformer_air_quality/20240525_T071240
2024-05-25 07:12:40 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/Transformer_air_quality/20240525_T071240/tensorboard
2024-05-25 07:12:40 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 07:12:40 [INFO]: Epoch 001 - training loss: 0.9239, validation loss: 0.4611
2024-05-25 07:12:40 [INFO]: Epoch 002 - training loss: 0.5763, validation loss: 0.3453
2024-05-25 07:12:40 [INFO]: Epoch 003 - training loss: 0.4860, validation loss: 0.2755
2024-05-25 07:12:41 [INFO]: Epoch 004 - training loss: 0.4373, validation loss: 0.2530
2024-05-25 07:12:41 [INFO]: Epoch 005 - training loss: 0.4097, validation loss: 0.2372
2024-05-25 07:12:41 [INFO]: Epoch 006 - training loss: 0.3959, validation loss: 0.2290
2024-05-25 07:12:41 [INFO]: Epoch 007 - training loss: 0.3742, validation loss: 0.2195
2024-05-25 07:12:42 [INFO]: Epoch 008 - training loss: 0.3628, validation loss: 0.2151
2024-05-25 07:12:42 [INFO]: Epoch 009 - training loss: 0.3520, validation loss: 0.2076
2024-05-25 07:12:42 [INFO]: Epoch 010 - training loss: 0.3458, validation loss: 0.2043
2024-05-25 07:12:43 [INFO]: Epoch 011 - training loss: 0.3376, validation loss: 0.2006
2024-05-25 07:12:43 [INFO]: Epoch 012 - training loss: 0.3327, validation loss: 0.1978
2024-05-25 07:12:43 [INFO]: Epoch 013 - training loss: 0.3271, validation loss: 0.1947
2024-05-25 07:12:43 [INFO]: Epoch 014 - training loss: 0.3202, validation loss: 0.1912
2024-05-25 07:12:44 [INFO]: Epoch 015 - training loss: 0.3173, validation loss: 0.1871
2024-05-25 07:12:44 [INFO]: Epoch 016 - training loss: 0.3142, validation loss: 0.1839
2024-05-25 07:12:44 [INFO]: Epoch 017 - training loss: 0.3081, validation loss: 0.1822
2024-05-25 07:12:44 [INFO]: Epoch 018 - training loss: 0.3055, validation loss: 0.1778
2024-05-25 07:12:45 [INFO]: Epoch 019 - training loss: 0.3034, validation loss: 0.1769
2024-05-25 07:12:45 [INFO]: Epoch 020 - training loss: 0.3002, validation loss: 0.1758
2024-05-25 07:12:45 [INFO]: Epoch 021 - training loss: 0.3015, validation loss: 0.1725
2024-05-25 07:12:45 [INFO]: Epoch 022 - training loss: 0.2952, validation loss: 0.1728
2024-05-25 07:12:46 [INFO]: Epoch 023 - training loss: 0.2909, validation loss: 0.1711
2024-05-25 07:12:46 [INFO]: Epoch 024 - training loss: 0.2874, validation loss: 0.1700
2024-05-25 07:12:46 [INFO]: Epoch 025 - training loss: 0.2848, validation loss: 0.1672
2024-05-25 07:12:46 [INFO]: Epoch 026 - training loss: 0.2840, validation loss: 0.1683
2024-05-25 07:12:47 [INFO]: Epoch 027 - training loss: 0.2812, validation loss: 0.1664
2024-05-25 07:12:47 [INFO]: Epoch 028 - training loss: 0.2794, validation loss: 0.1679
2024-05-25 07:12:47 [INFO]: Epoch 029 - training loss: 0.2766, validation loss: 0.1664
2024-05-25 07:12:47 [INFO]: Epoch 030 - training loss: 0.2763, validation loss: 0.1639
2024-05-25 07:12:48 [INFO]: Epoch 031 - training loss: 0.2749, validation loss: 0.1659
2024-05-25 07:12:48 [INFO]: Epoch 032 - training loss: 0.2740, validation loss: 0.1632
2024-05-25 07:12:48 [INFO]: Epoch 033 - training loss: 0.2689, validation loss: 0.1628
2024-05-25 07:12:48 [INFO]: Epoch 034 - training loss: 0.2669, validation loss: 0.1612
2024-05-25 07:12:49 [INFO]: Epoch 035 - training loss: 0.2694, validation loss: 0.1682
2024-05-25 07:12:49 [INFO]: Epoch 036 - training loss: 0.2678, validation loss: 0.1611
2024-05-25 07:12:49 [INFO]: Epoch 037 - training loss: 0.2637, validation loss: 0.1622
2024-05-25 07:12:49 [INFO]: Epoch 038 - training loss: 0.2618, validation loss: 0.1619
2024-05-25 07:12:50 [INFO]: Epoch 039 - training loss: 0.2602, validation loss: 0.1594
2024-05-25 07:12:50 [INFO]: Epoch 040 - training loss: 0.2620, validation loss: 0.1604
2024-05-25 07:12:50 [INFO]: Epoch 041 - training loss: 0.2568, validation loss: 0.1587
2024-05-25 07:12:50 [INFO]: Epoch 042 - training loss: 0.2550, validation loss: 0.1591
2024-05-25 07:12:51 [INFO]: Epoch 043 - training loss: 0.2549, validation loss: 0.1591
2024-05-25 07:12:51 [INFO]: Epoch 044 - training loss: 0.2532, validation loss: 0.1551
2024-05-25 07:12:51 [INFO]: Epoch 045 - training loss: 0.2519, validation loss: 0.1567
2024-05-25 07:12:51 [INFO]: Epoch 046 - training loss: 0.2502, validation loss: 0.1575
2024-05-25 07:12:52 [INFO]: Epoch 047 - training loss: 0.2511, validation loss: 0.1569
2024-05-25 07:12:52 [INFO]: Epoch 048 - training loss: 0.2478, validation loss: 0.1568
2024-05-25 07:12:52 [INFO]: Epoch 049 - training loss: 0.2502, validation loss: 0.1554
2024-05-25 07:12:52 [INFO]: Epoch 050 - training loss: 0.2468, validation loss: 0.1567
2024-05-25 07:12:53 [INFO]: Epoch 051 - training loss: 0.2424, validation loss: 0.1548
2024-05-25 07:12:53 [INFO]: Epoch 052 - training loss: 0.2444, validation loss: 0.1552
2024-05-25 07:12:53 [INFO]: Epoch 053 - training loss: 0.2432, validation loss: 0.1517
2024-05-25 07:12:53 [INFO]: Epoch 054 - training loss: 0.2399, validation loss: 0.1539
2024-05-25 07:12:54 [INFO]: Epoch 055 - training loss: 0.2393, validation loss: 0.1561
2024-05-25 07:12:54 [INFO]: Epoch 056 - training loss: 0.2393, validation loss: 0.1549
2024-05-25 07:12:54 [INFO]: Epoch 057 - training loss: 0.2421, validation loss: 0.1543
2024-05-25 07:12:54 [INFO]: Epoch 058 - training loss: 0.2369, validation loss: 0.1505
2024-05-25 07:12:55 [INFO]: Epoch 059 - training loss: 0.2354, validation loss: 0.1530
2024-05-25 07:12:55 [INFO]: Epoch 060 - training loss: 0.2345, validation loss: 0.1527
2024-05-25 07:12:55 [INFO]: Epoch 061 - training loss: 0.2381, validation loss: 0.1541
2024-05-25 07:12:55 [INFO]: Epoch 062 - training loss: 0.2319, validation loss: 0.1518
2024-05-25 07:12:56 [INFO]: Epoch 063 - training loss: 0.2293, validation loss: 0.1520
2024-05-25 07:12:56 [INFO]: Epoch 064 - training loss: 0.2272, validation loss: 0.1522
2024-05-25 07:12:56 [INFO]: Epoch 065 - training loss: 0.2279, validation loss: 0.1505
2024-05-25 07:12:56 [INFO]: Epoch 066 - training loss: 0.2265, validation loss: 0.1507
2024-05-25 07:12:57 [INFO]: Epoch 067 - training loss: 0.2278, validation loss: 0.1525
2024-05-25 07:12:57 [INFO]: Epoch 068 - training loss: 0.2250, validation loss: 0.1501
2024-05-25 07:12:57 [INFO]: Epoch 069 - training loss: 0.2243, validation loss: 0.1499
2024-05-25 07:12:57 [INFO]: Epoch 070 - training loss: 0.2240, validation loss: 0.1494
2024-05-25 07:12:58 [INFO]: Epoch 071 - training loss: 0.2215, validation loss: 0.1479
2024-05-25 07:12:58 [INFO]: Epoch 072 - training loss: 0.2211, validation loss: 0.1497
2024-05-25 07:12:58 [INFO]: Epoch 073 - training loss: 0.2213, validation loss: 0.1501
2024-05-25 07:12:58 [INFO]: Epoch 074 - training loss: 0.2204, validation loss: 0.1477
2024-05-25 07:12:59 [INFO]: Epoch 075 - training loss: 0.2177, validation loss: 0.1480
2024-05-25 07:12:59 [INFO]: Epoch 076 - training loss: 0.2185, validation loss: 0.1471
2024-05-25 07:12:59 [INFO]: Epoch 077 - training loss: 0.2196, validation loss: 0.1458
2024-05-25 07:12:59 [INFO]: Epoch 078 - training loss: 0.2201, validation loss: 0.1481
2024-05-25 07:13:00 [INFO]: Epoch 079 - training loss: 0.2148, validation loss: 0.1478
2024-05-25 07:13:00 [INFO]: Epoch 080 - training loss: 0.2135, validation loss: 0.1465
2024-05-25 07:13:00 [INFO]: Epoch 081 - training loss: 0.2134, validation loss: 0.1469
2024-05-25 07:13:00 [INFO]: Epoch 082 - training loss: 0.2126, validation loss: 0.1461
2024-05-25 07:13:01 [INFO]: Epoch 083 - training loss: 0.2104, validation loss: 0.1462
2024-05-25 07:13:01 [INFO]: Epoch 084 - training loss: 0.2105, validation loss: 0.1458
2024-05-25 07:13:01 [INFO]: Epoch 085 - training loss: 0.2091, validation loss: 0.1464
2024-05-25 07:13:01 [INFO]: Epoch 086 - training loss: 0.2080, validation loss: 0.1456
2024-05-25 07:13:02 [INFO]: Epoch 087 - training loss: 0.2112, validation loss: 0.1466
2024-05-25 07:13:02 [INFO]: Epoch 088 - training loss: 0.2156, validation loss: 0.1473
2024-05-25 07:13:02 [INFO]: Epoch 089 - training loss: 0.2191, validation loss: 0.1442
2024-05-25 07:13:02 [INFO]: Epoch 090 - training loss: 0.2130, validation loss: 0.1453
2024-05-25 07:13:03 [INFO]: Epoch 091 - training loss: 0.2117, validation loss: 0.1430
2024-05-25 07:13:03 [INFO]: Epoch 092 - training loss: 0.2089, validation loss: 0.1451
2024-05-25 07:13:03 [INFO]: Epoch 093 - training loss: 0.2067, validation loss: 0.1447
2024-05-25 07:13:03 [INFO]: Epoch 094 - training loss: 0.2046, validation loss: 0.1448
2024-05-25 07:13:04 [INFO]: Epoch 095 - training loss: 0.2037, validation loss: 0.1429
2024-05-25 07:13:04 [INFO]: Epoch 096 - training loss: 0.2026, validation loss: 0.1442
2024-05-25 07:13:04 [INFO]: Epoch 097 - training loss: 0.1995, validation loss: 0.1439
2024-05-25 07:13:04 [INFO]: Epoch 098 - training loss: 0.1999, validation loss: 0.1444
2024-05-25 07:13:05 [INFO]: Epoch 099 - training loss: 0.2002, validation loss: 0.1423
2024-05-25 07:13:05 [INFO]: Epoch 100 - training loss: 0.1993, validation loss: 0.1434
2024-05-25 07:13:05 [INFO]: Epoch 101 - training loss: 0.1974, validation loss: 0.1414
2024-05-25 07:13:05 [INFO]: Epoch 102 - training loss: 0.1955, validation loss: 0.1432
2024-05-25 07:13:06 [INFO]: Epoch 103 - training loss: 0.1953, validation loss: 0.1420
2024-05-25 07:13:06 [INFO]: Epoch 104 - training loss: 0.1956, validation loss: 0.1435
2024-05-25 07:13:06 [INFO]: Epoch 105 - training loss: 0.1944, validation loss: 0.1414
2024-05-25 07:13:06 [INFO]: Epoch 106 - training loss: 0.1945, validation loss: 0.1426
2024-05-25 07:13:07 [INFO]: Epoch 107 - training loss: 0.1943, validation loss: 0.1417
2024-05-25 07:13:07 [INFO]: Epoch 108 - training loss: 0.1938, validation loss: 0.1414
2024-05-25 07:13:07 [INFO]: Epoch 109 - training loss: 0.1912, validation loss: 0.1410
2024-05-25 07:13:07 [INFO]: Epoch 110 - training loss: 0.1916, validation loss: 0.1400
2024-05-25 07:13:08 [INFO]: Epoch 111 - training loss: 0.1919, validation loss: 0.1406
2024-05-25 07:13:08 [INFO]: Epoch 112 - training loss: 0.1917, validation loss: 0.1430
2024-05-25 07:13:08 [INFO]: Epoch 113 - training loss: 0.1918, validation loss: 0.1425
2024-05-25 07:13:08 [INFO]: Epoch 114 - training loss: 0.1898, validation loss: 0.1415
2024-05-25 07:13:09 [INFO]: Epoch 115 - training loss: 0.1892, validation loss: 0.1420
2024-05-25 07:13:09 [INFO]: Epoch 116 - training loss: 0.1907, validation loss: 0.1405
2024-05-25 07:13:09 [INFO]: Epoch 117 - training loss: 0.1891, validation loss: 0.1397
2024-05-25 07:13:09 [INFO]: Epoch 118 - training loss: 0.1895, validation loss: 0.1432
2024-05-25 07:13:10 [INFO]: Epoch 119 - training loss: 0.1891, validation loss: 0.1395
2024-05-25 07:13:10 [INFO]: Epoch 120 - training loss: 0.1862, validation loss: 0.1397
2024-05-25 07:13:10 [INFO]: Epoch 121 - training loss: 0.1894, validation loss: 0.1410
2024-05-25 07:13:10 [INFO]: Epoch 122 - training loss: 0.1921, validation loss: 0.1411
2024-05-25 07:13:11 [INFO]: Epoch 123 - training loss: 0.1866, validation loss: 0.1390
2024-05-25 07:13:11 [INFO]: Epoch 124 - training loss: 0.1861, validation loss: 0.1403
2024-05-25 07:13:11 [INFO]: Epoch 125 - training loss: 0.1859, validation loss: 0.1396
2024-05-25 07:13:11 [INFO]: Epoch 126 - training loss: 0.1838, validation loss: 0.1402
2024-05-25 07:13:12 [INFO]: Epoch 127 - training loss: 0.1819, validation loss: 0.1405
2024-05-25 07:13:12 [INFO]: Epoch 128 - training loss: 0.1807, validation loss: 0.1379
2024-05-25 07:13:12 [INFO]: Epoch 129 - training loss: 0.1800, validation loss: 0.1394
2024-05-25 07:13:12 [INFO]: Epoch 130 - training loss: 0.1804, validation loss: 0.1396
2024-05-25 07:13:13 [INFO]: Epoch 131 - training loss: 0.1791, validation loss: 0.1392
2024-05-25 07:13:13 [INFO]: Epoch 132 - training loss: 0.1780, validation loss: 0.1394
2024-05-25 07:13:13 [INFO]: Epoch 133 - training loss: 0.1776, validation loss: 0.1383
2024-05-25 07:13:13 [INFO]: Epoch 134 - training loss: 0.1765, validation loss: 0.1393
2024-05-25 07:13:14 [INFO]: Epoch 135 - training loss: 0.1775, validation loss: 0.1394
2024-05-25 07:13:14 [INFO]: Epoch 136 - training loss: 0.1770, validation loss: 0.1385
2024-05-25 07:13:14 [INFO]: Epoch 137 - training loss: 0.1771, validation loss: 0.1391
2024-05-25 07:13:14 [INFO]: Epoch 138 - training loss: 0.1780, validation loss: 0.1382
2024-05-25 07:13:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:13:14 [INFO]: Finished training. The best model is from epoch#128.
2024-05-25 07:13:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/Transformer_air_quality/20240525_T071240/Transformer.pypots
2024-05-25 07:13:14 [INFO]: Transformer on Air-Quality: MAE=0.1853, MSE=0.1871
2024-05-25 07:13:14 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Transformer_air_quality/imputation.pkl
2024-05-25 07:13:14 [INFO]: Using the given device: cuda:0
2024-05-25 07:13:14 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/TimesNet_air_quality/20240525_T071314
2024-05-25 07:13:14 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/TimesNet_air_quality/20240525_T071314/tensorboard
2024-05-25 07:13:15 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 07:13:15 [INFO]: Epoch 001 - training loss: 0.3039, validation loss: 0.2552
2024-05-25 07:13:16 [INFO]: Epoch 002 - training loss: 0.2327, validation loss: 0.2164
2024-05-25 07:13:16 [INFO]: Epoch 003 - training loss: 0.1988, validation loss: 0.1953
2024-05-25 07:13:17 [INFO]: Epoch 004 - training loss: 0.1754, validation loss: 0.1861
2024-05-25 07:13:17 [INFO]: Epoch 005 - training loss: 0.1642, validation loss: 0.1797
2024-05-25 07:13:18 [INFO]: Epoch 006 - training loss: 0.1574, validation loss: 0.1793
2024-05-25 07:13:18 [INFO]: Epoch 007 - training loss: 0.1504, validation loss: 0.1738
2024-05-25 07:13:19 [INFO]: Epoch 008 - training loss: 0.1416, validation loss: 0.1670
2024-05-25 07:13:19 [INFO]: Epoch 009 - training loss: 0.1341, validation loss: 0.1693
2024-05-25 07:13:20 [INFO]: Epoch 010 - training loss: 0.1269, validation loss: 0.1657
2024-05-25 07:13:20 [INFO]: Epoch 011 - training loss: 0.1266, validation loss: 0.1680
2024-05-25 07:13:20 [INFO]: Epoch 012 - training loss: 0.1420, validation loss: 0.1702
2024-05-25 07:13:21 [INFO]: Epoch 013 - training loss: 0.1322, validation loss: 0.1655
2024-05-25 07:13:21 [INFO]: Epoch 014 - training loss: 0.1181, validation loss: 0.1651
2024-05-25 07:13:22 [INFO]: Epoch 015 - training loss: 0.1144, validation loss: 0.1620
2024-05-25 07:13:22 [INFO]: Epoch 016 - training loss: 0.1153, validation loss: 0.1597
2024-05-25 07:13:23 [INFO]: Epoch 017 - training loss: 0.1100, validation loss: 0.1614
2024-05-25 07:13:23 [INFO]: Epoch 018 - training loss: 0.1126, validation loss: 0.1612
2024-05-25 07:13:24 [INFO]: Epoch 019 - training loss: 0.1069, validation loss: 0.1641
2024-05-25 07:13:24 [INFO]: Epoch 020 - training loss: 0.1030, validation loss: 0.1565
2024-05-25 07:13:25 [INFO]: Epoch 021 - training loss: 0.1053, validation loss: 0.1589
2024-05-25 07:13:25 [INFO]: Epoch 022 - training loss: 0.1043, validation loss: 0.1581
2024-05-25 07:13:25 [INFO]: Epoch 023 - training loss: 0.1016, validation loss: 0.1616
2024-05-25 07:13:26 [INFO]: Epoch 024 - training loss: 0.0999, validation loss: 0.1600
2024-05-25 07:13:26 [INFO]: Epoch 025 - training loss: 0.1027, validation loss: 0.1567
2024-05-25 07:13:27 [INFO]: Epoch 026 - training loss: 0.0956, validation loss: 0.1584
2024-05-25 07:13:27 [INFO]: Epoch 027 - training loss: 0.0935, validation loss: 0.1589
2024-05-25 07:13:28 [INFO]: Epoch 028 - training loss: 0.0953, validation loss: 0.1620
2024-05-25 07:13:28 [INFO]: Epoch 029 - training loss: 0.0905, validation loss: 0.1572
2024-05-25 07:13:29 [INFO]: Epoch 030 - training loss: 0.0907, validation loss: 0.1580
2024-05-25 07:13:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:13:29 [INFO]: Finished training. The best model is from epoch#20.
2024-05-25 07:13:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/TimesNet_air_quality/20240525_T071314/TimesNet.pypots
2024-05-25 07:13:29 [INFO]: TimesNet on Air-Quality: MAE=0.1753, MSE=0.2449
2024-05-25 07:13:29 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/TimesNet_air_quality/imputation.pkl
2024-05-25 07:13:29 [INFO]: Using the given device: cuda:0
2024-05-25 07:13:29 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329
2024-05-25 07:13:29 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/tensorboard
2024-05-25 07:13:29 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 07:13:46 [INFO]: Epoch 001 - training loss: 0.5335, validation loss: 0.3591
2024-05-25 07:13:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch1_loss0.3590857595205307.pypots
2024-05-25 07:14:02 [INFO]: Epoch 002 - training loss: 0.3189, validation loss: 0.2817
2024-05-25 07:14:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch2_loss0.2817123055458069.pypots
2024-05-25 07:14:19 [INFO]: Epoch 003 - training loss: 0.2612, validation loss: 0.2523
2024-05-25 07:14:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch3_loss0.25233185589313506.pypots
2024-05-25 07:14:36 [INFO]: Epoch 004 - training loss: 0.2390, validation loss: 0.2344
2024-05-25 07:14:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch4_loss0.23437882512807845.pypots
2024-05-25 07:14:52 [INFO]: Epoch 005 - training loss: 0.2386, validation loss: 0.2119
2024-05-25 07:14:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch5_loss0.2119194746017456.pypots
2024-05-25 07:15:09 [INFO]: Epoch 006 - training loss: 0.1904, validation loss: 0.1892
2024-05-25 07:15:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch6_loss0.1892225056886673.pypots
2024-05-25 07:15:26 [INFO]: Epoch 007 - training loss: 0.1979, validation loss: 0.1704
2024-05-25 07:15:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch7_loss0.17044321000576018.pypots
2024-05-25 07:15:42 [INFO]: Epoch 008 - training loss: 0.1725, validation loss: 0.1608
2024-05-25 07:15:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch8_loss0.1608378529548645.pypots
2024-05-25 07:15:59 [INFO]: Epoch 009 - training loss: 0.1575, validation loss: 0.1612
2024-05-25 07:15:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch9_loss0.16116973310708999.pypots
2024-05-25 07:16:16 [INFO]: Epoch 010 - training loss: 0.1547, validation loss: 0.1516
2024-05-25 07:16:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch10_loss0.1515947699546814.pypots
2024-05-25 07:16:32 [INFO]: Epoch 011 - training loss: 0.1592, validation loss: 0.1506
2024-05-25 07:16:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch11_loss0.15056853294372557.pypots
2024-05-25 07:16:49 [INFO]: Epoch 012 - training loss: 0.1578, validation loss: 0.1470
2024-05-25 07:16:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch12_loss0.14703088849782944.pypots
2024-05-25 07:17:06 [INFO]: Epoch 013 - training loss: 0.1558, validation loss: 0.1436
2024-05-25 07:17:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch13_loss0.1435980185866356.pypots
2024-05-25 07:17:22 [INFO]: Epoch 014 - training loss: 0.1672, validation loss: 0.1469
2024-05-25 07:17:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch14_loss0.1469256639480591.pypots
2024-05-25 07:17:39 [INFO]: Epoch 015 - training loss: 0.1428, validation loss: 0.1448
2024-05-25 07:17:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch15_loss0.14478318840265275.pypots
2024-05-25 07:17:56 [INFO]: Epoch 016 - training loss: 0.1568, validation loss: 0.1406
2024-05-25 07:17:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch16_loss0.14061388671398162.pypots
2024-05-25 07:18:12 [INFO]: Epoch 017 - training loss: 0.1475, validation loss: 0.1419
2024-05-25 07:18:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch17_loss0.1419443517923355.pypots
2024-05-25 07:18:29 [INFO]: Epoch 018 - training loss: 0.1441, validation loss: 0.1365
2024-05-25 07:18:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch18_loss0.1365162491798401.pypots
2024-05-25 07:18:46 [INFO]: Epoch 019 - training loss: 0.1331, validation loss: 0.1403
2024-05-25 07:18:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch19_loss0.14034238830208778.pypots
2024-05-25 07:19:02 [INFO]: Epoch 020 - training loss: 0.1232, validation loss: 0.1372
2024-05-25 07:19:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch20_loss0.1371525190770626.pypots
2024-05-25 07:19:19 [INFO]: Epoch 021 - training loss: 0.1490, validation loss: 0.1381
2024-05-25 07:19:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch21_loss0.13806584104895592.pypots
2024-05-25 07:19:36 [INFO]: Epoch 022 - training loss: 0.1433, validation loss: 0.1308
2024-05-25 07:19:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch22_loss0.13077589198946954.pypots
2024-05-25 07:19:52 [INFO]: Epoch 023 - training loss: 0.1287, validation loss: 0.1338
2024-05-25 07:19:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch23_loss0.13380715250968933.pypots
2024-05-25 07:20:09 [INFO]: Epoch 024 - training loss: 0.1252, validation loss: 0.1310
2024-05-25 07:20:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch24_loss0.13102260157465934.pypots
2024-05-25 07:20:26 [INFO]: Epoch 025 - training loss: 0.1354, validation loss: 0.1294
2024-05-25 07:20:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch25_loss0.12941234782338143.pypots
2024-05-25 07:20:42 [INFO]: Epoch 026 - training loss: 0.1404, validation loss: 0.1305
2024-05-25 07:20:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch26_loss0.13054922223091125.pypots
2024-05-25 07:20:59 [INFO]: Epoch 027 - training loss: 0.1333, validation loss: 0.1333
2024-05-25 07:20:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch27_loss0.1333393193781376.pypots
2024-05-25 07:21:16 [INFO]: Epoch 028 - training loss: 0.1304, validation loss: 0.1286
2024-05-25 07:21:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch28_loss0.1286488175392151.pypots
2024-05-25 07:21:32 [INFO]: Epoch 029 - training loss: 0.1333, validation loss: 0.1304
2024-05-25 07:21:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch29_loss0.13041413947939873.pypots
2024-05-25 07:21:49 [INFO]: Epoch 030 - training loss: 0.1251, validation loss: 0.1303
2024-05-25 07:21:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch30_loss0.13033048436045647.pypots
2024-05-25 07:22:06 [INFO]: Epoch 031 - training loss: 0.1221, validation loss: 0.1285
2024-05-25 07:22:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch31_loss0.12850294038653373.pypots
2024-05-25 07:22:22 [INFO]: Epoch 032 - training loss: 0.1274, validation loss: 0.1321
2024-05-25 07:22:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch32_loss0.13212914541363716.pypots
2024-05-25 07:22:39 [INFO]: Epoch 033 - training loss: 0.1159, validation loss: 0.1264
2024-05-25 07:22:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch33_loss0.12642617598176004.pypots
2024-05-25 07:22:56 [INFO]: Epoch 034 - training loss: 0.1287, validation loss: 0.1264
2024-05-25 07:22:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch34_loss0.1264031171798706.pypots
2024-05-25 07:23:12 [INFO]: Epoch 035 - training loss: 0.1331, validation loss: 0.1277
2024-05-25 07:23:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch35_loss0.12771559581160546.pypots
2024-05-25 07:23:29 [INFO]: Epoch 036 - training loss: 0.1106, validation loss: 0.1245
2024-05-25 07:23:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch36_loss0.12452902421355247.pypots
2024-05-25 07:23:46 [INFO]: Epoch 037 - training loss: 0.1219, validation loss: 0.1237
2024-05-25 07:23:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch37_loss0.12372652441263199.pypots
2024-05-25 07:24:02 [INFO]: Epoch 038 - training loss: 0.1275, validation loss: 0.1242
2024-05-25 07:24:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch38_loss0.12419813051819802.pypots
2024-05-25 07:24:19 [INFO]: Epoch 039 - training loss: 0.1202, validation loss: 0.1299
2024-05-25 07:24:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch39_loss0.12990594133734704.pypots
2024-05-25 07:24:36 [INFO]: Epoch 040 - training loss: 0.1222, validation loss: 0.1246
2024-05-25 07:24:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch40_loss0.12456720545887948.pypots
2024-05-25 07:24:52 [INFO]: Epoch 041 - training loss: 0.1339, validation loss: 0.1241
2024-05-25 07:24:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch41_loss0.12408862709999084.pypots
2024-05-25 07:25:09 [INFO]: Epoch 042 - training loss: 0.1247, validation loss: 0.1231
2024-05-25 07:25:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch42_loss0.12310278490185737.pypots
2024-05-25 07:25:26 [INFO]: Epoch 043 - training loss: 0.1237, validation loss: 0.1206
2024-05-25 07:25:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch43_loss0.12062893137335777.pypots
2024-05-25 07:25:43 [INFO]: Epoch 044 - training loss: 0.1122, validation loss: 0.1218
2024-05-25 07:25:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch44_loss0.12184489890933037.pypots
2024-05-25 07:25:59 [INFO]: Epoch 045 - training loss: 0.1243, validation loss: 0.1209
2024-05-25 07:25:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch45_loss0.12089375182986259.pypots
2024-05-25 07:26:16 [INFO]: Epoch 046 - training loss: 0.1168, validation loss: 0.1196
2024-05-25 07:26:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch46_loss0.11964796856045723.pypots
2024-05-25 07:26:33 [INFO]: Epoch 047 - training loss: 0.1199, validation loss: 0.1189
2024-05-25 07:26:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch47_loss0.11889505609869958.pypots
2024-05-25 07:26:49 [INFO]: Epoch 048 - training loss: 0.1206, validation loss: 0.1183
2024-05-25 07:26:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch48_loss0.11830391362309456.pypots
2024-05-25 07:27:06 [INFO]: Epoch 049 - training loss: 0.0987, validation loss: 0.1171
2024-05-25 07:27:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch49_loss0.11710775420069694.pypots
2024-05-25 07:27:23 [INFO]: Epoch 050 - training loss: 0.1018, validation loss: 0.1167
2024-05-25 07:27:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch50_loss0.11671487241983414.pypots
2024-05-25 07:27:39 [INFO]: Epoch 051 - training loss: 0.0984, validation loss: 0.1190
2024-05-25 07:27:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch51_loss0.11895741894841194.pypots
2024-05-25 07:27:56 [INFO]: Epoch 052 - training loss: 0.1102, validation loss: 0.1217
2024-05-25 07:27:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch52_loss0.12167047560214997.pypots
2024-05-25 07:28:13 [INFO]: Epoch 053 - training loss: 0.1118, validation loss: 0.1171
2024-05-25 07:28:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch53_loss0.11707020699977874.pypots
2024-05-25 07:28:29 [INFO]: Epoch 054 - training loss: 0.1187, validation loss: 0.1201
2024-05-25 07:28:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch54_loss0.12005501911044121.pypots
2024-05-25 07:28:46 [INFO]: Epoch 055 - training loss: 0.1171, validation loss: 0.1238
2024-05-25 07:28:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch55_loss0.12377390936017037.pypots
2024-05-25 07:29:03 [INFO]: Epoch 056 - training loss: 0.1371, validation loss: 0.1142
2024-05-25 07:29:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch56_loss0.11418718099594116.pypots
2024-05-25 07:29:19 [INFO]: Epoch 057 - training loss: 0.0944, validation loss: 0.1140
2024-05-25 07:29:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch57_loss0.11401502788066864.pypots
2024-05-25 07:29:36 [INFO]: Epoch 058 - training loss: 0.1033, validation loss: 0.1149
2024-05-25 07:29:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch58_loss0.1149493396282196.pypots
2024-05-25 07:29:53 [INFO]: Epoch 059 - training loss: 0.1242, validation loss: 0.1203
2024-05-25 07:29:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch59_loss0.12029816955327988.pypots
2024-05-25 07:30:09 [INFO]: Epoch 060 - training loss: 0.1039, validation loss: 0.1125
2024-05-25 07:30:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch60_loss0.11254603937268257.pypots
2024-05-25 07:30:26 [INFO]: Epoch 061 - training loss: 0.1053, validation loss: 0.1127
2024-05-25 07:30:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch61_loss0.11269443780183792.pypots
2024-05-25 07:30:43 [INFO]: Epoch 062 - training loss: 0.1065, validation loss: 0.1163
2024-05-25 07:30:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch62_loss0.1163466602563858.pypots
2024-05-25 07:30:59 [INFO]: Epoch 063 - training loss: 0.1254, validation loss: 0.1126
2024-05-25 07:30:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch63_loss0.1125546507537365.pypots
2024-05-25 07:31:16 [INFO]: Epoch 064 - training loss: 0.1063, validation loss: 0.1111
2024-05-25 07:31:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch64_loss0.11113702282309532.pypots
2024-05-25 07:31:33 [INFO]: Epoch 065 - training loss: 0.1026, validation loss: 0.1114
2024-05-25 07:31:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch65_loss0.11142885312438011.pypots
2024-05-25 07:31:49 [INFO]: Epoch 066 - training loss: 0.1131, validation loss: 0.1111
2024-05-25 07:31:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch66_loss0.11113934442400933.pypots
2024-05-25 07:32:06 [INFO]: Epoch 067 - training loss: 0.0986, validation loss: 0.1100
2024-05-25 07:32:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch67_loss0.11002102941274643.pypots
2024-05-25 07:32:23 [INFO]: Epoch 068 - training loss: 0.1105, validation loss: 0.1112
2024-05-25 07:32:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch68_loss0.11117063239216804.pypots
2024-05-25 07:32:39 [INFO]: Epoch 069 - training loss: 0.1055, validation loss: 0.1082
2024-05-25 07:32:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch69_loss0.10820862799882888.pypots
2024-05-25 07:32:56 [INFO]: Epoch 070 - training loss: 0.1077, validation loss: 0.1083
2024-05-25 07:32:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch70_loss0.10827936753630638.pypots
2024-05-25 07:33:13 [INFO]: Epoch 071 - training loss: 0.1051, validation loss: 0.1093
2024-05-25 07:33:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch71_loss0.10932965576648712.pypots
2024-05-25 07:33:29 [INFO]: Epoch 072 - training loss: 0.1026, validation loss: 0.1081
2024-05-25 07:33:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch72_loss0.10812630876898766.pypots
2024-05-25 07:33:46 [INFO]: Epoch 073 - training loss: 0.1016, validation loss: 0.1087
2024-05-25 07:33:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch73_loss0.10865010172128678.pypots
2024-05-25 07:34:03 [INFO]: Epoch 074 - training loss: 0.1111, validation loss: 0.1080
2024-05-25 07:34:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch74_loss0.1079976074397564.pypots
2024-05-25 07:34:19 [INFO]: Epoch 075 - training loss: 0.0907, validation loss: 0.1099
2024-05-25 07:34:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch75_loss0.10988062024116516.pypots
2024-05-25 07:34:36 [INFO]: Epoch 076 - training loss: 0.1120, validation loss: 0.1089
2024-05-25 07:34:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch76_loss0.10888004004955291.pypots
2024-05-25 07:34:53 [INFO]: Epoch 077 - training loss: 0.1134, validation loss: 0.1082
2024-05-25 07:34:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch77_loss0.10818063840270042.pypots
2024-05-25 07:35:09 [INFO]: Epoch 078 - training loss: 0.0993, validation loss: 0.1070
2024-05-25 07:35:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch78_loss0.10702572166919708.pypots
2024-05-25 07:35:26 [INFO]: Epoch 079 - training loss: 0.0961, validation loss: 0.1071
2024-05-25 07:35:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch79_loss0.10709867924451828.pypots
2024-05-25 07:35:43 [INFO]: Epoch 080 - training loss: 0.1040, validation loss: 0.1092
2024-05-25 07:35:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch80_loss0.10915151089429856.pypots
2024-05-25 07:35:59 [INFO]: Epoch 081 - training loss: 0.1181, validation loss: 0.1060
2024-05-25 07:35:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch81_loss0.10603065341711045.pypots
2024-05-25 07:36:16 [INFO]: Epoch 082 - training loss: 0.1039, validation loss: 0.1059
2024-05-25 07:36:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch82_loss0.10590981096029281.pypots
2024-05-25 07:36:33 [INFO]: Epoch 083 - training loss: 0.1006, validation loss: 0.1047
2024-05-25 07:36:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch83_loss0.10474865660071372.pypots
2024-05-25 07:36:49 [INFO]: Epoch 084 - training loss: 0.1062, validation loss: 0.1068
2024-05-25 07:36:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch84_loss0.10681558772921562.pypots
2024-05-25 07:37:06 [INFO]: Epoch 085 - training loss: 0.1133, validation loss: 0.1151
2024-05-25 07:37:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch85_loss0.11505589261651039.pypots
2024-05-25 07:37:23 [INFO]: Epoch 086 - training loss: 0.1079, validation loss: 0.1048
2024-05-25 07:37:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch86_loss0.10481672137975692.pypots
2024-05-25 07:37:39 [INFO]: Epoch 087 - training loss: 0.0944, validation loss: 0.1054
2024-05-25 07:37:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch87_loss0.10535243451595307.pypots
2024-05-25 07:37:56 [INFO]: Epoch 088 - training loss: 0.0927, validation loss: 0.1057
2024-05-25 07:37:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch88_loss0.1056679330766201.pypots
2024-05-25 07:38:13 [INFO]: Epoch 089 - training loss: 0.1120, validation loss: 0.1063
2024-05-25 07:38:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch89_loss0.10633696690201759.pypots
2024-05-25 07:38:29 [INFO]: Epoch 090 - training loss: 0.0989, validation loss: 0.1076
2024-05-25 07:38:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch90_loss0.10762578174471855.pypots
2024-05-25 07:38:46 [INFO]: Epoch 091 - training loss: 0.0960, validation loss: 0.1060
2024-05-25 07:38:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch91_loss0.10598596930503845.pypots
2024-05-25 07:39:03 [INFO]: Epoch 092 - training loss: 0.0938, validation loss: 0.1033
2024-05-25 07:39:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch92_loss0.10332810059189797.pypots
2024-05-25 07:39:19 [INFO]: Epoch 093 - training loss: 0.0907, validation loss: 0.1050
2024-05-25 07:39:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch93_loss0.10499262064695358.pypots
2024-05-25 07:39:36 [INFO]: Epoch 094 - training loss: 0.0947, validation loss: 0.1036
2024-05-25 07:39:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch94_loss0.1035696230828762.pypots
2024-05-25 07:39:53 [INFO]: Epoch 095 - training loss: 0.1106, validation loss: 0.1042
2024-05-25 07:39:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch95_loss0.10416319444775582.pypots
2024-05-25 07:40:09 [INFO]: Epoch 096 - training loss: 0.0884, validation loss: 0.1037
2024-05-25 07:40:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch96_loss0.1037408895790577.pypots
2024-05-25 07:40:26 [INFO]: Epoch 097 - training loss: 0.1093, validation loss: 0.1038
2024-05-25 07:40:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch97_loss0.10379792675375939.pypots
2024-05-25 07:40:43 [INFO]: Epoch 098 - training loss: 0.0996, validation loss: 0.1041
2024-05-25 07:40:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch98_loss0.10408570468425751.pypots
2024-05-25 07:40:59 [INFO]: Epoch 099 - training loss: 0.1153, validation loss: 0.1098
2024-05-25 07:40:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch99_loss0.10975316166877747.pypots
2024-05-25 07:41:16 [INFO]: Epoch 100 - training loss: 0.1042, validation loss: 0.1062
2024-05-25 07:41:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch100_loss0.10620968863368034.pypots
2024-05-25 07:41:33 [INFO]: Epoch 101 - training loss: 0.1101, validation loss: 0.1072
2024-05-25 07:41:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch101_loss0.10719253942370414.pypots
2024-05-25 07:41:49 [INFO]: Epoch 102 - training loss: 0.0968, validation loss: 0.1044
2024-05-25 07:41:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI_epoch102_loss0.10444281622767448.pypots
2024-05-25 07:41:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:41:49 [INFO]: Finished training. The best model is from epoch#92.
2024-05-25 07:41:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T071329/CSDI.pypots
2024-05-25 07:44:10 [INFO]: CSDI on Air-Quality: MAE=0.1071, MSE=0.1347
2024-05-25 07:44:10 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/CSDI_air_quality/imputation.pkl
2024-05-25 07:44:10 [INFO]: Using the given device: cuda:0
2024-05-25 07:44:10 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/GPVAE_air_quality/20240525_T074410
2024-05-25 07:44:10 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/GPVAE_air_quality/20240525_T074410/tensorboard
2024-05-25 07:44:10 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 07:44:10 [INFO]: Epoch 001 - training loss: 65603.8566, validation loss: 0.6273
2024-05-25 07:44:10 [INFO]: Epoch 002 - training loss: 41559.1416, validation loss: 0.5546
2024-05-25 07:44:11 [INFO]: Epoch 003 - training loss: 41204.2263, validation loss: 0.5488
2024-05-25 07:44:11 [INFO]: Epoch 004 - training loss: 41090.1600, validation loss: 0.5096
2024-05-25 07:44:11 [INFO]: Epoch 005 - training loss: 40993.3475, validation loss: 0.4527
2024-05-25 07:44:12 [INFO]: Epoch 006 - training loss: 40899.5059, validation loss: 0.4241
2024-05-25 07:44:12 [INFO]: Epoch 007 - training loss: 40862.3643, validation loss: 0.3871
2024-05-25 07:44:13 [INFO]: Epoch 008 - training loss: 40824.6396, validation loss: 0.3819
2024-05-25 07:44:13 [INFO]: Epoch 009 - training loss: 40798.0230, validation loss: 0.3472
2024-05-25 07:44:13 [INFO]: Epoch 010 - training loss: 40769.6091, validation loss: 0.3622
2024-05-25 07:44:14 [INFO]: Epoch 011 - training loss: 40792.9621, validation loss: 0.3579
2024-05-25 07:44:14 [INFO]: Epoch 012 - training loss: 40736.1330, validation loss: 0.3139
2024-05-25 07:44:14 [INFO]: Epoch 013 - training loss: 40706.7083, validation loss: 0.3070
2024-05-25 07:44:15 [INFO]: Epoch 014 - training loss: 40700.5920, validation loss: 0.3041
2024-05-25 07:44:15 [INFO]: Epoch 015 - training loss: 40719.3913, validation loss: 0.3359
2024-05-25 07:44:15 [INFO]: Epoch 016 - training loss: 40749.4550, validation loss: 0.3113
2024-05-25 07:44:16 [INFO]: Epoch 017 - training loss: 40695.7115, validation loss: 0.3039
2024-05-25 07:44:16 [INFO]: Epoch 018 - training loss: 40675.0635, validation loss: 0.2872
2024-05-25 07:44:16 [INFO]: Epoch 019 - training loss: 40658.4308, validation loss: 0.2900
2024-05-25 07:44:17 [INFO]: Epoch 020 - training loss: 40653.9181, validation loss: 0.2855
2024-05-25 07:44:17 [INFO]: Epoch 021 - training loss: 40646.6212, validation loss: 0.2682
2024-05-25 07:44:17 [INFO]: Epoch 022 - training loss: 40638.1710, validation loss: 0.2879
2024-05-25 07:44:18 [INFO]: Epoch 023 - training loss: 40631.7614, validation loss: 0.2642
2024-05-25 07:44:18 [INFO]: Epoch 024 - training loss: 40616.0670, validation loss: 0.2674
2024-05-25 07:44:18 [INFO]: Epoch 025 - training loss: 40622.4052, validation loss: 0.2604
2024-05-25 07:44:19 [INFO]: Epoch 026 - training loss: 40624.7368, validation loss: 0.2919
2024-05-25 07:44:19 [INFO]: Epoch 027 - training loss: 40615.9887, validation loss: 0.2546
2024-05-25 07:44:20 [INFO]: Epoch 028 - training loss: 40619.8132, validation loss: 0.2683
2024-05-25 07:44:20 [INFO]: Epoch 029 - training loss: 40605.8870, validation loss: 0.2523
2024-05-25 07:44:20 [INFO]: Epoch 030 - training loss: 40599.3409, validation loss: 0.2518
2024-05-25 07:44:21 [INFO]: Epoch 031 - training loss: 40601.0624, validation loss: 0.2513
2024-05-25 07:44:21 [INFO]: Epoch 032 - training loss: 40595.4502, validation loss: 0.2514
2024-05-25 07:44:21 [INFO]: Epoch 033 - training loss: 40587.3304, validation loss: 0.2436
2024-05-25 07:44:22 [INFO]: Epoch 034 - training loss: 40592.1551, validation loss: 0.2590
2024-05-25 07:44:22 [INFO]: Epoch 035 - training loss: 40589.4174, validation loss: 0.2484
2024-05-25 07:44:22 [INFO]: Epoch 036 - training loss: 40596.1437, validation loss: 0.2475
2024-05-25 07:44:23 [INFO]: Epoch 037 - training loss: 40585.3815, validation loss: 0.2495
2024-05-25 07:44:23 [INFO]: Epoch 038 - training loss: 40606.8565, validation loss: 0.2552
2024-05-25 07:44:23 [INFO]: Epoch 039 - training loss: 40621.1819, validation loss: 0.2490
2024-05-25 07:44:24 [INFO]: Epoch 040 - training loss: 40603.6749, validation loss: 0.2711
2024-05-25 07:44:24 [INFO]: Epoch 041 - training loss: 40620.2232, validation loss: 0.2669
2024-05-25 07:44:24 [INFO]: Epoch 042 - training loss: 40631.8598, validation loss: 0.3039
2024-05-25 07:44:25 [INFO]: Epoch 043 - training loss: 40617.6179, validation loss: 0.2552
2024-05-25 07:44:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:44:25 [INFO]: Finished training. The best model is from epoch#33.
2024-05-25 07:44:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/GPVAE_air_quality/20240525_T074410/GPVAE.pypots
2024-05-25 07:44:25 [INFO]: GP-VAE on Air-Quality: MAE=0.3142, MSE=0.3196
2024-05-25 07:44:25 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/GPVAE_air_quality/imputation.pkl
2024-05-25 07:44:25 [INFO]: Using the given device: cuda:0
2024-05-25 07:44:25 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/USGAN_air_quality/20240525_T074425
2024-05-25 07:44:25 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/USGAN_air_quality/20240525_T074425/tensorboard
2024-05-25 07:44:25 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 07:44:30 [INFO]: Epoch 001 - generator training loss: 0.3775, discriminator training loss: 0.5691, validation loss: 0.5115
2024-05-25 07:44:34 [INFO]: Epoch 002 - generator training loss: 0.0362, discriminator training loss: 0.5241, validation loss: 0.3891
2024-05-25 07:44:38 [INFO]: Epoch 003 - generator training loss: -0.0355, discriminator training loss: 0.5184, validation loss: 0.3192
2024-05-25 07:44:43 [INFO]: Epoch 004 - generator training loss: -0.0733, discriminator training loss: 0.5139, validation loss: 0.2760
2024-05-25 07:44:47 [INFO]: Epoch 005 - generator training loss: -0.0944, discriminator training loss: 0.5087, validation loss: 0.2509
2024-05-25 07:44:51 [INFO]: Epoch 006 - generator training loss: -0.1065, discriminator training loss: 0.5028, validation loss: 0.2310
2024-05-25 07:44:55 [INFO]: Epoch 007 - generator training loss: -0.1169, discriminator training loss: 0.4961, validation loss: 0.2176
2024-05-25 07:44:59 [INFO]: Epoch 008 - generator training loss: -0.1223, discriminator training loss: 0.4881, validation loss: 0.2070
2024-05-25 07:45:04 [INFO]: Epoch 009 - generator training loss: -0.1253, discriminator training loss: 0.4790, validation loss: 0.1977
2024-05-25 07:45:08 [INFO]: Epoch 010 - generator training loss: -0.1259, discriminator training loss: 0.4695, validation loss: 0.1910
2024-05-25 07:45:12 [INFO]: Epoch 011 - generator training loss: -0.1249, discriminator training loss: 0.4596, validation loss: 0.1846
2024-05-25 07:45:16 [INFO]: Epoch 012 - generator training loss: -0.1221, discriminator training loss: 0.4487, validation loss: 0.1797
2024-05-25 07:45:20 [INFO]: Epoch 013 - generator training loss: -0.1205, discriminator training loss: 0.4383, validation loss: 0.1746
2024-05-25 07:45:25 [INFO]: Epoch 014 - generator training loss: -0.1172, discriminator training loss: 0.4278, validation loss: 0.1715
2024-05-25 07:45:29 [INFO]: Epoch 015 - generator training loss: -0.1163, discriminator training loss: 0.4178, validation loss: 0.1671
2024-05-25 07:45:33 [INFO]: Epoch 016 - generator training loss: -0.1117, discriminator training loss: 0.4079, validation loss: 0.1639
2024-05-25 07:45:37 [INFO]: Epoch 017 - generator training loss: -0.1041, discriminator training loss: 0.3992, validation loss: 0.1614
2024-05-25 07:45:41 [INFO]: Epoch 018 - generator training loss: -0.1035, discriminator training loss: 0.3910, validation loss: 0.1588
2024-05-25 07:45:46 [INFO]: Epoch 019 - generator training loss: -0.1054, discriminator training loss: 0.3833, validation loss: 0.1558
2024-05-25 07:45:50 [INFO]: Epoch 020 - generator training loss: -0.1028, discriminator training loss: 0.3765, validation loss: 0.1538
2024-05-25 07:45:54 [INFO]: Epoch 021 - generator training loss: -0.1017, discriminator training loss: 0.3697, validation loss: 0.1515
2024-05-25 07:45:58 [INFO]: Epoch 022 - generator training loss: -0.0998, discriminator training loss: 0.3643, validation loss: 0.1494
2024-05-25 07:46:02 [INFO]: Epoch 023 - generator training loss: -0.0978, discriminator training loss: 0.3591, validation loss: 0.1474
2024-05-25 07:46:07 [INFO]: Epoch 024 - generator training loss: -0.0970, discriminator training loss: 0.3546, validation loss: 0.1463
2024-05-25 07:46:11 [INFO]: Epoch 025 - generator training loss: -0.0944, discriminator training loss: 0.3505, validation loss: 0.1444
2024-05-25 07:46:15 [INFO]: Epoch 026 - generator training loss: -0.0960, discriminator training loss: 0.3469, validation loss: 0.1431
2024-05-25 07:46:19 [INFO]: Epoch 027 - generator training loss: -0.0943, discriminator training loss: 0.3434, validation loss: 0.1417
2024-05-25 07:46:24 [INFO]: Epoch 028 - generator training loss: -0.0942, discriminator training loss: 0.3404, validation loss: 0.1405
2024-05-25 07:46:28 [INFO]: Epoch 029 - generator training loss: -0.0936, discriminator training loss: 0.3373, validation loss: 0.1387
2024-05-25 07:46:32 [INFO]: Epoch 030 - generator training loss: -0.0936, discriminator training loss: 0.3347, validation loss: 0.1375
2024-05-25 07:46:36 [INFO]: Epoch 031 - generator training loss: -0.0931, discriminator training loss: 0.3327, validation loss: 0.1367
2024-05-25 07:46:40 [INFO]: Epoch 032 - generator training loss: -0.0929, discriminator training loss: 0.3298, validation loss: 0.1348
2024-05-25 07:46:45 [INFO]: Epoch 033 - generator training loss: -0.0925, discriminator training loss: 0.3278, validation loss: 0.1336
2024-05-25 07:46:49 [INFO]: Epoch 034 - generator training loss: -0.0948, discriminator training loss: 0.3262, validation loss: 0.1324
2024-05-25 07:46:53 [INFO]: Epoch 035 - generator training loss: -0.0944, discriminator training loss: 0.3243, validation loss: 0.1305
2024-05-25 07:46:57 [INFO]: Epoch 036 - generator training loss: -0.0948, discriminator training loss: 0.3232, validation loss: 0.1293
2024-05-25 07:47:01 [INFO]: Epoch 037 - generator training loss: -0.0953, discriminator training loss: 0.3218, validation loss: 0.1285
2024-05-25 07:47:06 [INFO]: Epoch 038 - generator training loss: -0.0960, discriminator training loss: 0.3207, validation loss: 0.1272
2024-05-25 07:47:10 [INFO]: Epoch 039 - generator training loss: -0.0968, discriminator training loss: 0.3198, validation loss: 0.1269
2024-05-25 07:47:14 [INFO]: Epoch 040 - generator training loss: -0.0967, discriminator training loss: 0.3187, validation loss: 0.1254
2024-05-25 07:47:18 [INFO]: Epoch 041 - generator training loss: -0.0982, discriminator training loss: 0.3173, validation loss: 0.1244
2024-05-25 07:47:22 [INFO]: Epoch 042 - generator training loss: -0.0991, discriminator training loss: 0.3168, validation loss: 0.1237
2024-05-25 07:47:27 [INFO]: Epoch 043 - generator training loss: -0.0998, discriminator training loss: 0.3155, validation loss: 0.1231
2024-05-25 07:47:31 [INFO]: Epoch 044 - generator training loss: -0.1006, discriminator training loss: 0.3151, validation loss: 0.1220
2024-05-25 07:47:35 [INFO]: Epoch 045 - generator training loss: -0.0998, discriminator training loss: 0.3147, validation loss: 0.1212
2024-05-25 07:47:39 [INFO]: Epoch 046 - generator training loss: -0.1008, discriminator training loss: 0.3139, validation loss: 0.1209
2024-05-25 07:47:43 [INFO]: Epoch 047 - generator training loss: -0.1016, discriminator training loss: 0.3130, validation loss: 0.1202
2024-05-25 07:47:48 [INFO]: Epoch 048 - generator training loss: -0.1016, discriminator training loss: 0.3127, validation loss: 0.1197
2024-05-25 07:47:52 [INFO]: Epoch 049 - generator training loss: -0.1022, discriminator training loss: 0.3121, validation loss: 0.1188
2024-05-25 07:47:56 [INFO]: Epoch 050 - generator training loss: -0.1038, discriminator training loss: 0.3115, validation loss: 0.1184
2024-05-25 07:48:00 [INFO]: Epoch 051 - generator training loss: -0.1030, discriminator training loss: 0.3112, validation loss: 0.1183
2024-05-25 07:48:04 [INFO]: Epoch 052 - generator training loss: -0.1036, discriminator training loss: 0.3108, validation loss: 0.1174
2024-05-25 07:48:09 [INFO]: Epoch 053 - generator training loss: -0.1053, discriminator training loss: 0.3100, validation loss: 0.1166
2024-05-25 07:48:13 [INFO]: Epoch 054 - generator training loss: -0.1037, discriminator training loss: 0.3099, validation loss: 0.1159
2024-05-25 07:48:17 [INFO]: Epoch 055 - generator training loss: -0.1059, discriminator training loss: 0.3098, validation loss: 0.1165
2024-05-25 07:48:21 [INFO]: Epoch 056 - generator training loss: -0.1057, discriminator training loss: 0.3092, validation loss: 0.1158
2024-05-25 07:48:25 [INFO]: Epoch 057 - generator training loss: -0.1055, discriminator training loss: 0.3090, validation loss: 0.1151
2024-05-25 07:48:30 [INFO]: Epoch 058 - generator training loss: -0.1046, discriminator training loss: 0.3084, validation loss: 0.1148
2024-05-25 07:48:34 [INFO]: Epoch 059 - generator training loss: -0.1059, discriminator training loss: 0.3084, validation loss: 0.1147
2024-05-25 07:48:38 [INFO]: Epoch 060 - generator training loss: -0.1060, discriminator training loss: 0.3080, validation loss: 0.1147
2024-05-25 07:48:42 [INFO]: Epoch 061 - generator training loss: -0.1085, discriminator training loss: 0.3081, validation loss: 0.1137
2024-05-25 07:48:46 [INFO]: Epoch 062 - generator training loss: -0.1081, discriminator training loss: 0.3074, validation loss: 0.1136
2024-05-25 07:48:51 [INFO]: Epoch 063 - generator training loss: -0.1090, discriminator training loss: 0.3076, validation loss: 0.1132
2024-05-25 07:48:55 [INFO]: Epoch 064 - generator training loss: -0.1082, discriminator training loss: 0.3071, validation loss: 0.1128
2024-05-25 07:48:59 [INFO]: Epoch 065 - generator training loss: -0.1087, discriminator training loss: 0.3066, validation loss: 0.1122
2024-05-25 07:49:03 [INFO]: Epoch 066 - generator training loss: -0.1101, discriminator training loss: 0.3062, validation loss: 0.1123
2024-05-25 07:49:08 [INFO]: Epoch 067 - generator training loss: -0.1110, discriminator training loss: 0.3061, validation loss: 0.1115
2024-05-25 07:49:12 [INFO]: Epoch 068 - generator training loss: -0.1102, discriminator training loss: 0.3065, validation loss: 0.1115
2024-05-25 07:49:16 [INFO]: Epoch 069 - generator training loss: -0.1112, discriminator training loss: 0.3055, validation loss: 0.1113
2024-05-25 07:49:20 [INFO]: Epoch 070 - generator training loss: -0.1104, discriminator training loss: 0.3057, validation loss: 0.1108
2024-05-25 07:49:24 [INFO]: Epoch 071 - generator training loss: -0.1103, discriminator training loss: 0.3053, validation loss: 0.1106
2024-05-25 07:49:29 [INFO]: Epoch 072 - generator training loss: -0.1116, discriminator training loss: 0.3058, validation loss: 0.1105
2024-05-25 07:49:33 [INFO]: Epoch 073 - generator training loss: -0.1117, discriminator training loss: 0.3059, validation loss: 0.1104
2024-05-25 07:49:37 [INFO]: Epoch 074 - generator training loss: -0.1131, discriminator training loss: 0.3053, validation loss: 0.1100
2024-05-25 07:49:41 [INFO]: Epoch 075 - generator training loss: -0.1124, discriminator training loss: 0.3046, validation loss: 0.1102
2024-05-25 07:49:45 [INFO]: Epoch 076 - generator training loss: -0.1129, discriminator training loss: 0.3042, validation loss: 0.1097
2024-05-25 07:49:50 [INFO]: Epoch 077 - generator training loss: -0.1139, discriminator training loss: 0.3044, validation loss: 0.1092
2024-05-25 07:49:54 [INFO]: Epoch 078 - generator training loss: -0.1142, discriminator training loss: 0.3046, validation loss: 0.1090
2024-05-25 07:49:58 [INFO]: Epoch 079 - generator training loss: -0.1145, discriminator training loss: 0.3043, validation loss: 0.1088
2024-05-25 07:50:02 [INFO]: Epoch 080 - generator training loss: -0.1140, discriminator training loss: 0.3050, validation loss: 0.1095
2024-05-25 07:50:06 [INFO]: Epoch 081 - generator training loss: -0.1144, discriminator training loss: 0.3042, validation loss: 0.1087
2024-05-25 07:50:11 [INFO]: Epoch 082 - generator training loss: -0.1160, discriminator training loss: 0.3032, validation loss: 0.1095
2024-05-25 07:50:15 [INFO]: Epoch 083 - generator training loss: -0.1158, discriminator training loss: 0.3035, validation loss: 0.1087
2024-05-25 07:50:19 [INFO]: Epoch 084 - generator training loss: -0.1160, discriminator training loss: 0.3034, validation loss: 0.1084
2024-05-25 07:50:23 [INFO]: Epoch 085 - generator training loss: -0.1161, discriminator training loss: 0.3035, validation loss: 0.1085
2024-05-25 07:50:27 [INFO]: Epoch 086 - generator training loss: -0.1167, discriminator training loss: 0.3030, validation loss: 0.1085
2024-05-25 07:50:32 [INFO]: Epoch 087 - generator training loss: -0.1162, discriminator training loss: 0.3029, validation loss: 0.1077
2024-05-25 07:50:36 [INFO]: Epoch 088 - generator training loss: -0.1170, discriminator training loss: 0.3030, validation loss: 0.1083
2024-05-25 07:50:40 [INFO]: Epoch 089 - generator training loss: -0.1175, discriminator training loss: 0.3029, validation loss: 0.1082
2024-05-25 07:50:44 [INFO]: Epoch 090 - generator training loss: -0.1172, discriminator training loss: 0.3024, validation loss: 0.1080
2024-05-25 07:50:48 [INFO]: Epoch 091 - generator training loss: -0.1176, discriminator training loss: 0.3030, validation loss: 0.1078
2024-05-25 07:50:53 [INFO]: Epoch 092 - generator training loss: -0.1183, discriminator training loss: 0.3027, validation loss: 0.1076
2024-05-25 07:50:57 [INFO]: Epoch 093 - generator training loss: -0.1181, discriminator training loss: 0.3026, validation loss: 0.1072
2024-05-25 07:51:01 [INFO]: Epoch 094 - generator training loss: -0.1182, discriminator training loss: 0.3018, validation loss: 0.1075
2024-05-25 07:51:05 [INFO]: Epoch 095 - generator training loss: -0.1187, discriminator training loss: 0.3023, validation loss: 0.1078
2024-05-25 07:51:10 [INFO]: Epoch 096 - generator training loss: -0.1186, discriminator training loss: 0.3009, validation loss: 0.1074
2024-05-25 07:51:14 [INFO]: Epoch 097 - generator training loss: -0.1188, discriminator training loss: 0.3017, validation loss: 0.1071
2024-05-25 07:51:18 [INFO]: Epoch 098 - generator training loss: -0.1194, discriminator training loss: 0.3014, validation loss: 0.1073
2024-05-25 07:51:22 [INFO]: Epoch 099 - generator training loss: -0.1199, discriminator training loss: 0.3012, validation loss: 0.1078
2024-05-25 07:51:26 [INFO]: Epoch 100 - generator training loss: -0.1196, discriminator training loss: 0.3018, validation loss: 0.1070
2024-05-25 07:51:31 [INFO]: Epoch 101 - generator training loss: -0.1195, discriminator training loss: 0.3008, validation loss: 0.1075
2024-05-25 07:51:35 [INFO]: Epoch 102 - generator training loss: -0.1196, discriminator training loss: 0.3013, validation loss: 0.1065
2024-05-25 07:51:39 [INFO]: Epoch 103 - generator training loss: -0.1204, discriminator training loss: 0.3010, validation loss: 0.1069
2024-05-25 07:51:43 [INFO]: Epoch 104 - generator training loss: -0.1213, discriminator training loss: 0.3008, validation loss: 0.1070
2024-05-25 07:51:47 [INFO]: Epoch 105 - generator training loss: -0.1215, discriminator training loss: 0.3003, validation loss: 0.1070
2024-05-25 07:51:52 [INFO]: Epoch 106 - generator training loss: -0.1206, discriminator training loss: 0.3006, validation loss: 0.1064
2024-05-25 07:51:56 [INFO]: Epoch 107 - generator training loss: -0.1211, discriminator training loss: 0.3007, validation loss: 0.1071
2024-05-25 07:52:00 [INFO]: Epoch 108 - generator training loss: -0.1219, discriminator training loss: 0.3003, validation loss: 0.1065
2024-05-25 07:52:04 [INFO]: Epoch 109 - generator training loss: -0.1213, discriminator training loss: 0.3001, validation loss: 0.1068
2024-05-25 07:52:09 [INFO]: Epoch 110 - generator training loss: -0.1224, discriminator training loss: 0.2996, validation loss: 0.1068
2024-05-25 07:52:13 [INFO]: Epoch 111 - generator training loss: -0.1220, discriminator training loss: 0.2999, validation loss: 0.1068
2024-05-25 07:52:17 [INFO]: Epoch 112 - generator training loss: -0.1230, discriminator training loss: 0.2997, validation loss: 0.1065
2024-05-25 07:52:21 [INFO]: Epoch 113 - generator training loss: -0.1220, discriminator training loss: 0.3001, validation loss: 0.1061
2024-05-25 07:52:25 [INFO]: Epoch 114 - generator training loss: -0.1226, discriminator training loss: 0.2998, validation loss: 0.1063
2024-05-25 07:52:30 [INFO]: Epoch 115 - generator training loss: -0.1236, discriminator training loss: 0.2999, validation loss: 0.1071
2024-05-25 07:52:34 [INFO]: Epoch 116 - generator training loss: -0.1237, discriminator training loss: 0.2992, validation loss: 0.1065
2024-05-25 07:52:38 [INFO]: Epoch 117 - generator training loss: -0.1222, discriminator training loss: 0.2995, validation loss: 0.1072
2024-05-25 07:52:42 [INFO]: Epoch 118 - generator training loss: -0.1230, discriminator training loss: 0.2993, validation loss: 0.1062
2024-05-25 07:52:46 [INFO]: Epoch 119 - generator training loss: -0.1233, discriminator training loss: 0.2987, validation loss: 0.1066
2024-05-25 07:52:51 [INFO]: Epoch 120 - generator training loss: -0.1239, discriminator training loss: 0.2992, validation loss: 0.1059
2024-05-25 07:52:55 [INFO]: Epoch 121 - generator training loss: -0.1234, discriminator training loss: 0.2989, validation loss: 0.1062
2024-05-25 07:52:59 [INFO]: Epoch 122 - generator training loss: -0.1235, discriminator training loss: 0.2986, validation loss: 0.1064
2024-05-25 07:53:03 [INFO]: Epoch 123 - generator training loss: -0.1249, discriminator training loss: 0.2987, validation loss: 0.1061
2024-05-25 07:53:08 [INFO]: Epoch 124 - generator training loss: -0.1237, discriminator training loss: 0.2990, validation loss: 0.1061
2024-05-25 07:53:12 [INFO]: Epoch 125 - generator training loss: -0.1244, discriminator training loss: 0.2988, validation loss: 0.1060
2024-05-25 07:53:16 [INFO]: Epoch 126 - generator training loss: -0.1251, discriminator training loss: 0.2981, validation loss: 0.1059
2024-05-25 07:53:20 [INFO]: Epoch 127 - generator training loss: -0.1254, discriminator training loss: 0.2984, validation loss: 0.1059
2024-05-25 07:53:24 [INFO]: Epoch 128 - generator training loss: -0.1261, discriminator training loss: 0.2982, validation loss: 0.1060
2024-05-25 07:53:29 [INFO]: Epoch 129 - generator training loss: -0.1251, discriminator training loss: 0.2981, validation loss: 0.1056
2024-05-25 07:53:33 [INFO]: Epoch 130 - generator training loss: -0.1260, discriminator training loss: 0.2975, validation loss: 0.1065
2024-05-25 07:53:37 [INFO]: Epoch 131 - generator training loss: -0.1255, discriminator training loss: 0.2973, validation loss: 0.1058
2024-05-25 07:53:41 [INFO]: Epoch 132 - generator training loss: -0.1254, discriminator training loss: 0.2971, validation loss: 0.1056
2024-05-25 07:53:45 [INFO]: Epoch 133 - generator training loss: -0.1256, discriminator training loss: 0.2974, validation loss: 0.1056
2024-05-25 07:53:50 [INFO]: Epoch 134 - generator training loss: -0.1258, discriminator training loss: 0.2971, validation loss: 0.1058
2024-05-25 07:53:54 [INFO]: Epoch 135 - generator training loss: -0.1266, discriminator training loss: 0.2977, validation loss: 0.1060
2024-05-25 07:53:58 [INFO]: Epoch 136 - generator training loss: -0.1252, discriminator training loss: 0.2980, validation loss: 0.1054
2024-05-25 07:54:02 [INFO]: Epoch 137 - generator training loss: -0.1262, discriminator training loss: 0.2974, validation loss: 0.1054
2024-05-25 07:54:06 [INFO]: Epoch 138 - generator training loss: -0.1264, discriminator training loss: 0.2971, validation loss: 0.1056
2024-05-25 07:54:11 [INFO]: Epoch 139 - generator training loss: -0.1253, discriminator training loss: 0.2980, validation loss: 0.1061
2024-05-25 07:54:15 [INFO]: Epoch 140 - generator training loss: -0.1248, discriminator training loss: 0.2972, validation loss: 0.1059
2024-05-25 07:54:19 [INFO]: Epoch 141 - generator training loss: -0.1257, discriminator training loss: 0.2968, validation loss: 0.1056
2024-05-25 07:54:23 [INFO]: Epoch 142 - generator training loss: -0.1261, discriminator training loss: 0.2974, validation loss: 0.1052
2024-05-25 07:54:28 [INFO]: Epoch 143 - generator training loss: -0.1266, discriminator training loss: 0.2970, validation loss: 0.1055
2024-05-25 07:54:32 [INFO]: Epoch 144 - generator training loss: -0.1271, discriminator training loss: 0.2965, validation loss: 0.1056
2024-05-25 07:54:36 [INFO]: Epoch 145 - generator training loss: -0.1273, discriminator training loss: 0.2963, validation loss: 0.1050
2024-05-25 07:54:40 [INFO]: Epoch 146 - generator training loss: -0.1272, discriminator training loss: 0.2969, validation loss: 0.1059
2024-05-25 07:54:44 [INFO]: Epoch 147 - generator training loss: -0.1271, discriminator training loss: 0.2960, validation loss: 0.1054
2024-05-25 07:54:49 [INFO]: Epoch 148 - generator training loss: -0.1272, discriminator training loss: 0.2964, validation loss: 0.1062
2024-05-25 07:54:53 [INFO]: Epoch 149 - generator training loss: -0.1276, discriminator training loss: 0.2965, validation loss: 0.1056
2024-05-25 07:54:57 [INFO]: Epoch 150 - generator training loss: -0.1279, discriminator training loss: 0.2961, validation loss: 0.1052
2024-05-25 07:55:01 [INFO]: Epoch 151 - generator training loss: -0.1279, discriminator training loss: 0.2962, validation loss: 0.1054
2024-05-25 07:55:05 [INFO]: Epoch 152 - generator training loss: -0.1280, discriminator training loss: 0.2962, validation loss: 0.1057
2024-05-25 07:55:10 [INFO]: Epoch 153 - generator training loss: -0.1279, discriminator training loss: 0.2953, validation loss: 0.1054
2024-05-25 07:55:14 [INFO]: Epoch 154 - generator training loss: -0.1280, discriminator training loss: 0.2957, validation loss: 0.1056
2024-05-25 07:55:18 [INFO]: Epoch 155 - generator training loss: -0.1276, discriminator training loss: 0.2955, validation loss: 0.1057
2024-05-25 07:55:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:55:18 [INFO]: Finished training. The best model is from epoch#145.
2024-05-25 07:55:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/USGAN_air_quality/20240525_T074425/USGAN.pypots
2024-05-25 07:55:19 [INFO]: US-GAN on Air-Quality: MAE=0.1669, MSE=0.1452
2024-05-25 07:55:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/USGAN_air_quality/imputation.pkl
2024-05-25 07:55:19 [INFO]: Using the given device: cuda:0
2024-05-25 07:55:19 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/BRITS_air_quality/20240525_T075519
2024-05-25 07:55:19 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/BRITS_air_quality/20240525_T075519/tensorboard
2024-05-25 07:55:19 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 07:55:22 [INFO]: Epoch 001 - training loss: 1.4077, validation loss: 0.9434
2024-05-25 07:55:25 [INFO]: Epoch 002 - training loss: 1.1631, validation loss: 0.6954
2024-05-25 07:55:28 [INFO]: Epoch 003 - training loss: 0.9619, validation loss: 0.5788
2024-05-25 07:55:31 [INFO]: Epoch 004 - training loss: 0.8496, validation loss: 0.5075
2024-05-25 07:55:34 [INFO]: Epoch 005 - training loss: 0.7754, validation loss: 0.4609
2024-05-25 07:55:36 [INFO]: Epoch 006 - training loss: 0.7217, validation loss: 0.4243
2024-05-25 07:55:39 [INFO]: Epoch 007 - training loss: 0.6772, validation loss: 0.3943
2024-05-25 07:55:42 [INFO]: Epoch 008 - training loss: 0.6448, validation loss: 0.3704
2024-05-25 07:55:45 [INFO]: Epoch 009 - training loss: 0.6185, validation loss: 0.3514
2024-05-25 07:55:48 [INFO]: Epoch 010 - training loss: 0.5975, validation loss: 0.3361
2024-05-25 07:55:51 [INFO]: Epoch 011 - training loss: 0.5801, validation loss: 0.3228
2024-05-25 07:55:53 [INFO]: Epoch 012 - training loss: 0.5666, validation loss: 0.3110
2024-05-25 07:55:56 [INFO]: Epoch 013 - training loss: 0.5533, validation loss: 0.3008
2024-05-25 07:55:59 [INFO]: Epoch 014 - training loss: 0.5414, validation loss: 0.2919
2024-05-25 07:56:02 [INFO]: Epoch 015 - training loss: 0.5313, validation loss: 0.2844
2024-05-25 07:56:05 [INFO]: Epoch 016 - training loss: 0.5205, validation loss: 0.2771
2024-05-25 07:56:08 [INFO]: Epoch 017 - training loss: 0.5120, validation loss: 0.2706
2024-05-25 07:56:10 [INFO]: Epoch 018 - training loss: 0.5033, validation loss: 0.2646
2024-05-25 07:56:13 [INFO]: Epoch 019 - training loss: 0.4939, validation loss: 0.2599
2024-05-25 07:56:16 [INFO]: Epoch 020 - training loss: 0.4866, validation loss: 0.2545
2024-05-25 07:56:19 [INFO]: Epoch 021 - training loss: 0.4808, validation loss: 0.2496
2024-05-25 07:56:22 [INFO]: Epoch 022 - training loss: 0.4735, validation loss: 0.2454
2024-05-25 07:56:24 [INFO]: Epoch 023 - training loss: 0.4665, validation loss: 0.2413
2024-05-25 07:56:27 [INFO]: Epoch 024 - training loss: 0.4615, validation loss: 0.2372
2024-05-25 07:56:30 [INFO]: Epoch 025 - training loss: 0.4554, validation loss: 0.2332
2024-05-25 07:56:33 [INFO]: Epoch 026 - training loss: 0.4491, validation loss: 0.2289
2024-05-25 07:56:36 [INFO]: Epoch 027 - training loss: 0.4450, validation loss: 0.2259
2024-05-25 07:56:39 [INFO]: Epoch 028 - training loss: 0.4390, validation loss: 0.2225
2024-05-25 07:56:41 [INFO]: Epoch 029 - training loss: 0.4340, validation loss: 0.2193
2024-05-25 07:56:44 [INFO]: Epoch 030 - training loss: 0.4293, validation loss: 0.2163
2024-05-25 07:56:47 [INFO]: Epoch 031 - training loss: 0.4243, validation loss: 0.2133
2024-05-25 07:56:50 [INFO]: Epoch 032 - training loss: 0.4206, validation loss: 0.2104
2024-05-25 07:56:53 [INFO]: Epoch 033 - training loss: 0.4165, validation loss: 0.2077
2024-05-25 07:56:55 [INFO]: Epoch 034 - training loss: 0.4117, validation loss: 0.2048
2024-05-25 07:56:58 [INFO]: Epoch 035 - training loss: 0.4085, validation loss: 0.2025
2024-05-25 07:57:01 [INFO]: Epoch 036 - training loss: 0.4045, validation loss: 0.2000
2024-05-25 07:57:04 [INFO]: Epoch 037 - training loss: 0.4005, validation loss: 0.1977
2024-05-25 07:57:07 [INFO]: Epoch 038 - training loss: 0.3989, validation loss: 0.1953
2024-05-25 07:57:09 [INFO]: Epoch 039 - training loss: 0.3947, validation loss: 0.1926
2024-05-25 07:57:12 [INFO]: Epoch 040 - training loss: 0.3909, validation loss: 0.1907
2024-05-25 07:57:15 [INFO]: Epoch 041 - training loss: 0.3873, validation loss: 0.1887
2024-05-25 07:57:18 [INFO]: Epoch 042 - training loss: 0.3844, validation loss: 0.1863
2024-05-25 07:57:21 [INFO]: Epoch 043 - training loss: 0.3822, validation loss: 0.1843
2024-05-25 07:57:24 [INFO]: Epoch 044 - training loss: 0.3790, validation loss: 0.1827
2024-05-25 07:57:26 [INFO]: Epoch 045 - training loss: 0.3765, validation loss: 0.1807
2024-05-25 07:57:29 [INFO]: Epoch 046 - training loss: 0.3736, validation loss: 0.1789
2024-05-25 07:57:32 [INFO]: Epoch 047 - training loss: 0.3709, validation loss: 0.1774
2024-05-25 07:57:35 [INFO]: Epoch 048 - training loss: 0.3688, validation loss: 0.1757
2024-05-25 07:57:38 [INFO]: Epoch 049 - training loss: 0.3670, validation loss: 0.1741
2024-05-25 07:57:40 [INFO]: Epoch 050 - training loss: 0.3653, validation loss: 0.1726
2024-05-25 07:57:43 [INFO]: Epoch 051 - training loss: 0.3618, validation loss: 0.1709
2024-05-25 07:57:46 [INFO]: Epoch 052 - training loss: 0.3595, validation loss: 0.1697
2024-05-25 07:57:49 [INFO]: Epoch 053 - training loss: 0.3581, validation loss: 0.1681
2024-05-25 07:57:52 [INFO]: Epoch 054 - training loss: 0.3561, validation loss: 0.1668
2024-05-25 07:57:55 [INFO]: Epoch 055 - training loss: 0.3538, validation loss: 0.1655
2024-05-25 07:57:57 [INFO]: Epoch 056 - training loss: 0.3518, validation loss: 0.1647
2024-05-25 07:58:00 [INFO]: Epoch 057 - training loss: 0.3497, validation loss: 0.1633
2024-05-25 07:58:03 [INFO]: Epoch 058 - training loss: 0.3486, validation loss: 0.1622
2024-05-25 07:58:06 [INFO]: Epoch 059 - training loss: 0.3467, validation loss: 0.1612
2024-05-25 07:58:09 [INFO]: Epoch 060 - training loss: 0.3452, validation loss: 0.1603
2024-05-25 07:58:12 [INFO]: Epoch 061 - training loss: 0.3434, validation loss: 0.1591
2024-05-25 07:58:14 [INFO]: Epoch 062 - training loss: 0.3416, validation loss: 0.1586
2024-05-25 07:58:17 [INFO]: Epoch 063 - training loss: 0.3405, validation loss: 0.1575
2024-05-25 07:58:20 [INFO]: Epoch 064 - training loss: 0.3392, validation loss: 0.1568
2024-05-25 07:58:23 [INFO]: Epoch 065 - training loss: 0.3375, validation loss: 0.1561
2024-05-25 07:58:26 [INFO]: Epoch 066 - training loss: 0.3364, validation loss: 0.1552
2024-05-25 07:58:28 [INFO]: Epoch 067 - training loss: 0.3343, validation loss: 0.1545
2024-05-25 07:58:31 [INFO]: Epoch 068 - training loss: 0.3343, validation loss: 0.1538
2024-05-25 07:58:34 [INFO]: Epoch 069 - training loss: 0.3319, validation loss: 0.1531
2024-05-25 07:58:37 [INFO]: Epoch 070 - training loss: 0.3303, validation loss: 0.1523
2024-05-25 07:58:40 [INFO]: Epoch 071 - training loss: 0.3308, validation loss: 0.1516
2024-05-25 07:58:43 [INFO]: Epoch 072 - training loss: 0.3290, validation loss: 0.1513
2024-05-25 07:58:45 [INFO]: Epoch 073 - training loss: 0.3272, validation loss: 0.1505
2024-05-25 07:58:48 [INFO]: Epoch 074 - training loss: 0.3252, validation loss: 0.1501
2024-05-25 07:58:51 [INFO]: Epoch 075 - training loss: 0.3246, validation loss: 0.1494
2024-05-25 07:58:54 [INFO]: Epoch 076 - training loss: 0.3235, validation loss: 0.1487
2024-05-25 07:58:57 [INFO]: Epoch 077 - training loss: 0.3225, validation loss: 0.1484
2024-05-25 07:58:59 [INFO]: Epoch 078 - training loss: 0.3225, validation loss: 0.1481
2024-05-25 07:59:02 [INFO]: Epoch 079 - training loss: 0.3208, validation loss: 0.1475
2024-05-25 07:59:05 [INFO]: Epoch 080 - training loss: 0.3203, validation loss: 0.1469
2024-05-25 07:59:08 [INFO]: Epoch 081 - training loss: 0.3184, validation loss: 0.1464
2024-05-25 07:59:11 [INFO]: Epoch 082 - training loss: 0.3184, validation loss: 0.1459
2024-05-25 07:59:13 [INFO]: Epoch 083 - training loss: 0.3180, validation loss: 0.1456
2024-05-25 07:59:16 [INFO]: Epoch 084 - training loss: 0.3161, validation loss: 0.1449
2024-05-25 07:59:19 [INFO]: Epoch 085 - training loss: 0.3159, validation loss: 0.1448
2024-05-25 07:59:22 [INFO]: Epoch 086 - training loss: 0.3146, validation loss: 0.1444
2024-05-25 07:59:25 [INFO]: Epoch 087 - training loss: 0.3138, validation loss: 0.1441
2024-05-25 07:59:28 [INFO]: Epoch 088 - training loss: 0.3126, validation loss: 0.1435
2024-05-25 07:59:30 [INFO]: Epoch 089 - training loss: 0.3127, validation loss: 0.1430
2024-05-25 07:59:33 [INFO]: Epoch 090 - training loss: 0.3119, validation loss: 0.1427
2024-05-25 07:59:36 [INFO]: Epoch 091 - training loss: 0.3112, validation loss: 0.1424
2024-05-25 07:59:39 [INFO]: Epoch 092 - training loss: 0.3104, validation loss: 0.1421
2024-05-25 07:59:42 [INFO]: Epoch 093 - training loss: 0.3090, validation loss: 0.1416
2024-05-25 07:59:44 [INFO]: Epoch 094 - training loss: 0.3093, validation loss: 0.1411
2024-05-25 07:59:47 [INFO]: Epoch 095 - training loss: 0.3075, validation loss: 0.1407
2024-05-25 07:59:50 [INFO]: Epoch 096 - training loss: 0.3080, validation loss: 0.1404
2024-05-25 07:59:53 [INFO]: Epoch 097 - training loss: 0.3067, validation loss: 0.1399
2024-05-25 07:59:56 [INFO]: Epoch 098 - training loss: 0.3063, validation loss: 0.1398
2024-05-25 07:59:59 [INFO]: Epoch 099 - training loss: 0.3056, validation loss: 0.1394
2024-05-25 08:00:01 [INFO]: Epoch 100 - training loss: 0.3049, validation loss: 0.1392
2024-05-25 08:00:04 [INFO]: Epoch 101 - training loss: 0.3040, validation loss: 0.1390
2024-05-25 08:00:07 [INFO]: Epoch 102 - training loss: 0.3036, validation loss: 0.1384
2024-05-25 08:00:10 [INFO]: Epoch 103 - training loss: 0.3026, validation loss: 0.1380
2024-05-25 08:00:13 [INFO]: Epoch 104 - training loss: 0.3025, validation loss: 0.1377
2024-05-25 08:00:16 [INFO]: Epoch 105 - training loss: 0.3020, validation loss: 0.1374
2024-05-25 08:00:18 [INFO]: Epoch 106 - training loss: 0.3009, validation loss: 0.1372
2024-05-25 08:00:21 [INFO]: Epoch 107 - training loss: 0.3006, validation loss: 0.1367
2024-05-25 08:00:24 [INFO]: Epoch 108 - training loss: 0.3005, validation loss: 0.1368
2024-05-25 08:00:27 [INFO]: Epoch 109 - training loss: 0.2996, validation loss: 0.1363
2024-05-25 08:00:30 [INFO]: Epoch 110 - training loss: 0.2985, validation loss: 0.1359
2024-05-25 08:00:32 [INFO]: Epoch 111 - training loss: 0.2979, validation loss: 0.1358
2024-05-25 08:00:35 [INFO]: Epoch 112 - training loss: 0.2977, validation loss: 0.1351
2024-05-25 08:00:38 [INFO]: Epoch 113 - training loss: 0.2973, validation loss: 0.1352
2024-05-25 08:00:41 [INFO]: Epoch 114 - training loss: 0.2967, validation loss: 0.1349
2024-05-25 08:00:44 [INFO]: Epoch 115 - training loss: 0.2959, validation loss: 0.1345
2024-05-25 08:00:46 [INFO]: Epoch 116 - training loss: 0.2959, validation loss: 0.1344
2024-05-25 08:00:49 [INFO]: Epoch 117 - training loss: 0.2961, validation loss: 0.1338
2024-05-25 08:00:52 [INFO]: Epoch 118 - training loss: 0.2953, validation loss: 0.1337
2024-05-25 08:00:55 [INFO]: Epoch 119 - training loss: 0.2957, validation loss: 0.1335
2024-05-25 08:00:58 [INFO]: Epoch 120 - training loss: 0.2942, validation loss: 0.1333
2024-05-25 08:01:01 [INFO]: Epoch 121 - training loss: 0.2935, validation loss: 0.1329
2024-05-25 08:01:03 [INFO]: Epoch 122 - training loss: 0.2930, validation loss: 0.1326
2024-05-25 08:01:06 [INFO]: Epoch 123 - training loss: 0.2926, validation loss: 0.1327
2024-05-25 08:01:09 [INFO]: Epoch 124 - training loss: 0.2923, validation loss: 0.1321
2024-05-25 08:01:12 [INFO]: Epoch 125 - training loss: 0.2916, validation loss: 0.1318
2024-05-25 08:01:15 [INFO]: Epoch 126 - training loss: 0.2918, validation loss: 0.1314
2024-05-25 08:01:17 [INFO]: Epoch 127 - training loss: 0.2905, validation loss: 0.1314
2024-05-25 08:01:20 [INFO]: Epoch 128 - training loss: 0.2904, validation loss: 0.1311
2024-05-25 08:01:23 [INFO]: Epoch 129 - training loss: 0.2900, validation loss: 0.1308
2024-05-25 08:01:26 [INFO]: Epoch 130 - training loss: 0.2895, validation loss: 0.1307
2024-05-25 08:01:29 [INFO]: Epoch 131 - training loss: 0.2889, validation loss: 0.1303
2024-05-25 08:01:32 [INFO]: Epoch 132 - training loss: 0.2892, validation loss: 0.1300
2024-05-25 08:01:34 [INFO]: Epoch 133 - training loss: 0.2883, validation loss: 0.1298
2024-05-25 08:01:37 [INFO]: Epoch 134 - training loss: 0.2877, validation loss: 0.1296
2024-05-25 08:01:40 [INFO]: Epoch 135 - training loss: 0.2872, validation loss: 0.1292
2024-05-25 08:01:43 [INFO]: Epoch 136 - training loss: 0.2875, validation loss: 0.1292
2024-05-25 08:01:46 [INFO]: Epoch 137 - training loss: 0.2872, validation loss: 0.1290
2024-05-25 08:01:48 [INFO]: Epoch 138 - training loss: 0.2860, validation loss: 0.1286
2024-05-25 08:01:51 [INFO]: Epoch 139 - training loss: 0.2857, validation loss: 0.1285
2024-05-25 08:01:54 [INFO]: Epoch 140 - training loss: 0.2853, validation loss: 0.1282
2024-05-25 08:01:57 [INFO]: Epoch 141 - training loss: 0.2856, validation loss: 0.1280
2024-05-25 08:02:00 [INFO]: Epoch 142 - training loss: 0.2848, validation loss: 0.1278
2024-05-25 08:02:02 [INFO]: Epoch 143 - training loss: 0.2843, validation loss: 0.1274
2024-05-25 08:02:05 [INFO]: Epoch 144 - training loss: 0.2840, validation loss: 0.1274
2024-05-25 08:02:08 [INFO]: Epoch 145 - training loss: 0.2841, validation loss: 0.1272
2024-05-25 08:02:11 [INFO]: Epoch 146 - training loss: 0.2838, validation loss: 0.1270
2024-05-25 08:02:14 [INFO]: Epoch 147 - training loss: 0.2831, validation loss: 0.1266
2024-05-25 08:02:17 [INFO]: Epoch 148 - training loss: 0.2829, validation loss: 0.1265
2024-05-25 08:02:20 [INFO]: Epoch 149 - training loss: 0.2820, validation loss: 0.1261
2024-05-25 08:02:22 [INFO]: Epoch 150 - training loss: 0.2819, validation loss: 0.1262
2024-05-25 08:02:25 [INFO]: Epoch 151 - training loss: 0.2817, validation loss: 0.1262
2024-05-25 08:02:28 [INFO]: Epoch 152 - training loss: 0.2813, validation loss: 0.1257
2024-05-25 08:02:31 [INFO]: Epoch 153 - training loss: 0.2807, validation loss: 0.1255
2024-05-25 08:02:34 [INFO]: Epoch 154 - training loss: 0.2808, validation loss: 0.1255
2024-05-25 08:02:36 [INFO]: Epoch 155 - training loss: 0.2803, validation loss: 0.1250
2024-05-25 08:02:39 [INFO]: Epoch 156 - training loss: 0.2802, validation loss: 0.1250
2024-05-25 08:02:42 [INFO]: Epoch 157 - training loss: 0.2803, validation loss: 0.1247
2024-05-25 08:02:45 [INFO]: Epoch 158 - training loss: 0.2795, validation loss: 0.1247
2024-05-25 08:02:48 [INFO]: Epoch 159 - training loss: 0.2789, validation loss: 0.1245
2024-05-25 08:02:50 [INFO]: Epoch 160 - training loss: 0.2792, validation loss: 0.1241
2024-05-25 08:02:53 [INFO]: Epoch 161 - training loss: 0.2788, validation loss: 0.1241
2024-05-25 08:02:56 [INFO]: Epoch 162 - training loss: 0.2779, validation loss: 0.1239
2024-05-25 08:02:59 [INFO]: Epoch 163 - training loss: 0.2778, validation loss: 0.1240
2024-05-25 08:03:02 [INFO]: Epoch 164 - training loss: 0.2776, validation loss: 0.1235
2024-05-25 08:03:05 [INFO]: Epoch 165 - training loss: 0.2769, validation loss: 0.1234
2024-05-25 08:03:07 [INFO]: Epoch 166 - training loss: 0.2766, validation loss: 0.1232
2024-05-25 08:03:10 [INFO]: Epoch 167 - training loss: 0.2768, validation loss: 0.1231
2024-05-25 08:03:13 [INFO]: Epoch 168 - training loss: 0.2764, validation loss: 0.1228
2024-05-25 08:03:16 [INFO]: Epoch 169 - training loss: 0.2762, validation loss: 0.1227
2024-05-25 08:03:19 [INFO]: Epoch 170 - training loss: 0.2755, validation loss: 0.1226
2024-05-25 08:03:21 [INFO]: Epoch 171 - training loss: 0.2754, validation loss: 0.1223
2024-05-25 08:03:24 [INFO]: Epoch 172 - training loss: 0.2751, validation loss: 0.1225
2024-05-25 08:03:27 [INFO]: Epoch 173 - training loss: 0.2754, validation loss: 0.1221
2024-05-25 08:03:30 [INFO]: Epoch 174 - training loss: 0.2748, validation loss: 0.1218
2024-05-25 08:03:33 [INFO]: Epoch 175 - training loss: 0.2744, validation loss: 0.1216
2024-05-25 08:03:36 [INFO]: Epoch 176 - training loss: 0.2740, validation loss: 0.1217
2024-05-25 08:03:38 [INFO]: Epoch 177 - training loss: 0.2745, validation loss: 0.1214
2024-05-25 08:03:41 [INFO]: Epoch 178 - training loss: 0.2737, validation loss: 0.1214
2024-05-25 08:03:44 [INFO]: Epoch 179 - training loss: 0.2734, validation loss: 0.1212
2024-05-25 08:03:47 [INFO]: Epoch 180 - training loss: 0.2734, validation loss: 0.1212
2024-05-25 08:03:50 [INFO]: Epoch 181 - training loss: 0.2727, validation loss: 0.1210
2024-05-25 08:03:52 [INFO]: Epoch 182 - training loss: 0.2726, validation loss: 0.1208
2024-05-25 08:03:55 [INFO]: Epoch 183 - training loss: 0.2724, validation loss: 0.1206
2024-05-25 08:03:58 [INFO]: Epoch 184 - training loss: 0.2724, validation loss: 0.1205
2024-05-25 08:04:01 [INFO]: Epoch 185 - training loss: 0.2723, validation loss: 0.1203
2024-05-25 08:04:04 [INFO]: Epoch 186 - training loss: 0.2721, validation loss: 0.1201
2024-05-25 08:04:07 [INFO]: Epoch 187 - training loss: 0.2719, validation loss: 0.1198
2024-05-25 08:04:09 [INFO]: Epoch 188 - training loss: 0.2714, validation loss: 0.1199
2024-05-25 08:04:12 [INFO]: Epoch 189 - training loss: 0.2714, validation loss: 0.1197
2024-05-25 08:04:15 [INFO]: Epoch 190 - training loss: 0.2714, validation loss: 0.1197
2024-05-25 08:04:18 [INFO]: Epoch 191 - training loss: 0.2704, validation loss: 0.1194
2024-05-25 08:04:21 [INFO]: Epoch 192 - training loss: 0.2701, validation loss: 0.1193
2024-05-25 08:04:24 [INFO]: Epoch 193 - training loss: 0.2697, validation loss: 0.1193
2024-05-25 08:04:26 [INFO]: Epoch 194 - training loss: 0.2695, validation loss: 0.1192
2024-05-25 08:04:29 [INFO]: Epoch 195 - training loss: 0.2692, validation loss: 0.1189
2024-05-25 08:04:32 [INFO]: Epoch 196 - training loss: 0.2689, validation loss: 0.1189
2024-05-25 08:04:35 [INFO]: Epoch 197 - training loss: 0.2697, validation loss: 0.1187
2024-05-25 08:04:38 [INFO]: Epoch 198 - training loss: 0.2692, validation loss: 0.1185
2024-05-25 08:04:40 [INFO]: Epoch 199 - training loss: 0.2683, validation loss: 0.1187
2024-05-25 08:04:43 [INFO]: Epoch 200 - training loss: 0.2682, validation loss: 0.1185
2024-05-25 08:04:46 [INFO]: Epoch 201 - training loss: 0.2684, validation loss: 0.1184
2024-05-25 08:04:49 [INFO]: Epoch 202 - training loss: 0.2676, validation loss: 0.1182
2024-05-25 08:04:52 [INFO]: Epoch 203 - training loss: 0.2681, validation loss: 0.1181
2024-05-25 08:04:54 [INFO]: Epoch 204 - training loss: 0.2674, validation loss: 0.1179
2024-05-25 08:04:57 [INFO]: Epoch 205 - training loss: 0.2674, validation loss: 0.1179
2024-05-25 08:05:00 [INFO]: Epoch 206 - training loss: 0.2669, validation loss: 0.1176
2024-05-25 08:05:03 [INFO]: Epoch 207 - training loss: 0.2669, validation loss: 0.1176
2024-05-25 08:05:06 [INFO]: Epoch 208 - training loss: 0.2668, validation loss: 0.1177
2024-05-25 08:05:09 [INFO]: Epoch 209 - training loss: 0.2667, validation loss: 0.1175
2024-05-25 08:05:11 [INFO]: Epoch 210 - training loss: 0.2664, validation loss: 0.1171
2024-05-25 08:05:14 [INFO]: Epoch 211 - training loss: 0.2660, validation loss: 0.1172
2024-05-25 08:05:17 [INFO]: Epoch 212 - training loss: 0.2657, validation loss: 0.1171
2024-05-25 08:05:20 [INFO]: Epoch 213 - training loss: 0.2658, validation loss: 0.1169
2024-05-25 08:05:23 [INFO]: Epoch 214 - training loss: 0.2656, validation loss: 0.1169
2024-05-25 08:05:25 [INFO]: Epoch 215 - training loss: 0.2653, validation loss: 0.1168
2024-05-25 08:05:28 [INFO]: Epoch 216 - training loss: 0.2650, validation loss: 0.1167
2024-05-25 08:05:31 [INFO]: Epoch 217 - training loss: 0.2652, validation loss: 0.1165
2024-05-25 08:05:34 [INFO]: Epoch 218 - training loss: 0.2649, validation loss: 0.1166
2024-05-25 08:05:37 [INFO]: Epoch 219 - training loss: 0.2646, validation loss: 0.1163
2024-05-25 08:05:40 [INFO]: Epoch 220 - training loss: 0.2640, validation loss: 0.1164
2024-05-25 08:05:42 [INFO]: Epoch 221 - training loss: 0.2642, validation loss: 0.1162
2024-05-25 08:05:45 [INFO]: Epoch 222 - training loss: 0.2645, validation loss: 0.1160
2024-05-25 08:05:48 [INFO]: Epoch 223 - training loss: 0.2639, validation loss: 0.1159
2024-05-25 08:05:51 [INFO]: Epoch 224 - training loss: 0.2639, validation loss: 0.1159
2024-05-25 08:05:54 [INFO]: Epoch 225 - training loss: 0.2638, validation loss: 0.1158
2024-05-25 08:05:56 [INFO]: Epoch 226 - training loss: 0.2630, validation loss: 0.1157
2024-05-25 08:05:59 [INFO]: Epoch 227 - training loss: 0.2630, validation loss: 0.1155
2024-05-25 08:06:02 [INFO]: Epoch 228 - training loss: 0.2629, validation loss: 0.1154
2024-05-25 08:06:05 [INFO]: Epoch 229 - training loss: 0.2630, validation loss: 0.1154
2024-05-25 08:06:08 [INFO]: Epoch 230 - training loss: 0.2622, validation loss: 0.1155
2024-05-25 08:06:10 [INFO]: Epoch 231 - training loss: 0.2619, validation loss: 0.1153
2024-05-25 08:06:13 [INFO]: Epoch 232 - training loss: 0.2627, validation loss: 0.1154
2024-05-25 08:06:16 [INFO]: Epoch 233 - training loss: 0.2624, validation loss: 0.1152
2024-05-25 08:06:19 [INFO]: Epoch 234 - training loss: 0.2620, validation loss: 0.1150
2024-05-25 08:06:22 [INFO]: Epoch 235 - training loss: 0.2620, validation loss: 0.1151
2024-05-25 08:06:25 [INFO]: Epoch 236 - training loss: 0.2618, validation loss: 0.1149
2024-05-25 08:06:27 [INFO]: Epoch 237 - training loss: 0.2610, validation loss: 0.1149
2024-05-25 08:06:30 [INFO]: Epoch 238 - training loss: 0.2606, validation loss: 0.1148
2024-05-25 08:06:33 [INFO]: Epoch 239 - training loss: 0.2611, validation loss: 0.1146
2024-05-25 08:06:36 [INFO]: Epoch 240 - training loss: 0.2609, validation loss: 0.1145
2024-05-25 08:06:39 [INFO]: Epoch 241 - training loss: 0.2606, validation loss: 0.1145
2024-05-25 08:06:42 [INFO]: Epoch 242 - training loss: 0.2603, validation loss: 0.1147
2024-05-25 08:06:44 [INFO]: Epoch 243 - training loss: 0.2606, validation loss: 0.1143
2024-05-25 08:06:47 [INFO]: Epoch 244 - training loss: 0.2599, validation loss: 0.1140
2024-05-25 08:06:50 [INFO]: Epoch 245 - training loss: 0.2600, validation loss: 0.1142
2024-05-25 08:06:53 [INFO]: Epoch 246 - training loss: 0.2598, validation loss: 0.1143
2024-05-25 08:06:56 [INFO]: Epoch 247 - training loss: 0.2597, validation loss: 0.1140
2024-05-25 08:06:58 [INFO]: Epoch 248 - training loss: 0.2590, validation loss: 0.1139
2024-05-25 08:07:01 [INFO]: Epoch 249 - training loss: 0.2595, validation loss: 0.1139
2024-05-25 08:07:04 [INFO]: Epoch 250 - training loss: 0.2590, validation loss: 0.1140
2024-05-25 08:07:07 [INFO]: Epoch 251 - training loss: 0.2586, validation loss: 0.1138
2024-05-25 08:07:10 [INFO]: Epoch 252 - training loss: 0.2587, validation loss: 0.1139
2024-05-25 08:07:13 [INFO]: Epoch 253 - training loss: 0.2582, validation loss: 0.1138
2024-05-25 08:07:15 [INFO]: Epoch 254 - training loss: 0.2591, validation loss: 0.1137
2024-05-25 08:07:18 [INFO]: Epoch 255 - training loss: 0.2579, validation loss: 0.1136
2024-05-25 08:07:21 [INFO]: Epoch 256 - training loss: 0.2587, validation loss: 0.1135
2024-05-25 08:07:24 [INFO]: Epoch 257 - training loss: 0.2580, validation loss: 0.1134
2024-05-25 08:07:27 [INFO]: Epoch 258 - training loss: 0.2580, validation loss: 0.1135
2024-05-25 08:07:29 [INFO]: Epoch 259 - training loss: 0.2575, validation loss: 0.1133
2024-05-25 08:07:32 [INFO]: Epoch 260 - training loss: 0.2575, validation loss: 0.1132
2024-05-25 08:07:35 [INFO]: Epoch 261 - training loss: 0.2575, validation loss: 0.1134
2024-05-25 08:07:38 [INFO]: Epoch 262 - training loss: 0.2569, validation loss: 0.1135
2024-05-25 08:07:41 [INFO]: Epoch 263 - training loss: 0.2572, validation loss: 0.1130
2024-05-25 08:07:43 [INFO]: Epoch 264 - training loss: 0.2566, validation loss: 0.1130
2024-05-25 08:07:46 [INFO]: Epoch 265 - training loss: 0.2565, validation loss: 0.1130
2024-05-25 08:07:49 [INFO]: Epoch 266 - training loss: 0.2564, validation loss: 0.1129
2024-05-25 08:07:52 [INFO]: Epoch 267 - training loss: 0.2559, validation loss: 0.1128
2024-05-25 08:07:55 [INFO]: Epoch 268 - training loss: 0.2566, validation loss: 0.1129
2024-05-25 08:07:58 [INFO]: Epoch 269 - training loss: 0.2558, validation loss: 0.1129
2024-05-25 08:08:00 [INFO]: Epoch 270 - training loss: 0.2562, validation loss: 0.1127
2024-05-25 08:08:03 [INFO]: Epoch 271 - training loss: 0.2558, validation loss: 0.1128
2024-05-25 08:08:06 [INFO]: Epoch 272 - training loss: 0.2563, validation loss: 0.1128
2024-05-25 08:08:09 [INFO]: Epoch 273 - training loss: 0.2559, validation loss: 0.1127
2024-05-25 08:08:12 [INFO]: Epoch 274 - training loss: 0.2560, validation loss: 0.1125
2024-05-25 08:08:14 [INFO]: Epoch 275 - training loss: 0.2555, validation loss: 0.1125
2024-05-25 08:08:17 [INFO]: Epoch 276 - training loss: 0.2555, validation loss: 0.1126
2024-05-25 08:08:20 [INFO]: Epoch 277 - training loss: 0.2552, validation loss: 0.1123
2024-05-25 08:08:23 [INFO]: Epoch 278 - training loss: 0.2543, validation loss: 0.1123
2024-05-25 08:08:26 [INFO]: Epoch 279 - training loss: 0.2545, validation loss: 0.1122
2024-05-25 08:08:29 [INFO]: Epoch 280 - training loss: 0.2548, validation loss: 0.1124
2024-05-25 08:08:31 [INFO]: Epoch 281 - training loss: 0.2547, validation loss: 0.1123
2024-05-25 08:08:34 [INFO]: Epoch 282 - training loss: 0.2548, validation loss: 0.1120
2024-05-25 08:08:37 [INFO]: Epoch 283 - training loss: 0.2540, validation loss: 0.1121
2024-05-25 08:08:40 [INFO]: Epoch 284 - training loss: 0.2548, validation loss: 0.1122
2024-05-25 08:08:43 [INFO]: Epoch 285 - training loss: 0.2537, validation loss: 0.1120
2024-05-25 08:08:46 [INFO]: Epoch 286 - training loss: 0.2541, validation loss: 0.1118
2024-05-25 08:08:48 [INFO]: Epoch 287 - training loss: 0.2539, validation loss: 0.1119
2024-05-25 08:08:51 [INFO]: Epoch 288 - training loss: 0.2534, validation loss: 0.1119
2024-05-25 08:08:54 [INFO]: Epoch 289 - training loss: 0.2540, validation loss: 0.1119
2024-05-25 08:08:57 [INFO]: Epoch 290 - training loss: 0.2535, validation loss: 0.1118
2024-05-25 08:09:00 [INFO]: Epoch 291 - training loss: 0.2534, validation loss: 0.1118
2024-05-25 08:09:02 [INFO]: Epoch 292 - training loss: 0.2535, validation loss: 0.1117
2024-05-25 08:09:05 [INFO]: Epoch 293 - training loss: 0.2529, validation loss: 0.1117
2024-05-25 08:09:08 [INFO]: Epoch 294 - training loss: 0.2528, validation loss: 0.1118
2024-05-25 08:09:11 [INFO]: Epoch 295 - training loss: 0.2528, validation loss: 0.1117
2024-05-25 08:09:14 [INFO]: Epoch 296 - training loss: 0.2524, validation loss: 0.1116
2024-05-25 08:09:17 [INFO]: Epoch 297 - training loss: 0.2522, validation loss: 0.1116
2024-05-25 08:09:19 [INFO]: Epoch 298 - training loss: 0.2522, validation loss: 0.1115
2024-05-25 08:09:22 [INFO]: Epoch 299 - training loss: 0.2519, validation loss: 0.1115
2024-05-25 08:09:25 [INFO]: Epoch 300 - training loss: 0.2518, validation loss: 0.1115
2024-05-25 08:09:25 [INFO]: Finished training. The best model is from epoch#299.
2024-05-25 08:09:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/BRITS_air_quality/20240525_T075519/BRITS.pypots
2024-05-25 08:09:26 [INFO]: BRITS on Air-Quality: MAE=0.1532, MSE=0.1497
2024-05-25 08:09:26 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/BRITS_air_quality/imputation.pkl
2024-05-25 08:09:26 [INFO]: Using the given device: cuda:0
2024-05-25 08:09:26 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926
2024-05-25 08:09:26 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/tensorboard
2024-05-25 08:09:26 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 08:09:30 [INFO]: Epoch 001 - training loss: 1.4512, validation loss: 0.7960
2024-05-25 08:09:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch1_loss0.7960480123758316.pypots
2024-05-25 08:09:34 [INFO]: Epoch 002 - training loss: 1.0072, validation loss: 0.7404
2024-05-25 08:09:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch2_loss0.7404453963041305.pypots
2024-05-25 08:09:38 [INFO]: Epoch 003 - training loss: 0.9432, validation loss: 0.7131
2024-05-25 08:09:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch3_loss0.7130927592515945.pypots
2024-05-25 08:09:42 [INFO]: Epoch 004 - training loss: 0.9015, validation loss: 0.6999
2024-05-25 08:09:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch4_loss0.6999153524637223.pypots
2024-05-25 08:09:46 [INFO]: Epoch 005 - training loss: 0.8852, validation loss: 0.6893
2024-05-25 08:09:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch5_loss0.6892808705568314.pypots
2024-05-25 08:09:50 [INFO]: Epoch 006 - training loss: 0.8785, validation loss: 0.6821
2024-05-25 08:09:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch6_loss0.6820545554161072.pypots
2024-05-25 08:09:54 [INFO]: Epoch 007 - training loss: 0.8708, validation loss: 0.6772
2024-05-25 08:09:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch7_loss0.6772043943405152.pypots
2024-05-25 08:09:57 [INFO]: Epoch 008 - training loss: 0.8506, validation loss: 0.6728
2024-05-25 08:09:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch8_loss0.6728375136852265.pypots
2024-05-25 08:10:01 [INFO]: Epoch 009 - training loss: 0.8537, validation loss: 0.6694
2024-05-25 08:10:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch9_loss0.669402539730072.pypots
2024-05-25 08:10:05 [INFO]: Epoch 010 - training loss: 0.8545, validation loss: 0.6669
2024-05-25 08:10:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch10_loss0.6669454514980316.pypots
2024-05-25 08:10:09 [INFO]: Epoch 011 - training loss: 0.8413, validation loss: 0.6652
2024-05-25 08:10:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch11_loss0.6652320891618728.pypots
2024-05-25 08:10:13 [INFO]: Epoch 012 - training loss: 0.8354, validation loss: 0.6639
2024-05-25 08:10:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch12_loss0.6638853281736374.pypots
2024-05-25 08:10:17 [INFO]: Epoch 013 - training loss: 0.8399, validation loss: 0.6625
2024-05-25 08:10:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch13_loss0.6625403851270676.pypots
2024-05-25 08:10:21 [INFO]: Epoch 014 - training loss: 0.8234, validation loss: 0.6618
2024-05-25 08:10:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch14_loss0.6617783039808274.pypots
2024-05-25 08:10:24 [INFO]: Epoch 015 - training loss: 0.8158, validation loss: 0.6609
2024-05-25 08:10:24 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch15_loss0.6609440565109252.pypots
2024-05-25 08:10:28 [INFO]: Epoch 016 - training loss: 0.8148, validation loss: 0.6612
2024-05-25 08:10:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch16_loss0.6612466782331466.pypots
2024-05-25 08:10:32 [INFO]: Epoch 017 - training loss: 0.8132, validation loss: 0.6605
2024-05-25 08:10:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch17_loss0.6605291694402695.pypots
2024-05-25 08:10:36 [INFO]: Epoch 018 - training loss: 0.8185, validation loss: 0.6611
2024-05-25 08:10:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch18_loss0.6610598385334014.pypots
2024-05-25 08:10:40 [INFO]: Epoch 019 - training loss: 0.8243, validation loss: 0.6603
2024-05-25 08:10:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch19_loss0.6602961301803589.pypots
2024-05-25 08:10:44 [INFO]: Epoch 020 - training loss: 0.8146, validation loss: 0.6600
2024-05-25 08:10:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch20_loss0.6600097924470901.pypots
2024-05-25 08:10:48 [INFO]: Epoch 021 - training loss: 0.8137, validation loss: 0.6583
2024-05-25 08:10:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch21_loss0.658321875333786.pypots
2024-05-25 08:10:52 [INFO]: Epoch 022 - training loss: 0.8278, validation loss: 0.6617
2024-05-25 08:10:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch22_loss0.6616530358791352.pypots
2024-05-25 08:10:55 [INFO]: Epoch 023 - training loss: 0.8087, validation loss: 0.6619
2024-05-25 08:10:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch23_loss0.66193608045578.pypots
2024-05-25 08:10:59 [INFO]: Epoch 024 - training loss: 0.8107, validation loss: 0.6584
2024-05-25 08:10:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch24_loss0.6584258109331131.pypots
2024-05-25 08:11:03 [INFO]: Epoch 025 - training loss: 0.8103, validation loss: 0.6570
2024-05-25 08:11:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch25_loss0.6569713771343231.pypots
2024-05-25 08:11:07 [INFO]: Epoch 026 - training loss: 0.8058, validation loss: 0.6617
2024-05-25 08:11:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch26_loss0.6616515398025513.pypots
2024-05-25 08:11:11 [INFO]: Epoch 027 - training loss: 0.7968, validation loss: 0.6589
2024-05-25 08:11:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch27_loss0.6589037716388703.pypots
2024-05-25 08:11:15 [INFO]: Epoch 028 - training loss: 0.7939, validation loss: 0.6584
2024-05-25 08:11:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch28_loss0.6583905965089798.pypots
2024-05-25 08:11:19 [INFO]: Epoch 029 - training loss: 0.7955, validation loss: 0.6612
2024-05-25 08:11:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch29_loss0.6612315028905869.pypots
2024-05-25 08:11:23 [INFO]: Epoch 030 - training loss: 0.7860, validation loss: 0.6580
2024-05-25 08:11:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch30_loss0.6579664468765258.pypots
2024-05-25 08:11:26 [INFO]: Epoch 031 - training loss: 0.7873, validation loss: 0.6605
2024-05-25 08:11:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch31_loss0.6605386793613434.pypots
2024-05-25 08:11:30 [INFO]: Epoch 032 - training loss: 0.7897, validation loss: 0.6634
2024-05-25 08:11:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch32_loss0.6633896291255951.pypots
2024-05-25 08:11:34 [INFO]: Epoch 033 - training loss: 0.7957, validation loss: 0.6601
2024-05-25 08:11:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch33_loss0.6601337343454361.pypots
2024-05-25 08:11:38 [INFO]: Epoch 034 - training loss: 0.7915, validation loss: 0.6643
2024-05-25 08:11:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch34_loss0.6643158435821533.pypots
2024-05-25 08:11:42 [INFO]: Epoch 035 - training loss: 0.7814, validation loss: 0.6597
2024-05-25 08:11:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN_epoch35_loss0.6597353398799897.pypots
2024-05-25 08:11:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 08:11:42 [INFO]: Finished training. The best model is from epoch#25.
2024-05-25 08:11:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T080926/MRNN.pypots
2024-05-25 08:11:43 [INFO]: MRNN on Air-Quality: MAE=0.5229, MSE=0.6581
2024-05-25 08:11:43 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/MRNN_air_quality/imputation.pkl
2024-05-25 08:11:43 [INFO]: Using the given device: cpu
2024-05-25 08:11:43 [INFO]: LOCF on Air-Quality: MAE=0.2220, MSE=0.3375
2024-05-25 08:11:43 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_air_quality".
2024-05-25 08:11:43 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/LOCF_air_quality/imputation.pkl
2024-05-25 08:11:43 [INFO]: Median on Air-Quality: MAE=0.6640, MSE=1.0523
2024-05-25 08:11:43 [INFO]: Successfully created the given path "saved_results/round_4/Median_air_quality".
2024-05-25 08:11:43 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Median_air_quality/imputation.pkl
2024-05-25 08:11:43 [INFO]: Mean on Air-Quality: MAE=0.6951, MSE=0.9927
2024-05-25 08:11:43 [INFO]: Successfully created the given path "saved_results/round_4/Mean_air_quality".
2024-05-25 08:11:43 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Mean_air_quality/imputation.pkl
2024-05-25 08:11:43 [INFO]: 
SAITS on data_overlay_premask/air_quality: MAE=0.1620.0018125160983246554, MSE=0.1570.0013004552140160888
Transformer on data_overlay_premask/air_quality: MAE=0.1840.0013590951486336287, MSE=0.1870.001942017403062791
TimesNet on data_overlay_premask/air_quality: MAE=0.1740.0025420393298615043, MSE=0.2580.009647504998582237
CSDI on data_overlay_premask/air_quality: MAE=0.1110.0039010897704289398, MSE=0.1990.03901390216960416
GPVAE on data_overlay_premask/air_quality: MAE=0.2850.01749828869317839, MSE=0.2850.02529407555312904
USGAN on data_overlay_premask/air_quality: MAE=0.1670.0010697151932380692, MSE=0.1420.0023859959508875307
BRITS on data_overlay_premask/air_quality: MAE=0.1530.0002596247886007496, MSE=0.1500.0004979154299569751
MRNN on data_overlay_premask/air_quality: MAE=0.5220.0006694006175866915, MSE=0.6580.001098110402068912
LOCF on data_overlay_premask/air_quality: MAE=0.2222.7755575615628914e-17, MSE=0.3370.0
Median on data_overlay_premask/air_quality: MAE=0.6640.0, MSE=1.0520.0
Mean on data_overlay_premask/air_quality: MAE=0.6950.0, MSE=0.9930.0