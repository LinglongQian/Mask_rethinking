2024-05-25 03:14:33 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-25 03:14:33 [INFO]: Using the given device: cuda:0
2024-05-25 03:14:34 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/SAITS_ettm1/20240525_T031434
2024-05-25 03:14:34 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/SAITS_ettm1/20240525_T031434/tensorboard
2024-05-25 03:14:34 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 03:14:35 [INFO]: Epoch 001 - training loss: 1.2066, validation loss: 0.2706
2024-05-25 03:14:36 [INFO]: Epoch 002 - training loss: 0.9329, validation loss: 0.1456
2024-05-25 03:14:36 [INFO]: Epoch 003 - training loss: 0.7894, validation loss: 0.1032
2024-05-25 03:14:37 [INFO]: Epoch 004 - training loss: 0.7417, validation loss: 0.0923
2024-05-25 03:14:37 [INFO]: Epoch 005 - training loss: 0.7017, validation loss: 0.0911
2024-05-25 03:14:38 [INFO]: Epoch 006 - training loss: 0.6945, validation loss: 0.0752
2024-05-25 03:14:38 [INFO]: Epoch 007 - training loss: 0.6552, validation loss: 0.0684
2024-05-25 03:14:38 [INFO]: Epoch 008 - training loss: 0.6337, validation loss: 0.0739
2024-05-25 03:14:39 [INFO]: Epoch 009 - training loss: 0.6267, validation loss: 0.0699
2024-05-25 03:14:39 [INFO]: Epoch 010 - training loss: 0.6205, validation loss: 0.0713
2024-05-25 03:14:40 [INFO]: Epoch 011 - training loss: 0.5974, validation loss: 0.0751
2024-05-25 03:14:40 [INFO]: Epoch 012 - training loss: 0.5763, validation loss: 0.0664
2024-05-25 03:14:41 [INFO]: Epoch 013 - training loss: 0.5657, validation loss: 0.0575
2024-05-25 03:14:41 [INFO]: Epoch 014 - training loss: 0.5697, validation loss: 0.0592
2024-05-25 03:14:42 [INFO]: Epoch 015 - training loss: 0.5618, validation loss: 0.0580
2024-05-25 03:14:42 [INFO]: Epoch 016 - training loss: 0.5602, validation loss: 0.0454
2024-05-25 03:14:43 [INFO]: Epoch 017 - training loss: 0.5661, validation loss: 0.0451
2024-05-25 03:14:43 [INFO]: Epoch 018 - training loss: 0.5395, validation loss: 0.0424
2024-05-25 03:14:44 [INFO]: Epoch 019 - training loss: 0.5598, validation loss: 0.0529
2024-05-25 03:14:44 [INFO]: Epoch 020 - training loss: 0.5443, validation loss: 0.0523
2024-05-25 03:14:45 [INFO]: Epoch 021 - training loss: 0.5349, validation loss: 0.0519
2024-05-25 03:14:45 [INFO]: Epoch 022 - training loss: 0.5278, validation loss: 0.0405
2024-05-25 03:14:46 [INFO]: Epoch 023 - training loss: 0.5168, validation loss: 0.0559
2024-05-25 03:14:46 [INFO]: Epoch 024 - training loss: 0.5162, validation loss: 0.0472
2024-05-25 03:14:47 [INFO]: Epoch 025 - training loss: 0.5033, validation loss: 0.0481
2024-05-25 03:14:47 [INFO]: Epoch 026 - training loss: 0.5068, validation loss: 0.0427
2024-05-25 03:14:48 [INFO]: Epoch 027 - training loss: 0.4977, validation loss: 0.0442
2024-05-25 03:14:48 [INFO]: Epoch 028 - training loss: 0.4880, validation loss: 0.0536
2024-05-25 03:14:49 [INFO]: Epoch 029 - training loss: 0.4879, validation loss: 0.0394
2024-05-25 03:14:49 [INFO]: Epoch 030 - training loss: 0.4907, validation loss: 0.0462
2024-05-25 03:14:50 [INFO]: Epoch 031 - training loss: 0.5067, validation loss: 0.0397
2024-05-25 03:14:50 [INFO]: Epoch 032 - training loss: 0.4939, validation loss: 0.0544
2024-05-25 03:14:51 [INFO]: Epoch 033 - training loss: 0.4760, validation loss: 0.0438
2024-05-25 03:14:51 [INFO]: Epoch 034 - training loss: 0.4721, validation loss: 0.0350
2024-05-25 03:14:52 [INFO]: Epoch 035 - training loss: 0.4620, validation loss: 0.0407
2024-05-25 03:14:52 [INFO]: Epoch 036 - training loss: 0.4595, validation loss: 0.0436
2024-05-25 03:14:53 [INFO]: Epoch 037 - training loss: 0.4636, validation loss: 0.0331
2024-05-25 03:14:53 [INFO]: Epoch 038 - training loss: 0.4601, validation loss: 0.0373
2024-05-25 03:14:54 [INFO]: Epoch 039 - training loss: 0.4498, validation loss: 0.0346
2024-05-25 03:14:54 [INFO]: Epoch 040 - training loss: 0.4478, validation loss: 0.0429
2024-05-25 03:14:54 [INFO]: Epoch 041 - training loss: 0.4600, validation loss: 0.0627
2024-05-25 03:14:55 [INFO]: Epoch 042 - training loss: 0.4412, validation loss: 0.0377
2024-05-25 03:14:55 [INFO]: Epoch 043 - training loss: 0.4390, validation loss: 0.0445
2024-05-25 03:14:56 [INFO]: Epoch 044 - training loss: 0.4493, validation loss: 0.0385
2024-05-25 03:14:56 [INFO]: Epoch 045 - training loss: 0.4274, validation loss: 0.0471
2024-05-25 03:14:57 [INFO]: Epoch 046 - training loss: 0.4317, validation loss: 0.0419
2024-05-25 03:14:57 [INFO]: Epoch 047 - training loss: 0.4331, validation loss: 0.0398
2024-05-25 03:14:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:14:57 [INFO]: Finished training. The best model is from epoch#37.
2024-05-25 03:14:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/SAITS_ettm1/20240525_T031434/SAITS.pypots
2024-05-25 03:14:58 [INFO]: SAITS on ETTm1: MAE=0.1774, MSE=0.0596
2024-05-25 03:14:58 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/SAITS_ettm1/imputation.pkl
2024-05-25 03:14:58 [INFO]: Using the given device: cuda:0
2024-05-25 03:14:58 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/Transformer_ettm1/20240525_T031458
2024-05-25 03:14:58 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/Transformer_ettm1/20240525_T031458/tensorboard
2024-05-25 03:14:58 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 03:14:58 [INFO]: Epoch 001 - training loss: 1.1887, validation loss: 0.3384
2024-05-25 03:14:58 [INFO]: Epoch 002 - training loss: 0.7201, validation loss: 0.1933
2024-05-25 03:14:58 [INFO]: Epoch 003 - training loss: 0.5962, validation loss: 0.1514
2024-05-25 03:14:58 [INFO]: Epoch 004 - training loss: 0.5193, validation loss: 0.1021
2024-05-25 03:14:59 [INFO]: Epoch 005 - training loss: 0.4744, validation loss: 0.0896
2024-05-25 03:14:59 [INFO]: Epoch 006 - training loss: 0.4568, validation loss: 0.0834
2024-05-25 03:14:59 [INFO]: Epoch 007 - training loss: 0.4387, validation loss: 0.0770
2024-05-25 03:14:59 [INFO]: Epoch 008 - training loss: 0.4220, validation loss: 0.0697
2024-05-25 03:14:59 [INFO]: Epoch 009 - training loss: 0.4010, validation loss: 0.0669
2024-05-25 03:14:59 [INFO]: Epoch 010 - training loss: 0.3857, validation loss: 0.0629
2024-05-25 03:15:00 [INFO]: Epoch 011 - training loss: 0.3740, validation loss: 0.0579
2024-05-25 03:15:00 [INFO]: Epoch 012 - training loss: 0.3653, validation loss: 0.0557
2024-05-25 03:15:00 [INFO]: Epoch 013 - training loss: 0.3640, validation loss: 0.0540
2024-05-25 03:15:00 [INFO]: Epoch 014 - training loss: 0.3460, validation loss: 0.0500
2024-05-25 03:15:00 [INFO]: Epoch 015 - training loss: 0.3366, validation loss: 0.0475
2024-05-25 03:15:01 [INFO]: Epoch 016 - training loss: 0.3290, validation loss: 0.0518
2024-05-25 03:15:01 [INFO]: Epoch 017 - training loss: 0.3331, validation loss: 0.0484
2024-05-25 03:15:01 [INFO]: Epoch 018 - training loss: 0.3273, validation loss: 0.0456
2024-05-25 03:15:01 [INFO]: Epoch 019 - training loss: 0.3166, validation loss: 0.0495
2024-05-25 03:15:01 [INFO]: Epoch 020 - training loss: 0.3149, validation loss: 0.0477
2024-05-25 03:15:02 [INFO]: Epoch 021 - training loss: 0.3057, validation loss: 0.0422
2024-05-25 03:15:02 [INFO]: Epoch 022 - training loss: 0.2988, validation loss: 0.0414
2024-05-25 03:15:02 [INFO]: Epoch 023 - training loss: 0.2935, validation loss: 0.0446
2024-05-25 03:15:02 [INFO]: Epoch 024 - training loss: 0.2966, validation loss: 0.0477
2024-05-25 03:15:02 [INFO]: Epoch 025 - training loss: 0.3012, validation loss: 0.0446
2024-05-25 03:15:03 [INFO]: Epoch 026 - training loss: 0.2949, validation loss: 0.0413
2024-05-25 03:15:03 [INFO]: Epoch 027 - training loss: 0.2818, validation loss: 0.0405
2024-05-25 03:15:03 [INFO]: Epoch 028 - training loss: 0.2759, validation loss: 0.0408
2024-05-25 03:15:03 [INFO]: Epoch 029 - training loss: 0.2747, validation loss: 0.0408
2024-05-25 03:15:03 [INFO]: Epoch 030 - training loss: 0.2858, validation loss: 0.0395
2024-05-25 03:15:04 [INFO]: Epoch 031 - training loss: 0.2730, validation loss: 0.0354
2024-05-25 03:15:04 [INFO]: Epoch 032 - training loss: 0.2663, validation loss: 0.0367
2024-05-25 03:15:04 [INFO]: Epoch 033 - training loss: 0.2629, validation loss: 0.0388
2024-05-25 03:15:04 [INFO]: Epoch 034 - training loss: 0.2618, validation loss: 0.0354
2024-05-25 03:15:04 [INFO]: Epoch 035 - training loss: 0.2593, validation loss: 0.0350
2024-05-25 03:15:05 [INFO]: Epoch 036 - training loss: 0.2570, validation loss: 0.0353
2024-05-25 03:15:05 [INFO]: Epoch 037 - training loss: 0.2562, validation loss: 0.0330
2024-05-25 03:15:05 [INFO]: Epoch 038 - training loss: 0.2540, validation loss: 0.0331
2024-05-25 03:15:05 [INFO]: Epoch 039 - training loss: 0.2489, validation loss: 0.0332
2024-05-25 03:15:05 [INFO]: Epoch 040 - training loss: 0.2440, validation loss: 0.0319
2024-05-25 03:15:05 [INFO]: Epoch 041 - training loss: 0.2405, validation loss: 0.0318
2024-05-25 03:15:06 [INFO]: Epoch 042 - training loss: 0.2369, validation loss: 0.0309
2024-05-25 03:15:06 [INFO]: Epoch 043 - training loss: 0.2347, validation loss: 0.0317
2024-05-25 03:15:06 [INFO]: Epoch 044 - training loss: 0.2392, validation loss: 0.0291
2024-05-25 03:15:06 [INFO]: Epoch 045 - training loss: 0.2323, validation loss: 0.0295
2024-05-25 03:15:06 [INFO]: Epoch 046 - training loss: 0.2315, validation loss: 0.0314
2024-05-25 03:15:07 [INFO]: Epoch 047 - training loss: 0.2309, validation loss: 0.0321
2024-05-25 03:15:07 [INFO]: Epoch 048 - training loss: 0.2266, validation loss: 0.0295
2024-05-25 03:15:07 [INFO]: Epoch 049 - training loss: 0.2235, validation loss: 0.0295
2024-05-25 03:15:07 [INFO]: Epoch 050 - training loss: 0.2222, validation loss: 0.0324
2024-05-25 03:15:07 [INFO]: Epoch 051 - training loss: 0.2218, validation loss: 0.0361
2024-05-25 03:15:08 [INFO]: Epoch 052 - training loss: 0.2348, validation loss: 0.0291
2024-05-25 03:15:08 [INFO]: Epoch 053 - training loss: 0.2257, validation loss: 0.0289
2024-05-25 03:15:08 [INFO]: Epoch 054 - training loss: 0.2169, validation loss: 0.0330
2024-05-25 03:15:08 [INFO]: Epoch 055 - training loss: 0.2299, validation loss: 0.0288
2024-05-25 03:15:08 [INFO]: Epoch 056 - training loss: 0.2188, validation loss: 0.0275
2024-05-25 03:15:09 [INFO]: Epoch 057 - training loss: 0.2134, validation loss: 0.0292
2024-05-25 03:15:09 [INFO]: Epoch 058 - training loss: 0.2132, validation loss: 0.0269
2024-05-25 03:15:09 [INFO]: Epoch 059 - training loss: 0.2122, validation loss: 0.0274
2024-05-25 03:15:09 [INFO]: Epoch 060 - training loss: 0.2100, validation loss: 0.0285
2024-05-25 03:15:09 [INFO]: Epoch 061 - training loss: 0.2125, validation loss: 0.0291
2024-05-25 03:15:10 [INFO]: Epoch 062 - training loss: 0.2168, validation loss: 0.0300
2024-05-25 03:15:10 [INFO]: Epoch 063 - training loss: 0.2194, validation loss: 0.0261
2024-05-25 03:15:10 [INFO]: Epoch 064 - training loss: 0.2070, validation loss: 0.0274
2024-05-25 03:15:10 [INFO]: Epoch 065 - training loss: 0.2075, validation loss: 0.0270
2024-05-25 03:15:10 [INFO]: Epoch 066 - training loss: 0.2064, validation loss: 0.0287
2024-05-25 03:15:10 [INFO]: Epoch 067 - training loss: 0.2101, validation loss: 0.0272
2024-05-25 03:15:11 [INFO]: Epoch 068 - training loss: 0.2080, validation loss: 0.0266
2024-05-25 03:15:11 [INFO]: Epoch 069 - training loss: 0.2057, validation loss: 0.0302
2024-05-25 03:15:11 [INFO]: Epoch 070 - training loss: 0.2102, validation loss: 0.0275
2024-05-25 03:15:11 [INFO]: Epoch 071 - training loss: 0.2060, validation loss: 0.0274
2024-05-25 03:15:11 [INFO]: Epoch 072 - training loss: 0.2004, validation loss: 0.0256
2024-05-25 03:15:12 [INFO]: Epoch 073 - training loss: 0.1974, validation loss: 0.0257
2024-05-25 03:15:12 [INFO]: Epoch 074 - training loss: 0.1952, validation loss: 0.0242
2024-05-25 03:15:12 [INFO]: Epoch 075 - training loss: 0.1959, validation loss: 0.0267
2024-05-25 03:15:12 [INFO]: Epoch 076 - training loss: 0.1976, validation loss: 0.0245
2024-05-25 03:15:12 [INFO]: Epoch 077 - training loss: 0.1936, validation loss: 0.0248
2024-05-25 03:15:13 [INFO]: Epoch 078 - training loss: 0.1946, validation loss: 0.0281
2024-05-25 03:15:13 [INFO]: Epoch 079 - training loss: 0.1968, validation loss: 0.0305
2024-05-25 03:15:13 [INFO]: Epoch 080 - training loss: 0.2008, validation loss: 0.0264
2024-05-25 03:15:13 [INFO]: Epoch 081 - training loss: 0.1952, validation loss: 0.0241
2024-05-25 03:15:13 [INFO]: Epoch 082 - training loss: 0.1928, validation loss: 0.0249
2024-05-25 03:15:14 [INFO]: Epoch 083 - training loss: 0.1919, validation loss: 0.0252
2024-05-25 03:15:14 [INFO]: Epoch 084 - training loss: 0.1934, validation loss: 0.0262
2024-05-25 03:15:14 [INFO]: Epoch 085 - training loss: 0.1978, validation loss: 0.0269
2024-05-25 03:15:14 [INFO]: Epoch 086 - training loss: 0.1906, validation loss: 0.0263
2024-05-25 03:15:14 [INFO]: Epoch 087 - training loss: 0.1930, validation loss: 0.0263
2024-05-25 03:15:15 [INFO]: Epoch 088 - training loss: 0.1895, validation loss: 0.0288
2024-05-25 03:15:15 [INFO]: Epoch 089 - training loss: 0.1944, validation loss: 0.0262
2024-05-25 03:15:15 [INFO]: Epoch 090 - training loss: 0.1883, validation loss: 0.0245
2024-05-25 03:15:15 [INFO]: Epoch 091 - training loss: 0.1856, validation loss: 0.0241
2024-05-25 03:15:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:15:15 [INFO]: Finished training. The best model is from epoch#81.
2024-05-25 03:15:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/Transformer_ettm1/20240525_T031458/Transformer.pypots
2024-05-25 03:15:15 [INFO]: Transformer on ETTm1: MAE=0.1288, MSE=0.0352
2024-05-25 03:15:15 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Transformer_ettm1/imputation.pkl
2024-05-25 03:15:15 [INFO]: Using the given device: cuda:0
2024-05-25 03:15:15 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/TimesNet_ettm1/20240525_T031515
2024-05-25 03:15:15 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/TimesNet_ettm1/20240525_T031515/tensorboard
2024-05-25 03:15:15 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 03:15:16 [INFO]: Epoch 001 - training loss: 0.1317, validation loss: 0.0506
2024-05-25 03:15:16 [INFO]: Epoch 002 - training loss: 0.0593, validation loss: 0.0390
2024-05-25 03:15:16 [INFO]: Epoch 003 - training loss: 0.0496, validation loss: 0.0348
2024-05-25 03:15:16 [INFO]: Epoch 004 - training loss: 0.0451, validation loss: 0.0351
2024-05-25 03:15:17 [INFO]: Epoch 005 - training loss: 0.0447, validation loss: 0.0330
2024-05-25 03:15:17 [INFO]: Epoch 006 - training loss: 0.0402, validation loss: 0.0311
2024-05-25 03:15:17 [INFO]: Epoch 007 - training loss: 0.0406, validation loss: 0.0318
2024-05-25 03:15:17 [INFO]: Epoch 008 - training loss: 0.0421, validation loss: 0.0336
2024-05-25 03:15:17 [INFO]: Epoch 009 - training loss: 0.0435, validation loss: 0.0339
2024-05-25 03:15:18 [INFO]: Epoch 010 - training loss: 0.0407, validation loss: 0.0302
2024-05-25 03:15:18 [INFO]: Epoch 011 - training loss: 0.0371, validation loss: 0.0309
2024-05-25 03:15:18 [INFO]: Epoch 012 - training loss: 0.0364, validation loss: 0.0296
2024-05-25 03:15:18 [INFO]: Epoch 013 - training loss: 0.0348, validation loss: 0.0292
2024-05-25 03:15:18 [INFO]: Epoch 014 - training loss: 0.0362, validation loss: 0.0298
2024-05-25 03:15:19 [INFO]: Epoch 015 - training loss: 0.0365, validation loss: 0.0292
2024-05-25 03:15:19 [INFO]: Epoch 016 - training loss: 0.0354, validation loss: 0.0289
2024-05-25 03:15:19 [INFO]: Epoch 017 - training loss: 0.0336, validation loss: 0.0283
2024-05-25 03:15:19 [INFO]: Epoch 018 - training loss: 0.0325, validation loss: 0.0290
2024-05-25 03:15:19 [INFO]: Epoch 019 - training loss: 0.0325, validation loss: 0.0286
2024-05-25 03:15:19 [INFO]: Epoch 020 - training loss: 0.0337, validation loss: 0.0354
2024-05-25 03:15:20 [INFO]: Epoch 021 - training loss: 0.0384, validation loss: 0.0329
2024-05-25 03:15:20 [INFO]: Epoch 022 - training loss: 0.0379, validation loss: 0.0300
2024-05-25 03:15:20 [INFO]: Epoch 023 - training loss: 0.0356, validation loss: 0.0295
2024-05-25 03:15:20 [INFO]: Epoch 024 - training loss: 0.0307, validation loss: 0.0292
2024-05-25 03:15:20 [INFO]: Epoch 025 - training loss: 0.0299, validation loss: 0.0287
2024-05-25 03:15:21 [INFO]: Epoch 026 - training loss: 0.0312, validation loss: 0.0277
2024-05-25 03:15:21 [INFO]: Epoch 027 - training loss: 0.0301, validation loss: 0.0288
2024-05-25 03:15:21 [INFO]: Epoch 028 - training loss: 0.0292, validation loss: 0.0274
2024-05-25 03:15:21 [INFO]: Epoch 029 - training loss: 0.0667, validation loss: 0.0279
2024-05-25 03:15:21 [INFO]: Epoch 030 - training loss: 0.0310, validation loss: 0.0304
2024-05-25 03:15:22 [INFO]: Epoch 031 - training loss: 0.0307, validation loss: 0.0297
2024-05-25 03:15:22 [INFO]: Epoch 032 - training loss: 0.0305, validation loss: 0.0287
2024-05-25 03:15:22 [INFO]: Epoch 033 - training loss: 0.0270, validation loss: 0.0280
2024-05-25 03:15:22 [INFO]: Epoch 034 - training loss: 0.0277, validation loss: 0.0284
2024-05-25 03:15:22 [INFO]: Epoch 035 - training loss: 0.0280, validation loss: 0.0285
2024-05-25 03:15:22 [INFO]: Epoch 036 - training loss: 0.0279, validation loss: 0.0279
2024-05-25 03:15:23 [INFO]: Epoch 037 - training loss: 0.0259, validation loss: 0.0276
2024-05-25 03:15:23 [INFO]: Epoch 038 - training loss: 0.0256, validation loss: 0.0283
2024-05-25 03:15:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:15:23 [INFO]: Finished training. The best model is from epoch#28.
2024-05-25 03:15:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/TimesNet_ettm1/20240525_T031515/TimesNet.pypots
2024-05-25 03:15:23 [INFO]: TimesNet on ETTm1: MAE=0.1168, MSE=0.0294
2024-05-25 03:15:23 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/TimesNet_ettm1/imputation.pkl
2024-05-25 03:15:23 [INFO]: Using the given device: cuda:0
2024-05-25 03:15:23 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523
2024-05-25 03:15:23 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/tensorboard
2024-05-25 03:15:23 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 03:15:25 [INFO]: Epoch 001 - training loss: 0.6764, validation loss: 0.4036
2024-05-25 03:15:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch1_loss0.40355267375707626.pypots
2024-05-25 03:15:27 [INFO]: Epoch 002 - training loss: 0.3522, validation loss: 0.3685
2024-05-25 03:15:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch2_loss0.3685160502791405.pypots
2024-05-25 03:15:29 [INFO]: Epoch 003 - training loss: 0.3753, validation loss: 0.3049
2024-05-25 03:15:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch3_loss0.30494843423366547.pypots
2024-05-25 03:15:31 [INFO]: Epoch 004 - training loss: 0.3693, validation loss: 0.2953
2024-05-25 03:15:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch4_loss0.295309841632843.pypots
2024-05-25 03:15:33 [INFO]: Epoch 005 - training loss: 0.3001, validation loss: 0.2840
2024-05-25 03:15:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch5_loss0.2840422913432121.pypots
2024-05-25 03:15:35 [INFO]: Epoch 006 - training loss: 0.3197, validation loss: 0.2831
2024-05-25 03:15:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch6_loss0.28306929022073746.pypots
2024-05-25 03:15:37 [INFO]: Epoch 007 - training loss: 0.2787, validation loss: 0.2809
2024-05-25 03:15:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch7_loss0.2808720991015434.pypots
2024-05-25 03:15:39 [INFO]: Epoch 008 - training loss: 0.3196, validation loss: 0.2634
2024-05-25 03:15:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch8_loss0.2633870765566826.pypots
2024-05-25 03:15:41 [INFO]: Epoch 009 - training loss: 0.3401, validation loss: 0.2528
2024-05-25 03:15:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch9_loss0.2527627497911453.pypots
2024-05-25 03:15:43 [INFO]: Epoch 010 - training loss: 0.2267, validation loss: 0.2400
2024-05-25 03:15:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch10_loss0.24004795774817467.pypots
2024-05-25 03:15:45 [INFO]: Epoch 011 - training loss: 0.2184, validation loss: 0.2285
2024-05-25 03:15:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch11_loss0.22846611216664314.pypots
2024-05-25 03:15:48 [INFO]: Epoch 012 - training loss: 0.2347, validation loss: 0.2165
2024-05-25 03:15:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch12_loss0.2165391445159912.pypots
2024-05-25 03:15:50 [INFO]: Epoch 013 - training loss: 0.2155, validation loss: 0.2129
2024-05-25 03:15:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch13_loss0.21285627782344818.pypots
2024-05-25 03:15:52 [INFO]: Epoch 014 - training loss: 0.2470, validation loss: 0.2241
2024-05-25 03:15:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch14_loss0.2240818701684475.pypots
2024-05-25 03:15:54 [INFO]: Epoch 015 - training loss: 0.2841, validation loss: 0.2101
2024-05-25 03:15:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch15_loss0.21012431755661964.pypots
2024-05-25 03:15:56 [INFO]: Epoch 016 - training loss: 0.2036, validation loss: 0.2037
2024-05-25 03:15:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch16_loss0.20374785736203194.pypots
2024-05-25 03:15:58 [INFO]: Epoch 017 - training loss: 0.2101, validation loss: 0.1954
2024-05-25 03:15:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch17_loss0.19536853954195976.pypots
2024-05-25 03:16:00 [INFO]: Epoch 018 - training loss: 0.2276, validation loss: 0.2034
2024-05-25 03:16:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch18_loss0.2034141607582569.pypots
2024-05-25 03:16:02 [INFO]: Epoch 019 - training loss: 0.2015, validation loss: 0.2166
2024-05-25 03:16:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch19_loss0.21660807728767395.pypots
2024-05-25 03:16:04 [INFO]: Epoch 020 - training loss: 0.1934, validation loss: 0.1866
2024-05-25 03:16:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch20_loss0.1866271235048771.pypots
2024-05-25 03:16:06 [INFO]: Epoch 021 - training loss: 0.1942, validation loss: 0.1862
2024-05-25 03:16:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch21_loss0.1862420029938221.pypots
2024-05-25 03:16:08 [INFO]: Epoch 022 - training loss: 0.1713, validation loss: 0.1776
2024-05-25 03:16:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch22_loss0.177553441375494.pypots
2024-05-25 03:16:10 [INFO]: Epoch 023 - training loss: 0.1877, validation loss: 0.1731
2024-05-25 03:16:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch23_loss0.17310144379734993.pypots
2024-05-25 03:16:12 [INFO]: Epoch 024 - training loss: 0.1798, validation loss: 0.1690
2024-05-25 03:16:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch24_loss0.16898545622825623.pypots
2024-05-25 03:16:14 [INFO]: Epoch 025 - training loss: 0.1857, validation loss: 0.1691
2024-05-25 03:16:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch25_loss0.16909800097346306.pypots
2024-05-25 03:16:16 [INFO]: Epoch 026 - training loss: 0.1753, validation loss: 0.1660
2024-05-25 03:16:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch26_loss0.1659659706056118.pypots
2024-05-25 03:16:18 [INFO]: Epoch 027 - training loss: 0.1971, validation loss: 0.1664
2024-05-25 03:16:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch27_loss0.166352529078722.pypots
2024-05-25 03:16:20 [INFO]: Epoch 028 - training loss: 0.1807, validation loss: 0.1751
2024-05-25 03:16:20 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch28_loss0.17505520209670067.pypots
2024-05-25 03:16:22 [INFO]: Epoch 029 - training loss: 0.1927, validation loss: 0.1725
2024-05-25 03:16:22 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch29_loss0.17246847599744797.pypots
2024-05-25 03:16:24 [INFO]: Epoch 030 - training loss: 0.1772, validation loss: 0.1583
2024-05-25 03:16:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch30_loss0.15825022757053375.pypots
2024-05-25 03:16:26 [INFO]: Epoch 031 - training loss: 0.1699, validation loss: 0.1549
2024-05-25 03:16:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch31_loss0.15491340681910515.pypots
2024-05-25 03:16:28 [INFO]: Epoch 032 - training loss: 0.1539, validation loss: 0.1594
2024-05-25 03:16:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch32_loss0.15940289944410324.pypots
2024-05-25 03:16:30 [INFO]: Epoch 033 - training loss: 0.1715, validation loss: 0.1578
2024-05-25 03:16:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch33_loss0.15780678763985634.pypots
2024-05-25 03:16:32 [INFO]: Epoch 034 - training loss: 0.1530, validation loss: 0.1612
2024-05-25 03:16:32 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch34_loss0.16119957342743874.pypots
2024-05-25 03:16:34 [INFO]: Epoch 035 - training loss: 0.1684, validation loss: 0.1526
2024-05-25 03:16:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch35_loss0.15257121250033379.pypots
2024-05-25 03:16:36 [INFO]: Epoch 036 - training loss: 0.1783, validation loss: 0.1702
2024-05-25 03:16:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch36_loss0.17022160068154335.pypots
2024-05-25 03:16:38 [INFO]: Epoch 037 - training loss: 0.1838, validation loss: 0.1654
2024-05-25 03:16:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch37_loss0.16537462919950485.pypots
2024-05-25 03:16:41 [INFO]: Epoch 038 - training loss: 0.1636, validation loss: 0.1524
2024-05-25 03:16:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch38_loss0.1523948609828949.pypots
2024-05-25 03:16:43 [INFO]: Epoch 039 - training loss: 0.1781, validation loss: 0.1503
2024-05-25 03:16:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch39_loss0.1502513289451599.pypots
2024-05-25 03:16:45 [INFO]: Epoch 040 - training loss: 0.1537, validation loss: 0.1498
2024-05-25 03:16:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch40_loss0.1497519053518772.pypots
2024-05-25 03:16:47 [INFO]: Epoch 041 - training loss: 0.1734, validation loss: 0.1544
2024-05-25 03:16:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch41_loss0.15436145663261414.pypots
2024-05-25 03:16:49 [INFO]: Epoch 042 - training loss: 0.1600, validation loss: 0.1503
2024-05-25 03:16:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch42_loss0.15027224272489548.pypots
2024-05-25 03:16:51 [INFO]: Epoch 043 - training loss: 0.1471, validation loss: 0.1424
2024-05-25 03:16:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch43_loss0.14238013327121735.pypots
2024-05-25 03:16:53 [INFO]: Epoch 044 - training loss: 0.1489, validation loss: 0.1454
2024-05-25 03:16:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch44_loss0.14544709026813507.pypots
2024-05-25 03:16:55 [INFO]: Epoch 045 - training loss: 0.1454, validation loss: 0.1418
2024-05-25 03:16:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch45_loss0.141838438808918.pypots
2024-05-25 03:16:57 [INFO]: Epoch 046 - training loss: 0.1458, validation loss: 0.1381
2024-05-25 03:16:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch46_loss0.13805967196822166.pypots
2024-05-25 03:16:59 [INFO]: Epoch 047 - training loss: 0.1384, validation loss: 0.1345
2024-05-25 03:16:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch47_loss0.13453511148691177.pypots
2024-05-25 03:17:01 [INFO]: Epoch 048 - training loss: 0.1372, validation loss: 0.1354
2024-05-25 03:17:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch48_loss0.13544433191418648.pypots
2024-05-25 03:17:03 [INFO]: Epoch 049 - training loss: 0.1294, validation loss: 0.1365
2024-05-25 03:17:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch49_loss0.1365259699523449.pypots
2024-05-25 03:17:05 [INFO]: Epoch 050 - training loss: 0.1416, validation loss: 0.1329
2024-05-25 03:17:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch50_loss0.13287707418203354.pypots
2024-05-25 03:17:07 [INFO]: Epoch 051 - training loss: 0.1266, validation loss: 0.1349
2024-05-25 03:17:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch51_loss0.13491855934262276.pypots
2024-05-25 03:17:09 [INFO]: Epoch 052 - training loss: 0.1500, validation loss: 0.1334
2024-05-25 03:17:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch52_loss0.1333740521222353.pypots
2024-05-25 03:17:11 [INFO]: Epoch 053 - training loss: 0.1452, validation loss: 0.1304
2024-05-25 03:17:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch53_loss0.13042332231998444.pypots
2024-05-25 03:17:13 [INFO]: Epoch 054 - training loss: 0.1246, validation loss: 0.1311
2024-05-25 03:17:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch54_loss0.13113797828555107.pypots
2024-05-25 03:17:15 [INFO]: Epoch 055 - training loss: 0.1308, validation loss: 0.1288
2024-05-25 03:17:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch55_loss0.12877864949405193.pypots
2024-05-25 03:17:17 [INFO]: Epoch 056 - training loss: 0.1213, validation loss: 0.1303
2024-05-25 03:17:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch56_loss0.13033145852386951.pypots
2024-05-25 03:17:19 [INFO]: Epoch 057 - training loss: 0.1425, validation loss: 0.1344
2024-05-25 03:17:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch57_loss0.13441969454288483.pypots
2024-05-25 03:17:21 [INFO]: Epoch 058 - training loss: 0.1581, validation loss: 0.1330
2024-05-25 03:17:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch58_loss0.1329852044582367.pypots
2024-05-25 03:17:23 [INFO]: Epoch 059 - training loss: 0.2169, validation loss: 0.1306
2024-05-25 03:17:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch59_loss0.1305804494768381.pypots
2024-05-25 03:17:25 [INFO]: Epoch 060 - training loss: 0.1343, validation loss: 0.1366
2024-05-25 03:17:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch60_loss0.13660328090190887.pypots
2024-05-25 03:17:27 [INFO]: Epoch 061 - training loss: 0.1325, validation loss: 0.1296
2024-05-25 03:17:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch61_loss0.12955397740006447.pypots
2024-05-25 03:17:29 [INFO]: Epoch 062 - training loss: 0.1610, validation loss: 0.1301
2024-05-25 03:17:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch62_loss0.1301114335656166.pypots
2024-05-25 03:17:31 [INFO]: Epoch 063 - training loss: 0.1556, validation loss: 0.1348
2024-05-25 03:17:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch63_loss0.134781401604414.pypots
2024-05-25 03:17:34 [INFO]: Epoch 064 - training loss: 0.1356, validation loss: 0.1281
2024-05-25 03:17:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch64_loss0.12809851206839085.pypots
2024-05-25 03:17:36 [INFO]: Epoch 065 - training loss: 0.1818, validation loss: 0.1329
2024-05-25 03:17:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch65_loss0.13287206552922726.pypots
2024-05-25 03:17:38 [INFO]: Epoch 066 - training loss: 0.1476, validation loss: 0.1332
2024-05-25 03:17:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch66_loss0.13318584114313126.pypots
2024-05-25 03:17:40 [INFO]: Epoch 067 - training loss: 0.1412, validation loss: 0.1332
2024-05-25 03:17:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch67_loss0.13319367170333862.pypots
2024-05-25 03:17:42 [INFO]: Epoch 068 - training loss: 0.1319, validation loss: 0.1304
2024-05-25 03:17:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch68_loss0.1304408758878708.pypots
2024-05-25 03:17:44 [INFO]: Epoch 069 - training loss: 0.1399, validation loss: 0.1326
2024-05-25 03:17:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch69_loss0.13256731815636158.pypots
2024-05-25 03:17:46 [INFO]: Epoch 070 - training loss: 0.1445, validation loss: 0.1392
2024-05-25 03:17:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch70_loss0.13918789476156235.pypots
2024-05-25 03:17:48 [INFO]: Epoch 071 - training loss: 0.1227, validation loss: 0.1291
2024-05-25 03:17:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch71_loss0.1290551982820034.pypots
2024-05-25 03:17:50 [INFO]: Epoch 072 - training loss: 0.1307, validation loss: 0.1265
2024-05-25 03:17:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch72_loss0.12645086459815502.pypots
2024-05-25 03:17:52 [INFO]: Epoch 073 - training loss: 0.1386, validation loss: 0.1269
2024-05-25 03:17:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch73_loss0.12688289396464825.pypots
2024-05-25 03:17:54 [INFO]: Epoch 074 - training loss: 0.1369, validation loss: 0.1278
2024-05-25 03:17:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch74_loss0.12783830612897873.pypots
2024-05-25 03:17:56 [INFO]: Epoch 075 - training loss: 0.1242, validation loss: 0.1269
2024-05-25 03:17:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch75_loss0.12693875655531883.pypots
2024-05-25 03:17:58 [INFO]: Epoch 076 - training loss: 0.1368, validation loss: 0.1294
2024-05-25 03:17:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch76_loss0.1294206790626049.pypots
2024-05-25 03:18:00 [INFO]: Epoch 077 - training loss: 0.1656, validation loss: 0.1262
2024-05-25 03:18:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch77_loss0.1262461580336094.pypots
2024-05-25 03:18:02 [INFO]: Epoch 078 - training loss: 0.1417, validation loss: 0.1292
2024-05-25 03:18:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch78_loss0.12917502783238888.pypots
2024-05-25 03:18:04 [INFO]: Epoch 079 - training loss: 0.1333, validation loss: 0.1268
2024-05-25 03:18:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch79_loss0.1267811916768551.pypots
2024-05-25 03:18:06 [INFO]: Epoch 080 - training loss: 0.1385, validation loss: 0.1274
2024-05-25 03:18:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch80_loss0.1273543033748865.pypots
2024-05-25 03:18:08 [INFO]: Epoch 081 - training loss: 0.1114, validation loss: 0.1242
2024-05-25 03:18:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch81_loss0.12420131452381611.pypots
2024-05-25 03:18:10 [INFO]: Epoch 082 - training loss: 0.1213, validation loss: 0.1218
2024-05-25 03:18:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch82_loss0.12183071114122868.pypots
2024-05-25 03:18:12 [INFO]: Epoch 083 - training loss: 0.1205, validation loss: 0.1203
2024-05-25 03:18:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch83_loss0.12034978531301022.pypots
2024-05-25 03:18:14 [INFO]: Epoch 084 - training loss: 0.1214, validation loss: 0.1224
2024-05-25 03:18:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch84_loss0.12240135855972767.pypots
2024-05-25 03:18:16 [INFO]: Epoch 085 - training loss: 0.1211, validation loss: 0.1222
2024-05-25 03:18:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch85_loss0.12220347113907337.pypots
2024-05-25 03:18:18 [INFO]: Epoch 086 - training loss: 0.1287, validation loss: 0.1214
2024-05-25 03:18:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch86_loss0.12139085866510868.pypots
2024-05-25 03:18:20 [INFO]: Epoch 087 - training loss: 0.1122, validation loss: 0.1190
2024-05-25 03:18:20 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch87_loss0.11898418702185154.pypots
2024-05-25 03:18:22 [INFO]: Epoch 088 - training loss: 0.1942, validation loss: 0.1283
2024-05-25 03:18:22 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch88_loss0.12832141667604446.pypots
2024-05-25 03:18:24 [INFO]: Epoch 089 - training loss: 0.1388, validation loss: 0.1423
2024-05-25 03:18:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch89_loss0.14229173585772514.pypots
2024-05-25 03:18:27 [INFO]: Epoch 090 - training loss: 0.1541, validation loss: 0.1289
2024-05-25 03:18:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch90_loss0.1289002075791359.pypots
2024-05-25 03:18:29 [INFO]: Epoch 091 - training loss: 0.1422, validation loss: 0.1284
2024-05-25 03:18:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch91_loss0.1283592451363802.pypots
2024-05-25 03:18:31 [INFO]: Epoch 092 - training loss: 0.1204, validation loss: 0.1260
2024-05-25 03:18:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch92_loss0.12597011029720306.pypots
2024-05-25 03:18:33 [INFO]: Epoch 093 - training loss: 0.1204, validation loss: 0.1225
2024-05-25 03:18:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch93_loss0.12248137034475803.pypots
2024-05-25 03:18:35 [INFO]: Epoch 094 - training loss: 0.1322, validation loss: 0.1226
2024-05-25 03:18:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch94_loss0.12264666147530079.pypots
2024-05-25 03:18:37 [INFO]: Epoch 095 - training loss: 0.1214, validation loss: 0.1201
2024-05-25 03:18:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch95_loss0.12008700892329216.pypots
2024-05-25 03:18:39 [INFO]: Epoch 096 - training loss: 0.1260, validation loss: 0.1196
2024-05-25 03:18:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch96_loss0.11959857866168022.pypots
2024-05-25 03:18:41 [INFO]: Epoch 097 - training loss: 0.1226, validation loss: 0.1181
2024-05-25 03:18:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch97_loss0.11811574921011925.pypots
2024-05-25 03:18:43 [INFO]: Epoch 098 - training loss: 0.1215, validation loss: 0.1202
2024-05-25 03:18:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch98_loss0.12020381167531013.pypots
2024-05-25 03:18:45 [INFO]: Epoch 099 - training loss: 0.1316, validation loss: 0.1198
2024-05-25 03:18:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch99_loss0.11984113976359367.pypots
2024-05-25 03:18:47 [INFO]: Epoch 100 - training loss: 0.1277, validation loss: 0.1207
2024-05-25 03:18:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch100_loss0.1206792201846838.pypots
2024-05-25 03:18:49 [INFO]: Epoch 101 - training loss: 0.1224, validation loss: 0.1187
2024-05-25 03:18:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch101_loss0.11871710047125816.pypots
2024-05-25 03:18:51 [INFO]: Epoch 102 - training loss: 0.1212, validation loss: 0.1167
2024-05-25 03:18:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch102_loss0.11674574203789234.pypots
2024-05-25 03:18:53 [INFO]: Epoch 103 - training loss: 0.1269, validation loss: 0.1170
2024-05-25 03:18:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch103_loss0.11699654906988144.pypots
2024-05-25 03:18:55 [INFO]: Epoch 104 - training loss: 0.1107, validation loss: 0.1186
2024-05-25 03:18:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch104_loss0.11861937120556831.pypots
2024-05-25 03:18:57 [INFO]: Epoch 105 - training loss: 0.1313, validation loss: 0.1186
2024-05-25 03:18:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch105_loss0.11855164915323257.pypots
2024-05-25 03:18:59 [INFO]: Epoch 106 - training loss: 0.1230, validation loss: 0.1168
2024-05-25 03:18:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch106_loss0.1167815625667572.pypots
2024-05-25 03:19:01 [INFO]: Epoch 107 - training loss: 0.1136, validation loss: 0.1170
2024-05-25 03:19:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch107_loss0.11698275618255138.pypots
2024-05-25 03:19:03 [INFO]: Epoch 108 - training loss: 0.1114, validation loss: 0.1206
2024-05-25 03:19:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch108_loss0.12058825418353081.pypots
2024-05-25 03:19:05 [INFO]: Epoch 109 - training loss: 0.1201, validation loss: 0.1182
2024-05-25 03:19:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch109_loss0.11821739375591278.pypots
2024-05-25 03:19:07 [INFO]: Epoch 110 - training loss: 0.1277, validation loss: 0.1240
2024-05-25 03:19:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch110_loss0.12401494942605495.pypots
2024-05-25 03:19:09 [INFO]: Epoch 111 - training loss: 0.1423, validation loss: 0.1283
2024-05-25 03:19:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch111_loss0.128256281837821.pypots
2024-05-25 03:19:11 [INFO]: Epoch 112 - training loss: 0.1413, validation loss: 0.1211
2024-05-25 03:19:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI_epoch112_loss0.12113765440881252.pypots
2024-05-25 03:19:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:19:11 [INFO]: Finished training. The best model is from epoch#102.
2024-05-25 03:19:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T031523/CSDI.pypots
2024-05-25 03:19:27 [INFO]: CSDI on ETTm1: MAE=0.1185, MSE=0.0329
2024-05-25 03:19:27 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/CSDI_ettm1/imputation.pkl
2024-05-25 03:19:27 [INFO]: Using the given device: cuda:0
2024-05-25 03:19:27 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/GPVAE_ettm1/20240525_T031927
2024-05-25 03:19:27 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/GPVAE_ettm1/20240525_T031927/tensorboard
2024-05-25 03:19:27 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 03:19:27 [INFO]: Epoch 001 - training loss: 24246.2695, validation loss: 0.9435
2024-05-25 03:19:28 [INFO]: Epoch 002 - training loss: 22309.0073, validation loss: 0.9408
2024-05-25 03:19:28 [INFO]: Epoch 003 - training loss: 20395.9005, validation loss: 0.9370
2024-05-25 03:19:28 [INFO]: Epoch 004 - training loss: 18348.6307, validation loss: 0.9275
2024-05-25 03:19:28 [INFO]: Epoch 005 - training loss: 16383.4504, validation loss: 0.8961
2024-05-25 03:19:28 [INFO]: Epoch 006 - training loss: 14780.2767, validation loss: 0.8422
2024-05-25 03:19:28 [INFO]: Epoch 007 - training loss: 13183.9465, validation loss: 0.7634
2024-05-25 03:19:28 [INFO]: Epoch 008 - training loss: 12225.5007, validation loss: 0.6928
2024-05-25 03:19:28 [INFO]: Epoch 009 - training loss: 11491.0200, validation loss: 0.6073
2024-05-25 03:19:29 [INFO]: Epoch 010 - training loss: 11151.0417, validation loss: 0.5489
2024-05-25 03:19:29 [INFO]: Epoch 011 - training loss: 10685.4360, validation loss: 0.5113
2024-05-25 03:19:29 [INFO]: Epoch 012 - training loss: 10443.0248, validation loss: 0.4857
2024-05-25 03:19:29 [INFO]: Epoch 013 - training loss: 10280.9890, validation loss: 0.4594
2024-05-25 03:19:29 [INFO]: Epoch 014 - training loss: 10113.2618, validation loss: 0.4461
2024-05-25 03:19:29 [INFO]: Epoch 015 - training loss: 10080.4862, validation loss: 0.4310
2024-05-25 03:19:29 [INFO]: Epoch 016 - training loss: 9903.7402, validation loss: 0.4167
2024-05-25 03:19:29 [INFO]: Epoch 017 - training loss: 9839.5247, validation loss: 0.4066
2024-05-25 03:19:30 [INFO]: Epoch 018 - training loss: 9757.7888, validation loss: 0.3946
2024-05-25 03:19:30 [INFO]: Epoch 019 - training loss: 9699.9527, validation loss: 0.3830
2024-05-25 03:19:30 [INFO]: Epoch 020 - training loss: 9693.1169, validation loss: 0.3757
2024-05-25 03:19:30 [INFO]: Epoch 021 - training loss: 9617.8738, validation loss: 0.3692
2024-05-25 03:19:30 [INFO]: Epoch 022 - training loss: 9588.7014, validation loss: 0.3612
2024-05-25 03:19:30 [INFO]: Epoch 023 - training loss: 9551.9829, validation loss: 0.3479
2024-05-25 03:19:30 [INFO]: Epoch 024 - training loss: 9530.6164, validation loss: 0.3529
2024-05-25 03:19:30 [INFO]: Epoch 025 - training loss: 9509.7045, validation loss: 0.3405
2024-05-25 03:19:30 [INFO]: Epoch 026 - training loss: 9488.3934, validation loss: 0.3400
2024-05-25 03:19:31 [INFO]: Epoch 027 - training loss: 9474.0986, validation loss: 0.3374
2024-05-25 03:19:31 [INFO]: Epoch 028 - training loss: 9450.3527, validation loss: 0.3260
2024-05-25 03:19:31 [INFO]: Epoch 029 - training loss: 9447.6851, validation loss: 0.3225
2024-05-25 03:19:31 [INFO]: Epoch 030 - training loss: 9422.4590, validation loss: 0.3208
2024-05-25 03:19:31 [INFO]: Epoch 031 - training loss: 9421.6392, validation loss: 0.3182
2024-05-25 03:19:31 [INFO]: Epoch 032 - training loss: 9397.5182, validation loss: 0.3008
2024-05-25 03:19:31 [INFO]: Epoch 033 - training loss: 9398.2031, validation loss: 0.2978
2024-05-25 03:19:31 [INFO]: Epoch 034 - training loss: 9382.2585, validation loss: 0.2944
2024-05-25 03:19:32 [INFO]: Epoch 035 - training loss: 9370.4272, validation loss: 0.2860
2024-05-25 03:19:32 [INFO]: Epoch 036 - training loss: 9377.4155, validation loss: 0.2836
2024-05-25 03:19:32 [INFO]: Epoch 037 - training loss: 9393.2990, validation loss: 0.2766
2024-05-25 03:19:32 [INFO]: Epoch 038 - training loss: 9349.7589, validation loss: 0.2748
2024-05-25 03:19:32 [INFO]: Epoch 039 - training loss: 9341.2191, validation loss: 0.2637
2024-05-25 03:19:32 [INFO]: Epoch 040 - training loss: 9334.6495, validation loss: 0.2578
2024-05-25 03:19:32 [INFO]: Epoch 041 - training loss: 9338.1343, validation loss: 0.2599
2024-05-25 03:19:32 [INFO]: Epoch 042 - training loss: 9360.2315, validation loss: 0.2465
2024-05-25 03:19:33 [INFO]: Epoch 043 - training loss: 9322.8442, validation loss: 0.2456
2024-05-25 03:19:33 [INFO]: Epoch 044 - training loss: 9314.7611, validation loss: 0.2405
2024-05-25 03:19:33 [INFO]: Epoch 045 - training loss: 9311.1584, validation loss: 0.2354
2024-05-25 03:19:33 [INFO]: Epoch 046 - training loss: 9310.3632, validation loss: 0.2284
2024-05-25 03:19:33 [INFO]: Epoch 047 - training loss: 9315.0383, validation loss: 0.2242
2024-05-25 03:19:33 [INFO]: Epoch 048 - training loss: 9299.1119, validation loss: 0.2211
2024-05-25 03:19:33 [INFO]: Epoch 049 - training loss: 9298.0652, validation loss: 0.2185
2024-05-25 03:19:33 [INFO]: Epoch 050 - training loss: 9297.5112, validation loss: 0.2117
2024-05-25 03:19:34 [INFO]: Epoch 051 - training loss: 9294.3647, validation loss: 0.2103
2024-05-25 03:19:34 [INFO]: Epoch 052 - training loss: 9294.0560, validation loss: 0.2062
2024-05-25 03:19:34 [INFO]: Epoch 053 - training loss: 9291.7855, validation loss: 0.2036
2024-05-25 03:19:34 [INFO]: Epoch 054 - training loss: 9282.2601, validation loss: 0.1969
2024-05-25 03:19:34 [INFO]: Epoch 055 - training loss: 9283.8853, validation loss: 0.1901
2024-05-25 03:19:34 [INFO]: Epoch 056 - training loss: 9282.1213, validation loss: 0.1912
2024-05-25 03:19:34 [INFO]: Epoch 057 - training loss: 9292.2027, validation loss: 0.1876
2024-05-25 03:19:34 [INFO]: Epoch 058 - training loss: 9276.0881, validation loss: 0.1834
2024-05-25 03:19:35 [INFO]: Epoch 059 - training loss: 9279.9835, validation loss: 0.1829
2024-05-25 03:19:35 [INFO]: Epoch 060 - training loss: 9272.0921, validation loss: 0.1780
2024-05-25 03:19:35 [INFO]: Epoch 061 - training loss: 9277.4571, validation loss: 0.1736
2024-05-25 03:19:35 [INFO]: Epoch 062 - training loss: 9265.1244, validation loss: 0.1727
2024-05-25 03:19:35 [INFO]: Epoch 063 - training loss: 9268.8041, validation loss: 0.1687
2024-05-25 03:19:35 [INFO]: Epoch 064 - training loss: 9263.9190, validation loss: 0.1673
2024-05-25 03:19:35 [INFO]: Epoch 065 - training loss: 9262.8339, validation loss: 0.1667
2024-05-25 03:19:35 [INFO]: Epoch 066 - training loss: 9261.9691, validation loss: 0.1617
2024-05-25 03:19:36 [INFO]: Epoch 067 - training loss: 9261.9668, validation loss: 0.1617
2024-05-25 03:19:36 [INFO]: Epoch 068 - training loss: 9258.0599, validation loss: 0.1570
2024-05-25 03:19:36 [INFO]: Epoch 069 - training loss: 9260.7883, validation loss: 0.1551
2024-05-25 03:19:36 [INFO]: Epoch 070 - training loss: 9254.4752, validation loss: 0.1526
2024-05-25 03:19:36 [INFO]: Epoch 071 - training loss: 9260.5665, validation loss: 0.1518
2024-05-25 03:19:36 [INFO]: Epoch 072 - training loss: 9253.5356, validation loss: 0.1545
2024-05-25 03:19:36 [INFO]: Epoch 073 - training loss: 9252.6641, validation loss: 0.1497
2024-05-25 03:19:36 [INFO]: Epoch 074 - training loss: 9249.9297, validation loss: 0.1438
2024-05-25 03:19:36 [INFO]: Epoch 075 - training loss: 9250.0039, validation loss: 0.1449
2024-05-25 03:19:37 [INFO]: Epoch 076 - training loss: 9251.1970, validation loss: 0.1452
2024-05-25 03:19:37 [INFO]: Epoch 077 - training loss: 9247.2530, validation loss: 0.1381
2024-05-25 03:19:37 [INFO]: Epoch 078 - training loss: 9245.6694, validation loss: 0.1392
2024-05-25 03:19:37 [INFO]: Epoch 079 - training loss: 9242.6327, validation loss: 0.1396
2024-05-25 03:19:37 [INFO]: Epoch 080 - training loss: 9243.3953, validation loss: 0.1383
2024-05-25 03:19:37 [INFO]: Epoch 081 - training loss: 9242.9379, validation loss: 0.1371
2024-05-25 03:19:37 [INFO]: Epoch 082 - training loss: 9243.3757, validation loss: 0.1355
2024-05-25 03:19:37 [INFO]: Epoch 083 - training loss: 9242.9340, validation loss: 0.1358
2024-05-25 03:19:38 [INFO]: Epoch 084 - training loss: 9241.0580, validation loss: 0.1312
2024-05-25 03:19:38 [INFO]: Epoch 085 - training loss: 9239.6583, validation loss: 0.1338
2024-05-25 03:19:38 [INFO]: Epoch 086 - training loss: 9239.9296, validation loss: 0.1333
2024-05-25 03:19:38 [INFO]: Epoch 087 - training loss: 9239.9301, validation loss: 0.1341
2024-05-25 03:19:38 [INFO]: Epoch 088 - training loss: 9238.8577, validation loss: 0.1317
2024-05-25 03:19:38 [INFO]: Epoch 089 - training loss: 9237.1652, validation loss: 0.1301
2024-05-25 03:19:38 [INFO]: Epoch 090 - training loss: 9235.6213, validation loss: 0.1315
2024-05-25 03:19:38 [INFO]: Epoch 091 - training loss: 9235.1163, validation loss: 0.1294
2024-05-25 03:19:39 [INFO]: Epoch 092 - training loss: 9262.3180, validation loss: 0.1289
2024-05-25 03:19:39 [INFO]: Epoch 093 - training loss: 9236.3221, validation loss: 0.1296
2024-05-25 03:19:39 [INFO]: Epoch 094 - training loss: 9235.1176, validation loss: 0.1272
2024-05-25 03:19:39 [INFO]: Epoch 095 - training loss: 9233.5594, validation loss: 0.1276
2024-05-25 03:19:39 [INFO]: Epoch 096 - training loss: 9231.7528, validation loss: 0.1241
2024-05-25 03:19:39 [INFO]: Epoch 097 - training loss: 9231.4122, validation loss: 0.1251
2024-05-25 03:19:39 [INFO]: Epoch 098 - training loss: 9231.9173, validation loss: 0.1246
2024-05-25 03:19:39 [INFO]: Epoch 099 - training loss: 9231.9627, validation loss: 0.1230
2024-05-25 03:19:40 [INFO]: Epoch 100 - training loss: 9231.2922, validation loss: 0.1235
2024-05-25 03:19:40 [INFO]: Epoch 101 - training loss: 9233.1388, validation loss: 0.1213
2024-05-25 03:19:40 [INFO]: Epoch 102 - training loss: 9232.5853, validation loss: 0.1243
2024-05-25 03:19:40 [INFO]: Epoch 103 - training loss: 9230.3286, validation loss: 0.1300
2024-05-25 03:19:40 [INFO]: Epoch 104 - training loss: 9230.1221, validation loss: 0.1178
2024-05-25 03:19:40 [INFO]: Epoch 105 - training loss: 9228.7700, validation loss: 0.1189
2024-05-25 03:19:40 [INFO]: Epoch 106 - training loss: 9227.4598, validation loss: 0.1192
2024-05-25 03:19:40 [INFO]: Epoch 107 - training loss: 9230.0592, validation loss: 0.1184
2024-05-25 03:19:41 [INFO]: Epoch 108 - training loss: 9229.2073, validation loss: 0.1182
2024-05-25 03:19:41 [INFO]: Epoch 109 - training loss: 9227.8519, validation loss: 0.1168
2024-05-25 03:19:41 [INFO]: Epoch 110 - training loss: 9226.6919, validation loss: 0.1172
2024-05-25 03:19:41 [INFO]: Epoch 111 - training loss: 9227.8683, validation loss: 0.1162
2024-05-25 03:19:41 [INFO]: Epoch 112 - training loss: 9228.4060, validation loss: 0.1150
2024-05-25 03:19:41 [INFO]: Epoch 113 - training loss: 9225.8057, validation loss: 0.1161
2024-05-25 03:19:41 [INFO]: Epoch 114 - training loss: 9226.8435, validation loss: 0.1149
2024-05-25 03:19:41 [INFO]: Epoch 115 - training loss: 9224.6473, validation loss: 0.1143
2024-05-25 03:19:41 [INFO]: Epoch 116 - training loss: 9225.8383, validation loss: 0.1141
2024-05-25 03:19:42 [INFO]: Epoch 117 - training loss: 9228.2335, validation loss: 0.1157
2024-05-25 03:19:42 [INFO]: Epoch 118 - training loss: 9227.6569, validation loss: 0.1137
2024-05-25 03:19:42 [INFO]: Epoch 119 - training loss: 9224.1270, validation loss: 0.1121
2024-05-25 03:19:42 [INFO]: Epoch 120 - training loss: 9223.2518, validation loss: 0.1122
2024-05-25 03:19:42 [INFO]: Epoch 121 - training loss: 9224.9951, validation loss: 0.1124
2024-05-25 03:19:42 [INFO]: Epoch 122 - training loss: 9223.8641, validation loss: 0.1109
2024-05-25 03:19:42 [INFO]: Epoch 123 - training loss: 9224.9395, validation loss: 0.1104
2024-05-25 03:19:42 [INFO]: Epoch 124 - training loss: 9223.1971, validation loss: 0.1102
2024-05-25 03:19:43 [INFO]: Epoch 125 - training loss: 9221.2828, validation loss: 0.1108
2024-05-25 03:19:43 [INFO]: Epoch 126 - training loss: 9221.7994, validation loss: 0.1104
2024-05-25 03:19:43 [INFO]: Epoch 127 - training loss: 9222.6780, validation loss: 0.1105
2024-05-25 03:19:43 [INFO]: Epoch 128 - training loss: 9224.3452, validation loss: 0.1108
2024-05-25 03:19:43 [INFO]: Epoch 129 - training loss: 9221.6836, validation loss: 0.1077
2024-05-25 03:19:43 [INFO]: Epoch 130 - training loss: 9219.7325, validation loss: 0.1087
2024-05-25 03:19:43 [INFO]: Epoch 131 - training loss: 9221.0377, validation loss: 0.1086
2024-05-25 03:19:43 [INFO]: Epoch 132 - training loss: 9220.9772, validation loss: 0.1074
2024-05-25 03:19:44 [INFO]: Epoch 133 - training loss: 9221.6608, validation loss: 0.1067
2024-05-25 03:19:44 [INFO]: Epoch 134 - training loss: 9220.1315, validation loss: 0.1076
2024-05-25 03:19:44 [INFO]: Epoch 135 - training loss: 9221.4368, validation loss: 0.1074
2024-05-25 03:19:44 [INFO]: Epoch 136 - training loss: 9222.3951, validation loss: 0.1059
2024-05-25 03:19:44 [INFO]: Epoch 137 - training loss: 9222.0660, validation loss: 0.1063
2024-05-25 03:19:44 [INFO]: Epoch 138 - training loss: 9221.6464, validation loss: 0.1056
2024-05-25 03:19:44 [INFO]: Epoch 139 - training loss: 9219.4655, validation loss: 0.1042
2024-05-25 03:19:44 [INFO]: Epoch 140 - training loss: 9219.2106, validation loss: 0.1056
2024-05-25 03:19:45 [INFO]: Epoch 141 - training loss: 9218.8475, validation loss: 0.1041
2024-05-25 03:19:45 [INFO]: Epoch 142 - training loss: 9218.4482, validation loss: 0.1039
2024-05-25 03:19:45 [INFO]: Epoch 143 - training loss: 9218.2989, validation loss: 0.1039
2024-05-25 03:19:45 [INFO]: Epoch 144 - training loss: 9217.0957, validation loss: 0.1031
2024-05-25 03:19:45 [INFO]: Epoch 145 - training loss: 9216.9603, validation loss: 0.1022
2024-05-25 03:19:45 [INFO]: Epoch 146 - training loss: 9217.8771, validation loss: 0.1023
2024-05-25 03:19:45 [INFO]: Epoch 147 - training loss: 9219.5346, validation loss: 0.1017
2024-05-25 03:19:45 [INFO]: Epoch 148 - training loss: 9218.2654, validation loss: 0.1031
2024-05-25 03:19:46 [INFO]: Epoch 149 - training loss: 9219.2653, validation loss: 0.1011
2024-05-25 03:19:46 [INFO]: Epoch 150 - training loss: 9217.0835, validation loss: 0.1014
2024-05-25 03:19:46 [INFO]: Epoch 151 - training loss: 9219.7110, validation loss: 0.1007
2024-05-25 03:19:46 [INFO]: Epoch 152 - training loss: 9217.2372, validation loss: 0.0997
2024-05-25 03:19:46 [INFO]: Epoch 153 - training loss: 9215.4003, validation loss: 0.0991
2024-05-25 03:19:46 [INFO]: Epoch 154 - training loss: 9216.8882, validation loss: 0.0991
2024-05-25 03:19:46 [INFO]: Epoch 155 - training loss: 9216.5565, validation loss: 0.1000
2024-05-25 03:19:46 [INFO]: Epoch 156 - training loss: 9214.7903, validation loss: 0.0983
2024-05-25 03:19:46 [INFO]: Epoch 157 - training loss: 9215.8411, validation loss: 0.0992
2024-05-25 03:19:47 [INFO]: Epoch 158 - training loss: 9214.7054, validation loss: 0.0982
2024-05-25 03:19:47 [INFO]: Epoch 159 - training loss: 9215.7986, validation loss: 0.0980
2024-05-25 03:19:47 [INFO]: Epoch 160 - training loss: 9216.1588, validation loss: 0.0981
2024-05-25 03:19:47 [INFO]: Epoch 161 - training loss: 9215.6900, validation loss: 0.0973
2024-05-25 03:19:47 [INFO]: Epoch 162 - training loss: 9214.8514, validation loss: 0.0979
2024-05-25 03:19:47 [INFO]: Epoch 163 - training loss: 9215.1033, validation loss: 0.0970
2024-05-25 03:19:47 [INFO]: Epoch 164 - training loss: 9216.2121, validation loss: 0.0988
2024-05-25 03:19:47 [INFO]: Epoch 165 - training loss: 9216.1949, validation loss: 0.0970
2024-05-25 03:19:48 [INFO]: Epoch 166 - training loss: 9215.9842, validation loss: 0.0953
2024-05-25 03:19:48 [INFO]: Epoch 167 - training loss: 9215.2828, validation loss: 0.0986
2024-05-25 03:19:48 [INFO]: Epoch 168 - training loss: 9216.2080, validation loss: 0.0941
2024-05-25 03:19:48 [INFO]: Epoch 169 - training loss: 9216.0705, validation loss: 0.0989
2024-05-25 03:19:48 [INFO]: Epoch 170 - training loss: 9212.7026, validation loss: 0.0949
2024-05-25 03:19:48 [INFO]: Epoch 171 - training loss: 9214.4850, validation loss: 0.0943
2024-05-25 03:19:48 [INFO]: Epoch 172 - training loss: 9214.1476, validation loss: 0.0945
2024-05-25 03:19:48 [INFO]: Epoch 173 - training loss: 9211.6251, validation loss: 0.0938
2024-05-25 03:19:49 [INFO]: Epoch 174 - training loss: 9213.0645, validation loss: 0.0945
2024-05-25 03:19:49 [INFO]: Epoch 175 - training loss: 9212.5714, validation loss: 0.0943
2024-05-25 03:19:49 [INFO]: Epoch 176 - training loss: 9211.8673, validation loss: 0.0941
2024-05-25 03:19:49 [INFO]: Epoch 177 - training loss: 9213.1738, validation loss: 0.0943
2024-05-25 03:19:49 [INFO]: Epoch 178 - training loss: 9213.1075, validation loss: 0.0922
2024-05-25 03:19:49 [INFO]: Epoch 179 - training loss: 9211.4293, validation loss: 0.0924
2024-05-25 03:19:49 [INFO]: Epoch 180 - training loss: 9212.7585, validation loss: 0.0926
2024-05-25 03:19:49 [INFO]: Epoch 181 - training loss: 9212.7057, validation loss: 0.0925
2024-05-25 03:19:50 [INFO]: Epoch 182 - training loss: 9212.4189, validation loss: 0.0920
2024-05-25 03:19:50 [INFO]: Epoch 183 - training loss: 9211.6523, validation loss: 0.0913
2024-05-25 03:19:50 [INFO]: Epoch 184 - training loss: 9212.7490, validation loss: 0.0919
2024-05-25 03:19:50 [INFO]: Epoch 185 - training loss: 9211.9071, validation loss: 0.0914
2024-05-25 03:19:50 [INFO]: Epoch 186 - training loss: 9213.4144, validation loss: 0.0920
2024-05-25 03:19:50 [INFO]: Epoch 187 - training loss: 9211.6431, validation loss: 0.0898
2024-05-25 03:19:50 [INFO]: Epoch 188 - training loss: 9211.8139, validation loss: 0.0904
2024-05-25 03:19:50 [INFO]: Epoch 189 - training loss: 9211.0797, validation loss: 0.0900
2024-05-25 03:19:51 [INFO]: Epoch 190 - training loss: 9211.5519, validation loss: 0.0909
2024-05-25 03:19:51 [INFO]: Epoch 191 - training loss: 9211.5577, validation loss: 0.0904
2024-05-25 03:19:51 [INFO]: Epoch 192 - training loss: 9211.9218, validation loss: 0.0889
2024-05-25 03:19:51 [INFO]: Epoch 193 - training loss: 9211.9672, validation loss: 0.0882
2024-05-25 03:19:51 [INFO]: Epoch 194 - training loss: 9211.6414, validation loss: 0.0904
2024-05-25 03:19:51 [INFO]: Epoch 195 - training loss: 9212.3254, validation loss: 0.0905
2024-05-25 03:19:51 [INFO]: Epoch 196 - training loss: 9213.0701, validation loss: 0.0870
2024-05-25 03:19:51 [INFO]: Epoch 197 - training loss: 9210.6176, validation loss: 0.0916
2024-05-25 03:19:51 [INFO]: Epoch 198 - training loss: 9210.8159, validation loss: 0.0889
2024-05-25 03:19:52 [INFO]: Epoch 199 - training loss: 9210.1720, validation loss: 0.0893
2024-05-25 03:19:52 [INFO]: Epoch 200 - training loss: 9210.3096, validation loss: 0.0882
2024-05-25 03:19:52 [INFO]: Epoch 201 - training loss: 9209.5353, validation loss: 0.0888
2024-05-25 03:19:52 [INFO]: Epoch 202 - training loss: 9209.7529, validation loss: 0.0891
2024-05-25 03:19:52 [INFO]: Epoch 203 - training loss: 9209.8320, validation loss: 0.0873
2024-05-25 03:19:52 [INFO]: Epoch 204 - training loss: 9210.3810, validation loss: 0.0884
2024-05-25 03:19:52 [INFO]: Epoch 205 - training loss: 9211.1362, validation loss: 0.0887
2024-05-25 03:19:52 [INFO]: Epoch 206 - training loss: 9209.6392, validation loss: 0.0854
2024-05-25 03:19:53 [INFO]: Epoch 207 - training loss: 9209.5554, validation loss: 0.0873
2024-05-25 03:19:53 [INFO]: Epoch 208 - training loss: 9210.2430, validation loss: 0.0885
2024-05-25 03:19:53 [INFO]: Epoch 209 - training loss: 9208.3405, validation loss: 0.0877
2024-05-25 03:19:53 [INFO]: Epoch 210 - training loss: 9210.8293, validation loss: 0.0901
2024-05-25 03:19:53 [INFO]: Epoch 211 - training loss: 9210.9849, validation loss: 0.0875
2024-05-25 03:19:53 [INFO]: Epoch 212 - training loss: 9210.9719, validation loss: 0.0859
2024-05-25 03:19:53 [INFO]: Epoch 213 - training loss: 9209.0486, validation loss: 0.0857
2024-05-25 03:19:53 [INFO]: Epoch 214 - training loss: 9210.1805, validation loss: 0.0851
2024-05-25 03:19:54 [INFO]: Epoch 215 - training loss: 9211.8212, validation loss: 0.0862
2024-05-25 03:19:54 [INFO]: Epoch 216 - training loss: 9209.7966, validation loss: 0.0869
2024-05-25 03:19:54 [INFO]: Epoch 217 - training loss: 9208.0342, validation loss: 0.0861
2024-05-25 03:19:54 [INFO]: Epoch 218 - training loss: 9209.2956, validation loss: 0.0844
2024-05-25 03:19:54 [INFO]: Epoch 219 - training loss: 9207.6240, validation loss: 0.0849
2024-05-25 03:19:54 [INFO]: Epoch 220 - training loss: 9207.3941, validation loss: 0.0850
2024-05-25 03:19:54 [INFO]: Epoch 221 - training loss: 9208.3297, validation loss: 0.0856
2024-05-25 03:19:54 [INFO]: Epoch 222 - training loss: 9209.9954, validation loss: 0.0858
2024-05-25 03:19:55 [INFO]: Epoch 223 - training loss: 9209.7123, validation loss: 0.0859
2024-05-25 03:19:55 [INFO]: Epoch 224 - training loss: 9207.5401, validation loss: 0.0839
2024-05-25 03:19:55 [INFO]: Epoch 225 - training loss: 9208.6187, validation loss: 0.0862
2024-05-25 03:19:55 [INFO]: Epoch 226 - training loss: 9209.1373, validation loss: 0.0844
2024-05-25 03:19:55 [INFO]: Epoch 227 - training loss: 9209.6728, validation loss: 0.0888
2024-05-25 03:19:55 [INFO]: Epoch 228 - training loss: 9209.3049, validation loss: 0.0850
2024-05-25 03:19:55 [INFO]: Epoch 229 - training loss: 9209.3017, validation loss: 0.0868
2024-05-25 03:19:55 [INFO]: Epoch 230 - training loss: 9208.9260, validation loss: 0.0835
2024-05-25 03:19:56 [INFO]: Epoch 231 - training loss: 9208.5455, validation loss: 0.0854
2024-05-25 03:19:56 [INFO]: Epoch 232 - training loss: 9208.4807, validation loss: 0.0844
2024-05-25 03:19:56 [INFO]: Epoch 233 - training loss: 9208.1789, validation loss: 0.0840
2024-05-25 03:19:56 [INFO]: Epoch 234 - training loss: 9209.4478, validation loss: 0.0848
2024-05-25 03:19:56 [INFO]: Epoch 235 - training loss: 9209.6605, validation loss: 0.0806
2024-05-25 03:19:56 [INFO]: Epoch 236 - training loss: 9208.5300, validation loss: 0.0859
2024-05-25 03:19:56 [INFO]: Epoch 237 - training loss: 9209.3483, validation loss: 0.0827
2024-05-25 03:19:56 [INFO]: Epoch 238 - training loss: 9209.6779, validation loss: 0.0834
2024-05-25 03:19:56 [INFO]: Epoch 239 - training loss: 9207.6030, validation loss: 0.0835
2024-05-25 03:19:57 [INFO]: Epoch 240 - training loss: 9208.6198, validation loss: 0.0879
2024-05-25 03:19:57 [INFO]: Epoch 241 - training loss: 9207.8682, validation loss: 0.0853
2024-05-25 03:19:57 [INFO]: Epoch 242 - training loss: 9208.3994, validation loss: 0.0834
2024-05-25 03:19:57 [INFO]: Epoch 243 - training loss: 9208.1474, validation loss: 0.0817
2024-05-25 03:19:57 [INFO]: Epoch 244 - training loss: 9207.1682, validation loss: 0.0841
2024-05-25 03:19:57 [INFO]: Epoch 245 - training loss: 9207.3557, validation loss: 0.0855
2024-05-25 03:19:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:19:57 [INFO]: Finished training. The best model is from epoch#235.
2024-05-25 03:19:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/GPVAE_ettm1/20240525_T031927/GPVAE.pypots
2024-05-25 03:19:57 [INFO]: GP-VAE on ETTm1: MAE=0.2920, MSE=0.1872
2024-05-25 03:19:57 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/GPVAE_ettm1/imputation.pkl
2024-05-25 03:19:57 [INFO]: Using the given device: cuda:0
2024-05-25 03:19:57 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/USGAN_ettm1/20240525_T031957
2024-05-25 03:19:57 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/USGAN_ettm1/20240525_T031957/tensorboard
2024-05-25 03:19:57 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 03:20:08 [INFO]: Epoch 001 - generator training loss: 0.3948, discriminator training loss: 0.5431, validation loss: 0.3794
2024-05-25 03:20:17 [INFO]: Epoch 002 - generator training loss: -0.0706, discriminator training loss: 0.4747, validation loss: 0.1110
2024-05-25 03:20:25 [INFO]: Epoch 003 - generator training loss: -0.1695, discriminator training loss: 0.4338, validation loss: 0.0669
2024-05-25 03:20:34 [INFO]: Epoch 004 - generator training loss: -0.1569, discriminator training loss: 0.3772, validation loss: 0.0493
2024-05-25 03:20:43 [INFO]: Epoch 005 - generator training loss: -0.1163, discriminator training loss: 0.3019, validation loss: 0.0459
2024-05-25 03:20:51 [INFO]: Epoch 006 - generator training loss: -0.0792, discriminator training loss: 0.2390, validation loss: 0.0438
2024-05-25 03:21:00 [INFO]: Epoch 007 - generator training loss: -0.0665, discriminator training loss: 0.2033, validation loss: 0.0395
2024-05-25 03:21:09 [INFO]: Epoch 008 - generator training loss: -0.0625, discriminator training loss: 0.1866, validation loss: 0.0379
2024-05-25 03:21:18 [INFO]: Epoch 009 - generator training loss: -0.0610, discriminator training loss: 0.1795, validation loss: 0.0365
2024-05-25 03:21:26 [INFO]: Epoch 010 - generator training loss: -0.0576, discriminator training loss: 0.1788, validation loss: 0.0360
2024-05-25 03:21:35 [INFO]: Epoch 011 - generator training loss: -0.0605, discriminator training loss: 0.1761, validation loss: 0.0350
2024-05-25 03:21:44 [INFO]: Epoch 012 - generator training loss: -0.0598, discriminator training loss: 0.1713, validation loss: 0.0357
2024-05-25 03:21:52 [INFO]: Epoch 013 - generator training loss: -0.0608, discriminator training loss: 0.1735, validation loss: 0.0335
2024-05-25 03:22:01 [INFO]: Epoch 014 - generator training loss: -0.0631, discriminator training loss: 0.1723, validation loss: 0.0341
2024-05-25 03:22:10 [INFO]: Epoch 015 - generator training loss: -0.0612, discriminator training loss: 0.1706, validation loss: 0.0335
2024-05-25 03:22:18 [INFO]: Epoch 016 - generator training loss: -0.0620, discriminator training loss: 0.1734, validation loss: 0.0333
2024-05-25 03:22:27 [INFO]: Epoch 017 - generator training loss: -0.0621, discriminator training loss: 0.1711, validation loss: 0.0324
2024-05-25 03:22:36 [INFO]: Epoch 018 - generator training loss: -0.0623, discriminator training loss: 0.1701, validation loss: 0.0325
2024-05-25 03:22:45 [INFO]: Epoch 019 - generator training loss: -0.0633, discriminator training loss: 0.1697, validation loss: 0.0324
2024-05-25 03:22:53 [INFO]: Epoch 020 - generator training loss: -0.0624, discriminator training loss: 0.1685, validation loss: 0.0327
2024-05-25 03:23:02 [INFO]: Epoch 021 - generator training loss: -0.0652, discriminator training loss: 0.1679, validation loss: 0.0317
2024-05-25 03:23:11 [INFO]: Epoch 022 - generator training loss: -0.0655, discriminator training loss: 0.1696, validation loss: 0.0310
2024-05-25 03:23:20 [INFO]: Epoch 023 - generator training loss: -0.0626, discriminator training loss: 0.1688, validation loss: 0.0305
2024-05-25 03:23:29 [INFO]: Epoch 024 - generator training loss: -0.0654, discriminator training loss: 0.1682, validation loss: 0.0306
2024-05-25 03:23:37 [INFO]: Epoch 025 - generator training loss: -0.0663, discriminator training loss: 0.1706, validation loss: 0.0301
2024-05-25 03:23:46 [INFO]: Epoch 026 - generator training loss: -0.0647, discriminator training loss: 0.1691, validation loss: 0.0301
2024-05-25 03:23:55 [INFO]: Epoch 027 - generator training loss: -0.0646, discriminator training loss: 0.1680, validation loss: 0.0304
2024-05-25 03:24:03 [INFO]: Epoch 028 - generator training loss: -0.0653, discriminator training loss: 0.1651, validation loss: 0.0299
2024-05-25 03:24:12 [INFO]: Epoch 029 - generator training loss: -0.0692, discriminator training loss: 0.1662, validation loss: 0.0297
2024-05-25 03:24:21 [INFO]: Epoch 030 - generator training loss: -0.0657, discriminator training loss: 0.1651, validation loss: 0.0290
2024-05-25 03:24:29 [INFO]: Epoch 031 - generator training loss: -0.0720, discriminator training loss: 0.1657, validation loss: 0.0287
2024-05-25 03:24:38 [INFO]: Epoch 032 - generator training loss: -0.0677, discriminator training loss: 0.1674, validation loss: 0.0288
2024-05-25 03:24:47 [INFO]: Epoch 033 - generator training loss: -0.0660, discriminator training loss: 0.1686, validation loss: 0.0292
2024-05-25 03:24:55 [INFO]: Epoch 034 - generator training loss: -0.0679, discriminator training loss: 0.1670, validation loss: 0.0284
2024-05-25 03:25:04 [INFO]: Epoch 035 - generator training loss: -0.0709, discriminator training loss: 0.1687, validation loss: 0.0283
2024-05-25 03:25:13 [INFO]: Epoch 036 - generator training loss: -0.0665, discriminator training loss: 0.1647, validation loss: 0.0284
2024-05-25 03:25:22 [INFO]: Epoch 037 - generator training loss: -0.0676, discriminator training loss: 0.1667, validation loss: 0.0283
2024-05-25 03:25:30 [INFO]: Epoch 038 - generator training loss: -0.0688, discriminator training loss: 0.1656, validation loss: 0.0276
2024-05-25 03:25:39 [INFO]: Epoch 039 - generator training loss: -0.0692, discriminator training loss: 0.1668, validation loss: 0.0276
2024-05-25 03:25:48 [INFO]: Epoch 040 - generator training loss: -0.0705, discriminator training loss: 0.1666, validation loss: 0.0269
2024-05-25 03:25:57 [INFO]: Epoch 041 - generator training loss: -0.0708, discriminator training loss: 0.1650, validation loss: 0.0275
2024-05-25 03:26:05 [INFO]: Epoch 042 - generator training loss: -0.0708, discriminator training loss: 0.1650, validation loss: 0.0272
2024-05-25 03:26:14 [INFO]: Epoch 043 - generator training loss: -0.0682, discriminator training loss: 0.1666, validation loss: 0.0262
2024-05-25 03:26:23 [INFO]: Epoch 044 - generator training loss: -0.0708, discriminator training loss: 0.1641, validation loss: 0.0269
2024-05-25 03:26:32 [INFO]: Epoch 045 - generator training loss: -0.0702, discriminator training loss: 0.1648, validation loss: 0.0275
2024-05-25 03:26:40 [INFO]: Epoch 046 - generator training loss: -0.0710, discriminator training loss: 0.1643, validation loss: 0.0272
2024-05-25 03:26:49 [INFO]: Epoch 047 - generator training loss: -0.0710, discriminator training loss: 0.1652, validation loss: 0.0259
2024-05-25 03:26:58 [INFO]: Epoch 048 - generator training loss: -0.0711, discriminator training loss: 0.1650, validation loss: 0.0261
2024-05-25 03:27:06 [INFO]: Epoch 049 - generator training loss: -0.0691, discriminator training loss: 0.1654, validation loss: 0.0261
2024-05-25 03:27:15 [INFO]: Epoch 050 - generator training loss: -0.0703, discriminator training loss: 0.1663, validation loss: 0.0268
2024-05-25 03:27:24 [INFO]: Epoch 051 - generator training loss: -0.0700, discriminator training loss: 0.1661, validation loss: 0.0265
2024-05-25 03:27:33 [INFO]: Epoch 052 - generator training loss: -0.0707, discriminator training loss: 0.1657, validation loss: 0.0263
2024-05-25 03:27:41 [INFO]: Epoch 053 - generator training loss: -0.0685, discriminator training loss: 0.1651, validation loss: 0.0261
2024-05-25 03:27:50 [INFO]: Epoch 054 - generator training loss: -0.0684, discriminator training loss: 0.1649, validation loss: 0.0268
2024-05-25 03:27:59 [INFO]: Epoch 055 - generator training loss: -0.0704, discriminator training loss: 0.1637, validation loss: 0.0262
2024-05-25 03:28:07 [INFO]: Epoch 056 - generator training loss: -0.0675, discriminator training loss: 0.1640, validation loss: 0.0268
2024-05-25 03:28:16 [INFO]: Epoch 057 - generator training loss: -0.0705, discriminator training loss: 0.1643, validation loss: 0.0254
2024-05-25 03:28:25 [INFO]: Epoch 058 - generator training loss: -0.0707, discriminator training loss: 0.1634, validation loss: 0.0256
2024-05-25 03:28:34 [INFO]: Epoch 059 - generator training loss: -0.0704, discriminator training loss: 0.1654, validation loss: 0.0254
2024-05-25 03:28:42 [INFO]: Epoch 060 - generator training loss: -0.0691, discriminator training loss: 0.1652, validation loss: 0.0255
2024-05-25 03:28:51 [INFO]: Epoch 061 - generator training loss: -0.0704, discriminator training loss: 0.1626, validation loss: 0.0252
2024-05-25 03:29:00 [INFO]: Epoch 062 - generator training loss: -0.0704, discriminator training loss: 0.1627, validation loss: 0.0255
2024-05-25 03:29:09 [INFO]: Epoch 063 - generator training loss: -0.0713, discriminator training loss: 0.1622, validation loss: 0.0253
2024-05-25 03:29:17 [INFO]: Epoch 064 - generator training loss: -0.0719, discriminator training loss: 0.1639, validation loss: 0.0253
2024-05-25 03:29:26 [INFO]: Epoch 065 - generator training loss: -0.0730, discriminator training loss: 0.1643, validation loss: 0.0265
2024-05-25 03:29:35 [INFO]: Epoch 066 - generator training loss: -0.0683, discriminator training loss: 0.1626, validation loss: 0.0253
2024-05-25 03:29:44 [INFO]: Epoch 067 - generator training loss: -0.0726, discriminator training loss: 0.1627, validation loss: 0.0258
2024-05-25 03:29:52 [INFO]: Epoch 068 - generator training loss: -0.0696, discriminator training loss: 0.1636, validation loss: 0.0252
2024-05-25 03:30:01 [INFO]: Epoch 069 - generator training loss: -0.0690, discriminator training loss: 0.1642, validation loss: 0.0261
2024-05-25 03:30:10 [INFO]: Epoch 070 - generator training loss: -0.0726, discriminator training loss: 0.1628, validation loss: 0.0257
2024-05-25 03:30:18 [INFO]: Epoch 071 - generator training loss: -0.0704, discriminator training loss: 0.1625, validation loss: 0.0256
2024-05-25 03:30:27 [INFO]: Epoch 072 - generator training loss: -0.0703, discriminator training loss: 0.1617, validation loss: 0.0255
2024-05-25 03:30:36 [INFO]: Epoch 073 - generator training loss: -0.0698, discriminator training loss: 0.1630, validation loss: 0.0271
2024-05-25 03:30:44 [INFO]: Epoch 074 - generator training loss: -0.0689, discriminator training loss: 0.1626, validation loss: 0.0251
2024-05-25 03:30:53 [INFO]: Epoch 075 - generator training loss: -0.0697, discriminator training loss: 0.1638, validation loss: 0.0249
2024-05-25 03:31:02 [INFO]: Epoch 076 - generator training loss: -0.0763, discriminator training loss: 0.1628, validation loss: 0.0261
2024-05-25 03:31:10 [INFO]: Epoch 077 - generator training loss: -0.0670, discriminator training loss: 0.1628, validation loss: 0.0263
2024-05-25 03:31:19 [INFO]: Epoch 078 - generator training loss: -0.0679, discriminator training loss: 0.1627, validation loss: 0.0248
2024-05-25 03:31:28 [INFO]: Epoch 079 - generator training loss: -0.0713, discriminator training loss: 0.1618, validation loss: 0.0252
2024-05-25 03:31:37 [INFO]: Epoch 080 - generator training loss: -0.0696, discriminator training loss: 0.1635, validation loss: 0.0249
2024-05-25 03:31:45 [INFO]: Epoch 081 - generator training loss: -0.0731, discriminator training loss: 0.1619, validation loss: 0.0259
2024-05-25 03:31:54 [INFO]: Epoch 082 - generator training loss: -0.0697, discriminator training loss: 0.1619, validation loss: 0.0253
2024-05-25 03:32:03 [INFO]: Epoch 083 - generator training loss: -0.0714, discriminator training loss: 0.1619, validation loss: 0.0247
2024-05-25 03:32:12 [INFO]: Epoch 084 - generator training loss: -0.0723, discriminator training loss: 0.1626, validation loss: 0.0248
2024-05-25 03:32:21 [INFO]: Epoch 085 - generator training loss: -0.0710, discriminator training loss: 0.1616, validation loss: 0.0258
2024-05-25 03:32:29 [INFO]: Epoch 086 - generator training loss: -0.0729, discriminator training loss: 0.1607, validation loss: 0.0237
2024-05-25 03:32:38 [INFO]: Epoch 087 - generator training loss: -0.0704, discriminator training loss: 0.1647, validation loss: 0.0262
2024-05-25 03:32:47 [INFO]: Epoch 088 - generator training loss: -0.0692, discriminator training loss: 0.1612, validation loss: 0.0254
2024-05-25 03:32:56 [INFO]: Epoch 089 - generator training loss: -0.0712, discriminator training loss: 0.1614, validation loss: 0.0247
2024-05-25 03:33:05 [INFO]: Epoch 090 - generator training loss: -0.0719, discriminator training loss: 0.1583, validation loss: 0.0240
2024-05-25 03:33:13 [INFO]: Epoch 091 - generator training loss: -0.0719, discriminator training loss: 0.1598, validation loss: 0.0241
2024-05-25 03:33:22 [INFO]: Epoch 092 - generator training loss: -0.0728, discriminator training loss: 0.1610, validation loss: 0.0240
2024-05-25 03:33:31 [INFO]: Epoch 093 - generator training loss: -0.0723, discriminator training loss: 0.1612, validation loss: 0.0237
2024-05-25 03:33:40 [INFO]: Epoch 094 - generator training loss: -0.0734, discriminator training loss: 0.1590, validation loss: 0.0239
2024-05-25 03:33:48 [INFO]: Epoch 095 - generator training loss: -0.0724, discriminator training loss: 0.1594, validation loss: 0.0236
2024-05-25 03:33:57 [INFO]: Epoch 096 - generator training loss: -0.0727, discriminator training loss: 0.1594, validation loss: 0.0239
2024-05-25 03:34:06 [INFO]: Epoch 097 - generator training loss: -0.0743, discriminator training loss: 0.1616, validation loss: 0.0241
2024-05-25 03:34:15 [INFO]: Epoch 098 - generator training loss: -0.0714, discriminator training loss: 0.1592, validation loss: 0.0238
2024-05-25 03:34:23 [INFO]: Epoch 099 - generator training loss: -0.0706, discriminator training loss: 0.1603, validation loss: 0.0245
2024-05-25 03:34:32 [INFO]: Epoch 100 - generator training loss: -0.0729, discriminator training loss: 0.1590, validation loss: 0.0240
2024-05-25 03:34:41 [INFO]: Epoch 101 - generator training loss: -0.0704, discriminator training loss: 0.1588, validation loss: 0.0230
2024-05-25 03:34:49 [INFO]: Epoch 102 - generator training loss: -0.0717, discriminator training loss: 0.1607, validation loss: 0.0241
2024-05-25 03:34:58 [INFO]: Epoch 103 - generator training loss: -0.0729, discriminator training loss: 0.1577, validation loss: 0.0236
2024-05-25 03:35:07 [INFO]: Epoch 104 - generator training loss: -0.0727, discriminator training loss: 0.1587, validation loss: 0.0235
2024-05-25 03:35:15 [INFO]: Epoch 105 - generator training loss: -0.0697, discriminator training loss: 0.1592, validation loss: 0.0234
2024-05-25 03:35:24 [INFO]: Epoch 106 - generator training loss: -0.0733, discriminator training loss: 0.1595, validation loss: 0.0235
2024-05-25 03:35:33 [INFO]: Epoch 107 - generator training loss: -0.0709, discriminator training loss: 0.1583, validation loss: 0.0232
2024-05-25 03:35:41 [INFO]: Epoch 108 - generator training loss: -0.0742, discriminator training loss: 0.1568, validation loss: 0.0233
2024-05-25 03:35:50 [INFO]: Epoch 109 - generator training loss: -0.0732, discriminator training loss: 0.1593, validation loss: 0.0238
2024-05-25 03:35:59 [INFO]: Epoch 110 - generator training loss: -0.0742, discriminator training loss: 0.1569, validation loss: 0.0235
2024-05-25 03:36:07 [INFO]: Epoch 111 - generator training loss: -0.0737, discriminator training loss: 0.1594, validation loss: 0.0234
2024-05-25 03:36:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:36:07 [INFO]: Finished training. The best model is from epoch#101.
2024-05-25 03:36:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/USGAN_ettm1/20240525_T031957/USGAN.pypots
2024-05-25 03:36:08 [INFO]: US-GAN on ETTm1: MAE=0.1568, MSE=0.0634
2024-05-25 03:36:08 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/USGAN_ettm1/imputation.pkl
2024-05-25 03:36:08 [INFO]: Using the given device: cuda:0
2024-05-25 03:36:08 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/BRITS_ettm1/20240525_T033608
2024-05-25 03:36:08 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/BRITS_ettm1/20240525_T033608/tensorboard
2024-05-25 03:36:08 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 03:36:16 [INFO]: Epoch 001 - training loss: 1.3180, validation loss: 0.2991
2024-05-25 03:36:22 [INFO]: Epoch 002 - training loss: 0.9223, validation loss: 0.0964
2024-05-25 03:36:27 [INFO]: Epoch 003 - training loss: 0.7244, validation loss: 0.0659
2024-05-25 03:36:33 [INFO]: Epoch 004 - training loss: 0.6526, validation loss: 0.0513
2024-05-25 03:36:39 [INFO]: Epoch 005 - training loss: 0.5954, validation loss: 0.0441
2024-05-25 03:36:45 [INFO]: Epoch 006 - training loss: 0.5561, validation loss: 0.0412
2024-05-25 03:36:51 [INFO]: Epoch 007 - training loss: 0.5269, validation loss: 0.0369
2024-05-25 03:36:56 [INFO]: Epoch 008 - training loss: 0.5005, validation loss: 0.0341
2024-05-25 03:37:02 [INFO]: Epoch 009 - training loss: 0.5074, validation loss: 0.0340
2024-05-25 03:37:08 [INFO]: Epoch 010 - training loss: 0.4714, validation loss: 0.0348
2024-05-25 03:37:14 [INFO]: Epoch 011 - training loss: 0.4664, validation loss: 0.0313
2024-05-25 03:37:19 [INFO]: Epoch 012 - training loss: 0.4510, validation loss: 0.0303
2024-05-25 03:37:25 [INFO]: Epoch 013 - training loss: 0.4328, validation loss: 0.0293
2024-05-25 03:37:31 [INFO]: Epoch 014 - training loss: 0.4368, validation loss: 0.0288
2024-05-25 03:37:37 [INFO]: Epoch 015 - training loss: 0.4231, validation loss: 0.0284
2024-05-25 03:37:43 [INFO]: Epoch 016 - training loss: 0.4206, validation loss: 0.0280
2024-05-25 03:37:48 [INFO]: Epoch 017 - training loss: 0.4100, validation loss: 0.0268
2024-05-25 03:37:54 [INFO]: Epoch 018 - training loss: 0.4245, validation loss: 0.0288
2024-05-25 03:38:00 [INFO]: Epoch 019 - training loss: 0.4166, validation loss: 0.0269
2024-05-25 03:38:06 [INFO]: Epoch 020 - training loss: 0.4023, validation loss: 0.0268
2024-05-25 03:38:11 [INFO]: Epoch 021 - training loss: 0.4179, validation loss: 0.0275
2024-05-25 03:38:17 [INFO]: Epoch 022 - training loss: 0.4047, validation loss: 0.0272
2024-05-25 03:38:23 [INFO]: Epoch 023 - training loss: 0.4035, validation loss: 0.0267
2024-05-25 03:38:29 [INFO]: Epoch 024 - training loss: 0.4034, validation loss: 0.0266
2024-05-25 03:38:34 [INFO]: Epoch 025 - training loss: 0.3995, validation loss: 0.0269
2024-05-25 03:38:40 [INFO]: Epoch 026 - training loss: 0.3977, validation loss: 0.0265
2024-05-25 03:38:46 [INFO]: Epoch 027 - training loss: 0.3956, validation loss: 0.0269
2024-05-25 03:38:52 [INFO]: Epoch 028 - training loss: 0.3995, validation loss: 0.0266
2024-05-25 03:38:58 [INFO]: Epoch 029 - training loss: 0.4150, validation loss: 0.0266
2024-05-25 03:39:03 [INFO]: Epoch 030 - training loss: 0.4077, validation loss: 0.0266
2024-05-25 03:39:09 [INFO]: Epoch 031 - training loss: 0.4057, validation loss: 0.0281
2024-05-25 03:39:15 [INFO]: Epoch 032 - training loss: 0.4051, validation loss: 0.0269
2024-05-25 03:39:21 [INFO]: Epoch 033 - training loss: 0.4027, validation loss: 0.0272
2024-05-25 03:39:27 [INFO]: Epoch 034 - training loss: 0.3952, validation loss: 0.0267
2024-05-25 03:39:32 [INFO]: Epoch 035 - training loss: 0.3932, validation loss: 0.0264
2024-05-25 03:39:38 [INFO]: Epoch 036 - training loss: 0.3941, validation loss: 0.0264
2024-05-25 03:39:44 [INFO]: Epoch 037 - training loss: 0.3937, validation loss: 0.0271
2024-05-25 03:39:50 [INFO]: Epoch 038 - training loss: 0.4005, validation loss: 0.0264
2024-05-25 03:39:56 [INFO]: Epoch 039 - training loss: 0.3883, validation loss: 0.0315
2024-05-25 03:40:01 [INFO]: Epoch 040 - training loss: 0.4155, validation loss: 0.0299
2024-05-25 03:40:07 [INFO]: Epoch 041 - training loss: 0.3990, validation loss: 0.0271
2024-05-25 03:40:13 [INFO]: Epoch 042 - training loss: 0.3947, validation loss: 0.0262
2024-05-25 03:40:19 [INFO]: Epoch 043 - training loss: 0.3955, validation loss: 0.0267
2024-05-25 03:40:24 [INFO]: Epoch 044 - training loss: 0.3909, validation loss: 0.0263
2024-05-25 03:40:30 [INFO]: Epoch 045 - training loss: 0.3879, validation loss: 0.0263
2024-05-25 03:40:36 [INFO]: Epoch 046 - training loss: 0.3939, validation loss: 0.0260
2024-05-25 03:40:42 [INFO]: Epoch 047 - training loss: 0.3878, validation loss: 0.0266
2024-05-25 03:40:48 [INFO]: Epoch 048 - training loss: 0.3913, validation loss: 0.0268
2024-05-25 03:40:53 [INFO]: Epoch 049 - training loss: 0.4012, validation loss: 0.0268
2024-05-25 03:40:59 [INFO]: Epoch 050 - training loss: 0.3862, validation loss: 0.0282
2024-05-25 03:41:05 [INFO]: Epoch 051 - training loss: 0.4192, validation loss: 0.0278
2024-05-25 03:41:11 [INFO]: Epoch 052 - training loss: 0.3972, validation loss: 0.0269
2024-05-25 03:41:16 [INFO]: Epoch 053 - training loss: 0.3925, validation loss: 0.0269
2024-05-25 03:41:22 [INFO]: Epoch 054 - training loss: 0.3876, validation loss: 0.0262
2024-05-25 03:41:28 [INFO]: Epoch 055 - training loss: 0.3970, validation loss: 0.0260
2024-05-25 03:41:34 [INFO]: Epoch 056 - training loss: 0.3847, validation loss: 0.0264
2024-05-25 03:41:39 [INFO]: Epoch 057 - training loss: 0.3866, validation loss: 0.0259
2024-05-25 03:41:45 [INFO]: Epoch 058 - training loss: 0.3844, validation loss: 0.0261
2024-05-25 03:41:51 [INFO]: Epoch 059 - training loss: 0.3895, validation loss: 0.0268
2024-05-25 03:41:57 [INFO]: Epoch 060 - training loss: 0.3838, validation loss: 0.0260
2024-05-25 03:42:03 [INFO]: Epoch 061 - training loss: 0.3959, validation loss: 0.0273
2024-05-25 03:42:08 [INFO]: Epoch 062 - training loss: 0.3927, validation loss: 0.0267
2024-05-25 03:42:14 [INFO]: Epoch 063 - training loss: 0.3883, validation loss: 0.0261
2024-05-25 03:42:20 [INFO]: Epoch 064 - training loss: 0.3871, validation loss: 0.0270
2024-05-25 03:42:26 [INFO]: Epoch 065 - training loss: 0.3844, validation loss: 0.0270
2024-05-25 03:42:32 [INFO]: Epoch 066 - training loss: 0.3824, validation loss: 0.0272
2024-05-25 03:42:37 [INFO]: Epoch 067 - training loss: 0.3843, validation loss: 0.0264
2024-05-25 03:42:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:42:37 [INFO]: Finished training. The best model is from epoch#57.
2024-05-25 03:42:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/BRITS_ettm1/20240525_T033608/BRITS.pypots
2024-05-25 03:42:38 [INFO]: BRITS on ETTm1: MAE=0.1375, MSE=0.0552
2024-05-25 03:42:38 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/BRITS_ettm1/imputation.pkl
2024-05-25 03:42:38 [INFO]: Using the given device: cuda:0
2024-05-25 03:42:38 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238
2024-05-25 03:42:38 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/tensorboard
2024-05-25 03:42:38 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 03:42:40 [INFO]: Epoch 001 - training loss: 1.4387, validation loss: 1.2173
2024-05-25 03:42:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch1_loss1.2173486351966858.pypots
2024-05-25 03:42:41 [INFO]: Epoch 002 - training loss: 0.9946, validation loss: 1.0995
2024-05-25 03:42:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch2_loss1.0994778126478195.pypots
2024-05-25 03:42:41 [INFO]: Epoch 003 - training loss: 0.9202, validation loss: 1.0355
2024-05-25 03:42:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch3_loss1.0354903042316437.pypots
2024-05-25 03:42:41 [INFO]: Epoch 004 - training loss: 0.8760, validation loss: 1.0130
2024-05-25 03:42:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch4_loss1.0130037069320679.pypots
2024-05-25 03:42:41 [INFO]: Epoch 005 - training loss: 0.8881, validation loss: 1.0053
2024-05-25 03:42:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch5_loss1.0053391307592392.pypots
2024-05-25 03:42:41 [INFO]: Epoch 006 - training loss: 0.8855, validation loss: 0.9984
2024-05-25 03:42:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch6_loss0.9984049797058105.pypots
2024-05-25 03:42:41 [INFO]: Epoch 007 - training loss: 0.8691, validation loss: 0.9942
2024-05-25 03:42:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch7_loss0.9942358881235123.pypots
2024-05-25 03:42:42 [INFO]: Epoch 008 - training loss: 0.8630, validation loss: 0.9884
2024-05-25 03:42:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch8_loss0.9883711636066437.pypots
2024-05-25 03:42:42 [INFO]: Epoch 009 - training loss: 0.8429, validation loss: 0.9847
2024-05-25 03:42:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch9_loss0.9847359955310822.pypots
2024-05-25 03:42:42 [INFO]: Epoch 010 - training loss: 0.8376, validation loss: 0.9808
2024-05-25 03:42:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch10_loss0.9807538390159607.pypots
2024-05-25 03:42:42 [INFO]: Epoch 011 - training loss: 0.8173, validation loss: 0.9785
2024-05-25 03:42:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch11_loss0.9785401672124863.pypots
2024-05-25 03:42:42 [INFO]: Epoch 012 - training loss: 0.8381, validation loss: 0.9762
2024-05-25 03:42:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch12_loss0.9762256592512131.pypots
2024-05-25 03:42:43 [INFO]: Epoch 013 - training loss: 0.8106, validation loss: 0.9770
2024-05-25 03:42:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch13_loss0.9770106375217438.pypots
2024-05-25 03:42:43 [INFO]: Epoch 014 - training loss: 0.8181, validation loss: 0.9701
2024-05-25 03:42:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch14_loss0.970107689499855.pypots
2024-05-25 03:42:43 [INFO]: Epoch 015 - training loss: 0.7958, validation loss: 0.9657
2024-05-25 03:42:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch15_loss0.9657445996999741.pypots
2024-05-25 03:42:43 [INFO]: Epoch 016 - training loss: 0.8088, validation loss: 0.9609
2024-05-25 03:42:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch16_loss0.960854634642601.pypots
2024-05-25 03:42:43 [INFO]: Epoch 017 - training loss: 0.8109, validation loss: 0.9586
2024-05-25 03:42:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch17_loss0.9585854411125183.pypots
2024-05-25 03:42:44 [INFO]: Epoch 018 - training loss: 0.7952, validation loss: 0.9556
2024-05-25 03:42:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch18_loss0.9556179791688919.pypots
2024-05-25 03:42:44 [INFO]: Epoch 019 - training loss: 0.7920, validation loss: 0.9496
2024-05-25 03:42:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch19_loss0.9495884031057358.pypots
2024-05-25 03:42:44 [INFO]: Epoch 020 - training loss: 0.7933, validation loss: 0.9453
2024-05-25 03:42:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch20_loss0.9452771842479706.pypots
2024-05-25 03:42:44 [INFO]: Epoch 021 - training loss: 0.7835, validation loss: 0.9430
2024-05-25 03:42:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch21_loss0.9429944604635239.pypots
2024-05-25 03:42:44 [INFO]: Epoch 022 - training loss: 0.7801, validation loss: 0.9381
2024-05-25 03:42:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch22_loss0.9380972534418106.pypots
2024-05-25 03:42:44 [INFO]: Epoch 023 - training loss: 0.7601, validation loss: 0.9362
2024-05-25 03:42:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch23_loss0.9362138658761978.pypots
2024-05-25 03:42:45 [INFO]: Epoch 024 - training loss: 0.8022, validation loss: 0.9356
2024-05-25 03:42:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch24_loss0.9355756938457489.pypots
2024-05-25 03:42:45 [INFO]: Epoch 025 - training loss: 0.7837, validation loss: 0.9350
2024-05-25 03:42:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch25_loss0.934986487030983.pypots
2024-05-25 03:42:45 [INFO]: Epoch 026 - training loss: 0.7656, validation loss: 0.9302
2024-05-25 03:42:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch26_loss0.9302403628826141.pypots
2024-05-25 03:42:45 [INFO]: Epoch 027 - training loss: 0.7816, validation loss: 0.9284
2024-05-25 03:42:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch27_loss0.9284233450889587.pypots
2024-05-25 03:42:45 [INFO]: Epoch 028 - training loss: 0.7862, validation loss: 0.9288
2024-05-25 03:42:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch28_loss0.928807407617569.pypots
2024-05-25 03:42:46 [INFO]: Epoch 029 - training loss: 0.7784, validation loss: 0.9258
2024-05-25 03:42:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch29_loss0.9258228987455368.pypots
2024-05-25 03:42:46 [INFO]: Epoch 030 - training loss: 0.7671, validation loss: 0.9230
2024-05-25 03:42:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch30_loss0.9230158478021622.pypots
2024-05-25 03:42:46 [INFO]: Epoch 031 - training loss: 0.7699, validation loss: 0.9201
2024-05-25 03:42:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch31_loss0.9201311767101288.pypots
2024-05-25 03:42:46 [INFO]: Epoch 032 - training loss: 0.7447, validation loss: 0.9158
2024-05-25 03:42:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch32_loss0.9157819449901581.pypots
2024-05-25 03:42:46 [INFO]: Epoch 033 - training loss: 0.7545, validation loss: 0.9125
2024-05-25 03:42:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch33_loss0.9125204086303711.pypots
2024-05-25 03:42:47 [INFO]: Epoch 034 - training loss: 0.7633, validation loss: 0.9101
2024-05-25 03:42:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch34_loss0.9100576043128967.pypots
2024-05-25 03:42:47 [INFO]: Epoch 035 - training loss: 0.7586, validation loss: 0.9068
2024-05-25 03:42:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch35_loss0.9067746251821518.pypots
2024-05-25 03:42:47 [INFO]: Epoch 036 - training loss: 0.7558, validation loss: 0.9063
2024-05-25 03:42:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch36_loss0.9062585532665253.pypots
2024-05-25 03:42:47 [INFO]: Epoch 037 - training loss: 0.7797, validation loss: 0.9011
2024-05-25 03:42:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch37_loss0.9010836631059647.pypots
2024-05-25 03:42:47 [INFO]: Epoch 038 - training loss: 0.7728, validation loss: 0.8995
2024-05-25 03:42:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch38_loss0.8995081037282944.pypots
2024-05-25 03:42:47 [INFO]: Epoch 039 - training loss: 0.7684, validation loss: 0.8961
2024-05-25 03:42:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch39_loss0.8961074203252792.pypots
2024-05-25 03:42:48 [INFO]: Epoch 040 - training loss: 0.7799, validation loss: 0.8908
2024-05-25 03:42:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch40_loss0.8908233791589737.pypots
2024-05-25 03:42:48 [INFO]: Epoch 041 - training loss: 0.7493, validation loss: 0.8887
2024-05-25 03:42:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch41_loss0.8886736333370209.pypots
2024-05-25 03:42:48 [INFO]: Epoch 042 - training loss: 0.7689, validation loss: 0.8853
2024-05-25 03:42:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch42_loss0.8853455185890198.pypots
2024-05-25 03:42:48 [INFO]: Epoch 043 - training loss: 0.7629, validation loss: 0.8844
2024-05-25 03:42:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch43_loss0.8844442218542099.pypots
2024-05-25 03:42:48 [INFO]: Epoch 044 - training loss: 0.8015, validation loss: 0.8837
2024-05-25 03:42:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch44_loss0.8837316036224365.pypots
2024-05-25 03:42:49 [INFO]: Epoch 045 - training loss: 0.7599, validation loss: 0.8810
2024-05-25 03:42:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch45_loss0.8809858560562134.pypots
2024-05-25 03:42:49 [INFO]: Epoch 046 - training loss: 0.7474, validation loss: 0.8788
2024-05-25 03:42:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch46_loss0.8788106441497803.pypots
2024-05-25 03:42:49 [INFO]: Epoch 047 - training loss: 0.7483, validation loss: 0.8759
2024-05-25 03:42:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch47_loss0.8758949786424637.pypots
2024-05-25 03:42:49 [INFO]: Epoch 048 - training loss: 0.7364, validation loss: 0.8766
2024-05-25 03:42:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch48_loss0.8765723258256912.pypots
2024-05-25 03:42:49 [INFO]: Epoch 049 - training loss: 0.7325, validation loss: 0.8719
2024-05-25 03:42:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch49_loss0.8719064742326736.pypots
2024-05-25 03:42:50 [INFO]: Epoch 050 - training loss: 0.7397, validation loss: 0.8708
2024-05-25 03:42:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch50_loss0.8707803636789322.pypots
2024-05-25 03:42:50 [INFO]: Epoch 051 - training loss: 0.7796, validation loss: 0.8693
2024-05-25 03:42:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch51_loss0.8692817091941833.pypots
2024-05-25 03:42:50 [INFO]: Epoch 052 - training loss: 0.7376, validation loss: 0.8664
2024-05-25 03:42:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch52_loss0.8663524985313416.pypots
2024-05-25 03:42:50 [INFO]: Epoch 053 - training loss: 0.7424, validation loss: 0.8653
2024-05-25 03:42:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch53_loss0.865349605679512.pypots
2024-05-25 03:42:50 [INFO]: Epoch 054 - training loss: 0.7428, validation loss: 0.8658
2024-05-25 03:42:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch54_loss0.8657724559307098.pypots
2024-05-25 03:42:50 [INFO]: Epoch 055 - training loss: 0.7456, validation loss: 0.8643
2024-05-25 03:42:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch55_loss0.864314928650856.pypots
2024-05-25 03:42:51 [INFO]: Epoch 056 - training loss: 0.7383, validation loss: 0.8621
2024-05-25 03:42:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch56_loss0.8621058464050293.pypots
2024-05-25 03:42:51 [INFO]: Epoch 057 - training loss: 0.7300, validation loss: 0.8609
2024-05-25 03:42:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch57_loss0.8608917891979218.pypots
2024-05-25 03:42:51 [INFO]: Epoch 058 - training loss: 0.7404, validation loss: 0.8592
2024-05-25 03:42:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch58_loss0.8591654151678085.pypots
2024-05-25 03:42:51 [INFO]: Epoch 059 - training loss: 0.7679, validation loss: 0.8581
2024-05-25 03:42:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch59_loss0.8580541759729385.pypots
2024-05-25 03:42:51 [INFO]: Epoch 060 - training loss: 0.7275, validation loss: 0.8582
2024-05-25 03:42:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch60_loss0.8582102656364441.pypots
2024-05-25 03:42:52 [INFO]: Epoch 061 - training loss: 0.7341, validation loss: 0.8561
2024-05-25 03:42:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch61_loss0.8561042845249176.pypots
2024-05-25 03:42:52 [INFO]: Epoch 062 - training loss: 0.7381, validation loss: 0.8565
2024-05-25 03:42:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch62_loss0.8565329760313034.pypots
2024-05-25 03:42:52 [INFO]: Epoch 063 - training loss: 0.7450, validation loss: 0.8563
2024-05-25 03:42:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch63_loss0.8562633544206619.pypots
2024-05-25 03:42:52 [INFO]: Epoch 064 - training loss: 0.7458, validation loss: 0.8544
2024-05-25 03:42:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch64_loss0.8543802946805954.pypots
2024-05-25 03:42:52 [INFO]: Epoch 065 - training loss: 0.7171, validation loss: 0.8557
2024-05-25 03:42:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch65_loss0.8557208329439163.pypots
2024-05-25 03:42:53 [INFO]: Epoch 066 - training loss: 0.7304, validation loss: 0.8535
2024-05-25 03:42:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch66_loss0.8534739017486572.pypots
2024-05-25 03:42:53 [INFO]: Epoch 067 - training loss: 0.7366, validation loss: 0.8551
2024-05-25 03:42:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch67_loss0.8550586402416229.pypots
2024-05-25 03:42:53 [INFO]: Epoch 068 - training loss: 0.7229, validation loss: 0.8530
2024-05-25 03:42:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch68_loss0.8530402034521103.pypots
2024-05-25 03:42:53 [INFO]: Epoch 069 - training loss: 0.7194, validation loss: 0.8519
2024-05-25 03:42:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch69_loss0.8518952429294586.pypots
2024-05-25 03:42:53 [INFO]: Epoch 070 - training loss: 0.7329, validation loss: 0.8504
2024-05-25 03:42:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch70_loss0.850377231836319.pypots
2024-05-25 03:42:53 [INFO]: Epoch 071 - training loss: 0.7390, validation loss: 0.8522
2024-05-25 03:42:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch71_loss0.8522384613752365.pypots
2024-05-25 03:42:54 [INFO]: Epoch 072 - training loss: 0.7437, validation loss: 0.8494
2024-05-25 03:42:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch72_loss0.8494191020727158.pypots
2024-05-25 03:42:54 [INFO]: Epoch 073 - training loss: 0.7176, validation loss: 0.8483
2024-05-25 03:42:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch73_loss0.8482730984687805.pypots
2024-05-25 03:42:54 [INFO]: Epoch 074 - training loss: 0.7212, validation loss: 0.8472
2024-05-25 03:42:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch74_loss0.8471760302782059.pypots
2024-05-25 03:42:54 [INFO]: Epoch 075 - training loss: 0.7324, validation loss: 0.8461
2024-05-25 03:42:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch75_loss0.8461391776800156.pypots
2024-05-25 03:42:54 [INFO]: Epoch 076 - training loss: 0.7644, validation loss: 0.8454
2024-05-25 03:42:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch76_loss0.8454292565584183.pypots
2024-05-25 03:42:55 [INFO]: Epoch 077 - training loss: 0.7541, validation loss: 0.8497
2024-05-25 03:42:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch77_loss0.8497364372014999.pypots
2024-05-25 03:42:55 [INFO]: Epoch 078 - training loss: 0.7145, validation loss: 0.8498
2024-05-25 03:42:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch78_loss0.8498426228761673.pypots
2024-05-25 03:42:55 [INFO]: Epoch 079 - training loss: 0.7247, validation loss: 0.8459
2024-05-25 03:42:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch79_loss0.8459256589412689.pypots
2024-05-25 03:42:55 [INFO]: Epoch 080 - training loss: 0.7347, validation loss: 0.8464
2024-05-25 03:42:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch80_loss0.8464272916316986.pypots
2024-05-25 03:42:55 [INFO]: Epoch 081 - training loss: 0.7441, validation loss: 0.8453
2024-05-25 03:42:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch81_loss0.8453428894281387.pypots
2024-05-25 03:42:56 [INFO]: Epoch 082 - training loss: 0.7477, validation loss: 0.8449
2024-05-25 03:42:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch82_loss0.8448715358972549.pypots
2024-05-25 03:42:56 [INFO]: Epoch 083 - training loss: 0.7384, validation loss: 0.8418
2024-05-25 03:42:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch83_loss0.8418128788471222.pypots
2024-05-25 03:42:56 [INFO]: Epoch 084 - training loss: 0.7292, validation loss: 0.8437
2024-05-25 03:42:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch84_loss0.8436507433652878.pypots
2024-05-25 03:42:56 [INFO]: Epoch 085 - training loss: 0.7147, validation loss: 0.8417
2024-05-25 03:42:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch85_loss0.8416794985532761.pypots
2024-05-25 03:42:56 [INFO]: Epoch 086 - training loss: 0.7318, validation loss: 0.8429
2024-05-25 03:42:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch86_loss0.8428544998168945.pypots
2024-05-25 03:42:56 [INFO]: Epoch 087 - training loss: 0.7351, validation loss: 0.8392
2024-05-25 03:42:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch87_loss0.8392200917005539.pypots
2024-05-25 03:42:57 [INFO]: Epoch 088 - training loss: 0.7417, validation loss: 0.8468
2024-05-25 03:42:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch88_loss0.8468335866928101.pypots
2024-05-25 03:42:57 [INFO]: Epoch 089 - training loss: 0.7522, validation loss: 0.8386
2024-05-25 03:42:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch89_loss0.838597372174263.pypots
2024-05-25 03:42:57 [INFO]: Epoch 090 - training loss: 0.7262, validation loss: 0.8421
2024-05-25 03:42:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch90_loss0.8421474546194077.pypots
2024-05-25 03:42:57 [INFO]: Epoch 091 - training loss: 0.7130, validation loss: 0.8418
2024-05-25 03:42:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch91_loss0.8417944759130478.pypots
2024-05-25 03:42:57 [INFO]: Epoch 092 - training loss: 0.7180, validation loss: 0.8430
2024-05-25 03:42:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch92_loss0.8429608941078186.pypots
2024-05-25 03:42:58 [INFO]: Epoch 093 - training loss: 0.7294, validation loss: 0.8356
2024-05-25 03:42:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch93_loss0.8356121182441711.pypots
2024-05-25 03:42:58 [INFO]: Epoch 094 - training loss: 0.7397, validation loss: 0.8389
2024-05-25 03:42:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch94_loss0.8389168977737427.pypots
2024-05-25 03:42:58 [INFO]: Epoch 095 - training loss: 0.7363, validation loss: 0.8345
2024-05-25 03:42:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch95_loss0.8344788253307343.pypots
2024-05-25 03:42:58 [INFO]: Epoch 096 - training loss: 0.7250, validation loss: 0.8334
2024-05-25 03:42:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch96_loss0.833409994840622.pypots
2024-05-25 03:42:58 [INFO]: Epoch 097 - training loss: 0.7247, validation loss: 0.8380
2024-05-25 03:42:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch97_loss0.8380258679389954.pypots
2024-05-25 03:42:59 [INFO]: Epoch 098 - training loss: 0.7255, validation loss: 0.8343
2024-05-25 03:42:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch98_loss0.8342754542827606.pypots
2024-05-25 03:42:59 [INFO]: Epoch 099 - training loss: 0.7171, validation loss: 0.8344
2024-05-25 03:42:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch99_loss0.8343745172023773.pypots
2024-05-25 03:42:59 [INFO]: Epoch 100 - training loss: 0.7306, validation loss: 0.8323
2024-05-25 03:42:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch100_loss0.8323066830635071.pypots
2024-05-25 03:42:59 [INFO]: Epoch 101 - training loss: 0.7150, validation loss: 0.8306
2024-05-25 03:42:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch101_loss0.8305733352899551.pypots
2024-05-25 03:42:59 [INFO]: Epoch 102 - training loss: 0.7252, validation loss: 0.8322
2024-05-25 03:42:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch102_loss0.8321695923805237.pypots
2024-05-25 03:42:59 [INFO]: Epoch 103 - training loss: 0.7373, validation loss: 0.8330
2024-05-25 03:42:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch103_loss0.832969605922699.pypots
2024-05-25 03:43:00 [INFO]: Epoch 104 - training loss: 0.7249, validation loss: 0.8310
2024-05-25 03:43:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch104_loss0.8310432732105255.pypots
2024-05-25 03:43:00 [INFO]: Epoch 105 - training loss: 0.7219, validation loss: 0.8325
2024-05-25 03:43:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch105_loss0.8324778079986572.pypots
2024-05-25 03:43:00 [INFO]: Epoch 106 - training loss: 0.7307, validation loss: 0.8294
2024-05-25 03:43:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch106_loss0.829435721039772.pypots
2024-05-25 03:43:00 [INFO]: Epoch 107 - training loss: 0.7363, validation loss: 0.8304
2024-05-25 03:43:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch107_loss0.8304252326488495.pypots
2024-05-25 03:43:00 [INFO]: Epoch 108 - training loss: 0.7432, validation loss: 0.8280
2024-05-25 03:43:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch108_loss0.8279892653226852.pypots
2024-05-25 03:43:01 [INFO]: Epoch 109 - training loss: 0.7374, validation loss: 0.8259
2024-05-25 03:43:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch109_loss0.8259129226207733.pypots
2024-05-25 03:43:01 [INFO]: Epoch 110 - training loss: 0.7287, validation loss: 0.8288
2024-05-25 03:43:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch110_loss0.8288074731826782.pypots
2024-05-25 03:43:01 [INFO]: Epoch 111 - training loss: 0.7273, validation loss: 0.8256
2024-05-25 03:43:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch111_loss0.8256002217531204.pypots
2024-05-25 03:43:01 [INFO]: Epoch 112 - training loss: 0.7136, validation loss: 0.8220
2024-05-25 03:43:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch112_loss0.8219895213842392.pypots
2024-05-25 03:43:01 [INFO]: Epoch 113 - training loss: 0.7334, validation loss: 0.8230
2024-05-25 03:43:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch113_loss0.8229741752147675.pypots
2024-05-25 03:43:01 [INFO]: Epoch 114 - training loss: 0.7679, validation loss: 0.8227
2024-05-25 03:43:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch114_loss0.8226970136165619.pypots
2024-05-25 03:43:02 [INFO]: Epoch 115 - training loss: 0.7369, validation loss: 0.8213
2024-05-25 03:43:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch115_loss0.8213009834289551.pypots
2024-05-25 03:43:02 [INFO]: Epoch 116 - training loss: 0.7192, validation loss: 0.8220
2024-05-25 03:43:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch116_loss0.8219587653875351.pypots
2024-05-25 03:43:02 [INFO]: Epoch 117 - training loss: 0.7189, validation loss: 0.8217
2024-05-25 03:43:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch117_loss0.8217232376337051.pypots
2024-05-25 03:43:02 [INFO]: Epoch 118 - training loss: 0.7246, validation loss: 0.8229
2024-05-25 03:43:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch118_loss0.8229469805955887.pypots
2024-05-25 03:43:02 [INFO]: Epoch 119 - training loss: 0.7207, validation loss: 0.8224
2024-05-25 03:43:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch119_loss0.8224333077669144.pypots
2024-05-25 03:43:03 [INFO]: Epoch 120 - training loss: 0.7009, validation loss: 0.8195
2024-05-25 03:43:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch120_loss0.8195361793041229.pypots
2024-05-25 03:43:03 [INFO]: Epoch 121 - training loss: 0.7356, validation loss: 0.8190
2024-05-25 03:43:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch121_loss0.818989098072052.pypots
2024-05-25 03:43:03 [INFO]: Epoch 122 - training loss: 0.7125, validation loss: 0.8225
2024-05-25 03:43:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch122_loss0.8224725425243378.pypots
2024-05-25 03:43:03 [INFO]: Epoch 123 - training loss: 0.7241, validation loss: 0.8199
2024-05-25 03:43:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch123_loss0.8198695480823517.pypots
2024-05-25 03:43:03 [INFO]: Epoch 124 - training loss: 0.7740, validation loss: 0.8178
2024-05-25 03:43:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch124_loss0.8178370296955109.pypots
2024-05-25 03:43:04 [INFO]: Epoch 125 - training loss: 0.7383, validation loss: 0.8213
2024-05-25 03:43:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch125_loss0.8212968856096268.pypots
2024-05-25 03:43:04 [INFO]: Epoch 126 - training loss: 0.7197, validation loss: 0.8182
2024-05-25 03:43:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch126_loss0.8181956112384796.pypots
2024-05-25 03:43:04 [INFO]: Epoch 127 - training loss: 0.7180, validation loss: 0.8185
2024-05-25 03:43:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch127_loss0.8185308575630188.pypots
2024-05-25 03:43:04 [INFO]: Epoch 128 - training loss: 0.7231, validation loss: 0.8184
2024-05-25 03:43:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch128_loss0.8183845281600952.pypots
2024-05-25 03:43:04 [INFO]: Epoch 129 - training loss: 0.7359, validation loss: 0.8158
2024-05-25 03:43:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch129_loss0.8157761096954346.pypots
2024-05-25 03:43:04 [INFO]: Epoch 130 - training loss: 0.7041, validation loss: 0.8154
2024-05-25 03:43:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch130_loss0.8153654336929321.pypots
2024-05-25 03:43:05 [INFO]: Epoch 131 - training loss: 0.7143, validation loss: 0.8165
2024-05-25 03:43:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch131_loss0.8164977878332138.pypots
2024-05-25 03:43:05 [INFO]: Epoch 132 - training loss: 0.7232, validation loss: 0.8137
2024-05-25 03:43:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch132_loss0.8136731386184692.pypots
2024-05-25 03:43:05 [INFO]: Epoch 133 - training loss: 0.7241, validation loss: 0.8137
2024-05-25 03:43:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch133_loss0.8136778026819229.pypots
2024-05-25 03:43:05 [INFO]: Epoch 134 - training loss: 0.7293, validation loss: 0.8140
2024-05-25 03:43:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch134_loss0.8139748573303223.pypots
2024-05-25 03:43:05 [INFO]: Epoch 135 - training loss: 0.7160, validation loss: 0.8165
2024-05-25 03:43:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch135_loss0.8165473192930222.pypots
2024-05-25 03:43:06 [INFO]: Epoch 136 - training loss: 0.7398, validation loss: 0.8094
2024-05-25 03:43:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch136_loss0.8094367980957031.pypots
2024-05-25 03:43:06 [INFO]: Epoch 137 - training loss: 0.7166, validation loss: 0.8135
2024-05-25 03:43:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch137_loss0.8134805411100388.pypots
2024-05-25 03:43:06 [INFO]: Epoch 138 - training loss: 0.7259, validation loss: 0.8134
2024-05-25 03:43:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch138_loss0.813444659113884.pypots
2024-05-25 03:43:06 [INFO]: Epoch 139 - training loss: 0.7281, validation loss: 0.8109
2024-05-25 03:43:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch139_loss0.8109360188245773.pypots
2024-05-25 03:43:06 [INFO]: Epoch 140 - training loss: 0.7365, validation loss: 0.8130
2024-05-25 03:43:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch140_loss0.813044011592865.pypots
2024-05-25 03:43:07 [INFO]: Epoch 141 - training loss: 0.7233, validation loss: 0.8100
2024-05-25 03:43:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch141_loss0.80999855697155.pypots
2024-05-25 03:43:07 [INFO]: Epoch 142 - training loss: 0.7171, validation loss: 0.8083
2024-05-25 03:43:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch142_loss0.8082991540431976.pypots
2024-05-25 03:43:07 [INFO]: Epoch 143 - training loss: 0.7225, validation loss: 0.8065
2024-05-25 03:43:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch143_loss0.8065239042043686.pypots
2024-05-25 03:43:07 [INFO]: Epoch 144 - training loss: 0.7153, validation loss: 0.8082
2024-05-25 03:43:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch144_loss0.8082160800695419.pypots
2024-05-25 03:43:07 [INFO]: Epoch 145 - training loss: 0.7077, validation loss: 0.8077
2024-05-25 03:43:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch145_loss0.8076836913824081.pypots
2024-05-25 03:43:07 [INFO]: Epoch 146 - training loss: 0.7062, validation loss: 0.8070
2024-05-25 03:43:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch146_loss0.8070334494113922.pypots
2024-05-25 03:43:08 [INFO]: Epoch 147 - training loss: 0.7249, validation loss: 0.8076
2024-05-25 03:43:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch147_loss0.807554230093956.pypots
2024-05-25 03:43:08 [INFO]: Epoch 148 - training loss: 0.7370, validation loss: 0.8088
2024-05-25 03:43:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch148_loss0.8087592422962189.pypots
2024-05-25 03:43:08 [INFO]: Epoch 149 - training loss: 0.7085, validation loss: 0.8060
2024-05-25 03:43:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch149_loss0.8059554696083069.pypots
2024-05-25 03:43:08 [INFO]: Epoch 150 - training loss: 0.7139, validation loss: 0.8067
2024-05-25 03:43:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch150_loss0.8066554665565491.pypots
2024-05-25 03:43:08 [INFO]: Epoch 151 - training loss: 0.7220, validation loss: 0.8113
2024-05-25 03:43:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch151_loss0.8112928569316864.pypots
2024-05-25 03:43:09 [INFO]: Epoch 152 - training loss: 0.6995, validation loss: 0.8053
2024-05-25 03:43:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch152_loss0.8052684515714645.pypots
2024-05-25 03:43:09 [INFO]: Epoch 153 - training loss: 0.7162, validation loss: 0.8052
2024-05-25 03:43:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch153_loss0.8051729202270508.pypots
2024-05-25 03:43:09 [INFO]: Epoch 154 - training loss: 0.7051, validation loss: 0.8034
2024-05-25 03:43:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch154_loss0.80344258248806.pypots
2024-05-25 03:43:09 [INFO]: Epoch 155 - training loss: 0.7228, validation loss: 0.8046
2024-05-25 03:43:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch155_loss0.8045636862516403.pypots
2024-05-25 03:43:09 [INFO]: Epoch 156 - training loss: 0.7212, validation loss: 0.8033
2024-05-25 03:43:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch156_loss0.8033190071582794.pypots
2024-05-25 03:43:10 [INFO]: Epoch 157 - training loss: 0.6954, validation loss: 0.8057
2024-05-25 03:43:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch157_loss0.8057208061218262.pypots
2024-05-25 03:43:10 [INFO]: Epoch 158 - training loss: 0.7190, validation loss: 0.8019
2024-05-25 03:43:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch158_loss0.8018720746040344.pypots
2024-05-25 03:43:10 [INFO]: Epoch 159 - training loss: 0.7017, validation loss: 0.8024
2024-05-25 03:43:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch159_loss0.8024393320083618.pypots
2024-05-25 03:43:10 [INFO]: Epoch 160 - training loss: 0.7114, validation loss: 0.8000
2024-05-25 03:43:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch160_loss0.7999969869852066.pypots
2024-05-25 03:43:10 [INFO]: Epoch 161 - training loss: 0.7031, validation loss: 0.8039
2024-05-25 03:43:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch161_loss0.8038768172264099.pypots
2024-05-25 03:43:10 [INFO]: Epoch 162 - training loss: 0.7169, validation loss: 0.8017
2024-05-25 03:43:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch162_loss0.8016655892133713.pypots
2024-05-25 03:43:11 [INFO]: Epoch 163 - training loss: 0.7068, validation loss: 0.8015
2024-05-25 03:43:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch163_loss0.8014673888683319.pypots
2024-05-25 03:43:11 [INFO]: Epoch 164 - training loss: 0.7277, validation loss: 0.8053
2024-05-25 03:43:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch164_loss0.8052972704172134.pypots
2024-05-25 03:43:11 [INFO]: Epoch 165 - training loss: 0.7310, validation loss: 0.7995
2024-05-25 03:43:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch165_loss0.799540102481842.pypots
2024-05-25 03:43:11 [INFO]: Epoch 166 - training loss: 0.7135, validation loss: 0.8020
2024-05-25 03:43:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch166_loss0.8019875884056091.pypots
2024-05-25 03:43:11 [INFO]: Epoch 167 - training loss: 0.7067, validation loss: 0.8016
2024-05-25 03:43:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch167_loss0.8016407489776611.pypots
2024-05-25 03:43:12 [INFO]: Epoch 168 - training loss: 0.7281, validation loss: 0.7992
2024-05-25 03:43:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch168_loss0.7992083728313446.pypots
2024-05-25 03:43:12 [INFO]: Epoch 169 - training loss: 0.7280, validation loss: 0.8017
2024-05-25 03:43:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch169_loss0.8017481416463852.pypots
2024-05-25 03:43:12 [INFO]: Epoch 170 - training loss: 0.7057, validation loss: 0.7963
2024-05-25 03:43:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch170_loss0.7962560653686523.pypots
2024-05-25 03:43:12 [INFO]: Epoch 171 - training loss: 0.7043, validation loss: 0.7968
2024-05-25 03:43:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch171_loss0.7967867404222488.pypots
2024-05-25 03:43:12 [INFO]: Epoch 172 - training loss: 0.7093, validation loss: 0.7957
2024-05-25 03:43:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch172_loss0.7957349866628647.pypots
2024-05-25 03:43:13 [INFO]: Epoch 173 - training loss: 0.7201, validation loss: 0.7979
2024-05-25 03:43:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch173_loss0.7978867292404175.pypots
2024-05-25 03:43:13 [INFO]: Epoch 174 - training loss: 0.7169, validation loss: 0.8002
2024-05-25 03:43:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch174_loss0.8001983016729355.pypots
2024-05-25 03:43:13 [INFO]: Epoch 175 - training loss: 0.7038, validation loss: 0.7972
2024-05-25 03:43:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch175_loss0.7971639037132263.pypots
2024-05-25 03:43:13 [INFO]: Epoch 176 - training loss: 0.7124, validation loss: 0.7959
2024-05-25 03:43:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch176_loss0.7959106266498566.pypots
2024-05-25 03:43:13 [INFO]: Epoch 177 - training loss: 0.7064, validation loss: 0.7993
2024-05-25 03:43:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch177_loss0.7993285953998566.pypots
2024-05-25 03:43:13 [INFO]: Epoch 178 - training loss: 0.7659, validation loss: 0.7991
2024-05-25 03:43:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch178_loss0.7991199940443039.pypots
2024-05-25 03:43:14 [INFO]: Epoch 179 - training loss: 0.7122, validation loss: 0.7988
2024-05-25 03:43:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch179_loss0.798785075545311.pypots
2024-05-25 03:43:14 [INFO]: Epoch 180 - training loss: 0.7180, validation loss: 0.7972
2024-05-25 03:43:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch180_loss0.797160804271698.pypots
2024-05-25 03:43:14 [INFO]: Epoch 181 - training loss: 0.7260, validation loss: 0.7966
2024-05-25 03:43:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch181_loss0.7965995818376541.pypots
2024-05-25 03:43:14 [INFO]: Epoch 182 - training loss: 0.7027, validation loss: 0.7965
2024-05-25 03:43:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN_epoch182_loss0.7964586317539215.pypots
2024-05-25 03:43:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:43:14 [INFO]: Finished training. The best model is from epoch#172.
2024-05-25 03:43:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T034238/MRNN.pypots
2024-05-25 03:43:15 [INFO]: MRNN on ETTm1: MAE=0.6082, MSE=0.9949
2024-05-25 03:43:15 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/MRNN_ettm1/imputation.pkl
2024-05-25 03:43:15 [INFO]: Using the given device: cpu
2024-05-25 03:43:15 [INFO]: LOCF on ETTm1: MAE=0.1420, MSE=0.0788
2024-05-25 03:43:15 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_ettm1".
2024-05-25 03:43:15 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/LOCF_ettm1/imputation.pkl
2024-05-25 03:43:15 [INFO]: Median on ETTm1: MAE=0.6533, MSE=0.8148
2024-05-25 03:43:15 [INFO]: Successfully created the given path "saved_results/round_0/Median_ettm1".
2024-05-25 03:43:15 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Median_ettm1/imputation.pkl
2024-05-25 03:43:15 [INFO]: Mean on ETTm1: MAE=0.6593, MSE=0.7994
2024-05-25 03:43:15 [INFO]: Successfully created the given path "saved_results/round_0/Mean_ettm1".
2024-05-25 03:43:15 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Mean_ettm1/imputation.pkl
2024-05-25 03:43:15 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-25 03:43:15 [INFO]: Using the given device: cuda:0
2024-05-25 03:43:15 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/SAITS_ettm1/20240525_T034315
2024-05-25 03:43:15 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/SAITS_ettm1/20240525_T034315/tensorboard
2024-05-25 03:43:15 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 03:43:15 [INFO]: Epoch 001 - training loss: 1.1207, validation loss: 0.2972
2024-05-25 03:43:16 [INFO]: Epoch 002 - training loss: 0.8156, validation loss: 0.1425
2024-05-25 03:43:16 [INFO]: Epoch 003 - training loss: 0.7262, validation loss: 0.1078
2024-05-25 03:43:17 [INFO]: Epoch 004 - training loss: 0.6731, validation loss: 0.0876
2024-05-25 03:43:17 [INFO]: Epoch 005 - training loss: 0.6294, validation loss: 0.0752
2024-05-25 03:43:18 [INFO]: Epoch 006 - training loss: 0.5991, validation loss: 0.0778
2024-05-25 03:43:18 [INFO]: Epoch 007 - training loss: 0.5731, validation loss: 0.0665
2024-05-25 03:43:19 [INFO]: Epoch 008 - training loss: 0.5608, validation loss: 0.0698
2024-05-25 03:43:19 [INFO]: Epoch 009 - training loss: 0.5622, validation loss: 0.0750
2024-05-25 03:43:20 [INFO]: Epoch 010 - training loss: 0.5391, validation loss: 0.0609
2024-05-25 03:43:20 [INFO]: Epoch 011 - training loss: 0.5160, validation loss: 0.0642
2024-05-25 03:43:21 [INFO]: Epoch 012 - training loss: 0.5202, validation loss: 0.0602
2024-05-25 03:43:21 [INFO]: Epoch 013 - training loss: 0.4947, validation loss: 0.0534
2024-05-25 03:43:22 [INFO]: Epoch 014 - training loss: 0.4976, validation loss: 0.0529
2024-05-25 03:43:22 [INFO]: Epoch 015 - training loss: 0.4891, validation loss: 0.0523
2024-05-25 03:43:23 [INFO]: Epoch 016 - training loss: 0.4720, validation loss: 0.0439
2024-05-25 03:43:23 [INFO]: Epoch 017 - training loss: 0.4668, validation loss: 0.0509
2024-05-25 03:43:23 [INFO]: Epoch 018 - training loss: 0.4664, validation loss: 0.0452
2024-05-25 03:43:24 [INFO]: Epoch 019 - training loss: 0.4600, validation loss: 0.0450
2024-05-25 03:43:24 [INFO]: Epoch 020 - training loss: 0.4507, validation loss: 0.0478
2024-05-25 03:43:25 [INFO]: Epoch 021 - training loss: 0.4406, validation loss: 0.0467
2024-05-25 03:43:25 [INFO]: Epoch 022 - training loss: 0.4257, validation loss: 0.0470
2024-05-25 03:43:26 [INFO]: Epoch 023 - training loss: 0.4276, validation loss: 0.0485
2024-05-25 03:43:26 [INFO]: Epoch 024 - training loss: 0.4154, validation loss: 0.0471
2024-05-25 03:43:27 [INFO]: Epoch 025 - training loss: 0.4230, validation loss: 0.0496
2024-05-25 03:43:27 [INFO]: Epoch 026 - training loss: 0.4230, validation loss: 0.1304
2024-05-25 03:43:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:43:27 [INFO]: Finished training. The best model is from epoch#16.
2024-05-25 03:43:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/SAITS_ettm1/20240525_T034315/SAITS.pypots
2024-05-25 03:43:27 [INFO]: SAITS on ETTm1: MAE=0.1902, MSE=0.0716
2024-05-25 03:43:27 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/SAITS_ettm1/imputation.pkl
2024-05-25 03:43:27 [INFO]: Using the given device: cuda:0
2024-05-25 03:43:27 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/Transformer_ettm1/20240525_T034327
2024-05-25 03:43:27 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/Transformer_ettm1/20240525_T034327/tensorboard
2024-05-25 03:43:28 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 03:43:28 [INFO]: Epoch 001 - training loss: 1.1878, validation loss: 0.3592
2024-05-25 03:43:28 [INFO]: Epoch 002 - training loss: 0.6997, validation loss: 0.1771
2024-05-25 03:43:28 [INFO]: Epoch 003 - training loss: 0.5820, validation loss: 0.1414
2024-05-25 03:43:28 [INFO]: Epoch 004 - training loss: 0.5170, validation loss: 0.1135
2024-05-25 03:43:28 [INFO]: Epoch 005 - training loss: 0.4775, validation loss: 0.0958
2024-05-25 03:43:29 [INFO]: Epoch 006 - training loss: 0.4694, validation loss: 0.0839
2024-05-25 03:43:29 [INFO]: Epoch 007 - training loss: 0.4306, validation loss: 0.0753
2024-05-25 03:43:29 [INFO]: Epoch 008 - training loss: 0.4086, validation loss: 0.0719
2024-05-25 03:43:29 [INFO]: Epoch 009 - training loss: 0.4058, validation loss: 0.0662
2024-05-25 03:43:29 [INFO]: Epoch 010 - training loss: 0.3936, validation loss: 0.0664
2024-05-25 03:43:30 [INFO]: Epoch 011 - training loss: 0.3821, validation loss: 0.0636
2024-05-25 03:43:30 [INFO]: Epoch 012 - training loss: 0.3745, validation loss: 0.0575
2024-05-25 03:43:30 [INFO]: Epoch 013 - training loss: 0.3515, validation loss: 0.0530
2024-05-25 03:43:30 [INFO]: Epoch 014 - training loss: 0.3499, validation loss: 0.0547
2024-05-25 03:43:30 [INFO]: Epoch 015 - training loss: 0.3485, validation loss: 0.0514
2024-05-25 03:43:31 [INFO]: Epoch 016 - training loss: 0.3324, validation loss: 0.0470
2024-05-25 03:43:31 [INFO]: Epoch 017 - training loss: 0.3206, validation loss: 0.0486
2024-05-25 03:43:31 [INFO]: Epoch 018 - training loss: 0.3184, validation loss: 0.0473
2024-05-25 03:43:31 [INFO]: Epoch 019 - training loss: 0.3157, validation loss: 0.0482
2024-05-25 03:43:31 [INFO]: Epoch 020 - training loss: 0.3192, validation loss: 0.0459
2024-05-25 03:43:32 [INFO]: Epoch 021 - training loss: 0.3151, validation loss: 0.0482
2024-05-25 03:43:32 [INFO]: Epoch 022 - training loss: 0.3061, validation loss: 0.0462
2024-05-25 03:43:32 [INFO]: Epoch 023 - training loss: 0.3104, validation loss: 0.0443
2024-05-25 03:43:32 [INFO]: Epoch 024 - training loss: 0.2960, validation loss: 0.0398
2024-05-25 03:43:32 [INFO]: Epoch 025 - training loss: 0.2884, validation loss: 0.0412
2024-05-25 03:43:33 [INFO]: Epoch 026 - training loss: 0.2925, validation loss: 0.0500
2024-05-25 03:43:33 [INFO]: Epoch 027 - training loss: 0.2950, validation loss: 0.0385
2024-05-25 03:43:33 [INFO]: Epoch 028 - training loss: 0.2857, validation loss: 0.0385
2024-05-25 03:43:33 [INFO]: Epoch 029 - training loss: 0.2760, validation loss: 0.0367
2024-05-25 03:43:33 [INFO]: Epoch 030 - training loss: 0.2739, validation loss: 0.0368
2024-05-25 03:43:34 [INFO]: Epoch 031 - training loss: 0.2696, validation loss: 0.0354
2024-05-25 03:43:34 [INFO]: Epoch 032 - training loss: 0.2675, validation loss: 0.0353
2024-05-25 03:43:34 [INFO]: Epoch 033 - training loss: 0.2616, validation loss: 0.0353
2024-05-25 03:43:34 [INFO]: Epoch 034 - training loss: 0.2590, validation loss: 0.0328
2024-05-25 03:43:34 [INFO]: Epoch 035 - training loss: 0.2560, validation loss: 0.0337
2024-05-25 03:43:35 [INFO]: Epoch 036 - training loss: 0.2526, validation loss: 0.0342
2024-05-25 03:43:35 [INFO]: Epoch 037 - training loss: 0.2528, validation loss: 0.0320
2024-05-25 03:43:35 [INFO]: Epoch 038 - training loss: 0.2456, validation loss: 0.0344
2024-05-25 03:43:35 [INFO]: Epoch 039 - training loss: 0.2540, validation loss: 0.0304
2024-05-25 03:43:35 [INFO]: Epoch 040 - training loss: 0.2431, validation loss: 0.0340
2024-05-25 03:43:35 [INFO]: Epoch 041 - training loss: 0.2444, validation loss: 0.0313
2024-05-25 03:43:36 [INFO]: Epoch 042 - training loss: 0.2439, validation loss: 0.0305
2024-05-25 03:43:36 [INFO]: Epoch 043 - training loss: 0.2364, validation loss: 0.0308
2024-05-25 03:43:36 [INFO]: Epoch 044 - training loss: 0.2350, validation loss: 0.0308
2024-05-25 03:43:36 [INFO]: Epoch 045 - training loss: 0.2380, validation loss: 0.0315
2024-05-25 03:43:36 [INFO]: Epoch 046 - training loss: 0.2307, validation loss: 0.0306
2024-05-25 03:43:37 [INFO]: Epoch 047 - training loss: 0.2331, validation loss: 0.0317
2024-05-25 03:43:37 [INFO]: Epoch 048 - training loss: 0.2319, validation loss: 0.0298
2024-05-25 03:43:37 [INFO]: Epoch 049 - training loss: 0.2280, validation loss: 0.0317
2024-05-25 03:43:37 [INFO]: Epoch 050 - training loss: 0.2368, validation loss: 0.0323
2024-05-25 03:43:37 [INFO]: Epoch 051 - training loss: 0.2333, validation loss: 0.0301
2024-05-25 03:43:38 [INFO]: Epoch 052 - training loss: 0.2284, validation loss: 0.0273
2024-05-25 03:43:38 [INFO]: Epoch 053 - training loss: 0.2202, validation loss: 0.0307
2024-05-25 03:43:38 [INFO]: Epoch 054 - training loss: 0.2233, validation loss: 0.0304
2024-05-25 03:43:38 [INFO]: Epoch 055 - training loss: 0.2217, validation loss: 0.0278
2024-05-25 03:43:38 [INFO]: Epoch 056 - training loss: 0.2164, validation loss: 0.0272
2024-05-25 03:43:39 [INFO]: Epoch 057 - training loss: 0.2156, validation loss: 0.0319
2024-05-25 03:43:39 [INFO]: Epoch 058 - training loss: 0.2249, validation loss: 0.0265
2024-05-25 03:43:39 [INFO]: Epoch 059 - training loss: 0.2130, validation loss: 0.0266
2024-05-25 03:43:39 [INFO]: Epoch 060 - training loss: 0.2150, validation loss: 0.0292
2024-05-25 03:43:39 [INFO]: Epoch 061 - training loss: 0.2158, validation loss: 0.0295
2024-05-25 03:43:40 [INFO]: Epoch 062 - training loss: 0.2114, validation loss: 0.0275
2024-05-25 03:43:40 [INFO]: Epoch 063 - training loss: 0.2102, validation loss: 0.0289
2024-05-25 03:43:40 [INFO]: Epoch 064 - training loss: 0.2065, validation loss: 0.0292
2024-05-25 03:43:40 [INFO]: Epoch 065 - training loss: 0.2155, validation loss: 0.0310
2024-05-25 03:43:40 [INFO]: Epoch 066 - training loss: 0.2318, validation loss: 0.0300
2024-05-25 03:43:41 [INFO]: Epoch 067 - training loss: 0.2272, validation loss: 0.0274
2024-05-25 03:43:41 [INFO]: Epoch 068 - training loss: 0.2099, validation loss: 0.0259
2024-05-25 03:43:41 [INFO]: Epoch 069 - training loss: 0.2050, validation loss: 0.0254
2024-05-25 03:43:41 [INFO]: Epoch 070 - training loss: 0.1986, validation loss: 0.0282
2024-05-25 03:43:41 [INFO]: Epoch 071 - training loss: 0.2063, validation loss: 0.0276
2024-05-25 03:43:41 [INFO]: Epoch 072 - training loss: 0.2039, validation loss: 0.0258
2024-05-25 03:43:42 [INFO]: Epoch 073 - training loss: 0.2013, validation loss: 0.0260
2024-05-25 03:43:42 [INFO]: Epoch 074 - training loss: 0.2034, validation loss: 0.0258
2024-05-25 03:43:42 [INFO]: Epoch 075 - training loss: 0.2032, validation loss: 0.0249
2024-05-25 03:43:42 [INFO]: Epoch 076 - training loss: 0.1954, validation loss: 0.0254
2024-05-25 03:43:42 [INFO]: Epoch 077 - training loss: 0.2008, validation loss: 0.0255
2024-05-25 03:43:43 [INFO]: Epoch 078 - training loss: 0.1971, validation loss: 0.0248
2024-05-25 03:43:43 [INFO]: Epoch 079 - training loss: 0.1941, validation loss: 0.0253
2024-05-25 03:43:43 [INFO]: Epoch 080 - training loss: 0.1947, validation loss: 0.0260
2024-05-25 03:43:43 [INFO]: Epoch 081 - training loss: 0.1954, validation loss: 0.0258
2024-05-25 03:43:43 [INFO]: Epoch 082 - training loss: 0.1958, validation loss: 0.0264
2024-05-25 03:43:44 [INFO]: Epoch 083 - training loss: 0.2021, validation loss: 0.0263
2024-05-25 03:43:44 [INFO]: Epoch 084 - training loss: 0.1967, validation loss: 0.0243
2024-05-25 03:43:44 [INFO]: Epoch 085 - training loss: 0.1915, validation loss: 0.0261
2024-05-25 03:43:44 [INFO]: Epoch 086 - training loss: 0.1953, validation loss: 0.0259
2024-05-25 03:43:44 [INFO]: Epoch 087 - training loss: 0.1934, validation loss: 0.0262
2024-05-25 03:43:45 [INFO]: Epoch 088 - training loss: 0.1931, validation loss: 0.0257
2024-05-25 03:43:45 [INFO]: Epoch 089 - training loss: 0.1897, validation loss: 0.0238
2024-05-25 03:43:45 [INFO]: Epoch 090 - training loss: 0.1902, validation loss: 0.0267
2024-05-25 03:43:45 [INFO]: Epoch 091 - training loss: 0.1927, validation loss: 0.0260
2024-05-25 03:43:45 [INFO]: Epoch 092 - training loss: 0.1892, validation loss: 0.0244
2024-05-25 03:43:46 [INFO]: Epoch 093 - training loss: 0.1884, validation loss: 0.0251
2024-05-25 03:43:46 [INFO]: Epoch 094 - training loss: 0.1903, validation loss: 0.0263
2024-05-25 03:43:46 [INFO]: Epoch 095 - training loss: 0.1850, validation loss: 0.0249
2024-05-25 03:43:46 [INFO]: Epoch 096 - training loss: 0.1873, validation loss: 0.0258
2024-05-25 03:43:46 [INFO]: Epoch 097 - training loss: 0.1861, validation loss: 0.0240
2024-05-25 03:43:47 [INFO]: Epoch 098 - training loss: 0.1824, validation loss: 0.0248
2024-05-25 03:43:47 [INFO]: Epoch 099 - training loss: 0.1845, validation loss: 0.0245
2024-05-25 03:43:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:43:47 [INFO]: Finished training. The best model is from epoch#89.
2024-05-25 03:43:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/Transformer_ettm1/20240525_T034327/Transformer.pypots
2024-05-25 03:43:47 [INFO]: Transformer on ETTm1: MAE=0.1332, MSE=0.0366
2024-05-25 03:43:47 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Transformer_ettm1/imputation.pkl
2024-05-25 03:43:47 [INFO]: Using the given device: cuda:0
2024-05-25 03:43:47 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/TimesNet_ettm1/20240525_T034347
2024-05-25 03:43:47 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/TimesNet_ettm1/20240525_T034347/tensorboard
2024-05-25 03:43:47 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 03:43:47 [INFO]: Epoch 001 - training loss: 0.1526, validation loss: 0.0564
2024-05-25 03:43:47 [INFO]: Epoch 002 - training loss: 0.0618, validation loss: 0.0431
2024-05-25 03:43:48 [INFO]: Epoch 003 - training loss: 0.0518, validation loss: 0.0359
2024-05-25 03:43:48 [INFO]: Epoch 004 - training loss: 0.0478, validation loss: 0.0349
2024-05-25 03:43:48 [INFO]: Epoch 005 - training loss: 0.0441, validation loss: 0.0325
2024-05-25 03:43:48 [INFO]: Epoch 006 - training loss: 0.0415, validation loss: 0.0312
2024-05-25 03:43:48 [INFO]: Epoch 007 - training loss: 0.0392, validation loss: 0.0312
2024-05-25 03:43:48 [INFO]: Epoch 008 - training loss: 0.0405, validation loss: 0.0314
2024-05-25 03:43:49 [INFO]: Epoch 009 - training loss: 0.0387, validation loss: 0.0301
2024-05-25 03:43:49 [INFO]: Epoch 010 - training loss: 0.0383, validation loss: 0.0305
2024-05-25 03:43:49 [INFO]: Epoch 011 - training loss: 0.0395, validation loss: 0.0313
2024-05-25 03:43:49 [INFO]: Epoch 012 - training loss: 0.0419, validation loss: 0.0306
2024-05-25 03:43:49 [INFO]: Epoch 013 - training loss: 0.0398, validation loss: 0.0299
2024-05-25 03:43:50 [INFO]: Epoch 014 - training loss: 0.0369, validation loss: 0.0292
2024-05-25 03:43:50 [INFO]: Epoch 015 - training loss: 0.0369, validation loss: 0.0300
2024-05-25 03:43:50 [INFO]: Epoch 016 - training loss: 0.0384, validation loss: 0.0319
2024-05-25 03:43:50 [INFO]: Epoch 017 - training loss: 0.0423, validation loss: 0.0317
2024-05-25 03:43:50 [INFO]: Epoch 018 - training loss: 0.0389, validation loss: 0.0298
2024-05-25 03:43:51 [INFO]: Epoch 019 - training loss: 0.0340, validation loss: 0.0286
2024-05-25 03:43:51 [INFO]: Epoch 020 - training loss: 0.0327, validation loss: 0.0295
2024-05-25 03:43:51 [INFO]: Epoch 021 - training loss: 0.0347, validation loss: 0.0302
2024-05-25 03:43:51 [INFO]: Epoch 022 - training loss: 0.0356, validation loss: 0.0294
2024-05-25 03:43:51 [INFO]: Epoch 023 - training loss: 0.0323, validation loss: 0.0290
2024-05-25 03:43:51 [INFO]: Epoch 024 - training loss: 0.0322, validation loss: 0.0277
2024-05-25 03:43:52 [INFO]: Epoch 025 - training loss: 0.0320, validation loss: 0.0293
2024-05-25 03:43:52 [INFO]: Epoch 026 - training loss: 0.0304, validation loss: 0.0276
2024-05-25 03:43:52 [INFO]: Epoch 027 - training loss: 0.0295, validation loss: 0.0281
2024-05-25 03:43:52 [INFO]: Epoch 028 - training loss: 0.0288, validation loss: 0.0275
2024-05-25 03:43:52 [INFO]: Epoch 029 - training loss: 0.0286, validation loss: 0.0276
2024-05-25 03:43:53 [INFO]: Epoch 030 - training loss: 0.0290, validation loss: 0.0287
2024-05-25 03:43:53 [INFO]: Epoch 031 - training loss: 0.0294, validation loss: 0.0285
2024-05-25 03:43:53 [INFO]: Epoch 032 - training loss: 0.0282, validation loss: 0.0281
2024-05-25 03:43:53 [INFO]: Epoch 033 - training loss: 0.0278, validation loss: 0.0276
2024-05-25 03:43:53 [INFO]: Epoch 034 - training loss: 0.0261, validation loss: 0.0271
2024-05-25 03:43:54 [INFO]: Epoch 035 - training loss: 0.0263, validation loss: 0.0277
2024-05-25 03:43:54 [INFO]: Epoch 036 - training loss: 0.0288, validation loss: 0.0274
2024-05-25 03:43:54 [INFO]: Epoch 037 - training loss: 0.0279, validation loss: 0.0278
2024-05-25 03:43:54 [INFO]: Epoch 038 - training loss: 0.0279, validation loss: 0.0281
2024-05-25 03:43:54 [INFO]: Epoch 039 - training loss: 0.0270, validation loss: 0.0272
2024-05-25 03:43:54 [INFO]: Epoch 040 - training loss: 0.0248, validation loss: 0.0273
2024-05-25 03:43:55 [INFO]: Epoch 041 - training loss: 0.0245, validation loss: 0.0282
2024-05-25 03:43:55 [INFO]: Epoch 042 - training loss: 0.0262, validation loss: 0.0281
2024-05-25 03:43:55 [INFO]: Epoch 043 - training loss: 0.0233, validation loss: 0.0275
2024-05-25 03:43:55 [INFO]: Epoch 044 - training loss: 0.0228, validation loss: 0.0275
2024-05-25 03:43:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:43:55 [INFO]: Finished training. The best model is from epoch#34.
2024-05-25 03:43:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/TimesNet_ettm1/20240525_T034347/TimesNet.pypots
2024-05-25 03:43:55 [INFO]: TimesNet on ETTm1: MAE=0.1146, MSE=0.0285
2024-05-25 03:43:55 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/TimesNet_ettm1/imputation.pkl
2024-05-25 03:43:55 [INFO]: Using the given device: cuda:0
2024-05-25 03:43:55 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355
2024-05-25 03:43:55 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/tensorboard
2024-05-25 03:43:55 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 03:43:57 [INFO]: Epoch 001 - training loss: 0.7106, validation loss: 0.4636
2024-05-25 03:43:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch1_loss0.46358004212379456.pypots
2024-05-25 03:43:59 [INFO]: Epoch 002 - training loss: 0.4063, validation loss: 0.3696
2024-05-25 03:43:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch2_loss0.3695702478289604.pypots
2024-05-25 03:44:01 [INFO]: Epoch 003 - training loss: 0.3300, validation loss: 0.3360
2024-05-25 03:44:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch3_loss0.3359944596886635.pypots
2024-05-25 03:44:03 [INFO]: Epoch 004 - training loss: 0.3370, validation loss: 0.3022
2024-05-25 03:44:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch4_loss0.3021722659468651.pypots
2024-05-25 03:44:05 [INFO]: Epoch 005 - training loss: 0.3030, validation loss: 0.2804
2024-05-25 03:44:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch5_loss0.2803851291537285.pypots
2024-05-25 03:44:08 [INFO]: Epoch 006 - training loss: 0.3359, validation loss: 0.2902
2024-05-25 03:44:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch6_loss0.29022733867168427.pypots
2024-05-25 03:44:10 [INFO]: Epoch 007 - training loss: 0.2699, validation loss: 0.2674
2024-05-25 03:44:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch7_loss0.2674291878938675.pypots
2024-05-25 03:44:12 [INFO]: Epoch 008 - training loss: 0.2762, validation loss: 0.2575
2024-05-25 03:44:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch8_loss0.25754011422395706.pypots
2024-05-25 03:44:14 [INFO]: Epoch 009 - training loss: 0.3011, validation loss: 0.2602
2024-05-25 03:44:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch9_loss0.2601998373866081.pypots
2024-05-25 03:44:16 [INFO]: Epoch 010 - training loss: 0.2496, validation loss: 0.2415
2024-05-25 03:44:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch10_loss0.24149973317980766.pypots
2024-05-25 03:44:18 [INFO]: Epoch 011 - training loss: 0.2162, validation loss: 0.2206
2024-05-25 03:44:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch11_loss0.22061742842197418.pypots
2024-05-25 03:44:20 [INFO]: Epoch 012 - training loss: 0.2145, validation loss: 0.2081
2024-05-25 03:44:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch12_loss0.20807207375764847.pypots
2024-05-25 03:44:22 [INFO]: Epoch 013 - training loss: 0.1874, validation loss: 0.2013
2024-05-25 03:44:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch13_loss0.20130326971411705.pypots
2024-05-25 03:44:24 [INFO]: Epoch 014 - training loss: 0.2346, validation loss: 0.2074
2024-05-25 03:44:24 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch14_loss0.2073868028819561.pypots
2024-05-25 03:44:26 [INFO]: Epoch 015 - training loss: 0.1957, validation loss: 0.2016
2024-05-25 03:44:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch15_loss0.20158682391047478.pypots
2024-05-25 03:44:28 [INFO]: Epoch 016 - training loss: 0.1990, validation loss: 0.1953
2024-05-25 03:44:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch16_loss0.19531674310564995.pypots
2024-05-25 03:44:30 [INFO]: Epoch 017 - training loss: 0.1971, validation loss: 0.1874
2024-05-25 03:44:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch17_loss0.18742744997143745.pypots
2024-05-25 03:44:32 [INFO]: Epoch 018 - training loss: 0.2035, validation loss: 0.1849
2024-05-25 03:44:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch18_loss0.18486246839165688.pypots
2024-05-25 03:44:34 [INFO]: Epoch 019 - training loss: 0.2404, validation loss: 0.1891
2024-05-25 03:44:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch19_loss0.18908118829131126.pypots
2024-05-25 03:44:36 [INFO]: Epoch 020 - training loss: 0.2162, validation loss: 0.1858
2024-05-25 03:44:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch20_loss0.1858392097055912.pypots
2024-05-25 03:44:38 [INFO]: Epoch 021 - training loss: 0.1936, validation loss: 0.1965
2024-05-25 03:44:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch21_loss0.19645000621676445.pypots
2024-05-25 03:44:40 [INFO]: Epoch 022 - training loss: 0.2383, validation loss: 0.2374
2024-05-25 03:44:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch22_loss0.23739253729581833.pypots
2024-05-25 03:44:42 [INFO]: Epoch 023 - training loss: 0.2666, validation loss: 0.1967
2024-05-25 03:44:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch23_loss0.196744404733181.pypots
2024-05-25 03:44:44 [INFO]: Epoch 024 - training loss: 0.1929, validation loss: 0.1806
2024-05-25 03:44:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch24_loss0.18057356774806976.pypots
2024-05-25 03:44:46 [INFO]: Epoch 025 - training loss: 0.1739, validation loss: 0.1749
2024-05-25 03:44:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch25_loss0.17493239045143127.pypots
2024-05-25 03:44:48 [INFO]: Epoch 026 - training loss: 0.1822, validation loss: 0.1668
2024-05-25 03:44:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch26_loss0.16679731756448746.pypots
2024-05-25 03:44:51 [INFO]: Epoch 027 - training loss: 0.1788, validation loss: 0.1646
2024-05-25 03:44:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch27_loss0.16464083641767502.pypots
2024-05-25 03:44:53 [INFO]: Epoch 028 - training loss: 0.2368, validation loss: 0.1605
2024-05-25 03:44:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch28_loss0.16051801294088364.pypots
2024-05-25 03:44:55 [INFO]: Epoch 029 - training loss: 0.2248, validation loss: 0.1601
2024-05-25 03:44:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch29_loss0.16006826236844063.pypots
2024-05-25 03:44:57 [INFO]: Epoch 030 - training loss: 0.1711, validation loss: 0.1575
2024-05-25 03:44:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch30_loss0.15749529004096985.pypots
2024-05-25 03:44:59 [INFO]: Epoch 031 - training loss: 0.1651, validation loss: 0.1542
2024-05-25 03:44:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch31_loss0.15419267863035202.pypots
2024-05-25 03:45:01 [INFO]: Epoch 032 - training loss: 0.1597, validation loss: 0.1559
2024-05-25 03:45:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch32_loss0.15587486326694489.pypots
2024-05-25 03:45:03 [INFO]: Epoch 033 - training loss: 0.1415, validation loss: 0.1518
2024-05-25 03:45:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch33_loss0.1518414169549942.pypots
2024-05-25 03:45:05 [INFO]: Epoch 034 - training loss: 0.2165, validation loss: 0.1579
2024-05-25 03:45:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch34_loss0.1579338200390339.pypots
2024-05-25 03:45:07 [INFO]: Epoch 035 - training loss: 0.1786, validation loss: 0.1536
2024-05-25 03:45:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch35_loss0.15362128615379333.pypots
2024-05-25 03:45:09 [INFO]: Epoch 036 - training loss: 0.1936, validation loss: 0.1521
2024-05-25 03:45:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch36_loss0.15212729945778847.pypots
2024-05-25 03:45:11 [INFO]: Epoch 037 - training loss: 0.2317, validation loss: 0.1643
2024-05-25 03:45:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch37_loss0.1642647683620453.pypots
2024-05-25 03:45:13 [INFO]: Epoch 038 - training loss: 0.2158, validation loss: 0.1624
2024-05-25 03:45:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch38_loss0.16243701800704002.pypots
2024-05-25 03:45:15 [INFO]: Epoch 039 - training loss: 0.1489, validation loss: 0.1574
2024-05-25 03:45:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch39_loss0.15736760944128036.pypots
2024-05-25 03:45:17 [INFO]: Epoch 040 - training loss: 0.1566, validation loss: 0.1519
2024-05-25 03:45:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch40_loss0.15192099660634995.pypots
2024-05-25 03:45:19 [INFO]: Epoch 041 - training loss: 0.1515, validation loss: 0.1429
2024-05-25 03:45:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch41_loss0.1428515464067459.pypots
2024-05-25 03:45:21 [INFO]: Epoch 042 - training loss: 0.1868, validation loss: 0.1574
2024-05-25 03:45:21 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch42_loss0.1573650985956192.pypots
2024-05-25 03:45:23 [INFO]: Epoch 043 - training loss: 0.1600, validation loss: 0.1478
2024-05-25 03:45:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch43_loss0.1478343941271305.pypots
2024-05-25 03:45:25 [INFO]: Epoch 044 - training loss: 0.1582, validation loss: 0.1391
2024-05-25 03:45:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch44_loss0.13907888904213905.pypots
2024-05-25 03:45:27 [INFO]: Epoch 045 - training loss: 0.1520, validation loss: 0.1403
2024-05-25 03:45:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch45_loss0.14027059450745583.pypots
2024-05-25 03:45:29 [INFO]: Epoch 046 - training loss: 0.1538, validation loss: 0.1412
2024-05-25 03:45:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch46_loss0.14118118584156036.pypots
2024-05-25 03:45:31 [INFO]: Epoch 047 - training loss: 0.1270, validation loss: 0.1405
2024-05-25 03:45:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch47_loss0.14049381390213966.pypots
2024-05-25 03:45:33 [INFO]: Epoch 048 - training loss: 0.1476, validation loss: 0.1374
2024-05-25 03:45:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch48_loss0.13741816580295563.pypots
2024-05-25 03:45:35 [INFO]: Epoch 049 - training loss: 0.1340, validation loss: 0.1383
2024-05-25 03:45:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch49_loss0.13831393420696259.pypots
2024-05-25 03:45:37 [INFO]: Epoch 050 - training loss: 0.1463, validation loss: 0.1545
2024-05-25 03:45:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch50_loss0.15448428317904472.pypots
2024-05-25 03:45:40 [INFO]: Epoch 051 - training loss: 0.1492, validation loss: 0.1465
2024-05-25 03:45:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch51_loss0.14648199453949928.pypots
2024-05-25 03:45:42 [INFO]: Epoch 052 - training loss: 0.1299, validation loss: 0.1356
2024-05-25 03:45:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch52_loss0.13557574711740017.pypots
2024-05-25 03:45:44 [INFO]: Epoch 053 - training loss: 0.1511, validation loss: 0.1339
2024-05-25 03:45:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch53_loss0.1338856052607298.pypots
2024-05-25 03:45:46 [INFO]: Epoch 054 - training loss: 0.1347, validation loss: 0.1308
2024-05-25 03:45:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch54_loss0.13083837367594242.pypots
2024-05-25 03:45:48 [INFO]: Epoch 055 - training loss: 0.1154, validation loss: 0.1297
2024-05-25 03:45:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch55_loss0.1296671461313963.pypots
2024-05-25 03:45:50 [INFO]: Epoch 056 - training loss: 0.1336, validation loss: 0.1286
2024-05-25 03:45:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch56_loss0.12860279716551304.pypots
2024-05-25 03:45:52 [INFO]: Epoch 057 - training loss: 0.1282, validation loss: 0.1279
2024-05-25 03:45:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch57_loss0.12789305858314037.pypots
2024-05-25 03:45:54 [INFO]: Epoch 058 - training loss: 0.1557, validation loss: 0.1298
2024-05-25 03:45:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch58_loss0.12976757250726223.pypots
2024-05-25 03:45:56 [INFO]: Epoch 059 - training loss: 0.1882, validation loss: 0.1345
2024-05-25 03:45:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch59_loss0.1345108523964882.pypots
2024-05-25 03:45:58 [INFO]: Epoch 060 - training loss: 0.1378, validation loss: 0.1484
2024-05-25 03:45:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch60_loss0.1483621932566166.pypots
2024-05-25 03:46:00 [INFO]: Epoch 061 - training loss: 0.1453, validation loss: 0.1430
2024-05-25 03:46:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch61_loss0.14297020435333252.pypots
2024-05-25 03:46:02 [INFO]: Epoch 062 - training loss: 0.1501, validation loss: 0.1333
2024-05-25 03:46:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch62_loss0.13326673954725266.pypots
2024-05-25 03:46:04 [INFO]: Epoch 063 - training loss: 0.1838, validation loss: 0.1444
2024-05-25 03:46:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch63_loss0.14439242333173752.pypots
2024-05-25 03:46:06 [INFO]: Epoch 064 - training loss: 0.1820, validation loss: 0.1558
2024-05-25 03:46:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch64_loss0.1558050811290741.pypots
2024-05-25 03:46:08 [INFO]: Epoch 065 - training loss: 0.1575, validation loss: 0.1418
2024-05-25 03:46:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch65_loss0.14178242534399033.pypots
2024-05-25 03:46:10 [INFO]: Epoch 066 - training loss: 0.1441, validation loss: 0.1382
2024-05-25 03:46:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch66_loss0.13824178278446198.pypots
2024-05-25 03:46:12 [INFO]: Epoch 067 - training loss: 0.1299, validation loss: 0.1355
2024-05-25 03:46:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI_epoch67_loss0.13546523079276085.pypots
2024-05-25 03:46:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:46:12 [INFO]: Finished training. The best model is from epoch#57.
2024-05-25 03:46:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T034355/CSDI.pypots
2024-05-25 03:46:28 [INFO]: CSDI on ETTm1: MAE=0.1293, MSE=0.0418
2024-05-25 03:46:28 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/CSDI_ettm1/imputation.pkl
2024-05-25 03:46:28 [INFO]: Using the given device: cuda:0
2024-05-25 03:46:28 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/GPVAE_ettm1/20240525_T034628
2024-05-25 03:46:28 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/GPVAE_ettm1/20240525_T034628/tensorboard
2024-05-25 03:46:28 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 03:46:28 [INFO]: Epoch 001 - training loss: 23366.0515, validation loss: 0.9522
2024-05-25 03:46:29 [INFO]: Epoch 002 - training loss: 21361.5410, validation loss: 0.9413
2024-05-25 03:46:29 [INFO]: Epoch 003 - training loss: 19593.6829, validation loss: 0.9279
2024-05-25 03:46:29 [INFO]: Epoch 004 - training loss: 17377.2308, validation loss: 0.9085
2024-05-25 03:46:29 [INFO]: Epoch 005 - training loss: 15603.8826, validation loss: 0.8685
2024-05-25 03:46:29 [INFO]: Epoch 006 - training loss: 14029.6614, validation loss: 0.8138
2024-05-25 03:46:29 [INFO]: Epoch 007 - training loss: 12795.8972, validation loss: 0.7183
2024-05-25 03:46:29 [INFO]: Epoch 008 - training loss: 11890.2101, validation loss: 0.6507
2024-05-25 03:46:29 [INFO]: Epoch 009 - training loss: 11299.0727, validation loss: 0.6234
2024-05-25 03:46:30 [INFO]: Epoch 010 - training loss: 11035.1727, validation loss: 0.5882
2024-05-25 03:46:30 [INFO]: Epoch 011 - training loss: 10618.8010, validation loss: 0.5519
2024-05-25 03:46:30 [INFO]: Epoch 012 - training loss: 10429.6041, validation loss: 0.5065
2024-05-25 03:46:30 [INFO]: Epoch 013 - training loss: 10191.6837, validation loss: 0.4803
2024-05-25 03:46:30 [INFO]: Epoch 014 - training loss: 10033.2202, validation loss: 0.4631
2024-05-25 03:46:30 [INFO]: Epoch 015 - training loss: 9938.5412, validation loss: 0.4484
2024-05-25 03:46:30 [INFO]: Epoch 016 - training loss: 9848.0214, validation loss: 0.4093
2024-05-25 03:46:30 [INFO]: Epoch 017 - training loss: 9783.0749, validation loss: 0.3921
2024-05-25 03:46:30 [INFO]: Epoch 018 - training loss: 9762.2944, validation loss: 0.3698
2024-05-25 03:46:31 [INFO]: Epoch 019 - training loss: 9669.5452, validation loss: 0.3574
2024-05-25 03:46:31 [INFO]: Epoch 020 - training loss: 9642.9003, validation loss: 0.3481
2024-05-25 03:46:31 [INFO]: Epoch 021 - training loss: 9582.4882, validation loss: 0.3368
2024-05-25 03:46:31 [INFO]: Epoch 022 - training loss: 9578.2201, validation loss: 0.3391
2024-05-25 03:46:31 [INFO]: Epoch 023 - training loss: 9537.7157, validation loss: 0.3346
2024-05-25 03:46:31 [INFO]: Epoch 024 - training loss: 9519.3073, validation loss: 0.3257
2024-05-25 03:46:31 [INFO]: Epoch 025 - training loss: 9482.2233, validation loss: 0.3165
2024-05-25 03:46:31 [INFO]: Epoch 026 - training loss: 9475.0572, validation loss: 0.3191
2024-05-25 03:46:32 [INFO]: Epoch 027 - training loss: 9453.5599, validation loss: 0.3140
2024-05-25 03:46:32 [INFO]: Epoch 028 - training loss: 9425.1708, validation loss: 0.3073
2024-05-25 03:46:32 [INFO]: Epoch 029 - training loss: 9444.3854, validation loss: 0.3045
2024-05-25 03:46:32 [INFO]: Epoch 030 - training loss: 9412.0314, validation loss: 0.2905
2024-05-25 03:46:32 [INFO]: Epoch 031 - training loss: 9412.2956, validation loss: 0.2895
2024-05-25 03:46:32 [INFO]: Epoch 032 - training loss: 9375.6202, validation loss: 0.2803
2024-05-25 03:46:32 [INFO]: Epoch 033 - training loss: 9383.9349, validation loss: 0.2812
2024-05-25 03:46:32 [INFO]: Epoch 034 - training loss: 9366.5971, validation loss: 0.2708
2024-05-25 03:46:33 [INFO]: Epoch 035 - training loss: 9355.3732, validation loss: 0.2669
2024-05-25 03:46:33 [INFO]: Epoch 036 - training loss: 9347.8126, validation loss: 0.2570
2024-05-25 03:46:33 [INFO]: Epoch 037 - training loss: 9340.5572, validation loss: 0.2546
2024-05-25 03:46:33 [INFO]: Epoch 038 - training loss: 9372.4362, validation loss: 0.2473
2024-05-25 03:46:33 [INFO]: Epoch 039 - training loss: 9327.4041, validation loss: 0.2443
2024-05-25 03:46:33 [INFO]: Epoch 040 - training loss: 9326.3027, validation loss: 0.2418
2024-05-25 03:46:33 [INFO]: Epoch 041 - training loss: 9322.2287, validation loss: 0.2349
2024-05-25 03:46:33 [INFO]: Epoch 042 - training loss: 9319.1350, validation loss: 0.2345
2024-05-25 03:46:34 [INFO]: Epoch 043 - training loss: 9324.8275, validation loss: 0.2280
2024-05-25 03:46:34 [INFO]: Epoch 044 - training loss: 9307.7921, validation loss: 0.2316
2024-05-25 03:46:34 [INFO]: Epoch 045 - training loss: 9309.0232, validation loss: 0.2267
2024-05-25 03:46:34 [INFO]: Epoch 046 - training loss: 9300.1033, validation loss: 0.2184
2024-05-25 03:46:34 [INFO]: Epoch 047 - training loss: 9293.2489, validation loss: 0.2129
2024-05-25 03:46:34 [INFO]: Epoch 048 - training loss: 9297.5658, validation loss: 0.2079
2024-05-25 03:46:34 [INFO]: Epoch 049 - training loss: 9290.0791, validation loss: 0.2057
2024-05-25 03:46:34 [INFO]: Epoch 050 - training loss: 9304.5688, validation loss: 0.2043
2024-05-25 03:46:35 [INFO]: Epoch 051 - training loss: 9282.9371, validation loss: 0.1996
2024-05-25 03:46:35 [INFO]: Epoch 052 - training loss: 9300.5770, validation loss: 0.1947
2024-05-25 03:46:35 [INFO]: Epoch 053 - training loss: 9275.3288, validation loss: 0.1916
2024-05-25 03:46:35 [INFO]: Epoch 054 - training loss: 9279.9939, validation loss: 0.1893
2024-05-25 03:46:35 [INFO]: Epoch 055 - training loss: 9274.4613, validation loss: 0.1840
2024-05-25 03:46:35 [INFO]: Epoch 056 - training loss: 9278.2402, validation loss: 0.1820
2024-05-25 03:46:35 [INFO]: Epoch 057 - training loss: 9267.7700, validation loss: 0.1780
2024-05-25 03:46:35 [INFO]: Epoch 058 - training loss: 9266.4423, validation loss: 0.1745
2024-05-25 03:46:35 [INFO]: Epoch 059 - training loss: 9268.5399, validation loss: 0.1710
2024-05-25 03:46:36 [INFO]: Epoch 060 - training loss: 9265.7078, validation loss: 0.1689
2024-05-25 03:46:36 [INFO]: Epoch 061 - training loss: 9271.4318, validation loss: 0.1687
2024-05-25 03:46:36 [INFO]: Epoch 062 - training loss: 9266.7065, validation loss: 0.1665
2024-05-25 03:46:36 [INFO]: Epoch 063 - training loss: 9261.5332, validation loss: 0.1622
2024-05-25 03:46:36 [INFO]: Epoch 064 - training loss: 9256.5038, validation loss: 0.1572
2024-05-25 03:46:36 [INFO]: Epoch 065 - training loss: 9254.7133, validation loss: 0.1547
2024-05-25 03:46:36 [INFO]: Epoch 066 - training loss: 9252.7001, validation loss: 0.1539
2024-05-25 03:46:36 [INFO]: Epoch 067 - training loss: 9253.6505, validation loss: 0.1514
2024-05-25 03:46:37 [INFO]: Epoch 068 - training loss: 9253.4421, validation loss: 0.1483
2024-05-25 03:46:37 [INFO]: Epoch 069 - training loss: 9251.6124, validation loss: 0.1488
2024-05-25 03:46:37 [INFO]: Epoch 070 - training loss: 9250.2945, validation loss: 0.1437
2024-05-25 03:46:37 [INFO]: Epoch 071 - training loss: 9250.8977, validation loss: 0.1436
2024-05-25 03:46:37 [INFO]: Epoch 072 - training loss: 9252.5987, validation loss: 0.1431
2024-05-25 03:46:37 [INFO]: Epoch 073 - training loss: 9246.7907, validation loss: 0.1408
2024-05-25 03:46:37 [INFO]: Epoch 074 - training loss: 9247.5148, validation loss: 0.1418
2024-05-25 03:46:37 [INFO]: Epoch 075 - training loss: 9245.0273, validation loss: 0.1384
2024-05-25 03:46:38 [INFO]: Epoch 076 - training loss: 9245.4117, validation loss: 0.1360
2024-05-25 03:46:38 [INFO]: Epoch 077 - training loss: 9243.9167, validation loss: 0.1398
2024-05-25 03:46:38 [INFO]: Epoch 078 - training loss: 9242.3310, validation loss: 0.1374
2024-05-25 03:46:38 [INFO]: Epoch 079 - training loss: 9242.4276, validation loss: 0.1365
2024-05-25 03:46:38 [INFO]: Epoch 080 - training loss: 9241.3135, validation loss: 0.1337
2024-05-25 03:46:38 [INFO]: Epoch 081 - training loss: 9238.9393, validation loss: 0.1352
2024-05-25 03:46:38 [INFO]: Epoch 082 - training loss: 9241.2202, validation loss: 0.1309
2024-05-25 03:46:38 [INFO]: Epoch 083 - training loss: 9242.7305, validation loss: 0.1325
2024-05-25 03:46:39 [INFO]: Epoch 084 - training loss: 9237.9807, validation loss: 0.1293
2024-05-25 03:46:39 [INFO]: Epoch 085 - training loss: 9237.0480, validation loss: 0.1301
2024-05-25 03:46:39 [INFO]: Epoch 086 - training loss: 9236.8792, validation loss: 0.1294
2024-05-25 03:46:39 [INFO]: Epoch 087 - training loss: 9235.6393, validation loss: 0.1273
2024-05-25 03:46:39 [INFO]: Epoch 088 - training loss: 9236.5298, validation loss: 0.1279
2024-05-25 03:46:39 [INFO]: Epoch 089 - training loss: 9234.2812, validation loss: 0.1257
2024-05-25 03:46:39 [INFO]: Epoch 090 - training loss: 9233.6907, validation loss: 0.1256
2024-05-25 03:46:39 [INFO]: Epoch 091 - training loss: 9233.8293, validation loss: 0.1250
2024-05-25 03:46:40 [INFO]: Epoch 092 - training loss: 9234.1301, validation loss: 0.1249
2024-05-25 03:46:40 [INFO]: Epoch 093 - training loss: 9232.2006, validation loss: 0.1227
2024-05-25 03:46:40 [INFO]: Epoch 094 - training loss: 9233.1097, validation loss: 0.1223
2024-05-25 03:46:40 [INFO]: Epoch 095 - training loss: 9232.5070, validation loss: 0.1238
2024-05-25 03:46:40 [INFO]: Epoch 096 - training loss: 9230.6641, validation loss: 0.1224
2024-05-25 03:46:40 [INFO]: Epoch 097 - training loss: 9230.0047, validation loss: 0.1215
2024-05-25 03:46:40 [INFO]: Epoch 098 - training loss: 9230.2466, validation loss: 0.1225
2024-05-25 03:46:40 [INFO]: Epoch 099 - training loss: 9227.9293, validation loss: 0.1205
2024-05-25 03:46:40 [INFO]: Epoch 100 - training loss: 9231.9142, validation loss: 0.1207
2024-05-25 03:46:41 [INFO]: Epoch 101 - training loss: 9232.4996, validation loss: 0.1218
2024-05-25 03:46:41 [INFO]: Epoch 102 - training loss: 9227.5584, validation loss: 0.1174
2024-05-25 03:46:41 [INFO]: Epoch 103 - training loss: 9227.2112, validation loss: 0.1187
2024-05-25 03:46:41 [INFO]: Epoch 104 - training loss: 9227.9525, validation loss: 0.1162
2024-05-25 03:46:41 [INFO]: Epoch 105 - training loss: 9225.6801, validation loss: 0.1166
2024-05-25 03:46:41 [INFO]: Epoch 106 - training loss: 9231.7357, validation loss: 0.1162
2024-05-25 03:46:41 [INFO]: Epoch 107 - training loss: 9227.8276, validation loss: 0.1147
2024-05-25 03:46:41 [INFO]: Epoch 108 - training loss: 9225.0974, validation loss: 0.1174
2024-05-25 03:46:42 [INFO]: Epoch 109 - training loss: 9228.0751, validation loss: 0.1149
2024-05-25 03:46:42 [INFO]: Epoch 110 - training loss: 9226.0483, validation loss: 0.1140
2024-05-25 03:46:42 [INFO]: Epoch 111 - training loss: 9223.8209, validation loss: 0.1155
2024-05-25 03:46:42 [INFO]: Epoch 112 - training loss: 9223.3444, validation loss: 0.1129
2024-05-25 03:46:42 [INFO]: Epoch 113 - training loss: 9224.2142, validation loss: 0.1125
2024-05-25 03:46:42 [INFO]: Epoch 114 - training loss: 9224.9767, validation loss: 0.1120
2024-05-25 03:46:42 [INFO]: Epoch 115 - training loss: 9226.9904, validation loss: 0.1123
2024-05-25 03:46:42 [INFO]: Epoch 116 - training loss: 9226.7958, validation loss: 0.1118
2024-05-25 03:46:43 [INFO]: Epoch 117 - training loss: 9221.3643, validation loss: 0.1117
2024-05-25 03:46:43 [INFO]: Epoch 118 - training loss: 9221.0854, validation loss: 0.1102
2024-05-25 03:46:43 [INFO]: Epoch 119 - training loss: 9223.0779, validation loss: 0.1102
2024-05-25 03:46:43 [INFO]: Epoch 120 - training loss: 9221.7650, validation loss: 0.1091
2024-05-25 03:46:43 [INFO]: Epoch 121 - training loss: 9223.5767, validation loss: 0.1089
2024-05-25 03:46:43 [INFO]: Epoch 122 - training loss: 9221.6677, validation loss: 0.1096
2024-05-25 03:46:43 [INFO]: Epoch 123 - training loss: 9222.1091, validation loss: 0.1092
2024-05-25 03:46:43 [INFO]: Epoch 124 - training loss: 9220.8023, validation loss: 0.1083
2024-05-25 03:46:44 [INFO]: Epoch 125 - training loss: 9221.6021, validation loss: 0.1081
2024-05-25 03:46:44 [INFO]: Epoch 126 - training loss: 9221.4722, validation loss: 0.1084
2024-05-25 03:46:44 [INFO]: Epoch 127 - training loss: 9219.8442, validation loss: 0.1070
2024-05-25 03:46:44 [INFO]: Epoch 128 - training loss: 9221.2937, validation loss: 0.1063
2024-05-25 03:46:44 [INFO]: Epoch 129 - training loss: 9220.4944, validation loss: 0.1042
2024-05-25 03:46:44 [INFO]: Epoch 130 - training loss: 9218.5027, validation loss: 0.1078
2024-05-25 03:46:44 [INFO]: Epoch 131 - training loss: 9219.2341, validation loss: 0.1056
2024-05-25 03:46:44 [INFO]: Epoch 132 - training loss: 9220.8436, validation loss: 0.1041
2024-05-25 03:46:45 [INFO]: Epoch 133 - training loss: 9219.7502, validation loss: 0.1062
2024-05-25 03:46:45 [INFO]: Epoch 134 - training loss: 9217.5935, validation loss: 0.1045
2024-05-25 03:46:45 [INFO]: Epoch 135 - training loss: 9218.5542, validation loss: 0.1044
2024-05-25 03:46:45 [INFO]: Epoch 136 - training loss: 9218.5006, validation loss: 0.1039
2024-05-25 03:46:45 [INFO]: Epoch 137 - training loss: 9217.9182, validation loss: 0.1022
2024-05-25 03:46:45 [INFO]: Epoch 138 - training loss: 9218.0612, validation loss: 0.1041
2024-05-25 03:46:45 [INFO]: Epoch 139 - training loss: 9218.0919, validation loss: 0.1020
2024-05-25 03:46:45 [INFO]: Epoch 140 - training loss: 9215.7992, validation loss: 0.1034
2024-05-25 03:46:46 [INFO]: Epoch 141 - training loss: 9217.6994, validation loss: 0.1027
2024-05-25 03:46:46 [INFO]: Epoch 142 - training loss: 9217.1287, validation loss: 0.1011
2024-05-25 03:46:46 [INFO]: Epoch 143 - training loss: 9216.9360, validation loss: 0.1020
2024-05-25 03:46:46 [INFO]: Epoch 144 - training loss: 9217.8021, validation loss: 0.1009
2024-05-25 03:46:46 [INFO]: Epoch 145 - training loss: 9216.6938, validation loss: 0.1026
2024-05-25 03:46:46 [INFO]: Epoch 146 - training loss: 9216.0987, validation loss: 0.1011
2024-05-25 03:46:46 [INFO]: Epoch 147 - training loss: 9217.6476, validation loss: 0.0988
2024-05-25 03:46:46 [INFO]: Epoch 148 - training loss: 9215.2727, validation loss: 0.1033
2024-05-25 03:46:47 [INFO]: Epoch 149 - training loss: 9216.0340, validation loss: 0.1001
2024-05-25 03:46:47 [INFO]: Epoch 150 - training loss: 9215.7305, validation loss: 0.0993
2024-05-25 03:46:47 [INFO]: Epoch 151 - training loss: 9216.2047, validation loss: 0.1000
2024-05-25 03:46:47 [INFO]: Epoch 152 - training loss: 9216.4092, validation loss: 0.0988
2024-05-25 03:46:47 [INFO]: Epoch 153 - training loss: 9214.8241, validation loss: 0.1005
2024-05-25 03:46:47 [INFO]: Epoch 154 - training loss: 9215.1317, validation loss: 0.0994
2024-05-25 03:46:47 [INFO]: Epoch 155 - training loss: 9214.4263, validation loss: 0.0977
2024-05-25 03:46:47 [INFO]: Epoch 156 - training loss: 9214.1204, validation loss: 0.0977
2024-05-25 03:46:47 [INFO]: Epoch 157 - training loss: 9216.7151, validation loss: 0.0976
2024-05-25 03:46:48 [INFO]: Epoch 158 - training loss: 9214.7307, validation loss: 0.0972
2024-05-25 03:46:48 [INFO]: Epoch 159 - training loss: 9213.7292, validation loss: 0.0975
2024-05-25 03:46:48 [INFO]: Epoch 160 - training loss: 9213.5358, validation loss: 0.0956
2024-05-25 03:46:48 [INFO]: Epoch 161 - training loss: 9213.6575, validation loss: 0.0978
2024-05-25 03:46:48 [INFO]: Epoch 162 - training loss: 9215.6567, validation loss: 0.0960
2024-05-25 03:46:48 [INFO]: Epoch 163 - training loss: 9215.9340, validation loss: 0.0947
2024-05-25 03:46:48 [INFO]: Epoch 164 - training loss: 9214.0128, validation loss: 0.0968
2024-05-25 03:46:48 [INFO]: Epoch 165 - training loss: 9212.5917, validation loss: 0.0953
2024-05-25 03:46:49 [INFO]: Epoch 166 - training loss: 9212.3696, validation loss: 0.0951
2024-05-25 03:46:49 [INFO]: Epoch 167 - training loss: 9212.7206, validation loss: 0.0949
2024-05-25 03:46:49 [INFO]: Epoch 168 - training loss: 9213.0628, validation loss: 0.0950
2024-05-25 03:46:49 [INFO]: Epoch 169 - training loss: 9212.0910, validation loss: 0.0953
2024-05-25 03:46:49 [INFO]: Epoch 170 - training loss: 9213.0927, validation loss: 0.0942
2024-05-25 03:46:49 [INFO]: Epoch 171 - training loss: 9212.1423, validation loss: 0.0944
2024-05-25 03:46:49 [INFO]: Epoch 172 - training loss: 9212.0938, validation loss: 0.0946
2024-05-25 03:46:49 [INFO]: Epoch 173 - training loss: 9211.5283, validation loss: 0.0950
2024-05-25 03:46:50 [INFO]: Epoch 174 - training loss: 9213.3030, validation loss: 0.0940
2024-05-25 03:46:50 [INFO]: Epoch 175 - training loss: 9213.3801, validation loss: 0.0930
2024-05-25 03:46:50 [INFO]: Epoch 176 - training loss: 9212.1525, validation loss: 0.0919
2024-05-25 03:46:50 [INFO]: Epoch 177 - training loss: 9212.4128, validation loss: 0.0908
2024-05-25 03:46:50 [INFO]: Epoch 178 - training loss: 9212.6155, validation loss: 0.0938
2024-05-25 03:46:50 [INFO]: Epoch 179 - training loss: 9212.7741, validation loss: 0.0920
2024-05-25 03:46:50 [INFO]: Epoch 180 - training loss: 9211.0496, validation loss: 0.0924
2024-05-25 03:46:50 [INFO]: Epoch 181 - training loss: 9210.5711, validation loss: 0.0919
2024-05-25 03:46:51 [INFO]: Epoch 182 - training loss: 9210.5056, validation loss: 0.0925
2024-05-25 03:46:51 [INFO]: Epoch 183 - training loss: 9212.6938, validation loss: 0.0920
2024-05-25 03:46:51 [INFO]: Epoch 184 - training loss: 9213.3763, validation loss: 0.0945
2024-05-25 03:46:51 [INFO]: Epoch 185 - training loss: 9211.5593, validation loss: 0.0898
2024-05-25 03:46:51 [INFO]: Epoch 186 - training loss: 9212.5756, validation loss: 0.0911
2024-05-25 03:46:51 [INFO]: Epoch 187 - training loss: 9210.9018, validation loss: 0.0917
2024-05-25 03:46:51 [INFO]: Epoch 188 - training loss: 9210.1228, validation loss: 0.0910
2024-05-25 03:46:51 [INFO]: Epoch 189 - training loss: 9210.5678, validation loss: 0.0910
2024-05-25 03:46:51 [INFO]: Epoch 190 - training loss: 9212.2562, validation loss: 0.0898
2024-05-25 03:46:52 [INFO]: Epoch 191 - training loss: 9211.3242, validation loss: 0.0893
2024-05-25 03:46:52 [INFO]: Epoch 192 - training loss: 9210.4355, validation loss: 0.0891
2024-05-25 03:46:52 [INFO]: Epoch 193 - training loss: 9210.2955, validation loss: 0.0900
2024-05-25 03:46:52 [INFO]: Epoch 194 - training loss: 9210.6462, validation loss: 0.0916
2024-05-25 03:46:52 [INFO]: Epoch 195 - training loss: 9209.7594, validation loss: 0.0896
2024-05-25 03:46:52 [INFO]: Epoch 196 - training loss: 9211.0929, validation loss: 0.0917
2024-05-25 03:46:52 [INFO]: Epoch 197 - training loss: 9211.6875, validation loss: 0.0883
2024-05-25 03:46:52 [INFO]: Epoch 198 - training loss: 9210.2061, validation loss: 0.0923
2024-05-25 03:46:53 [INFO]: Epoch 199 - training loss: 9210.4501, validation loss: 0.0898
2024-05-25 03:46:53 [INFO]: Epoch 200 - training loss: 9210.4164, validation loss: 0.0905
2024-05-25 03:46:53 [INFO]: Epoch 201 - training loss: 9208.9976, validation loss: 0.0894
2024-05-25 03:46:53 [INFO]: Epoch 202 - training loss: 9210.1423, validation loss: 0.0882
2024-05-25 03:46:53 [INFO]: Epoch 203 - training loss: 9209.5258, validation loss: 0.0886
2024-05-25 03:46:53 [INFO]: Epoch 204 - training loss: 9209.0162, validation loss: 0.0874
2024-05-25 03:46:53 [INFO]: Epoch 205 - training loss: 9210.6722, validation loss: 0.0892
2024-05-25 03:46:53 [INFO]: Epoch 206 - training loss: 9209.0777, validation loss: 0.0879
2024-05-25 03:46:54 [INFO]: Epoch 207 - training loss: 9209.0320, validation loss: 0.0887
2024-05-25 03:46:54 [INFO]: Epoch 208 - training loss: 9209.8306, validation loss: 0.0867
2024-05-25 03:46:54 [INFO]: Epoch 209 - training loss: 9209.8835, validation loss: 0.0880
2024-05-25 03:46:54 [INFO]: Epoch 210 - training loss: 9210.1409, validation loss: 0.0886
2024-05-25 03:46:54 [INFO]: Epoch 211 - training loss: 9209.3499, validation loss: 0.0889
2024-05-25 03:46:54 [INFO]: Epoch 212 - training loss: 9208.0203, validation loss: 0.0876
2024-05-25 03:46:54 [INFO]: Epoch 213 - training loss: 9210.0105, validation loss: 0.0897
2024-05-25 03:46:54 [INFO]: Epoch 214 - training loss: 9208.8453, validation loss: 0.0877
2024-05-25 03:46:55 [INFO]: Epoch 215 - training loss: 9210.5503, validation loss: 0.0879
2024-05-25 03:46:55 [INFO]: Epoch 216 - training loss: 9209.7770, validation loss: 0.0884
2024-05-25 03:46:55 [INFO]: Epoch 217 - training loss: 9209.3009, validation loss: 0.0852
2024-05-25 03:46:55 [INFO]: Epoch 218 - training loss: 9210.0787, validation loss: 0.0861
2024-05-25 03:46:55 [INFO]: Epoch 219 - training loss: 9209.0227, validation loss: 0.0859
2024-05-25 03:46:55 [INFO]: Epoch 220 - training loss: 9208.2336, validation loss: 0.0854
2024-05-25 03:46:55 [INFO]: Epoch 221 - training loss: 9206.2753, validation loss: 0.0853
2024-05-25 03:46:55 [INFO]: Epoch 222 - training loss: 9207.6949, validation loss: 0.0856
2024-05-25 03:46:56 [INFO]: Epoch 223 - training loss: 9209.2753, validation loss: 0.0861
2024-05-25 03:46:56 [INFO]: Epoch 224 - training loss: 9209.6852, validation loss: 0.0868
2024-05-25 03:46:56 [INFO]: Epoch 225 - training loss: 9207.1639, validation loss: 0.0871
2024-05-25 03:46:56 [INFO]: Epoch 226 - training loss: 9209.0291, validation loss: 0.0853
2024-05-25 03:46:56 [INFO]: Epoch 227 - training loss: 9208.4876, validation loss: 0.0853
2024-05-25 03:46:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:46:56 [INFO]: Finished training. The best model is from epoch#217.
2024-05-25 03:46:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/GPVAE_ettm1/20240525_T034628/GPVAE.pypots
2024-05-25 03:46:56 [INFO]: GP-VAE on ETTm1: MAE=0.2848, MSE=0.1710
2024-05-25 03:46:56 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/GPVAE_ettm1/imputation.pkl
2024-05-25 03:46:56 [INFO]: Using the given device: cuda:0
2024-05-25 03:46:56 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/USGAN_ettm1/20240525_T034656
2024-05-25 03:46:56 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/USGAN_ettm1/20240525_T034656/tensorboard
2024-05-25 03:46:56 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 03:47:07 [INFO]: Epoch 001 - generator training loss: 0.4458, discriminator training loss: 0.5369, validation loss: 0.4260
2024-05-25 03:47:15 [INFO]: Epoch 002 - generator training loss: -0.0405, discriminator training loss: 0.4745, validation loss: 0.1237
2024-05-25 03:47:24 [INFO]: Epoch 003 - generator training loss: -0.1671, discriminator training loss: 0.4348, validation loss: 0.0691
2024-05-25 03:47:33 [INFO]: Epoch 004 - generator training loss: -0.1521, discriminator training loss: 0.3741, validation loss: 0.0571
2024-05-25 03:47:42 [INFO]: Epoch 005 - generator training loss: -0.1100, discriminator training loss: 0.2973, validation loss: 0.0481
2024-05-25 03:47:51 [INFO]: Epoch 006 - generator training loss: -0.0774, discriminator training loss: 0.2347, validation loss: 0.0449
2024-05-25 03:48:00 [INFO]: Epoch 007 - generator training loss: -0.0601, discriminator training loss: 0.2000, validation loss: 0.0435
2024-05-25 03:48:09 [INFO]: Epoch 008 - generator training loss: -0.0550, discriminator training loss: 0.1866, validation loss: 0.0435
2024-05-25 03:48:18 [INFO]: Epoch 009 - generator training loss: -0.0521, discriminator training loss: 0.1805, validation loss: 0.0401
2024-05-25 03:48:26 [INFO]: Epoch 010 - generator training loss: -0.0530, discriminator training loss: 0.1785, validation loss: 0.0412
2024-05-25 03:48:35 [INFO]: Epoch 011 - generator training loss: -0.0523, discriminator training loss: 0.1758, validation loss: 0.0391
2024-05-25 03:48:44 [INFO]: Epoch 012 - generator training loss: -0.0534, discriminator training loss: 0.1752, validation loss: 0.0379
2024-05-25 03:48:53 [INFO]: Epoch 013 - generator training loss: -0.0521, discriminator training loss: 0.1728, validation loss: 0.0376
2024-05-25 03:49:02 [INFO]: Epoch 014 - generator training loss: -0.0545, discriminator training loss: 0.1709, validation loss: 0.0378
2024-05-25 03:49:10 [INFO]: Epoch 015 - generator training loss: -0.0563, discriminator training loss: 0.1712, validation loss: 0.0379
2024-05-25 03:49:19 [INFO]: Epoch 016 - generator training loss: -0.0599, discriminator training loss: 0.1707, validation loss: 0.0365
2024-05-25 03:49:28 [INFO]: Epoch 017 - generator training loss: -0.0598, discriminator training loss: 0.1717, validation loss: 0.0367
2024-05-25 03:49:37 [INFO]: Epoch 018 - generator training loss: -0.0577, discriminator training loss: 0.1696, validation loss: 0.0364
2024-05-25 03:49:46 [INFO]: Epoch 019 - generator training loss: -0.0596, discriminator training loss: 0.1691, validation loss: 0.0363
2024-05-25 03:49:54 [INFO]: Epoch 020 - generator training loss: -0.0545, discriminator training loss: 0.1692, validation loss: 0.0378
2024-05-25 03:50:03 [INFO]: Epoch 021 - generator training loss: -0.0574, discriminator training loss: 0.1703, validation loss: 0.0375
2024-05-25 03:50:12 [INFO]: Epoch 022 - generator training loss: -0.0561, discriminator training loss: 0.1690, validation loss: 0.0356
2024-05-25 03:50:21 [INFO]: Epoch 023 - generator training loss: -0.0598, discriminator training loss: 0.1691, validation loss: 0.0347
2024-05-25 03:50:30 [INFO]: Epoch 024 - generator training loss: -0.0542, discriminator training loss: 0.1670, validation loss: 0.0371
2024-05-25 03:50:39 [INFO]: Epoch 025 - generator training loss: -0.0612, discriminator training loss: 0.1700, validation loss: 0.0353
2024-05-25 03:50:48 [INFO]: Epoch 026 - generator training loss: -0.0585, discriminator training loss: 0.1680, validation loss: 0.0360
2024-05-25 03:50:56 [INFO]: Epoch 027 - generator training loss: -0.0565, discriminator training loss: 0.1676, validation loss: 0.0343
2024-05-25 03:51:05 [INFO]: Epoch 028 - generator training loss: -0.0652, discriminator training loss: 0.1670, validation loss: 0.0342
2024-05-25 03:51:14 [INFO]: Epoch 029 - generator training loss: -0.0616, discriminator training loss: 0.1672, validation loss: 0.0342
2024-05-25 03:51:23 [INFO]: Epoch 030 - generator training loss: -0.0616, discriminator training loss: 0.1704, validation loss: 0.0327
2024-05-25 03:51:32 [INFO]: Epoch 031 - generator training loss: -0.0650, discriminator training loss: 0.1704, validation loss: 0.0330
2024-05-25 03:51:41 [INFO]: Epoch 032 - generator training loss: -0.0625, discriminator training loss: 0.1665, validation loss: 0.0335
2024-05-25 03:51:49 [INFO]: Epoch 033 - generator training loss: -0.0663, discriminator training loss: 0.1694, validation loss: 0.0328
2024-05-25 03:51:58 [INFO]: Epoch 034 - generator training loss: -0.0638, discriminator training loss: 0.1672, validation loss: 0.0325
2024-05-25 03:52:07 [INFO]: Epoch 035 - generator training loss: -0.0660, discriminator training loss: 0.1664, validation loss: 0.0325
2024-05-25 03:52:16 [INFO]: Epoch 036 - generator training loss: -0.0615, discriminator training loss: 0.1667, validation loss: 0.0321
2024-05-25 03:52:25 [INFO]: Epoch 037 - generator training loss: -0.0654, discriminator training loss: 0.1677, validation loss: 0.0311
2024-05-25 03:52:33 [INFO]: Epoch 038 - generator training loss: -0.0631, discriminator training loss: 0.1655, validation loss: 0.0302
2024-05-25 03:52:42 [INFO]: Epoch 039 - generator training loss: -0.0667, discriminator training loss: 0.1682, validation loss: 0.0306
2024-05-25 03:52:51 [INFO]: Epoch 040 - generator training loss: -0.0647, discriminator training loss: 0.1645, validation loss: 0.0306
2024-05-25 03:53:00 [INFO]: Epoch 041 - generator training loss: -0.0688, discriminator training loss: 0.1664, validation loss: 0.0300
2024-05-25 03:53:09 [INFO]: Epoch 042 - generator training loss: -0.0681, discriminator training loss: 0.1677, validation loss: 0.0300
2024-05-25 03:53:18 [INFO]: Epoch 043 - generator training loss: -0.0659, discriminator training loss: 0.1661, validation loss: 0.0300
2024-05-25 03:53:26 [INFO]: Epoch 044 - generator training loss: -0.0671, discriminator training loss: 0.1641, validation loss: 0.0293
2024-05-25 03:53:35 [INFO]: Epoch 045 - generator training loss: -0.0698, discriminator training loss: 0.1677, validation loss: 0.0289
2024-05-25 03:53:44 [INFO]: Epoch 046 - generator training loss: -0.0668, discriminator training loss: 0.1670, validation loss: 0.0306
2024-05-25 03:53:53 [INFO]: Epoch 047 - generator training loss: -0.0671, discriminator training loss: 0.1652, validation loss: 0.0295
2024-05-25 03:54:02 [INFO]: Epoch 048 - generator training loss: -0.0653, discriminator training loss: 0.1665, validation loss: 0.0302
2024-05-25 03:54:11 [INFO]: Epoch 049 - generator training loss: -0.0678, discriminator training loss: 0.1650, validation loss: 0.0294
2024-05-25 03:54:20 [INFO]: Epoch 050 - generator training loss: -0.0687, discriminator training loss: 0.1680, validation loss: 0.0293
2024-05-25 03:54:28 [INFO]: Epoch 051 - generator training loss: -0.0687, discriminator training loss: 0.1663, validation loss: 0.0293
2024-05-25 03:54:37 [INFO]: Epoch 052 - generator training loss: -0.0660, discriminator training loss: 0.1660, validation loss: 0.0290
2024-05-25 03:54:46 [INFO]: Epoch 053 - generator training loss: -0.0671, discriminator training loss: 0.1638, validation loss: 0.0287
2024-05-25 03:54:55 [INFO]: Epoch 054 - generator training loss: -0.0673, discriminator training loss: 0.1643, validation loss: 0.0293
2024-05-25 03:55:03 [INFO]: Epoch 055 - generator training loss: -0.0703, discriminator training loss: 0.1656, validation loss: 0.0280
2024-05-25 03:55:12 [INFO]: Epoch 056 - generator training loss: -0.0683, discriminator training loss: 0.1644, validation loss: 0.0282
2024-05-25 03:55:21 [INFO]: Epoch 057 - generator training loss: -0.0686, discriminator training loss: 0.1649, validation loss: 0.0273
2024-05-25 03:55:30 [INFO]: Epoch 058 - generator training loss: -0.0689, discriminator training loss: 0.1652, validation loss: 0.0280
2024-05-25 03:55:39 [INFO]: Epoch 059 - generator training loss: -0.0681, discriminator training loss: 0.1644, validation loss: 0.0267
2024-05-25 03:55:47 [INFO]: Epoch 060 - generator training loss: -0.0735, discriminator training loss: 0.1659, validation loss: 0.0258
2024-05-25 03:55:56 [INFO]: Epoch 061 - generator training loss: -0.0711, discriminator training loss: 0.1641, validation loss: 0.0260
2024-05-25 03:56:05 [INFO]: Epoch 062 - generator training loss: -0.0722, discriminator training loss: 0.1663, validation loss: 0.0260
2024-05-25 03:56:14 [INFO]: Epoch 063 - generator training loss: -0.0695, discriminator training loss: 0.1650, validation loss: 0.0262
2024-05-25 03:56:23 [INFO]: Epoch 064 - generator training loss: -0.0758, discriminator training loss: 0.1625, validation loss: 0.0262
2024-05-25 03:56:31 [INFO]: Epoch 065 - generator training loss: -0.0722, discriminator training loss: 0.1644, validation loss: 0.0256
2024-05-25 03:56:40 [INFO]: Epoch 066 - generator training loss: -0.0712, discriminator training loss: 0.1622, validation loss: 0.0254
2024-05-25 03:56:49 [INFO]: Epoch 067 - generator training loss: -0.0747, discriminator training loss: 0.1604, validation loss: 0.0260
2024-05-25 03:56:58 [INFO]: Epoch 068 - generator training loss: -0.0708, discriminator training loss: 0.1633, validation loss: 0.0256
2024-05-25 03:57:07 [INFO]: Epoch 069 - generator training loss: -0.0686, discriminator training loss: 0.1636, validation loss: 0.0265
2024-05-25 03:57:16 [INFO]: Epoch 070 - generator training loss: -0.0722, discriminator training loss: 0.1612, validation loss: 0.0258
2024-05-25 03:57:25 [INFO]: Epoch 071 - generator training loss: -0.0702, discriminator training loss: 0.1613, validation loss: 0.0258
2024-05-25 03:57:33 [INFO]: Epoch 072 - generator training loss: -0.0709, discriminator training loss: 0.1629, validation loss: 0.0258
2024-05-25 03:57:42 [INFO]: Epoch 073 - generator training loss: -0.0739, discriminator training loss: 0.1621, validation loss: 0.0256
2024-05-25 03:57:51 [INFO]: Epoch 074 - generator training loss: -0.0742, discriminator training loss: 0.1621, validation loss: 0.0247
2024-05-25 03:58:00 [INFO]: Epoch 075 - generator training loss: -0.0720, discriminator training loss: 0.1615, validation loss: 0.0247
2024-05-25 03:58:08 [INFO]: Epoch 076 - generator training loss: -0.0725, discriminator training loss: 0.1625, validation loss: 0.0248
2024-05-25 03:58:17 [INFO]: Epoch 077 - generator training loss: -0.0730, discriminator training loss: 0.1627, validation loss: 0.0248
2024-05-25 03:58:26 [INFO]: Epoch 078 - generator training loss: -0.0725, discriminator training loss: 0.1640, validation loss: 0.0246
2024-05-25 03:58:35 [INFO]: Epoch 079 - generator training loss: -0.0703, discriminator training loss: 0.1633, validation loss: 0.0251
2024-05-25 03:58:44 [INFO]: Epoch 080 - generator training loss: -0.0648, discriminator training loss: 0.1631, validation loss: 0.0261
2024-05-25 03:58:52 [INFO]: Epoch 081 - generator training loss: -0.0688, discriminator training loss: 0.1625, validation loss: 0.0259
2024-05-25 03:59:01 [INFO]: Epoch 082 - generator training loss: -0.0698, discriminator training loss: 0.1622, validation loss: 0.0255
2024-05-25 03:59:10 [INFO]: Epoch 083 - generator training loss: -0.0726, discriminator training loss: 0.1621, validation loss: 0.0255
2024-05-25 03:59:19 [INFO]: Epoch 084 - generator training loss: -0.0709, discriminator training loss: 0.1614, validation loss: 0.0253
2024-05-25 03:59:28 [INFO]: Epoch 085 - generator training loss: -0.0723, discriminator training loss: 0.1603, validation loss: 0.0252
2024-05-25 03:59:36 [INFO]: Epoch 086 - generator training loss: -0.0706, discriminator training loss: 0.1608, validation loss: 0.0242
2024-05-25 03:59:45 [INFO]: Epoch 087 - generator training loss: -0.0715, discriminator training loss: 0.1611, validation loss: 0.0244
2024-05-25 03:59:54 [INFO]: Epoch 088 - generator training loss: -0.0716, discriminator training loss: 0.1608, validation loss: 0.0256
2024-05-25 04:00:03 [INFO]: Epoch 089 - generator training loss: -0.0728, discriminator training loss: 0.1614, validation loss: 0.0243
2024-05-25 04:00:12 [INFO]: Epoch 090 - generator training loss: -0.0742, discriminator training loss: 0.1618, validation loss: 0.0248
2024-05-25 04:00:21 [INFO]: Epoch 091 - generator training loss: -0.0743, discriminator training loss: 0.1636, validation loss: 0.0288
2024-05-25 04:00:30 [INFO]: Epoch 092 - generator training loss: -0.0721, discriminator training loss: 0.1595, validation loss: 0.0244
2024-05-25 04:00:38 [INFO]: Epoch 093 - generator training loss: -0.0741, discriminator training loss: 0.1605, validation loss: 0.0256
2024-05-25 04:00:47 [INFO]: Epoch 094 - generator training loss: -0.0727, discriminator training loss: 0.1610, validation loss: 0.0241
2024-05-25 04:00:56 [INFO]: Epoch 095 - generator training loss: -0.0711, discriminator training loss: 0.1606, validation loss: 0.0254
2024-05-25 04:01:05 [INFO]: Epoch 096 - generator training loss: -0.0710, discriminator training loss: 0.1621, validation loss: 0.0245
2024-05-25 04:01:14 [INFO]: Epoch 097 - generator training loss: -0.0700, discriminator training loss: 0.1624, validation loss: 0.0244
2024-05-25 04:01:22 [INFO]: Epoch 098 - generator training loss: -0.0710, discriminator training loss: 0.1611, validation loss: 0.0243
2024-05-25 04:01:31 [INFO]: Epoch 099 - generator training loss: -0.0729, discriminator training loss: 0.1606, validation loss: 0.0246
2024-05-25 04:01:40 [INFO]: Epoch 100 - generator training loss: -0.0700, discriminator training loss: 0.1619, validation loss: 0.0245
2024-05-25 04:01:49 [INFO]: Epoch 101 - generator training loss: -0.0733, discriminator training loss: 0.1609, validation loss: 0.0241
2024-05-25 04:01:57 [INFO]: Epoch 102 - generator training loss: -0.0724, discriminator training loss: 0.1599, validation loss: 0.0243
2024-05-25 04:02:06 [INFO]: Epoch 103 - generator training loss: -0.0749, discriminator training loss: 0.1595, validation loss: 0.0233
2024-05-25 04:02:15 [INFO]: Epoch 104 - generator training loss: -0.0743, discriminator training loss: 0.1577, validation loss: 0.0240
2024-05-25 04:02:24 [INFO]: Epoch 105 - generator training loss: -0.0727, discriminator training loss: 0.1602, validation loss: 0.0245
2024-05-25 04:02:33 [INFO]: Epoch 106 - generator training loss: -0.0729, discriminator training loss: 0.1610, validation loss: 0.0246
2024-05-25 04:02:42 [INFO]: Epoch 107 - generator training loss: -0.0730, discriminator training loss: 0.1598, validation loss: 0.0242
2024-05-25 04:02:50 [INFO]: Epoch 108 - generator training loss: -0.0746, discriminator training loss: 0.1593, validation loss: 0.0240
2024-05-25 04:02:59 [INFO]: Epoch 109 - generator training loss: -0.0743, discriminator training loss: 0.1586, validation loss: 0.0232
2024-05-25 04:03:08 [INFO]: Epoch 110 - generator training loss: -0.0728, discriminator training loss: 0.1590, validation loss: 0.0236
2024-05-25 04:03:17 [INFO]: Epoch 111 - generator training loss: -0.0711, discriminator training loss: 0.1588, validation loss: 0.0233
2024-05-25 04:03:26 [INFO]: Epoch 112 - generator training loss: -0.0738, discriminator training loss: 0.1597, validation loss: 0.0238
2024-05-25 04:03:35 [INFO]: Epoch 113 - generator training loss: -0.0740, discriminator training loss: 0.1594, validation loss: 0.0229
2024-05-25 04:03:43 [INFO]: Epoch 114 - generator training loss: -0.0753, discriminator training loss: 0.1574, validation loss: 0.0230
2024-05-25 04:03:52 [INFO]: Epoch 115 - generator training loss: -0.0727, discriminator training loss: 0.1599, validation loss: 0.0228
2024-05-25 04:04:01 [INFO]: Epoch 116 - generator training loss: -0.0761, discriminator training loss: 0.1587, validation loss: 0.0233
2024-05-25 04:04:10 [INFO]: Epoch 117 - generator training loss: -0.0726, discriminator training loss: 0.1583, validation loss: 0.0242
2024-05-25 04:04:19 [INFO]: Epoch 118 - generator training loss: -0.0729, discriminator training loss: 0.1578, validation loss: 0.0229
2024-05-25 04:04:27 [INFO]: Epoch 119 - generator training loss: -0.0746, discriminator training loss: 0.1586, validation loss: 0.0231
2024-05-25 04:04:36 [INFO]: Epoch 120 - generator training loss: -0.0726, discriminator training loss: 0.1568, validation loss: 0.0228
2024-05-25 04:04:45 [INFO]: Epoch 121 - generator training loss: -0.0734, discriminator training loss: 0.1581, validation loss: 0.0226
2024-05-25 04:04:54 [INFO]: Epoch 122 - generator training loss: -0.0769, discriminator training loss: 0.1592, validation loss: 0.0223
2024-05-25 04:05:02 [INFO]: Epoch 123 - generator training loss: -0.0722, discriminator training loss: 0.1578, validation loss: 0.0233
2024-05-25 04:05:11 [INFO]: Epoch 124 - generator training loss: -0.0754, discriminator training loss: 0.1581, validation loss: 0.0230
2024-05-25 04:05:20 [INFO]: Epoch 125 - generator training loss: -0.0751, discriminator training loss: 0.1557, validation loss: 0.0229
2024-05-25 04:05:29 [INFO]: Epoch 126 - generator training loss: -0.0747, discriminator training loss: 0.1573, validation loss: 0.0228
2024-05-25 04:05:38 [INFO]: Epoch 127 - generator training loss: -0.0747, discriminator training loss: 0.1580, validation loss: 0.0228
2024-05-25 04:05:46 [INFO]: Epoch 128 - generator training loss: -0.0727, discriminator training loss: 0.1567, validation loss: 0.0228
2024-05-25 04:05:55 [INFO]: Epoch 129 - generator training loss: -0.0737, discriminator training loss: 0.1563, validation loss: 0.0234
2024-05-25 04:06:04 [INFO]: Epoch 130 - generator training loss: -0.0776, discriminator training loss: 0.1575, validation loss: 0.0227
2024-05-25 04:06:13 [INFO]: Epoch 131 - generator training loss: -0.0703, discriminator training loss: 0.1579, validation loss: 0.0236
2024-05-25 04:06:22 [INFO]: Epoch 132 - generator training loss: -0.0737, discriminator training loss: 0.1580, validation loss: 0.0226
2024-05-25 04:06:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:06:22 [INFO]: Finished training. The best model is from epoch#122.
2024-05-25 04:06:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/USGAN_ettm1/20240525_T034656/USGAN.pypots
2024-05-25 04:06:23 [INFO]: US-GAN on ETTm1: MAE=0.1612, MSE=0.0697
2024-05-25 04:06:23 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/USGAN_ettm1/imputation.pkl
2024-05-25 04:06:23 [INFO]: Using the given device: cuda:0
2024-05-25 04:06:23 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/BRITS_ettm1/20240525_T040623
2024-05-25 04:06:23 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/BRITS_ettm1/20240525_T040623/tensorboard
2024-05-25 04:06:23 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 04:06:31 [INFO]: Epoch 001 - training loss: 1.3123, validation loss: 0.2938
2024-05-25 04:06:37 [INFO]: Epoch 002 - training loss: 0.8886, validation loss: 0.0905
2024-05-25 04:06:43 [INFO]: Epoch 003 - training loss: 0.7257, validation loss: 0.0607
2024-05-25 04:06:49 [INFO]: Epoch 004 - training loss: 0.6596, validation loss: 0.0494
2024-05-25 04:06:55 [INFO]: Epoch 005 - training loss: 0.6164, validation loss: 0.0413
2024-05-25 04:07:00 [INFO]: Epoch 006 - training loss: 0.5811, validation loss: 0.0405
2024-05-25 04:07:06 [INFO]: Epoch 007 - training loss: 0.5521, validation loss: 0.0369
2024-05-25 04:07:12 [INFO]: Epoch 008 - training loss: 0.5359, validation loss: 0.0347
2024-05-25 04:07:18 [INFO]: Epoch 009 - training loss: 0.5216, validation loss: 0.0342
2024-05-25 04:07:24 [INFO]: Epoch 010 - training loss: 0.5008, validation loss: 0.0327
2024-05-25 04:07:30 [INFO]: Epoch 011 - training loss: 0.4905, validation loss: 0.0324
2024-05-25 04:07:36 [INFO]: Epoch 012 - training loss: 0.4847, validation loss: 0.0325
2024-05-25 04:07:42 [INFO]: Epoch 013 - training loss: 0.4577, validation loss: 0.0318
2024-05-25 04:07:48 [INFO]: Epoch 014 - training loss: 0.4395, validation loss: 0.0291
2024-05-25 04:07:54 [INFO]: Epoch 015 - training loss: 0.4334, validation loss: 0.0287
2024-05-25 04:07:59 [INFO]: Epoch 016 - training loss: 0.4357, validation loss: 0.0279
2024-05-25 04:08:05 [INFO]: Epoch 017 - training loss: 0.4315, validation loss: 0.0286
2024-05-25 04:08:11 [INFO]: Epoch 018 - training loss: 0.4261, validation loss: 0.0289
2024-05-25 04:08:17 [INFO]: Epoch 019 - training loss: 0.4150, validation loss: 0.0274
2024-05-25 04:08:23 [INFO]: Epoch 020 - training loss: 0.4096, validation loss: 0.0274
2024-05-25 04:08:29 [INFO]: Epoch 021 - training loss: 0.4075, validation loss: 0.0274
2024-05-25 04:08:35 [INFO]: Epoch 022 - training loss: 0.4036, validation loss: 0.0271
2024-05-25 04:08:41 [INFO]: Epoch 023 - training loss: 0.4080, validation loss: 0.0269
2024-05-25 04:08:47 [INFO]: Epoch 024 - training loss: 0.4183, validation loss: 0.0283
2024-05-25 04:08:53 [INFO]: Epoch 025 - training loss: 0.4063, validation loss: 0.0296
2024-05-25 04:08:59 [INFO]: Epoch 026 - training loss: 0.4061, validation loss: 0.0268
2024-05-25 04:09:04 [INFO]: Epoch 027 - training loss: 0.4027, validation loss: 0.0266
2024-05-25 04:09:10 [INFO]: Epoch 028 - training loss: 0.4011, validation loss: 0.0268
2024-05-25 04:09:16 [INFO]: Epoch 029 - training loss: 0.4003, validation loss: 0.0272
2024-05-25 04:09:22 [INFO]: Epoch 030 - training loss: 0.3947, validation loss: 0.0264
2024-05-25 04:09:28 [INFO]: Epoch 031 - training loss: 0.4007, validation loss: 0.0262
2024-05-25 04:09:34 [INFO]: Epoch 032 - training loss: 0.4022, validation loss: 0.0268
2024-05-25 04:09:40 [INFO]: Epoch 033 - training loss: 0.4068, validation loss: 0.0263
2024-05-25 04:09:46 [INFO]: Epoch 034 - training loss: 0.3989, validation loss: 0.0267
2024-05-25 04:09:52 [INFO]: Epoch 035 - training loss: 0.3960, validation loss: 0.0268
2024-05-25 04:09:58 [INFO]: Epoch 036 - training loss: 0.4086, validation loss: 0.0273
2024-05-25 04:10:04 [INFO]: Epoch 037 - training loss: 0.4068, validation loss: 0.0265
2024-05-25 04:10:10 [INFO]: Epoch 038 - training loss: 0.3977, validation loss: 0.0276
2024-05-25 04:10:15 [INFO]: Epoch 039 - training loss: 0.4025, validation loss: 0.0266
2024-05-25 04:10:21 [INFO]: Epoch 040 - training loss: 0.3943, validation loss: 0.0270
2024-05-25 04:10:27 [INFO]: Epoch 041 - training loss: 0.3946, validation loss: 0.0261
2024-05-25 04:10:33 [INFO]: Epoch 042 - training loss: 0.3974, validation loss: 0.0264
2024-05-25 04:10:39 [INFO]: Epoch 043 - training loss: 0.4009, validation loss: 0.0264
2024-05-25 04:10:45 [INFO]: Epoch 044 - training loss: 0.3927, validation loss: 0.0264
2024-05-25 04:10:51 [INFO]: Epoch 045 - training loss: 0.3950, validation loss: 0.0265
2024-05-25 04:10:57 [INFO]: Epoch 046 - training loss: 0.3908, validation loss: 0.0265
2024-05-25 04:11:03 [INFO]: Epoch 047 - training loss: 0.4046, validation loss: 0.0270
2024-05-25 04:11:09 [INFO]: Epoch 048 - training loss: 0.3960, validation loss: 0.0270
2024-05-25 04:11:15 [INFO]: Epoch 049 - training loss: 0.3996, validation loss: 0.0279
2024-05-25 04:11:21 [INFO]: Epoch 050 - training loss: 0.3932, validation loss: 0.0263
2024-05-25 04:11:27 [INFO]: Epoch 051 - training loss: 0.3872, validation loss: 0.0268
2024-05-25 04:11:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:11:27 [INFO]: Finished training. The best model is from epoch#41.
2024-05-25 04:11:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/BRITS_ettm1/20240525_T040623/BRITS.pypots
2024-05-25 04:11:28 [INFO]: BRITS on ETTm1: MAE=0.1434, MSE=0.0585
2024-05-25 04:11:28 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/BRITS_ettm1/imputation.pkl
2024-05-25 04:11:28 [INFO]: Using the given device: cuda:0
2024-05-25 04:11:28 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128
2024-05-25 04:11:28 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/tensorboard
2024-05-25 04:11:28 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 04:11:30 [INFO]: Epoch 001 - training loss: 1.3255, validation loss: 1.2692
2024-05-25 04:11:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch1_loss1.2691507190465927.pypots
2024-05-25 04:11:30 [INFO]: Epoch 002 - training loss: 0.9904, validation loss: 1.1033
2024-05-25 04:11:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch2_loss1.1033221781253815.pypots
2024-05-25 04:11:30 [INFO]: Epoch 003 - training loss: 0.9195, validation loss: 1.0421
2024-05-25 04:11:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch3_loss1.0421262383460999.pypots
2024-05-25 04:11:30 [INFO]: Epoch 004 - training loss: 0.8797, validation loss: 1.0217
2024-05-25 04:11:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch4_loss1.0217475146055222.pypots
2024-05-25 04:11:31 [INFO]: Epoch 005 - training loss: 0.8581, validation loss: 1.0028
2024-05-25 04:11:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch5_loss1.0028256922960281.pypots
2024-05-25 04:11:31 [INFO]: Epoch 006 - training loss: 0.8866, validation loss: 0.9921
2024-05-25 04:11:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch6_loss0.9920917451381683.pypots
2024-05-25 04:11:31 [INFO]: Epoch 007 - training loss: 0.8748, validation loss: 0.9854
2024-05-25 04:11:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch7_loss0.9854206144809723.pypots
2024-05-25 04:11:31 [INFO]: Epoch 008 - training loss: 0.8718, validation loss: 0.9798
2024-05-25 04:11:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch8_loss0.9798064827919006.pypots
2024-05-25 04:11:31 [INFO]: Epoch 009 - training loss: 0.8773, validation loss: 0.9776
2024-05-25 04:11:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch9_loss0.9775672554969788.pypots
2024-05-25 04:11:31 [INFO]: Epoch 010 - training loss: 0.8661, validation loss: 0.9728
2024-05-25 04:11:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch10_loss0.972817599773407.pypots
2024-05-25 04:11:32 [INFO]: Epoch 011 - training loss: 0.8944, validation loss: 0.9674
2024-05-25 04:11:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch11_loss0.9673928618431091.pypots
2024-05-25 04:11:32 [INFO]: Epoch 012 - training loss: 0.8620, validation loss: 0.9656
2024-05-25 04:11:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch12_loss0.9655588120222092.pypots
2024-05-25 04:11:32 [INFO]: Epoch 013 - training loss: 0.8437, validation loss: 0.9675
2024-05-25 04:11:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch13_loss0.967548206448555.pypots
2024-05-25 04:11:32 [INFO]: Epoch 014 - training loss: 0.8249, validation loss: 0.9666
2024-05-25 04:11:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch14_loss0.9665835201740265.pypots
2024-05-25 04:11:32 [INFO]: Epoch 015 - training loss: 0.8301, validation loss: 0.9626
2024-05-25 04:11:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch15_loss0.9626345336437225.pypots
2024-05-25 04:11:33 [INFO]: Epoch 016 - training loss: 0.8396, validation loss: 0.9612
2024-05-25 04:11:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch16_loss0.9612096548080444.pypots
2024-05-25 04:11:33 [INFO]: Epoch 017 - training loss: 0.8159, validation loss: 0.9621
2024-05-25 04:11:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch17_loss0.9621428847312927.pypots
2024-05-25 04:11:33 [INFO]: Epoch 018 - training loss: 0.8313, validation loss: 0.9592
2024-05-25 04:11:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch18_loss0.9592059850692749.pypots
2024-05-25 04:11:33 [INFO]: Epoch 019 - training loss: 0.8102, validation loss: 0.9641
2024-05-25 04:11:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch19_loss0.9640500992536545.pypots
2024-05-25 04:11:33 [INFO]: Epoch 020 - training loss: 0.7911, validation loss: 0.9623
2024-05-25 04:11:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch20_loss0.9622502774000168.pypots
2024-05-25 04:11:34 [INFO]: Epoch 021 - training loss: 0.7993, validation loss: 0.9632
2024-05-25 04:11:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch21_loss0.9631675332784653.pypots
2024-05-25 04:11:34 [INFO]: Epoch 022 - training loss: 0.8004, validation loss: 0.9608
2024-05-25 04:11:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch22_loss0.9608091562986374.pypots
2024-05-25 04:11:34 [INFO]: Epoch 023 - training loss: 0.7985, validation loss: 0.9558
2024-05-25 04:11:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch23_loss0.9557647407054901.pypots
2024-05-25 04:11:34 [INFO]: Epoch 024 - training loss: 0.7949, validation loss: 0.9524
2024-05-25 04:11:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch24_loss0.9524127095937729.pypots
2024-05-25 04:11:34 [INFO]: Epoch 025 - training loss: 0.7905, validation loss: 0.9510
2024-05-25 04:11:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch25_loss0.951014369726181.pypots
2024-05-25 04:11:35 [INFO]: Epoch 026 - training loss: 0.7735, validation loss: 0.9526
2024-05-25 04:11:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch26_loss0.9525717198848724.pypots
2024-05-25 04:11:35 [INFO]: Epoch 027 - training loss: 0.7641, validation loss: 0.9489
2024-05-25 04:11:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch27_loss0.9488503634929657.pypots
2024-05-25 04:11:35 [INFO]: Epoch 028 - training loss: 0.7726, validation loss: 0.9427
2024-05-25 04:11:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch28_loss0.9427165985107422.pypots
2024-05-25 04:11:35 [INFO]: Epoch 029 - training loss: 0.7585, validation loss: 0.9410
2024-05-25 04:11:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch29_loss0.9410419017076492.pypots
2024-05-25 04:11:35 [INFO]: Epoch 030 - training loss: 0.7715, validation loss: 0.9369
2024-05-25 04:11:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch30_loss0.9368670582771301.pypots
2024-05-25 04:11:35 [INFO]: Epoch 031 - training loss: 0.7766, validation loss: 0.9358
2024-05-25 04:11:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch31_loss0.9358332604169846.pypots
2024-05-25 04:11:36 [INFO]: Epoch 032 - training loss: 0.7758, validation loss: 0.9348
2024-05-25 04:11:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch32_loss0.9348299354314804.pypots
2024-05-25 04:11:36 [INFO]: Epoch 033 - training loss: 0.7530, validation loss: 0.9323
2024-05-25 04:11:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch33_loss0.932284489274025.pypots
2024-05-25 04:11:36 [INFO]: Epoch 034 - training loss: 0.7628, validation loss: 0.9285
2024-05-25 04:11:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch34_loss0.9285156428813934.pypots
2024-05-25 04:11:36 [INFO]: Epoch 035 - training loss: 0.7569, validation loss: 0.9306
2024-05-25 04:11:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch35_loss0.9306018799543381.pypots
2024-05-25 04:11:36 [INFO]: Epoch 036 - training loss: 0.7680, validation loss: 0.9278
2024-05-25 04:11:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch36_loss0.9277984350919724.pypots
2024-05-25 04:11:37 [INFO]: Epoch 037 - training loss: 0.7650, validation loss: 0.9285
2024-05-25 04:11:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch37_loss0.928488165140152.pypots
2024-05-25 04:11:37 [INFO]: Epoch 038 - training loss: 0.7725, validation loss: 0.9208
2024-05-25 04:11:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch38_loss0.9208334535360336.pypots
2024-05-25 04:11:37 [INFO]: Epoch 039 - training loss: 0.7522, validation loss: 0.9227
2024-05-25 04:11:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch39_loss0.9226595163345337.pypots
2024-05-25 04:11:37 [INFO]: Epoch 040 - training loss: 0.7361, validation loss: 0.9209
2024-05-25 04:11:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch40_loss0.9208636581897736.pypots
2024-05-25 04:11:37 [INFO]: Epoch 041 - training loss: 0.7770, validation loss: 0.9192
2024-05-25 04:11:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch41_loss0.919241651892662.pypots
2024-05-25 04:11:38 [INFO]: Epoch 042 - training loss: 0.7841, validation loss: 0.9217
2024-05-25 04:11:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch42_loss0.9216768890619278.pypots
2024-05-25 04:11:38 [INFO]: Epoch 043 - training loss: 0.7514, validation loss: 0.9162
2024-05-25 04:11:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch43_loss0.9162447899580002.pypots
2024-05-25 04:11:38 [INFO]: Epoch 044 - training loss: 0.7539, validation loss: 0.9151
2024-05-25 04:11:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch44_loss0.9150813817977905.pypots
2024-05-25 04:11:38 [INFO]: Epoch 045 - training loss: 0.7496, validation loss: 0.9155
2024-05-25 04:11:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch45_loss0.915527805685997.pypots
2024-05-25 04:11:38 [INFO]: Epoch 046 - training loss: 0.7513, validation loss: 0.9123
2024-05-25 04:11:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch46_loss0.9122656732797623.pypots
2024-05-25 04:11:38 [INFO]: Epoch 047 - training loss: 0.7500, validation loss: 0.9106
2024-05-25 04:11:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch47_loss0.9106464833021164.pypots
2024-05-25 04:11:39 [INFO]: Epoch 048 - training loss: 0.7364, validation loss: 0.9101
2024-05-25 04:11:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch48_loss0.9101293683052063.pypots
2024-05-25 04:11:39 [INFO]: Epoch 049 - training loss: 0.7318, validation loss: 0.9081
2024-05-25 04:11:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch49_loss0.9081435948610306.pypots
2024-05-25 04:11:39 [INFO]: Epoch 050 - training loss: 0.7529, validation loss: 0.9110
2024-05-25 04:11:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch50_loss0.9109859615564346.pypots
2024-05-25 04:11:39 [INFO]: Epoch 051 - training loss: 0.7661, validation loss: 0.9098
2024-05-25 04:11:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch51_loss0.9098003655672073.pypots
2024-05-25 04:11:39 [INFO]: Epoch 052 - training loss: 0.7325, validation loss: 0.9089
2024-05-25 04:11:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch52_loss0.9088503122329712.pypots
2024-05-25 04:11:40 [INFO]: Epoch 053 - training loss: 0.7460, validation loss: 0.9078
2024-05-25 04:11:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch53_loss0.907785639166832.pypots
2024-05-25 04:11:40 [INFO]: Epoch 054 - training loss: 0.7471, validation loss: 0.9061
2024-05-25 04:11:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch54_loss0.9061270505189896.pypots
2024-05-25 04:11:40 [INFO]: Epoch 055 - training loss: 0.7544, validation loss: 0.9015
2024-05-25 04:11:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch55_loss0.9014818221330643.pypots
2024-05-25 04:11:40 [INFO]: Epoch 056 - training loss: 0.7538, validation loss: 0.8969
2024-05-25 04:11:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch56_loss0.8968861699104309.pypots
2024-05-25 04:11:40 [INFO]: Epoch 057 - training loss: 0.7714, validation loss: 0.8989
2024-05-25 04:11:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch57_loss0.898927852511406.pypots
2024-05-25 04:11:41 [INFO]: Epoch 058 - training loss: 0.7439, validation loss: 0.9047
2024-05-25 04:11:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch58_loss0.9047061949968338.pypots
2024-05-25 04:11:41 [INFO]: Epoch 059 - training loss: 0.7607, validation loss: 0.9046
2024-05-25 04:11:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch59_loss0.9046055525541306.pypots
2024-05-25 04:11:41 [INFO]: Epoch 060 - training loss: 0.7339, validation loss: 0.9007
2024-05-25 04:11:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch60_loss0.9007434993982315.pypots
2024-05-25 04:11:41 [INFO]: Epoch 061 - training loss: 0.7647, validation loss: 0.8989
2024-05-25 04:11:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch61_loss0.8988849818706512.pypots
2024-05-25 04:11:41 [INFO]: Epoch 062 - training loss: 0.7735, validation loss: 0.8997
2024-05-25 04:11:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch62_loss0.8997434675693512.pypots
2024-05-25 04:11:42 [INFO]: Epoch 063 - training loss: 0.7676, validation loss: 0.8986
2024-05-25 04:11:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch63_loss0.8985698968172073.pypots
2024-05-25 04:11:42 [INFO]: Epoch 064 - training loss: 0.7431, validation loss: 0.9001
2024-05-25 04:11:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch64_loss0.9001471400260925.pypots
2024-05-25 04:11:42 [INFO]: Epoch 065 - training loss: 0.7375, validation loss: 0.8927
2024-05-25 04:11:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch65_loss0.8927019685506821.pypots
2024-05-25 04:11:42 [INFO]: Epoch 066 - training loss: 0.7479, validation loss: 0.8964
2024-05-25 04:11:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch66_loss0.8963888883590698.pypots
2024-05-25 04:11:42 [INFO]: Epoch 067 - training loss: 0.7371, validation loss: 0.8920
2024-05-25 04:11:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch67_loss0.8920127600431442.pypots
2024-05-25 04:11:42 [INFO]: Epoch 068 - training loss: 0.7358, validation loss: 0.8905
2024-05-25 04:11:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch68_loss0.8904794007539749.pypots
2024-05-25 04:11:43 [INFO]: Epoch 069 - training loss: 0.7362, validation loss: 0.8868
2024-05-25 04:11:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch69_loss0.886811375617981.pypots
2024-05-25 04:11:43 [INFO]: Epoch 070 - training loss: 0.7528, validation loss: 0.8948
2024-05-25 04:11:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch70_loss0.8947669565677643.pypots
2024-05-25 04:11:43 [INFO]: Epoch 071 - training loss: 0.7319, validation loss: 0.8941
2024-05-25 04:11:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch71_loss0.8941313773393631.pypots
2024-05-25 04:11:43 [INFO]: Epoch 072 - training loss: 0.7294, validation loss: 0.8907
2024-05-25 04:11:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch72_loss0.8906654566526413.pypots
2024-05-25 04:11:43 [INFO]: Epoch 073 - training loss: 0.7473, validation loss: 0.8882
2024-05-25 04:11:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch73_loss0.8882231116294861.pypots
2024-05-25 04:11:44 [INFO]: Epoch 074 - training loss: 0.7363, validation loss: 0.8877
2024-05-25 04:11:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch74_loss0.8876502066850662.pypots
2024-05-25 04:11:44 [INFO]: Epoch 075 - training loss: 0.7530, validation loss: 0.8885
2024-05-25 04:11:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch75_loss0.8884839415550232.pypots
2024-05-25 04:11:44 [INFO]: Epoch 076 - training loss: 0.7414, validation loss: 0.8883
2024-05-25 04:11:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch76_loss0.8882605284452438.pypots
2024-05-25 04:11:44 [INFO]: Epoch 077 - training loss: 0.7238, validation loss: 0.8853
2024-05-25 04:11:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch77_loss0.8853004276752472.pypots
2024-05-25 04:11:44 [INFO]: Epoch 078 - training loss: 0.7237, validation loss: 0.8819
2024-05-25 04:11:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch78_loss0.8819107115268707.pypots
2024-05-25 04:11:45 [INFO]: Epoch 079 - training loss: 0.7437, validation loss: 0.8822
2024-05-25 04:11:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch79_loss0.8821735233068466.pypots
2024-05-25 04:11:45 [INFO]: Epoch 080 - training loss: 0.7746, validation loss: 0.8843
2024-05-25 04:11:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch80_loss0.8843293786048889.pypots
2024-05-25 04:11:45 [INFO]: Epoch 081 - training loss: 0.7561, validation loss: 0.8765
2024-05-25 04:11:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch81_loss0.8765140324831009.pypots
2024-05-25 04:11:45 [INFO]: Epoch 082 - training loss: 0.7705, validation loss: 0.8807
2024-05-25 04:11:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch82_loss0.8807198107242584.pypots
2024-05-25 04:11:45 [INFO]: Epoch 083 - training loss: 0.7200, validation loss: 0.8777
2024-05-25 04:11:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch83_loss0.8777331560850143.pypots
2024-05-25 04:11:46 [INFO]: Epoch 084 - training loss: 0.7355, validation loss: 0.8825
2024-05-25 04:11:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch84_loss0.8825317025184631.pypots
2024-05-25 04:11:46 [INFO]: Epoch 085 - training loss: 0.7527, validation loss: 0.8755
2024-05-25 04:11:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch85_loss0.8754590004682541.pypots
2024-05-25 04:11:46 [INFO]: Epoch 086 - training loss: 0.7290, validation loss: 0.8770
2024-05-25 04:11:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch86_loss0.87696473300457.pypots
2024-05-25 04:11:46 [INFO]: Epoch 087 - training loss: 0.7336, validation loss: 0.8756
2024-05-25 04:11:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch87_loss0.8756072968244553.pypots
2024-05-25 04:11:46 [INFO]: Epoch 088 - training loss: 0.7271, validation loss: 0.8725
2024-05-25 04:11:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch88_loss0.8724751174449921.pypots
2024-05-25 04:11:46 [INFO]: Epoch 089 - training loss: 0.7260, validation loss: 0.8703
2024-05-25 04:11:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch89_loss0.8702818751335144.pypots
2024-05-25 04:11:47 [INFO]: Epoch 090 - training loss: 0.7274, validation loss: 0.8759
2024-05-25 04:11:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch90_loss0.8758616149425507.pypots
2024-05-25 04:11:47 [INFO]: Epoch 091 - training loss: 0.7369, validation loss: 0.8699
2024-05-25 04:11:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch91_loss0.8699274361133575.pypots
2024-05-25 04:11:47 [INFO]: Epoch 092 - training loss: 0.7122, validation loss: 0.8717
2024-05-25 04:11:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch92_loss0.8717325776815414.pypots
2024-05-25 04:11:47 [INFO]: Epoch 093 - training loss: 0.7383, validation loss: 0.8682
2024-05-25 04:11:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch93_loss0.8681510239839554.pypots
2024-05-25 04:11:47 [INFO]: Epoch 094 - training loss: 0.7180, validation loss: 0.8692
2024-05-25 04:11:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch94_loss0.8691738545894623.pypots
2024-05-25 04:11:48 [INFO]: Epoch 095 - training loss: 0.7154, validation loss: 0.8646
2024-05-25 04:11:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch95_loss0.8646009117364883.pypots
2024-05-25 04:11:48 [INFO]: Epoch 096 - training loss: 0.7312, validation loss: 0.8652
2024-05-25 04:11:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch96_loss0.8651731461286545.pypots
2024-05-25 04:11:48 [INFO]: Epoch 097 - training loss: 0.7110, validation loss: 0.8666
2024-05-25 04:11:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch97_loss0.8666025549173355.pypots
2024-05-25 04:11:48 [INFO]: Epoch 098 - training loss: 0.7341, validation loss: 0.8629
2024-05-25 04:11:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch98_loss0.8628627210855484.pypots
2024-05-25 04:11:48 [INFO]: Epoch 099 - training loss: 0.7133, validation loss: 0.8607
2024-05-25 04:11:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch99_loss0.8607441335916519.pypots
2024-05-25 04:11:49 [INFO]: Epoch 100 - training loss: 0.7385, validation loss: 0.8608
2024-05-25 04:11:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch100_loss0.8608108013868332.pypots
2024-05-25 04:11:49 [INFO]: Epoch 101 - training loss: 0.7258, validation loss: 0.8612
2024-05-25 04:11:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch101_loss0.8612385839223862.pypots
2024-05-25 04:11:49 [INFO]: Epoch 102 - training loss: 0.7289, validation loss: 0.8590
2024-05-25 04:11:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch102_loss0.8589674830436707.pypots
2024-05-25 04:11:49 [INFO]: Epoch 103 - training loss: 0.7142, validation loss: 0.8586
2024-05-25 04:11:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch103_loss0.8585641384124756.pypots
2024-05-25 04:11:49 [INFO]: Epoch 104 - training loss: 0.7095, validation loss: 0.8575
2024-05-25 04:11:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch104_loss0.8575281649827957.pypots
2024-05-25 04:11:50 [INFO]: Epoch 105 - training loss: 0.7343, validation loss: 0.8540
2024-05-25 04:11:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch105_loss0.8540390282869339.pypots
2024-05-25 04:11:50 [INFO]: Epoch 106 - training loss: 0.7200, validation loss: 0.8611
2024-05-25 04:11:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch106_loss0.8611359298229218.pypots
2024-05-25 04:11:50 [INFO]: Epoch 107 - training loss: 0.7145, validation loss: 0.8521
2024-05-25 04:11:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch107_loss0.8520979285240173.pypots
2024-05-25 04:11:50 [INFO]: Epoch 108 - training loss: 0.7436, validation loss: 0.8525
2024-05-25 04:11:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch108_loss0.8524688631296158.pypots
2024-05-25 04:11:50 [INFO]: Epoch 109 - training loss: 0.7439, validation loss: 0.8518
2024-05-25 04:11:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch109_loss0.8517582267522812.pypots
2024-05-25 04:11:50 [INFO]: Epoch 110 - training loss: 0.7106, validation loss: 0.8536
2024-05-25 04:11:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch110_loss0.8536335676908493.pypots
2024-05-25 04:11:51 [INFO]: Epoch 111 - training loss: 0.7188, validation loss: 0.8602
2024-05-25 04:11:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch111_loss0.8601879328489304.pypots
2024-05-25 04:11:51 [INFO]: Epoch 112 - training loss: 0.7421, validation loss: 0.8445
2024-05-25 04:11:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch112_loss0.8444551527500153.pypots
2024-05-25 04:11:51 [INFO]: Epoch 113 - training loss: 0.7203, validation loss: 0.8533
2024-05-25 04:11:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch113_loss0.8533450365066528.pypots
2024-05-25 04:11:51 [INFO]: Epoch 114 - training loss: 0.7231, validation loss: 0.8452
2024-05-25 04:11:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch114_loss0.8452179282903671.pypots
2024-05-25 04:11:51 [INFO]: Epoch 115 - training loss: 0.7236, validation loss: 0.8422
2024-05-25 04:11:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch115_loss0.8422246426343918.pypots
2024-05-25 04:11:52 [INFO]: Epoch 116 - training loss: 0.7293, validation loss: 0.8383
2024-05-25 04:11:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch116_loss0.8382673412561417.pypots
2024-05-25 04:11:52 [INFO]: Epoch 117 - training loss: 0.7262, validation loss: 0.8381
2024-05-25 04:11:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch117_loss0.8380930870771408.pypots
2024-05-25 04:11:52 [INFO]: Epoch 118 - training loss: 0.7142, validation loss: 0.8404
2024-05-25 04:11:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch118_loss0.8404451012611389.pypots
2024-05-25 04:11:52 [INFO]: Epoch 119 - training loss: 0.7384, validation loss: 0.8383
2024-05-25 04:11:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch119_loss0.8382722288370132.pypots
2024-05-25 04:11:52 [INFO]: Epoch 120 - training loss: 0.7160, validation loss: 0.8411
2024-05-25 04:11:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch120_loss0.8410582095384598.pypots
2024-05-25 04:11:53 [INFO]: Epoch 121 - training loss: 0.7113, validation loss: 0.8352
2024-05-25 04:11:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch121_loss0.8351923525333405.pypots
2024-05-25 04:11:53 [INFO]: Epoch 122 - training loss: 0.7007, validation loss: 0.8340
2024-05-25 04:11:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch122_loss0.834025502204895.pypots
2024-05-25 04:11:53 [INFO]: Epoch 123 - training loss: 0.7185, validation loss: 0.8376
2024-05-25 04:11:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch123_loss0.8375582545995712.pypots
2024-05-25 04:11:53 [INFO]: Epoch 124 - training loss: 0.7104, validation loss: 0.8347
2024-05-25 04:11:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch124_loss0.8347018957138062.pypots
2024-05-25 04:11:53 [INFO]: Epoch 125 - training loss: 0.7169, validation loss: 0.8311
2024-05-25 04:11:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch125_loss0.8311005085706711.pypots
2024-05-25 04:11:53 [INFO]: Epoch 126 - training loss: 0.7085, validation loss: 0.8334
2024-05-25 04:11:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch126_loss0.8333967477083206.pypots
2024-05-25 04:11:54 [INFO]: Epoch 127 - training loss: 0.7168, validation loss: 0.8301
2024-05-25 04:11:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch127_loss0.8301313370466232.pypots
2024-05-25 04:11:54 [INFO]: Epoch 128 - training loss: 0.7174, validation loss: 0.8299
2024-05-25 04:11:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch128_loss0.8299227952957153.pypots
2024-05-25 04:11:54 [INFO]: Epoch 129 - training loss: 0.7121, validation loss: 0.8272
2024-05-25 04:11:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch129_loss0.827167198061943.pypots
2024-05-25 04:11:54 [INFO]: Epoch 130 - training loss: 0.7210, validation loss: 0.8291
2024-05-25 04:11:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch130_loss0.8290650546550751.pypots
2024-05-25 04:11:54 [INFO]: Epoch 131 - training loss: 0.7247, validation loss: 0.8261
2024-05-25 04:11:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch131_loss0.826111450791359.pypots
2024-05-25 04:11:55 [INFO]: Epoch 132 - training loss: 0.7235, validation loss: 0.8227
2024-05-25 04:11:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch132_loss0.822736456990242.pypots
2024-05-25 04:11:55 [INFO]: Epoch 133 - training loss: 0.7262, validation loss: 0.8273
2024-05-25 04:11:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch133_loss0.8273022025823593.pypots
2024-05-25 04:11:55 [INFO]: Epoch 134 - training loss: 0.7170, validation loss: 0.8242
2024-05-25 04:11:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch134_loss0.8242354393005371.pypots
2024-05-25 04:11:55 [INFO]: Epoch 135 - training loss: 0.7028, validation loss: 0.8261
2024-05-25 04:11:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch135_loss0.8261350244283676.pypots
2024-05-25 04:11:55 [INFO]: Epoch 136 - training loss: 0.7054, validation loss: 0.8215
2024-05-25 04:11:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch136_loss0.8214612901210785.pypots
2024-05-25 04:11:56 [INFO]: Epoch 137 - training loss: 0.7133, validation loss: 0.8209
2024-05-25 04:11:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch137_loss0.8208954781293869.pypots
2024-05-25 04:11:56 [INFO]: Epoch 138 - training loss: 0.7239, validation loss: 0.8217
2024-05-25 04:11:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch138_loss0.8216768801212311.pypots
2024-05-25 04:11:56 [INFO]: Epoch 139 - training loss: 0.7169, validation loss: 0.8197
2024-05-25 04:11:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch139_loss0.8196684718132019.pypots
2024-05-25 04:11:56 [INFO]: Epoch 140 - training loss: 0.7144, validation loss: 0.8145
2024-05-25 04:11:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch140_loss0.8144660592079163.pypots
2024-05-25 04:11:56 [INFO]: Epoch 141 - training loss: 0.7144, validation loss: 0.8174
2024-05-25 04:11:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch141_loss0.8174000680446625.pypots
2024-05-25 04:11:57 [INFO]: Epoch 142 - training loss: 0.7364, validation loss: 0.8236
2024-05-25 04:11:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch142_loss0.8235635906457901.pypots
2024-05-25 04:11:57 [INFO]: Epoch 143 - training loss: 0.7308, validation loss: 0.8152
2024-05-25 04:11:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch143_loss0.8151925504207611.pypots
2024-05-25 04:11:57 [INFO]: Epoch 144 - training loss: 0.7451, validation loss: 0.8173
2024-05-25 04:11:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch144_loss0.817336305975914.pypots
2024-05-25 04:11:57 [INFO]: Epoch 145 - training loss: 0.7318, validation loss: 0.8102
2024-05-25 04:11:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch145_loss0.8102046251296997.pypots
2024-05-25 04:11:57 [INFO]: Epoch 146 - training loss: 0.7208, validation loss: 0.8144
2024-05-25 04:11:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch146_loss0.8143575489521027.pypots
2024-05-25 04:11:57 [INFO]: Epoch 147 - training loss: 0.7129, validation loss: 0.8105
2024-05-25 04:11:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch147_loss0.8105462789535522.pypots
2024-05-25 04:11:58 [INFO]: Epoch 148 - training loss: 0.7071, validation loss: 0.8137
2024-05-25 04:11:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch148_loss0.8136701434850693.pypots
2024-05-25 04:11:58 [INFO]: Epoch 149 - training loss: 0.7193, validation loss: 0.8131
2024-05-25 04:11:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch149_loss0.8130892366170883.pypots
2024-05-25 04:11:58 [INFO]: Epoch 150 - training loss: 0.7169, validation loss: 0.8091
2024-05-25 04:11:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch150_loss0.809080645442009.pypots
2024-05-25 04:11:58 [INFO]: Epoch 151 - training loss: 0.7312, validation loss: 0.8103
2024-05-25 04:11:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch151_loss0.8103164732456207.pypots
2024-05-25 04:11:58 [INFO]: Epoch 152 - training loss: 0.7324, validation loss: 0.8087
2024-05-25 04:11:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch152_loss0.8087184429168701.pypots
2024-05-25 04:11:59 [INFO]: Epoch 153 - training loss: 0.7251, validation loss: 0.8093
2024-05-25 04:11:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch153_loss0.8093255162239075.pypots
2024-05-25 04:11:59 [INFO]: Epoch 154 - training loss: 0.7232, validation loss: 0.8116
2024-05-25 04:11:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch154_loss0.8116216659545898.pypots
2024-05-25 04:11:59 [INFO]: Epoch 155 - training loss: 0.7041, validation loss: 0.8074
2024-05-25 04:11:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch155_loss0.8074072897434235.pypots
2024-05-25 04:11:59 [INFO]: Epoch 156 - training loss: 0.7166, validation loss: 0.8066
2024-05-25 04:11:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch156_loss0.8066096752882004.pypots
2024-05-25 04:11:59 [INFO]: Epoch 157 - training loss: 0.7310, validation loss: 0.8071
2024-05-25 04:11:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch157_loss0.8070696145296097.pypots
2024-05-25 04:12:00 [INFO]: Epoch 158 - training loss: 0.7198, validation loss: 0.8095
2024-05-25 04:12:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch158_loss0.8095417469739914.pypots
2024-05-25 04:12:00 [INFO]: Epoch 159 - training loss: 0.6985, validation loss: 0.8078
2024-05-25 04:12:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch159_loss0.807789146900177.pypots
2024-05-25 04:12:00 [INFO]: Epoch 160 - training loss: 0.7162, validation loss: 0.8063
2024-05-25 04:12:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch160_loss0.8063434958457947.pypots
2024-05-25 04:12:00 [INFO]: Epoch 161 - training loss: 0.7176, validation loss: 0.8036
2024-05-25 04:12:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch161_loss0.8036414086818695.pypots
2024-05-25 04:12:00 [INFO]: Epoch 162 - training loss: 0.7108, validation loss: 0.8058
2024-05-25 04:12:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch162_loss0.8058487623929977.pypots
2024-05-25 04:12:00 [INFO]: Epoch 163 - training loss: 0.7366, validation loss: 0.8033
2024-05-25 04:12:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch163_loss0.8032858818769455.pypots
2024-05-25 04:12:01 [INFO]: Epoch 164 - training loss: 0.7270, validation loss: 0.8016
2024-05-25 04:12:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch164_loss0.8016036450862885.pypots
2024-05-25 04:12:01 [INFO]: Epoch 165 - training loss: 0.7269, validation loss: 0.8045
2024-05-25 04:12:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch165_loss0.8045297116041183.pypots
2024-05-25 04:12:01 [INFO]: Epoch 166 - training loss: 0.7154, validation loss: 0.8003
2024-05-25 04:12:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch166_loss0.8002979904413223.pypots
2024-05-25 04:12:01 [INFO]: Epoch 167 - training loss: 0.7144, validation loss: 0.8050
2024-05-25 04:12:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch167_loss0.8049960434436798.pypots
2024-05-25 04:12:01 [INFO]: Epoch 168 - training loss: 0.7196, validation loss: 0.7996
2024-05-25 04:12:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch168_loss0.7995631545782089.pypots
2024-05-25 04:12:02 [INFO]: Epoch 169 - training loss: 0.7308, validation loss: 0.7985
2024-05-25 04:12:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch169_loss0.7984787672758102.pypots
2024-05-25 04:12:02 [INFO]: Epoch 170 - training loss: 0.7496, validation loss: 0.7978
2024-05-25 04:12:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch170_loss0.7978395521640778.pypots
2024-05-25 04:12:02 [INFO]: Epoch 171 - training loss: 0.7573, validation loss: 0.7973
2024-05-25 04:12:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch171_loss0.7973334789276123.pypots
2024-05-25 04:12:02 [INFO]: Epoch 172 - training loss: 0.7238, validation loss: 0.8032
2024-05-25 04:12:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch172_loss0.8031895011663437.pypots
2024-05-25 04:12:02 [INFO]: Epoch 173 - training loss: 0.7039, validation loss: 0.7981
2024-05-25 04:12:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch173_loss0.7981331795454025.pypots
2024-05-25 04:12:03 [INFO]: Epoch 174 - training loss: 0.7225, validation loss: 0.7985
2024-05-25 04:12:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch174_loss0.7985075265169144.pypots
2024-05-25 04:12:03 [INFO]: Epoch 175 - training loss: 0.7052, validation loss: 0.8036
2024-05-25 04:12:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch175_loss0.8035920709371567.pypots
2024-05-25 04:12:03 [INFO]: Epoch 176 - training loss: 0.7602, validation loss: 0.7970
2024-05-25 04:12:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch176_loss0.7970059365034103.pypots
2024-05-25 04:12:03 [INFO]: Epoch 177 - training loss: 0.7131, validation loss: 0.7978
2024-05-25 04:12:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch177_loss0.7977575659751892.pypots
2024-05-25 04:12:03 [INFO]: Epoch 178 - training loss: 0.7330, validation loss: 0.7934
2024-05-25 04:12:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch178_loss0.7933807373046875.pypots
2024-05-25 04:12:03 [INFO]: Epoch 179 - training loss: 0.7221, validation loss: 0.7970
2024-05-25 04:12:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch179_loss0.797032818198204.pypots
2024-05-25 04:12:04 [INFO]: Epoch 180 - training loss: 0.7127, validation loss: 0.7980
2024-05-25 04:12:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch180_loss0.7980093359947205.pypots
2024-05-25 04:12:04 [INFO]: Epoch 181 - training loss: 0.7208, validation loss: 0.7939
2024-05-25 04:12:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch181_loss0.7938803136348724.pypots
2024-05-25 04:12:04 [INFO]: Epoch 182 - training loss: 0.7207, validation loss: 0.7956
2024-05-25 04:12:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch182_loss0.7955776751041412.pypots
2024-05-25 04:12:04 [INFO]: Epoch 183 - training loss: 0.7069, validation loss: 0.7967
2024-05-25 04:12:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch183_loss0.7967491894960403.pypots
2024-05-25 04:12:04 [INFO]: Epoch 184 - training loss: 0.7168, validation loss: 0.7982
2024-05-25 04:12:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch184_loss0.7982116341590881.pypots
2024-05-25 04:12:05 [INFO]: Epoch 185 - training loss: 0.7346, validation loss: 0.7971
2024-05-25 04:12:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch185_loss0.7971131503582001.pypots
2024-05-25 04:12:05 [INFO]: Epoch 186 - training loss: 0.7242, validation loss: 0.7950
2024-05-25 04:12:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch186_loss0.7949980050325394.pypots
2024-05-25 04:12:05 [INFO]: Epoch 187 - training loss: 0.7148, validation loss: 0.7945
2024-05-25 04:12:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch187_loss0.794540524482727.pypots
2024-05-25 04:12:05 [INFO]: Epoch 188 - training loss: 0.7105, validation loss: 0.7972
2024-05-25 04:12:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN_epoch188_loss0.7971612513065338.pypots
2024-05-25 04:12:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:12:05 [INFO]: Finished training. The best model is from epoch#178.
2024-05-25 04:12:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T041128/MRNN.pypots
2024-05-25 04:12:06 [INFO]: MRNN on ETTm1: MAE=0.5997, MSE=0.9987
2024-05-25 04:12:06 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/MRNN_ettm1/imputation.pkl
2024-05-25 04:12:06 [INFO]: Using the given device: cpu
2024-05-25 04:12:06 [INFO]: LOCF on ETTm1: MAE=0.1420, MSE=0.0788
2024-05-25 04:12:06 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_ettm1".
2024-05-25 04:12:06 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/LOCF_ettm1/imputation.pkl
2024-05-25 04:12:06 [INFO]: Median on ETTm1: MAE=0.6533, MSE=0.8148
2024-05-25 04:12:06 [INFO]: Successfully created the given path "saved_results/round_1/Median_ettm1".
2024-05-25 04:12:06 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Median_ettm1/imputation.pkl
2024-05-25 04:12:06 [INFO]: Mean on ETTm1: MAE=0.6593, MSE=0.7994
2024-05-25 04:12:06 [INFO]: Successfully created the given path "saved_results/round_1/Mean_ettm1".
2024-05-25 04:12:06 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Mean_ettm1/imputation.pkl
2024-05-25 04:12:06 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-25 04:12:06 [INFO]: Using the given device: cuda:0
2024-05-25 04:12:06 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/SAITS_ettm1/20240525_T041206
2024-05-25 04:12:06 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/SAITS_ettm1/20240525_T041206/tensorboard
2024-05-25 04:12:06 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 04:12:06 [INFO]: Epoch 001 - training loss: 1.1676, validation loss: 0.2780
2024-05-25 04:12:07 [INFO]: Epoch 002 - training loss: 0.8415, validation loss: 0.1446
2024-05-25 04:12:07 [INFO]: Epoch 003 - training loss: 0.7227, validation loss: 0.1246
2024-05-25 04:12:08 [INFO]: Epoch 004 - training loss: 0.6445, validation loss: 0.0977
2024-05-25 04:12:08 [INFO]: Epoch 005 - training loss: 0.6171, validation loss: 0.1018
2024-05-25 04:12:09 [INFO]: Epoch 006 - training loss: 0.5832, validation loss: 0.0743
2024-05-25 04:12:09 [INFO]: Epoch 007 - training loss: 0.5606, validation loss: 0.0698
2024-05-25 04:12:10 [INFO]: Epoch 008 - training loss: 0.5365, validation loss: 0.0683
2024-05-25 04:12:10 [INFO]: Epoch 009 - training loss: 0.5317, validation loss: 0.0631
2024-05-25 04:12:11 [INFO]: Epoch 010 - training loss: 0.5149, validation loss: 0.0594
2024-05-25 04:12:11 [INFO]: Epoch 011 - training loss: 0.4838, validation loss: 0.0580
2024-05-25 04:12:12 [INFO]: Epoch 012 - training loss: 0.4891, validation loss: 0.0542
2024-05-25 04:12:12 [INFO]: Epoch 013 - training loss: 0.4800, validation loss: 0.0498
2024-05-25 04:12:13 [INFO]: Epoch 014 - training loss: 0.4676, validation loss: 0.0556
2024-05-25 04:12:13 [INFO]: Epoch 015 - training loss: 0.4778, validation loss: 0.0478
2024-05-25 04:12:13 [INFO]: Epoch 016 - training loss: 0.4492, validation loss: 0.0478
2024-05-25 04:12:14 [INFO]: Epoch 017 - training loss: 0.4820, validation loss: 0.0484
2024-05-25 04:12:14 [INFO]: Epoch 018 - training loss: 0.4515, validation loss: 0.0536
2024-05-25 04:12:15 [INFO]: Epoch 019 - training loss: 0.4339, validation loss: 0.0418
2024-05-25 04:12:15 [INFO]: Epoch 020 - training loss: 0.4145, validation loss: 0.0433
2024-05-25 04:12:16 [INFO]: Epoch 021 - training loss: 0.4419, validation loss: 0.0562
2024-05-25 04:12:16 [INFO]: Epoch 022 - training loss: 0.4203, validation loss: 0.0476
2024-05-25 04:12:17 [INFO]: Epoch 023 - training loss: 0.4086, validation loss: 0.0475
2024-05-25 04:12:17 [INFO]: Epoch 024 - training loss: 0.4084, validation loss: 0.0500
2024-05-25 04:12:18 [INFO]: Epoch 025 - training loss: 0.3929, validation loss: 0.0382
2024-05-25 04:12:18 [INFO]: Epoch 026 - training loss: 0.3891, validation loss: 0.0403
2024-05-25 04:12:19 [INFO]: Epoch 027 - training loss: 0.3819, validation loss: 0.0391
2024-05-25 04:12:19 [INFO]: Epoch 028 - training loss: 0.3827, validation loss: 0.0492
2024-05-25 04:12:20 [INFO]: Epoch 029 - training loss: 0.3984, validation loss: 0.0545
2024-05-25 04:12:20 [INFO]: Epoch 030 - training loss: 0.3806, validation loss: 0.0371
2024-05-25 04:12:21 [INFO]: Epoch 031 - training loss: 0.3820, validation loss: 0.0399
2024-05-25 04:12:21 [INFO]: Epoch 032 - training loss: 0.3716, validation loss: 0.0373
2024-05-25 04:12:22 [INFO]: Epoch 033 - training loss: 0.3584, validation loss: 0.0355
2024-05-25 04:12:22 [INFO]: Epoch 034 - training loss: 0.3584, validation loss: 0.0421
2024-05-25 04:12:23 [INFO]: Epoch 035 - training loss: 0.3481, validation loss: 0.0393
2024-05-25 04:12:23 [INFO]: Epoch 036 - training loss: 0.3616, validation loss: 0.0430
2024-05-25 04:12:24 [INFO]: Epoch 037 - training loss: 0.3708, validation loss: 0.0559
2024-05-25 04:12:24 [INFO]: Epoch 038 - training loss: 0.3604, validation loss: 0.0381
2024-05-25 04:12:25 [INFO]: Epoch 039 - training loss: 0.3751, validation loss: 0.0352
2024-05-25 04:12:25 [INFO]: Epoch 040 - training loss: 0.3533, validation loss: 0.0681
2024-05-25 04:12:26 [INFO]: Epoch 041 - training loss: 0.3523, validation loss: 0.0366
2024-05-25 04:12:26 [INFO]: Epoch 042 - training loss: 0.3329, validation loss: 0.0344
2024-05-25 04:12:27 [INFO]: Epoch 043 - training loss: 0.3293, validation loss: 0.0370
2024-05-25 04:12:27 [INFO]: Epoch 044 - training loss: 0.3230, validation loss: 0.0362
2024-05-25 04:12:28 [INFO]: Epoch 045 - training loss: 0.3271, validation loss: 0.0965
2024-05-25 04:12:28 [INFO]: Epoch 046 - training loss: 0.3561, validation loss: 0.0474
2024-05-25 04:12:29 [INFO]: Epoch 047 - training loss: 0.3335, validation loss: 0.0411
2024-05-25 04:12:29 [INFO]: Epoch 048 - training loss: 0.3249, validation loss: 0.0439
2024-05-25 04:12:30 [INFO]: Epoch 049 - training loss: 0.3313, validation loss: 0.0371
2024-05-25 04:12:30 [INFO]: Epoch 050 - training loss: 0.3106, validation loss: 0.0305
2024-05-25 04:12:31 [INFO]: Epoch 051 - training loss: 0.3097, validation loss: 0.0390
2024-05-25 04:12:31 [INFO]: Epoch 052 - training loss: 0.3126, validation loss: 0.0410
2024-05-25 04:12:32 [INFO]: Epoch 053 - training loss: 0.3036, validation loss: 0.0360
2024-05-25 04:12:32 [INFO]: Epoch 054 - training loss: 0.3091, validation loss: 0.0359
2024-05-25 04:12:32 [INFO]: Epoch 055 - training loss: 0.3161, validation loss: 0.0388
2024-05-25 04:12:33 [INFO]: Epoch 056 - training loss: 0.3055, validation loss: 0.0457
2024-05-25 04:12:33 [INFO]: Epoch 057 - training loss: 0.3073, validation loss: 0.0301
2024-05-25 04:12:34 [INFO]: Epoch 058 - training loss: 0.2914, validation loss: 0.0384
2024-05-25 04:12:34 [INFO]: Epoch 059 - training loss: 0.2947, validation loss: 0.0309
2024-05-25 04:12:35 [INFO]: Epoch 060 - training loss: 0.2930, validation loss: 0.0310
2024-05-25 04:12:35 [INFO]: Epoch 061 - training loss: 0.2905, validation loss: 0.0358
2024-05-25 04:12:36 [INFO]: Epoch 062 - training loss: 0.2906, validation loss: 0.0317
2024-05-25 04:12:36 [INFO]: Epoch 063 - training loss: 0.2904, validation loss: 0.0408
2024-05-25 04:12:37 [INFO]: Epoch 064 - training loss: 0.2975, validation loss: 0.0339
2024-05-25 04:12:37 [INFO]: Epoch 065 - training loss: 0.2867, validation loss: 0.0334
2024-05-25 04:12:38 [INFO]: Epoch 066 - training loss: 0.2815, validation loss: 0.0338
2024-05-25 04:12:38 [INFO]: Epoch 067 - training loss: 0.2844, validation loss: 0.0318
2024-05-25 04:12:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:12:38 [INFO]: Finished training. The best model is from epoch#57.
2024-05-25 04:12:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/SAITS_ettm1/20240525_T041206/SAITS.pypots
2024-05-25 04:12:38 [INFO]: SAITS on ETTm1: MAE=0.1587, MSE=0.0509
2024-05-25 04:12:38 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/SAITS_ettm1/imputation.pkl
2024-05-25 04:12:38 [INFO]: Using the given device: cuda:0
2024-05-25 04:12:38 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/Transformer_ettm1/20240525_T041238
2024-05-25 04:12:38 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/Transformer_ettm1/20240525_T041238/tensorboard
2024-05-25 04:12:38 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 04:12:39 [INFO]: Epoch 001 - training loss: 1.1978, validation loss: 0.3535
2024-05-25 04:12:39 [INFO]: Epoch 002 - training loss: 0.7147, validation loss: 0.1655
2024-05-25 04:12:39 [INFO]: Epoch 003 - training loss: 0.5731, validation loss: 0.1283
2024-05-25 04:12:39 [INFO]: Epoch 004 - training loss: 0.5101, validation loss: 0.1056
2024-05-25 04:12:39 [INFO]: Epoch 005 - training loss: 0.4749, validation loss: 0.0906
2024-05-25 04:12:40 [INFO]: Epoch 006 - training loss: 0.4518, validation loss: 0.0790
2024-05-25 04:12:40 [INFO]: Epoch 007 - training loss: 0.4304, validation loss: 0.0704
2024-05-25 04:12:40 [INFO]: Epoch 008 - training loss: 0.4248, validation loss: 0.0679
2024-05-25 04:12:40 [INFO]: Epoch 009 - training loss: 0.4063, validation loss: 0.0640
2024-05-25 04:12:40 [INFO]: Epoch 010 - training loss: 0.3857, validation loss: 0.0632
2024-05-25 04:12:41 [INFO]: Epoch 011 - training loss: 0.3806, validation loss: 0.0607
2024-05-25 04:12:41 [INFO]: Epoch 012 - training loss: 0.3728, validation loss: 0.0554
2024-05-25 04:12:41 [INFO]: Epoch 013 - training loss: 0.3593, validation loss: 0.0535
2024-05-25 04:12:41 [INFO]: Epoch 014 - training loss: 0.3534, validation loss: 0.0519
2024-05-25 04:12:41 [INFO]: Epoch 015 - training loss: 0.3394, validation loss: 0.0504
2024-05-25 04:12:42 [INFO]: Epoch 016 - training loss: 0.3305, validation loss: 0.0501
2024-05-25 04:12:42 [INFO]: Epoch 017 - training loss: 0.3285, validation loss: 0.0483
2024-05-25 04:12:42 [INFO]: Epoch 018 - training loss: 0.3213, validation loss: 0.0455
2024-05-25 04:12:42 [INFO]: Epoch 019 - training loss: 0.3212, validation loss: 0.0503
2024-05-25 04:12:42 [INFO]: Epoch 020 - training loss: 0.3193, validation loss: 0.0484
2024-05-25 04:12:43 [INFO]: Epoch 021 - training loss: 0.3134, validation loss: 0.0455
2024-05-25 04:12:43 [INFO]: Epoch 022 - training loss: 0.3062, validation loss: 0.0416
2024-05-25 04:12:43 [INFO]: Epoch 023 - training loss: 0.3010, validation loss: 0.0440
2024-05-25 04:12:43 [INFO]: Epoch 024 - training loss: 0.3014, validation loss: 0.0477
2024-05-25 04:12:43 [INFO]: Epoch 025 - training loss: 0.2996, validation loss: 0.0399
2024-05-25 04:12:44 [INFO]: Epoch 026 - training loss: 0.2895, validation loss: 0.0403
2024-05-25 04:12:44 [INFO]: Epoch 027 - training loss: 0.2916, validation loss: 0.0449
2024-05-25 04:12:44 [INFO]: Epoch 028 - training loss: 0.2854, validation loss: 0.0424
2024-05-25 04:12:44 [INFO]: Epoch 029 - training loss: 0.2863, validation loss: 0.0405
2024-05-25 04:12:44 [INFO]: Epoch 030 - training loss: 0.2825, validation loss: 0.0423
2024-05-25 04:12:44 [INFO]: Epoch 031 - training loss: 0.2795, validation loss: 0.0373
2024-05-25 04:12:45 [INFO]: Epoch 032 - training loss: 0.2746, validation loss: 0.0361
2024-05-25 04:12:45 [INFO]: Epoch 033 - training loss: 0.2689, validation loss: 0.0350
2024-05-25 04:12:45 [INFO]: Epoch 034 - training loss: 0.2633, validation loss: 0.0361
2024-05-25 04:12:45 [INFO]: Epoch 035 - training loss: 0.2651, validation loss: 0.0404
2024-05-25 04:12:46 [INFO]: Epoch 036 - training loss: 0.2645, validation loss: 0.0336
2024-05-25 04:12:46 [INFO]: Epoch 037 - training loss: 0.2541, validation loss: 0.0378
2024-05-25 04:12:46 [INFO]: Epoch 038 - training loss: 0.2538, validation loss: 0.0326
2024-05-25 04:12:46 [INFO]: Epoch 039 - training loss: 0.2503, validation loss: 0.0316
2024-05-25 04:12:46 [INFO]: Epoch 040 - training loss: 0.2469, validation loss: 0.0347
2024-05-25 04:12:46 [INFO]: Epoch 041 - training loss: 0.2485, validation loss: 0.0345
2024-05-25 04:12:47 [INFO]: Epoch 042 - training loss: 0.2492, validation loss: 0.0336
2024-05-25 04:12:47 [INFO]: Epoch 043 - training loss: 0.2474, validation loss: 0.0304
2024-05-25 04:12:47 [INFO]: Epoch 044 - training loss: 0.2352, validation loss: 0.0316
2024-05-25 04:12:47 [INFO]: Epoch 045 - training loss: 0.2371, validation loss: 0.0292
2024-05-25 04:12:47 [INFO]: Epoch 046 - training loss: 0.2332, validation loss: 0.0326
2024-05-25 04:12:48 [INFO]: Epoch 047 - training loss: 0.2298, validation loss: 0.0346
2024-05-25 04:12:48 [INFO]: Epoch 048 - training loss: 0.2296, validation loss: 0.0304
2024-05-25 04:12:48 [INFO]: Epoch 049 - training loss: 0.2278, validation loss: 0.0294
2024-05-25 04:12:48 [INFO]: Epoch 050 - training loss: 0.2284, validation loss: 0.0305
2024-05-25 04:12:48 [INFO]: Epoch 051 - training loss: 0.2235, validation loss: 0.0294
2024-05-25 04:12:49 [INFO]: Epoch 052 - training loss: 0.2263, validation loss: 0.0298
2024-05-25 04:12:49 [INFO]: Epoch 053 - training loss: 0.2215, validation loss: 0.0290
2024-05-25 04:12:49 [INFO]: Epoch 054 - training loss: 0.2223, validation loss: 0.0320
2024-05-25 04:12:49 [INFO]: Epoch 055 - training loss: 0.2258, validation loss: 0.0302
2024-05-25 04:12:49 [INFO]: Epoch 056 - training loss: 0.2209, validation loss: 0.0289
2024-05-25 04:12:50 [INFO]: Epoch 057 - training loss: 0.2188, validation loss: 0.0311
2024-05-25 04:12:50 [INFO]: Epoch 058 - training loss: 0.2194, validation loss: 0.0278
2024-05-25 04:12:50 [INFO]: Epoch 059 - training loss: 0.2112, validation loss: 0.0270
2024-05-25 04:12:50 [INFO]: Epoch 060 - training loss: 0.2107, validation loss: 0.0287
2024-05-25 04:12:50 [INFO]: Epoch 061 - training loss: 0.2168, validation loss: 0.0331
2024-05-25 04:12:51 [INFO]: Epoch 062 - training loss: 0.2210, validation loss: 0.0276
2024-05-25 04:12:51 [INFO]: Epoch 063 - training loss: 0.2117, validation loss: 0.0281
2024-05-25 04:12:51 [INFO]: Epoch 064 - training loss: 0.2138, validation loss: 0.0308
2024-05-25 04:12:51 [INFO]: Epoch 065 - training loss: 0.2182, validation loss: 0.0294
2024-05-25 04:12:51 [INFO]: Epoch 066 - training loss: 0.2106, validation loss: 0.0266
2024-05-25 04:12:52 [INFO]: Epoch 067 - training loss: 0.2078, validation loss: 0.0300
2024-05-25 04:12:52 [INFO]: Epoch 068 - training loss: 0.2091, validation loss: 0.0263
2024-05-25 04:12:52 [INFO]: Epoch 069 - training loss: 0.2031, validation loss: 0.0256
2024-05-25 04:12:52 [INFO]: Epoch 070 - training loss: 0.2006, validation loss: 0.0285
2024-05-25 04:12:52 [INFO]: Epoch 071 - training loss: 0.2022, validation loss: 0.0259
2024-05-25 04:12:52 [INFO]: Epoch 072 - training loss: 0.2013, validation loss: 0.0272
2024-05-25 04:12:53 [INFO]: Epoch 073 - training loss: 0.2026, validation loss: 0.0245
2024-05-25 04:12:53 [INFO]: Epoch 074 - training loss: 0.1997, validation loss: 0.0254
2024-05-25 04:12:53 [INFO]: Epoch 075 - training loss: 0.2041, validation loss: 0.0261
2024-05-25 04:12:53 [INFO]: Epoch 076 - training loss: 0.2017, validation loss: 0.0287
2024-05-25 04:12:53 [INFO]: Epoch 077 - training loss: 0.2018, validation loss: 0.0260
2024-05-25 04:12:54 [INFO]: Epoch 078 - training loss: 0.1964, validation loss: 0.0277
2024-05-25 04:12:54 [INFO]: Epoch 079 - training loss: 0.2000, validation loss: 0.0267
2024-05-25 04:12:54 [INFO]: Epoch 080 - training loss: 0.2006, validation loss: 0.0250
2024-05-25 04:12:54 [INFO]: Epoch 081 - training loss: 0.1944, validation loss: 0.0255
2024-05-25 04:12:54 [INFO]: Epoch 082 - training loss: 0.1907, validation loss: 0.0249
2024-05-25 04:12:55 [INFO]: Epoch 083 - training loss: 0.1944, validation loss: 0.0253
2024-05-25 04:12:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:12:55 [INFO]: Finished training. The best model is from epoch#73.
2024-05-25 04:12:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/Transformer_ettm1/20240525_T041238/Transformer.pypots
2024-05-25 04:12:55 [INFO]: Transformer on ETTm1: MAE=0.1387, MSE=0.0386
2024-05-25 04:12:55 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Transformer_ettm1/imputation.pkl
2024-05-25 04:12:55 [INFO]: Using the given device: cuda:0
2024-05-25 04:12:55 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/TimesNet_ettm1/20240525_T041255
2024-05-25 04:12:55 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/TimesNet_ettm1/20240525_T041255/tensorboard
2024-05-25 04:12:55 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 04:12:55 [INFO]: Epoch 001 - training loss: 0.1878, validation loss: 0.0641
2024-05-25 04:12:55 [INFO]: Epoch 002 - training loss: 0.0682, validation loss: 0.0426
2024-05-25 04:12:55 [INFO]: Epoch 003 - training loss: 0.0521, validation loss: 0.0386
2024-05-25 04:12:56 [INFO]: Epoch 004 - training loss: 0.0458, validation loss: 0.0344
2024-05-25 04:12:56 [INFO]: Epoch 005 - training loss: 0.0423, validation loss: 0.0330
2024-05-25 04:12:56 [INFO]: Epoch 006 - training loss: 0.0411, validation loss: 0.0315
2024-05-25 04:12:56 [INFO]: Epoch 007 - training loss: 0.0397, validation loss: 0.0316
2024-05-25 04:12:56 [INFO]: Epoch 008 - training loss: 0.0393, validation loss: 0.0303
2024-05-25 04:12:57 [INFO]: Epoch 009 - training loss: 0.0397, validation loss: 0.0322
2024-05-25 04:12:57 [INFO]: Epoch 010 - training loss: 0.0421, validation loss: 0.0314
2024-05-25 04:12:57 [INFO]: Epoch 011 - training loss: 0.0379, validation loss: 0.0298
2024-05-25 04:12:57 [INFO]: Epoch 012 - training loss: 0.0380, validation loss: 0.0297
2024-05-25 04:12:57 [INFO]: Epoch 013 - training loss: 0.0363, validation loss: 0.0292
2024-05-25 04:12:58 [INFO]: Epoch 014 - training loss: 0.0357, validation loss: 0.0294
2024-05-25 04:12:58 [INFO]: Epoch 015 - training loss: 0.0360, validation loss: 0.0291
2024-05-25 04:12:58 [INFO]: Epoch 016 - training loss: 0.0357, validation loss: 0.0287
2024-05-25 04:12:58 [INFO]: Epoch 017 - training loss: 0.0351, validation loss: 0.0292
2024-05-25 04:12:58 [INFO]: Epoch 018 - training loss: 0.0358, validation loss: 0.0293
2024-05-25 04:12:58 [INFO]: Epoch 019 - training loss: 0.0361, validation loss: 0.0287
2024-05-25 04:12:59 [INFO]: Epoch 020 - training loss: 0.0342, validation loss: 0.0290
2024-05-25 04:12:59 [INFO]: Epoch 021 - training loss: 0.0333, validation loss: 0.0288
2024-05-25 04:12:59 [INFO]: Epoch 022 - training loss: 0.0326, validation loss: 0.0288
2024-05-25 04:12:59 [INFO]: Epoch 023 - training loss: 0.0316, validation loss: 0.0280
2024-05-25 04:12:59 [INFO]: Epoch 024 - training loss: 0.0318, validation loss: 0.0282
2024-05-25 04:13:00 [INFO]: Epoch 025 - training loss: 0.0326, validation loss: 0.0294
2024-05-25 04:13:00 [INFO]: Epoch 026 - training loss: 0.0312, validation loss: 0.0282
2024-05-25 04:13:00 [INFO]: Epoch 027 - training loss: 0.0322, validation loss: 0.0290
2024-05-25 04:13:00 [INFO]: Epoch 028 - training loss: 0.0311, validation loss: 0.0280
2024-05-25 04:13:00 [INFO]: Epoch 029 - training loss: 0.0292, validation loss: 0.0279
2024-05-25 04:13:01 [INFO]: Epoch 030 - training loss: 0.0294, validation loss: 0.0277
2024-05-25 04:13:01 [INFO]: Epoch 031 - training loss: 0.0276, validation loss: 0.0279
2024-05-25 04:13:01 [INFO]: Epoch 032 - training loss: 0.0283, validation loss: 0.0279
2024-05-25 04:13:01 [INFO]: Epoch 033 - training loss: 0.0298, validation loss: 0.0289
2024-05-25 04:13:01 [INFO]: Epoch 034 - training loss: 0.0300, validation loss: 0.0281
2024-05-25 04:13:01 [INFO]: Epoch 035 - training loss: 0.0287, validation loss: 0.0282
2024-05-25 04:13:02 [INFO]: Epoch 036 - training loss: 0.0284, validation loss: 0.0296
2024-05-25 04:13:02 [INFO]: Epoch 037 - training loss: 0.0281, validation loss: 0.0272
2024-05-25 04:13:02 [INFO]: Epoch 038 - training loss: 0.0280, validation loss: 0.0271
2024-05-25 04:13:02 [INFO]: Epoch 039 - training loss: 0.0270, validation loss: 0.0284
2024-05-25 04:13:02 [INFO]: Epoch 040 - training loss: 0.0271, validation loss: 0.0272
2024-05-25 04:13:03 [INFO]: Epoch 041 - training loss: 0.0269, validation loss: 0.0278
2024-05-25 04:13:03 [INFO]: Epoch 042 - training loss: 0.0260, validation loss: 0.0270
2024-05-25 04:13:03 [INFO]: Epoch 043 - training loss: 0.0244, validation loss: 0.0270
2024-05-25 04:13:03 [INFO]: Epoch 044 - training loss: 0.0229, validation loss: 0.0278
2024-05-25 04:13:03 [INFO]: Epoch 045 - training loss: 0.0235, validation loss: 0.0272
2024-05-25 04:13:04 [INFO]: Epoch 046 - training loss: 0.0244, validation loss: 0.0271
2024-05-25 04:13:04 [INFO]: Epoch 047 - training loss: 0.0236, validation loss: 0.0270
2024-05-25 04:13:04 [INFO]: Epoch 048 - training loss: 0.0239, validation loss: 0.0278
2024-05-25 04:13:04 [INFO]: Epoch 049 - training loss: 0.0253, validation loss: 0.0281
2024-05-25 04:13:04 [INFO]: Epoch 050 - training loss: 0.0247, validation loss: 0.0279
2024-05-25 04:13:04 [INFO]: Epoch 051 - training loss: 0.0231, validation loss: 0.0285
2024-05-25 04:13:05 [INFO]: Epoch 052 - training loss: 0.0222, validation loss: 0.0269
2024-05-25 04:13:05 [INFO]: Epoch 053 - training loss: 0.0223, validation loss: 0.0281
2024-05-25 04:13:05 [INFO]: Epoch 054 - training loss: 0.0224, validation loss: 0.0279
2024-05-25 04:13:05 [INFO]: Epoch 055 - training loss: 0.0217, validation loss: 0.0288
2024-05-25 04:13:05 [INFO]: Epoch 056 - training loss: 0.0218, validation loss: 0.0297
2024-05-25 04:13:06 [INFO]: Epoch 057 - training loss: 0.0225, validation loss: 0.0301
2024-05-25 04:13:06 [INFO]: Epoch 058 - training loss: 0.0231, validation loss: 0.0276
2024-05-25 04:13:06 [INFO]: Epoch 059 - training loss: 0.0218, validation loss: 0.0297
2024-05-25 04:13:06 [INFO]: Epoch 060 - training loss: 0.0251, validation loss: 0.0379
2024-05-25 04:13:06 [INFO]: Epoch 061 - training loss: 0.0313, validation loss: 0.0281
2024-05-25 04:13:06 [INFO]: Epoch 062 - training loss: 0.0229, validation loss: 0.0283
2024-05-25 04:13:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:13:06 [INFO]: Finished training. The best model is from epoch#52.
2024-05-25 04:13:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/TimesNet_ettm1/20240525_T041255/TimesNet.pypots
2024-05-25 04:13:07 [INFO]: TimesNet on ETTm1: MAE=0.1157, MSE=0.0291
2024-05-25 04:13:07 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/TimesNet_ettm1/imputation.pkl
2024-05-25 04:13:07 [INFO]: Using the given device: cuda:0
2024-05-25 04:13:07 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307
2024-05-25 04:13:07 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/tensorboard
2024-05-25 04:13:07 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 04:13:09 [INFO]: Epoch 001 - training loss: 0.6665, validation loss: 0.4149
2024-05-25 04:13:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch1_loss0.4149344637989998.pypots
2024-05-25 04:13:11 [INFO]: Epoch 002 - training loss: 0.4139, validation loss: 0.3555
2024-05-25 04:13:11 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch2_loss0.3555067852139473.pypots
2024-05-25 04:13:13 [INFO]: Epoch 003 - training loss: 0.3429, validation loss: 0.3105
2024-05-25 04:13:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch3_loss0.3105229586362839.pypots
2024-05-25 04:13:15 [INFO]: Epoch 004 - training loss: 0.2729, validation loss: 0.2913
2024-05-25 04:13:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch4_loss0.2912692502140999.pypots
2024-05-25 04:13:17 [INFO]: Epoch 005 - training loss: 0.3327, validation loss: 0.2832
2024-05-25 04:13:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch5_loss0.2831775173544884.pypots
2024-05-25 04:13:19 [INFO]: Epoch 006 - training loss: 0.2569, validation loss: 0.2676
2024-05-25 04:13:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch6_loss0.26763027906417847.pypots
2024-05-25 04:13:21 [INFO]: Epoch 007 - training loss: 0.2616, validation loss: 0.2514
2024-05-25 04:13:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch7_loss0.25137921795248985.pypots
2024-05-25 04:13:23 [INFO]: Epoch 008 - training loss: 0.2532, validation loss: 0.2483
2024-05-25 04:13:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch8_loss0.24831746891140938.pypots
2024-05-25 04:13:25 [INFO]: Epoch 009 - training loss: 0.2408, validation loss: 0.2251
2024-05-25 04:13:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch9_loss0.22514966875314713.pypots
2024-05-25 04:13:27 [INFO]: Epoch 010 - training loss: 0.2406, validation loss: 0.2158
2024-05-25 04:13:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch10_loss0.2158111333847046.pypots
2024-05-25 04:13:29 [INFO]: Epoch 011 - training loss: 0.2084, validation loss: 0.2123
2024-05-25 04:13:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch11_loss0.21231018751859665.pypots
2024-05-25 04:13:31 [INFO]: Epoch 012 - training loss: 0.1980, validation loss: 0.2017
2024-05-25 04:13:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch12_loss0.2017388753592968.pypots
2024-05-25 04:13:33 [INFO]: Epoch 013 - training loss: 0.1993, validation loss: 0.2086
2024-05-25 04:13:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch13_loss0.20864490419626236.pypots
2024-05-25 04:13:35 [INFO]: Epoch 014 - training loss: 0.2178, validation loss: 0.1906
2024-05-25 04:13:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch14_loss0.1905970722436905.pypots
2024-05-25 04:13:37 [INFO]: Epoch 015 - training loss: 0.2073, validation loss: 0.1921
2024-05-25 04:13:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch15_loss0.1921103037893772.pypots
2024-05-25 04:13:39 [INFO]: Epoch 016 - training loss: 0.1996, validation loss: 0.1853
2024-05-25 04:13:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch16_loss0.1853376254439354.pypots
2024-05-25 04:13:41 [INFO]: Epoch 017 - training loss: 0.1888, validation loss: 0.1835
2024-05-25 04:13:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch17_loss0.1834593005478382.pypots
2024-05-25 04:13:43 [INFO]: Epoch 018 - training loss: 0.2029, validation loss: 0.1845
2024-05-25 04:13:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch18_loss0.18446661159396172.pypots
2024-05-25 04:13:45 [INFO]: Epoch 019 - training loss: 0.2120, validation loss: 0.1803
2024-05-25 04:13:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch19_loss0.18030067905783653.pypots
2024-05-25 04:13:47 [INFO]: Epoch 020 - training loss: 0.2047, validation loss: 0.1705
2024-05-25 04:13:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch20_loss0.17050980031490326.pypots
2024-05-25 04:13:49 [INFO]: Epoch 021 - training loss: 0.2023, validation loss: 0.1686
2024-05-25 04:13:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch21_loss0.168613001704216.pypots
2024-05-25 04:13:51 [INFO]: Epoch 022 - training loss: 0.1758, validation loss: 0.1715
2024-05-25 04:13:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch22_loss0.17149150371551514.pypots
2024-05-25 04:13:53 [INFO]: Epoch 023 - training loss: 0.1998, validation loss: 0.1739
2024-05-25 04:13:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch23_loss0.1739002987742424.pypots
2024-05-25 04:13:56 [INFO]: Epoch 024 - training loss: 0.2290, validation loss: 0.1635
2024-05-25 04:13:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch24_loss0.1635267175734043.pypots
2024-05-25 04:13:58 [INFO]: Epoch 025 - training loss: 0.1796, validation loss: 0.1657
2024-05-25 04:13:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch25_loss0.16567397490143776.pypots
2024-05-25 04:14:00 [INFO]: Epoch 026 - training loss: 0.1674, validation loss: 0.1585
2024-05-25 04:14:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch26_loss0.15847669169306755.pypots
2024-05-25 04:14:02 [INFO]: Epoch 027 - training loss: 0.1590, validation loss: 0.1539
2024-05-25 04:14:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch27_loss0.15393191203474998.pypots
2024-05-25 04:14:04 [INFO]: Epoch 028 - training loss: 0.1531, validation loss: 0.1567
2024-05-25 04:14:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch28_loss0.15671808645129204.pypots
2024-05-25 04:14:06 [INFO]: Epoch 029 - training loss: 0.1495, validation loss: 0.1496
2024-05-25 04:14:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch29_loss0.14959998056292534.pypots
2024-05-25 04:14:08 [INFO]: Epoch 030 - training loss: 0.1798, validation loss: 0.1492
2024-05-25 04:14:08 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch30_loss0.14920850098133087.pypots
2024-05-25 04:14:10 [INFO]: Epoch 031 - training loss: 0.1547, validation loss: 0.1452
2024-05-25 04:14:10 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch31_loss0.14518937468528748.pypots
2024-05-25 04:14:12 [INFO]: Epoch 032 - training loss: 0.1546, validation loss: 0.1433
2024-05-25 04:14:12 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch32_loss0.14333295449614525.pypots
2024-05-25 04:14:14 [INFO]: Epoch 033 - training loss: 0.1662, validation loss: 0.1526
2024-05-25 04:14:14 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch33_loss0.15258567407727242.pypots
2024-05-25 04:14:16 [INFO]: Epoch 034 - training loss: 0.1402, validation loss: 0.1431
2024-05-25 04:14:16 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch34_loss0.14312843978405.pypots
2024-05-25 04:14:18 [INFO]: Epoch 035 - training loss: 0.1864, validation loss: 0.1439
2024-05-25 04:14:18 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch35_loss0.14394406229257584.pypots
2024-05-25 04:14:20 [INFO]: Epoch 036 - training loss: 0.1852, validation loss: 0.1553
2024-05-25 04:14:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch36_loss0.15528615191578865.pypots
2024-05-25 04:14:22 [INFO]: Epoch 037 - training loss: 0.1583, validation loss: 0.1500
2024-05-25 04:14:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch37_loss0.15000062435865402.pypots
2024-05-25 04:14:24 [INFO]: Epoch 038 - training loss: 0.1436, validation loss: 0.1456
2024-05-25 04:14:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch38_loss0.14564650505781174.pypots
2024-05-25 04:14:26 [INFO]: Epoch 039 - training loss: 0.1389, validation loss: 0.1423
2024-05-25 04:14:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch39_loss0.14233848452568054.pypots
2024-05-25 04:14:28 [INFO]: Epoch 040 - training loss: 0.1432, validation loss: 0.1381
2024-05-25 04:14:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch40_loss0.1381421498954296.pypots
2024-05-25 04:14:30 [INFO]: Epoch 041 - training loss: 0.1355, validation loss: 0.1352
2024-05-25 04:14:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch41_loss0.13521890714764595.pypots
2024-05-25 04:14:32 [INFO]: Epoch 042 - training loss: 0.1644, validation loss: 0.1369
2024-05-25 04:14:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch42_loss0.1368837095797062.pypots
2024-05-25 04:14:34 [INFO]: Epoch 043 - training loss: 0.1176, validation loss: 0.1399
2024-05-25 04:14:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch43_loss0.1399010568857193.pypots
2024-05-25 04:14:36 [INFO]: Epoch 044 - training loss: 0.1283, validation loss: 0.1358
2024-05-25 04:14:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch44_loss0.13578839972615242.pypots
2024-05-25 04:14:38 [INFO]: Epoch 045 - training loss: 0.1477, validation loss: 0.1377
2024-05-25 04:14:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch45_loss0.13771283254027367.pypots
2024-05-25 04:14:40 [INFO]: Epoch 046 - training loss: 0.1367, validation loss: 0.1391
2024-05-25 04:14:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch46_loss0.13909904286265373.pypots
2024-05-25 04:14:42 [INFO]: Epoch 047 - training loss: 0.1319, validation loss: 0.1386
2024-05-25 04:14:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch47_loss0.13860458508133888.pypots
2024-05-25 04:14:44 [INFO]: Epoch 048 - training loss: 0.1271, validation loss: 0.1335
2024-05-25 04:14:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch48_loss0.13346173614263535.pypots
2024-05-25 04:14:46 [INFO]: Epoch 049 - training loss: 0.1432, validation loss: 0.1298
2024-05-25 04:14:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch49_loss0.12981821037828922.pypots
2024-05-25 04:14:49 [INFO]: Epoch 050 - training loss: 0.1258, validation loss: 0.1307
2024-05-25 04:14:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch50_loss0.13069238886237144.pypots
2024-05-25 04:14:51 [INFO]: Epoch 051 - training loss: 0.1385, validation loss: 0.1291
2024-05-25 04:14:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch51_loss0.12913542613387108.pypots
2024-05-25 04:14:53 [INFO]: Epoch 052 - training loss: 0.1148, validation loss: 0.1293
2024-05-25 04:14:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch52_loss0.1293111052364111.pypots
2024-05-25 04:14:55 [INFO]: Epoch 053 - training loss: 0.1305, validation loss: 0.1272
2024-05-25 04:14:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch53_loss0.1272302120923996.pypots
2024-05-25 04:14:57 [INFO]: Epoch 054 - training loss: 0.1288, validation loss: 0.1294
2024-05-25 04:14:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch54_loss0.12938024662435055.pypots
2024-05-25 04:14:59 [INFO]: Epoch 055 - training loss: 0.1383, validation loss: 0.1300
2024-05-25 04:14:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch55_loss0.13000072166323662.pypots
2024-05-25 04:15:01 [INFO]: Epoch 056 - training loss: 0.1370, validation loss: 0.1318
2024-05-25 04:15:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch56_loss0.13178505934774876.pypots
2024-05-25 04:15:03 [INFO]: Epoch 057 - training loss: 0.1263, validation loss: 0.1276
2024-05-25 04:15:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch57_loss0.12762716598808765.pypots
2024-05-25 04:15:05 [INFO]: Epoch 058 - training loss: 0.1442, validation loss: 0.1273
2024-05-25 04:15:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch58_loss0.12728477455675602.pypots
2024-05-25 04:15:07 [INFO]: Epoch 059 - training loss: 0.1313, validation loss: 0.1290
2024-05-25 04:15:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch59_loss0.12900954484939575.pypots
2024-05-25 04:15:09 [INFO]: Epoch 060 - training loss: 0.1453, validation loss: 0.1278
2024-05-25 04:15:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch60_loss0.12784728221595287.pypots
2024-05-25 04:15:11 [INFO]: Epoch 061 - training loss: 0.1252, validation loss: 0.1383
2024-05-25 04:15:11 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch61_loss0.138336393982172.pypots
2024-05-25 04:15:13 [INFO]: Epoch 062 - training loss: 0.1622, validation loss: 0.1374
2024-05-25 04:15:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch62_loss0.1373666562139988.pypots
2024-05-25 04:15:15 [INFO]: Epoch 063 - training loss: 0.1647, validation loss: 0.1416
2024-05-25 04:15:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI_epoch63_loss0.14159955829381943.pypots
2024-05-25 04:15:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:15:15 [INFO]: Finished training. The best model is from epoch#53.
2024-05-25 04:15:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T041307/CSDI.pypots
2024-05-25 04:15:31 [INFO]: CSDI on ETTm1: MAE=0.1254, MSE=0.0359
2024-05-25 04:15:31 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/CSDI_ettm1/imputation.pkl
2024-05-25 04:15:31 [INFO]: Using the given device: cuda:0
2024-05-25 04:15:31 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/GPVAE_ettm1/20240525_T041531
2024-05-25 04:15:31 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/GPVAE_ettm1/20240525_T041531/tensorboard
2024-05-25 04:15:31 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 04:15:31 [INFO]: Epoch 001 - training loss: 23390.3541, validation loss: 0.9376
2024-05-25 04:15:31 [INFO]: Epoch 002 - training loss: 21353.2931, validation loss: 0.9323
2024-05-25 04:15:31 [INFO]: Epoch 003 - training loss: 19310.6663, validation loss: 0.9283
2024-05-25 04:15:31 [INFO]: Epoch 004 - training loss: 17160.2752, validation loss: 0.9137
2024-05-25 04:15:32 [INFO]: Epoch 005 - training loss: 15297.7234, validation loss: 0.8711
2024-05-25 04:15:32 [INFO]: Epoch 006 - training loss: 13779.4312, validation loss: 0.7933
2024-05-25 04:15:32 [INFO]: Epoch 007 - training loss: 12666.7355, validation loss: 0.6835
2024-05-25 04:15:32 [INFO]: Epoch 008 - training loss: 11950.4768, validation loss: 0.5830
2024-05-25 04:15:32 [INFO]: Epoch 009 - training loss: 11210.5732, validation loss: 0.5080
2024-05-25 04:15:32 [INFO]: Epoch 010 - training loss: 10903.2591, validation loss: 0.4922
2024-05-25 04:15:32 [INFO]: Epoch 011 - training loss: 10565.2740, validation loss: 0.4781
2024-05-25 04:15:33 [INFO]: Epoch 012 - training loss: 10389.2133, validation loss: 0.4617
2024-05-25 04:15:33 [INFO]: Epoch 013 - training loss: 10195.9878, validation loss: 0.4576
2024-05-25 04:15:33 [INFO]: Epoch 014 - training loss: 10064.1165, validation loss: 0.4528
2024-05-25 04:15:33 [INFO]: Epoch 015 - training loss: 9982.2670, validation loss: 0.4416
2024-05-25 04:15:33 [INFO]: Epoch 016 - training loss: 9859.4633, validation loss: 0.4310
2024-05-25 04:15:33 [INFO]: Epoch 017 - training loss: 9807.7068, validation loss: 0.4137
2024-05-25 04:15:33 [INFO]: Epoch 018 - training loss: 9750.5562, validation loss: 0.4016
2024-05-25 04:15:33 [INFO]: Epoch 019 - training loss: 9674.9863, validation loss: 0.3964
2024-05-25 04:15:34 [INFO]: Epoch 020 - training loss: 9648.8698, validation loss: 0.3823
2024-05-25 04:15:34 [INFO]: Epoch 021 - training loss: 9610.7686, validation loss: 0.3641
2024-05-25 04:15:34 [INFO]: Epoch 022 - training loss: 9599.0293, validation loss: 0.3600
2024-05-25 04:15:34 [INFO]: Epoch 023 - training loss: 9560.8408, validation loss: 0.3461
2024-05-25 04:15:34 [INFO]: Epoch 024 - training loss: 9519.6270, validation loss: 0.3379
2024-05-25 04:15:34 [INFO]: Epoch 025 - training loss: 9490.6591, validation loss: 0.3315
2024-05-25 04:15:34 [INFO]: Epoch 026 - training loss: 9494.0159, validation loss: 0.3239
2024-05-25 04:15:34 [INFO]: Epoch 027 - training loss: 9463.6589, validation loss: 0.3190
2024-05-25 04:15:35 [INFO]: Epoch 028 - training loss: 9434.2972, validation loss: 0.3083
2024-05-25 04:15:35 [INFO]: Epoch 029 - training loss: 9434.8867, validation loss: 0.3082
2024-05-25 04:15:35 [INFO]: Epoch 030 - training loss: 9405.7981, validation loss: 0.3043
2024-05-25 04:15:35 [INFO]: Epoch 031 - training loss: 9395.3320, validation loss: 0.3000
2024-05-25 04:15:35 [INFO]: Epoch 032 - training loss: 9386.5347, validation loss: 0.2912
2024-05-25 04:15:35 [INFO]: Epoch 033 - training loss: 9409.1140, validation loss: 0.2823
2024-05-25 04:15:35 [INFO]: Epoch 034 - training loss: 9368.9753, validation loss: 0.2803
2024-05-25 04:15:35 [INFO]: Epoch 035 - training loss: 9363.2725, validation loss: 0.2691
2024-05-25 04:15:36 [INFO]: Epoch 036 - training loss: 9353.5448, validation loss: 0.2694
2024-05-25 04:15:36 [INFO]: Epoch 037 - training loss: 9353.6218, validation loss: 0.2649
2024-05-25 04:15:36 [INFO]: Epoch 038 - training loss: 9340.7343, validation loss: 0.2642
2024-05-25 04:15:36 [INFO]: Epoch 039 - training loss: 9338.3514, validation loss: 0.2571
2024-05-25 04:15:36 [INFO]: Epoch 040 - training loss: 9328.9068, validation loss: 0.2523
2024-05-25 04:15:36 [INFO]: Epoch 041 - training loss: 9348.3857, validation loss: 0.2482
2024-05-25 04:15:36 [INFO]: Epoch 042 - training loss: 9331.3486, validation loss: 0.2435
2024-05-25 04:15:37 [INFO]: Epoch 043 - training loss: 9315.2769, validation loss: 0.2366
2024-05-25 04:15:37 [INFO]: Epoch 044 - training loss: 9313.3666, validation loss: 0.2350
2024-05-25 04:15:37 [INFO]: Epoch 045 - training loss: 9306.1168, validation loss: 0.2323
2024-05-25 04:15:37 [INFO]: Epoch 046 - training loss: 9302.5327, validation loss: 0.2249
2024-05-25 04:15:37 [INFO]: Epoch 047 - training loss: 9303.0347, validation loss: 0.2230
2024-05-25 04:15:37 [INFO]: Epoch 048 - training loss: 9294.6450, validation loss: 0.2199
2024-05-25 04:15:37 [INFO]: Epoch 049 - training loss: 9289.9565, validation loss: 0.2159
2024-05-25 04:15:37 [INFO]: Epoch 050 - training loss: 9290.4139, validation loss: 0.2099
2024-05-25 04:15:38 [INFO]: Epoch 051 - training loss: 9289.2979, validation loss: 0.2074
2024-05-25 04:15:38 [INFO]: Epoch 052 - training loss: 9284.1498, validation loss: 0.2078
2024-05-25 04:15:38 [INFO]: Epoch 053 - training loss: 9288.7823, validation loss: 0.2012
2024-05-25 04:15:38 [INFO]: Epoch 054 - training loss: 9283.1829, validation loss: 0.1949
2024-05-25 04:15:38 [INFO]: Epoch 055 - training loss: 9276.3199, validation loss: 0.1961
2024-05-25 04:15:38 [INFO]: Epoch 056 - training loss: 9276.9463, validation loss: 0.1917
2024-05-25 04:15:38 [INFO]: Epoch 057 - training loss: 9276.3242, validation loss: 0.1876
2024-05-25 04:15:38 [INFO]: Epoch 058 - training loss: 9276.5393, validation loss: 0.1843
2024-05-25 04:15:39 [INFO]: Epoch 059 - training loss: 9269.9850, validation loss: 0.1789
2024-05-25 04:15:39 [INFO]: Epoch 060 - training loss: 9268.6161, validation loss: 0.1749
2024-05-25 04:15:39 [INFO]: Epoch 061 - training loss: 9268.1765, validation loss: 0.1759
2024-05-25 04:15:39 [INFO]: Epoch 062 - training loss: 9266.2173, validation loss: 0.1684
2024-05-25 04:15:39 [INFO]: Epoch 063 - training loss: 9268.5320, validation loss: 0.1656
2024-05-25 04:15:39 [INFO]: Epoch 064 - training loss: 9258.9346, validation loss: 0.1668
2024-05-25 04:15:39 [INFO]: Epoch 065 - training loss: 9256.5056, validation loss: 0.1617
2024-05-25 04:15:40 [INFO]: Epoch 066 - training loss: 9261.3283, validation loss: 0.1605
2024-05-25 04:15:40 [INFO]: Epoch 067 - training loss: 9255.7466, validation loss: 0.1608
2024-05-25 04:15:40 [INFO]: Epoch 068 - training loss: 9257.3981, validation loss: 0.1523
2024-05-25 04:15:40 [INFO]: Epoch 069 - training loss: 9253.3450, validation loss: 0.1531
2024-05-25 04:15:40 [INFO]: Epoch 070 - training loss: 9253.1021, validation loss: 0.1475
2024-05-25 04:15:40 [INFO]: Epoch 071 - training loss: 9249.9515, validation loss: 0.1451
2024-05-25 04:15:40 [INFO]: Epoch 072 - training loss: 9251.7674, validation loss: 0.1449
2024-05-25 04:15:40 [INFO]: Epoch 073 - training loss: 9248.1795, validation loss: 0.1423
2024-05-25 04:15:41 [INFO]: Epoch 074 - training loss: 9253.4542, validation loss: 0.1414
2024-05-25 04:15:41 [INFO]: Epoch 075 - training loss: 9248.2292, validation loss: 0.1410
2024-05-25 04:15:41 [INFO]: Epoch 076 - training loss: 9246.8707, validation loss: 0.1370
2024-05-25 04:15:41 [INFO]: Epoch 077 - training loss: 9246.3174, validation loss: 0.1372
2024-05-25 04:15:41 [INFO]: Epoch 078 - training loss: 9244.2136, validation loss: 0.1368
2024-05-25 04:15:41 [INFO]: Epoch 079 - training loss: 9245.3718, validation loss: 0.1338
2024-05-25 04:15:41 [INFO]: Epoch 080 - training loss: 9241.2825, validation loss: 0.1325
2024-05-25 04:15:42 [INFO]: Epoch 081 - training loss: 9240.0743, validation loss: 0.1321
2024-05-25 04:15:42 [INFO]: Epoch 082 - training loss: 9243.0663, validation loss: 0.1311
2024-05-25 04:15:42 [INFO]: Epoch 083 - training loss: 9246.1663, validation loss: 0.1296
2024-05-25 04:15:42 [INFO]: Epoch 084 - training loss: 9238.7357, validation loss: 0.1326
2024-05-25 04:15:42 [INFO]: Epoch 085 - training loss: 9237.5730, validation loss: 0.1278
2024-05-25 04:15:42 [INFO]: Epoch 086 - training loss: 9237.7988, validation loss: 0.1279
2024-05-25 04:15:42 [INFO]: Epoch 087 - training loss: 9240.1277, validation loss: 0.1262
2024-05-25 04:15:42 [INFO]: Epoch 088 - training loss: 9242.2887, validation loss: 0.1262
2024-05-25 04:15:43 [INFO]: Epoch 089 - training loss: 9234.9258, validation loss: 0.1244
2024-05-25 04:15:43 [INFO]: Epoch 090 - training loss: 9237.4473, validation loss: 0.1257
2024-05-25 04:15:43 [INFO]: Epoch 091 - training loss: 9234.1438, validation loss: 0.1264
2024-05-25 04:15:43 [INFO]: Epoch 092 - training loss: 9233.6909, validation loss: 0.1227
2024-05-25 04:15:43 [INFO]: Epoch 093 - training loss: 9234.4081, validation loss: 0.1241
2024-05-25 04:15:43 [INFO]: Epoch 094 - training loss: 9237.7234, validation loss: 0.1224
2024-05-25 04:15:43 [INFO]: Epoch 095 - training loss: 9231.6666, validation loss: 0.1226
2024-05-25 04:15:44 [INFO]: Epoch 096 - training loss: 9233.2614, validation loss: 0.1217
2024-05-25 04:15:44 [INFO]: Epoch 097 - training loss: 9230.6458, validation loss: 0.1205
2024-05-25 04:15:44 [INFO]: Epoch 098 - training loss: 9232.7566, validation loss: 0.1211
2024-05-25 04:15:44 [INFO]: Epoch 099 - training loss: 9231.9560, validation loss: 0.1180
2024-05-25 04:15:44 [INFO]: Epoch 100 - training loss: 9232.3452, validation loss: 0.1175
2024-05-25 04:15:44 [INFO]: Epoch 101 - training loss: 9231.1151, validation loss: 0.1194
2024-05-25 04:15:44 [INFO]: Epoch 102 - training loss: 9232.9446, validation loss: 0.1187
2024-05-25 04:15:44 [INFO]: Epoch 103 - training loss: 9229.9611, validation loss: 0.1170
2024-05-25 04:15:45 [INFO]: Epoch 104 - training loss: 9229.0955, validation loss: 0.1190
2024-05-25 04:15:45 [INFO]: Epoch 105 - training loss: 9224.6536, validation loss: 0.1162
2024-05-25 04:15:45 [INFO]: Epoch 106 - training loss: 9228.9423, validation loss: 0.1154
2024-05-25 04:15:45 [INFO]: Epoch 107 - training loss: 9226.4515, validation loss: 0.1197
2024-05-25 04:15:45 [INFO]: Epoch 108 - training loss: 9226.5029, validation loss: 0.1156
2024-05-25 04:15:45 [INFO]: Epoch 109 - training loss: 9227.0297, validation loss: 0.1167
2024-05-25 04:15:45 [INFO]: Epoch 110 - training loss: 9224.6599, validation loss: 0.1142
2024-05-25 04:15:45 [INFO]: Epoch 111 - training loss: 9226.3627, validation loss: 0.1153
2024-05-25 04:15:46 [INFO]: Epoch 112 - training loss: 9227.6419, validation loss: 0.1138
2024-05-25 04:15:46 [INFO]: Epoch 113 - training loss: 9224.6911, validation loss: 0.1140
2024-05-25 04:15:46 [INFO]: Epoch 114 - training loss: 9227.9987, validation loss: 0.1132
2024-05-25 04:15:46 [INFO]: Epoch 115 - training loss: 9224.4600, validation loss: 0.1120
2024-05-25 04:15:46 [INFO]: Epoch 116 - training loss: 9224.8399, validation loss: 0.1128
2024-05-25 04:15:46 [INFO]: Epoch 117 - training loss: 9224.3533, validation loss: 0.1113
2024-05-25 04:15:46 [INFO]: Epoch 118 - training loss: 9223.0079, validation loss: 0.1100
2024-05-25 04:15:46 [INFO]: Epoch 119 - training loss: 9223.7523, validation loss: 0.1116
2024-05-25 04:15:47 [INFO]: Epoch 120 - training loss: 9223.7151, validation loss: 0.1090
2024-05-25 04:15:47 [INFO]: Epoch 121 - training loss: 9221.8632, validation loss: 0.1086
2024-05-25 04:15:47 [INFO]: Epoch 122 - training loss: 9223.3342, validation loss: 0.1090
2024-05-25 04:15:47 [INFO]: Epoch 123 - training loss: 9221.9307, validation loss: 0.1082
2024-05-25 04:15:47 [INFO]: Epoch 124 - training loss: 9221.0507, validation loss: 0.1095
2024-05-25 04:15:47 [INFO]: Epoch 125 - training loss: 9221.6490, validation loss: 0.1084
2024-05-25 04:15:47 [INFO]: Epoch 126 - training loss: 9220.5410, validation loss: 0.1078
2024-05-25 04:15:48 [INFO]: Epoch 127 - training loss: 9221.3442, validation loss: 0.1075
2024-05-25 04:15:48 [INFO]: Epoch 128 - training loss: 9221.1667, validation loss: 0.1057
2024-05-25 04:15:48 [INFO]: Epoch 129 - training loss: 9222.7979, validation loss: 0.1065
2024-05-25 04:15:48 [INFO]: Epoch 130 - training loss: 9219.9857, validation loss: 0.1051
2024-05-25 04:15:48 [INFO]: Epoch 131 - training loss: 9219.6219, validation loss: 0.1057
2024-05-25 04:15:48 [INFO]: Epoch 132 - training loss: 9221.0239, validation loss: 0.1055
2024-05-25 04:15:48 [INFO]: Epoch 133 - training loss: 9220.3974, validation loss: 0.1054
2024-05-25 04:15:48 [INFO]: Epoch 134 - training loss: 9218.1791, validation loss: 0.1047
2024-05-25 04:15:49 [INFO]: Epoch 135 - training loss: 9220.0157, validation loss: 0.1058
2024-05-25 04:15:49 [INFO]: Epoch 136 - training loss: 9219.8927, validation loss: 0.1025
2024-05-25 04:15:49 [INFO]: Epoch 137 - training loss: 9220.2609, validation loss: 0.1044
2024-05-25 04:15:49 [INFO]: Epoch 138 - training loss: 9218.5274, validation loss: 0.1028
2024-05-25 04:15:49 [INFO]: Epoch 139 - training loss: 9218.4170, validation loss: 0.1039
2024-05-25 04:15:49 [INFO]: Epoch 140 - training loss: 9217.5295, validation loss: 0.1018
2024-05-25 04:15:49 [INFO]: Epoch 141 - training loss: 9217.9504, validation loss: 0.1024
2024-05-25 04:15:49 [INFO]: Epoch 142 - training loss: 9217.4028, validation loss: 0.1015
2024-05-25 04:15:50 [INFO]: Epoch 143 - training loss: 9218.8438, validation loss: 0.1024
2024-05-25 04:15:50 [INFO]: Epoch 144 - training loss: 9217.6373, validation loss: 0.1019
2024-05-25 04:15:50 [INFO]: Epoch 145 - training loss: 9216.8986, validation loss: 0.0995
2024-05-25 04:15:50 [INFO]: Epoch 146 - training loss: 9217.9306, validation loss: 0.1008
2024-05-25 04:15:50 [INFO]: Epoch 147 - training loss: 9216.4688, validation loss: 0.0997
2024-05-25 04:15:50 [INFO]: Epoch 148 - training loss: 9216.1047, validation loss: 0.1009
2024-05-25 04:15:50 [INFO]: Epoch 149 - training loss: 9215.9753, validation loss: 0.0991
2024-05-25 04:15:51 [INFO]: Epoch 150 - training loss: 9216.1202, validation loss: 0.0984
2024-05-25 04:15:51 [INFO]: Epoch 151 - training loss: 9216.4803, validation loss: 0.0993
2024-05-25 04:15:51 [INFO]: Epoch 152 - training loss: 9215.9706, validation loss: 0.0986
2024-05-25 04:15:51 [INFO]: Epoch 153 - training loss: 9218.1481, validation loss: 0.0965
2024-05-25 04:15:51 [INFO]: Epoch 154 - training loss: 9215.7836, validation loss: 0.1034
2024-05-25 04:15:51 [INFO]: Epoch 155 - training loss: 9214.7267, validation loss: 0.0982
2024-05-25 04:15:51 [INFO]: Epoch 156 - training loss: 9214.8794, validation loss: 0.0963
2024-05-25 04:15:51 [INFO]: Epoch 157 - training loss: 9215.2728, validation loss: 0.0977
2024-05-25 04:15:52 [INFO]: Epoch 158 - training loss: 9216.3457, validation loss: 0.0962
2024-05-25 04:15:52 [INFO]: Epoch 159 - training loss: 9214.9842, validation loss: 0.1023
2024-05-25 04:15:52 [INFO]: Epoch 160 - training loss: 9214.4120, validation loss: 0.0951
2024-05-25 04:15:52 [INFO]: Epoch 161 - training loss: 9213.7128, validation loss: 0.0956
2024-05-25 04:15:52 [INFO]: Epoch 162 - training loss: 9214.2491, validation loss: 0.0964
2024-05-25 04:15:52 [INFO]: Epoch 163 - training loss: 9214.3450, validation loss: 0.0959
2024-05-25 04:15:52 [INFO]: Epoch 164 - training loss: 9214.9844, validation loss: 0.0969
2024-05-25 04:15:53 [INFO]: Epoch 165 - training loss: 9213.6703, validation loss: 0.0942
2024-05-25 04:15:53 [INFO]: Epoch 166 - training loss: 9214.3833, validation loss: 0.0962
2024-05-25 04:15:53 [INFO]: Epoch 167 - training loss: 9213.9167, validation loss: 0.0954
2024-05-25 04:15:53 [INFO]: Epoch 168 - training loss: 9213.9169, validation loss: 0.0939
2024-05-25 04:15:53 [INFO]: Epoch 169 - training loss: 9212.2178, validation loss: 0.0952
2024-05-25 04:15:53 [INFO]: Epoch 170 - training loss: 9213.6984, validation loss: 0.0930
2024-05-25 04:15:53 [INFO]: Epoch 171 - training loss: 9214.5977, validation loss: 0.0931
2024-05-25 04:15:53 [INFO]: Epoch 172 - training loss: 9212.2740, validation loss: 0.0949
2024-05-25 04:15:54 [INFO]: Epoch 173 - training loss: 9213.1257, validation loss: 0.0922
2024-05-25 04:15:54 [INFO]: Epoch 174 - training loss: 9213.2186, validation loss: 0.0941
2024-05-25 04:15:54 [INFO]: Epoch 175 - training loss: 9214.3344, validation loss: 0.0936
2024-05-25 04:15:54 [INFO]: Epoch 176 - training loss: 9212.7532, validation loss: 0.0934
2024-05-25 04:15:54 [INFO]: Epoch 177 - training loss: 9212.0250, validation loss: 0.0912
2024-05-25 04:15:54 [INFO]: Epoch 178 - training loss: 9212.1481, validation loss: 0.0917
2024-05-25 04:15:54 [INFO]: Epoch 179 - training loss: 9212.2595, validation loss: 0.0929
2024-05-25 04:15:54 [INFO]: Epoch 180 - training loss: 9212.8611, validation loss: 0.0913
2024-05-25 04:15:55 [INFO]: Epoch 181 - training loss: 9211.6512, validation loss: 0.0922
2024-05-25 04:15:55 [INFO]: Epoch 182 - training loss: 9213.2131, validation loss: 0.0917
2024-05-25 04:15:55 [INFO]: Epoch 183 - training loss: 9213.3250, validation loss: 0.0901
2024-05-25 04:15:55 [INFO]: Epoch 184 - training loss: 9211.8157, validation loss: 0.0901
2024-05-25 04:15:55 [INFO]: Epoch 185 - training loss: 9210.8667, validation loss: 0.0898
2024-05-25 04:15:55 [INFO]: Epoch 186 - training loss: 9212.9802, validation loss: 0.0909
2024-05-25 04:15:55 [INFO]: Epoch 187 - training loss: 9210.8243, validation loss: 0.0901
2024-05-25 04:15:56 [INFO]: Epoch 188 - training loss: 9214.4113, validation loss: 0.0910
2024-05-25 04:15:56 [INFO]: Epoch 189 - training loss: 9210.2911, validation loss: 0.0919
2024-05-25 04:15:56 [INFO]: Epoch 190 - training loss: 9211.0771, validation loss: 0.0879
2024-05-25 04:15:56 [INFO]: Epoch 191 - training loss: 9211.7512, validation loss: 0.0921
2024-05-25 04:15:56 [INFO]: Epoch 192 - training loss: 9211.1240, validation loss: 0.0895
2024-05-25 04:15:56 [INFO]: Epoch 193 - training loss: 9209.6839, validation loss: 0.0888
2024-05-25 04:15:56 [INFO]: Epoch 194 - training loss: 9211.2534, validation loss: 0.0885
2024-05-25 04:15:56 [INFO]: Epoch 195 - training loss: 9210.5190, validation loss: 0.0892
2024-05-25 04:15:57 [INFO]: Epoch 196 - training loss: 9211.1851, validation loss: 0.0894
2024-05-25 04:15:57 [INFO]: Epoch 197 - training loss: 9211.9177, validation loss: 0.0882
2024-05-25 04:15:57 [INFO]: Epoch 198 - training loss: 9209.2911, validation loss: 0.0886
2024-05-25 04:15:57 [INFO]: Epoch 199 - training loss: 9209.8837, validation loss: 0.0890
2024-05-25 04:15:57 [INFO]: Epoch 200 - training loss: 9212.0739, validation loss: 0.0886
2024-05-25 04:15:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:15:57 [INFO]: Finished training. The best model is from epoch#190.
2024-05-25 04:15:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/GPVAE_ettm1/20240525_T041531/GPVAE.pypots
2024-05-25 04:15:57 [INFO]: GP-VAE on ETTm1: MAE=0.2840, MSE=0.1709
2024-05-25 04:15:57 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/GPVAE_ettm1/imputation.pkl
2024-05-25 04:15:57 [INFO]: Using the given device: cuda:0
2024-05-25 04:15:57 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/USGAN_ettm1/20240525_T041557
2024-05-25 04:15:57 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/USGAN_ettm1/20240525_T041557/tensorboard
2024-05-25 04:15:57 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 04:16:08 [INFO]: Epoch 001 - generator training loss: 0.4598, discriminator training loss: 0.5300, validation loss: 0.3155
2024-05-25 04:16:16 [INFO]: Epoch 002 - generator training loss: -0.0522, discriminator training loss: 0.4700, validation loss: 0.1190
2024-05-25 04:16:25 [INFO]: Epoch 003 - generator training loss: -0.1532, discriminator training loss: 0.4231, validation loss: 0.0716
2024-05-25 04:16:34 [INFO]: Epoch 004 - generator training loss: -0.1358, discriminator training loss: 0.3505, validation loss: 0.0551
2024-05-25 04:16:42 [INFO]: Epoch 005 - generator training loss: -0.0966, discriminator training loss: 0.2732, validation loss: 0.0479
2024-05-25 04:16:51 [INFO]: Epoch 006 - generator training loss: -0.0674, discriminator training loss: 0.2189, validation loss: 0.0438
2024-05-25 04:17:00 [INFO]: Epoch 007 - generator training loss: -0.0580, discriminator training loss: 0.1937, validation loss: 0.0426
2024-05-25 04:17:09 [INFO]: Epoch 008 - generator training loss: -0.0566, discriminator training loss: 0.1808, validation loss: 0.0399
2024-05-25 04:17:17 [INFO]: Epoch 009 - generator training loss: -0.0544, discriminator training loss: 0.1775, validation loss: 0.0382
2024-05-25 04:17:26 [INFO]: Epoch 010 - generator training loss: -0.0582, discriminator training loss: 0.1762, validation loss: 0.0382
2024-05-25 04:17:35 [INFO]: Epoch 011 - generator training loss: -0.0559, discriminator training loss: 0.1753, validation loss: 0.0371
2024-05-25 04:17:43 [INFO]: Epoch 012 - generator training loss: -0.0535, discriminator training loss: 0.1746, validation loss: 0.0359
2024-05-25 04:17:52 [INFO]: Epoch 013 - generator training loss: -0.0549, discriminator training loss: 0.1715, validation loss: 0.0350
2024-05-25 04:18:01 [INFO]: Epoch 014 - generator training loss: -0.0587, discriminator training loss: 0.1699, validation loss: 0.0350
2024-05-25 04:18:10 [INFO]: Epoch 015 - generator training loss: -0.0601, discriminator training loss: 0.1725, validation loss: 0.0351
2024-05-25 04:18:18 [INFO]: Epoch 016 - generator training loss: -0.0580, discriminator training loss: 0.1699, validation loss: 0.0338
2024-05-25 04:18:27 [INFO]: Epoch 017 - generator training loss: -0.0607, discriminator training loss: 0.1697, validation loss: 0.0341
2024-05-25 04:18:36 [INFO]: Epoch 018 - generator training loss: -0.0585, discriminator training loss: 0.1693, validation loss: 0.0340
2024-05-25 04:18:45 [INFO]: Epoch 019 - generator training loss: -0.0601, discriminator training loss: 0.1708, validation loss: 0.0337
2024-05-25 04:18:53 [INFO]: Epoch 020 - generator training loss: -0.0563, discriminator training loss: 0.1723, validation loss: 0.0338
2024-05-25 04:19:02 [INFO]: Epoch 021 - generator training loss: -0.0585, discriminator training loss: 0.1692, validation loss: 0.0361
2024-05-25 04:19:11 [INFO]: Epoch 022 - generator training loss: -0.0597, discriminator training loss: 0.1693, validation loss: 0.0331
2024-05-25 04:19:20 [INFO]: Epoch 023 - generator training loss: -0.0614, discriminator training loss: 0.1693, validation loss: 0.0331
2024-05-25 04:19:28 [INFO]: Epoch 024 - generator training loss: -0.0614, discriminator training loss: 0.1704, validation loss: 0.0321
2024-05-25 04:19:37 [INFO]: Epoch 025 - generator training loss: -0.0617, discriminator training loss: 0.1666, validation loss: 0.0321
2024-05-25 04:19:46 [INFO]: Epoch 026 - generator training loss: -0.0612, discriminator training loss: 0.1673, validation loss: 0.0319
2024-05-25 04:19:55 [INFO]: Epoch 027 - generator training loss: -0.0652, discriminator training loss: 0.1690, validation loss: 0.0316
2024-05-25 04:20:03 [INFO]: Epoch 028 - generator training loss: -0.0604, discriminator training loss: 0.1673, validation loss: 0.0332
2024-05-25 04:20:12 [INFO]: Epoch 029 - generator training loss: -0.0625, discriminator training loss: 0.1669, validation loss: 0.0318
2024-05-25 04:20:21 [INFO]: Epoch 030 - generator training loss: -0.0617, discriminator training loss: 0.1691, validation loss: 0.0325
2024-05-25 04:20:29 [INFO]: Epoch 031 - generator training loss: -0.0602, discriminator training loss: 0.1673, validation loss: 0.0317
2024-05-25 04:20:38 [INFO]: Epoch 032 - generator training loss: -0.0617, discriminator training loss: 0.1687, validation loss: 0.0328
2024-05-25 04:20:47 [INFO]: Epoch 033 - generator training loss: -0.0543, discriminator training loss: 0.1680, validation loss: 0.0338
2024-05-25 04:20:56 [INFO]: Epoch 034 - generator training loss: -0.0619, discriminator training loss: 0.1697, validation loss: 0.0319
2024-05-25 04:21:04 [INFO]: Epoch 035 - generator training loss: -0.0621, discriminator training loss: 0.1673, validation loss: 0.0314
2024-05-25 04:21:13 [INFO]: Epoch 036 - generator training loss: -0.0648, discriminator training loss: 0.1662, validation loss: 0.0306
2024-05-25 04:21:22 [INFO]: Epoch 037 - generator training loss: -0.0654, discriminator training loss: 0.1663, validation loss: 0.0303
2024-05-25 04:21:31 [INFO]: Epoch 038 - generator training loss: -0.0615, discriminator training loss: 0.1657, validation loss: 0.0298
2024-05-25 04:21:39 [INFO]: Epoch 039 - generator training loss: -0.0626, discriminator training loss: 0.1671, validation loss: 0.0300
2024-05-25 04:21:48 [INFO]: Epoch 040 - generator training loss: -0.0665, discriminator training loss: 0.1656, validation loss: 0.0290
2024-05-25 04:21:57 [INFO]: Epoch 041 - generator training loss: -0.0637, discriminator training loss: 0.1654, validation loss: 0.0292
2024-05-25 04:22:06 [INFO]: Epoch 042 - generator training loss: -0.0681, discriminator training loss: 0.1652, validation loss: 0.0286
2024-05-25 04:22:15 [INFO]: Epoch 043 - generator training loss: -0.0656, discriminator training loss: 0.1659, validation loss: 0.0279
2024-05-25 04:22:23 [INFO]: Epoch 044 - generator training loss: -0.0680, discriminator training loss: 0.1670, validation loss: 0.0285
2024-05-25 04:22:32 [INFO]: Epoch 045 - generator training loss: -0.0662, discriminator training loss: 0.1687, validation loss: 0.0285
2024-05-25 04:22:41 [INFO]: Epoch 046 - generator training loss: -0.0664, discriminator training loss: 0.1651, validation loss: 0.0281
2024-05-25 04:22:49 [INFO]: Epoch 047 - generator training loss: -0.0661, discriminator training loss: 0.1655, validation loss: 0.0277
2024-05-25 04:22:58 [INFO]: Epoch 048 - generator training loss: -0.0674, discriminator training loss: 0.1662, validation loss: 0.0275
2024-05-25 04:23:07 [INFO]: Epoch 049 - generator training loss: -0.0628, discriminator training loss: 0.1640, validation loss: 0.0272
2024-05-25 04:23:16 [INFO]: Epoch 050 - generator training loss: -0.0675, discriminator training loss: 0.1659, validation loss: 0.0273
2024-05-25 04:23:24 [INFO]: Epoch 051 - generator training loss: -0.0656, discriminator training loss: 0.1650, validation loss: 0.0273
2024-05-25 04:23:33 [INFO]: Epoch 052 - generator training loss: -0.0696, discriminator training loss: 0.1645, validation loss: 0.0276
2024-05-25 04:23:42 [INFO]: Epoch 053 - generator training loss: -0.0656, discriminator training loss: 0.1646, validation loss: 0.0268
2024-05-25 04:23:50 [INFO]: Epoch 054 - generator training loss: -0.0677, discriminator training loss: 0.1647, validation loss: 0.0268
2024-05-25 04:23:59 [INFO]: Epoch 055 - generator training loss: -0.0670, discriminator training loss: 0.1640, validation loss: 0.0282
2024-05-25 04:24:08 [INFO]: Epoch 056 - generator training loss: -0.0692, discriminator training loss: 0.1644, validation loss: 0.0274
2024-05-25 04:24:16 [INFO]: Epoch 057 - generator training loss: -0.0696, discriminator training loss: 0.1659, validation loss: 0.0266
2024-05-25 04:24:25 [INFO]: Epoch 058 - generator training loss: -0.0608, discriminator training loss: 0.1604, validation loss: 0.0266
2024-05-25 04:24:34 [INFO]: Epoch 059 - generator training loss: -0.0721, discriminator training loss: 0.1684, validation loss: 0.0265
2024-05-25 04:24:43 [INFO]: Epoch 060 - generator training loss: -0.0638, discriminator training loss: 0.1635, validation loss: 0.0270
2024-05-25 04:24:51 [INFO]: Epoch 061 - generator training loss: -0.0706, discriminator training loss: 0.1657, validation loss: 0.0268
2024-05-25 04:25:00 [INFO]: Epoch 062 - generator training loss: -0.0669, discriminator training loss: 0.1639, validation loss: 0.0264
2024-05-25 04:25:09 [INFO]: Epoch 063 - generator training loss: -0.0680, discriminator training loss: 0.1633, validation loss: 0.0265
2024-05-25 04:25:18 [INFO]: Epoch 064 - generator training loss: -0.0660, discriminator training loss: 0.1638, validation loss: 0.0261
2024-05-25 04:25:27 [INFO]: Epoch 065 - generator training loss: -0.0677, discriminator training loss: 0.1628, validation loss: 0.0266
2024-05-25 04:25:35 [INFO]: Epoch 066 - generator training loss: -0.0670, discriminator training loss: 0.1633, validation loss: 0.0266
2024-05-25 04:25:44 [INFO]: Epoch 067 - generator training loss: -0.0669, discriminator training loss: 0.1651, validation loss: 0.0270
2024-05-25 04:25:53 [INFO]: Epoch 068 - generator training loss: -0.0672, discriminator training loss: 0.1637, validation loss: 0.0265
2024-05-25 04:26:02 [INFO]: Epoch 069 - generator training loss: -0.0674, discriminator training loss: 0.1623, validation loss: 0.0265
2024-05-25 04:26:10 [INFO]: Epoch 070 - generator training loss: -0.0694, discriminator training loss: 0.1639, validation loss: 0.0264
2024-05-25 04:26:19 [INFO]: Epoch 071 - generator training loss: -0.0679, discriminator training loss: 0.1623, validation loss: 0.0264
2024-05-25 04:26:28 [INFO]: Epoch 072 - generator training loss: -0.0684, discriminator training loss: 0.1640, validation loss: 0.0256
2024-05-25 04:26:36 [INFO]: Epoch 073 - generator training loss: -0.0682, discriminator training loss: 0.1642, validation loss: 0.0263
2024-05-25 04:26:45 [INFO]: Epoch 074 - generator training loss: -0.0686, discriminator training loss: 0.1615, validation loss: 0.0264
2024-05-25 04:26:54 [INFO]: Epoch 075 - generator training loss: -0.0682, discriminator training loss: 0.1618, validation loss: 0.0273
2024-05-25 04:27:03 [INFO]: Epoch 076 - generator training loss: -0.0668, discriminator training loss: 0.1629, validation loss: 0.0264
2024-05-25 04:27:11 [INFO]: Epoch 077 - generator training loss: -0.0662, discriminator training loss: 0.1619, validation loss: 0.0258
2024-05-25 04:27:20 [INFO]: Epoch 078 - generator training loss: -0.0704, discriminator training loss: 0.1631, validation loss: 0.0259
2024-05-25 04:27:29 [INFO]: Epoch 079 - generator training loss: -0.0685, discriminator training loss: 0.1615, validation loss: 0.0262
2024-05-25 04:27:38 [INFO]: Epoch 080 - generator training loss: -0.0682, discriminator training loss: 0.1626, validation loss: 0.0258
2024-05-25 04:27:47 [INFO]: Epoch 081 - generator training loss: -0.0656, discriminator training loss: 0.1613, validation loss: 0.0262
2024-05-25 04:27:56 [INFO]: Epoch 082 - generator training loss: -0.0661, discriminator training loss: 0.1621, validation loss: 0.0261
2024-05-25 04:27:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:27:56 [INFO]: Finished training. The best model is from epoch#72.
2024-05-25 04:27:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/USGAN_ettm1/20240525_T041557/USGAN.pypots
2024-05-25 04:27:57 [INFO]: US-GAN on ETTm1: MAE=0.1619, MSE=0.0603
2024-05-25 04:27:57 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/USGAN_ettm1/imputation.pkl
2024-05-25 04:27:57 [INFO]: Using the given device: cuda:0
2024-05-25 04:27:57 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/BRITS_ettm1/20240525_T042757
2024-05-25 04:27:57 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/BRITS_ettm1/20240525_T042757/tensorboard
2024-05-25 04:27:57 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 04:28:04 [INFO]: Epoch 001 - training loss: 1.3051, validation loss: 0.3605
2024-05-25 04:28:10 [INFO]: Epoch 002 - training loss: 0.9248, validation loss: 0.1095
2024-05-25 04:28:16 [INFO]: Epoch 003 - training loss: 0.7236, validation loss: 0.0668
2024-05-25 04:28:22 [INFO]: Epoch 004 - training loss: 0.6700, validation loss: 0.0519
2024-05-25 04:28:27 [INFO]: Epoch 005 - training loss: 0.6018, validation loss: 0.0478
2024-05-25 04:28:33 [INFO]: Epoch 006 - training loss: 0.5656, validation loss: 0.0425
2024-05-25 04:28:39 [INFO]: Epoch 007 - training loss: 0.5576, validation loss: 0.0392
2024-05-25 04:28:45 [INFO]: Epoch 008 - training loss: 0.5339, validation loss: 0.0369
2024-05-25 04:28:51 [INFO]: Epoch 009 - training loss: 0.4981, validation loss: 0.0358
2024-05-25 04:28:57 [INFO]: Epoch 010 - training loss: 0.4780, validation loss: 0.0344
2024-05-25 04:29:03 [INFO]: Epoch 011 - training loss: 0.4495, validation loss: 0.0329
2024-05-25 04:29:08 [INFO]: Epoch 012 - training loss: 0.4901, validation loss: 0.0324
2024-05-25 04:29:14 [INFO]: Epoch 013 - training loss: 0.4481, validation loss: 0.0314
2024-05-25 04:29:20 [INFO]: Epoch 014 - training loss: 0.4428, validation loss: 0.0308
2024-05-25 04:29:26 [INFO]: Epoch 015 - training loss: 0.4345, validation loss: 0.0296
2024-05-25 04:29:32 [INFO]: Epoch 016 - training loss: 0.4184, validation loss: 0.0291
2024-05-25 04:29:37 [INFO]: Epoch 017 - training loss: 0.4112, validation loss: 0.0288
2024-05-25 04:29:43 [INFO]: Epoch 018 - training loss: 0.4098, validation loss: 0.0279
2024-05-25 04:29:49 [INFO]: Epoch 019 - training loss: 0.4083, validation loss: 0.0280
2024-05-25 04:29:55 [INFO]: Epoch 020 - training loss: 0.4013, validation loss: 0.0271
2024-05-25 04:30:01 [INFO]: Epoch 021 - training loss: 0.4039, validation loss: 0.0273
2024-05-25 04:30:06 [INFO]: Epoch 022 - training loss: 0.3988, validation loss: 0.0267
2024-05-25 04:30:12 [INFO]: Epoch 023 - training loss: 0.4012, validation loss: 0.0268
2024-05-25 04:30:18 [INFO]: Epoch 024 - training loss: 0.4100, validation loss: 0.0266
2024-05-25 04:30:24 [INFO]: Epoch 025 - training loss: 0.3983, validation loss: 0.0265
2024-05-25 04:30:30 [INFO]: Epoch 026 - training loss: 0.3994, validation loss: 0.0270
2024-05-25 04:30:35 [INFO]: Epoch 027 - training loss: 0.4108, validation loss: 0.0268
2024-05-25 04:30:41 [INFO]: Epoch 028 - training loss: 0.4033, validation loss: 0.0273
2024-05-25 04:30:47 [INFO]: Epoch 029 - training loss: 0.4065, validation loss: 0.0282
2024-05-25 04:30:53 [INFO]: Epoch 030 - training loss: 0.4026, validation loss: 0.0279
2024-05-25 04:30:58 [INFO]: Epoch 031 - training loss: 0.4019, validation loss: 0.0276
2024-05-25 04:31:04 [INFO]: Epoch 032 - training loss: 0.3996, validation loss: 0.0265
2024-05-25 04:31:10 [INFO]: Epoch 033 - training loss: 0.3942, validation loss: 0.0267
2024-05-25 04:31:16 [INFO]: Epoch 034 - training loss: 0.3991, validation loss: 0.0265
2024-05-25 04:31:22 [INFO]: Epoch 035 - training loss: 0.3907, validation loss: 0.0275
2024-05-25 04:31:27 [INFO]: Epoch 036 - training loss: 0.4031, validation loss: 0.0266
2024-05-25 04:31:33 [INFO]: Epoch 037 - training loss: 0.3921, validation loss: 0.0264
2024-05-25 04:31:39 [INFO]: Epoch 038 - training loss: 0.3956, validation loss: 0.0268
2024-05-25 04:31:45 [INFO]: Epoch 039 - training loss: 0.3977, validation loss: 0.0263
2024-05-25 04:31:51 [INFO]: Epoch 040 - training loss: 0.3900, validation loss: 0.0265
2024-05-25 04:31:56 [INFO]: Epoch 041 - training loss: 0.3956, validation loss: 0.0261
2024-05-25 04:32:02 [INFO]: Epoch 042 - training loss: 0.3922, validation loss: 0.0262
2024-05-25 04:32:08 [INFO]: Epoch 043 - training loss: 0.3877, validation loss: 0.0263
2024-05-25 04:32:14 [INFO]: Epoch 044 - training loss: 0.3915, validation loss: 0.0267
2024-05-25 04:32:19 [INFO]: Epoch 045 - training loss: 0.3888, validation loss: 0.0269
2024-05-25 04:32:25 [INFO]: Epoch 046 - training loss: 0.3887, validation loss: 0.0268
2024-05-25 04:32:31 [INFO]: Epoch 047 - training loss: 0.3948, validation loss: 0.0268
2024-05-25 04:32:37 [INFO]: Epoch 048 - training loss: 0.3895, validation loss: 0.0265
2024-05-25 04:32:43 [INFO]: Epoch 049 - training loss: 0.3921, validation loss: 0.0264
2024-05-25 04:32:49 [INFO]: Epoch 050 - training loss: 0.3901, validation loss: 0.0277
2024-05-25 04:32:54 [INFO]: Epoch 051 - training loss: 0.3926, validation loss: 0.0261
2024-05-25 04:33:00 [INFO]: Epoch 052 - training loss: 0.3846, validation loss: 0.0266
2024-05-25 04:33:06 [INFO]: Epoch 053 - training loss: 0.3888, validation loss: 0.0269
2024-05-25 04:33:12 [INFO]: Epoch 054 - training loss: 0.3883, validation loss: 0.0261
2024-05-25 04:33:17 [INFO]: Epoch 055 - training loss: 0.3871, validation loss: 0.0260
2024-05-25 04:33:23 [INFO]: Epoch 056 - training loss: 0.3866, validation loss: 0.0268
2024-05-25 04:33:29 [INFO]: Epoch 057 - training loss: 0.3865, validation loss: 0.0269
2024-05-25 04:33:35 [INFO]: Epoch 058 - training loss: 0.3870, validation loss: 0.0261
2024-05-25 04:33:41 [INFO]: Epoch 059 - training loss: 0.3846, validation loss: 0.0274
2024-05-25 04:33:46 [INFO]: Epoch 060 - training loss: 0.4004, validation loss: 0.0266
2024-05-25 04:33:52 [INFO]: Epoch 061 - training loss: 0.3859, validation loss: 0.0264
2024-05-25 04:33:58 [INFO]: Epoch 062 - training loss: 0.3868, validation loss: 0.0265
2024-05-25 04:34:04 [INFO]: Epoch 063 - training loss: 0.3813, validation loss: 0.0268
2024-05-25 04:34:10 [INFO]: Epoch 064 - training loss: 0.3828, validation loss: 0.0261
2024-05-25 04:34:15 [INFO]: Epoch 065 - training loss: 0.3827, validation loss: 0.0265
2024-05-25 04:34:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:34:15 [INFO]: Finished training. The best model is from epoch#55.
2024-05-25 04:34:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/BRITS_ettm1/20240525_T042757/BRITS.pypots
2024-05-25 04:34:16 [INFO]: BRITS on ETTm1: MAE=0.1395, MSE=0.0559
2024-05-25 04:34:16 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/BRITS_ettm1/imputation.pkl
2024-05-25 04:34:16 [INFO]: Using the given device: cuda:0
2024-05-25 04:34:16 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416
2024-05-25 04:34:16 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/tensorboard
2024-05-25 04:34:16 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 04:34:18 [INFO]: Epoch 001 - training loss: 1.4008, validation loss: 1.2757
2024-05-25 04:34:18 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch1_loss1.2757467478513718.pypots
2024-05-25 04:34:18 [INFO]: Epoch 002 - training loss: 1.0216, validation loss: 1.1396
2024-05-25 04:34:18 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch2_loss1.1395649313926697.pypots
2024-05-25 04:34:19 [INFO]: Epoch 003 - training loss: 0.9245, validation loss: 1.0590
2024-05-25 04:34:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch3_loss1.0590276271104813.pypots
2024-05-25 04:34:19 [INFO]: Epoch 004 - training loss: 0.8902, validation loss: 1.0268
2024-05-25 04:34:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch4_loss1.0268374383449554.pypots
2024-05-25 04:34:19 [INFO]: Epoch 005 - training loss: 0.8710, validation loss: 1.0151
2024-05-25 04:34:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch5_loss1.0150959938764572.pypots
2024-05-25 04:34:19 [INFO]: Epoch 006 - training loss: 0.8705, validation loss: 1.0103
2024-05-25 04:34:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch6_loss1.0103157609701157.pypots
2024-05-25 04:34:19 [INFO]: Epoch 007 - training loss: 0.8965, validation loss: 1.0076
2024-05-25 04:34:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch7_loss1.007621243596077.pypots
2024-05-25 04:34:20 [INFO]: Epoch 008 - training loss: 0.8597, validation loss: 1.0010
2024-05-25 04:34:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch8_loss1.0010140091180801.pypots
2024-05-25 04:34:20 [INFO]: Epoch 009 - training loss: 0.8505, validation loss: 0.9922
2024-05-25 04:34:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch9_loss0.9922230541706085.pypots
2024-05-25 04:34:20 [INFO]: Epoch 010 - training loss: 0.8151, validation loss: 0.9923
2024-05-25 04:34:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch10_loss0.9923234432935715.pypots
2024-05-25 04:34:20 [INFO]: Epoch 011 - training loss: 0.8229, validation loss: 0.9903
2024-05-25 04:34:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch11_loss0.9902998059988022.pypots
2024-05-25 04:34:20 [INFO]: Epoch 012 - training loss: 0.8235, validation loss: 0.9806
2024-05-25 04:34:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch12_loss0.9805588275194168.pypots
2024-05-25 04:34:20 [INFO]: Epoch 013 - training loss: 0.8218, validation loss: 0.9754
2024-05-25 04:34:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch13_loss0.9753808230161667.pypots
2024-05-25 04:34:21 [INFO]: Epoch 014 - training loss: 0.8135, validation loss: 0.9755
2024-05-25 04:34:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch14_loss0.9755182415246964.pypots
2024-05-25 04:34:21 [INFO]: Epoch 015 - training loss: 0.8207, validation loss: 0.9722
2024-05-25 04:34:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch15_loss0.9721675515174866.pypots
2024-05-25 04:34:21 [INFO]: Epoch 016 - training loss: 0.8341, validation loss: 0.9674
2024-05-25 04:34:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch16_loss0.9673609435558319.pypots
2024-05-25 04:34:21 [INFO]: Epoch 017 - training loss: 0.8003, validation loss: 0.9646
2024-05-25 04:34:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch17_loss0.9645868837833405.pypots
2024-05-25 04:34:21 [INFO]: Epoch 018 - training loss: 0.7925, validation loss: 0.9626
2024-05-25 04:34:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch18_loss0.9626313745975494.pypots
2024-05-25 04:34:22 [INFO]: Epoch 019 - training loss: 0.8009, validation loss: 0.9592
2024-05-25 04:34:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch19_loss0.9591742008924484.pypots
2024-05-25 04:34:22 [INFO]: Epoch 020 - training loss: 0.8098, validation loss: 0.9567
2024-05-25 04:34:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch20_loss0.9567144513130188.pypots
2024-05-25 04:34:22 [INFO]: Epoch 021 - training loss: 0.7920, validation loss: 0.9550
2024-05-25 04:34:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch21_loss0.9550300985574722.pypots
2024-05-25 04:34:22 [INFO]: Epoch 022 - training loss: 0.8246, validation loss: 0.9522
2024-05-25 04:34:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch22_loss0.9521742314100266.pypots
2024-05-25 04:34:22 [INFO]: Epoch 023 - training loss: 0.7933, validation loss: 0.9523
2024-05-25 04:34:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch23_loss0.9523333758115768.pypots
2024-05-25 04:34:23 [INFO]: Epoch 024 - training loss: 0.7989, validation loss: 0.9508
2024-05-25 04:34:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch24_loss0.9507513642311096.pypots
2024-05-25 04:34:23 [INFO]: Epoch 025 - training loss: 0.7991, validation loss: 0.9489
2024-05-25 04:34:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch25_loss0.9488653093576431.pypots
2024-05-25 04:34:23 [INFO]: Epoch 026 - training loss: 0.7803, validation loss: 0.9460
2024-05-25 04:34:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch26_loss0.9459503591060638.pypots
2024-05-25 04:34:23 [INFO]: Epoch 027 - training loss: 0.7696, validation loss: 0.9432
2024-05-25 04:34:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch27_loss0.9432211816310883.pypots
2024-05-25 04:34:23 [INFO]: Epoch 028 - training loss: 0.7786, validation loss: 0.9417
2024-05-25 04:34:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch28_loss0.9417304545640945.pypots
2024-05-25 04:34:23 [INFO]: Epoch 029 - training loss: 0.7788, validation loss: 0.9409
2024-05-25 04:34:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch29_loss0.9408909827470779.pypots
2024-05-25 04:34:24 [INFO]: Epoch 030 - training loss: 0.7831, validation loss: 0.9432
2024-05-25 04:34:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch30_loss0.9431823045015335.pypots
2024-05-25 04:34:24 [INFO]: Epoch 031 - training loss: 0.7793, validation loss: 0.9425
2024-05-25 04:34:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch31_loss0.9424653798341751.pypots
2024-05-25 04:34:24 [INFO]: Epoch 032 - training loss: 0.7774, validation loss: 0.9372
2024-05-25 04:34:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch32_loss0.9371931701898575.pypots
2024-05-25 04:34:24 [INFO]: Epoch 033 - training loss: 0.7651, validation loss: 0.9352
2024-05-25 04:34:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch33_loss0.9352075755596161.pypots
2024-05-25 04:34:24 [INFO]: Epoch 034 - training loss: 0.7762, validation loss: 0.9320
2024-05-25 04:34:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch34_loss0.9319618791341782.pypots
2024-05-25 04:34:25 [INFO]: Epoch 035 - training loss: 0.7521, validation loss: 0.9317
2024-05-25 04:34:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch35_loss0.9316947609186172.pypots
2024-05-25 04:34:25 [INFO]: Epoch 036 - training loss: 0.7712, validation loss: 0.9303
2024-05-25 04:34:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch36_loss0.9302879422903061.pypots
2024-05-25 04:34:25 [INFO]: Epoch 037 - training loss: 0.7585, validation loss: 0.9309
2024-05-25 04:34:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch37_loss0.930865541100502.pypots
2024-05-25 04:34:25 [INFO]: Epoch 038 - training loss: 0.7840, validation loss: 0.9269
2024-05-25 04:34:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch38_loss0.9268501996994019.pypots
2024-05-25 04:34:25 [INFO]: Epoch 039 - training loss: 0.7640, validation loss: 0.9230
2024-05-25 04:34:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch39_loss0.9230195432901382.pypots
2024-05-25 04:34:26 [INFO]: Epoch 040 - training loss: 0.7438, validation loss: 0.9198
2024-05-25 04:34:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch40_loss0.9198013842105865.pypots
2024-05-25 04:34:26 [INFO]: Epoch 041 - training loss: 0.7633, validation loss: 0.9172
2024-05-25 04:34:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch41_loss0.9171933233737946.pypots
2024-05-25 04:34:26 [INFO]: Epoch 042 - training loss: 0.7659, validation loss: 0.9142
2024-05-25 04:34:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch42_loss0.914196789264679.pypots
2024-05-25 04:34:26 [INFO]: Epoch 043 - training loss: 0.7412, validation loss: 0.9125
2024-05-25 04:34:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch43_loss0.9124584048986435.pypots
2024-05-25 04:34:26 [INFO]: Epoch 044 - training loss: 0.7542, validation loss: 0.9061
2024-05-25 04:34:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch44_loss0.9060710966587067.pypots
2024-05-25 04:34:26 [INFO]: Epoch 045 - training loss: 0.7560, validation loss: 0.9062
2024-05-25 04:34:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch45_loss0.9061783850193024.pypots
2024-05-25 04:34:27 [INFO]: Epoch 046 - training loss: 0.7571, validation loss: 0.9041
2024-05-25 04:34:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch46_loss0.9041258096694946.pypots
2024-05-25 04:34:27 [INFO]: Epoch 047 - training loss: 0.7411, validation loss: 0.9007
2024-05-25 04:34:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch47_loss0.9006669223308563.pypots
2024-05-25 04:34:27 [INFO]: Epoch 048 - training loss: 0.7602, validation loss: 0.8986
2024-05-25 04:34:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch48_loss0.8985886722803116.pypots
2024-05-25 04:34:27 [INFO]: Epoch 049 - training loss: 0.7489, validation loss: 0.8944
2024-05-25 04:34:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch49_loss0.8944160640239716.pypots
2024-05-25 04:34:27 [INFO]: Epoch 050 - training loss: 0.7517, validation loss: 0.8928
2024-05-25 04:34:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch50_loss0.892763614654541.pypots
2024-05-25 04:34:28 [INFO]: Epoch 051 - training loss: 0.7587, validation loss: 0.8908
2024-05-25 04:34:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch51_loss0.8907598406076431.pypots
2024-05-25 04:34:28 [INFO]: Epoch 052 - training loss: 0.7568, validation loss: 0.8865
2024-05-25 04:34:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch52_loss0.8864734917879105.pypots
2024-05-25 04:34:28 [INFO]: Epoch 053 - training loss: 0.7632, validation loss: 0.8870
2024-05-25 04:34:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch53_loss0.8869642466306686.pypots
2024-05-25 04:34:28 [INFO]: Epoch 054 - training loss: 0.7268, validation loss: 0.8836
2024-05-25 04:34:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch54_loss0.8835716843605042.pypots
2024-05-25 04:34:28 [INFO]: Epoch 055 - training loss: 0.7375, validation loss: 0.8860
2024-05-25 04:34:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch55_loss0.8859898447990417.pypots
2024-05-25 04:34:29 [INFO]: Epoch 056 - training loss: 0.7393, validation loss: 0.8839
2024-05-25 04:34:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch56_loss0.8838610500097275.pypots
2024-05-25 04:34:29 [INFO]: Epoch 057 - training loss: 0.7594, validation loss: 0.8821
2024-05-25 04:34:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch57_loss0.8821354061365128.pypots
2024-05-25 04:34:29 [INFO]: Epoch 058 - training loss: 0.7525, validation loss: 0.8780
2024-05-25 04:34:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch58_loss0.8779609948396683.pypots
2024-05-25 04:34:29 [INFO]: Epoch 059 - training loss: 0.7270, validation loss: 0.8776
2024-05-25 04:34:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch59_loss0.8775763213634491.pypots
2024-05-25 04:34:29 [INFO]: Epoch 060 - training loss: 0.7436, validation loss: 0.8776
2024-05-25 04:34:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch60_loss0.877636194229126.pypots
2024-05-25 04:34:29 [INFO]: Epoch 061 - training loss: 0.7295, validation loss: 0.8777
2024-05-25 04:34:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch61_loss0.877692773938179.pypots
2024-05-25 04:34:30 [INFO]: Epoch 062 - training loss: 0.7417, validation loss: 0.8750
2024-05-25 04:34:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch62_loss0.874950498342514.pypots
2024-05-25 04:34:30 [INFO]: Epoch 063 - training loss: 0.7868, validation loss: 0.8753
2024-05-25 04:34:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch63_loss0.8752900958061218.pypots
2024-05-25 04:34:30 [INFO]: Epoch 064 - training loss: 0.7631, validation loss: 0.8688
2024-05-25 04:34:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch64_loss0.8687677085399628.pypots
2024-05-25 04:34:30 [INFO]: Epoch 065 - training loss: 0.7458, validation loss: 0.8713
2024-05-25 04:34:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch65_loss0.871265783905983.pypots
2024-05-25 04:34:30 [INFO]: Epoch 066 - training loss: 0.7328, validation loss: 0.8687
2024-05-25 04:34:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch66_loss0.8686676323413849.pypots
2024-05-25 04:34:31 [INFO]: Epoch 067 - training loss: 0.7342, validation loss: 0.8689
2024-05-25 04:34:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch67_loss0.868861734867096.pypots
2024-05-25 04:34:31 [INFO]: Epoch 068 - training loss: 0.7413, validation loss: 0.8662
2024-05-25 04:34:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch68_loss0.8662164062261581.pypots
2024-05-25 04:34:31 [INFO]: Epoch 069 - training loss: 0.7311, validation loss: 0.8682
2024-05-25 04:34:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch69_loss0.8682135939598083.pypots
2024-05-25 04:34:31 [INFO]: Epoch 070 - training loss: 0.7563, validation loss: 0.8637
2024-05-25 04:34:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch70_loss0.8636500537395477.pypots
2024-05-25 04:34:31 [INFO]: Epoch 071 - training loss: 0.7767, validation loss: 0.8638
2024-05-25 04:34:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch71_loss0.8638399839401245.pypots
2024-05-25 04:34:32 [INFO]: Epoch 072 - training loss: 0.7280, validation loss: 0.8615
2024-05-25 04:34:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch72_loss0.8614826798439026.pypots
2024-05-25 04:34:32 [INFO]: Epoch 073 - training loss: 0.7393, validation loss: 0.8634
2024-05-25 04:34:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch73_loss0.8633655607700348.pypots
2024-05-25 04:34:32 [INFO]: Epoch 074 - training loss: 0.7316, validation loss: 0.8619
2024-05-25 04:34:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch74_loss0.8619316667318344.pypots
2024-05-25 04:34:32 [INFO]: Epoch 075 - training loss: 0.7316, validation loss: 0.8613
2024-05-25 04:34:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch75_loss0.8613321036100388.pypots
2024-05-25 04:34:32 [INFO]: Epoch 076 - training loss: 0.7262, validation loss: 0.8590
2024-05-25 04:34:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch76_loss0.8590438216924667.pypots
2024-05-25 04:34:32 [INFO]: Epoch 077 - training loss: 0.7326, validation loss: 0.8598
2024-05-25 04:34:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch77_loss0.8598436713218689.pypots
2024-05-25 04:34:33 [INFO]: Epoch 078 - training loss: 0.7205, validation loss: 0.8592
2024-05-25 04:34:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch78_loss0.859166607260704.pypots
2024-05-25 04:34:33 [INFO]: Epoch 079 - training loss: 0.7504, validation loss: 0.8582
2024-05-25 04:34:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch79_loss0.8581621646881104.pypots
2024-05-25 04:34:33 [INFO]: Epoch 080 - training loss: 0.7342, validation loss: 0.8565
2024-05-25 04:34:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch80_loss0.8565422743558884.pypots
2024-05-25 04:34:33 [INFO]: Epoch 081 - training loss: 0.7440, validation loss: 0.8603
2024-05-25 04:34:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch81_loss0.860336646437645.pypots
2024-05-25 04:34:33 [INFO]: Epoch 082 - training loss: 0.7440, validation loss: 0.8543
2024-05-25 04:34:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch82_loss0.8542632311582565.pypots
2024-05-25 04:34:34 [INFO]: Epoch 083 - training loss: 0.7327, validation loss: 0.8536
2024-05-25 04:34:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch83_loss0.8536063879728317.pypots
2024-05-25 04:34:34 [INFO]: Epoch 084 - training loss: 0.7323, validation loss: 0.8545
2024-05-25 04:34:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch84_loss0.8545132279396057.pypots
2024-05-25 04:34:34 [INFO]: Epoch 085 - training loss: 0.7317, validation loss: 0.8543
2024-05-25 04:34:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch85_loss0.8542677909135818.pypots
2024-05-25 04:34:34 [INFO]: Epoch 086 - training loss: 0.7393, validation loss: 0.8530
2024-05-25 04:34:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch86_loss0.8529596030712128.pypots
2024-05-25 04:34:34 [INFO]: Epoch 087 - training loss: 0.7427, validation loss: 0.8518
2024-05-25 04:34:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch87_loss0.8517645597457886.pypots
2024-05-25 04:34:35 [INFO]: Epoch 088 - training loss: 0.7328, validation loss: 0.8517
2024-05-25 04:34:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch88_loss0.8517154008150101.pypots
2024-05-25 04:34:35 [INFO]: Epoch 089 - training loss: 0.7341, validation loss: 0.8501
2024-05-25 04:34:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch89_loss0.850118950009346.pypots
2024-05-25 04:34:35 [INFO]: Epoch 090 - training loss: 0.7326, validation loss: 0.8489
2024-05-25 04:34:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch90_loss0.848865881562233.pypots
2024-05-25 04:34:35 [INFO]: Epoch 091 - training loss: 0.7448, validation loss: 0.8496
2024-05-25 04:34:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch91_loss0.8495856672525406.pypots
2024-05-25 04:34:35 [INFO]: Epoch 092 - training loss: 0.7368, validation loss: 0.8489
2024-05-25 04:34:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch92_loss0.8488967716693878.pypots
2024-05-25 04:34:35 [INFO]: Epoch 093 - training loss: 0.7313, validation loss: 0.8509
2024-05-25 04:34:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch93_loss0.8508883416652679.pypots
2024-05-25 04:34:36 [INFO]: Epoch 094 - training loss: 0.7436, validation loss: 0.8495
2024-05-25 04:34:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch94_loss0.8494661748409271.pypots
2024-05-25 04:34:36 [INFO]: Epoch 095 - training loss: 0.7616, validation loss: 0.8507
2024-05-25 04:34:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch95_loss0.85072161257267.pypots
2024-05-25 04:34:36 [INFO]: Epoch 096 - training loss: 0.7612, validation loss: 0.8462
2024-05-25 04:34:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch96_loss0.8461989164352417.pypots
2024-05-25 04:34:36 [INFO]: Epoch 097 - training loss: 0.7406, validation loss: 0.8466
2024-05-25 04:34:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch97_loss0.8466344475746155.pypots
2024-05-25 04:34:36 [INFO]: Epoch 098 - training loss: 0.7349, validation loss: 0.8450
2024-05-25 04:34:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch98_loss0.8450314551591873.pypots
2024-05-25 04:34:37 [INFO]: Epoch 099 - training loss: 0.7272, validation loss: 0.8463
2024-05-25 04:34:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch99_loss0.8462778180837631.pypots
2024-05-25 04:34:37 [INFO]: Epoch 100 - training loss: 0.7526, validation loss: 0.8466
2024-05-25 04:34:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch100_loss0.8466192930936813.pypots
2024-05-25 04:34:37 [INFO]: Epoch 101 - training loss: 0.7178, validation loss: 0.8494
2024-05-25 04:34:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch101_loss0.8493825495243073.pypots
2024-05-25 04:34:37 [INFO]: Epoch 102 - training loss: 0.7246, validation loss: 0.8458
2024-05-25 04:34:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch102_loss0.8458068072795868.pypots
2024-05-25 04:34:37 [INFO]: Epoch 103 - training loss: 0.7248, validation loss: 0.8395
2024-05-25 04:34:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch103_loss0.8395059704780579.pypots
2024-05-25 04:34:38 [INFO]: Epoch 104 - training loss: 0.7331, validation loss: 0.8412
2024-05-25 04:34:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch104_loss0.8411881327629089.pypots
2024-05-25 04:34:38 [INFO]: Epoch 105 - training loss: 0.7260, validation loss: 0.8427
2024-05-25 04:34:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch105_loss0.8426730781793594.pypots
2024-05-25 04:34:38 [INFO]: Epoch 106 - training loss: 0.7338, validation loss: 0.8422
2024-05-25 04:34:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch106_loss0.8421623408794403.pypots
2024-05-25 04:34:38 [INFO]: Epoch 107 - training loss: 0.7256, validation loss: 0.8389
2024-05-25 04:34:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch107_loss0.8388518393039703.pypots
2024-05-25 04:34:38 [INFO]: Epoch 108 - training loss: 0.7606, validation loss: 0.8402
2024-05-25 04:34:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch108_loss0.8401967734098434.pypots
2024-05-25 04:34:38 [INFO]: Epoch 109 - training loss: 0.7163, validation loss: 0.8380
2024-05-25 04:34:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch109_loss0.8380306363105774.pypots
2024-05-25 04:34:39 [INFO]: Epoch 110 - training loss: 0.7185, validation loss: 0.8402
2024-05-25 04:34:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch110_loss0.840216189622879.pypots
2024-05-25 04:34:39 [INFO]: Epoch 111 - training loss: 0.7380, validation loss: 0.8371
2024-05-25 04:34:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch111_loss0.8371197581291199.pypots
2024-05-25 04:34:39 [INFO]: Epoch 112 - training loss: 0.7386, validation loss: 0.8359
2024-05-25 04:34:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch112_loss0.8359373807907104.pypots
2024-05-25 04:34:39 [INFO]: Epoch 113 - training loss: 0.7267, validation loss: 0.8365
2024-05-25 04:34:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch113_loss0.8365243226289749.pypots
2024-05-25 04:34:39 [INFO]: Epoch 114 - training loss: 0.7329, validation loss: 0.8350
2024-05-25 04:34:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch114_loss0.8350242227315903.pypots
2024-05-25 04:34:40 [INFO]: Epoch 115 - training loss: 0.7308, validation loss: 0.8367
2024-05-25 04:34:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch115_loss0.8366519212722778.pypots
2024-05-25 04:34:40 [INFO]: Epoch 116 - training loss: 0.7141, validation loss: 0.8371
2024-05-25 04:34:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch116_loss0.8371276557445526.pypots
2024-05-25 04:34:40 [INFO]: Epoch 117 - training loss: 0.7312, validation loss: 0.8350
2024-05-25 04:34:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch117_loss0.8349678069353104.pypots
2024-05-25 04:34:40 [INFO]: Epoch 118 - training loss: 0.7303, validation loss: 0.8336
2024-05-25 04:34:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch118_loss0.8335882276296616.pypots
2024-05-25 04:34:40 [INFO]: Epoch 119 - training loss: 0.7104, validation loss: 0.8351
2024-05-25 04:34:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch119_loss0.835115984082222.pypots
2024-05-25 04:34:41 [INFO]: Epoch 120 - training loss: 0.7294, validation loss: 0.8291
2024-05-25 04:34:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch120_loss0.8291115909814835.pypots
2024-05-25 04:34:41 [INFO]: Epoch 121 - training loss: 0.7298, validation loss: 0.8280
2024-05-25 04:34:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch121_loss0.8280251026153564.pypots
2024-05-25 04:34:41 [INFO]: Epoch 122 - training loss: 0.7395, validation loss: 0.8332
2024-05-25 04:34:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch122_loss0.8332412093877792.pypots
2024-05-25 04:34:41 [INFO]: Epoch 123 - training loss: 0.7141, validation loss: 0.8285
2024-05-25 04:34:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch123_loss0.8284848779439926.pypots
2024-05-25 04:34:41 [INFO]: Epoch 124 - training loss: 0.7556, validation loss: 0.8280
2024-05-25 04:34:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch124_loss0.8279952853918076.pypots
2024-05-25 04:34:41 [INFO]: Epoch 125 - training loss: 0.7219, validation loss: 0.8281
2024-05-25 04:34:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch125_loss0.8281351625919342.pypots
2024-05-25 04:34:42 [INFO]: Epoch 126 - training loss: 0.7168, validation loss: 0.8326
2024-05-25 04:34:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch126_loss0.8326335251331329.pypots
2024-05-25 04:34:42 [INFO]: Epoch 127 - training loss: 0.7401, validation loss: 0.8276
2024-05-25 04:34:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch127_loss0.8276226967573166.pypots
2024-05-25 04:34:42 [INFO]: Epoch 128 - training loss: 0.7791, validation loss: 0.8261
2024-05-25 04:34:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch128_loss0.8261455148458481.pypots
2024-05-25 04:34:42 [INFO]: Epoch 129 - training loss: 0.7293, validation loss: 0.8275
2024-05-25 04:34:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch129_loss0.8274590373039246.pypots
2024-05-25 04:34:42 [INFO]: Epoch 130 - training loss: 0.7205, validation loss: 0.8242
2024-05-25 04:34:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch130_loss0.8241599202156067.pypots
2024-05-25 04:34:43 [INFO]: Epoch 131 - training loss: 0.7304, validation loss: 0.8291
2024-05-25 04:34:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch131_loss0.8291305750608444.pypots
2024-05-25 04:34:43 [INFO]: Epoch 132 - training loss: 0.7447, validation loss: 0.8286
2024-05-25 04:34:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch132_loss0.8286439478397369.pypots
2024-05-25 04:34:43 [INFO]: Epoch 133 - training loss: 0.7283, validation loss: 0.8244
2024-05-25 04:34:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch133_loss0.8244063407182693.pypots
2024-05-25 04:34:43 [INFO]: Epoch 134 - training loss: 0.7296, validation loss: 0.8260
2024-05-25 04:34:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch134_loss0.8260095864534378.pypots
2024-05-25 04:34:43 [INFO]: Epoch 135 - training loss: 0.7201, validation loss: 0.8249
2024-05-25 04:34:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch135_loss0.8248983770608902.pypots
2024-05-25 04:34:44 [INFO]: Epoch 136 - training loss: 0.7106, validation loss: 0.8234
2024-05-25 04:34:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch136_loss0.8233910799026489.pypots
2024-05-25 04:34:44 [INFO]: Epoch 137 - training loss: 0.7155, validation loss: 0.8263
2024-05-25 04:34:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch137_loss0.8263201862573624.pypots
2024-05-25 04:34:44 [INFO]: Epoch 138 - training loss: 0.7254, validation loss: 0.8252
2024-05-25 04:34:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch138_loss0.8251826763153076.pypots
2024-05-25 04:34:44 [INFO]: Epoch 139 - training loss: 0.7155, validation loss: 0.8209
2024-05-25 04:34:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch139_loss0.8208680897951126.pypots
2024-05-25 04:34:44 [INFO]: Epoch 140 - training loss: 0.7234, validation loss: 0.8193
2024-05-25 04:34:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch140_loss0.819322794675827.pypots
2024-05-25 04:34:44 [INFO]: Epoch 141 - training loss: 0.7269, validation loss: 0.8180
2024-05-25 04:34:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch141_loss0.8179996758699417.pypots
2024-05-25 04:34:45 [INFO]: Epoch 142 - training loss: 0.7276, validation loss: 0.8194
2024-05-25 04:34:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch142_loss0.8194246292114258.pypots
2024-05-25 04:34:45 [INFO]: Epoch 143 - training loss: 0.7442, validation loss: 0.8207
2024-05-25 04:34:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch143_loss0.8207175731658936.pypots
2024-05-25 04:34:45 [INFO]: Epoch 144 - training loss: 0.7211, validation loss: 0.8176
2024-05-25 04:34:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch144_loss0.8175919055938721.pypots
2024-05-25 04:34:45 [INFO]: Epoch 145 - training loss: 0.7235, validation loss: 0.8179
2024-05-25 04:34:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch145_loss0.8178944438695908.pypots
2024-05-25 04:34:45 [INFO]: Epoch 146 - training loss: 0.7066, validation loss: 0.8171
2024-05-25 04:34:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch146_loss0.8171399384737015.pypots
2024-05-25 04:34:46 [INFO]: Epoch 147 - training loss: 0.7229, validation loss: 0.8161
2024-05-25 04:34:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch147_loss0.8161022365093231.pypots
2024-05-25 04:34:46 [INFO]: Epoch 148 - training loss: 0.7296, validation loss: 0.8181
2024-05-25 04:34:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch148_loss0.8180890381336212.pypots
2024-05-25 04:34:46 [INFO]: Epoch 149 - training loss: 0.7356, validation loss: 0.8164
2024-05-25 04:34:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch149_loss0.8164297044277191.pypots
2024-05-25 04:34:46 [INFO]: Epoch 150 - training loss: 0.7303, validation loss: 0.8157
2024-05-25 04:34:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch150_loss0.8157023638486862.pypots
2024-05-25 04:34:46 [INFO]: Epoch 151 - training loss: 0.7281, validation loss: 0.8161
2024-05-25 04:34:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch151_loss0.8161095529794693.pypots
2024-05-25 04:34:47 [INFO]: Epoch 152 - training loss: 0.7325, validation loss: 0.8107
2024-05-25 04:34:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch152_loss0.8106650710105896.pypots
2024-05-25 04:34:47 [INFO]: Epoch 153 - training loss: 0.7078, validation loss: 0.8140
2024-05-25 04:34:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch153_loss0.8140047490596771.pypots
2024-05-25 04:34:47 [INFO]: Epoch 154 - training loss: 0.7588, validation loss: 0.8165
2024-05-25 04:34:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch154_loss0.8165233880281448.pypots
2024-05-25 04:34:47 [INFO]: Epoch 155 - training loss: 0.7150, validation loss: 0.8100
2024-05-25 04:34:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch155_loss0.8100097328424454.pypots
2024-05-25 04:34:47 [INFO]: Epoch 156 - training loss: 0.7260, validation loss: 0.8111
2024-05-25 04:34:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch156_loss0.8111030161380768.pypots
2024-05-25 04:34:47 [INFO]: Epoch 157 - training loss: 0.7234, validation loss: 0.8111
2024-05-25 04:34:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch157_loss0.8110774010419846.pypots
2024-05-25 04:34:48 [INFO]: Epoch 158 - training loss: 0.7154, validation loss: 0.8140
2024-05-25 04:34:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch158_loss0.8140211552381516.pypots
2024-05-25 04:34:48 [INFO]: Epoch 159 - training loss: 0.7022, validation loss: 0.8113
2024-05-25 04:34:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch159_loss0.8112800121307373.pypots
2024-05-25 04:34:48 [INFO]: Epoch 160 - training loss: 0.7161, validation loss: 0.8135
2024-05-25 04:34:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch160_loss0.8134592026472092.pypots
2024-05-25 04:34:48 [INFO]: Epoch 161 - training loss: 0.7031, validation loss: 0.8138
2024-05-25 04:34:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch161_loss0.8137959390878677.pypots
2024-05-25 04:34:48 [INFO]: Epoch 162 - training loss: 0.7315, validation loss: 0.8100
2024-05-25 04:34:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch162_loss0.8100431114435196.pypots
2024-05-25 04:34:49 [INFO]: Epoch 163 - training loss: 0.7320, validation loss: 0.8133
2024-05-25 04:34:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch163_loss0.8133368790149689.pypots
2024-05-25 04:34:49 [INFO]: Epoch 164 - training loss: 0.7113, validation loss: 0.8098
2024-05-25 04:34:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch164_loss0.8097762018442154.pypots
2024-05-25 04:34:49 [INFO]: Epoch 165 - training loss: 0.7211, validation loss: 0.8073
2024-05-25 04:34:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch165_loss0.8073324710130692.pypots
2024-05-25 04:34:49 [INFO]: Epoch 166 - training loss: 0.7020, validation loss: 0.8070
2024-05-25 04:34:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch166_loss0.8069931864738464.pypots
2024-05-25 04:34:49 [INFO]: Epoch 167 - training loss: 0.7482, validation loss: 0.8084
2024-05-25 04:34:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch167_loss0.808374747633934.pypots
2024-05-25 04:34:50 [INFO]: Epoch 168 - training loss: 0.7212, validation loss: 0.8086
2024-05-25 04:34:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch168_loss0.8085666745901108.pypots
2024-05-25 04:34:50 [INFO]: Epoch 169 - training loss: 0.7089, validation loss: 0.8083
2024-05-25 04:34:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch169_loss0.8082850873470306.pypots
2024-05-25 04:34:50 [INFO]: Epoch 170 - training loss: 0.7180, validation loss: 0.8047
2024-05-25 04:34:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch170_loss0.8046553134918213.pypots
2024-05-25 04:34:50 [INFO]: Epoch 171 - training loss: 0.7254, validation loss: 0.8064
2024-05-25 04:34:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch171_loss0.8064086735248566.pypots
2024-05-25 04:34:50 [INFO]: Epoch 172 - training loss: 0.7119, validation loss: 0.8038
2024-05-25 04:34:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch172_loss0.8038200438022614.pypots
2024-05-25 04:34:50 [INFO]: Epoch 173 - training loss: 0.7203, validation loss: 0.8113
2024-05-25 04:34:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch173_loss0.8113435357809067.pypots
2024-05-25 04:34:51 [INFO]: Epoch 174 - training loss: 0.7085, validation loss: 0.8037
2024-05-25 04:34:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch174_loss0.8037114143371582.pypots
2024-05-25 04:34:51 [INFO]: Epoch 175 - training loss: 0.6964, validation loss: 0.8055
2024-05-25 04:34:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch175_loss0.8054556101560593.pypots
2024-05-25 04:34:51 [INFO]: Epoch 176 - training loss: 0.7697, validation loss: 0.8061
2024-05-25 04:34:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch176_loss0.8060922771692276.pypots
2024-05-25 04:34:51 [INFO]: Epoch 177 - training loss: 0.7304, validation loss: 0.8045
2024-05-25 04:34:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch177_loss0.804485559463501.pypots
2024-05-25 04:34:51 [INFO]: Epoch 178 - training loss: 0.7207, validation loss: 0.8034
2024-05-25 04:34:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch178_loss0.8034247606992722.pypots
2024-05-25 04:34:52 [INFO]: Epoch 179 - training loss: 0.7327, validation loss: 0.8038
2024-05-25 04:34:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch179_loss0.8037717044353485.pypots
2024-05-25 04:34:52 [INFO]: Epoch 180 - training loss: 0.7055, validation loss: 0.8023
2024-05-25 04:34:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch180_loss0.802256390452385.pypots
2024-05-25 04:34:52 [INFO]: Epoch 181 - training loss: 0.7058, validation loss: 0.7998
2024-05-25 04:34:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch181_loss0.7997963428497314.pypots
2024-05-25 04:34:52 [INFO]: Epoch 182 - training loss: 0.7220, validation loss: 0.8037
2024-05-25 04:34:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch182_loss0.8036842942237854.pypots
2024-05-25 04:34:52 [INFO]: Epoch 183 - training loss: 0.7192, validation loss: 0.8022
2024-05-25 04:34:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch183_loss0.8021737188100815.pypots
2024-05-25 04:34:53 [INFO]: Epoch 184 - training loss: 0.7066, validation loss: 0.8002
2024-05-25 04:34:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch184_loss0.8002093881368637.pypots
2024-05-25 04:34:53 [INFO]: Epoch 185 - training loss: 0.7303, validation loss: 0.8009
2024-05-25 04:34:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch185_loss0.8009065687656403.pypots
2024-05-25 04:34:53 [INFO]: Epoch 186 - training loss: 0.7174, validation loss: 0.8050
2024-05-25 04:34:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch186_loss0.8049895614385605.pypots
2024-05-25 04:34:53 [INFO]: Epoch 187 - training loss: 0.6949, validation loss: 0.8002
2024-05-25 04:34:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch187_loss0.8001857548952103.pypots
2024-05-25 04:34:53 [INFO]: Epoch 188 - training loss: 0.7063, validation loss: 0.7971
2024-05-25 04:34:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch188_loss0.7970574796199799.pypots
2024-05-25 04:34:53 [INFO]: Epoch 189 - training loss: 0.7136, validation loss: 0.8030
2024-05-25 04:34:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch189_loss0.8030341416597366.pypots
2024-05-25 04:34:54 [INFO]: Epoch 190 - training loss: 0.7213, validation loss: 0.7992
2024-05-25 04:34:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch190_loss0.7992310672998428.pypots
2024-05-25 04:34:54 [INFO]: Epoch 191 - training loss: 0.7199, validation loss: 0.7984
2024-05-25 04:34:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch191_loss0.7984434813261032.pypots
2024-05-25 04:34:54 [INFO]: Epoch 192 - training loss: 0.7404, validation loss: 0.8017
2024-05-25 04:34:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch192_loss0.8017344027757645.pypots
2024-05-25 04:34:54 [INFO]: Epoch 193 - training loss: 0.7303, validation loss: 0.7984
2024-05-25 04:34:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch193_loss0.7983727604150772.pypots
2024-05-25 04:34:54 [INFO]: Epoch 194 - training loss: 0.7223, validation loss: 0.8012
2024-05-25 04:34:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch194_loss0.8011916875839233.pypots
2024-05-25 04:34:55 [INFO]: Epoch 195 - training loss: 0.7124, validation loss: 0.7982
2024-05-25 04:34:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch195_loss0.7982156276702881.pypots
2024-05-25 04:34:55 [INFO]: Epoch 196 - training loss: 0.7245, validation loss: 0.7983
2024-05-25 04:34:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch196_loss0.7982819080352783.pypots
2024-05-25 04:34:55 [INFO]: Epoch 197 - training loss: 0.7197, validation loss: 0.7966
2024-05-25 04:34:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch197_loss0.7966069579124451.pypots
2024-05-25 04:34:55 [INFO]: Epoch 198 - training loss: 0.7150, validation loss: 0.7970
2024-05-25 04:34:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch198_loss0.7969933301210403.pypots
2024-05-25 04:34:55 [INFO]: Epoch 199 - training loss: 0.7051, validation loss: 0.7968
2024-05-25 04:34:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch199_loss0.7967578023672104.pypots
2024-05-25 04:34:56 [INFO]: Epoch 200 - training loss: 0.7128, validation loss: 0.7982
2024-05-25 04:34:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch200_loss0.798214465379715.pypots
2024-05-25 04:34:56 [INFO]: Epoch 201 - training loss: 0.6958, validation loss: 0.7949
2024-05-25 04:34:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch201_loss0.7948778718709946.pypots
2024-05-25 04:34:56 [INFO]: Epoch 202 - training loss: 0.6956, validation loss: 0.7961
2024-05-25 04:34:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch202_loss0.7961411029100418.pypots
2024-05-25 04:34:56 [INFO]: Epoch 203 - training loss: 0.7191, validation loss: 0.7970
2024-05-25 04:34:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch203_loss0.7970350384712219.pypots
2024-05-25 04:34:56 [INFO]: Epoch 204 - training loss: 0.7236, validation loss: 0.7979
2024-05-25 04:34:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch204_loss0.7979116588830948.pypots
2024-05-25 04:34:56 [INFO]: Epoch 205 - training loss: 0.7247, validation loss: 0.7954
2024-05-25 04:34:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch205_loss0.7953940629959106.pypots
2024-05-25 04:34:57 [INFO]: Epoch 206 - training loss: 0.7128, validation loss: 0.7941
2024-05-25 04:34:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch206_loss0.7940833121538162.pypots
2024-05-25 04:34:57 [INFO]: Epoch 207 - training loss: 0.7220, validation loss: 0.7946
2024-05-25 04:34:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch207_loss0.7946068346500397.pypots
2024-05-25 04:34:57 [INFO]: Epoch 208 - training loss: 0.6932, validation loss: 0.7955
2024-05-25 04:34:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch208_loss0.7955016046762466.pypots
2024-05-25 04:34:57 [INFO]: Epoch 209 - training loss: 0.7000, validation loss: 0.7938
2024-05-25 04:34:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch209_loss0.793829619884491.pypots
2024-05-25 04:34:57 [INFO]: Epoch 210 - training loss: 0.7590, validation loss: 0.7970
2024-05-25 04:34:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch210_loss0.7969692200422287.pypots
2024-05-25 04:34:58 [INFO]: Epoch 211 - training loss: 0.7385, validation loss: 0.8003
2024-05-25 04:34:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch211_loss0.8002896755933762.pypots
2024-05-25 04:34:58 [INFO]: Epoch 212 - training loss: 0.7162, validation loss: 0.7930
2024-05-25 04:34:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch212_loss0.7930280119180679.pypots
2024-05-25 04:34:58 [INFO]: Epoch 213 - training loss: 0.7210, validation loss: 0.7926
2024-05-25 04:34:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch213_loss0.792646586894989.pypots
2024-05-25 04:34:58 [INFO]: Epoch 214 - training loss: 0.7112, validation loss: 0.7936
2024-05-25 04:34:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch214_loss0.7936112135648727.pypots
2024-05-25 04:34:58 [INFO]: Epoch 215 - training loss: 0.7145, validation loss: 0.7924
2024-05-25 04:34:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch215_loss0.7924303710460663.pypots
2024-05-25 04:34:59 [INFO]: Epoch 216 - training loss: 0.7206, validation loss: 0.7958
2024-05-25 04:34:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch216_loss0.7958498001098633.pypots
2024-05-25 04:34:59 [INFO]: Epoch 217 - training loss: 0.7212, validation loss: 0.7996
2024-05-25 04:34:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch217_loss0.7995658963918686.pypots
2024-05-25 04:34:59 [INFO]: Epoch 218 - training loss: 0.7289, validation loss: 0.7950
2024-05-25 04:34:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch218_loss0.7950029373168945.pypots
2024-05-25 04:34:59 [INFO]: Epoch 219 - training loss: 0.7082, validation loss: 0.7942
2024-05-25 04:34:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch219_loss0.7941626757383347.pypots
2024-05-25 04:34:59 [INFO]: Epoch 220 - training loss: 0.7007, validation loss: 0.7926
2024-05-25 04:34:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch220_loss0.7925504744052887.pypots
2024-05-25 04:34:59 [INFO]: Epoch 221 - training loss: 0.7200, validation loss: 0.7947
2024-05-25 04:34:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch221_loss0.7946500927209854.pypots
2024-05-25 04:35:00 [INFO]: Epoch 222 - training loss: 0.7067, validation loss: 0.7923
2024-05-25 04:35:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch222_loss0.7922619879245758.pypots
2024-05-25 04:35:00 [INFO]: Epoch 223 - training loss: 0.7013, validation loss: 0.7917
2024-05-25 04:35:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch223_loss0.7917428612709045.pypots
2024-05-25 04:35:00 [INFO]: Epoch 224 - training loss: 0.7210, validation loss: 0.7921
2024-05-25 04:35:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch224_loss0.7921336442232132.pypots
2024-05-25 04:35:00 [INFO]: Epoch 225 - training loss: 0.7178, validation loss: 0.7926
2024-05-25 04:35:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch225_loss0.7925653457641602.pypots
2024-05-25 04:35:00 [INFO]: Epoch 226 - training loss: 0.7215, validation loss: 0.7927
2024-05-25 04:35:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch226_loss0.7927184253931046.pypots
2024-05-25 04:35:01 [INFO]: Epoch 227 - training loss: 0.7403, validation loss: 0.7908
2024-05-25 04:35:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch227_loss0.7908171862363815.pypots
2024-05-25 04:35:01 [INFO]: Epoch 228 - training loss: 0.7206, validation loss: 0.7904
2024-05-25 04:35:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch228_loss0.7903817445039749.pypots
2024-05-25 04:35:01 [INFO]: Epoch 229 - training loss: 0.7134, validation loss: 0.7920
2024-05-25 04:35:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch229_loss0.7919773906469345.pypots
2024-05-25 04:35:01 [INFO]: Epoch 230 - training loss: 0.7463, validation loss: 0.7908
2024-05-25 04:35:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch230_loss0.7907674163579941.pypots
2024-05-25 04:35:01 [INFO]: Epoch 231 - training loss: 0.7224, validation loss: 0.7887
2024-05-25 04:35:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch231_loss0.7887077927589417.pypots
2024-05-25 04:35:02 [INFO]: Epoch 232 - training loss: 0.7202, validation loss: 0.7863
2024-05-25 04:35:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch232_loss0.7862749397754669.pypots
2024-05-25 04:35:02 [INFO]: Epoch 233 - training loss: 0.7239, validation loss: 0.7919
2024-05-25 04:35:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch233_loss0.7918849438428879.pypots
2024-05-25 04:35:02 [INFO]: Epoch 234 - training loss: 0.7245, validation loss: 0.7919
2024-05-25 04:35:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch234_loss0.791865885257721.pypots
2024-05-25 04:35:02 [INFO]: Epoch 235 - training loss: 0.7245, validation loss: 0.7893
2024-05-25 04:35:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch235_loss0.7893157750368118.pypots
2024-05-25 04:35:02 [INFO]: Epoch 236 - training loss: 0.7086, validation loss: 0.7926
2024-05-25 04:35:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch236_loss0.7926233857870102.pypots
2024-05-25 04:35:03 [INFO]: Epoch 237 - training loss: 0.7059, validation loss: 0.7897
2024-05-25 04:35:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch237_loss0.7897140681743622.pypots
2024-05-25 04:35:03 [INFO]: Epoch 238 - training loss: 0.6977, validation loss: 0.7915
2024-05-25 04:35:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch238_loss0.7915314733982086.pypots
2024-05-25 04:35:03 [INFO]: Epoch 239 - training loss: 0.7351, validation loss: 0.7907
2024-05-25 04:35:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch239_loss0.7907030582427979.pypots
2024-05-25 04:35:03 [INFO]: Epoch 240 - training loss: 0.7094, validation loss: 0.7886
2024-05-25 04:35:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch240_loss0.7885797470808029.pypots
2024-05-25 04:35:03 [INFO]: Epoch 241 - training loss: 0.7046, validation loss: 0.7890
2024-05-25 04:35:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch241_loss0.7889598906040192.pypots
2024-05-25 04:35:03 [INFO]: Epoch 242 - training loss: 0.6967, validation loss: 0.7894
2024-05-25 04:35:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN_epoch242_loss0.78936967253685.pypots
2024-05-25 04:35:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:35:03 [INFO]: Finished training. The best model is from epoch#232.
2024-05-25 04:35:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T043416/MRNN.pypots
2024-05-25 04:35:04 [INFO]: MRNN on ETTm1: MAE=0.5770, MSE=0.9681
2024-05-25 04:35:04 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/MRNN_ettm1/imputation.pkl
2024-05-25 04:35:04 [INFO]: Using the given device: cpu
2024-05-25 04:35:04 [INFO]: LOCF on ETTm1: MAE=0.1420, MSE=0.0788
2024-05-25 04:35:04 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_ettm1".
2024-05-25 04:35:04 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/LOCF_ettm1/imputation.pkl
2024-05-25 04:35:04 [INFO]: Median on ETTm1: MAE=0.6533, MSE=0.8148
2024-05-25 04:35:04 [INFO]: Successfully created the given path "saved_results/round_2/Median_ettm1".
2024-05-25 04:35:04 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Median_ettm1/imputation.pkl
2024-05-25 04:35:04 [INFO]: Mean on ETTm1: MAE=0.6593, MSE=0.7994
2024-05-25 04:35:04 [INFO]: Successfully created the given path "saved_results/round_2/Mean_ettm1".
2024-05-25 04:35:04 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Mean_ettm1/imputation.pkl
2024-05-25 04:35:04 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-25 04:35:04 [INFO]: Using the given device: cuda:0
2024-05-25 04:35:04 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/SAITS_ettm1/20240525_T043504
2024-05-25 04:35:04 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/SAITS_ettm1/20240525_T043504/tensorboard
2024-05-25 04:35:04 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 04:35:04 [INFO]: Epoch 001 - training loss: 1.1848, validation loss: 0.2920
2024-05-25 04:35:05 [INFO]: Epoch 002 - training loss: 0.8455, validation loss: 0.1907
2024-05-25 04:35:05 [INFO]: Epoch 003 - training loss: 0.7586, validation loss: 0.1083
2024-05-25 04:35:06 [INFO]: Epoch 004 - training loss: 0.6945, validation loss: 0.0974
2024-05-25 04:35:06 [INFO]: Epoch 005 - training loss: 0.6611, validation loss: 0.0941
2024-05-25 04:35:07 [INFO]: Epoch 006 - training loss: 0.6393, validation loss: 0.0853
2024-05-25 04:35:07 [INFO]: Epoch 007 - training loss: 0.6192, validation loss: 0.0862
2024-05-25 04:35:08 [INFO]: Epoch 008 - training loss: 0.6023, validation loss: 0.0651
2024-05-25 04:35:08 [INFO]: Epoch 009 - training loss: 0.5930, validation loss: 0.0715
2024-05-25 04:35:09 [INFO]: Epoch 010 - training loss: 0.5856, validation loss: 0.0610
2024-05-25 04:35:09 [INFO]: Epoch 011 - training loss: 0.5716, validation loss: 0.0598
2024-05-25 04:35:10 [INFO]: Epoch 012 - training loss: 0.5632, validation loss: 0.0641
2024-05-25 04:35:10 [INFO]: Epoch 013 - training loss: 0.5494, validation loss: 0.0559
2024-05-25 04:35:11 [INFO]: Epoch 014 - training loss: 0.5354, validation loss: 0.0535
2024-05-25 04:35:11 [INFO]: Epoch 015 - training loss: 0.5380, validation loss: 0.0492
2024-05-25 04:35:12 [INFO]: Epoch 016 - training loss: 0.5465, validation loss: 0.0525
2024-05-25 04:35:12 [INFO]: Epoch 017 - training loss: 0.5365, validation loss: 0.0442
2024-05-25 04:35:13 [INFO]: Epoch 018 - training loss: 0.5283, validation loss: 0.0458
2024-05-25 04:35:13 [INFO]: Epoch 019 - training loss: 0.5294, validation loss: 0.0462
2024-05-25 04:35:14 [INFO]: Epoch 020 - training loss: 0.5171, validation loss: 0.0556
2024-05-25 04:35:14 [INFO]: Epoch 021 - training loss: 0.5065, validation loss: 0.0604
2024-05-25 04:35:15 [INFO]: Epoch 022 - training loss: 0.5000, validation loss: 0.0430
2024-05-25 04:35:15 [INFO]: Epoch 023 - training loss: 0.4878, validation loss: 0.0407
2024-05-25 04:35:16 [INFO]: Epoch 024 - training loss: 0.4927, validation loss: 0.0505
2024-05-25 04:35:16 [INFO]: Epoch 025 - training loss: 0.4981, validation loss: 0.0482
2024-05-25 04:35:17 [INFO]: Epoch 026 - training loss: 0.4828, validation loss: 0.0388
2024-05-25 04:35:17 [INFO]: Epoch 027 - training loss: 0.4912, validation loss: 0.0563
2024-05-25 04:35:18 [INFO]: Epoch 028 - training loss: 0.4865, validation loss: 0.0491
2024-05-25 04:35:18 [INFO]: Epoch 029 - training loss: 0.4686, validation loss: 0.0453
2024-05-25 04:35:19 [INFO]: Epoch 030 - training loss: 0.4658, validation loss: 0.0632
2024-05-25 04:35:19 [INFO]: Epoch 031 - training loss: 0.4596, validation loss: 0.0370
2024-05-25 04:35:20 [INFO]: Epoch 032 - training loss: 0.4588, validation loss: 0.0448
2024-05-25 04:35:20 [INFO]: Epoch 033 - training loss: 0.4554, validation loss: 0.0502
2024-05-25 04:35:20 [INFO]: Epoch 034 - training loss: 0.4642, validation loss: 0.0449
2024-05-25 04:35:21 [INFO]: Epoch 035 - training loss: 0.4695, validation loss: 0.0448
2024-05-25 04:35:21 [INFO]: Epoch 036 - training loss: 0.4655, validation loss: 0.0523
2024-05-25 04:35:22 [INFO]: Epoch 037 - training loss: 0.4657, validation loss: 0.0489
2024-05-25 04:35:22 [INFO]: Epoch 038 - training loss: 0.4500, validation loss: 0.0367
2024-05-25 04:35:23 [INFO]: Epoch 039 - training loss: 0.4312, validation loss: 0.0415
2024-05-25 04:35:23 [INFO]: Epoch 040 - training loss: 0.4430, validation loss: 0.0387
2024-05-25 04:35:24 [INFO]: Epoch 041 - training loss: 0.4419, validation loss: 0.0388
2024-05-25 04:35:24 [INFO]: Epoch 042 - training loss: 0.4236, validation loss: 0.0365
2024-05-25 04:35:25 [INFO]: Epoch 043 - training loss: 0.4359, validation loss: 0.0416
2024-05-25 04:35:25 [INFO]: Epoch 044 - training loss: 0.4380, validation loss: 0.0555
2024-05-25 04:35:26 [INFO]: Epoch 045 - training loss: 0.4402, validation loss: 0.0359
2024-05-25 04:35:26 [INFO]: Epoch 046 - training loss: 0.4259, validation loss: 0.0415
2024-05-25 04:35:27 [INFO]: Epoch 047 - training loss: 0.4229, validation loss: 0.0452
2024-05-25 04:35:27 [INFO]: Epoch 048 - training loss: 0.4430, validation loss: 0.0441
2024-05-25 04:35:28 [INFO]: Epoch 049 - training loss: 0.4180, validation loss: 0.0364
2024-05-25 04:35:28 [INFO]: Epoch 050 - training loss: 0.4189, validation loss: 0.0380
2024-05-25 04:35:29 [INFO]: Epoch 051 - training loss: 0.4070, validation loss: 0.0373
2024-05-25 04:35:29 [INFO]: Epoch 052 - training loss: 0.4051, validation loss: 0.0338
2024-05-25 04:35:30 [INFO]: Epoch 053 - training loss: 0.4086, validation loss: 0.0365
2024-05-25 04:35:30 [INFO]: Epoch 054 - training loss: 0.4035, validation loss: 0.0359
2024-05-25 04:35:31 [INFO]: Epoch 055 - training loss: 0.4019, validation loss: 0.0330
2024-05-25 04:35:31 [INFO]: Epoch 056 - training loss: 0.4123, validation loss: 0.0464
2024-05-25 04:35:32 [INFO]: Epoch 057 - training loss: 0.3993, validation loss: 0.0403
2024-05-25 04:35:32 [INFO]: Epoch 058 - training loss: 0.3864, validation loss: 0.0498
2024-05-25 04:35:33 [INFO]: Epoch 059 - training loss: 0.3872, validation loss: 0.0372
2024-05-25 04:35:33 [INFO]: Epoch 060 - training loss: 0.3805, validation loss: 0.0362
2024-05-25 04:35:34 [INFO]: Epoch 061 - training loss: 0.3971, validation loss: 0.0439
2024-05-25 04:35:34 [INFO]: Epoch 062 - training loss: 0.3806, validation loss: 0.0390
2024-05-25 04:35:35 [INFO]: Epoch 063 - training loss: 0.3799, validation loss: 0.0357
2024-05-25 04:35:35 [INFO]: Epoch 064 - training loss: 0.3753, validation loss: 0.0378
2024-05-25 04:35:36 [INFO]: Epoch 065 - training loss: 0.3729, validation loss: 0.0374
2024-05-25 04:35:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:35:36 [INFO]: Finished training. The best model is from epoch#55.
2024-05-25 04:35:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/SAITS_ettm1/20240525_T043504/SAITS.pypots
2024-05-25 04:35:36 [INFO]: SAITS on ETTm1: MAE=0.1450, MSE=0.0390
2024-05-25 04:35:36 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/SAITS_ettm1/imputation.pkl
2024-05-25 04:35:36 [INFO]: Using the given device: cuda:0
2024-05-25 04:35:36 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/Transformer_ettm1/20240525_T043536
2024-05-25 04:35:36 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/Transformer_ettm1/20240525_T043536/tensorboard
2024-05-25 04:35:36 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 04:35:36 [INFO]: Epoch 001 - training loss: 1.1586, validation loss: 0.3478
2024-05-25 04:35:36 [INFO]: Epoch 002 - training loss: 0.7068, validation loss: 0.1789
2024-05-25 04:35:36 [INFO]: Epoch 003 - training loss: 0.5747, validation loss: 0.1312
2024-05-25 04:35:36 [INFO]: Epoch 004 - training loss: 0.5146, validation loss: 0.1063
2024-05-25 04:35:37 [INFO]: Epoch 005 - training loss: 0.4829, validation loss: 0.0915
2024-05-25 04:35:37 [INFO]: Epoch 006 - training loss: 0.4521, validation loss: 0.0862
2024-05-25 04:35:37 [INFO]: Epoch 007 - training loss: 0.4441, validation loss: 0.0807
2024-05-25 04:35:37 [INFO]: Epoch 008 - training loss: 0.4264, validation loss: 0.0711
2024-05-25 04:35:37 [INFO]: Epoch 009 - training loss: 0.4110, validation loss: 0.0703
2024-05-25 04:35:38 [INFO]: Epoch 010 - training loss: 0.3887, validation loss: 0.0606
2024-05-25 04:35:38 [INFO]: Epoch 011 - training loss: 0.3831, validation loss: 0.0610
2024-05-25 04:35:38 [INFO]: Epoch 012 - training loss: 0.3715, validation loss: 0.0553
2024-05-25 04:35:38 [INFO]: Epoch 013 - training loss: 0.3556, validation loss: 0.0593
2024-05-25 04:35:38 [INFO]: Epoch 014 - training loss: 0.3517, validation loss: 0.0522
2024-05-25 04:35:39 [INFO]: Epoch 015 - training loss: 0.3394, validation loss: 0.0505
2024-05-25 04:35:39 [INFO]: Epoch 016 - training loss: 0.3298, validation loss: 0.0484
2024-05-25 04:35:39 [INFO]: Epoch 017 - training loss: 0.3266, validation loss: 0.0509
2024-05-25 04:35:39 [INFO]: Epoch 018 - training loss: 0.3214, validation loss: 0.0468
2024-05-25 04:35:39 [INFO]: Epoch 019 - training loss: 0.3191, validation loss: 0.0441
2024-05-25 04:35:40 [INFO]: Epoch 020 - training loss: 0.3093, validation loss: 0.0456
2024-05-25 04:35:40 [INFO]: Epoch 021 - training loss: 0.3072, validation loss: 0.0443
2024-05-25 04:35:40 [INFO]: Epoch 022 - training loss: 0.3025, validation loss: 0.0432
2024-05-25 04:35:40 [INFO]: Epoch 023 - training loss: 0.2960, validation loss: 0.0445
2024-05-25 04:35:40 [INFO]: Epoch 024 - training loss: 0.2939, validation loss: 0.0414
2024-05-25 04:35:41 [INFO]: Epoch 025 - training loss: 0.2905, validation loss: 0.0392
2024-05-25 04:35:41 [INFO]: Epoch 026 - training loss: 0.2840, validation loss: 0.0381
2024-05-25 04:35:41 [INFO]: Epoch 027 - training loss: 0.2812, validation loss: 0.0404
2024-05-25 04:35:41 [INFO]: Epoch 028 - training loss: 0.2808, validation loss: 0.0387
2024-05-25 04:35:41 [INFO]: Epoch 029 - training loss: 0.2775, validation loss: 0.0409
2024-05-25 04:35:42 [INFO]: Epoch 030 - training loss: 0.2796, validation loss: 0.0411
2024-05-25 04:35:42 [INFO]: Epoch 031 - training loss: 0.2769, validation loss: 0.0388
2024-05-25 04:35:42 [INFO]: Epoch 032 - training loss: 0.2708, validation loss: 0.0395
2024-05-25 04:35:42 [INFO]: Epoch 033 - training loss: 0.2698, validation loss: 0.0352
2024-05-25 04:35:42 [INFO]: Epoch 034 - training loss: 0.2584, validation loss: 0.0371
2024-05-25 04:35:43 [INFO]: Epoch 035 - training loss: 0.2597, validation loss: 0.0348
2024-05-25 04:35:43 [INFO]: Epoch 036 - training loss: 0.2563, validation loss: 0.0353
2024-05-25 04:35:43 [INFO]: Epoch 037 - training loss: 0.2508, validation loss: 0.0353
2024-05-25 04:35:43 [INFO]: Epoch 038 - training loss: 0.2494, validation loss: 0.0326
2024-05-25 04:35:43 [INFO]: Epoch 039 - training loss: 0.2480, validation loss: 0.0386
2024-05-25 04:35:43 [INFO]: Epoch 040 - training loss: 0.2515, validation loss: 0.0337
2024-05-25 04:35:44 [INFO]: Epoch 041 - training loss: 0.2458, validation loss: 0.0335
2024-05-25 04:35:44 [INFO]: Epoch 042 - training loss: 0.2417, validation loss: 0.0313
2024-05-25 04:35:44 [INFO]: Epoch 043 - training loss: 0.2368, validation loss: 0.0326
2024-05-25 04:35:44 [INFO]: Epoch 044 - training loss: 0.2379, validation loss: 0.0297
2024-05-25 04:35:44 [INFO]: Epoch 045 - training loss: 0.2331, validation loss: 0.0333
2024-05-25 04:35:45 [INFO]: Epoch 046 - training loss: 0.2312, validation loss: 0.0325
2024-05-25 04:35:45 [INFO]: Epoch 047 - training loss: 0.2375, validation loss: 0.0290
2024-05-25 04:35:45 [INFO]: Epoch 048 - training loss: 0.2252, validation loss: 0.0308
2024-05-25 04:35:45 [INFO]: Epoch 049 - training loss: 0.2252, validation loss: 0.0318
2024-05-25 04:35:45 [INFO]: Epoch 050 - training loss: 0.2316, validation loss: 0.0367
2024-05-25 04:35:46 [INFO]: Epoch 051 - training loss: 0.2356, validation loss: 0.0289
2024-05-25 04:35:46 [INFO]: Epoch 052 - training loss: 0.2209, validation loss: 0.0339
2024-05-25 04:35:46 [INFO]: Epoch 053 - training loss: 0.2325, validation loss: 0.0289
2024-05-25 04:35:46 [INFO]: Epoch 054 - training loss: 0.2278, validation loss: 0.0313
2024-05-25 04:35:46 [INFO]: Epoch 055 - training loss: 0.2295, validation loss: 0.0279
2024-05-25 04:35:47 [INFO]: Epoch 056 - training loss: 0.2257, validation loss: 0.0324
2024-05-25 04:35:47 [INFO]: Epoch 057 - training loss: 0.2290, validation loss: 0.0308
2024-05-25 04:35:47 [INFO]: Epoch 058 - training loss: 0.2211, validation loss: 0.0270
2024-05-25 04:35:47 [INFO]: Epoch 059 - training loss: 0.2132, validation loss: 0.0294
2024-05-25 04:35:47 [INFO]: Epoch 060 - training loss: 0.2180, validation loss: 0.0266
2024-05-25 04:35:48 [INFO]: Epoch 061 - training loss: 0.2085, validation loss: 0.0276
2024-05-25 04:35:48 [INFO]: Epoch 062 - training loss: 0.2106, validation loss: 0.0266
2024-05-25 04:35:48 [INFO]: Epoch 063 - training loss: 0.2089, validation loss: 0.0289
2024-05-25 04:35:48 [INFO]: Epoch 064 - training loss: 0.2129, validation loss: 0.0304
2024-05-25 04:35:48 [INFO]: Epoch 065 - training loss: 0.2072, validation loss: 0.0255
2024-05-25 04:35:49 [INFO]: Epoch 066 - training loss: 0.2036, validation loss: 0.0265
2024-05-25 04:35:49 [INFO]: Epoch 067 - training loss: 0.2028, validation loss: 0.0250
2024-05-25 04:35:49 [INFO]: Epoch 068 - training loss: 0.2006, validation loss: 0.0259
2024-05-25 04:35:49 [INFO]: Epoch 069 - training loss: 0.2051, validation loss: 0.0257
2024-05-25 04:35:49 [INFO]: Epoch 070 - training loss: 0.2011, validation loss: 0.0282
2024-05-25 04:35:49 [INFO]: Epoch 071 - training loss: 0.2020, validation loss: 0.0296
2024-05-25 04:35:50 [INFO]: Epoch 072 - training loss: 0.2059, validation loss: 0.0248
2024-05-25 04:35:50 [INFO]: Epoch 073 - training loss: 0.2004, validation loss: 0.0258
2024-05-25 04:35:50 [INFO]: Epoch 074 - training loss: 0.1970, validation loss: 0.0248
2024-05-25 04:35:50 [INFO]: Epoch 075 - training loss: 0.1966, validation loss: 0.0254
2024-05-25 04:35:50 [INFO]: Epoch 076 - training loss: 0.1926, validation loss: 0.0309
2024-05-25 04:35:51 [INFO]: Epoch 077 - training loss: 0.2002, validation loss: 0.0269
2024-05-25 04:35:51 [INFO]: Epoch 078 - training loss: 0.2054, validation loss: 0.0260
2024-05-25 04:35:51 [INFO]: Epoch 079 - training loss: 0.1989, validation loss: 0.0264
2024-05-25 04:35:51 [INFO]: Epoch 080 - training loss: 0.1963, validation loss: 0.0239
2024-05-25 04:35:51 [INFO]: Epoch 081 - training loss: 0.1974, validation loss: 0.0254
2024-05-25 04:35:52 [INFO]: Epoch 082 - training loss: 0.1901, validation loss: 0.0284
2024-05-25 04:35:52 [INFO]: Epoch 083 - training loss: 0.1986, validation loss: 0.0283
2024-05-25 04:35:52 [INFO]: Epoch 084 - training loss: 0.1990, validation loss: 0.0247
2024-05-25 04:35:52 [INFO]: Epoch 085 - training loss: 0.1963, validation loss: 0.0246
2024-05-25 04:35:52 [INFO]: Epoch 086 - training loss: 0.2056, validation loss: 0.0255
2024-05-25 04:35:53 [INFO]: Epoch 087 - training loss: 0.1961, validation loss: 0.0251
2024-05-25 04:35:53 [INFO]: Epoch 088 - training loss: 0.1914, validation loss: 0.0265
2024-05-25 04:35:53 [INFO]: Epoch 089 - training loss: 0.1904, validation loss: 0.0249
2024-05-25 04:35:53 [INFO]: Epoch 090 - training loss: 0.1904, validation loss: 0.0239
2024-05-25 04:35:53 [INFO]: Epoch 091 - training loss: 0.1878, validation loss: 0.0242
2024-05-25 04:35:54 [INFO]: Epoch 092 - training loss: 0.1890, validation loss: 0.0263
2024-05-25 04:35:54 [INFO]: Epoch 093 - training loss: 0.1894, validation loss: 0.0253
2024-05-25 04:35:54 [INFO]: Epoch 094 - training loss: 0.1908, validation loss: 0.0242
2024-05-25 04:35:54 [INFO]: Epoch 095 - training loss: 0.1933, validation loss: 0.0247
2024-05-25 04:35:54 [INFO]: Epoch 096 - training loss: 0.1898, validation loss: 0.0276
2024-05-25 04:35:55 [INFO]: Epoch 097 - training loss: 0.1933, validation loss: 0.0250
2024-05-25 04:35:55 [INFO]: Epoch 098 - training loss: 0.1876, validation loss: 0.0247
2024-05-25 04:35:55 [INFO]: Epoch 099 - training loss: 0.1859, validation loss: 0.0249
2024-05-25 04:35:55 [INFO]: Epoch 100 - training loss: 0.1849, validation loss: 0.0264
2024-05-25 04:35:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:35:55 [INFO]: Finished training. The best model is from epoch#90.
2024-05-25 04:35:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/Transformer_ettm1/20240525_T043536/Transformer.pypots
2024-05-25 04:35:55 [INFO]: Transformer on ETTm1: MAE=0.1350, MSE=0.0364
2024-05-25 04:35:55 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Transformer_ettm1/imputation.pkl
2024-05-25 04:35:55 [INFO]: Using the given device: cuda:0
2024-05-25 04:35:55 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/TimesNet_ettm1/20240525_T043555
2024-05-25 04:35:55 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/TimesNet_ettm1/20240525_T043555/tensorboard
2024-05-25 04:35:55 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 04:35:56 [INFO]: Epoch 001 - training loss: 0.1775, validation loss: 0.0655
2024-05-25 04:35:56 [INFO]: Epoch 002 - training loss: 0.0725, validation loss: 0.0458
2024-05-25 04:35:56 [INFO]: Epoch 003 - training loss: 0.0556, validation loss: 0.0391
2024-05-25 04:35:56 [INFO]: Epoch 004 - training loss: 0.0475, validation loss: 0.0343
2024-05-25 04:35:56 [INFO]: Epoch 005 - training loss: 0.0424, validation loss: 0.0330
2024-05-25 04:35:56 [INFO]: Epoch 006 - training loss: 0.0414, validation loss: 0.0323
2024-05-25 04:35:57 [INFO]: Epoch 007 - training loss: 0.0393, validation loss: 0.0318
2024-05-25 04:35:57 [INFO]: Epoch 008 - training loss: 0.0396, validation loss: 0.0319
2024-05-25 04:35:57 [INFO]: Epoch 009 - training loss: 0.0394, validation loss: 0.0312
2024-05-25 04:35:57 [INFO]: Epoch 010 - training loss: 0.0386, validation loss: 0.0302
2024-05-25 04:35:57 [INFO]: Epoch 011 - training loss: 0.0371, validation loss: 0.0309
2024-05-25 04:35:58 [INFO]: Epoch 012 - training loss: 0.0368, validation loss: 0.0298
2024-05-25 04:35:58 [INFO]: Epoch 013 - training loss: 0.0367, validation loss: 0.0310
2024-05-25 04:35:58 [INFO]: Epoch 014 - training loss: 0.0388, validation loss: 0.0302
2024-05-25 04:35:58 [INFO]: Epoch 015 - training loss: 0.0371, validation loss: 0.0299
2024-05-25 04:35:58 [INFO]: Epoch 016 - training loss: 0.0374, validation loss: 0.0308
2024-05-25 04:35:59 [INFO]: Epoch 017 - training loss: 0.0391, validation loss: 0.0300
2024-05-25 04:35:59 [INFO]: Epoch 018 - training loss: 0.0356, validation loss: 0.0287
2024-05-25 04:35:59 [INFO]: Epoch 019 - training loss: 0.0331, validation loss: 0.0287
2024-05-25 04:35:59 [INFO]: Epoch 020 - training loss: 0.0328, validation loss: 0.0289
2024-05-25 04:35:59 [INFO]: Epoch 021 - training loss: 0.0348, validation loss: 0.0301
2024-05-25 04:35:59 [INFO]: Epoch 022 - training loss: 0.0333, validation loss: 0.0293
2024-05-25 04:36:00 [INFO]: Epoch 023 - training loss: 0.0327, validation loss: 0.0295
2024-05-25 04:36:00 [INFO]: Epoch 024 - training loss: 0.0313, validation loss: 0.0281
2024-05-25 04:36:00 [INFO]: Epoch 025 - training loss: 0.0308, validation loss: 0.0285
2024-05-25 04:36:00 [INFO]: Epoch 026 - training loss: 0.0340, validation loss: 0.0284
2024-05-25 04:36:00 [INFO]: Epoch 027 - training loss: 0.0325, validation loss: 0.0296
2024-05-25 04:36:01 [INFO]: Epoch 028 - training loss: 0.0343, validation loss: 0.0293
2024-05-25 04:36:01 [INFO]: Epoch 029 - training loss: 0.0304, validation loss: 0.0281
2024-05-25 04:36:01 [INFO]: Epoch 030 - training loss: 0.0298, validation loss: 0.0285
2024-05-25 04:36:01 [INFO]: Epoch 031 - training loss: 0.0321, validation loss: 0.0283
2024-05-25 04:36:01 [INFO]: Epoch 032 - training loss: 0.0303, validation loss: 0.0278
2024-05-25 04:36:02 [INFO]: Epoch 033 - training loss: 0.0280, validation loss: 0.0282
2024-05-25 04:36:02 [INFO]: Epoch 034 - training loss: 0.0286, validation loss: 0.0284
2024-05-25 04:36:02 [INFO]: Epoch 035 - training loss: 0.0282, validation loss: 0.0271
2024-05-25 04:36:02 [INFO]: Epoch 036 - training loss: 0.0263, validation loss: 0.0271
2024-05-25 04:36:02 [INFO]: Epoch 037 - training loss: 0.0255, validation loss: 0.0277
2024-05-25 04:36:02 [INFO]: Epoch 038 - training loss: 0.0270, validation loss: 0.0281
2024-05-25 04:36:03 [INFO]: Epoch 039 - training loss: 0.0279, validation loss: 0.0280
2024-05-25 04:36:03 [INFO]: Epoch 040 - training loss: 0.0265, validation loss: 0.0278
2024-05-25 04:36:03 [INFO]: Epoch 041 - training loss: 0.0281, validation loss: 0.0277
2024-05-25 04:36:03 [INFO]: Epoch 042 - training loss: 0.0282, validation loss: 0.0326
2024-05-25 04:36:03 [INFO]: Epoch 043 - training loss: 0.0319, validation loss: 0.0300
2024-05-25 04:36:04 [INFO]: Epoch 044 - training loss: 0.0274, validation loss: 0.0279
2024-05-25 04:36:04 [INFO]: Epoch 045 - training loss: 0.0248, validation loss: 0.0273
2024-05-25 04:36:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:36:04 [INFO]: Finished training. The best model is from epoch#35.
2024-05-25 04:36:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/TimesNet_ettm1/20240525_T043555/TimesNet.pypots
2024-05-25 04:36:04 [INFO]: TimesNet on ETTm1: MAE=0.1140, MSE=0.0286
2024-05-25 04:36:04 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/TimesNet_ettm1/imputation.pkl
2024-05-25 04:36:04 [INFO]: Using the given device: cuda:0
2024-05-25 04:36:04 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604
2024-05-25 04:36:04 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/tensorboard
2024-05-25 04:36:04 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 04:36:06 [INFO]: Epoch 001 - training loss: 0.6819, validation loss: 0.5058
2024-05-25 04:36:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch1_loss0.5058331415057182.pypots
2024-05-25 04:36:08 [INFO]: Epoch 002 - training loss: 0.4835, validation loss: 0.3614
2024-05-25 04:36:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch2_loss0.3614071160554886.pypots
2024-05-25 04:36:10 [INFO]: Epoch 003 - training loss: 0.3782, validation loss: 0.3427
2024-05-25 04:36:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch3_loss0.34274475276470184.pypots
2024-05-25 04:36:12 [INFO]: Epoch 004 - training loss: 0.3744, validation loss: 0.3132
2024-05-25 04:36:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch4_loss0.31317369639873505.pypots
2024-05-25 04:36:14 [INFO]: Epoch 005 - training loss: 0.3312, validation loss: 0.2840
2024-05-25 04:36:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch5_loss0.28403761237859726.pypots
2024-05-25 04:36:16 [INFO]: Epoch 006 - training loss: 0.3687, validation loss: 0.2830
2024-05-25 04:36:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch6_loss0.2829533666372299.pypots
2024-05-25 04:36:18 [INFO]: Epoch 007 - training loss: 0.2678, validation loss: 0.2614
2024-05-25 04:36:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch7_loss0.26141469180583954.pypots
2024-05-25 04:36:20 [INFO]: Epoch 008 - training loss: 0.3037, validation loss: 0.2527
2024-05-25 04:36:20 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch8_loss0.25265172868967056.pypots
2024-05-25 04:36:22 [INFO]: Epoch 009 - training loss: 0.2825, validation loss: 0.2476
2024-05-25 04:36:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch9_loss0.24756953865289688.pypots
2024-05-25 04:36:24 [INFO]: Epoch 010 - training loss: 0.2881, validation loss: 0.2733
2024-05-25 04:36:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch10_loss0.2733232378959656.pypots
2024-05-25 04:36:26 [INFO]: Epoch 011 - training loss: 0.3100, validation loss: 0.2603
2024-05-25 04:36:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch11_loss0.2602681890130043.pypots
2024-05-25 04:36:28 [INFO]: Epoch 012 - training loss: 0.2608, validation loss: 0.2490
2024-05-25 04:36:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch12_loss0.2489674985408783.pypots
2024-05-25 04:36:30 [INFO]: Epoch 013 - training loss: 0.2340, validation loss: 0.2334
2024-05-25 04:36:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch13_loss0.23342210426926613.pypots
2024-05-25 04:36:33 [INFO]: Epoch 014 - training loss: 0.2240, validation loss: 0.2207
2024-05-25 04:36:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch14_loss0.22074617817997932.pypots
2024-05-25 04:36:35 [INFO]: Epoch 015 - training loss: 0.2389, validation loss: 0.2115
2024-05-25 04:36:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch15_loss0.21148956194519997.pypots
2024-05-25 04:36:37 [INFO]: Epoch 016 - training loss: 0.2107, validation loss: 0.2143
2024-05-25 04:36:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch16_loss0.2142602987587452.pypots
2024-05-25 04:36:39 [INFO]: Epoch 017 - training loss: 0.2016, validation loss: 0.2042
2024-05-25 04:36:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch17_loss0.20423613488674164.pypots
2024-05-25 04:36:41 [INFO]: Epoch 018 - training loss: 0.2004, validation loss: 0.1913
2024-05-25 04:36:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch18_loss0.1912924386560917.pypots
2024-05-25 04:36:43 [INFO]: Epoch 019 - training loss: 0.2366, validation loss: 0.1882
2024-05-25 04:36:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch19_loss0.18816633522510529.pypots
2024-05-25 04:36:45 [INFO]: Epoch 020 - training loss: 0.1906, validation loss: 0.1900
2024-05-25 04:36:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch20_loss0.1899632215499878.pypots
2024-05-25 04:36:47 [INFO]: Epoch 021 - training loss: 0.1880, validation loss: 0.1744
2024-05-25 04:36:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch21_loss0.17442014068365097.pypots
2024-05-25 04:36:49 [INFO]: Epoch 022 - training loss: 0.1513, validation loss: 0.1699
2024-05-25 04:36:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch22_loss0.16986391320824623.pypots
2024-05-25 04:36:51 [INFO]: Epoch 023 - training loss: 0.1688, validation loss: 0.1651
2024-05-25 04:36:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch23_loss0.1650676131248474.pypots
2024-05-25 04:36:53 [INFO]: Epoch 024 - training loss: 0.1724, validation loss: 0.1817
2024-05-25 04:36:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch24_loss0.1817232333123684.pypots
2024-05-25 04:36:55 [INFO]: Epoch 025 - training loss: 0.1980, validation loss: 0.1705
2024-05-25 04:36:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch25_loss0.17051659151911736.pypots
2024-05-25 04:36:57 [INFO]: Epoch 026 - training loss: 0.2217, validation loss: 0.1625
2024-05-25 04:36:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch26_loss0.16247355192899704.pypots
2024-05-25 04:36:59 [INFO]: Epoch 027 - training loss: 0.1877, validation loss: 0.1660
2024-05-25 04:36:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch27_loss0.16599832102656364.pypots
2024-05-25 04:37:01 [INFO]: Epoch 028 - training loss: 0.2692, validation loss: 0.1647
2024-05-25 04:37:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch28_loss0.16471896320581436.pypots
2024-05-25 04:37:03 [INFO]: Epoch 029 - training loss: 0.2016, validation loss: 0.1623
2024-05-25 04:37:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch29_loss0.16230256482958794.pypots
2024-05-25 04:37:05 [INFO]: Epoch 030 - training loss: 0.1519, validation loss: 0.1602
2024-05-25 04:37:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch30_loss0.16022520139813423.pypots
2024-05-25 04:37:07 [INFO]: Epoch 031 - training loss: 0.1431, validation loss: 0.1541
2024-05-25 04:37:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch31_loss0.15409770980477333.pypots
2024-05-25 04:37:09 [INFO]: Epoch 032 - training loss: 0.1447, validation loss: 0.1485
2024-05-25 04:37:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch32_loss0.148468516767025.pypots
2024-05-25 04:37:11 [INFO]: Epoch 033 - training loss: 0.1886, validation loss: 0.1677
2024-05-25 04:37:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch33_loss0.1676916852593422.pypots
2024-05-25 04:37:13 [INFO]: Epoch 034 - training loss: 0.1543, validation loss: 0.1631
2024-05-25 04:37:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch34_loss0.16308370232582092.pypots
2024-05-25 04:37:15 [INFO]: Epoch 035 - training loss: 0.1441, validation loss: 0.1520
2024-05-25 04:37:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch35_loss0.1519782729446888.pypots
2024-05-25 04:37:17 [INFO]: Epoch 036 - training loss: 0.1704, validation loss: 0.1505
2024-05-25 04:37:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch36_loss0.15048187598586082.pypots
2024-05-25 04:37:19 [INFO]: Epoch 037 - training loss: 0.2353, validation loss: 0.1447
2024-05-25 04:37:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch37_loss0.1446794755756855.pypots
2024-05-25 04:37:22 [INFO]: Epoch 038 - training loss: 0.1699, validation loss: 0.1662
2024-05-25 04:37:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch38_loss0.16617464274168015.pypots
2024-05-25 04:37:24 [INFO]: Epoch 039 - training loss: 0.1657, validation loss: 0.1528
2024-05-25 04:37:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch39_loss0.15279114246368408.pypots
2024-05-25 04:37:26 [INFO]: Epoch 040 - training loss: 0.1807, validation loss: 0.1525
2024-05-25 04:37:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch40_loss0.15247243642807007.pypots
2024-05-25 04:37:28 [INFO]: Epoch 041 - training loss: 0.1534, validation loss: 0.1509
2024-05-25 04:37:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch41_loss0.15093408897519112.pypots
2024-05-25 04:37:30 [INFO]: Epoch 042 - training loss: 0.1587, validation loss: 0.1408
2024-05-25 04:37:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch42_loss0.14081129431724548.pypots
2024-05-25 04:37:32 [INFO]: Epoch 043 - training loss: 0.1472, validation loss: 0.1369
2024-05-25 04:37:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch43_loss0.13694344833493233.pypots
2024-05-25 04:37:34 [INFO]: Epoch 044 - training loss: 0.2024, validation loss: 0.1424
2024-05-25 04:37:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch44_loss0.14242956042289734.pypots
2024-05-25 04:37:36 [INFO]: Epoch 045 - training loss: 0.1749, validation loss: 0.1622
2024-05-25 04:37:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch45_loss0.1622072122991085.pypots
2024-05-25 04:37:38 [INFO]: Epoch 046 - training loss: 0.1502, validation loss: 0.1474
2024-05-25 04:37:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch46_loss0.1474319063127041.pypots
2024-05-25 04:37:40 [INFO]: Epoch 047 - training loss: 0.1691, validation loss: 0.1374
2024-05-25 04:37:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch47_loss0.13735870644450188.pypots
2024-05-25 04:37:42 [INFO]: Epoch 048 - training loss: 0.1295, validation loss: 0.1346
2024-05-25 04:37:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch48_loss0.13460271060466766.pypots
2024-05-25 04:37:44 [INFO]: Epoch 049 - training loss: 0.1589, validation loss: 0.1434
2024-05-25 04:37:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch49_loss0.14337631687521935.pypots
2024-05-25 04:37:46 [INFO]: Epoch 050 - training loss: 0.1535, validation loss: 0.1524
2024-05-25 04:37:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch50_loss0.15244713053107262.pypots
2024-05-25 04:37:48 [INFO]: Epoch 051 - training loss: 0.1790, validation loss: 0.1513
2024-05-25 04:37:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch51_loss0.15133928135037422.pypots
2024-05-25 04:37:50 [INFO]: Epoch 052 - training loss: 0.1496, validation loss: 0.1496
2024-05-25 04:37:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch52_loss0.14955778792500496.pypots
2024-05-25 04:37:52 [INFO]: Epoch 053 - training loss: 0.1585, validation loss: 0.1443
2024-05-25 04:37:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch53_loss0.1443464756011963.pypots
2024-05-25 04:37:54 [INFO]: Epoch 054 - training loss: 0.1410, validation loss: 0.1330
2024-05-25 04:37:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch54_loss0.133001571521163.pypots
2024-05-25 04:37:56 [INFO]: Epoch 055 - training loss: 0.1349, validation loss: 0.1297
2024-05-25 04:37:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch55_loss0.12971161305904388.pypots
2024-05-25 04:37:58 [INFO]: Epoch 056 - training loss: 0.1519, validation loss: 0.1322
2024-05-25 04:37:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch56_loss0.13223901391029358.pypots
2024-05-25 04:38:00 [INFO]: Epoch 057 - training loss: 0.1529, validation loss: 0.1275
2024-05-25 04:38:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch57_loss0.12747430615127087.pypots
2024-05-25 04:38:02 [INFO]: Epoch 058 - training loss: 0.1563, validation loss: 0.1325
2024-05-25 04:38:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch58_loss0.13248288072645664.pypots
2024-05-25 04:38:04 [INFO]: Epoch 059 - training loss: 0.1752, validation loss: 0.1446
2024-05-25 04:38:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch59_loss0.14458560943603516.pypots
2024-05-25 04:38:06 [INFO]: Epoch 060 - training loss: 0.1420, validation loss: 0.1339
2024-05-25 04:38:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch60_loss0.13385770842432976.pypots
2024-05-25 04:38:08 [INFO]: Epoch 061 - training loss: 0.1354, validation loss: 0.1308
2024-05-25 04:38:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch61_loss0.1308167539536953.pypots
2024-05-25 04:38:10 [INFO]: Epoch 062 - training loss: 0.2096, validation loss: 0.1295
2024-05-25 04:38:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch62_loss0.12954423390328884.pypots
2024-05-25 04:38:13 [INFO]: Epoch 063 - training loss: 0.1358, validation loss: 0.1277
2024-05-25 04:38:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch63_loss0.12774505838751793.pypots
2024-05-25 04:38:15 [INFO]: Epoch 064 - training loss: 0.1518, validation loss: 0.1299
2024-05-25 04:38:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch64_loss0.12987477891147137.pypots
2024-05-25 04:38:17 [INFO]: Epoch 065 - training loss: 0.1351, validation loss: 0.1245
2024-05-25 04:38:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch65_loss0.12445534951984882.pypots
2024-05-25 04:38:19 [INFO]: Epoch 066 - training loss: 0.1496, validation loss: 0.1290
2024-05-25 04:38:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch66_loss0.128992335870862.pypots
2024-05-25 04:38:21 [INFO]: Epoch 067 - training loss: 0.1567, validation loss: 0.1322
2024-05-25 04:38:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch67_loss0.13224859535694122.pypots
2024-05-25 04:38:23 [INFO]: Epoch 068 - training loss: 0.1419, validation loss: 0.1294
2024-05-25 04:38:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch68_loss0.1294019278138876.pypots
2024-05-25 04:38:25 [INFO]: Epoch 069 - training loss: 0.1541, validation loss: 0.1266
2024-05-25 04:38:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch69_loss0.12656119838356972.pypots
2024-05-25 04:38:27 [INFO]: Epoch 070 - training loss: 0.1928, validation loss: 0.1362
2024-05-25 04:38:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch70_loss0.1362084075808525.pypots
2024-05-25 04:38:29 [INFO]: Epoch 071 - training loss: 0.1500, validation loss: 0.1466
2024-05-25 04:38:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch71_loss0.1465807668864727.pypots
2024-05-25 04:38:31 [INFO]: Epoch 072 - training loss: 0.1590, validation loss: 0.1329
2024-05-25 04:38:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch72_loss0.13289756700396538.pypots
2024-05-25 04:38:33 [INFO]: Epoch 073 - training loss: 0.1909, validation loss: 0.1379
2024-05-25 04:38:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch73_loss0.13791857287287712.pypots
2024-05-25 04:38:35 [INFO]: Epoch 074 - training loss: 0.1635, validation loss: 0.1412
2024-05-25 04:38:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch74_loss0.14122073724865913.pypots
2024-05-25 04:38:37 [INFO]: Epoch 075 - training loss: 0.1883, validation loss: 0.1330
2024-05-25 04:38:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI_epoch75_loss0.13303720206022263.pypots
2024-05-25 04:38:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:38:37 [INFO]: Finished training. The best model is from epoch#65.
2024-05-25 04:38:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T043604/CSDI.pypots
2024-05-25 04:38:53 [INFO]: CSDI on ETTm1: MAE=0.1491, MSE=0.0489
2024-05-25 04:38:53 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/CSDI_ettm1/imputation.pkl
2024-05-25 04:38:53 [INFO]: Using the given device: cuda:0
2024-05-25 04:38:53 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/GPVAE_ettm1/20240525_T043853
2024-05-25 04:38:53 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/GPVAE_ettm1/20240525_T043853/tensorboard
2024-05-25 04:38:53 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 04:38:53 [INFO]: Epoch 001 - training loss: 24029.7286, validation loss: 0.9549
2024-05-25 04:38:53 [INFO]: Epoch 002 - training loss: 21980.0636, validation loss: 0.9504
2024-05-25 04:38:53 [INFO]: Epoch 003 - training loss: 19888.6768, validation loss: 0.9507
2024-05-25 04:38:53 [INFO]: Epoch 004 - training loss: 17795.1649, validation loss: 0.9422
2024-05-25 04:38:54 [INFO]: Epoch 005 - training loss: 15872.6587, validation loss: 0.9204
2024-05-25 04:38:54 [INFO]: Epoch 006 - training loss: 14309.7520, validation loss: 0.8707
2024-05-25 04:38:54 [INFO]: Epoch 007 - training loss: 12951.4459, validation loss: 0.7996
2024-05-25 04:38:54 [INFO]: Epoch 008 - training loss: 12129.8997, validation loss: 0.7377
2024-05-25 04:38:54 [INFO]: Epoch 009 - training loss: 11511.8716, validation loss: 0.7033
2024-05-25 04:38:54 [INFO]: Epoch 010 - training loss: 11175.6136, validation loss: 0.6585
2024-05-25 04:38:54 [INFO]: Epoch 011 - training loss: 10804.4785, validation loss: 0.6108
2024-05-25 04:38:54 [INFO]: Epoch 012 - training loss: 10554.7363, validation loss: 0.5636
2024-05-25 04:38:55 [INFO]: Epoch 013 - training loss: 10457.2260, validation loss: 0.5484
2024-05-25 04:38:55 [INFO]: Epoch 014 - training loss: 10413.1514, validation loss: 0.5288
2024-05-25 04:38:55 [INFO]: Epoch 015 - training loss: 10066.4349, validation loss: 0.5018
2024-05-25 04:38:55 [INFO]: Epoch 016 - training loss: 10017.0574, validation loss: 0.4964
2024-05-25 04:38:55 [INFO]: Epoch 017 - training loss: 9903.8979, validation loss: 0.4917
2024-05-25 04:38:55 [INFO]: Epoch 018 - training loss: 9828.5263, validation loss: 0.4634
2024-05-25 04:38:55 [INFO]: Epoch 019 - training loss: 9817.2524, validation loss: 0.4466
2024-05-25 04:38:56 [INFO]: Epoch 020 - training loss: 9737.2637, validation loss: 0.4284
2024-05-25 04:38:56 [INFO]: Epoch 021 - training loss: 9690.8378, validation loss: 0.3998
2024-05-25 04:38:56 [INFO]: Epoch 022 - training loss: 9631.1768, validation loss: 0.3804
2024-05-25 04:38:56 [INFO]: Epoch 023 - training loss: 9601.1135, validation loss: 0.3581
2024-05-25 04:38:56 [INFO]: Epoch 024 - training loss: 9577.8357, validation loss: 0.3425
2024-05-25 04:38:56 [INFO]: Epoch 025 - training loss: 9610.6755, validation loss: 0.3303
2024-05-25 04:38:56 [INFO]: Epoch 026 - training loss: 9516.7526, validation loss: 0.3308
2024-05-25 04:38:56 [INFO]: Epoch 027 - training loss: 9539.9755, validation loss: 0.3231
2024-05-25 04:38:57 [INFO]: Epoch 028 - training loss: 9491.2278, validation loss: 0.3160
2024-05-25 04:38:57 [INFO]: Epoch 029 - training loss: 9459.9827, validation loss: 0.3115
2024-05-25 04:38:57 [INFO]: Epoch 030 - training loss: 9448.5068, validation loss: 0.3120
2024-05-25 04:38:57 [INFO]: Epoch 031 - training loss: 9436.1730, validation loss: 0.3092
2024-05-25 04:38:57 [INFO]: Epoch 032 - training loss: 9413.6993, validation loss: 0.3033
2024-05-25 04:38:57 [INFO]: Epoch 033 - training loss: 9401.6066, validation loss: 0.2989
2024-05-25 04:38:57 [INFO]: Epoch 034 - training loss: 9395.9482, validation loss: 0.2921
2024-05-25 04:38:57 [INFO]: Epoch 035 - training loss: 9378.2714, validation loss: 0.2839
2024-05-25 04:38:58 [INFO]: Epoch 036 - training loss: 9371.1703, validation loss: 0.2802
2024-05-25 04:38:58 [INFO]: Epoch 037 - training loss: 9368.0843, validation loss: 0.2768
2024-05-25 04:38:58 [INFO]: Epoch 038 - training loss: 9358.3834, validation loss: 0.2765
2024-05-25 04:38:58 [INFO]: Epoch 039 - training loss: 9355.4983, validation loss: 0.2723
2024-05-25 04:38:58 [INFO]: Epoch 040 - training loss: 9342.6232, validation loss: 0.2629
2024-05-25 04:38:58 [INFO]: Epoch 041 - training loss: 9346.8639, validation loss: 0.2628
2024-05-25 04:38:58 [INFO]: Epoch 042 - training loss: 9333.8631, validation loss: 0.2559
2024-05-25 04:38:58 [INFO]: Epoch 043 - training loss: 9327.5078, validation loss: 0.2543
2024-05-25 04:38:59 [INFO]: Epoch 044 - training loss: 9328.0093, validation loss: 0.2474
2024-05-25 04:38:59 [INFO]: Epoch 045 - training loss: 9320.5248, validation loss: 0.2442
2024-05-25 04:38:59 [INFO]: Epoch 046 - training loss: 9327.4972, validation loss: 0.2411
2024-05-25 04:38:59 [INFO]: Epoch 047 - training loss: 9318.4271, validation loss: 0.2370
2024-05-25 04:38:59 [INFO]: Epoch 048 - training loss: 9309.2791, validation loss: 0.2305
2024-05-25 04:38:59 [INFO]: Epoch 049 - training loss: 9304.8845, validation loss: 0.2272
2024-05-25 04:38:59 [INFO]: Epoch 050 - training loss: 9304.6328, validation loss: 0.2244
2024-05-25 04:38:59 [INFO]: Epoch 051 - training loss: 9306.8367, validation loss: 0.2179
2024-05-25 04:39:00 [INFO]: Epoch 052 - training loss: 9300.4208, validation loss: 0.2175
2024-05-25 04:39:00 [INFO]: Epoch 053 - training loss: 9290.9744, validation loss: 0.2130
2024-05-25 04:39:00 [INFO]: Epoch 054 - training loss: 9287.4577, validation loss: 0.2104
2024-05-25 04:39:00 [INFO]: Epoch 055 - training loss: 9286.2053, validation loss: 0.2080
2024-05-25 04:39:00 [INFO]: Epoch 056 - training loss: 9287.4259, validation loss: 0.2025
2024-05-25 04:39:00 [INFO]: Epoch 057 - training loss: 9280.0872, validation loss: 0.1926
2024-05-25 04:39:00 [INFO]: Epoch 058 - training loss: 9286.0735, validation loss: 0.1909
2024-05-25 04:39:01 [INFO]: Epoch 059 - training loss: 9277.1331, validation loss: 0.1883
2024-05-25 04:39:01 [INFO]: Epoch 060 - training loss: 9276.0714, validation loss: 0.1872
2024-05-25 04:39:01 [INFO]: Epoch 061 - training loss: 9274.9754, validation loss: 0.1841
2024-05-25 04:39:01 [INFO]: Epoch 062 - training loss: 9271.0270, validation loss: 0.1798
2024-05-25 04:39:01 [INFO]: Epoch 063 - training loss: 9268.6793, validation loss: 0.1766
2024-05-25 04:39:01 [INFO]: Epoch 064 - training loss: 9269.4502, validation loss: 0.1741
2024-05-25 04:39:01 [INFO]: Epoch 065 - training loss: 9265.0520, validation loss: 0.1715
2024-05-25 04:39:01 [INFO]: Epoch 066 - training loss: 9265.3171, validation loss: 0.1695
2024-05-25 04:39:02 [INFO]: Epoch 067 - training loss: 9263.1461, validation loss: 0.1657
2024-05-25 04:39:02 [INFO]: Epoch 068 - training loss: 9260.2142, validation loss: 0.1626
2024-05-25 04:39:02 [INFO]: Epoch 069 - training loss: 9259.5499, validation loss: 0.1604
2024-05-25 04:39:02 [INFO]: Epoch 070 - training loss: 9257.9641, validation loss: 0.1582
2024-05-25 04:39:02 [INFO]: Epoch 071 - training loss: 9263.0143, validation loss: 0.1582
2024-05-25 04:39:02 [INFO]: Epoch 072 - training loss: 9254.4039, validation loss: 0.1539
2024-05-25 04:39:02 [INFO]: Epoch 073 - training loss: 9254.8205, validation loss: 0.1521
2024-05-25 04:39:02 [INFO]: Epoch 074 - training loss: 9255.1702, validation loss: 0.1512
2024-05-25 04:39:03 [INFO]: Epoch 075 - training loss: 9254.2436, validation loss: 0.1501
2024-05-25 04:39:03 [INFO]: Epoch 076 - training loss: 9248.8165, validation loss: 0.1464
2024-05-25 04:39:03 [INFO]: Epoch 077 - training loss: 9251.8760, validation loss: 0.1469
2024-05-25 04:39:03 [INFO]: Epoch 078 - training loss: 9251.9010, validation loss: 0.1437
2024-05-25 04:39:03 [INFO]: Epoch 079 - training loss: 9249.0195, validation loss: 0.1425
2024-05-25 04:39:03 [INFO]: Epoch 080 - training loss: 9249.1752, validation loss: 0.1409
2024-05-25 04:39:03 [INFO]: Epoch 081 - training loss: 9244.6812, validation loss: 0.1405
2024-05-25 04:39:03 [INFO]: Epoch 082 - training loss: 9243.9088, validation loss: 0.1382
2024-05-25 04:39:04 [INFO]: Epoch 083 - training loss: 9243.0329, validation loss: 0.1380
2024-05-25 04:39:04 [INFO]: Epoch 084 - training loss: 9245.2813, validation loss: 0.1375
2024-05-25 04:39:04 [INFO]: Epoch 085 - training loss: 9241.8897, validation loss: 0.1367
2024-05-25 04:39:04 [INFO]: Epoch 086 - training loss: 9241.6761, validation loss: 0.1366
2024-05-25 04:39:04 [INFO]: Epoch 087 - training loss: 9240.6821, validation loss: 0.1340
2024-05-25 04:39:04 [INFO]: Epoch 088 - training loss: 9241.7675, validation loss: 0.1331
2024-05-25 04:39:04 [INFO]: Epoch 089 - training loss: 9238.6943, validation loss: 0.1336
2024-05-25 04:39:05 [INFO]: Epoch 090 - training loss: 9239.9537, validation loss: 0.1316
2024-05-25 04:39:05 [INFO]: Epoch 091 - training loss: 9242.3680, validation loss: 0.1302
2024-05-25 04:39:05 [INFO]: Epoch 092 - training loss: 9237.5069, validation loss: 0.1309
2024-05-25 04:39:05 [INFO]: Epoch 093 - training loss: 9237.8505, validation loss: 0.1299
2024-05-25 04:39:05 [INFO]: Epoch 094 - training loss: 9237.5986, validation loss: 0.1292
2024-05-25 04:39:05 [INFO]: Epoch 095 - training loss: 9237.3273, validation loss: 0.1273
2024-05-25 04:39:05 [INFO]: Epoch 096 - training loss: 9235.6115, validation loss: 0.1279
2024-05-25 04:39:05 [INFO]: Epoch 097 - training loss: 9234.1863, validation loss: 0.1266
2024-05-25 04:39:06 [INFO]: Epoch 098 - training loss: 9234.0890, validation loss: 0.1265
2024-05-25 04:39:06 [INFO]: Epoch 099 - training loss: 9233.4611, validation loss: 0.1239
2024-05-25 04:39:06 [INFO]: Epoch 100 - training loss: 9234.3686, validation loss: 0.1252
2024-05-25 04:39:06 [INFO]: Epoch 101 - training loss: 9231.9946, validation loss: 0.1235
2024-05-25 04:39:06 [INFO]: Epoch 102 - training loss: 9233.2814, validation loss: 0.1231
2024-05-25 04:39:06 [INFO]: Epoch 103 - training loss: 9231.1223, validation loss: 0.1223
2024-05-25 04:39:06 [INFO]: Epoch 104 - training loss: 9230.6641, validation loss: 0.1231
2024-05-25 04:39:06 [INFO]: Epoch 105 - training loss: 9230.6552, validation loss: 0.1232
2024-05-25 04:39:07 [INFO]: Epoch 106 - training loss: 9235.8474, validation loss: 0.1220
2024-05-25 04:39:07 [INFO]: Epoch 107 - training loss: 9229.4474, validation loss: 0.1212
2024-05-25 04:39:07 [INFO]: Epoch 108 - training loss: 9228.1818, validation loss: 0.1207
2024-05-25 04:39:07 [INFO]: Epoch 109 - training loss: 9228.6997, validation loss: 0.1209
2024-05-25 04:39:07 [INFO]: Epoch 110 - training loss: 9227.9412, validation loss: 0.1188
2024-05-25 04:39:07 [INFO]: Epoch 111 - training loss: 9227.4152, validation loss: 0.1178
2024-05-25 04:39:07 [INFO]: Epoch 112 - training loss: 9226.7908, validation loss: 0.1195
2024-05-25 04:39:07 [INFO]: Epoch 113 - training loss: 9227.6519, validation loss: 0.1198
2024-05-25 04:39:08 [INFO]: Epoch 114 - training loss: 9226.3542, validation loss: 0.1191
2024-05-25 04:39:08 [INFO]: Epoch 115 - training loss: 9225.4594, validation loss: 0.1200
2024-05-25 04:39:08 [INFO]: Epoch 116 - training loss: 9226.7931, validation loss: 0.1169
2024-05-25 04:39:08 [INFO]: Epoch 117 - training loss: 9227.1662, validation loss: 0.1163
2024-05-25 04:39:08 [INFO]: Epoch 118 - training loss: 9224.0975, validation loss: 0.1180
2024-05-25 04:39:08 [INFO]: Epoch 119 - training loss: 9224.0233, validation loss: 0.1143
2024-05-25 04:39:08 [INFO]: Epoch 120 - training loss: 9227.2517, validation loss: 0.1148
2024-05-25 04:39:09 [INFO]: Epoch 121 - training loss: 9224.9401, validation loss: 0.1151
2024-05-25 04:39:09 [INFO]: Epoch 122 - training loss: 9228.8089, validation loss: 0.1147
2024-05-25 04:39:09 [INFO]: Epoch 123 - training loss: 9223.0295, validation loss: 0.1142
2024-05-25 04:39:09 [INFO]: Epoch 124 - training loss: 9223.2946, validation loss: 0.1145
2024-05-25 04:39:09 [INFO]: Epoch 125 - training loss: 9222.0333, validation loss: 0.1130
2024-05-25 04:39:09 [INFO]: Epoch 126 - training loss: 9221.5496, validation loss: 0.1115
2024-05-25 04:39:09 [INFO]: Epoch 127 - training loss: 9225.5895, validation loss: 0.1124
2024-05-25 04:39:09 [INFO]: Epoch 128 - training loss: 9222.6421, validation loss: 0.1116
2024-05-25 04:39:10 [INFO]: Epoch 129 - training loss: 9223.2867, validation loss: 0.1099
2024-05-25 04:39:10 [INFO]: Epoch 130 - training loss: 9223.3787, validation loss: 0.1142
2024-05-25 04:39:10 [INFO]: Epoch 131 - training loss: 9222.9919, validation loss: 0.1095
2024-05-25 04:39:10 [INFO]: Epoch 132 - training loss: 9221.2152, validation loss: 0.1088
2024-05-25 04:39:10 [INFO]: Epoch 133 - training loss: 9220.5240, validation loss: 0.1085
2024-05-25 04:39:10 [INFO]: Epoch 134 - training loss: 9221.4830, validation loss: 0.1092
2024-05-25 04:39:10 [INFO]: Epoch 135 - training loss: 9219.7645, validation loss: 0.1089
2024-05-25 04:39:10 [INFO]: Epoch 136 - training loss: 9221.3923, validation loss: 0.1084
2024-05-25 04:39:11 [INFO]: Epoch 137 - training loss: 9222.1832, validation loss: 0.1067
2024-05-25 04:39:11 [INFO]: Epoch 138 - training loss: 9219.3977, validation loss: 0.1064
2024-05-25 04:39:11 [INFO]: Epoch 139 - training loss: 9218.9180, validation loss: 0.1068
2024-05-25 04:39:11 [INFO]: Epoch 140 - training loss: 9223.0586, validation loss: 0.1071
2024-05-25 04:39:11 [INFO]: Epoch 141 - training loss: 9221.6790, validation loss: 0.1085
2024-05-25 04:39:11 [INFO]: Epoch 142 - training loss: 9220.1102, validation loss: 0.1064
2024-05-25 04:39:11 [INFO]: Epoch 143 - training loss: 9220.6561, validation loss: 0.1059
2024-05-25 04:39:11 [INFO]: Epoch 144 - training loss: 9218.5022, validation loss: 0.1039
2024-05-25 04:39:12 [INFO]: Epoch 145 - training loss: 9219.4493, validation loss: 0.1039
2024-05-25 04:39:12 [INFO]: Epoch 146 - training loss: 9219.6489, validation loss: 0.1057
2024-05-25 04:39:12 [INFO]: Epoch 147 - training loss: 9216.9056, validation loss: 0.1045
2024-05-25 04:39:12 [INFO]: Epoch 148 - training loss: 9218.3070, validation loss: 0.1043
2024-05-25 04:39:12 [INFO]: Epoch 149 - training loss: 9215.7903, validation loss: 0.1039
2024-05-25 04:39:12 [INFO]: Epoch 150 - training loss: 9215.7415, validation loss: 0.1035
2024-05-25 04:39:12 [INFO]: Epoch 151 - training loss: 9217.7901, validation loss: 0.1015
2024-05-25 04:39:13 [INFO]: Epoch 152 - training loss: 9218.3173, validation loss: 0.1017
2024-05-25 04:39:13 [INFO]: Epoch 153 - training loss: 9217.8254, validation loss: 0.1005
2024-05-25 04:39:13 [INFO]: Epoch 154 - training loss: 9216.9488, validation loss: 0.1039
2024-05-25 04:39:13 [INFO]: Epoch 155 - training loss: 9216.6532, validation loss: 0.0997
2024-05-25 04:39:13 [INFO]: Epoch 156 - training loss: 9215.4003, validation loss: 0.1008
2024-05-25 04:39:13 [INFO]: Epoch 157 - training loss: 9214.9893, validation loss: 0.0989
2024-05-25 04:39:13 [INFO]: Epoch 158 - training loss: 9215.9137, validation loss: 0.0999
2024-05-25 04:39:13 [INFO]: Epoch 159 - training loss: 9217.0247, validation loss: 0.1006
2024-05-25 04:39:14 [INFO]: Epoch 160 - training loss: 9215.1182, validation loss: 0.1001
2024-05-25 04:39:14 [INFO]: Epoch 161 - training loss: 9216.3958, validation loss: 0.1000
2024-05-25 04:39:14 [INFO]: Epoch 162 - training loss: 9215.7825, validation loss: 0.1015
2024-05-25 04:39:14 [INFO]: Epoch 163 - training loss: 9215.9017, validation loss: 0.0996
2024-05-25 04:39:14 [INFO]: Epoch 164 - training loss: 9213.7384, validation loss: 0.0984
2024-05-25 04:39:14 [INFO]: Epoch 165 - training loss: 9215.2999, validation loss: 0.1005
2024-05-25 04:39:14 [INFO]: Epoch 166 - training loss: 9214.2872, validation loss: 0.0984
2024-05-25 04:39:14 [INFO]: Epoch 167 - training loss: 9215.6348, validation loss: 0.0991
2024-05-25 04:39:15 [INFO]: Epoch 168 - training loss: 9215.5828, validation loss: 0.0984
2024-05-25 04:39:15 [INFO]: Epoch 169 - training loss: 9213.3647, validation loss: 0.0978
2024-05-25 04:39:15 [INFO]: Epoch 170 - training loss: 9213.8166, validation loss: 0.0970
2024-05-25 04:39:15 [INFO]: Epoch 171 - training loss: 9214.1616, validation loss: 0.0977
2024-05-25 04:39:15 [INFO]: Epoch 172 - training loss: 9214.2391, validation loss: 0.0958
2024-05-25 04:39:15 [INFO]: Epoch 173 - training loss: 9214.5225, validation loss: 0.0976
2024-05-25 04:39:15 [INFO]: Epoch 174 - training loss: 9214.0355, validation loss: 0.0964
2024-05-25 04:39:15 [INFO]: Epoch 175 - training loss: 9213.8718, validation loss: 0.0983
2024-05-25 04:39:16 [INFO]: Epoch 176 - training loss: 9214.1329, validation loss: 0.0967
2024-05-25 04:39:16 [INFO]: Epoch 177 - training loss: 9214.2082, validation loss: 0.0952
2024-05-25 04:39:16 [INFO]: Epoch 178 - training loss: 9213.5557, validation loss: 0.0971
2024-05-25 04:39:16 [INFO]: Epoch 179 - training loss: 9213.3467, validation loss: 0.0939
2024-05-25 04:39:16 [INFO]: Epoch 180 - training loss: 9212.7532, validation loss: 0.0954
2024-05-25 04:39:16 [INFO]: Epoch 181 - training loss: 9213.8557, validation loss: 0.0935
2024-05-25 04:39:16 [INFO]: Epoch 182 - training loss: 9213.8066, validation loss: 0.0933
2024-05-25 04:39:16 [INFO]: Epoch 183 - training loss: 9212.6703, validation loss: 0.0955
2024-05-25 04:39:17 [INFO]: Epoch 184 - training loss: 9212.4337, validation loss: 0.0940
2024-05-25 04:39:17 [INFO]: Epoch 185 - training loss: 9212.7791, validation loss: 0.0937
2024-05-25 04:39:17 [INFO]: Epoch 186 - training loss: 9212.8238, validation loss: 0.0947
2024-05-25 04:39:17 [INFO]: Epoch 187 - training loss: 9214.6936, validation loss: 0.0919
2024-05-25 04:39:17 [INFO]: Epoch 188 - training loss: 9214.1887, validation loss: 0.0979
2024-05-25 04:39:17 [INFO]: Epoch 189 - training loss: 9211.4412, validation loss: 0.0930
2024-05-25 04:39:17 [INFO]: Epoch 190 - training loss: 9212.5789, validation loss: 0.0948
2024-05-25 04:39:18 [INFO]: Epoch 191 - training loss: 9212.0722, validation loss: 0.0931
2024-05-25 04:39:18 [INFO]: Epoch 192 - training loss: 9211.3032, validation loss: 0.0947
2024-05-25 04:39:18 [INFO]: Epoch 193 - training loss: 9212.2532, validation loss: 0.0934
2024-05-25 04:39:18 [INFO]: Epoch 194 - training loss: 9213.0328, validation loss: 0.0926
2024-05-25 04:39:18 [INFO]: Epoch 195 - training loss: 9210.9890, validation loss: 0.0937
2024-05-25 04:39:18 [INFO]: Epoch 196 - training loss: 9210.3270, validation loss: 0.0921
2024-05-25 04:39:18 [INFO]: Epoch 197 - training loss: 9211.7353, validation loss: 0.0943
2024-05-25 04:39:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:39:18 [INFO]: Finished training. The best model is from epoch#187.
2024-05-25 04:39:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/GPVAE_ettm1/20240525_T043853/GPVAE.pypots
2024-05-25 04:39:18 [INFO]: GP-VAE on ETTm1: MAE=0.2866, MSE=0.1749
2024-05-25 04:39:18 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/GPVAE_ettm1/imputation.pkl
2024-05-25 04:39:18 [INFO]: Using the given device: cuda:0
2024-05-25 04:39:18 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/USGAN_ettm1/20240525_T043918
2024-05-25 04:39:18 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/USGAN_ettm1/20240525_T043918/tensorboard
2024-05-25 04:39:18 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 04:39:29 [INFO]: Epoch 001 - generator training loss: 0.4605, discriminator training loss: 0.5399, validation loss: 0.3509
2024-05-25 04:39:37 [INFO]: Epoch 002 - generator training loss: -0.0480, discriminator training loss: 0.4736, validation loss: 0.1286
2024-05-25 04:39:46 [INFO]: Epoch 003 - generator training loss: -0.1581, discriminator training loss: 0.4336, validation loss: 0.0762
2024-05-25 04:39:55 [INFO]: Epoch 004 - generator training loss: -0.1495, discriminator training loss: 0.3758, validation loss: 0.0585
2024-05-25 04:40:04 [INFO]: Epoch 005 - generator training loss: -0.1108, discriminator training loss: 0.3010, validation loss: 0.0499
2024-05-25 04:40:12 [INFO]: Epoch 006 - generator training loss: -0.0822, discriminator training loss: 0.2407, validation loss: 0.0443
2024-05-25 04:40:21 [INFO]: Epoch 007 - generator training loss: -0.0599, discriminator training loss: 0.2047, validation loss: 0.0445
2024-05-25 04:40:30 [INFO]: Epoch 008 - generator training loss: -0.0570, discriminator training loss: 0.1891, validation loss: 0.0428
2024-05-25 04:40:39 [INFO]: Epoch 009 - generator training loss: -0.0545, discriminator training loss: 0.1808, validation loss: 0.0405
2024-05-25 04:40:47 [INFO]: Epoch 010 - generator training loss: -0.0527, discriminator training loss: 0.1793, validation loss: 0.0396
2024-05-25 04:40:56 [INFO]: Epoch 011 - generator training loss: -0.0557, discriminator training loss: 0.1744, validation loss: 0.0386
2024-05-25 04:41:05 [INFO]: Epoch 012 - generator training loss: -0.0596, discriminator training loss: 0.1730, validation loss: 0.0376
2024-05-25 04:41:14 [INFO]: Epoch 013 - generator training loss: -0.0572, discriminator training loss: 0.1727, validation loss: 0.0373
2024-05-25 04:41:23 [INFO]: Epoch 014 - generator training loss: -0.0556, discriminator training loss: 0.1721, validation loss: 0.0380
2024-05-25 04:41:31 [INFO]: Epoch 015 - generator training loss: -0.0587, discriminator training loss: 0.1741, validation loss: 0.0375
2024-05-25 04:41:40 [INFO]: Epoch 016 - generator training loss: -0.0572, discriminator training loss: 0.1706, validation loss: 0.0368
2024-05-25 04:41:49 [INFO]: Epoch 017 - generator training loss: -0.0588, discriminator training loss: 0.1711, validation loss: 0.0365
2024-05-25 04:41:58 [INFO]: Epoch 018 - generator training loss: -0.0598, discriminator training loss: 0.1746, validation loss: 0.0392
2024-05-25 04:42:07 [INFO]: Epoch 019 - generator training loss: -0.0584, discriminator training loss: 0.1709, validation loss: 0.0353
2024-05-25 04:42:15 [INFO]: Epoch 020 - generator training loss: -0.0596, discriminator training loss: 0.1711, validation loss: 0.0362
2024-05-25 04:42:24 [INFO]: Epoch 021 - generator training loss: -0.0587, discriminator training loss: 0.1709, validation loss: 0.0361
2024-05-25 04:42:33 [INFO]: Epoch 022 - generator training loss: -0.0516, discriminator training loss: 0.1708, validation loss: 0.0365
2024-05-25 04:42:41 [INFO]: Epoch 023 - generator training loss: -0.0607, discriminator training loss: 0.1693, validation loss: 0.0360
2024-05-25 04:42:50 [INFO]: Epoch 024 - generator training loss: -0.0589, discriminator training loss: 0.1698, validation loss: 0.0342
2024-05-25 04:42:59 [INFO]: Epoch 025 - generator training loss: -0.0626, discriminator training loss: 0.1687, validation loss: 0.0343
2024-05-25 04:43:08 [INFO]: Epoch 026 - generator training loss: -0.0628, discriminator training loss: 0.1706, validation loss: 0.0332
2024-05-25 04:43:16 [INFO]: Epoch 027 - generator training loss: -0.0602, discriminator training loss: 0.1701, validation loss: 0.0326
2024-05-25 04:43:25 [INFO]: Epoch 028 - generator training loss: -0.0644, discriminator training loss: 0.1726, validation loss: 0.0327
2024-05-25 04:43:34 [INFO]: Epoch 029 - generator training loss: -0.0595, discriminator training loss: 0.1671, validation loss: 0.0335
2024-05-25 04:43:43 [INFO]: Epoch 030 - generator training loss: -0.0676, discriminator training loss: 0.1678, validation loss: 0.0332
2024-05-25 04:43:51 [INFO]: Epoch 031 - generator training loss: -0.0597, discriminator training loss: 0.1685, validation loss: 0.0324
2024-05-25 04:44:00 [INFO]: Epoch 032 - generator training loss: -0.0660, discriminator training loss: 0.1675, validation loss: 0.0314
2024-05-25 04:44:09 [INFO]: Epoch 033 - generator training loss: -0.0612, discriminator training loss: 0.1673, validation loss: 0.0323
2024-05-25 04:44:18 [INFO]: Epoch 034 - generator training loss: -0.0647, discriminator training loss: 0.1654, validation loss: 0.0315
2024-05-25 04:44:26 [INFO]: Epoch 035 - generator training loss: -0.0670, discriminator training loss: 0.1660, validation loss: 0.0309
2024-05-25 04:44:35 [INFO]: Epoch 036 - generator training loss: -0.0663, discriminator training loss: 0.1660, validation loss: 0.0307
2024-05-25 04:44:44 [INFO]: Epoch 037 - generator training loss: -0.0672, discriminator training loss: 0.1684, validation loss: 0.0307
2024-05-25 04:44:53 [INFO]: Epoch 038 - generator training loss: -0.0663, discriminator training loss: 0.1669, validation loss: 0.0312
2024-05-25 04:45:02 [INFO]: Epoch 039 - generator training loss: -0.0672, discriminator training loss: 0.1656, validation loss: 0.0309
2024-05-25 04:45:10 [INFO]: Epoch 040 - generator training loss: -0.0685, discriminator training loss: 0.1663, validation loss: 0.0297
2024-05-25 04:45:19 [INFO]: Epoch 041 - generator training loss: -0.0650, discriminator training loss: 0.1673, validation loss: 0.0303
2024-05-25 04:45:28 [INFO]: Epoch 042 - generator training loss: -0.0698, discriminator training loss: 0.1660, validation loss: 0.0298
2024-05-25 04:45:37 [INFO]: Epoch 043 - generator training loss: -0.0667, discriminator training loss: 0.1651, validation loss: 0.0297
2024-05-25 04:45:45 [INFO]: Epoch 044 - generator training loss: -0.0674, discriminator training loss: 0.1639, validation loss: 0.0290
2024-05-25 04:45:54 [INFO]: Epoch 045 - generator training loss: -0.0684, discriminator training loss: 0.1683, validation loss: 0.0290
2024-05-25 04:46:03 [INFO]: Epoch 046 - generator training loss: -0.0673, discriminator training loss: 0.1677, validation loss: 0.0279
2024-05-25 04:46:11 [INFO]: Epoch 047 - generator training loss: -0.0668, discriminator training loss: 0.1669, validation loss: 0.0279
2024-05-25 04:46:20 [INFO]: Epoch 048 - generator training loss: -0.0717, discriminator training loss: 0.1662, validation loss: 0.0281
2024-05-25 04:46:29 [INFO]: Epoch 049 - generator training loss: -0.0689, discriminator training loss: 0.1664, validation loss: 0.0291
2024-05-25 04:46:38 [INFO]: Epoch 050 - generator training loss: -0.0687, discriminator training loss: 0.1655, validation loss: 0.0278
2024-05-25 04:46:46 [INFO]: Epoch 051 - generator training loss: -0.0716, discriminator training loss: 0.1662, validation loss: 0.0268
2024-05-25 04:46:55 [INFO]: Epoch 052 - generator training loss: -0.0713, discriminator training loss: 0.1650, validation loss: 0.0268
2024-05-25 04:47:04 [INFO]: Epoch 053 - generator training loss: -0.0700, discriminator training loss: 0.1659, validation loss: 0.0268
2024-05-25 04:47:13 [INFO]: Epoch 054 - generator training loss: -0.0707, discriminator training loss: 0.1660, validation loss: 0.0264
2024-05-25 04:47:21 [INFO]: Epoch 055 - generator training loss: -0.0707, discriminator training loss: 0.1651, validation loss: 0.0257
2024-05-25 04:47:30 [INFO]: Epoch 056 - generator training loss: -0.0768, discriminator training loss: 0.1664, validation loss: 0.0256
2024-05-25 04:47:39 [INFO]: Epoch 057 - generator training loss: -0.0707, discriminator training loss: 0.1660, validation loss: 0.0254
2024-05-25 04:47:48 [INFO]: Epoch 058 - generator training loss: -0.0718, discriminator training loss: 0.1652, validation loss: 0.0254
2024-05-25 04:47:57 [INFO]: Epoch 059 - generator training loss: -0.0729, discriminator training loss: 0.1676, validation loss: 0.0255
2024-05-25 04:48:05 [INFO]: Epoch 060 - generator training loss: -0.0716, discriminator training loss: 0.1668, validation loss: 0.0251
2024-05-25 04:48:14 [INFO]: Epoch 061 - generator training loss: -0.0721, discriminator training loss: 0.1641, validation loss: 0.0247
2024-05-25 04:48:23 [INFO]: Epoch 062 - generator training loss: -0.0735, discriminator training loss: 0.1625, validation loss: 0.0254
2024-05-25 04:48:32 [INFO]: Epoch 063 - generator training loss: -0.0756, discriminator training loss: 0.1640, validation loss: 0.0244
2024-05-25 04:48:40 [INFO]: Epoch 064 - generator training loss: -0.0707, discriminator training loss: 0.1646, validation loss: 0.0246
2024-05-25 04:48:49 [INFO]: Epoch 065 - generator training loss: -0.0728, discriminator training loss: 0.1644, validation loss: 0.0250
2024-05-25 04:48:58 [INFO]: Epoch 066 - generator training loss: -0.0724, discriminator training loss: 0.1627, validation loss: 0.0248
2024-05-25 04:49:06 [INFO]: Epoch 067 - generator training loss: -0.0723, discriminator training loss: 0.1640, validation loss: 0.0245
2024-05-25 04:49:15 [INFO]: Epoch 068 - generator training loss: -0.0759, discriminator training loss: 0.1621, validation loss: 0.0254
2024-05-25 04:49:24 [INFO]: Epoch 069 - generator training loss: -0.0696, discriminator training loss: 0.1634, validation loss: 0.0247
2024-05-25 04:49:33 [INFO]: Epoch 070 - generator training loss: -0.0732, discriminator training loss: 0.1641, validation loss: 0.0241
2024-05-25 04:49:41 [INFO]: Epoch 071 - generator training loss: -0.0727, discriminator training loss: 0.1613, validation loss: 0.0243
2024-05-25 04:49:50 [INFO]: Epoch 072 - generator training loss: -0.0722, discriminator training loss: 0.1605, validation loss: 0.0244
2024-05-25 04:49:59 [INFO]: Epoch 073 - generator training loss: -0.0744, discriminator training loss: 0.1638, validation loss: 0.0241
2024-05-25 04:50:08 [INFO]: Epoch 074 - generator training loss: -0.0724, discriminator training loss: 0.1642, validation loss: 0.0245
2024-05-25 04:50:16 [INFO]: Epoch 075 - generator training loss: -0.0709, discriminator training loss: 0.1636, validation loss: 0.0241
2024-05-25 04:50:25 [INFO]: Epoch 076 - generator training loss: -0.0761, discriminator training loss: 0.1632, validation loss: 0.0237
2024-05-25 04:50:34 [INFO]: Epoch 077 - generator training loss: -0.0696, discriminator training loss: 0.1607, validation loss: 0.0246
2024-05-25 04:50:43 [INFO]: Epoch 078 - generator training loss: -0.0729, discriminator training loss: 0.1624, validation loss: 0.0235
2024-05-25 04:50:52 [INFO]: Epoch 079 - generator training loss: -0.0742, discriminator training loss: 0.1629, validation loss: 0.0240
2024-05-25 04:51:00 [INFO]: Epoch 080 - generator training loss: -0.0749, discriminator training loss: 0.1621, validation loss: 0.0242
2024-05-25 04:51:09 [INFO]: Epoch 081 - generator training loss: -0.0742, discriminator training loss: 0.1631, validation loss: 0.0246
2024-05-25 04:51:18 [INFO]: Epoch 082 - generator training loss: -0.0707, discriminator training loss: 0.1626, validation loss: 0.0238
2024-05-25 04:51:27 [INFO]: Epoch 083 - generator training loss: -0.0701, discriminator training loss: 0.1613, validation loss: 0.0240
2024-05-25 04:51:35 [INFO]: Epoch 084 - generator training loss: -0.0715, discriminator training loss: 0.1617, validation loss: 0.0251
2024-05-25 04:51:44 [INFO]: Epoch 085 - generator training loss: -0.0757, discriminator training loss: 0.1616, validation loss: 0.0240
2024-05-25 04:51:53 [INFO]: Epoch 086 - generator training loss: -0.0709, discriminator training loss: 0.1620, validation loss: 0.0240
2024-05-25 04:52:02 [INFO]: Epoch 087 - generator training loss: -0.0733, discriminator training loss: 0.1607, validation loss: 0.0237
2024-05-25 04:52:10 [INFO]: Epoch 088 - generator training loss: -0.0754, discriminator training loss: 0.1615, validation loss: 0.0240
2024-05-25 04:52:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:52:10 [INFO]: Finished training. The best model is from epoch#78.
2024-05-25 04:52:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/USGAN_ettm1/20240525_T043918/USGAN.pypots
2024-05-25 04:52:11 [INFO]: US-GAN on ETTm1: MAE=0.1488, MSE=0.0590
2024-05-25 04:52:11 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/USGAN_ettm1/imputation.pkl
2024-05-25 04:52:11 [INFO]: Using the given device: cuda:0
2024-05-25 04:52:11 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/BRITS_ettm1/20240525_T045211
2024-05-25 04:52:11 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/BRITS_ettm1/20240525_T045211/tensorboard
2024-05-25 04:52:11 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 04:52:19 [INFO]: Epoch 001 - training loss: 1.3618, validation loss: 0.3882
2024-05-25 04:52:25 [INFO]: Epoch 002 - training loss: 0.9181, validation loss: 0.1279
2024-05-25 04:52:31 [INFO]: Epoch 003 - training loss: 0.7477, validation loss: 0.0643
2024-05-25 04:52:36 [INFO]: Epoch 004 - training loss: 0.6520, validation loss: 0.0491
2024-05-25 04:52:42 [INFO]: Epoch 005 - training loss: 0.6128, validation loss: 0.0465
2024-05-25 04:52:48 [INFO]: Epoch 006 - training loss: 0.5853, validation loss: 0.0398
2024-05-25 04:52:54 [INFO]: Epoch 007 - training loss: 0.5483, validation loss: 0.0380
2024-05-25 04:53:00 [INFO]: Epoch 008 - training loss: 0.5183, validation loss: 0.0361
2024-05-25 04:53:06 [INFO]: Epoch 009 - training loss: 0.4962, validation loss: 0.0338
2024-05-25 04:53:11 [INFO]: Epoch 010 - training loss: 0.4853, validation loss: 0.0343
2024-05-25 04:53:17 [INFO]: Epoch 011 - training loss: 0.4728, validation loss: 0.0339
2024-05-25 04:53:23 [INFO]: Epoch 012 - training loss: 0.4532, validation loss: 0.0311
2024-05-25 04:53:29 [INFO]: Epoch 013 - training loss: 0.4384, validation loss: 0.0323
2024-05-25 04:53:35 [INFO]: Epoch 014 - training loss: 0.4361, validation loss: 0.0309
2024-05-25 04:53:41 [INFO]: Epoch 015 - training loss: 0.4163, validation loss: 0.0289
2024-05-25 04:53:46 [INFO]: Epoch 016 - training loss: 0.4140, validation loss: 0.0291
2024-05-25 04:53:52 [INFO]: Epoch 017 - training loss: 0.4096, validation loss: 0.0281
2024-05-25 04:53:58 [INFO]: Epoch 018 - training loss: 0.4046, validation loss: 0.0273
2024-05-25 04:54:04 [INFO]: Epoch 019 - training loss: 0.4013, validation loss: 0.0270
2024-05-25 04:54:10 [INFO]: Epoch 020 - training loss: 0.4083, validation loss: 0.0278
2024-05-25 04:54:16 [INFO]: Epoch 021 - training loss: 0.4127, validation loss: 0.0277
2024-05-25 04:54:22 [INFO]: Epoch 022 - training loss: 0.4054, validation loss: 0.0272
2024-05-25 04:54:27 [INFO]: Epoch 023 - training loss: 0.4102, validation loss: 0.0268
2024-05-25 04:54:33 [INFO]: Epoch 024 - training loss: 0.4037, validation loss: 0.0265
2024-05-25 04:54:39 [INFO]: Epoch 025 - training loss: 0.4168, validation loss: 0.0274
2024-05-25 04:54:45 [INFO]: Epoch 026 - training loss: 0.4087, validation loss: 0.0272
2024-05-25 04:54:51 [INFO]: Epoch 027 - training loss: 0.4082, validation loss: 0.0270
2024-05-25 04:54:57 [INFO]: Epoch 028 - training loss: 0.4116, validation loss: 0.0269
2024-05-25 04:55:02 [INFO]: Epoch 029 - training loss: 0.4126, validation loss: 0.0284
2024-05-25 04:55:08 [INFO]: Epoch 030 - training loss: 0.4128, validation loss: 0.0270
2024-05-25 04:55:14 [INFO]: Epoch 031 - training loss: 0.4049, validation loss: 0.0263
2024-05-25 04:55:20 [INFO]: Epoch 032 - training loss: 0.3978, validation loss: 0.0261
2024-05-25 04:55:26 [INFO]: Epoch 033 - training loss: 0.3984, validation loss: 0.0269
2024-05-25 04:55:32 [INFO]: Epoch 034 - training loss: 0.3955, validation loss: 0.0264
2024-05-25 04:55:37 [INFO]: Epoch 035 - training loss: 0.3955, validation loss: 0.0268
2024-05-25 04:55:43 [INFO]: Epoch 036 - training loss: 0.4417, validation loss: 0.0270
2024-05-25 04:55:49 [INFO]: Epoch 037 - training loss: 0.4139, validation loss: 0.0273
2024-05-25 04:55:55 [INFO]: Epoch 038 - training loss: 0.4013, validation loss: 0.0274
2024-05-25 04:56:01 [INFO]: Epoch 039 - training loss: 0.4024, validation loss: 0.0271
2024-05-25 04:56:07 [INFO]: Epoch 040 - training loss: 0.4013, validation loss: 0.0273
2024-05-25 04:56:12 [INFO]: Epoch 041 - training loss: 0.4073, validation loss: 0.0274
2024-05-25 04:56:18 [INFO]: Epoch 042 - training loss: 0.3953, validation loss: 0.0271
2024-05-25 04:56:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:56:18 [INFO]: Finished training. The best model is from epoch#32.
2024-05-25 04:56:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/BRITS_ettm1/20240525_T045211/BRITS.pypots
2024-05-25 04:56:19 [INFO]: BRITS on ETTm1: MAE=0.1450, MSE=0.0599
2024-05-25 04:56:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/BRITS_ettm1/imputation.pkl
2024-05-25 04:56:19 [INFO]: Using the given device: cuda:0
2024-05-25 04:56:19 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619
2024-05-25 04:56:19 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/tensorboard
2024-05-25 04:56:19 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 04:56:21 [INFO]: Epoch 001 - training loss: 1.3222, validation loss: 1.2410
2024-05-25 04:56:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch1_loss1.2409809231758118.pypots
2024-05-25 04:56:21 [INFO]: Epoch 002 - training loss: 0.9838, validation loss: 1.1174
2024-05-25 04:56:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch2_loss1.117400273680687.pypots
2024-05-25 04:56:22 [INFO]: Epoch 003 - training loss: 0.9046, validation loss: 1.0552
2024-05-25 04:56:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch3_loss1.055160939693451.pypots
2024-05-25 04:56:22 [INFO]: Epoch 004 - training loss: 0.8742, validation loss: 1.0365
2024-05-25 04:56:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch4_loss1.036459356546402.pypots
2024-05-25 04:56:22 [INFO]: Epoch 005 - training loss: 0.8721, validation loss: 1.0253
2024-05-25 04:56:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch5_loss1.0253318697214127.pypots
2024-05-25 04:56:22 [INFO]: Epoch 006 - training loss: 0.8826, validation loss: 1.0203
2024-05-25 04:56:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch6_loss1.0202940553426743.pypots
2024-05-25 04:56:22 [INFO]: Epoch 007 - training loss: 0.8887, validation loss: 1.0130
2024-05-25 04:56:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch7_loss1.0130112916231155.pypots
2024-05-25 04:56:23 [INFO]: Epoch 008 - training loss: 0.8631, validation loss: 1.0145
2024-05-25 04:56:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch8_loss1.014463946223259.pypots
2024-05-25 04:56:23 [INFO]: Epoch 009 - training loss: 0.8557, validation loss: 1.0172
2024-05-25 04:56:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch9_loss1.0172190070152283.pypots
2024-05-25 04:56:23 [INFO]: Epoch 010 - training loss: 0.8520, validation loss: 1.0182
2024-05-25 04:56:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch10_loss1.0181862711906433.pypots
2024-05-25 04:56:23 [INFO]: Epoch 011 - training loss: 0.8329, validation loss: 1.0161
2024-05-25 04:56:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch11_loss1.0161089152097702.pypots
2024-05-25 04:56:23 [INFO]: Epoch 012 - training loss: 0.8542, validation loss: 1.0216
2024-05-25 04:56:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch12_loss1.021593302488327.pypots
2024-05-25 04:56:23 [INFO]: Epoch 013 - training loss: 0.8412, validation loss: 1.0231
2024-05-25 04:56:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch13_loss1.0230717957019806.pypots
2024-05-25 04:56:24 [INFO]: Epoch 014 - training loss: 0.8478, validation loss: 1.0202
2024-05-25 04:56:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch14_loss1.0202467143535614.pypots
2024-05-25 04:56:24 [INFO]: Epoch 015 - training loss: 0.8427, validation loss: 1.0194
2024-05-25 04:56:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch15_loss1.019409254193306.pypots
2024-05-25 04:56:24 [INFO]: Epoch 016 - training loss: 0.8167, validation loss: 1.0150
2024-05-25 04:56:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch16_loss1.015002116560936.pypots
2024-05-25 04:56:24 [INFO]: Epoch 017 - training loss: 0.8200, validation loss: 1.0103
2024-05-25 04:56:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch17_loss1.0103252530097961.pypots
2024-05-25 04:56:24 [INFO]: Epoch 018 - training loss: 0.8287, validation loss: 1.0138
2024-05-25 04:56:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch18_loss1.013831689953804.pypots
2024-05-25 04:56:25 [INFO]: Epoch 019 - training loss: 0.8497, validation loss: 1.0166
2024-05-25 04:56:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch19_loss1.0166112929582596.pypots
2024-05-25 04:56:25 [INFO]: Epoch 020 - training loss: 0.8027, validation loss: 1.0070
2024-05-25 04:56:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch20_loss1.0070013403892517.pypots
2024-05-25 04:56:25 [INFO]: Epoch 021 - training loss: 0.8007, validation loss: 1.0091
2024-05-25 04:56:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch21_loss1.009133666753769.pypots
2024-05-25 04:56:25 [INFO]: Epoch 022 - training loss: 0.8291, validation loss: 0.9987
2024-05-25 04:56:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch22_loss0.9986687302589417.pypots
2024-05-25 04:56:25 [INFO]: Epoch 023 - training loss: 0.7981, validation loss: 0.9931
2024-05-25 04:56:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch23_loss0.9931476265192032.pypots
2024-05-25 04:56:26 [INFO]: Epoch 024 - training loss: 0.7947, validation loss: 0.9954
2024-05-25 04:56:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch24_loss0.9954187273979187.pypots
2024-05-25 04:56:26 [INFO]: Epoch 025 - training loss: 0.7768, validation loss: 0.9892
2024-05-25 04:56:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch25_loss0.9891986399888992.pypots
2024-05-25 04:56:26 [INFO]: Epoch 026 - training loss: 0.7808, validation loss: 0.9835
2024-05-25 04:56:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch26_loss0.983526885509491.pypots
2024-05-25 04:56:26 [INFO]: Epoch 027 - training loss: 0.7820, validation loss: 0.9791
2024-05-25 04:56:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch27_loss0.9791230410337448.pypots
2024-05-25 04:56:26 [INFO]: Epoch 028 - training loss: 0.7611, validation loss: 0.9795
2024-05-25 04:56:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch28_loss0.9795391857624054.pypots
2024-05-25 04:56:27 [INFO]: Epoch 029 - training loss: 0.7658, validation loss: 0.9768
2024-05-25 04:56:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch29_loss0.9767699986696243.pypots
2024-05-25 04:56:27 [INFO]: Epoch 030 - training loss: 0.7809, validation loss: 0.9700
2024-05-25 04:56:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch30_loss0.9700185805559158.pypots
2024-05-25 04:56:27 [INFO]: Epoch 031 - training loss: 0.7922, validation loss: 0.9656
2024-05-25 04:56:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch31_loss0.9655646532773972.pypots
2024-05-25 04:56:27 [INFO]: Epoch 032 - training loss: 0.7775, validation loss: 0.9578
2024-05-25 04:56:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch32_loss0.957786500453949.pypots
2024-05-25 04:56:27 [INFO]: Epoch 033 - training loss: 0.7840, validation loss: 0.9480
2024-05-25 04:56:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch33_loss0.9480414092540741.pypots
2024-05-25 04:56:27 [INFO]: Epoch 034 - training loss: 0.7515, validation loss: 0.9467
2024-05-25 04:56:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch34_loss0.9466669410467148.pypots
2024-05-25 04:56:28 [INFO]: Epoch 035 - training loss: 0.7452, validation loss: 0.9398
2024-05-25 04:56:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch35_loss0.9397987723350525.pypots
2024-05-25 04:56:28 [INFO]: Epoch 036 - training loss: 0.7462, validation loss: 0.9356
2024-05-25 04:56:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch36_loss0.9356205314397812.pypots
2024-05-25 04:56:28 [INFO]: Epoch 037 - training loss: 0.7712, validation loss: 0.9279
2024-05-25 04:56:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch37_loss0.9278617948293686.pypots
2024-05-25 04:56:28 [INFO]: Epoch 038 - training loss: 0.7644, validation loss: 0.9235
2024-05-25 04:56:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch38_loss0.9235105067491531.pypots
2024-05-25 04:56:28 [INFO]: Epoch 039 - training loss: 0.7626, validation loss: 0.9201
2024-05-25 04:56:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch39_loss0.9200791567564011.pypots
2024-05-25 04:56:29 [INFO]: Epoch 040 - training loss: 0.7550, validation loss: 0.9169
2024-05-25 04:56:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch40_loss0.9168633818626404.pypots
2024-05-25 04:56:29 [INFO]: Epoch 041 - training loss: 0.7488, validation loss: 0.9110
2024-05-25 04:56:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch41_loss0.9109712690114975.pypots
2024-05-25 04:56:29 [INFO]: Epoch 042 - training loss: 0.7759, validation loss: 0.9076
2024-05-25 04:56:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch42_loss0.9076303839683533.pypots
2024-05-25 04:56:29 [INFO]: Epoch 043 - training loss: 0.7828, validation loss: 0.9021
2024-05-25 04:56:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch43_loss0.9020676165819168.pypots
2024-05-25 04:56:29 [INFO]: Epoch 044 - training loss: 0.7648, validation loss: 0.8982
2024-05-25 04:56:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch44_loss0.8982413560152054.pypots
2024-05-25 04:56:30 [INFO]: Epoch 045 - training loss: 0.7722, validation loss: 0.8936
2024-05-25 04:56:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch45_loss0.8936268538236618.pypots
2024-05-25 04:56:30 [INFO]: Epoch 046 - training loss: 0.7320, validation loss: 0.8940
2024-05-25 04:56:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch46_loss0.8939553499221802.pypots
2024-05-25 04:56:30 [INFO]: Epoch 047 - training loss: 0.7422, validation loss: 0.8904
2024-05-25 04:56:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch47_loss0.8903841972351074.pypots
2024-05-25 04:56:30 [INFO]: Epoch 048 - training loss: 0.7533, validation loss: 0.8847
2024-05-25 04:56:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch48_loss0.884698361158371.pypots
2024-05-25 04:56:30 [INFO]: Epoch 049 - training loss: 0.7613, validation loss: 0.8846
2024-05-25 04:56:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch49_loss0.8845987468957901.pypots
2024-05-25 04:56:30 [INFO]: Epoch 050 - training loss: 0.7482, validation loss: 0.8803
2024-05-25 04:56:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch50_loss0.8803065717220306.pypots
2024-05-25 04:56:31 [INFO]: Epoch 051 - training loss: 0.7851, validation loss: 0.8814
2024-05-25 04:56:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch51_loss0.8813836723566055.pypots
2024-05-25 04:56:31 [INFO]: Epoch 052 - training loss: 0.7293, validation loss: 0.8765
2024-05-25 04:56:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch52_loss0.876523032784462.pypots
2024-05-25 04:56:31 [INFO]: Epoch 053 - training loss: 0.7573, validation loss: 0.8754
2024-05-25 04:56:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch53_loss0.8754380792379379.pypots
2024-05-25 04:56:31 [INFO]: Epoch 054 - training loss: 0.7687, validation loss: 0.8755
2024-05-25 04:56:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch54_loss0.8754895776510239.pypots
2024-05-25 04:56:31 [INFO]: Epoch 055 - training loss: 0.7430, validation loss: 0.8729
2024-05-25 04:56:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch55_loss0.8729484230279922.pypots
2024-05-25 04:56:32 [INFO]: Epoch 056 - training loss: 0.7510, validation loss: 0.8734
2024-05-25 04:56:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch56_loss0.8733876943588257.pypots
2024-05-25 04:56:32 [INFO]: Epoch 057 - training loss: 0.7557, validation loss: 0.8731
2024-05-25 04:56:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch57_loss0.8730908334255219.pypots
2024-05-25 04:56:32 [INFO]: Epoch 058 - training loss: 0.7256, validation loss: 0.8727
2024-05-25 04:56:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch58_loss0.8726528882980347.pypots
2024-05-25 04:56:32 [INFO]: Epoch 059 - training loss: 0.7215, validation loss: 0.8712
2024-05-25 04:56:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch59_loss0.8711763322353363.pypots
2024-05-25 04:56:32 [INFO]: Epoch 060 - training loss: 0.7365, validation loss: 0.8662
2024-05-25 04:56:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch60_loss0.8662074953317642.pypots
2024-05-25 04:56:33 [INFO]: Epoch 061 - training loss: 0.7473, validation loss: 0.8696
2024-05-25 04:56:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch61_loss0.8695565164089203.pypots
2024-05-25 04:56:33 [INFO]: Epoch 062 - training loss: 0.7259, validation loss: 0.8665
2024-05-25 04:56:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch62_loss0.8664868623018265.pypots
2024-05-25 04:56:33 [INFO]: Epoch 063 - training loss: 0.7590, validation loss: 0.8670
2024-05-25 04:56:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch63_loss0.8669557571411133.pypots
2024-05-25 04:56:33 [INFO]: Epoch 064 - training loss: 0.7253, validation loss: 0.8676
2024-05-25 04:56:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch64_loss0.8676147907972336.pypots
2024-05-25 04:56:33 [INFO]: Epoch 065 - training loss: 0.7332, validation loss: 0.8654
2024-05-25 04:56:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch65_loss0.8654230237007141.pypots
2024-05-25 04:56:33 [INFO]: Epoch 066 - training loss: 0.7356, validation loss: 0.8681
2024-05-25 04:56:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch66_loss0.8681229650974274.pypots
2024-05-25 04:56:34 [INFO]: Epoch 067 - training loss: 0.7252, validation loss: 0.8665
2024-05-25 04:56:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch67_loss0.8665168285369873.pypots
2024-05-25 04:56:34 [INFO]: Epoch 068 - training loss: 0.7483, validation loss: 0.8669
2024-05-25 04:56:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch68_loss0.8668684363365173.pypots
2024-05-25 04:56:34 [INFO]: Epoch 069 - training loss: 0.7680, validation loss: 0.8639
2024-05-25 04:56:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch69_loss0.863882914185524.pypots
2024-05-25 04:56:34 [INFO]: Epoch 070 - training loss: 0.7504, validation loss: 0.8617
2024-05-25 04:56:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch70_loss0.8616905808448792.pypots
2024-05-25 04:56:34 [INFO]: Epoch 071 - training loss: 0.7385, validation loss: 0.8647
2024-05-25 04:56:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch71_loss0.8646814525127411.pypots
2024-05-25 04:56:35 [INFO]: Epoch 072 - training loss: 0.7147, validation loss: 0.8632
2024-05-25 04:56:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch72_loss0.863225907087326.pypots
2024-05-25 04:56:35 [INFO]: Epoch 073 - training loss: 0.7238, validation loss: 0.8656
2024-05-25 04:56:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch73_loss0.8656000345945358.pypots
2024-05-25 04:56:35 [INFO]: Epoch 074 - training loss: 0.7378, validation loss: 0.8622
2024-05-25 04:56:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch74_loss0.8622497618198395.pypots
2024-05-25 04:56:35 [INFO]: Epoch 075 - training loss: 0.7343, validation loss: 0.8570
2024-05-25 04:56:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch75_loss0.8570432662963867.pypots
2024-05-25 04:56:35 [INFO]: Epoch 076 - training loss: 0.7375, validation loss: 0.8584
2024-05-25 04:56:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch76_loss0.8583548963069916.pypots
2024-05-25 04:56:36 [INFO]: Epoch 077 - training loss: 0.7379, validation loss: 0.8592
2024-05-25 04:56:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch77_loss0.8591521233320236.pypots
2024-05-25 04:56:36 [INFO]: Epoch 078 - training loss: 0.7457, validation loss: 0.8599
2024-05-25 04:56:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch78_loss0.8598527908325195.pypots
2024-05-25 04:56:36 [INFO]: Epoch 079 - training loss: 0.7382, validation loss: 0.8566
2024-05-25 04:56:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch79_loss0.8566378802061081.pypots
2024-05-25 04:56:36 [INFO]: Epoch 080 - training loss: 0.7322, validation loss: 0.8604
2024-05-25 04:56:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch80_loss0.8603761494159698.pypots
2024-05-25 04:56:36 [INFO]: Epoch 081 - training loss: 0.7362, validation loss: 0.8573
2024-05-25 04:56:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch81_loss0.8573090881109238.pypots
2024-05-25 04:56:36 [INFO]: Epoch 082 - training loss: 0.7304, validation loss: 0.8580
2024-05-25 04:56:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch82_loss0.8579740673303604.pypots
2024-05-25 04:56:37 [INFO]: Epoch 083 - training loss: 0.7214, validation loss: 0.8538
2024-05-25 04:56:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch83_loss0.8537725210189819.pypots
2024-05-25 04:56:37 [INFO]: Epoch 084 - training loss: 0.7344, validation loss: 0.8612
2024-05-25 04:56:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch84_loss0.8612471967935562.pypots
2024-05-25 04:56:37 [INFO]: Epoch 085 - training loss: 0.7340, validation loss: 0.8549
2024-05-25 04:56:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch85_loss0.8549293279647827.pypots
2024-05-25 04:56:37 [INFO]: Epoch 086 - training loss: 0.7057, validation loss: 0.8542
2024-05-25 04:56:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch86_loss0.8542095422744751.pypots
2024-05-25 04:56:37 [INFO]: Epoch 087 - training loss: 0.7124, validation loss: 0.8540
2024-05-25 04:56:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch87_loss0.8540340662002563.pypots
2024-05-25 04:56:38 [INFO]: Epoch 088 - training loss: 0.7362, validation loss: 0.8592
2024-05-25 04:56:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch88_loss0.859198734164238.pypots
2024-05-25 04:56:38 [INFO]: Epoch 089 - training loss: 0.7250, validation loss: 0.8517
2024-05-25 04:56:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch89_loss0.851709395647049.pypots
2024-05-25 04:56:38 [INFO]: Epoch 090 - training loss: 0.7269, validation loss: 0.8532
2024-05-25 04:56:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch90_loss0.853176087141037.pypots
2024-05-25 04:56:38 [INFO]: Epoch 091 - training loss: 0.7354, validation loss: 0.8538
2024-05-25 04:56:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch91_loss0.8538401126861572.pypots
2024-05-25 04:56:38 [INFO]: Epoch 092 - training loss: 0.7371, validation loss: 0.8572
2024-05-25 04:56:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch92_loss0.8571767956018448.pypots
2024-05-25 04:56:39 [INFO]: Epoch 093 - training loss: 0.7291, validation loss: 0.8516
2024-05-25 04:56:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch93_loss0.8516363054513931.pypots
2024-05-25 04:56:39 [INFO]: Epoch 094 - training loss: 0.7150, validation loss: 0.8541
2024-05-25 04:56:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch94_loss0.8541097193956375.pypots
2024-05-25 04:56:39 [INFO]: Epoch 095 - training loss: 0.7315, validation loss: 0.8495
2024-05-25 04:56:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch95_loss0.8494808822870255.pypots
2024-05-25 04:56:39 [INFO]: Epoch 096 - training loss: 0.7286, validation loss: 0.8503
2024-05-25 04:56:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch96_loss0.8503288179636002.pypots
2024-05-25 04:56:39 [INFO]: Epoch 097 - training loss: 0.7245, validation loss: 0.8507
2024-05-25 04:56:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch97_loss0.8507186025381088.pypots
2024-05-25 04:56:39 [INFO]: Epoch 098 - training loss: 0.7269, validation loss: 0.8487
2024-05-25 04:56:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch98_loss0.8487386703491211.pypots
2024-05-25 04:56:40 [INFO]: Epoch 099 - training loss: 0.7421, validation loss: 0.8513
2024-05-25 04:56:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch99_loss0.8513442575931549.pypots
2024-05-25 04:56:40 [INFO]: Epoch 100 - training loss: 0.7477, validation loss: 0.8495
2024-05-25 04:56:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch100_loss0.8494504243135452.pypots
2024-05-25 04:56:40 [INFO]: Epoch 101 - training loss: 0.7437, validation loss: 0.8476
2024-05-25 04:56:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch101_loss0.8476263582706451.pypots
2024-05-25 04:56:40 [INFO]: Epoch 102 - training loss: 0.7124, validation loss: 0.8471
2024-05-25 04:56:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch102_loss0.847062423825264.pypots
2024-05-25 04:56:40 [INFO]: Epoch 103 - training loss: 0.7601, validation loss: 0.8528
2024-05-25 04:56:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch103_loss0.8527835607528687.pypots
2024-05-25 04:56:41 [INFO]: Epoch 104 - training loss: 0.7430, validation loss: 0.8462
2024-05-25 04:56:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch104_loss0.8462413400411606.pypots
2024-05-25 04:56:41 [INFO]: Epoch 105 - training loss: 0.7281, validation loss: 0.8439
2024-05-25 04:56:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch105_loss0.84385547041893.pypots
2024-05-25 04:56:41 [INFO]: Epoch 106 - training loss: 0.7125, validation loss: 0.8443
2024-05-25 04:56:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch106_loss0.8443107008934021.pypots
2024-05-25 04:56:41 [INFO]: Epoch 107 - training loss: 0.7314, validation loss: 0.8452
2024-05-25 04:56:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch107_loss0.8451765477657318.pypots
2024-05-25 04:56:41 [INFO]: Epoch 108 - training loss: 0.7214, validation loss: 0.8432
2024-05-25 04:56:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch108_loss0.8432066142559052.pypots
2024-05-25 04:56:42 [INFO]: Epoch 109 - training loss: 0.7208, validation loss: 0.8447
2024-05-25 04:56:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch109_loss0.8446558117866516.pypots
2024-05-25 04:56:42 [INFO]: Epoch 110 - training loss: 0.7258, validation loss: 0.8397
2024-05-25 04:56:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch110_loss0.8397417515516281.pypots
2024-05-25 04:56:42 [INFO]: Epoch 111 - training loss: 0.7249, validation loss: 0.8413
2024-05-25 04:56:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch111_loss0.841290071606636.pypots
2024-05-25 04:56:42 [INFO]: Epoch 112 - training loss: 0.7149, validation loss: 0.8418
2024-05-25 04:56:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch112_loss0.8417875021696091.pypots
2024-05-25 04:56:42 [INFO]: Epoch 113 - training loss: 0.7291, validation loss: 0.8390
2024-05-25 04:56:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch113_loss0.8390002548694611.pypots
2024-05-25 04:56:42 [INFO]: Epoch 114 - training loss: 0.7197, validation loss: 0.8388
2024-05-25 04:56:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch114_loss0.8387849926948547.pypots
2024-05-25 04:56:43 [INFO]: Epoch 115 - training loss: 0.7182, validation loss: 0.8393
2024-05-25 04:56:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch115_loss0.8392638266086578.pypots
2024-05-25 04:56:43 [INFO]: Epoch 116 - training loss: 0.7273, validation loss: 0.8354
2024-05-25 04:56:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch116_loss0.8353535532951355.pypots
2024-05-25 04:56:43 [INFO]: Epoch 117 - training loss: 0.7268, validation loss: 0.8390
2024-05-25 04:56:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch117_loss0.8390301764011383.pypots
2024-05-25 04:56:43 [INFO]: Epoch 118 - training loss: 0.7210, validation loss: 0.8329
2024-05-25 04:56:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch118_loss0.8329182118177414.pypots
2024-05-25 04:56:43 [INFO]: Epoch 119 - training loss: 0.7459, validation loss: 0.8336
2024-05-25 04:56:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch119_loss0.8335887938737869.pypots
2024-05-25 04:56:44 [INFO]: Epoch 120 - training loss: 0.7193, validation loss: 0.8342
2024-05-25 04:56:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch120_loss0.8341769576072693.pypots
2024-05-25 04:56:44 [INFO]: Epoch 121 - training loss: 0.7261, validation loss: 0.8299
2024-05-25 04:56:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch121_loss0.8298979848623276.pypots
2024-05-25 04:56:44 [INFO]: Epoch 122 - training loss: 0.7582, validation loss: 0.8340
2024-05-25 04:56:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch122_loss0.8340364396572113.pypots
2024-05-25 04:56:44 [INFO]: Epoch 123 - training loss: 0.7153, validation loss: 0.8290
2024-05-25 04:56:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch123_loss0.8290156722068787.pypots
2024-05-25 04:56:44 [INFO]: Epoch 124 - training loss: 0.7239, validation loss: 0.8318
2024-05-25 04:56:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch124_loss0.8317901343107224.pypots
2024-05-25 04:56:45 [INFO]: Epoch 125 - training loss: 0.7194, validation loss: 0.8276
2024-05-25 04:56:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch125_loss0.8276018351316452.pypots
2024-05-25 04:56:45 [INFO]: Epoch 126 - training loss: 0.7161, validation loss: 0.8281
2024-05-25 04:56:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch126_loss0.8280518651008606.pypots
2024-05-25 04:56:45 [INFO]: Epoch 127 - training loss: 0.7117, validation loss: 0.8267
2024-05-25 04:56:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch127_loss0.8266726583242416.pypots
2024-05-25 04:56:45 [INFO]: Epoch 128 - training loss: 0.7217, validation loss: 0.8316
2024-05-25 04:56:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch128_loss0.8316183090209961.pypots
2024-05-25 04:56:45 [INFO]: Epoch 129 - training loss: 0.7274, validation loss: 0.8267
2024-05-25 04:56:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch129_loss0.8267457038164139.pypots
2024-05-25 04:56:45 [INFO]: Epoch 130 - training loss: 0.7471, validation loss: 0.8265
2024-05-25 04:56:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch130_loss0.8264853358268738.pypots
2024-05-25 04:56:46 [INFO]: Epoch 131 - training loss: 0.7045, validation loss: 0.8248
2024-05-25 04:56:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch131_loss0.824797660112381.pypots
2024-05-25 04:56:46 [INFO]: Epoch 132 - training loss: 0.7245, validation loss: 0.8244
2024-05-25 04:56:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch132_loss0.8244239985942841.pypots
2024-05-25 04:56:46 [INFO]: Epoch 133 - training loss: 0.7270, validation loss: 0.8268
2024-05-25 04:56:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch133_loss0.8268121033906937.pypots
2024-05-25 04:56:46 [INFO]: Epoch 134 - training loss: 0.7329, validation loss: 0.8236
2024-05-25 04:56:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch134_loss0.8235512971878052.pypots
2024-05-25 04:56:46 [INFO]: Epoch 135 - training loss: 0.7140, validation loss: 0.8226
2024-05-25 04:56:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch135_loss0.8225792497396469.pypots
2024-05-25 04:56:47 [INFO]: Epoch 136 - training loss: 0.7193, validation loss: 0.8205
2024-05-25 04:56:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch136_loss0.8205082714557648.pypots
2024-05-25 04:56:47 [INFO]: Epoch 137 - training loss: 0.7255, validation loss: 0.8243
2024-05-25 04:56:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch137_loss0.8243463635444641.pypots
2024-05-25 04:56:47 [INFO]: Epoch 138 - training loss: 0.7121, validation loss: 0.8187
2024-05-25 04:56:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch138_loss0.8187124729156494.pypots
2024-05-25 04:56:47 [INFO]: Epoch 139 - training loss: 0.7186, validation loss: 0.8185
2024-05-25 04:56:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch139_loss0.8184545934200287.pypots
2024-05-25 04:56:47 [INFO]: Epoch 140 - training loss: 0.7122, validation loss: 0.8185
2024-05-25 04:56:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch140_loss0.8184583336114883.pypots
2024-05-25 04:56:48 [INFO]: Epoch 141 - training loss: 0.7250, validation loss: 0.8141
2024-05-25 04:56:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch141_loss0.81413933634758.pypots
2024-05-25 04:56:48 [INFO]: Epoch 142 - training loss: 0.7215, validation loss: 0.8140
2024-05-25 04:56:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch142_loss0.8139584213495255.pypots
2024-05-25 04:56:48 [INFO]: Epoch 143 - training loss: 0.7116, validation loss: 0.8169
2024-05-25 04:56:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch143_loss0.8169436901807785.pypots
2024-05-25 04:56:48 [INFO]: Epoch 144 - training loss: 0.7392, validation loss: 0.8152
2024-05-25 04:56:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch144_loss0.8152218014001846.pypots
2024-05-25 04:56:48 [INFO]: Epoch 145 - training loss: 0.7273, validation loss: 0.8211
2024-05-25 04:56:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch145_loss0.8211423009634018.pypots
2024-05-25 04:56:49 [INFO]: Epoch 146 - training loss: 0.7284, validation loss: 0.8144
2024-05-25 04:56:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch146_loss0.8143613338470459.pypots
2024-05-25 04:56:49 [INFO]: Epoch 147 - training loss: 0.7610, validation loss: 0.8138
2024-05-25 04:56:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch147_loss0.8138382881879807.pypots
2024-05-25 04:56:49 [INFO]: Epoch 148 - training loss: 0.7305, validation loss: 0.8084
2024-05-25 04:56:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch148_loss0.8083898276090622.pypots
2024-05-25 04:56:49 [INFO]: Epoch 149 - training loss: 0.7397, validation loss: 0.8108
2024-05-25 04:56:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch149_loss0.8107576966285706.pypots
2024-05-25 04:56:49 [INFO]: Epoch 150 - training loss: 0.7033, validation loss: 0.8155
2024-05-25 04:56:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch150_loss0.8155327290296555.pypots
2024-05-25 04:56:49 [INFO]: Epoch 151 - training loss: 0.7561, validation loss: 0.8182
2024-05-25 04:56:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch151_loss0.8181807547807693.pypots
2024-05-25 04:56:50 [INFO]: Epoch 152 - training loss: 0.7195, validation loss: 0.8123
2024-05-25 04:56:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch152_loss0.812316283583641.pypots
2024-05-25 04:56:50 [INFO]: Epoch 153 - training loss: 0.7141, validation loss: 0.8147
2024-05-25 04:56:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch153_loss0.8147426694631577.pypots
2024-05-25 04:56:50 [INFO]: Epoch 154 - training loss: 0.7120, validation loss: 0.8100
2024-05-25 04:56:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch154_loss0.8100484311580658.pypots
2024-05-25 04:56:50 [INFO]: Epoch 155 - training loss: 0.7251, validation loss: 0.8123
2024-05-25 04:56:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch155_loss0.8122735917568207.pypots
2024-05-25 04:56:50 [INFO]: Epoch 156 - training loss: 0.7557, validation loss: 0.8100
2024-05-25 04:56:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch156_loss0.810028538107872.pypots
2024-05-25 04:56:51 [INFO]: Epoch 157 - training loss: 0.7218, validation loss: 0.8096
2024-05-25 04:56:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch157_loss0.8095767199993134.pypots
2024-05-25 04:56:51 [INFO]: Epoch 158 - training loss: 0.7019, validation loss: 0.8052
2024-05-25 04:56:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch158_loss0.8052001744508743.pypots
2024-05-25 04:56:51 [INFO]: Epoch 159 - training loss: 0.7165, validation loss: 0.8094
2024-05-25 04:56:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch159_loss0.8094310611486435.pypots
2024-05-25 04:56:51 [INFO]: Epoch 160 - training loss: 0.7283, validation loss: 0.8096
2024-05-25 04:56:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch160_loss0.8096279501914978.pypots
2024-05-25 04:56:51 [INFO]: Epoch 161 - training loss: 0.7144, validation loss: 0.8065
2024-05-25 04:56:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch161_loss0.8064982891082764.pypots
2024-05-25 04:56:52 [INFO]: Epoch 162 - training loss: 0.7007, validation loss: 0.8083
2024-05-25 04:56:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch162_loss0.8082754760980606.pypots
2024-05-25 04:56:52 [INFO]: Epoch 163 - training loss: 0.7217, validation loss: 0.8086
2024-05-25 04:56:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch163_loss0.8085980266332626.pypots
2024-05-25 04:56:52 [INFO]: Epoch 164 - training loss: 0.7352, validation loss: 0.8097
2024-05-25 04:56:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch164_loss0.8097120523452759.pypots
2024-05-25 04:56:52 [INFO]: Epoch 165 - training loss: 0.7289, validation loss: 0.8066
2024-05-25 04:56:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch165_loss0.8066000491380692.pypots
2024-05-25 04:56:52 [INFO]: Epoch 166 - training loss: 0.7058, validation loss: 0.8043
2024-05-25 04:56:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch166_loss0.8042585253715515.pypots
2024-05-25 04:56:52 [INFO]: Epoch 167 - training loss: 0.7352, validation loss: 0.8082
2024-05-25 04:56:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch167_loss0.8082302808761597.pypots
2024-05-25 04:56:53 [INFO]: Epoch 168 - training loss: 0.7228, validation loss: 0.8064
2024-05-25 04:56:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch168_loss0.8064458072185516.pypots
2024-05-25 04:56:53 [INFO]: Epoch 169 - training loss: 0.7282, validation loss: 0.8045
2024-05-25 04:56:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch169_loss0.8044826239347458.pypots
2024-05-25 04:56:53 [INFO]: Epoch 170 - training loss: 0.7127, validation loss: 0.8047
2024-05-25 04:56:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch170_loss0.8047016710042953.pypots
2024-05-25 04:56:53 [INFO]: Epoch 171 - training loss: 0.7173, validation loss: 0.8022
2024-05-25 04:56:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch171_loss0.8021960556507111.pypots
2024-05-25 04:56:53 [INFO]: Epoch 172 - training loss: 0.7484, validation loss: 0.8035
2024-05-25 04:56:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch172_loss0.8035379946231842.pypots
2024-05-25 04:56:54 [INFO]: Epoch 173 - training loss: 0.7326, validation loss: 0.8015
2024-05-25 04:56:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch173_loss0.8014535009860992.pypots
2024-05-25 04:56:54 [INFO]: Epoch 174 - training loss: 0.7063, validation loss: 0.8044
2024-05-25 04:56:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch174_loss0.804396778345108.pypots
2024-05-25 04:56:54 [INFO]: Epoch 175 - training loss: 0.7250, validation loss: 0.8017
2024-05-25 04:56:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch175_loss0.8017457574605942.pypots
2024-05-25 04:56:54 [INFO]: Epoch 176 - training loss: 0.6982, validation loss: 0.7984
2024-05-25 04:56:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch176_loss0.7983946949243546.pypots
2024-05-25 04:56:54 [INFO]: Epoch 177 - training loss: 0.7137, validation loss: 0.7975
2024-05-25 04:56:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch177_loss0.7974870651960373.pypots
2024-05-25 04:56:55 [INFO]: Epoch 178 - training loss: 0.7172, validation loss: 0.8004
2024-05-25 04:56:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch178_loss0.8004344403743744.pypots
2024-05-25 04:56:55 [INFO]: Epoch 179 - training loss: 0.7115, validation loss: 0.7986
2024-05-25 04:56:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch179_loss0.7986433207988739.pypots
2024-05-25 04:56:55 [INFO]: Epoch 180 - training loss: 0.7122, validation loss: 0.7975
2024-05-25 04:56:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch180_loss0.7975119650363922.pypots
2024-05-25 04:56:55 [INFO]: Epoch 181 - training loss: 0.7276, validation loss: 0.7999
2024-05-25 04:56:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch181_loss0.7998770624399185.pypots
2024-05-25 04:56:55 [INFO]: Epoch 182 - training loss: 0.7106, validation loss: 0.8025
2024-05-25 04:56:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch182_loss0.8025223016738892.pypots
2024-05-25 04:56:55 [INFO]: Epoch 183 - training loss: 0.7378, validation loss: 0.7931
2024-05-25 04:56:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch183_loss0.7930599749088287.pypots
2024-05-25 04:56:56 [INFO]: Epoch 184 - training loss: 0.7181, validation loss: 0.7967
2024-05-25 04:56:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch184_loss0.7967196255922318.pypots
2024-05-25 04:56:56 [INFO]: Epoch 185 - training loss: 0.7157, validation loss: 0.7987
2024-05-25 04:56:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch185_loss0.7987149506807327.pypots
2024-05-25 04:56:56 [INFO]: Epoch 186 - training loss: 0.7207, validation loss: 0.8005
2024-05-25 04:56:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch186_loss0.8004963248968124.pypots
2024-05-25 04:56:56 [INFO]: Epoch 187 - training loss: 0.7096, validation loss: 0.7947
2024-05-25 04:56:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch187_loss0.7946839332580566.pypots
2024-05-25 04:56:56 [INFO]: Epoch 188 - training loss: 0.7073, validation loss: 0.7960
2024-05-25 04:56:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch188_loss0.7960206419229507.pypots
2024-05-25 04:56:57 [INFO]: Epoch 189 - training loss: 0.7081, validation loss: 0.7957
2024-05-25 04:56:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch189_loss0.7957143783569336.pypots
2024-05-25 04:56:57 [INFO]: Epoch 190 - training loss: 0.6979, validation loss: 0.7958
2024-05-25 04:56:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch190_loss0.7957926541566849.pypots
2024-05-25 04:56:57 [INFO]: Epoch 191 - training loss: 0.7262, validation loss: 0.7968
2024-05-25 04:56:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch191_loss0.7967750281095505.pypots
2024-05-25 04:56:57 [INFO]: Epoch 192 - training loss: 0.7253, validation loss: 0.7930
2024-05-25 04:56:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch192_loss0.7930117845535278.pypots
2024-05-25 04:56:57 [INFO]: Epoch 193 - training loss: 0.6954, validation loss: 0.7963
2024-05-25 04:56:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch193_loss0.7963176667690277.pypots
2024-05-25 04:56:58 [INFO]: Epoch 194 - training loss: 0.7218, validation loss: 0.7972
2024-05-25 04:56:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch194_loss0.7972319722175598.pypots
2024-05-25 04:56:58 [INFO]: Epoch 195 - training loss: 0.7355, validation loss: 0.7953
2024-05-25 04:56:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch195_loss0.7953242063522339.pypots
2024-05-25 04:56:58 [INFO]: Epoch 196 - training loss: 0.7197, validation loss: 0.7956
2024-05-25 04:56:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch196_loss0.7956256866455078.pypots
2024-05-25 04:56:58 [INFO]: Epoch 197 - training loss: 0.7345, validation loss: 0.7932
2024-05-25 04:56:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch197_loss0.7931768447160721.pypots
2024-05-25 04:56:58 [INFO]: Epoch 198 - training loss: 0.7655, validation loss: 0.7942
2024-05-25 04:56:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch198_loss0.7942467480897903.pypots
2024-05-25 04:56:58 [INFO]: Epoch 199 - training loss: 0.7290, validation loss: 0.7942
2024-05-25 04:56:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch199_loss0.7941684722900391.pypots
2024-05-25 04:56:59 [INFO]: Epoch 200 - training loss: 0.7055, validation loss: 0.7932
2024-05-25 04:56:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch200_loss0.793217271566391.pypots
2024-05-25 04:56:59 [INFO]: Epoch 201 - training loss: 0.7127, validation loss: 0.7941
2024-05-25 04:56:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch201_loss0.794122725725174.pypots
2024-05-25 04:56:59 [INFO]: Epoch 202 - training loss: 0.7216, validation loss: 0.7942
2024-05-25 04:56:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN_epoch202_loss0.7941917181015015.pypots
2024-05-25 04:56:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:56:59 [INFO]: Finished training. The best model is from epoch#192.
2024-05-25 04:56:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T045619/MRNN.pypots
2024-05-25 04:56:59 [INFO]: MRNN on ETTm1: MAE=0.5972, MSE=0.9920
2024-05-25 04:56:59 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/MRNN_ettm1/imputation.pkl
2024-05-25 04:56:59 [INFO]: Using the given device: cpu
2024-05-25 04:56:59 [INFO]: LOCF on ETTm1: MAE=0.1420, MSE=0.0788
2024-05-25 04:56:59 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_ettm1".
2024-05-25 04:56:59 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/LOCF_ettm1/imputation.pkl
2024-05-25 04:56:59 [INFO]: Median on ETTm1: MAE=0.6533, MSE=0.8148
2024-05-25 04:56:59 [INFO]: Successfully created the given path "saved_results/round_3/Median_ettm1".
2024-05-25 04:56:59 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Median_ettm1/imputation.pkl
2024-05-25 04:56:59 [INFO]: Mean on ETTm1: MAE=0.6593, MSE=0.7994
2024-05-25 04:56:59 [INFO]: Successfully created the given path "saved_results/round_3/Mean_ettm1".
2024-05-25 04:56:59 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Mean_ettm1/imputation.pkl
2024-05-25 04:56:59 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-25 04:56:59 [INFO]: Using the given device: cuda:0
2024-05-25 04:56:59 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/SAITS_ettm1/20240525_T045659
2024-05-25 04:56:59 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/SAITS_ettm1/20240525_T045659/tensorboard
2024-05-25 04:57:00 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 04:57:00 [INFO]: Epoch 001 - training loss: 1.1704, validation loss: 0.2504
2024-05-25 04:57:01 [INFO]: Epoch 002 - training loss: 0.8879, validation loss: 0.1504
2024-05-25 04:57:01 [INFO]: Epoch 003 - training loss: 0.8010, validation loss: 0.1046
2024-05-25 04:57:01 [INFO]: Epoch 004 - training loss: 0.7477, validation loss: 0.0985
2024-05-25 04:57:02 [INFO]: Epoch 005 - training loss: 0.7302, validation loss: 0.0869
2024-05-25 04:57:02 [INFO]: Epoch 006 - training loss: 0.7092, validation loss: 0.0873
2024-05-25 04:57:03 [INFO]: Epoch 007 - training loss: 0.6698, validation loss: 0.0701
2024-05-25 04:57:03 [INFO]: Epoch 008 - training loss: 0.6513, validation loss: 0.0700
2024-05-25 04:57:04 [INFO]: Epoch 009 - training loss: 0.6281, validation loss: 0.0787
2024-05-25 04:57:04 [INFO]: Epoch 010 - training loss: 0.6093, validation loss: 0.0582
2024-05-25 04:57:05 [INFO]: Epoch 011 - training loss: 0.6123, validation loss: 0.0581
2024-05-25 04:57:05 [INFO]: Epoch 012 - training loss: 0.5963, validation loss: 0.0571
2024-05-25 04:57:06 [INFO]: Epoch 013 - training loss: 0.5887, validation loss: 0.0588
2024-05-25 04:57:06 [INFO]: Epoch 014 - training loss: 0.5865, validation loss: 0.0755
2024-05-25 04:57:07 [INFO]: Epoch 015 - training loss: 0.6097, validation loss: 0.0487
2024-05-25 04:57:07 [INFO]: Epoch 016 - training loss: 0.5860, validation loss: 0.0606
2024-05-25 04:57:08 [INFO]: Epoch 017 - training loss: 0.5984, validation loss: 0.0546
2024-05-25 04:57:08 [INFO]: Epoch 018 - training loss: 0.5795, validation loss: 0.0581
2024-05-25 04:57:09 [INFO]: Epoch 019 - training loss: 0.5542, validation loss: 0.0512
2024-05-25 04:57:09 [INFO]: Epoch 020 - training loss: 0.5477, validation loss: 0.0502
2024-05-25 04:57:10 [INFO]: Epoch 021 - training loss: 0.5435, validation loss: 0.0427
2024-05-25 04:57:10 [INFO]: Epoch 022 - training loss: 0.5422, validation loss: 0.0451
2024-05-25 04:57:11 [INFO]: Epoch 023 - training loss: 0.5505, validation loss: 0.0523
2024-05-25 04:57:11 [INFO]: Epoch 024 - training loss: 0.5360, validation loss: 0.0466
2024-05-25 04:57:12 [INFO]: Epoch 025 - training loss: 0.5290, validation loss: 0.0472
2024-05-25 04:57:12 [INFO]: Epoch 026 - training loss: 0.5216, validation loss: 0.0416
2024-05-25 04:57:13 [INFO]: Epoch 027 - training loss: 0.5197, validation loss: 0.0406
2024-05-25 04:57:13 [INFO]: Epoch 028 - training loss: 0.5349, validation loss: 0.0524
2024-05-25 04:57:14 [INFO]: Epoch 029 - training loss: 0.5253, validation loss: 0.0477
2024-05-25 04:57:14 [INFO]: Epoch 030 - training loss: 0.5043, validation loss: 0.0567
2024-05-25 04:57:15 [INFO]: Epoch 031 - training loss: 0.5077, validation loss: 0.0440
2024-05-25 04:57:15 [INFO]: Epoch 032 - training loss: 0.5024, validation loss: 0.0433
2024-05-25 04:57:16 [INFO]: Epoch 033 - training loss: 0.5105, validation loss: 0.0572
2024-05-25 04:57:16 [INFO]: Epoch 034 - training loss: 0.5261, validation loss: 0.0389
2024-05-25 04:57:17 [INFO]: Epoch 035 - training loss: 0.5024, validation loss: 0.0405
2024-05-25 04:57:17 [INFO]: Epoch 036 - training loss: 0.4879, validation loss: 0.0477
2024-05-25 04:57:18 [INFO]: Epoch 037 - training loss: 0.4829, validation loss: 0.0436
2024-05-25 04:57:18 [INFO]: Epoch 038 - training loss: 0.4876, validation loss: 0.0346
2024-05-25 04:57:19 [INFO]: Epoch 039 - training loss: 0.4943, validation loss: 0.0336
2024-05-25 04:57:19 [INFO]: Epoch 040 - training loss: 0.4862, validation loss: 0.0543
2024-05-25 04:57:20 [INFO]: Epoch 041 - training loss: 0.5090, validation loss: 0.0496
2024-05-25 04:57:20 [INFO]: Epoch 042 - training loss: 0.4952, validation loss: 0.0457
2024-05-25 04:57:20 [INFO]: Epoch 043 - training loss: 0.4813, validation loss: 0.0376
2024-05-25 04:57:21 [INFO]: Epoch 044 - training loss: 0.4913, validation loss: 0.0429
2024-05-25 04:57:21 [INFO]: Epoch 045 - training loss: 0.4760, validation loss: 0.0353
2024-05-25 04:57:22 [INFO]: Epoch 046 - training loss: 0.4729, validation loss: 0.0384
2024-05-25 04:57:22 [INFO]: Epoch 047 - training loss: 0.4573, validation loss: 0.0521
2024-05-25 04:57:23 [INFO]: Epoch 048 - training loss: 0.4660, validation loss: 0.0520
2024-05-25 04:57:23 [INFO]: Epoch 049 - training loss: 0.4889, validation loss: 0.0398
2024-05-25 04:57:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:57:23 [INFO]: Finished training. The best model is from epoch#39.
2024-05-25 04:57:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/SAITS_ettm1/20240525_T045659/SAITS.pypots
2024-05-25 04:57:24 [INFO]: SAITS on ETTm1: MAE=0.1593, MSE=0.0484
2024-05-25 04:57:24 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/SAITS_ettm1/imputation.pkl
2024-05-25 04:57:24 [INFO]: Using the given device: cuda:0
2024-05-25 04:57:24 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/Transformer_ettm1/20240525_T045724
2024-05-25 04:57:24 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/Transformer_ettm1/20240525_T045724/tensorboard
2024-05-25 04:57:24 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 04:57:24 [INFO]: Epoch 001 - training loss: 1.2574, validation loss: 0.3398
2024-05-25 04:57:24 [INFO]: Epoch 002 - training loss: 0.7194, validation loss: 0.1691
2024-05-25 04:57:24 [INFO]: Epoch 003 - training loss: 0.5758, validation loss: 0.1337
2024-05-25 04:57:24 [INFO]: Epoch 004 - training loss: 0.5159, validation loss: 0.1028
2024-05-25 04:57:25 [INFO]: Epoch 005 - training loss: 0.4736, validation loss: 0.0945
2024-05-25 04:57:25 [INFO]: Epoch 006 - training loss: 0.4616, validation loss: 0.0819
2024-05-25 04:57:25 [INFO]: Epoch 007 - training loss: 0.4368, validation loss: 0.0740
2024-05-25 04:57:25 [INFO]: Epoch 008 - training loss: 0.4287, validation loss: 0.0704
2024-05-25 04:57:25 [INFO]: Epoch 009 - training loss: 0.4126, validation loss: 0.0652
2024-05-25 04:57:26 [INFO]: Epoch 010 - training loss: 0.3850, validation loss: 0.0621
2024-05-25 04:57:26 [INFO]: Epoch 011 - training loss: 0.3752, validation loss: 0.0573
2024-05-25 04:57:26 [INFO]: Epoch 012 - training loss: 0.3638, validation loss: 0.0577
2024-05-25 04:57:26 [INFO]: Epoch 013 - training loss: 0.3570, validation loss: 0.0560
2024-05-25 04:57:26 [INFO]: Epoch 014 - training loss: 0.3502, validation loss: 0.0517
2024-05-25 04:57:26 [INFO]: Epoch 015 - training loss: 0.3404, validation loss: 0.0483
2024-05-25 04:57:27 [INFO]: Epoch 016 - training loss: 0.3348, validation loss: 0.0513
2024-05-25 04:57:27 [INFO]: Epoch 017 - training loss: 0.3304, validation loss: 0.0495
2024-05-25 04:57:27 [INFO]: Epoch 018 - training loss: 0.3235, validation loss: 0.0494
2024-05-25 04:57:27 [INFO]: Epoch 019 - training loss: 0.3209, validation loss: 0.0484
2024-05-25 04:57:27 [INFO]: Epoch 020 - training loss: 0.3190, validation loss: 0.0492
2024-05-25 04:57:28 [INFO]: Epoch 021 - training loss: 0.3134, validation loss: 0.0418
2024-05-25 04:57:28 [INFO]: Epoch 022 - training loss: 0.3010, validation loss: 0.0444
2024-05-25 04:57:28 [INFO]: Epoch 023 - training loss: 0.3013, validation loss: 0.0435
2024-05-25 04:57:28 [INFO]: Epoch 024 - training loss: 0.2949, validation loss: 0.0424
2024-05-25 04:57:28 [INFO]: Epoch 025 - training loss: 0.2997, validation loss: 0.0400
2024-05-25 04:57:29 [INFO]: Epoch 026 - training loss: 0.2877, validation loss: 0.0414
2024-05-25 04:57:29 [INFO]: Epoch 027 - training loss: 0.2872, validation loss: 0.0392
2024-05-25 04:57:29 [INFO]: Epoch 028 - training loss: 0.2796, validation loss: 0.0390
2024-05-25 04:57:29 [INFO]: Epoch 029 - training loss: 0.2775, validation loss: 0.0376
2024-05-25 04:57:29 [INFO]: Epoch 030 - training loss: 0.2690, validation loss: 0.0397
2024-05-25 04:57:30 [INFO]: Epoch 031 - training loss: 0.2711, validation loss: 0.0366
2024-05-25 04:57:30 [INFO]: Epoch 032 - training loss: 0.2671, validation loss: 0.0373
2024-05-25 04:57:30 [INFO]: Epoch 033 - training loss: 0.2647, validation loss: 0.0405
2024-05-25 04:57:30 [INFO]: Epoch 034 - training loss: 0.2635, validation loss: 0.0400
2024-05-25 04:57:30 [INFO]: Epoch 035 - training loss: 0.2636, validation loss: 0.0387
2024-05-25 04:57:31 [INFO]: Epoch 036 - training loss: 0.2630, validation loss: 0.0342
2024-05-25 04:57:31 [INFO]: Epoch 037 - training loss: 0.2600, validation loss: 0.0332
2024-05-25 04:57:31 [INFO]: Epoch 038 - training loss: 0.2545, validation loss: 0.0340
2024-05-25 04:57:31 [INFO]: Epoch 039 - training loss: 0.2486, validation loss: 0.0339
2024-05-25 04:57:31 [INFO]: Epoch 040 - training loss: 0.2501, validation loss: 0.0342
2024-05-25 04:57:32 [INFO]: Epoch 041 - training loss: 0.2479, validation loss: 0.0330
2024-05-25 04:57:32 [INFO]: Epoch 042 - training loss: 0.2408, validation loss: 0.0309
2024-05-25 04:57:32 [INFO]: Epoch 043 - training loss: 0.2395, validation loss: 0.0313
2024-05-25 04:57:32 [INFO]: Epoch 044 - training loss: 0.2387, validation loss: 0.0308
2024-05-25 04:57:32 [INFO]: Epoch 045 - training loss: 0.2331, validation loss: 0.0310
2024-05-25 04:57:32 [INFO]: Epoch 046 - training loss: 0.2320, validation loss: 0.0333
2024-05-25 04:57:33 [INFO]: Epoch 047 - training loss: 0.2348, validation loss: 0.0299
2024-05-25 04:57:33 [INFO]: Epoch 048 - training loss: 0.2283, validation loss: 0.0287
2024-05-25 04:57:33 [INFO]: Epoch 049 - training loss: 0.2242, validation loss: 0.0292
2024-05-25 04:57:33 [INFO]: Epoch 050 - training loss: 0.2251, validation loss: 0.0292
2024-05-25 04:57:33 [INFO]: Epoch 051 - training loss: 0.2235, validation loss: 0.0313
2024-05-25 04:57:34 [INFO]: Epoch 052 - training loss: 0.2271, validation loss: 0.0290
2024-05-25 04:57:34 [INFO]: Epoch 053 - training loss: 0.2247, validation loss: 0.0306
2024-05-25 04:57:34 [INFO]: Epoch 054 - training loss: 0.2191, validation loss: 0.0307
2024-05-25 04:57:34 [INFO]: Epoch 055 - training loss: 0.2168, validation loss: 0.0293
2024-05-25 04:57:34 [INFO]: Epoch 056 - training loss: 0.2213, validation loss: 0.0292
2024-05-25 04:57:35 [INFO]: Epoch 057 - training loss: 0.2197, validation loss: 0.0310
2024-05-25 04:57:35 [INFO]: Epoch 058 - training loss: 0.2203, validation loss: 0.0303
2024-05-25 04:57:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:57:35 [INFO]: Finished training. The best model is from epoch#48.
2024-05-25 04:57:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/Transformer_ettm1/20240525_T045724/Transformer.pypots
2024-05-25 04:57:35 [INFO]: Transformer on ETTm1: MAE=0.1508, MSE=0.0465
2024-05-25 04:57:35 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Transformer_ettm1/imputation.pkl
2024-05-25 04:57:35 [INFO]: Using the given device: cuda:0
2024-05-25 04:57:35 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/TimesNet_ettm1/20240525_T045735
2024-05-25 04:57:35 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/TimesNet_ettm1/20240525_T045735/tensorboard
2024-05-25 04:57:35 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 04:57:35 [INFO]: Epoch 001 - training loss: 0.1675, validation loss: 0.0579
2024-05-25 04:57:35 [INFO]: Epoch 002 - training loss: 0.0727, validation loss: 0.0453
2024-05-25 04:57:36 [INFO]: Epoch 003 - training loss: 0.0549, validation loss: 0.0379
2024-05-25 04:57:36 [INFO]: Epoch 004 - training loss: 0.0476, validation loss: 0.0361
2024-05-25 04:57:36 [INFO]: Epoch 005 - training loss: 0.0454, validation loss: 0.0331
2024-05-25 04:57:36 [INFO]: Epoch 006 - training loss: 0.0411, validation loss: 0.0328
2024-05-25 04:57:36 [INFO]: Epoch 007 - training loss: 0.0416, validation loss: 0.0318
2024-05-25 04:57:37 [INFO]: Epoch 008 - training loss: 0.0391, validation loss: 0.0309
2024-05-25 04:57:37 [INFO]: Epoch 009 - training loss: 0.0387, validation loss: 0.0307
2024-05-25 04:57:37 [INFO]: Epoch 010 - training loss: 0.0408, validation loss: 0.0316
2024-05-25 04:57:37 [INFO]: Epoch 011 - training loss: 0.0421, validation loss: 0.0310
2024-05-25 04:57:37 [INFO]: Epoch 012 - training loss: 0.0395, validation loss: 0.0316
2024-05-25 04:57:38 [INFO]: Epoch 013 - training loss: 0.0388, validation loss: 0.0310
2024-05-25 04:57:38 [INFO]: Epoch 014 - training loss: 0.0380, validation loss: 0.0296
2024-05-25 04:57:38 [INFO]: Epoch 015 - training loss: 0.0363, validation loss: 0.0301
2024-05-25 04:57:38 [INFO]: Epoch 016 - training loss: 0.0360, validation loss: 0.0288
2024-05-25 04:57:38 [INFO]: Epoch 017 - training loss: 0.0352, validation loss: 0.0290
2024-05-25 04:57:38 [INFO]: Epoch 018 - training loss: 0.0345, validation loss: 0.0286
2024-05-25 04:57:39 [INFO]: Epoch 019 - training loss: 0.0368, validation loss: 0.0321
2024-05-25 04:57:39 [INFO]: Epoch 020 - training loss: 0.0464, validation loss: 0.0320
2024-05-25 04:57:39 [INFO]: Epoch 021 - training loss: 0.0395, validation loss: 0.0304
2024-05-25 04:57:39 [INFO]: Epoch 022 - training loss: 0.0365, validation loss: 0.0297
2024-05-25 04:57:39 [INFO]: Epoch 023 - training loss: 0.0369, validation loss: 0.0306
2024-05-25 04:57:40 [INFO]: Epoch 024 - training loss: 0.0338, validation loss: 0.0292
2024-05-25 04:57:40 [INFO]: Epoch 025 - training loss: 0.0326, validation loss: 0.0297
2024-05-25 04:57:40 [INFO]: Epoch 026 - training loss: 0.0336, validation loss: 0.0280
2024-05-25 04:57:40 [INFO]: Epoch 027 - training loss: 0.0324, validation loss: 0.0293
2024-05-25 04:57:40 [INFO]: Epoch 028 - training loss: 0.0314, validation loss: 0.0287
2024-05-25 04:57:41 [INFO]: Epoch 029 - training loss: 0.0303, validation loss: 0.0289
2024-05-25 04:57:41 [INFO]: Epoch 030 - training loss: 0.0349, validation loss: 0.0280
2024-05-25 04:57:41 [INFO]: Epoch 031 - training loss: 0.0316, validation loss: 0.0282
2024-05-25 04:57:41 [INFO]: Epoch 032 - training loss: 0.0316, validation loss: 0.0282
2024-05-25 04:57:41 [INFO]: Epoch 033 - training loss: 0.0296, validation loss: 0.0281
2024-05-25 04:57:41 [INFO]: Epoch 034 - training loss: 0.0300, validation loss: 0.0279
2024-05-25 04:57:42 [INFO]: Epoch 035 - training loss: 0.0297, validation loss: 0.0281
2024-05-25 04:57:42 [INFO]: Epoch 036 - training loss: 0.0300, validation loss: 0.0287
2024-05-25 04:57:42 [INFO]: Epoch 037 - training loss: 0.0301, validation loss: 0.0280
2024-05-25 04:57:42 [INFO]: Epoch 038 - training loss: 0.0285, validation loss: 0.0280
2024-05-25 04:57:42 [INFO]: Epoch 039 - training loss: 0.0279, validation loss: 0.0277
2024-05-25 04:57:43 [INFO]: Epoch 040 - training loss: 0.0261, validation loss: 0.0278
2024-05-25 04:57:43 [INFO]: Epoch 041 - training loss: 0.0280, validation loss: 0.0305
2024-05-25 04:57:43 [INFO]: Epoch 042 - training loss: 0.0292, validation loss: 0.0291
2024-05-25 04:57:43 [INFO]: Epoch 043 - training loss: 0.0278, validation loss: 0.0277
2024-05-25 04:57:43 [INFO]: Epoch 044 - training loss: 0.0256, validation loss: 0.0276
2024-05-25 04:57:44 [INFO]: Epoch 045 - training loss: 0.0257, validation loss: 0.0286
2024-05-25 04:57:44 [INFO]: Epoch 046 - training loss: 0.0270, validation loss: 0.0280
2024-05-25 04:57:44 [INFO]: Epoch 047 - training loss: 0.0248, validation loss: 0.0273
2024-05-25 04:57:44 [INFO]: Epoch 048 - training loss: 0.0247, validation loss: 0.0273
2024-05-25 04:57:44 [INFO]: Epoch 049 - training loss: 0.0238, validation loss: 0.0279
2024-05-25 04:57:44 [INFO]: Epoch 050 - training loss: 0.0234, validation loss: 0.0273
2024-05-25 04:57:45 [INFO]: Epoch 051 - training loss: 0.0238, validation loss: 0.0282
2024-05-25 04:57:45 [INFO]: Epoch 052 - training loss: 0.0263, validation loss: 0.0281
2024-05-25 04:57:45 [INFO]: Epoch 053 - training loss: 0.0239, validation loss: 0.0271
2024-05-25 04:57:45 [INFO]: Epoch 054 - training loss: 0.0235, validation loss: 0.0278
2024-05-25 04:57:45 [INFO]: Epoch 055 - training loss: 0.0236, validation loss: 0.0277
2024-05-25 04:57:46 [INFO]: Epoch 056 - training loss: 0.0225, validation loss: 0.0274
2024-05-25 04:57:46 [INFO]: Epoch 057 - training loss: 0.0226, validation loss: 0.0282
2024-05-25 04:57:46 [INFO]: Epoch 058 - training loss: 0.0225, validation loss: 0.0271
2024-05-25 04:57:46 [INFO]: Epoch 059 - training loss: 0.0219, validation loss: 0.0270
2024-05-25 04:57:46 [INFO]: Epoch 060 - training loss: 0.0205, validation loss: 0.0275
2024-05-25 04:57:47 [INFO]: Epoch 061 - training loss: 0.0219, validation loss: 0.0283
2024-05-25 04:57:47 [INFO]: Epoch 062 - training loss: 0.0229, validation loss: 0.0287
2024-05-25 04:57:47 [INFO]: Epoch 063 - training loss: 0.0218, validation loss: 0.0283
2024-05-25 04:57:47 [INFO]: Epoch 064 - training loss: 0.0209, validation loss: 0.0277
2024-05-25 04:57:47 [INFO]: Epoch 065 - training loss: 0.0199, validation loss: 0.0284
2024-05-25 04:57:47 [INFO]: Epoch 066 - training loss: 0.0216, validation loss: 0.0279
2024-05-25 04:57:48 [INFO]: Epoch 067 - training loss: 0.0200, validation loss: 0.0278
2024-05-25 04:57:48 [INFO]: Epoch 068 - training loss: 0.0182, validation loss: 0.0275
2024-05-25 04:57:48 [INFO]: Epoch 069 - training loss: 0.0180, validation loss: 0.0270
2024-05-25 04:57:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:57:48 [INFO]: Finished training. The best model is from epoch#59.
2024-05-25 04:57:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/TimesNet_ettm1/20240525_T045735/TimesNet.pypots
2024-05-25 04:57:48 [INFO]: TimesNet on ETTm1: MAE=0.1153, MSE=0.0288
2024-05-25 04:57:48 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/TimesNet_ettm1/imputation.pkl
2024-05-25 04:57:48 [INFO]: Using the given device: cuda:0
2024-05-25 04:57:48 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748
2024-05-25 04:57:48 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/tensorboard
2024-05-25 04:57:48 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 04:57:50 [INFO]: Epoch 001 - training loss: 0.6879, validation loss: 0.4160
2024-05-25 04:57:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch1_loss0.41599735617637634.pypots
2024-05-25 04:57:52 [INFO]: Epoch 002 - training loss: 0.3421, validation loss: 0.3536
2024-05-25 04:57:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch2_loss0.3535505533218384.pypots
2024-05-25 04:57:54 [INFO]: Epoch 003 - training loss: 0.3278, validation loss: 0.3287
2024-05-25 04:57:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch3_loss0.32869259268045425.pypots
2024-05-25 04:57:56 [INFO]: Epoch 004 - training loss: 0.3383, validation loss: 0.2857
2024-05-25 04:57:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch4_loss0.2856679707765579.pypots
2024-05-25 04:57:58 [INFO]: Epoch 005 - training loss: 0.2849, validation loss: 0.2742
2024-05-25 04:57:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch5_loss0.27421728521585464.pypots
2024-05-25 04:58:00 [INFO]: Epoch 006 - training loss: 0.2406, validation loss: 0.2538
2024-05-25 04:58:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch6_loss0.2537917159497738.pypots
2024-05-25 04:58:02 [INFO]: Epoch 007 - training loss: 0.2117, validation loss: 0.2500
2024-05-25 04:58:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch7_loss0.2500011846423149.pypots
2024-05-25 04:58:04 [INFO]: Epoch 008 - training loss: 0.2814, validation loss: 0.2452
2024-05-25 04:58:04 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch8_loss0.24522723630070686.pypots
2024-05-25 04:58:06 [INFO]: Epoch 009 - training loss: 0.2239, validation loss: 0.2364
2024-05-25 04:58:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch9_loss0.23640938848257065.pypots
2024-05-25 04:58:08 [INFO]: Epoch 010 - training loss: 0.2887, validation loss: 0.2532
2024-05-25 04:58:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch10_loss0.253238070756197.pypots
2024-05-25 04:58:11 [INFO]: Epoch 011 - training loss: 0.2338, validation loss: 0.2362
2024-05-25 04:58:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch11_loss0.23616109788417816.pypots
2024-05-25 04:58:13 [INFO]: Epoch 012 - training loss: 0.2687, validation loss: 0.2461
2024-05-25 04:58:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch12_loss0.24606474116444588.pypots
2024-05-25 04:58:15 [INFO]: Epoch 013 - training loss: 0.2473, validation loss: 0.2279
2024-05-25 04:58:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch13_loss0.227890994399786.pypots
2024-05-25 04:58:17 [INFO]: Epoch 014 - training loss: 0.2418, validation loss: 0.2114
2024-05-25 04:58:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch14_loss0.21143430843949318.pypots
2024-05-25 04:58:19 [INFO]: Epoch 015 - training loss: 0.2109, validation loss: 0.2044
2024-05-25 04:58:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch15_loss0.20440152287483215.pypots
2024-05-25 04:58:21 [INFO]: Epoch 016 - training loss: 0.2455, validation loss: 0.2054
2024-05-25 04:58:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch16_loss0.2053600363433361.pypots
2024-05-25 04:58:23 [INFO]: Epoch 017 - training loss: 0.1898, validation loss: 0.1872
2024-05-25 04:58:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch17_loss0.187208354473114.pypots
2024-05-25 04:58:25 [INFO]: Epoch 018 - training loss: 0.1888, validation loss: 0.1806
2024-05-25 04:58:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch18_loss0.18055161088705063.pypots
2024-05-25 04:58:27 [INFO]: Epoch 019 - training loss: 0.1812, validation loss: 0.1737
2024-05-25 04:58:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch19_loss0.1736568808555603.pypots
2024-05-25 04:58:29 [INFO]: Epoch 020 - training loss: 0.1703, validation loss: 0.1669
2024-05-25 04:58:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch20_loss0.16689522936940193.pypots
2024-05-25 04:58:31 [INFO]: Epoch 021 - training loss: 0.1616, validation loss: 0.1635
2024-05-25 04:58:31 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch21_loss0.16354380548000336.pypots
2024-05-25 04:58:33 [INFO]: Epoch 022 - training loss: 0.1660, validation loss: 0.1563
2024-05-25 04:58:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch22_loss0.1563262827694416.pypots
2024-05-25 04:58:35 [INFO]: Epoch 023 - training loss: 0.1633, validation loss: 0.1563
2024-05-25 04:58:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch23_loss0.15633582323789597.pypots
2024-05-25 04:58:37 [INFO]: Epoch 024 - training loss: 0.1810, validation loss: 0.1569
2024-05-25 04:58:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch24_loss0.1569078490138054.pypots
2024-05-25 04:58:39 [INFO]: Epoch 025 - training loss: 0.1934, validation loss: 0.1696
2024-05-25 04:58:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch25_loss0.16961806267499924.pypots
2024-05-25 04:58:41 [INFO]: Epoch 026 - training loss: 0.1844, validation loss: 0.1563
2024-05-25 04:58:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch26_loss0.15634288266301155.pypots
2024-05-25 04:58:43 [INFO]: Epoch 027 - training loss: 0.1719, validation loss: 0.1519
2024-05-25 04:58:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch27_loss0.15190013498067856.pypots
2024-05-25 04:58:45 [INFO]: Epoch 028 - training loss: 0.1577, validation loss: 0.1514
2024-05-25 04:58:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch28_loss0.1514119952917099.pypots
2024-05-25 04:58:47 [INFO]: Epoch 029 - training loss: 0.1476, validation loss: 0.1488
2024-05-25 04:58:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch29_loss0.14877231419086456.pypots
2024-05-25 04:58:49 [INFO]: Epoch 030 - training loss: 0.1399, validation loss: 0.1476
2024-05-25 04:58:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch30_loss0.1476401351392269.pypots
2024-05-25 04:58:51 [INFO]: Epoch 031 - training loss: 0.1576, validation loss: 0.1471
2024-05-25 04:58:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch31_loss0.14712443202733994.pypots
2024-05-25 04:58:53 [INFO]: Epoch 032 - training loss: 0.1446, validation loss: 0.1533
2024-05-25 04:58:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch32_loss0.1533251367509365.pypots
2024-05-25 04:58:55 [INFO]: Epoch 033 - training loss: 0.1780, validation loss: 0.1714
2024-05-25 04:58:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch33_loss0.1713671013712883.pypots
2024-05-25 04:58:57 [INFO]: Epoch 034 - training loss: 0.2264, validation loss: 0.1918
2024-05-25 04:58:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch34_loss0.19176504015922546.pypots
2024-05-25 04:58:59 [INFO]: Epoch 035 - training loss: 0.1807, validation loss: 0.1731
2024-05-25 04:58:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch35_loss0.17310414463281631.pypots
2024-05-25 04:59:02 [INFO]: Epoch 036 - training loss: 0.1715, validation loss: 0.1525
2024-05-25 04:59:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch36_loss0.15251225605607033.pypots
2024-05-25 04:59:04 [INFO]: Epoch 037 - training loss: 0.2039, validation loss: 0.1462
2024-05-25 04:59:04 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch37_loss0.1461729258298874.pypots
2024-05-25 04:59:06 [INFO]: Epoch 038 - training loss: 0.1583, validation loss: 0.1473
2024-05-25 04:59:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch38_loss0.1472645178437233.pypots
2024-05-25 04:59:08 [INFO]: Epoch 039 - training loss: 0.1564, validation loss: 0.1434
2024-05-25 04:59:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch39_loss0.14338327944278717.pypots
2024-05-25 04:59:10 [INFO]: Epoch 040 - training loss: 0.1510, validation loss: 0.1391
2024-05-25 04:59:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch40_loss0.13905860483646393.pypots
2024-05-25 04:59:12 [INFO]: Epoch 041 - training loss: 0.1458, validation loss: 0.1359
2024-05-25 04:59:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch41_loss0.13585619628429413.pypots
2024-05-25 04:59:14 [INFO]: Epoch 042 - training loss: 0.1396, validation loss: 0.1383
2024-05-25 04:59:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch42_loss0.13826045766472816.pypots
2024-05-25 04:59:16 [INFO]: Epoch 043 - training loss: 0.1307, validation loss: 0.1356
2024-05-25 04:59:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch43_loss0.1356060951948166.pypots
2024-05-25 04:59:18 [INFO]: Epoch 044 - training loss: 0.1268, validation loss: 0.1336
2024-05-25 04:59:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch44_loss0.13356791250407696.pypots
2024-05-25 04:59:20 [INFO]: Epoch 045 - training loss: 0.1448, validation loss: 0.1310
2024-05-25 04:59:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch45_loss0.13099100068211555.pypots
2024-05-25 04:59:22 [INFO]: Epoch 046 - training loss: 0.1531, validation loss: 0.1748
2024-05-25 04:59:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch46_loss0.17482497915625572.pypots
2024-05-25 04:59:24 [INFO]: Epoch 047 - training loss: 0.2004, validation loss: 0.1572
2024-05-25 04:59:24 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch47_loss0.15723198279738426.pypots
2024-05-25 04:59:26 [INFO]: Epoch 048 - training loss: 0.1913, validation loss: 0.1566
2024-05-25 04:59:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch48_loss0.15657197684049606.pypots
2024-05-25 04:59:28 [INFO]: Epoch 049 - training loss: 0.1685, validation loss: 0.1558
2024-05-25 04:59:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch49_loss0.15576807036995888.pypots
2024-05-25 04:59:30 [INFO]: Epoch 050 - training loss: 0.1617, validation loss: 0.1429
2024-05-25 04:59:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch50_loss0.14286763593554497.pypots
2024-05-25 04:59:32 [INFO]: Epoch 051 - training loss: 0.1629, validation loss: 0.1364
2024-05-25 04:59:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch51_loss0.1363532729446888.pypots
2024-05-25 04:59:34 [INFO]: Epoch 052 - training loss: 0.1403, validation loss: 0.1334
2024-05-25 04:59:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch52_loss0.13341146893799305.pypots
2024-05-25 04:59:36 [INFO]: Epoch 053 - training loss: 0.1379, validation loss: 0.1328
2024-05-25 04:59:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch53_loss0.1327575482428074.pypots
2024-05-25 04:59:38 [INFO]: Epoch 054 - training loss: 0.1366, validation loss: 0.1332
2024-05-25 04:59:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch54_loss0.13317121379077435.pypots
2024-05-25 04:59:40 [INFO]: Epoch 055 - training loss: 0.1307, validation loss: 0.1329
2024-05-25 04:59:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI_epoch55_loss0.1328869592398405.pypots
2024-05-25 04:59:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:59:40 [INFO]: Finished training. The best model is from epoch#45.
2024-05-25 04:59:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T045748/CSDI.pypots
2024-05-25 04:59:56 [INFO]: CSDI on ETTm1: MAE=0.1434, MSE=0.0495
2024-05-25 04:59:56 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/CSDI_ettm1/imputation.pkl
2024-05-25 04:59:56 [INFO]: Using the given device: cuda:0
2024-05-25 04:59:56 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/GPVAE_ettm1/20240525_T045956
2024-05-25 04:59:56 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/GPVAE_ettm1/20240525_T045956/tensorboard
2024-05-25 04:59:56 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 04:59:56 [INFO]: Epoch 001 - training loss: 24063.3121, validation loss: 0.9296
2024-05-25 04:59:56 [INFO]: Epoch 002 - training loss: 22130.4058, validation loss: 0.9267
2024-05-25 04:59:57 [INFO]: Epoch 003 - training loss: 20268.8090, validation loss: 0.9230
2024-05-25 04:59:57 [INFO]: Epoch 004 - training loss: 18435.8232, validation loss: 0.9063
2024-05-25 04:59:57 [INFO]: Epoch 005 - training loss: 16303.1436, validation loss: 0.8792
2024-05-25 04:59:57 [INFO]: Epoch 006 - training loss: 14607.9077, validation loss: 0.8074
2024-05-25 04:59:57 [INFO]: Epoch 007 - training loss: 13207.5094, validation loss: 0.6915
2024-05-25 04:59:57 [INFO]: Epoch 008 - training loss: 12187.4960, validation loss: 0.5923
2024-05-25 04:59:57 [INFO]: Epoch 009 - training loss: 11732.6369, validation loss: 0.5326
2024-05-25 04:59:57 [INFO]: Epoch 010 - training loss: 11136.8466, validation loss: 0.5079
2024-05-25 04:59:58 [INFO]: Epoch 011 - training loss: 10733.7339, validation loss: 0.5025
2024-05-25 04:59:58 [INFO]: Epoch 012 - training loss: 10451.7836, validation loss: 0.4963
2024-05-25 04:59:58 [INFO]: Epoch 013 - training loss: 10340.1694, validation loss: 0.4907
2024-05-25 04:59:58 [INFO]: Epoch 014 - training loss: 10132.9237, validation loss: 0.4886
2024-05-25 04:59:58 [INFO]: Epoch 015 - training loss: 10035.8710, validation loss: 0.4885
2024-05-25 04:59:58 [INFO]: Epoch 016 - training loss: 9997.2431, validation loss: 0.4824
2024-05-25 04:59:58 [INFO]: Epoch 017 - training loss: 9892.8094, validation loss: 0.4842
2024-05-25 04:59:58 [INFO]: Epoch 018 - training loss: 9782.6990, validation loss: 0.4781
2024-05-25 04:59:59 [INFO]: Epoch 019 - training loss: 9733.0262, validation loss: 0.4770
2024-05-25 04:59:59 [INFO]: Epoch 020 - training loss: 9686.6662, validation loss: 0.4726
2024-05-25 04:59:59 [INFO]: Epoch 021 - training loss: 9639.5574, validation loss: 0.4788
2024-05-25 04:59:59 [INFO]: Epoch 022 - training loss: 9606.8486, validation loss: 0.4497
2024-05-25 04:59:59 [INFO]: Epoch 023 - training loss: 9578.6218, validation loss: 0.4320
2024-05-25 04:59:59 [INFO]: Epoch 024 - training loss: 9555.4838, validation loss: 0.4278
2024-05-25 04:59:59 [INFO]: Epoch 025 - training loss: 9517.3699, validation loss: 0.4195
2024-05-25 05:00:00 [INFO]: Epoch 026 - training loss: 9497.2300, validation loss: 0.4061
2024-05-25 05:00:00 [INFO]: Epoch 027 - training loss: 9476.3818, validation loss: 0.4004
2024-05-25 05:00:00 [INFO]: Epoch 028 - training loss: 9484.8261, validation loss: 0.3866
2024-05-25 05:00:00 [INFO]: Epoch 029 - training loss: 9462.3938, validation loss: 0.3802
2024-05-25 05:00:00 [INFO]: Epoch 030 - training loss: 9437.8189, validation loss: 0.3731
2024-05-25 05:00:00 [INFO]: Epoch 031 - training loss: 9434.1981, validation loss: 0.3688
2024-05-25 05:00:00 [INFO]: Epoch 032 - training loss: 9406.5596, validation loss: 0.3608
2024-05-25 05:00:00 [INFO]: Epoch 033 - training loss: 9395.0743, validation loss: 0.3546
2024-05-25 05:00:01 [INFO]: Epoch 034 - training loss: 9397.8926, validation loss: 0.3496
2024-05-25 05:00:01 [INFO]: Epoch 035 - training loss: 9376.5013, validation loss: 0.3429
2024-05-25 05:00:01 [INFO]: Epoch 036 - training loss: 9366.4788, validation loss: 0.3387
2024-05-25 05:00:01 [INFO]: Epoch 037 - training loss: 9357.8646, validation loss: 0.3311
2024-05-25 05:00:01 [INFO]: Epoch 038 - training loss: 9357.4119, validation loss: 0.3277
2024-05-25 05:00:01 [INFO]: Epoch 039 - training loss: 9356.9835, validation loss: 0.3212
2024-05-25 05:00:01 [INFO]: Epoch 040 - training loss: 9338.0475, validation loss: 0.3197
2024-05-25 05:00:01 [INFO]: Epoch 041 - training loss: 9353.0798, validation loss: 0.3152
2024-05-25 05:00:02 [INFO]: Epoch 042 - training loss: 9328.8205, validation loss: 0.3066
2024-05-25 05:00:02 [INFO]: Epoch 043 - training loss: 9324.9820, validation loss: 0.3030
2024-05-25 05:00:02 [INFO]: Epoch 044 - training loss: 9319.6260, validation loss: 0.2958
2024-05-25 05:00:02 [INFO]: Epoch 045 - training loss: 9319.6864, validation loss: 0.2877
2024-05-25 05:00:02 [INFO]: Epoch 046 - training loss: 9308.2797, validation loss: 0.2823
2024-05-25 05:00:02 [INFO]: Epoch 047 - training loss: 9309.7832, validation loss: 0.2768
2024-05-25 05:00:02 [INFO]: Epoch 048 - training loss: 9309.2386, validation loss: 0.2668
2024-05-25 05:00:02 [INFO]: Epoch 049 - training loss: 9299.4287, validation loss: 0.2706
2024-05-25 05:00:03 [INFO]: Epoch 050 - training loss: 9293.2155, validation loss: 0.2629
2024-05-25 05:00:03 [INFO]: Epoch 051 - training loss: 9288.5715, validation loss: 0.2579
2024-05-25 05:00:03 [INFO]: Epoch 052 - training loss: 9289.3242, validation loss: 0.2517
2024-05-25 05:00:03 [INFO]: Epoch 053 - training loss: 9284.7130, validation loss: 0.2468
2024-05-25 05:00:03 [INFO]: Epoch 054 - training loss: 9284.7338, validation loss: 0.2445
2024-05-25 05:00:03 [INFO]: Epoch 055 - training loss: 9279.2960, validation loss: 0.2367
2024-05-25 05:00:03 [INFO]: Epoch 056 - training loss: 9281.1577, validation loss: 0.2303
2024-05-25 05:00:03 [INFO]: Epoch 057 - training loss: 9277.6096, validation loss: 0.2258
2024-05-25 05:00:04 [INFO]: Epoch 058 - training loss: 9280.2282, validation loss: 0.2194
2024-05-25 05:00:04 [INFO]: Epoch 059 - training loss: 9270.0988, validation loss: 0.2138
2024-05-25 05:00:04 [INFO]: Epoch 060 - training loss: 9270.0359, validation loss: 0.2094
2024-05-25 05:00:04 [INFO]: Epoch 061 - training loss: 9268.2014, validation loss: 0.2046
2024-05-25 05:00:04 [INFO]: Epoch 062 - training loss: 9267.2480, validation loss: 0.2015
2024-05-25 05:00:04 [INFO]: Epoch 063 - training loss: 9272.0380, validation loss: 0.1944
2024-05-25 05:00:04 [INFO]: Epoch 064 - training loss: 9262.5228, validation loss: 0.1879
2024-05-25 05:00:04 [INFO]: Epoch 065 - training loss: 9263.4122, validation loss: 0.1866
2024-05-25 05:00:05 [INFO]: Epoch 066 - training loss: 9266.3038, validation loss: 0.1754
2024-05-25 05:00:05 [INFO]: Epoch 067 - training loss: 9258.2155, validation loss: 0.1719
2024-05-25 05:00:05 [INFO]: Epoch 068 - training loss: 9256.0700, validation loss: 0.1675
2024-05-25 05:00:05 [INFO]: Epoch 069 - training loss: 9255.5167, validation loss: 0.1652
2024-05-25 05:00:05 [INFO]: Epoch 070 - training loss: 9255.3607, validation loss: 0.1627
2024-05-25 05:00:05 [INFO]: Epoch 071 - training loss: 9251.9032, validation loss: 0.1578
2024-05-25 05:00:05 [INFO]: Epoch 072 - training loss: 9251.3431, validation loss: 0.1548
2024-05-25 05:00:05 [INFO]: Epoch 073 - training loss: 9250.2031, validation loss: 0.1504
2024-05-25 05:00:06 [INFO]: Epoch 074 - training loss: 9247.8463, validation loss: 0.1512
2024-05-25 05:00:06 [INFO]: Epoch 075 - training loss: 9246.1934, validation loss: 0.1463
2024-05-25 05:00:06 [INFO]: Epoch 076 - training loss: 9248.1200, validation loss: 0.1445
2024-05-25 05:00:06 [INFO]: Epoch 077 - training loss: 9246.9507, validation loss: 0.1412
2024-05-25 05:00:06 [INFO]: Epoch 078 - training loss: 9246.9990, validation loss: 0.1391
2024-05-25 05:00:06 [INFO]: Epoch 079 - training loss: 9248.9964, validation loss: 0.1375
2024-05-25 05:00:06 [INFO]: Epoch 080 - training loss: 9243.4736, validation loss: 0.1345
2024-05-25 05:00:06 [INFO]: Epoch 081 - training loss: 9240.2394, validation loss: 0.1344
2024-05-25 05:00:07 [INFO]: Epoch 082 - training loss: 9241.3441, validation loss: 0.1329
2024-05-25 05:00:07 [INFO]: Epoch 083 - training loss: 9239.9318, validation loss: 0.1323
2024-05-25 05:00:07 [INFO]: Epoch 084 - training loss: 9238.9077, validation loss: 0.1317
2024-05-25 05:00:07 [INFO]: Epoch 085 - training loss: 9239.9604, validation loss: 0.1301
2024-05-25 05:00:07 [INFO]: Epoch 086 - training loss: 9241.0321, validation loss: 0.1299
2024-05-25 05:00:07 [INFO]: Epoch 087 - training loss: 9242.3118, validation loss: 0.1281
2024-05-25 05:00:07 [INFO]: Epoch 088 - training loss: 9235.9718, validation loss: 0.1258
2024-05-25 05:00:08 [INFO]: Epoch 089 - training loss: 9235.1959, validation loss: 0.1252
2024-05-25 05:00:08 [INFO]: Epoch 090 - training loss: 9235.5187, validation loss: 0.1226
2024-05-25 05:00:08 [INFO]: Epoch 091 - training loss: 9236.1310, validation loss: 0.1227
2024-05-25 05:00:08 [INFO]: Epoch 092 - training loss: 9235.5320, validation loss: 0.1244
2024-05-25 05:00:08 [INFO]: Epoch 093 - training loss: 9234.3016, validation loss: 0.1200
2024-05-25 05:00:08 [INFO]: Epoch 094 - training loss: 9233.2078, validation loss: 0.1208
2024-05-25 05:00:08 [INFO]: Epoch 095 - training loss: 9233.4032, validation loss: 0.1197
2024-05-25 05:00:08 [INFO]: Epoch 096 - training loss: 9233.1478, validation loss: 0.1195
2024-05-25 05:00:09 [INFO]: Epoch 097 - training loss: 9232.8561, validation loss: 0.1185
2024-05-25 05:00:09 [INFO]: Epoch 098 - training loss: 9234.1509, validation loss: 0.1190
2024-05-25 05:00:09 [INFO]: Epoch 099 - training loss: 9231.8175, validation loss: 0.1189
2024-05-25 05:00:09 [INFO]: Epoch 100 - training loss: 9231.8212, validation loss: 0.1164
2024-05-25 05:00:09 [INFO]: Epoch 101 - training loss: 9231.7507, validation loss: 0.1157
2024-05-25 05:00:09 [INFO]: Epoch 102 - training loss: 9228.7136, validation loss: 0.1157
2024-05-25 05:00:09 [INFO]: Epoch 103 - training loss: 9230.4832, validation loss: 0.1133
2024-05-25 05:00:09 [INFO]: Epoch 104 - training loss: 9228.2043, validation loss: 0.1191
2024-05-25 05:00:10 [INFO]: Epoch 105 - training loss: 9229.0825, validation loss: 0.1134
2024-05-25 05:00:10 [INFO]: Epoch 106 - training loss: 9228.5889, validation loss: 0.1125
2024-05-25 05:00:10 [INFO]: Epoch 107 - training loss: 9227.6739, validation loss: 0.1122
2024-05-25 05:00:10 [INFO]: Epoch 108 - training loss: 9226.7242, validation loss: 0.1117
2024-05-25 05:00:10 [INFO]: Epoch 109 - training loss: 9228.6177, validation loss: 0.1124
2024-05-25 05:00:10 [INFO]: Epoch 110 - training loss: 9226.0121, validation loss: 0.1102
2024-05-25 05:00:10 [INFO]: Epoch 111 - training loss: 9225.0505, validation loss: 0.1088
2024-05-25 05:00:10 [INFO]: Epoch 112 - training loss: 9224.8926, validation loss: 0.1097
2024-05-25 05:00:11 [INFO]: Epoch 113 - training loss: 9224.7733, validation loss: 0.1092
2024-05-25 05:00:11 [INFO]: Epoch 114 - training loss: 9224.6563, validation loss: 0.1078
2024-05-25 05:00:11 [INFO]: Epoch 115 - training loss: 9224.8704, validation loss: 0.1081
2024-05-25 05:00:11 [INFO]: Epoch 116 - training loss: 9226.5127, validation loss: 0.1093
2024-05-25 05:00:11 [INFO]: Epoch 117 - training loss: 9223.8015, validation loss: 0.1066
2024-05-25 05:00:11 [INFO]: Epoch 118 - training loss: 9224.1918, validation loss: 0.1085
2024-05-25 05:00:11 [INFO]: Epoch 119 - training loss: 9222.1981, validation loss: 0.1090
2024-05-25 05:00:11 [INFO]: Epoch 120 - training loss: 9224.0818, validation loss: 0.1047
2024-05-25 05:00:12 [INFO]: Epoch 121 - training loss: 9222.4659, validation loss: 0.1051
2024-05-25 05:00:12 [INFO]: Epoch 122 - training loss: 9221.8541, validation loss: 0.1061
2024-05-25 05:00:12 [INFO]: Epoch 123 - training loss: 9222.8950, validation loss: 0.1038
2024-05-25 05:00:12 [INFO]: Epoch 124 - training loss: 9222.2907, validation loss: 0.1038
2024-05-25 05:00:12 [INFO]: Epoch 125 - training loss: 9223.3215, validation loss: 0.1036
2024-05-25 05:00:12 [INFO]: Epoch 126 - training loss: 9221.3775, validation loss: 0.1065
2024-05-25 05:00:12 [INFO]: Epoch 127 - training loss: 9220.3753, validation loss: 0.1032
2024-05-25 05:00:13 [INFO]: Epoch 128 - training loss: 9220.9904, validation loss: 0.1022
2024-05-25 05:00:13 [INFO]: Epoch 129 - training loss: 9234.5645, validation loss: 0.1039
2024-05-25 05:00:13 [INFO]: Epoch 130 - training loss: 9221.5162, validation loss: 0.1019
2024-05-25 05:00:13 [INFO]: Epoch 131 - training loss: 9219.2917, validation loss: 0.1025
2024-05-25 05:00:13 [INFO]: Epoch 132 - training loss: 9221.6594, validation loss: 0.1027
2024-05-25 05:00:13 [INFO]: Epoch 133 - training loss: 9218.3684, validation loss: 0.1005
2024-05-25 05:00:13 [INFO]: Epoch 134 - training loss: 9218.7373, validation loss: 0.1005
2024-05-25 05:00:13 [INFO]: Epoch 135 - training loss: 9217.6483, validation loss: 0.1022
2024-05-25 05:00:14 [INFO]: Epoch 136 - training loss: 9217.2439, validation loss: 0.0990
2024-05-25 05:00:14 [INFO]: Epoch 137 - training loss: 9218.6146, validation loss: 0.1008
2024-05-25 05:00:14 [INFO]: Epoch 138 - training loss: 9218.1065, validation loss: 0.0994
2024-05-25 05:00:14 [INFO]: Epoch 139 - training loss: 9216.3267, validation loss: 0.0994
2024-05-25 05:00:14 [INFO]: Epoch 140 - training loss: 9217.4827, validation loss: 0.0994
2024-05-25 05:00:14 [INFO]: Epoch 141 - training loss: 9218.2065, validation loss: 0.1002
2024-05-25 05:00:14 [INFO]: Epoch 142 - training loss: 9217.6696, validation loss: 0.0986
2024-05-25 05:00:14 [INFO]: Epoch 143 - training loss: 9215.7386, validation loss: 0.0985
2024-05-25 05:00:15 [INFO]: Epoch 144 - training loss: 9218.6318, validation loss: 0.0973
2024-05-25 05:00:15 [INFO]: Epoch 145 - training loss: 9217.7062, validation loss: 0.0979
2024-05-25 05:00:15 [INFO]: Epoch 146 - training loss: 9218.4622, validation loss: 0.0978
2024-05-25 05:00:15 [INFO]: Epoch 147 - training loss: 9216.6276, validation loss: 0.0974
2024-05-25 05:00:15 [INFO]: Epoch 148 - training loss: 9217.6890, validation loss: 0.0950
2024-05-25 05:00:15 [INFO]: Epoch 149 - training loss: 9215.2775, validation loss: 0.0968
2024-05-25 05:00:15 [INFO]: Epoch 150 - training loss: 9215.6785, validation loss: 0.0966
2024-05-25 05:00:15 [INFO]: Epoch 151 - training loss: 9216.1378, validation loss: 0.0949
2024-05-25 05:00:16 [INFO]: Epoch 152 - training loss: 9215.2220, validation loss: 0.0958
2024-05-25 05:00:16 [INFO]: Epoch 153 - training loss: 9214.9003, validation loss: 0.0944
2024-05-25 05:00:16 [INFO]: Epoch 154 - training loss: 9213.9528, validation loss: 0.0951
2024-05-25 05:00:16 [INFO]: Epoch 155 - training loss: 9215.4036, validation loss: 0.0953
2024-05-25 05:00:16 [INFO]: Epoch 156 - training loss: 9215.6771, validation loss: 0.0945
2024-05-25 05:00:16 [INFO]: Epoch 157 - training loss: 9214.5380, validation loss: 0.0948
2024-05-25 05:00:16 [INFO]: Epoch 158 - training loss: 9215.2881, validation loss: 0.0954
2024-05-25 05:00:16 [INFO]: Epoch 159 - training loss: 9214.1102, validation loss: 0.0937
2024-05-25 05:00:17 [INFO]: Epoch 160 - training loss: 9214.6583, validation loss: 0.0925
2024-05-25 05:00:17 [INFO]: Epoch 161 - training loss: 9214.1055, validation loss: 0.0930
2024-05-25 05:00:17 [INFO]: Epoch 162 - training loss: 9212.8087, validation loss: 0.0934
2024-05-25 05:00:17 [INFO]: Epoch 163 - training loss: 9214.0410, validation loss: 0.0955
2024-05-25 05:00:17 [INFO]: Epoch 164 - training loss: 9213.5837, validation loss: 0.0933
2024-05-25 05:00:17 [INFO]: Epoch 165 - training loss: 9214.2081, validation loss: 0.0915
2024-05-25 05:00:17 [INFO]: Epoch 166 - training loss: 9212.5987, validation loss: 0.0915
2024-05-25 05:00:17 [INFO]: Epoch 167 - training loss: 9210.5545, validation loss: 0.0904
2024-05-25 05:00:18 [INFO]: Epoch 168 - training loss: 9213.4493, validation loss: 0.0935
2024-05-25 05:00:18 [INFO]: Epoch 169 - training loss: 9214.5053, validation loss: 0.0932
2024-05-25 05:00:18 [INFO]: Epoch 170 - training loss: 9213.5129, validation loss: 0.0917
2024-05-25 05:00:18 [INFO]: Epoch 171 - training loss: 9212.2901, validation loss: 0.0895
2024-05-25 05:00:18 [INFO]: Epoch 172 - training loss: 9212.0282, validation loss: 0.0894
2024-05-25 05:00:18 [INFO]: Epoch 173 - training loss: 9211.9608, validation loss: 0.0925
2024-05-25 05:00:18 [INFO]: Epoch 174 - training loss: 9212.8424, validation loss: 0.0910
2024-05-25 05:00:18 [INFO]: Epoch 175 - training loss: 9213.0253, validation loss: 0.0914
2024-05-25 05:00:19 [INFO]: Epoch 176 - training loss: 9212.1909, validation loss: 0.0886
2024-05-25 05:00:19 [INFO]: Epoch 177 - training loss: 9212.4914, validation loss: 0.0901
2024-05-25 05:00:19 [INFO]: Epoch 178 - training loss: 9213.3840, validation loss: 0.0924
2024-05-25 05:00:19 [INFO]: Epoch 179 - training loss: 9212.2954, validation loss: 0.0896
2024-05-25 05:00:19 [INFO]: Epoch 180 - training loss: 9211.6661, validation loss: 0.0918
2024-05-25 05:00:19 [INFO]: Epoch 181 - training loss: 9210.9722, validation loss: 0.0905
2024-05-25 05:00:19 [INFO]: Epoch 182 - training loss: 9212.1387, validation loss: 0.0889
2024-05-25 05:00:19 [INFO]: Epoch 183 - training loss: 9211.3543, validation loss: 0.0880
2024-05-25 05:00:20 [INFO]: Epoch 184 - training loss: 9209.9899, validation loss: 0.0899
2024-05-25 05:00:20 [INFO]: Epoch 185 - training loss: 9212.1370, validation loss: 0.0888
2024-05-25 05:00:20 [INFO]: Epoch 186 - training loss: 9211.1306, validation loss: 0.0872
2024-05-25 05:00:20 [INFO]: Epoch 187 - training loss: 9211.1241, validation loss: 0.0886
2024-05-25 05:00:20 [INFO]: Epoch 188 - training loss: 9208.5939, validation loss: 0.0888
2024-05-25 05:00:20 [INFO]: Epoch 189 - training loss: 9209.8152, validation loss: 0.0877
2024-05-25 05:00:20 [INFO]: Epoch 190 - training loss: 9211.0646, validation loss: 0.0871
2024-05-25 05:00:21 [INFO]: Epoch 191 - training loss: 9210.4035, validation loss: 0.0879
2024-05-25 05:00:21 [INFO]: Epoch 192 - training loss: 9210.8000, validation loss: 0.0921
2024-05-25 05:00:21 [INFO]: Epoch 193 - training loss: 9209.9948, validation loss: 0.0866
2024-05-25 05:00:21 [INFO]: Epoch 194 - training loss: 9213.1229, validation loss: 0.0894
2024-05-25 05:00:21 [INFO]: Epoch 195 - training loss: 9211.1110, validation loss: 0.0861
2024-05-25 05:00:21 [INFO]: Epoch 196 - training loss: 9211.6920, validation loss: 0.0882
2024-05-25 05:00:21 [INFO]: Epoch 197 - training loss: 9209.3221, validation loss: 0.0858
2024-05-25 05:00:21 [INFO]: Epoch 198 - training loss: 9209.8151, validation loss: 0.0870
2024-05-25 05:00:22 [INFO]: Epoch 199 - training loss: 9211.4120, validation loss: 0.0866
2024-05-25 05:00:22 [INFO]: Epoch 200 - training loss: 9210.4440, validation loss: 0.0887
2024-05-25 05:00:22 [INFO]: Epoch 201 - training loss: 9210.0105, validation loss: 0.0884
2024-05-25 05:00:22 [INFO]: Epoch 202 - training loss: 9211.5212, validation loss: 0.0888
2024-05-25 05:00:22 [INFO]: Epoch 203 - training loss: 9209.9034, validation loss: 0.0852
2024-05-25 05:00:22 [INFO]: Epoch 204 - training loss: 9213.5703, validation loss: 0.0870
2024-05-25 05:00:22 [INFO]: Epoch 205 - training loss: 9209.8502, validation loss: 0.0866
2024-05-25 05:00:22 [INFO]: Epoch 206 - training loss: 9210.2503, validation loss: 0.0856
2024-05-25 05:00:23 [INFO]: Epoch 207 - training loss: 9209.6880, validation loss: 0.0851
2024-05-25 05:00:23 [INFO]: Epoch 208 - training loss: 9209.3302, validation loss: 0.0858
2024-05-25 05:00:23 [INFO]: Epoch 209 - training loss: 9211.1740, validation loss: 0.0846
2024-05-25 05:00:23 [INFO]: Epoch 210 - training loss: 9209.8325, validation loss: 0.0855
2024-05-25 05:00:23 [INFO]: Epoch 211 - training loss: 9209.6009, validation loss: 0.0855
2024-05-25 05:00:23 [INFO]: Epoch 212 - training loss: 9212.5952, validation loss: 0.0851
2024-05-25 05:00:23 [INFO]: Epoch 213 - training loss: 9213.5554, validation loss: 0.0884
2024-05-25 05:00:23 [INFO]: Epoch 214 - training loss: 9210.4077, validation loss: 0.0867
2024-05-25 05:00:24 [INFO]: Epoch 215 - training loss: 9209.8473, validation loss: 0.0839
2024-05-25 05:00:24 [INFO]: Epoch 216 - training loss: 9209.1027, validation loss: 0.0877
2024-05-25 05:00:24 [INFO]: Epoch 217 - training loss: 9207.9467, validation loss: 0.0849
2024-05-25 05:00:24 [INFO]: Epoch 218 - training loss: 9208.5255, validation loss: 0.0845
2024-05-25 05:00:24 [INFO]: Epoch 219 - training loss: 9207.8895, validation loss: 0.0837
2024-05-25 05:00:24 [INFO]: Epoch 220 - training loss: 9209.7786, validation loss: 0.0849
2024-05-25 05:00:24 [INFO]: Epoch 221 - training loss: 9209.3689, validation loss: 0.0856
2024-05-25 05:00:24 [INFO]: Epoch 222 - training loss: 9208.8026, validation loss: 0.0842
2024-05-25 05:00:25 [INFO]: Epoch 223 - training loss: 9210.5990, validation loss: 0.0839
2024-05-25 05:00:25 [INFO]: Epoch 224 - training loss: 9209.5939, validation loss: 0.0856
2024-05-25 05:00:25 [INFO]: Epoch 225 - training loss: 9208.0124, validation loss: 0.0836
2024-05-25 05:00:25 [INFO]: Epoch 226 - training loss: 9210.4551, validation loss: 0.0817
2024-05-25 05:00:25 [INFO]: Epoch 227 - training loss: 9208.7813, validation loss: 0.0850
2024-05-25 05:00:25 [INFO]: Epoch 228 - training loss: 9208.3802, validation loss: 0.0842
2024-05-25 05:00:25 [INFO]: Epoch 229 - training loss: 9209.0172, validation loss: 0.0829
2024-05-25 05:00:25 [INFO]: Epoch 230 - training loss: 9207.7814, validation loss: 0.0846
2024-05-25 05:00:26 [INFO]: Epoch 231 - training loss: 9208.3565, validation loss: 0.0831
2024-05-25 05:00:26 [INFO]: Epoch 232 - training loss: 9208.1672, validation loss: 0.0825
2024-05-25 05:00:26 [INFO]: Epoch 233 - training loss: 9208.1481, validation loss: 0.0844
2024-05-25 05:00:26 [INFO]: Epoch 234 - training loss: 9206.4146, validation loss: 0.0835
2024-05-25 05:00:26 [INFO]: Epoch 235 - training loss: 9209.0628, validation loss: 0.0833
2024-05-25 05:00:26 [INFO]: Epoch 236 - training loss: 9208.5063, validation loss: 0.0850
2024-05-25 05:00:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:00:26 [INFO]: Finished training. The best model is from epoch#226.
2024-05-25 05:00:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/GPVAE_ettm1/20240525_T045956/GPVAE.pypots
2024-05-25 05:00:26 [INFO]: GP-VAE on ETTm1: MAE=0.2952, MSE=0.1849
2024-05-25 05:00:26 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/GPVAE_ettm1/imputation.pkl
2024-05-25 05:00:26 [INFO]: Using the given device: cuda:0
2024-05-25 05:00:26 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/USGAN_ettm1/20240525_T050026
2024-05-25 05:00:26 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/USGAN_ettm1/20240525_T050026/tensorboard
2024-05-25 05:00:26 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 05:00:37 [INFO]: Epoch 001 - generator training loss: 0.4702, discriminator training loss: 0.5363, validation loss: 0.2971
2024-05-25 05:00:46 [INFO]: Epoch 002 - generator training loss: -0.0584, discriminator training loss: 0.4735, validation loss: 0.1173
2024-05-25 05:00:54 [INFO]: Epoch 003 - generator training loss: -0.1635, discriminator training loss: 0.4331, validation loss: 0.0707
2024-05-25 05:01:03 [INFO]: Epoch 004 - generator training loss: -0.1500, discriminator training loss: 0.3707, validation loss: 0.0560
2024-05-25 05:01:12 [INFO]: Epoch 005 - generator training loss: -0.1081, discriminator training loss: 0.2944, validation loss: 0.0499
2024-05-25 05:01:21 [INFO]: Epoch 006 - generator training loss: -0.0720, discriminator training loss: 0.2326, validation loss: 0.0437
2024-05-25 05:01:29 [INFO]: Epoch 007 - generator training loss: -0.0604, discriminator training loss: 0.2009, validation loss: 0.0419
2024-05-25 05:01:38 [INFO]: Epoch 008 - generator training loss: -0.0519, discriminator training loss: 0.1864, validation loss: 0.0411
2024-05-25 05:01:47 [INFO]: Epoch 009 - generator training loss: -0.0509, discriminator training loss: 0.1810, validation loss: 0.0416
2024-05-25 05:01:56 [INFO]: Epoch 010 - generator training loss: -0.0508, discriminator training loss: 0.1790, validation loss: 0.0393
2024-05-25 05:02:05 [INFO]: Epoch 011 - generator training loss: -0.0506, discriminator training loss: 0.1772, validation loss: 0.0386
2024-05-25 05:02:13 [INFO]: Epoch 012 - generator training loss: -0.0552, discriminator training loss: 0.1752, validation loss: 0.0368
2024-05-25 05:02:22 [INFO]: Epoch 013 - generator training loss: -0.0555, discriminator training loss: 0.1733, validation loss: 0.0366
2024-05-25 05:02:31 [INFO]: Epoch 014 - generator training loss: -0.0549, discriminator training loss: 0.1709, validation loss: 0.0361
2024-05-25 05:02:39 [INFO]: Epoch 015 - generator training loss: -0.0605, discriminator training loss: 0.1724, validation loss: 0.0362
2024-05-25 05:02:48 [INFO]: Epoch 016 - generator training loss: -0.0546, discriminator training loss: 0.1714, validation loss: 0.0350
2024-05-25 05:02:57 [INFO]: Epoch 017 - generator training loss: -0.0602, discriminator training loss: 0.1688, validation loss: 0.0356
2024-05-25 05:03:05 [INFO]: Epoch 018 - generator training loss: -0.0591, discriminator training loss: 0.1719, validation loss: 0.0342
2024-05-25 05:03:14 [INFO]: Epoch 019 - generator training loss: -0.0568, discriminator training loss: 0.1689, validation loss: 0.0342
2024-05-25 05:03:22 [INFO]: Epoch 020 - generator training loss: -0.0569, discriminator training loss: 0.1719, validation loss: 0.0341
2024-05-25 05:03:31 [INFO]: Epoch 021 - generator training loss: -0.0554, discriminator training loss: 0.1722, validation loss: 0.0338
2024-05-25 05:03:40 [INFO]: Epoch 022 - generator training loss: -0.0593, discriminator training loss: 0.1698, validation loss: 0.0333
2024-05-25 05:03:48 [INFO]: Epoch 023 - generator training loss: -0.0591, discriminator training loss: 0.1702, validation loss: 0.0331
2024-05-25 05:03:57 [INFO]: Epoch 024 - generator training loss: -0.0598, discriminator training loss: 0.1677, validation loss: 0.0343
2024-05-25 05:04:05 [INFO]: Epoch 025 - generator training loss: -0.0604, discriminator training loss: 0.1696, validation loss: 0.0331
2024-05-25 05:04:14 [INFO]: Epoch 026 - generator training loss: -0.0573, discriminator training loss: 0.1665, validation loss: 0.0328
2024-05-25 05:04:23 [INFO]: Epoch 027 - generator training loss: -0.0605, discriminator training loss: 0.1699, validation loss: 0.0328
2024-05-25 05:04:31 [INFO]: Epoch 028 - generator training loss: -0.0596, discriminator training loss: 0.1692, validation loss: 0.0326
2024-05-25 05:04:40 [INFO]: Epoch 029 - generator training loss: -0.0633, discriminator training loss: 0.1682, validation loss: 0.0316
2024-05-25 05:04:50 [INFO]: Epoch 030 - generator training loss: -0.0643, discriminator training loss: 0.1689, validation loss: 0.0319
2024-05-25 05:04:59 [INFO]: Epoch 031 - generator training loss: -0.0595, discriminator training loss: 0.1674, validation loss: 0.0311
2024-05-25 05:05:07 [INFO]: Epoch 032 - generator training loss: -0.0647, discriminator training loss: 0.1663, validation loss: 0.0313
2024-05-25 05:05:16 [INFO]: Epoch 033 - generator training loss: -0.0639, discriminator training loss: 0.1684, validation loss: 0.0317
2024-05-25 05:05:25 [INFO]: Epoch 034 - generator training loss: -0.0625, discriminator training loss: 0.1681, validation loss: 0.0317
2024-05-25 05:05:34 [INFO]: Epoch 035 - generator training loss: -0.0611, discriminator training loss: 0.1684, validation loss: 0.0321
2024-05-25 05:05:43 [INFO]: Epoch 036 - generator training loss: -0.0612, discriminator training loss: 0.1694, validation loss: 0.0312
2024-05-25 05:05:52 [INFO]: Epoch 037 - generator training loss: -0.0625, discriminator training loss: 0.1677, validation loss: 0.0309
2024-05-25 05:06:01 [INFO]: Epoch 038 - generator training loss: -0.0642, discriminator training loss: 0.1696, validation loss: 0.0309
2024-05-25 05:06:10 [INFO]: Epoch 039 - generator training loss: -0.0623, discriminator training loss: 0.1681, validation loss: 0.0326
2024-05-25 05:06:19 [INFO]: Epoch 040 - generator training loss: -0.0638, discriminator training loss: 0.1693, validation loss: 0.0313
2024-05-25 05:06:28 [INFO]: Epoch 041 - generator training loss: -0.0650, discriminator training loss: 0.1671, validation loss: 0.0304
2024-05-25 05:06:36 [INFO]: Epoch 042 - generator training loss: -0.0616, discriminator training loss: 0.1668, validation loss: 0.0303
2024-05-25 05:06:45 [INFO]: Epoch 043 - generator training loss: -0.0651, discriminator training loss: 0.1638, validation loss: 0.0301
2024-05-25 05:06:54 [INFO]: Epoch 044 - generator training loss: -0.0619, discriminator training loss: 0.1653, validation loss: 0.0298
2024-05-25 05:07:03 [INFO]: Epoch 045 - generator training loss: -0.0601, discriminator training loss: 0.1672, validation loss: 0.0295
2024-05-25 05:07:12 [INFO]: Epoch 046 - generator training loss: -0.0615, discriminator training loss: 0.1675, validation loss: 0.0298
2024-05-25 05:07:21 [INFO]: Epoch 047 - generator training loss: -0.0637, discriminator training loss: 0.1659, validation loss: 0.0297
2024-05-25 05:07:29 [INFO]: Epoch 048 - generator training loss: -0.0641, discriminator training loss: 0.1655, validation loss: 0.0298
2024-05-25 05:07:38 [INFO]: Epoch 049 - generator training loss: -0.0664, discriminator training loss: 0.1647, validation loss: 0.0296
2024-05-25 05:07:47 [INFO]: Epoch 050 - generator training loss: -0.0655, discriminator training loss: 0.1647, validation loss: 0.0295
2024-05-25 05:07:56 [INFO]: Epoch 051 - generator training loss: -0.0658, discriminator training loss: 0.1674, validation loss: 0.0302
2024-05-25 05:08:05 [INFO]: Epoch 052 - generator training loss: -0.0661, discriminator training loss: 0.1669, validation loss: 0.0294
2024-05-25 05:08:14 [INFO]: Epoch 053 - generator training loss: -0.0664, discriminator training loss: 0.1635, validation loss: 0.0315
2024-05-25 05:08:23 [INFO]: Epoch 054 - generator training loss: -0.0639, discriminator training loss: 0.1652, validation loss: 0.0311
2024-05-25 05:08:31 [INFO]: Epoch 055 - generator training loss: -0.0601, discriminator training loss: 0.1656, validation loss: 0.0300
2024-05-25 05:08:40 [INFO]: Epoch 056 - generator training loss: -0.0667, discriminator training loss: 0.1656, validation loss: 0.0304
2024-05-25 05:08:49 [INFO]: Epoch 057 - generator training loss: -0.0638, discriminator training loss: 0.1659, validation loss: 0.0303
2024-05-25 05:08:58 [INFO]: Epoch 058 - generator training loss: -0.0630, discriminator training loss: 0.1659, validation loss: 0.0291
2024-05-25 05:09:07 [INFO]: Epoch 059 - generator training loss: -0.0665, discriminator training loss: 0.1633, validation loss: 0.0289
2024-05-25 05:09:16 [INFO]: Epoch 060 - generator training loss: -0.0677, discriminator training loss: 0.1650, validation loss: 0.0283
2024-05-25 05:09:24 [INFO]: Epoch 061 - generator training loss: -0.0646, discriminator training loss: 0.1642, validation loss: 0.0283
2024-05-25 05:09:33 [INFO]: Epoch 062 - generator training loss: -0.0700, discriminator training loss: 0.1648, validation loss: 0.0295
2024-05-25 05:09:42 [INFO]: Epoch 063 - generator training loss: -0.0653, discriminator training loss: 0.1645, validation loss: 0.0279
2024-05-25 05:09:51 [INFO]: Epoch 064 - generator training loss: -0.0700, discriminator training loss: 0.1641, validation loss: 0.0282
2024-05-25 05:10:00 [INFO]: Epoch 065 - generator training loss: -0.0669, discriminator training loss: 0.1629, validation loss: 0.0275
2024-05-25 05:10:09 [INFO]: Epoch 066 - generator training loss: -0.0676, discriminator training loss: 0.1631, validation loss: 0.0278
2024-05-25 05:10:17 [INFO]: Epoch 067 - generator training loss: -0.0692, discriminator training loss: 0.1655, validation loss: 0.0287
2024-05-25 05:10:26 [INFO]: Epoch 068 - generator training loss: -0.0668, discriminator training loss: 0.1638, validation loss: 0.0273
2024-05-25 05:10:35 [INFO]: Epoch 069 - generator training loss: -0.0717, discriminator training loss: 0.1645, validation loss: 0.0273
2024-05-25 05:10:44 [INFO]: Epoch 070 - generator training loss: -0.0689, discriminator training loss: 0.1635, validation loss: 0.0263
2024-05-25 05:10:53 [INFO]: Epoch 071 - generator training loss: -0.0680, discriminator training loss: 0.1621, validation loss: 0.0262
2024-05-25 05:11:02 [INFO]: Epoch 072 - generator training loss: -0.0689, discriminator training loss: 0.1644, validation loss: 0.0264
2024-05-25 05:11:10 [INFO]: Epoch 073 - generator training loss: -0.0669, discriminator training loss: 0.1622, validation loss: 0.0260
2024-05-25 05:11:19 [INFO]: Epoch 074 - generator training loss: -0.0715, discriminator training loss: 0.1612, validation loss: 0.0259
2024-05-25 05:11:28 [INFO]: Epoch 075 - generator training loss: -0.0688, discriminator training loss: 0.1621, validation loss: 0.0259
2024-05-25 05:11:37 [INFO]: Epoch 076 - generator training loss: -0.0692, discriminator training loss: 0.1621, validation loss: 0.0279
2024-05-25 05:11:46 [INFO]: Epoch 077 - generator training loss: -0.0683, discriminator training loss: 0.1611, validation loss: 0.0255
2024-05-25 05:11:55 [INFO]: Epoch 078 - generator training loss: -0.0713, discriminator training loss: 0.1621, validation loss: 0.0259
2024-05-25 05:12:04 [INFO]: Epoch 079 - generator training loss: -0.0726, discriminator training loss: 0.1630, validation loss: 0.0254
2024-05-25 05:12:12 [INFO]: Epoch 080 - generator training loss: -0.0716, discriminator training loss: 0.1621, validation loss: 0.0264
2024-05-25 05:12:21 [INFO]: Epoch 081 - generator training loss: -0.0701, discriminator training loss: 0.1624, validation loss: 0.0253
2024-05-25 05:12:30 [INFO]: Epoch 082 - generator training loss: -0.0712, discriminator training loss: 0.1641, validation loss: 0.0255
2024-05-25 05:12:39 [INFO]: Epoch 083 - generator training loss: -0.0675, discriminator training loss: 0.1617, validation loss: 0.0263
2024-05-25 05:12:48 [INFO]: Epoch 084 - generator training loss: -0.0710, discriminator training loss: 0.1634, validation loss: 0.0251
2024-05-25 05:12:56 [INFO]: Epoch 085 - generator training loss: -0.0699, discriminator training loss: 0.1616, validation loss: 0.0251
2024-05-25 05:13:05 [INFO]: Epoch 086 - generator training loss: -0.0709, discriminator training loss: 0.1627, validation loss: 0.0255
2024-05-25 05:13:14 [INFO]: Epoch 087 - generator training loss: -0.0679, discriminator training loss: 0.1612, validation loss: 0.0247
2024-05-25 05:13:23 [INFO]: Epoch 088 - generator training loss: -0.0700, discriminator training loss: 0.1609, validation loss: 0.0250
2024-05-25 05:13:32 [INFO]: Epoch 089 - generator training loss: -0.0705, discriminator training loss: 0.1602, validation loss: 0.0247
2024-05-25 05:13:40 [INFO]: Epoch 090 - generator training loss: -0.0673, discriminator training loss: 0.1621, validation loss: 0.0249
2024-05-25 05:13:49 [INFO]: Epoch 091 - generator training loss: -0.0719, discriminator training loss: 0.1637, validation loss: 0.0244
2024-05-25 05:13:58 [INFO]: Epoch 092 - generator training loss: -0.0670, discriminator training loss: 0.1584, validation loss: 0.0252
2024-05-25 05:14:07 [INFO]: Epoch 093 - generator training loss: -0.0726, discriminator training loss: 0.1589, validation loss: 0.0247
2024-05-25 05:14:16 [INFO]: Epoch 094 - generator training loss: -0.0715, discriminator training loss: 0.1602, validation loss: 0.0249
2024-05-25 05:14:25 [INFO]: Epoch 095 - generator training loss: -0.0724, discriminator training loss: 0.1586, validation loss: 0.0248
2024-05-25 05:14:34 [INFO]: Epoch 096 - generator training loss: -0.0679, discriminator training loss: 0.1619, validation loss: 0.0251
2024-05-25 05:14:42 [INFO]: Epoch 097 - generator training loss: -0.0681, discriminator training loss: 0.1605, validation loss: 0.0243
2024-05-25 05:14:51 [INFO]: Epoch 098 - generator training loss: -0.0725, discriminator training loss: 0.1603, validation loss: 0.0247
2024-05-25 05:15:00 [INFO]: Epoch 099 - generator training loss: -0.0679, discriminator training loss: 0.1593, validation loss: 0.0250
2024-05-25 05:15:09 [INFO]: Epoch 100 - generator training loss: -0.0702, discriminator training loss: 0.1608, validation loss: 0.0248
2024-05-25 05:15:18 [INFO]: Epoch 101 - generator training loss: -0.0702, discriminator training loss: 0.1599, validation loss: 0.0249
2024-05-25 05:15:27 [INFO]: Epoch 102 - generator training loss: -0.0698, discriminator training loss: 0.1604, validation loss: 0.0249
2024-05-25 05:15:35 [INFO]: Epoch 103 - generator training loss: -0.0712, discriminator training loss: 0.1588, validation loss: 0.0248
2024-05-25 05:15:44 [INFO]: Epoch 104 - generator training loss: -0.0686, discriminator training loss: 0.1574, validation loss: 0.0249
2024-05-25 05:15:53 [INFO]: Epoch 105 - generator training loss: -0.0687, discriminator training loss: 0.1574, validation loss: 0.0245
2024-05-25 05:16:02 [INFO]: Epoch 106 - generator training loss: -0.0691, discriminator training loss: 0.1585, validation loss: 0.0256
2024-05-25 05:16:11 [INFO]: Epoch 107 - generator training loss: -0.0716, discriminator training loss: 0.1594, validation loss: 0.0249
2024-05-25 05:16:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:16:11 [INFO]: Finished training. The best model is from epoch#97.
2024-05-25 05:16:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/USGAN_ettm1/20240525_T050026/USGAN.pypots
2024-05-25 05:16:12 [INFO]: US-GAN on ETTm1: MAE=0.1650, MSE=0.0645
2024-05-25 05:16:12 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/USGAN_ettm1/imputation.pkl
2024-05-25 05:16:12 [INFO]: Using the given device: cuda:0
2024-05-25 05:16:12 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/BRITS_ettm1/20240525_T051612
2024-05-25 05:16:12 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/BRITS_ettm1/20240525_T051612/tensorboard
2024-05-25 05:16:12 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 05:16:19 [INFO]: Epoch 001 - training loss: 1.3879, validation loss: 0.3090
2024-05-25 05:16:25 [INFO]: Epoch 002 - training loss: 0.9470, validation loss: 0.1050
2024-05-25 05:16:31 [INFO]: Epoch 003 - training loss: 0.7624, validation loss: 0.0606
2024-05-25 05:16:37 [INFO]: Epoch 004 - training loss: 0.6955, validation loss: 0.0470
2024-05-25 05:16:43 [INFO]: Epoch 005 - training loss: 0.6215, validation loss: 0.0442
2024-05-25 05:16:49 [INFO]: Epoch 006 - training loss: 0.5901, validation loss: 0.0410
2024-05-25 05:16:54 [INFO]: Epoch 007 - training loss: 0.5657, validation loss: 0.0384
2024-05-25 05:17:00 [INFO]: Epoch 008 - training loss: 0.5354, validation loss: 0.0356
2024-05-25 05:17:06 [INFO]: Epoch 009 - training loss: 0.5071, validation loss: 0.0362
2024-05-25 05:17:12 [INFO]: Epoch 010 - training loss: 0.5532, validation loss: 0.0388
2024-05-25 05:17:18 [INFO]: Epoch 011 - training loss: 0.4998, validation loss: 0.0372
2024-05-25 05:17:24 [INFO]: Epoch 012 - training loss: 0.4766, validation loss: 0.0340
2024-05-25 05:17:30 [INFO]: Epoch 013 - training loss: 0.4607, validation loss: 0.0313
2024-05-25 05:17:36 [INFO]: Epoch 014 - training loss: 0.4443, validation loss: 0.0306
2024-05-25 05:17:42 [INFO]: Epoch 015 - training loss: 0.4364, validation loss: 0.0298
2024-05-25 05:17:48 [INFO]: Epoch 016 - training loss: 0.4345, validation loss: 0.0292
2024-05-25 05:17:53 [INFO]: Epoch 017 - training loss: 0.4222, validation loss: 0.0281
2024-05-25 05:17:59 [INFO]: Epoch 018 - training loss: 0.4155, validation loss: 0.0275
2024-05-25 05:18:05 [INFO]: Epoch 019 - training loss: 0.4171, validation loss: 0.0277
2024-05-25 05:18:11 [INFO]: Epoch 020 - training loss: 0.4113, validation loss: 0.0277
2024-05-25 05:18:17 [INFO]: Epoch 021 - training loss: 0.4107, validation loss: 0.0268
2024-05-25 05:18:23 [INFO]: Epoch 022 - training loss: 0.4069, validation loss: 0.0263
2024-05-25 05:18:29 [INFO]: Epoch 023 - training loss: 0.4055, validation loss: 0.0264
2024-05-25 05:18:34 [INFO]: Epoch 024 - training loss: 0.4078, validation loss: 0.0264
2024-05-25 05:18:40 [INFO]: Epoch 025 - training loss: 0.4063, validation loss: 0.0270
2024-05-25 05:18:46 [INFO]: Epoch 026 - training loss: 0.4022, validation loss: 0.0271
2024-05-25 05:18:52 [INFO]: Epoch 027 - training loss: 0.4053, validation loss: 0.0268
2024-05-25 05:18:58 [INFO]: Epoch 028 - training loss: 0.3946, validation loss: 0.0274
2024-05-25 05:19:04 [INFO]: Epoch 029 - training loss: 0.4394, validation loss: 0.0279
2024-05-25 05:19:10 [INFO]: Epoch 030 - training loss: 0.4080, validation loss: 0.0282
2024-05-25 05:19:16 [INFO]: Epoch 031 - training loss: 0.4035, validation loss: 0.0268
2024-05-25 05:19:21 [INFO]: Epoch 032 - training loss: 0.4015, validation loss: 0.0265
2024-05-25 05:19:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:19:21 [INFO]: Finished training. The best model is from epoch#22.
2024-05-25 05:19:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/BRITS_ettm1/20240525_T051612/BRITS.pypots
2024-05-25 05:19:22 [INFO]: BRITS on ETTm1: MAE=0.1413, MSE=0.0564
2024-05-25 05:19:22 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/BRITS_ettm1/imputation.pkl
2024-05-25 05:19:22 [INFO]: Using the given device: cuda:0
2024-05-25 05:19:22 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922
2024-05-25 05:19:22 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/tensorboard
2024-05-25 05:19:22 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 05:19:24 [INFO]: Epoch 001 - training loss: 1.3987, validation loss: 1.2805
2024-05-25 05:19:24 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch1_loss1.2805159986019135.pypots
2024-05-25 05:19:25 [INFO]: Epoch 002 - training loss: 1.0213, validation loss: 1.1152
2024-05-25 05:19:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch2_loss1.1151928156614304.pypots
2024-05-25 05:19:25 [INFO]: Epoch 003 - training loss: 0.9121, validation loss: 1.0231
2024-05-25 05:19:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch3_loss1.0231232792139053.pypots
2024-05-25 05:19:25 [INFO]: Epoch 004 - training loss: 0.8620, validation loss: 0.9978
2024-05-25 05:19:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch4_loss0.9977861195802689.pypots
2024-05-25 05:19:25 [INFO]: Epoch 005 - training loss: 0.8576, validation loss: 0.9896
2024-05-25 05:19:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch5_loss0.9896387904882431.pypots
2024-05-25 05:19:25 [INFO]: Epoch 006 - training loss: 0.8743, validation loss: 0.9834
2024-05-25 05:19:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch6_loss0.9833817332983017.pypots
2024-05-25 05:19:25 [INFO]: Epoch 007 - training loss: 0.8615, validation loss: 0.9802
2024-05-25 05:19:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch7_loss0.9801590889692307.pypots
2024-05-25 05:19:26 [INFO]: Epoch 008 - training loss: 0.8673, validation loss: 0.9769
2024-05-25 05:19:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch8_loss0.9769354909658432.pypots
2024-05-25 05:19:26 [INFO]: Epoch 009 - training loss: 0.8576, validation loss: 0.9776
2024-05-25 05:19:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch9_loss0.9776143729686737.pypots
2024-05-25 05:19:26 [INFO]: Epoch 010 - training loss: 0.8414, validation loss: 0.9792
2024-05-25 05:19:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch10_loss0.9792484194040298.pypots
2024-05-25 05:19:26 [INFO]: Epoch 011 - training loss: 0.8386, validation loss: 0.9803
2024-05-25 05:19:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch11_loss0.9803303182125092.pypots
2024-05-25 05:19:26 [INFO]: Epoch 012 - training loss: 0.8384, validation loss: 0.9826
2024-05-25 05:19:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch12_loss0.9825743734836578.pypots
2024-05-25 05:19:27 [INFO]: Epoch 013 - training loss: 0.8374, validation loss: 0.9852
2024-05-25 05:19:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch13_loss0.9852463454008102.pypots
2024-05-25 05:19:27 [INFO]: Epoch 014 - training loss: 0.8394, validation loss: 0.9830
2024-05-25 05:19:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch14_loss0.9829709976911545.pypots
2024-05-25 05:19:27 [INFO]: Epoch 015 - training loss: 0.8137, validation loss: 0.9818
2024-05-25 05:19:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch15_loss0.9818464517593384.pypots
2024-05-25 05:19:27 [INFO]: Epoch 016 - training loss: 0.8123, validation loss: 0.9825
2024-05-25 05:19:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch16_loss0.9824870824813843.pypots
2024-05-25 05:19:27 [INFO]: Epoch 017 - training loss: 0.8148, validation loss: 0.9814
2024-05-25 05:19:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch17_loss0.9814218878746033.pypots
2024-05-25 05:19:28 [INFO]: Epoch 018 - training loss: 0.8261, validation loss: 0.9784
2024-05-25 05:19:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN_epoch18_loss0.9783763438463211.pypots
2024-05-25 05:19:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:19:28 [INFO]: Finished training. The best model is from epoch#8.
2024-05-25 05:19:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T051922/MRNN.pypots
2024-05-25 05:19:28 [INFO]: MRNN on ETTm1: MAE=0.8851, MSE=1.6514
2024-05-25 05:19:28 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/MRNN_ettm1/imputation.pkl
2024-05-25 05:19:28 [INFO]: Using the given device: cpu
2024-05-25 05:19:28 [INFO]: LOCF on ETTm1: MAE=0.1420, MSE=0.0788
2024-05-25 05:19:28 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_ettm1".
2024-05-25 05:19:28 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/LOCF_ettm1/imputation.pkl
2024-05-25 05:19:28 [INFO]: Median on ETTm1: MAE=0.6533, MSE=0.8148
2024-05-25 05:19:28 [INFO]: Successfully created the given path "saved_results/round_4/Median_ettm1".
2024-05-25 05:19:28 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Median_ettm1/imputation.pkl
2024-05-25 05:19:28 [INFO]: Mean on ETTm1: MAE=0.6593, MSE=0.7994
2024-05-25 05:19:28 [INFO]: Successfully created the given path "saved_results/round_4/Mean_ettm1".
2024-05-25 05:19:28 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Mean_ettm1/imputation.pkl
2024-05-25 05:19:28 [INFO]: 
SAITS on data_overlay_premask/ettm1: MAE=0.1660.01582925732698455, MSE=0.0540.010998071924281594
Transformer on data_overlay_premask/ettm1: MAE=0.1370.007456990699675313, MSE=0.0390.0040762789341240255
TimesNet on data_overlay_premask/ettm1: MAE=0.1150.0009456327331487199, MSE=0.0290.00033645078442880866
CSDI on data_overlay_premask/ettm1: MAE=0.1330.011388909376584416, MSE=0.0420.006700107102209795
GPVAE on data_overlay_premask/ettm1: MAE=0.2890.004327346864538805, MSE=0.1780.006927588861562325
USGAN on data_overlay_premask/ettm1: MAE=0.1590.005636148865440058, MSE=0.0630.003756942681480856
BRITS on data_overlay_premask/ettm1: MAE=0.1410.0026656530243172353, MSE=0.0570.0017626081445188191
MRNN on data_overlay_premask/ettm1: MAE=0.6530.11626381113086087, MSE=1.1210.2654122958761271
LOCF on data_overlay_premask/ettm1: MAE=0.1420.0, MSE=0.0790.0
Median on data_overlay_premask/ettm1: MAE=0.6530.0, MSE=0.8151.1102230246251565e-16
Mean on data_overlay_premask/ettm1: MAE=0.6590.0, MSE=0.7990.0
