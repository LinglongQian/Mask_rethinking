2024-05-25 00:56:42 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-25 00:56:42 [INFO]: Using the given device: cuda:0
2024-05-25 00:56:43 [INFO]: Model files will be saved to augmentation_saved_results/round_0/SAITS_air_quality/20240525_T005643
2024-05-25 00:56:43 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/SAITS_air_quality/20240525_T005643/tensorboard
2024-05-25 00:56:43 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 00:56:44 [INFO]: Epoch 001 - training loss: 1.0553, validation loss: 0.5318
2024-05-25 00:56:45 [INFO]: Epoch 002 - training loss: 0.7635, validation loss: 0.4108
2024-05-25 00:56:46 [INFO]: Epoch 003 - training loss: 0.6584, validation loss: 0.3321
2024-05-25 00:56:46 [INFO]: Epoch 004 - training loss: 0.5806, validation loss: 0.2883
2024-05-25 00:56:47 [INFO]: Epoch 005 - training loss: 0.5245, validation loss: 0.2636
2024-05-25 00:56:48 [INFO]: Epoch 006 - training loss: 0.4864, validation loss: 0.2514
2024-05-25 00:56:48 [INFO]: Epoch 007 - training loss: 0.4623, validation loss: 0.2387
2024-05-25 00:56:49 [INFO]: Epoch 008 - training loss: 0.4413, validation loss: 0.2339
2024-05-25 00:56:50 [INFO]: Epoch 009 - training loss: 0.4270, validation loss: 0.2278
2024-05-25 00:56:50 [INFO]: Epoch 010 - training loss: 0.4174, validation loss: 0.2247
2024-05-25 00:56:51 [INFO]: Epoch 011 - training loss: 0.4061, validation loss: 0.2186
2024-05-25 00:56:52 [INFO]: Epoch 012 - training loss: 0.3985, validation loss: 0.2135
2024-05-25 00:56:52 [INFO]: Epoch 013 - training loss: 0.3904, validation loss: 0.2097
2024-05-25 00:56:53 [INFO]: Epoch 014 - training loss: 0.3820, validation loss: 0.2089
2024-05-25 00:56:54 [INFO]: Epoch 015 - training loss: 0.3771, validation loss: 0.2056
2024-05-25 00:56:54 [INFO]: Epoch 016 - training loss: 0.3711, validation loss: 0.2030
2024-05-25 00:56:55 [INFO]: Epoch 017 - training loss: 0.3668, validation loss: 0.1992
2024-05-25 00:56:56 [INFO]: Epoch 018 - training loss: 0.3616, validation loss: 0.1984
2024-05-25 00:56:56 [INFO]: Epoch 019 - training loss: 0.3577, validation loss: 0.1955
2024-05-25 00:56:57 [INFO]: Epoch 020 - training loss: 0.3528, validation loss: 0.1936
2024-05-25 00:56:58 [INFO]: Epoch 021 - training loss: 0.3494, validation loss: 0.1927
2024-05-25 00:56:58 [INFO]: Epoch 022 - training loss: 0.3467, validation loss: 0.1908
2024-05-25 00:56:59 [INFO]: Epoch 023 - training loss: 0.3431, validation loss: 0.1902
2024-05-25 00:57:00 [INFO]: Epoch 024 - training loss: 0.3402, validation loss: 0.1866
2024-05-25 00:57:00 [INFO]: Epoch 025 - training loss: 0.3383, validation loss: 0.1863
2024-05-25 00:57:01 [INFO]: Epoch 026 - training loss: 0.3358, validation loss: 0.1856
2024-05-25 00:57:02 [INFO]: Epoch 027 - training loss: 0.3330, validation loss: 0.1838
2024-05-25 00:57:02 [INFO]: Epoch 028 - training loss: 0.3305, validation loss: 0.1824
2024-05-25 00:57:03 [INFO]: Epoch 029 - training loss: 0.3271, validation loss: 0.1807
2024-05-25 00:57:04 [INFO]: Epoch 030 - training loss: 0.3263, validation loss: 0.1803
2024-05-25 00:57:04 [INFO]: Epoch 031 - training loss: 0.3231, validation loss: 0.1793
2024-05-25 00:57:05 [INFO]: Epoch 032 - training loss: 0.3209, validation loss: 0.1776
2024-05-25 00:57:06 [INFO]: Epoch 033 - training loss: 0.3195, validation loss: 0.1748
2024-05-25 00:57:06 [INFO]: Epoch 034 - training loss: 0.3168, validation loss: 0.1759
2024-05-25 00:57:07 [INFO]: Epoch 035 - training loss: 0.3184, validation loss: 0.1755
2024-05-25 00:57:08 [INFO]: Epoch 036 - training loss: 0.3155, validation loss: 0.1742
2024-05-25 00:57:08 [INFO]: Epoch 037 - training loss: 0.3136, validation loss: 0.1718
2024-05-25 00:57:09 [INFO]: Epoch 038 - training loss: 0.3093, validation loss: 0.1723
2024-05-25 00:57:10 [INFO]: Epoch 039 - training loss: 0.3089, validation loss: 0.1695
2024-05-25 00:57:10 [INFO]: Epoch 040 - training loss: 0.3064, validation loss: 0.1682
2024-05-25 00:57:11 [INFO]: Epoch 041 - training loss: 0.3044, validation loss: 0.1679
2024-05-25 00:57:12 [INFO]: Epoch 042 - training loss: 0.3020, validation loss: 0.1672
2024-05-25 00:57:12 [INFO]: Epoch 043 - training loss: 0.3017, validation loss: 0.1656
2024-05-25 00:57:13 [INFO]: Epoch 044 - training loss: 0.3007, validation loss: 0.1655
2024-05-25 00:57:14 [INFO]: Epoch 045 - training loss: 0.2979, validation loss: 0.1658
2024-05-25 00:57:14 [INFO]: Epoch 046 - training loss: 0.2987, validation loss: 0.1638
2024-05-25 00:57:15 [INFO]: Epoch 047 - training loss: 0.2973, validation loss: 0.1626
2024-05-25 00:57:16 [INFO]: Epoch 048 - training loss: 0.2932, validation loss: 0.1628
2024-05-25 00:57:16 [INFO]: Epoch 049 - training loss: 0.2940, validation loss: 0.1620
2024-05-25 00:57:17 [INFO]: Epoch 050 - training loss: 0.2912, validation loss: 0.1614
2024-05-25 00:57:18 [INFO]: Epoch 051 - training loss: 0.2916, validation loss: 0.1610
2024-05-25 00:57:18 [INFO]: Epoch 052 - training loss: 0.2898, validation loss: 0.1593
2024-05-25 00:57:19 [INFO]: Epoch 053 - training loss: 0.2886, validation loss: 0.1590
2024-05-25 00:57:20 [INFO]: Epoch 054 - training loss: 0.2864, validation loss: 0.1588
2024-05-25 00:57:20 [INFO]: Epoch 055 - training loss: 0.2848, validation loss: 0.1574
2024-05-25 00:57:21 [INFO]: Epoch 056 - training loss: 0.2838, validation loss: 0.1568
2024-05-25 00:57:22 [INFO]: Epoch 057 - training loss: 0.2823, validation loss: 0.1551
2024-05-25 00:57:22 [INFO]: Epoch 058 - training loss: 0.2823, validation loss: 0.1547
2024-05-25 00:57:23 [INFO]: Epoch 059 - training loss: 0.2805, validation loss: 0.1545
2024-05-25 00:57:24 [INFO]: Epoch 060 - training loss: 0.2808, validation loss: 0.1548
2024-05-25 00:57:24 [INFO]: Epoch 061 - training loss: 0.2776, validation loss: 0.1542
2024-05-25 00:57:25 [INFO]: Epoch 062 - training loss: 0.2763, validation loss: 0.1526
2024-05-25 00:57:26 [INFO]: Epoch 063 - training loss: 0.2755, validation loss: 0.1530
2024-05-25 00:57:26 [INFO]: Epoch 064 - training loss: 0.2749, validation loss: 0.1507
2024-05-25 00:57:27 [INFO]: Epoch 065 - training loss: 0.2727, validation loss: 0.1521
2024-05-25 00:57:27 [INFO]: Epoch 066 - training loss: 0.2715, validation loss: 0.1508
2024-05-25 00:57:28 [INFO]: Epoch 067 - training loss: 0.2702, validation loss: 0.1501
2024-05-25 00:57:29 [INFO]: Epoch 068 - training loss: 0.2703, validation loss: 0.1497
2024-05-25 00:57:29 [INFO]: Epoch 069 - training loss: 0.2677, validation loss: 0.1497
2024-05-25 00:57:30 [INFO]: Epoch 070 - training loss: 0.2671, validation loss: 0.1499
2024-05-25 00:57:31 [INFO]: Epoch 071 - training loss: 0.2658, validation loss: 0.1492
2024-05-25 00:57:31 [INFO]: Epoch 072 - training loss: 0.2657, validation loss: 0.1476
2024-05-25 00:57:32 [INFO]: Epoch 073 - training loss: 0.2662, validation loss: 0.1469
2024-05-25 00:57:33 [INFO]: Epoch 074 - training loss: 0.2638, validation loss: 0.1472
2024-05-25 00:57:33 [INFO]: Epoch 075 - training loss: 0.2623, validation loss: 0.1466
2024-05-25 00:57:34 [INFO]: Epoch 076 - training loss: 0.2615, validation loss: 0.1458
2024-05-25 00:57:35 [INFO]: Epoch 077 - training loss: 0.2610, validation loss: 0.1458
2024-05-25 00:57:35 [INFO]: Epoch 078 - training loss: 0.2611, validation loss: 0.1463
2024-05-25 00:57:36 [INFO]: Epoch 079 - training loss: 0.2603, validation loss: 0.1452
2024-05-25 00:57:37 [INFO]: Epoch 080 - training loss: 0.2574, validation loss: 0.1445
2024-05-25 00:57:37 [INFO]: Epoch 081 - training loss: 0.2578, validation loss: 0.1440
2024-05-25 00:57:38 [INFO]: Epoch 082 - training loss: 0.2576, validation loss: 0.1447
2024-05-25 00:57:39 [INFO]: Epoch 083 - training loss: 0.2562, validation loss: 0.1433
2024-05-25 00:57:39 [INFO]: Epoch 084 - training loss: 0.2546, validation loss: 0.1427
2024-05-25 00:57:40 [INFO]: Epoch 085 - training loss: 0.2534, validation loss: 0.1430
2024-05-25 00:57:41 [INFO]: Epoch 086 - training loss: 0.2533, validation loss: 0.1411
2024-05-25 00:57:41 [INFO]: Epoch 087 - training loss: 0.2540, validation loss: 0.1419
2024-05-25 00:57:42 [INFO]: Epoch 088 - training loss: 0.2536, validation loss: 0.1416
2024-05-25 00:57:43 [INFO]: Epoch 089 - training loss: 0.2516, validation loss: 0.1406
2024-05-25 00:57:43 [INFO]: Epoch 090 - training loss: 0.2504, validation loss: 0.1400
2024-05-25 00:57:44 [INFO]: Epoch 091 - training loss: 0.2500, validation loss: 0.1404
2024-05-25 00:57:45 [INFO]: Epoch 092 - training loss: 0.2496, validation loss: 0.1394
2024-05-25 00:57:45 [INFO]: Epoch 093 - training loss: 0.2492, validation loss: 0.1401
2024-05-25 00:57:46 [INFO]: Epoch 094 - training loss: 0.2472, validation loss: 0.1392
2024-05-25 00:57:47 [INFO]: Epoch 095 - training loss: 0.2475, validation loss: 0.1389
2024-05-25 00:57:47 [INFO]: Epoch 096 - training loss: 0.2469, validation loss: 0.1392
2024-05-25 00:57:48 [INFO]: Epoch 097 - training loss: 0.2482, validation loss: 0.1385
2024-05-25 00:57:49 [INFO]: Epoch 098 - training loss: 0.2459, validation loss: 0.1382
2024-05-25 00:57:49 [INFO]: Epoch 099 - training loss: 0.2448, validation loss: 0.1386
2024-05-25 00:57:50 [INFO]: Epoch 100 - training loss: 0.2465, validation loss: 0.1384
2024-05-25 00:57:51 [INFO]: Epoch 101 - training loss: 0.2451, validation loss: 0.1373
2024-05-25 00:57:51 [INFO]: Epoch 102 - training loss: 0.2440, validation loss: 0.1369
2024-05-25 00:57:52 [INFO]: Epoch 103 - training loss: 0.2429, validation loss: 0.1367
2024-05-25 00:57:53 [INFO]: Epoch 104 - training loss: 0.2426, validation loss: 0.1369
2024-05-25 00:57:53 [INFO]: Epoch 105 - training loss: 0.2430, validation loss: 0.1363
2024-05-25 00:57:54 [INFO]: Epoch 106 - training loss: 0.2420, validation loss: 0.1360
2024-05-25 00:57:55 [INFO]: Epoch 107 - training loss: 0.2417, validation loss: 0.1367
2024-05-25 00:57:55 [INFO]: Epoch 108 - training loss: 0.2405, validation loss: 0.1353
2024-05-25 00:57:56 [INFO]: Epoch 109 - training loss: 0.2401, validation loss: 0.1365
2024-05-25 00:57:57 [INFO]: Epoch 110 - training loss: 0.2409, validation loss: 0.1357
2024-05-25 00:57:57 [INFO]: Epoch 111 - training loss: 0.2396, validation loss: 0.1363
2024-05-25 00:57:58 [INFO]: Epoch 112 - training loss: 0.2383, validation loss: 0.1348
2024-05-25 00:57:59 [INFO]: Epoch 113 - training loss: 0.2368, validation loss: 0.1343
2024-05-25 00:57:59 [INFO]: Epoch 114 - training loss: 0.2371, validation loss: 0.1346
2024-05-25 00:58:00 [INFO]: Epoch 115 - training loss: 0.2379, validation loss: 0.1341
2024-05-25 00:58:01 [INFO]: Epoch 116 - training loss: 0.2376, validation loss: 0.1340
2024-05-25 00:58:01 [INFO]: Epoch 117 - training loss: 0.2352, validation loss: 0.1341
2024-05-25 00:58:02 [INFO]: Epoch 118 - training loss: 0.2349, validation loss: 0.1336
2024-05-25 00:58:02 [INFO]: Epoch 119 - training loss: 0.2340, validation loss: 0.1335
2024-05-25 00:58:03 [INFO]: Epoch 120 - training loss: 0.2331, validation loss: 0.1331
2024-05-25 00:58:04 [INFO]: Epoch 121 - training loss: 0.2324, validation loss: 0.1326
2024-05-25 00:58:04 [INFO]: Epoch 122 - training loss: 0.2342, validation loss: 0.1327
2024-05-25 00:58:05 [INFO]: Epoch 123 - training loss: 0.2347, validation loss: 0.1322
2024-05-25 00:58:06 [INFO]: Epoch 124 - training loss: 0.2320, validation loss: 0.1323
2024-05-25 00:58:06 [INFO]: Epoch 125 - training loss: 0.2323, validation loss: 0.1326
2024-05-25 00:58:07 [INFO]: Epoch 126 - training loss: 0.2313, validation loss: 0.1318
2024-05-25 00:58:08 [INFO]: Epoch 127 - training loss: 0.2326, validation loss: 0.1327
2024-05-25 00:58:08 [INFO]: Epoch 128 - training loss: 0.2309, validation loss: 0.1332
2024-05-25 00:58:09 [INFO]: Epoch 129 - training loss: 0.2301, validation loss: 0.1322
2024-05-25 00:58:10 [INFO]: Epoch 130 - training loss: 0.2300, validation loss: 0.1314
2024-05-25 00:58:10 [INFO]: Epoch 131 - training loss: 0.2298, validation loss: 0.1319
2024-05-25 00:58:11 [INFO]: Epoch 132 - training loss: 0.2300, validation loss: 0.1313
2024-05-25 00:58:12 [INFO]: Epoch 133 - training loss: 0.2289, validation loss: 0.1316
2024-05-25 00:58:12 [INFO]: Epoch 134 - training loss: 0.2279, validation loss: 0.1311
2024-05-25 00:58:13 [INFO]: Epoch 135 - training loss: 0.2270, validation loss: 0.1305
2024-05-25 00:58:14 [INFO]: Epoch 136 - training loss: 0.2283, validation loss: 0.1319
2024-05-25 00:58:14 [INFO]: Epoch 137 - training loss: 0.2279, validation loss: 0.1306
2024-05-25 00:58:15 [INFO]: Epoch 138 - training loss: 0.2264, validation loss: 0.1302
2024-05-25 00:58:16 [INFO]: Epoch 139 - training loss: 0.2248, validation loss: 0.1301
2024-05-25 00:58:16 [INFO]: Epoch 140 - training loss: 0.2258, validation loss: 0.1293
2024-05-25 00:58:17 [INFO]: Epoch 141 - training loss: 0.2263, validation loss: 0.1300
2024-05-25 00:58:18 [INFO]: Epoch 142 - training loss: 0.2249, validation loss: 0.1294
2024-05-25 00:58:18 [INFO]: Epoch 143 - training loss: 0.2246, validation loss: 0.1285
2024-05-25 00:58:19 [INFO]: Epoch 144 - training loss: 0.2235, validation loss: 0.1277
2024-05-25 00:58:20 [INFO]: Epoch 145 - training loss: 0.2238, validation loss: 0.1293
2024-05-25 00:58:20 [INFO]: Epoch 146 - training loss: 0.2232, validation loss: 0.1284
2024-05-25 00:58:21 [INFO]: Epoch 147 - training loss: 0.2249, validation loss: 0.1287
2024-05-25 00:58:22 [INFO]: Epoch 148 - training loss: 0.2224, validation loss: 0.1292
2024-05-25 00:58:22 [INFO]: Epoch 149 - training loss: 0.2231, validation loss: 0.1281
2024-05-25 00:58:23 [INFO]: Epoch 150 - training loss: 0.2233, validation loss: 0.1283
2024-05-25 00:58:24 [INFO]: Epoch 151 - training loss: 0.2229, validation loss: 0.1274
2024-05-25 00:58:24 [INFO]: Epoch 152 - training loss: 0.2216, validation loss: 0.1273
2024-05-25 00:58:25 [INFO]: Epoch 153 - training loss: 0.2202, validation loss: 0.1274
2024-05-25 00:58:26 [INFO]: Epoch 154 - training loss: 0.2205, validation loss: 0.1275
2024-05-25 00:58:26 [INFO]: Epoch 155 - training loss: 0.2218, validation loss: 0.1265
2024-05-25 00:58:27 [INFO]: Epoch 156 - training loss: 0.2193, validation loss: 0.1270
2024-05-25 00:58:28 [INFO]: Epoch 157 - training loss: 0.2194, validation loss: 0.1267
2024-05-25 00:58:28 [INFO]: Epoch 158 - training loss: 0.2200, validation loss: 0.1270
2024-05-25 00:58:29 [INFO]: Epoch 159 - training loss: 0.2189, validation loss: 0.1269
2024-05-25 00:58:30 [INFO]: Epoch 160 - training loss: 0.2198, validation loss: 0.1273
2024-05-25 00:58:30 [INFO]: Epoch 161 - training loss: 0.2194, validation loss: 0.1265
2024-05-25 00:58:31 [INFO]: Epoch 162 - training loss: 0.2226, validation loss: 0.1262
2024-05-25 00:58:31 [INFO]: Epoch 163 - training loss: 0.2193, validation loss: 0.1259
2024-05-25 00:58:32 [INFO]: Epoch 164 - training loss: 0.2169, validation loss: 0.1258
2024-05-25 00:58:33 [INFO]: Epoch 165 - training loss: 0.2175, validation loss: 0.1260
2024-05-25 00:58:33 [INFO]: Epoch 166 - training loss: 0.2180, validation loss: 0.1257
2024-05-25 00:58:34 [INFO]: Epoch 167 - training loss: 0.2169, validation loss: 0.1259
2024-05-25 00:58:35 [INFO]: Epoch 168 - training loss: 0.2165, validation loss: 0.1251
2024-05-25 00:58:35 [INFO]: Epoch 169 - training loss: 0.2167, validation loss: 0.1253
2024-05-25 00:58:36 [INFO]: Epoch 170 - training loss: 0.2166, validation loss: 0.1248
2024-05-25 00:58:37 [INFO]: Epoch 171 - training loss: 0.2167, validation loss: 0.1250
2024-05-25 00:58:37 [INFO]: Epoch 172 - training loss: 0.2182, validation loss: 0.1255
2024-05-25 00:58:38 [INFO]: Epoch 173 - training loss: 0.2148, validation loss: 0.1246
2024-05-25 00:58:39 [INFO]: Epoch 174 - training loss: 0.2140, validation loss: 0.1240
2024-05-25 00:58:39 [INFO]: Epoch 175 - training loss: 0.2138, validation loss: 0.1257
2024-05-25 00:58:40 [INFO]: Epoch 176 - training loss: 0.2145, validation loss: 0.1245
2024-05-25 00:58:41 [INFO]: Epoch 177 - training loss: 0.2137, validation loss: 0.1243
2024-05-25 00:58:41 [INFO]: Epoch 178 - training loss: 0.2150, validation loss: 0.1250
2024-05-25 00:58:42 [INFO]: Epoch 179 - training loss: 0.2127, validation loss: 0.1242
2024-05-25 00:58:43 [INFO]: Epoch 180 - training loss: 0.2136, validation loss: 0.1248
2024-05-25 00:58:43 [INFO]: Epoch 181 - training loss: 0.2144, validation loss: 0.1250
2024-05-25 00:58:44 [INFO]: Epoch 182 - training loss: 0.2185, validation loss: 0.1234
2024-05-25 00:58:45 [INFO]: Epoch 183 - training loss: 0.2131, validation loss: 0.1231
2024-05-25 00:58:45 [INFO]: Epoch 184 - training loss: 0.2124, validation loss: 0.1236
2024-05-25 00:58:46 [INFO]: Epoch 185 - training loss: 0.2115, validation loss: 0.1239
2024-05-25 00:58:47 [INFO]: Epoch 186 - training loss: 0.2123, validation loss: 0.1233
2024-05-25 00:58:47 [INFO]: Epoch 187 - training loss: 0.2111, validation loss: 0.1228
2024-05-25 00:58:48 [INFO]: Epoch 188 - training loss: 0.2108, validation loss: 0.1229
2024-05-25 00:58:49 [INFO]: Epoch 189 - training loss: 0.2110, validation loss: 0.1225
2024-05-25 00:58:49 [INFO]: Epoch 190 - training loss: 0.2115, validation loss: 0.1238
2024-05-25 00:58:50 [INFO]: Epoch 191 - training loss: 0.2106, validation loss: 0.1219
2024-05-25 00:58:51 [INFO]: Epoch 192 - training loss: 0.2101, validation loss: 0.1222
2024-05-25 00:58:51 [INFO]: Epoch 193 - training loss: 0.2090, validation loss: 0.1221
2024-05-25 00:58:52 [INFO]: Epoch 194 - training loss: 0.2087, validation loss: 0.1228
2024-05-25 00:58:53 [INFO]: Epoch 195 - training loss: 0.2099, validation loss: 0.1225
2024-05-25 00:58:53 [INFO]: Epoch 196 - training loss: 0.2092, validation loss: 0.1229
2024-05-25 00:58:54 [INFO]: Epoch 197 - training loss: 0.2090, validation loss: 0.1220
2024-05-25 00:58:55 [INFO]: Epoch 198 - training loss: 0.2077, validation loss: 0.1222
2024-05-25 00:58:55 [INFO]: Epoch 199 - training loss: 0.2083, validation loss: 0.1223
2024-05-25 00:58:56 [INFO]: Epoch 200 - training loss: 0.2076, validation loss: 0.1220
2024-05-25 00:58:57 [INFO]: Epoch 201 - training loss: 0.2080, validation loss: 0.1218
2024-05-25 00:58:57 [INFO]: Epoch 202 - training loss: 0.2088, validation loss: 0.1210
2024-05-25 00:58:58 [INFO]: Epoch 203 - training loss: 0.2083, validation loss: 0.1210
2024-05-25 00:58:59 [INFO]: Epoch 204 - training loss: 0.2079, validation loss: 0.1217
2024-05-25 00:58:59 [INFO]: Epoch 205 - training loss: 0.2064, validation loss: 0.1212
2024-05-25 00:59:00 [INFO]: Epoch 206 - training loss: 0.2066, validation loss: 0.1212
2024-05-25 00:59:01 [INFO]: Epoch 207 - training loss: 0.2053, validation loss: 0.1200
2024-05-25 00:59:01 [INFO]: Epoch 208 - training loss: 0.2058, validation loss: 0.1214
2024-05-25 00:59:02 [INFO]: Epoch 209 - training loss: 0.2084, validation loss: 0.1208
2024-05-25 00:59:03 [INFO]: Epoch 210 - training loss: 0.2058, validation loss: 0.1209
2024-05-25 00:59:03 [INFO]: Epoch 211 - training loss: 0.2053, validation loss: 0.1213
2024-05-25 00:59:04 [INFO]: Epoch 212 - training loss: 0.2033, validation loss: 0.1207
2024-05-25 00:59:05 [INFO]: Epoch 213 - training loss: 0.2050, validation loss: 0.1200
2024-05-25 00:59:05 [INFO]: Epoch 214 - training loss: 0.2050, validation loss: 0.1212
2024-05-25 00:59:06 [INFO]: Epoch 215 - training loss: 0.2042, validation loss: 0.1200
2024-05-25 00:59:07 [INFO]: Epoch 216 - training loss: 0.2038, validation loss: 0.1194
2024-05-25 00:59:07 [INFO]: Epoch 217 - training loss: 0.2034, validation loss: 0.1203
2024-05-25 00:59:08 [INFO]: Epoch 218 - training loss: 0.2027, validation loss: 0.1194
2024-05-25 00:59:09 [INFO]: Epoch 219 - training loss: 0.2034, validation loss: 0.1192
2024-05-25 00:59:09 [INFO]: Epoch 220 - training loss: 0.2034, validation loss: 0.1200
2024-05-25 00:59:10 [INFO]: Epoch 221 - training loss: 0.2034, validation loss: 0.1193
2024-05-25 00:59:11 [INFO]: Epoch 222 - training loss: 0.2047, validation loss: 0.1194
2024-05-25 00:59:11 [INFO]: Epoch 223 - training loss: 0.2039, validation loss: 0.1189
2024-05-25 00:59:12 [INFO]: Epoch 224 - training loss: 0.2018, validation loss: 0.1188
2024-05-25 00:59:13 [INFO]: Epoch 225 - training loss: 0.2019, validation loss: 0.1188
2024-05-25 00:59:13 [INFO]: Epoch 226 - training loss: 0.2013, validation loss: 0.1185
2024-05-25 00:59:14 [INFO]: Epoch 227 - training loss: 0.2019, validation loss: 0.1183
2024-05-25 00:59:15 [INFO]: Epoch 228 - training loss: 0.2018, validation loss: 0.1190
2024-05-25 00:59:15 [INFO]: Epoch 229 - training loss: 0.2019, validation loss: 0.1183
2024-05-25 00:59:16 [INFO]: Epoch 230 - training loss: 0.2013, validation loss: 0.1179
2024-05-25 00:59:17 [INFO]: Epoch 231 - training loss: 0.2008, validation loss: 0.1180
2024-05-25 00:59:17 [INFO]: Epoch 232 - training loss: 0.2002, validation loss: 0.1180
2024-05-25 00:59:18 [INFO]: Epoch 233 - training loss: 0.2013, validation loss: 0.1188
2024-05-25 00:59:18 [INFO]: Epoch 234 - training loss: 0.2005, validation loss: 0.1182
2024-05-25 00:59:19 [INFO]: Epoch 235 - training loss: 0.2015, validation loss: 0.1177
2024-05-25 00:59:20 [INFO]: Epoch 236 - training loss: 0.2027, validation loss: 0.1180
2024-05-25 00:59:20 [INFO]: Epoch 237 - training loss: 0.2019, validation loss: 0.1176
2024-05-25 00:59:21 [INFO]: Epoch 238 - training loss: 0.1998, validation loss: 0.1168
2024-05-25 00:59:22 [INFO]: Epoch 239 - training loss: 0.2016, validation loss: 0.1175
2024-05-25 00:59:22 [INFO]: Epoch 240 - training loss: 0.1984, validation loss: 0.1174
2024-05-25 00:59:23 [INFO]: Epoch 241 - training loss: 0.1985, validation loss: 0.1168
2024-05-25 00:59:24 [INFO]: Epoch 242 - training loss: 0.1982, validation loss: 0.1168
2024-05-25 00:59:24 [INFO]: Epoch 243 - training loss: 0.1999, validation loss: 0.1165
2024-05-25 00:59:25 [INFO]: Epoch 244 - training loss: 0.1989, validation loss: 0.1170
2024-05-25 00:59:26 [INFO]: Epoch 245 - training loss: 0.1994, validation loss: 0.1166
2024-05-25 00:59:26 [INFO]: Epoch 246 - training loss: 0.1976, validation loss: 0.1178
2024-05-25 00:59:27 [INFO]: Epoch 247 - training loss: 0.1987, validation loss: 0.1167
2024-05-25 00:59:28 [INFO]: Epoch 248 - training loss: 0.1976, validation loss: 0.1157
2024-05-25 00:59:28 [INFO]: Epoch 249 - training loss: 0.1952, validation loss: 0.1160
2024-05-25 00:59:29 [INFO]: Epoch 250 - training loss: 0.1973, validation loss: 0.1153
2024-05-25 00:59:30 [INFO]: Epoch 251 - training loss: 0.1960, validation loss: 0.1158
2024-05-25 00:59:30 [INFO]: Epoch 252 - training loss: 0.1973, validation loss: 0.1151
2024-05-25 00:59:31 [INFO]: Epoch 253 - training loss: 0.1969, validation loss: 0.1148
2024-05-25 00:59:32 [INFO]: Epoch 254 - training loss: 0.1960, validation loss: 0.1154
2024-05-25 00:59:32 [INFO]: Epoch 255 - training loss: 0.1963, validation loss: 0.1158
2024-05-25 00:59:33 [INFO]: Epoch 256 - training loss: 0.1968, validation loss: 0.1164
2024-05-25 00:59:34 [INFO]: Epoch 257 - training loss: 0.1951, validation loss: 0.1156
2024-05-25 00:59:34 [INFO]: Epoch 258 - training loss: 0.1943, validation loss: 0.1164
2024-05-25 00:59:35 [INFO]: Epoch 259 - training loss: 0.1948, validation loss: 0.1157
2024-05-25 00:59:36 [INFO]: Epoch 260 - training loss: 0.1957, validation loss: 0.1161
2024-05-25 00:59:36 [INFO]: Epoch 261 - training loss: 0.1958, validation loss: 0.1163
2024-05-25 00:59:37 [INFO]: Epoch 262 - training loss: 0.1982, validation loss: 0.1152
2024-05-25 00:59:38 [INFO]: Epoch 263 - training loss: 0.1959, validation loss: 0.1161
2024-05-25 00:59:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:59:38 [INFO]: Finished training. The best model is from epoch#253.
2024-05-25 00:59:38 [INFO]: Saved the model to augmentation_saved_results/round_0/SAITS_air_quality/20240525_T005643/SAITS.pypots
2024-05-25 00:59:38 [INFO]: SAITS on Air-Quality: MAE=0.1507, MSE=0.1780
2024-05-25 00:59:38 [INFO]: Successfully saved to augmentation_saved_results/round_0/SAITS_air_quality/imputation.pkl
2024-05-25 00:59:38 [INFO]: Using the given device: cuda:0
2024-05-25 00:59:38 [INFO]: Model files will be saved to augmentation_saved_results/round_0/Transformer_air_quality/20240525_T005938
2024-05-25 00:59:38 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/Transformer_air_quality/20240525_T005938/tensorboard
2024-05-25 00:59:38 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 00:59:38 [INFO]: Epoch 001 - training loss: 0.9379, validation loss: 0.4766
2024-05-25 00:59:39 [INFO]: Epoch 002 - training loss: 0.5871, validation loss: 0.3663
2024-05-25 00:59:39 [INFO]: Epoch 003 - training loss: 0.4902, validation loss: 0.2983
2024-05-25 00:59:39 [INFO]: Epoch 004 - training loss: 0.4397, validation loss: 0.2708
2024-05-25 00:59:40 [INFO]: Epoch 005 - training loss: 0.4116, validation loss: 0.2623
2024-05-25 00:59:40 [INFO]: Epoch 006 - training loss: 0.3926, validation loss: 0.2507
2024-05-25 00:59:40 [INFO]: Epoch 007 - training loss: 0.3792, validation loss: 0.2391
2024-05-25 00:59:41 [INFO]: Epoch 008 - training loss: 0.3646, validation loss: 0.2321
2024-05-25 00:59:41 [INFO]: Epoch 009 - training loss: 0.3567, validation loss: 0.2271
2024-05-25 00:59:41 [INFO]: Epoch 010 - training loss: 0.3492, validation loss: 0.2247
2024-05-25 00:59:41 [INFO]: Epoch 011 - training loss: 0.3436, validation loss: 0.2179
2024-05-25 00:59:42 [INFO]: Epoch 012 - training loss: 0.3349, validation loss: 0.2144
2024-05-25 00:59:42 [INFO]: Epoch 013 - training loss: 0.3301, validation loss: 0.2121
2024-05-25 00:59:42 [INFO]: Epoch 014 - training loss: 0.3250, validation loss: 0.2107
2024-05-25 00:59:43 [INFO]: Epoch 015 - training loss: 0.3223, validation loss: 0.2053
2024-05-25 00:59:43 [INFO]: Epoch 016 - training loss: 0.3226, validation loss: 0.2042
2024-05-25 00:59:43 [INFO]: Epoch 017 - training loss: 0.3210, validation loss: 0.2026
2024-05-25 00:59:44 [INFO]: Epoch 018 - training loss: 0.3141, validation loss: 0.2006
2024-05-25 00:59:44 [INFO]: Epoch 019 - training loss: 0.3104, validation loss: 0.1984
2024-05-25 00:59:44 [INFO]: Epoch 020 - training loss: 0.3060, validation loss: 0.1940
2024-05-25 00:59:45 [INFO]: Epoch 021 - training loss: 0.3024, validation loss: 0.1928
2024-05-25 00:59:45 [INFO]: Epoch 022 - training loss: 0.3032, validation loss: 0.1900
2024-05-25 00:59:45 [INFO]: Epoch 023 - training loss: 0.3002, validation loss: 0.1902
2024-05-25 00:59:46 [INFO]: Epoch 024 - training loss: 0.2993, validation loss: 0.1888
2024-05-25 00:59:46 [INFO]: Epoch 025 - training loss: 0.2955, validation loss: 0.1869
2024-05-25 00:59:46 [INFO]: Epoch 026 - training loss: 0.2933, validation loss: 0.1878
2024-05-25 00:59:46 [INFO]: Epoch 027 - training loss: 0.2939, validation loss: 0.1866
2024-05-25 00:59:47 [INFO]: Epoch 028 - training loss: 0.2898, validation loss: 0.1842
2024-05-25 00:59:47 [INFO]: Epoch 029 - training loss: 0.2885, validation loss: 0.1805
2024-05-25 00:59:47 [INFO]: Epoch 030 - training loss: 0.2869, validation loss: 0.1810
2024-05-25 00:59:48 [INFO]: Epoch 031 - training loss: 0.2862, validation loss: 0.1790
2024-05-25 00:59:48 [INFO]: Epoch 032 - training loss: 0.2836, validation loss: 0.1814
2024-05-25 00:59:48 [INFO]: Epoch 033 - training loss: 0.2805, validation loss: 0.1799
2024-05-25 00:59:49 [INFO]: Epoch 034 - training loss: 0.2802, validation loss: 0.1782
2024-05-25 00:59:49 [INFO]: Epoch 035 - training loss: 0.2803, validation loss: 0.1779
2024-05-25 00:59:49 [INFO]: Epoch 036 - training loss: 0.2795, validation loss: 0.1803
2024-05-25 00:59:50 [INFO]: Epoch 037 - training loss: 0.2786, validation loss: 0.1790
2024-05-25 00:59:50 [INFO]: Epoch 038 - training loss: 0.2763, validation loss: 0.1764
2024-05-25 00:59:50 [INFO]: Epoch 039 - training loss: 0.2739, validation loss: 0.1755
2024-05-25 00:59:51 [INFO]: Epoch 040 - training loss: 0.2729, validation loss: 0.1760
2024-05-25 00:59:51 [INFO]: Epoch 041 - training loss: 0.2729, validation loss: 0.1753
2024-05-25 00:59:51 [INFO]: Epoch 042 - training loss: 0.2724, validation loss: 0.1736
2024-05-25 00:59:52 [INFO]: Epoch 043 - training loss: 0.2707, validation loss: 0.1741
2024-05-25 00:59:52 [INFO]: Epoch 044 - training loss: 0.2700, validation loss: 0.1741
2024-05-25 00:59:52 [INFO]: Epoch 045 - training loss: 0.2679, validation loss: 0.1735
2024-05-25 00:59:52 [INFO]: Epoch 046 - training loss: 0.2682, validation loss: 0.1733
2024-05-25 00:59:53 [INFO]: Epoch 047 - training loss: 0.2677, validation loss: 0.1702
2024-05-25 00:59:53 [INFO]: Epoch 048 - training loss: 0.2661, validation loss: 0.1723
2024-05-25 00:59:53 [INFO]: Epoch 049 - training loss: 0.2728, validation loss: 0.1697
2024-05-25 00:59:54 [INFO]: Epoch 050 - training loss: 0.2669, validation loss: 0.1711
2024-05-25 00:59:54 [INFO]: Epoch 051 - training loss: 0.2628, validation loss: 0.1694
2024-05-25 00:59:54 [INFO]: Epoch 052 - training loss: 0.2639, validation loss: 0.1682
2024-05-25 00:59:55 [INFO]: Epoch 053 - training loss: 0.2606, validation loss: 0.1691
2024-05-25 00:59:55 [INFO]: Epoch 054 - training loss: 0.2617, validation loss: 0.1677
2024-05-25 00:59:55 [INFO]: Epoch 055 - training loss: 0.2583, validation loss: 0.1674
2024-05-25 00:59:56 [INFO]: Epoch 056 - training loss: 0.2577, validation loss: 0.1691
2024-05-25 00:59:56 [INFO]: Epoch 057 - training loss: 0.2593, validation loss: 0.1675
2024-05-25 00:59:56 [INFO]: Epoch 058 - training loss: 0.2630, validation loss: 0.1681
2024-05-25 00:59:57 [INFO]: Epoch 059 - training loss: 0.2586, validation loss: 0.1660
2024-05-25 00:59:57 [INFO]: Epoch 060 - training loss: 0.2568, validation loss: 0.1694
2024-05-25 00:59:57 [INFO]: Epoch 061 - training loss: 0.2561, validation loss: 0.1656
2024-05-25 00:59:57 [INFO]: Epoch 062 - training loss: 0.2551, validation loss: 0.1635
2024-05-25 00:59:58 [INFO]: Epoch 063 - training loss: 0.2529, validation loss: 0.1642
2024-05-25 00:59:58 [INFO]: Epoch 064 - training loss: 0.2510, validation loss: 0.1626
2024-05-25 00:59:58 [INFO]: Epoch 065 - training loss: 0.2509, validation loss: 0.1631
2024-05-25 00:59:59 [INFO]: Epoch 066 - training loss: 0.2498, validation loss: 0.1640
2024-05-25 00:59:59 [INFO]: Epoch 067 - training loss: 0.2503, validation loss: 0.1637
2024-05-25 00:59:59 [INFO]: Epoch 068 - training loss: 0.2506, validation loss: 0.1634
2024-05-25 01:00:00 [INFO]: Epoch 069 - training loss: 0.2489, validation loss: 0.1639
2024-05-25 01:00:00 [INFO]: Epoch 070 - training loss: 0.2467, validation loss: 0.1611
2024-05-25 01:00:00 [INFO]: Epoch 071 - training loss: 0.2459, validation loss: 0.1612
2024-05-25 01:00:01 [INFO]: Epoch 072 - training loss: 0.2464, validation loss: 0.1616
2024-05-25 01:00:01 [INFO]: Epoch 073 - training loss: 0.2472, validation loss: 0.1601
2024-05-25 01:00:01 [INFO]: Epoch 074 - training loss: 0.2452, validation loss: 0.1609
2024-05-25 01:00:02 [INFO]: Epoch 075 - training loss: 0.2445, validation loss: 0.1595
2024-05-25 01:00:02 [INFO]: Epoch 076 - training loss: 0.2447, validation loss: 0.1600
2024-05-25 01:00:02 [INFO]: Epoch 077 - training loss: 0.2440, validation loss: 0.1599
2024-05-25 01:00:03 [INFO]: Epoch 078 - training loss: 0.2431, validation loss: 0.1582
2024-05-25 01:00:03 [INFO]: Epoch 079 - training loss: 0.2429, validation loss: 0.1577
2024-05-25 01:00:03 [INFO]: Epoch 080 - training loss: 0.2414, validation loss: 0.1579
2024-05-25 01:00:03 [INFO]: Epoch 081 - training loss: 0.2416, validation loss: 0.1595
2024-05-25 01:00:04 [INFO]: Epoch 082 - training loss: 0.2410, validation loss: 0.1592
2024-05-25 01:00:04 [INFO]: Epoch 083 - training loss: 0.2420, validation loss: 0.1553
2024-05-25 01:00:04 [INFO]: Epoch 084 - training loss: 0.2382, validation loss: 0.1549
2024-05-25 01:00:05 [INFO]: Epoch 085 - training loss: 0.2384, validation loss: 0.1606
2024-05-25 01:00:05 [INFO]: Epoch 086 - training loss: 0.2392, validation loss: 0.1561
2024-05-25 01:00:05 [INFO]: Epoch 087 - training loss: 0.2369, validation loss: 0.1571
2024-05-25 01:00:06 [INFO]: Epoch 088 - training loss: 0.2381, validation loss: 0.1559
2024-05-25 01:00:06 [INFO]: Epoch 089 - training loss: 0.2363, validation loss: 0.1545
2024-05-25 01:00:06 [INFO]: Epoch 090 - training loss: 0.2356, validation loss: 0.1548
2024-05-25 01:00:07 [INFO]: Epoch 091 - training loss: 0.2358, validation loss: 0.1565
2024-05-25 01:00:07 [INFO]: Epoch 092 - training loss: 0.2371, validation loss: 0.1542
2024-05-25 01:00:07 [INFO]: Epoch 093 - training loss: 0.2335, validation loss: 0.1539
2024-05-25 01:00:07 [INFO]: Epoch 094 - training loss: 0.2351, validation loss: 0.1535
2024-05-25 01:00:08 [INFO]: Epoch 095 - training loss: 0.2331, validation loss: 0.1560
2024-05-25 01:00:08 [INFO]: Epoch 096 - training loss: 0.2303, validation loss: 0.1541
2024-05-25 01:00:08 [INFO]: Epoch 097 - training loss: 0.2349, validation loss: 0.1516
2024-05-25 01:00:09 [INFO]: Epoch 098 - training loss: 0.2314, validation loss: 0.1522
2024-05-25 01:00:09 [INFO]: Epoch 099 - training loss: 0.2293, validation loss: 0.1518
2024-05-25 01:00:09 [INFO]: Epoch 100 - training loss: 0.2298, validation loss: 0.1529
2024-05-25 01:00:10 [INFO]: Epoch 101 - training loss: 0.2338, validation loss: 0.1536
2024-05-25 01:00:10 [INFO]: Epoch 102 - training loss: 0.2362, validation loss: 0.1547
2024-05-25 01:00:10 [INFO]: Epoch 103 - training loss: 0.2340, validation loss: 0.1530
2024-05-25 01:00:11 [INFO]: Epoch 104 - training loss: 0.2317, validation loss: 0.1539
2024-05-25 01:00:11 [INFO]: Epoch 105 - training loss: 0.2328, validation loss: 0.1516
2024-05-25 01:00:11 [INFO]: Epoch 106 - training loss: 0.2283, validation loss: 0.1508
2024-05-25 01:00:11 [INFO]: Epoch 107 - training loss: 0.2268, validation loss: 0.1505
2024-05-25 01:00:12 [INFO]: Epoch 108 - training loss: 0.2268, validation loss: 0.1504
2024-05-25 01:00:12 [INFO]: Epoch 109 - training loss: 0.2259, validation loss: 0.1495
2024-05-25 01:00:12 [INFO]: Epoch 110 - training loss: 0.2252, validation loss: 0.1512
2024-05-25 01:00:13 [INFO]: Epoch 111 - training loss: 0.2277, validation loss: 0.1492
2024-05-25 01:00:13 [INFO]: Epoch 112 - training loss: 0.2270, validation loss: 0.1526
2024-05-25 01:00:13 [INFO]: Epoch 113 - training loss: 0.2236, validation loss: 0.1500
2024-05-25 01:00:14 [INFO]: Epoch 114 - training loss: 0.2231, validation loss: 0.1502
2024-05-25 01:00:14 [INFO]: Epoch 115 - training loss: 0.2225, validation loss: 0.1494
2024-05-25 01:00:14 [INFO]: Epoch 116 - training loss: 0.2229, validation loss: 0.1496
2024-05-25 01:00:15 [INFO]: Epoch 117 - training loss: 0.2212, validation loss: 0.1487
2024-05-25 01:00:15 [INFO]: Epoch 118 - training loss: 0.2220, validation loss: 0.1482
2024-05-25 01:00:15 [INFO]: Epoch 119 - training loss: 0.2219, validation loss: 0.1461
2024-05-25 01:00:16 [INFO]: Epoch 120 - training loss: 0.2195, validation loss: 0.1478
2024-05-25 01:00:16 [INFO]: Epoch 121 - training loss: 0.2208, validation loss: 0.1477
2024-05-25 01:00:16 [INFO]: Epoch 122 - training loss: 0.2211, validation loss: 0.1470
2024-05-25 01:00:16 [INFO]: Epoch 123 - training loss: 0.2194, validation loss: 0.1456
2024-05-25 01:00:17 [INFO]: Epoch 124 - training loss: 0.2180, validation loss: 0.1484
2024-05-25 01:00:17 [INFO]: Epoch 125 - training loss: 0.2193, validation loss: 0.1449
2024-05-25 01:00:17 [INFO]: Epoch 126 - training loss: 0.2190, validation loss: 0.1451
2024-05-25 01:00:18 [INFO]: Epoch 127 - training loss: 0.2168, validation loss: 0.1467
2024-05-25 01:00:18 [INFO]: Epoch 128 - training loss: 0.2163, validation loss: 0.1452
2024-05-25 01:00:18 [INFO]: Epoch 129 - training loss: 0.2166, validation loss: 0.1448
2024-05-25 01:00:19 [INFO]: Epoch 130 - training loss: 0.2193, validation loss: 0.1448
2024-05-25 01:00:19 [INFO]: Epoch 131 - training loss: 0.2173, validation loss: 0.1461
2024-05-25 01:00:19 [INFO]: Epoch 132 - training loss: 0.2168, validation loss: 0.1461
2024-05-25 01:00:20 [INFO]: Epoch 133 - training loss: 0.2179, validation loss: 0.1428
2024-05-25 01:00:20 [INFO]: Epoch 134 - training loss: 0.2169, validation loss: 0.1448
2024-05-25 01:00:20 [INFO]: Epoch 135 - training loss: 0.2140, validation loss: 0.1453
2024-05-25 01:00:21 [INFO]: Epoch 136 - training loss: 0.2152, validation loss: 0.1430
2024-05-25 01:00:21 [INFO]: Epoch 137 - training loss: 0.2147, validation loss: 0.1454
2024-05-25 01:00:21 [INFO]: Epoch 138 - training loss: 0.2130, validation loss: 0.1448
2024-05-25 01:00:22 [INFO]: Epoch 139 - training loss: 0.2132, validation loss: 0.1446
2024-05-25 01:00:22 [INFO]: Epoch 140 - training loss: 0.2126, validation loss: 0.1431
2024-05-25 01:00:22 [INFO]: Epoch 141 - training loss: 0.2130, validation loss: 0.1427
2024-05-25 01:00:22 [INFO]: Epoch 142 - training loss: 0.2145, validation loss: 0.1429
2024-05-25 01:00:23 [INFO]: Epoch 143 - training loss: 0.2139, validation loss: 0.1439
2024-05-25 01:00:23 [INFO]: Epoch 144 - training loss: 0.2150, validation loss: 0.1430
2024-05-25 01:00:23 [INFO]: Epoch 145 - training loss: 0.2151, validation loss: 0.1426
2024-05-25 01:00:24 [INFO]: Epoch 146 - training loss: 0.2127, validation loss: 0.1425
2024-05-25 01:00:24 [INFO]: Epoch 147 - training loss: 0.2097, validation loss: 0.1424
2024-05-25 01:00:24 [INFO]: Epoch 148 - training loss: 0.2120, validation loss: 0.1436
2024-05-25 01:00:25 [INFO]: Epoch 149 - training loss: 0.2111, validation loss: 0.1432
2024-05-25 01:00:25 [INFO]: Epoch 150 - training loss: 0.2125, validation loss: 0.1413
2024-05-25 01:00:25 [INFO]: Epoch 151 - training loss: 0.2122, validation loss: 0.1409
2024-05-25 01:00:26 [INFO]: Epoch 152 - training loss: 0.2098, validation loss: 0.1407
2024-05-25 01:00:26 [INFO]: Epoch 153 - training loss: 0.2086, validation loss: 0.1414
2024-05-25 01:00:26 [INFO]: Epoch 154 - training loss: 0.2101, validation loss: 0.1400
2024-05-25 01:00:26 [INFO]: Epoch 155 - training loss: 0.2090, validation loss: 0.1432
2024-05-25 01:00:27 [INFO]: Epoch 156 - training loss: 0.2133, validation loss: 0.1424
2024-05-25 01:00:27 [INFO]: Epoch 157 - training loss: 0.2098, validation loss: 0.1398
2024-05-25 01:00:27 [INFO]: Epoch 158 - training loss: 0.2068, validation loss: 0.1405
2024-05-25 01:00:28 [INFO]: Epoch 159 - training loss: 0.2070, validation loss: 0.1401
2024-05-25 01:00:28 [INFO]: Epoch 160 - training loss: 0.2086, validation loss: 0.1401
2024-05-25 01:00:28 [INFO]: Epoch 161 - training loss: 0.2057, validation loss: 0.1400
2024-05-25 01:00:29 [INFO]: Epoch 162 - training loss: 0.2057, validation loss: 0.1401
2024-05-25 01:00:29 [INFO]: Epoch 163 - training loss: 0.2069, validation loss: 0.1391
2024-05-25 01:00:29 [INFO]: Epoch 164 - training loss: 0.2072, validation loss: 0.1397
2024-05-25 01:00:30 [INFO]: Epoch 165 - training loss: 0.2079, validation loss: 0.1389
2024-05-25 01:00:30 [INFO]: Epoch 166 - training loss: 0.2098, validation loss: 0.1395
2024-05-25 01:00:30 [INFO]: Epoch 167 - training loss: 0.2071, validation loss: 0.1406
2024-05-25 01:00:30 [INFO]: Epoch 168 - training loss: 0.2095, validation loss: 0.1402
2024-05-25 01:00:31 [INFO]: Epoch 169 - training loss: 0.2079, validation loss: 0.1395
2024-05-25 01:00:31 [INFO]: Epoch 170 - training loss: 0.2041, validation loss: 0.1376
2024-05-25 01:00:31 [INFO]: Epoch 171 - training loss: 0.2040, validation loss: 0.1385
2024-05-25 01:00:32 [INFO]: Epoch 172 - training loss: 0.2046, validation loss: 0.1375
2024-05-25 01:00:32 [INFO]: Epoch 173 - training loss: 0.2039, validation loss: 0.1382
2024-05-25 01:00:32 [INFO]: Epoch 174 - training loss: 0.2046, validation loss: 0.1370
2024-05-25 01:00:33 [INFO]: Epoch 175 - training loss: 0.2029, validation loss: 0.1376
2024-05-25 01:00:33 [INFO]: Epoch 176 - training loss: 0.2023, validation loss: 0.1373
2024-05-25 01:00:33 [INFO]: Epoch 177 - training loss: 0.2036, validation loss: 0.1379
2024-05-25 01:00:34 [INFO]: Epoch 178 - training loss: 0.2019, validation loss: 0.1357
2024-05-25 01:00:34 [INFO]: Epoch 179 - training loss: 0.2009, validation loss: 0.1367
2024-05-25 01:00:34 [INFO]: Epoch 180 - training loss: 0.2015, validation loss: 0.1357
2024-05-25 01:00:35 [INFO]: Epoch 181 - training loss: 0.2031, validation loss: 0.1375
2024-05-25 01:00:35 [INFO]: Epoch 182 - training loss: 0.2019, validation loss: 0.1365
2024-05-25 01:00:35 [INFO]: Epoch 183 - training loss: 0.2015, validation loss: 0.1365
2024-05-25 01:00:35 [INFO]: Epoch 184 - training loss: 0.2019, validation loss: 0.1357
2024-05-25 01:00:36 [INFO]: Epoch 185 - training loss: 0.1998, validation loss: 0.1368
2024-05-25 01:00:36 [INFO]: Epoch 186 - training loss: 0.2002, validation loss: 0.1378
2024-05-25 01:00:36 [INFO]: Epoch 187 - training loss: 0.2011, validation loss: 0.1364
2024-05-25 01:00:37 [INFO]: Epoch 188 - training loss: 0.1998, validation loss: 0.1382
2024-05-25 01:00:37 [INFO]: Epoch 189 - training loss: 0.2005, validation loss: 0.1363
2024-05-25 01:00:37 [INFO]: Epoch 190 - training loss: 0.1994, validation loss: 0.1355
2024-05-25 01:00:38 [INFO]: Epoch 191 - training loss: 0.2008, validation loss: 0.1363
2024-05-25 01:00:38 [INFO]: Epoch 192 - training loss: 0.1986, validation loss: 0.1362
2024-05-25 01:00:38 [INFO]: Epoch 193 - training loss: 0.2007, validation loss: 0.1357
2024-05-25 01:00:39 [INFO]: Epoch 194 - training loss: 0.2017, validation loss: 0.1364
2024-05-25 01:00:39 [INFO]: Epoch 195 - training loss: 0.1977, validation loss: 0.1357
2024-05-25 01:00:39 [INFO]: Epoch 196 - training loss: 0.1968, validation loss: 0.1346
2024-05-25 01:00:39 [INFO]: Epoch 197 - training loss: 0.1979, validation loss: 0.1353
2024-05-25 01:00:40 [INFO]: Epoch 198 - training loss: 0.1964, validation loss: 0.1346
2024-05-25 01:00:40 [INFO]: Epoch 199 - training loss: 0.1983, validation loss: 0.1355
2024-05-25 01:00:40 [INFO]: Epoch 200 - training loss: 0.2007, validation loss: 0.1345
2024-05-25 01:00:41 [INFO]: Epoch 201 - training loss: 0.2008, validation loss: 0.1339
2024-05-25 01:00:41 [INFO]: Epoch 202 - training loss: 0.1987, validation loss: 0.1342
2024-05-25 01:00:41 [INFO]: Epoch 203 - training loss: 0.1985, validation loss: 0.1342
2024-05-25 01:00:42 [INFO]: Epoch 204 - training loss: 0.1984, validation loss: 0.1339
2024-05-25 01:00:42 [INFO]: Epoch 205 - training loss: 0.1957, validation loss: 0.1328
2024-05-25 01:00:42 [INFO]: Epoch 206 - training loss: 0.1954, validation loss: 0.1354
2024-05-25 01:00:43 [INFO]: Epoch 207 - training loss: 0.1947, validation loss: 0.1343
2024-05-25 01:00:43 [INFO]: Epoch 208 - training loss: 0.1960, validation loss: 0.1333
2024-05-25 01:00:43 [INFO]: Epoch 209 - training loss: 0.1967, validation loss: 0.1336
2024-05-25 01:00:43 [INFO]: Epoch 210 - training loss: 0.1931, validation loss: 0.1346
2024-05-25 01:00:44 [INFO]: Epoch 211 - training loss: 0.1935, validation loss: 0.1340
2024-05-25 01:00:44 [INFO]: Epoch 212 - training loss: 0.1931, validation loss: 0.1327
2024-05-25 01:00:44 [INFO]: Epoch 213 - training loss: 0.1940, validation loss: 0.1337
2024-05-25 01:00:45 [INFO]: Epoch 214 - training loss: 0.1937, validation loss: 0.1333
2024-05-25 01:00:45 [INFO]: Epoch 215 - training loss: 0.1951, validation loss: 0.1334
2024-05-25 01:00:45 [INFO]: Epoch 216 - training loss: 0.1970, validation loss: 0.1319
2024-05-25 01:00:46 [INFO]: Epoch 217 - training loss: 0.1936, validation loss: 0.1337
2024-05-25 01:00:46 [INFO]: Epoch 218 - training loss: 0.1926, validation loss: 0.1330
2024-05-25 01:00:46 [INFO]: Epoch 219 - training loss: 0.1930, validation loss: 0.1325
2024-05-25 01:00:47 [INFO]: Epoch 220 - training loss: 0.1957, validation loss: 0.1321
2024-05-25 01:00:47 [INFO]: Epoch 221 - training loss: 0.1929, validation loss: 0.1328
2024-05-25 01:00:47 [INFO]: Epoch 222 - training loss: 0.1929, validation loss: 0.1316
2024-05-25 01:00:47 [INFO]: Epoch 223 - training loss: 0.1924, validation loss: 0.1329
2024-05-25 01:00:48 [INFO]: Epoch 224 - training loss: 0.1930, validation loss: 0.1316
2024-05-25 01:00:48 [INFO]: Epoch 225 - training loss: 0.1957, validation loss: 0.1325
2024-05-25 01:00:48 [INFO]: Epoch 226 - training loss: 0.1923, validation loss: 0.1329
2024-05-25 01:00:49 [INFO]: Epoch 227 - training loss: 0.1914, validation loss: 0.1311
2024-05-25 01:00:49 [INFO]: Epoch 228 - training loss: 0.1909, validation loss: 0.1324
2024-05-25 01:00:49 [INFO]: Epoch 229 - training loss: 0.1914, validation loss: 0.1318
2024-05-25 01:00:50 [INFO]: Epoch 230 - training loss: 0.1921, validation loss: 0.1320
2024-05-25 01:00:50 [INFO]: Epoch 231 - training loss: 0.1914, validation loss: 0.1322
2024-05-25 01:00:50 [INFO]: Epoch 232 - training loss: 0.1902, validation loss: 0.1311
2024-05-25 01:00:51 [INFO]: Epoch 233 - training loss: 0.1888, validation loss: 0.1321
2024-05-25 01:00:51 [INFO]: Epoch 234 - training loss: 0.1896, validation loss: 0.1314
2024-05-25 01:00:51 [INFO]: Epoch 235 - training loss: 0.1916, validation loss: 0.1311
2024-05-25 01:00:52 [INFO]: Epoch 236 - training loss: 0.1912, validation loss: 0.1296
2024-05-25 01:00:52 [INFO]: Epoch 237 - training loss: 0.1890, validation loss: 0.1305
2024-05-25 01:00:52 [INFO]: Epoch 238 - training loss: 0.1901, validation loss: 0.1317
2024-05-25 01:00:52 [INFO]: Epoch 239 - training loss: 0.1889, validation loss: 0.1296
2024-05-25 01:00:53 [INFO]: Epoch 240 - training loss: 0.1922, validation loss: 0.1350
2024-05-25 01:00:53 [INFO]: Epoch 241 - training loss: 0.1884, validation loss: 0.1305
2024-05-25 01:00:53 [INFO]: Epoch 242 - training loss: 0.1875, validation loss: 0.1317
2024-05-25 01:00:54 [INFO]: Epoch 243 - training loss: 0.1897, validation loss: 0.1318
2024-05-25 01:00:54 [INFO]: Epoch 244 - training loss: 0.1901, validation loss: 0.1308
2024-05-25 01:00:54 [INFO]: Epoch 245 - training loss: 0.1883, validation loss: 0.1295
2024-05-25 01:00:55 [INFO]: Epoch 246 - training loss: 0.1872, validation loss: 0.1314
2024-05-25 01:00:55 [INFO]: Epoch 247 - training loss: 0.1870, validation loss: 0.1290
2024-05-25 01:00:55 [INFO]: Epoch 248 - training loss: 0.1860, validation loss: 0.1303
2024-05-25 01:00:56 [INFO]: Epoch 249 - training loss: 0.1851, validation loss: 0.1311
2024-05-25 01:00:56 [INFO]: Epoch 250 - training loss: 0.1868, validation loss: 0.1294
2024-05-25 01:00:56 [INFO]: Epoch 251 - training loss: 0.1868, validation loss: 0.1294
2024-05-25 01:00:56 [INFO]: Epoch 252 - training loss: 0.1856, validation loss: 0.1302
2024-05-25 01:00:57 [INFO]: Epoch 253 - training loss: 0.1852, validation loss: 0.1309
2024-05-25 01:00:57 [INFO]: Epoch 254 - training loss: 0.1834, validation loss: 0.1296
2024-05-25 01:00:57 [INFO]: Epoch 255 - training loss: 0.1840, validation loss: 0.1297
2024-05-25 01:00:58 [INFO]: Epoch 256 - training loss: 0.1847, validation loss: 0.1290
2024-05-25 01:00:58 [INFO]: Epoch 257 - training loss: 0.1867, validation loss: 0.1284
2024-05-25 01:00:58 [INFO]: Epoch 258 - training loss: 0.1858, validation loss: 0.1299
2024-05-25 01:00:59 [INFO]: Epoch 259 - training loss: 0.1876, validation loss: 0.1298
2024-05-25 01:00:59 [INFO]: Epoch 260 - training loss: 0.1857, validation loss: 0.1299
2024-05-25 01:00:59 [INFO]: Epoch 261 - training loss: 0.1836, validation loss: 0.1295
2024-05-25 01:01:00 [INFO]: Epoch 262 - training loss: 0.1827, validation loss: 0.1296
2024-05-25 01:01:00 [INFO]: Epoch 263 - training loss: 0.1844, validation loss: 0.1301
2024-05-25 01:01:00 [INFO]: Epoch 264 - training loss: 0.1883, validation loss: 0.1291
2024-05-25 01:01:00 [INFO]: Epoch 265 - training loss: 0.1867, validation loss: 0.1297
2024-05-25 01:01:01 [INFO]: Epoch 266 - training loss: 0.1851, validation loss: 0.1284
2024-05-25 01:01:01 [INFO]: Epoch 267 - training loss: 0.1848, validation loss: 0.1279
2024-05-25 01:01:01 [INFO]: Epoch 268 - training loss: 0.1842, validation loss: 0.1280
2024-05-25 01:01:02 [INFO]: Epoch 269 - training loss: 0.1827, validation loss: 0.1274
2024-05-25 01:01:02 [INFO]: Epoch 270 - training loss: 0.1846, validation loss: 0.1275
2024-05-25 01:01:02 [INFO]: Epoch 271 - training loss: 0.1837, validation loss: 0.1280
2024-05-25 01:01:03 [INFO]: Epoch 272 - training loss: 0.1839, validation loss: 0.1291
2024-05-25 01:01:03 [INFO]: Epoch 273 - training loss: 0.1833, validation loss: 0.1295
2024-05-25 01:01:03 [INFO]: Epoch 274 - training loss: 0.1823, validation loss: 0.1267
2024-05-25 01:01:04 [INFO]: Epoch 275 - training loss: 0.1829, validation loss: 0.1273
2024-05-25 01:01:04 [INFO]: Epoch 276 - training loss: 0.1833, validation loss: 0.1280
2024-05-25 01:01:04 [INFO]: Epoch 277 - training loss: 0.1826, validation loss: 0.1271
2024-05-25 01:01:05 [INFO]: Epoch 278 - training loss: 0.1814, validation loss: 0.1276
2024-05-25 01:01:05 [INFO]: Epoch 279 - training loss: 0.1855, validation loss: 0.1277
2024-05-25 01:01:05 [INFO]: Epoch 280 - training loss: 0.1859, validation loss: 0.1281
2024-05-25 01:01:05 [INFO]: Epoch 281 - training loss: 0.1826, validation loss: 0.1264
2024-05-25 01:01:06 [INFO]: Epoch 282 - training loss: 0.1811, validation loss: 0.1278
2024-05-25 01:01:06 [INFO]: Epoch 283 - training loss: 0.1783, validation loss: 0.1275
2024-05-25 01:01:06 [INFO]: Epoch 284 - training loss: 0.1800, validation loss: 0.1276
2024-05-25 01:01:07 [INFO]: Epoch 285 - training loss: 0.1795, validation loss: 0.1264
2024-05-25 01:01:07 [INFO]: Epoch 286 - training loss: 0.1800, validation loss: 0.1268
2024-05-25 01:01:07 [INFO]: Epoch 287 - training loss: 0.1785, validation loss: 0.1264
2024-05-25 01:01:08 [INFO]: Epoch 288 - training loss: 0.1783, validation loss: 0.1273
2024-05-25 01:01:08 [INFO]: Epoch 289 - training loss: 0.1785, validation loss: 0.1279
2024-05-25 01:01:08 [INFO]: Epoch 290 - training loss: 0.1781, validation loss: 0.1269
2024-05-25 01:01:09 [INFO]: Epoch 291 - training loss: 0.1781, validation loss: 0.1271
2024-05-25 01:01:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:01:09 [INFO]: Finished training. The best model is from epoch#281.
2024-05-25 01:01:09 [INFO]: Saved the model to augmentation_saved_results/round_0/Transformer_air_quality/20240525_T005938/Transformer.pypots
2024-05-25 01:01:09 [INFO]: Transformer on Air-Quality: MAE=0.1616, MSE=0.1915
2024-05-25 01:01:09 [INFO]: Successfully saved to augmentation_saved_results/round_0/Transformer_air_quality/imputation.pkl
2024-05-25 01:01:09 [INFO]: Using the given device: cuda:0
2024-05-25 01:01:09 [INFO]: Model files will be saved to augmentation_saved_results/round_0/TimesNet_air_quality/20240525_T010109
2024-05-25 01:01:09 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/TimesNet_air_quality/20240525_T010109/tensorboard
2024-05-25 01:01:09 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 01:01:10 [INFO]: Epoch 001 - training loss: 0.2919, validation loss: 0.2843
2024-05-25 01:01:10 [INFO]: Epoch 002 - training loss: 0.2231, validation loss: 0.2316
2024-05-25 01:01:11 [INFO]: Epoch 003 - training loss: 0.1950, validation loss: 0.2176
2024-05-25 01:01:11 [INFO]: Epoch 004 - training loss: 0.1764, validation loss: 0.2077
2024-05-25 01:01:12 [INFO]: Epoch 005 - training loss: 0.1632, validation loss: 0.1949
2024-05-25 01:01:13 [INFO]: Epoch 006 - training loss: 0.1662, validation loss: 0.1939
2024-05-25 01:01:13 [INFO]: Epoch 007 - training loss: 0.1642, validation loss: 0.1865
2024-05-25 01:01:14 [INFO]: Epoch 008 - training loss: 0.1468, validation loss: 0.1856
2024-05-25 01:01:14 [INFO]: Epoch 009 - training loss: 0.1544, validation loss: 0.1774
2024-05-25 01:01:15 [INFO]: Epoch 010 - training loss: 0.1552, validation loss: 0.1742
2024-05-25 01:01:15 [INFO]: Epoch 011 - training loss: 0.1595, validation loss: 0.1707
2024-05-25 01:01:16 [INFO]: Epoch 012 - training loss: 0.1424, validation loss: 0.1730
2024-05-25 01:01:16 [INFO]: Epoch 013 - training loss: 0.1424, validation loss: 0.1719
2024-05-25 01:01:17 [INFO]: Epoch 014 - training loss: 0.1468, validation loss: 0.1728
2024-05-25 01:01:17 [INFO]: Epoch 015 - training loss: 0.1251, validation loss: 0.1687
2024-05-25 01:01:18 [INFO]: Epoch 016 - training loss: 0.1273, validation loss: 0.1704
2024-05-25 01:01:18 [INFO]: Epoch 017 - training loss: 0.1515, validation loss: 0.1681
2024-05-25 01:01:19 [INFO]: Epoch 018 - training loss: 0.1341, validation loss: 0.1701
2024-05-25 01:01:19 [INFO]: Epoch 019 - training loss: 0.1325, validation loss: 0.1669
2024-05-25 01:01:20 [INFO]: Epoch 020 - training loss: 0.1153, validation loss: 0.1622
2024-05-25 01:01:20 [INFO]: Epoch 021 - training loss: 0.1329, validation loss: 0.1633
2024-05-25 01:01:21 [INFO]: Epoch 022 - training loss: 0.1325, validation loss: 0.1630
2024-05-25 01:01:21 [INFO]: Epoch 023 - training loss: 0.1287, validation loss: 0.1641
2024-05-25 01:01:22 [INFO]: Epoch 024 - training loss: 0.1304, validation loss: 0.1603
2024-05-25 01:01:22 [INFO]: Epoch 025 - training loss: 0.1333, validation loss: 0.1585
2024-05-25 01:01:23 [INFO]: Epoch 026 - training loss: 0.1340, validation loss: 0.1587
2024-05-25 01:01:23 [INFO]: Epoch 027 - training loss: 0.1167, validation loss: 0.1601
2024-05-25 01:01:24 [INFO]: Epoch 028 - training loss: 0.1135, validation loss: 0.1568
2024-05-25 01:01:25 [INFO]: Epoch 029 - training loss: 0.1093, validation loss: 0.1585
2024-05-25 01:01:25 [INFO]: Epoch 030 - training loss: 0.1303, validation loss: 0.1574
2024-05-25 01:01:26 [INFO]: Epoch 031 - training loss: 0.1151, validation loss: 0.1613
2024-05-25 01:01:26 [INFO]: Epoch 032 - training loss: 0.1206, validation loss: 0.1604
2024-05-25 01:01:27 [INFO]: Epoch 033 - training loss: 0.1275, validation loss: 0.1615
2024-05-25 01:01:27 [INFO]: Epoch 034 - training loss: 0.1286, validation loss: 0.1565
2024-05-25 01:01:28 [INFO]: Epoch 035 - training loss: 0.1166, validation loss: 0.1561
2024-05-25 01:01:28 [INFO]: Epoch 036 - training loss: 0.1175, validation loss: 0.1519
2024-05-25 01:01:29 [INFO]: Epoch 037 - training loss: 0.1195, validation loss: 0.1520
2024-05-25 01:01:29 [INFO]: Epoch 038 - training loss: 0.1097, validation loss: 0.1554
2024-05-25 01:01:30 [INFO]: Epoch 039 - training loss: 0.1233, validation loss: 0.1520
2024-05-25 01:01:30 [INFO]: Epoch 040 - training loss: 0.1442, validation loss: 0.1585
2024-05-25 01:01:31 [INFO]: Epoch 041 - training loss: 0.1107, validation loss: 0.1570
2024-05-25 01:01:31 [INFO]: Epoch 042 - training loss: 0.1130, validation loss: 0.1584
2024-05-25 01:01:32 [INFO]: Epoch 043 - training loss: 0.1109, validation loss: 0.1520
2024-05-25 01:01:32 [INFO]: Epoch 044 - training loss: 0.0968, validation loss: 0.1540
2024-05-25 01:01:33 [INFO]: Epoch 045 - training loss: 0.1205, validation loss: 0.1512
2024-05-25 01:01:33 [INFO]: Epoch 046 - training loss: 0.1065, validation loss: 0.1548
2024-05-25 01:01:34 [INFO]: Epoch 047 - training loss: 0.1022, validation loss: 0.1614
2024-05-25 01:01:34 [INFO]: Epoch 048 - training loss: 0.1109, validation loss: 0.1533
2024-05-25 01:01:35 [INFO]: Epoch 049 - training loss: 0.0988, validation loss: 0.1519
2024-05-25 01:01:35 [INFO]: Epoch 050 - training loss: 0.0886, validation loss: 0.1507
2024-05-25 01:01:36 [INFO]: Epoch 051 - training loss: 0.0980, validation loss: 0.1495
2024-05-25 01:01:36 [INFO]: Epoch 052 - training loss: 0.1045, validation loss: 0.1506
2024-05-25 01:01:37 [INFO]: Epoch 053 - training loss: 0.0959, validation loss: 0.1590
2024-05-25 01:01:38 [INFO]: Epoch 054 - training loss: 0.1040, validation loss: 0.1533
2024-05-25 01:01:38 [INFO]: Epoch 055 - training loss: 0.0977, validation loss: 0.1532
2024-05-25 01:01:39 [INFO]: Epoch 056 - training loss: 0.1004, validation loss: 0.1539
2024-05-25 01:01:39 [INFO]: Epoch 057 - training loss: 0.0993, validation loss: 0.1572
2024-05-25 01:01:40 [INFO]: Epoch 058 - training loss: 0.0957, validation loss: 0.1525
2024-05-25 01:01:40 [INFO]: Epoch 059 - training loss: 0.1013, validation loss: 0.1479
2024-05-25 01:01:41 [INFO]: Epoch 060 - training loss: 0.1052, validation loss: 0.1514
2024-05-25 01:01:41 [INFO]: Epoch 061 - training loss: 0.1065, validation loss: 0.1477
2024-05-25 01:01:42 [INFO]: Epoch 062 - training loss: 0.1122, validation loss: 0.1464
2024-05-25 01:01:42 [INFO]: Epoch 063 - training loss: 0.1037, validation loss: 0.1465
2024-05-25 01:01:43 [INFO]: Epoch 064 - training loss: 0.1126, validation loss: 0.1511
2024-05-25 01:01:43 [INFO]: Epoch 065 - training loss: 0.0982, validation loss: 0.1600
2024-05-25 01:01:44 [INFO]: Epoch 066 - training loss: 0.1036, validation loss: 0.1607
2024-05-25 01:01:44 [INFO]: Epoch 067 - training loss: 0.0897, validation loss: 0.1503
2024-05-25 01:01:45 [INFO]: Epoch 068 - training loss: 0.0877, validation loss: 0.1511
2024-05-25 01:01:45 [INFO]: Epoch 069 - training loss: 0.0942, validation loss: 0.1571
2024-05-25 01:01:46 [INFO]: Epoch 070 - training loss: 0.0941, validation loss: 0.1550
2024-05-25 01:01:46 [INFO]: Epoch 071 - training loss: 0.0939, validation loss: 0.1541
2024-05-25 01:01:47 [INFO]: Epoch 072 - training loss: 0.0863, validation loss: 0.1625
2024-05-25 01:01:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:01:47 [INFO]: Finished training. The best model is from epoch#62.
2024-05-25 01:01:47 [INFO]: Saved the model to augmentation_saved_results/round_0/TimesNet_air_quality/20240525_T010109/TimesNet.pypots
2024-05-25 01:01:47 [INFO]: TimesNet on Air-Quality: MAE=0.1620, MSE=0.2395
2024-05-25 01:01:47 [INFO]: Successfully saved to augmentation_saved_results/round_0/TimesNet_air_quality/imputation.pkl
2024-05-25 01:01:47 [INFO]: Using the given device: cuda:0
2024-05-25 01:01:47 [INFO]: Model files will be saved to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147
2024-05-25 01:01:47 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/tensorboard
2024-05-25 01:01:47 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 01:02:04 [INFO]: Epoch 001 - training loss: 0.4732, validation loss: 0.3438
2024-05-25 01:02:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch1_loss0.3437965512275696.pypots
2024-05-25 01:02:21 [INFO]: Epoch 002 - training loss: 0.2839, validation loss: 0.2731
2024-05-25 01:02:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch2_loss0.2730853259563446.pypots
2024-05-25 01:02:38 [INFO]: Epoch 003 - training loss: 0.2801, validation loss: 0.2483
2024-05-25 01:02:38 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch3_loss0.24834464639425277.pypots
2024-05-25 01:02:54 [INFO]: Epoch 004 - training loss: 0.2463, validation loss: 0.2276
2024-05-25 01:02:54 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch4_loss0.22761240750551223.pypots
2024-05-25 01:03:11 [INFO]: Epoch 005 - training loss: 0.2041, validation loss: 0.2057
2024-05-25 01:03:11 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch5_loss0.2056923508644104.pypots
2024-05-25 01:03:28 [INFO]: Epoch 006 - training loss: 0.2206, validation loss: 0.1891
2024-05-25 01:03:28 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch6_loss0.18907804936170577.pypots
2024-05-25 01:03:45 [INFO]: Epoch 007 - training loss: 0.2103, validation loss: 0.1844
2024-05-25 01:03:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch7_loss0.18435705900192262.pypots
2024-05-25 01:04:02 [INFO]: Epoch 008 - training loss: 0.1864, validation loss: 0.1687
2024-05-25 01:04:02 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch8_loss0.168746779859066.pypots
2024-05-25 01:04:18 [INFO]: Epoch 009 - training loss: 0.1950, validation loss: 0.1598
2024-05-25 01:04:18 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch9_loss0.1597720667719841.pypots
2024-05-25 01:04:35 [INFO]: Epoch 010 - training loss: 0.1772, validation loss: 0.1614
2024-05-25 01:04:35 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch10_loss0.16139031797647477.pypots
2024-05-25 01:04:52 [INFO]: Epoch 011 - training loss: 0.1895, validation loss: 0.1585
2024-05-25 01:04:52 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch11_loss0.15850189626216887.pypots
2024-05-25 01:05:09 [INFO]: Epoch 012 - training loss: 0.1631, validation loss: 0.1506
2024-05-25 01:05:09 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch12_loss0.15058652609586715.pypots
2024-05-25 01:05:26 [INFO]: Epoch 013 - training loss: 0.1765, validation loss: 0.1521
2024-05-25 01:05:26 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch13_loss0.152077117562294.pypots
2024-05-25 01:05:42 [INFO]: Epoch 014 - training loss: 0.1727, validation loss: 0.1523
2024-05-25 01:05:42 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch14_loss0.15232685804367066.pypots
2024-05-25 01:05:59 [INFO]: Epoch 015 - training loss: 0.1731, validation loss: 0.1445
2024-05-25 01:05:59 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch15_loss0.1445154592394829.pypots
2024-05-25 01:06:16 [INFO]: Epoch 016 - training loss: 0.1620, validation loss: 0.1434
2024-05-25 01:06:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch16_loss0.1433906339108944.pypots
2024-05-25 01:06:33 [INFO]: Epoch 017 - training loss: 0.1608, validation loss: 0.1443
2024-05-25 01:06:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch17_loss0.14431368708610534.pypots
2024-05-25 01:06:50 [INFO]: Epoch 018 - training loss: 0.1563, validation loss: 0.1438
2024-05-25 01:06:50 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch18_loss0.14383276253938676.pypots
2024-05-25 01:07:06 [INFO]: Epoch 019 - training loss: 0.1704, validation loss: 0.1408
2024-05-25 01:07:06 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch19_loss0.14081742092967034.pypots
2024-05-25 01:07:23 [INFO]: Epoch 020 - training loss: 0.1509, validation loss: 0.1386
2024-05-25 01:07:23 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch20_loss0.13857793807983398.pypots
2024-05-25 01:07:40 [INFO]: Epoch 021 - training loss: 0.1378, validation loss: 0.1403
2024-05-25 01:07:40 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch21_loss0.14028594195842742.pypots
2024-05-25 01:07:57 [INFO]: Epoch 022 - training loss: 0.1443, validation loss: 0.1349
2024-05-25 01:07:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch22_loss0.13487205579876899.pypots
2024-05-25 01:08:14 [INFO]: Epoch 023 - training loss: 0.1434, validation loss: 0.1325
2024-05-25 01:08:14 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch23_loss0.13249145671725274.pypots
2024-05-25 01:08:30 [INFO]: Epoch 024 - training loss: 0.1502, validation loss: 0.1343
2024-05-25 01:08:30 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch24_loss0.13426445722579955.pypots
2024-05-25 01:08:47 [INFO]: Epoch 025 - training loss: 0.1497, validation loss: 0.1416
2024-05-25 01:08:47 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch25_loss0.14160436689853667.pypots
2024-05-25 01:09:04 [INFO]: Epoch 026 - training loss: 0.1512, validation loss: 0.1327
2024-05-25 01:09:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch26_loss0.13274393156170844.pypots
2024-05-25 01:09:21 [INFO]: Epoch 027 - training loss: 0.1398, validation loss: 0.1330
2024-05-25 01:09:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch27_loss0.1329743631184101.pypots
2024-05-25 01:09:38 [INFO]: Epoch 028 - training loss: 0.1430, validation loss: 0.1309
2024-05-25 01:09:38 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch28_loss0.1309105224907398.pypots
2024-05-25 01:09:54 [INFO]: Epoch 029 - training loss: 0.1164, validation loss: 0.1364
2024-05-25 01:09:54 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch29_loss0.13638752698898315.pypots
2024-05-25 01:10:11 [INFO]: Epoch 030 - training loss: 0.1143, validation loss: 0.1268
2024-05-25 01:10:11 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch30_loss0.12678826078772545.pypots
2024-05-25 01:10:28 [INFO]: Epoch 031 - training loss: 0.1373, validation loss: 0.1254
2024-05-25 01:10:28 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch31_loss0.12538000866770743.pypots
2024-05-25 01:10:45 [INFO]: Epoch 032 - training loss: 0.1205, validation loss: 0.1262
2024-05-25 01:10:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch32_loss0.12619297653436662.pypots
2024-05-25 01:11:02 [INFO]: Epoch 033 - training loss: 0.1435, validation loss: 0.1296
2024-05-25 01:11:02 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch33_loss0.12963859289884566.pypots
2024-05-25 01:11:18 [INFO]: Epoch 034 - training loss: 0.1403, validation loss: 0.1376
2024-05-25 01:11:18 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch34_loss0.13763174638152123.pypots
2024-05-25 01:11:35 [INFO]: Epoch 035 - training loss: 0.1561, validation loss: 0.1264
2024-05-25 01:11:35 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch35_loss0.12636348009109497.pypots
2024-05-25 01:11:52 [INFO]: Epoch 036 - training loss: 0.1459, validation loss: 0.1218
2024-05-25 01:11:52 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch36_loss0.12180614396929741.pypots
2024-05-25 01:12:09 [INFO]: Epoch 037 - training loss: 0.1229, validation loss: 0.1224
2024-05-25 01:12:09 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch37_loss0.12237083986401558.pypots
2024-05-25 01:12:26 [INFO]: Epoch 038 - training loss: 0.1430, validation loss: 0.1202
2024-05-25 01:12:26 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch38_loss0.12020620703697205.pypots
2024-05-25 01:12:42 [INFO]: Epoch 039 - training loss: 0.1252, validation loss: 0.1173
2024-05-25 01:12:42 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch39_loss0.11726159751415252.pypots
2024-05-25 01:12:59 [INFO]: Epoch 040 - training loss: 0.1253, validation loss: 0.1189
2024-05-25 01:12:59 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch40_loss0.11886274293065072.pypots
2024-05-25 01:13:16 [INFO]: Epoch 041 - training loss: 0.1186, validation loss: 0.1176
2024-05-25 01:13:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch41_loss0.11761742904782295.pypots
2024-05-25 01:13:33 [INFO]: Epoch 042 - training loss: 0.1165, validation loss: 0.1167
2024-05-25 01:13:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch42_loss0.11673391014337539.pypots
2024-05-25 01:13:50 [INFO]: Epoch 043 - training loss: 0.1271, validation loss: 0.1334
2024-05-25 01:13:50 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch43_loss0.13343215510249137.pypots
2024-05-25 01:14:06 [INFO]: Epoch 044 - training loss: 0.1124, validation loss: 0.1150
2024-05-25 01:14:06 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch44_loss0.11503549367189407.pypots
2024-05-25 01:14:23 [INFO]: Epoch 045 - training loss: 0.1139, validation loss: 0.1176
2024-05-25 01:14:23 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch45_loss0.1175511546432972.pypots
2024-05-25 01:14:40 [INFO]: Epoch 046 - training loss: 0.1224, validation loss: 0.1177
2024-05-25 01:14:40 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch46_loss0.11772522702813148.pypots
2024-05-25 01:14:57 [INFO]: Epoch 047 - training loss: 0.1285, validation loss: 0.1119
2024-05-25 01:14:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch47_loss0.11193751692771911.pypots
2024-05-25 01:15:14 [INFO]: Epoch 048 - training loss: 0.1320, validation loss: 0.1139
2024-05-25 01:15:14 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch48_loss0.11385230645537377.pypots
2024-05-25 01:15:30 [INFO]: Epoch 049 - training loss: 0.1374, validation loss: 0.1116
2024-05-25 01:15:30 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch49_loss0.11156648322939873.pypots
2024-05-25 01:15:47 [INFO]: Epoch 050 - training loss: 0.1060, validation loss: 0.1113
2024-05-25 01:15:47 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch50_loss0.11125593855977059.pypots
2024-05-25 01:16:04 [INFO]: Epoch 051 - training loss: 0.1203, validation loss: 0.1111
2024-05-25 01:16:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch51_loss0.11106196269392968.pypots
2024-05-25 01:16:21 [INFO]: Epoch 052 - training loss: 0.1343, validation loss: 0.1127
2024-05-25 01:16:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch52_loss0.11271335780620576.pypots
2024-05-25 01:16:38 [INFO]: Epoch 053 - training loss: 0.1121, validation loss: 0.1155
2024-05-25 01:16:38 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch53_loss0.11546291038393974.pypots
2024-05-25 01:16:54 [INFO]: Epoch 054 - training loss: 0.1233, validation loss: 0.1103
2024-05-25 01:16:54 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch54_loss0.11031110137701035.pypots
2024-05-25 01:17:11 [INFO]: Epoch 055 - training loss: 0.1150, validation loss: 0.1114
2024-05-25 01:17:11 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch55_loss0.11140520125627518.pypots
2024-05-25 01:17:28 [INFO]: Epoch 056 - training loss: 0.1176, validation loss: 0.1099
2024-05-25 01:17:28 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch56_loss0.10991785302758217.pypots
2024-05-25 01:17:45 [INFO]: Epoch 057 - training loss: 0.1075, validation loss: 0.1105
2024-05-25 01:17:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch57_loss0.11050576344132423.pypots
2024-05-25 01:18:01 [INFO]: Epoch 058 - training loss: 0.1182, validation loss: 0.1114
2024-05-25 01:18:02 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch58_loss0.1114130936563015.pypots
2024-05-25 01:18:18 [INFO]: Epoch 059 - training loss: 0.1336, validation loss: 0.1138
2024-05-25 01:18:18 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch59_loss0.11378861740231513.pypots
2024-05-25 01:18:35 [INFO]: Epoch 060 - training loss: 0.1232, validation loss: 0.1110
2024-05-25 01:18:35 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch60_loss0.11095895245671272.pypots
2024-05-25 01:18:52 [INFO]: Epoch 061 - training loss: 0.1256, validation loss: 0.1109
2024-05-25 01:18:52 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch61_loss0.11093634739518166.pypots
2024-05-25 01:19:09 [INFO]: Epoch 062 - training loss: 0.1142, validation loss: 0.1110
2024-05-25 01:19:09 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch62_loss0.11100937277078629.pypots
2024-05-25 01:19:25 [INFO]: Epoch 063 - training loss: 0.1150, validation loss: 0.1118
2024-05-25 01:19:25 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch63_loss0.11183784827589989.pypots
2024-05-25 01:19:42 [INFO]: Epoch 064 - training loss: 0.1317, validation loss: 0.1103
2024-05-25 01:19:42 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch64_loss0.11030213758349419.pypots
2024-05-25 01:19:59 [INFO]: Epoch 065 - training loss: 0.1316, validation loss: 0.1138
2024-05-25 01:19:59 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch65_loss0.11376252844929695.pypots
2024-05-25 01:20:16 [INFO]: Epoch 066 - training loss: 0.1025, validation loss: 0.1088
2024-05-25 01:20:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch66_loss0.10879779234528542.pypots
2024-05-25 01:20:33 [INFO]: Epoch 067 - training loss: 0.1119, validation loss: 0.1086
2024-05-25 01:20:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch67_loss0.10864450559020042.pypots
2024-05-25 01:20:49 [INFO]: Epoch 068 - training loss: 0.1176, validation loss: 0.1075
2024-05-25 01:20:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch68_loss0.10753834024071693.pypots
2024-05-25 01:21:06 [INFO]: Epoch 069 - training loss: 0.1170, validation loss: 0.1095
2024-05-25 01:21:06 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch69_loss0.1095009833574295.pypots
2024-05-25 01:21:23 [INFO]: Epoch 070 - training loss: 0.1168, validation loss: 0.1097
2024-05-25 01:21:23 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch70_loss0.10972025319933891.pypots
2024-05-25 01:21:40 [INFO]: Epoch 071 - training loss: 0.1226, validation loss: 0.1095
2024-05-25 01:21:40 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch71_loss0.10946582332253456.pypots
2024-05-25 01:21:57 [INFO]: Epoch 072 - training loss: 0.1062, validation loss: 0.1105
2024-05-25 01:21:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch72_loss0.11048280745744705.pypots
2024-05-25 01:22:13 [INFO]: Epoch 073 - training loss: 0.1163, validation loss: 0.1086
2024-05-25 01:22:13 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch73_loss0.10859863013029099.pypots
2024-05-25 01:22:30 [INFO]: Epoch 074 - training loss: 0.1168, validation loss: 0.1114
2024-05-25 01:22:30 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch74_loss0.11138047948479653.pypots
2024-05-25 01:22:47 [INFO]: Epoch 075 - training loss: 0.1125, validation loss: 0.1067
2024-05-25 01:22:47 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch75_loss0.10672340840101242.pypots
2024-05-25 01:23:04 [INFO]: Epoch 076 - training loss: 0.1247, validation loss: 0.1127
2024-05-25 01:23:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch76_loss0.11272014081478118.pypots
2024-05-25 01:23:21 [INFO]: Epoch 077 - training loss: 0.1339, validation loss: 0.1082
2024-05-25 01:23:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch77_loss0.1081618219614029.pypots
2024-05-25 01:23:37 [INFO]: Epoch 078 - training loss: 0.1123, validation loss: 0.1219
2024-05-25 01:23:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch78_loss0.12191096320748329.pypots
2024-05-25 01:23:54 [INFO]: Epoch 079 - training loss: 0.1291, validation loss: 0.1086
2024-05-25 01:23:54 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch79_loss0.10861668810248375.pypots
2024-05-25 01:24:11 [INFO]: Epoch 080 - training loss: 0.1155, validation loss: 0.1070
2024-05-25 01:24:11 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch80_loss0.10699854642152787.pypots
2024-05-25 01:24:28 [INFO]: Epoch 081 - training loss: 0.1209, validation loss: 0.1058
2024-05-25 01:24:28 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch81_loss0.10577481389045715.pypots
2024-05-25 01:24:45 [INFO]: Epoch 082 - training loss: 0.1288, validation loss: 0.1076
2024-05-25 01:24:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch82_loss0.10759874805808067.pypots
2024-05-25 01:25:01 [INFO]: Epoch 083 - training loss: 0.1276, validation loss: 0.1078
2024-05-25 01:25:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch83_loss0.1078069970011711.pypots
2024-05-25 01:25:18 [INFO]: Epoch 084 - training loss: 0.1194, validation loss: 0.1065
2024-05-25 01:25:18 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch84_loss0.10652347803115844.pypots
2024-05-25 01:25:35 [INFO]: Epoch 085 - training loss: 0.1267, validation loss: 0.1045
2024-05-25 01:25:35 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch85_loss0.10453879535198211.pypots
2024-05-25 01:25:52 [INFO]: Epoch 086 - training loss: 0.1131, validation loss: 0.1049
2024-05-25 01:25:52 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch86_loss0.10492512360215187.pypots
2024-05-25 01:26:09 [INFO]: Epoch 087 - training loss: 0.1223, validation loss: 0.1050
2024-05-25 01:26:09 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch87_loss0.10496896654367446.pypots
2024-05-25 01:26:25 [INFO]: Epoch 088 - training loss: 0.1215, validation loss: 0.1087
2024-05-25 01:26:25 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch88_loss0.10866744220256805.pypots
2024-05-25 01:26:42 [INFO]: Epoch 089 - training loss: 0.1174, validation loss: 0.1039
2024-05-25 01:26:42 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch89_loss0.10389202237129211.pypots
2024-05-25 01:26:59 [INFO]: Epoch 090 - training loss: 0.1116, validation loss: 0.1088
2024-05-25 01:26:59 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch90_loss0.10879522636532783.pypots
2024-05-25 01:27:16 [INFO]: Epoch 091 - training loss: 0.1205, validation loss: 0.1048
2024-05-25 01:27:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch91_loss0.1047535441815853.pypots
2024-05-25 01:27:33 [INFO]: Epoch 092 - training loss: 0.1311, validation loss: 0.1039
2024-05-25 01:27:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch92_loss0.10389365702867508.pypots
2024-05-25 01:27:49 [INFO]: Epoch 093 - training loss: 0.1244, validation loss: 0.1041
2024-05-25 01:27:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch93_loss0.10410388559103012.pypots
2024-05-25 01:28:06 [INFO]: Epoch 094 - training loss: 0.1111, validation loss: 0.1093
2024-05-25 01:28:06 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch94_loss0.10928836390376091.pypots
2024-05-25 01:28:23 [INFO]: Epoch 095 - training loss: 0.1164, validation loss: 0.1059
2024-05-25 01:28:23 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch95_loss0.105940230935812.pypots
2024-05-25 01:28:40 [INFO]: Epoch 096 - training loss: 0.1091, validation loss: 0.1043
2024-05-25 01:28:40 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch96_loss0.10425272509455681.pypots
2024-05-25 01:28:57 [INFO]: Epoch 097 - training loss: 0.1035, validation loss: 0.1036
2024-05-25 01:28:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch97_loss0.10357265919446945.pypots
2024-05-25 01:29:13 [INFO]: Epoch 098 - training loss: 0.1019, validation loss: 0.1028
2024-05-25 01:29:13 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch98_loss0.10282358229160309.pypots
2024-05-25 01:29:30 [INFO]: Epoch 099 - training loss: 0.1269, validation loss: 0.1031
2024-05-25 01:29:30 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch99_loss0.10313833430409432.pypots
2024-05-25 01:29:47 [INFO]: Epoch 100 - training loss: 0.1088, validation loss: 0.1043
2024-05-25 01:29:47 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch100_loss0.10425662398338317.pypots
2024-05-25 01:30:04 [INFO]: Epoch 101 - training loss: 0.1290, validation loss: 0.1059
2024-05-25 01:30:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch101_loss0.10586150363087654.pypots
2024-05-25 01:30:20 [INFO]: Epoch 102 - training loss: 0.1279, validation loss: 0.1027
2024-05-25 01:30:20 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch102_loss0.10274246409535408.pypots
2024-05-25 01:30:37 [INFO]: Epoch 103 - training loss: 0.1019, validation loss: 0.1058
2024-05-25 01:30:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch103_loss0.10575330927968025.pypots
2024-05-25 01:30:54 [INFO]: Epoch 104 - training loss: 0.1007, validation loss: 0.1023
2024-05-25 01:30:54 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch104_loss0.10228374749422073.pypots
2024-05-25 01:31:11 [INFO]: Epoch 105 - training loss: 0.1080, validation loss: 0.1028
2024-05-25 01:31:11 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch105_loss0.10276921018958092.pypots
2024-05-25 01:31:28 [INFO]: Epoch 106 - training loss: 0.1103, validation loss: 0.1037
2024-05-25 01:31:28 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch106_loss0.10371656715869904.pypots
2024-05-25 01:31:45 [INFO]: Epoch 107 - training loss: 0.1168, validation loss: 0.1027
2024-05-25 01:31:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch107_loss0.10272635966539383.pypots
2024-05-25 01:32:01 [INFO]: Epoch 108 - training loss: 0.1108, validation loss: 0.1038
2024-05-25 01:32:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch108_loss0.10382901579141617.pypots
2024-05-25 01:32:18 [INFO]: Epoch 109 - training loss: 0.1046, validation loss: 0.1051
2024-05-25 01:32:18 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch109_loss0.10508401021361351.pypots
2024-05-25 01:32:35 [INFO]: Epoch 110 - training loss: 0.1113, validation loss: 0.1035
2024-05-25 01:32:35 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch110_loss0.1034750521183014.pypots
2024-05-25 01:32:52 [INFO]: Epoch 111 - training loss: 0.1144, validation loss: 0.1022
2024-05-25 01:32:52 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch111_loss0.10220268964767457.pypots
2024-05-25 01:33:08 [INFO]: Epoch 112 - training loss: 0.1084, validation loss: 0.1038
2024-05-25 01:33:09 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch112_loss0.10378683060407638.pypots
2024-05-25 01:33:25 [INFO]: Epoch 113 - training loss: 0.1147, validation loss: 0.1026
2024-05-25 01:33:25 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch113_loss0.10261464044451714.pypots
2024-05-25 01:33:42 [INFO]: Epoch 114 - training loss: 0.1215, validation loss: 0.1054
2024-05-25 01:33:42 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch114_loss0.1054073803126812.pypots
2024-05-25 01:33:59 [INFO]: Epoch 115 - training loss: 0.1065, validation loss: 0.1025
2024-05-25 01:33:59 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch115_loss0.10254641100764275.pypots
2024-05-25 01:34:16 [INFO]: Epoch 116 - training loss: 0.1278, validation loss: 0.1048
2024-05-25 01:34:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch116_loss0.10480021238327027.pypots
2024-05-25 01:34:32 [INFO]: Epoch 117 - training loss: 0.1306, validation loss: 0.1021
2024-05-25 01:34:32 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch117_loss0.1020518645644188.pypots
2024-05-25 01:34:49 [INFO]: Epoch 118 - training loss: 0.1167, validation loss: 0.1025
2024-05-25 01:34:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch118_loss0.10245554372668267.pypots
2024-05-25 01:35:06 [INFO]: Epoch 119 - training loss: 0.1025, validation loss: 0.1012
2024-05-25 01:35:06 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch119_loss0.10115815177559853.pypots
2024-05-25 01:35:23 [INFO]: Epoch 120 - training loss: 0.1090, validation loss: 0.1013
2024-05-25 01:35:23 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch120_loss0.10128964856266975.pypots
2024-05-25 01:35:40 [INFO]: Epoch 121 - training loss: 0.1123, validation loss: 0.1037
2024-05-25 01:35:40 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch121_loss0.10369600802659988.pypots
2024-05-25 01:35:56 [INFO]: Epoch 122 - training loss: 0.1195, validation loss: 0.1022
2024-05-25 01:35:56 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch122_loss0.1021914727985859.pypots
2024-05-25 01:36:13 [INFO]: Epoch 123 - training loss: 0.1258, validation loss: 0.1019
2024-05-25 01:36:13 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch123_loss0.10185078606009483.pypots
2024-05-25 01:36:30 [INFO]: Epoch 124 - training loss: 0.1091, validation loss: 0.1014
2024-05-25 01:36:30 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch124_loss0.10142634958028793.pypots
2024-05-25 01:36:47 [INFO]: Epoch 125 - training loss: 0.1195, validation loss: 0.1008
2024-05-25 01:36:47 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch125_loss0.10077821388840676.pypots
2024-05-25 01:37:04 [INFO]: Epoch 126 - training loss: 0.0951, validation loss: 0.1008
2024-05-25 01:37:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch126_loss0.10081466361880302.pypots
2024-05-25 01:37:20 [INFO]: Epoch 127 - training loss: 0.1124, validation loss: 0.1055
2024-05-25 01:37:20 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch127_loss0.10548207461833954.pypots
2024-05-25 01:37:37 [INFO]: Epoch 128 - training loss: 0.1124, validation loss: 0.1031
2024-05-25 01:37:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch128_loss0.10314926952123642.pypots
2024-05-25 01:37:54 [INFO]: Epoch 129 - training loss: 0.1090, validation loss: 0.1036
2024-05-25 01:37:54 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch129_loss0.10360164865851403.pypots
2024-05-25 01:38:11 [INFO]: Epoch 130 - training loss: 0.1150, validation loss: 0.1023
2024-05-25 01:38:11 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch130_loss0.10232600122690201.pypots
2024-05-25 01:38:28 [INFO]: Epoch 131 - training loss: 0.1161, validation loss: 0.1011
2024-05-25 01:38:28 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch131_loss0.10105757638812066.pypots
2024-05-25 01:38:44 [INFO]: Epoch 132 - training loss: 0.1052, validation loss: 0.1007
2024-05-25 01:38:44 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch132_loss0.10067235827445983.pypots
2024-05-25 01:39:01 [INFO]: Epoch 133 - training loss: 0.1074, validation loss: 0.1047
2024-05-25 01:39:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch133_loss0.10466304272413254.pypots
2024-05-25 01:39:18 [INFO]: Epoch 134 - training loss: 0.1065, validation loss: 0.0996
2024-05-25 01:39:18 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch134_loss0.09961874559521675.pypots
2024-05-25 01:39:35 [INFO]: Epoch 135 - training loss: 0.1204, validation loss: 0.0992
2024-05-25 01:39:35 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch135_loss0.09919817000627518.pypots
2024-05-25 01:39:52 [INFO]: Epoch 136 - training loss: 0.1063, validation loss: 0.1028
2024-05-25 01:39:52 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch136_loss0.10281966030597686.pypots
2024-05-25 01:40:08 [INFO]: Epoch 137 - training loss: 0.1098, validation loss: 0.1018
2024-05-25 01:40:08 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch137_loss0.10181116387248039.pypots
2024-05-25 01:40:25 [INFO]: Epoch 138 - training loss: 0.1191, validation loss: 0.0994
2024-05-25 01:40:25 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch138_loss0.09943219348788261.pypots
2024-05-25 01:40:42 [INFO]: Epoch 139 - training loss: 0.0932, validation loss: 0.1003
2024-05-25 01:40:42 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch139_loss0.10025403052568435.pypots
2024-05-25 01:40:59 [INFO]: Epoch 140 - training loss: 0.1227, validation loss: 0.0984
2024-05-25 01:40:59 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch140_loss0.09844759479165077.pypots
2024-05-25 01:41:16 [INFO]: Epoch 141 - training loss: 0.1073, validation loss: 0.0999
2024-05-25 01:41:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch141_loss0.09994176626205445.pypots
2024-05-25 01:41:32 [INFO]: Epoch 142 - training loss: 0.1131, validation loss: 0.1021
2024-05-25 01:41:32 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch142_loss0.10207233279943466.pypots
2024-05-25 01:41:49 [INFO]: Epoch 143 - training loss: 0.1127, validation loss: 0.1004
2024-05-25 01:41:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch143_loss0.10042393282055855.pypots
2024-05-25 01:42:06 [INFO]: Epoch 144 - training loss: 0.1048, validation loss: 0.0979
2024-05-25 01:42:06 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch144_loss0.0978672131896019.pypots
2024-05-25 01:42:23 [INFO]: Epoch 145 - training loss: 0.1035, validation loss: 0.0973
2024-05-25 01:42:23 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch145_loss0.0973426952958107.pypots
2024-05-25 01:42:40 [INFO]: Epoch 146 - training loss: 0.1079, validation loss: 0.1032
2024-05-25 01:42:40 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch146_loss0.10320970043540001.pypots
2024-05-25 01:42:56 [INFO]: Epoch 147 - training loss: 0.1075, validation loss: 0.1010
2024-05-25 01:42:56 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch147_loss0.10099007934331894.pypots
2024-05-25 01:43:13 [INFO]: Epoch 148 - training loss: 0.1029, validation loss: 0.1059
2024-05-25 01:43:13 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch148_loss0.1058715246617794.pypots
2024-05-25 01:43:30 [INFO]: Epoch 149 - training loss: 0.1250, validation loss: 0.1001
2024-05-25 01:43:30 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch149_loss0.10007229968905448.pypots
2024-05-25 01:43:47 [INFO]: Epoch 150 - training loss: 0.1090, validation loss: 0.0994
2024-05-25 01:43:47 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch150_loss0.09943852201104164.pypots
2024-05-25 01:44:04 [INFO]: Epoch 151 - training loss: 0.1020, validation loss: 0.0993
2024-05-25 01:44:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch151_loss0.0992814302444458.pypots
2024-05-25 01:44:20 [INFO]: Epoch 152 - training loss: 0.1147, validation loss: 0.0992
2024-05-25 01:44:20 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch152_loss0.09915124103426934.pypots
2024-05-25 01:44:37 [INFO]: Epoch 153 - training loss: 0.1082, validation loss: 0.0987
2024-05-25 01:44:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch153_loss0.09873274266719818.pypots
2024-05-25 01:44:54 [INFO]: Epoch 154 - training loss: 0.1018, validation loss: 0.0987
2024-05-25 01:44:54 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch154_loss0.0987077496945858.pypots
2024-05-25 01:45:11 [INFO]: Epoch 155 - training loss: 0.1127, validation loss: 0.0984
2024-05-25 01:45:11 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI_epoch155_loss0.0984185978770256.pypots
2024-05-25 01:45:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:45:11 [INFO]: Finished training. The best model is from epoch#145.
2024-05-25 01:45:11 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240525_T010147/CSDI.pypots
2024-05-25 01:47:31 [INFO]: CSDI on Air-Quality: MAE=0.1011, MSE=0.1720
2024-05-25 01:47:31 [INFO]: Successfully saved to augmentation_saved_results/round_0/CSDI_air_quality/imputation.pkl
2024-05-25 01:47:31 [INFO]: Using the given device: cuda:0
2024-05-25 01:47:31 [INFO]: Model files will be saved to augmentation_saved_results/round_0/GPVAE_air_quality/20240525_T014731
2024-05-25 01:47:31 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/GPVAE_air_quality/20240525_T014731/tensorboard
2024-05-25 01:47:31 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 01:47:31 [INFO]: Epoch 001 - training loss: 64347.1545, validation loss: 0.7033
2024-05-25 01:47:31 [INFO]: Epoch 002 - training loss: 42071.6764, validation loss: 0.5961
2024-05-25 01:47:32 [INFO]: Epoch 003 - training loss: 41775.2904, validation loss: 0.5632
2024-05-25 01:47:32 [INFO]: Epoch 004 - training loss: 41636.0020, validation loss: 0.4862
2024-05-25 01:47:32 [INFO]: Epoch 005 - training loss: 41557.0370, validation loss: 0.4668
2024-05-25 01:47:33 [INFO]: Epoch 006 - training loss: 41493.5557, validation loss: 0.4156
2024-05-25 01:47:33 [INFO]: Epoch 007 - training loss: 41461.0339, validation loss: 0.3946
2024-05-25 01:47:33 [INFO]: Epoch 008 - training loss: 41426.4563, validation loss: 0.3779
2024-05-25 01:47:34 [INFO]: Epoch 009 - training loss: 41428.9680, validation loss: 0.4019
2024-05-25 01:47:34 [INFO]: Epoch 010 - training loss: 41416.8016, validation loss: 0.3683
2024-05-25 01:47:34 [INFO]: Epoch 011 - training loss: 41356.1159, validation loss: 0.3488
2024-05-25 01:47:35 [INFO]: Epoch 012 - training loss: 41348.2368, validation loss: 0.3450
2024-05-25 01:47:35 [INFO]: Epoch 013 - training loss: 41350.5383, validation loss: 0.3373
2024-05-25 01:47:35 [INFO]: Epoch 014 - training loss: 41318.8832, validation loss: 0.3397
2024-05-25 01:47:36 [INFO]: Epoch 015 - training loss: 41311.4382, validation loss: 0.3580
2024-05-25 01:47:36 [INFO]: Epoch 016 - training loss: 41297.3442, validation loss: 0.3440
2024-05-25 01:47:36 [INFO]: Epoch 017 - training loss: 41344.7791, validation loss: 0.3502
2024-05-25 01:47:36 [INFO]: Epoch 018 - training loss: 41318.3209, validation loss: 0.3235
2024-05-25 01:47:37 [INFO]: Epoch 019 - training loss: 41278.9326, validation loss: 0.3233
2024-05-25 01:47:37 [INFO]: Epoch 020 - training loss: 41262.9637, validation loss: 0.3098
2024-05-25 01:47:37 [INFO]: Epoch 021 - training loss: 41263.3809, validation loss: 0.3229
2024-05-25 01:47:38 [INFO]: Epoch 022 - training loss: 41254.6992, validation loss: 0.3649
2024-05-25 01:47:38 [INFO]: Epoch 023 - training loss: 41251.9638, validation loss: 0.3086
2024-05-25 01:47:38 [INFO]: Epoch 024 - training loss: 41233.6134, validation loss: 0.3069
2024-05-25 01:47:39 [INFO]: Epoch 025 - training loss: 41235.4076, validation loss: 0.3097
2024-05-25 01:47:39 [INFO]: Epoch 026 - training loss: 41237.2196, validation loss: 0.2882
2024-05-25 01:47:39 [INFO]: Epoch 027 - training loss: 41237.7021, validation loss: 0.2978
2024-05-25 01:47:40 [INFO]: Epoch 028 - training loss: 41224.9130, validation loss: 0.2844
2024-05-25 01:47:40 [INFO]: Epoch 029 - training loss: 41225.3129, validation loss: 0.2836
2024-05-25 01:47:40 [INFO]: Epoch 030 - training loss: 41238.5091, validation loss: 0.3053
2024-05-25 01:47:40 [INFO]: Epoch 031 - training loss: 41251.8796, validation loss: 0.3272
2024-05-25 01:47:41 [INFO]: Epoch 032 - training loss: 41259.2640, validation loss: 0.2867
2024-05-25 01:47:41 [INFO]: Epoch 033 - training loss: 41278.5184, validation loss: 0.3101
2024-05-25 01:47:41 [INFO]: Epoch 034 - training loss: 41269.9505, validation loss: 0.2903
2024-05-25 01:47:42 [INFO]: Epoch 035 - training loss: 41227.2797, validation loss: 0.2966
2024-05-25 01:47:42 [INFO]: Epoch 036 - training loss: 41206.4100, validation loss: 0.2862
2024-05-25 01:47:42 [INFO]: Epoch 037 - training loss: 41190.5920, validation loss: 0.2732
2024-05-25 01:47:43 [INFO]: Epoch 038 - training loss: 41184.4168, validation loss: 0.2729
2024-05-25 01:47:43 [INFO]: Epoch 039 - training loss: 41196.6085, validation loss: 0.2618
2024-05-25 01:47:43 [INFO]: Epoch 040 - training loss: 41193.4308, validation loss: 0.2638
2024-05-25 01:47:44 [INFO]: Epoch 041 - training loss: 41215.2875, validation loss: 0.2932
2024-05-25 01:47:44 [INFO]: Epoch 042 - training loss: 41207.5184, validation loss: 0.2701
2024-05-25 01:47:44 [INFO]: Epoch 043 - training loss: 41189.5094, validation loss: 0.2680
2024-05-25 01:47:44 [INFO]: Epoch 044 - training loss: 41177.8490, validation loss: 0.2793
2024-05-25 01:47:45 [INFO]: Epoch 045 - training loss: 41179.5819, validation loss: 0.2687
2024-05-25 01:47:45 [INFO]: Epoch 046 - training loss: 41174.5346, validation loss: 0.2712
2024-05-25 01:47:45 [INFO]: Epoch 047 - training loss: 41176.0752, validation loss: 0.2563
2024-05-25 01:47:46 [INFO]: Epoch 048 - training loss: 41179.5017, validation loss: 0.2623
2024-05-25 01:47:46 [INFO]: Epoch 049 - training loss: 41167.1341, validation loss: 0.2602
2024-05-25 01:47:46 [INFO]: Epoch 050 - training loss: 41170.5583, validation loss: 0.2745
2024-05-25 01:47:47 [INFO]: Epoch 051 - training loss: 41182.7519, validation loss: 0.2674
2024-05-25 01:47:47 [INFO]: Epoch 052 - training loss: 41172.7672, validation loss: 0.2546
2024-05-25 01:47:47 [INFO]: Epoch 053 - training loss: 41178.6249, validation loss: 0.2678
2024-05-25 01:47:48 [INFO]: Epoch 054 - training loss: 41168.6266, validation loss: 0.2663
2024-05-25 01:47:48 [INFO]: Epoch 055 - training loss: 41201.2465, validation loss: 0.2878
2024-05-25 01:47:48 [INFO]: Epoch 056 - training loss: 41215.6897, validation loss: 0.2666
2024-05-25 01:47:49 [INFO]: Epoch 057 - training loss: 41181.0940, validation loss: 0.2739
2024-05-25 01:47:49 [INFO]: Epoch 058 - training loss: 41201.7700, validation loss: 0.2769
2024-05-25 01:47:49 [INFO]: Epoch 059 - training loss: 41211.9935, validation loss: 0.2662
2024-05-25 01:47:49 [INFO]: Epoch 060 - training loss: 41177.7271, validation loss: 0.2607
2024-05-25 01:47:50 [INFO]: Epoch 061 - training loss: 41172.4651, validation loss: 0.2757
2024-05-25 01:47:50 [INFO]: Epoch 062 - training loss: 41165.5177, validation loss: 0.2767
2024-05-25 01:47:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:47:50 [INFO]: Finished training. The best model is from epoch#52.
2024-05-25 01:47:50 [INFO]: Saved the model to augmentation_saved_results/round_0/GPVAE_air_quality/20240525_T014731/GPVAE.pypots
2024-05-25 01:47:50 [INFO]: GP-VAE on Air-Quality: MAE=0.3166, MSE=0.3420
2024-05-25 01:47:50 [INFO]: Successfully saved to augmentation_saved_results/round_0/GPVAE_air_quality/imputation.pkl
2024-05-25 01:47:50 [INFO]: Using the given device: cuda:0
2024-05-25 01:47:50 [INFO]: Model files will be saved to augmentation_saved_results/round_0/USGAN_air_quality/20240525_T014750
2024-05-25 01:47:50 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/USGAN_air_quality/20240525_T014750/tensorboard
2024-05-25 01:47:50 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 01:47:55 [INFO]: Epoch 001 - generator training loss: 0.6075, discriminator training loss: 0.2986, validation loss: 0.5277
2024-05-25 01:47:59 [INFO]: Epoch 002 - generator training loss: 0.2923, discriminator training loss: 0.0680, validation loss: 0.3934
2024-05-25 01:48:03 [INFO]: Epoch 003 - generator training loss: 0.2131, discriminator training loss: 0.0627, validation loss: 0.3240
2024-05-25 01:48:07 [INFO]: Epoch 004 - generator training loss: 0.1766, discriminator training loss: 0.0618, validation loss: 0.2831
2024-05-25 01:48:11 [INFO]: Epoch 005 - generator training loss: 0.1508, discriminator training loss: 0.0619, validation loss: 0.2581
2024-05-25 01:48:15 [INFO]: Epoch 006 - generator training loss: 0.1337, discriminator training loss: 0.0613, validation loss: 0.2404
2024-05-25 01:48:19 [INFO]: Epoch 007 - generator training loss: 0.1221, discriminator training loss: 0.0608, validation loss: 0.2280
2024-05-25 01:48:23 [INFO]: Epoch 008 - generator training loss: 0.1109, discriminator training loss: 0.0601, validation loss: 0.2177
2024-05-25 01:48:27 [INFO]: Epoch 009 - generator training loss: 0.1034, discriminator training loss: 0.0599, validation loss: 0.2088
2024-05-25 01:48:32 [INFO]: Epoch 010 - generator training loss: 0.0948, discriminator training loss: 0.0589, validation loss: 0.2015
2024-05-25 01:48:36 [INFO]: Epoch 011 - generator training loss: 0.0909, discriminator training loss: 0.0576, validation loss: 0.1962
2024-05-25 01:48:40 [INFO]: Epoch 012 - generator training loss: 0.0849, discriminator training loss: 0.0567, validation loss: 0.1916
2024-05-25 01:48:44 [INFO]: Epoch 013 - generator training loss: 0.0817, discriminator training loss: 0.0554, validation loss: 0.1873
2024-05-25 01:48:48 [INFO]: Epoch 014 - generator training loss: 0.0786, discriminator training loss: 0.0539, validation loss: 0.1840
2024-05-25 01:48:52 [INFO]: Epoch 015 - generator training loss: 0.0774, discriminator training loss: 0.0523, validation loss: 0.1808
2024-05-25 01:48:56 [INFO]: Epoch 016 - generator training loss: 0.0751, discriminator training loss: 0.0506, validation loss: 0.1770
2024-05-25 01:49:00 [INFO]: Epoch 017 - generator training loss: 0.0770, discriminator training loss: 0.0481, validation loss: 0.1759
2024-05-25 01:49:04 [INFO]: Epoch 018 - generator training loss: 0.0722, discriminator training loss: 0.0471, validation loss: 0.1732
2024-05-25 01:49:08 [INFO]: Epoch 019 - generator training loss: 0.0702, discriminator training loss: 0.0463, validation loss: 0.1707
2024-05-25 01:49:12 [INFO]: Epoch 020 - generator training loss: 0.0727, discriminator training loss: 0.0450, validation loss: 0.1698
2024-05-25 01:49:16 [INFO]: Epoch 021 - generator training loss: 0.0686, discriminator training loss: 0.0438, validation loss: 0.1674
2024-05-25 01:49:20 [INFO]: Epoch 022 - generator training loss: 0.0672, discriminator training loss: 0.0434, validation loss: 0.1656
2024-05-25 01:49:24 [INFO]: Epoch 023 - generator training loss: 0.0686, discriminator training loss: 0.0423, validation loss: 0.1639
2024-05-25 01:49:28 [INFO]: Epoch 024 - generator training loss: 0.0656, discriminator training loss: 0.0414, validation loss: 0.1634
2024-05-25 01:49:32 [INFO]: Epoch 025 - generator training loss: 0.0651, discriminator training loss: 0.0406, validation loss: 0.1616
2024-05-25 01:49:36 [INFO]: Epoch 026 - generator training loss: 0.0653, discriminator training loss: 0.0398, validation loss: 0.1608
2024-05-25 01:49:40 [INFO]: Epoch 027 - generator training loss: 0.0635, discriminator training loss: 0.0387, validation loss: 0.1593
2024-05-25 01:49:44 [INFO]: Epoch 028 - generator training loss: 0.0620, discriminator training loss: 0.0384, validation loss: 0.1585
2024-05-25 01:49:48 [INFO]: Epoch 029 - generator training loss: 0.0611, discriminator training loss: 0.0373, validation loss: 0.1574
2024-05-25 01:49:52 [INFO]: Epoch 030 - generator training loss: 0.0611, discriminator training loss: 0.0366, validation loss: 0.1572
2024-05-25 01:49:56 [INFO]: Epoch 031 - generator training loss: 0.0607, discriminator training loss: 0.0355, validation loss: 0.1556
2024-05-25 01:50:00 [INFO]: Epoch 032 - generator training loss: 0.0616, discriminator training loss: 0.0347, validation loss: 0.1554
2024-05-25 01:50:04 [INFO]: Epoch 033 - generator training loss: 0.0595, discriminator training loss: 0.0337, validation loss: 0.1545
2024-05-25 01:50:09 [INFO]: Epoch 034 - generator training loss: 0.0604, discriminator training loss: 0.0328, validation loss: 0.1535
2024-05-25 01:50:13 [INFO]: Epoch 035 - generator training loss: 0.0586, discriminator training loss: 0.0327, validation loss: 0.1528
2024-05-25 01:50:17 [INFO]: Epoch 036 - generator training loss: 0.0574, discriminator training loss: 0.0320, validation loss: 0.1528
2024-05-25 01:50:21 [INFO]: Epoch 037 - generator training loss: 0.0569, discriminator training loss: 0.0312, validation loss: 0.1525
2024-05-25 01:50:25 [INFO]: Epoch 038 - generator training loss: 0.0582, discriminator training loss: 0.0303, validation loss: 0.1524
2024-05-25 01:50:29 [INFO]: Epoch 039 - generator training loss: 0.0556, discriminator training loss: 0.0303, validation loss: 0.1515
2024-05-25 01:50:33 [INFO]: Epoch 040 - generator training loss: 0.0554, discriminator training loss: 0.0294, validation loss: 0.1514
2024-05-25 01:50:37 [INFO]: Epoch 041 - generator training loss: 0.0556, discriminator training loss: 0.0288, validation loss: 0.1504
2024-05-25 01:50:41 [INFO]: Epoch 042 - generator training loss: 0.0548, discriminator training loss: 0.0287, validation loss: 0.1505
2024-05-25 01:50:45 [INFO]: Epoch 043 - generator training loss: 0.0538, discriminator training loss: 0.0280, validation loss: 0.1485
2024-05-25 01:50:49 [INFO]: Epoch 044 - generator training loss: 0.0537, discriminator training loss: 0.0274, validation loss: 0.1483
2024-05-25 01:50:53 [INFO]: Epoch 045 - generator training loss: 0.0530, discriminator training loss: 0.0274, validation loss: 0.1479
2024-05-25 01:50:57 [INFO]: Epoch 046 - generator training loss: 0.0530, discriminator training loss: 0.0265, validation loss: 0.1474
2024-05-25 01:51:01 [INFO]: Epoch 047 - generator training loss: 0.0528, discriminator training loss: 0.0259, validation loss: 0.1459
2024-05-25 01:51:05 [INFO]: Epoch 048 - generator training loss: 0.0521, discriminator training loss: 0.0257, validation loss: 0.1466
2024-05-25 01:51:09 [INFO]: Epoch 049 - generator training loss: 0.0518, discriminator training loss: 0.0254, validation loss: 0.1458
2024-05-25 01:51:13 [INFO]: Epoch 050 - generator training loss: 0.0517, discriminator training loss: 0.0248, validation loss: 0.1454
2024-05-25 01:51:17 [INFO]: Epoch 051 - generator training loss: 0.0515, discriminator training loss: 0.0244, validation loss: 0.1447
2024-05-25 01:51:21 [INFO]: Epoch 052 - generator training loss: 0.0509, discriminator training loss: 0.0242, validation loss: 0.1439
2024-05-25 01:51:25 [INFO]: Epoch 053 - generator training loss: 0.0509, discriminator training loss: 0.0239, validation loss: 0.1441
2024-05-25 01:51:29 [INFO]: Epoch 054 - generator training loss: 0.0505, discriminator training loss: 0.0237, validation loss: 0.1437
2024-05-25 01:51:33 [INFO]: Epoch 055 - generator training loss: 0.0498, discriminator training loss: 0.0233, validation loss: 0.1431
2024-05-25 01:51:37 [INFO]: Epoch 056 - generator training loss: 0.0493, discriminator training loss: 0.0231, validation loss: 0.1428
2024-05-25 01:51:41 [INFO]: Epoch 057 - generator training loss: 0.0497, discriminator training loss: 0.0227, validation loss: 0.1424
2024-05-25 01:51:45 [INFO]: Epoch 058 - generator training loss: 0.0500, discriminator training loss: 0.0224, validation loss: 0.1422
2024-05-25 01:51:49 [INFO]: Epoch 059 - generator training loss: 0.0490, discriminator training loss: 0.0222, validation loss: 0.1414
2024-05-25 01:51:53 [INFO]: Epoch 060 - generator training loss: 0.0497, discriminator training loss: 0.0217, validation loss: 0.1417
2024-05-25 01:51:58 [INFO]: Epoch 061 - generator training loss: 0.0485, discriminator training loss: 0.0216, validation loss: 0.1423
2024-05-25 01:52:02 [INFO]: Epoch 062 - generator training loss: 0.0482, discriminator training loss: 0.0214, validation loss: 0.1405
2024-05-25 01:52:06 [INFO]: Epoch 063 - generator training loss: 0.0480, discriminator training loss: 0.0211, validation loss: 0.1413
2024-05-25 01:52:10 [INFO]: Epoch 064 - generator training loss: 0.0492, discriminator training loss: 0.0210, validation loss: 0.1407
2024-05-25 01:52:14 [INFO]: Epoch 065 - generator training loss: 0.0471, discriminator training loss: 0.0206, validation loss: 0.1409
2024-05-25 01:52:18 [INFO]: Epoch 066 - generator training loss: 0.0467, discriminator training loss: 0.0205, validation loss: 0.1407
2024-05-25 01:52:22 [INFO]: Epoch 067 - generator training loss: 0.0479, discriminator training loss: 0.0203, validation loss: 0.1411
2024-05-25 01:52:26 [INFO]: Epoch 068 - generator training loss: 0.0475, discriminator training loss: 0.0200, validation loss: 0.1394
2024-05-25 01:52:30 [INFO]: Epoch 069 - generator training loss: 0.0464, discriminator training loss: 0.0197, validation loss: 0.1400
2024-05-25 01:52:34 [INFO]: Epoch 070 - generator training loss: 0.0468, discriminator training loss: 0.0193, validation loss: 0.1393
2024-05-25 01:52:38 [INFO]: Epoch 071 - generator training loss: 0.0460, discriminator training loss: 0.0193, validation loss: 0.1399
2024-05-25 01:52:42 [INFO]: Epoch 072 - generator training loss: 0.0454, discriminator training loss: 0.0192, validation loss: 0.1395
2024-05-25 01:52:46 [INFO]: Epoch 073 - generator training loss: 0.0452, discriminator training loss: 0.0190, validation loss: 0.1399
2024-05-25 01:52:50 [INFO]: Epoch 074 - generator training loss: 0.0459, discriminator training loss: 0.0190, validation loss: 0.1384
2024-05-25 01:52:54 [INFO]: Epoch 075 - generator training loss: 0.0457, discriminator training loss: 0.0187, validation loss: 0.1393
2024-05-25 01:52:58 [INFO]: Epoch 076 - generator training loss: 0.0449, discriminator training loss: 0.0184, validation loss: 0.1390
2024-05-25 01:53:02 [INFO]: Epoch 077 - generator training loss: 0.0450, discriminator training loss: 0.0184, validation loss: 0.1385
2024-05-25 01:53:06 [INFO]: Epoch 078 - generator training loss: 0.0441, discriminator training loss: 0.0182, validation loss: 0.1394
2024-05-25 01:53:10 [INFO]: Epoch 079 - generator training loss: 0.0453, discriminator training loss: 0.0181, validation loss: 0.1386
2024-05-25 01:53:14 [INFO]: Epoch 080 - generator training loss: 0.0441, discriminator training loss: 0.0179, validation loss: 0.1386
2024-05-25 01:53:18 [INFO]: Epoch 081 - generator training loss: 0.0444, discriminator training loss: 0.0179, validation loss: 0.1380
2024-05-25 01:53:22 [INFO]: Epoch 082 - generator training loss: 0.0434, discriminator training loss: 0.0175, validation loss: 0.1380
2024-05-25 01:53:26 [INFO]: Epoch 083 - generator training loss: 0.0424, discriminator training loss: 0.0176, validation loss: 0.1381
2024-05-25 01:53:30 [INFO]: Epoch 084 - generator training loss: 0.0424, discriminator training loss: 0.0172, validation loss: 0.1391
2024-05-25 01:53:34 [INFO]: Epoch 085 - generator training loss: 0.0427, discriminator training loss: 0.0174, validation loss: 0.1386
2024-05-25 01:53:38 [INFO]: Epoch 086 - generator training loss: 0.0416, discriminator training loss: 0.0171, validation loss: 0.1393
2024-05-25 01:53:42 [INFO]: Epoch 087 - generator training loss: 0.0412, discriminator training loss: 0.0169, validation loss: 0.1380
2024-05-25 01:53:46 [INFO]: Epoch 088 - generator training loss: 0.0403, discriminator training loss: 0.0170, validation loss: 0.1383
2024-05-25 01:53:50 [INFO]: Epoch 089 - generator training loss: 0.0404, discriminator training loss: 0.0169, validation loss: 0.1375
2024-05-25 01:53:54 [INFO]: Epoch 090 - generator training loss: 0.0407, discriminator training loss: 0.0166, validation loss: 0.1380
2024-05-25 01:53:58 [INFO]: Epoch 091 - generator training loss: 0.0404, discriminator training loss: 0.0165, validation loss: 0.1375
2024-05-25 01:54:02 [INFO]: Epoch 092 - generator training loss: 0.0408, discriminator training loss: 0.0164, validation loss: 0.1374
2024-05-25 01:54:06 [INFO]: Epoch 093 - generator training loss: 0.0396, discriminator training loss: 0.0163, validation loss: 0.1375
2024-05-25 01:54:11 [INFO]: Epoch 094 - generator training loss: 0.0408, discriminator training loss: 0.0161, validation loss: 0.1380
2024-05-25 01:54:15 [INFO]: Epoch 095 - generator training loss: 0.0402, discriminator training loss: 0.0161, validation loss: 0.1380
2024-05-25 01:54:19 [INFO]: Epoch 096 - generator training loss: 0.0395, discriminator training loss: 0.0159, validation loss: 0.1377
2024-05-25 01:54:23 [INFO]: Epoch 097 - generator training loss: 0.0390, discriminator training loss: 0.0159, validation loss: 0.1380
2024-05-25 01:54:27 [INFO]: Epoch 098 - generator training loss: 0.0382, discriminator training loss: 0.0159, validation loss: 0.1381
2024-05-25 01:54:31 [INFO]: Epoch 099 - generator training loss: 0.0380, discriminator training loss: 0.0156, validation loss: 0.1380
2024-05-25 01:54:35 [INFO]: Epoch 100 - generator training loss: 0.0381, discriminator training loss: 0.0155, validation loss: 0.1389
2024-05-25 01:54:39 [INFO]: Epoch 101 - generator training loss: 0.0376, discriminator training loss: 0.0156, validation loss: 0.1381
2024-05-25 01:54:43 [INFO]: Epoch 102 - generator training loss: 0.0374, discriminator training loss: 0.0154, validation loss: 0.1373
2024-05-25 01:54:47 [INFO]: Epoch 103 - generator training loss: 0.0375, discriminator training loss: 0.0155, validation loss: 0.1381
2024-05-25 01:54:51 [INFO]: Epoch 104 - generator training loss: 0.0379, discriminator training loss: 0.0153, validation loss: 0.1391
2024-05-25 01:54:55 [INFO]: Epoch 105 - generator training loss: 0.0374, discriminator training loss: 0.0152, validation loss: 0.1384
2024-05-25 01:54:59 [INFO]: Epoch 106 - generator training loss: 0.0369, discriminator training loss: 0.0152, validation loss: 0.1386
2024-05-25 01:55:03 [INFO]: Epoch 107 - generator training loss: 0.0367, discriminator training loss: 0.0151, validation loss: 0.1393
2024-05-25 01:55:07 [INFO]: Epoch 108 - generator training loss: 0.0362, discriminator training loss: 0.0150, validation loss: 0.1396
2024-05-25 01:55:11 [INFO]: Epoch 109 - generator training loss: 0.0361, discriminator training loss: 0.0149, validation loss: 0.1396
2024-05-25 01:55:15 [INFO]: Epoch 110 - generator training loss: 0.0367, discriminator training loss: 0.0151, validation loss: 0.1390
2024-05-25 01:55:19 [INFO]: Epoch 111 - generator training loss: 0.0370, discriminator training loss: 0.0148, validation loss: 0.1393
2024-05-25 01:55:23 [INFO]: Epoch 112 - generator training loss: 0.0375, discriminator training loss: 0.0148, validation loss: 0.1389
2024-05-25 01:55:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:55:23 [INFO]: Finished training. The best model is from epoch#102.
2024-05-25 01:55:23 [INFO]: Saved the model to augmentation_saved_results/round_0/USGAN_air_quality/20240525_T014750/USGAN.pypots
2024-05-25 01:55:24 [INFO]: US-GAN on Air-Quality: MAE=0.2087, MSE=0.2004
2024-05-25 01:55:24 [INFO]: Successfully saved to augmentation_saved_results/round_0/USGAN_air_quality/imputation.pkl
2024-05-25 01:55:24 [INFO]: Using the given device: cuda:0
2024-05-25 01:55:24 [INFO]: Model files will be saved to augmentation_saved_results/round_0/BRITS_air_quality/20240525_T015524
2024-05-25 01:55:24 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/BRITS_air_quality/20240525_T015524/tensorboard
2024-05-25 01:55:24 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 01:55:27 [INFO]: Epoch 001 - training loss: 1.3748, validation loss: 0.9371
2024-05-25 01:55:30 [INFO]: Epoch 002 - training loss: 1.1102, validation loss: 0.7098
2024-05-25 01:55:33 [INFO]: Epoch 003 - training loss: 0.9240, validation loss: 0.6026
2024-05-25 01:55:36 [INFO]: Epoch 004 - training loss: 0.8201, validation loss: 0.5349
2024-05-25 01:55:38 [INFO]: Epoch 005 - training loss: 0.7445, validation loss: 0.4854
2024-05-25 01:55:41 [INFO]: Epoch 006 - training loss: 0.6916, validation loss: 0.4493
2024-05-25 01:55:44 [INFO]: Epoch 007 - training loss: 0.6487, validation loss: 0.4174
2024-05-25 01:55:47 [INFO]: Epoch 008 - training loss: 0.6154, validation loss: 0.3932
2024-05-25 01:55:49 [INFO]: Epoch 009 - training loss: 0.5896, validation loss: 0.3731
2024-05-25 01:55:52 [INFO]: Epoch 010 - training loss: 0.5685, validation loss: 0.3577
2024-05-25 01:55:55 [INFO]: Epoch 011 - training loss: 0.5515, validation loss: 0.3425
2024-05-25 01:55:58 [INFO]: Epoch 012 - training loss: 0.5376, validation loss: 0.3307
2024-05-25 01:56:00 [INFO]: Epoch 013 - training loss: 0.5236, validation loss: 0.3202
2024-05-25 01:56:03 [INFO]: Epoch 014 - training loss: 0.5120, validation loss: 0.3109
2024-05-25 01:56:06 [INFO]: Epoch 015 - training loss: 0.5032, validation loss: 0.3032
2024-05-25 01:56:09 [INFO]: Epoch 016 - training loss: 0.4929, validation loss: 0.2963
2024-05-25 01:56:12 [INFO]: Epoch 017 - training loss: 0.4838, validation loss: 0.2900
2024-05-25 01:56:14 [INFO]: Epoch 018 - training loss: 0.4757, validation loss: 0.2841
2024-05-25 01:56:17 [INFO]: Epoch 019 - training loss: 0.4669, validation loss: 0.2787
2024-05-25 01:56:20 [INFO]: Epoch 020 - training loss: 0.4604, validation loss: 0.2739
2024-05-25 01:56:23 [INFO]: Epoch 021 - training loss: 0.4534, validation loss: 0.2694
2024-05-25 01:56:25 [INFO]: Epoch 022 - training loss: 0.4477, validation loss: 0.2647
2024-05-25 01:56:28 [INFO]: Epoch 023 - training loss: 0.4402, validation loss: 0.2602
2024-05-25 01:56:31 [INFO]: Epoch 024 - training loss: 0.4349, validation loss: 0.2568
2024-05-25 01:56:34 [INFO]: Epoch 025 - training loss: 0.4301, validation loss: 0.2531
2024-05-25 01:56:36 [INFO]: Epoch 026 - training loss: 0.4237, validation loss: 0.2496
2024-05-25 01:56:39 [INFO]: Epoch 027 - training loss: 0.4186, validation loss: 0.2459
2024-05-25 01:56:42 [INFO]: Epoch 028 - training loss: 0.4147, validation loss: 0.2425
2024-05-25 01:56:45 [INFO]: Epoch 029 - training loss: 0.4083, validation loss: 0.2395
2024-05-25 01:56:47 [INFO]: Epoch 030 - training loss: 0.4045, validation loss: 0.2365
2024-05-25 01:56:50 [INFO]: Epoch 031 - training loss: 0.4004, validation loss: 0.2334
2024-05-25 01:56:53 [INFO]: Epoch 032 - training loss: 0.3968, validation loss: 0.2302
2024-05-25 01:56:56 [INFO]: Epoch 033 - training loss: 0.3920, validation loss: 0.2276
2024-05-25 01:56:58 [INFO]: Epoch 034 - training loss: 0.3874, validation loss: 0.2245
2024-05-25 01:57:01 [INFO]: Epoch 035 - training loss: 0.3845, validation loss: 0.2219
2024-05-25 01:57:04 [INFO]: Epoch 036 - training loss: 0.3803, validation loss: 0.2188
2024-05-25 01:57:07 [INFO]: Epoch 037 - training loss: 0.3771, validation loss: 0.2165
2024-05-25 01:57:09 [INFO]: Epoch 038 - training loss: 0.3735, validation loss: 0.2140
2024-05-25 01:57:12 [INFO]: Epoch 039 - training loss: 0.3701, validation loss: 0.2112
2024-05-25 01:57:15 [INFO]: Epoch 040 - training loss: 0.3660, validation loss: 0.2089
2024-05-25 01:57:18 [INFO]: Epoch 041 - training loss: 0.3633, validation loss: 0.2064
2024-05-25 01:57:20 [INFO]: Epoch 042 - training loss: 0.3604, validation loss: 0.2042
2024-05-25 01:57:23 [INFO]: Epoch 043 - training loss: 0.3581, validation loss: 0.2022
2024-05-25 01:57:26 [INFO]: Epoch 044 - training loss: 0.3551, validation loss: 0.1994
2024-05-25 01:57:29 [INFO]: Epoch 045 - training loss: 0.3525, validation loss: 0.1973
2024-05-25 01:57:31 [INFO]: Epoch 046 - training loss: 0.3507, validation loss: 0.1954
2024-05-25 01:57:34 [INFO]: Epoch 047 - training loss: 0.3477, validation loss: 0.1933
2024-05-25 01:57:37 [INFO]: Epoch 048 - training loss: 0.3448, validation loss: 0.1915
2024-05-25 01:57:40 [INFO]: Epoch 049 - training loss: 0.3414, validation loss: 0.1897
2024-05-25 01:57:43 [INFO]: Epoch 050 - training loss: 0.3411, validation loss: 0.1882
2024-05-25 01:57:45 [INFO]: Epoch 051 - training loss: 0.3372, validation loss: 0.1858
2024-05-25 01:57:48 [INFO]: Epoch 052 - training loss: 0.3344, validation loss: 0.1845
2024-05-25 01:57:51 [INFO]: Epoch 053 - training loss: 0.3331, validation loss: 0.1835
2024-05-25 01:57:54 [INFO]: Epoch 054 - training loss: 0.3313, validation loss: 0.1818
2024-05-25 01:57:56 [INFO]: Epoch 055 - training loss: 0.3285, validation loss: 0.1804
2024-05-25 01:57:59 [INFO]: Epoch 056 - training loss: 0.3273, validation loss: 0.1792
2024-05-25 01:58:02 [INFO]: Epoch 057 - training loss: 0.3252, validation loss: 0.1779
2024-05-25 01:58:05 [INFO]: Epoch 058 - training loss: 0.3237, validation loss: 0.1768
2024-05-25 01:58:07 [INFO]: Epoch 059 - training loss: 0.3216, validation loss: 0.1759
2024-05-25 01:58:10 [INFO]: Epoch 060 - training loss: 0.3204, validation loss: 0.1747
2024-05-25 01:58:13 [INFO]: Epoch 061 - training loss: 0.3186, validation loss: 0.1738
2024-05-25 01:58:16 [INFO]: Epoch 062 - training loss: 0.3170, validation loss: 0.1728
2024-05-25 01:58:18 [INFO]: Epoch 063 - training loss: 0.3155, validation loss: 0.1720
2024-05-25 01:58:21 [INFO]: Epoch 064 - training loss: 0.3143, validation loss: 0.1714
2024-05-25 01:58:24 [INFO]: Epoch 065 - training loss: 0.3122, validation loss: 0.1702
2024-05-25 01:58:27 [INFO]: Epoch 066 - training loss: 0.3111, validation loss: 0.1694
2024-05-25 01:58:29 [INFO]: Epoch 067 - training loss: 0.3098, validation loss: 0.1686
2024-05-25 01:58:32 [INFO]: Epoch 068 - training loss: 0.3090, validation loss: 0.1679
2024-05-25 01:58:35 [INFO]: Epoch 069 - training loss: 0.3069, validation loss: 0.1672
2024-05-25 01:58:38 [INFO]: Epoch 070 - training loss: 0.3059, validation loss: 0.1664
2024-05-25 01:58:40 [INFO]: Epoch 071 - training loss: 0.3045, validation loss: 0.1657
2024-05-25 01:58:43 [INFO]: Epoch 072 - training loss: 0.3033, validation loss: 0.1650
2024-05-25 01:58:46 [INFO]: Epoch 073 - training loss: 0.3026, validation loss: 0.1643
2024-05-25 01:58:49 [INFO]: Epoch 074 - training loss: 0.3011, validation loss: 0.1636
2024-05-25 01:58:51 [INFO]: Epoch 075 - training loss: 0.3003, validation loss: 0.1631
2024-05-25 01:58:54 [INFO]: Epoch 076 - training loss: 0.2992, validation loss: 0.1624
2024-05-25 01:58:57 [INFO]: Epoch 077 - training loss: 0.2979, validation loss: 0.1617
2024-05-25 01:59:00 [INFO]: Epoch 078 - training loss: 0.2975, validation loss: 0.1612
2024-05-25 01:59:02 [INFO]: Epoch 079 - training loss: 0.2959, validation loss: 0.1607
2024-05-25 01:59:05 [INFO]: Epoch 080 - training loss: 0.2955, validation loss: 0.1599
2024-05-25 01:59:08 [INFO]: Epoch 081 - training loss: 0.2937, validation loss: 0.1593
2024-05-25 01:59:11 [INFO]: Epoch 082 - training loss: 0.2934, validation loss: 0.1588
2024-05-25 01:59:13 [INFO]: Epoch 083 - training loss: 0.2931, validation loss: 0.1583
2024-05-25 01:59:16 [INFO]: Epoch 084 - training loss: 0.2918, validation loss: 0.1578
2024-05-25 01:59:19 [INFO]: Epoch 085 - training loss: 0.2906, validation loss: 0.1571
2024-05-25 01:59:22 [INFO]: Epoch 086 - training loss: 0.2904, validation loss: 0.1565
2024-05-25 01:59:24 [INFO]: Epoch 087 - training loss: 0.2892, validation loss: 0.1561
2024-05-25 01:59:27 [INFO]: Epoch 088 - training loss: 0.2879, validation loss: 0.1557
2024-05-25 01:59:30 [INFO]: Epoch 089 - training loss: 0.2875, validation loss: 0.1554
2024-05-25 01:59:33 [INFO]: Epoch 090 - training loss: 0.2873, validation loss: 0.1548
2024-05-25 01:59:35 [INFO]: Epoch 091 - training loss: 0.2866, validation loss: 0.1543
2024-05-25 01:59:38 [INFO]: Epoch 092 - training loss: 0.2851, validation loss: 0.1537
2024-05-25 01:59:41 [INFO]: Epoch 093 - training loss: 0.2847, validation loss: 0.1534
2024-05-25 01:59:44 [INFO]: Epoch 094 - training loss: 0.2840, validation loss: 0.1529
2024-05-25 01:59:47 [INFO]: Epoch 095 - training loss: 0.2838, validation loss: 0.1524
2024-05-25 01:59:49 [INFO]: Epoch 096 - training loss: 0.2831, validation loss: 0.1522
2024-05-25 01:59:52 [INFO]: Epoch 097 - training loss: 0.2827, validation loss: 0.1515
2024-05-25 01:59:55 [INFO]: Epoch 098 - training loss: 0.2817, validation loss: 0.1511
2024-05-25 01:59:58 [INFO]: Epoch 099 - training loss: 0.2808, validation loss: 0.1508
2024-05-25 02:00:01 [INFO]: Epoch 100 - training loss: 0.2803, validation loss: 0.1501
2024-05-25 02:00:03 [INFO]: Epoch 101 - training loss: 0.2794, validation loss: 0.1495
2024-05-25 02:00:06 [INFO]: Epoch 102 - training loss: 0.2789, validation loss: 0.1492
2024-05-25 02:00:09 [INFO]: Epoch 103 - training loss: 0.2785, validation loss: 0.1487
2024-05-25 02:00:12 [INFO]: Epoch 104 - training loss: 0.2779, validation loss: 0.1484
2024-05-25 02:00:14 [INFO]: Epoch 105 - training loss: 0.2771, validation loss: 0.1479
2024-05-25 02:00:17 [INFO]: Epoch 106 - training loss: 0.2765, validation loss: 0.1475
2024-05-25 02:00:20 [INFO]: Epoch 107 - training loss: 0.2760, validation loss: 0.1470
2024-05-25 02:00:23 [INFO]: Epoch 108 - training loss: 0.2755, validation loss: 0.1468
2024-05-25 02:00:25 [INFO]: Epoch 109 - training loss: 0.2749, validation loss: 0.1465
2024-05-25 02:00:28 [INFO]: Epoch 110 - training loss: 0.2741, validation loss: 0.1457
2024-05-25 02:00:31 [INFO]: Epoch 111 - training loss: 0.2737, validation loss: 0.1454
2024-05-25 02:00:34 [INFO]: Epoch 112 - training loss: 0.2727, validation loss: 0.1451
2024-05-25 02:00:36 [INFO]: Epoch 113 - training loss: 0.2728, validation loss: 0.1448
2024-05-25 02:00:39 [INFO]: Epoch 114 - training loss: 0.2719, validation loss: 0.1443
2024-05-25 02:00:42 [INFO]: Epoch 115 - training loss: 0.2717, validation loss: 0.1441
2024-05-25 02:00:45 [INFO]: Epoch 116 - training loss: 0.2709, validation loss: 0.1437
2024-05-25 02:00:47 [INFO]: Epoch 117 - training loss: 0.2711, validation loss: 0.1433
2024-05-25 02:00:50 [INFO]: Epoch 118 - training loss: 0.2702, validation loss: 0.1431
2024-05-25 02:00:53 [INFO]: Epoch 119 - training loss: 0.2694, validation loss: 0.1427
2024-05-25 02:00:56 [INFO]: Epoch 120 - training loss: 0.2689, validation loss: 0.1422
2024-05-25 02:00:58 [INFO]: Epoch 121 - training loss: 0.2687, validation loss: 0.1418
2024-05-25 02:01:01 [INFO]: Epoch 122 - training loss: 0.2678, validation loss: 0.1417
2024-05-25 02:01:04 [INFO]: Epoch 123 - training loss: 0.2682, validation loss: 0.1411
2024-05-25 02:01:07 [INFO]: Epoch 124 - training loss: 0.2676, validation loss: 0.1410
2024-05-25 02:01:09 [INFO]: Epoch 125 - training loss: 0.2663, validation loss: 0.1405
2024-05-25 02:01:12 [INFO]: Epoch 126 - training loss: 0.2661, validation loss: 0.1403
2024-05-25 02:01:15 [INFO]: Epoch 127 - training loss: 0.2659, validation loss: 0.1399
2024-05-25 02:01:18 [INFO]: Epoch 128 - training loss: 0.2654, validation loss: 0.1395
2024-05-25 02:01:20 [INFO]: Epoch 129 - training loss: 0.2647, validation loss: 0.1391
2024-05-25 02:01:23 [INFO]: Epoch 130 - training loss: 0.2645, validation loss: 0.1390
2024-05-25 02:01:26 [INFO]: Epoch 131 - training loss: 0.2640, validation loss: 0.1387
2024-05-25 02:01:29 [INFO]: Epoch 132 - training loss: 0.2640, validation loss: 0.1385
2024-05-25 02:01:31 [INFO]: Epoch 133 - training loss: 0.2631, validation loss: 0.1380
2024-05-25 02:01:34 [INFO]: Epoch 134 - training loss: 0.2634, validation loss: 0.1375
2024-05-25 02:01:37 [INFO]: Epoch 135 - training loss: 0.2627, validation loss: 0.1375
2024-05-25 02:01:40 [INFO]: Epoch 136 - training loss: 0.2623, validation loss: 0.1368
2024-05-25 02:01:43 [INFO]: Epoch 137 - training loss: 0.2622, validation loss: 0.1367
2024-05-25 02:01:45 [INFO]: Epoch 138 - training loss: 0.2610, validation loss: 0.1367
2024-05-25 02:01:48 [INFO]: Epoch 139 - training loss: 0.2610, validation loss: 0.1363
2024-05-25 02:01:51 [INFO]: Epoch 140 - training loss: 0.2604, validation loss: 0.1358
2024-05-25 02:01:54 [INFO]: Epoch 141 - training loss: 0.2603, validation loss: 0.1356
2024-05-25 02:01:56 [INFO]: Epoch 142 - training loss: 0.2597, validation loss: 0.1354
2024-05-25 02:01:59 [INFO]: Epoch 143 - training loss: 0.2591, validation loss: 0.1354
2024-05-25 02:02:02 [INFO]: Epoch 144 - training loss: 0.2594, validation loss: 0.1349
2024-05-25 02:02:05 [INFO]: Epoch 145 - training loss: 0.2595, validation loss: 0.1348
2024-05-25 02:02:07 [INFO]: Epoch 146 - training loss: 0.2582, validation loss: 0.1344
2024-05-25 02:02:10 [INFO]: Epoch 147 - training loss: 0.2587, validation loss: 0.1342
2024-05-25 02:02:13 [INFO]: Epoch 148 - training loss: 0.2575, validation loss: 0.1338
2024-05-25 02:02:16 [INFO]: Epoch 149 - training loss: 0.2572, validation loss: 0.1336
2024-05-25 02:02:18 [INFO]: Epoch 150 - training loss: 0.2569, validation loss: 0.1332
2024-05-25 02:02:21 [INFO]: Epoch 151 - training loss: 0.2568, validation loss: 0.1331
2024-05-25 02:02:24 [INFO]: Epoch 152 - training loss: 0.2561, validation loss: 0.1329
2024-05-25 02:02:27 [INFO]: Epoch 153 - training loss: 0.2561, validation loss: 0.1329
2024-05-25 02:02:29 [INFO]: Epoch 154 - training loss: 0.2561, validation loss: 0.1324
2024-05-25 02:02:32 [INFO]: Epoch 155 - training loss: 0.2552, validation loss: 0.1323
2024-05-25 02:02:35 [INFO]: Epoch 156 - training loss: 0.2550, validation loss: 0.1321
2024-05-25 02:02:38 [INFO]: Epoch 157 - training loss: 0.2543, validation loss: 0.1316
2024-05-25 02:02:40 [INFO]: Epoch 158 - training loss: 0.2549, validation loss: 0.1316
2024-05-25 02:02:43 [INFO]: Epoch 159 - training loss: 0.2544, validation loss: 0.1313
2024-05-25 02:02:46 [INFO]: Epoch 160 - training loss: 0.2540, validation loss: 0.1309
2024-05-25 02:02:49 [INFO]: Epoch 161 - training loss: 0.2541, validation loss: 0.1310
2024-05-25 02:02:51 [INFO]: Epoch 162 - training loss: 0.2536, validation loss: 0.1306
2024-05-25 02:02:54 [INFO]: Epoch 163 - training loss: 0.2525, validation loss: 0.1307
2024-05-25 02:02:57 [INFO]: Epoch 164 - training loss: 0.2530, validation loss: 0.1301
2024-05-25 02:03:00 [INFO]: Epoch 165 - training loss: 0.2525, validation loss: 0.1300
2024-05-25 02:03:03 [INFO]: Epoch 166 - training loss: 0.2520, validation loss: 0.1301
2024-05-25 02:03:05 [INFO]: Epoch 167 - training loss: 0.2517, validation loss: 0.1295
2024-05-25 02:03:08 [INFO]: Epoch 168 - training loss: 0.2515, validation loss: 0.1296
2024-05-25 02:03:11 [INFO]: Epoch 169 - training loss: 0.2513, validation loss: 0.1292
2024-05-25 02:03:14 [INFO]: Epoch 170 - training loss: 0.2507, validation loss: 0.1291
2024-05-25 02:03:17 [INFO]: Epoch 171 - training loss: 0.2503, validation loss: 0.1291
2024-05-25 02:03:19 [INFO]: Epoch 172 - training loss: 0.2507, validation loss: 0.1287
2024-05-25 02:03:22 [INFO]: Epoch 173 - training loss: 0.2503, validation loss: 0.1286
2024-05-25 02:03:25 [INFO]: Epoch 174 - training loss: 0.2498, validation loss: 0.1283
2024-05-25 02:03:28 [INFO]: Epoch 175 - training loss: 0.2500, validation loss: 0.1284
2024-05-25 02:03:30 [INFO]: Epoch 176 - training loss: 0.2494, validation loss: 0.1279
2024-05-25 02:03:33 [INFO]: Epoch 177 - training loss: 0.2489, validation loss: 0.1277
2024-05-25 02:03:36 [INFO]: Epoch 178 - training loss: 0.2484, validation loss: 0.1277
2024-05-25 02:03:39 [INFO]: Epoch 179 - training loss: 0.2482, validation loss: 0.1273
2024-05-25 02:03:41 [INFO]: Epoch 180 - training loss: 0.2483, validation loss: 0.1272
2024-05-25 02:03:44 [INFO]: Epoch 181 - training loss: 0.2480, validation loss: 0.1271
2024-05-25 02:03:47 [INFO]: Epoch 182 - training loss: 0.2478, validation loss: 0.1271
2024-05-25 02:03:50 [INFO]: Epoch 183 - training loss: 0.2473, validation loss: 0.1272
2024-05-25 02:03:53 [INFO]: Epoch 184 - training loss: 0.2475, validation loss: 0.1267
2024-05-25 02:03:55 [INFO]: Epoch 185 - training loss: 0.2469, validation loss: 0.1266
2024-05-25 02:03:58 [INFO]: Epoch 186 - training loss: 0.2470, validation loss: 0.1264
2024-05-25 02:04:01 [INFO]: Epoch 187 - training loss: 0.2470, validation loss: 0.1261
2024-05-25 02:04:04 [INFO]: Epoch 188 - training loss: 0.2467, validation loss: 0.1262
2024-05-25 02:04:06 [INFO]: Epoch 189 - training loss: 0.2468, validation loss: 0.1258
2024-05-25 02:04:09 [INFO]: Epoch 190 - training loss: 0.2461, validation loss: 0.1257
2024-05-25 02:04:12 [INFO]: Epoch 191 - training loss: 0.2461, validation loss: 0.1255
2024-05-25 02:04:15 [INFO]: Epoch 192 - training loss: 0.2453, validation loss: 0.1255
2024-05-25 02:04:17 [INFO]: Epoch 193 - training loss: 0.2453, validation loss: 0.1253
2024-05-25 02:04:20 [INFO]: Epoch 194 - training loss: 0.2454, validation loss: 0.1250
2024-05-25 02:04:23 [INFO]: Epoch 195 - training loss: 0.2453, validation loss: 0.1250
2024-05-25 02:04:26 [INFO]: Epoch 196 - training loss: 0.2448, validation loss: 0.1250
2024-05-25 02:04:28 [INFO]: Epoch 197 - training loss: 0.2446, validation loss: 0.1247
2024-05-25 02:04:31 [INFO]: Epoch 198 - training loss: 0.2442, validation loss: 0.1246
2024-05-25 02:04:34 [INFO]: Epoch 199 - training loss: 0.2442, validation loss: 0.1246
2024-05-25 02:04:37 [INFO]: Epoch 200 - training loss: 0.2447, validation loss: 0.1245
2024-05-25 02:04:40 [INFO]: Epoch 201 - training loss: 0.2439, validation loss: 0.1242
2024-05-25 02:04:42 [INFO]: Epoch 202 - training loss: 0.2430, validation loss: 0.1240
2024-05-25 02:04:45 [INFO]: Epoch 203 - training loss: 0.2438, validation loss: 0.1237
2024-05-25 02:04:48 [INFO]: Epoch 204 - training loss: 0.2430, validation loss: 0.1238
2024-05-25 02:04:51 [INFO]: Epoch 205 - training loss: 0.2430, validation loss: 0.1237
2024-05-25 02:04:53 [INFO]: Epoch 206 - training loss: 0.2434, validation loss: 0.1235
2024-05-25 02:04:56 [INFO]: Epoch 207 - training loss: 0.2426, validation loss: 0.1234
2024-05-25 02:04:59 [INFO]: Epoch 208 - training loss: 0.2425, validation loss: 0.1234
2024-05-25 02:05:02 [INFO]: Epoch 209 - training loss: 0.2423, validation loss: 0.1232
2024-05-25 02:05:04 [INFO]: Epoch 210 - training loss: 0.2422, validation loss: 0.1230
2024-05-25 02:05:07 [INFO]: Epoch 211 - training loss: 0.2419, validation loss: 0.1228
2024-05-25 02:05:10 [INFO]: Epoch 212 - training loss: 0.2415, validation loss: 0.1229
2024-05-25 02:05:13 [INFO]: Epoch 213 - training loss: 0.2417, validation loss: 0.1228
2024-05-25 02:05:15 [INFO]: Epoch 214 - training loss: 0.2411, validation loss: 0.1226
2024-05-25 02:05:18 [INFO]: Epoch 215 - training loss: 0.2413, validation loss: 0.1226
2024-05-25 02:05:21 [INFO]: Epoch 216 - training loss: 0.2405, validation loss: 0.1224
2024-05-25 02:05:24 [INFO]: Epoch 217 - training loss: 0.2410, validation loss: 0.1222
2024-05-25 02:05:26 [INFO]: Epoch 218 - training loss: 0.2402, validation loss: 0.1220
2024-05-25 02:05:29 [INFO]: Epoch 219 - training loss: 0.2402, validation loss: 0.1221
2024-05-25 02:05:32 [INFO]: Epoch 220 - training loss: 0.2401, validation loss: 0.1221
2024-05-25 02:05:35 [INFO]: Epoch 221 - training loss: 0.2402, validation loss: 0.1218
2024-05-25 02:05:37 [INFO]: Epoch 222 - training loss: 0.2400, validation loss: 0.1218
2024-05-25 02:05:40 [INFO]: Epoch 223 - training loss: 0.2394, validation loss: 0.1216
2024-05-25 02:05:43 [INFO]: Epoch 224 - training loss: 0.2395, validation loss: 0.1214
2024-05-25 02:05:46 [INFO]: Epoch 225 - training loss: 0.2395, validation loss: 0.1214
2024-05-25 02:05:49 [INFO]: Epoch 226 - training loss: 0.2387, validation loss: 0.1214
2024-05-25 02:05:51 [INFO]: Epoch 227 - training loss: 0.2386, validation loss: 0.1212
2024-05-25 02:05:54 [INFO]: Epoch 228 - training loss: 0.2389, validation loss: 0.1213
2024-05-25 02:05:57 [INFO]: Epoch 229 - training loss: 0.2385, validation loss: 0.1212
2024-05-25 02:06:00 [INFO]: Epoch 230 - training loss: 0.2385, validation loss: 0.1210
2024-05-25 02:06:02 [INFO]: Epoch 231 - training loss: 0.2390, validation loss: 0.1210
2024-05-25 02:06:05 [INFO]: Epoch 232 - training loss: 0.2384, validation loss: 0.1208
2024-05-25 02:06:08 [INFO]: Epoch 233 - training loss: 0.2387, validation loss: 0.1206
2024-05-25 02:06:11 [INFO]: Epoch 234 - training loss: 0.2379, validation loss: 0.1207
2024-05-25 02:06:14 [INFO]: Epoch 235 - training loss: 0.2377, validation loss: 0.1206
2024-05-25 02:06:16 [INFO]: Epoch 236 - training loss: 0.2376, validation loss: 0.1204
2024-05-25 02:06:19 [INFO]: Epoch 237 - training loss: 0.2375, validation loss: 0.1206
2024-05-25 02:06:22 [INFO]: Epoch 238 - training loss: 0.2373, validation loss: 0.1203
2024-05-25 02:06:25 [INFO]: Epoch 239 - training loss: 0.2376, validation loss: 0.1200
2024-05-25 02:06:27 [INFO]: Epoch 240 - training loss: 0.2370, validation loss: 0.1202
2024-05-25 02:06:30 [INFO]: Epoch 241 - training loss: 0.2369, validation loss: 0.1200
2024-05-25 02:06:33 [INFO]: Epoch 242 - training loss: 0.2369, validation loss: 0.1199
2024-05-25 02:06:36 [INFO]: Epoch 243 - training loss: 0.2371, validation loss: 0.1201
2024-05-25 02:06:38 [INFO]: Epoch 244 - training loss: 0.2361, validation loss: 0.1198
2024-05-25 02:06:41 [INFO]: Epoch 245 - training loss: 0.2359, validation loss: 0.1198
2024-05-25 02:06:44 [INFO]: Epoch 246 - training loss: 0.2365, validation loss: 0.1196
2024-05-25 02:06:47 [INFO]: Epoch 247 - training loss: 0.2360, validation loss: 0.1196
2024-05-25 02:06:49 [INFO]: Epoch 248 - training loss: 0.2357, validation loss: 0.1194
2024-05-25 02:06:52 [INFO]: Epoch 249 - training loss: 0.2355, validation loss: 0.1196
2024-05-25 02:06:55 [INFO]: Epoch 250 - training loss: 0.2353, validation loss: 0.1191
2024-05-25 02:06:58 [INFO]: Epoch 251 - training loss: 0.2352, validation loss: 0.1192
2024-05-25 02:07:00 [INFO]: Epoch 252 - training loss: 0.2352, validation loss: 0.1192
2024-05-25 02:07:03 [INFO]: Epoch 253 - training loss: 0.2351, validation loss: 0.1189
2024-05-25 02:07:06 [INFO]: Epoch 254 - training loss: 0.2351, validation loss: 0.1190
2024-05-25 02:07:09 [INFO]: Epoch 255 - training loss: 0.2349, validation loss: 0.1190
2024-05-25 02:07:12 [INFO]: Epoch 256 - training loss: 0.2353, validation loss: 0.1190
2024-05-25 02:07:14 [INFO]: Epoch 257 - training loss: 0.2345, validation loss: 0.1188
2024-05-25 02:07:17 [INFO]: Epoch 258 - training loss: 0.2345, validation loss: 0.1186
2024-05-25 02:07:20 [INFO]: Epoch 259 - training loss: 0.2349, validation loss: 0.1188
2024-05-25 02:07:23 [INFO]: Epoch 260 - training loss: 0.2341, validation loss: 0.1187
2024-05-25 02:07:25 [INFO]: Epoch 261 - training loss: 0.2345, validation loss: 0.1185
2024-05-25 02:07:28 [INFO]: Epoch 262 - training loss: 0.2340, validation loss: 0.1184
2024-05-25 02:07:31 [INFO]: Epoch 263 - training loss: 0.2333, validation loss: 0.1186
2024-05-25 02:07:34 [INFO]: Epoch 264 - training loss: 0.2333, validation loss: 0.1185
2024-05-25 02:07:36 [INFO]: Epoch 265 - training loss: 0.2336, validation loss: 0.1182
2024-05-25 02:07:39 [INFO]: Epoch 266 - training loss: 0.2332, validation loss: 0.1182
2024-05-25 02:07:42 [INFO]: Epoch 267 - training loss: 0.2336, validation loss: 0.1182
2024-05-25 02:07:45 [INFO]: Epoch 268 - training loss: 0.2331, validation loss: 0.1182
2024-05-25 02:07:47 [INFO]: Epoch 269 - training loss: 0.2337, validation loss: 0.1180
2024-05-25 02:07:50 [INFO]: Epoch 270 - training loss: 0.2329, validation loss: 0.1180
2024-05-25 02:07:53 [INFO]: Epoch 271 - training loss: 0.2327, validation loss: 0.1178
2024-05-25 02:07:56 [INFO]: Epoch 272 - training loss: 0.2322, validation loss: 0.1180
2024-05-25 02:07:59 [INFO]: Epoch 273 - training loss: 0.2327, validation loss: 0.1179
2024-05-25 02:08:01 [INFO]: Epoch 274 - training loss: 0.2332, validation loss: 0.1176
2024-05-25 02:08:04 [INFO]: Epoch 275 - training loss: 0.2324, validation loss: 0.1179
2024-05-25 02:08:07 [INFO]: Epoch 276 - training loss: 0.2320, validation loss: 0.1175
2024-05-25 02:08:10 [INFO]: Epoch 277 - training loss: 0.2323, validation loss: 0.1177
2024-05-25 02:08:12 [INFO]: Epoch 278 - training loss: 0.2317, validation loss: 0.1175
2024-05-25 02:08:15 [INFO]: Epoch 279 - training loss: 0.2315, validation loss: 0.1175
2024-05-25 02:08:18 [INFO]: Epoch 280 - training loss: 0.2316, validation loss: 0.1177
2024-05-25 02:08:21 [INFO]: Epoch 281 - training loss: 0.2322, validation loss: 0.1175
2024-05-25 02:08:23 [INFO]: Epoch 282 - training loss: 0.2318, validation loss: 0.1174
2024-05-25 02:08:26 [INFO]: Epoch 283 - training loss: 0.2315, validation loss: 0.1173
2024-05-25 02:08:29 [INFO]: Epoch 284 - training loss: 0.2316, validation loss: 0.1172
2024-05-25 02:08:32 [INFO]: Epoch 285 - training loss: 0.2308, validation loss: 0.1173
2024-05-25 02:08:34 [INFO]: Epoch 286 - training loss: 0.2307, validation loss: 0.1173
2024-05-25 02:08:37 [INFO]: Epoch 287 - training loss: 0.2309, validation loss: 0.1169
2024-05-25 02:08:40 [INFO]: Epoch 288 - training loss: 0.2305, validation loss: 0.1171
2024-05-25 02:08:43 [INFO]: Epoch 289 - training loss: 0.2307, validation loss: 0.1168
2024-05-25 02:08:45 [INFO]: Epoch 290 - training loss: 0.2304, validation loss: 0.1169
2024-05-25 02:08:48 [INFO]: Epoch 291 - training loss: 0.2298, validation loss: 0.1171
2024-05-25 02:08:51 [INFO]: Epoch 292 - training loss: 0.2305, validation loss: 0.1169
2024-05-25 02:08:54 [INFO]: Epoch 293 - training loss: 0.2305, validation loss: 0.1166
2024-05-25 02:08:57 [INFO]: Epoch 294 - training loss: 0.2303, validation loss: 0.1169
2024-05-25 02:08:59 [INFO]: Epoch 295 - training loss: 0.2303, validation loss: 0.1166
2024-05-25 02:09:02 [INFO]: Epoch 296 - training loss: 0.2297, validation loss: 0.1166
2024-05-25 02:09:05 [INFO]: Epoch 297 - training loss: 0.2295, validation loss: 0.1168
2024-05-25 02:09:08 [INFO]: Epoch 298 - training loss: 0.2301, validation loss: 0.1165
2024-05-25 02:09:10 [INFO]: Epoch 299 - training loss: 0.2295, validation loss: 0.1167
2024-05-25 02:09:13 [INFO]: Epoch 300 - training loss: 0.2296, validation loss: 0.1165
2024-05-25 02:09:13 [INFO]: Finished training. The best model is from epoch#300.
2024-05-25 02:09:13 [INFO]: Saved the model to augmentation_saved_results/round_0/BRITS_air_quality/20240525_T015524/BRITS.pypots
2024-05-25 02:09:14 [INFO]: BRITS on Air-Quality: MAE=0.1540, MSE=0.1657
2024-05-25 02:09:14 [INFO]: Successfully saved to augmentation_saved_results/round_0/BRITS_air_quality/imputation.pkl
2024-05-25 02:09:14 [INFO]: Using the given device: cuda:0
2024-05-25 02:09:14 [INFO]: Model files will be saved to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914
2024-05-25 02:09:14 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/tensorboard
2024-05-25 02:09:14 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 02:09:19 [INFO]: Epoch 001 - training loss: 1.5118, validation loss: 0.7887
2024-05-25 02:09:19 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch1_loss0.7886669605970382.pypots
2024-05-25 02:09:22 [INFO]: Epoch 002 - training loss: 1.0565, validation loss: 0.7416
2024-05-25 02:09:22 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch2_loss0.741589629650116.pypots
2024-05-25 02:09:26 [INFO]: Epoch 003 - training loss: 0.9716, validation loss: 0.7251
2024-05-25 02:09:26 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch3_loss0.72513148188591.pypots
2024-05-25 02:09:30 [INFO]: Epoch 004 - training loss: 0.9641, validation loss: 0.7134
2024-05-25 02:09:30 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch4_loss0.7133851200342178.pypots
2024-05-25 02:09:34 [INFO]: Epoch 005 - training loss: 0.9322, validation loss: 0.7043
2024-05-25 02:09:34 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch5_loss0.7043404042720794.pypots
2024-05-25 02:09:38 [INFO]: Epoch 006 - training loss: 0.9453, validation loss: 0.6989
2024-05-25 02:09:38 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch6_loss0.6988731324672699.pypots
2024-05-25 02:09:41 [INFO]: Epoch 007 - training loss: 0.9167, validation loss: 0.6947
2024-05-25 02:09:41 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch7_loss0.6947253674268723.pypots
2024-05-25 02:09:45 [INFO]: Epoch 008 - training loss: 0.9399, validation loss: 0.6911
2024-05-25 02:09:45 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch8_loss0.6910560518503189.pypots
2024-05-25 02:09:49 [INFO]: Epoch 009 - training loss: 0.9240, validation loss: 0.6882
2024-05-25 02:09:49 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch9_loss0.6882349759340286.pypots
2024-05-25 02:09:53 [INFO]: Epoch 010 - training loss: 0.9246, validation loss: 0.6874
2024-05-25 02:09:53 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch10_loss0.6873847037553787.pypots
2024-05-25 02:09:57 [INFO]: Epoch 011 - training loss: 0.9216, validation loss: 0.6850
2024-05-25 02:09:57 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch11_loss0.6849981397390366.pypots
2024-05-25 02:10:01 [INFO]: Epoch 012 - training loss: 0.9263, validation loss: 0.6836
2024-05-25 02:10:01 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch12_loss0.6836222857236862.pypots
2024-05-25 02:10:04 [INFO]: Epoch 013 - training loss: 0.9184, validation loss: 0.6831
2024-05-25 02:10:04 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch13_loss0.6831391721963882.pypots
2024-05-25 02:10:08 [INFO]: Epoch 014 - training loss: 0.9017, validation loss: 0.6816
2024-05-25 02:10:08 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch14_loss0.6816479682922363.pypots
2024-05-25 02:10:12 [INFO]: Epoch 015 - training loss: 0.9090, validation loss: 0.6827
2024-05-25 02:10:12 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch15_loss0.6826810568571091.pypots
2024-05-25 02:10:16 [INFO]: Epoch 016 - training loss: 0.9092, validation loss: 0.6818
2024-05-25 02:10:16 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch16_loss0.681775164604187.pypots
2024-05-25 02:10:20 [INFO]: Epoch 017 - training loss: 0.8915, validation loss: 0.6825
2024-05-25 02:10:20 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch17_loss0.6824650138616561.pypots
2024-05-25 02:10:24 [INFO]: Epoch 018 - training loss: 0.8971, validation loss: 0.6820
2024-05-25 02:10:24 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch18_loss0.6819977581501007.pypots
2024-05-25 02:10:27 [INFO]: Epoch 019 - training loss: 0.8853, validation loss: 0.6838
2024-05-25 02:10:27 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch19_loss0.68376305103302.pypots
2024-05-25 02:10:31 [INFO]: Epoch 020 - training loss: 0.8910, validation loss: 0.6848
2024-05-25 02:10:31 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch20_loss0.6848256349563598.pypots
2024-05-25 02:10:35 [INFO]: Epoch 021 - training loss: 0.8800, validation loss: 0.6851
2024-05-25 02:10:35 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch21_loss0.6850681066513061.pypots
2024-05-25 02:10:39 [INFO]: Epoch 022 - training loss: 0.8969, validation loss: 0.6854
2024-05-25 02:10:39 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch22_loss0.6854216068983078.pypots
2024-05-25 02:10:43 [INFO]: Epoch 023 - training loss: 0.8913, validation loss: 0.6832
2024-05-25 02:10:43 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch23_loss0.6832360655069352.pypots
2024-05-25 02:10:47 [INFO]: Epoch 024 - training loss: 0.8904, validation loss: 0.6876
2024-05-25 02:10:47 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN_epoch24_loss0.6875857084989547.pypots
2024-05-25 02:10:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:10:47 [INFO]: Finished training. The best model is from epoch#14.
2024-05-25 02:10:47 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240525_T020914/MRNN.pypots
2024-05-25 02:10:47 [INFO]: MRNN on Air-Quality: MAE=0.5281, MSE=0.7025
2024-05-25 02:10:47 [INFO]: Successfully saved to augmentation_saved_results/round_0/MRNN_air_quality/imputation.pkl
2024-05-25 02:10:47 [INFO]: Using the given device: cpu
2024-05-25 02:10:47 [INFO]: LOCF on Air-Quality: MAE=0.2206, MSE=0.3343
2024-05-25 02:10:47 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_air_quality".
2024-05-25 02:10:47 [INFO]: Successfully saved to augmentation_saved_results/round_0/LOCF_air_quality/imputation.pkl
2024-05-25 02:10:48 [INFO]: Median on Air-Quality: MAE=0.6668, MSE=1.0938
2024-05-25 02:10:48 [INFO]: Successfully created the given path "saved_results/round_0/Median_air_quality".
2024-05-25 02:10:48 [INFO]: Successfully saved to augmentation_saved_results/round_0/Median_air_quality/imputation.pkl
2024-05-25 02:10:48 [INFO]: Mean on Air-Quality: MAE=0.6965, MSE=1.0305
2024-05-25 02:10:48 [INFO]: Successfully created the given path "saved_results/round_0/Mean_air_quality".
2024-05-25 02:10:48 [INFO]: Successfully saved to augmentation_saved_results/round_0/Mean_air_quality/imputation.pkl
2024-05-25 02:10:48 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-25 02:10:48 [INFO]: Using the given device: cuda:0
2024-05-25 02:10:48 [INFO]: Model files will be saved to augmentation_saved_results/round_1/SAITS_air_quality/20240525_T021048
2024-05-25 02:10:48 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/SAITS_air_quality/20240525_T021048/tensorboard
2024-05-25 02:10:48 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 02:10:49 [INFO]: Epoch 001 - training loss: 1.0523, validation loss: 0.5284
2024-05-25 02:10:49 [INFO]: Epoch 002 - training loss: 0.7487, validation loss: 0.4107
2024-05-25 02:10:50 [INFO]: Epoch 003 - training loss: 0.6404, validation loss: 0.3399
2024-05-25 02:10:51 [INFO]: Epoch 004 - training loss: 0.5674, validation loss: 0.2933
2024-05-25 02:10:51 [INFO]: Epoch 005 - training loss: 0.5196, validation loss: 0.2649
2024-05-25 02:10:52 [INFO]: Epoch 006 - training loss: 0.4823, validation loss: 0.2508
2024-05-25 02:10:53 [INFO]: Epoch 007 - training loss: 0.4580, validation loss: 0.2407
2024-05-25 02:10:53 [INFO]: Epoch 008 - training loss: 0.4397, validation loss: 0.2348
2024-05-25 02:10:54 [INFO]: Epoch 009 - training loss: 0.4272, validation loss: 0.2277
2024-05-25 02:10:55 [INFO]: Epoch 010 - training loss: 0.4143, validation loss: 0.2221
2024-05-25 02:10:55 [INFO]: Epoch 011 - training loss: 0.4049, validation loss: 0.2192
2024-05-25 02:10:56 [INFO]: Epoch 012 - training loss: 0.3965, validation loss: 0.2138
2024-05-25 02:10:57 [INFO]: Epoch 013 - training loss: 0.3883, validation loss: 0.2090
2024-05-25 02:10:57 [INFO]: Epoch 014 - training loss: 0.3823, validation loss: 0.2059
2024-05-25 02:10:58 [INFO]: Epoch 015 - training loss: 0.3757, validation loss: 0.2044
2024-05-25 02:10:59 [INFO]: Epoch 016 - training loss: 0.3702, validation loss: 0.2030
2024-05-25 02:10:59 [INFO]: Epoch 017 - training loss: 0.3650, validation loss: 0.1999
2024-05-25 02:11:00 [INFO]: Epoch 018 - training loss: 0.3615, validation loss: 0.1969
2024-05-25 02:11:01 [INFO]: Epoch 019 - training loss: 0.3570, validation loss: 0.1956
2024-05-25 02:11:01 [INFO]: Epoch 020 - training loss: 0.3546, validation loss: 0.1950
2024-05-25 02:11:02 [INFO]: Epoch 021 - training loss: 0.3499, validation loss: 0.1929
2024-05-25 02:11:03 [INFO]: Epoch 022 - training loss: 0.3454, validation loss: 0.1899
2024-05-25 02:11:03 [INFO]: Epoch 023 - training loss: 0.3427, validation loss: 0.1882
2024-05-25 02:11:04 [INFO]: Epoch 024 - training loss: 0.3414, validation loss: 0.1865
2024-05-25 02:11:05 [INFO]: Epoch 025 - training loss: 0.3380, validation loss: 0.1849
2024-05-25 02:11:05 [INFO]: Epoch 026 - training loss: 0.3342, validation loss: 0.1832
2024-05-25 02:11:06 [INFO]: Epoch 027 - training loss: 0.3314, validation loss: 0.1820
2024-05-25 02:11:07 [INFO]: Epoch 028 - training loss: 0.3279, validation loss: 0.1800
2024-05-25 02:11:07 [INFO]: Epoch 029 - training loss: 0.3257, validation loss: 0.1799
2024-05-25 02:11:08 [INFO]: Epoch 030 - training loss: 0.3240, validation loss: 0.1775
2024-05-25 02:11:09 [INFO]: Epoch 031 - training loss: 0.3250, validation loss: 0.1772
2024-05-25 02:11:09 [INFO]: Epoch 032 - training loss: 0.3188, validation loss: 0.1742
2024-05-25 02:11:10 [INFO]: Epoch 033 - training loss: 0.3169, validation loss: 0.1726
2024-05-25 02:11:11 [INFO]: Epoch 034 - training loss: 0.3155, validation loss: 0.1718
2024-05-25 02:11:11 [INFO]: Epoch 035 - training loss: 0.3129, validation loss: 0.1710
2024-05-25 02:11:12 [INFO]: Epoch 036 - training loss: 0.3135, validation loss: 0.1713
2024-05-25 02:11:13 [INFO]: Epoch 037 - training loss: 0.3126, validation loss: 0.1678
2024-05-25 02:11:13 [INFO]: Epoch 038 - training loss: 0.3109, validation loss: 0.1675
2024-05-25 02:11:14 [INFO]: Epoch 039 - training loss: 0.3076, validation loss: 0.1660
2024-05-25 02:11:15 [INFO]: Epoch 040 - training loss: 0.3047, validation loss: 0.1659
2024-05-25 02:11:15 [INFO]: Epoch 041 - training loss: 0.3030, validation loss: 0.1643
2024-05-25 02:11:16 [INFO]: Epoch 042 - training loss: 0.3013, validation loss: 0.1638
2024-05-25 02:11:17 [INFO]: Epoch 043 - training loss: 0.2995, validation loss: 0.1632
2024-05-25 02:11:17 [INFO]: Epoch 044 - training loss: 0.2991, validation loss: 0.1608
2024-05-25 02:11:18 [INFO]: Epoch 045 - training loss: 0.2965, validation loss: 0.1603
2024-05-25 02:11:19 [INFO]: Epoch 046 - training loss: 0.2948, validation loss: 0.1607
2024-05-25 02:11:19 [INFO]: Epoch 047 - training loss: 0.2948, validation loss: 0.1584
2024-05-25 02:11:20 [INFO]: Epoch 048 - training loss: 0.2938, validation loss: 0.1586
2024-05-25 02:11:21 [INFO]: Epoch 049 - training loss: 0.2918, validation loss: 0.1570
2024-05-25 02:11:21 [INFO]: Epoch 050 - training loss: 0.2892, validation loss: 0.1572
2024-05-25 02:11:22 [INFO]: Epoch 051 - training loss: 0.2883, validation loss: 0.1562
2024-05-25 02:11:23 [INFO]: Epoch 052 - training loss: 0.2890, validation loss: 0.1564
2024-05-25 02:11:23 [INFO]: Epoch 053 - training loss: 0.2858, validation loss: 0.1543
2024-05-25 02:11:24 [INFO]: Epoch 054 - training loss: 0.2831, validation loss: 0.1544
2024-05-25 02:11:25 [INFO]: Epoch 055 - training loss: 0.2827, validation loss: 0.1526
2024-05-25 02:11:25 [INFO]: Epoch 056 - training loss: 0.2811, validation loss: 0.1526
2024-05-25 02:11:26 [INFO]: Epoch 057 - training loss: 0.2813, validation loss: 0.1526
2024-05-25 02:11:27 [INFO]: Epoch 058 - training loss: 0.2806, validation loss: 0.1522
2024-05-25 02:11:27 [INFO]: Epoch 059 - training loss: 0.2772, validation loss: 0.1522
2024-05-25 02:11:28 [INFO]: Epoch 060 - training loss: 0.2767, validation loss: 0.1513
2024-05-25 02:11:29 [INFO]: Epoch 061 - training loss: 0.2749, validation loss: 0.1491
2024-05-25 02:11:29 [INFO]: Epoch 062 - training loss: 0.2736, validation loss: 0.1499
2024-05-25 02:11:30 [INFO]: Epoch 063 - training loss: 0.2728, validation loss: 0.1490
2024-05-25 02:11:31 [INFO]: Epoch 064 - training loss: 0.2727, validation loss: 0.1491
2024-05-25 02:11:31 [INFO]: Epoch 065 - training loss: 0.2708, validation loss: 0.1489
2024-05-25 02:11:32 [INFO]: Epoch 066 - training loss: 0.2712, validation loss: 0.1472
2024-05-25 02:11:33 [INFO]: Epoch 067 - training loss: 0.2689, validation loss: 0.1477
2024-05-25 02:11:34 [INFO]: Epoch 068 - training loss: 0.2677, validation loss: 0.1479
2024-05-25 02:11:34 [INFO]: Epoch 069 - training loss: 0.2675, validation loss: 0.1468
2024-05-25 02:11:35 [INFO]: Epoch 070 - training loss: 0.2661, validation loss: 0.1475
2024-05-25 02:11:36 [INFO]: Epoch 071 - training loss: 0.2646, validation loss: 0.1467
2024-05-25 02:11:36 [INFO]: Epoch 072 - training loss: 0.2643, validation loss: 0.1463
2024-05-25 02:11:37 [INFO]: Epoch 073 - training loss: 0.2628, validation loss: 0.1457
2024-05-25 02:11:38 [INFO]: Epoch 074 - training loss: 0.2637, validation loss: 0.1460
2024-05-25 02:11:38 [INFO]: Epoch 075 - training loss: 0.2620, validation loss: 0.1461
2024-05-25 02:11:39 [INFO]: Epoch 076 - training loss: 0.2606, validation loss: 0.1440
2024-05-25 02:11:40 [INFO]: Epoch 077 - training loss: 0.2600, validation loss: 0.1438
2024-05-25 02:11:40 [INFO]: Epoch 078 - training loss: 0.2598, validation loss: 0.1440
2024-05-25 02:11:41 [INFO]: Epoch 079 - training loss: 0.2579, validation loss: 0.1443
2024-05-25 02:11:42 [INFO]: Epoch 080 - training loss: 0.2581, validation loss: 0.1435
2024-05-25 02:11:42 [INFO]: Epoch 081 - training loss: 0.2571, validation loss: 0.1427
2024-05-25 02:11:43 [INFO]: Epoch 082 - training loss: 0.2586, validation loss: 0.1418
2024-05-25 02:11:44 [INFO]: Epoch 083 - training loss: 0.2565, validation loss: 0.1410
2024-05-25 02:11:44 [INFO]: Epoch 084 - training loss: 0.2552, validation loss: 0.1417
2024-05-25 02:11:45 [INFO]: Epoch 085 - training loss: 0.2535, validation loss: 0.1414
2024-05-25 02:11:46 [INFO]: Epoch 086 - training loss: 0.2543, validation loss: 0.1403
2024-05-25 02:11:46 [INFO]: Epoch 087 - training loss: 0.2549, validation loss: 0.1404
2024-05-25 02:11:47 [INFO]: Epoch 088 - training loss: 0.2536, validation loss: 0.1407
2024-05-25 02:11:48 [INFO]: Epoch 089 - training loss: 0.2529, validation loss: 0.1403
2024-05-25 02:11:48 [INFO]: Epoch 090 - training loss: 0.2516, validation loss: 0.1402
2024-05-25 02:11:49 [INFO]: Epoch 091 - training loss: 0.2501, validation loss: 0.1401
2024-05-25 02:11:50 [INFO]: Epoch 092 - training loss: 0.2503, validation loss: 0.1391
2024-05-25 02:11:50 [INFO]: Epoch 093 - training loss: 0.2494, validation loss: 0.1383
2024-05-25 02:11:51 [INFO]: Epoch 094 - training loss: 0.2493, validation loss: 0.1388
2024-05-25 02:11:52 [INFO]: Epoch 095 - training loss: 0.2473, validation loss: 0.1378
2024-05-25 02:11:52 [INFO]: Epoch 096 - training loss: 0.2472, validation loss: 0.1375
2024-05-25 02:11:53 [INFO]: Epoch 097 - training loss: 0.2464, validation loss: 0.1382
2024-05-25 02:11:54 [INFO]: Epoch 098 - training loss: 0.2456, validation loss: 0.1373
2024-05-25 02:11:54 [INFO]: Epoch 099 - training loss: 0.2460, validation loss: 0.1385
2024-05-25 02:11:55 [INFO]: Epoch 100 - training loss: 0.2476, validation loss: 0.1368
2024-05-25 02:11:56 [INFO]: Epoch 101 - training loss: 0.2470, validation loss: 0.1357
2024-05-25 02:11:56 [INFO]: Epoch 102 - training loss: 0.2435, validation loss: 0.1368
2024-05-25 02:11:57 [INFO]: Epoch 103 - training loss: 0.2436, validation loss: 0.1361
2024-05-25 02:11:58 [INFO]: Epoch 104 - training loss: 0.2447, validation loss: 0.1351
2024-05-25 02:11:58 [INFO]: Epoch 105 - training loss: 0.2421, validation loss: 0.1357
2024-05-25 02:11:59 [INFO]: Epoch 106 - training loss: 0.2409, validation loss: 0.1352
2024-05-25 02:12:00 [INFO]: Epoch 107 - training loss: 0.2407, validation loss: 0.1340
2024-05-25 02:12:00 [INFO]: Epoch 108 - training loss: 0.2409, validation loss: 0.1347
2024-05-25 02:12:01 [INFO]: Epoch 109 - training loss: 0.2410, validation loss: 0.1334
2024-05-25 02:12:02 [INFO]: Epoch 110 - training loss: 0.2391, validation loss: 0.1342
2024-05-25 02:12:02 [INFO]: Epoch 111 - training loss: 0.2389, validation loss: 0.1349
2024-05-25 02:12:03 [INFO]: Epoch 112 - training loss: 0.2381, validation loss: 0.1324
2024-05-25 02:12:04 [INFO]: Epoch 113 - training loss: 0.2385, validation loss: 0.1335
2024-05-25 02:12:04 [INFO]: Epoch 114 - training loss: 0.2376, validation loss: 0.1337
2024-05-25 02:12:05 [INFO]: Epoch 115 - training loss: 0.2377, validation loss: 0.1331
2024-05-25 02:12:06 [INFO]: Epoch 116 - training loss: 0.2378, validation loss: 0.1337
2024-05-25 02:12:06 [INFO]: Epoch 117 - training loss: 0.2371, validation loss: 0.1327
2024-05-25 02:12:07 [INFO]: Epoch 118 - training loss: 0.2361, validation loss: 0.1333
2024-05-25 02:12:08 [INFO]: Epoch 119 - training loss: 0.2348, validation loss: 0.1314
2024-05-25 02:12:08 [INFO]: Epoch 120 - training loss: 0.2341, validation loss: 0.1327
2024-05-25 02:12:09 [INFO]: Epoch 121 - training loss: 0.2349, validation loss: 0.1324
2024-05-25 02:12:10 [INFO]: Epoch 122 - training loss: 0.2343, validation loss: 0.1328
2024-05-25 02:12:10 [INFO]: Epoch 123 - training loss: 0.2345, validation loss: 0.1305
2024-05-25 02:12:11 [INFO]: Epoch 124 - training loss: 0.2333, validation loss: 0.1313
2024-05-25 02:12:12 [INFO]: Epoch 125 - training loss: 0.2322, validation loss: 0.1307
2024-05-25 02:12:12 [INFO]: Epoch 126 - training loss: 0.2326, validation loss: 0.1307
2024-05-25 02:12:13 [INFO]: Epoch 127 - training loss: 0.2316, validation loss: 0.1305
2024-05-25 02:12:14 [INFO]: Epoch 128 - training loss: 0.2329, validation loss: 0.1304
2024-05-25 02:12:14 [INFO]: Epoch 129 - training loss: 0.2310, validation loss: 0.1306
2024-05-25 02:12:15 [INFO]: Epoch 130 - training loss: 0.2315, validation loss: 0.1297
2024-05-25 02:12:16 [INFO]: Epoch 131 - training loss: 0.2317, validation loss: 0.1290
2024-05-25 02:12:16 [INFO]: Epoch 132 - training loss: 0.2294, validation loss: 0.1295
2024-05-25 02:12:17 [INFO]: Epoch 133 - training loss: 0.2293, validation loss: 0.1285
2024-05-25 02:12:18 [INFO]: Epoch 134 - training loss: 0.2284, validation loss: 0.1291
2024-05-25 02:12:18 [INFO]: Epoch 135 - training loss: 0.2281, validation loss: 0.1290
2024-05-25 02:12:19 [INFO]: Epoch 136 - training loss: 0.2271, validation loss: 0.1285
2024-05-25 02:12:20 [INFO]: Epoch 137 - training loss: 0.2285, validation loss: 0.1282
2024-05-25 02:12:20 [INFO]: Epoch 138 - training loss: 0.2276, validation loss: 0.1275
2024-05-25 02:12:21 [INFO]: Epoch 139 - training loss: 0.2265, validation loss: 0.1305
2024-05-25 02:12:22 [INFO]: Epoch 140 - training loss: 0.2281, validation loss: 0.1276
2024-05-25 02:12:22 [INFO]: Epoch 141 - training loss: 0.2259, validation loss: 0.1282
2024-05-25 02:12:23 [INFO]: Epoch 142 - training loss: 0.2259, validation loss: 0.1277
2024-05-25 02:12:24 [INFO]: Epoch 143 - training loss: 0.2263, validation loss: 0.1293
2024-05-25 02:12:24 [INFO]: Epoch 144 - training loss: 0.2262, validation loss: 0.1274
2024-05-25 02:12:25 [INFO]: Epoch 145 - training loss: 0.2249, validation loss: 0.1264
2024-05-25 02:12:26 [INFO]: Epoch 146 - training loss: 0.2247, validation loss: 0.1262
2024-05-25 02:12:26 [INFO]: Epoch 147 - training loss: 0.2255, validation loss: 0.1283
2024-05-25 02:12:27 [INFO]: Epoch 148 - training loss: 0.2254, validation loss: 0.1266
2024-05-25 02:12:28 [INFO]: Epoch 149 - training loss: 0.2231, validation loss: 0.1259
2024-05-25 02:12:28 [INFO]: Epoch 150 - training loss: 0.2239, validation loss: 0.1260
2024-05-25 02:12:29 [INFO]: Epoch 151 - training loss: 0.2232, validation loss: 0.1258
2024-05-25 02:12:30 [INFO]: Epoch 152 - training loss: 0.2210, validation loss: 0.1266
2024-05-25 02:12:30 [INFO]: Epoch 153 - training loss: 0.2219, validation loss: 0.1254
2024-05-25 02:12:31 [INFO]: Epoch 154 - training loss: 0.2209, validation loss: 0.1253
2024-05-25 02:12:32 [INFO]: Epoch 155 - training loss: 0.2200, validation loss: 0.1249
2024-05-25 02:12:32 [INFO]: Epoch 156 - training loss: 0.2209, validation loss: 0.1255
2024-05-25 02:12:33 [INFO]: Epoch 157 - training loss: 0.2214, validation loss: 0.1245
2024-05-25 02:12:34 [INFO]: Epoch 158 - training loss: 0.2212, validation loss: 0.1247
2024-05-25 02:12:34 [INFO]: Epoch 159 - training loss: 0.2207, validation loss: 0.1265
2024-05-25 02:12:35 [INFO]: Epoch 160 - training loss: 0.2208, validation loss: 0.1238
2024-05-25 02:12:36 [INFO]: Epoch 161 - training loss: 0.2209, validation loss: 0.1248
2024-05-25 02:12:37 [INFO]: Epoch 162 - training loss: 0.2197, validation loss: 0.1236
2024-05-25 02:12:37 [INFO]: Epoch 163 - training loss: 0.2177, validation loss: 0.1227
2024-05-25 02:12:38 [INFO]: Epoch 164 - training loss: 0.2188, validation loss: 0.1242
2024-05-25 02:12:39 [INFO]: Epoch 165 - training loss: 0.2185, validation loss: 0.1236
2024-05-25 02:12:39 [INFO]: Epoch 166 - training loss: 0.2178, validation loss: 0.1241
2024-05-25 02:12:40 [INFO]: Epoch 167 - training loss: 0.2187, validation loss: 0.1227
2024-05-25 02:12:41 [INFO]: Epoch 168 - training loss: 0.2167, validation loss: 0.1229
2024-05-25 02:12:41 [INFO]: Epoch 169 - training loss: 0.2170, validation loss: 0.1238
2024-05-25 02:12:42 [INFO]: Epoch 170 - training loss: 0.2157, validation loss: 0.1234
2024-05-25 02:12:43 [INFO]: Epoch 171 - training loss: 0.2165, validation loss: 0.1221
2024-05-25 02:12:43 [INFO]: Epoch 172 - training loss: 0.2148, validation loss: 0.1229
2024-05-25 02:12:44 [INFO]: Epoch 173 - training loss: 0.2154, validation loss: 0.1221
2024-05-25 02:12:45 [INFO]: Epoch 174 - training loss: 0.2147, validation loss: 0.1228
2024-05-25 02:12:45 [INFO]: Epoch 175 - training loss: 0.2165, validation loss: 0.1225
2024-05-25 02:12:46 [INFO]: Epoch 176 - training loss: 0.2173, validation loss: 0.1221
2024-05-25 02:12:47 [INFO]: Epoch 177 - training loss: 0.2144, validation loss: 0.1214
2024-05-25 02:12:47 [INFO]: Epoch 178 - training loss: 0.2132, validation loss: 0.1222
2024-05-25 02:12:48 [INFO]: Epoch 179 - training loss: 0.2135, validation loss: 0.1209
2024-05-25 02:12:49 [INFO]: Epoch 180 - training loss: 0.2134, validation loss: 0.1223
2024-05-25 02:12:49 [INFO]: Epoch 181 - training loss: 0.2130, validation loss: 0.1215
2024-05-25 02:12:50 [INFO]: Epoch 182 - training loss: 0.2127, validation loss: 0.1206
2024-05-25 02:12:51 [INFO]: Epoch 183 - training loss: 0.2129, validation loss: 0.1226
2024-05-25 02:12:51 [INFO]: Epoch 184 - training loss: 0.2135, validation loss: 0.1203
2024-05-25 02:12:52 [INFO]: Epoch 185 - training loss: 0.2138, validation loss: 0.1206
2024-05-25 02:12:53 [INFO]: Epoch 186 - training loss: 0.2129, validation loss: 0.1214
2024-05-25 02:12:53 [INFO]: Epoch 187 - training loss: 0.2122, validation loss: 0.1209
2024-05-25 02:12:54 [INFO]: Epoch 188 - training loss: 0.2111, validation loss: 0.1212
2024-05-25 02:12:55 [INFO]: Epoch 189 - training loss: 0.2111, validation loss: 0.1201
2024-05-25 02:12:55 [INFO]: Epoch 190 - training loss: 0.2102, validation loss: 0.1201
2024-05-25 02:12:56 [INFO]: Epoch 191 - training loss: 0.2100, validation loss: 0.1199
2024-05-25 02:12:57 [INFO]: Epoch 192 - training loss: 0.2100, validation loss: 0.1200
2024-05-25 02:12:57 [INFO]: Epoch 193 - training loss: 0.2098, validation loss: 0.1188
2024-05-25 02:12:58 [INFO]: Epoch 194 - training loss: 0.2097, validation loss: 0.1200
2024-05-25 02:12:59 [INFO]: Epoch 195 - training loss: 0.2103, validation loss: 0.1202
2024-05-25 02:12:59 [INFO]: Epoch 196 - training loss: 0.2094, validation loss: 0.1201
2024-05-25 02:13:00 [INFO]: Epoch 197 - training loss: 0.2080, validation loss: 0.1206
2024-05-25 02:13:01 [INFO]: Epoch 198 - training loss: 0.2084, validation loss: 0.1193
2024-05-25 02:13:01 [INFO]: Epoch 199 - training loss: 0.2109, validation loss: 0.1205
2024-05-25 02:13:02 [INFO]: Epoch 200 - training loss: 0.2096, validation loss: 0.1190
2024-05-25 02:13:03 [INFO]: Epoch 201 - training loss: 0.2081, validation loss: 0.1193
2024-05-25 02:13:03 [INFO]: Epoch 202 - training loss: 0.2077, validation loss: 0.1188
2024-05-25 02:13:04 [INFO]: Epoch 203 - training loss: 0.2075, validation loss: 0.1186
2024-05-25 02:13:05 [INFO]: Epoch 204 - training loss: 0.2072, validation loss: 0.1181
2024-05-25 02:13:05 [INFO]: Epoch 205 - training loss: 0.2067, validation loss: 0.1182
2024-05-25 02:13:06 [INFO]: Epoch 206 - training loss: 0.2073, validation loss: 0.1174
2024-05-25 02:13:07 [INFO]: Epoch 207 - training loss: 0.2074, validation loss: 0.1195
2024-05-25 02:13:07 [INFO]: Epoch 208 - training loss: 0.2071, validation loss: 0.1180
2024-05-25 02:13:08 [INFO]: Epoch 209 - training loss: 0.2066, validation loss: 0.1191
2024-05-25 02:13:09 [INFO]: Epoch 210 - training loss: 0.2062, validation loss: 0.1180
2024-05-25 02:13:09 [INFO]: Epoch 211 - training loss: 0.2060, validation loss: 0.1203
2024-05-25 02:13:10 [INFO]: Epoch 212 - training loss: 0.2053, validation loss: 0.1181
2024-05-25 02:13:11 [INFO]: Epoch 213 - training loss: 0.2049, validation loss: 0.1174
2024-05-25 02:13:11 [INFO]: Epoch 214 - training loss: 0.2051, validation loss: 0.1177
2024-05-25 02:13:12 [INFO]: Epoch 215 - training loss: 0.2053, validation loss: 0.1174
2024-05-25 02:13:13 [INFO]: Epoch 216 - training loss: 0.2038, validation loss: 0.1181
2024-05-25 02:13:13 [INFO]: Epoch 217 - training loss: 0.2038, validation loss: 0.1189
2024-05-25 02:13:14 [INFO]: Epoch 218 - training loss: 0.2039, validation loss: 0.1185
2024-05-25 02:13:15 [INFO]: Epoch 219 - training loss: 0.2043, validation loss: 0.1165
2024-05-25 02:13:15 [INFO]: Epoch 220 - training loss: 0.2030, validation loss: 0.1166
2024-05-25 02:13:16 [INFO]: Epoch 221 - training loss: 0.2042, validation loss: 0.1162
2024-05-25 02:13:17 [INFO]: Epoch 222 - training loss: 0.2034, validation loss: 0.1177
2024-05-25 02:13:17 [INFO]: Epoch 223 - training loss: 0.2060, validation loss: 0.1168
2024-05-25 02:13:18 [INFO]: Epoch 224 - training loss: 0.2064, validation loss: 0.1177
2024-05-25 02:13:19 [INFO]: Epoch 225 - training loss: 0.2055, validation loss: 0.1186
2024-05-25 02:13:19 [INFO]: Epoch 226 - training loss: 0.2022, validation loss: 0.1162
2024-05-25 02:13:20 [INFO]: Epoch 227 - training loss: 0.2018, validation loss: 0.1167
2024-05-25 02:13:21 [INFO]: Epoch 228 - training loss: 0.2021, validation loss: 0.1167
2024-05-25 02:13:21 [INFO]: Epoch 229 - training loss: 0.2008, validation loss: 0.1162
2024-05-25 02:13:22 [INFO]: Epoch 230 - training loss: 0.1999, validation loss: 0.1166
2024-05-25 02:13:23 [INFO]: Epoch 231 - training loss: 0.2011, validation loss: 0.1153
2024-05-25 02:13:23 [INFO]: Epoch 232 - training loss: 0.2018, validation loss: 0.1171
2024-05-25 02:13:24 [INFO]: Epoch 233 - training loss: 0.2017, validation loss: 0.1162
2024-05-25 02:13:25 [INFO]: Epoch 234 - training loss: 0.2003, validation loss: 0.1161
2024-05-25 02:13:25 [INFO]: Epoch 235 - training loss: 0.1993, validation loss: 0.1160
2024-05-25 02:13:26 [INFO]: Epoch 236 - training loss: 0.1997, validation loss: 0.1161
2024-05-25 02:13:27 [INFO]: Epoch 237 - training loss: 0.1999, validation loss: 0.1159
2024-05-25 02:13:27 [INFO]: Epoch 238 - training loss: 0.1991, validation loss: 0.1159
2024-05-25 02:13:28 [INFO]: Epoch 239 - training loss: 0.1992, validation loss: 0.1157
2024-05-25 02:13:29 [INFO]: Epoch 240 - training loss: 0.1991, validation loss: 0.1156
2024-05-25 02:13:29 [INFO]: Epoch 241 - training loss: 0.1991, validation loss: 0.1168
2024-05-25 02:13:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:13:29 [INFO]: Finished training. The best model is from epoch#231.
2024-05-25 02:13:30 [INFO]: Saved the model to augmentation_saved_results/round_1/SAITS_air_quality/20240525_T021048/SAITS.pypots
2024-05-25 02:13:30 [INFO]: SAITS on Air-Quality: MAE=0.1517, MSE=0.1797
2024-05-25 02:13:30 [INFO]: Successfully saved to augmentation_saved_results/round_1/SAITS_air_quality/imputation.pkl
2024-05-25 02:13:30 [INFO]: Using the given device: cuda:0
2024-05-25 02:13:30 [INFO]: Model files will be saved to augmentation_saved_results/round_1/Transformer_air_quality/20240525_T021330
2024-05-25 02:13:30 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/Transformer_air_quality/20240525_T021330/tensorboard
2024-05-25 02:13:30 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 02:13:30 [INFO]: Epoch 001 - training loss: 0.9043, validation loss: 0.4721
2024-05-25 02:13:30 [INFO]: Epoch 002 - training loss: 0.5713, validation loss: 0.3540
2024-05-25 02:13:31 [INFO]: Epoch 003 - training loss: 0.4814, validation loss: 0.3022
2024-05-25 02:13:31 [INFO]: Epoch 004 - training loss: 0.4369, validation loss: 0.2712
2024-05-25 02:13:31 [INFO]: Epoch 005 - training loss: 0.4095, validation loss: 0.2552
2024-05-25 02:13:32 [INFO]: Epoch 006 - training loss: 0.3907, validation loss: 0.2522
2024-05-25 02:13:32 [INFO]: Epoch 007 - training loss: 0.3780, validation loss: 0.2394
2024-05-25 02:13:32 [INFO]: Epoch 008 - training loss: 0.3637, validation loss: 0.2348
2024-05-25 02:13:33 [INFO]: Epoch 009 - training loss: 0.3566, validation loss: 0.2295
2024-05-25 02:13:33 [INFO]: Epoch 010 - training loss: 0.3486, validation loss: 0.2213
2024-05-25 02:13:33 [INFO]: Epoch 011 - training loss: 0.3444, validation loss: 0.2209
2024-05-25 02:13:34 [INFO]: Epoch 012 - training loss: 0.3375, validation loss: 0.2145
2024-05-25 02:13:34 [INFO]: Epoch 013 - training loss: 0.3308, validation loss: 0.2130
2024-05-25 02:13:34 [INFO]: Epoch 014 - training loss: 0.3274, validation loss: 0.2110
2024-05-25 02:13:34 [INFO]: Epoch 015 - training loss: 0.3263, validation loss: 0.2037
2024-05-25 02:13:35 [INFO]: Epoch 016 - training loss: 0.3197, validation loss: 0.2023
2024-05-25 02:13:35 [INFO]: Epoch 017 - training loss: 0.3143, validation loss: 0.1997
2024-05-25 02:13:35 [INFO]: Epoch 018 - training loss: 0.3122, validation loss: 0.1974
2024-05-25 02:13:36 [INFO]: Epoch 019 - training loss: 0.3070, validation loss: 0.1948
2024-05-25 02:13:36 [INFO]: Epoch 020 - training loss: 0.3059, validation loss: 0.1911
2024-05-25 02:13:36 [INFO]: Epoch 021 - training loss: 0.3029, validation loss: 0.1900
2024-05-25 02:13:37 [INFO]: Epoch 022 - training loss: 0.3022, validation loss: 0.1879
2024-05-25 02:13:37 [INFO]: Epoch 023 - training loss: 0.2992, validation loss: 0.1903
2024-05-25 02:13:37 [INFO]: Epoch 024 - training loss: 0.2981, validation loss: 0.1898
2024-05-25 02:13:38 [INFO]: Epoch 025 - training loss: 0.2970, validation loss: 0.1849
2024-05-25 02:13:38 [INFO]: Epoch 026 - training loss: 0.2951, validation loss: 0.1859
2024-05-25 02:13:38 [INFO]: Epoch 027 - training loss: 0.2908, validation loss: 0.1858
2024-05-25 02:13:39 [INFO]: Epoch 028 - training loss: 0.2912, validation loss: 0.1826
2024-05-25 02:13:39 [INFO]: Epoch 029 - training loss: 0.2903, validation loss: 0.1832
2024-05-25 02:13:39 [INFO]: Epoch 030 - training loss: 0.2879, validation loss: 0.1815
2024-05-25 02:13:40 [INFO]: Epoch 031 - training loss: 0.2873, validation loss: 0.1843
2024-05-25 02:13:40 [INFO]: Epoch 032 - training loss: 0.2853, validation loss: 0.1824
2024-05-25 02:13:40 [INFO]: Epoch 033 - training loss: 0.2820, validation loss: 0.1804
2024-05-25 02:13:40 [INFO]: Epoch 034 - training loss: 0.2809, validation loss: 0.1799
2024-05-25 02:13:41 [INFO]: Epoch 035 - training loss: 0.2818, validation loss: 0.1790
2024-05-25 02:13:41 [INFO]: Epoch 036 - training loss: 0.2792, validation loss: 0.1800
2024-05-25 02:13:41 [INFO]: Epoch 037 - training loss: 0.2832, validation loss: 0.1770
2024-05-25 02:13:42 [INFO]: Epoch 038 - training loss: 0.2781, validation loss: 0.1766
2024-05-25 02:13:42 [INFO]: Epoch 039 - training loss: 0.2753, validation loss: 0.1766
2024-05-25 02:13:42 [INFO]: Epoch 040 - training loss: 0.2748, validation loss: 0.1763
2024-05-25 02:13:43 [INFO]: Epoch 041 - training loss: 0.2717, validation loss: 0.1768
2024-05-25 02:13:43 [INFO]: Epoch 042 - training loss: 0.2712, validation loss: 0.1760
2024-05-25 02:13:43 [INFO]: Epoch 043 - training loss: 0.2703, validation loss: 0.1730
2024-05-25 02:13:44 [INFO]: Epoch 044 - training loss: 0.2690, validation loss: 0.1752
2024-05-25 02:13:44 [INFO]: Epoch 045 - training loss: 0.2748, validation loss: 0.1795
2024-05-25 02:13:44 [INFO]: Epoch 046 - training loss: 0.2709, validation loss: 0.1742
2024-05-25 02:13:45 [INFO]: Epoch 047 - training loss: 0.2673, validation loss: 0.1723
2024-05-25 02:13:45 [INFO]: Epoch 048 - training loss: 0.2666, validation loss: 0.1705
2024-05-25 02:13:45 [INFO]: Epoch 049 - training loss: 0.2629, validation loss: 0.1703
2024-05-25 02:13:46 [INFO]: Epoch 050 - training loss: 0.2632, validation loss: 0.1704
2024-05-25 02:13:46 [INFO]: Epoch 051 - training loss: 0.2626, validation loss: 0.1693
2024-05-25 02:13:46 [INFO]: Epoch 052 - training loss: 0.2641, validation loss: 0.1704
2024-05-25 02:13:46 [INFO]: Epoch 053 - training loss: 0.2618, validation loss: 0.1677
2024-05-25 02:13:47 [INFO]: Epoch 054 - training loss: 0.2605, validation loss: 0.1679
2024-05-25 02:13:47 [INFO]: Epoch 055 - training loss: 0.2585, validation loss: 0.1672
2024-05-25 02:13:47 [INFO]: Epoch 056 - training loss: 0.2589, validation loss: 0.1692
2024-05-25 02:13:48 [INFO]: Epoch 057 - training loss: 0.2622, validation loss: 0.1682
2024-05-25 02:13:48 [INFO]: Epoch 058 - training loss: 0.2560, validation loss: 0.1671
2024-05-25 02:13:48 [INFO]: Epoch 059 - training loss: 0.2577, validation loss: 0.1672
2024-05-25 02:13:49 [INFO]: Epoch 060 - training loss: 0.2569, validation loss: 0.1684
2024-05-25 02:13:49 [INFO]: Epoch 061 - training loss: 0.2548, validation loss: 0.1668
2024-05-25 02:13:49 [INFO]: Epoch 062 - training loss: 0.2548, validation loss: 0.1651
2024-05-25 02:13:50 [INFO]: Epoch 063 - training loss: 0.2534, validation loss: 0.1630
2024-05-25 02:13:50 [INFO]: Epoch 064 - training loss: 0.2517, validation loss: 0.1625
2024-05-25 02:13:50 [INFO]: Epoch 065 - training loss: 0.2521, validation loss: 0.1634
2024-05-25 02:13:51 [INFO]: Epoch 066 - training loss: 0.2503, validation loss: 0.1616
2024-05-25 02:13:51 [INFO]: Epoch 067 - training loss: 0.2520, validation loss: 0.1638
2024-05-25 02:13:51 [INFO]: Epoch 068 - training loss: 0.2529, validation loss: 0.1616
2024-05-25 02:13:52 [INFO]: Epoch 069 - training loss: 0.2501, validation loss: 0.1629
2024-05-25 02:13:52 [INFO]: Epoch 070 - training loss: 0.2486, validation loss: 0.1647
2024-05-25 02:13:52 [INFO]: Epoch 071 - training loss: 0.2498, validation loss: 0.1625
2024-05-25 02:13:52 [INFO]: Epoch 072 - training loss: 0.2456, validation loss: 0.1618
2024-05-25 02:13:53 [INFO]: Epoch 073 - training loss: 0.2440, validation loss: 0.1600
2024-05-25 02:13:53 [INFO]: Epoch 074 - training loss: 0.2448, validation loss: 0.1613
2024-05-25 02:13:53 [INFO]: Epoch 075 - training loss: 0.2439, validation loss: 0.1602
2024-05-25 02:13:54 [INFO]: Epoch 076 - training loss: 0.2456, validation loss: 0.1594
2024-05-25 02:13:54 [INFO]: Epoch 077 - training loss: 0.2430, validation loss: 0.1601
2024-05-25 02:13:54 [INFO]: Epoch 078 - training loss: 0.2426, validation loss: 0.1584
2024-05-25 02:13:55 [INFO]: Epoch 079 - training loss: 0.2400, validation loss: 0.1589
2024-05-25 02:13:55 [INFO]: Epoch 080 - training loss: 0.2397, validation loss: 0.1569
2024-05-25 02:13:55 [INFO]: Epoch 081 - training loss: 0.2415, validation loss: 0.1589
2024-05-25 02:13:56 [INFO]: Epoch 082 - training loss: 0.2426, validation loss: 0.1579
2024-05-25 02:13:56 [INFO]: Epoch 083 - training loss: 0.2395, validation loss: 0.1566
2024-05-25 02:13:56 [INFO]: Epoch 084 - training loss: 0.2391, validation loss: 0.1571
2024-05-25 02:13:57 [INFO]: Epoch 085 - training loss: 0.2390, validation loss: 0.1567
2024-05-25 02:13:57 [INFO]: Epoch 086 - training loss: 0.2382, validation loss: 0.1589
2024-05-25 02:13:57 [INFO]: Epoch 087 - training loss: 0.2448, validation loss: 0.1562
2024-05-25 02:13:58 [INFO]: Epoch 088 - training loss: 0.2377, validation loss: 0.1568
2024-05-25 02:13:58 [INFO]: Epoch 089 - training loss: 0.2370, validation loss: 0.1564
2024-05-25 02:13:58 [INFO]: Epoch 090 - training loss: 0.2363, validation loss: 0.1549
2024-05-25 02:13:58 [INFO]: Epoch 091 - training loss: 0.2387, validation loss: 0.1592
2024-05-25 02:13:59 [INFO]: Epoch 092 - training loss: 0.2384, validation loss: 0.1549
2024-05-25 02:13:59 [INFO]: Epoch 093 - training loss: 0.2354, validation loss: 0.1547
2024-05-25 02:13:59 [INFO]: Epoch 094 - training loss: 0.2360, validation loss: 0.1572
2024-05-25 02:14:00 [INFO]: Epoch 095 - training loss: 0.2332, validation loss: 0.1532
2024-05-25 02:14:00 [INFO]: Epoch 096 - training loss: 0.2316, validation loss: 0.1520
2024-05-25 02:14:00 [INFO]: Epoch 097 - training loss: 0.2309, validation loss: 0.1546
2024-05-25 02:14:01 [INFO]: Epoch 098 - training loss: 0.2307, validation loss: 0.1548
2024-05-25 02:14:01 [INFO]: Epoch 099 - training loss: 0.2311, validation loss: 0.1540
2024-05-25 02:14:01 [INFO]: Epoch 100 - training loss: 0.2323, validation loss: 0.1523
2024-05-25 02:14:02 [INFO]: Epoch 101 - training loss: 0.2292, validation loss: 0.1519
2024-05-25 02:14:02 [INFO]: Epoch 102 - training loss: 0.2287, validation loss: 0.1510
2024-05-25 02:14:02 [INFO]: Epoch 103 - training loss: 0.2273, validation loss: 0.1516
2024-05-25 02:14:03 [INFO]: Epoch 104 - training loss: 0.2281, validation loss: 0.1515
2024-05-25 02:14:03 [INFO]: Epoch 105 - training loss: 0.2285, validation loss: 0.1505
2024-05-25 02:14:03 [INFO]: Epoch 106 - training loss: 0.2270, validation loss: 0.1508
2024-05-25 02:14:04 [INFO]: Epoch 107 - training loss: 0.2268, validation loss: 0.1487
2024-05-25 02:14:04 [INFO]: Epoch 108 - training loss: 0.2237, validation loss: 0.1502
2024-05-25 02:14:04 [INFO]: Epoch 109 - training loss: 0.2264, validation loss: 0.1501
2024-05-25 02:14:04 [INFO]: Epoch 110 - training loss: 0.2268, validation loss: 0.1490
2024-05-25 02:14:05 [INFO]: Epoch 111 - training loss: 0.2227, validation loss: 0.1513
2024-05-25 02:14:05 [INFO]: Epoch 112 - training loss: 0.2248, validation loss: 0.1482
2024-05-25 02:14:05 [INFO]: Epoch 113 - training loss: 0.2267, validation loss: 0.1492
2024-05-25 02:14:06 [INFO]: Epoch 114 - training loss: 0.2245, validation loss: 0.1487
2024-05-25 02:14:06 [INFO]: Epoch 115 - training loss: 0.2231, validation loss: 0.1482
2024-05-25 02:14:06 [INFO]: Epoch 116 - training loss: 0.2223, validation loss: 0.1483
2024-05-25 02:14:07 [INFO]: Epoch 117 - training loss: 0.2224, validation loss: 0.1485
2024-05-25 02:14:07 [INFO]: Epoch 118 - training loss: 0.2233, validation loss: 0.1472
2024-05-25 02:14:07 [INFO]: Epoch 119 - training loss: 0.2214, validation loss: 0.1460
2024-05-25 02:14:08 [INFO]: Epoch 120 - training loss: 0.2190, validation loss: 0.1477
2024-05-25 02:14:08 [INFO]: Epoch 121 - training loss: 0.2189, validation loss: 0.1460
2024-05-25 02:14:08 [INFO]: Epoch 122 - training loss: 0.2207, validation loss: 0.1465
2024-05-25 02:14:09 [INFO]: Epoch 123 - training loss: 0.2237, validation loss: 0.1483
2024-05-25 02:14:09 [INFO]: Epoch 124 - training loss: 0.2220, validation loss: 0.1479
2024-05-25 02:14:09 [INFO]: Epoch 125 - training loss: 0.2195, validation loss: 0.1458
2024-05-25 02:14:10 [INFO]: Epoch 126 - training loss: 0.2202, validation loss: 0.1460
2024-05-25 02:14:10 [INFO]: Epoch 127 - training loss: 0.2170, validation loss: 0.1442
2024-05-25 02:14:10 [INFO]: Epoch 128 - training loss: 0.2173, validation loss: 0.1453
2024-05-25 02:14:10 [INFO]: Epoch 129 - training loss: 0.2167, validation loss: 0.1470
2024-05-25 02:14:11 [INFO]: Epoch 130 - training loss: 0.2176, validation loss: 0.1442
2024-05-25 02:14:11 [INFO]: Epoch 131 - training loss: 0.2152, validation loss: 0.1454
2024-05-25 02:14:11 [INFO]: Epoch 132 - training loss: 0.2158, validation loss: 0.1446
2024-05-25 02:14:12 [INFO]: Epoch 133 - training loss: 0.2150, validation loss: 0.1439
2024-05-25 02:14:12 [INFO]: Epoch 134 - training loss: 0.2143, validation loss: 0.1442
2024-05-25 02:14:12 [INFO]: Epoch 135 - training loss: 0.2129, validation loss: 0.1441
2024-05-25 02:14:13 [INFO]: Epoch 136 - training loss: 0.2141, validation loss: 0.1427
2024-05-25 02:14:13 [INFO]: Epoch 137 - training loss: 0.2140, validation loss: 0.1439
2024-05-25 02:14:13 [INFO]: Epoch 138 - training loss: 0.2185, validation loss: 0.1415
2024-05-25 02:14:14 [INFO]: Epoch 139 - training loss: 0.2173, validation loss: 0.1454
2024-05-25 02:14:14 [INFO]: Epoch 140 - training loss: 0.2131, validation loss: 0.1426
2024-05-25 02:14:14 [INFO]: Epoch 141 - training loss: 0.2108, validation loss: 0.1434
2024-05-25 02:14:15 [INFO]: Epoch 142 - training loss: 0.2125, validation loss: 0.1426
2024-05-25 02:14:15 [INFO]: Epoch 143 - training loss: 0.2138, validation loss: 0.1432
2024-05-25 02:14:15 [INFO]: Epoch 144 - training loss: 0.2113, validation loss: 0.1436
2024-05-25 02:14:16 [INFO]: Epoch 145 - training loss: 0.2090, validation loss: 0.1438
2024-05-25 02:14:16 [INFO]: Epoch 146 - training loss: 0.2113, validation loss: 0.1412
2024-05-25 02:14:16 [INFO]: Epoch 147 - training loss: 0.2108, validation loss: 0.1417
2024-05-25 02:14:16 [INFO]: Epoch 148 - training loss: 0.2111, validation loss: 0.1427
2024-05-25 02:14:17 [INFO]: Epoch 149 - training loss: 0.2087, validation loss: 0.1434
2024-05-25 02:14:17 [INFO]: Epoch 150 - training loss: 0.2106, validation loss: 0.1411
2024-05-25 02:14:17 [INFO]: Epoch 151 - training loss: 0.2085, validation loss: 0.1414
2024-05-25 02:14:18 [INFO]: Epoch 152 - training loss: 0.2086, validation loss: 0.1398
2024-05-25 02:14:18 [INFO]: Epoch 153 - training loss: 0.2084, validation loss: 0.1412
2024-05-25 02:14:18 [INFO]: Epoch 154 - training loss: 0.2065, validation loss: 0.1419
2024-05-25 02:14:19 [INFO]: Epoch 155 - training loss: 0.2081, validation loss: 0.1416
2024-05-25 02:14:19 [INFO]: Epoch 156 - training loss: 0.2069, validation loss: 0.1405
2024-05-25 02:14:19 [INFO]: Epoch 157 - training loss: 0.2056, validation loss: 0.1413
2024-05-25 02:14:20 [INFO]: Epoch 158 - training loss: 0.2063, validation loss: 0.1405
2024-05-25 02:14:20 [INFO]: Epoch 159 - training loss: 0.2081, validation loss: 0.1433
2024-05-25 02:14:20 [INFO]: Epoch 160 - training loss: 0.2113, validation loss: 0.1444
2024-05-25 02:14:21 [INFO]: Epoch 161 - training loss: 0.2126, validation loss: 0.1399
2024-05-25 02:14:21 [INFO]: Epoch 162 - training loss: 0.2085, validation loss: 0.1418
2024-05-25 02:14:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:14:21 [INFO]: Finished training. The best model is from epoch#152.
2024-05-25 02:14:21 [INFO]: Saved the model to augmentation_saved_results/round_1/Transformer_air_quality/20240525_T021330/Transformer.pypots
2024-05-25 02:14:21 [INFO]: Transformer on Air-Quality: MAE=0.1708, MSE=0.2086
2024-05-25 02:14:21 [INFO]: Successfully saved to augmentation_saved_results/round_1/Transformer_air_quality/imputation.pkl
2024-05-25 02:14:21 [INFO]: Using the given device: cuda:0
2024-05-25 02:14:21 [INFO]: Model files will be saved to augmentation_saved_results/round_1/TimesNet_air_quality/20240525_T021421
2024-05-25 02:14:21 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/TimesNet_air_quality/20240525_T021421/tensorboard
2024-05-25 02:14:21 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 02:14:22 [INFO]: Epoch 001 - training loss: 0.2825, validation loss: 0.2627
2024-05-25 02:14:22 [INFO]: Epoch 002 - training loss: 0.2075, validation loss: 0.2287
2024-05-25 02:14:23 [INFO]: Epoch 003 - training loss: 0.1999, validation loss: 0.2095
2024-05-25 02:14:24 [INFO]: Epoch 004 - training loss: 0.1837, validation loss: 0.2023
2024-05-25 02:14:24 [INFO]: Epoch 005 - training loss: 0.1800, validation loss: 0.1916
2024-05-25 02:14:25 [INFO]: Epoch 006 - training loss: 0.1864, validation loss: 0.1969
2024-05-25 02:14:25 [INFO]: Epoch 007 - training loss: 0.1714, validation loss: 0.1829
2024-05-25 02:14:26 [INFO]: Epoch 008 - training loss: 0.1466, validation loss: 0.1827
2024-05-25 02:14:26 [INFO]: Epoch 009 - training loss: 0.1435, validation loss: 0.1808
2024-05-25 02:14:27 [INFO]: Epoch 010 - training loss: 0.1432, validation loss: 0.1812
2024-05-25 02:14:27 [INFO]: Epoch 011 - training loss: 0.1420, validation loss: 0.1790
2024-05-25 02:14:28 [INFO]: Epoch 012 - training loss: 0.1556, validation loss: 0.1794
2024-05-25 02:14:28 [INFO]: Epoch 013 - training loss: 0.1393, validation loss: 0.1781
2024-05-25 02:14:29 [INFO]: Epoch 014 - training loss: 0.1400, validation loss: 0.1854
2024-05-25 02:14:29 [INFO]: Epoch 015 - training loss: 0.1382, validation loss: 0.1754
2024-05-25 02:14:30 [INFO]: Epoch 016 - training loss: 0.1262, validation loss: 0.1754
2024-05-25 02:14:30 [INFO]: Epoch 017 - training loss: 0.1410, validation loss: 0.1760
2024-05-25 02:14:31 [INFO]: Epoch 018 - training loss: 0.1357, validation loss: 0.1702
2024-05-25 02:14:31 [INFO]: Epoch 019 - training loss: 0.1272, validation loss: 0.1699
2024-05-25 02:14:32 [INFO]: Epoch 020 - training loss: 0.1421, validation loss: 0.1678
2024-05-25 02:14:32 [INFO]: Epoch 021 - training loss: 0.1175, validation loss: 0.1644
2024-05-25 02:14:33 [INFO]: Epoch 022 - training loss: 0.1271, validation loss: 0.1722
2024-05-25 02:14:33 [INFO]: Epoch 023 - training loss: 0.1361, validation loss: 0.1613
2024-05-25 02:14:34 [INFO]: Epoch 024 - training loss: 0.1170, validation loss: 0.1637
2024-05-25 02:14:35 [INFO]: Epoch 025 - training loss: 0.1148, validation loss: 0.1636
2024-05-25 02:14:35 [INFO]: Epoch 026 - training loss: 0.1309, validation loss: 0.1586
2024-05-25 02:14:36 [INFO]: Epoch 027 - training loss: 0.1293, validation loss: 0.1601
2024-05-25 02:14:36 [INFO]: Epoch 028 - training loss: 0.1138, validation loss: 0.1610
2024-05-25 02:14:37 [INFO]: Epoch 029 - training loss: 0.1231, validation loss: 0.1644
2024-05-25 02:14:37 [INFO]: Epoch 030 - training loss: 0.1223, validation loss: 0.1565
2024-05-25 02:14:38 [INFO]: Epoch 031 - training loss: 0.1227, validation loss: 0.1610
2024-05-25 02:14:38 [INFO]: Epoch 032 - training loss: 0.1048, validation loss: 0.1577
2024-05-25 02:14:39 [INFO]: Epoch 033 - training loss: 0.1243, validation loss: 0.1604
2024-05-25 02:14:39 [INFO]: Epoch 034 - training loss: 0.1129, validation loss: 0.1614
2024-05-25 02:14:40 [INFO]: Epoch 035 - training loss: 0.1058, validation loss: 0.1564
2024-05-25 02:14:40 [INFO]: Epoch 036 - training loss: 0.1064, validation loss: 0.1558
2024-05-25 02:14:41 [INFO]: Epoch 037 - training loss: 0.1016, validation loss: 0.1553
2024-05-25 02:14:41 [INFO]: Epoch 038 - training loss: 0.1085, validation loss: 0.1548
2024-05-25 02:14:42 [INFO]: Epoch 039 - training loss: 0.1094, validation loss: 0.1533
2024-05-25 02:14:42 [INFO]: Epoch 040 - training loss: 0.1094, validation loss: 0.1539
2024-05-25 02:14:43 [INFO]: Epoch 041 - training loss: 0.0961, validation loss: 0.1585
2024-05-25 02:14:43 [INFO]: Epoch 042 - training loss: 0.1002, validation loss: 0.1623
2024-05-25 02:14:44 [INFO]: Epoch 043 - training loss: 0.1304, validation loss: 0.1545
2024-05-25 02:14:45 [INFO]: Epoch 044 - training loss: 0.1043, validation loss: 0.1580
2024-05-25 02:14:45 [INFO]: Epoch 045 - training loss: 0.1104, validation loss: 0.1537
2024-05-25 02:14:46 [INFO]: Epoch 046 - training loss: 0.1364, validation loss: 0.1557
2024-05-25 02:14:46 [INFO]: Epoch 047 - training loss: 0.1098, validation loss: 0.1527
2024-05-25 02:14:47 [INFO]: Epoch 048 - training loss: 0.1061, validation loss: 0.1547
2024-05-25 02:14:47 [INFO]: Epoch 049 - training loss: 0.0942, validation loss: 0.1568
2024-05-25 02:14:48 [INFO]: Epoch 050 - training loss: 0.1038, validation loss: 0.1536
2024-05-25 02:14:48 [INFO]: Epoch 051 - training loss: 0.1012, validation loss: 0.1518
2024-05-25 02:14:49 [INFO]: Epoch 052 - training loss: 0.1044, validation loss: 0.1518
2024-05-25 02:14:49 [INFO]: Epoch 053 - training loss: 0.0940, validation loss: 0.1533
2024-05-25 02:14:50 [INFO]: Epoch 054 - training loss: 0.1016, validation loss: 0.1489
2024-05-25 02:14:50 [INFO]: Epoch 055 - training loss: 0.1029, validation loss: 0.1531
2024-05-25 02:14:51 [INFO]: Epoch 056 - training loss: 0.1049, validation loss: 0.1504
2024-05-25 02:14:51 [INFO]: Epoch 057 - training loss: 0.1088, validation loss: 0.1552
2024-05-25 02:14:52 [INFO]: Epoch 058 - training loss: 0.0937, validation loss: 0.1579
2024-05-25 02:14:52 [INFO]: Epoch 059 - training loss: 0.1047, validation loss: 0.1549
2024-05-25 02:14:53 [INFO]: Epoch 060 - training loss: 0.1268, validation loss: 0.1565
2024-05-25 02:14:53 [INFO]: Epoch 061 - training loss: 0.1139, validation loss: 0.1525
2024-05-25 02:14:54 [INFO]: Epoch 062 - training loss: 0.1039, validation loss: 0.1607
2024-05-25 02:14:54 [INFO]: Epoch 063 - training loss: 0.0946, validation loss: 0.1572
2024-05-25 02:14:55 [INFO]: Epoch 064 - training loss: 0.1037, validation loss: 0.1548
2024-05-25 02:14:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:14:55 [INFO]: Finished training. The best model is from epoch#54.
2024-05-25 02:14:55 [INFO]: Saved the model to augmentation_saved_results/round_1/TimesNet_air_quality/20240525_T021421/TimesNet.pypots
2024-05-25 02:14:55 [INFO]: TimesNet on Air-Quality: MAE=0.1619, MSE=0.2343
2024-05-25 02:14:55 [INFO]: Successfully saved to augmentation_saved_results/round_1/TimesNet_air_quality/imputation.pkl
2024-05-25 02:14:55 [INFO]: Using the given device: cuda:0
2024-05-25 02:14:55 [INFO]: Model files will be saved to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455
2024-05-25 02:14:55 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/tensorboard
2024-05-25 02:14:55 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 02:15:12 [INFO]: Epoch 001 - training loss: 0.4871, validation loss: 0.3374
2024-05-25 02:15:12 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch1_loss0.3374335914850235.pypots
2024-05-25 02:15:29 [INFO]: Epoch 002 - training loss: 0.3019, validation loss: 0.2749
2024-05-25 02:15:29 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch2_loss0.2748941034078598.pypots
2024-05-25 02:15:46 [INFO]: Epoch 003 - training loss: 0.2646, validation loss: 0.2538
2024-05-25 02:15:46 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch3_loss0.2538271680474281.pypots
2024-05-25 02:16:02 [INFO]: Epoch 004 - training loss: 0.2504, validation loss: 0.2359
2024-05-25 02:16:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch4_loss0.23587508350610734.pypots
2024-05-25 02:16:19 [INFO]: Epoch 005 - training loss: 0.2389, validation loss: 0.2175
2024-05-25 02:16:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch5_loss0.2174968108534813.pypots
2024-05-25 02:16:36 [INFO]: Epoch 006 - training loss: 0.2049, validation loss: 0.2026
2024-05-25 02:16:36 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch6_loss0.20255614519119264.pypots
2024-05-25 02:16:53 [INFO]: Epoch 007 - training loss: 0.2029, validation loss: 0.1882
2024-05-25 02:16:53 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch7_loss0.18819467276334761.pypots
2024-05-25 02:17:10 [INFO]: Epoch 008 - training loss: 0.1936, validation loss: 0.1762
2024-05-25 02:17:10 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch8_loss0.1762288600206375.pypots
2024-05-25 02:17:26 [INFO]: Epoch 009 - training loss: 0.1831, validation loss: 0.1768
2024-05-25 02:17:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch9_loss0.17677770256996156.pypots
2024-05-25 02:17:43 [INFO]: Epoch 010 - training loss: 0.1880, validation loss: 0.1710
2024-05-25 02:17:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch10_loss0.1709878459572792.pypots
2024-05-25 02:18:00 [INFO]: Epoch 011 - training loss: 0.1819, validation loss: 0.1687
2024-05-25 02:18:00 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch11_loss0.16873221695423127.pypots
2024-05-25 02:18:17 [INFO]: Epoch 012 - training loss: 0.1569, validation loss: 0.1574
2024-05-25 02:18:17 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch12_loss0.15740036964416504.pypots
2024-05-25 02:18:34 [INFO]: Epoch 013 - training loss: 0.1736, validation loss: 0.1557
2024-05-25 02:18:34 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch13_loss0.15573349744081497.pypots
2024-05-25 02:18:50 [INFO]: Epoch 014 - training loss: 0.1803, validation loss: 0.1530
2024-05-25 02:18:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch14_loss0.1530460983514786.pypots
2024-05-25 02:19:07 [INFO]: Epoch 015 - training loss: 0.1582, validation loss: 0.1535
2024-05-25 02:19:07 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch15_loss0.15350839048624038.pypots
2024-05-25 02:19:24 [INFO]: Epoch 016 - training loss: 0.1715, validation loss: 0.1479
2024-05-25 02:19:24 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch16_loss0.14785932749509811.pypots
2024-05-25 02:19:41 [INFO]: Epoch 017 - training loss: 0.1533, validation loss: 0.1452
2024-05-25 02:19:41 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch17_loss0.1452324226498604.pypots
2024-05-25 02:19:57 [INFO]: Epoch 018 - training loss: 0.1613, validation loss: 0.1457
2024-05-25 02:19:57 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch18_loss0.14565404802560805.pypots
2024-05-25 02:20:14 [INFO]: Epoch 019 - training loss: 0.1479, validation loss: 0.1411
2024-05-25 02:20:14 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch19_loss0.1410796746611595.pypots
2024-05-25 02:20:31 [INFO]: Epoch 020 - training loss: 0.1404, validation loss: 0.1441
2024-05-25 02:20:31 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch20_loss0.14413557648658754.pypots
2024-05-25 02:20:48 [INFO]: Epoch 021 - training loss: 0.1525, validation loss: 0.1384
2024-05-25 02:20:48 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch21_loss0.13835825696587561.pypots
2024-05-25 02:21:05 [INFO]: Epoch 022 - training loss: 0.1639, validation loss: 0.1369
2024-05-25 02:21:05 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch22_loss0.13688021823763846.pypots
2024-05-25 02:21:21 [INFO]: Epoch 023 - training loss: 0.1400, validation loss: 0.1349
2024-05-25 02:21:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch23_loss0.13492544293403624.pypots
2024-05-25 02:21:38 [INFO]: Epoch 024 - training loss: 0.1456, validation loss: 0.1626
2024-05-25 02:21:38 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch24_loss0.16260134428739548.pypots
2024-05-25 02:21:55 [INFO]: Epoch 025 - training loss: 0.1553, validation loss: 0.1414
2024-05-25 02:21:55 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch25_loss0.1414182424545288.pypots
2024-05-25 02:22:12 [INFO]: Epoch 026 - training loss: 0.1541, validation loss: 0.1339
2024-05-25 02:22:12 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch26_loss0.13385896235704423.pypots
2024-05-25 02:22:28 [INFO]: Epoch 027 - training loss: 0.1455, validation loss: 0.1317
2024-05-25 02:22:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch27_loss0.13168684169650077.pypots
2024-05-25 02:22:45 [INFO]: Epoch 028 - training loss: 0.1508, validation loss: 0.1352
2024-05-25 02:22:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch28_loss0.13519161567091942.pypots
2024-05-25 02:23:02 [INFO]: Epoch 029 - training loss: 0.1513, validation loss: 0.1312
2024-05-25 02:23:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch29_loss0.1311916135251522.pypots
2024-05-25 02:23:19 [INFO]: Epoch 030 - training loss: 0.1241, validation loss: 0.1270
2024-05-25 02:23:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch30_loss0.12703171521425247.pypots
2024-05-25 02:23:36 [INFO]: Epoch 031 - training loss: 0.1585, validation loss: 0.1321
2024-05-25 02:23:36 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch31_loss0.13205820843577384.pypots
2024-05-25 02:23:52 [INFO]: Epoch 032 - training loss: 0.1465, validation loss: 0.1326
2024-05-25 02:23:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch32_loss0.13258082568645477.pypots
2024-05-25 02:24:09 [INFO]: Epoch 033 - training loss: 0.1369, validation loss: 0.1278
2024-05-25 02:24:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch33_loss0.12778839096426964.pypots
2024-05-25 02:24:26 [INFO]: Epoch 034 - training loss: 0.1338, validation loss: 0.1248
2024-05-25 02:24:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch34_loss0.12479183450341225.pypots
2024-05-25 02:24:43 [INFO]: Epoch 035 - training loss: 0.1408, validation loss: 0.1252
2024-05-25 02:24:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch35_loss0.12522107511758804.pypots
2024-05-25 02:25:00 [INFO]: Epoch 036 - training loss: 0.1464, validation loss: 0.1283
2024-05-25 02:25:00 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch36_loss0.12825008779764174.pypots
2024-05-25 02:25:16 [INFO]: Epoch 037 - training loss: 0.1415, validation loss: 0.1309
2024-05-25 02:25:16 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch37_loss0.13087268024683.pypots
2024-05-25 02:25:33 [INFO]: Epoch 038 - training loss: 0.1114, validation loss: 0.1275
2024-05-25 02:25:33 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch38_loss0.12752164974808694.pypots
2024-05-25 02:25:50 [INFO]: Epoch 039 - training loss: 0.1302, validation loss: 0.1300
2024-05-25 02:25:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch39_loss0.12995414212346076.pypots
2024-05-25 02:26:07 [INFO]: Epoch 040 - training loss: 0.1361, validation loss: 0.1231
2024-05-25 02:26:07 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch40_loss0.12313484922051429.pypots
2024-05-25 02:26:24 [INFO]: Epoch 041 - training loss: 0.1344, validation loss: 0.1253
2024-05-25 02:26:24 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch41_loss0.12534987330436706.pypots
2024-05-25 02:26:40 [INFO]: Epoch 042 - training loss: 0.1373, validation loss: 0.1251
2024-05-25 02:26:40 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch42_loss0.1251160316169262.pypots
2024-05-25 02:26:57 [INFO]: Epoch 043 - training loss: 0.1373, validation loss: 0.1211
2024-05-25 02:26:57 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch43_loss0.12110486328601837.pypots
2024-05-25 02:27:14 [INFO]: Epoch 044 - training loss: 0.1292, validation loss: 0.1201
2024-05-25 02:27:14 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch44_loss0.12011236697435379.pypots
2024-05-25 02:27:31 [INFO]: Epoch 045 - training loss: 0.1389, validation loss: 0.1219
2024-05-25 02:27:31 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch45_loss0.12189882323145866.pypots
2024-05-25 02:27:48 [INFO]: Epoch 046 - training loss: 0.1277, validation loss: 0.1195
2024-05-25 02:27:48 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch46_loss0.1194932997226715.pypots
2024-05-25 02:28:04 [INFO]: Epoch 047 - training loss: 0.1257, validation loss: 0.1164
2024-05-25 02:28:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch47_loss0.11644946485757827.pypots
2024-05-25 02:28:21 [INFO]: Epoch 048 - training loss: 0.1206, validation loss: 0.1184
2024-05-25 02:28:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch48_loss0.11838991865515709.pypots
2024-05-25 02:28:38 [INFO]: Epoch 049 - training loss: 0.1255, validation loss: 0.1179
2024-05-25 02:28:38 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch49_loss0.11791807189583778.pypots
2024-05-25 02:28:55 [INFO]: Epoch 050 - training loss: 0.1234, validation loss: 0.1178
2024-05-25 02:28:55 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch50_loss0.11780513152480125.pypots
2024-05-25 02:29:12 [INFO]: Epoch 051 - training loss: 0.1190, validation loss: 0.1144
2024-05-25 02:29:12 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch51_loss0.11435473784804344.pypots
2024-05-25 02:29:28 [INFO]: Epoch 052 - training loss: 0.1180, validation loss: 0.1142
2024-05-25 02:29:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch52_loss0.11415951550006867.pypots
2024-05-25 02:29:45 [INFO]: Epoch 053 - training loss: 0.1440, validation loss: 0.1158
2024-05-25 02:29:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch53_loss0.11575745269656182.pypots
2024-05-25 02:30:02 [INFO]: Epoch 054 - training loss: 0.1263, validation loss: 0.1144
2024-05-25 02:30:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch54_loss0.11439669355750084.pypots
2024-05-25 02:30:19 [INFO]: Epoch 055 - training loss: 0.1089, validation loss: 0.1140
2024-05-25 02:30:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch55_loss0.1140152782201767.pypots
2024-05-25 02:30:35 [INFO]: Epoch 056 - training loss: 0.1285, validation loss: 0.1124
2024-05-25 02:30:35 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch56_loss0.11240217238664627.pypots
2024-05-25 02:30:52 [INFO]: Epoch 057 - training loss: 0.1164, validation loss: 0.1144
2024-05-25 02:30:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch57_loss0.11443504542112351.pypots
2024-05-25 02:31:09 [INFO]: Epoch 058 - training loss: 0.1147, validation loss: 0.1185
2024-05-25 02:31:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch58_loss0.1184650830924511.pypots
2024-05-25 02:31:26 [INFO]: Epoch 059 - training loss: 0.1200, validation loss: 0.1120
2024-05-25 02:31:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch59_loss0.11199730187654496.pypots
2024-05-25 02:31:43 [INFO]: Epoch 060 - training loss: 0.1247, validation loss: 0.1139
2024-05-25 02:31:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch60_loss0.11388923376798629.pypots
2024-05-25 02:31:59 [INFO]: Epoch 061 - training loss: 0.1255, validation loss: 0.1113
2024-05-25 02:31:59 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch61_loss0.111276263743639.pypots
2024-05-25 02:32:16 [INFO]: Epoch 062 - training loss: 0.1227, validation loss: 0.1096
2024-05-25 02:32:16 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch62_loss0.10964870825409889.pypots
2024-05-25 02:32:33 [INFO]: Epoch 063 - training loss: 0.1288, validation loss: 0.1115
2024-05-25 02:32:33 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch63_loss0.11148196682333947.pypots
2024-05-25 02:32:50 [INFO]: Epoch 064 - training loss: 0.1248, validation loss: 0.1142
2024-05-25 02:32:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch64_loss0.11423296481370926.pypots
2024-05-25 02:33:07 [INFO]: Epoch 065 - training loss: 0.1230, validation loss: 0.1110
2024-05-25 02:33:07 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch65_loss0.11097463220357895.pypots
2024-05-25 02:33:23 [INFO]: Epoch 066 - training loss: 0.1146, validation loss: 0.1091
2024-05-25 02:33:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch66_loss0.10914698988199234.pypots
2024-05-25 02:33:40 [INFO]: Epoch 067 - training loss: 0.1156, validation loss: 0.1133
2024-05-25 02:33:40 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch67_loss0.11326163411140441.pypots
2024-05-25 02:33:57 [INFO]: Epoch 068 - training loss: 0.1215, validation loss: 0.1115
2024-05-25 02:33:57 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch68_loss0.11152731403708457.pypots
2024-05-25 02:34:14 [INFO]: Epoch 069 - training loss: 0.1373, validation loss: 0.1130
2024-05-25 02:34:14 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch69_loss0.11301561295986176.pypots
2024-05-25 02:34:31 [INFO]: Epoch 070 - training loss: 0.1184, validation loss: 0.1113
2024-05-25 02:34:31 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch70_loss0.11125092953443527.pypots
2024-05-25 02:34:47 [INFO]: Epoch 071 - training loss: 0.1336, validation loss: 0.1092
2024-05-25 02:34:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch71_loss0.1091801531612873.pypots
2024-05-25 02:35:04 [INFO]: Epoch 072 - training loss: 0.1208, validation loss: 0.1076
2024-05-25 02:35:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch72_loss0.10761420652270318.pypots
2024-05-25 02:35:21 [INFO]: Epoch 073 - training loss: 0.1286, validation loss: 0.1093
2024-05-25 02:35:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch73_loss0.10928718969225884.pypots
2024-05-25 02:35:38 [INFO]: Epoch 074 - training loss: 0.1184, validation loss: 0.1086
2024-05-25 02:35:38 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch74_loss0.10861271545290947.pypots
2024-05-25 02:35:55 [INFO]: Epoch 075 - training loss: 0.1121, validation loss: 0.1135
2024-05-25 02:35:55 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch75_loss0.1134792186319828.pypots
2024-05-25 02:36:11 [INFO]: Epoch 076 - training loss: 0.1168, validation loss: 0.1070
2024-05-25 02:36:11 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch76_loss0.10698672011494637.pypots
2024-05-25 02:36:28 [INFO]: Epoch 077 - training loss: 0.1159, validation loss: 0.1075
2024-05-25 02:36:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch77_loss0.10748252868652344.pypots
2024-05-25 02:36:45 [INFO]: Epoch 078 - training loss: 0.1265, validation loss: 0.1258
2024-05-25 02:36:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch78_loss0.12578876912593842.pypots
2024-05-25 02:37:02 [INFO]: Epoch 079 - training loss: 0.1189, validation loss: 0.1095
2024-05-25 02:37:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch79_loss0.1095213308930397.pypots
2024-05-25 02:37:18 [INFO]: Epoch 080 - training loss: 0.1070, validation loss: 0.1087
2024-05-25 02:37:18 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch80_loss0.10874410569667817.pypots
2024-05-25 02:37:35 [INFO]: Epoch 081 - training loss: 0.1276, validation loss: 0.1076
2024-05-25 02:37:35 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch81_loss0.10763280168175697.pypots
2024-05-25 02:37:52 [INFO]: Epoch 082 - training loss: 0.1137, validation loss: 0.1062
2024-05-25 02:37:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch82_loss0.10619343742728234.pypots
2024-05-25 02:38:09 [INFO]: Epoch 083 - training loss: 0.1192, validation loss: 0.1055
2024-05-25 02:38:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch83_loss0.10550753250718117.pypots
2024-05-25 02:38:26 [INFO]: Epoch 084 - training loss: 0.1253, validation loss: 0.1074
2024-05-25 02:38:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch84_loss0.10744450315833091.pypots
2024-05-25 02:38:42 [INFO]: Epoch 085 - training loss: 0.1170, validation loss: 0.1090
2024-05-25 02:38:42 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch85_loss0.10903319641947747.pypots
2024-05-25 02:38:59 [INFO]: Epoch 086 - training loss: 0.1087, validation loss: 0.1053
2024-05-25 02:38:59 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch86_loss0.10528439804911613.pypots
2024-05-25 02:39:16 [INFO]: Epoch 087 - training loss: 0.1238, validation loss: 0.1108
2024-05-25 02:39:16 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch87_loss0.11082695573568344.pypots
2024-05-25 02:39:33 [INFO]: Epoch 088 - training loss: 0.1208, validation loss: 0.1063
2024-05-25 02:39:33 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch88_loss0.10629764050245286.pypots
2024-05-25 02:39:49 [INFO]: Epoch 089 - training loss: 0.1166, validation loss: 0.1091
2024-05-25 02:39:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch89_loss0.10914141237735749.pypots
2024-05-25 02:40:06 [INFO]: Epoch 090 - training loss: 0.1122, validation loss: 0.1060
2024-05-25 02:40:06 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch90_loss0.10601244643330573.pypots
2024-05-25 02:40:23 [INFO]: Epoch 091 - training loss: 0.1187, validation loss: 0.1067
2024-05-25 02:40:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch91_loss0.10665800049901009.pypots
2024-05-25 02:40:40 [INFO]: Epoch 092 - training loss: 0.1126, validation loss: 0.1078
2024-05-25 02:40:40 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch92_loss0.10776550918817521.pypots
2024-05-25 02:40:57 [INFO]: Epoch 093 - training loss: 0.1280, validation loss: 0.1097
2024-05-25 02:40:57 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch93_loss0.10974513888359069.pypots
2024-05-25 02:41:13 [INFO]: Epoch 094 - training loss: 0.1191, validation loss: 0.1044
2024-05-25 02:41:13 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch94_loss0.10438982993364335.pypots
2024-05-25 02:41:30 [INFO]: Epoch 095 - training loss: 0.1223, validation loss: 0.1104
2024-05-25 02:41:30 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch95_loss0.11037349924445153.pypots
2024-05-25 02:41:47 [INFO]: Epoch 096 - training loss: 0.1262, validation loss: 0.1075
2024-05-25 02:41:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch96_loss0.10746299475431442.pypots
2024-05-25 02:42:04 [INFO]: Epoch 097 - training loss: 0.1200, validation loss: 0.1056
2024-05-25 02:42:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch97_loss0.10564688071608544.pypots
2024-05-25 02:42:21 [INFO]: Epoch 098 - training loss: 0.1186, validation loss: 0.1066
2024-05-25 02:42:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch98_loss0.10656785666942596.pypots
2024-05-25 02:42:37 [INFO]: Epoch 099 - training loss: 0.1163, validation loss: 0.1125
2024-05-25 02:42:37 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch99_loss0.1124760314822197.pypots
2024-05-25 02:42:54 [INFO]: Epoch 100 - training loss: 0.1076, validation loss: 0.1055
2024-05-25 02:42:54 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch100_loss0.10549194589257241.pypots
2024-05-25 02:43:11 [INFO]: Epoch 101 - training loss: 0.1133, validation loss: 0.1038
2024-05-25 02:43:11 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch101_loss0.103756482899189.pypots
2024-05-25 02:43:28 [INFO]: Epoch 102 - training loss: 0.1147, validation loss: 0.1052
2024-05-25 02:43:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch102_loss0.10518265217542648.pypots
2024-05-25 02:43:44 [INFO]: Epoch 103 - training loss: 0.1122, validation loss: 0.1052
2024-05-25 02:43:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch103_loss0.10521562919020652.pypots
2024-05-25 02:44:01 [INFO]: Epoch 104 - training loss: 0.1204, validation loss: 0.1054
2024-05-25 02:44:01 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch104_loss0.10537951365113259.pypots
2024-05-25 02:44:18 [INFO]: Epoch 105 - training loss: 0.0994, validation loss: 0.1049
2024-05-25 02:44:18 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch105_loss0.10488396883010864.pypots
2024-05-25 02:44:35 [INFO]: Epoch 106 - training loss: 0.1180, validation loss: 0.1061
2024-05-25 02:44:35 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch106_loss0.10614752322435379.pypots
2024-05-25 02:44:52 [INFO]: Epoch 107 - training loss: 0.1258, validation loss: 0.1046
2024-05-25 02:44:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch107_loss0.10456920713186264.pypots
2024-05-25 02:45:08 [INFO]: Epoch 108 - training loss: 0.1245, validation loss: 0.1036
2024-05-25 02:45:08 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch108_loss0.10363705828785896.pypots
2024-05-25 02:45:25 [INFO]: Epoch 109 - training loss: 0.1191, validation loss: 0.1071
2024-05-25 02:45:25 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch109_loss0.10714829415082931.pypots
2024-05-25 02:45:42 [INFO]: Epoch 110 - training loss: 0.1119, validation loss: 0.1054
2024-05-25 02:45:42 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch110_loss0.10541263371706008.pypots
2024-05-25 02:45:59 [INFO]: Epoch 111 - training loss: 0.1297, validation loss: 0.1040
2024-05-25 02:45:59 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch111_loss0.10403873398900032.pypots
2024-05-25 02:46:16 [INFO]: Epoch 112 - training loss: 0.1205, validation loss: 0.1039
2024-05-25 02:46:16 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch112_loss0.103905089199543.pypots
2024-05-25 02:46:32 [INFO]: Epoch 113 - training loss: 0.1162, validation loss: 0.1097
2024-05-25 02:46:32 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch113_loss0.10973888710141182.pypots
2024-05-25 02:46:49 [INFO]: Epoch 114 - training loss: 0.1257, validation loss: 0.1073
2024-05-25 02:46:49 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch114_loss0.10733967944979668.pypots
2024-05-25 02:47:06 [INFO]: Epoch 115 - training loss: 0.1112, validation loss: 0.1053
2024-05-25 02:47:06 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch115_loss0.10534876435995102.pypots
2024-05-25 02:47:23 [INFO]: Epoch 116 - training loss: 0.1194, validation loss: 0.1066
2024-05-25 02:47:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch116_loss0.10656328424811363.pypots
2024-05-25 02:47:40 [INFO]: Epoch 117 - training loss: 0.1160, validation loss: 0.1097
2024-05-25 02:47:40 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch117_loss0.10966699197888374.pypots
2024-05-25 02:47:56 [INFO]: Epoch 118 - training loss: 0.1079, validation loss: 0.1045
2024-05-25 02:47:56 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI_epoch118_loss0.10449263677001.pypots
2024-05-25 02:47:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:47:56 [INFO]: Finished training. The best model is from epoch#108.
2024-05-25 02:47:56 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240525_T021455/CSDI.pypots
2024-05-25 02:50:17 [INFO]: CSDI on Air-Quality: MAE=0.1091, MSE=0.2005
2024-05-25 02:50:17 [INFO]: Successfully saved to augmentation_saved_results/round_1/CSDI_air_quality/imputation.pkl
2024-05-25 02:50:17 [INFO]: Using the given device: cuda:0
2024-05-25 02:50:17 [INFO]: Model files will be saved to augmentation_saved_results/round_1/GPVAE_air_quality/20240525_T025017
2024-05-25 02:50:17 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/GPVAE_air_quality/20240525_T025017/tensorboard
2024-05-25 02:50:17 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 02:50:17 [INFO]: Epoch 001 - training loss: 63343.8725, validation loss: 0.6685
2024-05-25 02:50:17 [INFO]: Epoch 002 - training loss: 42054.3455, validation loss: 0.5915
2024-05-25 02:50:18 [INFO]: Epoch 003 - training loss: 41728.2985, validation loss: 0.5282
2024-05-25 02:50:18 [INFO]: Epoch 004 - training loss: 41607.3601, validation loss: 0.5118
2024-05-25 02:50:18 [INFO]: Epoch 005 - training loss: 41584.8161, validation loss: 0.4643
2024-05-25 02:50:18 [INFO]: Epoch 006 - training loss: 41514.9172, validation loss: 0.4578
2024-05-25 02:50:19 [INFO]: Epoch 007 - training loss: 41464.4132, validation loss: 0.4244
2024-05-25 02:50:19 [INFO]: Epoch 008 - training loss: 41435.1115, validation loss: 0.3774
2024-05-25 02:50:19 [INFO]: Epoch 009 - training loss: 41407.4439, validation loss: 0.3744
2024-05-25 02:50:20 [INFO]: Epoch 010 - training loss: 41396.0609, validation loss: 0.3799
2024-05-25 02:50:20 [INFO]: Epoch 011 - training loss: 41386.7405, validation loss: 0.3603
2024-05-25 02:50:20 [INFO]: Epoch 012 - training loss: 41345.4829, validation loss: 0.3304
2024-05-25 02:50:21 [INFO]: Epoch 013 - training loss: 41333.0198, validation loss: 0.3596
2024-05-25 02:50:21 [INFO]: Epoch 014 - training loss: 41327.0448, validation loss: 0.3221
2024-05-25 02:50:21 [INFO]: Epoch 015 - training loss: 41307.3927, validation loss: 0.3199
2024-05-25 02:50:22 [INFO]: Epoch 016 - training loss: 41288.5612, validation loss: 0.3220
2024-05-25 02:50:22 [INFO]: Epoch 017 - training loss: 41303.8288, validation loss: 0.3332
2024-05-25 02:50:22 [INFO]: Epoch 018 - training loss: 41280.6775, validation loss: 0.3038
2024-05-25 02:50:23 [INFO]: Epoch 019 - training loss: 41268.5422, validation loss: 0.3152
2024-05-25 02:50:23 [INFO]: Epoch 020 - training loss: 41263.2844, validation loss: 0.3023
2024-05-25 02:50:23 [INFO]: Epoch 021 - training loss: 41245.9983, validation loss: 0.3093
2024-05-25 02:50:24 [INFO]: Epoch 022 - training loss: 41240.1399, validation loss: 0.2896
2024-05-25 02:50:24 [INFO]: Epoch 023 - training loss: 41237.8238, validation loss: 0.3170
2024-05-25 02:50:24 [INFO]: Epoch 024 - training loss: 41258.1325, validation loss: 0.2910
2024-05-25 02:50:25 [INFO]: Epoch 025 - training loss: 41304.2716, validation loss: 0.3280
2024-05-25 02:50:25 [INFO]: Epoch 026 - training loss: 41324.5913, validation loss: 0.3350
2024-05-25 02:50:25 [INFO]: Epoch 027 - training loss: 41307.4962, validation loss: 0.3220
2024-05-25 02:50:25 [INFO]: Epoch 028 - training loss: 41282.6029, validation loss: 0.3040
2024-05-25 02:50:26 [INFO]: Epoch 029 - training loss: 41254.1228, validation loss: 0.2922
2024-05-25 02:50:26 [INFO]: Epoch 030 - training loss: 41218.1040, validation loss: 0.2830
2024-05-25 02:50:26 [INFO]: Epoch 031 - training loss: 41216.2245, validation loss: 0.2722
2024-05-25 02:50:27 [INFO]: Epoch 032 - training loss: 41212.2944, validation loss: 0.2803
2024-05-25 02:50:27 [INFO]: Epoch 033 - training loss: 41208.6839, validation loss: 0.2725
2024-05-25 02:50:27 [INFO]: Epoch 034 - training loss: 41212.3552, validation loss: 0.2680
2024-05-25 02:50:28 [INFO]: Epoch 035 - training loss: 41206.9376, validation loss: 0.2683
2024-05-25 02:50:28 [INFO]: Epoch 036 - training loss: 41223.5421, validation loss: 0.2844
2024-05-25 02:50:28 [INFO]: Epoch 037 - training loss: 41204.6163, validation loss: 0.2688
2024-05-25 02:50:29 [INFO]: Epoch 038 - training loss: 41188.0420, validation loss: 0.2651
2024-05-25 02:50:29 [INFO]: Epoch 039 - training loss: 41186.1019, validation loss: 0.2693
2024-05-25 02:50:29 [INFO]: Epoch 040 - training loss: 41182.0875, validation loss: 0.2634
2024-05-25 02:50:30 [INFO]: Epoch 041 - training loss: 41183.0417, validation loss: 0.2619
2024-05-25 02:50:30 [INFO]: Epoch 042 - training loss: 41175.2546, validation loss: 0.2690
2024-05-25 02:50:30 [INFO]: Epoch 043 - training loss: 41181.8605, validation loss: 0.2831
2024-05-25 02:50:31 [INFO]: Epoch 044 - training loss: 41181.9651, validation loss: 0.2756
2024-05-25 02:50:31 [INFO]: Epoch 045 - training loss: 41177.7250, validation loss: 0.2689
2024-05-25 02:50:31 [INFO]: Epoch 046 - training loss: 41199.2448, validation loss: 0.2789
2024-05-25 02:50:32 [INFO]: Epoch 047 - training loss: 41180.4274, validation loss: 0.2651
2024-05-25 02:50:32 [INFO]: Epoch 048 - training loss: 41175.5952, validation loss: 0.2480
2024-05-25 02:50:32 [INFO]: Epoch 049 - training loss: 41182.8413, validation loss: 0.2660
2024-05-25 02:50:32 [INFO]: Epoch 050 - training loss: 41249.6117, validation loss: 0.2677
2024-05-25 02:50:33 [INFO]: Epoch 051 - training loss: 41367.3979, validation loss: 0.2938
2024-05-25 02:50:33 [INFO]: Epoch 052 - training loss: 41282.1115, validation loss: 0.2710
2024-05-25 02:50:33 [INFO]: Epoch 053 - training loss: 41244.5435, validation loss: 0.2772
2024-05-25 02:50:34 [INFO]: Epoch 054 - training loss: 41226.7746, validation loss: 0.2803
2024-05-25 02:50:34 [INFO]: Epoch 055 - training loss: 41194.7541, validation loss: 0.2697
2024-05-25 02:50:34 [INFO]: Epoch 056 - training loss: 41181.1259, validation loss: 0.2777
2024-05-25 02:50:35 [INFO]: Epoch 057 - training loss: 41201.6898, validation loss: 0.2489
2024-05-25 02:50:35 [INFO]: Epoch 058 - training loss: 41174.9965, validation loss: 0.2756
2024-05-25 02:50:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:50:35 [INFO]: Finished training. The best model is from epoch#48.
2024-05-25 02:50:35 [INFO]: Saved the model to augmentation_saved_results/round_1/GPVAE_air_quality/20240525_T025017/GPVAE.pypots
2024-05-25 02:50:35 [INFO]: GP-VAE on Air-Quality: MAE=0.3206, MSE=0.3544
2024-05-25 02:50:35 [INFO]: Successfully saved to augmentation_saved_results/round_1/GPVAE_air_quality/imputation.pkl
2024-05-25 02:50:35 [INFO]: Using the given device: cuda:0
2024-05-25 02:50:35 [INFO]: Model files will be saved to augmentation_saved_results/round_1/USGAN_air_quality/20240525_T025035
2024-05-25 02:50:35 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/USGAN_air_quality/20240525_T025035/tensorboard
2024-05-25 02:50:35 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 02:50:40 [INFO]: Epoch 001 - generator training loss: 0.5924, discriminator training loss: 0.2819, validation loss: 0.5183
2024-05-25 02:50:44 [INFO]: Epoch 002 - generator training loss: 0.2910, discriminator training loss: 0.0666, validation loss: 0.3939
2024-05-25 02:50:48 [INFO]: Epoch 003 - generator training loss: 0.2147, discriminator training loss: 0.0630, validation loss: 0.3292
2024-05-25 02:50:52 [INFO]: Epoch 004 - generator training loss: 0.1802, discriminator training loss: 0.0622, validation loss: 0.2892
2024-05-25 02:50:56 [INFO]: Epoch 005 - generator training loss: 0.1537, discriminator training loss: 0.0618, validation loss: 0.2605
2024-05-25 02:51:01 [INFO]: Epoch 006 - generator training loss: 0.1354, discriminator training loss: 0.0624, validation loss: 0.2416
2024-05-25 02:51:05 [INFO]: Epoch 007 - generator training loss: 0.1228, discriminator training loss: 0.0614, validation loss: 0.2277
2024-05-25 02:51:09 [INFO]: Epoch 008 - generator training loss: 0.1133, discriminator training loss: 0.0601, validation loss: 0.2167
2024-05-25 02:51:13 [INFO]: Epoch 009 - generator training loss: 0.1037, discriminator training loss: 0.0593, validation loss: 0.2086
2024-05-25 02:51:17 [INFO]: Epoch 010 - generator training loss: 0.1033, discriminator training loss: 0.0592, validation loss: 0.2025
2024-05-25 02:51:21 [INFO]: Epoch 011 - generator training loss: 0.0915, discriminator training loss: 0.0576, validation loss: 0.1959
2024-05-25 02:51:25 [INFO]: Epoch 012 - generator training loss: 0.0864, discriminator training loss: 0.0567, validation loss: 0.1914
2024-05-25 02:51:30 [INFO]: Epoch 013 - generator training loss: 0.0837, discriminator training loss: 0.0552, validation loss: 0.1879
2024-05-25 02:51:34 [INFO]: Epoch 014 - generator training loss: 0.0807, discriminator training loss: 0.0535, validation loss: 0.1845
2024-05-25 02:51:38 [INFO]: Epoch 015 - generator training loss: 0.0801, discriminator training loss: 0.0522, validation loss: 0.1807
2024-05-25 02:51:42 [INFO]: Epoch 016 - generator training loss: 0.0766, discriminator training loss: 0.0500, validation loss: 0.1784
2024-05-25 02:51:46 [INFO]: Epoch 017 - generator training loss: 0.0741, discriminator training loss: 0.0482, validation loss: 0.1762
2024-05-25 02:51:50 [INFO]: Epoch 018 - generator training loss: 0.0720, discriminator training loss: 0.0474, validation loss: 0.1750
2024-05-25 02:51:54 [INFO]: Epoch 019 - generator training loss: 0.0720, discriminator training loss: 0.0459, validation loss: 0.1729
2024-05-25 02:51:58 [INFO]: Epoch 020 - generator training loss: 0.0686, discriminator training loss: 0.0455, validation loss: 0.1720
2024-05-25 02:52:02 [INFO]: Epoch 021 - generator training loss: 0.0673, discriminator training loss: 0.0445, validation loss: 0.1696
2024-05-25 02:52:06 [INFO]: Epoch 022 - generator training loss: 0.0665, discriminator training loss: 0.0436, validation loss: 0.1681
2024-05-25 02:52:10 [INFO]: Epoch 023 - generator training loss: 0.0672, discriminator training loss: 0.0428, validation loss: 0.1680
2024-05-25 02:52:14 [INFO]: Epoch 024 - generator training loss: 0.0638, discriminator training loss: 0.0423, validation loss: 0.1663
2024-05-25 02:52:18 [INFO]: Epoch 025 - generator training loss: 0.0628, discriminator training loss: 0.0413, validation loss: 0.1658
2024-05-25 02:52:22 [INFO]: Epoch 026 - generator training loss: 0.0625, discriminator training loss: 0.0403, validation loss: 0.1643
2024-05-25 02:52:26 [INFO]: Epoch 027 - generator training loss: 0.0609, discriminator training loss: 0.0398, validation loss: 0.1636
2024-05-25 02:52:31 [INFO]: Epoch 028 - generator training loss: 0.0608, discriminator training loss: 0.0390, validation loss: 0.1642
2024-05-25 02:52:35 [INFO]: Epoch 029 - generator training loss: 0.0597, discriminator training loss: 0.0384, validation loss: 0.1630
2024-05-25 02:52:39 [INFO]: Epoch 030 - generator training loss: 0.0594, discriminator training loss: 0.0376, validation loss: 0.1619
2024-05-25 02:52:43 [INFO]: Epoch 031 - generator training loss: 0.0580, discriminator training loss: 0.0366, validation loss: 0.1607
2024-05-25 02:52:47 [INFO]: Epoch 032 - generator training loss: 0.0574, discriminator training loss: 0.0359, validation loss: 0.1607
2024-05-25 02:52:51 [INFO]: Epoch 033 - generator training loss: 0.0579, discriminator training loss: 0.0349, validation loss: 0.1598
2024-05-25 02:52:55 [INFO]: Epoch 034 - generator training loss: 0.0566, discriminator training loss: 0.0342, validation loss: 0.1594
2024-05-25 02:52:59 [INFO]: Epoch 035 - generator training loss: 0.0559, discriminator training loss: 0.0336, validation loss: 0.1592
2024-05-25 02:53:03 [INFO]: Epoch 036 - generator training loss: 0.0553, discriminator training loss: 0.0332, validation loss: 0.1584
2024-05-25 02:53:07 [INFO]: Epoch 037 - generator training loss: 0.0555, discriminator training loss: 0.0324, validation loss: 0.1585
2024-05-25 02:53:11 [INFO]: Epoch 038 - generator training loss: 0.0556, discriminator training loss: 0.0314, validation loss: 0.1576
2024-05-25 02:53:15 [INFO]: Epoch 039 - generator training loss: 0.0564, discriminator training loss: 0.0308, validation loss: 0.1573
2024-05-25 02:53:19 [INFO]: Epoch 040 - generator training loss: 0.0544, discriminator training loss: 0.0304, validation loss: 0.1561
2024-05-25 02:53:23 [INFO]: Epoch 041 - generator training loss: 0.0548, discriminator training loss: 0.0298, validation loss: 0.1559
2024-05-25 02:53:27 [INFO]: Epoch 042 - generator training loss: 0.0541, discriminator training loss: 0.0290, validation loss: 0.1552
2024-05-25 02:53:31 [INFO]: Epoch 043 - generator training loss: 0.0543, discriminator training loss: 0.0286, validation loss: 0.1550
2024-05-25 02:53:36 [INFO]: Epoch 044 - generator training loss: 0.0532, discriminator training loss: 0.0281, validation loss: 0.1542
2024-05-25 02:53:40 [INFO]: Epoch 045 - generator training loss: 0.0531, discriminator training loss: 0.0276, validation loss: 0.1533
2024-05-25 02:53:44 [INFO]: Epoch 046 - generator training loss: 0.0528, discriminator training loss: 0.0273, validation loss: 0.1539
2024-05-25 02:53:48 [INFO]: Epoch 047 - generator training loss: 0.0529, discriminator training loss: 0.0268, validation loss: 0.1529
2024-05-25 02:53:52 [INFO]: Epoch 048 - generator training loss: 0.0524, discriminator training loss: 0.0263, validation loss: 0.1519
2024-05-25 02:53:56 [INFO]: Epoch 049 - generator training loss: 0.0521, discriminator training loss: 0.0257, validation loss: 0.1518
2024-05-25 02:54:00 [INFO]: Epoch 050 - generator training loss: 0.0517, discriminator training loss: 0.0251, validation loss: 0.1513
2024-05-25 02:54:04 [INFO]: Epoch 051 - generator training loss: 0.0510, discriminator training loss: 0.0250, validation loss: 0.1501
2024-05-25 02:54:08 [INFO]: Epoch 052 - generator training loss: 0.0505, discriminator training loss: 0.0248, validation loss: 0.1504
2024-05-25 02:54:12 [INFO]: Epoch 053 - generator training loss: 0.0509, discriminator training loss: 0.0243, validation loss: 0.1501
2024-05-25 02:54:16 [INFO]: Epoch 054 - generator training loss: 0.0500, discriminator training loss: 0.0240, validation loss: 0.1498
2024-05-25 02:54:20 [INFO]: Epoch 055 - generator training loss: 0.0498, discriminator training loss: 0.0236, validation loss: 0.1491
2024-05-25 02:54:24 [INFO]: Epoch 056 - generator training loss: 0.0496, discriminator training loss: 0.0232, validation loss: 0.1498
2024-05-25 02:54:28 [INFO]: Epoch 057 - generator training loss: 0.0494, discriminator training loss: 0.0229, validation loss: 0.1482
2024-05-25 02:54:32 [INFO]: Epoch 058 - generator training loss: 0.0494, discriminator training loss: 0.0223, validation loss: 0.1481
2024-05-25 02:54:36 [INFO]: Epoch 059 - generator training loss: 0.0485, discriminator training loss: 0.0224, validation loss: 0.1482
2024-05-25 02:54:40 [INFO]: Epoch 060 - generator training loss: 0.0479, discriminator training loss: 0.0218, validation loss: 0.1480
2024-05-25 02:54:45 [INFO]: Epoch 061 - generator training loss: 0.0480, discriminator training loss: 0.0217, validation loss: 0.1473
2024-05-25 02:54:49 [INFO]: Epoch 062 - generator training loss: 0.0479, discriminator training loss: 0.0214, validation loss: 0.1470
2024-05-25 02:54:53 [INFO]: Epoch 063 - generator training loss: 0.0473, discriminator training loss: 0.0210, validation loss: 0.1462
2024-05-25 02:54:57 [INFO]: Epoch 064 - generator training loss: 0.0474, discriminator training loss: 0.0207, validation loss: 0.1461
2024-05-25 02:55:01 [INFO]: Epoch 065 - generator training loss: 0.0470, discriminator training loss: 0.0207, validation loss: 0.1455
2024-05-25 02:55:05 [INFO]: Epoch 066 - generator training loss: 0.0473, discriminator training loss: 0.0204, validation loss: 0.1453
2024-05-25 02:55:09 [INFO]: Epoch 067 - generator training loss: 0.0461, discriminator training loss: 0.0201, validation loss: 0.1441
2024-05-25 02:55:13 [INFO]: Epoch 068 - generator training loss: 0.0456, discriminator training loss: 0.0202, validation loss: 0.1431
2024-05-25 02:55:17 [INFO]: Epoch 069 - generator training loss: 0.0453, discriminator training loss: 0.0198, validation loss: 0.1430
2024-05-25 02:55:21 [INFO]: Epoch 070 - generator training loss: 0.0445, discriminator training loss: 0.0198, validation loss: 0.1428
2024-05-25 02:55:25 [INFO]: Epoch 071 - generator training loss: 0.0449, discriminator training loss: 0.0193, validation loss: 0.1427
2024-05-25 02:55:29 [INFO]: Epoch 072 - generator training loss: 0.0450, discriminator training loss: 0.0192, validation loss: 0.1421
2024-05-25 02:55:33 [INFO]: Epoch 073 - generator training loss: 0.0440, discriminator training loss: 0.0189, validation loss: 0.1415
2024-05-25 02:55:37 [INFO]: Epoch 074 - generator training loss: 0.0439, discriminator training loss: 0.0188, validation loss: 0.1417
2024-05-25 02:55:41 [INFO]: Epoch 075 - generator training loss: 0.0429, discriminator training loss: 0.0184, validation loss: 0.1412
2024-05-25 02:55:46 [INFO]: Epoch 076 - generator training loss: 0.0430, discriminator training loss: 0.0184, validation loss: 0.1410
2024-05-25 02:55:50 [INFO]: Epoch 077 - generator training loss: 0.0427, discriminator training loss: 0.0184, validation loss: 0.1413
2024-05-25 02:55:54 [INFO]: Epoch 078 - generator training loss: 0.0425, discriminator training loss: 0.0181, validation loss: 0.1408
2024-05-25 02:55:58 [INFO]: Epoch 079 - generator training loss: 0.0432, discriminator training loss: 0.0180, validation loss: 0.1405
2024-05-25 02:56:02 [INFO]: Epoch 080 - generator training loss: 0.0420, discriminator training loss: 0.0177, validation loss: 0.1401
2024-05-25 02:56:06 [INFO]: Epoch 081 - generator training loss: 0.0418, discriminator training loss: 0.0177, validation loss: 0.1404
2024-05-25 02:56:10 [INFO]: Epoch 082 - generator training loss: 0.0419, discriminator training loss: 0.0176, validation loss: 0.1408
2024-05-25 02:56:14 [INFO]: Epoch 083 - generator training loss: 0.0416, discriminator training loss: 0.0174, validation loss: 0.1400
2024-05-25 02:56:18 [INFO]: Epoch 084 - generator training loss: 0.0406, discriminator training loss: 0.0174, validation loss: 0.1400
2024-05-25 02:56:22 [INFO]: Epoch 085 - generator training loss: 0.0407, discriminator training loss: 0.0172, validation loss: 0.1397
2024-05-25 02:56:26 [INFO]: Epoch 086 - generator training loss: 0.0434, discriminator training loss: 0.0169, validation loss: 0.1422
2024-05-25 02:56:30 [INFO]: Epoch 087 - generator training loss: 0.0438, discriminator training loss: 0.0170, validation loss: 0.1413
2024-05-25 02:56:34 [INFO]: Epoch 088 - generator training loss: 0.0423, discriminator training loss: 0.0168, validation loss: 0.1406
2024-05-25 02:56:38 [INFO]: Epoch 089 - generator training loss: 0.0409, discriminator training loss: 0.0165, validation loss: 0.1397
2024-05-25 02:56:42 [INFO]: Epoch 090 - generator training loss: 0.0410, discriminator training loss: 0.0165, validation loss: 0.1399
2024-05-25 02:56:46 [INFO]: Epoch 091 - generator training loss: 0.0398, discriminator training loss: 0.0166, validation loss: 0.1392
2024-05-25 02:56:50 [INFO]: Epoch 092 - generator training loss: 0.0403, discriminator training loss: 0.0163, validation loss: 0.1394
2024-05-25 02:56:54 [INFO]: Epoch 093 - generator training loss: 0.0397, discriminator training loss: 0.0164, validation loss: 0.1391
2024-05-25 02:56:59 [INFO]: Epoch 094 - generator training loss: 0.0403, discriminator training loss: 0.0161, validation loss: 0.1399
2024-05-25 02:57:03 [INFO]: Epoch 095 - generator training loss: 0.0390, discriminator training loss: 0.0160, validation loss: 0.1395
2024-05-25 02:57:07 [INFO]: Epoch 096 - generator training loss: 0.0392, discriminator training loss: 0.0159, validation loss: 0.1392
2024-05-25 02:57:11 [INFO]: Epoch 097 - generator training loss: 0.0385, discriminator training loss: 0.0159, validation loss: 0.1387
2024-05-25 02:57:15 [INFO]: Epoch 098 - generator training loss: 0.0378, discriminator training loss: 0.0155, validation loss: 0.1391
2024-05-25 02:57:19 [INFO]: Epoch 099 - generator training loss: 0.0378, discriminator training loss: 0.0156, validation loss: 0.1390
2024-05-25 02:57:23 [INFO]: Epoch 100 - generator training loss: 0.0385, discriminator training loss: 0.0155, validation loss: 0.1386
2024-05-25 02:57:27 [INFO]: Epoch 101 - generator training loss: 0.0376, discriminator training loss: 0.0155, validation loss: 0.1390
2024-05-25 02:57:31 [INFO]: Epoch 102 - generator training loss: 0.0386, discriminator training loss: 0.0153, validation loss: 0.1394
2024-05-25 02:57:35 [INFO]: Epoch 103 - generator training loss: 0.0376, discriminator training loss: 0.0153, validation loss: 0.1393
2024-05-25 02:57:39 [INFO]: Epoch 104 - generator training loss: 0.0368, discriminator training loss: 0.0152, validation loss: 0.1393
2024-05-25 02:57:43 [INFO]: Epoch 105 - generator training loss: 0.0370, discriminator training loss: 0.0149, validation loss: 0.1384
2024-05-25 02:57:47 [INFO]: Epoch 106 - generator training loss: 0.0365, discriminator training loss: 0.0151, validation loss: 0.1389
2024-05-25 02:57:51 [INFO]: Epoch 107 - generator training loss: 0.0370, discriminator training loss: 0.0148, validation loss: 0.1385
2024-05-25 02:57:55 [INFO]: Epoch 108 - generator training loss: 0.0361, discriminator training loss: 0.0148, validation loss: 0.1398
2024-05-25 02:58:00 [INFO]: Epoch 109 - generator training loss: 0.0363, discriminator training loss: 0.0148, validation loss: 0.1401
2024-05-25 02:58:04 [INFO]: Epoch 110 - generator training loss: 0.0362, discriminator training loss: 0.0148, validation loss: 0.1395
2024-05-25 02:58:08 [INFO]: Epoch 111 - generator training loss: 0.0357, discriminator training loss: 0.0145, validation loss: 0.1394
2024-05-25 02:58:12 [INFO]: Epoch 112 - generator training loss: 0.0359, discriminator training loss: 0.0145, validation loss: 0.1405
2024-05-25 02:58:16 [INFO]: Epoch 113 - generator training loss: 0.0363, discriminator training loss: 0.0144, validation loss: 0.1399
2024-05-25 02:58:20 [INFO]: Epoch 114 - generator training loss: 0.0356, discriminator training loss: 0.0144, validation loss: 0.1399
2024-05-25 02:58:24 [INFO]: Epoch 115 - generator training loss: 0.0359, discriminator training loss: 0.0145, validation loss: 0.1402
2024-05-25 02:58:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:58:24 [INFO]: Finished training. The best model is from epoch#105.
2024-05-25 02:58:24 [INFO]: Saved the model to augmentation_saved_results/round_1/USGAN_air_quality/20240525_T025035/USGAN.pypots
2024-05-25 02:58:25 [INFO]: US-GAN on Air-Quality: MAE=0.2082, MSE=0.1961
2024-05-25 02:58:25 [INFO]: Successfully saved to augmentation_saved_results/round_1/USGAN_air_quality/imputation.pkl
2024-05-25 02:58:25 [INFO]: Using the given device: cuda:0
2024-05-25 02:58:25 [INFO]: Model files will be saved to augmentation_saved_results/round_1/BRITS_air_quality/20240525_T025825
2024-05-25 02:58:25 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/BRITS_air_quality/20240525_T025825/tensorboard
2024-05-25 02:58:25 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 02:58:28 [INFO]: Epoch 001 - training loss: 1.4012, validation loss: 0.9495
2024-05-25 02:58:31 [INFO]: Epoch 002 - training loss: 1.1274, validation loss: 0.7169
2024-05-25 02:58:34 [INFO]: Epoch 003 - training loss: 0.9387, validation loss: 0.5987
2024-05-25 02:58:37 [INFO]: Epoch 004 - training loss: 0.8255, validation loss: 0.5284
2024-05-25 02:58:39 [INFO]: Epoch 005 - training loss: 0.7519, validation loss: 0.4806
2024-05-25 02:58:42 [INFO]: Epoch 006 - training loss: 0.6954, validation loss: 0.4439
2024-05-25 02:58:45 [INFO]: Epoch 007 - training loss: 0.6518, validation loss: 0.4138
2024-05-25 02:58:48 [INFO]: Epoch 008 - training loss: 0.6190, validation loss: 0.3890
2024-05-25 02:58:50 [INFO]: Epoch 009 - training loss: 0.5930, validation loss: 0.3683
2024-05-25 02:58:53 [INFO]: Epoch 010 - training loss: 0.5702, validation loss: 0.3517
2024-05-25 02:58:56 [INFO]: Epoch 011 - training loss: 0.5536, validation loss: 0.3375
2024-05-25 02:58:59 [INFO]: Epoch 012 - training loss: 0.5390, validation loss: 0.3258
2024-05-25 02:59:01 [INFO]: Epoch 013 - training loss: 0.5246, validation loss: 0.3157
2024-05-25 02:59:04 [INFO]: Epoch 014 - training loss: 0.5144, validation loss: 0.3074
2024-05-25 02:59:07 [INFO]: Epoch 015 - training loss: 0.5034, validation loss: 0.2994
2024-05-25 02:59:10 [INFO]: Epoch 016 - training loss: 0.4938, validation loss: 0.2923
2024-05-25 02:59:13 [INFO]: Epoch 017 - training loss: 0.4865, validation loss: 0.2864
2024-05-25 02:59:15 [INFO]: Epoch 018 - training loss: 0.4771, validation loss: 0.2807
2024-05-25 02:59:18 [INFO]: Epoch 019 - training loss: 0.4695, validation loss: 0.2759
2024-05-25 02:59:21 [INFO]: Epoch 020 - training loss: 0.4614, validation loss: 0.2708
2024-05-25 02:59:24 [INFO]: Epoch 021 - training loss: 0.4560, validation loss: 0.2665
2024-05-25 02:59:26 [INFO]: Epoch 022 - training loss: 0.4480, validation loss: 0.2624
2024-05-25 02:59:29 [INFO]: Epoch 023 - training loss: 0.4419, validation loss: 0.2585
2024-05-25 02:59:32 [INFO]: Epoch 024 - training loss: 0.4359, validation loss: 0.2542
2024-05-25 02:59:35 [INFO]: Epoch 025 - training loss: 0.4297, validation loss: 0.2507
2024-05-25 02:59:38 [INFO]: Epoch 026 - training loss: 0.4244, validation loss: 0.2470
2024-05-25 02:59:40 [INFO]: Epoch 027 - training loss: 0.4194, validation loss: 0.2441
2024-05-25 02:59:43 [INFO]: Epoch 028 - training loss: 0.4144, validation loss: 0.2404
2024-05-25 02:59:46 [INFO]: Epoch 029 - training loss: 0.4110, validation loss: 0.2369
2024-05-25 02:59:49 [INFO]: Epoch 030 - training loss: 0.4056, validation loss: 0.2340
2024-05-25 02:59:52 [INFO]: Epoch 031 - training loss: 0.4007, validation loss: 0.2311
2024-05-25 02:59:54 [INFO]: Epoch 032 - training loss: 0.3958, validation loss: 0.2280
2024-05-25 02:59:57 [INFO]: Epoch 033 - training loss: 0.3920, validation loss: 0.2251
2024-05-25 03:00:00 [INFO]: Epoch 034 - training loss: 0.3877, validation loss: 0.2227
2024-05-25 03:00:03 [INFO]: Epoch 035 - training loss: 0.3835, validation loss: 0.2199
2024-05-25 03:00:05 [INFO]: Epoch 036 - training loss: 0.3803, validation loss: 0.2171
2024-05-25 03:00:08 [INFO]: Epoch 037 - training loss: 0.3765, validation loss: 0.2142
2024-05-25 03:00:11 [INFO]: Epoch 038 - training loss: 0.3740, validation loss: 0.2118
2024-05-25 03:00:14 [INFO]: Epoch 039 - training loss: 0.3694, validation loss: 0.2095
2024-05-25 03:00:17 [INFO]: Epoch 040 - training loss: 0.3670, validation loss: 0.2075
2024-05-25 03:00:19 [INFO]: Epoch 041 - training loss: 0.3628, validation loss: 0.2048
2024-05-25 03:00:22 [INFO]: Epoch 042 - training loss: 0.3597, validation loss: 0.2027
2024-05-25 03:00:25 [INFO]: Epoch 043 - training loss: 0.3577, validation loss: 0.2008
2024-05-25 03:00:28 [INFO]: Epoch 044 - training loss: 0.3555, validation loss: 0.1984
2024-05-25 03:00:30 [INFO]: Epoch 045 - training loss: 0.3516, validation loss: 0.1966
2024-05-25 03:00:33 [INFO]: Epoch 046 - training loss: 0.3494, validation loss: 0.1948
2024-05-25 03:00:36 [INFO]: Epoch 047 - training loss: 0.3470, validation loss: 0.1931
2024-05-25 03:00:39 [INFO]: Epoch 048 - training loss: 0.3452, validation loss: 0.1911
2024-05-25 03:00:42 [INFO]: Epoch 049 - training loss: 0.3418, validation loss: 0.1892
2024-05-25 03:00:44 [INFO]: Epoch 050 - training loss: 0.3396, validation loss: 0.1879
2024-05-25 03:00:47 [INFO]: Epoch 051 - training loss: 0.3367, validation loss: 0.1861
2024-05-25 03:00:50 [INFO]: Epoch 052 - training loss: 0.3345, validation loss: 0.1844
2024-05-25 03:00:53 [INFO]: Epoch 053 - training loss: 0.3337, validation loss: 0.1826
2024-05-25 03:00:55 [INFO]: Epoch 054 - training loss: 0.3305, validation loss: 0.1815
2024-05-25 03:00:58 [INFO]: Epoch 055 - training loss: 0.3287, validation loss: 0.1801
2024-05-25 03:01:01 [INFO]: Epoch 056 - training loss: 0.3270, validation loss: 0.1789
2024-05-25 03:01:04 [INFO]: Epoch 057 - training loss: 0.3249, validation loss: 0.1776
2024-05-25 03:01:06 [INFO]: Epoch 058 - training loss: 0.3233, validation loss: 0.1767
2024-05-25 03:01:09 [INFO]: Epoch 059 - training loss: 0.3215, validation loss: 0.1754
2024-05-25 03:01:12 [INFO]: Epoch 060 - training loss: 0.3213, validation loss: 0.1748
2024-05-25 03:01:15 [INFO]: Epoch 061 - training loss: 0.3191, validation loss: 0.1729
2024-05-25 03:01:18 [INFO]: Epoch 062 - training loss: 0.3168, validation loss: 0.1720
2024-05-25 03:01:20 [INFO]: Epoch 063 - training loss: 0.3146, validation loss: 0.1711
2024-05-25 03:01:23 [INFO]: Epoch 064 - training loss: 0.3134, validation loss: 0.1703
2024-05-25 03:01:26 [INFO]: Epoch 065 - training loss: 0.3127, validation loss: 0.1695
2024-05-25 03:01:29 [INFO]: Epoch 066 - training loss: 0.3109, validation loss: 0.1687
2024-05-25 03:01:31 [INFO]: Epoch 067 - training loss: 0.3100, validation loss: 0.1678
2024-05-25 03:01:34 [INFO]: Epoch 068 - training loss: 0.3083, validation loss: 0.1669
2024-05-25 03:01:37 [INFO]: Epoch 069 - training loss: 0.3071, validation loss: 0.1662
2024-05-25 03:01:40 [INFO]: Epoch 070 - training loss: 0.3051, validation loss: 0.1657
2024-05-25 03:01:43 [INFO]: Epoch 071 - training loss: 0.3041, validation loss: 0.1647
2024-05-25 03:01:45 [INFO]: Epoch 072 - training loss: 0.3034, validation loss: 0.1641
2024-05-25 03:01:48 [INFO]: Epoch 073 - training loss: 0.3024, validation loss: 0.1632
2024-05-25 03:01:51 [INFO]: Epoch 074 - training loss: 0.3010, validation loss: 0.1626
2024-05-25 03:01:54 [INFO]: Epoch 075 - training loss: 0.2996, validation loss: 0.1623
2024-05-25 03:01:57 [INFO]: Epoch 076 - training loss: 0.2992, validation loss: 0.1612
2024-05-25 03:01:59 [INFO]: Epoch 077 - training loss: 0.2976, validation loss: 0.1606
2024-05-25 03:02:02 [INFO]: Epoch 078 - training loss: 0.2964, validation loss: 0.1600
2024-05-25 03:02:05 [INFO]: Epoch 079 - training loss: 0.2962, validation loss: 0.1596
2024-05-25 03:02:08 [INFO]: Epoch 080 - training loss: 0.2949, validation loss: 0.1590
2024-05-25 03:02:10 [INFO]: Epoch 081 - training loss: 0.2944, validation loss: 0.1581
2024-05-25 03:02:13 [INFO]: Epoch 082 - training loss: 0.2927, validation loss: 0.1578
2024-05-25 03:02:16 [INFO]: Epoch 083 - training loss: 0.2918, validation loss: 0.1570
2024-05-25 03:02:19 [INFO]: Epoch 084 - training loss: 0.2915, validation loss: 0.1565
2024-05-25 03:02:21 [INFO]: Epoch 085 - training loss: 0.2904, validation loss: 0.1562
2024-05-25 03:02:24 [INFO]: Epoch 086 - training loss: 0.2900, validation loss: 0.1555
2024-05-25 03:02:27 [INFO]: Epoch 087 - training loss: 0.2891, validation loss: 0.1551
2024-05-25 03:02:30 [INFO]: Epoch 088 - training loss: 0.2883, validation loss: 0.1546
2024-05-25 03:02:33 [INFO]: Epoch 089 - training loss: 0.2876, validation loss: 0.1542
2024-05-25 03:02:35 [INFO]: Epoch 090 - training loss: 0.2867, validation loss: 0.1536
2024-05-25 03:02:38 [INFO]: Epoch 091 - training loss: 0.2859, validation loss: 0.1529
2024-05-25 03:02:41 [INFO]: Epoch 092 - training loss: 0.2849, validation loss: 0.1526
2024-05-25 03:02:44 [INFO]: Epoch 093 - training loss: 0.2849, validation loss: 0.1523
2024-05-25 03:02:46 [INFO]: Epoch 094 - training loss: 0.2838, validation loss: 0.1516
2024-05-25 03:02:49 [INFO]: Epoch 095 - training loss: 0.2833, validation loss: 0.1512
2024-05-25 03:02:52 [INFO]: Epoch 096 - training loss: 0.2827, validation loss: 0.1508
2024-05-25 03:02:55 [INFO]: Epoch 097 - training loss: 0.2814, validation loss: 0.1504
2024-05-25 03:02:58 [INFO]: Epoch 098 - training loss: 0.2813, validation loss: 0.1499
2024-05-25 03:03:00 [INFO]: Epoch 099 - training loss: 0.2800, validation loss: 0.1493
2024-05-25 03:03:03 [INFO]: Epoch 100 - training loss: 0.2795, validation loss: 0.1490
2024-05-25 03:03:06 [INFO]: Epoch 101 - training loss: 0.2789, validation loss: 0.1487
2024-05-25 03:03:09 [INFO]: Epoch 102 - training loss: 0.2782, validation loss: 0.1482
2024-05-25 03:03:11 [INFO]: Epoch 103 - training loss: 0.2782, validation loss: 0.1477
2024-05-25 03:03:14 [INFO]: Epoch 104 - training loss: 0.2772, validation loss: 0.1473
2024-05-25 03:03:17 [INFO]: Epoch 105 - training loss: 0.2764, validation loss: 0.1471
2024-05-25 03:03:20 [INFO]: Epoch 106 - training loss: 0.2764, validation loss: 0.1465
2024-05-25 03:03:23 [INFO]: Epoch 107 - training loss: 0.2755, validation loss: 0.1462
2024-05-25 03:03:25 [INFO]: Epoch 108 - training loss: 0.2752, validation loss: 0.1455
2024-05-25 03:03:28 [INFO]: Epoch 109 - training loss: 0.2744, validation loss: 0.1454
2024-05-25 03:03:31 [INFO]: Epoch 110 - training loss: 0.2735, validation loss: 0.1451
2024-05-25 03:03:34 [INFO]: Epoch 111 - training loss: 0.2738, validation loss: 0.1447
2024-05-25 03:03:36 [INFO]: Epoch 112 - training loss: 0.2734, validation loss: 0.1441
2024-05-25 03:03:39 [INFO]: Epoch 113 - training loss: 0.2722, validation loss: 0.1438
2024-05-25 03:03:42 [INFO]: Epoch 114 - training loss: 0.2713, validation loss: 0.1432
2024-05-25 03:03:45 [INFO]: Epoch 115 - training loss: 0.2712, validation loss: 0.1429
2024-05-25 03:03:48 [INFO]: Epoch 116 - training loss: 0.2704, validation loss: 0.1427
2024-05-25 03:03:50 [INFO]: Epoch 117 - training loss: 0.2704, validation loss: 0.1424
2024-05-25 03:03:53 [INFO]: Epoch 118 - training loss: 0.2698, validation loss: 0.1418
2024-05-25 03:03:56 [INFO]: Epoch 119 - training loss: 0.2690, validation loss: 0.1417
2024-05-25 03:03:59 [INFO]: Epoch 120 - training loss: 0.2687, validation loss: 0.1413
2024-05-25 03:04:01 [INFO]: Epoch 121 - training loss: 0.2682, validation loss: 0.1409
2024-05-25 03:04:04 [INFO]: Epoch 122 - training loss: 0.2674, validation loss: 0.1405
2024-05-25 03:04:07 [INFO]: Epoch 123 - training loss: 0.2670, validation loss: 0.1402
2024-05-25 03:04:10 [INFO]: Epoch 124 - training loss: 0.2667, validation loss: 0.1397
2024-05-25 03:04:13 [INFO]: Epoch 125 - training loss: 0.2663, validation loss: 0.1397
2024-05-25 03:04:15 [INFO]: Epoch 126 - training loss: 0.2662, validation loss: 0.1391
2024-05-25 03:04:18 [INFO]: Epoch 127 - training loss: 0.2650, validation loss: 0.1387
2024-05-25 03:04:21 [INFO]: Epoch 128 - training loss: 0.2653, validation loss: 0.1385
2024-05-25 03:04:24 [INFO]: Epoch 129 - training loss: 0.2651, validation loss: 0.1384
2024-05-25 03:04:26 [INFO]: Epoch 130 - training loss: 0.2651, validation loss: 0.1382
2024-05-25 03:04:29 [INFO]: Epoch 131 - training loss: 0.2637, validation loss: 0.1375
2024-05-25 03:04:32 [INFO]: Epoch 132 - training loss: 0.2633, validation loss: 0.1372
2024-05-25 03:04:35 [INFO]: Epoch 133 - training loss: 0.2628, validation loss: 0.1371
2024-05-25 03:04:37 [INFO]: Epoch 134 - training loss: 0.2626, validation loss: 0.1367
2024-05-25 03:04:40 [INFO]: Epoch 135 - training loss: 0.2627, validation loss: 0.1363
2024-05-25 03:04:43 [INFO]: Epoch 136 - training loss: 0.2615, validation loss: 0.1361
2024-05-25 03:04:46 [INFO]: Epoch 137 - training loss: 0.2617, validation loss: 0.1357
2024-05-25 03:04:49 [INFO]: Epoch 138 - training loss: 0.2607, validation loss: 0.1353
2024-05-25 03:04:51 [INFO]: Epoch 139 - training loss: 0.2608, validation loss: 0.1352
2024-05-25 03:04:54 [INFO]: Epoch 140 - training loss: 0.2604, validation loss: 0.1349
2024-05-25 03:04:57 [INFO]: Epoch 141 - training loss: 0.2600, validation loss: 0.1346
2024-05-25 03:05:00 [INFO]: Epoch 142 - training loss: 0.2597, validation loss: 0.1345
2024-05-25 03:05:02 [INFO]: Epoch 143 - training loss: 0.2589, validation loss: 0.1341
2024-05-25 03:05:05 [INFO]: Epoch 144 - training loss: 0.2586, validation loss: 0.1339
2024-05-25 03:05:08 [INFO]: Epoch 145 - training loss: 0.2584, validation loss: 0.1335
2024-05-25 03:05:11 [INFO]: Epoch 146 - training loss: 0.2585, validation loss: 0.1334
2024-05-25 03:05:13 [INFO]: Epoch 147 - training loss: 0.2573, validation loss: 0.1332
2024-05-25 03:05:16 [INFO]: Epoch 148 - training loss: 0.2571, validation loss: 0.1328
2024-05-25 03:05:19 [INFO]: Epoch 149 - training loss: 0.2567, validation loss: 0.1327
2024-05-25 03:05:22 [INFO]: Epoch 150 - training loss: 0.2565, validation loss: 0.1321
2024-05-25 03:05:25 [INFO]: Epoch 151 - training loss: 0.2564, validation loss: 0.1322
2024-05-25 03:05:27 [INFO]: Epoch 152 - training loss: 0.2558, validation loss: 0.1318
2024-05-25 03:05:30 [INFO]: Epoch 153 - training loss: 0.2553, validation loss: 0.1315
2024-05-25 03:05:33 [INFO]: Epoch 154 - training loss: 0.2554, validation loss: 0.1313
2024-05-25 03:05:36 [INFO]: Epoch 155 - training loss: 0.2551, validation loss: 0.1311
2024-05-25 03:05:38 [INFO]: Epoch 156 - training loss: 0.2547, validation loss: 0.1311
2024-05-25 03:05:41 [INFO]: Epoch 157 - training loss: 0.2550, validation loss: 0.1309
2024-05-25 03:05:44 [INFO]: Epoch 158 - training loss: 0.2539, validation loss: 0.1305
2024-05-25 03:05:47 [INFO]: Epoch 159 - training loss: 0.2547, validation loss: 0.1301
2024-05-25 03:05:50 [INFO]: Epoch 160 - training loss: 0.2533, validation loss: 0.1301
2024-05-25 03:05:52 [INFO]: Epoch 161 - training loss: 0.2533, validation loss: 0.1297
2024-05-25 03:05:55 [INFO]: Epoch 162 - training loss: 0.2531, validation loss: 0.1298
2024-05-25 03:05:58 [INFO]: Epoch 163 - training loss: 0.2529, validation loss: 0.1294
2024-05-25 03:06:01 [INFO]: Epoch 164 - training loss: 0.2521, validation loss: 0.1293
2024-05-25 03:06:03 [INFO]: Epoch 165 - training loss: 0.2522, validation loss: 0.1291
2024-05-25 03:06:06 [INFO]: Epoch 166 - training loss: 0.2519, validation loss: 0.1289
2024-05-25 03:06:09 [INFO]: Epoch 167 - training loss: 0.2514, validation loss: 0.1287
2024-05-25 03:06:12 [INFO]: Epoch 168 - training loss: 0.2517, validation loss: 0.1285
2024-05-25 03:06:15 [INFO]: Epoch 169 - training loss: 0.2510, validation loss: 0.1281
2024-05-25 03:06:18 [INFO]: Epoch 170 - training loss: 0.2509, validation loss: 0.1282
2024-05-25 03:06:21 [INFO]: Epoch 171 - training loss: 0.2505, validation loss: 0.1278
2024-05-25 03:06:23 [INFO]: Epoch 172 - training loss: 0.2505, validation loss: 0.1277
2024-05-25 03:06:26 [INFO]: Epoch 173 - training loss: 0.2502, validation loss: 0.1274
2024-05-25 03:06:29 [INFO]: Epoch 174 - training loss: 0.2496, validation loss: 0.1273
2024-05-25 03:06:32 [INFO]: Epoch 175 - training loss: 0.2497, validation loss: 0.1272
2024-05-25 03:06:35 [INFO]: Epoch 176 - training loss: 0.2492, validation loss: 0.1270
2024-05-25 03:06:37 [INFO]: Epoch 177 - training loss: 0.2489, validation loss: 0.1268
2024-05-25 03:06:40 [INFO]: Epoch 178 - training loss: 0.2485, validation loss: 0.1268
2024-05-25 03:06:43 [INFO]: Epoch 179 - training loss: 0.2484, validation loss: 0.1265
2024-05-25 03:06:46 [INFO]: Epoch 180 - training loss: 0.2481, validation loss: 0.1265
2024-05-25 03:06:48 [INFO]: Epoch 181 - training loss: 0.2476, validation loss: 0.1262
2024-05-25 03:06:51 [INFO]: Epoch 182 - training loss: 0.2475, validation loss: 0.1261
2024-05-25 03:06:54 [INFO]: Epoch 183 - training loss: 0.2475, validation loss: 0.1258
2024-05-25 03:06:57 [INFO]: Epoch 184 - training loss: 0.2476, validation loss: 0.1256
2024-05-25 03:07:00 [INFO]: Epoch 185 - training loss: 0.2473, validation loss: 0.1255
2024-05-25 03:07:02 [INFO]: Epoch 186 - training loss: 0.2466, validation loss: 0.1254
2024-05-25 03:07:05 [INFO]: Epoch 187 - training loss: 0.2469, validation loss: 0.1251
2024-05-25 03:07:08 [INFO]: Epoch 188 - training loss: 0.2464, validation loss: 0.1250
2024-05-25 03:07:11 [INFO]: Epoch 189 - training loss: 0.2463, validation loss: 0.1247
2024-05-25 03:07:14 [INFO]: Epoch 190 - training loss: 0.2461, validation loss: 0.1248
2024-05-25 03:07:16 [INFO]: Epoch 191 - training loss: 0.2455, validation loss: 0.1245
2024-05-25 03:07:19 [INFO]: Epoch 192 - training loss: 0.2457, validation loss: 0.1247
2024-05-25 03:07:22 [INFO]: Epoch 193 - training loss: 0.2450, validation loss: 0.1243
2024-05-25 03:07:25 [INFO]: Epoch 194 - training loss: 0.2448, validation loss: 0.1243
2024-05-25 03:07:27 [INFO]: Epoch 195 - training loss: 0.2452, validation loss: 0.1243
2024-05-25 03:07:30 [INFO]: Epoch 196 - training loss: 0.2452, validation loss: 0.1241
2024-05-25 03:07:33 [INFO]: Epoch 197 - training loss: 0.2442, validation loss: 0.1238
2024-05-25 03:07:36 [INFO]: Epoch 198 - training loss: 0.2447, validation loss: 0.1236
2024-05-25 03:07:39 [INFO]: Epoch 199 - training loss: 0.2439, validation loss: 0.1234
2024-05-25 03:07:41 [INFO]: Epoch 200 - training loss: 0.2435, validation loss: 0.1235
2024-05-25 03:07:44 [INFO]: Epoch 201 - training loss: 0.2432, validation loss: 0.1235
2024-05-25 03:07:47 [INFO]: Epoch 202 - training loss: 0.2437, validation loss: 0.1232
2024-05-25 03:07:50 [INFO]: Epoch 203 - training loss: 0.2434, validation loss: 0.1228
2024-05-25 03:07:53 [INFO]: Epoch 204 - training loss: 0.2426, validation loss: 0.1231
2024-05-25 03:07:55 [INFO]: Epoch 205 - training loss: 0.2427, validation loss: 0.1227
2024-05-25 03:07:58 [INFO]: Epoch 206 - training loss: 0.2428, validation loss: 0.1225
2024-05-25 03:08:01 [INFO]: Epoch 207 - training loss: 0.2425, validation loss: 0.1226
2024-05-25 03:08:04 [INFO]: Epoch 208 - training loss: 0.2424, validation loss: 0.1222
2024-05-25 03:08:06 [INFO]: Epoch 209 - training loss: 0.2417, validation loss: 0.1225
2024-05-25 03:08:09 [INFO]: Epoch 210 - training loss: 0.2418, validation loss: 0.1220
2024-05-25 03:08:12 [INFO]: Epoch 211 - training loss: 0.2422, validation loss: 0.1220
2024-05-25 03:08:15 [INFO]: Epoch 212 - training loss: 0.2412, validation loss: 0.1218
2024-05-25 03:08:18 [INFO]: Epoch 213 - training loss: 0.2413, validation loss: 0.1218
2024-05-25 03:08:20 [INFO]: Epoch 214 - training loss: 0.2408, validation loss: 0.1217
2024-05-25 03:08:23 [INFO]: Epoch 215 - training loss: 0.2412, validation loss: 0.1215
2024-05-25 03:08:26 [INFO]: Epoch 216 - training loss: 0.2410, validation loss: 0.1215
2024-05-25 03:08:29 [INFO]: Epoch 217 - training loss: 0.2408, validation loss: 0.1212
2024-05-25 03:08:32 [INFO]: Epoch 218 - training loss: 0.2403, validation loss: 0.1212
2024-05-25 03:08:34 [INFO]: Epoch 219 - training loss: 0.2403, validation loss: 0.1211
2024-05-25 03:08:37 [INFO]: Epoch 220 - training loss: 0.2402, validation loss: 0.1209
2024-05-25 03:08:40 [INFO]: Epoch 221 - training loss: 0.2400, validation loss: 0.1208
2024-05-25 03:08:43 [INFO]: Epoch 222 - training loss: 0.2399, validation loss: 0.1208
2024-05-25 03:08:45 [INFO]: Epoch 223 - training loss: 0.2389, validation loss: 0.1207
2024-05-25 03:08:48 [INFO]: Epoch 224 - training loss: 0.2394, validation loss: 0.1208
2024-05-25 03:08:51 [INFO]: Epoch 225 - training loss: 0.2394, validation loss: 0.1206
2024-05-25 03:08:54 [INFO]: Epoch 226 - training loss: 0.2394, validation loss: 0.1203
2024-05-25 03:08:57 [INFO]: Epoch 227 - training loss: 0.2388, validation loss: 0.1202
2024-05-25 03:08:59 [INFO]: Epoch 228 - training loss: 0.2386, validation loss: 0.1203
2024-05-25 03:09:02 [INFO]: Epoch 229 - training loss: 0.2387, validation loss: 0.1202
2024-05-25 03:09:05 [INFO]: Epoch 230 - training loss: 0.2386, validation loss: 0.1200
2024-05-25 03:09:08 [INFO]: Epoch 231 - training loss: 0.2386, validation loss: 0.1199
2024-05-25 03:09:11 [INFO]: Epoch 232 - training loss: 0.2373, validation loss: 0.1196
2024-05-25 03:09:13 [INFO]: Epoch 233 - training loss: 0.2378, validation loss: 0.1199
2024-05-25 03:09:16 [INFO]: Epoch 234 - training loss: 0.2378, validation loss: 0.1195
2024-05-25 03:09:19 [INFO]: Epoch 235 - training loss: 0.2375, validation loss: 0.1195
2024-05-25 03:09:22 [INFO]: Epoch 236 - training loss: 0.2374, validation loss: 0.1194
2024-05-25 03:09:25 [INFO]: Epoch 237 - training loss: 0.2373, validation loss: 0.1193
2024-05-25 03:09:27 [INFO]: Epoch 238 - training loss: 0.2371, validation loss: 0.1191
2024-05-25 03:09:30 [INFO]: Epoch 239 - training loss: 0.2370, validation loss: 0.1192
2024-05-25 03:09:33 [INFO]: Epoch 240 - training loss: 0.2369, validation loss: 0.1190
2024-05-25 03:09:36 [INFO]: Epoch 241 - training loss: 0.2371, validation loss: 0.1189
2024-05-25 03:09:38 [INFO]: Epoch 242 - training loss: 0.2364, validation loss: 0.1188
2024-05-25 03:09:41 [INFO]: Epoch 243 - training loss: 0.2363, validation loss: 0.1189
2024-05-25 03:09:44 [INFO]: Epoch 244 - training loss: 0.2364, validation loss: 0.1187
2024-05-25 03:09:47 [INFO]: Epoch 245 - training loss: 0.2357, validation loss: 0.1188
2024-05-25 03:09:50 [INFO]: Epoch 246 - training loss: 0.2356, validation loss: 0.1186
2024-05-25 03:09:53 [INFO]: Epoch 247 - training loss: 0.2358, validation loss: 0.1183
2024-05-25 03:09:55 [INFO]: Epoch 248 - training loss: 0.2360, validation loss: 0.1185
2024-05-25 03:09:58 [INFO]: Epoch 249 - training loss: 0.2353, validation loss: 0.1185
2024-05-25 03:10:01 [INFO]: Epoch 250 - training loss: 0.2355, validation loss: 0.1182
2024-05-25 03:10:04 [INFO]: Epoch 251 - training loss: 0.2355, validation loss: 0.1180
2024-05-25 03:10:06 [INFO]: Epoch 252 - training loss: 0.2356, validation loss: 0.1181
2024-05-25 03:10:09 [INFO]: Epoch 253 - training loss: 0.2352, validation loss: 0.1180
2024-05-25 03:10:12 [INFO]: Epoch 254 - training loss: 0.2345, validation loss: 0.1180
2024-05-25 03:10:15 [INFO]: Epoch 255 - training loss: 0.2348, validation loss: 0.1179
2024-05-25 03:10:17 [INFO]: Epoch 256 - training loss: 0.2344, validation loss: 0.1180
2024-05-25 03:10:20 [INFO]: Epoch 257 - training loss: 0.2345, validation loss: 0.1180
2024-05-25 03:10:23 [INFO]: Epoch 258 - training loss: 0.2344, validation loss: 0.1177
2024-05-25 03:10:26 [INFO]: Epoch 259 - training loss: 0.2340, validation loss: 0.1177
2024-05-25 03:10:29 [INFO]: Epoch 260 - training loss: 0.2341, validation loss: 0.1177
2024-05-25 03:10:31 [INFO]: Epoch 261 - training loss: 0.2343, validation loss: 0.1174
2024-05-25 03:10:34 [INFO]: Epoch 262 - training loss: 0.2338, validation loss: 0.1173
2024-05-25 03:10:37 [INFO]: Epoch 263 - training loss: 0.2342, validation loss: 0.1174
2024-05-25 03:10:40 [INFO]: Epoch 264 - training loss: 0.2334, validation loss: 0.1173
2024-05-25 03:10:42 [INFO]: Epoch 265 - training loss: 0.2334, validation loss: 0.1173
2024-05-25 03:10:45 [INFO]: Epoch 266 - training loss: 0.2334, validation loss: 0.1172
2024-05-25 03:10:48 [INFO]: Epoch 267 - training loss: 0.2328, validation loss: 0.1173
2024-05-25 03:10:51 [INFO]: Epoch 268 - training loss: 0.2332, validation loss: 0.1170
2024-05-25 03:10:53 [INFO]: Epoch 269 - training loss: 0.2328, validation loss: 0.1172
2024-05-25 03:10:56 [INFO]: Epoch 270 - training loss: 0.2326, validation loss: 0.1172
2024-05-25 03:10:59 [INFO]: Epoch 271 - training loss: 0.2327, validation loss: 0.1170
2024-05-25 03:11:02 [INFO]: Epoch 272 - training loss: 0.2330, validation loss: 0.1167
2024-05-25 03:11:05 [INFO]: Epoch 273 - training loss: 0.2333, validation loss: 0.1168
2024-05-25 03:11:07 [INFO]: Epoch 274 - training loss: 0.2320, validation loss: 0.1166
2024-05-25 03:11:10 [INFO]: Epoch 275 - training loss: 0.2320, validation loss: 0.1166
2024-05-25 03:11:13 [INFO]: Epoch 276 - training loss: 0.2322, validation loss: 0.1166
2024-05-25 03:11:16 [INFO]: Epoch 277 - training loss: 0.2317, validation loss: 0.1165
2024-05-25 03:11:18 [INFO]: Epoch 278 - training loss: 0.2314, validation loss: 0.1166
2024-05-25 03:11:21 [INFO]: Epoch 279 - training loss: 0.2312, validation loss: 0.1168
2024-05-25 03:11:24 [INFO]: Epoch 280 - training loss: 0.2315, validation loss: 0.1165
2024-05-25 03:11:27 [INFO]: Epoch 281 - training loss: 0.2314, validation loss: 0.1162
2024-05-25 03:11:29 [INFO]: Epoch 282 - training loss: 0.2314, validation loss: 0.1166
2024-05-25 03:11:32 [INFO]: Epoch 283 - training loss: 0.2313, validation loss: 0.1164
2024-05-25 03:11:35 [INFO]: Epoch 284 - training loss: 0.2314, validation loss: 0.1164
2024-05-25 03:11:38 [INFO]: Epoch 285 - training loss: 0.2310, validation loss: 0.1166
2024-05-25 03:11:41 [INFO]: Epoch 286 - training loss: 0.2310, validation loss: 0.1164
2024-05-25 03:11:43 [INFO]: Epoch 287 - training loss: 0.2310, validation loss: 0.1162
2024-05-25 03:11:46 [INFO]: Epoch 288 - training loss: 0.2303, validation loss: 0.1162
2024-05-25 03:11:49 [INFO]: Epoch 289 - training loss: 0.2306, validation loss: 0.1160
2024-05-25 03:11:52 [INFO]: Epoch 290 - training loss: 0.2304, validation loss: 0.1162
2024-05-25 03:11:54 [INFO]: Epoch 291 - training loss: 0.2303, validation loss: 0.1160
2024-05-25 03:11:57 [INFO]: Epoch 292 - training loss: 0.2306, validation loss: 0.1160
2024-05-25 03:12:00 [INFO]: Epoch 293 - training loss: 0.2301, validation loss: 0.1158
2024-05-25 03:12:03 [INFO]: Epoch 294 - training loss: 0.2299, validation loss: 0.1158
2024-05-25 03:12:06 [INFO]: Epoch 295 - training loss: 0.2297, validation loss: 0.1159
2024-05-25 03:12:08 [INFO]: Epoch 296 - training loss: 0.2301, validation loss: 0.1157
2024-05-25 03:12:11 [INFO]: Epoch 297 - training loss: 0.2296, validation loss: 0.1158
2024-05-25 03:12:14 [INFO]: Epoch 298 - training loss: 0.2297, validation loss: 0.1158
2024-05-25 03:12:17 [INFO]: Epoch 299 - training loss: 0.2292, validation loss: 0.1160
2024-05-25 03:12:19 [INFO]: Epoch 300 - training loss: 0.2295, validation loss: 0.1157
2024-05-25 03:12:19 [INFO]: Finished training. The best model is from epoch#300.
2024-05-25 03:12:19 [INFO]: Saved the model to augmentation_saved_results/round_1/BRITS_air_quality/20240525_T025825/BRITS.pypots
2024-05-25 03:12:20 [INFO]: BRITS on Air-Quality: MAE=0.1543, MSE=0.1641
2024-05-25 03:12:20 [INFO]: Successfully saved to augmentation_saved_results/round_1/BRITS_air_quality/imputation.pkl
2024-05-25 03:12:20 [INFO]: Using the given device: cuda:0
2024-05-25 03:12:20 [INFO]: Model files will be saved to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220
2024-05-25 03:12:20 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/tensorboard
2024-05-25 03:12:20 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 03:12:25 [INFO]: Epoch 001 - training loss: 1.4057, validation loss: 0.7961
2024-05-25 03:12:25 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch1_loss0.796119225025177.pypots
2024-05-25 03:12:29 [INFO]: Epoch 002 - training loss: 1.0566, validation loss: 0.7442
2024-05-25 03:12:29 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch2_loss0.7442163795232772.pypots
2024-05-25 03:12:32 [INFO]: Epoch 003 - training loss: 0.9967, validation loss: 0.7271
2024-05-25 03:12:32 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch3_loss0.727076244354248.pypots
2024-05-25 03:12:36 [INFO]: Epoch 004 - training loss: 0.9537, validation loss: 0.7142
2024-05-25 03:12:36 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch4_loss0.7142231404781342.pypots
2024-05-25 03:12:40 [INFO]: Epoch 005 - training loss: 0.9590, validation loss: 0.7058
2024-05-25 03:12:40 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch5_loss0.7057694375514985.pypots
2024-05-25 03:12:44 [INFO]: Epoch 006 - training loss: 0.9468, validation loss: 0.6994
2024-05-25 03:12:44 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch6_loss0.6993704229593277.pypots
2024-05-25 03:12:48 [INFO]: Epoch 007 - training loss: 0.9406, validation loss: 0.6951
2024-05-25 03:12:48 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch7_loss0.6950933009386062.pypots
2024-05-25 03:12:52 [INFO]: Epoch 008 - training loss: 0.9303, validation loss: 0.6929
2024-05-25 03:12:52 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch8_loss0.692850312590599.pypots
2024-05-25 03:12:55 [INFO]: Epoch 009 - training loss: 0.9150, validation loss: 0.6886
2024-05-25 03:12:55 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch9_loss0.6885866224765778.pypots
2024-05-25 03:12:59 [INFO]: Epoch 010 - training loss: 0.9179, validation loss: 0.6876
2024-05-25 03:12:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch10_loss0.6876001864671707.pypots
2024-05-25 03:13:03 [INFO]: Epoch 011 - training loss: 0.8966, validation loss: 0.6860
2024-05-25 03:13:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch11_loss0.6859620779752731.pypots
2024-05-25 03:13:07 [INFO]: Epoch 012 - training loss: 0.9000, validation loss: 0.6855
2024-05-25 03:13:07 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch12_loss0.6855082213878632.pypots
2024-05-25 03:13:11 [INFO]: Epoch 013 - training loss: 0.9267, validation loss: 0.6833
2024-05-25 03:13:11 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch13_loss0.6832580596208573.pypots
2024-05-25 03:13:15 [INFO]: Epoch 014 - training loss: 0.9297, validation loss: 0.6843
2024-05-25 03:13:15 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch14_loss0.6842719465494156.pypots
2024-05-25 03:13:18 [INFO]: Epoch 015 - training loss: 0.9160, validation loss: 0.6845
2024-05-25 03:13:18 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch15_loss0.684478223323822.pypots
2024-05-25 03:13:22 [INFO]: Epoch 016 - training loss: 0.9024, validation loss: 0.6828
2024-05-25 03:13:22 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch16_loss0.6827672868967056.pypots
2024-05-25 03:13:26 [INFO]: Epoch 017 - training loss: 0.8800, validation loss: 0.6832
2024-05-25 03:13:26 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch17_loss0.6831592589616775.pypots
2024-05-25 03:13:30 [INFO]: Epoch 018 - training loss: 0.8785, validation loss: 0.6819
2024-05-25 03:13:30 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch18_loss0.6818933337926865.pypots
2024-05-25 03:13:34 [INFO]: Epoch 019 - training loss: 0.8901, validation loss: 0.6820
2024-05-25 03:13:34 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch19_loss0.6820059716701508.pypots
2024-05-25 03:13:38 [INFO]: Epoch 020 - training loss: 0.8724, validation loss: 0.6835
2024-05-25 03:13:38 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch20_loss0.6834863871335983.pypots
2024-05-25 03:13:41 [INFO]: Epoch 021 - training loss: 0.8820, validation loss: 0.6848
2024-05-25 03:13:41 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch21_loss0.6847755938768387.pypots
2024-05-25 03:13:45 [INFO]: Epoch 022 - training loss: 0.8731, validation loss: 0.6833
2024-05-25 03:13:45 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch22_loss0.6832793027162551.pypots
2024-05-25 03:13:49 [INFO]: Epoch 023 - training loss: 0.8644, validation loss: 0.6859
2024-05-25 03:13:49 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch23_loss0.6858772158622741.pypots
2024-05-25 03:13:53 [INFO]: Epoch 024 - training loss: 0.8667, validation loss: 0.6842
2024-05-25 03:13:53 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch24_loss0.6841946005821228.pypots
2024-05-25 03:13:57 [INFO]: Epoch 025 - training loss: 0.8798, validation loss: 0.6854
2024-05-25 03:13:57 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch25_loss0.6853698641061783.pypots
2024-05-25 03:14:00 [INFO]: Epoch 026 - training loss: 0.8594, validation loss: 0.6873
2024-05-25 03:14:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch26_loss0.6872761219739913.pypots
2024-05-25 03:14:04 [INFO]: Epoch 027 - training loss: 0.8618, validation loss: 0.6898
2024-05-25 03:14:04 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch27_loss0.689767187833786.pypots
2024-05-25 03:14:08 [INFO]: Epoch 028 - training loss: 0.8516, validation loss: 0.6924
2024-05-25 03:14:08 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN_epoch28_loss0.6923529148101807.pypots
2024-05-25 03:14:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:14:08 [INFO]: Finished training. The best model is from epoch#18.
2024-05-25 03:14:08 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240525_T031220/MRNN.pypots
2024-05-25 03:14:09 [INFO]: MRNN on Air-Quality: MAE=0.5334, MSE=0.7087
2024-05-25 03:14:09 [INFO]: Successfully saved to augmentation_saved_results/round_1/MRNN_air_quality/imputation.pkl
2024-05-25 03:14:09 [INFO]: Using the given device: cpu
2024-05-25 03:14:09 [INFO]: LOCF on Air-Quality: MAE=0.2206, MSE=0.3343
2024-05-25 03:14:09 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_air_quality".
2024-05-25 03:14:09 [INFO]: Successfully saved to augmentation_saved_results/round_1/LOCF_air_quality/imputation.pkl
2024-05-25 03:14:09 [INFO]: Median on Air-Quality: MAE=0.6668, MSE=1.0938
2024-05-25 03:14:09 [INFO]: Successfully created the given path "saved_results/round_1/Median_air_quality".
2024-05-25 03:14:09 [INFO]: Successfully saved to augmentation_saved_results/round_1/Median_air_quality/imputation.pkl
2024-05-25 03:14:09 [INFO]: Mean on Air-Quality: MAE=0.6965, MSE=1.0305
2024-05-25 03:14:09 [INFO]: Successfully created the given path "saved_results/round_1/Mean_air_quality".
2024-05-25 03:14:09 [INFO]: Successfully saved to augmentation_saved_results/round_1/Mean_air_quality/imputation.pkl
2024-05-25 03:14:09 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-25 03:14:09 [INFO]: Using the given device: cuda:0
2024-05-25 03:14:09 [INFO]: Model files will be saved to augmentation_saved_results/round_2/SAITS_air_quality/20240525_T031409
2024-05-25 03:14:09 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/SAITS_air_quality/20240525_T031409/tensorboard
2024-05-25 03:14:09 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 03:14:10 [INFO]: Epoch 001 - training loss: 1.0583, validation loss: 0.5392
2024-05-25 03:14:11 [INFO]: Epoch 002 - training loss: 0.7601, validation loss: 0.4078
2024-05-25 03:14:11 [INFO]: Epoch 003 - training loss: 0.6514, validation loss: 0.3291
2024-05-25 03:14:12 [INFO]: Epoch 004 - training loss: 0.5814, validation loss: 0.2873
2024-05-25 03:14:13 [INFO]: Epoch 005 - training loss: 0.5266, validation loss: 0.2640
2024-05-25 03:14:13 [INFO]: Epoch 006 - training loss: 0.4869, validation loss: 0.2483
2024-05-25 03:14:14 [INFO]: Epoch 007 - training loss: 0.4604, validation loss: 0.2379
2024-05-25 03:14:15 [INFO]: Epoch 008 - training loss: 0.4394, validation loss: 0.2308
2024-05-25 03:14:15 [INFO]: Epoch 009 - training loss: 0.4256, validation loss: 0.2236
2024-05-25 03:14:16 [INFO]: Epoch 010 - training loss: 0.4135, validation loss: 0.2189
2024-05-25 03:14:17 [INFO]: Epoch 011 - training loss: 0.4031, validation loss: 0.2182
2024-05-25 03:14:17 [INFO]: Epoch 012 - training loss: 0.3973, validation loss: 0.2122
2024-05-25 03:14:18 [INFO]: Epoch 013 - training loss: 0.3884, validation loss: 0.2096
2024-05-25 03:14:19 [INFO]: Epoch 014 - training loss: 0.3812, validation loss: 0.2071
2024-05-25 03:14:19 [INFO]: Epoch 015 - training loss: 0.3764, validation loss: 0.2035
2024-05-25 03:14:20 [INFO]: Epoch 016 - training loss: 0.3714, validation loss: 0.2014
2024-05-25 03:14:21 [INFO]: Epoch 017 - training loss: 0.3659, validation loss: 0.1992
2024-05-25 03:14:21 [INFO]: Epoch 018 - training loss: 0.3589, validation loss: 0.1976
2024-05-25 03:14:22 [INFO]: Epoch 019 - training loss: 0.3567, validation loss: 0.1955
2024-05-25 03:14:23 [INFO]: Epoch 020 - training loss: 0.3521, validation loss: 0.1944
2024-05-25 03:14:23 [INFO]: Epoch 021 - training loss: 0.3495, validation loss: 0.1939
2024-05-25 03:14:24 [INFO]: Epoch 022 - training loss: 0.3464, validation loss: 0.1912
2024-05-25 03:14:25 [INFO]: Epoch 023 - training loss: 0.3426, validation loss: 0.1899
2024-05-25 03:14:25 [INFO]: Epoch 024 - training loss: 0.3398, validation loss: 0.1875
2024-05-25 03:14:26 [INFO]: Epoch 025 - training loss: 0.3379, validation loss: 0.1860
2024-05-25 03:14:27 [INFO]: Epoch 026 - training loss: 0.3340, validation loss: 0.1847
2024-05-25 03:14:27 [INFO]: Epoch 027 - training loss: 0.3309, validation loss: 0.1847
2024-05-25 03:14:28 [INFO]: Epoch 028 - training loss: 0.3291, validation loss: 0.1831
2024-05-25 03:14:29 [INFO]: Epoch 029 - training loss: 0.3272, validation loss: 0.1818
2024-05-25 03:14:29 [INFO]: Epoch 030 - training loss: 0.3262, validation loss: 0.1804
2024-05-25 03:14:30 [INFO]: Epoch 031 - training loss: 0.3233, validation loss: 0.1796
2024-05-25 03:14:31 [INFO]: Epoch 032 - training loss: 0.3205, validation loss: 0.1778
2024-05-25 03:14:31 [INFO]: Epoch 033 - training loss: 0.3174, validation loss: 0.1770
2024-05-25 03:14:32 [INFO]: Epoch 034 - training loss: 0.3168, validation loss: 0.1765
2024-05-25 03:14:33 [INFO]: Epoch 035 - training loss: 0.3165, validation loss: 0.1746
2024-05-25 03:14:33 [INFO]: Epoch 036 - training loss: 0.3139, validation loss: 0.1742
2024-05-25 03:14:34 [INFO]: Epoch 037 - training loss: 0.3111, validation loss: 0.1737
2024-05-25 03:14:35 [INFO]: Epoch 038 - training loss: 0.3087, validation loss: 0.1726
2024-05-25 03:14:35 [INFO]: Epoch 039 - training loss: 0.3077, validation loss: 0.1712
2024-05-25 03:14:36 [INFO]: Epoch 040 - training loss: 0.3052, validation loss: 0.1693
2024-05-25 03:14:37 [INFO]: Epoch 041 - training loss: 0.3049, validation loss: 0.1681
2024-05-25 03:14:37 [INFO]: Epoch 042 - training loss: 0.3030, validation loss: 0.1695
2024-05-25 03:14:38 [INFO]: Epoch 043 - training loss: 0.2999, validation loss: 0.1668
2024-05-25 03:14:39 [INFO]: Epoch 044 - training loss: 0.2980, validation loss: 0.1668
2024-05-25 03:14:39 [INFO]: Epoch 045 - training loss: 0.2969, validation loss: 0.1660
2024-05-25 03:14:40 [INFO]: Epoch 046 - training loss: 0.2958, validation loss: 0.1654
2024-05-25 03:14:41 [INFO]: Epoch 047 - training loss: 0.2951, validation loss: 0.1645
2024-05-25 03:14:41 [INFO]: Epoch 048 - training loss: 0.2950, validation loss: 0.1628
2024-05-25 03:14:42 [INFO]: Epoch 049 - training loss: 0.2917, validation loss: 0.1615
2024-05-25 03:14:43 [INFO]: Epoch 050 - training loss: 0.2899, validation loss: 0.1611
2024-05-25 03:14:43 [INFO]: Epoch 051 - training loss: 0.2899, validation loss: 0.1617
2024-05-25 03:14:44 [INFO]: Epoch 052 - training loss: 0.2872, validation loss: 0.1601
2024-05-25 03:14:45 [INFO]: Epoch 053 - training loss: 0.2862, validation loss: 0.1590
2024-05-25 03:14:45 [INFO]: Epoch 054 - training loss: 0.2844, validation loss: 0.1587
2024-05-25 03:14:46 [INFO]: Epoch 055 - training loss: 0.2833, validation loss: 0.1576
2024-05-25 03:14:47 [INFO]: Epoch 056 - training loss: 0.2819, validation loss: 0.1572
2024-05-25 03:14:47 [INFO]: Epoch 057 - training loss: 0.2801, validation loss: 0.1568
2024-05-25 03:14:48 [INFO]: Epoch 058 - training loss: 0.2806, validation loss: 0.1556
2024-05-25 03:14:49 [INFO]: Epoch 059 - training loss: 0.2782, validation loss: 0.1559
2024-05-25 03:14:49 [INFO]: Epoch 060 - training loss: 0.2775, validation loss: 0.1529
2024-05-25 03:14:50 [INFO]: Epoch 061 - training loss: 0.2769, validation loss: 0.1543
2024-05-25 03:14:51 [INFO]: Epoch 062 - training loss: 0.2763, validation loss: 0.1538
2024-05-25 03:14:51 [INFO]: Epoch 063 - training loss: 0.2737, validation loss: 0.1523
2024-05-25 03:14:52 [INFO]: Epoch 064 - training loss: 0.2731, validation loss: 0.1524
2024-05-25 03:14:53 [INFO]: Epoch 065 - training loss: 0.2720, validation loss: 0.1528
2024-05-25 03:14:53 [INFO]: Epoch 066 - training loss: 0.2711, validation loss: 0.1516
2024-05-25 03:14:54 [INFO]: Epoch 067 - training loss: 0.2689, validation loss: 0.1505
2024-05-25 03:14:55 [INFO]: Epoch 068 - training loss: 0.2695, validation loss: 0.1510
2024-05-25 03:14:55 [INFO]: Epoch 069 - training loss: 0.2678, validation loss: 0.1491
2024-05-25 03:14:56 [INFO]: Epoch 070 - training loss: 0.2666, validation loss: 0.1486
2024-05-25 03:14:57 [INFO]: Epoch 071 - training loss: 0.2660, validation loss: 0.1490
2024-05-25 03:14:57 [INFO]: Epoch 072 - training loss: 0.2634, validation loss: 0.1487
2024-05-25 03:14:58 [INFO]: Epoch 073 - training loss: 0.2636, validation loss: 0.1471
2024-05-25 03:14:59 [INFO]: Epoch 074 - training loss: 0.2633, validation loss: 0.1477
2024-05-25 03:14:59 [INFO]: Epoch 075 - training loss: 0.2642, validation loss: 0.1464
2024-05-25 03:15:00 [INFO]: Epoch 076 - training loss: 0.2623, validation loss: 0.1464
2024-05-25 03:15:01 [INFO]: Epoch 077 - training loss: 0.2614, validation loss: 0.1454
2024-05-25 03:15:01 [INFO]: Epoch 078 - training loss: 0.2602, validation loss: 0.1459
2024-05-25 03:15:02 [INFO]: Epoch 079 - training loss: 0.2586, validation loss: 0.1438
2024-05-25 03:15:03 [INFO]: Epoch 080 - training loss: 0.2579, validation loss: 0.1448
2024-05-25 03:15:03 [INFO]: Epoch 081 - training loss: 0.2580, validation loss: 0.1441
2024-05-25 03:15:04 [INFO]: Epoch 082 - training loss: 0.2568, validation loss: 0.1439
2024-05-25 03:15:05 [INFO]: Epoch 083 - training loss: 0.2568, validation loss: 0.1432
2024-05-25 03:15:05 [INFO]: Epoch 084 - training loss: 0.2546, validation loss: 0.1433
2024-05-25 03:15:06 [INFO]: Epoch 085 - training loss: 0.2549, validation loss: 0.1428
2024-05-25 03:15:07 [INFO]: Epoch 086 - training loss: 0.2542, validation loss: 0.1420
2024-05-25 03:15:07 [INFO]: Epoch 087 - training loss: 0.2531, validation loss: 0.1428
2024-05-25 03:15:08 [INFO]: Epoch 088 - training loss: 0.2528, validation loss: 0.1417
2024-05-25 03:15:09 [INFO]: Epoch 089 - training loss: 0.2546, validation loss: 0.1427
2024-05-25 03:15:09 [INFO]: Epoch 090 - training loss: 0.2554, validation loss: 0.1415
2024-05-25 03:15:10 [INFO]: Epoch 091 - training loss: 0.2537, validation loss: 0.1411
2024-05-25 03:15:11 [INFO]: Epoch 092 - training loss: 0.2504, validation loss: 0.1404
2024-05-25 03:15:11 [INFO]: Epoch 093 - training loss: 0.2499, validation loss: 0.1392
2024-05-25 03:15:12 [INFO]: Epoch 094 - training loss: 0.2475, validation loss: 0.1388
2024-05-25 03:15:13 [INFO]: Epoch 095 - training loss: 0.2495, validation loss: 0.1386
2024-05-25 03:15:13 [INFO]: Epoch 096 - training loss: 0.2477, validation loss: 0.1390
2024-05-25 03:15:14 [INFO]: Epoch 097 - training loss: 0.2486, validation loss: 0.1382
2024-05-25 03:15:15 [INFO]: Epoch 098 - training loss: 0.2481, validation loss: 0.1378
2024-05-25 03:15:15 [INFO]: Epoch 099 - training loss: 0.2469, validation loss: 0.1385
2024-05-25 03:15:16 [INFO]: Epoch 100 - training loss: 0.2461, validation loss: 0.1389
2024-05-25 03:15:17 [INFO]: Epoch 101 - training loss: 0.2441, validation loss: 0.1375
2024-05-25 03:15:17 [INFO]: Epoch 102 - training loss: 0.2441, validation loss: 0.1369
2024-05-25 03:15:18 [INFO]: Epoch 103 - training loss: 0.2440, validation loss: 0.1369
2024-05-25 03:15:19 [INFO]: Epoch 104 - training loss: 0.2431, validation loss: 0.1365
2024-05-25 03:15:19 [INFO]: Epoch 105 - training loss: 0.2420, validation loss: 0.1362
2024-05-25 03:15:20 [INFO]: Epoch 106 - training loss: 0.2424, validation loss: 0.1359
2024-05-25 03:15:21 [INFO]: Epoch 107 - training loss: 0.2429, validation loss: 0.1355
2024-05-25 03:15:21 [INFO]: Epoch 108 - training loss: 0.2408, validation loss: 0.1358
2024-05-25 03:15:22 [INFO]: Epoch 109 - training loss: 0.2405, validation loss: 0.1361
2024-05-25 03:15:23 [INFO]: Epoch 110 - training loss: 0.2413, validation loss: 0.1344
2024-05-25 03:15:23 [INFO]: Epoch 111 - training loss: 0.2403, validation loss: 0.1347
2024-05-25 03:15:24 [INFO]: Epoch 112 - training loss: 0.2391, validation loss: 0.1339
2024-05-25 03:15:25 [INFO]: Epoch 113 - training loss: 0.2380, validation loss: 0.1334
2024-05-25 03:15:25 [INFO]: Epoch 114 - training loss: 0.2379, validation loss: 0.1338
2024-05-25 03:15:26 [INFO]: Epoch 115 - training loss: 0.2371, validation loss: 0.1335
2024-05-25 03:15:27 [INFO]: Epoch 116 - training loss: 0.2375, validation loss: 0.1343
2024-05-25 03:15:27 [INFO]: Epoch 117 - training loss: 0.2364, validation loss: 0.1335
2024-05-25 03:15:28 [INFO]: Epoch 118 - training loss: 0.2363, validation loss: 0.1328
2024-05-25 03:15:29 [INFO]: Epoch 119 - training loss: 0.2359, validation loss: 0.1333
2024-05-25 03:15:29 [INFO]: Epoch 120 - training loss: 0.2355, validation loss: 0.1329
2024-05-25 03:15:30 [INFO]: Epoch 121 - training loss: 0.2352, validation loss: 0.1328
2024-05-25 03:15:31 [INFO]: Epoch 122 - training loss: 0.2337, validation loss: 0.1324
2024-05-25 03:15:31 [INFO]: Epoch 123 - training loss: 0.2352, validation loss: 0.1310
2024-05-25 03:15:32 [INFO]: Epoch 124 - training loss: 0.2332, validation loss: 0.1314
2024-05-25 03:15:33 [INFO]: Epoch 125 - training loss: 0.2322, validation loss: 0.1314
2024-05-25 03:15:33 [INFO]: Epoch 126 - training loss: 0.2339, validation loss: 0.1318
2024-05-25 03:15:34 [INFO]: Epoch 127 - training loss: 0.2322, validation loss: 0.1301
2024-05-25 03:15:35 [INFO]: Epoch 128 - training loss: 0.2318, validation loss: 0.1303
2024-05-25 03:15:35 [INFO]: Epoch 129 - training loss: 0.2311, validation loss: 0.1306
2024-05-25 03:15:36 [INFO]: Epoch 130 - training loss: 0.2313, validation loss: 0.1305
2024-05-25 03:15:37 [INFO]: Epoch 131 - training loss: 0.2307, validation loss: 0.1295
2024-05-25 03:15:37 [INFO]: Epoch 132 - training loss: 0.2310, validation loss: 0.1308
2024-05-25 03:15:38 [INFO]: Epoch 133 - training loss: 0.2316, validation loss: 0.1292
2024-05-25 03:15:39 [INFO]: Epoch 134 - training loss: 0.2314, validation loss: 0.1293
2024-05-25 03:15:39 [INFO]: Epoch 135 - training loss: 0.2316, validation loss: 0.1293
2024-05-25 03:15:40 [INFO]: Epoch 136 - training loss: 0.2300, validation loss: 0.1282
2024-05-25 03:15:41 [INFO]: Epoch 137 - training loss: 0.2279, validation loss: 0.1283
2024-05-25 03:15:41 [INFO]: Epoch 138 - training loss: 0.2282, validation loss: 0.1283
2024-05-25 03:15:42 [INFO]: Epoch 139 - training loss: 0.2269, validation loss: 0.1277
2024-05-25 03:15:43 [INFO]: Epoch 140 - training loss: 0.2270, validation loss: 0.1279
2024-05-25 03:15:43 [INFO]: Epoch 141 - training loss: 0.2264, validation loss: 0.1275
2024-05-25 03:15:44 [INFO]: Epoch 142 - training loss: 0.2261, validation loss: 0.1281
2024-05-25 03:15:45 [INFO]: Epoch 143 - training loss: 0.2271, validation loss: 0.1275
2024-05-25 03:15:45 [INFO]: Epoch 144 - training loss: 0.2249, validation loss: 0.1268
2024-05-25 03:15:46 [INFO]: Epoch 145 - training loss: 0.2253, validation loss: 0.1272
2024-05-25 03:15:47 [INFO]: Epoch 146 - training loss: 0.2257, validation loss: 0.1272
2024-05-25 03:15:47 [INFO]: Epoch 147 - training loss: 0.2259, validation loss: 0.1261
2024-05-25 03:15:48 [INFO]: Epoch 148 - training loss: 0.2236, validation loss: 0.1269
2024-05-25 03:15:49 [INFO]: Epoch 149 - training loss: 0.2237, validation loss: 0.1268
2024-05-25 03:15:49 [INFO]: Epoch 150 - training loss: 0.2228, validation loss: 0.1259
2024-05-25 03:15:50 [INFO]: Epoch 151 - training loss: 0.2239, validation loss: 0.1266
2024-05-25 03:15:51 [INFO]: Epoch 152 - training loss: 0.2236, validation loss: 0.1270
2024-05-25 03:15:51 [INFO]: Epoch 153 - training loss: 0.2220, validation loss: 0.1265
2024-05-25 03:15:52 [INFO]: Epoch 154 - training loss: 0.2220, validation loss: 0.1260
2024-05-25 03:15:53 [INFO]: Epoch 155 - training loss: 0.2223, validation loss: 0.1262
2024-05-25 03:15:53 [INFO]: Epoch 156 - training loss: 0.2210, validation loss: 0.1258
2024-05-25 03:15:54 [INFO]: Epoch 157 - training loss: 0.2198, validation loss: 0.1245
2024-05-25 03:15:55 [INFO]: Epoch 158 - training loss: 0.2209, validation loss: 0.1247
2024-05-25 03:15:55 [INFO]: Epoch 159 - training loss: 0.2207, validation loss: 0.1269
2024-05-25 03:15:56 [INFO]: Epoch 160 - training loss: 0.2221, validation loss: 0.1245
2024-05-25 03:15:57 [INFO]: Epoch 161 - training loss: 0.2219, validation loss: 0.1254
2024-05-25 03:15:57 [INFO]: Epoch 162 - training loss: 0.2190, validation loss: 0.1242
2024-05-25 03:15:58 [INFO]: Epoch 163 - training loss: 0.2192, validation loss: 0.1249
2024-05-25 03:15:59 [INFO]: Epoch 164 - training loss: 0.2182, validation loss: 0.1236
2024-05-25 03:15:59 [INFO]: Epoch 165 - training loss: 0.2172, validation loss: 0.1243
2024-05-25 03:16:00 [INFO]: Epoch 166 - training loss: 0.2183, validation loss: 0.1233
2024-05-25 03:16:01 [INFO]: Epoch 167 - training loss: 0.2172, validation loss: 0.1230
2024-05-25 03:16:01 [INFO]: Epoch 168 - training loss: 0.2168, validation loss: 0.1233
2024-05-25 03:16:02 [INFO]: Epoch 169 - training loss: 0.2154, validation loss: 0.1232
2024-05-25 03:16:03 [INFO]: Epoch 170 - training loss: 0.2180, validation loss: 0.1243
2024-05-25 03:16:03 [INFO]: Epoch 171 - training loss: 0.2191, validation loss: 0.1246
2024-05-25 03:16:04 [INFO]: Epoch 172 - training loss: 0.2160, validation loss: 0.1227
2024-05-25 03:16:05 [INFO]: Epoch 173 - training loss: 0.2156, validation loss: 0.1231
2024-05-25 03:16:05 [INFO]: Epoch 174 - training loss: 0.2161, validation loss: 0.1227
2024-05-25 03:16:06 [INFO]: Epoch 175 - training loss: 0.2172, validation loss: 0.1236
2024-05-25 03:16:07 [INFO]: Epoch 176 - training loss: 0.2168, validation loss: 0.1224
2024-05-25 03:16:07 [INFO]: Epoch 177 - training loss: 0.2155, validation loss: 0.1233
2024-05-25 03:16:08 [INFO]: Epoch 178 - training loss: 0.2153, validation loss: 0.1218
2024-05-25 03:16:09 [INFO]: Epoch 179 - training loss: 0.2154, validation loss: 0.1215
2024-05-25 03:16:09 [INFO]: Epoch 180 - training loss: 0.2150, validation loss: 0.1216
2024-05-25 03:16:10 [INFO]: Epoch 181 - training loss: 0.2138, validation loss: 0.1220
2024-05-25 03:16:11 [INFO]: Epoch 182 - training loss: 0.2141, validation loss: 0.1214
2024-05-25 03:16:11 [INFO]: Epoch 183 - training loss: 0.2168, validation loss: 0.1226
2024-05-25 03:16:12 [INFO]: Epoch 184 - training loss: 0.2151, validation loss: 0.1207
2024-05-25 03:16:13 [INFO]: Epoch 185 - training loss: 0.2122, validation loss: 0.1215
2024-05-25 03:16:13 [INFO]: Epoch 186 - training loss: 0.2107, validation loss: 0.1208
2024-05-25 03:16:14 [INFO]: Epoch 187 - training loss: 0.2119, validation loss: 0.1214
2024-05-25 03:16:15 [INFO]: Epoch 188 - training loss: 0.2108, validation loss: 0.1210
2024-05-25 03:16:15 [INFO]: Epoch 189 - training loss: 0.2114, validation loss: 0.1205
2024-05-25 03:16:16 [INFO]: Epoch 190 - training loss: 0.2101, validation loss: 0.1212
2024-05-25 03:16:17 [INFO]: Epoch 191 - training loss: 0.2097, validation loss: 0.1201
2024-05-25 03:16:17 [INFO]: Epoch 192 - training loss: 0.2103, validation loss: 0.1197
2024-05-25 03:16:18 [INFO]: Epoch 193 - training loss: 0.2093, validation loss: 0.1202
2024-05-25 03:16:19 [INFO]: Epoch 194 - training loss: 0.2090, validation loss: 0.1200
2024-05-25 03:16:19 [INFO]: Epoch 195 - training loss: 0.2095, validation loss: 0.1191
2024-05-25 03:16:20 [INFO]: Epoch 196 - training loss: 0.2085, validation loss: 0.1193
2024-05-25 03:16:21 [INFO]: Epoch 197 - training loss: 0.2081, validation loss: 0.1204
2024-05-25 03:16:21 [INFO]: Epoch 198 - training loss: 0.2082, validation loss: 0.1197
2024-05-25 03:16:22 [INFO]: Epoch 199 - training loss: 0.2085, validation loss: 0.1210
2024-05-25 03:16:23 [INFO]: Epoch 200 - training loss: 0.2082, validation loss: 0.1189
2024-05-25 03:16:23 [INFO]: Epoch 201 - training loss: 0.2074, validation loss: 0.1191
2024-05-25 03:16:24 [INFO]: Epoch 202 - training loss: 0.2080, validation loss: 0.1214
2024-05-25 03:16:25 [INFO]: Epoch 203 - training loss: 0.2088, validation loss: 0.1189
2024-05-25 03:16:25 [INFO]: Epoch 204 - training loss: 0.2086, validation loss: 0.1190
2024-05-25 03:16:26 [INFO]: Epoch 205 - training loss: 0.2076, validation loss: 0.1180
2024-05-25 03:16:27 [INFO]: Epoch 206 - training loss: 0.2065, validation loss: 0.1182
2024-05-25 03:16:27 [INFO]: Epoch 207 - training loss: 0.2068, validation loss: 0.1180
2024-05-25 03:16:28 [INFO]: Epoch 208 - training loss: 0.2066, validation loss: 0.1174
2024-05-25 03:16:29 [INFO]: Epoch 209 - training loss: 0.2068, validation loss: 0.1179
2024-05-25 03:16:29 [INFO]: Epoch 210 - training loss: 0.2062, validation loss: 0.1184
2024-05-25 03:16:30 [INFO]: Epoch 211 - training loss: 0.2058, validation loss: 0.1177
2024-05-25 03:16:31 [INFO]: Epoch 212 - training loss: 0.2061, validation loss: 0.1185
2024-05-25 03:16:31 [INFO]: Epoch 213 - training loss: 0.2058, validation loss: 0.1180
2024-05-25 03:16:32 [INFO]: Epoch 214 - training loss: 0.2043, validation loss: 0.1175
2024-05-25 03:16:33 [INFO]: Epoch 215 - training loss: 0.2044, validation loss: 0.1173
2024-05-25 03:16:33 [INFO]: Epoch 216 - training loss: 0.2053, validation loss: 0.1171
2024-05-25 03:16:34 [INFO]: Epoch 217 - training loss: 0.2028, validation loss: 0.1175
2024-05-25 03:16:35 [INFO]: Epoch 218 - training loss: 0.2035, validation loss: 0.1175
2024-05-25 03:16:35 [INFO]: Epoch 219 - training loss: 0.2049, validation loss: 0.1185
2024-05-25 03:16:36 [INFO]: Epoch 220 - training loss: 0.2039, validation loss: 0.1179
2024-05-25 03:16:37 [INFO]: Epoch 221 - training loss: 0.2022, validation loss: 0.1173
2024-05-25 03:16:37 [INFO]: Epoch 222 - training loss: 0.2027, validation loss: 0.1172
2024-05-25 03:16:38 [INFO]: Epoch 223 - training loss: 0.2026, validation loss: 0.1178
2024-05-25 03:16:39 [INFO]: Epoch 224 - training loss: 0.2044, validation loss: 0.1164
2024-05-25 03:16:39 [INFO]: Epoch 225 - training loss: 0.2042, validation loss: 0.1173
2024-05-25 03:16:40 [INFO]: Epoch 226 - training loss: 0.2022, validation loss: 0.1158
2024-05-25 03:16:41 [INFO]: Epoch 227 - training loss: 0.2015, validation loss: 0.1171
2024-05-25 03:16:41 [INFO]: Epoch 228 - training loss: 0.2020, validation loss: 0.1168
2024-05-25 03:16:42 [INFO]: Epoch 229 - training loss: 0.2010, validation loss: 0.1161
2024-05-25 03:16:43 [INFO]: Epoch 230 - training loss: 0.2008, validation loss: 0.1163
2024-05-25 03:16:43 [INFO]: Epoch 231 - training loss: 0.2007, validation loss: 0.1158
2024-05-25 03:16:44 [INFO]: Epoch 232 - training loss: 0.2001, validation loss: 0.1158
2024-05-25 03:16:45 [INFO]: Epoch 233 - training loss: 0.2026, validation loss: 0.1162
2024-05-25 03:16:45 [INFO]: Epoch 234 - training loss: 0.2002, validation loss: 0.1162
2024-05-25 03:16:46 [INFO]: Epoch 235 - training loss: 0.2000, validation loss: 0.1157
2024-05-25 03:16:47 [INFO]: Epoch 236 - training loss: 0.1991, validation loss: 0.1159
2024-05-25 03:16:47 [INFO]: Epoch 237 - training loss: 0.1995, validation loss: 0.1159
2024-05-25 03:16:48 [INFO]: Epoch 238 - training loss: 0.1989, validation loss: 0.1147
2024-05-25 03:16:49 [INFO]: Epoch 239 - training loss: 0.1981, validation loss: 0.1161
2024-05-25 03:16:49 [INFO]: Epoch 240 - training loss: 0.1990, validation loss: 0.1166
2024-05-25 03:16:50 [INFO]: Epoch 241 - training loss: 0.2013, validation loss: 0.1150
2024-05-25 03:16:51 [INFO]: Epoch 242 - training loss: 0.2000, validation loss: 0.1146
2024-05-25 03:16:51 [INFO]: Epoch 243 - training loss: 0.1992, validation loss: 0.1159
2024-05-25 03:16:52 [INFO]: Epoch 244 - training loss: 0.1994, validation loss: 0.1166
2024-05-25 03:16:53 [INFO]: Epoch 245 - training loss: 0.1999, validation loss: 0.1164
2024-05-25 03:16:53 [INFO]: Epoch 246 - training loss: 0.2007, validation loss: 0.1154
2024-05-25 03:16:54 [INFO]: Epoch 247 - training loss: 0.1996, validation loss: 0.1174
2024-05-25 03:16:55 [INFO]: Epoch 248 - training loss: 0.2003, validation loss: 0.1152
2024-05-25 03:16:55 [INFO]: Epoch 249 - training loss: 0.1972, validation loss: 0.1150
2024-05-25 03:16:56 [INFO]: Epoch 250 - training loss: 0.1966, validation loss: 0.1151
2024-05-25 03:16:57 [INFO]: Epoch 251 - training loss: 0.1969, validation loss: 0.1146
2024-05-25 03:16:57 [INFO]: Epoch 252 - training loss: 0.1971, validation loss: 0.1151
2024-05-25 03:16:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:16:57 [INFO]: Finished training. The best model is from epoch#242.
2024-05-25 03:16:57 [INFO]: Saved the model to augmentation_saved_results/round_2/SAITS_air_quality/20240525_T031409/SAITS.pypots
2024-05-25 03:16:58 [INFO]: SAITS on Air-Quality: MAE=0.1500, MSE=0.1791
2024-05-25 03:16:58 [INFO]: Successfully saved to augmentation_saved_results/round_2/SAITS_air_quality/imputation.pkl
2024-05-25 03:16:58 [INFO]: Using the given device: cuda:0
2024-05-25 03:16:58 [INFO]: Model files will be saved to augmentation_saved_results/round_2/Transformer_air_quality/20240525_T031658
2024-05-25 03:16:58 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/Transformer_air_quality/20240525_T031658/tensorboard
2024-05-25 03:16:58 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 03:16:58 [INFO]: Epoch 001 - training loss: 0.9104, validation loss: 0.4789
2024-05-25 03:16:58 [INFO]: Epoch 002 - training loss: 0.5771, validation loss: 0.3519
2024-05-25 03:16:59 [INFO]: Epoch 003 - training loss: 0.4863, validation loss: 0.2954
2024-05-25 03:16:59 [INFO]: Epoch 004 - training loss: 0.4403, validation loss: 0.2715
2024-05-25 03:16:59 [INFO]: Epoch 005 - training loss: 0.4108, validation loss: 0.2589
2024-05-25 03:17:00 [INFO]: Epoch 006 - training loss: 0.3932, validation loss: 0.2469
2024-05-25 03:17:00 [INFO]: Epoch 007 - training loss: 0.3802, validation loss: 0.2390
2024-05-25 03:17:00 [INFO]: Epoch 008 - training loss: 0.3672, validation loss: 0.2349
2024-05-25 03:17:00 [INFO]: Epoch 009 - training loss: 0.3559, validation loss: 0.2312
2024-05-25 03:17:01 [INFO]: Epoch 010 - training loss: 0.3504, validation loss: 0.2248
2024-05-25 03:17:01 [INFO]: Epoch 011 - training loss: 0.3416, validation loss: 0.2213
2024-05-25 03:17:01 [INFO]: Epoch 012 - training loss: 0.3388, validation loss: 0.2167
2024-05-25 03:17:02 [INFO]: Epoch 013 - training loss: 0.3336, validation loss: 0.2133
2024-05-25 03:17:02 [INFO]: Epoch 014 - training loss: 0.3302, validation loss: 0.2093
2024-05-25 03:17:02 [INFO]: Epoch 015 - training loss: 0.3244, validation loss: 0.2085
2024-05-25 03:17:03 [INFO]: Epoch 016 - training loss: 0.3211, validation loss: 0.2061
2024-05-25 03:17:03 [INFO]: Epoch 017 - training loss: 0.3154, validation loss: 0.2017
2024-05-25 03:17:03 [INFO]: Epoch 018 - training loss: 0.3135, validation loss: 0.2011
2024-05-25 03:17:04 [INFO]: Epoch 019 - training loss: 0.3100, validation loss: 0.1982
2024-05-25 03:17:04 [INFO]: Epoch 020 - training loss: 0.3096, validation loss: 0.1972
2024-05-25 03:17:04 [INFO]: Epoch 021 - training loss: 0.3084, validation loss: 0.1963
2024-05-25 03:17:05 [INFO]: Epoch 022 - training loss: 0.3047, validation loss: 0.1899
2024-05-25 03:17:05 [INFO]: Epoch 023 - training loss: 0.3013, validation loss: 0.1893
2024-05-25 03:17:05 [INFO]: Epoch 024 - training loss: 0.2978, validation loss: 0.1874
2024-05-25 03:17:05 [INFO]: Epoch 025 - training loss: 0.2960, validation loss: 0.1863
2024-05-25 03:17:06 [INFO]: Epoch 026 - training loss: 0.2934, validation loss: 0.1852
2024-05-25 03:17:06 [INFO]: Epoch 027 - training loss: 0.2907, validation loss: 0.1858
2024-05-25 03:17:06 [INFO]: Epoch 028 - training loss: 0.2894, validation loss: 0.1838
2024-05-25 03:17:07 [INFO]: Epoch 029 - training loss: 0.2886, validation loss: 0.1840
2024-05-25 03:17:07 [INFO]: Epoch 030 - training loss: 0.2870, validation loss: 0.1829
2024-05-25 03:17:07 [INFO]: Epoch 031 - training loss: 0.2856, validation loss: 0.1811
2024-05-25 03:17:08 [INFO]: Epoch 032 - training loss: 0.2838, validation loss: 0.1801
2024-05-25 03:17:08 [INFO]: Epoch 033 - training loss: 0.2809, validation loss: 0.1784
2024-05-25 03:17:08 [INFO]: Epoch 034 - training loss: 0.2801, validation loss: 0.1786
2024-05-25 03:17:09 [INFO]: Epoch 035 - training loss: 0.2827, validation loss: 0.1813
2024-05-25 03:17:09 [INFO]: Epoch 036 - training loss: 0.2832, validation loss: 0.1780
2024-05-25 03:17:09 [INFO]: Epoch 037 - training loss: 0.2794, validation loss: 0.1756
2024-05-25 03:17:10 [INFO]: Epoch 038 - training loss: 0.2779, validation loss: 0.1774
2024-05-25 03:17:10 [INFO]: Epoch 039 - training loss: 0.2758, validation loss: 0.1765
2024-05-25 03:17:10 [INFO]: Epoch 040 - training loss: 0.2742, validation loss: 0.1755
2024-05-25 03:17:11 [INFO]: Epoch 041 - training loss: 0.2751, validation loss: 0.1747
2024-05-25 03:17:11 [INFO]: Epoch 042 - training loss: 0.2744, validation loss: 0.1755
2024-05-25 03:17:11 [INFO]: Epoch 043 - training loss: 0.2724, validation loss: 0.1731
2024-05-25 03:17:11 [INFO]: Epoch 044 - training loss: 0.2726, validation loss: 0.1744
2024-05-25 03:17:12 [INFO]: Epoch 045 - training loss: 0.2708, validation loss: 0.1746
2024-05-25 03:17:12 [INFO]: Epoch 046 - training loss: 0.2687, validation loss: 0.1741
2024-05-25 03:17:12 [INFO]: Epoch 047 - training loss: 0.2679, validation loss: 0.1740
2024-05-25 03:17:13 [INFO]: Epoch 048 - training loss: 0.2646, validation loss: 0.1702
2024-05-25 03:17:13 [INFO]: Epoch 049 - training loss: 0.2644, validation loss: 0.1693
2024-05-25 03:17:13 [INFO]: Epoch 050 - training loss: 0.2687, validation loss: 0.1723
2024-05-25 03:17:14 [INFO]: Epoch 051 - training loss: 0.2652, validation loss: 0.1696
2024-05-25 03:17:14 [INFO]: Epoch 052 - training loss: 0.2629, validation loss: 0.1657
2024-05-25 03:17:14 [INFO]: Epoch 053 - training loss: 0.2599, validation loss: 0.1691
2024-05-25 03:17:15 [INFO]: Epoch 054 - training loss: 0.2590, validation loss: 0.1725
2024-05-25 03:17:15 [INFO]: Epoch 055 - training loss: 0.2599, validation loss: 0.1660
2024-05-25 03:17:15 [INFO]: Epoch 056 - training loss: 0.2584, validation loss: 0.1676
2024-05-25 03:17:16 [INFO]: Epoch 057 - training loss: 0.2572, validation loss: 0.1671
2024-05-25 03:17:16 [INFO]: Epoch 058 - training loss: 0.2574, validation loss: 0.1690
2024-05-25 03:17:16 [INFO]: Epoch 059 - training loss: 0.2563, validation loss: 0.1672
2024-05-25 03:17:16 [INFO]: Epoch 060 - training loss: 0.2544, validation loss: 0.1645
2024-05-25 03:17:17 [INFO]: Epoch 061 - training loss: 0.2567, validation loss: 0.1667
2024-05-25 03:17:17 [INFO]: Epoch 062 - training loss: 0.2572, validation loss: 0.1635
2024-05-25 03:17:17 [INFO]: Epoch 063 - training loss: 0.2558, validation loss: 0.1622
2024-05-25 03:17:18 [INFO]: Epoch 064 - training loss: 0.2536, validation loss: 0.1619
2024-05-25 03:17:18 [INFO]: Epoch 065 - training loss: 0.2512, validation loss: 0.1624
2024-05-25 03:17:18 [INFO]: Epoch 066 - training loss: 0.2497, validation loss: 0.1652
2024-05-25 03:17:19 [INFO]: Epoch 067 - training loss: 0.2504, validation loss: 0.1615
2024-05-25 03:17:19 [INFO]: Epoch 068 - training loss: 0.2502, validation loss: 0.1602
2024-05-25 03:17:19 [INFO]: Epoch 069 - training loss: 0.2510, validation loss: 0.1633
2024-05-25 03:17:20 [INFO]: Epoch 070 - training loss: 0.2498, validation loss: 0.1632
2024-05-25 03:17:20 [INFO]: Epoch 071 - training loss: 0.2489, validation loss: 0.1596
2024-05-25 03:17:20 [INFO]: Epoch 072 - training loss: 0.2461, validation loss: 0.1634
2024-05-25 03:17:21 [INFO]: Epoch 073 - training loss: 0.2447, validation loss: 0.1616
2024-05-25 03:17:21 [INFO]: Epoch 074 - training loss: 0.2428, validation loss: 0.1617
2024-05-25 03:17:21 [INFO]: Epoch 075 - training loss: 0.2431, validation loss: 0.1594
2024-05-25 03:17:22 [INFO]: Epoch 076 - training loss: 0.2447, validation loss: 0.1611
2024-05-25 03:17:22 [INFO]: Epoch 077 - training loss: 0.2434, validation loss: 0.1590
2024-05-25 03:17:22 [INFO]: Epoch 078 - training loss: 0.2428, validation loss: 0.1601
2024-05-25 03:17:22 [INFO]: Epoch 079 - training loss: 0.2440, validation loss: 0.1597
2024-05-25 03:17:23 [INFO]: Epoch 080 - training loss: 0.2431, validation loss: 0.1569
2024-05-25 03:17:23 [INFO]: Epoch 081 - training loss: 0.2434, validation loss: 0.1569
2024-05-25 03:17:23 [INFO]: Epoch 082 - training loss: 0.2429, validation loss: 0.1565
2024-05-25 03:17:24 [INFO]: Epoch 083 - training loss: 0.2443, validation loss: 0.1571
2024-05-25 03:17:24 [INFO]: Epoch 084 - training loss: 0.2411, validation loss: 0.1580
2024-05-25 03:17:24 [INFO]: Epoch 085 - training loss: 0.2370, validation loss: 0.1571
2024-05-25 03:17:25 [INFO]: Epoch 086 - training loss: 0.2356, validation loss: 0.1552
2024-05-25 03:17:25 [INFO]: Epoch 087 - training loss: 0.2363, validation loss: 0.1558
2024-05-25 03:17:25 [INFO]: Epoch 088 - training loss: 0.2354, validation loss: 0.1557
2024-05-25 03:17:26 [INFO]: Epoch 089 - training loss: 0.2343, validation loss: 0.1536
2024-05-25 03:17:26 [INFO]: Epoch 090 - training loss: 0.2335, validation loss: 0.1547
2024-05-25 03:17:26 [INFO]: Epoch 091 - training loss: 0.2338, validation loss: 0.1552
2024-05-25 03:17:27 [INFO]: Epoch 092 - training loss: 0.2353, validation loss: 0.1564
2024-05-25 03:17:27 [INFO]: Epoch 093 - training loss: 0.2343, validation loss: 0.1520
2024-05-25 03:17:27 [INFO]: Epoch 094 - training loss: 0.2341, validation loss: 0.1568
2024-05-25 03:17:27 [INFO]: Epoch 095 - training loss: 0.2329, validation loss: 0.1550
2024-05-25 03:17:28 [INFO]: Epoch 096 - training loss: 0.2312, validation loss: 0.1525
2024-05-25 03:17:28 [INFO]: Epoch 097 - training loss: 0.2294, validation loss: 0.1524
2024-05-25 03:17:28 [INFO]: Epoch 098 - training loss: 0.2293, validation loss: 0.1538
2024-05-25 03:17:29 [INFO]: Epoch 099 - training loss: 0.2301, validation loss: 0.1543
2024-05-25 03:17:29 [INFO]: Epoch 100 - training loss: 0.2321, validation loss: 0.1530
2024-05-25 03:17:29 [INFO]: Epoch 101 - training loss: 0.2322, validation loss: 0.1517
2024-05-25 03:17:30 [INFO]: Epoch 102 - training loss: 0.2286, validation loss: 0.1519
2024-05-25 03:17:30 [INFO]: Epoch 103 - training loss: 0.2281, validation loss: 0.1517
2024-05-25 03:17:30 [INFO]: Epoch 104 - training loss: 0.2277, validation loss: 0.1530
2024-05-25 03:17:31 [INFO]: Epoch 105 - training loss: 0.2260, validation loss: 0.1498
2024-05-25 03:17:31 [INFO]: Epoch 106 - training loss: 0.2249, validation loss: 0.1524
2024-05-25 03:17:31 [INFO]: Epoch 107 - training loss: 0.2242, validation loss: 0.1493
2024-05-25 03:17:32 [INFO]: Epoch 108 - training loss: 0.2237, validation loss: 0.1509
2024-05-25 03:17:32 [INFO]: Epoch 109 - training loss: 0.2251, validation loss: 0.1508
2024-05-25 03:17:32 [INFO]: Epoch 110 - training loss: 0.2266, validation loss: 0.1509
2024-05-25 03:17:32 [INFO]: Epoch 111 - training loss: 0.2266, validation loss: 0.1484
2024-05-25 03:17:33 [INFO]: Epoch 112 - training loss: 0.2263, validation loss: 0.1485
2024-05-25 03:17:33 [INFO]: Epoch 113 - training loss: 0.2261, validation loss: 0.1488
2024-05-25 03:17:33 [INFO]: Epoch 114 - training loss: 0.2256, validation loss: 0.1480
2024-05-25 03:17:34 [INFO]: Epoch 115 - training loss: 0.2249, validation loss: 0.1492
2024-05-25 03:17:34 [INFO]: Epoch 116 - training loss: 0.2221, validation loss: 0.1484
2024-05-25 03:17:34 [INFO]: Epoch 117 - training loss: 0.2220, validation loss: 0.1487
2024-05-25 03:17:35 [INFO]: Epoch 118 - training loss: 0.2195, validation loss: 0.1485
2024-05-25 03:17:35 [INFO]: Epoch 119 - training loss: 0.2189, validation loss: 0.1468
2024-05-25 03:17:35 [INFO]: Epoch 120 - training loss: 0.2234, validation loss: 0.1484
2024-05-25 03:17:36 [INFO]: Epoch 121 - training loss: 0.2194, validation loss: 0.1467
2024-05-25 03:17:36 [INFO]: Epoch 122 - training loss: 0.2194, validation loss: 0.1455
2024-05-25 03:17:36 [INFO]: Epoch 123 - training loss: 0.2192, validation loss: 0.1462
2024-05-25 03:17:37 [INFO]: Epoch 124 - training loss: 0.2197, validation loss: 0.1447
2024-05-25 03:17:37 [INFO]: Epoch 125 - training loss: 0.2168, validation loss: 0.1456
2024-05-25 03:17:37 [INFO]: Epoch 126 - training loss: 0.2163, validation loss: 0.1460
2024-05-25 03:17:38 [INFO]: Epoch 127 - training loss: 0.2173, validation loss: 0.1485
2024-05-25 03:17:38 [INFO]: Epoch 128 - training loss: 0.2168, validation loss: 0.1445
2024-05-25 03:17:38 [INFO]: Epoch 129 - training loss: 0.2171, validation loss: 0.1463
2024-05-25 03:17:38 [INFO]: Epoch 130 - training loss: 0.2185, validation loss: 0.1463
2024-05-25 03:17:39 [INFO]: Epoch 131 - training loss: 0.2180, validation loss: 0.1461
2024-05-25 03:17:39 [INFO]: Epoch 132 - training loss: 0.2149, validation loss: 0.1459
2024-05-25 03:17:39 [INFO]: Epoch 133 - training loss: 0.2152, validation loss: 0.1442
2024-05-25 03:17:40 [INFO]: Epoch 134 - training loss: 0.2172, validation loss: 0.1446
2024-05-25 03:17:40 [INFO]: Epoch 135 - training loss: 0.2142, validation loss: 0.1439
2024-05-25 03:17:40 [INFO]: Epoch 136 - training loss: 0.2164, validation loss: 0.1461
2024-05-25 03:17:41 [INFO]: Epoch 137 - training loss: 0.2206, validation loss: 0.1448
2024-05-25 03:17:41 [INFO]: Epoch 138 - training loss: 0.2137, validation loss: 0.1437
2024-05-25 03:17:41 [INFO]: Epoch 139 - training loss: 0.2138, validation loss: 0.1433
2024-05-25 03:17:42 [INFO]: Epoch 140 - training loss: 0.2135, validation loss: 0.1446
2024-05-25 03:17:42 [INFO]: Epoch 141 - training loss: 0.2138, validation loss: 0.1447
2024-05-25 03:17:42 [INFO]: Epoch 142 - training loss: 0.2134, validation loss: 0.1419
2024-05-25 03:17:43 [INFO]: Epoch 143 - training loss: 0.2145, validation loss: 0.1432
2024-05-25 03:17:43 [INFO]: Epoch 144 - training loss: 0.2121, validation loss: 0.1445
2024-05-25 03:17:43 [INFO]: Epoch 145 - training loss: 0.2111, validation loss: 0.1437
2024-05-25 03:17:43 [INFO]: Epoch 146 - training loss: 0.2101, validation loss: 0.1418
2024-05-25 03:17:44 [INFO]: Epoch 147 - training loss: 0.2102, validation loss: 0.1424
2024-05-25 03:17:44 [INFO]: Epoch 148 - training loss: 0.2086, validation loss: 0.1436
2024-05-25 03:17:44 [INFO]: Epoch 149 - training loss: 0.2103, validation loss: 0.1438
2024-05-25 03:17:45 [INFO]: Epoch 150 - training loss: 0.2116, validation loss: 0.1434
2024-05-25 03:17:45 [INFO]: Epoch 151 - training loss: 0.2104, validation loss: 0.1421
2024-05-25 03:17:45 [INFO]: Epoch 152 - training loss: 0.2103, validation loss: 0.1420
2024-05-25 03:17:46 [INFO]: Epoch 153 - training loss: 0.2072, validation loss: 0.1421
2024-05-25 03:17:46 [INFO]: Epoch 154 - training loss: 0.2089, validation loss: 0.1409
2024-05-25 03:17:46 [INFO]: Epoch 155 - training loss: 0.2113, validation loss: 0.1412
2024-05-25 03:17:47 [INFO]: Epoch 156 - training loss: 0.2080, validation loss: 0.1429
2024-05-25 03:17:47 [INFO]: Epoch 157 - training loss: 0.2086, validation loss: 0.1413
2024-05-25 03:17:47 [INFO]: Epoch 158 - training loss: 0.2076, validation loss: 0.1400
2024-05-25 03:17:48 [INFO]: Epoch 159 - training loss: 0.2069, validation loss: 0.1404
2024-05-25 03:17:48 [INFO]: Epoch 160 - training loss: 0.2083, validation loss: 0.1393
2024-05-25 03:17:48 [INFO]: Epoch 161 - training loss: 0.2077, validation loss: 0.1405
2024-05-25 03:17:48 [INFO]: Epoch 162 - training loss: 0.2050, validation loss: 0.1406
2024-05-25 03:17:49 [INFO]: Epoch 163 - training loss: 0.2058, validation loss: 0.1399
2024-05-25 03:17:49 [INFO]: Epoch 164 - training loss: 0.2052, validation loss: 0.1389
2024-05-25 03:17:49 [INFO]: Epoch 165 - training loss: 0.2057, validation loss: 0.1405
2024-05-25 03:17:50 [INFO]: Epoch 166 - training loss: 0.2068, validation loss: 0.1401
2024-05-25 03:17:50 [INFO]: Epoch 167 - training loss: 0.2060, validation loss: 0.1400
2024-05-25 03:17:50 [INFO]: Epoch 168 - training loss: 0.2043, validation loss: 0.1408
2024-05-25 03:17:51 [INFO]: Epoch 169 - training loss: 0.2071, validation loss: 0.1380
2024-05-25 03:17:51 [INFO]: Epoch 170 - training loss: 0.2045, validation loss: 0.1389
2024-05-25 03:17:51 [INFO]: Epoch 171 - training loss: 0.2017, validation loss: 0.1386
2024-05-25 03:17:52 [INFO]: Epoch 172 - training loss: 0.2027, validation loss: 0.1367
2024-05-25 03:17:52 [INFO]: Epoch 173 - training loss: 0.2025, validation loss: 0.1388
2024-05-25 03:17:52 [INFO]: Epoch 174 - training loss: 0.2034, validation loss: 0.1377
2024-05-25 03:17:53 [INFO]: Epoch 175 - training loss: 0.2038, validation loss: 0.1391
2024-05-25 03:17:53 [INFO]: Epoch 176 - training loss: 0.2043, validation loss: 0.1377
2024-05-25 03:17:53 [INFO]: Epoch 177 - training loss: 0.2029, validation loss: 0.1376
2024-05-25 03:17:54 [INFO]: Epoch 178 - training loss: 0.2048, validation loss: 0.1366
2024-05-25 03:17:54 [INFO]: Epoch 179 - training loss: 0.2025, validation loss: 0.1370
2024-05-25 03:17:54 [INFO]: Epoch 180 - training loss: 0.2026, validation loss: 0.1362
2024-05-25 03:17:54 [INFO]: Epoch 181 - training loss: 0.2003, validation loss: 0.1380
2024-05-25 03:17:55 [INFO]: Epoch 182 - training loss: 0.2020, validation loss: 0.1375
2024-05-25 03:17:55 [INFO]: Epoch 183 - training loss: 0.2030, validation loss: 0.1366
2024-05-25 03:17:55 [INFO]: Epoch 184 - training loss: 0.1997, validation loss: 0.1363
2024-05-25 03:17:56 [INFO]: Epoch 185 - training loss: 0.2003, validation loss: 0.1371
2024-05-25 03:17:56 [INFO]: Epoch 186 - training loss: 0.1998, validation loss: 0.1380
2024-05-25 03:17:56 [INFO]: Epoch 187 - training loss: 0.2014, validation loss: 0.1356
2024-05-25 03:17:57 [INFO]: Epoch 188 - training loss: 0.1984, validation loss: 0.1361
2024-05-25 03:17:57 [INFO]: Epoch 189 - training loss: 0.1996, validation loss: 0.1382
2024-05-25 03:17:57 [INFO]: Epoch 190 - training loss: 0.2003, validation loss: 0.1355
2024-05-25 03:17:58 [INFO]: Epoch 191 - training loss: 0.1981, validation loss: 0.1357
2024-05-25 03:17:58 [INFO]: Epoch 192 - training loss: 0.1976, validation loss: 0.1351
2024-05-25 03:17:58 [INFO]: Epoch 193 - training loss: 0.1984, validation loss: 0.1351
2024-05-25 03:17:59 [INFO]: Epoch 194 - training loss: 0.1975, validation loss: 0.1353
2024-05-25 03:17:59 [INFO]: Epoch 195 - training loss: 0.1996, validation loss: 0.1343
2024-05-25 03:17:59 [INFO]: Epoch 196 - training loss: 0.1995, validation loss: 0.1355
2024-05-25 03:17:59 [INFO]: Epoch 197 - training loss: 0.1972, validation loss: 0.1365
2024-05-25 03:18:00 [INFO]: Epoch 198 - training loss: 0.1970, validation loss: 0.1345
2024-05-25 03:18:00 [INFO]: Epoch 199 - training loss: 0.1976, validation loss: 0.1355
2024-05-25 03:18:00 [INFO]: Epoch 200 - training loss: 0.1975, validation loss: 0.1354
2024-05-25 03:18:01 [INFO]: Epoch 201 - training loss: 0.1973, validation loss: 0.1357
2024-05-25 03:18:01 [INFO]: Epoch 202 - training loss: 0.1960, validation loss: 0.1345
2024-05-25 03:18:01 [INFO]: Epoch 203 - training loss: 0.1950, validation loss: 0.1340
2024-05-25 03:18:02 [INFO]: Epoch 204 - training loss: 0.1953, validation loss: 0.1344
2024-05-25 03:18:02 [INFO]: Epoch 205 - training loss: 0.1959, validation loss: 0.1343
2024-05-25 03:18:02 [INFO]: Epoch 206 - training loss: 0.1940, validation loss: 0.1340
2024-05-25 03:18:03 [INFO]: Epoch 207 - training loss: 0.1933, validation loss: 0.1327
2024-05-25 03:18:03 [INFO]: Epoch 208 - training loss: 0.1966, validation loss: 0.1341
2024-05-25 03:18:03 [INFO]: Epoch 209 - training loss: 0.1943, validation loss: 0.1344
2024-05-25 03:18:04 [INFO]: Epoch 210 - training loss: 0.1936, validation loss: 0.1355
2024-05-25 03:18:04 [INFO]: Epoch 211 - training loss: 0.1931, validation loss: 0.1330
2024-05-25 03:18:04 [INFO]: Epoch 212 - training loss: 0.1918, validation loss: 0.1334
2024-05-25 03:18:05 [INFO]: Epoch 213 - training loss: 0.1951, validation loss: 0.1325
2024-05-25 03:18:05 [INFO]: Epoch 214 - training loss: 0.1942, validation loss: 0.1327
2024-05-25 03:18:05 [INFO]: Epoch 215 - training loss: 0.1933, validation loss: 0.1351
2024-05-25 03:18:05 [INFO]: Epoch 216 - training loss: 0.1914, validation loss: 0.1335
2024-05-25 03:18:06 [INFO]: Epoch 217 - training loss: 0.1924, validation loss: 0.1326
2024-05-25 03:18:06 [INFO]: Epoch 218 - training loss: 0.1918, validation loss: 0.1335
2024-05-25 03:18:06 [INFO]: Epoch 219 - training loss: 0.1920, validation loss: 0.1332
2024-05-25 03:18:07 [INFO]: Epoch 220 - training loss: 0.1924, validation loss: 0.1309
2024-05-25 03:18:07 [INFO]: Epoch 221 - training loss: 0.1917, validation loss: 0.1322
2024-05-25 03:18:07 [INFO]: Epoch 222 - training loss: 0.1913, validation loss: 0.1334
2024-05-25 03:18:08 [INFO]: Epoch 223 - training loss: 0.1927, validation loss: 0.1331
2024-05-25 03:18:08 [INFO]: Epoch 224 - training loss: 0.1916, validation loss: 0.1342
2024-05-25 03:18:08 [INFO]: Epoch 225 - training loss: 0.1908, validation loss: 0.1320
2024-05-25 03:18:09 [INFO]: Epoch 226 - training loss: 0.1923, validation loss: 0.1323
2024-05-25 03:18:09 [INFO]: Epoch 227 - training loss: 0.1894, validation loss: 0.1326
2024-05-25 03:18:09 [INFO]: Epoch 228 - training loss: 0.1918, validation loss: 0.1316
2024-05-25 03:18:10 [INFO]: Epoch 229 - training loss: 0.1913, validation loss: 0.1330
2024-05-25 03:18:10 [INFO]: Epoch 230 - training loss: 0.1886, validation loss: 0.1306
2024-05-25 03:18:10 [INFO]: Epoch 231 - training loss: 0.1882, validation loss: 0.1309
2024-05-25 03:18:11 [INFO]: Epoch 232 - training loss: 0.1881, validation loss: 0.1320
2024-05-25 03:18:11 [INFO]: Epoch 233 - training loss: 0.1935, validation loss: 0.1319
2024-05-25 03:18:11 [INFO]: Epoch 234 - training loss: 0.1913, validation loss: 0.1315
2024-05-25 03:18:11 [INFO]: Epoch 235 - training loss: 0.1874, validation loss: 0.1310
2024-05-25 03:18:12 [INFO]: Epoch 236 - training loss: 0.1881, validation loss: 0.1309
2024-05-25 03:18:12 [INFO]: Epoch 237 - training loss: 0.1891, validation loss: 0.1306
2024-05-25 03:18:12 [INFO]: Epoch 238 - training loss: 0.1872, validation loss: 0.1333
2024-05-25 03:18:13 [INFO]: Epoch 239 - training loss: 0.1876, validation loss: 0.1303
2024-05-25 03:18:13 [INFO]: Epoch 240 - training loss: 0.1876, validation loss: 0.1322
2024-05-25 03:18:13 [INFO]: Epoch 241 - training loss: 0.1871, validation loss: 0.1305
2024-05-25 03:18:14 [INFO]: Epoch 242 - training loss: 0.1897, validation loss: 0.1305
2024-05-25 03:18:14 [INFO]: Epoch 243 - training loss: 0.1887, validation loss: 0.1310
2024-05-25 03:18:14 [INFO]: Epoch 244 - training loss: 0.1877, validation loss: 0.1312
2024-05-25 03:18:15 [INFO]: Epoch 245 - training loss: 0.1898, validation loss: 0.1296
2024-05-25 03:18:15 [INFO]: Epoch 246 - training loss: 0.1860, validation loss: 0.1306
2024-05-25 03:18:15 [INFO]: Epoch 247 - training loss: 0.1856, validation loss: 0.1307
2024-05-25 03:18:16 [INFO]: Epoch 248 - training loss: 0.1856, validation loss: 0.1307
2024-05-25 03:18:16 [INFO]: Epoch 249 - training loss: 0.1878, validation loss: 0.1296
2024-05-25 03:18:16 [INFO]: Epoch 250 - training loss: 0.1863, validation loss: 0.1300
2024-05-25 03:18:16 [INFO]: Epoch 251 - training loss: 0.1838, validation loss: 0.1312
2024-05-25 03:18:17 [INFO]: Epoch 252 - training loss: 0.1855, validation loss: 0.1297
2024-05-25 03:18:17 [INFO]: Epoch 253 - training loss: 0.1859, validation loss: 0.1292
2024-05-25 03:18:17 [INFO]: Epoch 254 - training loss: 0.1862, validation loss: 0.1296
2024-05-25 03:18:18 [INFO]: Epoch 255 - training loss: 0.1860, validation loss: 0.1284
2024-05-25 03:18:18 [INFO]: Epoch 256 - training loss: 0.1850, validation loss: 0.1304
2024-05-25 03:18:18 [INFO]: Epoch 257 - training loss: 0.1833, validation loss: 0.1287
2024-05-25 03:18:19 [INFO]: Epoch 258 - training loss: 0.1843, validation loss: 0.1302
2024-05-25 03:18:19 [INFO]: Epoch 259 - training loss: 0.1836, validation loss: 0.1284
2024-05-25 03:18:19 [INFO]: Epoch 260 - training loss: 0.1840, validation loss: 0.1291
2024-05-25 03:18:20 [INFO]: Epoch 261 - training loss: 0.1837, validation loss: 0.1283
2024-05-25 03:18:20 [INFO]: Epoch 262 - training loss: 0.1857, validation loss: 0.1278
2024-05-25 03:18:20 [INFO]: Epoch 263 - training loss: 0.1880, validation loss: 0.1288
2024-05-25 03:18:21 [INFO]: Epoch 264 - training loss: 0.1873, validation loss: 0.1286
2024-05-25 03:18:21 [INFO]: Epoch 265 - training loss: 0.1816, validation loss: 0.1287
2024-05-25 03:18:21 [INFO]: Epoch 266 - training loss: 0.1825, validation loss: 0.1281
2024-05-25 03:18:21 [INFO]: Epoch 267 - training loss: 0.1828, validation loss: 0.1275
2024-05-25 03:18:22 [INFO]: Epoch 268 - training loss: 0.1848, validation loss: 0.1294
2024-05-25 03:18:22 [INFO]: Epoch 269 - training loss: 0.1826, validation loss: 0.1283
2024-05-25 03:18:22 [INFO]: Epoch 270 - training loss: 0.1822, validation loss: 0.1291
2024-05-25 03:18:23 [INFO]: Epoch 271 - training loss: 0.1813, validation loss: 0.1280
2024-05-25 03:18:23 [INFO]: Epoch 272 - training loss: 0.1818, validation loss: 0.1279
2024-05-25 03:18:23 [INFO]: Epoch 273 - training loss: 0.1817, validation loss: 0.1273
2024-05-25 03:18:24 [INFO]: Epoch 274 - training loss: 0.1806, validation loss: 0.1269
2024-05-25 03:18:24 [INFO]: Epoch 275 - training loss: 0.1802, validation loss: 0.1296
2024-05-25 03:18:24 [INFO]: Epoch 276 - training loss: 0.1856, validation loss: 0.1297
2024-05-25 03:18:25 [INFO]: Epoch 277 - training loss: 0.1836, validation loss: 0.1279
2024-05-25 03:18:25 [INFO]: Epoch 278 - training loss: 0.1823, validation loss: 0.1271
2024-05-25 03:18:25 [INFO]: Epoch 279 - training loss: 0.1859, validation loss: 0.1270
2024-05-25 03:18:26 [INFO]: Epoch 280 - training loss: 0.1828, validation loss: 0.1284
2024-05-25 03:18:26 [INFO]: Epoch 281 - training loss: 0.1817, validation loss: 0.1291
2024-05-25 03:18:26 [INFO]: Epoch 282 - training loss: 0.1848, validation loss: 0.1273
2024-05-25 03:18:27 [INFO]: Epoch 283 - training loss: 0.1801, validation loss: 0.1280
2024-05-25 03:18:27 [INFO]: Epoch 284 - training loss: 0.1782, validation loss: 0.1273
2024-05-25 03:18:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:18:27 [INFO]: Finished training. The best model is from epoch#274.
2024-05-25 03:18:27 [INFO]: Saved the model to augmentation_saved_results/round_2/Transformer_air_quality/20240525_T031658/Transformer.pypots
2024-05-25 03:18:27 [INFO]: Transformer on Air-Quality: MAE=0.1612, MSE=0.1915
2024-05-25 03:18:27 [INFO]: Successfully saved to augmentation_saved_results/round_2/Transformer_air_quality/imputation.pkl
2024-05-25 03:18:27 [INFO]: Using the given device: cuda:0
2024-05-25 03:18:27 [INFO]: Model files will be saved to augmentation_saved_results/round_2/TimesNet_air_quality/20240525_T031827
2024-05-25 03:18:27 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/TimesNet_air_quality/20240525_T031827/tensorboard
2024-05-25 03:18:27 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 03:18:28 [INFO]: Epoch 001 - training loss: 0.3054, validation loss: 0.2738
2024-05-25 03:18:28 [INFO]: Epoch 002 - training loss: 0.2454, validation loss: 0.2297
2024-05-25 03:18:29 [INFO]: Epoch 003 - training loss: 0.1879, validation loss: 0.2101
2024-05-25 03:18:29 [INFO]: Epoch 004 - training loss: 0.1688, validation loss: 0.2005
2024-05-25 03:18:30 [INFO]: Epoch 005 - training loss: 0.1769, validation loss: 0.1954
2024-05-25 03:18:30 [INFO]: Epoch 006 - training loss: 0.1679, validation loss: 0.1967
2024-05-25 03:18:31 [INFO]: Epoch 007 - training loss: 0.1483, validation loss: 0.1875
2024-05-25 03:18:32 [INFO]: Epoch 008 - training loss: 0.1787, validation loss: 0.1875
2024-05-25 03:18:32 [INFO]: Epoch 009 - training loss: 0.1490, validation loss: 0.1817
2024-05-25 03:18:33 [INFO]: Epoch 010 - training loss: 0.1424, validation loss: 0.1765
2024-05-25 03:18:33 [INFO]: Epoch 011 - training loss: 0.1414, validation loss: 0.1741
2024-05-25 03:18:34 [INFO]: Epoch 012 - training loss: 0.1241, validation loss: 0.1720
2024-05-25 03:18:34 [INFO]: Epoch 013 - training loss: 0.1318, validation loss: 0.1725
2024-05-25 03:18:35 [INFO]: Epoch 014 - training loss: 0.1301, validation loss: 0.1708
2024-05-25 03:18:35 [INFO]: Epoch 015 - training loss: 0.1343, validation loss: 0.1713
2024-05-25 03:18:36 [INFO]: Epoch 016 - training loss: 0.1427, validation loss: 0.1694
2024-05-25 03:18:36 [INFO]: Epoch 017 - training loss: 0.1265, validation loss: 0.1683
2024-05-25 03:18:37 [INFO]: Epoch 018 - training loss: 0.1418, validation loss: 0.1633
2024-05-25 03:18:37 [INFO]: Epoch 019 - training loss: 0.1317, validation loss: 0.1696
2024-05-25 03:18:38 [INFO]: Epoch 020 - training loss: 0.1126, validation loss: 0.1722
2024-05-25 03:18:38 [INFO]: Epoch 021 - training loss: 0.1440, validation loss: 0.1761
2024-05-25 03:18:39 [INFO]: Epoch 022 - training loss: 0.1335, validation loss: 0.1692
2024-05-25 03:18:39 [INFO]: Epoch 023 - training loss: 0.1349, validation loss: 0.1688
2024-05-25 03:18:40 [INFO]: Epoch 024 - training loss: 0.1173, validation loss: 0.1646
2024-05-25 03:18:40 [INFO]: Epoch 025 - training loss: 0.1320, validation loss: 0.1582
2024-05-25 03:18:41 [INFO]: Epoch 026 - training loss: 0.1225, validation loss: 0.1598
2024-05-25 03:18:41 [INFO]: Epoch 027 - training loss: 0.1111, validation loss: 0.1586
2024-05-25 03:18:42 [INFO]: Epoch 028 - training loss: 0.1105, validation loss: 0.1679
2024-05-25 03:18:42 [INFO]: Epoch 029 - training loss: 0.1181, validation loss: 0.1742
2024-05-25 03:18:43 [INFO]: Epoch 030 - training loss: 0.1125, validation loss: 0.1601
2024-05-25 03:18:44 [INFO]: Epoch 031 - training loss: 0.1183, validation loss: 0.1629
2024-05-25 03:18:44 [INFO]: Epoch 032 - training loss: 0.1181, validation loss: 0.1583
2024-05-25 03:18:45 [INFO]: Epoch 033 - training loss: 0.0987, validation loss: 0.1557
2024-05-25 03:18:45 [INFO]: Epoch 034 - training loss: 0.1289, validation loss: 0.1584
2024-05-25 03:18:46 [INFO]: Epoch 035 - training loss: 0.1194, validation loss: 0.1578
2024-05-25 03:18:46 [INFO]: Epoch 036 - training loss: 0.1133, validation loss: 0.1577
2024-05-25 03:18:47 [INFO]: Epoch 037 - training loss: 0.1083, validation loss: 0.1609
2024-05-25 03:18:47 [INFO]: Epoch 038 - training loss: 0.1073, validation loss: 0.1605
2024-05-25 03:18:48 [INFO]: Epoch 039 - training loss: 0.1109, validation loss: 0.1601
2024-05-25 03:18:48 [INFO]: Epoch 040 - training loss: 0.1010, validation loss: 0.1575
2024-05-25 03:18:49 [INFO]: Epoch 041 - training loss: 0.1156, validation loss: 0.1582
2024-05-25 03:18:49 [INFO]: Epoch 042 - training loss: 0.1112, validation loss: 0.1534
2024-05-25 03:18:50 [INFO]: Epoch 043 - training loss: 0.1251, validation loss: 0.1601
2024-05-25 03:18:50 [INFO]: Epoch 044 - training loss: 0.1205, validation loss: 0.1538
2024-05-25 03:18:51 [INFO]: Epoch 045 - training loss: 0.1215, validation loss: 0.1565
2024-05-25 03:18:51 [INFO]: Epoch 046 - training loss: 0.1203, validation loss: 0.1570
2024-05-25 03:18:52 [INFO]: Epoch 047 - training loss: 0.1015, validation loss: 0.1503
2024-05-25 03:18:52 [INFO]: Epoch 048 - training loss: 0.1057, validation loss: 0.1520
2024-05-25 03:18:53 [INFO]: Epoch 049 - training loss: 0.1039, validation loss: 0.1497
2024-05-25 03:18:53 [INFO]: Epoch 050 - training loss: 0.1204, validation loss: 0.1528
2024-05-25 03:18:54 [INFO]: Epoch 051 - training loss: 0.1044, validation loss: 0.1558
2024-05-25 03:18:54 [INFO]: Epoch 052 - training loss: 0.0973, validation loss: 0.1511
2024-05-25 03:18:55 [INFO]: Epoch 053 - training loss: 0.1220, validation loss: 0.1516
2024-05-25 03:18:56 [INFO]: Epoch 054 - training loss: 0.0934, validation loss: 0.1503
2024-05-25 03:18:56 [INFO]: Epoch 055 - training loss: 0.1035, validation loss: 0.1505
2024-05-25 03:18:57 [INFO]: Epoch 056 - training loss: 0.1165, validation loss: 0.1515
2024-05-25 03:18:57 [INFO]: Epoch 057 - training loss: 0.0994, validation loss: 0.1547
2024-05-25 03:18:58 [INFO]: Epoch 058 - training loss: 0.1143, validation loss: 0.1595
2024-05-25 03:18:58 [INFO]: Epoch 059 - training loss: 0.1061, validation loss: 0.1505
2024-05-25 03:18:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:18:58 [INFO]: Finished training. The best model is from epoch#49.
2024-05-25 03:18:58 [INFO]: Saved the model to augmentation_saved_results/round_2/TimesNet_air_quality/20240525_T031827/TimesNet.pypots
2024-05-25 03:18:58 [INFO]: TimesNet on Air-Quality: MAE=0.1647, MSE=0.2309
2024-05-25 03:18:58 [INFO]: Successfully saved to augmentation_saved_results/round_2/TimesNet_air_quality/imputation.pkl
2024-05-25 03:18:58 [INFO]: Using the given device: cuda:0
2024-05-25 03:18:58 [INFO]: Model files will be saved to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858
2024-05-25 03:18:58 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/tensorboard
2024-05-25 03:18:58 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 03:19:15 [INFO]: Epoch 001 - training loss: 0.5002, validation loss: 0.3358
2024-05-25 03:19:15 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch1_loss0.3357509940862656.pypots
2024-05-25 03:19:32 [INFO]: Epoch 002 - training loss: 0.2625, validation loss: 0.2809
2024-05-25 03:19:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch2_loss0.280914717912674.pypots
2024-05-25 03:19:49 [INFO]: Epoch 003 - training loss: 0.2480, validation loss: 0.2538
2024-05-25 03:19:49 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch3_loss0.25377552062273023.pypots
2024-05-25 03:20:06 [INFO]: Epoch 004 - training loss: 0.2386, validation loss: 0.2367
2024-05-25 03:20:06 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch4_loss0.2366889163851738.pypots
2024-05-25 03:20:22 [INFO]: Epoch 005 - training loss: 0.2186, validation loss: 0.2018
2024-05-25 03:20:22 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch5_loss0.20183323919773102.pypots
2024-05-25 03:20:39 [INFO]: Epoch 006 - training loss: 0.1927, validation loss: 0.1774
2024-05-25 03:20:39 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch6_loss0.17740297466516494.pypots
2024-05-25 03:20:56 [INFO]: Epoch 007 - training loss: 0.2148, validation loss: 0.1715
2024-05-25 03:20:56 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch7_loss0.1715166375041008.pypots
2024-05-25 03:21:13 [INFO]: Epoch 008 - training loss: 0.2025, validation loss: 0.1828
2024-05-25 03:21:13 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch8_loss0.1827901318669319.pypots
2024-05-25 03:21:29 [INFO]: Epoch 009 - training loss: 0.1868, validation loss: 0.1603
2024-05-25 03:21:29 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch9_loss0.16033611744642257.pypots
2024-05-25 03:21:46 [INFO]: Epoch 010 - training loss: 0.1836, validation loss: 0.1537
2024-05-25 03:21:46 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch10_loss0.15366822481155396.pypots
2024-05-25 03:22:03 [INFO]: Epoch 011 - training loss: 0.1732, validation loss: 0.1589
2024-05-25 03:22:03 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch11_loss0.1589415341615677.pypots
2024-05-25 03:22:20 [INFO]: Epoch 012 - training loss: 0.1856, validation loss: 0.1551
2024-05-25 03:22:20 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch12_loss0.1550907388329506.pypots
2024-05-25 03:22:36 [INFO]: Epoch 013 - training loss: 0.1726, validation loss: 0.1457
2024-05-25 03:22:37 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch13_loss0.14569736272096634.pypots
2024-05-25 03:22:53 [INFO]: Epoch 014 - training loss: 0.1655, validation loss: 0.1460
2024-05-25 03:22:53 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch14_loss0.1459659978747368.pypots
2024-05-25 03:23:10 [INFO]: Epoch 015 - training loss: 0.1621, validation loss: 0.1412
2024-05-25 03:23:10 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch15_loss0.14122269973158835.pypots
2024-05-25 03:23:27 [INFO]: Epoch 016 - training loss: 0.1582, validation loss: 0.1434
2024-05-25 03:23:27 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch16_loss0.14338941425085067.pypots
2024-05-25 03:23:44 [INFO]: Epoch 017 - training loss: 0.1645, validation loss: 0.1421
2024-05-25 03:23:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch17_loss0.1420810617506504.pypots
2024-05-25 03:24:00 [INFO]: Epoch 018 - training loss: 0.1674, validation loss: 0.1377
2024-05-25 03:24:00 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch18_loss0.13768782168626786.pypots
2024-05-25 03:24:17 [INFO]: Epoch 019 - training loss: 0.1565, validation loss: 0.1389
2024-05-25 03:24:17 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch19_loss0.13892583400011063.pypots
2024-05-25 03:24:34 [INFO]: Epoch 020 - training loss: 0.1550, validation loss: 0.1394
2024-05-25 03:24:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch20_loss0.13940007314085961.pypots
2024-05-25 03:24:51 [INFO]: Epoch 021 - training loss: 0.1419, validation loss: 0.1349
2024-05-25 03:24:51 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch21_loss0.1349143572151661.pypots
2024-05-25 03:25:07 [INFO]: Epoch 022 - training loss: 0.1499, validation loss: 0.1337
2024-05-25 03:25:07 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch22_loss0.13367266729474067.pypots
2024-05-25 03:25:24 [INFO]: Epoch 023 - training loss: 0.1471, validation loss: 0.1345
2024-05-25 03:25:24 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch23_loss0.13450529426336288.pypots
2024-05-25 03:25:41 [INFO]: Epoch 024 - training loss: 0.1551, validation loss: 0.1319
2024-05-25 03:25:41 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch24_loss0.13186521232128143.pypots
2024-05-25 03:25:58 [INFO]: Epoch 025 - training loss: 0.1316, validation loss: 0.1328
2024-05-25 03:25:58 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch25_loss0.13277141377329826.pypots
2024-05-25 03:26:15 [INFO]: Epoch 026 - training loss: 0.1544, validation loss: 0.1327
2024-05-25 03:26:15 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch26_loss0.13270822465419768.pypots
2024-05-25 03:26:31 [INFO]: Epoch 027 - training loss: 0.1441, validation loss: 0.1354
2024-05-25 03:26:31 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch27_loss0.13536253795027733.pypots
2024-05-25 03:26:48 [INFO]: Epoch 028 - training loss: 0.1508, validation loss: 0.1291
2024-05-25 03:26:48 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch28_loss0.12908266633749008.pypots
2024-05-25 03:27:05 [INFO]: Epoch 029 - training loss: 0.1307, validation loss: 0.1279
2024-05-25 03:27:05 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch29_loss0.127871223539114.pypots
2024-05-25 03:27:22 [INFO]: Epoch 030 - training loss: 0.1390, validation loss: 0.1324
2024-05-25 03:27:22 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch30_loss0.1324262447655201.pypots
2024-05-25 03:27:38 [INFO]: Epoch 031 - training loss: 0.1520, validation loss: 0.1301
2024-05-25 03:27:38 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch31_loss0.13010315746068954.pypots
2024-05-25 03:27:55 [INFO]: Epoch 032 - training loss: 0.1267, validation loss: 0.1274
2024-05-25 03:27:55 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch32_loss0.12736724093556404.pypots
2024-05-25 03:28:12 [INFO]: Epoch 033 - training loss: 0.1635, validation loss: 0.1277
2024-05-25 03:28:12 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch33_loss0.12771118730306624.pypots
2024-05-25 03:28:29 [INFO]: Epoch 034 - training loss: 0.1382, validation loss: 0.1303
2024-05-25 03:28:29 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch34_loss0.13025032058358194.pypots
2024-05-25 03:28:45 [INFO]: Epoch 035 - training loss: 0.1215, validation loss: 0.1248
2024-05-25 03:28:45 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch35_loss0.12480990961194038.pypots
2024-05-25 03:29:02 [INFO]: Epoch 036 - training loss: 0.1197, validation loss: 0.1234
2024-05-25 03:29:02 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch36_loss0.12338092476129532.pypots
2024-05-25 03:29:19 [INFO]: Epoch 037 - training loss: 0.1301, validation loss: 0.1303
2024-05-25 03:29:19 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch37_loss0.1302514486014843.pypots
2024-05-25 03:29:36 [INFO]: Epoch 038 - training loss: 0.1270, validation loss: 0.1285
2024-05-25 03:29:36 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch38_loss0.12850370779633521.pypots
2024-05-25 03:29:53 [INFO]: Epoch 039 - training loss: 0.1496, validation loss: 0.1243
2024-05-25 03:29:53 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch39_loss0.1243203267455101.pypots
2024-05-25 03:30:09 [INFO]: Epoch 040 - training loss: 0.1251, validation loss: 0.1221
2024-05-25 03:30:09 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch40_loss0.12210586294531822.pypots
2024-05-25 03:30:26 [INFO]: Epoch 041 - training loss: 0.1183, validation loss: 0.1215
2024-05-25 03:30:26 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch41_loss0.12147251740098.pypots
2024-05-25 03:30:43 [INFO]: Epoch 042 - training loss: 0.1331, validation loss: 0.1249
2024-05-25 03:30:43 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch42_loss0.1248943030834198.pypots
2024-05-25 03:31:00 [INFO]: Epoch 043 - training loss: 0.1278, validation loss: 0.1208
2024-05-25 03:31:00 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch43_loss0.12080335319042206.pypots
2024-05-25 03:31:17 [INFO]: Epoch 044 - training loss: 0.1307, validation loss: 0.1234
2024-05-25 03:31:17 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch44_loss0.12339660227298736.pypots
2024-05-25 03:31:33 [INFO]: Epoch 045 - training loss: 0.1245, validation loss: 0.1205
2024-05-25 03:31:33 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch45_loss0.1205236405134201.pypots
2024-05-25 03:31:50 [INFO]: Epoch 046 - training loss: 0.1278, validation loss: 0.1165
2024-05-25 03:31:50 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch46_loss0.11650181040167809.pypots
2024-05-25 03:32:07 [INFO]: Epoch 047 - training loss: 0.1285, validation loss: 0.1179
2024-05-25 03:32:07 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch47_loss0.11788535118103027.pypots
2024-05-25 03:32:24 [INFO]: Epoch 048 - training loss: 0.1324, validation loss: 0.1188
2024-05-25 03:32:24 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch48_loss0.11883513033390045.pypots
2024-05-25 03:32:40 [INFO]: Epoch 049 - training loss: 0.1528, validation loss: 0.1190
2024-05-25 03:32:40 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch49_loss0.1190236248075962.pypots
2024-05-25 03:32:57 [INFO]: Epoch 050 - training loss: 0.1316, validation loss: 0.1155
2024-05-25 03:32:57 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch50_loss0.11546075567603112.pypots
2024-05-25 03:33:14 [INFO]: Epoch 051 - training loss: 0.1203, validation loss: 0.1141
2024-05-25 03:33:14 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch51_loss0.1140898659825325.pypots
2024-05-25 03:33:31 [INFO]: Epoch 052 - training loss: 0.1248, validation loss: 0.1162
2024-05-25 03:33:31 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch52_loss0.11619887799024582.pypots
2024-05-25 03:33:48 [INFO]: Epoch 053 - training loss: 0.1169, validation loss: 0.1151
2024-05-25 03:33:48 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch53_loss0.1150553934276104.pypots
2024-05-25 03:34:04 [INFO]: Epoch 054 - training loss: 0.1309, validation loss: 0.1137
2024-05-25 03:34:04 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch54_loss0.1137302540242672.pypots
2024-05-25 03:34:21 [INFO]: Epoch 055 - training loss: 0.1156, validation loss: 0.1131
2024-05-25 03:34:21 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch55_loss0.1131412260234356.pypots
2024-05-25 03:34:38 [INFO]: Epoch 056 - training loss: 0.1186, validation loss: 0.1135
2024-05-25 03:34:38 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch56_loss0.11349155902862548.pypots
2024-05-25 03:34:55 [INFO]: Epoch 057 - training loss: 0.1199, validation loss: 0.1125
2024-05-25 03:34:55 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch57_loss0.11245310381054878.pypots
2024-05-25 03:35:11 [INFO]: Epoch 058 - training loss: 0.1264, validation loss: 0.1121
2024-05-25 03:35:11 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch58_loss0.11209373846650124.pypots
2024-05-25 03:35:28 [INFO]: Epoch 059 - training loss: 0.1285, validation loss: 0.1129
2024-05-25 03:35:28 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch59_loss0.11290916278958321.pypots
2024-05-25 03:35:45 [INFO]: Epoch 060 - training loss: 0.1118, validation loss: 0.1159
2024-05-25 03:35:45 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch60_loss0.11589825376868249.pypots
2024-05-25 03:36:02 [INFO]: Epoch 061 - training loss: 0.1401, validation loss: 0.1129
2024-05-25 03:36:02 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch61_loss0.11288662105798722.pypots
2024-05-25 03:36:18 [INFO]: Epoch 062 - training loss: 0.1165, validation loss: 0.1108
2024-05-25 03:36:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch62_loss0.11075377091765404.pypots
2024-05-25 03:36:35 [INFO]: Epoch 063 - training loss: 0.1163, validation loss: 0.1116
2024-05-25 03:36:35 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch63_loss0.1116170533001423.pypots
2024-05-25 03:36:52 [INFO]: Epoch 064 - training loss: 0.1288, validation loss: 0.1121
2024-05-25 03:36:52 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch64_loss0.112098228931427.pypots
2024-05-25 03:37:09 [INFO]: Epoch 065 - training loss: 0.1064, validation loss: 0.1126
2024-05-25 03:37:09 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch65_loss0.11257255673408509.pypots
2024-05-25 03:37:26 [INFO]: Epoch 066 - training loss: 0.1144, validation loss: 0.1118
2024-05-25 03:37:26 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch66_loss0.11175134181976318.pypots
2024-05-25 03:37:42 [INFO]: Epoch 067 - training loss: 0.1242, validation loss: 0.1129
2024-05-25 03:37:42 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch67_loss0.11290674135088921.pypots
2024-05-25 03:37:59 [INFO]: Epoch 068 - training loss: 0.1207, validation loss: 0.1129
2024-05-25 03:37:59 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch68_loss0.11293864995241165.pypots
2024-05-25 03:38:16 [INFO]: Epoch 069 - training loss: 0.1268, validation loss: 0.1107
2024-05-25 03:38:16 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch69_loss0.11070248633623123.pypots
2024-05-25 03:38:33 [INFO]: Epoch 070 - training loss: 0.1092, validation loss: 0.1090
2024-05-25 03:38:33 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch70_loss0.10895133838057518.pypots
2024-05-25 03:38:49 [INFO]: Epoch 071 - training loss: 0.1137, validation loss: 0.1139
2024-05-25 03:38:49 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch71_loss0.11385258585214615.pypots
2024-05-25 03:39:06 [INFO]: Epoch 072 - training loss: 0.1095, validation loss: 0.1094
2024-05-25 03:39:06 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch72_loss0.10939648374915123.pypots
2024-05-25 03:39:23 [INFO]: Epoch 073 - training loss: 0.1171, validation loss: 0.1097
2024-05-25 03:39:23 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch73_loss0.10970616489648818.pypots
2024-05-25 03:39:40 [INFO]: Epoch 074 - training loss: 0.1082, validation loss: 0.1087
2024-05-25 03:39:40 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch74_loss0.10866626203060151.pypots
2024-05-25 03:39:56 [INFO]: Epoch 075 - training loss: 0.1107, validation loss: 0.1072
2024-05-25 03:39:56 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch75_loss0.10721269100904465.pypots
2024-05-25 03:40:13 [INFO]: Epoch 076 - training loss: 0.1107, validation loss: 0.1138
2024-05-25 03:40:13 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch76_loss0.11376238241791725.pypots
2024-05-25 03:40:30 [INFO]: Epoch 077 - training loss: 0.1152, validation loss: 0.1065
2024-05-25 03:40:30 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch77_loss0.10654077008366585.pypots
2024-05-25 03:40:47 [INFO]: Epoch 078 - training loss: 0.1258, validation loss: 0.1118
2024-05-25 03:40:47 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch78_loss0.11178240031003953.pypots
2024-05-25 03:41:03 [INFO]: Epoch 079 - training loss: 0.1295, validation loss: 0.1104
2024-05-25 03:41:03 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch79_loss0.11036331728100776.pypots
2024-05-25 03:41:20 [INFO]: Epoch 080 - training loss: 0.1174, validation loss: 0.1076
2024-05-25 03:41:20 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch80_loss0.10760665237903595.pypots
2024-05-25 03:41:37 [INFO]: Epoch 081 - training loss: 0.1244, validation loss: 0.1111
2024-05-25 03:41:37 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch81_loss0.11112805157899856.pypots
2024-05-25 03:41:54 [INFO]: Epoch 082 - training loss: 0.1232, validation loss: 0.1114
2024-05-25 03:41:54 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch82_loss0.1113570436835289.pypots
2024-05-25 03:42:10 [INFO]: Epoch 083 - training loss: 0.1085, validation loss: 0.1079
2024-05-25 03:42:11 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch83_loss0.10791495218873023.pypots
2024-05-25 03:42:27 [INFO]: Epoch 084 - training loss: 0.1184, validation loss: 0.1084
2024-05-25 03:42:27 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch84_loss0.10837716609239578.pypots
2024-05-25 03:42:44 [INFO]: Epoch 085 - training loss: 0.1127, validation loss: 0.1095
2024-05-25 03:42:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch85_loss0.10948630422353745.pypots
2024-05-25 03:43:01 [INFO]: Epoch 086 - training loss: 0.1045, validation loss: 0.1070
2024-05-25 03:43:01 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch86_loss0.10699538514018059.pypots
2024-05-25 03:43:18 [INFO]: Epoch 087 - training loss: 0.1084, validation loss: 0.1088
2024-05-25 03:43:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI_epoch87_loss0.10876407697796822.pypots
2024-05-25 03:43:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:43:18 [INFO]: Finished training. The best model is from epoch#77.
2024-05-25 03:43:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240525_T031858/CSDI.pypots
2024-05-25 03:45:37 [INFO]: CSDI on Air-Quality: MAE=0.1133, MSE=0.1830
2024-05-25 03:45:37 [INFO]: Successfully saved to augmentation_saved_results/round_2/CSDI_air_quality/imputation.pkl
2024-05-25 03:45:37 [INFO]: Using the given device: cuda:0
2024-05-25 03:45:37 [INFO]: Model files will be saved to augmentation_saved_results/round_2/GPVAE_air_quality/20240525_T034537
2024-05-25 03:45:37 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/GPVAE_air_quality/20240525_T034537/tensorboard
2024-05-25 03:45:37 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 03:45:38 [INFO]: Epoch 001 - training loss: 64090.4083, validation loss: 0.6950
2024-05-25 03:45:38 [INFO]: Epoch 002 - training loss: 42055.3808, validation loss: 0.6027
2024-05-25 03:45:38 [INFO]: Epoch 003 - training loss: 41741.7669, validation loss: 0.5186
2024-05-25 03:45:39 [INFO]: Epoch 004 - training loss: 41615.6005, validation loss: 0.4867
2024-05-25 03:45:39 [INFO]: Epoch 005 - training loss: 41527.1100, validation loss: 0.4182
2024-05-25 03:45:39 [INFO]: Epoch 006 - training loss: 41480.2951, validation loss: 0.4030
2024-05-25 03:45:40 [INFO]: Epoch 007 - training loss: 41449.6918, validation loss: 0.3969
2024-05-25 03:45:40 [INFO]: Epoch 008 - training loss: 41434.2892, validation loss: 0.3574
2024-05-25 03:45:40 [INFO]: Epoch 009 - training loss: 41410.8673, validation loss: 0.3994
2024-05-25 03:45:41 [INFO]: Epoch 010 - training loss: 41374.4222, validation loss: 0.3626
2024-05-25 03:45:41 [INFO]: Epoch 011 - training loss: 41341.4336, validation loss: 0.3615
2024-05-25 03:45:41 [INFO]: Epoch 012 - training loss: 41342.1667, validation loss: 0.3751
2024-05-25 03:45:42 [INFO]: Epoch 013 - training loss: 41322.3795, validation loss: 0.3500
2024-05-25 03:45:42 [INFO]: Epoch 014 - training loss: 41349.8527, validation loss: 0.3381
2024-05-25 03:45:42 [INFO]: Epoch 015 - training loss: 41306.1790, validation loss: 0.3310
2024-05-25 03:45:43 [INFO]: Epoch 016 - training loss: 41314.0311, validation loss: 0.3272
2024-05-25 03:45:43 [INFO]: Epoch 017 - training loss: 41308.7302, validation loss: 0.3160
2024-05-25 03:45:43 [INFO]: Epoch 018 - training loss: 41275.0265, validation loss: 0.3310
2024-05-25 03:45:44 [INFO]: Epoch 019 - training loss: 41266.5498, validation loss: 0.3050
2024-05-25 03:45:44 [INFO]: Epoch 020 - training loss: 41256.0103, validation loss: 0.3003
2024-05-25 03:45:44 [INFO]: Epoch 021 - training loss: 41249.0453, validation loss: 0.3075
2024-05-25 03:45:45 [INFO]: Epoch 022 - training loss: 41270.9576, validation loss: 0.3364
2024-05-25 03:45:45 [INFO]: Epoch 023 - training loss: 41249.5952, validation loss: 0.2890
2024-05-25 03:45:45 [INFO]: Epoch 024 - training loss: 41246.3594, validation loss: 0.2928
2024-05-25 03:45:45 [INFO]: Epoch 025 - training loss: 41231.6811, validation loss: 0.2999
2024-05-25 03:45:46 [INFO]: Epoch 026 - training loss: 41233.0273, validation loss: 0.2872
2024-05-25 03:45:46 [INFO]: Epoch 027 - training loss: 41225.2253, validation loss: 0.2804
2024-05-25 03:45:46 [INFO]: Epoch 028 - training loss: 41233.4284, validation loss: 0.2896
2024-05-25 03:45:47 [INFO]: Epoch 029 - training loss: 41216.3610, validation loss: 0.2860
2024-05-25 03:45:47 [INFO]: Epoch 030 - training loss: 41213.5936, validation loss: 0.3042
2024-05-25 03:45:47 [INFO]: Epoch 031 - training loss: 41234.4964, validation loss: 0.2891
2024-05-25 03:45:48 [INFO]: Epoch 032 - training loss: 41228.3322, validation loss: 0.3050
2024-05-25 03:45:48 [INFO]: Epoch 033 - training loss: 41209.7426, validation loss: 0.2695
2024-05-25 03:45:48 [INFO]: Epoch 034 - training loss: 41196.5285, validation loss: 0.2759
2024-05-25 03:45:49 [INFO]: Epoch 035 - training loss: 41195.3516, validation loss: 0.2996
2024-05-25 03:45:49 [INFO]: Epoch 036 - training loss: 41209.6399, validation loss: 0.2721
2024-05-25 03:45:49 [INFO]: Epoch 037 - training loss: 41197.5569, validation loss: 0.2625
2024-05-25 03:45:50 [INFO]: Epoch 038 - training loss: 41199.6379, validation loss: 0.2577
2024-05-25 03:45:50 [INFO]: Epoch 039 - training loss: 41193.8785, validation loss: 0.2780
2024-05-25 03:45:50 [INFO]: Epoch 040 - training loss: 41184.5508, validation loss: 0.2786
2024-05-25 03:45:51 [INFO]: Epoch 041 - training loss: 41186.5352, validation loss: 0.2583
2024-05-25 03:45:51 [INFO]: Epoch 042 - training loss: 41190.7821, validation loss: 0.2559
2024-05-25 03:45:51 [INFO]: Epoch 043 - training loss: 41184.3649, validation loss: 0.2722
2024-05-25 03:45:52 [INFO]: Epoch 044 - training loss: 41224.0783, validation loss: 0.3209
2024-05-25 03:45:52 [INFO]: Epoch 045 - training loss: 41275.6593, validation loss: 0.2861
2024-05-25 03:45:52 [INFO]: Epoch 046 - training loss: 41281.5379, validation loss: 0.2953
2024-05-25 03:45:53 [INFO]: Epoch 047 - training loss: 41196.6066, validation loss: 0.2618
2024-05-25 03:45:53 [INFO]: Epoch 048 - training loss: 41173.4018, validation loss: 0.2587
2024-05-25 03:45:53 [INFO]: Epoch 049 - training loss: 41172.2568, validation loss: 0.2600
2024-05-25 03:45:53 [INFO]: Epoch 050 - training loss: 41166.3015, validation loss: 0.2590
2024-05-25 03:45:54 [INFO]: Epoch 051 - training loss: 41161.2420, validation loss: 0.2520
2024-05-25 03:45:54 [INFO]: Epoch 052 - training loss: 41160.8534, validation loss: 0.2466
2024-05-25 03:45:54 [INFO]: Epoch 053 - training loss: 41171.0966, validation loss: 0.2649
2024-05-25 03:45:55 [INFO]: Epoch 054 - training loss: 41165.7471, validation loss: 0.2502
2024-05-25 03:45:55 [INFO]: Epoch 055 - training loss: 41157.0275, validation loss: 0.2640
2024-05-25 03:45:55 [INFO]: Epoch 056 - training loss: 41171.3323, validation loss: 0.2465
2024-05-25 03:45:56 [INFO]: Epoch 057 - training loss: 41179.4592, validation loss: 0.2907
2024-05-25 03:45:56 [INFO]: Epoch 058 - training loss: 41205.7979, validation loss: 0.2579
2024-05-25 03:45:56 [INFO]: Epoch 059 - training loss: 41181.2292, validation loss: 0.2652
2024-05-25 03:45:57 [INFO]: Epoch 060 - training loss: 41167.5972, validation loss: 0.2691
2024-05-25 03:45:57 [INFO]: Epoch 061 - training loss: 41171.0904, validation loss: 0.2670
2024-05-25 03:45:57 [INFO]: Epoch 062 - training loss: 41152.8479, validation loss: 0.2618
2024-05-25 03:45:58 [INFO]: Epoch 063 - training loss: 41148.6589, validation loss: 0.2517
2024-05-25 03:45:58 [INFO]: Epoch 064 - training loss: 41143.2882, validation loss: 0.2438
2024-05-25 03:45:58 [INFO]: Epoch 065 - training loss: 41144.4284, validation loss: 0.2460
2024-05-25 03:45:59 [INFO]: Epoch 066 - training loss: 41151.2418, validation loss: 0.2534
2024-05-25 03:45:59 [INFO]: Epoch 067 - training loss: 41163.5071, validation loss: 0.2838
2024-05-25 03:45:59 [INFO]: Epoch 068 - training loss: 41185.5026, validation loss: 0.2690
2024-05-25 03:46:00 [INFO]: Epoch 069 - training loss: 41170.1357, validation loss: 0.2732
2024-05-25 03:46:00 [INFO]: Epoch 070 - training loss: 41170.1997, validation loss: 0.2531
2024-05-25 03:46:00 [INFO]: Epoch 071 - training loss: 41156.3701, validation loss: 0.2462
2024-05-25 03:46:01 [INFO]: Epoch 072 - training loss: 41144.7998, validation loss: 0.2475
2024-05-25 03:46:01 [INFO]: Epoch 073 - training loss: 41145.6885, validation loss: 0.2630
2024-05-25 03:46:01 [INFO]: Epoch 074 - training loss: 41140.4154, validation loss: 0.2476
2024-05-25 03:46:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:46:01 [INFO]: Finished training. The best model is from epoch#64.
2024-05-25 03:46:01 [INFO]: Saved the model to augmentation_saved_results/round_2/GPVAE_air_quality/20240525_T034537/GPVAE.pypots
2024-05-25 03:46:01 [INFO]: GP-VAE on Air-Quality: MAE=0.3022, MSE=0.3109
2024-05-25 03:46:01 [INFO]: Successfully saved to augmentation_saved_results/round_2/GPVAE_air_quality/imputation.pkl
2024-05-25 03:46:01 [INFO]: Using the given device: cuda:0
2024-05-25 03:46:01 [INFO]: Model files will be saved to augmentation_saved_results/round_2/USGAN_air_quality/20240525_T034601
2024-05-25 03:46:01 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/USGAN_air_quality/20240525_T034601/tensorboard
2024-05-25 03:46:01 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 03:46:06 [INFO]: Epoch 001 - generator training loss: 0.6136, discriminator training loss: 0.3012, validation loss: 0.5241
2024-05-25 03:46:10 [INFO]: Epoch 002 - generator training loss: 0.2901, discriminator training loss: 0.0681, validation loss: 0.3955
2024-05-25 03:46:14 [INFO]: Epoch 003 - generator training loss: 0.2162, discriminator training loss: 0.0636, validation loss: 0.3287
2024-05-25 03:46:18 [INFO]: Epoch 004 - generator training loss: 0.1799, discriminator training loss: 0.0621, validation loss: 0.2855
2024-05-25 03:46:22 [INFO]: Epoch 005 - generator training loss: 0.1509, discriminator training loss: 0.0621, validation loss: 0.2575
2024-05-25 03:46:26 [INFO]: Epoch 006 - generator training loss: 0.1338, discriminator training loss: 0.0613, validation loss: 0.2401
2024-05-25 03:46:30 [INFO]: Epoch 007 - generator training loss: 0.1204, discriminator training loss: 0.0605, validation loss: 0.2266
2024-05-25 03:46:34 [INFO]: Epoch 008 - generator training loss: 0.1099, discriminator training loss: 0.0600, validation loss: 0.2172
2024-05-25 03:46:39 [INFO]: Epoch 009 - generator training loss: 0.1009, discriminator training loss: 0.0595, validation loss: 0.2087
2024-05-25 03:46:43 [INFO]: Epoch 010 - generator training loss: 0.0941, discriminator training loss: 0.0587, validation loss: 0.2024
2024-05-25 03:46:47 [INFO]: Epoch 011 - generator training loss: 0.0888, discriminator training loss: 0.0583, validation loss: 0.1967
2024-05-25 03:46:51 [INFO]: Epoch 012 - generator training loss: 0.0841, discriminator training loss: 0.0571, validation loss: 0.1923
2024-05-25 03:46:55 [INFO]: Epoch 013 - generator training loss: 0.0813, discriminator training loss: 0.0560, validation loss: 0.1890
2024-05-25 03:46:59 [INFO]: Epoch 014 - generator training loss: 0.0786, discriminator training loss: 0.0543, validation loss: 0.1848
2024-05-25 03:47:03 [INFO]: Epoch 015 - generator training loss: 0.0757, discriminator training loss: 0.0530, validation loss: 0.1817
2024-05-25 03:47:07 [INFO]: Epoch 016 - generator training loss: 0.0743, discriminator training loss: 0.0509, validation loss: 0.1785
2024-05-25 03:47:11 [INFO]: Epoch 017 - generator training loss: 0.0719, discriminator training loss: 0.0496, validation loss: 0.1763
2024-05-25 03:47:15 [INFO]: Epoch 018 - generator training loss: 0.0707, discriminator training loss: 0.0480, validation loss: 0.1739
2024-05-25 03:47:20 [INFO]: Epoch 019 - generator training loss: 0.0691, discriminator training loss: 0.0474, validation loss: 0.1718
2024-05-25 03:47:24 [INFO]: Epoch 020 - generator training loss: 0.0687, discriminator training loss: 0.0462, validation loss: 0.1692
2024-05-25 03:47:28 [INFO]: Epoch 021 - generator training loss: 0.0669, discriminator training loss: 0.0449, validation loss: 0.1678
2024-05-25 03:47:32 [INFO]: Epoch 022 - generator training loss: 0.0644, discriminator training loss: 0.0439, validation loss: 0.1663
2024-05-25 03:47:36 [INFO]: Epoch 023 - generator training loss: 0.0633, discriminator training loss: 0.0433, validation loss: 0.1652
2024-05-25 03:47:40 [INFO]: Epoch 024 - generator training loss: 0.0630, discriminator training loss: 0.0426, validation loss: 0.1634
2024-05-25 03:47:44 [INFO]: Epoch 025 - generator training loss: 0.0629, discriminator training loss: 0.0419, validation loss: 0.1623
2024-05-25 03:47:48 [INFO]: Epoch 026 - generator training loss: 0.0607, discriminator training loss: 0.0410, validation loss: 0.1603
2024-05-25 03:47:52 [INFO]: Epoch 027 - generator training loss: 0.0603, discriminator training loss: 0.0407, validation loss: 0.1601
2024-05-25 03:47:56 [INFO]: Epoch 028 - generator training loss: 0.0585, discriminator training loss: 0.0396, validation loss: 0.1588
2024-05-25 03:48:00 [INFO]: Epoch 029 - generator training loss: 0.0580, discriminator training loss: 0.0387, validation loss: 0.1581
2024-05-25 03:48:04 [INFO]: Epoch 030 - generator training loss: 0.0587, discriminator training loss: 0.0383, validation loss: 0.1576
2024-05-25 03:48:08 [INFO]: Epoch 031 - generator training loss: 0.0572, discriminator training loss: 0.0371, validation loss: 0.1553
2024-05-25 03:48:12 [INFO]: Epoch 032 - generator training loss: 0.0557, discriminator training loss: 0.0364, validation loss: 0.1554
2024-05-25 03:48:16 [INFO]: Epoch 033 - generator training loss: 0.0555, discriminator training loss: 0.0356, validation loss: 0.1537
2024-05-25 03:48:21 [INFO]: Epoch 034 - generator training loss: 0.0556, discriminator training loss: 0.0346, validation loss: 0.1537
2024-05-25 03:48:25 [INFO]: Epoch 035 - generator training loss: 0.0546, discriminator training loss: 0.0336, validation loss: 0.1534
2024-05-25 03:48:29 [INFO]: Epoch 036 - generator training loss: 0.0540, discriminator training loss: 0.0336, validation loss: 0.1520
2024-05-25 03:48:33 [INFO]: Epoch 037 - generator training loss: 0.0548, discriminator training loss: 0.0326, validation loss: 0.1512
2024-05-25 03:48:37 [INFO]: Epoch 038 - generator training loss: 0.0534, discriminator training loss: 0.0317, validation loss: 0.1511
2024-05-25 03:48:41 [INFO]: Epoch 039 - generator training loss: 0.0536, discriminator training loss: 0.0313, validation loss: 0.1499
2024-05-25 03:48:45 [INFO]: Epoch 040 - generator training loss: 0.0528, discriminator training loss: 0.0306, validation loss: 0.1498
2024-05-25 03:48:49 [INFO]: Epoch 041 - generator training loss: 0.0529, discriminator training loss: 0.0301, validation loss: 0.1496
2024-05-25 03:48:53 [INFO]: Epoch 042 - generator training loss: 0.0517, discriminator training loss: 0.0296, validation loss: 0.1477
2024-05-25 03:48:57 [INFO]: Epoch 043 - generator training loss: 0.0517, discriminator training loss: 0.0290, validation loss: 0.1462
2024-05-25 03:49:01 [INFO]: Epoch 044 - generator training loss: 0.0501, discriminator training loss: 0.0285, validation loss: 0.1448
2024-05-25 03:49:05 [INFO]: Epoch 045 - generator training loss: 0.0499, discriminator training loss: 0.0274, validation loss: 0.1450
2024-05-25 03:49:09 [INFO]: Epoch 046 - generator training loss: 0.0504, discriminator training loss: 0.0272, validation loss: 0.1437
2024-05-25 03:49:13 [INFO]: Epoch 047 - generator training loss: 0.0490, discriminator training loss: 0.0267, validation loss: 0.1441
2024-05-25 03:49:17 [INFO]: Epoch 048 - generator training loss: 0.0488, discriminator training loss: 0.0260, validation loss: 0.1430
2024-05-25 03:49:21 [INFO]: Epoch 049 - generator training loss: 0.0493, discriminator training loss: 0.0255, validation loss: 0.1426
2024-05-25 03:49:25 [INFO]: Epoch 050 - generator training loss: 0.0470, discriminator training loss: 0.0252, validation loss: 0.1427
2024-05-25 03:49:29 [INFO]: Epoch 051 - generator training loss: 0.0465, discriminator training loss: 0.0249, validation loss: 0.1428
2024-05-25 03:49:34 [INFO]: Epoch 052 - generator training loss: 0.0462, discriminator training loss: 0.0246, validation loss: 0.1418
2024-05-25 03:49:38 [INFO]: Epoch 053 - generator training loss: 0.0460, discriminator training loss: 0.0238, validation loss: 0.1417
2024-05-25 03:49:42 [INFO]: Epoch 054 - generator training loss: 0.0457, discriminator training loss: 0.0233, validation loss: 0.1413
2024-05-25 03:49:46 [INFO]: Epoch 055 - generator training loss: 0.0464, discriminator training loss: 0.0233, validation loss: 0.1410
2024-05-25 03:49:50 [INFO]: Epoch 056 - generator training loss: 0.0457, discriminator training loss: 0.0228, validation loss: 0.1406
2024-05-25 03:49:54 [INFO]: Epoch 057 - generator training loss: 0.0455, discriminator training loss: 0.0227, validation loss: 0.1396
2024-05-25 03:49:58 [INFO]: Epoch 058 - generator training loss: 0.0450, discriminator training loss: 0.0221, validation loss: 0.1399
2024-05-25 03:50:02 [INFO]: Epoch 059 - generator training loss: 0.0450, discriminator training loss: 0.0218, validation loss: 0.1391
2024-05-25 03:50:06 [INFO]: Epoch 060 - generator training loss: 0.0439, discriminator training loss: 0.0213, validation loss: 0.1392
2024-05-25 03:50:10 [INFO]: Epoch 061 - generator training loss: 0.0437, discriminator training loss: 0.0211, validation loss: 0.1394
2024-05-25 03:50:14 [INFO]: Epoch 062 - generator training loss: 0.0444, discriminator training loss: 0.0209, validation loss: 0.1383
2024-05-25 03:50:18 [INFO]: Epoch 063 - generator training loss: 0.0434, discriminator training loss: 0.0207, validation loss: 0.1379
2024-05-25 03:50:22 [INFO]: Epoch 064 - generator training loss: 0.0430, discriminator training loss: 0.0206, validation loss: 0.1377
2024-05-25 03:50:27 [INFO]: Epoch 065 - generator training loss: 0.0423, discriminator training loss: 0.0203, validation loss: 0.1371
2024-05-25 03:50:31 [INFO]: Epoch 066 - generator training loss: 0.0425, discriminator training loss: 0.0198, validation loss: 0.1371
2024-05-25 03:50:35 [INFO]: Epoch 067 - generator training loss: 0.0423, discriminator training loss: 0.0197, validation loss: 0.1374
2024-05-25 03:50:39 [INFO]: Epoch 068 - generator training loss: 0.0418, discriminator training loss: 0.0194, validation loss: 0.1368
2024-05-25 03:50:43 [INFO]: Epoch 069 - generator training loss: 0.0413, discriminator training loss: 0.0193, validation loss: 0.1368
2024-05-25 03:50:47 [INFO]: Epoch 070 - generator training loss: 0.0416, discriminator training loss: 0.0189, validation loss: 0.1362
2024-05-25 03:50:51 [INFO]: Epoch 071 - generator training loss: 0.0413, discriminator training loss: 0.0189, validation loss: 0.1373
2024-05-25 03:50:55 [INFO]: Epoch 072 - generator training loss: 0.0409, discriminator training loss: 0.0187, validation loss: 0.1362
2024-05-25 03:50:59 [INFO]: Epoch 073 - generator training loss: 0.0407, discriminator training loss: 0.0184, validation loss: 0.1362
2024-05-25 03:51:03 [INFO]: Epoch 074 - generator training loss: 0.0407, discriminator training loss: 0.0183, validation loss: 0.1364
2024-05-25 03:51:07 [INFO]: Epoch 075 - generator training loss: 0.0406, discriminator training loss: 0.0182, validation loss: 0.1359
2024-05-25 03:51:11 [INFO]: Epoch 076 - generator training loss: 0.0402, discriminator training loss: 0.0181, validation loss: 0.1365
2024-05-25 03:51:15 [INFO]: Epoch 077 - generator training loss: 0.0399, discriminator training loss: 0.0177, validation loss: 0.1358
2024-05-25 03:51:19 [INFO]: Epoch 078 - generator training loss: 0.0400, discriminator training loss: 0.0175, validation loss: 0.1354
2024-05-25 03:51:23 [INFO]: Epoch 079 - generator training loss: 0.0393, discriminator training loss: 0.0175, validation loss: 0.1356
2024-05-25 03:51:27 [INFO]: Epoch 080 - generator training loss: 0.0388, discriminator training loss: 0.0174, validation loss: 0.1355
2024-05-25 03:51:31 [INFO]: Epoch 081 - generator training loss: 0.0389, discriminator training loss: 0.0172, validation loss: 0.1355
2024-05-25 03:51:35 [INFO]: Epoch 082 - generator training loss: 0.0391, discriminator training loss: 0.0171, validation loss: 0.1363
2024-05-25 03:51:40 [INFO]: Epoch 083 - generator training loss: 0.0389, discriminator training loss: 0.0167, validation loss: 0.1350
2024-05-25 03:51:44 [INFO]: Epoch 084 - generator training loss: 0.0388, discriminator training loss: 0.0169, validation loss: 0.1358
2024-05-25 03:51:48 [INFO]: Epoch 085 - generator training loss: 0.0376, discriminator training loss: 0.0166, validation loss: 0.1357
2024-05-25 03:51:52 [INFO]: Epoch 086 - generator training loss: 0.0375, discriminator training loss: 0.0164, validation loss: 0.1354
2024-05-25 03:51:56 [INFO]: Epoch 087 - generator training loss: 0.0369, discriminator training loss: 0.0165, validation loss: 0.1369
2024-05-25 03:52:00 [INFO]: Epoch 088 - generator training loss: 0.0369, discriminator training loss: 0.0165, validation loss: 0.1354
2024-05-25 03:52:04 [INFO]: Epoch 089 - generator training loss: 0.0363, discriminator training loss: 0.0162, validation loss: 0.1357
2024-05-25 03:52:08 [INFO]: Epoch 090 - generator training loss: 0.0376, discriminator training loss: 0.0161, validation loss: 0.1359
2024-05-25 03:52:12 [INFO]: Epoch 091 - generator training loss: 0.0359, discriminator training loss: 0.0160, validation loss: 0.1355
2024-05-25 03:52:16 [INFO]: Epoch 092 - generator training loss: 0.0362, discriminator training loss: 0.0159, validation loss: 0.1355
2024-05-25 03:52:20 [INFO]: Epoch 093 - generator training loss: 0.0363, discriminator training loss: 0.0160, validation loss: 0.1379
2024-05-25 03:52:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:52:20 [INFO]: Finished training. The best model is from epoch#83.
2024-05-25 03:52:20 [INFO]: Saved the model to augmentation_saved_results/round_2/USGAN_air_quality/20240525_T034601/USGAN.pypots
2024-05-25 03:52:21 [INFO]: US-GAN on Air-Quality: MAE=0.2088, MSE=0.1907
2024-05-25 03:52:21 [INFO]: Successfully saved to augmentation_saved_results/round_2/USGAN_air_quality/imputation.pkl
2024-05-25 03:52:21 [INFO]: Using the given device: cuda:0
2024-05-25 03:52:21 [INFO]: Model files will be saved to augmentation_saved_results/round_2/BRITS_air_quality/20240525_T035221
2024-05-25 03:52:21 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/BRITS_air_quality/20240525_T035221/tensorboard
2024-05-25 03:52:21 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 03:52:25 [INFO]: Epoch 001 - training loss: 1.4085, validation loss: 0.9502
2024-05-25 03:52:27 [INFO]: Epoch 002 - training loss: 1.1308, validation loss: 0.7148
2024-05-25 03:52:30 [INFO]: Epoch 003 - training loss: 0.9439, validation loss: 0.6080
2024-05-25 03:52:33 [INFO]: Epoch 004 - training loss: 0.8349, validation loss: 0.5387
2024-05-25 03:52:36 [INFO]: Epoch 005 - training loss: 0.7588, validation loss: 0.4900
2024-05-25 03:52:38 [INFO]: Epoch 006 - training loss: 0.7024, validation loss: 0.4493
2024-05-25 03:52:41 [INFO]: Epoch 007 - training loss: 0.6563, validation loss: 0.4179
2024-05-25 03:52:44 [INFO]: Epoch 008 - training loss: 0.6232, validation loss: 0.3927
2024-05-25 03:52:47 [INFO]: Epoch 009 - training loss: 0.5973, validation loss: 0.3718
2024-05-25 03:52:50 [INFO]: Epoch 010 - training loss: 0.5747, validation loss: 0.3550
2024-05-25 03:52:52 [INFO]: Epoch 011 - training loss: 0.5585, validation loss: 0.3408
2024-05-25 03:52:55 [INFO]: Epoch 012 - training loss: 0.5429, validation loss: 0.3296
2024-05-25 03:52:58 [INFO]: Epoch 013 - training loss: 0.5294, validation loss: 0.3187
2024-05-25 03:53:01 [INFO]: Epoch 014 - training loss: 0.5189, validation loss: 0.3101
2024-05-25 03:53:03 [INFO]: Epoch 015 - training loss: 0.5074, validation loss: 0.3021
2024-05-25 03:53:06 [INFO]: Epoch 016 - training loss: 0.4980, validation loss: 0.2952
2024-05-25 03:53:09 [INFO]: Epoch 017 - training loss: 0.4883, validation loss: 0.2895
2024-05-25 03:53:12 [INFO]: Epoch 018 - training loss: 0.4810, validation loss: 0.2827
2024-05-25 03:53:15 [INFO]: Epoch 019 - training loss: 0.4721, validation loss: 0.2773
2024-05-25 03:53:17 [INFO]: Epoch 020 - training loss: 0.4649, validation loss: 0.2731
2024-05-25 03:53:20 [INFO]: Epoch 021 - training loss: 0.4584, validation loss: 0.2687
2024-05-25 03:53:23 [INFO]: Epoch 022 - training loss: 0.4509, validation loss: 0.2643
2024-05-25 03:53:26 [INFO]: Epoch 023 - training loss: 0.4457, validation loss: 0.2603
2024-05-25 03:53:28 [INFO]: Epoch 024 - training loss: 0.4401, validation loss: 0.2562
2024-05-25 03:53:31 [INFO]: Epoch 025 - training loss: 0.4333, validation loss: 0.2524
2024-05-25 03:53:34 [INFO]: Epoch 026 - training loss: 0.4285, validation loss: 0.2485
2024-05-25 03:53:37 [INFO]: Epoch 027 - training loss: 0.4228, validation loss: 0.2454
2024-05-25 03:53:40 [INFO]: Epoch 028 - training loss: 0.4176, validation loss: 0.2422
2024-05-25 03:53:42 [INFO]: Epoch 029 - training loss: 0.4128, validation loss: 0.2390
2024-05-25 03:53:45 [INFO]: Epoch 030 - training loss: 0.4075, validation loss: 0.2361
2024-05-25 03:53:48 [INFO]: Epoch 031 - training loss: 0.4029, validation loss: 0.2325
2024-05-25 03:53:51 [INFO]: Epoch 032 - training loss: 0.3982, validation loss: 0.2298
2024-05-25 03:53:53 [INFO]: Epoch 033 - training loss: 0.3952, validation loss: 0.2266
2024-05-25 03:53:56 [INFO]: Epoch 034 - training loss: 0.3904, validation loss: 0.2237
2024-05-25 03:53:59 [INFO]: Epoch 035 - training loss: 0.3865, validation loss: 0.2208
2024-05-25 03:54:02 [INFO]: Epoch 036 - training loss: 0.3829, validation loss: 0.2183
2024-05-25 03:54:05 [INFO]: Epoch 037 - training loss: 0.3786, validation loss: 0.2154
2024-05-25 03:54:07 [INFO]: Epoch 038 - training loss: 0.3756, validation loss: 0.2128
2024-05-25 03:54:10 [INFO]: Epoch 039 - training loss: 0.3725, validation loss: 0.2108
2024-05-25 03:54:13 [INFO]: Epoch 040 - training loss: 0.3689, validation loss: 0.2074
2024-05-25 03:54:16 [INFO]: Epoch 041 - training loss: 0.3653, validation loss: 0.2054
2024-05-25 03:54:18 [INFO]: Epoch 042 - training loss: 0.3626, validation loss: 0.2027
2024-05-25 03:54:21 [INFO]: Epoch 043 - training loss: 0.3593, validation loss: 0.2006
2024-05-25 03:54:24 [INFO]: Epoch 044 - training loss: 0.3572, validation loss: 0.1985
2024-05-25 03:54:27 [INFO]: Epoch 045 - training loss: 0.3547, validation loss: 0.1967
2024-05-25 03:54:30 [INFO]: Epoch 046 - training loss: 0.3507, validation loss: 0.1944
2024-05-25 03:54:32 [INFO]: Epoch 047 - training loss: 0.3484, validation loss: 0.1924
2024-05-25 03:54:35 [INFO]: Epoch 048 - training loss: 0.3462, validation loss: 0.1911
2024-05-25 03:54:38 [INFO]: Epoch 049 - training loss: 0.3442, validation loss: 0.1892
2024-05-25 03:54:41 [INFO]: Epoch 050 - training loss: 0.3417, validation loss: 0.1881
2024-05-25 03:54:43 [INFO]: Epoch 051 - training loss: 0.3388, validation loss: 0.1863
2024-05-25 03:54:46 [INFO]: Epoch 052 - training loss: 0.3364, validation loss: 0.1848
2024-05-25 03:54:49 [INFO]: Epoch 053 - training loss: 0.3346, validation loss: 0.1833
2024-05-25 03:54:52 [INFO]: Epoch 054 - training loss: 0.3329, validation loss: 0.1820
2024-05-25 03:54:54 [INFO]: Epoch 055 - training loss: 0.3299, validation loss: 0.1810
2024-05-25 03:54:57 [INFO]: Epoch 056 - training loss: 0.3286, validation loss: 0.1799
2024-05-25 03:55:00 [INFO]: Epoch 057 - training loss: 0.3264, validation loss: 0.1787
2024-05-25 03:55:03 [INFO]: Epoch 058 - training loss: 0.3246, validation loss: 0.1775
2024-05-25 03:55:06 [INFO]: Epoch 059 - training loss: 0.3235, validation loss: 0.1766
2024-05-25 03:55:08 [INFO]: Epoch 060 - training loss: 0.3211, validation loss: 0.1755
2024-05-25 03:55:11 [INFO]: Epoch 061 - training loss: 0.3200, validation loss: 0.1746
2024-05-25 03:55:14 [INFO]: Epoch 062 - training loss: 0.3177, validation loss: 0.1734
2024-05-25 03:55:17 [INFO]: Epoch 063 - training loss: 0.3168, validation loss: 0.1730
2024-05-25 03:55:20 [INFO]: Epoch 064 - training loss: 0.3153, validation loss: 0.1720
2024-05-25 03:55:22 [INFO]: Epoch 065 - training loss: 0.3137, validation loss: 0.1712
2024-05-25 03:55:25 [INFO]: Epoch 066 - training loss: 0.3123, validation loss: 0.1704
2024-05-25 03:55:28 [INFO]: Epoch 067 - training loss: 0.3120, validation loss: 0.1694
2024-05-25 03:55:31 [INFO]: Epoch 068 - training loss: 0.3096, validation loss: 0.1686
2024-05-25 03:55:33 [INFO]: Epoch 069 - training loss: 0.3079, validation loss: 0.1681
2024-05-25 03:55:36 [INFO]: Epoch 070 - training loss: 0.3066, validation loss: 0.1672
2024-05-25 03:55:39 [INFO]: Epoch 071 - training loss: 0.3062, validation loss: 0.1666
2024-05-25 03:55:42 [INFO]: Epoch 072 - training loss: 0.3053, validation loss: 0.1661
2024-05-25 03:55:45 [INFO]: Epoch 073 - training loss: 0.3035, validation loss: 0.1651
2024-05-25 03:55:47 [INFO]: Epoch 074 - training loss: 0.3022, validation loss: 0.1646
2024-05-25 03:55:50 [INFO]: Epoch 075 - training loss: 0.3007, validation loss: 0.1639
2024-05-25 03:55:53 [INFO]: Epoch 076 - training loss: 0.3007, validation loss: 0.1633
2024-05-25 03:55:56 [INFO]: Epoch 077 - training loss: 0.2990, validation loss: 0.1627
2024-05-25 03:55:58 [INFO]: Epoch 078 - training loss: 0.2980, validation loss: 0.1622
2024-05-25 03:56:01 [INFO]: Epoch 079 - training loss: 0.2969, validation loss: 0.1616
2024-05-25 03:56:04 [INFO]: Epoch 080 - training loss: 0.2957, validation loss: 0.1611
2024-05-25 03:56:07 [INFO]: Epoch 081 - training loss: 0.2953, validation loss: 0.1603
2024-05-25 03:56:09 [INFO]: Epoch 082 - training loss: 0.2944, validation loss: 0.1599
2024-05-25 03:56:12 [INFO]: Epoch 083 - training loss: 0.2931, validation loss: 0.1591
2024-05-25 03:56:15 [INFO]: Epoch 084 - training loss: 0.2931, validation loss: 0.1588
2024-05-25 03:56:18 [INFO]: Epoch 085 - training loss: 0.2916, validation loss: 0.1584
2024-05-25 03:56:21 [INFO]: Epoch 086 - training loss: 0.2906, validation loss: 0.1576
2024-05-25 03:56:23 [INFO]: Epoch 087 - training loss: 0.2899, validation loss: 0.1572
2024-05-25 03:56:26 [INFO]: Epoch 088 - training loss: 0.2894, validation loss: 0.1567
2024-05-25 03:56:29 [INFO]: Epoch 089 - training loss: 0.2885, validation loss: 0.1560
2024-05-25 03:56:32 [INFO]: Epoch 090 - training loss: 0.2874, validation loss: 0.1557
2024-05-25 03:56:34 [INFO]: Epoch 091 - training loss: 0.2872, validation loss: 0.1552
2024-05-25 03:56:37 [INFO]: Epoch 092 - training loss: 0.2862, validation loss: 0.1544
2024-05-25 03:56:40 [INFO]: Epoch 093 - training loss: 0.2847, validation loss: 0.1541
2024-05-25 03:56:43 [INFO]: Epoch 094 - training loss: 0.2848, validation loss: 0.1534
2024-05-25 03:56:46 [INFO]: Epoch 095 - training loss: 0.2837, validation loss: 0.1531
2024-05-25 03:56:48 [INFO]: Epoch 096 - training loss: 0.2830, validation loss: 0.1527
2024-05-25 03:56:51 [INFO]: Epoch 097 - training loss: 0.2823, validation loss: 0.1521
2024-05-25 03:56:54 [INFO]: Epoch 098 - training loss: 0.2816, validation loss: 0.1516
2024-05-25 03:56:57 [INFO]: Epoch 099 - training loss: 0.2804, validation loss: 0.1511
2024-05-25 03:56:59 [INFO]: Epoch 100 - training loss: 0.2802, validation loss: 0.1506
2024-05-25 03:57:02 [INFO]: Epoch 101 - training loss: 0.2798, validation loss: 0.1504
2024-05-25 03:57:05 [INFO]: Epoch 102 - training loss: 0.2789, validation loss: 0.1498
2024-05-25 03:57:08 [INFO]: Epoch 103 - training loss: 0.2787, validation loss: 0.1492
2024-05-25 03:57:10 [INFO]: Epoch 104 - training loss: 0.2775, validation loss: 0.1489
2024-05-25 03:57:13 [INFO]: Epoch 105 - training loss: 0.2770, validation loss: 0.1484
2024-05-25 03:57:16 [INFO]: Epoch 106 - training loss: 0.2773, validation loss: 0.1481
2024-05-25 03:57:19 [INFO]: Epoch 107 - training loss: 0.2765, validation loss: 0.1475
2024-05-25 03:57:22 [INFO]: Epoch 108 - training loss: 0.2756, validation loss: 0.1473
2024-05-25 03:57:24 [INFO]: Epoch 109 - training loss: 0.2748, validation loss: 0.1467
2024-05-25 03:57:27 [INFO]: Epoch 110 - training loss: 0.2745, validation loss: 0.1463
2024-05-25 03:57:30 [INFO]: Epoch 111 - training loss: 0.2735, validation loss: 0.1458
2024-05-25 03:57:33 [INFO]: Epoch 112 - training loss: 0.2729, validation loss: 0.1453
2024-05-25 03:57:36 [INFO]: Epoch 113 - training loss: 0.2730, validation loss: 0.1450
2024-05-25 03:57:38 [INFO]: Epoch 114 - training loss: 0.2718, validation loss: 0.1447
2024-05-25 03:57:41 [INFO]: Epoch 115 - training loss: 0.2717, validation loss: 0.1443
2024-05-25 03:57:44 [INFO]: Epoch 116 - training loss: 0.2709, validation loss: 0.1438
2024-05-25 03:57:47 [INFO]: Epoch 117 - training loss: 0.2704, validation loss: 0.1435
2024-05-25 03:57:49 [INFO]: Epoch 118 - training loss: 0.2700, validation loss: 0.1431
2024-05-25 03:57:52 [INFO]: Epoch 119 - training loss: 0.2697, validation loss: 0.1429
2024-05-25 03:57:55 [INFO]: Epoch 120 - training loss: 0.2697, validation loss: 0.1424
2024-05-25 03:57:58 [INFO]: Epoch 121 - training loss: 0.2686, validation loss: 0.1419
2024-05-25 03:58:01 [INFO]: Epoch 122 - training loss: 0.2686, validation loss: 0.1415
2024-05-25 03:58:03 [INFO]: Epoch 123 - training loss: 0.2680, validation loss: 0.1412
2024-05-25 03:58:06 [INFO]: Epoch 124 - training loss: 0.2672, validation loss: 0.1410
2024-05-25 03:58:09 [INFO]: Epoch 125 - training loss: 0.2667, validation loss: 0.1406
2024-05-25 03:58:12 [INFO]: Epoch 126 - training loss: 0.2669, validation loss: 0.1403
2024-05-25 03:58:14 [INFO]: Epoch 127 - training loss: 0.2658, validation loss: 0.1396
2024-05-25 03:58:17 [INFO]: Epoch 128 - training loss: 0.2657, validation loss: 0.1394
2024-05-25 03:58:20 [INFO]: Epoch 129 - training loss: 0.2654, validation loss: 0.1390
2024-05-25 03:58:23 [INFO]: Epoch 130 - training loss: 0.2642, validation loss: 0.1388
2024-05-25 03:58:25 [INFO]: Epoch 131 - training loss: 0.2647, validation loss: 0.1384
2024-05-25 03:58:28 [INFO]: Epoch 132 - training loss: 0.2639, validation loss: 0.1380
2024-05-25 03:58:31 [INFO]: Epoch 133 - training loss: 0.2636, validation loss: 0.1378
2024-05-25 03:58:34 [INFO]: Epoch 134 - training loss: 0.2636, validation loss: 0.1375
2024-05-25 03:58:37 [INFO]: Epoch 135 - training loss: 0.2620, validation loss: 0.1371
2024-05-25 03:58:39 [INFO]: Epoch 136 - training loss: 0.2623, validation loss: 0.1368
2024-05-25 03:58:42 [INFO]: Epoch 137 - training loss: 0.2616, validation loss: 0.1367
2024-05-25 03:58:45 [INFO]: Epoch 138 - training loss: 0.2621, validation loss: 0.1365
2024-05-25 03:58:48 [INFO]: Epoch 139 - training loss: 0.2606, validation loss: 0.1359
2024-05-25 03:58:50 [INFO]: Epoch 140 - training loss: 0.2612, validation loss: 0.1357
2024-05-25 03:58:53 [INFO]: Epoch 141 - training loss: 0.2606, validation loss: 0.1355
2024-05-25 03:58:56 [INFO]: Epoch 142 - training loss: 0.2596, validation loss: 0.1352
2024-05-25 03:58:59 [INFO]: Epoch 143 - training loss: 0.2601, validation loss: 0.1350
2024-05-25 03:59:02 [INFO]: Epoch 144 - training loss: 0.2590, validation loss: 0.1345
2024-05-25 03:59:04 [INFO]: Epoch 145 - training loss: 0.2589, validation loss: 0.1344
2024-05-25 03:59:07 [INFO]: Epoch 146 - training loss: 0.2584, validation loss: 0.1343
2024-05-25 03:59:10 [INFO]: Epoch 147 - training loss: 0.2576, validation loss: 0.1339
2024-05-25 03:59:13 [INFO]: Epoch 148 - training loss: 0.2579, validation loss: 0.1335
2024-05-25 03:59:15 [INFO]: Epoch 149 - training loss: 0.2573, validation loss: 0.1335
2024-05-25 03:59:18 [INFO]: Epoch 150 - training loss: 0.2572, validation loss: 0.1330
2024-05-25 03:59:21 [INFO]: Epoch 151 - training loss: 0.2570, validation loss: 0.1329
2024-05-25 03:59:24 [INFO]: Epoch 152 - training loss: 0.2560, validation loss: 0.1326
2024-05-25 03:59:27 [INFO]: Epoch 153 - training loss: 0.2558, validation loss: 0.1325
2024-05-25 03:59:29 [INFO]: Epoch 154 - training loss: 0.2562, validation loss: 0.1322
2024-05-25 03:59:32 [INFO]: Epoch 155 - training loss: 0.2553, validation loss: 0.1320
2024-05-25 03:59:35 [INFO]: Epoch 156 - training loss: 0.2551, validation loss: 0.1318
2024-05-25 03:59:38 [INFO]: Epoch 157 - training loss: 0.2545, validation loss: 0.1315
2024-05-25 03:59:41 [INFO]: Epoch 158 - training loss: 0.2542, validation loss: 0.1312
2024-05-25 03:59:43 [INFO]: Epoch 159 - training loss: 0.2541, validation loss: 0.1310
2024-05-25 03:59:46 [INFO]: Epoch 160 - training loss: 0.2540, validation loss: 0.1308
2024-05-25 03:59:49 [INFO]: Epoch 161 - training loss: 0.2536, validation loss: 0.1307
2024-05-25 03:59:52 [INFO]: Epoch 162 - training loss: 0.2531, validation loss: 0.1303
2024-05-25 03:59:54 [INFO]: Epoch 163 - training loss: 0.2526, validation loss: 0.1302
2024-05-25 03:59:57 [INFO]: Epoch 164 - training loss: 0.2525, validation loss: 0.1300
2024-05-25 04:00:00 [INFO]: Epoch 165 - training loss: 0.2519, validation loss: 0.1297
2024-05-25 04:00:03 [INFO]: Epoch 166 - training loss: 0.2522, validation loss: 0.1296
2024-05-25 04:00:05 [INFO]: Epoch 167 - training loss: 0.2522, validation loss: 0.1294
2024-05-25 04:00:08 [INFO]: Epoch 168 - training loss: 0.2513, validation loss: 0.1293
2024-05-25 04:00:11 [INFO]: Epoch 169 - training loss: 0.2510, validation loss: 0.1290
2024-05-25 04:00:14 [INFO]: Epoch 170 - training loss: 0.2507, validation loss: 0.1290
2024-05-25 04:00:17 [INFO]: Epoch 171 - training loss: 0.2514, validation loss: 0.1287
2024-05-25 04:00:19 [INFO]: Epoch 172 - training loss: 0.2508, validation loss: 0.1284
2024-05-25 04:00:22 [INFO]: Epoch 173 - training loss: 0.2497, validation loss: 0.1282
2024-05-25 04:00:25 [INFO]: Epoch 174 - training loss: 0.2504, validation loss: 0.1279
2024-05-25 04:00:28 [INFO]: Epoch 175 - training loss: 0.2494, validation loss: 0.1279
2024-05-25 04:00:30 [INFO]: Epoch 176 - training loss: 0.2495, validation loss: 0.1277
2024-05-25 04:00:33 [INFO]: Epoch 177 - training loss: 0.2491, validation loss: 0.1276
2024-05-25 04:00:36 [INFO]: Epoch 178 - training loss: 0.2489, validation loss: 0.1275
2024-05-25 04:00:39 [INFO]: Epoch 179 - training loss: 0.2489, validation loss: 0.1271
2024-05-25 04:00:42 [INFO]: Epoch 180 - training loss: 0.2482, validation loss: 0.1271
2024-05-25 04:00:44 [INFO]: Epoch 181 - training loss: 0.2478, validation loss: 0.1267
2024-05-25 04:00:47 [INFO]: Epoch 182 - training loss: 0.2477, validation loss: 0.1265
2024-05-25 04:00:50 [INFO]: Epoch 183 - training loss: 0.2474, validation loss: 0.1266
2024-05-25 04:00:53 [INFO]: Epoch 184 - training loss: 0.2485, validation loss: 0.1263
2024-05-25 04:00:55 [INFO]: Epoch 185 - training loss: 0.2472, validation loss: 0.1261
2024-05-25 04:00:58 [INFO]: Epoch 186 - training loss: 0.2469, validation loss: 0.1259
2024-05-25 04:01:01 [INFO]: Epoch 187 - training loss: 0.2465, validation loss: 0.1258
2024-05-25 04:01:04 [INFO]: Epoch 188 - training loss: 0.2467, validation loss: 0.1256
2024-05-25 04:01:07 [INFO]: Epoch 189 - training loss: 0.2464, validation loss: 0.1255
2024-05-25 04:01:09 [INFO]: Epoch 190 - training loss: 0.2461, validation loss: 0.1253
2024-05-25 04:01:12 [INFO]: Epoch 191 - training loss: 0.2462, validation loss: 0.1253
2024-05-25 04:01:15 [INFO]: Epoch 192 - training loss: 0.2457, validation loss: 0.1251
2024-05-25 04:01:18 [INFO]: Epoch 193 - training loss: 0.2452, validation loss: 0.1250
2024-05-25 04:01:20 [INFO]: Epoch 194 - training loss: 0.2451, validation loss: 0.1247
2024-05-25 04:01:23 [INFO]: Epoch 195 - training loss: 0.2446, validation loss: 0.1248
2024-05-25 04:01:26 [INFO]: Epoch 196 - training loss: 0.2447, validation loss: 0.1247
2024-05-25 04:01:29 [INFO]: Epoch 197 - training loss: 0.2444, validation loss: 0.1245
2024-05-25 04:01:32 [INFO]: Epoch 198 - training loss: 0.2441, validation loss: 0.1243
2024-05-25 04:01:34 [INFO]: Epoch 199 - training loss: 0.2441, validation loss: 0.1242
2024-05-25 04:01:37 [INFO]: Epoch 200 - training loss: 0.2440, validation loss: 0.1239
2024-05-25 04:01:40 [INFO]: Epoch 201 - training loss: 0.2439, validation loss: 0.1239
2024-05-25 04:01:43 [INFO]: Epoch 202 - training loss: 0.2434, validation loss: 0.1236
2024-05-25 04:01:45 [INFO]: Epoch 203 - training loss: 0.2430, validation loss: 0.1237
2024-05-25 04:01:48 [INFO]: Epoch 204 - training loss: 0.2429, validation loss: 0.1234
2024-05-25 04:01:51 [INFO]: Epoch 205 - training loss: 0.2434, validation loss: 0.1234
2024-05-25 04:01:54 [INFO]: Epoch 206 - training loss: 0.2423, validation loss: 0.1231
2024-05-25 04:01:57 [INFO]: Epoch 207 - training loss: 0.2428, validation loss: 0.1230
2024-05-25 04:01:59 [INFO]: Epoch 208 - training loss: 0.2425, validation loss: 0.1230
2024-05-25 04:02:02 [INFO]: Epoch 209 - training loss: 0.2417, validation loss: 0.1230
2024-05-25 04:02:05 [INFO]: Epoch 210 - training loss: 0.2421, validation loss: 0.1229
2024-05-25 04:02:08 [INFO]: Epoch 211 - training loss: 0.2412, validation loss: 0.1226
2024-05-25 04:02:10 [INFO]: Epoch 212 - training loss: 0.2413, validation loss: 0.1224
2024-05-25 04:02:13 [INFO]: Epoch 213 - training loss: 0.2419, validation loss: 0.1224
2024-05-25 04:02:16 [INFO]: Epoch 214 - training loss: 0.2411, validation loss: 0.1223
2024-05-25 04:02:19 [INFO]: Epoch 215 - training loss: 0.2410, validation loss: 0.1221
2024-05-25 04:02:21 [INFO]: Epoch 216 - training loss: 0.2406, validation loss: 0.1221
2024-05-25 04:02:24 [INFO]: Epoch 217 - training loss: 0.2405, validation loss: 0.1220
2024-05-25 04:02:27 [INFO]: Epoch 218 - training loss: 0.2407, validation loss: 0.1217
2024-05-25 04:02:30 [INFO]: Epoch 219 - training loss: 0.2404, validation loss: 0.1217
2024-05-25 04:02:33 [INFO]: Epoch 220 - training loss: 0.2403, validation loss: 0.1219
2024-05-25 04:02:35 [INFO]: Epoch 221 - training loss: 0.2403, validation loss: 0.1215
2024-05-25 04:02:38 [INFO]: Epoch 222 - training loss: 0.2398, validation loss: 0.1213
2024-05-25 04:02:41 [INFO]: Epoch 223 - training loss: 0.2397, validation loss: 0.1213
2024-05-25 04:02:44 [INFO]: Epoch 224 - training loss: 0.2397, validation loss: 0.1211
2024-05-25 04:02:46 [INFO]: Epoch 225 - training loss: 0.2395, validation loss: 0.1210
2024-05-25 04:02:49 [INFO]: Epoch 226 - training loss: 0.2392, validation loss: 0.1210
2024-05-25 04:02:52 [INFO]: Epoch 227 - training loss: 0.2392, validation loss: 0.1209
2024-05-25 04:02:55 [INFO]: Epoch 228 - training loss: 0.2387, validation loss: 0.1208
2024-05-25 04:02:58 [INFO]: Epoch 229 - training loss: 0.2385, validation loss: 0.1208
2024-05-25 04:03:00 [INFO]: Epoch 230 - training loss: 0.2385, validation loss: 0.1206
2024-05-25 04:03:03 [INFO]: Epoch 231 - training loss: 0.2381, validation loss: 0.1205
2024-05-25 04:03:06 [INFO]: Epoch 232 - training loss: 0.2383, validation loss: 0.1205
2024-05-25 04:03:09 [INFO]: Epoch 233 - training loss: 0.2378, validation loss: 0.1204
2024-05-25 04:03:11 [INFO]: Epoch 234 - training loss: 0.2375, validation loss: 0.1204
2024-05-25 04:03:14 [INFO]: Epoch 235 - training loss: 0.2376, validation loss: 0.1202
2024-05-25 04:03:17 [INFO]: Epoch 236 - training loss: 0.2375, validation loss: 0.1203
2024-05-25 04:03:20 [INFO]: Epoch 237 - training loss: 0.2375, validation loss: 0.1199
2024-05-25 04:03:23 [INFO]: Epoch 238 - training loss: 0.2372, validation loss: 0.1198
2024-05-25 04:03:25 [INFO]: Epoch 239 - training loss: 0.2372, validation loss: 0.1200
2024-05-25 04:03:28 [INFO]: Epoch 240 - training loss: 0.2371, validation loss: 0.1199
2024-05-25 04:03:31 [INFO]: Epoch 241 - training loss: 0.2372, validation loss: 0.1199
2024-05-25 04:03:34 [INFO]: Epoch 242 - training loss: 0.2372, validation loss: 0.1194
2024-05-25 04:03:37 [INFO]: Epoch 243 - training loss: 0.2364, validation loss: 0.1194
2024-05-25 04:03:39 [INFO]: Epoch 244 - training loss: 0.2366, validation loss: 0.1195
2024-05-25 04:03:42 [INFO]: Epoch 245 - training loss: 0.2361, validation loss: 0.1194
2024-05-25 04:03:45 [INFO]: Epoch 246 - training loss: 0.2363, validation loss: 0.1193
2024-05-25 04:03:48 [INFO]: Epoch 247 - training loss: 0.2360, validation loss: 0.1192
2024-05-25 04:03:50 [INFO]: Epoch 248 - training loss: 0.2355, validation loss: 0.1191
2024-05-25 04:03:53 [INFO]: Epoch 249 - training loss: 0.2355, validation loss: 0.1191
2024-05-25 04:03:56 [INFO]: Epoch 250 - training loss: 0.2359, validation loss: 0.1190
2024-05-25 04:03:59 [INFO]: Epoch 251 - training loss: 0.2353, validation loss: 0.1188
2024-05-25 04:04:01 [INFO]: Epoch 252 - training loss: 0.2354, validation loss: 0.1188
2024-05-25 04:04:04 [INFO]: Epoch 253 - training loss: 0.2351, validation loss: 0.1188
2024-05-25 04:04:07 [INFO]: Epoch 254 - training loss: 0.2350, validation loss: 0.1186
2024-05-25 04:04:10 [INFO]: Epoch 255 - training loss: 0.2348, validation loss: 0.1184
2024-05-25 04:04:13 [INFO]: Epoch 256 - training loss: 0.2347, validation loss: 0.1185
2024-05-25 04:04:15 [INFO]: Epoch 257 - training loss: 0.2343, validation loss: 0.1184
2024-05-25 04:04:18 [INFO]: Epoch 258 - training loss: 0.2347, validation loss: 0.1182
2024-05-25 04:04:21 [INFO]: Epoch 259 - training loss: 0.2341, validation loss: 0.1183
2024-05-25 04:04:24 [INFO]: Epoch 260 - training loss: 0.2341, validation loss: 0.1181
2024-05-25 04:04:26 [INFO]: Epoch 261 - training loss: 0.2342, validation loss: 0.1181
2024-05-25 04:04:29 [INFO]: Epoch 262 - training loss: 0.2340, validation loss: 0.1181
2024-05-25 04:04:32 [INFO]: Epoch 263 - training loss: 0.2337, validation loss: 0.1181
2024-05-25 04:04:35 [INFO]: Epoch 264 - training loss: 0.2336, validation loss: 0.1179
2024-05-25 04:04:37 [INFO]: Epoch 265 - training loss: 0.2330, validation loss: 0.1178
2024-05-25 04:04:40 [INFO]: Epoch 266 - training loss: 0.2338, validation loss: 0.1177
2024-05-25 04:04:43 [INFO]: Epoch 267 - training loss: 0.2328, validation loss: 0.1177
2024-05-25 04:04:46 [INFO]: Epoch 268 - training loss: 0.2331, validation loss: 0.1177
2024-05-25 04:04:49 [INFO]: Epoch 269 - training loss: 0.2325, validation loss: 0.1177
2024-05-25 04:04:51 [INFO]: Epoch 270 - training loss: 0.2330, validation loss: 0.1177
2024-05-25 04:04:54 [INFO]: Epoch 271 - training loss: 0.2325, validation loss: 0.1175
2024-05-25 04:04:57 [INFO]: Epoch 272 - training loss: 0.2322, validation loss: 0.1176
2024-05-25 04:05:00 [INFO]: Epoch 273 - training loss: 0.2327, validation loss: 0.1175
2024-05-25 04:05:02 [INFO]: Epoch 274 - training loss: 0.2327, validation loss: 0.1174
2024-05-25 04:05:05 [INFO]: Epoch 275 - training loss: 0.2319, validation loss: 0.1174
2024-05-25 04:05:08 [INFO]: Epoch 276 - training loss: 0.2322, validation loss: 0.1172
2024-05-25 04:05:11 [INFO]: Epoch 277 - training loss: 0.2321, validation loss: 0.1175
2024-05-25 04:05:14 [INFO]: Epoch 278 - training loss: 0.2324, validation loss: 0.1170
2024-05-25 04:05:16 [INFO]: Epoch 279 - training loss: 0.2319, validation loss: 0.1171
2024-05-25 04:05:19 [INFO]: Epoch 280 - training loss: 0.2318, validation loss: 0.1169
2024-05-25 04:05:22 [INFO]: Epoch 281 - training loss: 0.2315, validation loss: 0.1173
2024-05-25 04:05:25 [INFO]: Epoch 282 - training loss: 0.2314, validation loss: 0.1168
2024-05-25 04:05:27 [INFO]: Epoch 283 - training loss: 0.2315, validation loss: 0.1169
2024-05-25 04:05:30 [INFO]: Epoch 284 - training loss: 0.2312, validation loss: 0.1170
2024-05-25 04:05:33 [INFO]: Epoch 285 - training loss: 0.2311, validation loss: 0.1168
2024-05-25 04:05:36 [INFO]: Epoch 286 - training loss: 0.2312, validation loss: 0.1170
2024-05-25 04:05:39 [INFO]: Epoch 287 - training loss: 0.2307, validation loss: 0.1168
2024-05-25 04:05:41 [INFO]: Epoch 288 - training loss: 0.2309, validation loss: 0.1166
2024-05-25 04:05:44 [INFO]: Epoch 289 - training loss: 0.2314, validation loss: 0.1165
2024-05-25 04:05:47 [INFO]: Epoch 290 - training loss: 0.2314, validation loss: 0.1167
2024-05-25 04:05:50 [INFO]: Epoch 291 - training loss: 0.2314, validation loss: 0.1161
2024-05-25 04:05:52 [INFO]: Epoch 292 - training loss: 0.2306, validation loss: 0.1163
2024-05-25 04:05:55 [INFO]: Epoch 293 - training loss: 0.2303, validation loss: 0.1163
2024-05-25 04:05:58 [INFO]: Epoch 294 - training loss: 0.2301, validation loss: 0.1164
2024-05-25 04:06:01 [INFO]: Epoch 295 - training loss: 0.2304, validation loss: 0.1165
2024-05-25 04:06:04 [INFO]: Epoch 296 - training loss: 0.2300, validation loss: 0.1163
2024-05-25 04:06:06 [INFO]: Epoch 297 - training loss: 0.2297, validation loss: 0.1162
2024-05-25 04:06:09 [INFO]: Epoch 298 - training loss: 0.2301, validation loss: 0.1160
2024-05-25 04:06:12 [INFO]: Epoch 299 - training loss: 0.2296, validation loss: 0.1163
2024-05-25 04:06:15 [INFO]: Epoch 300 - training loss: 0.2296, validation loss: 0.1165
2024-05-25 04:06:15 [INFO]: Finished training. The best model is from epoch#298.
2024-05-25 04:06:15 [INFO]: Saved the model to augmentation_saved_results/round_2/BRITS_air_quality/20240525_T035221/BRITS.pypots
2024-05-25 04:06:16 [INFO]: BRITS on Air-Quality: MAE=0.1553, MSE=0.1658
2024-05-25 04:06:16 [INFO]: Successfully saved to augmentation_saved_results/round_2/BRITS_air_quality/imputation.pkl
2024-05-25 04:06:16 [INFO]: Using the given device: cuda:0
2024-05-25 04:06:16 [INFO]: Model files will be saved to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616
2024-05-25 04:06:16 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/tensorboard
2024-05-25 04:06:16 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 04:06:20 [INFO]: Epoch 001 - training loss: 1.5015, validation loss: 0.8052
2024-05-25 04:06:20 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch1_loss0.8051846861839295.pypots
2024-05-25 04:06:24 [INFO]: Epoch 002 - training loss: 1.0795, validation loss: 0.7523
2024-05-25 04:06:24 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch2_loss0.7522991001605988.pypots
2024-05-25 04:06:28 [INFO]: Epoch 003 - training loss: 1.0036, validation loss: 0.7275
2024-05-25 04:06:28 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch3_loss0.7274904847145081.pypots
2024-05-25 04:06:32 [INFO]: Epoch 004 - training loss: 0.9746, validation loss: 0.7135
2024-05-25 04:06:32 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch4_loss0.7134966403245926.pypots
2024-05-25 04:06:36 [INFO]: Epoch 005 - training loss: 0.9479, validation loss: 0.7053
2024-05-25 04:06:36 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch5_loss0.7053210258483886.pypots
2024-05-25 04:06:40 [INFO]: Epoch 006 - training loss: 0.9464, validation loss: 0.6987
2024-05-25 04:06:40 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch6_loss0.698670893907547.pypots
2024-05-25 04:06:44 [INFO]: Epoch 007 - training loss: 0.9438, validation loss: 0.6934
2024-05-25 04:06:44 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch7_loss0.6934399664402008.pypots
2024-05-25 04:06:47 [INFO]: Epoch 008 - training loss: 0.9305, validation loss: 0.6913
2024-05-25 04:06:47 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch8_loss0.6913292437791825.pypots
2024-05-25 04:06:51 [INFO]: Epoch 009 - training loss: 0.9319, validation loss: 0.6890
2024-05-25 04:06:51 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch9_loss0.6889850318431854.pypots
2024-05-25 04:06:55 [INFO]: Epoch 010 - training loss: 0.9213, validation loss: 0.6873
2024-05-25 04:06:55 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch10_loss0.6872971922159195.pypots
2024-05-25 04:06:59 [INFO]: Epoch 011 - training loss: 0.9114, validation loss: 0.6859
2024-05-25 04:06:59 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch11_loss0.6858611285686493.pypots
2024-05-25 04:07:03 [INFO]: Epoch 012 - training loss: 0.9028, validation loss: 0.6836
2024-05-25 04:07:03 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch12_loss0.6836399555206298.pypots
2024-05-25 04:07:07 [INFO]: Epoch 013 - training loss: 0.9011, validation loss: 0.6842
2024-05-25 04:07:07 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch13_loss0.6842147052288056.pypots
2024-05-25 04:07:10 [INFO]: Epoch 014 - training loss: 0.9079, validation loss: 0.6856
2024-05-25 04:07:10 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch14_loss0.6856250107288361.pypots
2024-05-25 04:07:14 [INFO]: Epoch 015 - training loss: 0.8992, validation loss: 0.6841
2024-05-25 04:07:14 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch15_loss0.684062522649765.pypots
2024-05-25 04:07:18 [INFO]: Epoch 016 - training loss: 0.9032, validation loss: 0.6837
2024-05-25 04:07:18 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch16_loss0.6837089508771896.pypots
2024-05-25 04:07:22 [INFO]: Epoch 017 - training loss: 0.8927, validation loss: 0.6848
2024-05-25 04:07:22 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch17_loss0.6847752302885055.pypots
2024-05-25 04:07:26 [INFO]: Epoch 018 - training loss: 0.8838, validation loss: 0.6844
2024-05-25 04:07:26 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch18_loss0.6843716979026795.pypots
2024-05-25 04:07:30 [INFO]: Epoch 019 - training loss: 0.8925, validation loss: 0.6826
2024-05-25 04:07:30 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch19_loss0.6826309621334076.pypots
2024-05-25 04:07:33 [INFO]: Epoch 020 - training loss: 0.8787, validation loss: 0.6864
2024-05-25 04:07:33 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch20_loss0.6863761752843857.pypots
2024-05-25 04:07:37 [INFO]: Epoch 021 - training loss: 0.8697, validation loss: 0.6843
2024-05-25 04:07:37 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch21_loss0.6843372792005539.pypots
2024-05-25 04:07:41 [INFO]: Epoch 022 - training loss: 0.8864, validation loss: 0.6888
2024-05-25 04:07:41 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch22_loss0.6887628346681595.pypots
2024-05-25 04:07:45 [INFO]: Epoch 023 - training loss: 0.8935, validation loss: 0.6873
2024-05-25 04:07:45 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch23_loss0.6873417854309082.pypots
2024-05-25 04:07:49 [INFO]: Epoch 024 - training loss: 0.8664, validation loss: 0.6900
2024-05-25 04:07:49 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch24_loss0.6900481462478638.pypots
2024-05-25 04:07:53 [INFO]: Epoch 025 - training loss: 0.8888, validation loss: 0.6880
2024-05-25 04:07:53 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch25_loss0.6880445420742035.pypots
2024-05-25 04:07:57 [INFO]: Epoch 026 - training loss: 0.8783, validation loss: 0.6977
2024-05-25 04:07:57 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch26_loss0.6977428227663041.pypots
2024-05-25 04:08:00 [INFO]: Epoch 027 - training loss: 0.8722, validation loss: 0.6892
2024-05-25 04:08:00 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch27_loss0.6891795635223389.pypots
2024-05-25 04:08:04 [INFO]: Epoch 028 - training loss: 0.8749, validation loss: 0.6935
2024-05-25 04:08:04 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch28_loss0.6934784322977066.pypots
2024-05-25 04:08:08 [INFO]: Epoch 029 - training loss: 0.8724, validation loss: 0.6932
2024-05-25 04:08:08 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN_epoch29_loss0.6932013273239136.pypots
2024-05-25 04:08:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:08:08 [INFO]: Finished training. The best model is from epoch#19.
2024-05-25 04:08:08 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240525_T040616/MRNN.pypots
2024-05-25 04:08:09 [INFO]: MRNN on Air-Quality: MAE=0.5308, MSE=0.7084
2024-05-25 04:08:09 [INFO]: Successfully saved to augmentation_saved_results/round_2/MRNN_air_quality/imputation.pkl
2024-05-25 04:08:09 [INFO]: Using the given device: cpu
2024-05-25 04:08:09 [INFO]: LOCF on Air-Quality: MAE=0.2206, MSE=0.3343
2024-05-25 04:08:09 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_air_quality".
2024-05-25 04:08:09 [INFO]: Successfully saved to augmentation_saved_results/round_2/LOCF_air_quality/imputation.pkl
2024-05-25 04:08:09 [INFO]: Median on Air-Quality: MAE=0.6668, MSE=1.0938
2024-05-25 04:08:09 [INFO]: Successfully created the given path "saved_results/round_2/Median_air_quality".
2024-05-25 04:08:09 [INFO]: Successfully saved to augmentation_saved_results/round_2/Median_air_quality/imputation.pkl
2024-05-25 04:08:09 [INFO]: Mean on Air-Quality: MAE=0.6965, MSE=1.0305
2024-05-25 04:08:09 [INFO]: Successfully created the given path "saved_results/round_2/Mean_air_quality".
2024-05-25 04:08:09 [INFO]: Successfully saved to augmentation_saved_results/round_2/Mean_air_quality/imputation.pkl
2024-05-25 04:08:09 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-25 04:08:09 [INFO]: Using the given device: cuda:0
2024-05-25 04:08:09 [INFO]: Model files will be saved to augmentation_saved_results/round_3/SAITS_air_quality/20240525_T040809
2024-05-25 04:08:09 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/SAITS_air_quality/20240525_T040809/tensorboard
2024-05-25 04:08:09 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 04:08:10 [INFO]: Epoch 001 - training loss: 1.0581, validation loss: 0.5411
2024-05-25 04:08:11 [INFO]: Epoch 002 - training loss: 0.7659, validation loss: 0.4153
2024-05-25 04:08:11 [INFO]: Epoch 003 - training loss: 0.6562, validation loss: 0.3325
2024-05-25 04:08:12 [INFO]: Epoch 004 - training loss: 0.5811, validation loss: 0.2933
2024-05-25 04:08:13 [INFO]: Epoch 005 - training loss: 0.5251, validation loss: 0.2660
2024-05-25 04:08:13 [INFO]: Epoch 006 - training loss: 0.4870, validation loss: 0.2520
2024-05-25 04:08:14 [INFO]: Epoch 007 - training loss: 0.4609, validation loss: 0.2401
2024-05-25 04:08:15 [INFO]: Epoch 008 - training loss: 0.4427, validation loss: 0.2335
2024-05-25 04:08:15 [INFO]: Epoch 009 - training loss: 0.4277, validation loss: 0.2275
2024-05-25 04:08:16 [INFO]: Epoch 010 - training loss: 0.4169, validation loss: 0.2225
2024-05-25 04:08:17 [INFO]: Epoch 011 - training loss: 0.4063, validation loss: 0.2178
2024-05-25 04:08:17 [INFO]: Epoch 012 - training loss: 0.3972, validation loss: 0.2127
2024-05-25 04:08:18 [INFO]: Epoch 013 - training loss: 0.3888, validation loss: 0.2112
2024-05-25 04:08:19 [INFO]: Epoch 014 - training loss: 0.3837, validation loss: 0.2076
2024-05-25 04:08:19 [INFO]: Epoch 015 - training loss: 0.3769, validation loss: 0.2065
2024-05-25 04:08:20 [INFO]: Epoch 016 - training loss: 0.3714, validation loss: 0.2044
2024-05-25 04:08:21 [INFO]: Epoch 017 - training loss: 0.3659, validation loss: 0.2009
2024-05-25 04:08:21 [INFO]: Epoch 018 - training loss: 0.3608, validation loss: 0.1974
2024-05-25 04:08:22 [INFO]: Epoch 019 - training loss: 0.3571, validation loss: 0.1949
2024-05-25 04:08:23 [INFO]: Epoch 020 - training loss: 0.3527, validation loss: 0.1939
2024-05-25 04:08:23 [INFO]: Epoch 021 - training loss: 0.3471, validation loss: 0.1914
2024-05-25 04:08:24 [INFO]: Epoch 022 - training loss: 0.3453, validation loss: 0.1899
2024-05-25 04:08:25 [INFO]: Epoch 023 - training loss: 0.3424, validation loss: 0.1909
2024-05-25 04:08:25 [INFO]: Epoch 024 - training loss: 0.3394, validation loss: 0.1882
2024-05-25 04:08:26 [INFO]: Epoch 025 - training loss: 0.3368, validation loss: 0.1857
2024-05-25 04:08:27 [INFO]: Epoch 026 - training loss: 0.3322, validation loss: 0.1847
2024-05-25 04:08:27 [INFO]: Epoch 027 - training loss: 0.3302, validation loss: 0.1831
2024-05-25 04:08:28 [INFO]: Epoch 028 - training loss: 0.3279, validation loss: 0.1818
2024-05-25 04:08:29 [INFO]: Epoch 029 - training loss: 0.3269, validation loss: 0.1801
2024-05-25 04:08:29 [INFO]: Epoch 030 - training loss: 0.3236, validation loss: 0.1776
2024-05-25 04:08:30 [INFO]: Epoch 031 - training loss: 0.3215, validation loss: 0.1764
2024-05-25 04:08:31 [INFO]: Epoch 032 - training loss: 0.3223, validation loss: 0.1763
2024-05-25 04:08:31 [INFO]: Epoch 033 - training loss: 0.3180, validation loss: 0.1744
2024-05-25 04:08:32 [INFO]: Epoch 034 - training loss: 0.3156, validation loss: 0.1733
2024-05-25 04:08:33 [INFO]: Epoch 035 - training loss: 0.3136, validation loss: 0.1717
2024-05-25 04:08:33 [INFO]: Epoch 036 - training loss: 0.3132, validation loss: 0.1702
2024-05-25 04:08:34 [INFO]: Epoch 037 - training loss: 0.3111, validation loss: 0.1677
2024-05-25 04:08:35 [INFO]: Epoch 038 - training loss: 0.3082, validation loss: 0.1678
2024-05-25 04:08:36 [INFO]: Epoch 039 - training loss: 0.3080, validation loss: 0.1664
2024-05-25 04:08:36 [INFO]: Epoch 040 - training loss: 0.3068, validation loss: 0.1648
2024-05-25 04:08:37 [INFO]: Epoch 041 - training loss: 0.3042, validation loss: 0.1646
2024-05-25 04:08:38 [INFO]: Epoch 042 - training loss: 0.3023, validation loss: 0.1629
2024-05-25 04:08:38 [INFO]: Epoch 043 - training loss: 0.3011, validation loss: 0.1622
2024-05-25 04:08:39 [INFO]: Epoch 044 - training loss: 0.2989, validation loss: 0.1604
2024-05-25 04:08:40 [INFO]: Epoch 045 - training loss: 0.2970, validation loss: 0.1600
2024-05-25 04:08:40 [INFO]: Epoch 046 - training loss: 0.2965, validation loss: 0.1591
2024-05-25 04:08:41 [INFO]: Epoch 047 - training loss: 0.2948, validation loss: 0.1581
2024-05-25 04:08:42 [INFO]: Epoch 048 - training loss: 0.2932, validation loss: 0.1568
2024-05-25 04:08:42 [INFO]: Epoch 049 - training loss: 0.2919, validation loss: 0.1561
2024-05-25 04:08:43 [INFO]: Epoch 050 - training loss: 0.2913, validation loss: 0.1556
2024-05-25 04:08:44 [INFO]: Epoch 051 - training loss: 0.2896, validation loss: 0.1562
2024-05-25 04:08:44 [INFO]: Epoch 052 - training loss: 0.2874, validation loss: 0.1536
2024-05-25 04:08:45 [INFO]: Epoch 053 - training loss: 0.2869, validation loss: 0.1542
2024-05-25 04:08:46 [INFO]: Epoch 054 - training loss: 0.2864, validation loss: 0.1537
2024-05-25 04:08:46 [INFO]: Epoch 055 - training loss: 0.2857, validation loss: 0.1532
2024-05-25 04:08:47 [INFO]: Epoch 056 - training loss: 0.2834, validation loss: 0.1513
2024-05-25 04:08:48 [INFO]: Epoch 057 - training loss: 0.2809, validation loss: 0.1506
2024-05-25 04:08:48 [INFO]: Epoch 058 - training loss: 0.2803, validation loss: 0.1516
2024-05-25 04:08:49 [INFO]: Epoch 059 - training loss: 0.2798, validation loss: 0.1505
2024-05-25 04:08:50 [INFO]: Epoch 060 - training loss: 0.2790, validation loss: 0.1504
2024-05-25 04:08:50 [INFO]: Epoch 061 - training loss: 0.2776, validation loss: 0.1498
2024-05-25 04:08:51 [INFO]: Epoch 062 - training loss: 0.2767, validation loss: 0.1491
2024-05-25 04:08:52 [INFO]: Epoch 063 - training loss: 0.2773, validation loss: 0.1483
2024-05-25 04:08:52 [INFO]: Epoch 064 - training loss: 0.2752, validation loss: 0.1488
2024-05-25 04:08:53 [INFO]: Epoch 065 - training loss: 0.2743, validation loss: 0.1471
2024-05-25 04:08:54 [INFO]: Epoch 066 - training loss: 0.2718, validation loss: 0.1475
2024-05-25 04:08:54 [INFO]: Epoch 067 - training loss: 0.2700, validation loss: 0.1474
2024-05-25 04:08:55 [INFO]: Epoch 068 - training loss: 0.2696, validation loss: 0.1470
2024-05-25 04:08:56 [INFO]: Epoch 069 - training loss: 0.2690, validation loss: 0.1452
2024-05-25 04:08:56 [INFO]: Epoch 070 - training loss: 0.2688, validation loss: 0.1455
2024-05-25 04:08:57 [INFO]: Epoch 071 - training loss: 0.2663, validation loss: 0.1455
2024-05-25 04:08:58 [INFO]: Epoch 072 - training loss: 0.2647, validation loss: 0.1458
2024-05-25 04:08:58 [INFO]: Epoch 073 - training loss: 0.2648, validation loss: 0.1443
2024-05-25 04:08:59 [INFO]: Epoch 074 - training loss: 0.2642, validation loss: 0.1449
2024-05-25 04:09:00 [INFO]: Epoch 075 - training loss: 0.2643, validation loss: 0.1443
2024-05-25 04:09:00 [INFO]: Epoch 076 - training loss: 0.2632, validation loss: 0.1444
2024-05-25 04:09:01 [INFO]: Epoch 077 - training loss: 0.2623, validation loss: 0.1430
2024-05-25 04:09:02 [INFO]: Epoch 078 - training loss: 0.2622, validation loss: 0.1431
2024-05-25 04:09:02 [INFO]: Epoch 079 - training loss: 0.2613, validation loss: 0.1430
2024-05-25 04:09:03 [INFO]: Epoch 080 - training loss: 0.2599, validation loss: 0.1419
2024-05-25 04:09:04 [INFO]: Epoch 081 - training loss: 0.2586, validation loss: 0.1434
2024-05-25 04:09:04 [INFO]: Epoch 082 - training loss: 0.2578, validation loss: 0.1411
2024-05-25 04:09:05 [INFO]: Epoch 083 - training loss: 0.2577, validation loss: 0.1411
2024-05-25 04:09:06 [INFO]: Epoch 084 - training loss: 0.2559, validation loss: 0.1411
2024-05-25 04:09:06 [INFO]: Epoch 085 - training loss: 0.2556, validation loss: 0.1403
2024-05-25 04:09:07 [INFO]: Epoch 086 - training loss: 0.2547, validation loss: 0.1400
2024-05-25 04:09:08 [INFO]: Epoch 087 - training loss: 0.2541, validation loss: 0.1402
2024-05-25 04:09:08 [INFO]: Epoch 088 - training loss: 0.2544, validation loss: 0.1399
2024-05-25 04:09:09 [INFO]: Epoch 089 - training loss: 0.2524, validation loss: 0.1401
2024-05-25 04:09:10 [INFO]: Epoch 090 - training loss: 0.2514, validation loss: 0.1396
2024-05-25 04:09:10 [INFO]: Epoch 091 - training loss: 0.2517, validation loss: 0.1390
2024-05-25 04:09:11 [INFO]: Epoch 092 - training loss: 0.2498, validation loss: 0.1379
2024-05-25 04:09:12 [INFO]: Epoch 093 - training loss: 0.2496, validation loss: 0.1378
2024-05-25 04:09:12 [INFO]: Epoch 094 - training loss: 0.2490, validation loss: 0.1379
2024-05-25 04:09:13 [INFO]: Epoch 095 - training loss: 0.2486, validation loss: 0.1368
2024-05-25 04:09:14 [INFO]: Epoch 096 - training loss: 0.2481, validation loss: 0.1378
2024-05-25 04:09:14 [INFO]: Epoch 097 - training loss: 0.2492, validation loss: 0.1378
2024-05-25 04:09:15 [INFO]: Epoch 098 - training loss: 0.2497, validation loss: 0.1361
2024-05-25 04:09:16 [INFO]: Epoch 099 - training loss: 0.2462, validation loss: 0.1365
2024-05-25 04:09:16 [INFO]: Epoch 100 - training loss: 0.2448, validation loss: 0.1364
2024-05-25 04:09:17 [INFO]: Epoch 101 - training loss: 0.2454, validation loss: 0.1364
2024-05-25 04:09:18 [INFO]: Epoch 102 - training loss: 0.2443, validation loss: 0.1361
2024-05-25 04:09:18 [INFO]: Epoch 103 - training loss: 0.2437, validation loss: 0.1354
2024-05-25 04:09:19 [INFO]: Epoch 104 - training loss: 0.2432, validation loss: 0.1348
2024-05-25 04:09:20 [INFO]: Epoch 105 - training loss: 0.2429, validation loss: 0.1347
2024-05-25 04:09:21 [INFO]: Epoch 106 - training loss: 0.2430, validation loss: 0.1343
2024-05-25 04:09:21 [INFO]: Epoch 107 - training loss: 0.2430, validation loss: 0.1347
2024-05-25 04:09:22 [INFO]: Epoch 108 - training loss: 0.2458, validation loss: 0.1345
2024-05-25 04:09:23 [INFO]: Epoch 109 - training loss: 0.2415, validation loss: 0.1339
2024-05-25 04:09:23 [INFO]: Epoch 110 - training loss: 0.2437, validation loss: 0.1340
2024-05-25 04:09:24 [INFO]: Epoch 111 - training loss: 0.2404, validation loss: 0.1334
2024-05-25 04:09:25 [INFO]: Epoch 112 - training loss: 0.2382, validation loss: 0.1334
2024-05-25 04:09:25 [INFO]: Epoch 113 - training loss: 0.2407, validation loss: 0.1322
2024-05-25 04:09:26 [INFO]: Epoch 114 - training loss: 0.2383, validation loss: 0.1321
2024-05-25 04:09:27 [INFO]: Epoch 115 - training loss: 0.2384, validation loss: 0.1324
2024-05-25 04:09:27 [INFO]: Epoch 116 - training loss: 0.2383, validation loss: 0.1312
2024-05-25 04:09:28 [INFO]: Epoch 117 - training loss: 0.2398, validation loss: 0.1325
2024-05-25 04:09:29 [INFO]: Epoch 118 - training loss: 0.2380, validation loss: 0.1309
2024-05-25 04:09:29 [INFO]: Epoch 119 - training loss: 0.2366, validation loss: 0.1306
2024-05-25 04:09:30 [INFO]: Epoch 120 - training loss: 0.2358, validation loss: 0.1314
2024-05-25 04:09:31 [INFO]: Epoch 121 - training loss: 0.2358, validation loss: 0.1310
2024-05-25 04:09:31 [INFO]: Epoch 122 - training loss: 0.2340, validation loss: 0.1301
2024-05-25 04:09:32 [INFO]: Epoch 123 - training loss: 0.2345, validation loss: 0.1296
2024-05-25 04:09:33 [INFO]: Epoch 124 - training loss: 0.2336, validation loss: 0.1301
2024-05-25 04:09:33 [INFO]: Epoch 125 - training loss: 0.2339, validation loss: 0.1300
2024-05-25 04:09:34 [INFO]: Epoch 126 - training loss: 0.2329, validation loss: 0.1301
2024-05-25 04:09:35 [INFO]: Epoch 127 - training loss: 0.2338, validation loss: 0.1301
2024-05-25 04:09:35 [INFO]: Epoch 128 - training loss: 0.2339, validation loss: 0.1293
2024-05-25 04:09:36 [INFO]: Epoch 129 - training loss: 0.2318, validation loss: 0.1292
2024-05-25 04:09:37 [INFO]: Epoch 130 - training loss: 0.2305, validation loss: 0.1292
2024-05-25 04:09:37 [INFO]: Epoch 131 - training loss: 0.2310, validation loss: 0.1287
2024-05-25 04:09:38 [INFO]: Epoch 132 - training loss: 0.2303, validation loss: 0.1286
2024-05-25 04:09:39 [INFO]: Epoch 133 - training loss: 0.2295, validation loss: 0.1280
2024-05-25 04:09:39 [INFO]: Epoch 134 - training loss: 0.2306, validation loss: 0.1278
2024-05-25 04:09:40 [INFO]: Epoch 135 - training loss: 0.2296, validation loss: 0.1279
2024-05-25 04:09:41 [INFO]: Epoch 136 - training loss: 0.2286, validation loss: 0.1287
2024-05-25 04:09:41 [INFO]: Epoch 137 - training loss: 0.2277, validation loss: 0.1279
2024-05-25 04:09:42 [INFO]: Epoch 138 - training loss: 0.2286, validation loss: 0.1275
2024-05-25 04:09:43 [INFO]: Epoch 139 - training loss: 0.2281, validation loss: 0.1281
2024-05-25 04:09:43 [INFO]: Epoch 140 - training loss: 0.2268, validation loss: 0.1289
2024-05-25 04:09:44 [INFO]: Epoch 141 - training loss: 0.2287, validation loss: 0.1275
2024-05-25 04:09:45 [INFO]: Epoch 142 - training loss: 0.2293, validation loss: 0.1276
2024-05-25 04:09:45 [INFO]: Epoch 143 - training loss: 0.2273, validation loss: 0.1261
2024-05-25 04:09:46 [INFO]: Epoch 144 - training loss: 0.2264, validation loss: 0.1263
2024-05-25 04:09:47 [INFO]: Epoch 145 - training loss: 0.2261, validation loss: 0.1275
2024-05-25 04:09:47 [INFO]: Epoch 146 - training loss: 0.2251, validation loss: 0.1273
2024-05-25 04:09:48 [INFO]: Epoch 147 - training loss: 0.2251, validation loss: 0.1271
2024-05-25 04:09:49 [INFO]: Epoch 148 - training loss: 0.2252, validation loss: 0.1257
2024-05-25 04:09:49 [INFO]: Epoch 149 - training loss: 0.2239, validation loss: 0.1263
2024-05-25 04:09:50 [INFO]: Epoch 150 - training loss: 0.2239, validation loss: 0.1246
2024-05-25 04:09:51 [INFO]: Epoch 151 - training loss: 0.2231, validation loss: 0.1252
2024-05-25 04:09:51 [INFO]: Epoch 152 - training loss: 0.2238, validation loss: 0.1260
2024-05-25 04:09:52 [INFO]: Epoch 153 - training loss: 0.2231, validation loss: 0.1251
2024-05-25 04:09:53 [INFO]: Epoch 154 - training loss: 0.2222, validation loss: 0.1246
2024-05-25 04:09:53 [INFO]: Epoch 155 - training loss: 0.2226, validation loss: 0.1246
2024-05-25 04:09:54 [INFO]: Epoch 156 - training loss: 0.2233, validation loss: 0.1249
2024-05-25 04:09:55 [INFO]: Epoch 157 - training loss: 0.2230, validation loss: 0.1241
2024-05-25 04:09:55 [INFO]: Epoch 158 - training loss: 0.2210, validation loss: 0.1241
2024-05-25 04:09:56 [INFO]: Epoch 159 - training loss: 0.2199, validation loss: 0.1233
2024-05-25 04:09:57 [INFO]: Epoch 160 - training loss: 0.2199, validation loss: 0.1236
2024-05-25 04:09:58 [INFO]: Epoch 161 - training loss: 0.2184, validation loss: 0.1234
2024-05-25 04:09:58 [INFO]: Epoch 162 - training loss: 0.2194, validation loss: 0.1225
2024-05-25 04:09:59 [INFO]: Epoch 163 - training loss: 0.2192, validation loss: 0.1226
2024-05-25 04:10:00 [INFO]: Epoch 164 - training loss: 0.2183, validation loss: 0.1224
2024-05-25 04:10:00 [INFO]: Epoch 165 - training loss: 0.2191, validation loss: 0.1223
2024-05-25 04:10:01 [INFO]: Epoch 166 - training loss: 0.2186, validation loss: 0.1221
2024-05-25 04:10:02 [INFO]: Epoch 167 - training loss: 0.2187, validation loss: 0.1232
2024-05-25 04:10:02 [INFO]: Epoch 168 - training loss: 0.2189, validation loss: 0.1227
2024-05-25 04:10:03 [INFO]: Epoch 169 - training loss: 0.2199, validation loss: 0.1226
2024-05-25 04:10:04 [INFO]: Epoch 170 - training loss: 0.2197, validation loss: 0.1233
2024-05-25 04:10:04 [INFO]: Epoch 171 - training loss: 0.2192, validation loss: 0.1213
2024-05-25 04:10:05 [INFO]: Epoch 172 - training loss: 0.2170, validation loss: 0.1223
2024-05-25 04:10:06 [INFO]: Epoch 173 - training loss: 0.2166, validation loss: 0.1205
2024-05-25 04:10:06 [INFO]: Epoch 174 - training loss: 0.2158, validation loss: 0.1208
2024-05-25 04:10:07 [INFO]: Epoch 175 - training loss: 0.2165, validation loss: 0.1204
2024-05-25 04:10:08 [INFO]: Epoch 176 - training loss: 0.2151, validation loss: 0.1214
2024-05-25 04:10:08 [INFO]: Epoch 177 - training loss: 0.2152, validation loss: 0.1219
2024-05-25 04:10:09 [INFO]: Epoch 178 - training loss: 0.2144, validation loss: 0.1212
2024-05-25 04:10:10 [INFO]: Epoch 179 - training loss: 0.2138, validation loss: 0.1203
2024-05-25 04:10:10 [INFO]: Epoch 180 - training loss: 0.2133, validation loss: 0.1197
2024-05-25 04:10:11 [INFO]: Epoch 181 - training loss: 0.2127, validation loss: 0.1199
2024-05-25 04:10:12 [INFO]: Epoch 182 - training loss: 0.2139, validation loss: 0.1211
2024-05-25 04:10:12 [INFO]: Epoch 183 - training loss: 0.2137, validation loss: 0.1200
2024-05-25 04:10:13 [INFO]: Epoch 184 - training loss: 0.2129, validation loss: 0.1199
2024-05-25 04:10:14 [INFO]: Epoch 185 - training loss: 0.2127, validation loss: 0.1200
2024-05-25 04:10:14 [INFO]: Epoch 186 - training loss: 0.2124, validation loss: 0.1206
2024-05-25 04:10:15 [INFO]: Epoch 187 - training loss: 0.2135, validation loss: 0.1199
2024-05-25 04:10:16 [INFO]: Epoch 188 - training loss: 0.2121, validation loss: 0.1218
2024-05-25 04:10:16 [INFO]: Epoch 189 - training loss: 0.2123, validation loss: 0.1187
2024-05-25 04:10:17 [INFO]: Epoch 190 - training loss: 0.2118, validation loss: 0.1192
2024-05-25 04:10:18 [INFO]: Epoch 191 - training loss: 0.2109, validation loss: 0.1195
2024-05-25 04:10:18 [INFO]: Epoch 192 - training loss: 0.2110, validation loss: 0.1209
2024-05-25 04:10:19 [INFO]: Epoch 193 - training loss: 0.2114, validation loss: 0.1196
2024-05-25 04:10:20 [INFO]: Epoch 194 - training loss: 0.2116, validation loss: 0.1191
2024-05-25 04:10:20 [INFO]: Epoch 195 - training loss: 0.2112, validation loss: 0.1191
2024-05-25 04:10:21 [INFO]: Epoch 196 - training loss: 0.2101, validation loss: 0.1188
2024-05-25 04:10:22 [INFO]: Epoch 197 - training loss: 0.2093, validation loss: 0.1186
2024-05-25 04:10:22 [INFO]: Epoch 198 - training loss: 0.2091, validation loss: 0.1189
2024-05-25 04:10:23 [INFO]: Epoch 199 - training loss: 0.2087, validation loss: 0.1189
2024-05-25 04:10:24 [INFO]: Epoch 200 - training loss: 0.2096, validation loss: 0.1184
2024-05-25 04:10:24 [INFO]: Epoch 201 - training loss: 0.2089, validation loss: 0.1178
2024-05-25 04:10:25 [INFO]: Epoch 202 - training loss: 0.2072, validation loss: 0.1182
2024-05-25 04:10:26 [INFO]: Epoch 203 - training loss: 0.2088, validation loss: 0.1183
2024-05-25 04:10:26 [INFO]: Epoch 204 - training loss: 0.2118, validation loss: 0.1190
2024-05-25 04:10:27 [INFO]: Epoch 205 - training loss: 0.2106, validation loss: 0.1178
2024-05-25 04:10:28 [INFO]: Epoch 206 - training loss: 0.2075, validation loss: 0.1185
2024-05-25 04:10:28 [INFO]: Epoch 207 - training loss: 0.2075, validation loss: 0.1177
2024-05-25 04:10:29 [INFO]: Epoch 208 - training loss: 0.2068, validation loss: 0.1180
2024-05-25 04:10:30 [INFO]: Epoch 209 - training loss: 0.2073, validation loss: 0.1186
2024-05-25 04:10:30 [INFO]: Epoch 210 - training loss: 0.2060, validation loss: 0.1169
2024-05-25 04:10:31 [INFO]: Epoch 211 - training loss: 0.2061, validation loss: 0.1169
2024-05-25 04:10:32 [INFO]: Epoch 212 - training loss: 0.2056, validation loss: 0.1177
2024-05-25 04:10:32 [INFO]: Epoch 213 - training loss: 0.2064, validation loss: 0.1183
2024-05-25 04:10:33 [INFO]: Epoch 214 - training loss: 0.2072, validation loss: 0.1176
2024-05-25 04:10:34 [INFO]: Epoch 215 - training loss: 0.2063, validation loss: 0.1170
2024-05-25 04:10:34 [INFO]: Epoch 216 - training loss: 0.2067, validation loss: 0.1166
2024-05-25 04:10:35 [INFO]: Epoch 217 - training loss: 0.2052, validation loss: 0.1163
2024-05-25 04:10:36 [INFO]: Epoch 218 - training loss: 0.2052, validation loss: 0.1168
2024-05-25 04:10:36 [INFO]: Epoch 219 - training loss: 0.2045, validation loss: 0.1164
2024-05-25 04:10:37 [INFO]: Epoch 220 - training loss: 0.2038, validation loss: 0.1167
2024-05-25 04:10:38 [INFO]: Epoch 221 - training loss: 0.2050, validation loss: 0.1166
2024-05-25 04:10:38 [INFO]: Epoch 222 - training loss: 0.2037, validation loss: 0.1180
2024-05-25 04:10:39 [INFO]: Epoch 223 - training loss: 0.2031, validation loss: 0.1178
2024-05-25 04:10:40 [INFO]: Epoch 224 - training loss: 0.2029, validation loss: 0.1170
2024-05-25 04:10:40 [INFO]: Epoch 225 - training loss: 0.2039, validation loss: 0.1163
2024-05-25 04:10:41 [INFO]: Epoch 226 - training loss: 0.2040, validation loss: 0.1166
2024-05-25 04:10:42 [INFO]: Epoch 227 - training loss: 0.2047, validation loss: 0.1163
2024-05-25 04:10:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:10:42 [INFO]: Finished training. The best model is from epoch#217.
2024-05-25 04:10:42 [INFO]: Saved the model to augmentation_saved_results/round_3/SAITS_air_quality/20240525_T040809/SAITS.pypots
2024-05-25 04:10:42 [INFO]: SAITS on Air-Quality: MAE=0.1522, MSE=0.1791
2024-05-25 04:10:42 [INFO]: Successfully saved to augmentation_saved_results/round_3/SAITS_air_quality/imputation.pkl
2024-05-25 04:10:42 [INFO]: Using the given device: cuda:0
2024-05-25 04:10:42 [INFO]: Model files will be saved to augmentation_saved_results/round_3/Transformer_air_quality/20240525_T041042
2024-05-25 04:10:42 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/Transformer_air_quality/20240525_T041042/tensorboard
2024-05-25 04:10:42 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 04:10:42 [INFO]: Epoch 001 - training loss: 0.9266, validation loss: 0.4731
2024-05-25 04:10:43 [INFO]: Epoch 002 - training loss: 0.5834, validation loss: 0.3672
2024-05-25 04:10:43 [INFO]: Epoch 003 - training loss: 0.4905, validation loss: 0.3015
2024-05-25 04:10:43 [INFO]: Epoch 004 - training loss: 0.4442, validation loss: 0.2721
2024-05-25 04:10:44 [INFO]: Epoch 005 - training loss: 0.4151, validation loss: 0.2564
2024-05-25 04:10:44 [INFO]: Epoch 006 - training loss: 0.3950, validation loss: 0.2459
2024-05-25 04:10:44 [INFO]: Epoch 007 - training loss: 0.3796, validation loss: 0.2409
2024-05-25 04:10:45 [INFO]: Epoch 008 - training loss: 0.3673, validation loss: 0.2334
2024-05-25 04:10:45 [INFO]: Epoch 009 - training loss: 0.3582, validation loss: 0.2267
2024-05-25 04:10:45 [INFO]: Epoch 010 - training loss: 0.3508, validation loss: 0.2228
2024-05-25 04:10:46 [INFO]: Epoch 011 - training loss: 0.3426, validation loss: 0.2188
2024-05-25 04:10:46 [INFO]: Epoch 012 - training loss: 0.3372, validation loss: 0.2149
2024-05-25 04:10:46 [INFO]: Epoch 013 - training loss: 0.3332, validation loss: 0.2139
2024-05-25 04:10:47 [INFO]: Epoch 014 - training loss: 0.3279, validation loss: 0.2078
2024-05-25 04:10:47 [INFO]: Epoch 015 - training loss: 0.3202, validation loss: 0.2034
2024-05-25 04:10:47 [INFO]: Epoch 016 - training loss: 0.3164, validation loss: 0.2013
2024-05-25 04:10:47 [INFO]: Epoch 017 - training loss: 0.3134, validation loss: 0.1975
2024-05-25 04:10:48 [INFO]: Epoch 018 - training loss: 0.3118, validation loss: 0.1947
2024-05-25 04:10:48 [INFO]: Epoch 019 - training loss: 0.3090, validation loss: 0.1931
2024-05-25 04:10:48 [INFO]: Epoch 020 - training loss: 0.3049, validation loss: 0.1927
2024-05-25 04:10:49 [INFO]: Epoch 021 - training loss: 0.3037, validation loss: 0.1894
2024-05-25 04:10:49 [INFO]: Epoch 022 - training loss: 0.3016, validation loss: 0.1923
2024-05-25 04:10:49 [INFO]: Epoch 023 - training loss: 0.2994, validation loss: 0.1859
2024-05-25 04:10:50 [INFO]: Epoch 024 - training loss: 0.2967, validation loss: 0.1880
2024-05-25 04:10:50 [INFO]: Epoch 025 - training loss: 0.2943, validation loss: 0.1858
2024-05-25 04:10:50 [INFO]: Epoch 026 - training loss: 0.2931, validation loss: 0.1877
2024-05-25 04:10:51 [INFO]: Epoch 027 - training loss: 0.2912, validation loss: 0.1832
2024-05-25 04:10:51 [INFO]: Epoch 028 - training loss: 0.2889, validation loss: 0.1820
2024-05-25 04:10:51 [INFO]: Epoch 029 - training loss: 0.2877, validation loss: 0.1828
2024-05-25 04:10:52 [INFO]: Epoch 030 - training loss: 0.2865, validation loss: 0.1812
2024-05-25 04:10:52 [INFO]: Epoch 031 - training loss: 0.2856, validation loss: 0.1788
2024-05-25 04:10:52 [INFO]: Epoch 032 - training loss: 0.2846, validation loss: 0.1808
2024-05-25 04:10:53 [INFO]: Epoch 033 - training loss: 0.2841, validation loss: 0.1806
2024-05-25 04:10:53 [INFO]: Epoch 034 - training loss: 0.2802, validation loss: 0.1784
2024-05-25 04:10:53 [INFO]: Epoch 035 - training loss: 0.2777, validation loss: 0.1763
2024-05-25 04:10:53 [INFO]: Epoch 036 - training loss: 0.2781, validation loss: 0.1765
2024-05-25 04:10:54 [INFO]: Epoch 037 - training loss: 0.2779, validation loss: 0.1755
2024-05-25 04:10:54 [INFO]: Epoch 038 - training loss: 0.2744, validation loss: 0.1765
2024-05-25 04:10:54 [INFO]: Epoch 039 - training loss: 0.2760, validation loss: 0.1765
2024-05-25 04:10:55 [INFO]: Epoch 040 - training loss: 0.2733, validation loss: 0.1776
2024-05-25 04:10:55 [INFO]: Epoch 041 - training loss: 0.2729, validation loss: 0.1727
2024-05-25 04:10:55 [INFO]: Epoch 042 - training loss: 0.2693, validation loss: 0.1742
2024-05-25 04:10:56 [INFO]: Epoch 043 - training loss: 0.2679, validation loss: 0.1741
2024-05-25 04:10:56 [INFO]: Epoch 044 - training loss: 0.2691, validation loss: 0.1704
2024-05-25 04:10:56 [INFO]: Epoch 045 - training loss: 0.2678, validation loss: 0.1713
2024-05-25 04:10:57 [INFO]: Epoch 046 - training loss: 0.2693, validation loss: 0.1717
2024-05-25 04:10:57 [INFO]: Epoch 047 - training loss: 0.2662, validation loss: 0.1714
2024-05-25 04:10:57 [INFO]: Epoch 048 - training loss: 0.2643, validation loss: 0.1704
2024-05-25 04:10:58 [INFO]: Epoch 049 - training loss: 0.2657, validation loss: 0.1694
2024-05-25 04:10:58 [INFO]: Epoch 050 - training loss: 0.2643, validation loss: 0.1703
2024-05-25 04:10:58 [INFO]: Epoch 051 - training loss: 0.2606, validation loss: 0.1712
2024-05-25 04:10:59 [INFO]: Epoch 052 - training loss: 0.2607, validation loss: 0.1679
2024-05-25 04:10:59 [INFO]: Epoch 053 - training loss: 0.2601, validation loss: 0.1682
2024-05-25 04:10:59 [INFO]: Epoch 054 - training loss: 0.2581, validation loss: 0.1682
2024-05-25 04:10:59 [INFO]: Epoch 055 - training loss: 0.2596, validation loss: 0.1678
2024-05-25 04:11:00 [INFO]: Epoch 056 - training loss: 0.2599, validation loss: 0.1661
2024-05-25 04:11:00 [INFO]: Epoch 057 - training loss: 0.2575, validation loss: 0.1669
2024-05-25 04:11:00 [INFO]: Epoch 058 - training loss: 0.2569, validation loss: 0.1646
2024-05-25 04:11:01 [INFO]: Epoch 059 - training loss: 0.2564, validation loss: 0.1642
2024-05-25 04:11:01 [INFO]: Epoch 060 - training loss: 0.2543, validation loss: 0.1658
2024-05-25 04:11:01 [INFO]: Epoch 061 - training loss: 0.2566, validation loss: 0.1659
2024-05-25 04:11:02 [INFO]: Epoch 062 - training loss: 0.2539, validation loss: 0.1642
2024-05-25 04:11:02 [INFO]: Epoch 063 - training loss: 0.2524, validation loss: 0.1638
2024-05-25 04:11:02 [INFO]: Epoch 064 - training loss: 0.2513, validation loss: 0.1635
2024-05-25 04:11:03 [INFO]: Epoch 065 - training loss: 0.2517, validation loss: 0.1633
2024-05-25 04:11:03 [INFO]: Epoch 066 - training loss: 0.2491, validation loss: 0.1607
2024-05-25 04:11:03 [INFO]: Epoch 067 - training loss: 0.2496, validation loss: 0.1631
2024-05-25 04:11:04 [INFO]: Epoch 068 - training loss: 0.2478, validation loss: 0.1631
2024-05-25 04:11:04 [INFO]: Epoch 069 - training loss: 0.2495, validation loss: 0.1647
2024-05-25 04:11:04 [INFO]: Epoch 070 - training loss: 0.2470, validation loss: 0.1601
2024-05-25 04:11:05 [INFO]: Epoch 071 - training loss: 0.2464, validation loss: 0.1612
2024-05-25 04:11:05 [INFO]: Epoch 072 - training loss: 0.2456, validation loss: 0.1593
2024-05-25 04:11:05 [INFO]: Epoch 073 - training loss: 0.2448, validation loss: 0.1609
2024-05-25 04:11:05 [INFO]: Epoch 074 - training loss: 0.2464, validation loss: 0.1607
2024-05-25 04:11:06 [INFO]: Epoch 075 - training loss: 0.2457, validation loss: 0.1637
2024-05-25 04:11:06 [INFO]: Epoch 076 - training loss: 0.2455, validation loss: 0.1606
2024-05-25 04:11:06 [INFO]: Epoch 077 - training loss: 0.2424, validation loss: 0.1580
2024-05-25 04:11:07 [INFO]: Epoch 078 - training loss: 0.2409, validation loss: 0.1581
2024-05-25 04:11:07 [INFO]: Epoch 079 - training loss: 0.2399, validation loss: 0.1582
2024-05-25 04:11:07 [INFO]: Epoch 080 - training loss: 0.2408, validation loss: 0.1587
2024-05-25 04:11:08 [INFO]: Epoch 081 - training loss: 0.2396, validation loss: 0.1599
2024-05-25 04:11:08 [INFO]: Epoch 082 - training loss: 0.2425, validation loss: 0.1581
2024-05-25 04:11:08 [INFO]: Epoch 083 - training loss: 0.2391, validation loss: 0.1556
2024-05-25 04:11:09 [INFO]: Epoch 084 - training loss: 0.2384, validation loss: 0.1565
2024-05-25 04:11:09 [INFO]: Epoch 085 - training loss: 0.2385, validation loss: 0.1563
2024-05-25 04:11:09 [INFO]: Epoch 086 - training loss: 0.2352, validation loss: 0.1565
2024-05-25 04:11:10 [INFO]: Epoch 087 - training loss: 0.2381, validation loss: 0.1552
2024-05-25 04:11:10 [INFO]: Epoch 088 - training loss: 0.2382, validation loss: 0.1554
2024-05-25 04:11:10 [INFO]: Epoch 089 - training loss: 0.2363, validation loss: 0.1544
2024-05-25 04:11:11 [INFO]: Epoch 090 - training loss: 0.2341, validation loss: 0.1564
2024-05-25 04:11:11 [INFO]: Epoch 091 - training loss: 0.2361, validation loss: 0.1558
2024-05-25 04:11:11 [INFO]: Epoch 092 - training loss: 0.2336, validation loss: 0.1544
2024-05-25 04:11:12 [INFO]: Epoch 093 - training loss: 0.2340, validation loss: 0.1533
2024-05-25 04:11:12 [INFO]: Epoch 094 - training loss: 0.2340, validation loss: 0.1521
2024-05-25 04:11:12 [INFO]: Epoch 095 - training loss: 0.2306, validation loss: 0.1541
2024-05-25 04:11:13 [INFO]: Epoch 096 - training loss: 0.2349, validation loss: 0.1561
2024-05-25 04:11:13 [INFO]: Epoch 097 - training loss: 0.2324, validation loss: 0.1527
2024-05-25 04:11:13 [INFO]: Epoch 098 - training loss: 0.2328, validation loss: 0.1522
2024-05-25 04:11:13 [INFO]: Epoch 099 - training loss: 0.2295, validation loss: 0.1529
2024-05-25 04:11:14 [INFO]: Epoch 100 - training loss: 0.2284, validation loss: 0.1509
2024-05-25 04:11:14 [INFO]: Epoch 101 - training loss: 0.2305, validation loss: 0.1513
2024-05-25 04:11:14 [INFO]: Epoch 102 - training loss: 0.2290, validation loss: 0.1510
2024-05-25 04:11:15 [INFO]: Epoch 103 - training loss: 0.2290, validation loss: 0.1519
2024-05-25 04:11:15 [INFO]: Epoch 104 - training loss: 0.2272, validation loss: 0.1527
2024-05-25 04:11:15 [INFO]: Epoch 105 - training loss: 0.2274, validation loss: 0.1496
2024-05-25 04:11:16 [INFO]: Epoch 106 - training loss: 0.2273, validation loss: 0.1506
2024-05-25 04:11:16 [INFO]: Epoch 107 - training loss: 0.2254, validation loss: 0.1494
2024-05-25 04:11:16 [INFO]: Epoch 108 - training loss: 0.2268, validation loss: 0.1500
2024-05-25 04:11:17 [INFO]: Epoch 109 - training loss: 0.2246, validation loss: 0.1505
2024-05-25 04:11:17 [INFO]: Epoch 110 - training loss: 0.2245, validation loss: 0.1484
2024-05-25 04:11:17 [INFO]: Epoch 111 - training loss: 0.2229, validation loss: 0.1484
2024-05-25 04:11:18 [INFO]: Epoch 112 - training loss: 0.2229, validation loss: 0.1502
2024-05-25 04:11:18 [INFO]: Epoch 113 - training loss: 0.2237, validation loss: 0.1497
2024-05-25 04:11:18 [INFO]: Epoch 114 - training loss: 0.2212, validation loss: 0.1479
2024-05-25 04:11:19 [INFO]: Epoch 115 - training loss: 0.2235, validation loss: 0.1472
2024-05-25 04:11:19 [INFO]: Epoch 116 - training loss: 0.2222, validation loss: 0.1489
2024-05-25 04:11:19 [INFO]: Epoch 117 - training loss: 0.2217, validation loss: 0.1479
2024-05-25 04:11:19 [INFO]: Epoch 118 - training loss: 0.2193, validation loss: 0.1477
2024-05-25 04:11:20 [INFO]: Epoch 119 - training loss: 0.2194, validation loss: 0.1481
2024-05-25 04:11:20 [INFO]: Epoch 120 - training loss: 0.2205, validation loss: 0.1459
2024-05-25 04:11:20 [INFO]: Epoch 121 - training loss: 0.2180, validation loss: 0.1467
2024-05-25 04:11:21 [INFO]: Epoch 122 - training loss: 0.2180, validation loss: 0.1470
2024-05-25 04:11:21 [INFO]: Epoch 123 - training loss: 0.2179, validation loss: 0.1463
2024-05-25 04:11:21 [INFO]: Epoch 124 - training loss: 0.2176, validation loss: 0.1459
2024-05-25 04:11:22 [INFO]: Epoch 125 - training loss: 0.2171, validation loss: 0.1469
2024-05-25 04:11:22 [INFO]: Epoch 126 - training loss: 0.2169, validation loss: 0.1460
2024-05-25 04:11:22 [INFO]: Epoch 127 - training loss: 0.2175, validation loss: 0.1464
2024-05-25 04:11:23 [INFO]: Epoch 128 - training loss: 0.2163, validation loss: 0.1459
2024-05-25 04:11:23 [INFO]: Epoch 129 - training loss: 0.2157, validation loss: 0.1443
2024-05-25 04:11:23 [INFO]: Epoch 130 - training loss: 0.2176, validation loss: 0.1442
2024-05-25 04:11:24 [INFO]: Epoch 131 - training loss: 0.2162, validation loss: 0.1435
2024-05-25 04:11:24 [INFO]: Epoch 132 - training loss: 0.2163, validation loss: 0.1450
2024-05-25 04:11:24 [INFO]: Epoch 133 - training loss: 0.2156, validation loss: 0.1420
2024-05-25 04:11:25 [INFO]: Epoch 134 - training loss: 0.2141, validation loss: 0.1450
2024-05-25 04:11:25 [INFO]: Epoch 135 - training loss: 0.2165, validation loss: 0.1434
2024-05-25 04:11:25 [INFO]: Epoch 136 - training loss: 0.2136, validation loss: 0.1427
2024-05-25 04:11:25 [INFO]: Epoch 137 - training loss: 0.2139, validation loss: 0.1449
2024-05-25 04:11:26 [INFO]: Epoch 138 - training loss: 0.2137, validation loss: 0.1437
2024-05-25 04:11:26 [INFO]: Epoch 139 - training loss: 0.2166, validation loss: 0.1453
2024-05-25 04:11:26 [INFO]: Epoch 140 - training loss: 0.2178, validation loss: 0.1444
2024-05-25 04:11:27 [INFO]: Epoch 141 - training loss: 0.2154, validation loss: 0.1429
2024-05-25 04:11:27 [INFO]: Epoch 142 - training loss: 0.2122, validation loss: 0.1428
2024-05-25 04:11:27 [INFO]: Epoch 143 - training loss: 0.2103, validation loss: 0.1432
2024-05-25 04:11:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:11:27 [INFO]: Finished training. The best model is from epoch#133.
2024-05-25 04:11:27 [INFO]: Saved the model to augmentation_saved_results/round_3/Transformer_air_quality/20240525_T041042/Transformer.pypots
2024-05-25 04:11:27 [INFO]: Transformer on Air-Quality: MAE=0.1713, MSE=0.2104
2024-05-25 04:11:27 [INFO]: Successfully saved to augmentation_saved_results/round_3/Transformer_air_quality/imputation.pkl
2024-05-25 04:11:27 [INFO]: Using the given device: cuda:0
2024-05-25 04:11:27 [INFO]: Model files will be saved to augmentation_saved_results/round_3/TimesNet_air_quality/20240525_T041127
2024-05-25 04:11:27 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/TimesNet_air_quality/20240525_T041127/tensorboard
2024-05-25 04:11:28 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 04:11:28 [INFO]: Epoch 001 - training loss: 0.3091, validation loss: 0.2529
2024-05-25 04:11:29 [INFO]: Epoch 002 - training loss: 0.2293, validation loss: 0.2280
2024-05-25 04:11:29 [INFO]: Epoch 003 - training loss: 0.1888, validation loss: 0.2076
2024-05-25 04:11:30 [INFO]: Epoch 004 - training loss: 0.1887, validation loss: 0.2029
2024-05-25 04:11:31 [INFO]: Epoch 005 - training loss: 0.1715, validation loss: 0.1980
2024-05-25 04:11:31 [INFO]: Epoch 006 - training loss: 0.1631, validation loss: 0.1886
2024-05-25 04:11:32 [INFO]: Epoch 007 - training loss: 0.1425, validation loss: 0.1872
2024-05-25 04:11:32 [INFO]: Epoch 008 - training loss: 0.1466, validation loss: 0.1853
2024-05-25 04:11:33 [INFO]: Epoch 009 - training loss: 0.1495, validation loss: 0.1817
2024-05-25 04:11:33 [INFO]: Epoch 010 - training loss: 0.1630, validation loss: 0.1829
2024-05-25 04:11:34 [INFO]: Epoch 011 - training loss: 0.1388, validation loss: 0.1802
2024-05-25 04:11:34 [INFO]: Epoch 012 - training loss: 0.1345, validation loss: 0.1747
2024-05-25 04:11:35 [INFO]: Epoch 013 - training loss: 0.1594, validation loss: 0.1727
2024-05-25 04:11:35 [INFO]: Epoch 014 - training loss: 0.1475, validation loss: 0.1704
2024-05-25 04:11:36 [INFO]: Epoch 015 - training loss: 0.1387, validation loss: 0.1678
2024-05-25 04:11:36 [INFO]: Epoch 016 - training loss: 0.1263, validation loss: 0.1651
2024-05-25 04:11:37 [INFO]: Epoch 017 - training loss: 0.1176, validation loss: 0.1693
2024-05-25 04:11:37 [INFO]: Epoch 018 - training loss: 0.1356, validation loss: 0.1691
2024-05-25 04:11:38 [INFO]: Epoch 019 - training loss: 0.1471, validation loss: 0.1713
2024-05-25 04:11:38 [INFO]: Epoch 020 - training loss: 0.1264, validation loss: 0.1647
2024-05-25 04:11:39 [INFO]: Epoch 021 - training loss: 0.1238, validation loss: 0.1674
2024-05-25 04:11:39 [INFO]: Epoch 022 - training loss: 0.1332, validation loss: 0.1650
2024-05-25 04:11:40 [INFO]: Epoch 023 - training loss: 0.1535, validation loss: 0.1615
2024-05-25 04:11:41 [INFO]: Epoch 024 - training loss: 0.1251, validation loss: 0.1664
2024-05-25 04:11:41 [INFO]: Epoch 025 - training loss: 0.1256, validation loss: 0.1590
2024-05-25 04:11:42 [INFO]: Epoch 026 - training loss: 0.1212, validation loss: 0.1615
2024-05-25 04:11:42 [INFO]: Epoch 027 - training loss: 0.1308, validation loss: 0.1628
2024-05-25 04:11:43 [INFO]: Epoch 028 - training loss: 0.1267, validation loss: 0.1597
2024-05-25 04:11:43 [INFO]: Epoch 029 - training loss: 0.1235, validation loss: 0.1612
2024-05-25 04:11:44 [INFO]: Epoch 030 - training loss: 0.1103, validation loss: 0.1587
2024-05-25 04:11:44 [INFO]: Epoch 031 - training loss: 0.1053, validation loss: 0.1626
2024-05-25 04:11:45 [INFO]: Epoch 032 - training loss: 0.1108, validation loss: 0.1579
2024-05-25 04:11:45 [INFO]: Epoch 033 - training loss: 0.1309, validation loss: 0.1564
2024-05-25 04:11:46 [INFO]: Epoch 034 - training loss: 0.1086, validation loss: 0.1679
2024-05-25 04:11:46 [INFO]: Epoch 035 - training loss: 0.1092, validation loss: 0.1608
2024-05-25 04:11:47 [INFO]: Epoch 036 - training loss: 0.1070, validation loss: 0.1599
2024-05-25 04:11:47 [INFO]: Epoch 037 - training loss: 0.1080, validation loss: 0.1694
2024-05-25 04:11:48 [INFO]: Epoch 038 - training loss: 0.0920, validation loss: 0.1600
2024-05-25 04:11:48 [INFO]: Epoch 039 - training loss: 0.1446, validation loss: 0.1596
2024-05-25 04:11:49 [INFO]: Epoch 040 - training loss: 0.1048, validation loss: 0.1634
2024-05-25 04:11:49 [INFO]: Epoch 041 - training loss: 0.1174, validation loss: 0.1573
2024-05-25 04:11:50 [INFO]: Epoch 042 - training loss: 0.1070, validation loss: 0.1602
2024-05-25 04:11:51 [INFO]: Epoch 043 - training loss: 0.1168, validation loss: 0.1531
2024-05-25 04:11:51 [INFO]: Epoch 044 - training loss: 0.1019, validation loss: 0.1664
2024-05-25 04:11:52 [INFO]: Epoch 045 - training loss: 0.1064, validation loss: 0.1727
2024-05-25 04:11:52 [INFO]: Epoch 046 - training loss: 0.1009, validation loss: 0.1624
2024-05-25 04:11:53 [INFO]: Epoch 047 - training loss: 0.0903, validation loss: 0.1560
2024-05-25 04:11:53 [INFO]: Epoch 048 - training loss: 0.0991, validation loss: 0.1578
2024-05-25 04:11:54 [INFO]: Epoch 049 - training loss: 0.1229, validation loss: 0.1521
2024-05-25 04:11:54 [INFO]: Epoch 050 - training loss: 0.1044, validation loss: 0.1600
2024-05-25 04:11:55 [INFO]: Epoch 051 - training loss: 0.1059, validation loss: 0.1731
2024-05-25 04:11:55 [INFO]: Epoch 052 - training loss: 0.0997, validation loss: 0.1548
2024-05-25 04:11:56 [INFO]: Epoch 053 - training loss: 0.0982, validation loss: 0.1576
2024-05-25 04:11:56 [INFO]: Epoch 054 - training loss: 0.1100, validation loss: 0.1564
2024-05-25 04:11:57 [INFO]: Epoch 055 - training loss: 0.1020, validation loss: 0.1538
2024-05-25 04:11:57 [INFO]: Epoch 056 - training loss: 0.0927, validation loss: 0.1594
2024-05-25 04:11:58 [INFO]: Epoch 057 - training loss: 0.1057, validation loss: 0.1562
2024-05-25 04:11:58 [INFO]: Epoch 058 - training loss: 0.0991, validation loss: 0.1605
2024-05-25 04:11:59 [INFO]: Epoch 059 - training loss: 0.0967, validation loss: 0.1600
2024-05-25 04:11:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:11:59 [INFO]: Finished training. The best model is from epoch#49.
2024-05-25 04:11:59 [INFO]: Saved the model to augmentation_saved_results/round_3/TimesNet_air_quality/20240525_T041127/TimesNet.pypots
2024-05-25 04:11:59 [INFO]: TimesNet on Air-Quality: MAE=0.1633, MSE=0.2299
2024-05-25 04:11:59 [INFO]: Successfully saved to augmentation_saved_results/round_3/TimesNet_air_quality/imputation.pkl
2024-05-25 04:11:59 [INFO]: Using the given device: cuda:0
2024-05-25 04:11:59 [INFO]: Model files will be saved to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159
2024-05-25 04:11:59 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/tensorboard
2024-05-25 04:11:59 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 04:12:16 [INFO]: Epoch 001 - training loss: 0.5099, validation loss: 0.3416
2024-05-25 04:12:16 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch1_loss0.3416153758764267.pypots
2024-05-25 04:12:33 [INFO]: Epoch 002 - training loss: 0.2920, validation loss: 0.2838
2024-05-25 04:12:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch2_loss0.2837946504354477.pypots
2024-05-25 04:12:50 [INFO]: Epoch 003 - training loss: 0.2583, validation loss: 0.2564
2024-05-25 04:12:50 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch3_loss0.25637521743774416.pypots
2024-05-25 04:13:06 [INFO]: Epoch 004 - training loss: 0.2338, validation loss: 0.2333
2024-05-25 04:13:06 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch4_loss0.2332836002111435.pypots
2024-05-25 04:13:23 [INFO]: Epoch 005 - training loss: 0.2381, validation loss: 0.2137
2024-05-25 04:13:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch5_loss0.2137295588850975.pypots
2024-05-25 04:13:40 [INFO]: Epoch 006 - training loss: 0.2132, validation loss: 0.1909
2024-05-25 04:13:40 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch6_loss0.19088040590286254.pypots
2024-05-25 04:13:57 [INFO]: Epoch 007 - training loss: 0.2014, validation loss: 0.1788
2024-05-25 04:13:57 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch7_loss0.17875480502843857.pypots
2024-05-25 04:14:14 [INFO]: Epoch 008 - training loss: 0.1840, validation loss: 0.1784
2024-05-25 04:14:14 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch8_loss0.178434556722641.pypots
2024-05-25 04:14:30 [INFO]: Epoch 009 - training loss: 0.1780, validation loss: 0.1656
2024-05-25 04:14:30 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch9_loss0.16561219245195388.pypots
2024-05-25 04:14:47 [INFO]: Epoch 010 - training loss: 0.1970, validation loss: 0.1645
2024-05-25 04:14:47 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch10_loss0.1644767314195633.pypots
2024-05-25 04:15:04 [INFO]: Epoch 011 - training loss: 0.1770, validation loss: 0.1574
2024-05-25 04:15:04 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch11_loss0.1574421003460884.pypots
2024-05-25 04:15:21 [INFO]: Epoch 012 - training loss: 0.1808, validation loss: 0.1556
2024-05-25 04:15:21 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch12_loss0.15556681007146836.pypots
2024-05-25 04:15:38 [INFO]: Epoch 013 - training loss: 0.1892, validation loss: 0.1531
2024-05-25 04:15:38 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch13_loss0.15310157388448714.pypots
2024-05-25 04:15:54 [INFO]: Epoch 014 - training loss: 0.1565, validation loss: 0.1512
2024-05-25 04:15:54 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch14_loss0.1511881247162819.pypots
2024-05-25 04:16:11 [INFO]: Epoch 015 - training loss: 0.1569, validation loss: 0.1481
2024-05-25 04:16:11 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch15_loss0.1481033444404602.pypots
2024-05-25 04:16:28 [INFO]: Epoch 016 - training loss: 0.1673, validation loss: 0.1422
2024-05-25 04:16:28 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch16_loss0.14222971573472024.pypots
2024-05-25 04:16:45 [INFO]: Epoch 017 - training loss: 0.1595, validation loss: 0.1397
2024-05-25 04:16:45 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch17_loss0.13971570506691933.pypots
2024-05-25 04:17:02 [INFO]: Epoch 018 - training loss: 0.1547, validation loss: 0.1365
2024-05-25 04:17:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch18_loss0.13649995177984237.pypots
2024-05-25 04:17:19 [INFO]: Epoch 019 - training loss: 0.1611, validation loss: 0.1394
2024-05-25 04:17:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch19_loss0.13940384313464166.pypots
2024-05-25 04:17:35 [INFO]: Epoch 020 - training loss: 0.1488, validation loss: 0.1590
2024-05-25 04:17:35 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch20_loss0.1590188056230545.pypots
2024-05-25 04:17:52 [INFO]: Epoch 021 - training loss: 0.1543, validation loss: 0.1370
2024-05-25 04:17:52 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch21_loss0.13704876005649566.pypots
2024-05-25 04:18:09 [INFO]: Epoch 022 - training loss: 0.1525, validation loss: 0.1341
2024-05-25 04:18:09 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch22_loss0.13408984914422034.pypots
2024-05-25 04:18:26 [INFO]: Epoch 023 - training loss: 0.1396, validation loss: 0.1441
2024-05-25 04:18:26 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch23_loss0.14413466155529023.pypots
2024-05-25 04:18:43 [INFO]: Epoch 024 - training loss: 0.1527, validation loss: 0.1464
2024-05-25 04:18:43 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch24_loss0.14644671678543092.pypots
2024-05-25 04:18:59 [INFO]: Epoch 025 - training loss: 0.1659, validation loss: 0.1361
2024-05-25 04:18:59 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch25_loss0.13608433231711387.pypots
2024-05-25 04:19:16 [INFO]: Epoch 026 - training loss: 0.1463, validation loss: 0.1332
2024-05-25 04:19:16 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch26_loss0.1331854946911335.pypots
2024-05-25 04:19:33 [INFO]: Epoch 027 - training loss: 0.1581, validation loss: 0.1339
2024-05-25 04:19:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch27_loss0.13387570157647133.pypots
2024-05-25 04:19:50 [INFO]: Epoch 028 - training loss: 0.1410, validation loss: 0.1294
2024-05-25 04:19:50 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch28_loss0.12938246205449105.pypots
2024-05-25 04:20:07 [INFO]: Epoch 029 - training loss: 0.1235, validation loss: 0.1276
2024-05-25 04:20:07 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch29_loss0.1276412509381771.pypots
2024-05-25 04:20:23 [INFO]: Epoch 030 - training loss: 0.1490, validation loss: 0.1304
2024-05-25 04:20:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch30_loss0.1304206907749176.pypots
2024-05-25 04:20:40 [INFO]: Epoch 031 - training loss: 0.1310, validation loss: 0.1281
2024-05-25 04:20:40 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch31_loss0.12805743217468263.pypots
2024-05-25 04:20:57 [INFO]: Epoch 032 - training loss: 0.1372, validation loss: 0.1286
2024-05-25 04:20:57 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch32_loss0.1285819262266159.pypots
2024-05-25 04:21:14 [INFO]: Epoch 033 - training loss: 0.1392, validation loss: 0.1258
2024-05-25 04:21:14 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch33_loss0.12578258961439132.pypots
2024-05-25 04:21:31 [INFO]: Epoch 034 - training loss: 0.1321, validation loss: 0.1262
2024-05-25 04:21:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch34_loss0.12616033852100372.pypots
2024-05-25 04:21:48 [INFO]: Epoch 035 - training loss: 0.1392, validation loss: 0.1287
2024-05-25 04:21:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch35_loss0.12866339311003686.pypots
2024-05-25 04:22:04 [INFO]: Epoch 036 - training loss: 0.1388, validation loss: 0.1221
2024-05-25 04:22:04 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch36_loss0.12211515605449677.pypots
2024-05-25 04:22:21 [INFO]: Epoch 037 - training loss: 0.1285, validation loss: 0.1262
2024-05-25 04:22:21 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch37_loss0.12618664652109146.pypots
2024-05-25 04:22:38 [INFO]: Epoch 038 - training loss: 0.1584, validation loss: 0.1249
2024-05-25 04:22:38 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch38_loss0.12487772479653358.pypots
2024-05-25 04:22:55 [INFO]: Epoch 039 - training loss: 0.1223, validation loss: 0.1211
2024-05-25 04:22:55 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch39_loss0.1210538886487484.pypots
2024-05-25 04:23:12 [INFO]: Epoch 040 - training loss: 0.1342, validation loss: 0.1209
2024-05-25 04:23:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch40_loss0.12091276198625564.pypots
2024-05-25 04:23:28 [INFO]: Epoch 041 - training loss: 0.1388, validation loss: 0.1207
2024-05-25 04:23:28 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch41_loss0.12069654166698456.pypots
2024-05-25 04:23:45 [INFO]: Epoch 042 - training loss: 0.1281, validation loss: 0.1302
2024-05-25 04:23:45 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch42_loss0.13017495349049568.pypots
2024-05-25 04:24:02 [INFO]: Epoch 043 - training loss: 0.1285, validation loss: 0.1248
2024-05-25 04:24:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch43_loss0.12478784024715424.pypots
2024-05-25 04:24:19 [INFO]: Epoch 044 - training loss: 0.1233, validation loss: 0.1212
2024-05-25 04:24:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch44_loss0.1211975246667862.pypots
2024-05-25 04:24:36 [INFO]: Epoch 045 - training loss: 0.1347, validation loss: 0.1218
2024-05-25 04:24:36 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch45_loss0.12181023955345154.pypots
2024-05-25 04:24:52 [INFO]: Epoch 046 - training loss: 0.1316, validation loss: 0.1247
2024-05-25 04:24:52 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch46_loss0.1247353158891201.pypots
2024-05-25 04:25:09 [INFO]: Epoch 047 - training loss: 0.1426, validation loss: 0.1195
2024-05-25 04:25:09 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch47_loss0.11950651183724403.pypots
2024-05-25 04:25:26 [INFO]: Epoch 048 - training loss: 0.1188, validation loss: 0.1188
2024-05-25 04:25:26 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch48_loss0.11883685365319252.pypots
2024-05-25 04:25:43 [INFO]: Epoch 049 - training loss: 0.1316, validation loss: 0.1160
2024-05-25 04:25:43 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch49_loss0.11598311439156532.pypots
2024-05-25 04:26:00 [INFO]: Epoch 050 - training loss: 0.1284, validation loss: 0.1155
2024-05-25 04:26:00 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch50_loss0.11547554656863213.pypots
2024-05-25 04:26:17 [INFO]: Epoch 051 - training loss: 0.1435, validation loss: 0.1153
2024-05-25 04:26:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch51_loss0.11534378081560134.pypots
2024-05-25 04:26:33 [INFO]: Epoch 052 - training loss: 0.1250, validation loss: 0.1168
2024-05-25 04:26:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch52_loss0.11681545227766037.pypots
2024-05-25 04:26:50 [INFO]: Epoch 053 - training loss: 0.1205, validation loss: 0.1162
2024-05-25 04:26:50 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch53_loss0.11624284386634827.pypots
2024-05-25 04:27:07 [INFO]: Epoch 054 - training loss: 0.1238, validation loss: 0.1157
2024-05-25 04:27:07 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch54_loss0.1157374620437622.pypots
2024-05-25 04:27:24 [INFO]: Epoch 055 - training loss: 0.1170, validation loss: 0.1135
2024-05-25 04:27:24 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch55_loss0.11347363367676735.pypots
2024-05-25 04:27:41 [INFO]: Epoch 056 - training loss: 0.1093, validation loss: 0.1142
2024-05-25 04:27:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch56_loss0.1142214633524418.pypots
2024-05-25 04:27:57 [INFO]: Epoch 057 - training loss: 0.1137, validation loss: 0.1116
2024-05-25 04:27:57 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch57_loss0.11160336583852767.pypots
2024-05-25 04:28:14 [INFO]: Epoch 058 - training loss: 0.1281, validation loss: 0.1157
2024-05-25 04:28:14 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch58_loss0.1157245010137558.pypots
2024-05-25 04:28:31 [INFO]: Epoch 059 - training loss: 0.1181, validation loss: 0.1165
2024-05-25 04:28:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch59_loss0.11645214036107063.pypots
2024-05-25 04:28:48 [INFO]: Epoch 060 - training loss: 0.1390, validation loss: 0.1207
2024-05-25 04:28:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch60_loss0.12068302407860756.pypots
2024-05-25 04:29:05 [INFO]: Epoch 061 - training loss: 0.1176, validation loss: 0.1116
2024-05-25 04:29:05 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch61_loss0.1115830697119236.pypots
2024-05-25 04:29:21 [INFO]: Epoch 062 - training loss: 0.1201, validation loss: 0.1155
2024-05-25 04:29:21 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch62_loss0.11549201160669327.pypots
2024-05-25 04:29:38 [INFO]: Epoch 063 - training loss: 0.1227, validation loss: 0.1119
2024-05-25 04:29:38 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch63_loss0.11186709180474282.pypots
2024-05-25 04:29:55 [INFO]: Epoch 064 - training loss: 0.1074, validation loss: 0.1122
2024-05-25 04:29:55 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch64_loss0.11219229847192765.pypots
2024-05-25 04:30:12 [INFO]: Epoch 065 - training loss: 0.1149, validation loss: 0.1127
2024-05-25 04:30:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch65_loss0.11267179623246193.pypots
2024-05-25 04:30:29 [INFO]: Epoch 066 - training loss: 0.1293, validation loss: 0.1133
2024-05-25 04:30:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch66_loss0.1132869228720665.pypots
2024-05-25 04:30:45 [INFO]: Epoch 067 - training loss: 0.1262, validation loss: 0.1138
2024-05-25 04:30:45 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch67_loss0.11381330490112304.pypots
2024-05-25 04:31:02 [INFO]: Epoch 068 - training loss: 0.1205, validation loss: 0.1124
2024-05-25 04:31:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch68_loss0.11241410896182061.pypots
2024-05-25 04:31:19 [INFO]: Epoch 069 - training loss: 0.1221, validation loss: 0.1111
2024-05-25 04:31:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch69_loss0.11107692196965217.pypots
2024-05-25 04:31:36 [INFO]: Epoch 070 - training loss: 0.1165, validation loss: 0.1146
2024-05-25 04:31:36 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch70_loss0.11459173709154129.pypots
2024-05-25 04:31:53 [INFO]: Epoch 071 - training loss: 0.1272, validation loss: 0.1108
2024-05-25 04:31:53 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch71_loss0.11081184521317482.pypots
2024-05-25 04:32:09 [INFO]: Epoch 072 - training loss: 0.1206, validation loss: 0.1107
2024-05-25 04:32:09 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch72_loss0.1107348419725895.pypots
2024-05-25 04:32:26 [INFO]: Epoch 073 - training loss: 0.1169, validation loss: 0.1123
2024-05-25 04:32:26 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch73_loss0.11225760355591774.pypots
2024-05-25 04:32:43 [INFO]: Epoch 074 - training loss: 0.1210, validation loss: 0.1107
2024-05-25 04:32:43 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch74_loss0.11066723838448525.pypots
2024-05-25 04:33:00 [INFO]: Epoch 075 - training loss: 0.1295, validation loss: 0.1084
2024-05-25 04:33:00 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch75_loss0.10842465758323669.pypots
2024-05-25 04:33:17 [INFO]: Epoch 076 - training loss: 0.1230, validation loss: 0.1100
2024-05-25 04:33:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch76_loss0.11003393903374672.pypots
2024-05-25 04:33:33 [INFO]: Epoch 077 - training loss: 0.1271, validation loss: 0.1139
2024-05-25 04:33:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch77_loss0.11392282620072365.pypots
2024-05-25 04:33:50 [INFO]: Epoch 078 - training loss: 0.1198, validation loss: 0.1093
2024-05-25 04:33:50 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch78_loss0.10932009071111679.pypots
2024-05-25 04:34:07 [INFO]: Epoch 079 - training loss: 0.1233, validation loss: 0.1094
2024-05-25 04:34:07 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch79_loss0.1094386950135231.pypots
2024-05-25 04:34:24 [INFO]: Epoch 080 - training loss: 0.1463, validation loss: 0.1099
2024-05-25 04:34:24 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch80_loss0.10986728221178055.pypots
2024-05-25 04:34:41 [INFO]: Epoch 081 - training loss: 0.1222, validation loss: 0.1096
2024-05-25 04:34:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch81_loss0.10958856791257858.pypots
2024-05-25 04:34:57 [INFO]: Epoch 082 - training loss: 0.1084, validation loss: 0.1103
2024-05-25 04:34:57 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch82_loss0.11026394963264466.pypots
2024-05-25 04:35:14 [INFO]: Epoch 083 - training loss: 0.1148, validation loss: 0.1072
2024-05-25 04:35:14 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch83_loss0.10720196440815925.pypots
2024-05-25 04:35:31 [INFO]: Epoch 084 - training loss: 0.1104, validation loss: 0.1125
2024-05-25 04:35:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch84_loss0.11254169046878815.pypots
2024-05-25 04:35:48 [INFO]: Epoch 085 - training loss: 0.1312, validation loss: 0.1089
2024-05-25 04:35:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch85_loss0.10889236629009247.pypots
2024-05-25 04:36:05 [INFO]: Epoch 086 - training loss: 0.1077, validation loss: 0.1106
2024-05-25 04:36:05 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch86_loss0.11057290136814117.pypots
2024-05-25 04:36:22 [INFO]: Epoch 087 - training loss: 0.1244, validation loss: 0.1085
2024-05-25 04:36:22 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch87_loss0.10852633118629455.pypots
2024-05-25 04:36:38 [INFO]: Epoch 088 - training loss: 0.1276, validation loss: 0.1098
2024-05-25 04:36:38 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch88_loss0.10982367470860481.pypots
2024-05-25 04:36:55 [INFO]: Epoch 089 - training loss: 0.1199, validation loss: 0.1089
2024-05-25 04:36:55 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch89_loss0.10891327559947968.pypots
2024-05-25 04:37:12 [INFO]: Epoch 090 - training loss: 0.1200, validation loss: 0.1087
2024-05-25 04:37:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch90_loss0.10873925164341927.pypots
2024-05-25 04:37:29 [INFO]: Epoch 091 - training loss: 0.1107, validation loss: 0.1071
2024-05-25 04:37:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch91_loss0.10711454302072525.pypots
2024-05-25 04:37:46 [INFO]: Epoch 092 - training loss: 0.1111, validation loss: 0.1116
2024-05-25 04:37:46 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch92_loss0.11158545538783074.pypots
2024-05-25 04:38:02 [INFO]: Epoch 093 - training loss: 0.1278, validation loss: 0.1081
2024-05-25 04:38:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch93_loss0.10808440521359444.pypots
2024-05-25 04:38:19 [INFO]: Epoch 094 - training loss: 0.1145, validation loss: 0.1103
2024-05-25 04:38:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch94_loss0.11028342843055725.pypots
2024-05-25 04:38:36 [INFO]: Epoch 095 - training loss: 0.1081, validation loss: 0.1077
2024-05-25 04:38:36 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch95_loss0.1076578252017498.pypots
2024-05-25 04:38:53 [INFO]: Epoch 096 - training loss: 0.1237, validation loss: 0.1069
2024-05-25 04:38:53 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch96_loss0.10691418424248696.pypots
2024-05-25 04:39:10 [INFO]: Epoch 097 - training loss: 0.1307, validation loss: 0.1067
2024-05-25 04:39:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch97_loss0.10665013566613198.pypots
2024-05-25 04:39:26 [INFO]: Epoch 098 - training loss: 0.1111, validation loss: 0.1081
2024-05-25 04:39:26 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch98_loss0.1080512210726738.pypots
2024-05-25 04:39:43 [INFO]: Epoch 099 - training loss: 0.1313, validation loss: 0.1080
2024-05-25 04:39:43 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch99_loss0.10804664194583893.pypots
2024-05-25 04:40:00 [INFO]: Epoch 100 - training loss: 0.1259, validation loss: 0.1061
2024-05-25 04:40:00 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch100_loss0.10610371008515358.pypots
2024-05-25 04:40:17 [INFO]: Epoch 101 - training loss: 0.1020, validation loss: 0.1070
2024-05-25 04:40:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch101_loss0.10697774514555931.pypots
2024-05-25 04:40:34 [INFO]: Epoch 102 - training loss: 0.1120, validation loss: 0.1074
2024-05-25 04:40:34 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch102_loss0.10742745846509934.pypots
2024-05-25 04:40:50 [INFO]: Epoch 103 - training loss: 0.1216, validation loss: 0.1087
2024-05-25 04:40:50 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch103_loss0.10866880416870117.pypots
2024-05-25 04:41:07 [INFO]: Epoch 104 - training loss: 0.1249, validation loss: 0.1120
2024-05-25 04:41:07 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch104_loss0.11197197064757347.pypots
2024-05-25 04:41:24 [INFO]: Epoch 105 - training loss: 0.1136, validation loss: 0.1087
2024-05-25 04:41:24 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch105_loss0.10870349258184434.pypots
2024-05-25 04:41:41 [INFO]: Epoch 106 - training loss: 0.1029, validation loss: 0.1086
2024-05-25 04:41:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch106_loss0.10858171507716179.pypots
2024-05-25 04:41:58 [INFO]: Epoch 107 - training loss: 0.1151, validation loss: 0.1069
2024-05-25 04:41:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch107_loss0.1069350704550743.pypots
2024-05-25 04:42:15 [INFO]: Epoch 108 - training loss: 0.1035, validation loss: 0.1053
2024-05-25 04:42:15 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch108_loss0.10528221800923347.pypots
2024-05-25 04:42:31 [INFO]: Epoch 109 - training loss: 0.1210, validation loss: 0.1054
2024-05-25 04:42:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch109_loss0.10537204593420028.pypots
2024-05-25 04:42:48 [INFO]: Epoch 110 - training loss: 0.1153, validation loss: 0.1061
2024-05-25 04:42:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch110_loss0.1060556374490261.pypots
2024-05-25 04:43:05 [INFO]: Epoch 111 - training loss: 0.1064, validation loss: 0.1045
2024-05-25 04:43:05 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch111_loss0.10453495383262634.pypots
2024-05-25 04:43:22 [INFO]: Epoch 112 - training loss: 0.1067, validation loss: 0.1065
2024-05-25 04:43:22 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch112_loss0.10652308762073517.pypots
2024-05-25 04:43:39 [INFO]: Epoch 113 - training loss: 0.1141, validation loss: 0.1056
2024-05-25 04:43:39 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch113_loss0.10562585517764092.pypots
2024-05-25 04:43:55 [INFO]: Epoch 114 - training loss: 0.1079, validation loss: 0.1066
2024-05-25 04:43:55 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch114_loss0.10662601441144944.pypots
2024-05-25 04:44:12 [INFO]: Epoch 115 - training loss: 0.1102, validation loss: 0.1049
2024-05-25 04:44:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch115_loss0.10487821996212006.pypots
2024-05-25 04:44:29 [INFO]: Epoch 116 - training loss: 0.1103, validation loss: 0.1038
2024-05-25 04:44:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch116_loss0.10381548255681991.pypots
2024-05-25 04:44:46 [INFO]: Epoch 117 - training loss: 0.1029, validation loss: 0.1038
2024-05-25 04:44:46 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch117_loss0.1038003109395504.pypots
2024-05-25 04:45:03 [INFO]: Epoch 118 - training loss: 0.1144, validation loss: 0.1048
2024-05-25 04:45:03 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch118_loss0.10476830378174781.pypots
2024-05-25 04:45:19 [INFO]: Epoch 119 - training loss: 0.1074, validation loss: 0.1039
2024-05-25 04:45:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch119_loss0.1039299100637436.pypots
2024-05-25 04:45:36 [INFO]: Epoch 120 - training loss: 0.1080, validation loss: 0.1037
2024-05-25 04:45:36 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch120_loss0.10373867750167846.pypots
2024-05-25 04:45:53 [INFO]: Epoch 121 - training loss: 0.1254, validation loss: 0.1069
2024-05-25 04:45:53 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch121_loss0.10691758543252945.pypots
2024-05-25 04:46:10 [INFO]: Epoch 122 - training loss: 0.1069, validation loss: 0.1032
2024-05-25 04:46:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch122_loss0.10319581031799316.pypots
2024-05-25 04:46:27 [INFO]: Epoch 123 - training loss: 0.1167, validation loss: 0.1045
2024-05-25 04:46:27 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch123_loss0.10452957078814507.pypots
2024-05-25 04:46:43 [INFO]: Epoch 124 - training loss: 0.1152, validation loss: 0.1031
2024-05-25 04:46:43 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch124_loss0.10305135846138.pypots
2024-05-25 04:47:00 [INFO]: Epoch 125 - training loss: 0.1107, validation loss: 0.1024
2024-05-25 04:47:00 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch125_loss0.10236012786626816.pypots
2024-05-25 04:47:17 [INFO]: Epoch 126 - training loss: 0.1092, validation loss: 0.1061
2024-05-25 04:47:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch126_loss0.10607714504003525.pypots
2024-05-25 04:47:34 [INFO]: Epoch 127 - training loss: 0.1054, validation loss: 0.1035
2024-05-25 04:47:34 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch127_loss0.10347776636481285.pypots
2024-05-25 04:47:51 [INFO]: Epoch 128 - training loss: 0.1126, validation loss: 0.1047
2024-05-25 04:47:51 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch128_loss0.10474715083837509.pypots
2024-05-25 04:48:08 [INFO]: Epoch 129 - training loss: 0.1316, validation loss: 0.1036
2024-05-25 04:48:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch129_loss0.10355644524097443.pypots
2024-05-25 04:48:24 [INFO]: Epoch 130 - training loss: 0.1058, validation loss: 0.1060
2024-05-25 04:48:24 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch130_loss0.10595432221889496.pypots
2024-05-25 04:48:41 [INFO]: Epoch 131 - training loss: 0.1156, validation loss: 0.1051
2024-05-25 04:48:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch131_loss0.10507873669266701.pypots
2024-05-25 04:48:58 [INFO]: Epoch 132 - training loss: 0.1093, validation loss: 0.1021
2024-05-25 04:48:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch132_loss0.10212943851947784.pypots
2024-05-25 04:49:15 [INFO]: Epoch 133 - training loss: 0.1162, validation loss: 0.1016
2024-05-25 04:49:15 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch133_loss0.1016440212726593.pypots
2024-05-25 04:49:32 [INFO]: Epoch 134 - training loss: 0.1103, validation loss: 0.1024
2024-05-25 04:49:32 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch134_loss0.10236521810293198.pypots
2024-05-25 04:49:48 [INFO]: Epoch 135 - training loss: 0.1107, validation loss: 0.1015
2024-05-25 04:49:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch135_loss0.10145949199795723.pypots
2024-05-25 04:50:05 [INFO]: Epoch 136 - training loss: 0.1241, validation loss: 0.1018
2024-05-25 04:50:05 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch136_loss0.10180911049246788.pypots
2024-05-25 04:50:22 [INFO]: Epoch 137 - training loss: 0.1102, validation loss: 0.1014
2024-05-25 04:50:22 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch137_loss0.10140513703227043.pypots
2024-05-25 04:50:39 [INFO]: Epoch 138 - training loss: 0.1060, validation loss: 0.1018
2024-05-25 04:50:39 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch138_loss0.1018463172018528.pypots
2024-05-25 04:50:56 [INFO]: Epoch 139 - training loss: 0.1103, validation loss: 0.1041
2024-05-25 04:50:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch139_loss0.10412165895104408.pypots
2024-05-25 04:51:12 [INFO]: Epoch 140 - training loss: 0.1181, validation loss: 0.1020
2024-05-25 04:51:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch140_loss0.10198952481150628.pypots
2024-05-25 04:51:29 [INFO]: Epoch 141 - training loss: 0.1186, validation loss: 0.1034
2024-05-25 04:51:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch141_loss0.10340836644172668.pypots
2024-05-25 04:51:46 [INFO]: Epoch 142 - training loss: 0.1202, validation loss: 0.1024
2024-05-25 04:51:46 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch142_loss0.10237687900662422.pypots
2024-05-25 04:52:03 [INFO]: Epoch 143 - training loss: 0.1100, validation loss: 0.1027
2024-05-25 04:52:03 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch143_loss0.102660171687603.pypots
2024-05-25 04:52:20 [INFO]: Epoch 144 - training loss: 0.1149, validation loss: 0.1011
2024-05-25 04:52:20 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch144_loss0.10108127743005753.pypots
2024-05-25 04:52:36 [INFO]: Epoch 145 - training loss: 0.1131, validation loss: 0.1013
2024-05-25 04:52:36 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch145_loss0.10131147876381874.pypots
2024-05-25 04:52:53 [INFO]: Epoch 146 - training loss: 0.1118, validation loss: 0.1008
2024-05-25 04:52:53 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch146_loss0.100809046626091.pypots
2024-05-25 04:53:10 [INFO]: Epoch 147 - training loss: 0.1028, validation loss: 0.1015
2024-05-25 04:53:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch147_loss0.10148965865373612.pypots
2024-05-25 04:53:27 [INFO]: Epoch 148 - training loss: 0.1100, validation loss: 0.1016
2024-05-25 04:53:27 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch148_loss0.10159630551934243.pypots
2024-05-25 04:53:44 [INFO]: Epoch 149 - training loss: 0.1118, validation loss: 0.1044
2024-05-25 04:53:44 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch149_loss0.10442128032445908.pypots
2024-05-25 04:54:00 [INFO]: Epoch 150 - training loss: 0.1086, validation loss: 0.1008
2024-05-25 04:54:00 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch150_loss0.100790486484766.pypots
2024-05-25 04:54:17 [INFO]: Epoch 151 - training loss: 0.1083, validation loss: 0.0997
2024-05-25 04:54:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch151_loss0.09966504573822021.pypots
2024-05-25 04:54:34 [INFO]: Epoch 152 - training loss: 0.1139, validation loss: 0.1018
2024-05-25 04:54:34 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch152_loss0.1017592616379261.pypots
2024-05-25 04:54:51 [INFO]: Epoch 153 - training loss: 0.1231, validation loss: 0.1080
2024-05-25 04:54:51 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch153_loss0.10800918117165566.pypots
2024-05-25 04:55:08 [INFO]: Epoch 154 - training loss: 0.1028, validation loss: 0.1003
2024-05-25 04:55:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch154_loss0.10029294863343238.pypots
2024-05-25 04:55:25 [INFO]: Epoch 155 - training loss: 0.1155, validation loss: 0.1019
2024-05-25 04:55:25 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch155_loss0.1019030749797821.pypots
2024-05-25 04:55:41 [INFO]: Epoch 156 - training loss: 0.1054, validation loss: 0.0993
2024-05-25 04:55:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch156_loss0.09930264577269554.pypots
2024-05-25 04:55:58 [INFO]: Epoch 157 - training loss: 0.1088, validation loss: 0.1026
2024-05-25 04:55:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch157_loss0.10255897268652917.pypots
2024-05-25 04:56:15 [INFO]: Epoch 158 - training loss: 0.1036, validation loss: 0.1025
2024-05-25 04:56:15 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch158_loss0.10253117755055427.pypots
2024-05-25 04:56:32 [INFO]: Epoch 159 - training loss: 0.1153, validation loss: 0.1016
2024-05-25 04:56:32 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch159_loss0.10157746225595474.pypots
2024-05-25 04:56:49 [INFO]: Epoch 160 - training loss: 0.1182, validation loss: 0.1000
2024-05-25 04:56:49 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch160_loss0.09995860904455185.pypots
2024-05-25 04:57:05 [INFO]: Epoch 161 - training loss: 0.1155, validation loss: 0.1002
2024-05-25 04:57:05 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch161_loss0.1001945212483406.pypots
2024-05-25 04:57:22 [INFO]: Epoch 162 - training loss: 0.1151, validation loss: 0.1003
2024-05-25 04:57:22 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch162_loss0.100324746966362.pypots
2024-05-25 04:57:39 [INFO]: Epoch 163 - training loss: 0.1098, validation loss: 0.1031
2024-05-25 04:57:39 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch163_loss0.10305044651031495.pypots
2024-05-25 04:57:56 [INFO]: Epoch 164 - training loss: 0.0944, validation loss: 0.0994
2024-05-25 04:57:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch164_loss0.09942074194550514.pypots
2024-05-25 04:58:13 [INFO]: Epoch 165 - training loss: 0.1143, validation loss: 0.0987
2024-05-25 04:58:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch165_loss0.0986778974533081.pypots
2024-05-25 04:58:29 [INFO]: Epoch 166 - training loss: 0.1043, validation loss: 0.1027
2024-05-25 04:58:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch166_loss0.10270316451787949.pypots
2024-05-25 04:58:46 [INFO]: Epoch 167 - training loss: 0.1056, validation loss: 0.1004
2024-05-25 04:58:46 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch167_loss0.10043751671910287.pypots
2024-05-25 04:59:03 [INFO]: Epoch 168 - training loss: 0.1128, validation loss: 0.1005
2024-05-25 04:59:03 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch168_loss0.10053445398807526.pypots
2024-05-25 04:59:20 [INFO]: Epoch 169 - training loss: 0.0985, validation loss: 0.0978
2024-05-25 04:59:20 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch169_loss0.09776566699147224.pypots
2024-05-25 04:59:37 [INFO]: Epoch 170 - training loss: 0.1138, validation loss: 0.0997
2024-05-25 04:59:37 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch170_loss0.09966337829828262.pypots
2024-05-25 04:59:53 [INFO]: Epoch 171 - training loss: 0.1205, validation loss: 0.0995
2024-05-25 04:59:53 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch171_loss0.09949687644839286.pypots
2024-05-25 05:00:10 [INFO]: Epoch 172 - training loss: 0.1040, validation loss: 0.1001
2024-05-25 05:00:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch172_loss0.10005586594343185.pypots
2024-05-25 05:00:27 [INFO]: Epoch 173 - training loss: 0.1082, validation loss: 0.1008
2024-05-25 05:00:27 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch173_loss0.10079981312155724.pypots
2024-05-25 05:00:44 [INFO]: Epoch 174 - training loss: 0.1039, validation loss: 0.0995
2024-05-25 05:00:44 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch174_loss0.09948488101363182.pypots
2024-05-25 05:01:01 [INFO]: Epoch 175 - training loss: 0.1073, validation loss: 0.0991
2024-05-25 05:01:01 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch175_loss0.09914880990982056.pypots
2024-05-25 05:01:17 [INFO]: Epoch 176 - training loss: 0.1172, validation loss: 0.1030
2024-05-25 05:01:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch176_loss0.10298964604735375.pypots
2024-05-25 05:01:34 [INFO]: Epoch 177 - training loss: 0.1088, validation loss: 0.1018
2024-05-25 05:01:34 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch177_loss0.10175976604223251.pypots
2024-05-25 05:01:51 [INFO]: Epoch 178 - training loss: 0.1109, validation loss: 0.0991
2024-05-25 05:01:51 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch178_loss0.0990973062813282.pypots
2024-05-25 05:02:08 [INFO]: Epoch 179 - training loss: 0.1022, validation loss: 0.1015
2024-05-25 05:02:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI_epoch179_loss0.10147047117352485.pypots
2024-05-25 05:02:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:02:08 [INFO]: Finished training. The best model is from epoch#169.
2024-05-25 05:02:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240525_T041159/CSDI.pypots
2024-05-25 05:04:28 [INFO]: CSDI on Air-Quality: MAE=0.1046, MSE=0.2099
2024-05-25 05:04:28 [INFO]: Successfully saved to augmentation_saved_results/round_3/CSDI_air_quality/imputation.pkl
2024-05-25 05:04:28 [INFO]: Using the given device: cuda:0
2024-05-25 05:04:28 [INFO]: Model files will be saved to augmentation_saved_results/round_3/GPVAE_air_quality/20240525_T050428
2024-05-25 05:04:28 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/GPVAE_air_quality/20240525_T050428/tensorboard
2024-05-25 05:04:28 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 05:04:28 [INFO]: Epoch 001 - training loss: 63133.8222, validation loss: 0.7261
2024-05-25 05:04:29 [INFO]: Epoch 002 - training loss: 42045.6481, validation loss: 0.5900
2024-05-25 05:04:29 [INFO]: Epoch 003 - training loss: 41754.1986, validation loss: 0.5678
2024-05-25 05:04:29 [INFO]: Epoch 004 - training loss: 41629.2747, validation loss: 0.5065
2024-05-25 05:04:30 [INFO]: Epoch 005 - training loss: 41560.5346, validation loss: 0.4731
2024-05-25 05:04:30 [INFO]: Epoch 006 - training loss: 41502.1124, validation loss: 0.4385
2024-05-25 05:04:30 [INFO]: Epoch 007 - training loss: 41460.8597, validation loss: 0.4010
2024-05-25 05:04:31 [INFO]: Epoch 008 - training loss: 41426.0762, validation loss: 0.3765
2024-05-25 05:04:31 [INFO]: Epoch 009 - training loss: 41374.4728, validation loss: 0.3590
2024-05-25 05:04:31 [INFO]: Epoch 010 - training loss: 41359.6826, validation loss: 0.3415
2024-05-25 05:04:32 [INFO]: Epoch 011 - training loss: 41363.0940, validation loss: 0.3595
2024-05-25 05:04:32 [INFO]: Epoch 012 - training loss: 41341.5644, validation loss: 0.3528
2024-05-25 05:04:32 [INFO]: Epoch 013 - training loss: 41325.8145, validation loss: 0.3331
2024-05-25 05:04:33 [INFO]: Epoch 014 - training loss: 41319.0605, validation loss: 0.3496
2024-05-25 05:04:33 [INFO]: Epoch 015 - training loss: 41343.8397, validation loss: 0.3254
2024-05-25 05:04:33 [INFO]: Epoch 016 - training loss: 41351.8650, validation loss: 0.3392
2024-05-25 05:04:34 [INFO]: Epoch 017 - training loss: 41331.3451, validation loss: 0.3337
2024-05-25 05:04:34 [INFO]: Epoch 018 - training loss: 41303.7720, validation loss: 0.3065
2024-05-25 05:04:34 [INFO]: Epoch 019 - training loss: 41267.3206, validation loss: 0.3413
2024-05-25 05:04:35 [INFO]: Epoch 020 - training loss: 41266.8393, validation loss: 0.3797
2024-05-25 05:04:35 [INFO]: Epoch 021 - training loss: 41268.7846, validation loss: 0.2955
2024-05-25 05:04:35 [INFO]: Epoch 022 - training loss: 41264.8142, validation loss: 0.3192
2024-05-25 05:04:36 [INFO]: Epoch 023 - training loss: 41246.3995, validation loss: 0.3038
2024-05-25 05:04:36 [INFO]: Epoch 024 - training loss: 41233.5009, validation loss: 0.2854
2024-05-25 05:04:36 [INFO]: Epoch 025 - training loss: 41223.5910, validation loss: 0.2863
2024-05-25 05:04:36 [INFO]: Epoch 026 - training loss: 41223.5498, validation loss: 0.2912
2024-05-25 05:04:37 [INFO]: Epoch 027 - training loss: 41223.5302, validation loss: 0.2834
2024-05-25 05:04:37 [INFO]: Epoch 028 - training loss: 41216.4107, validation loss: 0.2868
2024-05-25 05:04:37 [INFO]: Epoch 029 - training loss: 41227.8209, validation loss: 0.2946
2024-05-25 05:04:38 [INFO]: Epoch 030 - training loss: 41218.2387, validation loss: 0.2953
2024-05-25 05:04:38 [INFO]: Epoch 031 - training loss: 41215.8270, validation loss: 0.2799
2024-05-25 05:04:38 [INFO]: Epoch 032 - training loss: 41210.7092, validation loss: 0.3048
2024-05-25 05:04:39 [INFO]: Epoch 033 - training loss: 41266.4554, validation loss: 0.2914
2024-05-25 05:04:39 [INFO]: Epoch 034 - training loss: 41255.7587, validation loss: 0.2824
2024-05-25 05:04:39 [INFO]: Epoch 035 - training loss: 41232.9359, validation loss: 0.2956
2024-05-25 05:04:40 [INFO]: Epoch 036 - training loss: 41208.9343, validation loss: 0.2896
2024-05-25 05:04:40 [INFO]: Epoch 037 - training loss: 41216.0081, validation loss: 0.2787
2024-05-25 05:04:40 [INFO]: Epoch 038 - training loss: 41191.4421, validation loss: 0.2731
2024-05-25 05:04:41 [INFO]: Epoch 039 - training loss: 41188.1638, validation loss: 0.2673
2024-05-25 05:04:41 [INFO]: Epoch 040 - training loss: 41190.6633, validation loss: 0.2686
2024-05-25 05:04:41 [INFO]: Epoch 041 - training loss: 41188.8511, validation loss: 0.2795
2024-05-25 05:04:42 [INFO]: Epoch 042 - training loss: 41186.9368, validation loss: 0.2631
2024-05-25 05:04:42 [INFO]: Epoch 043 - training loss: 41189.1170, validation loss: 0.2770
2024-05-25 05:04:42 [INFO]: Epoch 044 - training loss: 41212.3255, validation loss: 0.2918
2024-05-25 05:04:43 [INFO]: Epoch 045 - training loss: 41202.8098, validation loss: 0.2787
2024-05-25 05:04:43 [INFO]: Epoch 046 - training loss: 41218.1918, validation loss: 0.2585
2024-05-25 05:04:43 [INFO]: Epoch 047 - training loss: 41256.2697, validation loss: 0.2800
2024-05-25 05:04:44 [INFO]: Epoch 048 - training loss: 41241.0968, validation loss: 0.2731
2024-05-25 05:04:44 [INFO]: Epoch 049 - training loss: 41216.6981, validation loss: 0.2759
2024-05-25 05:04:44 [INFO]: Epoch 050 - training loss: 41178.9838, validation loss: 0.2694
2024-05-25 05:04:45 [INFO]: Epoch 051 - training loss: 41181.6207, validation loss: 0.2612
2024-05-25 05:04:45 [INFO]: Epoch 052 - training loss: 41172.9291, validation loss: 0.3010
2024-05-25 05:04:45 [INFO]: Epoch 053 - training loss: 41169.6957, validation loss: 0.2565
2024-05-25 05:04:46 [INFO]: Epoch 054 - training loss: 41163.8958, validation loss: 0.2725
2024-05-25 05:04:46 [INFO]: Epoch 055 - training loss: 41170.5221, validation loss: 0.2592
2024-05-25 05:04:46 [INFO]: Epoch 056 - training loss: 41159.8821, validation loss: 0.2682
2024-05-25 05:04:46 [INFO]: Epoch 057 - training loss: 41168.0123, validation loss: 0.2677
2024-05-25 05:04:47 [INFO]: Epoch 058 - training loss: 41176.3516, validation loss: 0.2939
2024-05-25 05:04:47 [INFO]: Epoch 059 - training loss: 41185.5479, validation loss: 0.2766
2024-05-25 05:04:47 [INFO]: Epoch 060 - training loss: 41193.3584, validation loss: 0.2634
2024-05-25 05:04:48 [INFO]: Epoch 061 - training loss: 41163.6590, validation loss: 0.2560
2024-05-25 05:04:48 [INFO]: Epoch 062 - training loss: 41158.6139, validation loss: 0.2567
2024-05-25 05:04:48 [INFO]: Epoch 063 - training loss: 41152.4362, validation loss: 0.2529
2024-05-25 05:04:49 [INFO]: Epoch 064 - training loss: 41164.3137, validation loss: 0.2524
2024-05-25 05:04:49 [INFO]: Epoch 065 - training loss: 41162.5645, validation loss: 0.2713
2024-05-25 05:04:49 [INFO]: Epoch 066 - training loss: 41153.8546, validation loss: 0.2460
2024-05-25 05:04:50 [INFO]: Epoch 067 - training loss: 41150.2839, validation loss: 0.2693
2024-05-25 05:04:50 [INFO]: Epoch 068 - training loss: 41176.9065, validation loss: 0.2723
2024-05-25 05:04:50 [INFO]: Epoch 069 - training loss: 41170.7784, validation loss: 0.2671
2024-05-25 05:04:51 [INFO]: Epoch 070 - training loss: 41169.4851, validation loss: 0.2525
2024-05-25 05:04:51 [INFO]: Epoch 071 - training loss: 41145.5003, validation loss: 0.2489
2024-05-25 05:04:51 [INFO]: Epoch 072 - training loss: 41139.4026, validation loss: 0.2484
2024-05-25 05:04:52 [INFO]: Epoch 073 - training loss: 41138.2446, validation loss: 0.2595
2024-05-25 05:04:52 [INFO]: Epoch 074 - training loss: 41137.8465, validation loss: 0.2399
2024-05-25 05:04:52 [INFO]: Epoch 075 - training loss: 41137.5001, validation loss: 0.2493
2024-05-25 05:04:53 [INFO]: Epoch 076 - training loss: 41134.9421, validation loss: 0.2423
2024-05-25 05:04:53 [INFO]: Epoch 077 - training loss: 41133.0952, validation loss: 0.2528
2024-05-25 05:04:53 [INFO]: Epoch 078 - training loss: 41130.5563, validation loss: 0.2481
2024-05-25 05:04:54 [INFO]: Epoch 079 - training loss: 41126.1457, validation loss: 0.2551
2024-05-25 05:04:54 [INFO]: Epoch 080 - training loss: 41147.9993, validation loss: 0.2616
2024-05-25 05:04:54 [INFO]: Epoch 081 - training loss: 41144.3527, validation loss: 0.2491
2024-05-25 05:04:54 [INFO]: Epoch 082 - training loss: 41127.5263, validation loss: 0.2479
2024-05-25 05:04:55 [INFO]: Epoch 083 - training loss: 41142.4838, validation loss: 0.2446
2024-05-25 05:04:55 [INFO]: Epoch 084 - training loss: 41132.8809, validation loss: 0.2483
2024-05-25 05:04:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:04:55 [INFO]: Finished training. The best model is from epoch#74.
2024-05-25 05:04:55 [INFO]: Saved the model to augmentation_saved_results/round_3/GPVAE_air_quality/20240525_T050428/GPVAE.pypots
2024-05-25 05:04:55 [INFO]: GP-VAE on Air-Quality: MAE=0.2975, MSE=0.3163
2024-05-25 05:04:55 [INFO]: Successfully saved to augmentation_saved_results/round_3/GPVAE_air_quality/imputation.pkl
2024-05-25 05:04:55 [INFO]: Using the given device: cuda:0
2024-05-25 05:04:55 [INFO]: Model files will be saved to augmentation_saved_results/round_3/USGAN_air_quality/20240525_T050455
2024-05-25 05:04:55 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/USGAN_air_quality/20240525_T050455/tensorboard
2024-05-25 05:04:55 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 05:05:00 [INFO]: Epoch 001 - generator training loss: 0.6017, discriminator training loss: 0.2788, validation loss: 0.5221
2024-05-25 05:05:04 [INFO]: Epoch 002 - generator training loss: 0.2843, discriminator training loss: 0.0670, validation loss: 0.3952
2024-05-25 05:05:08 [INFO]: Epoch 003 - generator training loss: 0.2128, discriminator training loss: 0.0634, validation loss: 0.3301
2024-05-25 05:05:12 [INFO]: Epoch 004 - generator training loss: 0.1746, discriminator training loss: 0.0622, validation loss: 0.2899
2024-05-25 05:05:16 [INFO]: Epoch 005 - generator training loss: 0.1545, discriminator training loss: 0.0622, validation loss: 0.2618
2024-05-25 05:05:20 [INFO]: Epoch 006 - generator training loss: 0.1357, discriminator training loss: 0.0613, validation loss: 0.2436
2024-05-25 05:05:24 [INFO]: Epoch 007 - generator training loss: 0.1208, discriminator training loss: 0.0611, validation loss: 0.2292
2024-05-25 05:05:28 [INFO]: Epoch 008 - generator training loss: 0.1096, discriminator training loss: 0.0602, validation loss: 0.2178
2024-05-25 05:05:32 [INFO]: Epoch 009 - generator training loss: 0.1000, discriminator training loss: 0.0599, validation loss: 0.2092
2024-05-25 05:05:37 [INFO]: Epoch 010 - generator training loss: 0.0943, discriminator training loss: 0.0592, validation loss: 0.2017
2024-05-25 05:05:41 [INFO]: Epoch 011 - generator training loss: 0.0893, discriminator training loss: 0.0584, validation loss: 0.1957
2024-05-25 05:05:45 [INFO]: Epoch 012 - generator training loss: 0.0841, discriminator training loss: 0.0570, validation loss: 0.1910
2024-05-25 05:05:49 [INFO]: Epoch 013 - generator training loss: 0.0825, discriminator training loss: 0.0559, validation loss: 0.1872
2024-05-25 05:05:53 [INFO]: Epoch 014 - generator training loss: 0.0777, discriminator training loss: 0.0543, validation loss: 0.1832
2024-05-25 05:05:58 [INFO]: Epoch 015 - generator training loss: 0.0758, discriminator training loss: 0.0526, validation loss: 0.1796
2024-05-25 05:06:02 [INFO]: Epoch 016 - generator training loss: 0.0744, discriminator training loss: 0.0510, validation loss: 0.1770
2024-05-25 05:06:06 [INFO]: Epoch 017 - generator training loss: 0.0721, discriminator training loss: 0.0490, validation loss: 0.1739
2024-05-25 05:06:10 [INFO]: Epoch 018 - generator training loss: 0.0729, discriminator training loss: 0.0476, validation loss: 0.1716
2024-05-25 05:06:15 [INFO]: Epoch 019 - generator training loss: 0.0688, discriminator training loss: 0.0462, validation loss: 0.1698
2024-05-25 05:06:19 [INFO]: Epoch 020 - generator training loss: 0.0668, discriminator training loss: 0.0456, validation loss: 0.1678
2024-05-25 05:06:23 [INFO]: Epoch 021 - generator training loss: 0.0658, discriminator training loss: 0.0446, validation loss: 0.1653
2024-05-25 05:06:27 [INFO]: Epoch 022 - generator training loss: 0.0658, discriminator training loss: 0.0438, validation loss: 0.1647
2024-05-25 05:06:31 [INFO]: Epoch 023 - generator training loss: 0.0629, discriminator training loss: 0.0430, validation loss: 0.1622
2024-05-25 05:06:35 [INFO]: Epoch 024 - generator training loss: 0.0624, discriminator training loss: 0.0421, validation loss: 0.1613
2024-05-25 05:06:39 [INFO]: Epoch 025 - generator training loss: 0.0624, discriminator training loss: 0.0414, validation loss: 0.1597
2024-05-25 05:06:43 [INFO]: Epoch 026 - generator training loss: 0.0600, discriminator training loss: 0.0405, validation loss: 0.1590
2024-05-25 05:06:47 [INFO]: Epoch 027 - generator training loss: 0.0591, discriminator training loss: 0.0399, validation loss: 0.1577
2024-05-25 05:06:51 [INFO]: Epoch 028 - generator training loss: 0.0592, discriminator training loss: 0.0390, validation loss: 0.1566
2024-05-25 05:06:55 [INFO]: Epoch 029 - generator training loss: 0.0582, discriminator training loss: 0.0381, validation loss: 0.1555
2024-05-25 05:06:59 [INFO]: Epoch 030 - generator training loss: 0.0577, discriminator training loss: 0.0371, validation loss: 0.1550
2024-05-25 05:07:03 [INFO]: Epoch 031 - generator training loss: 0.0578, discriminator training loss: 0.0365, validation loss: 0.1535
2024-05-25 05:07:07 [INFO]: Epoch 032 - generator training loss: 0.0581, discriminator training loss: 0.0362, validation loss: 0.1530
2024-05-25 05:07:11 [INFO]: Epoch 033 - generator training loss: 0.0572, discriminator training loss: 0.0352, validation loss: 0.1528
2024-05-25 05:07:16 [INFO]: Epoch 034 - generator training loss: 0.0567, discriminator training loss: 0.0340, validation loss: 0.1512
2024-05-25 05:07:20 [INFO]: Epoch 035 - generator training loss: 0.0570, discriminator training loss: 0.0337, validation loss: 0.1508
2024-05-25 05:07:24 [INFO]: Epoch 036 - generator training loss: 0.0553, discriminator training loss: 0.0332, validation loss: 0.1503
2024-05-25 05:07:28 [INFO]: Epoch 037 - generator training loss: 0.0551, discriminator training loss: 0.0323, validation loss: 0.1493
2024-05-25 05:07:32 [INFO]: Epoch 038 - generator training loss: 0.0543, discriminator training loss: 0.0313, validation loss: 0.1486
2024-05-25 05:07:36 [INFO]: Epoch 039 - generator training loss: 0.0538, discriminator training loss: 0.0310, validation loss: 0.1484
2024-05-25 05:07:40 [INFO]: Epoch 040 - generator training loss: 0.0535, discriminator training loss: 0.0302, validation loss: 0.1473
2024-05-25 05:07:44 [INFO]: Epoch 041 - generator training loss: 0.0531, discriminator training loss: 0.0296, validation loss: 0.1467
2024-05-25 05:07:48 [INFO]: Epoch 042 - generator training loss: 0.0541, discriminator training loss: 0.0292, validation loss: 0.1459
2024-05-25 05:07:52 [INFO]: Epoch 043 - generator training loss: 0.0519, discriminator training loss: 0.0287, validation loss: 0.1447
2024-05-25 05:07:56 [INFO]: Epoch 044 - generator training loss: 0.0527, discriminator training loss: 0.0282, validation loss: 0.1438
2024-05-25 05:08:00 [INFO]: Epoch 045 - generator training loss: 0.0513, discriminator training loss: 0.0278, validation loss: 0.1443
2024-05-25 05:08:04 [INFO]: Epoch 046 - generator training loss: 0.0522, discriminator training loss: 0.0274, validation loss: 0.1436
2024-05-25 05:08:08 [INFO]: Epoch 047 - generator training loss: 0.0511, discriminator training loss: 0.0265, validation loss: 0.1432
2024-05-25 05:08:12 [INFO]: Epoch 048 - generator training loss: 0.0506, discriminator training loss: 0.0263, validation loss: 0.1420
2024-05-25 05:08:16 [INFO]: Epoch 049 - generator training loss: 0.0495, discriminator training loss: 0.0259, validation loss: 0.1423
2024-05-25 05:08:20 [INFO]: Epoch 050 - generator training loss: 0.0501, discriminator training loss: 0.0257, validation loss: 0.1413
2024-05-25 05:08:24 [INFO]: Epoch 051 - generator training loss: 0.0485, discriminator training loss: 0.0250, validation loss: 0.1409
2024-05-25 05:08:28 [INFO]: Epoch 052 - generator training loss: 0.0487, discriminator training loss: 0.0246, validation loss: 0.1411
2024-05-25 05:08:33 [INFO]: Epoch 053 - generator training loss: 0.0479, discriminator training loss: 0.0241, validation loss: 0.1407
2024-05-25 05:08:37 [INFO]: Epoch 054 - generator training loss: 0.0493, discriminator training loss: 0.0238, validation loss: 0.1404
2024-05-25 05:08:41 [INFO]: Epoch 055 - generator training loss: 0.0474, discriminator training loss: 0.0235, validation loss: 0.1399
2024-05-25 05:08:45 [INFO]: Epoch 056 - generator training loss: 0.0472, discriminator training loss: 0.0232, validation loss: 0.1392
2024-05-25 05:08:49 [INFO]: Epoch 057 - generator training loss: 0.0471, discriminator training loss: 0.0228, validation loss: 0.1392
2024-05-25 05:08:53 [INFO]: Epoch 058 - generator training loss: 0.0475, discriminator training loss: 0.0227, validation loss: 0.1387
2024-05-25 05:08:57 [INFO]: Epoch 059 - generator training loss: 0.0464, discriminator training loss: 0.0224, validation loss: 0.1386
2024-05-25 05:09:01 [INFO]: Epoch 060 - generator training loss: 0.0467, discriminator training loss: 0.0217, validation loss: 0.1385
2024-05-25 05:09:05 [INFO]: Epoch 061 - generator training loss: 0.0469, discriminator training loss: 0.0216, validation loss: 0.1373
2024-05-25 05:09:09 [INFO]: Epoch 062 - generator training loss: 0.0459, discriminator training loss: 0.0214, validation loss: 0.1376
2024-05-25 05:09:13 [INFO]: Epoch 063 - generator training loss: 0.0453, discriminator training loss: 0.0211, validation loss: 0.1371
2024-05-25 05:09:17 [INFO]: Epoch 064 - generator training loss: 0.0453, discriminator training loss: 0.0210, validation loss: 0.1379
2024-05-25 05:09:21 [INFO]: Epoch 065 - generator training loss: 0.0453, discriminator training loss: 0.0207, validation loss: 0.1374
2024-05-25 05:09:25 [INFO]: Epoch 066 - generator training loss: 0.0454, discriminator training loss: 0.0204, validation loss: 0.1363
2024-05-25 05:09:29 [INFO]: Epoch 067 - generator training loss: 0.0451, discriminator training loss: 0.0201, validation loss: 0.1358
2024-05-25 05:09:33 [INFO]: Epoch 068 - generator training loss: 0.0447, discriminator training loss: 0.0198, validation loss: 0.1364
2024-05-25 05:09:37 [INFO]: Epoch 069 - generator training loss: 0.0442, discriminator training loss: 0.0200, validation loss: 0.1362
2024-05-25 05:09:41 [INFO]: Epoch 070 - generator training loss: 0.0437, discriminator training loss: 0.0197, validation loss: 0.1352
2024-05-25 05:09:45 [INFO]: Epoch 071 - generator training loss: 0.0442, discriminator training loss: 0.0193, validation loss: 0.1358
2024-05-25 05:09:50 [INFO]: Epoch 072 - generator training loss: 0.0435, discriminator training loss: 0.0191, validation loss: 0.1364
2024-05-25 05:09:54 [INFO]: Epoch 073 - generator training loss: 0.0436, discriminator training loss: 0.0192, validation loss: 0.1358
2024-05-25 05:09:58 [INFO]: Epoch 074 - generator training loss: 0.0429, discriminator training loss: 0.0188, validation loss: 0.1363
2024-05-25 05:10:02 [INFO]: Epoch 075 - generator training loss: 0.0440, discriminator training loss: 0.0188, validation loss: 0.1354
2024-05-25 05:10:06 [INFO]: Epoch 076 - generator training loss: 0.0432, discriminator training loss: 0.0185, validation loss: 0.1352
2024-05-25 05:10:10 [INFO]: Epoch 077 - generator training loss: 0.0423, discriminator training loss: 0.0183, validation loss: 0.1350
2024-05-25 05:10:14 [INFO]: Epoch 078 - generator training loss: 0.0426, discriminator training loss: 0.0183, validation loss: 0.1351
2024-05-25 05:10:18 [INFO]: Epoch 079 - generator training loss: 0.0421, discriminator training loss: 0.0179, validation loss: 0.1357
2024-05-25 05:10:22 [INFO]: Epoch 080 - generator training loss: 0.0417, discriminator training loss: 0.0176, validation loss: 0.1353
2024-05-25 05:10:26 [INFO]: Epoch 081 - generator training loss: 0.0415, discriminator training loss: 0.0177, validation loss: 0.1349
2024-05-25 05:10:30 [INFO]: Epoch 082 - generator training loss: 0.0414, discriminator training loss: 0.0176, validation loss: 0.1346
2024-05-25 05:10:34 [INFO]: Epoch 083 - generator training loss: 0.0407, discriminator training loss: 0.0175, validation loss: 0.1346
2024-05-25 05:10:38 [INFO]: Epoch 084 - generator training loss: 0.0409, discriminator training loss: 0.0172, validation loss: 0.1349
2024-05-25 05:10:42 [INFO]: Epoch 085 - generator training loss: 0.0418, discriminator training loss: 0.0171, validation loss: 0.1354
2024-05-25 05:10:46 [INFO]: Epoch 086 - generator training loss: 0.0405, discriminator training loss: 0.0168, validation loss: 0.1348
2024-05-25 05:10:50 [INFO]: Epoch 087 - generator training loss: 0.0401, discriminator training loss: 0.0167, validation loss: 0.1343
2024-05-25 05:10:54 [INFO]: Epoch 088 - generator training loss: 0.0403, discriminator training loss: 0.0167, validation loss: 0.1358
2024-05-25 05:10:58 [INFO]: Epoch 089 - generator training loss: 0.0401, discriminator training loss: 0.0166, validation loss: 0.1345
2024-05-25 05:11:02 [INFO]: Epoch 090 - generator training loss: 0.0394, discriminator training loss: 0.0164, validation loss: 0.1351
2024-05-25 05:11:07 [INFO]: Epoch 091 - generator training loss: 0.0395, discriminator training loss: 0.0162, validation loss: 0.1349
2024-05-25 05:11:11 [INFO]: Epoch 092 - generator training loss: 0.0396, discriminator training loss: 0.0160, validation loss: 0.1337
2024-05-25 05:11:15 [INFO]: Epoch 093 - generator training loss: 0.0396, discriminator training loss: 0.0160, validation loss: 0.1348
2024-05-25 05:11:19 [INFO]: Epoch 094 - generator training loss: 0.0387, discriminator training loss: 0.0161, validation loss: 0.1346
2024-05-25 05:11:23 [INFO]: Epoch 095 - generator training loss: 0.0392, discriminator training loss: 0.0160, validation loss: 0.1351
2024-05-25 05:11:27 [INFO]: Epoch 096 - generator training loss: 0.0395, discriminator training loss: 0.0157, validation loss: 0.1348
2024-05-25 05:11:31 [INFO]: Epoch 097 - generator training loss: 0.0385, discriminator training loss: 0.0156, validation loss: 0.1352
2024-05-25 05:11:35 [INFO]: Epoch 098 - generator training loss: 0.0382, discriminator training loss: 0.0156, validation loss: 0.1350
2024-05-25 05:11:39 [INFO]: Epoch 099 - generator training loss: 0.0378, discriminator training loss: 0.0157, validation loss: 0.1344
2024-05-25 05:11:43 [INFO]: Epoch 100 - generator training loss: 0.0382, discriminator training loss: 0.0154, validation loss: 0.1349
2024-05-25 05:11:47 [INFO]: Epoch 101 - generator training loss: 0.0379, discriminator training loss: 0.0152, validation loss: 0.1351
2024-05-25 05:11:51 [INFO]: Epoch 102 - generator training loss: 0.0380, discriminator training loss: 0.0150, validation loss: 0.1343
2024-05-25 05:11:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:11:51 [INFO]: Finished training. The best model is from epoch#92.
2024-05-25 05:11:51 [INFO]: Saved the model to augmentation_saved_results/round_3/USGAN_air_quality/20240525_T050455/USGAN.pypots
2024-05-25 05:11:52 [INFO]: US-GAN on Air-Quality: MAE=0.2068, MSE=0.1922
2024-05-25 05:11:52 [INFO]: Successfully saved to augmentation_saved_results/round_3/USGAN_air_quality/imputation.pkl
2024-05-25 05:11:52 [INFO]: Using the given device: cuda:0
2024-05-25 05:11:52 [INFO]: Model files will be saved to augmentation_saved_results/round_3/BRITS_air_quality/20240525_T051152
2024-05-25 05:11:52 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/BRITS_air_quality/20240525_T051152/tensorboard
2024-05-25 05:11:52 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 05:11:55 [INFO]: Epoch 001 - training loss: 1.3984, validation loss: 0.9538
2024-05-25 05:11:58 [INFO]: Epoch 002 - training loss: 1.1266, validation loss: 0.7166
2024-05-25 05:12:01 [INFO]: Epoch 003 - training loss: 0.9357, validation loss: 0.6047
2024-05-25 05:12:04 [INFO]: Epoch 004 - training loss: 0.8248, validation loss: 0.5363
2024-05-25 05:12:07 [INFO]: Epoch 005 - training loss: 0.7545, validation loss: 0.4870
2024-05-25 05:12:09 [INFO]: Epoch 006 - training loss: 0.6974, validation loss: 0.4511
2024-05-25 05:12:12 [INFO]: Epoch 007 - training loss: 0.6567, validation loss: 0.4206
2024-05-25 05:12:15 [INFO]: Epoch 008 - training loss: 0.6208, validation loss: 0.3957
2024-05-25 05:12:18 [INFO]: Epoch 009 - training loss: 0.5946, validation loss: 0.3762
2024-05-25 05:12:20 [INFO]: Epoch 010 - training loss: 0.5743, validation loss: 0.3592
2024-05-25 05:12:23 [INFO]: Epoch 011 - training loss: 0.5572, validation loss: 0.3443
2024-05-25 05:12:26 [INFO]: Epoch 012 - training loss: 0.5421, validation loss: 0.3322
2024-05-25 05:12:29 [INFO]: Epoch 013 - training loss: 0.5273, validation loss: 0.3218
2024-05-25 05:12:32 [INFO]: Epoch 014 - training loss: 0.5165, validation loss: 0.3114
2024-05-25 05:12:34 [INFO]: Epoch 015 - training loss: 0.5061, validation loss: 0.3039
2024-05-25 05:12:37 [INFO]: Epoch 016 - training loss: 0.4976, validation loss: 0.2968
2024-05-25 05:12:40 [INFO]: Epoch 017 - training loss: 0.4862, validation loss: 0.2898
2024-05-25 05:12:43 [INFO]: Epoch 018 - training loss: 0.4777, validation loss: 0.2839
2024-05-25 05:12:45 [INFO]: Epoch 019 - training loss: 0.4697, validation loss: 0.2789
2024-05-25 05:12:48 [INFO]: Epoch 020 - training loss: 0.4624, validation loss: 0.2736
2024-05-25 05:12:51 [INFO]: Epoch 021 - training loss: 0.4558, validation loss: 0.2691
2024-05-25 05:12:54 [INFO]: Epoch 022 - training loss: 0.4495, validation loss: 0.2647
2024-05-25 05:12:57 [INFO]: Epoch 023 - training loss: 0.4417, validation loss: 0.2600
2024-05-25 05:12:59 [INFO]: Epoch 024 - training loss: 0.4370, validation loss: 0.2563
2024-05-25 05:13:02 [INFO]: Epoch 025 - training loss: 0.4307, validation loss: 0.2525
2024-05-25 05:13:05 [INFO]: Epoch 026 - training loss: 0.4256, validation loss: 0.2483
2024-05-25 05:13:08 [INFO]: Epoch 027 - training loss: 0.4203, validation loss: 0.2449
2024-05-25 05:13:10 [INFO]: Epoch 028 - training loss: 0.4151, validation loss: 0.2413
2024-05-25 05:13:13 [INFO]: Epoch 029 - training loss: 0.4103, validation loss: 0.2379
2024-05-25 05:13:16 [INFO]: Epoch 030 - training loss: 0.4051, validation loss: 0.2345
2024-05-25 05:13:19 [INFO]: Epoch 031 - training loss: 0.4001, validation loss: 0.2319
2024-05-25 05:13:22 [INFO]: Epoch 032 - training loss: 0.3974, validation loss: 0.2281
2024-05-25 05:13:24 [INFO]: Epoch 033 - training loss: 0.3937, validation loss: 0.2253
2024-05-25 05:13:27 [INFO]: Epoch 034 - training loss: 0.3885, validation loss: 0.2220
2024-05-25 05:13:30 [INFO]: Epoch 035 - training loss: 0.3844, validation loss: 0.2197
2024-05-25 05:13:33 [INFO]: Epoch 036 - training loss: 0.3809, validation loss: 0.2163
2024-05-25 05:13:35 [INFO]: Epoch 037 - training loss: 0.3775, validation loss: 0.2136
2024-05-25 05:13:38 [INFO]: Epoch 038 - training loss: 0.3738, validation loss: 0.2110
2024-05-25 05:13:41 [INFO]: Epoch 039 - training loss: 0.3699, validation loss: 0.2086
2024-05-25 05:13:44 [INFO]: Epoch 040 - training loss: 0.3678, validation loss: 0.2063
2024-05-25 05:13:46 [INFO]: Epoch 041 - training loss: 0.3648, validation loss: 0.2035
2024-05-25 05:13:49 [INFO]: Epoch 042 - training loss: 0.3609, validation loss: 0.2015
2024-05-25 05:13:52 [INFO]: Epoch 043 - training loss: 0.3583, validation loss: 0.1995
2024-05-25 05:13:55 [INFO]: Epoch 044 - training loss: 0.3545, validation loss: 0.1975
2024-05-25 05:13:58 [INFO]: Epoch 045 - training loss: 0.3525, validation loss: 0.1954
2024-05-25 05:14:00 [INFO]: Epoch 046 - training loss: 0.3494, validation loss: 0.1935
2024-05-25 05:14:03 [INFO]: Epoch 047 - training loss: 0.3475, validation loss: 0.1915
2024-05-25 05:14:06 [INFO]: Epoch 048 - training loss: 0.3447, validation loss: 0.1896
2024-05-25 05:14:09 [INFO]: Epoch 049 - training loss: 0.3423, validation loss: 0.1882
2024-05-25 05:14:11 [INFO]: Epoch 050 - training loss: 0.3410, validation loss: 0.1868
2024-05-25 05:14:14 [INFO]: Epoch 051 - training loss: 0.3376, validation loss: 0.1850
2024-05-25 05:14:17 [INFO]: Epoch 052 - training loss: 0.3352, validation loss: 0.1839
2024-05-25 05:14:20 [INFO]: Epoch 053 - training loss: 0.3345, validation loss: 0.1826
2024-05-25 05:14:22 [INFO]: Epoch 054 - training loss: 0.3311, validation loss: 0.1811
2024-05-25 05:14:25 [INFO]: Epoch 055 - training loss: 0.3301, validation loss: 0.1797
2024-05-25 05:14:28 [INFO]: Epoch 056 - training loss: 0.3273, validation loss: 0.1784
2024-05-25 05:14:31 [INFO]: Epoch 057 - training loss: 0.3256, validation loss: 0.1777
2024-05-25 05:14:34 [INFO]: Epoch 058 - training loss: 0.3243, validation loss: 0.1764
2024-05-25 05:14:36 [INFO]: Epoch 059 - training loss: 0.3225, validation loss: 0.1753
2024-05-25 05:14:39 [INFO]: Epoch 060 - training loss: 0.3207, validation loss: 0.1743
2024-05-25 05:14:42 [INFO]: Epoch 061 - training loss: 0.3192, validation loss: 0.1735
2024-05-25 05:14:45 [INFO]: Epoch 062 - training loss: 0.3166, validation loss: 0.1723
2024-05-25 05:14:48 [INFO]: Epoch 063 - training loss: 0.3156, validation loss: 0.1716
2024-05-25 05:14:50 [INFO]: Epoch 064 - training loss: 0.3142, validation loss: 0.1710
2024-05-25 05:14:53 [INFO]: Epoch 065 - training loss: 0.3127, validation loss: 0.1700
2024-05-25 05:14:56 [INFO]: Epoch 066 - training loss: 0.3118, validation loss: 0.1691
2024-05-25 05:14:59 [INFO]: Epoch 067 - training loss: 0.3102, validation loss: 0.1685
2024-05-25 05:15:01 [INFO]: Epoch 068 - training loss: 0.3083, validation loss: 0.1675
2024-05-25 05:15:04 [INFO]: Epoch 069 - training loss: 0.3074, validation loss: 0.1665
2024-05-25 05:15:07 [INFO]: Epoch 070 - training loss: 0.3059, validation loss: 0.1660
2024-05-25 05:15:10 [INFO]: Epoch 071 - training loss: 0.3052, validation loss: 0.1655
2024-05-25 05:15:12 [INFO]: Epoch 072 - training loss: 0.3035, validation loss: 0.1647
2024-05-25 05:15:15 [INFO]: Epoch 073 - training loss: 0.3030, validation loss: 0.1642
2024-05-25 05:15:18 [INFO]: Epoch 074 - training loss: 0.3020, validation loss: 0.1632
2024-05-25 05:15:21 [INFO]: Epoch 075 - training loss: 0.3008, validation loss: 0.1627
2024-05-25 05:15:24 [INFO]: Epoch 076 - training loss: 0.2994, validation loss: 0.1620
2024-05-25 05:15:26 [INFO]: Epoch 077 - training loss: 0.2997, validation loss: 0.1615
2024-05-25 05:15:29 [INFO]: Epoch 078 - training loss: 0.2973, validation loss: 0.1607
2024-05-25 05:15:32 [INFO]: Epoch 079 - training loss: 0.2969, validation loss: 0.1602
2024-05-25 05:15:35 [INFO]: Epoch 080 - training loss: 0.2957, validation loss: 0.1596
2024-05-25 05:15:37 [INFO]: Epoch 081 - training loss: 0.2944, validation loss: 0.1589
2024-05-25 05:15:40 [INFO]: Epoch 082 - training loss: 0.2939, validation loss: 0.1585
2024-05-25 05:15:43 [INFO]: Epoch 083 - training loss: 0.2935, validation loss: 0.1578
2024-05-25 05:15:46 [INFO]: Epoch 084 - training loss: 0.2915, validation loss: 0.1572
2024-05-25 05:15:48 [INFO]: Epoch 085 - training loss: 0.2905, validation loss: 0.1567
2024-05-25 05:15:51 [INFO]: Epoch 086 - training loss: 0.2903, validation loss: 0.1562
2024-05-25 05:15:54 [INFO]: Epoch 087 - training loss: 0.2903, validation loss: 0.1557
2024-05-25 05:15:57 [INFO]: Epoch 088 - training loss: 0.2890, validation loss: 0.1550
2024-05-25 05:16:00 [INFO]: Epoch 089 - training loss: 0.2873, validation loss: 0.1546
2024-05-25 05:16:02 [INFO]: Epoch 090 - training loss: 0.2873, validation loss: 0.1542
2024-05-25 05:16:05 [INFO]: Epoch 091 - training loss: 0.2870, validation loss: 0.1536
2024-05-25 05:16:08 [INFO]: Epoch 092 - training loss: 0.2856, validation loss: 0.1533
2024-05-25 05:16:11 [INFO]: Epoch 093 - training loss: 0.2846, validation loss: 0.1528
2024-05-25 05:16:13 [INFO]: Epoch 094 - training loss: 0.2842, validation loss: 0.1524
2024-05-25 05:16:16 [INFO]: Epoch 095 - training loss: 0.2834, validation loss: 0.1514
2024-05-25 05:16:19 [INFO]: Epoch 096 - training loss: 0.2829, validation loss: 0.1512
2024-05-25 05:16:22 [INFO]: Epoch 097 - training loss: 0.2820, validation loss: 0.1507
2024-05-25 05:16:24 [INFO]: Epoch 098 - training loss: 0.2816, validation loss: 0.1503
2024-05-25 05:16:27 [INFO]: Epoch 099 - training loss: 0.2804, validation loss: 0.1498
2024-05-25 05:16:30 [INFO]: Epoch 100 - training loss: 0.2803, validation loss: 0.1493
2024-05-25 05:16:33 [INFO]: Epoch 101 - training loss: 0.2796, validation loss: 0.1487
2024-05-25 05:16:36 [INFO]: Epoch 102 - training loss: 0.2789, validation loss: 0.1484
2024-05-25 05:16:38 [INFO]: Epoch 103 - training loss: 0.2784, validation loss: 0.1479
2024-05-25 05:16:41 [INFO]: Epoch 104 - training loss: 0.2780, validation loss: 0.1473
2024-05-25 05:16:44 [INFO]: Epoch 105 - training loss: 0.2769, validation loss: 0.1470
2024-05-25 05:16:47 [INFO]: Epoch 106 - training loss: 0.2763, validation loss: 0.1468
2024-05-25 05:16:49 [INFO]: Epoch 107 - training loss: 0.2763, validation loss: 0.1461
2024-05-25 05:16:52 [INFO]: Epoch 108 - training loss: 0.2753, validation loss: 0.1457
2024-05-25 05:16:55 [INFO]: Epoch 109 - training loss: 0.2745, validation loss: 0.1452
2024-05-25 05:16:58 [INFO]: Epoch 110 - training loss: 0.2749, validation loss: 0.1450
2024-05-25 05:17:01 [INFO]: Epoch 111 - training loss: 0.2736, validation loss: 0.1446
2024-05-25 05:17:03 [INFO]: Epoch 112 - training loss: 0.2735, validation loss: 0.1439
2024-05-25 05:17:06 [INFO]: Epoch 113 - training loss: 0.2726, validation loss: 0.1437
2024-05-25 05:17:09 [INFO]: Epoch 114 - training loss: 0.2722, validation loss: 0.1433
2024-05-25 05:17:12 [INFO]: Epoch 115 - training loss: 0.2715, validation loss: 0.1428
2024-05-25 05:17:14 [INFO]: Epoch 116 - training loss: 0.2713, validation loss: 0.1426
2024-05-25 05:17:17 [INFO]: Epoch 117 - training loss: 0.2707, validation loss: 0.1422
2024-05-25 05:17:20 [INFO]: Epoch 118 - training loss: 0.2696, validation loss: 0.1417
2024-05-25 05:17:23 [INFO]: Epoch 119 - training loss: 0.2690, validation loss: 0.1413
2024-05-25 05:17:25 [INFO]: Epoch 120 - training loss: 0.2691, validation loss: 0.1411
2024-05-25 05:17:28 [INFO]: Epoch 121 - training loss: 0.2694, validation loss: 0.1406
2024-05-25 05:17:31 [INFO]: Epoch 122 - training loss: 0.2682, validation loss: 0.1399
2024-05-25 05:17:34 [INFO]: Epoch 123 - training loss: 0.2676, validation loss: 0.1398
2024-05-25 05:17:36 [INFO]: Epoch 124 - training loss: 0.2666, validation loss: 0.1395
2024-05-25 05:17:39 [INFO]: Epoch 125 - training loss: 0.2666, validation loss: 0.1391
2024-05-25 05:17:42 [INFO]: Epoch 126 - training loss: 0.2668, validation loss: 0.1387
2024-05-25 05:17:45 [INFO]: Epoch 127 - training loss: 0.2653, validation loss: 0.1384
2024-05-25 05:17:48 [INFO]: Epoch 128 - training loss: 0.2657, validation loss: 0.1382
2024-05-25 05:17:50 [INFO]: Epoch 129 - training loss: 0.2647, validation loss: 0.1377
2024-05-25 05:17:53 [INFO]: Epoch 130 - training loss: 0.2650, validation loss: 0.1374
2024-05-25 05:17:56 [INFO]: Epoch 131 - training loss: 0.2642, validation loss: 0.1373
2024-05-25 05:17:59 [INFO]: Epoch 132 - training loss: 0.2638, validation loss: 0.1369
2024-05-25 05:18:01 [INFO]: Epoch 133 - training loss: 0.2633, validation loss: 0.1364
2024-05-25 05:18:04 [INFO]: Epoch 134 - training loss: 0.2629, validation loss: 0.1362
2024-05-25 05:18:07 [INFO]: Epoch 135 - training loss: 0.2624, validation loss: 0.1358
2024-05-25 05:18:10 [INFO]: Epoch 136 - training loss: 0.2618, validation loss: 0.1356
2024-05-25 05:18:12 [INFO]: Epoch 137 - training loss: 0.2613, validation loss: 0.1352
2024-05-25 05:18:15 [INFO]: Epoch 138 - training loss: 0.2607, validation loss: 0.1350
2024-05-25 05:18:18 [INFO]: Epoch 139 - training loss: 0.2607, validation loss: 0.1347
2024-05-25 05:18:21 [INFO]: Epoch 140 - training loss: 0.2612, validation loss: 0.1345
2024-05-25 05:18:24 [INFO]: Epoch 141 - training loss: 0.2599, validation loss: 0.1342
2024-05-25 05:18:26 [INFO]: Epoch 142 - training loss: 0.2597, validation loss: 0.1339
2024-05-25 05:18:29 [INFO]: Epoch 143 - training loss: 0.2594, validation loss: 0.1335
2024-05-25 05:18:32 [INFO]: Epoch 144 - training loss: 0.2590, validation loss: 0.1333
2024-05-25 05:18:35 [INFO]: Epoch 145 - training loss: 0.2589, validation loss: 0.1329
2024-05-25 05:18:37 [INFO]: Epoch 146 - training loss: 0.2582, validation loss: 0.1329
2024-05-25 05:18:40 [INFO]: Epoch 147 - training loss: 0.2576, validation loss: 0.1325
2024-05-25 05:18:43 [INFO]: Epoch 148 - training loss: 0.2575, validation loss: 0.1323
2024-05-25 05:18:46 [INFO]: Epoch 149 - training loss: 0.2569, validation loss: 0.1321
2024-05-25 05:18:48 [INFO]: Epoch 150 - training loss: 0.2566, validation loss: 0.1317
2024-05-25 05:18:51 [INFO]: Epoch 151 - training loss: 0.2565, validation loss: 0.1315
2024-05-25 05:18:54 [INFO]: Epoch 152 - training loss: 0.2562, validation loss: 0.1312
2024-05-25 05:18:57 [INFO]: Epoch 153 - training loss: 0.2560, validation loss: 0.1310
2024-05-25 05:19:00 [INFO]: Epoch 154 - training loss: 0.2557, validation loss: 0.1309
2024-05-25 05:19:02 [INFO]: Epoch 155 - training loss: 0.2549, validation loss: 0.1303
2024-05-25 05:19:05 [INFO]: Epoch 156 - training loss: 0.2548, validation loss: 0.1306
2024-05-25 05:19:08 [INFO]: Epoch 157 - training loss: 0.2547, validation loss: 0.1301
2024-05-25 05:19:11 [INFO]: Epoch 158 - training loss: 0.2548, validation loss: 0.1299
2024-05-25 05:19:13 [INFO]: Epoch 159 - training loss: 0.2544, validation loss: 0.1298
2024-05-25 05:19:16 [INFO]: Epoch 160 - training loss: 0.2539, validation loss: 0.1292
2024-05-25 05:19:19 [INFO]: Epoch 161 - training loss: 0.2535, validation loss: 0.1293
2024-05-25 05:19:22 [INFO]: Epoch 162 - training loss: 0.2530, validation loss: 0.1290
2024-05-25 05:19:24 [INFO]: Epoch 163 - training loss: 0.2525, validation loss: 0.1287
2024-05-25 05:19:27 [INFO]: Epoch 164 - training loss: 0.2525, validation loss: 0.1287
2024-05-25 05:19:30 [INFO]: Epoch 165 - training loss: 0.2522, validation loss: 0.1281
2024-05-25 05:19:33 [INFO]: Epoch 166 - training loss: 0.2524, validation loss: 0.1281
2024-05-25 05:19:36 [INFO]: Epoch 167 - training loss: 0.2515, validation loss: 0.1280
2024-05-25 05:19:38 [INFO]: Epoch 168 - training loss: 0.2510, validation loss: 0.1277
2024-05-25 05:19:41 [INFO]: Epoch 169 - training loss: 0.2511, validation loss: 0.1274
2024-05-25 05:19:44 [INFO]: Epoch 170 - training loss: 0.2511, validation loss: 0.1274
2024-05-25 05:19:47 [INFO]: Epoch 171 - training loss: 0.2508, validation loss: 0.1271
2024-05-25 05:19:49 [INFO]: Epoch 172 - training loss: 0.2504, validation loss: 0.1270
2024-05-25 05:19:52 [INFO]: Epoch 173 - training loss: 0.2503, validation loss: 0.1268
2024-05-25 05:19:55 [INFO]: Epoch 174 - training loss: 0.2496, validation loss: 0.1267
2024-05-25 05:19:58 [INFO]: Epoch 175 - training loss: 0.2492, validation loss: 0.1263
2024-05-25 05:20:00 [INFO]: Epoch 176 - training loss: 0.2498, validation loss: 0.1260
2024-05-25 05:20:03 [INFO]: Epoch 177 - training loss: 0.2490, validation loss: 0.1261
2024-05-25 05:20:06 [INFO]: Epoch 178 - training loss: 0.2488, validation loss: 0.1258
2024-05-25 05:20:09 [INFO]: Epoch 179 - training loss: 0.2483, validation loss: 0.1258
2024-05-25 05:20:12 [INFO]: Epoch 180 - training loss: 0.2485, validation loss: 0.1255
2024-05-25 05:20:14 [INFO]: Epoch 181 - training loss: 0.2477, validation loss: 0.1255
2024-05-25 05:20:17 [INFO]: Epoch 182 - training loss: 0.2481, validation loss: 0.1252
2024-05-25 05:20:20 [INFO]: Epoch 183 - training loss: 0.2476, validation loss: 0.1252
2024-05-25 05:20:23 [INFO]: Epoch 184 - training loss: 0.2473, validation loss: 0.1249
2024-05-25 05:20:25 [INFO]: Epoch 185 - training loss: 0.2473, validation loss: 0.1248
2024-05-25 05:20:28 [INFO]: Epoch 186 - training loss: 0.2471, validation loss: 0.1245
2024-05-25 05:20:31 [INFO]: Epoch 187 - training loss: 0.2465, validation loss: 0.1246
2024-05-25 05:20:34 [INFO]: Epoch 188 - training loss: 0.2463, validation loss: 0.1241
2024-05-25 05:20:36 [INFO]: Epoch 189 - training loss: 0.2470, validation loss: 0.1242
2024-05-25 05:20:39 [INFO]: Epoch 190 - training loss: 0.2462, validation loss: 0.1238
2024-05-25 05:20:42 [INFO]: Epoch 191 - training loss: 0.2457, validation loss: 0.1238
2024-05-25 05:20:45 [INFO]: Epoch 192 - training loss: 0.2457, validation loss: 0.1237
2024-05-25 05:20:47 [INFO]: Epoch 193 - training loss: 0.2454, validation loss: 0.1235
2024-05-25 05:20:50 [INFO]: Epoch 194 - training loss: 0.2453, validation loss: 0.1235
2024-05-25 05:20:53 [INFO]: Epoch 195 - training loss: 0.2457, validation loss: 0.1233
2024-05-25 05:20:56 [INFO]: Epoch 196 - training loss: 0.2448, validation loss: 0.1232
2024-05-25 05:20:59 [INFO]: Epoch 197 - training loss: 0.2444, validation loss: 0.1229
2024-05-25 05:21:01 [INFO]: Epoch 198 - training loss: 0.2443, validation loss: 0.1227
2024-05-25 05:21:04 [INFO]: Epoch 199 - training loss: 0.2441, validation loss: 0.1228
2024-05-25 05:21:07 [INFO]: Epoch 200 - training loss: 0.2436, validation loss: 0.1226
2024-05-25 05:21:10 [INFO]: Epoch 201 - training loss: 0.2437, validation loss: 0.1225
2024-05-25 05:21:13 [INFO]: Epoch 202 - training loss: 0.2437, validation loss: 0.1224
2024-05-25 05:21:15 [INFO]: Epoch 203 - training loss: 0.2436, validation loss: 0.1221
2024-05-25 05:21:18 [INFO]: Epoch 204 - training loss: 0.2435, validation loss: 0.1222
2024-05-25 05:21:21 [INFO]: Epoch 205 - training loss: 0.2429, validation loss: 0.1219
2024-05-25 05:21:24 [INFO]: Epoch 206 - training loss: 0.2435, validation loss: 0.1220
2024-05-25 05:21:26 [INFO]: Epoch 207 - training loss: 0.2426, validation loss: 0.1218
2024-05-25 05:21:29 [INFO]: Epoch 208 - training loss: 0.2423, validation loss: 0.1214
2024-05-25 05:21:32 [INFO]: Epoch 209 - training loss: 0.2421, validation loss: 0.1215
2024-05-25 05:21:35 [INFO]: Epoch 210 - training loss: 0.2424, validation loss: 0.1212
2024-05-25 05:21:37 [INFO]: Epoch 211 - training loss: 0.2419, validation loss: 0.1212
2024-05-25 05:21:40 [INFO]: Epoch 212 - training loss: 0.2419, validation loss: 0.1211
2024-05-25 05:21:43 [INFO]: Epoch 213 - training loss: 0.2417, validation loss: 0.1210
2024-05-25 05:21:46 [INFO]: Epoch 214 - training loss: 0.2410, validation loss: 0.1209
2024-05-25 05:21:49 [INFO]: Epoch 215 - training loss: 0.2409, validation loss: 0.1207
2024-05-25 05:21:51 [INFO]: Epoch 216 - training loss: 0.2411, validation loss: 0.1207
2024-05-25 05:21:54 [INFO]: Epoch 217 - training loss: 0.2408, validation loss: 0.1205
2024-05-25 05:21:57 [INFO]: Epoch 218 - training loss: 0.2404, validation loss: 0.1205
2024-05-25 05:22:00 [INFO]: Epoch 219 - training loss: 0.2406, validation loss: 0.1203
2024-05-25 05:22:02 [INFO]: Epoch 220 - training loss: 0.2403, validation loss: 0.1204
2024-05-25 05:22:05 [INFO]: Epoch 221 - training loss: 0.2403, validation loss: 0.1202
2024-05-25 05:22:08 [INFO]: Epoch 222 - training loss: 0.2401, validation loss: 0.1200
2024-05-25 05:22:11 [INFO]: Epoch 223 - training loss: 0.2398, validation loss: 0.1200
2024-05-25 05:22:14 [INFO]: Epoch 224 - training loss: 0.2392, validation loss: 0.1195
2024-05-25 05:22:16 [INFO]: Epoch 225 - training loss: 0.2393, validation loss: 0.1197
2024-05-25 05:22:19 [INFO]: Epoch 226 - training loss: 0.2387, validation loss: 0.1196
2024-05-25 05:22:22 [INFO]: Epoch 227 - training loss: 0.2387, validation loss: 0.1194
2024-05-25 05:22:25 [INFO]: Epoch 228 - training loss: 0.2387, validation loss: 0.1197
2024-05-25 05:22:27 [INFO]: Epoch 229 - training loss: 0.2390, validation loss: 0.1192
2024-05-25 05:22:30 [INFO]: Epoch 230 - training loss: 0.2392, validation loss: 0.1192
2024-05-25 05:22:33 [INFO]: Epoch 231 - training loss: 0.2384, validation loss: 0.1189
2024-05-25 05:22:36 [INFO]: Epoch 232 - training loss: 0.2385, validation loss: 0.1189
2024-05-25 05:22:38 [INFO]: Epoch 233 - training loss: 0.2377, validation loss: 0.1190
2024-05-25 05:22:41 [INFO]: Epoch 234 - training loss: 0.2382, validation loss: 0.1189
2024-05-25 05:22:44 [INFO]: Epoch 235 - training loss: 0.2374, validation loss: 0.1186
2024-05-25 05:22:47 [INFO]: Epoch 236 - training loss: 0.2378, validation loss: 0.1187
2024-05-25 05:22:50 [INFO]: Epoch 237 - training loss: 0.2377, validation loss: 0.1185
2024-05-25 05:22:52 [INFO]: Epoch 238 - training loss: 0.2370, validation loss: 0.1185
2024-05-25 05:22:55 [INFO]: Epoch 239 - training loss: 0.2374, validation loss: 0.1186
2024-05-25 05:22:58 [INFO]: Epoch 240 - training loss: 0.2367, validation loss: 0.1182
2024-05-25 05:23:01 [INFO]: Epoch 241 - training loss: 0.2367, validation loss: 0.1183
2024-05-25 05:23:04 [INFO]: Epoch 242 - training loss: 0.2366, validation loss: 0.1181
2024-05-25 05:23:06 [INFO]: Epoch 243 - training loss: 0.2365, validation loss: 0.1182
2024-05-25 05:23:09 [INFO]: Epoch 244 - training loss: 0.2363, validation loss: 0.1178
2024-05-25 05:23:12 [INFO]: Epoch 245 - training loss: 0.2365, validation loss: 0.1179
2024-05-25 05:23:15 [INFO]: Epoch 246 - training loss: 0.2363, validation loss: 0.1176
2024-05-25 05:23:17 [INFO]: Epoch 247 - training loss: 0.2358, validation loss: 0.1177
2024-05-25 05:23:20 [INFO]: Epoch 248 - training loss: 0.2356, validation loss: 0.1177
2024-05-25 05:23:23 [INFO]: Epoch 249 - training loss: 0.2359, validation loss: 0.1176
2024-05-25 05:23:26 [INFO]: Epoch 250 - training loss: 0.2357, validation loss: 0.1176
2024-05-25 05:23:28 [INFO]: Epoch 251 - training loss: 0.2356, validation loss: 0.1173
2024-05-25 05:23:31 [INFO]: Epoch 252 - training loss: 0.2351, validation loss: 0.1174
2024-05-25 05:23:34 [INFO]: Epoch 253 - training loss: 0.2353, validation loss: 0.1171
2024-05-25 05:23:37 [INFO]: Epoch 254 - training loss: 0.2349, validation loss: 0.1174
2024-05-25 05:23:40 [INFO]: Epoch 255 - training loss: 0.2348, validation loss: 0.1172
2024-05-25 05:23:42 [INFO]: Epoch 256 - training loss: 0.2351, validation loss: 0.1170
2024-05-25 05:23:45 [INFO]: Epoch 257 - training loss: 0.2341, validation loss: 0.1168
2024-05-25 05:23:48 [INFO]: Epoch 258 - training loss: 0.2342, validation loss: 0.1170
2024-05-25 05:23:51 [INFO]: Epoch 259 - training loss: 0.2346, validation loss: 0.1168
2024-05-25 05:23:53 [INFO]: Epoch 260 - training loss: 0.2342, validation loss: 0.1170
2024-05-25 05:23:56 [INFO]: Epoch 261 - training loss: 0.2346, validation loss: 0.1165
2024-05-25 05:23:59 [INFO]: Epoch 262 - training loss: 0.2338, validation loss: 0.1165
2024-05-25 05:24:02 [INFO]: Epoch 263 - training loss: 0.2341, validation loss: 0.1164
2024-05-25 05:24:05 [INFO]: Epoch 264 - training loss: 0.2332, validation loss: 0.1166
2024-05-25 05:24:07 [INFO]: Epoch 265 - training loss: 0.2334, validation loss: 0.1164
2024-05-25 05:24:10 [INFO]: Epoch 266 - training loss: 0.2332, validation loss: 0.1163
2024-05-25 05:24:13 [INFO]: Epoch 267 - training loss: 0.2327, validation loss: 0.1161
2024-05-25 05:24:16 [INFO]: Epoch 268 - training loss: 0.2330, validation loss: 0.1162
2024-05-25 05:24:18 [INFO]: Epoch 269 - training loss: 0.2328, validation loss: 0.1160
2024-05-25 05:24:21 [INFO]: Epoch 270 - training loss: 0.2334, validation loss: 0.1160
2024-05-25 05:24:24 [INFO]: Epoch 271 - training loss: 0.2332, validation loss: 0.1161
2024-05-25 05:24:27 [INFO]: Epoch 272 - training loss: 0.2323, validation loss: 0.1158
2024-05-25 05:24:29 [INFO]: Epoch 273 - training loss: 0.2325, validation loss: 0.1161
2024-05-25 05:24:32 [INFO]: Epoch 274 - training loss: 0.2324, validation loss: 0.1158
2024-05-25 05:24:35 [INFO]: Epoch 275 - training loss: 0.2326, validation loss: 0.1158
2024-05-25 05:24:38 [INFO]: Epoch 276 - training loss: 0.2322, validation loss: 0.1158
2024-05-25 05:24:41 [INFO]: Epoch 277 - training loss: 0.2314, validation loss: 0.1157
2024-05-25 05:24:43 [INFO]: Epoch 278 - training loss: 0.2319, validation loss: 0.1158
2024-05-25 05:24:46 [INFO]: Epoch 279 - training loss: 0.2317, validation loss: 0.1156
2024-05-25 05:24:49 [INFO]: Epoch 280 - training loss: 0.2314, validation loss: 0.1157
2024-05-25 05:24:52 [INFO]: Epoch 281 - training loss: 0.2317, validation loss: 0.1155
2024-05-25 05:24:54 [INFO]: Epoch 282 - training loss: 0.2315, validation loss: 0.1156
2024-05-25 05:24:57 [INFO]: Epoch 283 - training loss: 0.2313, validation loss: 0.1155
2024-05-25 05:25:00 [INFO]: Epoch 284 - training loss: 0.2313, validation loss: 0.1154
2024-05-25 05:25:03 [INFO]: Epoch 285 - training loss: 0.2310, validation loss: 0.1156
2024-05-25 05:25:06 [INFO]: Epoch 286 - training loss: 0.2307, validation loss: 0.1153
2024-05-25 05:25:08 [INFO]: Epoch 287 - training loss: 0.2306, validation loss: 0.1151
2024-05-25 05:25:11 [INFO]: Epoch 288 - training loss: 0.2307, validation loss: 0.1151
2024-05-25 05:25:14 [INFO]: Epoch 289 - training loss: 0.2311, validation loss: 0.1152
2024-05-25 05:25:17 [INFO]: Epoch 290 - training loss: 0.2302, validation loss: 0.1154
2024-05-25 05:25:19 [INFO]: Epoch 291 - training loss: 0.2303, validation loss: 0.1149
2024-05-25 05:25:22 [INFO]: Epoch 292 - training loss: 0.2302, validation loss: 0.1148
2024-05-25 05:25:25 [INFO]: Epoch 293 - training loss: 0.2301, validation loss: 0.1149
2024-05-25 05:25:28 [INFO]: Epoch 294 - training loss: 0.2302, validation loss: 0.1149
2024-05-25 05:25:31 [INFO]: Epoch 295 - training loss: 0.2301, validation loss: 0.1149
2024-05-25 05:25:33 [INFO]: Epoch 296 - training loss: 0.2298, validation loss: 0.1149
2024-05-25 05:25:36 [INFO]: Epoch 297 - training loss: 0.2300, validation loss: 0.1150
2024-05-25 05:25:39 [INFO]: Epoch 298 - training loss: 0.2303, validation loss: 0.1149
2024-05-25 05:25:42 [INFO]: Epoch 299 - training loss: 0.2296, validation loss: 0.1145
2024-05-25 05:25:44 [INFO]: Epoch 300 - training loss: 0.2296, validation loss: 0.1148
2024-05-25 05:25:44 [INFO]: Finished training. The best model is from epoch#299.
2024-05-25 05:25:44 [INFO]: Saved the model to augmentation_saved_results/round_3/BRITS_air_quality/20240525_T051152/BRITS.pypots
2024-05-25 05:25:45 [INFO]: BRITS on Air-Quality: MAE=0.1555, MSE=0.1631
2024-05-25 05:25:45 [INFO]: Successfully saved to augmentation_saved_results/round_3/BRITS_air_quality/imputation.pkl
2024-05-25 05:25:45 [INFO]: Using the given device: cuda:0
2024-05-25 05:25:45 [INFO]: Model files will be saved to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545
2024-05-25 05:25:45 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/tensorboard
2024-05-25 05:25:45 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 05:25:50 [INFO]: Epoch 001 - training loss: 1.4448, validation loss: 0.7982
2024-05-25 05:25:50 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch1_loss0.798185083270073.pypots
2024-05-25 05:25:54 [INFO]: Epoch 002 - training loss: 1.0622, validation loss: 0.7431
2024-05-25 05:25:54 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch2_loss0.743079686164856.pypots
2024-05-25 05:25:57 [INFO]: Epoch 003 - training loss: 0.9882, validation loss: 0.7264
2024-05-25 05:25:57 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch3_loss0.7264355033636093.pypots
2024-05-25 05:26:01 [INFO]: Epoch 004 - training loss: 0.9597, validation loss: 0.7124
2024-05-25 05:26:01 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch4_loss0.7124255865812301.pypots
2024-05-25 05:26:05 [INFO]: Epoch 005 - training loss: 0.9619, validation loss: 0.7047
2024-05-25 05:26:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch5_loss0.7047274798154831.pypots
2024-05-25 05:26:09 [INFO]: Epoch 006 - training loss: 0.9438, validation loss: 0.7008
2024-05-25 05:26:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch6_loss0.7008165210485459.pypots
2024-05-25 05:26:13 [INFO]: Epoch 007 - training loss: 0.9247, validation loss: 0.6955
2024-05-25 05:26:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch7_loss0.6954873085021973.pypots
2024-05-25 05:26:17 [INFO]: Epoch 008 - training loss: 0.9433, validation loss: 0.6931
2024-05-25 05:26:17 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch8_loss0.6930629789829255.pypots
2024-05-25 05:26:21 [INFO]: Epoch 009 - training loss: 0.9427, validation loss: 0.6900
2024-05-25 05:26:21 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch9_loss0.6899630308151246.pypots
2024-05-25 05:26:24 [INFO]: Epoch 010 - training loss: 0.9057, validation loss: 0.6865
2024-05-25 05:26:24 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch10_loss0.686536630988121.pypots
2024-05-25 05:26:28 [INFO]: Epoch 011 - training loss: 0.9106, validation loss: 0.6851
2024-05-25 05:26:28 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch11_loss0.6850782811641694.pypots
2024-05-25 05:26:32 [INFO]: Epoch 012 - training loss: 0.9022, validation loss: 0.6833
2024-05-25 05:26:32 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch12_loss0.6833385616540909.pypots
2024-05-25 05:26:36 [INFO]: Epoch 013 - training loss: 0.8965, validation loss: 0.6835
2024-05-25 05:26:36 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch13_loss0.6834764838218689.pypots
2024-05-25 05:26:40 [INFO]: Epoch 014 - training loss: 0.9077, validation loss: 0.6819
2024-05-25 05:26:40 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch14_loss0.6818915784358979.pypots
2024-05-25 05:26:44 [INFO]: Epoch 015 - training loss: 0.8933, validation loss: 0.6826
2024-05-25 05:26:44 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch15_loss0.6826434314250946.pypots
2024-05-25 05:26:47 [INFO]: Epoch 016 - training loss: 0.8895, validation loss: 0.6809
2024-05-25 05:26:47 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch16_loss0.6808604240417481.pypots
2024-05-25 05:26:51 [INFO]: Epoch 017 - training loss: 0.8873, validation loss: 0.6816
2024-05-25 05:26:51 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch17_loss0.6815519481897354.pypots
2024-05-25 05:26:55 [INFO]: Epoch 018 - training loss: 0.8779, validation loss: 0.6825
2024-05-25 05:26:55 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch18_loss0.6824672251939774.pypots
2024-05-25 05:26:59 [INFO]: Epoch 019 - training loss: 0.8808, validation loss: 0.6818
2024-05-25 05:26:59 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch19_loss0.6818477571010589.pypots
2024-05-25 05:27:03 [INFO]: Epoch 020 - training loss: 0.8895, validation loss: 0.6823
2024-05-25 05:27:03 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch20_loss0.682252436876297.pypots
2024-05-25 05:27:07 [INFO]: Epoch 021 - training loss: 0.8840, validation loss: 0.6825
2024-05-25 05:27:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch21_loss0.6825122773647309.pypots
2024-05-25 05:27:11 [INFO]: Epoch 022 - training loss: 0.8943, validation loss: 0.6826
2024-05-25 05:27:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch22_loss0.6825650066137314.pypots
2024-05-25 05:27:14 [INFO]: Epoch 023 - training loss: 0.9044, validation loss: 0.6831
2024-05-25 05:27:14 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch23_loss0.6830826103687286.pypots
2024-05-25 05:27:18 [INFO]: Epoch 024 - training loss: 0.8735, validation loss: 0.6859
2024-05-25 05:27:18 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch24_loss0.6858616441488266.pypots
2024-05-25 05:27:22 [INFO]: Epoch 025 - training loss: 0.8531, validation loss: 0.6893
2024-05-25 05:27:22 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch25_loss0.6892747014760972.pypots
2024-05-25 05:27:26 [INFO]: Epoch 026 - training loss: 0.8744, validation loss: 0.6881
2024-05-25 05:27:26 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN_epoch26_loss0.6881491422653199.pypots
2024-05-25 05:27:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:27:26 [INFO]: Finished training. The best model is from epoch#16.
2024-05-25 05:27:26 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240525_T052545/MRNN.pypots
2024-05-25 05:27:27 [INFO]: MRNN on Air-Quality: MAE=0.5281, MSE=0.7030
2024-05-25 05:27:27 [INFO]: Successfully saved to augmentation_saved_results/round_3/MRNN_air_quality/imputation.pkl
2024-05-25 05:27:27 [INFO]: Using the given device: cpu
2024-05-25 05:27:27 [INFO]: LOCF on Air-Quality: MAE=0.2206, MSE=0.3343
2024-05-25 05:27:27 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_air_quality".
2024-05-25 05:27:27 [INFO]: Successfully saved to augmentation_saved_results/round_3/LOCF_air_quality/imputation.pkl
2024-05-25 05:27:27 [INFO]: Median on Air-Quality: MAE=0.6668, MSE=1.0938
2024-05-25 05:27:27 [INFO]: Successfully created the given path "saved_results/round_3/Median_air_quality".
2024-05-25 05:27:27 [INFO]: Successfully saved to augmentation_saved_results/round_3/Median_air_quality/imputation.pkl
2024-05-25 05:27:27 [INFO]: Mean on Air-Quality: MAE=0.6965, MSE=1.0305
2024-05-25 05:27:27 [INFO]: Successfully created the given path "saved_results/round_3/Mean_air_quality".
2024-05-25 05:27:27 [INFO]: Successfully saved to augmentation_saved_results/round_3/Mean_air_quality/imputation.pkl
2024-05-25 05:27:27 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-25 05:27:27 [INFO]: Using the given device: cuda:0
2024-05-25 05:27:27 [INFO]: Model files will be saved to augmentation_saved_results/round_4/SAITS_air_quality/20240525_T052727
2024-05-25 05:27:27 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/SAITS_air_quality/20240525_T052727/tensorboard
2024-05-25 05:27:27 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 05:27:28 [INFO]: Epoch 001 - training loss: 1.0577, validation loss: 0.5180
2024-05-25 05:27:28 [INFO]: Epoch 002 - training loss: 0.7519, validation loss: 0.4025
2024-05-25 05:27:29 [INFO]: Epoch 003 - training loss: 0.6445, validation loss: 0.3246
2024-05-25 05:27:30 [INFO]: Epoch 004 - training loss: 0.5712, validation loss: 0.2849
2024-05-25 05:27:30 [INFO]: Epoch 005 - training loss: 0.5166, validation loss: 0.2638
2024-05-25 05:27:31 [INFO]: Epoch 006 - training loss: 0.4809, validation loss: 0.2471
2024-05-25 05:27:32 [INFO]: Epoch 007 - training loss: 0.4559, validation loss: 0.2382
2024-05-25 05:27:32 [INFO]: Epoch 008 - training loss: 0.4394, validation loss: 0.2290
2024-05-25 05:27:33 [INFO]: Epoch 009 - training loss: 0.4255, validation loss: 0.2245
2024-05-25 05:27:34 [INFO]: Epoch 010 - training loss: 0.4137, validation loss: 0.2191
2024-05-25 05:27:34 [INFO]: Epoch 011 - training loss: 0.4040, validation loss: 0.2157
2024-05-25 05:27:35 [INFO]: Epoch 012 - training loss: 0.3968, validation loss: 0.2120
2024-05-25 05:27:36 [INFO]: Epoch 013 - training loss: 0.3900, validation loss: 0.2099
2024-05-25 05:27:36 [INFO]: Epoch 014 - training loss: 0.3818, validation loss: 0.2061
2024-05-25 05:27:37 [INFO]: Epoch 015 - training loss: 0.3748, validation loss: 0.2046
2024-05-25 05:27:38 [INFO]: Epoch 016 - training loss: 0.3699, validation loss: 0.2015
2024-05-25 05:27:38 [INFO]: Epoch 017 - training loss: 0.3650, validation loss: 0.1981
2024-05-25 05:27:39 [INFO]: Epoch 018 - training loss: 0.3607, validation loss: 0.1957
2024-05-25 05:27:40 [INFO]: Epoch 019 - training loss: 0.3554, validation loss: 0.1937
2024-05-25 05:27:40 [INFO]: Epoch 020 - training loss: 0.3525, validation loss: 0.1920
2024-05-25 05:27:41 [INFO]: Epoch 021 - training loss: 0.3506, validation loss: 0.1897
2024-05-25 05:27:42 [INFO]: Epoch 022 - training loss: 0.3457, validation loss: 0.1887
2024-05-25 05:27:42 [INFO]: Epoch 023 - training loss: 0.3429, validation loss: 0.1891
2024-05-25 05:27:43 [INFO]: Epoch 024 - training loss: 0.3403, validation loss: 0.1875
2024-05-25 05:27:44 [INFO]: Epoch 025 - training loss: 0.3363, validation loss: 0.1849
2024-05-25 05:27:44 [INFO]: Epoch 026 - training loss: 0.3337, validation loss: 0.1821
2024-05-25 05:27:45 [INFO]: Epoch 027 - training loss: 0.3325, validation loss: 0.1812
2024-05-25 05:27:46 [INFO]: Epoch 028 - training loss: 0.3295, validation loss: 0.1807
2024-05-25 05:27:46 [INFO]: Epoch 029 - training loss: 0.3267, validation loss: 0.1785
2024-05-25 05:27:47 [INFO]: Epoch 030 - training loss: 0.3243, validation loss: 0.1764
2024-05-25 05:27:48 [INFO]: Epoch 031 - training loss: 0.3238, validation loss: 0.1763
2024-05-25 05:27:48 [INFO]: Epoch 032 - training loss: 0.3214, validation loss: 0.1747
2024-05-25 05:27:49 [INFO]: Epoch 033 - training loss: 0.3188, validation loss: 0.1726
2024-05-25 05:27:50 [INFO]: Epoch 034 - training loss: 0.3190, validation loss: 0.1728
2024-05-25 05:27:50 [INFO]: Epoch 035 - training loss: 0.3165, validation loss: 0.1720
2024-05-25 05:27:51 [INFO]: Epoch 036 - training loss: 0.3132, validation loss: 0.1686
2024-05-25 05:27:52 [INFO]: Epoch 037 - training loss: 0.3106, validation loss: 0.1701
2024-05-25 05:27:52 [INFO]: Epoch 038 - training loss: 0.3112, validation loss: 0.1678
2024-05-25 05:27:53 [INFO]: Epoch 039 - training loss: 0.3074, validation loss: 0.1661
2024-05-25 05:27:54 [INFO]: Epoch 040 - training loss: 0.3064, validation loss: 0.1656
2024-05-25 05:27:54 [INFO]: Epoch 041 - training loss: 0.3042, validation loss: 0.1655
2024-05-25 05:27:55 [INFO]: Epoch 042 - training loss: 0.3039, validation loss: 0.1641
2024-05-25 05:27:56 [INFO]: Epoch 043 - training loss: 0.3016, validation loss: 0.1624
2024-05-25 05:27:56 [INFO]: Epoch 044 - training loss: 0.3005, validation loss: 0.1613
2024-05-25 05:27:57 [INFO]: Epoch 045 - training loss: 0.2986, validation loss: 0.1608
2024-05-25 05:27:58 [INFO]: Epoch 046 - training loss: 0.2966, validation loss: 0.1602
2024-05-25 05:27:58 [INFO]: Epoch 047 - training loss: 0.2961, validation loss: 0.1588
2024-05-25 05:27:59 [INFO]: Epoch 048 - training loss: 0.2933, validation loss: 0.1584
2024-05-25 05:28:00 [INFO]: Epoch 049 - training loss: 0.2921, validation loss: 0.1576
2024-05-25 05:28:00 [INFO]: Epoch 050 - training loss: 0.2923, validation loss: 0.1563
2024-05-25 05:28:01 [INFO]: Epoch 051 - training loss: 0.2902, validation loss: 0.1564
2024-05-25 05:28:02 [INFO]: Epoch 052 - training loss: 0.2900, validation loss: 0.1549
2024-05-25 05:28:02 [INFO]: Epoch 053 - training loss: 0.2884, validation loss: 0.1553
2024-05-25 05:28:03 [INFO]: Epoch 054 - training loss: 0.2873, validation loss: 0.1551
2024-05-25 05:28:04 [INFO]: Epoch 055 - training loss: 0.2860, validation loss: 0.1541
2024-05-25 05:28:04 [INFO]: Epoch 056 - training loss: 0.2849, validation loss: 0.1536
2024-05-25 05:28:05 [INFO]: Epoch 057 - training loss: 0.2830, validation loss: 0.1524
2024-05-25 05:28:06 [INFO]: Epoch 058 - training loss: 0.2808, validation loss: 0.1536
2024-05-25 05:28:07 [INFO]: Epoch 059 - training loss: 0.2801, validation loss: 0.1519
2024-05-25 05:28:07 [INFO]: Epoch 060 - training loss: 0.2789, validation loss: 0.1511
2024-05-25 05:28:08 [INFO]: Epoch 061 - training loss: 0.2787, validation loss: 0.1506
2024-05-25 05:28:09 [INFO]: Epoch 062 - training loss: 0.2778, validation loss: 0.1495
2024-05-25 05:28:09 [INFO]: Epoch 063 - training loss: 0.2762, validation loss: 0.1495
2024-05-25 05:28:10 [INFO]: Epoch 064 - training loss: 0.2746, validation loss: 0.1491
2024-05-25 05:28:11 [INFO]: Epoch 065 - training loss: 0.2737, validation loss: 0.1483
2024-05-25 05:28:11 [INFO]: Epoch 066 - training loss: 0.2737, validation loss: 0.1490
2024-05-25 05:28:12 [INFO]: Epoch 067 - training loss: 0.2739, validation loss: 0.1487
2024-05-25 05:28:13 [INFO]: Epoch 068 - training loss: 0.2715, validation loss: 0.1461
2024-05-25 05:28:13 [INFO]: Epoch 069 - training loss: 0.2714, validation loss: 0.1462
2024-05-25 05:28:14 [INFO]: Epoch 070 - training loss: 0.2691, validation loss: 0.1468
2024-05-25 05:28:15 [INFO]: Epoch 071 - training loss: 0.2676, validation loss: 0.1455
2024-05-25 05:28:15 [INFO]: Epoch 072 - training loss: 0.2661, validation loss: 0.1450
2024-05-25 05:28:16 [INFO]: Epoch 073 - training loss: 0.2639, validation loss: 0.1455
2024-05-25 05:28:17 [INFO]: Epoch 074 - training loss: 0.2653, validation loss: 0.1446
2024-05-25 05:28:17 [INFO]: Epoch 075 - training loss: 0.2641, validation loss: 0.1441
2024-05-25 05:28:18 [INFO]: Epoch 076 - training loss: 0.2634, validation loss: 0.1441
2024-05-25 05:28:19 [INFO]: Epoch 077 - training loss: 0.2620, validation loss: 0.1443
2024-05-25 05:28:19 [INFO]: Epoch 078 - training loss: 0.2618, validation loss: 0.1428
2024-05-25 05:28:20 [INFO]: Epoch 079 - training loss: 0.2604, validation loss: 0.1436
2024-05-25 05:28:21 [INFO]: Epoch 080 - training loss: 0.2604, validation loss: 0.1417
2024-05-25 05:28:21 [INFO]: Epoch 081 - training loss: 0.2587, validation loss: 0.1423
2024-05-25 05:28:22 [INFO]: Epoch 082 - training loss: 0.2592, validation loss: 0.1415
2024-05-25 05:28:23 [INFO]: Epoch 083 - training loss: 0.2564, validation loss: 0.1408
2024-05-25 05:28:23 [INFO]: Epoch 084 - training loss: 0.2569, validation loss: 0.1401
2024-05-25 05:28:24 [INFO]: Epoch 085 - training loss: 0.2557, validation loss: 0.1409
2024-05-25 05:28:25 [INFO]: Epoch 086 - training loss: 0.2550, validation loss: 0.1403
2024-05-25 05:28:25 [INFO]: Epoch 087 - training loss: 0.2537, validation loss: 0.1402
2024-05-25 05:28:26 [INFO]: Epoch 088 - training loss: 0.2543, validation loss: 0.1407
2024-05-25 05:28:27 [INFO]: Epoch 089 - training loss: 0.2531, validation loss: 0.1388
2024-05-25 05:28:27 [INFO]: Epoch 090 - training loss: 0.2522, validation loss: 0.1385
2024-05-25 05:28:28 [INFO]: Epoch 091 - training loss: 0.2519, validation loss: 0.1384
2024-05-25 05:28:29 [INFO]: Epoch 092 - training loss: 0.2510, validation loss: 0.1379
2024-05-25 05:28:29 [INFO]: Epoch 093 - training loss: 0.2503, validation loss: 0.1382
2024-05-25 05:28:30 [INFO]: Epoch 094 - training loss: 0.2513, validation loss: 0.1378
2024-05-25 05:28:31 [INFO]: Epoch 095 - training loss: 0.2496, validation loss: 0.1379
2024-05-25 05:28:31 [INFO]: Epoch 096 - training loss: 0.2489, validation loss: 0.1368
2024-05-25 05:28:32 [INFO]: Epoch 097 - training loss: 0.2482, validation loss: 0.1371
2024-05-25 05:28:33 [INFO]: Epoch 098 - training loss: 0.2477, validation loss: 0.1359
2024-05-25 05:28:33 [INFO]: Epoch 099 - training loss: 0.2476, validation loss: 0.1362
2024-05-25 05:28:34 [INFO]: Epoch 100 - training loss: 0.2466, validation loss: 0.1354
2024-05-25 05:28:35 [INFO]: Epoch 101 - training loss: 0.2450, validation loss: 0.1349
2024-05-25 05:28:35 [INFO]: Epoch 102 - training loss: 0.2445, validation loss: 0.1350
2024-05-25 05:28:36 [INFO]: Epoch 103 - training loss: 0.2440, validation loss: 0.1353
2024-05-25 05:28:37 [INFO]: Epoch 104 - training loss: 0.2453, validation loss: 0.1353
2024-05-25 05:28:37 [INFO]: Epoch 105 - training loss: 0.2436, validation loss: 0.1336
2024-05-25 05:28:38 [INFO]: Epoch 106 - training loss: 0.2441, validation loss: 0.1340
2024-05-25 05:28:39 [INFO]: Epoch 107 - training loss: 0.2435, validation loss: 0.1346
2024-05-25 05:28:39 [INFO]: Epoch 108 - training loss: 0.2432, validation loss: 0.1337
2024-05-25 05:28:40 [INFO]: Epoch 109 - training loss: 0.2434, validation loss: 0.1334
2024-05-25 05:28:41 [INFO]: Epoch 110 - training loss: 0.2421, validation loss: 0.1333
2024-05-25 05:28:41 [INFO]: Epoch 111 - training loss: 0.2409, validation loss: 0.1326
2024-05-25 05:28:42 [INFO]: Epoch 112 - training loss: 0.2412, validation loss: 0.1327
2024-05-25 05:28:43 [INFO]: Epoch 113 - training loss: 0.2408, validation loss: 0.1319
2024-05-25 05:28:43 [INFO]: Epoch 114 - training loss: 0.2399, validation loss: 0.1318
2024-05-25 05:28:44 [INFO]: Epoch 115 - training loss: 0.2381, validation loss: 0.1318
2024-05-25 05:28:45 [INFO]: Epoch 116 - training loss: 0.2388, validation loss: 0.1316
2024-05-25 05:28:45 [INFO]: Epoch 117 - training loss: 0.2371, validation loss: 0.1308
2024-05-25 05:28:46 [INFO]: Epoch 118 - training loss: 0.2366, validation loss: 0.1312
2024-05-25 05:28:47 [INFO]: Epoch 119 - training loss: 0.2355, validation loss: 0.1316
2024-05-25 05:28:47 [INFO]: Epoch 120 - training loss: 0.2362, validation loss: 0.1315
2024-05-25 05:28:48 [INFO]: Epoch 121 - training loss: 0.2361, validation loss: 0.1308
2024-05-25 05:28:49 [INFO]: Epoch 122 - training loss: 0.2360, validation loss: 0.1314
2024-05-25 05:28:49 [INFO]: Epoch 123 - training loss: 0.2349, validation loss: 0.1309
2024-05-25 05:28:50 [INFO]: Epoch 124 - training loss: 0.2348, validation loss: 0.1300
2024-05-25 05:28:51 [INFO]: Epoch 125 - training loss: 0.2341, validation loss: 0.1312
2024-05-25 05:28:51 [INFO]: Epoch 126 - training loss: 0.2354, validation loss: 0.1292
2024-05-25 05:28:52 [INFO]: Epoch 127 - training loss: 0.2337, validation loss: 0.1291
2024-05-25 05:28:53 [INFO]: Epoch 128 - training loss: 0.2329, validation loss: 0.1293
2024-05-25 05:28:53 [INFO]: Epoch 129 - training loss: 0.2333, validation loss: 0.1295
2024-05-25 05:28:54 [INFO]: Epoch 130 - training loss: 0.2341, validation loss: 0.1291
2024-05-25 05:28:55 [INFO]: Epoch 131 - training loss: 0.2325, validation loss: 0.1293
2024-05-25 05:28:55 [INFO]: Epoch 132 - training loss: 0.2311, validation loss: 0.1278
2024-05-25 05:28:56 [INFO]: Epoch 133 - training loss: 0.2306, validation loss: 0.1284
2024-05-25 05:28:57 [INFO]: Epoch 134 - training loss: 0.2297, validation loss: 0.1284
2024-05-25 05:28:57 [INFO]: Epoch 135 - training loss: 0.2297, validation loss: 0.1281
2024-05-25 05:28:58 [INFO]: Epoch 136 - training loss: 0.2297, validation loss: 0.1278
2024-05-25 05:28:59 [INFO]: Epoch 137 - training loss: 0.2281, validation loss: 0.1277
2024-05-25 05:28:59 [INFO]: Epoch 138 - training loss: 0.2300, validation loss: 0.1269
2024-05-25 05:29:00 [INFO]: Epoch 139 - training loss: 0.2288, validation loss: 0.1270
2024-05-25 05:29:01 [INFO]: Epoch 140 - training loss: 0.2273, validation loss: 0.1270
2024-05-25 05:29:01 [INFO]: Epoch 141 - training loss: 0.2274, validation loss: 0.1264
2024-05-25 05:29:02 [INFO]: Epoch 142 - training loss: 0.2268, validation loss: 0.1254
2024-05-25 05:29:03 [INFO]: Epoch 143 - training loss: 0.2261, validation loss: 0.1260
2024-05-25 05:29:03 [INFO]: Epoch 144 - training loss: 0.2279, validation loss: 0.1255
2024-05-25 05:29:04 [INFO]: Epoch 145 - training loss: 0.2274, validation loss: 0.1262
2024-05-25 05:29:05 [INFO]: Epoch 146 - training loss: 0.2263, validation loss: 0.1260
2024-05-25 05:29:05 [INFO]: Epoch 147 - training loss: 0.2261, validation loss: 0.1258
2024-05-25 05:29:06 [INFO]: Epoch 148 - training loss: 0.2253, validation loss: 0.1243
2024-05-25 05:29:07 [INFO]: Epoch 149 - training loss: 0.2252, validation loss: 0.1254
2024-05-25 05:29:07 [INFO]: Epoch 150 - training loss: 0.2249, validation loss: 0.1246
2024-05-25 05:29:08 [INFO]: Epoch 151 - training loss: 0.2233, validation loss: 0.1241
2024-05-25 05:29:09 [INFO]: Epoch 152 - training loss: 0.2223, validation loss: 0.1244
2024-05-25 05:29:09 [INFO]: Epoch 153 - training loss: 0.2226, validation loss: 0.1236
2024-05-25 05:29:10 [INFO]: Epoch 154 - training loss: 0.2231, validation loss: 0.1242
2024-05-25 05:29:11 [INFO]: Epoch 155 - training loss: 0.2234, validation loss: 0.1240
2024-05-25 05:29:11 [INFO]: Epoch 156 - training loss: 0.2232, validation loss: 0.1237
2024-05-25 05:29:12 [INFO]: Epoch 157 - training loss: 0.2230, validation loss: 0.1234
2024-05-25 05:29:13 [INFO]: Epoch 158 - training loss: 0.2223, validation loss: 0.1238
2024-05-25 05:29:13 [INFO]: Epoch 159 - training loss: 0.2220, validation loss: 0.1239
2024-05-25 05:29:14 [INFO]: Epoch 160 - training loss: 0.2216, validation loss: 0.1229
2024-05-25 05:29:15 [INFO]: Epoch 161 - training loss: 0.2205, validation loss: 0.1233
2024-05-25 05:29:15 [INFO]: Epoch 162 - training loss: 0.2194, validation loss: 0.1232
2024-05-25 05:29:16 [INFO]: Epoch 163 - training loss: 0.2200, validation loss: 0.1229
2024-05-25 05:29:17 [INFO]: Epoch 164 - training loss: 0.2196, validation loss: 0.1226
2024-05-25 05:29:17 [INFO]: Epoch 165 - training loss: 0.2193, validation loss: 0.1225
2024-05-25 05:29:18 [INFO]: Epoch 166 - training loss: 0.2188, validation loss: 0.1219
2024-05-25 05:29:19 [INFO]: Epoch 167 - training loss: 0.2192, validation loss: 0.1231
2024-05-25 05:29:20 [INFO]: Epoch 168 - training loss: 0.2193, validation loss: 0.1216
2024-05-25 05:29:20 [INFO]: Epoch 169 - training loss: 0.2179, validation loss: 0.1218
2024-05-25 05:29:21 [INFO]: Epoch 170 - training loss: 0.2175, validation loss: 0.1209
2024-05-25 05:29:22 [INFO]: Epoch 171 - training loss: 0.2189, validation loss: 0.1213
2024-05-25 05:29:22 [INFO]: Epoch 172 - training loss: 0.2196, validation loss: 0.1214
2024-05-25 05:29:23 [INFO]: Epoch 173 - training loss: 0.2185, validation loss: 0.1218
2024-05-25 05:29:24 [INFO]: Epoch 174 - training loss: 0.2177, validation loss: 0.1205
2024-05-25 05:29:24 [INFO]: Epoch 175 - training loss: 0.2159, validation loss: 0.1215
2024-05-25 05:29:25 [INFO]: Epoch 176 - training loss: 0.2154, validation loss: 0.1214
2024-05-25 05:29:26 [INFO]: Epoch 177 - training loss: 0.2148, validation loss: 0.1208
2024-05-25 05:29:26 [INFO]: Epoch 178 - training loss: 0.2154, validation loss: 0.1205
2024-05-25 05:29:27 [INFO]: Epoch 179 - training loss: 0.2153, validation loss: 0.1203
2024-05-25 05:29:28 [INFO]: Epoch 180 - training loss: 0.2138, validation loss: 0.1200
2024-05-25 05:29:28 [INFO]: Epoch 181 - training loss: 0.2146, validation loss: 0.1200
2024-05-25 05:29:29 [INFO]: Epoch 182 - training loss: 0.2162, validation loss: 0.1207
2024-05-25 05:29:30 [INFO]: Epoch 183 - training loss: 0.2150, validation loss: 0.1200
2024-05-25 05:29:30 [INFO]: Epoch 184 - training loss: 0.2136, validation loss: 0.1200
2024-05-25 05:29:31 [INFO]: Epoch 185 - training loss: 0.2119, validation loss: 0.1198
2024-05-25 05:29:32 [INFO]: Epoch 186 - training loss: 0.2125, validation loss: 0.1196
2024-05-25 05:29:32 [INFO]: Epoch 187 - training loss: 0.2136, validation loss: 0.1200
2024-05-25 05:29:33 [INFO]: Epoch 188 - training loss: 0.2139, validation loss: 0.1200
2024-05-25 05:29:34 [INFO]: Epoch 189 - training loss: 0.2124, validation loss: 0.1193
2024-05-25 05:29:34 [INFO]: Epoch 190 - training loss: 0.2135, validation loss: 0.1195
2024-05-25 05:29:35 [INFO]: Epoch 191 - training loss: 0.2114, validation loss: 0.1191
2024-05-25 05:29:36 [INFO]: Epoch 192 - training loss: 0.2109, validation loss: 0.1183
2024-05-25 05:29:36 [INFO]: Epoch 193 - training loss: 0.2103, validation loss: 0.1187
2024-05-25 05:29:37 [INFO]: Epoch 194 - training loss: 0.2104, validation loss: 0.1195
2024-05-25 05:29:38 [INFO]: Epoch 195 - training loss: 0.2111, validation loss: 0.1181
2024-05-25 05:29:38 [INFO]: Epoch 196 - training loss: 0.2109, validation loss: 0.1190
2024-05-25 05:29:39 [INFO]: Epoch 197 - training loss: 0.2110, validation loss: 0.1182
2024-05-25 05:29:40 [INFO]: Epoch 198 - training loss: 0.2101, validation loss: 0.1197
2024-05-25 05:29:40 [INFO]: Epoch 199 - training loss: 0.2112, validation loss: 0.1181
2024-05-25 05:29:41 [INFO]: Epoch 200 - training loss: 0.2092, validation loss: 0.1179
2024-05-25 05:29:42 [INFO]: Epoch 201 - training loss: 0.2102, validation loss: 0.1181
2024-05-25 05:29:42 [INFO]: Epoch 202 - training loss: 0.2095, validation loss: 0.1179
2024-05-25 05:29:43 [INFO]: Epoch 203 - training loss: 0.2087, validation loss: 0.1173
2024-05-25 05:29:44 [INFO]: Epoch 204 - training loss: 0.2087, validation loss: 0.1185
2024-05-25 05:29:44 [INFO]: Epoch 205 - training loss: 0.2082, validation loss: 0.1176
2024-05-25 05:29:45 [INFO]: Epoch 206 - training loss: 0.2075, validation loss: 0.1169
2024-05-25 05:29:46 [INFO]: Epoch 207 - training loss: 0.2080, validation loss: 0.1172
2024-05-25 05:29:46 [INFO]: Epoch 208 - training loss: 0.2076, validation loss: 0.1181
2024-05-25 05:29:47 [INFO]: Epoch 209 - training loss: 0.2080, validation loss: 0.1169
2024-05-25 05:29:48 [INFO]: Epoch 210 - training loss: 0.2058, validation loss: 0.1171
2024-05-25 05:29:48 [INFO]: Epoch 211 - training loss: 0.2068, validation loss: 0.1173
2024-05-25 05:29:49 [INFO]: Epoch 212 - training loss: 0.2070, validation loss: 0.1171
2024-05-25 05:29:50 [INFO]: Epoch 213 - training loss: 0.2068, validation loss: 0.1164
2024-05-25 05:29:50 [INFO]: Epoch 214 - training loss: 0.2068, validation loss: 0.1163
2024-05-25 05:29:51 [INFO]: Epoch 215 - training loss: 0.2060, validation loss: 0.1172
2024-05-25 05:29:52 [INFO]: Epoch 216 - training loss: 0.2061, validation loss: 0.1168
2024-05-25 05:29:52 [INFO]: Epoch 217 - training loss: 0.2082, validation loss: 0.1178
2024-05-25 05:29:53 [INFO]: Epoch 218 - training loss: 0.2070, validation loss: 0.1170
2024-05-25 05:29:54 [INFO]: Epoch 219 - training loss: 0.2063, validation loss: 0.1165
2024-05-25 05:29:54 [INFO]: Epoch 220 - training loss: 0.2057, validation loss: 0.1160
2024-05-25 05:29:55 [INFO]: Epoch 221 - training loss: 0.2040, validation loss: 0.1165
2024-05-25 05:29:56 [INFO]: Epoch 222 - training loss: 0.2035, validation loss: 0.1156
2024-05-25 05:29:56 [INFO]: Epoch 223 - training loss: 0.2042, validation loss: 0.1157
2024-05-25 05:29:57 [INFO]: Epoch 224 - training loss: 0.2030, validation loss: 0.1162
2024-05-25 05:29:58 [INFO]: Epoch 225 - training loss: 0.2021, validation loss: 0.1158
2024-05-25 05:29:58 [INFO]: Epoch 226 - training loss: 0.2044, validation loss: 0.1155
2024-05-25 05:29:59 [INFO]: Epoch 227 - training loss: 0.2049, validation loss: 0.1159
2024-05-25 05:30:00 [INFO]: Epoch 228 - training loss: 0.2053, validation loss: 0.1158
2024-05-25 05:30:00 [INFO]: Epoch 229 - training loss: 0.2030, validation loss: 0.1150
2024-05-25 05:30:01 [INFO]: Epoch 230 - training loss: 0.2033, validation loss: 0.1149
2024-05-25 05:30:02 [INFO]: Epoch 231 - training loss: 0.2021, validation loss: 0.1143
2024-05-25 05:30:02 [INFO]: Epoch 232 - training loss: 0.2057, validation loss: 0.1156
2024-05-25 05:30:03 [INFO]: Epoch 233 - training loss: 0.2039, validation loss: 0.1148
2024-05-25 05:30:04 [INFO]: Epoch 234 - training loss: 0.2029, validation loss: 0.1150
2024-05-25 05:30:04 [INFO]: Epoch 235 - training loss: 0.2034, validation loss: 0.1148
2024-05-25 05:30:05 [INFO]: Epoch 236 - training loss: 0.2030, validation loss: 0.1160
2024-05-25 05:30:06 [INFO]: Epoch 237 - training loss: 0.2053, validation loss: 0.1153
2024-05-25 05:30:06 [INFO]: Epoch 238 - training loss: 0.2017, validation loss: 0.1145
2024-05-25 05:30:07 [INFO]: Epoch 239 - training loss: 0.2000, validation loss: 0.1143
2024-05-25 05:30:08 [INFO]: Epoch 240 - training loss: 0.1992, validation loss: 0.1138
2024-05-25 05:30:08 [INFO]: Epoch 241 - training loss: 0.2003, validation loss: 0.1142
2024-05-25 05:30:09 [INFO]: Epoch 242 - training loss: 0.2003, validation loss: 0.1145
2024-05-25 05:30:10 [INFO]: Epoch 243 - training loss: 0.1990, validation loss: 0.1140
2024-05-25 05:30:10 [INFO]: Epoch 244 - training loss: 0.1987, validation loss: 0.1146
2024-05-25 05:30:11 [INFO]: Epoch 245 - training loss: 0.1997, validation loss: 0.1151
2024-05-25 05:30:12 [INFO]: Epoch 246 - training loss: 0.1992, validation loss: 0.1138
2024-05-25 05:30:12 [INFO]: Epoch 247 - training loss: 0.1991, validation loss: 0.1147
2024-05-25 05:30:13 [INFO]: Epoch 248 - training loss: 0.2003, validation loss: 0.1142
2024-05-25 05:30:14 [INFO]: Epoch 249 - training loss: 0.2012, validation loss: 0.1139
2024-05-25 05:30:14 [INFO]: Epoch 250 - training loss: 0.1989, validation loss: 0.1142
2024-05-25 05:30:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:30:14 [INFO]: Finished training. The best model is from epoch#240.
2024-05-25 05:30:15 [INFO]: Saved the model to augmentation_saved_results/round_4/SAITS_air_quality/20240525_T052727/SAITS.pypots
2024-05-25 05:30:15 [INFO]: SAITS on Air-Quality: MAE=0.1505, MSE=0.1793
2024-05-25 05:30:15 [INFO]: Successfully saved to augmentation_saved_results/round_4/SAITS_air_quality/imputation.pkl
2024-05-25 05:30:15 [INFO]: Using the given device: cuda:0
2024-05-25 05:30:15 [INFO]: Model files will be saved to augmentation_saved_results/round_4/Transformer_air_quality/20240525_T053015
2024-05-25 05:30:15 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/Transformer_air_quality/20240525_T053015/tensorboard
2024-05-25 05:30:15 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 05:30:15 [INFO]: Epoch 001 - training loss: 0.9247, validation loss: 0.4716
2024-05-25 05:30:15 [INFO]: Epoch 002 - training loss: 0.5809, validation loss: 0.3576
2024-05-25 05:30:16 [INFO]: Epoch 003 - training loss: 0.4872, validation loss: 0.2972
2024-05-25 05:30:16 [INFO]: Epoch 004 - training loss: 0.4397, validation loss: 0.2713
2024-05-25 05:30:16 [INFO]: Epoch 005 - training loss: 0.4098, validation loss: 0.2574
2024-05-25 05:30:17 [INFO]: Epoch 006 - training loss: 0.3919, validation loss: 0.2462
2024-05-25 05:30:17 [INFO]: Epoch 007 - training loss: 0.3811, validation loss: 0.2362
2024-05-25 05:30:17 [INFO]: Epoch 008 - training loss: 0.3649, validation loss: 0.2339
2024-05-25 05:30:18 [INFO]: Epoch 009 - training loss: 0.3559, validation loss: 0.2266
2024-05-25 05:30:18 [INFO]: Epoch 010 - training loss: 0.3476, validation loss: 0.2225
2024-05-25 05:30:18 [INFO]: Epoch 011 - training loss: 0.3399, validation loss: 0.2172
2024-05-25 05:30:19 [INFO]: Epoch 012 - training loss: 0.3347, validation loss: 0.2134
2024-05-25 05:30:19 [INFO]: Epoch 013 - training loss: 0.3299, validation loss: 0.2113
2024-05-25 05:30:19 [INFO]: Epoch 014 - training loss: 0.3260, validation loss: 0.2074
2024-05-25 05:30:19 [INFO]: Epoch 015 - training loss: 0.3219, validation loss: 0.2044
2024-05-25 05:30:20 [INFO]: Epoch 016 - training loss: 0.3191, validation loss: 0.2037
2024-05-25 05:30:20 [INFO]: Epoch 017 - training loss: 0.3146, validation loss: 0.1982
2024-05-25 05:30:20 [INFO]: Epoch 018 - training loss: 0.3102, validation loss: 0.1972
2024-05-25 05:30:21 [INFO]: Epoch 019 - training loss: 0.3080, validation loss: 0.1936
2024-05-25 05:30:21 [INFO]: Epoch 020 - training loss: 0.3077, validation loss: 0.1941
2024-05-25 05:30:21 [INFO]: Epoch 021 - training loss: 0.3072, validation loss: 0.1893
2024-05-25 05:30:22 [INFO]: Epoch 022 - training loss: 0.3037, validation loss: 0.1903
2024-05-25 05:30:22 [INFO]: Epoch 023 - training loss: 0.3017, validation loss: 0.1886
2024-05-25 05:30:22 [INFO]: Epoch 024 - training loss: 0.2986, validation loss: 0.1844
2024-05-25 05:30:23 [INFO]: Epoch 025 - training loss: 0.2943, validation loss: 0.1844
2024-05-25 05:30:23 [INFO]: Epoch 026 - training loss: 0.2962, validation loss: 0.1878
2024-05-25 05:30:23 [INFO]: Epoch 027 - training loss: 0.2950, validation loss: 0.1861
2024-05-25 05:30:24 [INFO]: Epoch 028 - training loss: 0.2893, validation loss: 0.1832
2024-05-25 05:30:24 [INFO]: Epoch 029 - training loss: 0.2892, validation loss: 0.1812
2024-05-25 05:30:24 [INFO]: Epoch 030 - training loss: 0.2915, validation loss: 0.1808
2024-05-25 05:30:25 [INFO]: Epoch 031 - training loss: 0.2854, validation loss: 0.1803
2024-05-25 05:30:25 [INFO]: Epoch 032 - training loss: 0.2828, validation loss: 0.1796
2024-05-25 05:30:25 [INFO]: Epoch 033 - training loss: 0.2853, validation loss: 0.1788
2024-05-25 05:30:25 [INFO]: Epoch 034 - training loss: 0.2820, validation loss: 0.1777
2024-05-25 05:30:26 [INFO]: Epoch 035 - training loss: 0.2796, validation loss: 0.1775
2024-05-25 05:30:26 [INFO]: Epoch 036 - training loss: 0.2797, validation loss: 0.1746
2024-05-25 05:30:26 [INFO]: Epoch 037 - training loss: 0.2771, validation loss: 0.1757
2024-05-25 05:30:27 [INFO]: Epoch 038 - training loss: 0.2758, validation loss: 0.1746
2024-05-25 05:30:27 [INFO]: Epoch 039 - training loss: 0.2757, validation loss: 0.1726
2024-05-25 05:30:27 [INFO]: Epoch 040 - training loss: 0.2733, validation loss: 0.1738
2024-05-25 05:30:28 [INFO]: Epoch 041 - training loss: 0.2731, validation loss: 0.1740
2024-05-25 05:30:28 [INFO]: Epoch 042 - training loss: 0.2706, validation loss: 0.1725
2024-05-25 05:30:28 [INFO]: Epoch 043 - training loss: 0.2702, validation loss: 0.1731
2024-05-25 05:30:29 [INFO]: Epoch 044 - training loss: 0.2682, validation loss: 0.1707
2024-05-25 05:30:29 [INFO]: Epoch 045 - training loss: 0.2685, validation loss: 0.1719
2024-05-25 05:30:29 [INFO]: Epoch 046 - training loss: 0.2684, validation loss: 0.1699
2024-05-25 05:30:30 [INFO]: Epoch 047 - training loss: 0.2672, validation loss: 0.1701
2024-05-25 05:30:30 [INFO]: Epoch 048 - training loss: 0.2666, validation loss: 0.1698
2024-05-25 05:30:30 [INFO]: Epoch 049 - training loss: 0.2655, validation loss: 0.1702
2024-05-25 05:30:31 [INFO]: Epoch 050 - training loss: 0.2636, validation loss: 0.1687
2024-05-25 05:30:31 [INFO]: Epoch 051 - training loss: 0.2659, validation loss: 0.1671
2024-05-25 05:30:31 [INFO]: Epoch 052 - training loss: 0.2632, validation loss: 0.1670
2024-05-25 05:30:31 [INFO]: Epoch 053 - training loss: 0.2630, validation loss: 0.1679
2024-05-25 05:30:32 [INFO]: Epoch 054 - training loss: 0.2609, validation loss: 0.1681
2024-05-25 05:30:32 [INFO]: Epoch 055 - training loss: 0.2583, validation loss: 0.1681
2024-05-25 05:30:32 [INFO]: Epoch 056 - training loss: 0.2583, validation loss: 0.1647
2024-05-25 05:30:33 [INFO]: Epoch 057 - training loss: 0.2593, validation loss: 0.1654
2024-05-25 05:30:33 [INFO]: Epoch 058 - training loss: 0.2588, validation loss: 0.1673
2024-05-25 05:30:33 [INFO]: Epoch 059 - training loss: 0.2572, validation loss: 0.1625
2024-05-25 05:30:34 [INFO]: Epoch 060 - training loss: 0.2554, validation loss: 0.1639
2024-05-25 05:30:34 [INFO]: Epoch 061 - training loss: 0.2542, validation loss: 0.1647
2024-05-25 05:30:34 [INFO]: Epoch 062 - training loss: 0.2551, validation loss: 0.1677
2024-05-25 05:30:35 [INFO]: Epoch 063 - training loss: 0.2572, validation loss: 0.1629
2024-05-25 05:30:35 [INFO]: Epoch 064 - training loss: 0.2571, validation loss: 0.1598
2024-05-25 05:30:35 [INFO]: Epoch 065 - training loss: 0.2525, validation loss: 0.1630
2024-05-25 05:30:36 [INFO]: Epoch 066 - training loss: 0.2507, validation loss: 0.1601
2024-05-25 05:30:36 [INFO]: Epoch 067 - training loss: 0.2514, validation loss: 0.1624
2024-05-25 05:30:36 [INFO]: Epoch 068 - training loss: 0.2521, validation loss: 0.1614
2024-05-25 05:30:37 [INFO]: Epoch 069 - training loss: 0.2502, validation loss: 0.1607
2024-05-25 05:30:37 [INFO]: Epoch 070 - training loss: 0.2463, validation loss: 0.1590
2024-05-25 05:30:37 [INFO]: Epoch 071 - training loss: 0.2469, validation loss: 0.1611
2024-05-25 05:30:37 [INFO]: Epoch 072 - training loss: 0.2454, validation loss: 0.1596
2024-05-25 05:30:38 [INFO]: Epoch 073 - training loss: 0.2454, validation loss: 0.1583
2024-05-25 05:30:38 [INFO]: Epoch 074 - training loss: 0.2445, validation loss: 0.1593
2024-05-25 05:30:38 [INFO]: Epoch 075 - training loss: 0.2450, validation loss: 0.1578
2024-05-25 05:30:39 [INFO]: Epoch 076 - training loss: 0.2438, validation loss: 0.1604
2024-05-25 05:30:39 [INFO]: Epoch 077 - training loss: 0.2410, validation loss: 0.1593
2024-05-25 05:30:39 [INFO]: Epoch 078 - training loss: 0.2430, validation loss: 0.1575
2024-05-25 05:30:40 [INFO]: Epoch 079 - training loss: 0.2433, validation loss: 0.1576
2024-05-25 05:30:40 [INFO]: Epoch 080 - training loss: 0.2423, validation loss: 0.1573
2024-05-25 05:30:40 [INFO]: Epoch 081 - training loss: 0.2425, validation loss: 0.1572
2024-05-25 05:30:41 [INFO]: Epoch 082 - training loss: 0.2382, validation loss: 0.1594
2024-05-25 05:30:41 [INFO]: Epoch 083 - training loss: 0.2387, validation loss: 0.1571
2024-05-25 05:30:41 [INFO]: Epoch 084 - training loss: 0.2409, validation loss: 0.1555
2024-05-25 05:30:42 [INFO]: Epoch 085 - training loss: 0.2404, validation loss: 0.1543
2024-05-25 05:30:42 [INFO]: Epoch 086 - training loss: 0.2379, validation loss: 0.1554
2024-05-25 05:30:42 [INFO]: Epoch 087 - training loss: 0.2375, validation loss: 0.1548
2024-05-25 05:30:43 [INFO]: Epoch 088 - training loss: 0.2377, validation loss: 0.1562
2024-05-25 05:30:43 [INFO]: Epoch 089 - training loss: 0.2380, validation loss: 0.1545
2024-05-25 05:30:43 [INFO]: Epoch 090 - training loss: 0.2347, validation loss: 0.1544
2024-05-25 05:30:43 [INFO]: Epoch 091 - training loss: 0.2353, validation loss: 0.1508
2024-05-25 05:30:44 [INFO]: Epoch 092 - training loss: 0.2338, validation loss: 0.1541
2024-05-25 05:30:44 [INFO]: Epoch 093 - training loss: 0.2398, validation loss: 0.1586
2024-05-25 05:30:44 [INFO]: Epoch 094 - training loss: 0.2381, validation loss: 0.1569
2024-05-25 05:30:45 [INFO]: Epoch 095 - training loss: 0.2350, validation loss: 0.1539
2024-05-25 05:30:45 [INFO]: Epoch 096 - training loss: 0.2321, validation loss: 0.1509
2024-05-25 05:30:45 [INFO]: Epoch 097 - training loss: 0.2316, validation loss: 0.1526
2024-05-25 05:30:46 [INFO]: Epoch 098 - training loss: 0.2294, validation loss: 0.1512
2024-05-25 05:30:46 [INFO]: Epoch 099 - training loss: 0.2281, validation loss: 0.1514
2024-05-25 05:30:46 [INFO]: Epoch 100 - training loss: 0.2311, validation loss: 0.1521
2024-05-25 05:30:47 [INFO]: Epoch 101 - training loss: 0.2291, validation loss: 0.1507
2024-05-25 05:30:47 [INFO]: Epoch 102 - training loss: 0.2302, validation loss: 0.1508
2024-05-25 05:30:47 [INFO]: Epoch 103 - training loss: 0.2272, validation loss: 0.1507
2024-05-25 05:30:48 [INFO]: Epoch 104 - training loss: 0.2266, validation loss: 0.1494
2024-05-25 05:30:48 [INFO]: Epoch 105 - training loss: 0.2263, validation loss: 0.1511
2024-05-25 05:30:48 [INFO]: Epoch 106 - training loss: 0.2259, validation loss: 0.1507
2024-05-25 05:30:49 [INFO]: Epoch 107 - training loss: 0.2285, validation loss: 0.1483
2024-05-25 05:30:49 [INFO]: Epoch 108 - training loss: 0.2267, validation loss: 0.1489
2024-05-25 05:30:49 [INFO]: Epoch 109 - training loss: 0.2250, validation loss: 0.1481
2024-05-25 05:30:49 [INFO]: Epoch 110 - training loss: 0.2245, validation loss: 0.1479
2024-05-25 05:30:50 [INFO]: Epoch 111 - training loss: 0.2267, validation loss: 0.1482
2024-05-25 05:30:50 [INFO]: Epoch 112 - training loss: 0.2245, validation loss: 0.1497
2024-05-25 05:30:50 [INFO]: Epoch 113 - training loss: 0.2236, validation loss: 0.1493
2024-05-25 05:30:51 [INFO]: Epoch 114 - training loss: 0.2228, validation loss: 0.1485
2024-05-25 05:30:51 [INFO]: Epoch 115 - training loss: 0.2234, validation loss: 0.1467
2024-05-25 05:30:51 [INFO]: Epoch 116 - training loss: 0.2202, validation loss: 0.1496
2024-05-25 05:30:52 [INFO]: Epoch 117 - training loss: 0.2204, validation loss: 0.1481
2024-05-25 05:30:52 [INFO]: Epoch 118 - training loss: 0.2205, validation loss: 0.1496
2024-05-25 05:30:52 [INFO]: Epoch 119 - training loss: 0.2228, validation loss: 0.1459
2024-05-25 05:30:53 [INFO]: Epoch 120 - training loss: 0.2206, validation loss: 0.1475
2024-05-25 05:30:53 [INFO]: Epoch 121 - training loss: 0.2208, validation loss: 0.1471
2024-05-25 05:30:53 [INFO]: Epoch 122 - training loss: 0.2181, validation loss: 0.1462
2024-05-25 05:30:54 [INFO]: Epoch 123 - training loss: 0.2186, validation loss: 0.1462
2024-05-25 05:30:54 [INFO]: Epoch 124 - training loss: 0.2212, validation loss: 0.1453
2024-05-25 05:30:54 [INFO]: Epoch 125 - training loss: 0.2185, validation loss: 0.1460
2024-05-25 05:30:55 [INFO]: Epoch 126 - training loss: 0.2216, validation loss: 0.1457
2024-05-25 05:30:55 [INFO]: Epoch 127 - training loss: 0.2194, validation loss: 0.1447
2024-05-25 05:30:55 [INFO]: Epoch 128 - training loss: 0.2153, validation loss: 0.1459
2024-05-25 05:30:56 [INFO]: Epoch 129 - training loss: 0.2155, validation loss: 0.1449
2024-05-25 05:30:56 [INFO]: Epoch 130 - training loss: 0.2163, validation loss: 0.1474
2024-05-25 05:30:56 [INFO]: Epoch 131 - training loss: 0.2178, validation loss: 0.1456
2024-05-25 05:30:56 [INFO]: Epoch 132 - training loss: 0.2145, validation loss: 0.1445
2024-05-25 05:30:57 [INFO]: Epoch 133 - training loss: 0.2151, validation loss: 0.1452
2024-05-25 05:30:57 [INFO]: Epoch 134 - training loss: 0.2151, validation loss: 0.1454
2024-05-25 05:30:57 [INFO]: Epoch 135 - training loss: 0.2142, validation loss: 0.1433
2024-05-25 05:30:58 [INFO]: Epoch 136 - training loss: 0.2138, validation loss: 0.1439
2024-05-25 05:30:58 [INFO]: Epoch 137 - training loss: 0.2144, validation loss: 0.1446
2024-05-25 05:30:58 [INFO]: Epoch 138 - training loss: 0.2150, validation loss: 0.1432
2024-05-25 05:30:59 [INFO]: Epoch 139 - training loss: 0.2133, validation loss: 0.1428
2024-05-25 05:30:59 [INFO]: Epoch 140 - training loss: 0.2150, validation loss: 0.1421
2024-05-25 05:30:59 [INFO]: Epoch 141 - training loss: 0.2139, validation loss: 0.1430
2024-05-25 05:31:00 [INFO]: Epoch 142 - training loss: 0.2108, validation loss: 0.1411
2024-05-25 05:31:00 [INFO]: Epoch 143 - training loss: 0.2110, validation loss: 0.1413
2024-05-25 05:31:00 [INFO]: Epoch 144 - training loss: 0.2112, validation loss: 0.1410
2024-05-25 05:31:01 [INFO]: Epoch 145 - training loss: 0.2120, validation loss: 0.1427
2024-05-25 05:31:01 [INFO]: Epoch 146 - training loss: 0.2108, validation loss: 0.1423
2024-05-25 05:31:01 [INFO]: Epoch 147 - training loss: 0.2120, validation loss: 0.1409
2024-05-25 05:31:02 [INFO]: Epoch 148 - training loss: 0.2112, validation loss: 0.1415
2024-05-25 05:31:02 [INFO]: Epoch 149 - training loss: 0.2127, validation loss: 0.1420
2024-05-25 05:31:02 [INFO]: Epoch 150 - training loss: 0.2122, validation loss: 0.1416
2024-05-25 05:31:02 [INFO]: Epoch 151 - training loss: 0.2087, validation loss: 0.1411
2024-05-25 05:31:03 [INFO]: Epoch 152 - training loss: 0.2094, validation loss: 0.1415
2024-05-25 05:31:03 [INFO]: Epoch 153 - training loss: 0.2097, validation loss: 0.1412
2024-05-25 05:31:03 [INFO]: Epoch 154 - training loss: 0.2101, validation loss: 0.1432
2024-05-25 05:31:04 [INFO]: Epoch 155 - training loss: 0.2130, validation loss: 0.1444
2024-05-25 05:31:04 [INFO]: Epoch 156 - training loss: 0.2099, validation loss: 0.1421
2024-05-25 05:31:04 [INFO]: Epoch 157 - training loss: 0.2080, validation loss: 0.1413
2024-05-25 05:31:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:31:04 [INFO]: Finished training. The best model is from epoch#147.
2024-05-25 05:31:04 [INFO]: Saved the model to augmentation_saved_results/round_4/Transformer_air_quality/20240525_T053015/Transformer.pypots
2024-05-25 05:31:04 [INFO]: Transformer on Air-Quality: MAE=0.1721, MSE=0.2109
2024-05-25 05:31:04 [INFO]: Successfully saved to augmentation_saved_results/round_4/Transformer_air_quality/imputation.pkl
2024-05-25 05:31:04 [INFO]: Using the given device: cuda:0
2024-05-25 05:31:04 [INFO]: Model files will be saved to augmentation_saved_results/round_4/TimesNet_air_quality/20240525_T053104
2024-05-25 05:31:04 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/TimesNet_air_quality/20240525_T053104/tensorboard
2024-05-25 05:31:05 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 05:31:05 [INFO]: Epoch 001 - training loss: 0.3253, validation loss: 0.2642
2024-05-25 05:31:06 [INFO]: Epoch 002 - training loss: 0.2282, validation loss: 0.2273
2024-05-25 05:31:07 [INFO]: Epoch 003 - training loss: 0.2128, validation loss: 0.2082
2024-05-25 05:31:07 [INFO]: Epoch 004 - training loss: 0.1656, validation loss: 0.2014
2024-05-25 05:31:08 [INFO]: Epoch 005 - training loss: 0.1751, validation loss: 0.2001
2024-05-25 05:31:08 [INFO]: Epoch 006 - training loss: 0.1748, validation loss: 0.1918
2024-05-25 05:31:09 [INFO]: Epoch 007 - training loss: 0.1750, validation loss: 0.1885
2024-05-25 05:31:09 [INFO]: Epoch 008 - training loss: 0.1679, validation loss: 0.1768
2024-05-25 05:31:10 [INFO]: Epoch 009 - training loss: 0.1683, validation loss: 0.1775
2024-05-25 05:31:10 [INFO]: Epoch 010 - training loss: 0.1658, validation loss: 0.1742
2024-05-25 05:31:11 [INFO]: Epoch 011 - training loss: 0.1445, validation loss: 0.1761
2024-05-25 05:31:11 [INFO]: Epoch 012 - training loss: 0.1521, validation loss: 0.1702
2024-05-25 05:31:12 [INFO]: Epoch 013 - training loss: 0.1572, validation loss: 0.1721
2024-05-25 05:31:12 [INFO]: Epoch 014 - training loss: 0.1425, validation loss: 0.1705
2024-05-25 05:31:13 [INFO]: Epoch 015 - training loss: 0.1367, validation loss: 0.1721
2024-05-25 05:31:13 [INFO]: Epoch 016 - training loss: 0.1619, validation loss: 0.1708
2024-05-25 05:31:14 [INFO]: Epoch 017 - training loss: 0.1355, validation loss: 0.1777
2024-05-25 05:31:14 [INFO]: Epoch 018 - training loss: 0.1385, validation loss: 0.1693
2024-05-25 05:31:15 [INFO]: Epoch 019 - training loss: 0.1166, validation loss: 0.1659
2024-05-25 05:31:15 [INFO]: Epoch 020 - training loss: 0.1150, validation loss: 0.1646
2024-05-25 05:31:16 [INFO]: Epoch 021 - training loss: 0.1366, validation loss: 0.1623
2024-05-25 05:31:17 [INFO]: Epoch 022 - training loss: 0.1170, validation loss: 0.1618
2024-05-25 05:31:17 [INFO]: Epoch 023 - training loss: 0.1072, validation loss: 0.1602
2024-05-25 05:31:18 [INFO]: Epoch 024 - training loss: 0.1066, validation loss: 0.1606
2024-05-25 05:31:18 [INFO]: Epoch 025 - training loss: 0.1079, validation loss: 0.1586
2024-05-25 05:31:19 [INFO]: Epoch 026 - training loss: 0.1194, validation loss: 0.1615
2024-05-25 05:31:19 [INFO]: Epoch 027 - training loss: 0.1214, validation loss: 0.1584
2024-05-25 05:31:20 [INFO]: Epoch 028 - training loss: 0.1180, validation loss: 0.1592
2024-05-25 05:31:20 [INFO]: Epoch 029 - training loss: 0.1118, validation loss: 0.1568
2024-05-25 05:31:21 [INFO]: Epoch 030 - training loss: 0.1370, validation loss: 0.1590
2024-05-25 05:31:21 [INFO]: Epoch 031 - training loss: 0.1165, validation loss: 0.1577
2024-05-25 05:31:22 [INFO]: Epoch 032 - training loss: 0.1219, validation loss: 0.1587
2024-05-25 05:31:22 [INFO]: Epoch 033 - training loss: 0.1231, validation loss: 0.1563
2024-05-25 05:31:23 [INFO]: Epoch 034 - training loss: 0.1184, validation loss: 0.1578
2024-05-25 05:31:23 [INFO]: Epoch 035 - training loss: 0.1049, validation loss: 0.1544
2024-05-25 05:31:24 [INFO]: Epoch 036 - training loss: 0.1138, validation loss: 0.1548
2024-05-25 05:31:24 [INFO]: Epoch 037 - training loss: 0.1059, validation loss: 0.1541
2024-05-25 05:31:25 [INFO]: Epoch 038 - training loss: 0.1065, validation loss: 0.1540
2024-05-25 05:31:25 [INFO]: Epoch 039 - training loss: 0.1001, validation loss: 0.1541
2024-05-25 05:31:26 [INFO]: Epoch 040 - training loss: 0.1135, validation loss: 0.1545
2024-05-25 05:31:26 [INFO]: Epoch 041 - training loss: 0.1037, validation loss: 0.1582
2024-05-25 05:31:27 [INFO]: Epoch 042 - training loss: 0.1195, validation loss: 0.1487
2024-05-25 05:31:28 [INFO]: Epoch 043 - training loss: 0.1184, validation loss: 0.1535
2024-05-25 05:31:28 [INFO]: Epoch 044 - training loss: 0.1071, validation loss: 0.1516
2024-05-25 05:31:29 [INFO]: Epoch 045 - training loss: 0.1082, validation loss: 0.1523
2024-05-25 05:31:29 [INFO]: Epoch 046 - training loss: 0.1016, validation loss: 0.1512
2024-05-25 05:31:30 [INFO]: Epoch 047 - training loss: 0.1003, validation loss: 0.1519
2024-05-25 05:31:30 [INFO]: Epoch 048 - training loss: 0.0915, validation loss: 0.1485
2024-05-25 05:31:31 [INFO]: Epoch 049 - training loss: 0.1120, validation loss: 0.1497
2024-05-25 05:31:31 [INFO]: Epoch 050 - training loss: 0.1125, validation loss: 0.1546
2024-05-25 05:31:32 [INFO]: Epoch 051 - training loss: 0.1206, validation loss: 0.1503
2024-05-25 05:31:32 [INFO]: Epoch 052 - training loss: 0.1117, validation loss: 0.1557
2024-05-25 05:31:33 [INFO]: Epoch 053 - training loss: 0.1086, validation loss: 0.1531
2024-05-25 05:31:33 [INFO]: Epoch 054 - training loss: 0.0930, validation loss: 0.1518
2024-05-25 05:31:34 [INFO]: Epoch 055 - training loss: 0.1160, validation loss: 0.1520
2024-05-25 05:31:34 [INFO]: Epoch 056 - training loss: 0.0935, validation loss: 0.1534
2024-05-25 05:31:35 [INFO]: Epoch 057 - training loss: 0.1129, validation loss: 0.1553
2024-05-25 05:31:35 [INFO]: Epoch 058 - training loss: 0.0970, validation loss: 0.1482
2024-05-25 05:31:36 [INFO]: Epoch 059 - training loss: 0.0975, validation loss: 0.1524
2024-05-25 05:31:36 [INFO]: Epoch 060 - training loss: 0.1018, validation loss: 0.1554
2024-05-25 05:31:37 [INFO]: Epoch 061 - training loss: 0.1101, validation loss: 0.1506
2024-05-25 05:31:38 [INFO]: Epoch 062 - training loss: 0.0913, validation loss: 0.1521
2024-05-25 05:31:38 [INFO]: Epoch 063 - training loss: 0.1102, validation loss: 0.1509
2024-05-25 05:31:39 [INFO]: Epoch 064 - training loss: 0.0975, validation loss: 0.1588
2024-05-25 05:31:39 [INFO]: Epoch 065 - training loss: 0.1016, validation loss: 0.1532
2024-05-25 05:31:40 [INFO]: Epoch 066 - training loss: 0.0976, validation loss: 0.1505
2024-05-25 05:31:40 [INFO]: Epoch 067 - training loss: 0.0951, validation loss: 0.1501
2024-05-25 05:31:41 [INFO]: Epoch 068 - training loss: 0.1045, validation loss: 0.1512
2024-05-25 05:31:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:31:41 [INFO]: Finished training. The best model is from epoch#58.
2024-05-25 05:31:41 [INFO]: Saved the model to augmentation_saved_results/round_4/TimesNet_air_quality/20240525_T053104/TimesNet.pypots
2024-05-25 05:31:41 [INFO]: TimesNet on Air-Quality: MAE=0.1647, MSE=0.2335
2024-05-25 05:31:41 [INFO]: Successfully saved to augmentation_saved_results/round_4/TimesNet_air_quality/imputation.pkl
2024-05-25 05:31:41 [INFO]: Using the given device: cuda:0
2024-05-25 05:31:41 [INFO]: Model files will be saved to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141
2024-05-25 05:31:41 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/tensorboard
2024-05-25 05:31:41 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 05:31:58 [INFO]: Epoch 001 - training loss: 0.4758, validation loss: 0.3370
2024-05-25 05:31:58 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch1_loss0.33696078062057494.pypots
2024-05-25 05:32:15 [INFO]: Epoch 002 - training loss: 0.2860, validation loss: 0.2764
2024-05-25 05:32:15 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch2_loss0.2763753682374954.pypots
2024-05-25 05:32:31 [INFO]: Epoch 003 - training loss: 0.2437, validation loss: 0.2404
2024-05-25 05:32:31 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch3_loss0.24039330333471298.pypots
2024-05-25 05:32:48 [INFO]: Epoch 004 - training loss: 0.2400, validation loss: 0.2096
2024-05-25 05:32:48 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch4_loss0.20958315283060075.pypots
2024-05-25 05:33:05 [INFO]: Epoch 005 - training loss: 0.2091, validation loss: 0.2003
2024-05-25 05:33:05 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch5_loss0.200261627137661.pypots
2024-05-25 05:33:22 [INFO]: Epoch 006 - training loss: 0.1881, validation loss: 0.1719
2024-05-25 05:33:22 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch6_loss0.17189861088991165.pypots
2024-05-25 05:33:38 [INFO]: Epoch 007 - training loss: 0.1938, validation loss: 0.1667
2024-05-25 05:33:38 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch7_loss0.16665276885032654.pypots
2024-05-25 05:33:55 [INFO]: Epoch 008 - training loss: 0.1780, validation loss: 0.1710
2024-05-25 05:33:55 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch8_loss0.17095465064048768.pypots
2024-05-25 05:34:12 [INFO]: Epoch 009 - training loss: 0.1800, validation loss: 0.1627
2024-05-25 05:34:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch9_loss0.16272925287485124.pypots
2024-05-25 05:34:29 [INFO]: Epoch 010 - training loss: 0.1893, validation loss: 0.1594
2024-05-25 05:34:29 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch10_loss0.15938640236854554.pypots
2024-05-25 05:34:46 [INFO]: Epoch 011 - training loss: 0.1666, validation loss: 0.1531
2024-05-25 05:34:46 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch11_loss0.1531197115778923.pypots
2024-05-25 05:35:02 [INFO]: Epoch 012 - training loss: 0.1753, validation loss: 0.1504
2024-05-25 05:35:02 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch12_loss0.15044160187244415.pypots
2024-05-25 05:35:19 [INFO]: Epoch 013 - training loss: 0.1766, validation loss: 0.1559
2024-05-25 05:35:19 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch13_loss0.15589769929647446.pypots
2024-05-25 05:35:36 [INFO]: Epoch 014 - training loss: 0.1710, validation loss: 0.1495
2024-05-25 05:35:36 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch14_loss0.14954855144023896.pypots
2024-05-25 05:35:53 [INFO]: Epoch 015 - training loss: 0.1665, validation loss: 0.1514
2024-05-25 05:35:53 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch15_loss0.15137399435043336.pypots
2024-05-25 05:36:10 [INFO]: Epoch 016 - training loss: 0.1694, validation loss: 0.1423
2024-05-25 05:36:10 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch16_loss0.14228666201233864.pypots
2024-05-25 05:36:26 [INFO]: Epoch 017 - training loss: 0.1665, validation loss: 0.1490
2024-05-25 05:36:26 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch17_loss0.1490217849612236.pypots
2024-05-25 05:36:43 [INFO]: Epoch 018 - training loss: 0.1523, validation loss: 0.1391
2024-05-25 05:36:43 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch18_loss0.13907381966710092.pypots
2024-05-25 05:37:00 [INFO]: Epoch 019 - training loss: 0.1663, validation loss: 0.1428
2024-05-25 05:37:00 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch19_loss0.1428412526845932.pypots
2024-05-25 05:37:17 [INFO]: Epoch 020 - training loss: 0.1761, validation loss: 0.1474
2024-05-25 05:37:17 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch20_loss0.14737250953912734.pypots
2024-05-25 05:37:34 [INFO]: Epoch 021 - training loss: 0.1649, validation loss: 0.1352
2024-05-25 05:37:34 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch21_loss0.13518187329173087.pypots
2024-05-25 05:37:50 [INFO]: Epoch 022 - training loss: 0.1700, validation loss: 0.1354
2024-05-25 05:37:50 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch22_loss0.1354055479168892.pypots
2024-05-25 05:38:07 [INFO]: Epoch 023 - training loss: 0.1376, validation loss: 0.1330
2024-05-25 05:38:07 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch23_loss0.13304673582315446.pypots
2024-05-25 05:38:24 [INFO]: Epoch 024 - training loss: 0.1544, validation loss: 0.1346
2024-05-25 05:38:24 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch24_loss0.1345917120575905.pypots
2024-05-25 05:38:41 [INFO]: Epoch 025 - training loss: 0.1443, validation loss: 0.1306
2024-05-25 05:38:41 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch25_loss0.1306091971695423.pypots
2024-05-25 05:38:57 [INFO]: Epoch 026 - training loss: 0.1391, validation loss: 0.1304
2024-05-25 05:38:58 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch26_loss0.13036669790744781.pypots
2024-05-25 05:39:14 [INFO]: Epoch 027 - training loss: 0.1391, validation loss: 0.1336
2024-05-25 05:39:14 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch27_loss0.13363526836037637.pypots
2024-05-25 05:39:31 [INFO]: Epoch 028 - training loss: 0.1392, validation loss: 0.1298
2024-05-25 05:39:31 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch28_loss0.12977969720959665.pypots
2024-05-25 05:39:48 [INFO]: Epoch 029 - training loss: 0.1467, validation loss: 0.1299
2024-05-25 05:39:48 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch29_loss0.12987066954374313.pypots
2024-05-25 05:40:05 [INFO]: Epoch 030 - training loss: 0.1419, validation loss: 0.1316
2024-05-25 05:40:05 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch30_loss0.13161581084132196.pypots
2024-05-25 05:40:21 [INFO]: Epoch 031 - training loss: 0.1320, validation loss: 0.1316
2024-05-25 05:40:21 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch31_loss0.1316089391708374.pypots
2024-05-25 05:40:38 [INFO]: Epoch 032 - training loss: 0.1512, validation loss: 0.1282
2024-05-25 05:40:38 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch32_loss0.12817232236266135.pypots
2024-05-25 05:40:55 [INFO]: Epoch 033 - training loss: 0.1428, validation loss: 0.1264
2024-05-25 05:40:55 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch33_loss0.12639149650931358.pypots
2024-05-25 05:41:12 [INFO]: Epoch 034 - training loss: 0.1376, validation loss: 0.1247
2024-05-25 05:41:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch34_loss0.12468534782528877.pypots
2024-05-25 05:41:29 [INFO]: Epoch 035 - training loss: 0.1364, validation loss: 0.1273
2024-05-25 05:41:29 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch35_loss0.1273347795009613.pypots
2024-05-25 05:41:45 [INFO]: Epoch 036 - training loss: 0.1286, validation loss: 0.1258
2024-05-25 05:41:45 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch36_loss0.12584484443068505.pypots
2024-05-25 05:42:02 [INFO]: Epoch 037 - training loss: 0.1311, validation loss: 0.1212
2024-05-25 05:42:02 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch37_loss0.12119270041584969.pypots
2024-05-25 05:42:19 [INFO]: Epoch 038 - training loss: 0.1317, validation loss: 0.1219
2024-05-25 05:42:19 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch38_loss0.12193112596869468.pypots
2024-05-25 05:42:36 [INFO]: Epoch 039 - training loss: 0.1421, validation loss: 0.1209
2024-05-25 05:42:36 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch39_loss0.12089436501264572.pypots
2024-05-25 05:42:53 [INFO]: Epoch 040 - training loss: 0.1404, validation loss: 0.1198
2024-05-25 05:42:53 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch40_loss0.1197940655052662.pypots
2024-05-25 05:43:09 [INFO]: Epoch 041 - training loss: 0.1239, validation loss: 0.1213
2024-05-25 05:43:09 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch41_loss0.12126481756567956.pypots
2024-05-25 05:43:26 [INFO]: Epoch 042 - training loss: 0.1285, validation loss: 0.1212
2024-05-25 05:43:26 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch42_loss0.12117295935750008.pypots
2024-05-25 05:43:43 [INFO]: Epoch 043 - training loss: 0.1278, validation loss: 0.1218
2024-05-25 05:43:43 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch43_loss0.1218270257115364.pypots
2024-05-25 05:44:00 [INFO]: Epoch 044 - training loss: 0.1428, validation loss: 0.1200
2024-05-25 05:44:00 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch44_loss0.12001268193125725.pypots
2024-05-25 05:44:16 [INFO]: Epoch 045 - training loss: 0.1202, validation loss: 0.1179
2024-05-25 05:44:16 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch45_loss0.11793348789215088.pypots
2024-05-25 05:44:33 [INFO]: Epoch 046 - training loss: 0.1283, validation loss: 0.1162
2024-05-25 05:44:33 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch46_loss0.11615621075034141.pypots
2024-05-25 05:44:50 [INFO]: Epoch 047 - training loss: 0.1318, validation loss: 0.1206
2024-05-25 05:44:50 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch47_loss0.12062998637557029.pypots
2024-05-25 05:45:07 [INFO]: Epoch 048 - training loss: 0.1327, validation loss: 0.1132
2024-05-25 05:45:07 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch48_loss0.1132317304611206.pypots
2024-05-25 05:45:24 [INFO]: Epoch 049 - training loss: 0.1229, validation loss: 0.1191
2024-05-25 05:45:24 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch49_loss0.11909371241927147.pypots
2024-05-25 05:45:40 [INFO]: Epoch 050 - training loss: 0.1269, validation loss: 0.1188
2024-05-25 05:45:40 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch50_loss0.1188213661313057.pypots
2024-05-25 05:45:57 [INFO]: Epoch 051 - training loss: 0.1398, validation loss: 0.1148
2024-05-25 05:45:57 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch51_loss0.1147598534822464.pypots
2024-05-25 05:46:14 [INFO]: Epoch 052 - training loss: 0.1304, validation loss: 0.1134
2024-05-25 05:46:14 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch52_loss0.11336644738912582.pypots
2024-05-25 05:46:31 [INFO]: Epoch 053 - training loss: 0.1279, validation loss: 0.1128
2024-05-25 05:46:31 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch53_loss0.11283781081438064.pypots
2024-05-25 05:46:48 [INFO]: Epoch 054 - training loss: 0.1151, validation loss: 0.1164
2024-05-25 05:46:48 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch54_loss0.1163919098675251.pypots
2024-05-25 05:47:04 [INFO]: Epoch 055 - training loss: 0.1271, validation loss: 0.1130
2024-05-25 05:47:04 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch55_loss0.11295897141098976.pypots
2024-05-25 05:47:21 [INFO]: Epoch 056 - training loss: 0.1146, validation loss: 0.1160
2024-05-25 05:47:21 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch56_loss0.11595359593629836.pypots
2024-05-25 05:47:38 [INFO]: Epoch 057 - training loss: 0.1235, validation loss: 0.1126
2024-05-25 05:47:38 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch57_loss0.11255827248096466.pypots
2024-05-25 05:47:55 [INFO]: Epoch 058 - training loss: 0.1136, validation loss: 0.1132
2024-05-25 05:47:55 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch58_loss0.11318687200546265.pypots
2024-05-25 05:48:12 [INFO]: Epoch 059 - training loss: 0.1243, validation loss: 0.1140
2024-05-25 05:48:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch59_loss0.11395053267478943.pypots
2024-05-25 05:48:28 [INFO]: Epoch 060 - training loss: 0.1315, validation loss: 0.1133
2024-05-25 05:48:28 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch60_loss0.1133352778851986.pypots
2024-05-25 05:48:45 [INFO]: Epoch 061 - training loss: 0.1331, validation loss: 0.1131
2024-05-25 05:48:45 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch61_loss0.11310840174555778.pypots
2024-05-25 05:49:02 [INFO]: Epoch 062 - training loss: 0.1138, validation loss: 0.1115
2024-05-25 05:49:02 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch62_loss0.11149042099714279.pypots
2024-05-25 05:49:19 [INFO]: Epoch 063 - training loss: 0.1133, validation loss: 0.1100
2024-05-25 05:49:19 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch63_loss0.10999536216259002.pypots
2024-05-25 05:49:36 [INFO]: Epoch 064 - training loss: 0.1293, validation loss: 0.1137
2024-05-25 05:49:36 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch64_loss0.11365738064050675.pypots
2024-05-25 05:49:52 [INFO]: Epoch 065 - training loss: 0.1143, validation loss: 0.1198
2024-05-25 05:49:52 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch65_loss0.11984925791621208.pypots
2024-05-25 05:50:09 [INFO]: Epoch 066 - training loss: 0.1290, validation loss: 0.1128
2024-05-25 05:50:09 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch66_loss0.11283228099346161.pypots
2024-05-25 05:50:26 [INFO]: Epoch 067 - training loss: 0.1355, validation loss: 0.1160
2024-05-25 05:50:26 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch67_loss0.11599836423993111.pypots
2024-05-25 05:50:43 [INFO]: Epoch 068 - training loss: 0.1161, validation loss: 0.1131
2024-05-25 05:50:43 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch68_loss0.11310444697737694.pypots
2024-05-25 05:51:00 [INFO]: Epoch 069 - training loss: 0.1220, validation loss: 0.1089
2024-05-25 05:51:00 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch69_loss0.10887884050607681.pypots
2024-05-25 05:51:16 [INFO]: Epoch 070 - training loss: 0.1207, validation loss: 0.1094
2024-05-25 05:51:16 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch70_loss0.10941006690263748.pypots
2024-05-25 05:51:33 [INFO]: Epoch 071 - training loss: 0.1070, validation loss: 0.1112
2024-05-25 05:51:33 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch71_loss0.11115357726812362.pypots
2024-05-25 05:51:50 [INFO]: Epoch 072 - training loss: 0.1155, validation loss: 0.1102
2024-05-25 05:51:50 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch72_loss0.11016789153218269.pypots
2024-05-25 05:52:07 [INFO]: Epoch 073 - training loss: 0.1094, validation loss: 0.1078
2024-05-25 05:52:07 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch73_loss0.10780690759420394.pypots
2024-05-25 05:52:24 [INFO]: Epoch 074 - training loss: 0.1016, validation loss: 0.1131
2024-05-25 05:52:24 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch74_loss0.11310987398028374.pypots
2024-05-25 05:52:40 [INFO]: Epoch 075 - training loss: 0.1237, validation loss: 0.1080
2024-05-25 05:52:41 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch75_loss0.10802780389785767.pypots
2024-05-25 05:52:57 [INFO]: Epoch 076 - training loss: 0.1300, validation loss: 0.1076
2024-05-25 05:52:57 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch76_loss0.10758017227053643.pypots
2024-05-25 05:53:14 [INFO]: Epoch 077 - training loss: 0.1269, validation loss: 0.1103
2024-05-25 05:53:14 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch77_loss0.11033822223544121.pypots
2024-05-25 05:53:31 [INFO]: Epoch 078 - training loss: 0.1333, validation loss: 0.1092
2024-05-25 05:53:31 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch78_loss0.10920156165957451.pypots
2024-05-25 05:53:48 [INFO]: Epoch 079 - training loss: 0.1194, validation loss: 0.1088
2024-05-25 05:53:48 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch79_loss0.1088424876332283.pypots
2024-05-25 05:54:04 [INFO]: Epoch 080 - training loss: 0.1069, validation loss: 0.1206
2024-05-25 05:54:05 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch80_loss0.12062909379601479.pypots
2024-05-25 05:54:21 [INFO]: Epoch 081 - training loss: 0.1267, validation loss: 0.1118
2024-05-25 05:54:21 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch81_loss0.11182895228266716.pypots
2024-05-25 05:54:38 [INFO]: Epoch 082 - training loss: 0.1172, validation loss: 0.1089
2024-05-25 05:54:38 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch82_loss0.10888228192925453.pypots
2024-05-25 05:54:55 [INFO]: Epoch 083 - training loss: 0.1135, validation loss: 0.1081
2024-05-25 05:54:55 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch83_loss0.10808622166514396.pypots
2024-05-25 05:55:12 [INFO]: Epoch 084 - training loss: 0.1144, validation loss: 0.1094
2024-05-25 05:55:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch84_loss0.10935055762529373.pypots
2024-05-25 05:55:29 [INFO]: Epoch 085 - training loss: 0.1298, validation loss: 0.1075
2024-05-25 05:55:29 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch85_loss0.10747793391346931.pypots
2024-05-25 05:55:45 [INFO]: Epoch 086 - training loss: 0.1201, validation loss: 0.1060
2024-05-25 05:55:45 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch86_loss0.10597261562943458.pypots
2024-05-25 05:56:02 [INFO]: Epoch 087 - training loss: 0.1226, validation loss: 0.1076
2024-05-25 05:56:02 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch87_loss0.10756273940205574.pypots
2024-05-25 05:56:19 [INFO]: Epoch 088 - training loss: 0.1201, validation loss: 0.1054
2024-05-25 05:56:19 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch88_loss0.10542072057723999.pypots
2024-05-25 05:56:36 [INFO]: Epoch 089 - training loss: 0.1170, validation loss: 0.1111
2024-05-25 05:56:36 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch89_loss0.1111284151673317.pypots
2024-05-25 05:56:53 [INFO]: Epoch 090 - training loss: 0.1221, validation loss: 0.1120
2024-05-25 05:56:53 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch90_loss0.11195626556873321.pypots
2024-05-25 05:57:09 [INFO]: Epoch 091 - training loss: 0.1145, validation loss: 0.1099
2024-05-25 05:57:09 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch91_loss0.10989439189434051.pypots
2024-05-25 05:57:26 [INFO]: Epoch 092 - training loss: 0.1188, validation loss: 0.1089
2024-05-25 05:57:26 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch92_loss0.10889843627810478.pypots
2024-05-25 05:57:43 [INFO]: Epoch 093 - training loss: 0.1325, validation loss: 0.1110
2024-05-25 05:57:43 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch93_loss0.11096211969852447.pypots
2024-05-25 05:58:00 [INFO]: Epoch 094 - training loss: 0.1238, validation loss: 0.1110
2024-05-25 05:58:00 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch94_loss0.11099092289805412.pypots
2024-05-25 05:58:17 [INFO]: Epoch 095 - training loss: 0.1171, validation loss: 0.1068
2024-05-25 05:58:17 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch95_loss0.10675249099731446.pypots
2024-05-25 05:58:33 [INFO]: Epoch 096 - training loss: 0.1257, validation loss: 0.1115
2024-05-25 05:58:33 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch96_loss0.11150504425168037.pypots
2024-05-25 05:58:50 [INFO]: Epoch 097 - training loss: 0.1210, validation loss: 0.1059
2024-05-25 05:58:50 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch97_loss0.10594160109758377.pypots
2024-05-25 05:59:07 [INFO]: Epoch 098 - training loss: 0.1069, validation loss: 0.1056
2024-05-25 05:59:07 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI_epoch98_loss0.10563758611679078.pypots
2024-05-25 05:59:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:59:07 [INFO]: Finished training. The best model is from epoch#88.
2024-05-25 05:59:07 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240525_T053141/CSDI.pypots
2024-05-25 06:01:27 [INFO]: CSDI on Air-Quality: MAE=0.1099, MSE=0.1562
2024-05-25 06:01:27 [INFO]: Successfully saved to augmentation_saved_results/round_4/CSDI_air_quality/imputation.pkl
2024-05-25 06:01:27 [INFO]: Using the given device: cuda:0
2024-05-25 06:01:27 [INFO]: Model files will be saved to augmentation_saved_results/round_4/GPVAE_air_quality/20240525_T060127
2024-05-25 06:01:27 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/GPVAE_air_quality/20240525_T060127/tensorboard
2024-05-25 06:01:27 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 06:01:27 [INFO]: Epoch 001 - training loss: 63072.0777, validation loss: 0.6873
2024-05-25 06:01:28 [INFO]: Epoch 002 - training loss: 42070.2733, validation loss: 0.5841
2024-05-25 06:01:28 [INFO]: Epoch 003 - training loss: 41775.5385, validation loss: 0.6265
2024-05-25 06:01:28 [INFO]: Epoch 004 - training loss: 41638.4452, validation loss: 0.4972
2024-05-25 06:01:29 [INFO]: Epoch 005 - training loss: 41532.7691, validation loss: 0.5073
2024-05-25 06:01:29 [INFO]: Epoch 006 - training loss: 41487.0072, validation loss: 0.4725
2024-05-25 06:01:29 [INFO]: Epoch 007 - training loss: 41519.4443, validation loss: 0.4823
2024-05-25 06:01:30 [INFO]: Epoch 008 - training loss: 41438.5987, validation loss: 0.3923
2024-05-25 06:01:30 [INFO]: Epoch 009 - training loss: 41390.9188, validation loss: 0.3872
2024-05-25 06:01:30 [INFO]: Epoch 010 - training loss: 41378.9782, validation loss: 0.3603
2024-05-25 06:01:31 [INFO]: Epoch 011 - training loss: 41376.0223, validation loss: 0.3482
2024-05-25 06:01:31 [INFO]: Epoch 012 - training loss: 41361.1408, validation loss: 0.3438
2024-05-25 06:01:31 [INFO]: Epoch 013 - training loss: 41319.0203, validation loss: 0.4046
2024-05-25 06:01:32 [INFO]: Epoch 014 - training loss: 41357.5896, validation loss: 0.3537
2024-05-25 06:01:32 [INFO]: Epoch 015 - training loss: 41343.3801, validation loss: 0.3575
2024-05-25 06:01:32 [INFO]: Epoch 016 - training loss: 41354.4601, validation loss: 0.3590
2024-05-25 06:01:33 [INFO]: Epoch 017 - training loss: 41344.1891, validation loss: 0.3319
2024-05-25 06:01:33 [INFO]: Epoch 018 - training loss: 41304.9368, validation loss: 0.3206
2024-05-25 06:01:33 [INFO]: Epoch 019 - training loss: 41286.6267, validation loss: 0.3342
2024-05-25 06:01:34 [INFO]: Epoch 020 - training loss: 41265.5033, validation loss: 0.3023
2024-05-25 06:01:34 [INFO]: Epoch 021 - training loss: 41258.3161, validation loss: 0.2961
2024-05-25 06:01:34 [INFO]: Epoch 022 - training loss: 41255.0088, validation loss: 0.3105
2024-05-25 06:01:35 [INFO]: Epoch 023 - training loss: 41249.7773, validation loss: 0.3065
2024-05-25 06:01:35 [INFO]: Epoch 024 - training loss: 41235.3986, validation loss: 0.2856
2024-05-25 06:01:35 [INFO]: Epoch 025 - training loss: 41229.4709, validation loss: 0.3013
2024-05-25 06:01:36 [INFO]: Epoch 026 - training loss: 41227.1801, validation loss: 0.2800
2024-05-25 06:01:36 [INFO]: Epoch 027 - training loss: 41222.6338, validation loss: 0.2812
2024-05-25 06:01:36 [INFO]: Epoch 028 - training loss: 41221.5266, validation loss: 0.2921
2024-05-25 06:01:37 [INFO]: Epoch 029 - training loss: 41216.1981, validation loss: 0.2937
2024-05-25 06:01:37 [INFO]: Epoch 030 - training loss: 41224.4787, validation loss: 0.3040
2024-05-25 06:01:37 [INFO]: Epoch 031 - training loss: 41214.4933, validation loss: 0.2729
2024-05-25 06:01:38 [INFO]: Epoch 032 - training loss: 41208.1636, validation loss: 0.2916
2024-05-25 06:01:38 [INFO]: Epoch 033 - training loss: 41205.3164, validation loss: 0.2809
2024-05-25 06:01:38 [INFO]: Epoch 034 - training loss: 41202.9852, validation loss: 0.2962
2024-05-25 06:01:39 [INFO]: Epoch 035 - training loss: 41203.0266, validation loss: 0.2749
2024-05-25 06:01:39 [INFO]: Epoch 036 - training loss: 41197.6497, validation loss: 0.2652
2024-05-25 06:01:39 [INFO]: Epoch 037 - training loss: 41191.0153, validation loss: 0.2834
2024-05-25 06:01:40 [INFO]: Epoch 038 - training loss: 41210.0748, validation loss: 0.3796
2024-05-25 06:01:40 [INFO]: Epoch 039 - training loss: 41365.1483, validation loss: 0.3000
2024-05-25 06:01:40 [INFO]: Epoch 040 - training loss: 41266.5201, validation loss: 0.2728
2024-05-25 06:01:41 [INFO]: Epoch 041 - training loss: 41199.8035, validation loss: 0.2854
2024-05-25 06:01:41 [INFO]: Epoch 042 - training loss: 41188.8260, validation loss: 0.2686
2024-05-25 06:01:41 [INFO]: Epoch 043 - training loss: 41184.4841, validation loss: 0.2770
2024-05-25 06:01:42 [INFO]: Epoch 044 - training loss: 41188.6510, validation loss: 0.2872
2024-05-25 06:01:42 [INFO]: Epoch 045 - training loss: 41245.1205, validation loss: 0.2959
2024-05-25 06:01:42 [INFO]: Epoch 046 - training loss: 41236.0067, validation loss: 0.2622
2024-05-25 06:01:43 [INFO]: Epoch 047 - training loss: 41208.5734, validation loss: 0.2707
2024-05-25 06:01:43 [INFO]: Epoch 048 - training loss: 41197.8070, validation loss: 0.2798
2024-05-25 06:01:43 [INFO]: Epoch 049 - training loss: 41187.5392, validation loss: 0.2673
2024-05-25 06:01:44 [INFO]: Epoch 050 - training loss: 41178.3038, validation loss: 0.2664
2024-05-25 06:01:44 [INFO]: Epoch 051 - training loss: 41169.5800, validation loss: 0.2656
2024-05-25 06:01:44 [INFO]: Epoch 052 - training loss: 41175.7833, validation loss: 0.2519
2024-05-25 06:01:45 [INFO]: Epoch 053 - training loss: 41167.2248, validation loss: 0.2819
2024-05-25 06:01:45 [INFO]: Epoch 054 - training loss: 41166.4144, validation loss: 0.2643
2024-05-25 06:01:45 [INFO]: Epoch 055 - training loss: 41161.4634, validation loss: 0.2515
2024-05-25 06:01:46 [INFO]: Epoch 056 - training loss: 41154.9478, validation loss: 0.2464
2024-05-25 06:01:46 [INFO]: Epoch 057 - training loss: 41153.9813, validation loss: 0.2668
2024-05-25 06:01:46 [INFO]: Epoch 058 - training loss: 41150.5448, validation loss: 0.2625
2024-05-25 06:01:47 [INFO]: Epoch 059 - training loss: 41155.2310, validation loss: 0.2576
2024-05-25 06:01:47 [INFO]: Epoch 060 - training loss: 41156.0323, validation loss: 0.2650
2024-05-25 06:01:48 [INFO]: Epoch 061 - training loss: 41156.7199, validation loss: 0.2815
2024-05-25 06:01:48 [INFO]: Epoch 062 - training loss: 41253.3624, validation loss: 0.2762
2024-05-25 06:01:48 [INFO]: Epoch 063 - training loss: 41187.9233, validation loss: 0.2543
2024-05-25 06:01:49 [INFO]: Epoch 064 - training loss: 41160.4045, validation loss: 0.2504
2024-05-25 06:01:49 [INFO]: Epoch 065 - training loss: 41159.2795, validation loss: 0.2641
2024-05-25 06:01:49 [INFO]: Epoch 066 - training loss: 41164.4400, validation loss: 0.2717
2024-05-25 06:01:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:01:49 [INFO]: Finished training. The best model is from epoch#56.
2024-05-25 06:01:49 [INFO]: Saved the model to augmentation_saved_results/round_4/GPVAE_air_quality/20240525_T060127/GPVAE.pypots
2024-05-25 06:01:49 [INFO]: GP-VAE on Air-Quality: MAE=0.3150, MSE=0.3502
2024-05-25 06:01:49 [INFO]: Successfully saved to augmentation_saved_results/round_4/GPVAE_air_quality/imputation.pkl
2024-05-25 06:01:49 [INFO]: Using the given device: cuda:0
2024-05-25 06:01:49 [INFO]: Model files will be saved to augmentation_saved_results/round_4/USGAN_air_quality/20240525_T060149
2024-05-25 06:01:49 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/USGAN_air_quality/20240525_T060149/tensorboard
2024-05-25 06:01:49 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 06:01:54 [INFO]: Epoch 001 - generator training loss: 0.6029, discriminator training loss: 0.2970, validation loss: 0.5206
2024-05-25 06:01:58 [INFO]: Epoch 002 - generator training loss: 0.2869, discriminator training loss: 0.0672, validation loss: 0.4059
2024-05-25 06:02:02 [INFO]: Epoch 003 - generator training loss: 0.2156, discriminator training loss: 0.0628, validation loss: 0.3346
2024-05-25 06:02:07 [INFO]: Epoch 004 - generator training loss: 0.1828, discriminator training loss: 0.0626, validation loss: 0.2943
2024-05-25 06:02:11 [INFO]: Epoch 005 - generator training loss: 0.1573, discriminator training loss: 0.0620, validation loss: 0.2670
2024-05-25 06:02:15 [INFO]: Epoch 006 - generator training loss: 0.1374, discriminator training loss: 0.0609, validation loss: 0.2464
2024-05-25 06:02:19 [INFO]: Epoch 007 - generator training loss: 0.1240, discriminator training loss: 0.0602, validation loss: 0.2306
2024-05-25 06:02:23 [INFO]: Epoch 008 - generator training loss: 0.1177, discriminator training loss: 0.0597, validation loss: 0.2210
2024-05-25 06:02:27 [INFO]: Epoch 009 - generator training loss: 0.1048, discriminator training loss: 0.0590, validation loss: 0.2117
2024-05-25 06:02:31 [INFO]: Epoch 010 - generator training loss: 0.0961, discriminator training loss: 0.0584, validation loss: 0.2054
2024-05-25 06:02:35 [INFO]: Epoch 011 - generator training loss: 0.0916, discriminator training loss: 0.0565, validation loss: 0.1998
2024-05-25 06:02:39 [INFO]: Epoch 012 - generator training loss: 0.0869, discriminator training loss: 0.0551, validation loss: 0.1946
2024-05-25 06:02:43 [INFO]: Epoch 013 - generator training loss: 0.0826, discriminator training loss: 0.0542, validation loss: 0.1905
2024-05-25 06:02:47 [INFO]: Epoch 014 - generator training loss: 0.0793, discriminator training loss: 0.0527, validation loss: 0.1870
2024-05-25 06:02:52 [INFO]: Epoch 015 - generator training loss: 0.0781, discriminator training loss: 0.0515, validation loss: 0.1833
2024-05-25 06:02:56 [INFO]: Epoch 016 - generator training loss: 0.0758, discriminator training loss: 0.0493, validation loss: 0.1805
2024-05-25 06:03:00 [INFO]: Epoch 017 - generator training loss: 0.0742, discriminator training loss: 0.0474, validation loss: 0.1780
2024-05-25 06:03:04 [INFO]: Epoch 018 - generator training loss: 0.0721, discriminator training loss: 0.0464, validation loss: 0.1765
2024-05-25 06:03:08 [INFO]: Epoch 019 - generator training loss: 0.0700, discriminator training loss: 0.0460, validation loss: 0.1739
2024-05-25 06:03:12 [INFO]: Epoch 020 - generator training loss: 0.0682, discriminator training loss: 0.0445, validation loss: 0.1703
2024-05-25 06:03:16 [INFO]: Epoch 021 - generator training loss: 0.0656, discriminator training loss: 0.0439, validation loss: 0.1681
2024-05-25 06:03:20 [INFO]: Epoch 022 - generator training loss: 0.0644, discriminator training loss: 0.0431, validation loss: 0.1669
2024-05-25 06:03:24 [INFO]: Epoch 023 - generator training loss: 0.0629, discriminator training loss: 0.0421, validation loss: 0.1650
2024-05-25 06:03:29 [INFO]: Epoch 024 - generator training loss: 0.0602, discriminator training loss: 0.0413, validation loss: 0.1637
2024-05-25 06:03:33 [INFO]: Epoch 025 - generator training loss: 0.0592, discriminator training loss: 0.0405, validation loss: 0.1626
2024-05-25 06:03:37 [INFO]: Epoch 026 - generator training loss: 0.0583, discriminator training loss: 0.0401, validation loss: 0.1604
2024-05-25 06:03:41 [INFO]: Epoch 027 - generator training loss: 0.0575, discriminator training loss: 0.0390, validation loss: 0.1601
2024-05-25 06:03:45 [INFO]: Epoch 028 - generator training loss: 0.0568, discriminator training loss: 0.0384, validation loss: 0.1588
2024-05-25 06:03:49 [INFO]: Epoch 029 - generator training loss: 0.0564, discriminator training loss: 0.0371, validation loss: 0.1574
2024-05-25 06:03:53 [INFO]: Epoch 030 - generator training loss: 0.0554, discriminator training loss: 0.0365, validation loss: 0.1568
2024-05-25 06:03:57 [INFO]: Epoch 031 - generator training loss: 0.0554, discriminator training loss: 0.0354, validation loss: 0.1557
2024-05-25 06:04:01 [INFO]: Epoch 032 - generator training loss: 0.0546, discriminator training loss: 0.0345, validation loss: 0.1545
2024-05-25 06:04:06 [INFO]: Epoch 033 - generator training loss: 0.0537, discriminator training loss: 0.0338, validation loss: 0.1543
2024-05-25 06:04:10 [INFO]: Epoch 034 - generator training loss: 0.0537, discriminator training loss: 0.0332, validation loss: 0.1538
2024-05-25 06:04:14 [INFO]: Epoch 035 - generator training loss: 0.0533, discriminator training loss: 0.0325, validation loss: 0.1528
2024-05-25 06:04:18 [INFO]: Epoch 036 - generator training loss: 0.0526, discriminator training loss: 0.0319, validation loss: 0.1526
2024-05-25 06:04:22 [INFO]: Epoch 037 - generator training loss: 0.0524, discriminator training loss: 0.0312, validation loss: 0.1514
2024-05-25 06:04:26 [INFO]: Epoch 038 - generator training loss: 0.0518, discriminator training loss: 0.0308, validation loss: 0.1517
2024-05-25 06:04:30 [INFO]: Epoch 039 - generator training loss: 0.0514, discriminator training loss: 0.0302, validation loss: 0.1501
2024-05-25 06:04:34 [INFO]: Epoch 040 - generator training loss: 0.0520, discriminator training loss: 0.0293, validation loss: 0.1501
2024-05-25 06:04:38 [INFO]: Epoch 041 - generator training loss: 0.0509, discriminator training loss: 0.0286, validation loss: 0.1491
2024-05-25 06:04:42 [INFO]: Epoch 042 - generator training loss: 0.0508, discriminator training loss: 0.0283, validation loss: 0.1490
2024-05-25 06:04:46 [INFO]: Epoch 043 - generator training loss: 0.0504, discriminator training loss: 0.0280, validation loss: 0.1486
2024-05-25 06:04:51 [INFO]: Epoch 044 - generator training loss: 0.0515, discriminator training loss: 0.0275, validation loss: 0.1479
2024-05-25 06:04:55 [INFO]: Epoch 045 - generator training loss: 0.0512, discriminator training loss: 0.0267, validation loss: 0.1472
2024-05-25 06:04:59 [INFO]: Epoch 046 - generator training loss: 0.0487, discriminator training loss: 0.0263, validation loss: 0.1468
2024-05-25 06:05:03 [INFO]: Epoch 047 - generator training loss: 0.0484, discriminator training loss: 0.0259, validation loss: 0.1465
2024-05-25 06:05:07 [INFO]: Epoch 048 - generator training loss: 0.0479, discriminator training loss: 0.0255, validation loss: 0.1448
2024-05-25 06:05:11 [INFO]: Epoch 049 - generator training loss: 0.0498, discriminator training loss: 0.0252, validation loss: 0.1445
2024-05-25 06:05:15 [INFO]: Epoch 050 - generator training loss: 0.0470, discriminator training loss: 0.0247, validation loss: 0.1441
2024-05-25 06:05:19 [INFO]: Epoch 051 - generator training loss: 0.0464, discriminator training loss: 0.0243, validation loss: 0.1437
2024-05-25 06:05:23 [INFO]: Epoch 052 - generator training loss: 0.0464, discriminator training loss: 0.0238, validation loss: 0.1437
2024-05-25 06:05:28 [INFO]: Epoch 053 - generator training loss: 0.0463, discriminator training loss: 0.0234, validation loss: 0.1432
2024-05-25 06:05:32 [INFO]: Epoch 054 - generator training loss: 0.0473, discriminator training loss: 0.0231, validation loss: 0.1427
2024-05-25 06:05:36 [INFO]: Epoch 055 - generator training loss: 0.0456, discriminator training loss: 0.0228, validation loss: 0.1424
2024-05-25 06:05:40 [INFO]: Epoch 056 - generator training loss: 0.0455, discriminator training loss: 0.0227, validation loss: 0.1417
2024-05-25 06:05:44 [INFO]: Epoch 057 - generator training loss: 0.0448, discriminator training loss: 0.0223, validation loss: 0.1419
2024-05-25 06:05:48 [INFO]: Epoch 058 - generator training loss: 0.0453, discriminator training loss: 0.0220, validation loss: 0.1413
2024-05-25 06:05:52 [INFO]: Epoch 059 - generator training loss: 0.0441, discriminator training loss: 0.0217, validation loss: 0.1410
2024-05-25 06:05:56 [INFO]: Epoch 060 - generator training loss: 0.0447, discriminator training loss: 0.0216, validation loss: 0.1403
2024-05-25 06:06:00 [INFO]: Epoch 061 - generator training loss: 0.0446, discriminator training loss: 0.0212, validation loss: 0.1403
2024-05-25 06:06:04 [INFO]: Epoch 062 - generator training loss: 0.0435, discriminator training loss: 0.0210, validation loss: 0.1400
2024-05-25 06:06:09 [INFO]: Epoch 063 - generator training loss: 0.0432, discriminator training loss: 0.0207, validation loss: 0.1398
2024-05-25 06:06:13 [INFO]: Epoch 064 - generator training loss: 0.0427, discriminator training loss: 0.0205, validation loss: 0.1396
2024-05-25 06:06:17 [INFO]: Epoch 065 - generator training loss: 0.0428, discriminator training loss: 0.0202, validation loss: 0.1390
2024-05-25 06:06:21 [INFO]: Epoch 066 - generator training loss: 0.0422, discriminator training loss: 0.0202, validation loss: 0.1399
2024-05-25 06:06:25 [INFO]: Epoch 067 - generator training loss: 0.0422, discriminator training loss: 0.0198, validation loss: 0.1388
2024-05-25 06:06:29 [INFO]: Epoch 068 - generator training loss: 0.0417, discriminator training loss: 0.0196, validation loss: 0.1382
2024-05-25 06:06:33 [INFO]: Epoch 069 - generator training loss: 0.0415, discriminator training loss: 0.0193, validation loss: 0.1384
2024-05-25 06:06:37 [INFO]: Epoch 070 - generator training loss: 0.0413, discriminator training loss: 0.0190, validation loss: 0.1391
2024-05-25 06:06:41 [INFO]: Epoch 071 - generator training loss: 0.0406, discriminator training loss: 0.0190, validation loss: 0.1379
2024-05-25 06:06:45 [INFO]: Epoch 072 - generator training loss: 0.0406, discriminator training loss: 0.0189, validation loss: 0.1384
2024-05-25 06:06:50 [INFO]: Epoch 073 - generator training loss: 0.0406, discriminator training loss: 0.0188, validation loss: 0.1379
2024-05-25 06:06:54 [INFO]: Epoch 074 - generator training loss: 0.0407, discriminator training loss: 0.0186, validation loss: 0.1388
2024-05-25 06:06:58 [INFO]: Epoch 075 - generator training loss: 0.0405, discriminator training loss: 0.0184, validation loss: 0.1379
2024-05-25 06:07:02 [INFO]: Epoch 076 - generator training loss: 0.0410, discriminator training loss: 0.0178, validation loss: 0.1371
2024-05-25 06:07:06 [INFO]: Epoch 077 - generator training loss: 0.0403, discriminator training loss: 0.0179, validation loss: 0.1377
2024-05-25 06:07:10 [INFO]: Epoch 078 - generator training loss: 0.0400, discriminator training loss: 0.0178, validation loss: 0.1385
2024-05-25 06:07:14 [INFO]: Epoch 079 - generator training loss: 0.0392, discriminator training loss: 0.0178, validation loss: 0.1380
2024-05-25 06:07:18 [INFO]: Epoch 080 - generator training loss: 0.0396, discriminator training loss: 0.0174, validation loss: 0.1377
2024-05-25 06:07:22 [INFO]: Epoch 081 - generator training loss: 0.0387, discriminator training loss: 0.0172, validation loss: 0.1371
2024-05-25 06:07:26 [INFO]: Epoch 082 - generator training loss: 0.0384, discriminator training loss: 0.0172, validation loss: 0.1377
2024-05-25 06:07:31 [INFO]: Epoch 083 - generator training loss: 0.0390, discriminator training loss: 0.0172, validation loss: 0.1377
2024-05-25 06:07:35 [INFO]: Epoch 084 - generator training loss: 0.0388, discriminator training loss: 0.0171, validation loss: 0.1361
2024-05-25 06:07:39 [INFO]: Epoch 085 - generator training loss: 0.0384, discriminator training loss: 0.0169, validation loss: 0.1374
2024-05-25 06:07:43 [INFO]: Epoch 086 - generator training loss: 0.0386, discriminator training loss: 0.0168, validation loss: 0.1372
2024-05-25 06:07:47 [INFO]: Epoch 087 - generator training loss: 0.0375, discriminator training loss: 0.0166, validation loss: 0.1374
2024-05-25 06:07:51 [INFO]: Epoch 088 - generator training loss: 0.0373, discriminator training loss: 0.0165, validation loss: 0.1371
2024-05-25 06:07:55 [INFO]: Epoch 089 - generator training loss: 0.0370, discriminator training loss: 0.0165, validation loss: 0.1368
2024-05-25 06:07:59 [INFO]: Epoch 090 - generator training loss: 0.0372, discriminator training loss: 0.0163, validation loss: 0.1370
2024-05-25 06:08:03 [INFO]: Epoch 091 - generator training loss: 0.0379, discriminator training loss: 0.0161, validation loss: 0.1370
2024-05-25 06:08:08 [INFO]: Epoch 092 - generator training loss: 0.0378, discriminator training loss: 0.0161, validation loss: 0.1365
2024-05-25 06:08:12 [INFO]: Epoch 093 - generator training loss: 0.0367, discriminator training loss: 0.0159, validation loss: 0.1366
2024-05-25 06:08:16 [INFO]: Epoch 094 - generator training loss: 0.0366, discriminator training loss: 0.0158, validation loss: 0.1373
2024-05-25 06:08:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:08:16 [INFO]: Finished training. The best model is from epoch#84.
2024-05-25 06:08:16 [INFO]: Saved the model to augmentation_saved_results/round_4/USGAN_air_quality/20240525_T060149/USGAN.pypots
2024-05-25 06:08:16 [INFO]: US-GAN on Air-Quality: MAE=0.2087, MSE=0.1955
2024-05-25 06:08:16 [INFO]: Successfully saved to augmentation_saved_results/round_4/USGAN_air_quality/imputation.pkl
2024-05-25 06:08:16 [INFO]: Using the given device: cuda:0
2024-05-25 06:08:16 [INFO]: Model files will be saved to augmentation_saved_results/round_4/BRITS_air_quality/20240525_T060816
2024-05-25 06:08:16 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/BRITS_air_quality/20240525_T060816/tensorboard
2024-05-25 06:08:16 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 06:08:20 [INFO]: Epoch 001 - training loss: 1.3942, validation loss: 0.9381
2024-05-25 06:08:23 [INFO]: Epoch 002 - training loss: 1.1187, validation loss: 0.7067
2024-05-25 06:08:26 [INFO]: Epoch 003 - training loss: 0.9360, validation loss: 0.6057
2024-05-25 06:08:28 [INFO]: Epoch 004 - training loss: 0.8322, validation loss: 0.5395
2024-05-25 06:08:31 [INFO]: Epoch 005 - training loss: 0.7589, validation loss: 0.4918
2024-05-25 06:08:34 [INFO]: Epoch 006 - training loss: 0.7016, validation loss: 0.4513
2024-05-25 06:08:37 [INFO]: Epoch 007 - training loss: 0.6588, validation loss: 0.4214
2024-05-25 06:08:40 [INFO]: Epoch 008 - training loss: 0.6245, validation loss: 0.3962
2024-05-25 06:08:42 [INFO]: Epoch 009 - training loss: 0.5975, validation loss: 0.3754
2024-05-25 06:08:45 [INFO]: Epoch 010 - training loss: 0.5744, validation loss: 0.3574
2024-05-25 06:08:48 [INFO]: Epoch 011 - training loss: 0.5594, validation loss: 0.3443
2024-05-25 06:08:51 [INFO]: Epoch 012 - training loss: 0.5421, validation loss: 0.3312
2024-05-25 06:08:54 [INFO]: Epoch 013 - training loss: 0.5296, validation loss: 0.3211
2024-05-25 06:08:56 [INFO]: Epoch 014 - training loss: 0.5164, validation loss: 0.3119
2024-05-25 06:08:59 [INFO]: Epoch 015 - training loss: 0.5065, validation loss: 0.3038
2024-05-25 06:09:02 [INFO]: Epoch 016 - training loss: 0.4971, validation loss: 0.2968
2024-05-25 06:09:05 [INFO]: Epoch 017 - training loss: 0.4884, validation loss: 0.2901
2024-05-25 06:09:08 [INFO]: Epoch 018 - training loss: 0.4803, validation loss: 0.2844
2024-05-25 06:09:10 [INFO]: Epoch 019 - training loss: 0.4719, validation loss: 0.2786
2024-05-25 06:09:13 [INFO]: Epoch 020 - training loss: 0.4649, validation loss: 0.2737
2024-05-25 06:09:16 [INFO]: Epoch 021 - training loss: 0.4585, validation loss: 0.2690
2024-05-25 06:09:19 [INFO]: Epoch 022 - training loss: 0.4499, validation loss: 0.2644
2024-05-25 06:09:22 [INFO]: Epoch 023 - training loss: 0.4442, validation loss: 0.2608
2024-05-25 06:09:24 [INFO]: Epoch 024 - training loss: 0.4397, validation loss: 0.2561
2024-05-25 06:09:27 [INFO]: Epoch 025 - training loss: 0.4328, validation loss: 0.2527
2024-05-25 06:09:30 [INFO]: Epoch 026 - training loss: 0.4267, validation loss: 0.2482
2024-05-25 06:09:33 [INFO]: Epoch 027 - training loss: 0.4214, validation loss: 0.2448
2024-05-25 06:09:36 [INFO]: Epoch 028 - training loss: 0.4168, validation loss: 0.2413
2024-05-25 06:09:38 [INFO]: Epoch 029 - training loss: 0.4115, validation loss: 0.2379
2024-05-25 06:09:41 [INFO]: Epoch 030 - training loss: 0.4070, validation loss: 0.2346
2024-05-25 06:09:44 [INFO]: Epoch 031 - training loss: 0.4017, validation loss: 0.2315
2024-05-25 06:09:47 [INFO]: Epoch 032 - training loss: 0.3980, validation loss: 0.2287
2024-05-25 06:09:50 [INFO]: Epoch 033 - training loss: 0.3937, validation loss: 0.2261
2024-05-25 06:09:52 [INFO]: Epoch 034 - training loss: 0.3893, validation loss: 0.2229
2024-05-25 06:09:55 [INFO]: Epoch 035 - training loss: 0.3855, validation loss: 0.2205
2024-05-25 06:09:58 [INFO]: Epoch 036 - training loss: 0.3817, validation loss: 0.2174
2024-05-25 06:10:01 [INFO]: Epoch 037 - training loss: 0.3778, validation loss: 0.2151
2024-05-25 06:10:03 [INFO]: Epoch 038 - training loss: 0.3745, validation loss: 0.2124
2024-05-25 06:10:06 [INFO]: Epoch 039 - training loss: 0.3710, validation loss: 0.2105
2024-05-25 06:10:09 [INFO]: Epoch 040 - training loss: 0.3677, validation loss: 0.2079
2024-05-25 06:10:12 [INFO]: Epoch 041 - training loss: 0.3645, validation loss: 0.2053
2024-05-25 06:10:15 [INFO]: Epoch 042 - training loss: 0.3620, validation loss: 0.2031
2024-05-25 06:10:17 [INFO]: Epoch 043 - training loss: 0.3596, validation loss: 0.2012
2024-05-25 06:10:20 [INFO]: Epoch 044 - training loss: 0.3567, validation loss: 0.1993
2024-05-25 06:10:23 [INFO]: Epoch 045 - training loss: 0.3528, validation loss: 0.1971
2024-05-25 06:10:26 [INFO]: Epoch 046 - training loss: 0.3499, validation loss: 0.1948
2024-05-25 06:10:29 [INFO]: Epoch 047 - training loss: 0.3474, validation loss: 0.1932
2024-05-25 06:10:31 [INFO]: Epoch 048 - training loss: 0.3452, validation loss: 0.1914
2024-05-25 06:10:34 [INFO]: Epoch 049 - training loss: 0.3423, validation loss: 0.1901
2024-05-25 06:10:37 [INFO]: Epoch 050 - training loss: 0.3401, validation loss: 0.1882
2024-05-25 06:10:40 [INFO]: Epoch 051 - training loss: 0.3380, validation loss: 0.1867
2024-05-25 06:10:43 [INFO]: Epoch 052 - training loss: 0.3351, validation loss: 0.1852
2024-05-25 06:10:45 [INFO]: Epoch 053 - training loss: 0.3337, validation loss: 0.1836
2024-05-25 06:10:48 [INFO]: Epoch 054 - training loss: 0.3320, validation loss: 0.1824
2024-05-25 06:10:51 [INFO]: Epoch 055 - training loss: 0.3305, validation loss: 0.1813
2024-05-25 06:10:54 [INFO]: Epoch 056 - training loss: 0.3275, validation loss: 0.1800
2024-05-25 06:10:57 [INFO]: Epoch 057 - training loss: 0.3260, validation loss: 0.1789
2024-05-25 06:10:59 [INFO]: Epoch 058 - training loss: 0.3236, validation loss: 0.1779
2024-05-25 06:11:02 [INFO]: Epoch 059 - training loss: 0.3215, validation loss: 0.1768
2024-05-25 06:11:05 [INFO]: Epoch 060 - training loss: 0.3207, validation loss: 0.1756
2024-05-25 06:11:08 [INFO]: Epoch 061 - training loss: 0.3193, validation loss: 0.1747
2024-05-25 06:11:11 [INFO]: Epoch 062 - training loss: 0.3177, validation loss: 0.1736
2024-05-25 06:11:13 [INFO]: Epoch 063 - training loss: 0.3156, validation loss: 0.1729
2024-05-25 06:11:16 [INFO]: Epoch 064 - training loss: 0.3145, validation loss: 0.1716
2024-05-25 06:11:19 [INFO]: Epoch 065 - training loss: 0.3126, validation loss: 0.1714
2024-05-25 06:11:22 [INFO]: Epoch 066 - training loss: 0.3118, validation loss: 0.1701
2024-05-25 06:11:25 [INFO]: Epoch 067 - training loss: 0.3100, validation loss: 0.1692
2024-05-25 06:11:27 [INFO]: Epoch 068 - training loss: 0.3090, validation loss: 0.1686
2024-05-25 06:11:30 [INFO]: Epoch 069 - training loss: 0.3072, validation loss: 0.1677
2024-05-25 06:11:33 [INFO]: Epoch 070 - training loss: 0.3057, validation loss: 0.1668
2024-05-25 06:11:36 [INFO]: Epoch 071 - training loss: 0.3049, validation loss: 0.1662
2024-05-25 06:11:38 [INFO]: Epoch 072 - training loss: 0.3033, validation loss: 0.1656
2024-05-25 06:11:41 [INFO]: Epoch 073 - training loss: 0.3023, validation loss: 0.1648
2024-05-25 06:11:44 [INFO]: Epoch 074 - training loss: 0.3019, validation loss: 0.1641
2024-05-25 06:11:47 [INFO]: Epoch 075 - training loss: 0.3009, validation loss: 0.1636
2024-05-25 06:11:50 [INFO]: Epoch 076 - training loss: 0.2999, validation loss: 0.1629
2024-05-25 06:11:52 [INFO]: Epoch 077 - training loss: 0.2984, validation loss: 0.1619
2024-05-25 06:11:55 [INFO]: Epoch 078 - training loss: 0.2974, validation loss: 0.1615
2024-05-25 06:11:58 [INFO]: Epoch 079 - training loss: 0.2966, validation loss: 0.1610
2024-05-25 06:12:01 [INFO]: Epoch 080 - training loss: 0.2954, validation loss: 0.1601
2024-05-25 06:12:04 [INFO]: Epoch 081 - training loss: 0.2946, validation loss: 0.1594
2024-05-25 06:12:06 [INFO]: Epoch 082 - training loss: 0.2938, validation loss: 0.1590
2024-05-25 06:12:09 [INFO]: Epoch 083 - training loss: 0.2933, validation loss: 0.1584
2024-05-25 06:12:12 [INFO]: Epoch 084 - training loss: 0.2922, validation loss: 0.1577
2024-05-25 06:12:15 [INFO]: Epoch 085 - training loss: 0.2913, validation loss: 0.1572
2024-05-25 06:12:18 [INFO]: Epoch 086 - training loss: 0.2907, validation loss: 0.1567
2024-05-25 06:12:20 [INFO]: Epoch 087 - training loss: 0.2896, validation loss: 0.1561
2024-05-25 06:12:23 [INFO]: Epoch 088 - training loss: 0.2889, validation loss: 0.1556
2024-05-25 06:12:26 [INFO]: Epoch 089 - training loss: 0.2881, validation loss: 0.1550
2024-05-25 06:12:29 [INFO]: Epoch 090 - training loss: 0.2878, validation loss: 0.1547
2024-05-25 06:12:32 [INFO]: Epoch 091 - training loss: 0.2865, validation loss: 0.1537
2024-05-25 06:12:34 [INFO]: Epoch 092 - training loss: 0.2860, validation loss: 0.1535
2024-05-25 06:12:37 [INFO]: Epoch 093 - training loss: 0.2851, validation loss: 0.1527
2024-05-25 06:12:40 [INFO]: Epoch 094 - training loss: 0.2842, validation loss: 0.1525
2024-05-25 06:12:43 [INFO]: Epoch 095 - training loss: 0.2839, validation loss: 0.1520
2024-05-25 06:12:46 [INFO]: Epoch 096 - training loss: 0.2824, validation loss: 0.1516
2024-05-25 06:12:48 [INFO]: Epoch 097 - training loss: 0.2824, validation loss: 0.1511
2024-05-25 06:12:51 [INFO]: Epoch 098 - training loss: 0.2814, validation loss: 0.1505
2024-05-25 06:12:54 [INFO]: Epoch 099 - training loss: 0.2813, validation loss: 0.1500
2024-05-25 06:12:57 [INFO]: Epoch 100 - training loss: 0.2799, validation loss: 0.1497
2024-05-25 06:13:00 [INFO]: Epoch 101 - training loss: 0.2797, validation loss: 0.1493
2024-05-25 06:13:02 [INFO]: Epoch 102 - training loss: 0.2785, validation loss: 0.1488
2024-05-25 06:13:05 [INFO]: Epoch 103 - training loss: 0.2782, validation loss: 0.1484
2024-05-25 06:13:08 [INFO]: Epoch 104 - training loss: 0.2776, validation loss: 0.1480
2024-05-25 06:13:11 [INFO]: Epoch 105 - training loss: 0.2772, validation loss: 0.1476
2024-05-25 06:13:14 [INFO]: Epoch 106 - training loss: 0.2767, validation loss: 0.1471
2024-05-25 06:13:16 [INFO]: Epoch 107 - training loss: 0.2757, validation loss: 0.1468
2024-05-25 06:13:19 [INFO]: Epoch 108 - training loss: 0.2756, validation loss: 0.1463
2024-05-25 06:13:22 [INFO]: Epoch 109 - training loss: 0.2753, validation loss: 0.1458
2024-05-25 06:13:25 [INFO]: Epoch 110 - training loss: 0.2744, validation loss: 0.1454
2024-05-25 06:13:28 [INFO]: Epoch 111 - training loss: 0.2740, validation loss: 0.1451
2024-05-25 06:13:30 [INFO]: Epoch 112 - training loss: 0.2736, validation loss: 0.1446
2024-05-25 06:13:33 [INFO]: Epoch 113 - training loss: 0.2730, validation loss: 0.1444
2024-05-25 06:13:36 [INFO]: Epoch 114 - training loss: 0.2724, validation loss: 0.1438
2024-05-25 06:13:39 [INFO]: Epoch 115 - training loss: 0.2715, validation loss: 0.1436
2024-05-25 06:13:42 [INFO]: Epoch 116 - training loss: 0.2713, validation loss: 0.1435
2024-05-25 06:13:44 [INFO]: Epoch 117 - training loss: 0.2706, validation loss: 0.1429
2024-05-25 06:13:47 [INFO]: Epoch 118 - training loss: 0.2705, validation loss: 0.1423
2024-05-25 06:13:50 [INFO]: Epoch 119 - training loss: 0.2696, validation loss: 0.1421
2024-05-25 06:13:53 [INFO]: Epoch 120 - training loss: 0.2691, validation loss: 0.1417
2024-05-25 06:13:56 [INFO]: Epoch 121 - training loss: 0.2688, validation loss: 0.1413
2024-05-25 06:13:58 [INFO]: Epoch 122 - training loss: 0.2683, validation loss: 0.1411
2024-05-25 06:14:01 [INFO]: Epoch 123 - training loss: 0.2677, validation loss: 0.1409
2024-05-25 06:14:04 [INFO]: Epoch 124 - training loss: 0.2671, validation loss: 0.1405
2024-05-25 06:14:07 [INFO]: Epoch 125 - training loss: 0.2665, validation loss: 0.1401
2024-05-25 06:14:10 [INFO]: Epoch 126 - training loss: 0.2660, validation loss: 0.1396
2024-05-25 06:14:12 [INFO]: Epoch 127 - training loss: 0.2661, validation loss: 0.1395
2024-05-25 06:14:15 [INFO]: Epoch 128 - training loss: 0.2653, validation loss: 0.1392
2024-05-25 06:14:18 [INFO]: Epoch 129 - training loss: 0.2653, validation loss: 0.1389
2024-05-25 06:14:21 [INFO]: Epoch 130 - training loss: 0.2647, validation loss: 0.1384
2024-05-25 06:14:24 [INFO]: Epoch 131 - training loss: 0.2648, validation loss: 0.1383
2024-05-25 06:14:26 [INFO]: Epoch 132 - training loss: 0.2636, validation loss: 0.1379
2024-05-25 06:14:29 [INFO]: Epoch 133 - training loss: 0.2634, validation loss: 0.1377
2024-05-25 06:14:32 [INFO]: Epoch 134 - training loss: 0.2630, validation loss: 0.1373
2024-05-25 06:14:35 [INFO]: Epoch 135 - training loss: 0.2627, validation loss: 0.1371
2024-05-25 06:14:38 [INFO]: Epoch 136 - training loss: 0.2623, validation loss: 0.1367
2024-05-25 06:14:41 [INFO]: Epoch 137 - training loss: 0.2621, validation loss: 0.1364
2024-05-25 06:14:43 [INFO]: Epoch 138 - training loss: 0.2611, validation loss: 0.1362
2024-05-25 06:14:46 [INFO]: Epoch 139 - training loss: 0.2613, validation loss: 0.1360
2024-05-25 06:14:49 [INFO]: Epoch 140 - training loss: 0.2609, validation loss: 0.1355
2024-05-25 06:14:52 [INFO]: Epoch 141 - training loss: 0.2601, validation loss: 0.1353
2024-05-25 06:14:55 [INFO]: Epoch 142 - training loss: 0.2601, validation loss: 0.1351
2024-05-25 06:14:58 [INFO]: Epoch 143 - training loss: 0.2597, validation loss: 0.1347
2024-05-25 06:15:00 [INFO]: Epoch 144 - training loss: 0.2593, validation loss: 0.1344
2024-05-25 06:15:03 [INFO]: Epoch 145 - training loss: 0.2590, validation loss: 0.1342
2024-05-25 06:15:06 [INFO]: Epoch 146 - training loss: 0.2587, validation loss: 0.1340
2024-05-25 06:15:09 [INFO]: Epoch 147 - training loss: 0.2580, validation loss: 0.1337
2024-05-25 06:15:11 [INFO]: Epoch 148 - training loss: 0.2580, validation loss: 0.1334
2024-05-25 06:15:14 [INFO]: Epoch 149 - training loss: 0.2576, validation loss: 0.1332
2024-05-25 06:15:17 [INFO]: Epoch 150 - training loss: 0.2568, validation loss: 0.1329
2024-05-25 06:15:20 [INFO]: Epoch 151 - training loss: 0.2567, validation loss: 0.1327
2024-05-25 06:15:23 [INFO]: Epoch 152 - training loss: 0.2563, validation loss: 0.1326
2024-05-25 06:15:25 [INFO]: Epoch 153 - training loss: 0.2562, validation loss: 0.1321
2024-05-25 06:15:28 [INFO]: Epoch 154 - training loss: 0.2560, validation loss: 0.1320
2024-05-25 06:15:31 [INFO]: Epoch 155 - training loss: 0.2557, validation loss: 0.1317
2024-05-25 06:15:34 [INFO]: Epoch 156 - training loss: 0.2553, validation loss: 0.1316
2024-05-25 06:15:36 [INFO]: Epoch 157 - training loss: 0.2553, validation loss: 0.1315
2024-05-25 06:15:39 [INFO]: Epoch 158 - training loss: 0.2548, validation loss: 0.1312
2024-05-25 06:15:42 [INFO]: Epoch 159 - training loss: 0.2543, validation loss: 0.1310
2024-05-25 06:15:45 [INFO]: Epoch 160 - training loss: 0.2536, validation loss: 0.1307
2024-05-25 06:15:48 [INFO]: Epoch 161 - training loss: 0.2530, validation loss: 0.1304
2024-05-25 06:15:50 [INFO]: Epoch 162 - training loss: 0.2536, validation loss: 0.1306
2024-05-25 06:15:53 [INFO]: Epoch 163 - training loss: 0.2531, validation loss: 0.1301
2024-05-25 06:15:56 [INFO]: Epoch 164 - training loss: 0.2526, validation loss: 0.1297
2024-05-25 06:15:59 [INFO]: Epoch 165 - training loss: 0.2519, validation loss: 0.1298
2024-05-25 06:16:01 [INFO]: Epoch 166 - training loss: 0.2524, validation loss: 0.1295
2024-05-25 06:16:04 [INFO]: Epoch 167 - training loss: 0.2519, validation loss: 0.1294
2024-05-25 06:16:07 [INFO]: Epoch 168 - training loss: 0.2517, validation loss: 0.1290
2024-05-25 06:16:10 [INFO]: Epoch 169 - training loss: 0.2514, validation loss: 0.1290
2024-05-25 06:16:12 [INFO]: Epoch 170 - training loss: 0.2513, validation loss: 0.1288
2024-05-25 06:16:15 [INFO]: Epoch 171 - training loss: 0.2508, validation loss: 0.1285
2024-05-25 06:16:18 [INFO]: Epoch 172 - training loss: 0.2509, validation loss: 0.1286
2024-05-25 06:16:21 [INFO]: Epoch 173 - training loss: 0.2508, validation loss: 0.1283
2024-05-25 06:16:24 [INFO]: Epoch 174 - training loss: 0.2501, validation loss: 0.1280
2024-05-25 06:16:26 [INFO]: Epoch 175 - training loss: 0.2498, validation loss: 0.1280
2024-05-25 06:16:29 [INFO]: Epoch 176 - training loss: 0.2493, validation loss: 0.1278
2024-05-25 06:16:32 [INFO]: Epoch 177 - training loss: 0.2495, validation loss: 0.1276
2024-05-25 06:16:35 [INFO]: Epoch 178 - training loss: 0.2491, validation loss: 0.1273
2024-05-25 06:16:38 [INFO]: Epoch 179 - training loss: 0.2490, validation loss: 0.1273
2024-05-25 06:16:40 [INFO]: Epoch 180 - training loss: 0.2482, validation loss: 0.1270
2024-05-25 06:16:43 [INFO]: Epoch 181 - training loss: 0.2483, validation loss: 0.1269
2024-05-25 06:16:46 [INFO]: Epoch 182 - training loss: 0.2482, validation loss: 0.1268
2024-05-25 06:16:49 [INFO]: Epoch 183 - training loss: 0.2477, validation loss: 0.1261
2024-05-25 06:16:51 [INFO]: Epoch 184 - training loss: 0.2472, validation loss: 0.1264
2024-05-25 06:16:54 [INFO]: Epoch 185 - training loss: 0.2475, validation loss: 0.1262
2024-05-25 06:16:57 [INFO]: Epoch 186 - training loss: 0.2474, validation loss: 0.1260
2024-05-25 06:17:00 [INFO]: Epoch 187 - training loss: 0.2468, validation loss: 0.1258
2024-05-25 06:17:03 [INFO]: Epoch 188 - training loss: 0.2467, validation loss: 0.1260
2024-05-25 06:17:05 [INFO]: Epoch 189 - training loss: 0.2464, validation loss: 0.1256
2024-05-25 06:17:08 [INFO]: Epoch 190 - training loss: 0.2456, validation loss: 0.1257
2024-05-25 06:17:11 [INFO]: Epoch 191 - training loss: 0.2459, validation loss: 0.1255
2024-05-25 06:17:14 [INFO]: Epoch 192 - training loss: 0.2459, validation loss: 0.1253
2024-05-25 06:17:17 [INFO]: Epoch 193 - training loss: 0.2458, validation loss: 0.1250
2024-05-25 06:17:19 [INFO]: Epoch 194 - training loss: 0.2455, validation loss: 0.1248
2024-05-25 06:17:22 [INFO]: Epoch 195 - training loss: 0.2456, validation loss: 0.1249
2024-05-25 06:17:25 [INFO]: Epoch 196 - training loss: 0.2451, validation loss: 0.1248
2024-05-25 06:17:28 [INFO]: Epoch 197 - training loss: 0.2449, validation loss: 0.1246
2024-05-25 06:17:30 [INFO]: Epoch 198 - training loss: 0.2444, validation loss: 0.1243
2024-05-25 06:17:33 [INFO]: Epoch 199 - training loss: 0.2443, validation loss: 0.1243
2024-05-25 06:17:36 [INFO]: Epoch 200 - training loss: 0.2443, validation loss: 0.1241
2024-05-25 06:17:39 [INFO]: Epoch 201 - training loss: 0.2438, validation loss: 0.1241
2024-05-25 06:17:42 [INFO]: Epoch 202 - training loss: 0.2438, validation loss: 0.1239
2024-05-25 06:17:44 [INFO]: Epoch 203 - training loss: 0.2442, validation loss: 0.1238
2024-05-25 06:17:47 [INFO]: Epoch 204 - training loss: 0.2434, validation loss: 0.1235
2024-05-25 06:17:50 [INFO]: Epoch 205 - training loss: 0.2431, validation loss: 0.1234
2024-05-25 06:17:53 [INFO]: Epoch 206 - training loss: 0.2425, validation loss: 0.1233
2024-05-25 06:17:55 [INFO]: Epoch 207 - training loss: 0.2426, validation loss: 0.1233
2024-05-25 06:17:58 [INFO]: Epoch 208 - training loss: 0.2428, validation loss: 0.1232
2024-05-25 06:18:01 [INFO]: Epoch 209 - training loss: 0.2422, validation loss: 0.1230
2024-05-25 06:18:04 [INFO]: Epoch 210 - training loss: 0.2419, validation loss: 0.1229
2024-05-25 06:18:07 [INFO]: Epoch 211 - training loss: 0.2420, validation loss: 0.1228
2024-05-25 06:18:09 [INFO]: Epoch 212 - training loss: 0.2413, validation loss: 0.1227
2024-05-25 06:18:12 [INFO]: Epoch 213 - training loss: 0.2414, validation loss: 0.1228
2024-05-25 06:18:15 [INFO]: Epoch 214 - training loss: 0.2412, validation loss: 0.1227
2024-05-25 06:18:18 [INFO]: Epoch 215 - training loss: 0.2411, validation loss: 0.1226
2024-05-25 06:18:20 [INFO]: Epoch 216 - training loss: 0.2407, validation loss: 0.1223
2024-05-25 06:18:23 [INFO]: Epoch 217 - training loss: 0.2408, validation loss: 0.1220
2024-05-25 06:18:26 [INFO]: Epoch 218 - training loss: 0.2406, validation loss: 0.1222
2024-05-25 06:18:29 [INFO]: Epoch 219 - training loss: 0.2411, validation loss: 0.1220
2024-05-25 06:18:32 [INFO]: Epoch 220 - training loss: 0.2402, validation loss: 0.1219
2024-05-25 06:18:34 [INFO]: Epoch 221 - training loss: 0.2400, validation loss: 0.1218
2024-05-25 06:18:37 [INFO]: Epoch 222 - training loss: 0.2401, validation loss: 0.1218
2024-05-25 06:18:40 [INFO]: Epoch 223 - training loss: 0.2397, validation loss: 0.1214
2024-05-25 06:18:43 [INFO]: Epoch 224 - training loss: 0.2394, validation loss: 0.1215
2024-05-25 06:18:45 [INFO]: Epoch 225 - training loss: 0.2394, validation loss: 0.1212
2024-05-25 06:18:48 [INFO]: Epoch 226 - training loss: 0.2395, validation loss: 0.1214
2024-05-25 06:18:51 [INFO]: Epoch 227 - training loss: 0.2390, validation loss: 0.1210
2024-05-25 06:18:54 [INFO]: Epoch 228 - training loss: 0.2393, validation loss: 0.1211
2024-05-25 06:18:57 [INFO]: Epoch 229 - training loss: 0.2390, validation loss: 0.1210
2024-05-25 06:18:59 [INFO]: Epoch 230 - training loss: 0.2388, validation loss: 0.1209
2024-05-25 06:19:02 [INFO]: Epoch 231 - training loss: 0.2384, validation loss: 0.1208
2024-05-25 06:19:05 [INFO]: Epoch 232 - training loss: 0.2381, validation loss: 0.1204
2024-05-25 06:19:08 [INFO]: Epoch 233 - training loss: 0.2381, validation loss: 0.1208
2024-05-25 06:19:11 [INFO]: Epoch 234 - training loss: 0.2389, validation loss: 0.1208
2024-05-25 06:19:13 [INFO]: Epoch 235 - training loss: 0.2382, validation loss: 0.1201
2024-05-25 06:19:16 [INFO]: Epoch 236 - training loss: 0.2380, validation loss: 0.1202
2024-05-25 06:19:19 [INFO]: Epoch 237 - training loss: 0.2371, validation loss: 0.1203
2024-05-25 06:19:22 [INFO]: Epoch 238 - training loss: 0.2370, validation loss: 0.1202
2024-05-25 06:19:24 [INFO]: Epoch 239 - training loss: 0.2371, validation loss: 0.1201
2024-05-25 06:19:27 [INFO]: Epoch 240 - training loss: 0.2373, validation loss: 0.1199
2024-05-25 06:19:30 [INFO]: Epoch 241 - training loss: 0.2373, validation loss: 0.1200
2024-05-25 06:19:33 [INFO]: Epoch 242 - training loss: 0.2370, validation loss: 0.1199
2024-05-25 06:19:36 [INFO]: Epoch 243 - training loss: 0.2363, validation loss: 0.1199
2024-05-25 06:19:38 [INFO]: Epoch 244 - training loss: 0.2364, validation loss: 0.1197
2024-05-25 06:19:41 [INFO]: Epoch 245 - training loss: 0.2373, validation loss: 0.1198
2024-05-25 06:19:44 [INFO]: Epoch 246 - training loss: 0.2363, validation loss: 0.1195
2024-05-25 06:19:47 [INFO]: Epoch 247 - training loss: 0.2360, validation loss: 0.1195
2024-05-25 06:19:49 [INFO]: Epoch 248 - training loss: 0.2355, validation loss: 0.1194
2024-05-25 06:19:52 [INFO]: Epoch 249 - training loss: 0.2361, validation loss: 0.1192
2024-05-25 06:19:55 [INFO]: Epoch 250 - training loss: 0.2357, validation loss: 0.1195
2024-05-25 06:19:58 [INFO]: Epoch 251 - training loss: 0.2359, validation loss: 0.1192
2024-05-25 06:20:01 [INFO]: Epoch 252 - training loss: 0.2352, validation loss: 0.1192
2024-05-25 06:20:03 [INFO]: Epoch 253 - training loss: 0.2351, validation loss: 0.1188
2024-05-25 06:20:06 [INFO]: Epoch 254 - training loss: 0.2343, validation loss: 0.1190
2024-05-25 06:20:09 [INFO]: Epoch 255 - training loss: 0.2351, validation loss: 0.1190
2024-05-25 06:20:12 [INFO]: Epoch 256 - training loss: 0.2347, validation loss: 0.1189
2024-05-25 06:20:14 [INFO]: Epoch 257 - training loss: 0.2345, validation loss: 0.1188
2024-05-25 06:20:17 [INFO]: Epoch 258 - training loss: 0.2342, validation loss: 0.1186
2024-05-25 06:20:20 [INFO]: Epoch 259 - training loss: 0.2343, validation loss: 0.1186
2024-05-25 06:20:23 [INFO]: Epoch 260 - training loss: 0.2344, validation loss: 0.1184
2024-05-25 06:20:26 [INFO]: Epoch 261 - training loss: 0.2338, validation loss: 0.1185
2024-05-25 06:20:28 [INFO]: Epoch 262 - training loss: 0.2337, validation loss: 0.1184
2024-05-25 06:20:31 [INFO]: Epoch 263 - training loss: 0.2337, validation loss: 0.1182
2024-05-25 06:20:34 [INFO]: Epoch 264 - training loss: 0.2333, validation loss: 0.1186
2024-05-25 06:20:37 [INFO]: Epoch 265 - training loss: 0.2338, validation loss: 0.1181
2024-05-25 06:20:39 [INFO]: Epoch 266 - training loss: 0.2335, validation loss: 0.1181
2024-05-25 06:20:42 [INFO]: Epoch 267 - training loss: 0.2332, validation loss: 0.1180
2024-05-25 06:20:45 [INFO]: Epoch 268 - training loss: 0.2331, validation loss: 0.1180
2024-05-25 06:20:48 [INFO]: Epoch 269 - training loss: 0.2329, validation loss: 0.1182
2024-05-25 06:20:51 [INFO]: Epoch 270 - training loss: 0.2329, validation loss: 0.1179
2024-05-25 06:20:53 [INFO]: Epoch 271 - training loss: 0.2328, validation loss: 0.1177
2024-05-25 06:20:56 [INFO]: Epoch 272 - training loss: 0.2324, validation loss: 0.1178
2024-05-25 06:20:59 [INFO]: Epoch 273 - training loss: 0.2328, validation loss: 0.1177
2024-05-25 06:21:02 [INFO]: Epoch 274 - training loss: 0.2325, validation loss: 0.1182
2024-05-25 06:21:04 [INFO]: Epoch 275 - training loss: 0.2320, validation loss: 0.1175
2024-05-25 06:21:07 [INFO]: Epoch 276 - training loss: 0.2318, validation loss: 0.1175
2024-05-25 06:21:10 [INFO]: Epoch 277 - training loss: 0.2319, validation loss: 0.1175
2024-05-25 06:21:13 [INFO]: Epoch 278 - training loss: 0.2321, validation loss: 0.1177
2024-05-25 06:21:16 [INFO]: Epoch 279 - training loss: 0.2322, validation loss: 0.1175
2024-05-25 06:21:18 [INFO]: Epoch 280 - training loss: 0.2314, validation loss: 0.1175
2024-05-25 06:21:21 [INFO]: Epoch 281 - training loss: 0.2320, validation loss: 0.1176
2024-05-25 06:21:24 [INFO]: Epoch 282 - training loss: 0.2316, validation loss: 0.1174
2024-05-25 06:21:27 [INFO]: Epoch 283 - training loss: 0.2318, validation loss: 0.1172
2024-05-25 06:21:29 [INFO]: Epoch 284 - training loss: 0.2312, validation loss: 0.1173
2024-05-25 06:21:32 [INFO]: Epoch 285 - training loss: 0.2316, validation loss: 0.1171
2024-05-25 06:21:35 [INFO]: Epoch 286 - training loss: 0.2309, validation loss: 0.1169
2024-05-25 06:21:38 [INFO]: Epoch 287 - training loss: 0.2310, validation loss: 0.1173
2024-05-25 06:21:41 [INFO]: Epoch 288 - training loss: 0.2305, validation loss: 0.1170
2024-05-25 06:21:43 [INFO]: Epoch 289 - training loss: 0.2308, validation loss: 0.1169
2024-05-25 06:21:46 [INFO]: Epoch 290 - training loss: 0.2309, validation loss: 0.1168
2024-05-25 06:21:49 [INFO]: Epoch 291 - training loss: 0.2307, validation loss: 0.1169
2024-05-25 06:21:52 [INFO]: Epoch 292 - training loss: 0.2307, validation loss: 0.1168
2024-05-25 06:21:55 [INFO]: Epoch 293 - training loss: 0.2303, validation loss: 0.1170
2024-05-25 06:21:57 [INFO]: Epoch 294 - training loss: 0.2302, validation loss: 0.1165
2024-05-25 06:22:00 [INFO]: Epoch 295 - training loss: 0.2300, validation loss: 0.1169
2024-05-25 06:22:03 [INFO]: Epoch 296 - training loss: 0.2305, validation loss: 0.1168
2024-05-25 06:22:06 [INFO]: Epoch 297 - training loss: 0.2301, validation loss: 0.1166
2024-05-25 06:22:08 [INFO]: Epoch 298 - training loss: 0.2302, validation loss: 0.1166
2024-05-25 06:22:11 [INFO]: Epoch 299 - training loss: 0.2304, validation loss: 0.1167
2024-05-25 06:22:14 [INFO]: Epoch 300 - training loss: 0.2298, validation loss: 0.1167
2024-05-25 06:22:14 [INFO]: Finished training. The best model is from epoch#294.
2024-05-25 06:22:14 [INFO]: Saved the model to augmentation_saved_results/round_4/BRITS_air_quality/20240525_T060816/BRITS.pypots
2024-05-25 06:22:15 [INFO]: BRITS on Air-Quality: MAE=0.1551, MSE=0.1657
2024-05-25 06:22:15 [INFO]: Successfully saved to augmentation_saved_results/round_4/BRITS_air_quality/imputation.pkl
2024-05-25 06:22:15 [INFO]: Using the given device: cuda:0
2024-05-25 06:22:15 [INFO]: Model files will be saved to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215
2024-05-25 06:22:15 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/tensorboard
2024-05-25 06:22:15 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 06:22:19 [INFO]: Epoch 001 - training loss: 1.4863, validation loss: 0.7955
2024-05-25 06:22:19 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch1_loss0.7955290049314498.pypots
2024-05-25 06:22:23 [INFO]: Epoch 002 - training loss: 1.0662, validation loss: 0.7474
2024-05-25 06:22:23 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch2_loss0.7473502099514008.pypots
2024-05-25 06:22:27 [INFO]: Epoch 003 - training loss: 0.9853, validation loss: 0.7273
2024-05-25 06:22:27 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch3_loss0.7272859424352646.pypots
2024-05-25 06:22:31 [INFO]: Epoch 004 - training loss: 0.9667, validation loss: 0.7134
2024-05-25 06:22:31 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch4_loss0.7134207785129547.pypots
2024-05-25 06:22:35 [INFO]: Epoch 005 - training loss: 0.9434, validation loss: 0.7048
2024-05-25 06:22:35 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch5_loss0.7048158258199692.pypots
2024-05-25 06:22:39 [INFO]: Epoch 006 - training loss: 0.9477, validation loss: 0.6990
2024-05-25 06:22:39 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch6_loss0.6989776879549027.pypots
2024-05-25 06:22:42 [INFO]: Epoch 007 - training loss: 0.9431, validation loss: 0.6941
2024-05-25 06:22:42 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch7_loss0.6940896928310394.pypots
2024-05-25 06:22:46 [INFO]: Epoch 008 - training loss: 0.9225, validation loss: 0.6908
2024-05-25 06:22:46 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch8_loss0.6908430904150009.pypots
2024-05-25 06:22:50 [INFO]: Epoch 009 - training loss: 0.9118, validation loss: 0.6886
2024-05-25 06:22:50 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch9_loss0.6885755121707916.pypots
2024-05-25 06:22:54 [INFO]: Epoch 010 - training loss: 0.9111, validation loss: 0.6859
2024-05-25 06:22:54 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch10_loss0.6859427988529205.pypots
2024-05-25 06:22:58 [INFO]: Epoch 011 - training loss: 0.9210, validation loss: 0.6842
2024-05-25 06:22:58 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch11_loss0.684184941649437.pypots
2024-05-25 06:23:02 [INFO]: Epoch 012 - training loss: 0.9079, validation loss: 0.6834
2024-05-25 06:23:02 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch12_loss0.6833779156208039.pypots
2024-05-25 06:23:05 [INFO]: Epoch 013 - training loss: 0.8956, validation loss: 0.6819
2024-05-25 06:23:05 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch13_loss0.681878200173378.pypots
2024-05-25 06:23:09 [INFO]: Epoch 014 - training loss: 0.8987, validation loss: 0.6814
2024-05-25 06:23:09 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch14_loss0.6813998520374298.pypots
2024-05-25 06:23:13 [INFO]: Epoch 015 - training loss: 0.8878, validation loss: 0.6822
2024-05-25 06:23:13 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch15_loss0.6822344362735748.pypots
2024-05-25 06:23:17 [INFO]: Epoch 016 - training loss: 0.8862, validation loss: 0.6814
2024-05-25 06:23:17 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch16_loss0.6813570469617843.pypots
2024-05-25 06:23:21 [INFO]: Epoch 017 - training loss: 0.8841, validation loss: 0.6808
2024-05-25 06:23:21 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch17_loss0.6808175414800643.pypots
2024-05-25 06:23:25 [INFO]: Epoch 018 - training loss: 0.8748, validation loss: 0.6804
2024-05-25 06:23:25 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch18_loss0.6803871780633927.pypots
2024-05-25 06:23:29 [INFO]: Epoch 019 - training loss: 0.8758, validation loss: 0.6802
2024-05-25 06:23:29 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch19_loss0.6801971763372421.pypots
2024-05-25 06:23:33 [INFO]: Epoch 020 - training loss: 0.8787, validation loss: 0.6820
2024-05-25 06:23:33 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch20_loss0.6819815099239349.pypots
2024-05-25 06:23:36 [INFO]: Epoch 021 - training loss: 0.8752, validation loss: 0.6840
2024-05-25 06:23:36 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch21_loss0.6840358048677444.pypots
2024-05-25 06:23:40 [INFO]: Epoch 022 - training loss: 0.8697, validation loss: 0.6833
2024-05-25 06:23:40 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch22_loss0.6832698792219162.pypots
2024-05-25 06:23:44 [INFO]: Epoch 023 - training loss: 0.8582, validation loss: 0.6851
2024-05-25 06:23:44 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch23_loss0.6850872546434402.pypots
2024-05-25 06:23:48 [INFO]: Epoch 024 - training loss: 0.8801, validation loss: 0.6839
2024-05-25 06:23:48 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch24_loss0.683912244439125.pypots
2024-05-25 06:23:52 [INFO]: Epoch 025 - training loss: 0.8737, validation loss: 0.6844
2024-05-25 06:23:52 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch25_loss0.6843800991773605.pypots
2024-05-25 06:23:56 [INFO]: Epoch 026 - training loss: 0.8621, validation loss: 0.6863
2024-05-25 06:23:56 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch26_loss0.6862851172685623.pypots
2024-05-25 06:23:59 [INFO]: Epoch 027 - training loss: 0.8552, validation loss: 0.6862
2024-05-25 06:23:59 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch27_loss0.6861584603786468.pypots
2024-05-25 06:24:03 [INFO]: Epoch 028 - training loss: 0.8604, validation loss: 0.6885
2024-05-25 06:24:03 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch28_loss0.6884981155395508.pypots
2024-05-25 06:24:07 [INFO]: Epoch 029 - training loss: 0.8416, validation loss: 0.6894
2024-05-25 06:24:07 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN_epoch29_loss0.6893960952758789.pypots
2024-05-25 06:24:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:24:07 [INFO]: Finished training. The best model is from epoch#19.
2024-05-25 06:24:07 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240525_T062215/MRNN.pypots
2024-05-25 06:24:08 [INFO]: MRNN on Air-Quality: MAE=0.5285, MSE=0.7057
2024-05-25 06:24:08 [INFO]: Successfully saved to augmentation_saved_results/round_4/MRNN_air_quality/imputation.pkl
2024-05-25 06:24:08 [INFO]: Using the given device: cpu
2024-05-25 06:24:08 [INFO]: LOCF on Air-Quality: MAE=0.2206, MSE=0.3343
2024-05-25 06:24:08 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_air_quality".
2024-05-25 06:24:08 [INFO]: Successfully saved to augmentation_saved_results/round_4/LOCF_air_quality/imputation.pkl
2024-05-25 06:24:08 [INFO]: Median on Air-Quality: MAE=0.6668, MSE=1.0938
2024-05-25 06:24:08 [INFO]: Successfully created the given path "saved_results/round_4/Median_air_quality".
2024-05-25 06:24:08 [INFO]: Successfully saved to augmentation_saved_results/round_4/Median_air_quality/imputation.pkl
2024-05-25 06:24:08 [INFO]: Mean on Air-Quality: MAE=0.6965, MSE=1.0305
2024-05-25 06:24:08 [INFO]: Successfully created the given path "saved_results/round_4/Mean_air_quality".
2024-05-25 06:24:08 [INFO]: Successfully saved to augmentation_saved_results/round_4/Mean_air_quality/imputation.pkl
2024-05-25 06:24:08 [INFO]: 
SAITS on data/air_quality: MAE=0.1510.0008013450499064316, MSE=0.1790.0005462822308157362
Transformer on data/air_quality: MAE=0.1670.004908990569974806, MSE=0.2030.009071951277934304
TimesNet on data/air_quality: MAE=0.1630.0012618116557934806, MSE=0.2340.0033674065533561446
CSDI on data/air_quality: MAE=0.1080.004272195112072752, MSE=0.1840.01927849278239118
GPVAE on data/air_quality: MAE=0.3100.008923377584631605, MSE=0.3350.017811456543422723
USGAN on data/air_quality: MAE=0.2080.0007676482354995524, MSE=0.1950.0033768010516337437
BRITS on data/air_quality: MAE=0.1550.000596658745677552, MSE=0.1650.00108307663097749
MRNN on data/air_quality: MAE=0.5300.0020588213225524897, MSE=0.7060.0026097722757189327
LOCF on data/air_quality: MAE=0.2210.0, MSE=0.3340.0
Median on data/air_quality: MAE=0.6670.0, MSE=1.0940.0
Mean on data/air_quality: MAE=0.6970.0, MSE=1.0300.0

