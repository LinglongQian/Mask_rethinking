2024-05-21 21:46:13 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-21 21:46:14 [INFO]: Using the given device: cuda:0
2024-05-21 21:46:15 [INFO]: Model files will be saved to saved_results/round_0/SAITS_physionet2012/20240521_T214615
2024-05-21 21:46:15 [INFO]: Tensorboard file will be saved to saved_results/round_0/SAITS_physionet2012/20240521_T214615/tensorboard
2024-05-21 21:46:15 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-21 21:46:34 [INFO]: Epoch 001 - training loss: 0.7593, validation loss: 0.3963
2024-05-21 21:46:52 [INFO]: Epoch 002 - training loss: 0.4836, validation loss: 0.3453
2024-05-21 21:47:09 [INFO]: Epoch 003 - training loss: 0.4164, validation loss: 0.3179
2024-05-21 21:47:25 [INFO]: Epoch 004 - training loss: 0.3734, validation loss: 0.3035
2024-05-21 21:47:42 [INFO]: Epoch 005 - training loss: 0.3430, validation loss: 0.2862
2024-05-21 21:47:58 [INFO]: Epoch 006 - training loss: 0.3255, validation loss: 0.2766
2024-05-21 21:48:16 [INFO]: Epoch 007 - training loss: 0.3124, validation loss: 0.2664
2024-05-21 21:48:36 [INFO]: Epoch 008 - training loss: 0.3014, validation loss: 0.2641
2024-05-21 21:48:56 [INFO]: Epoch 009 - training loss: 0.2946, validation loss: 0.2603
2024-05-21 21:49:16 [INFO]: Epoch 010 - training loss: 0.2872, validation loss: 0.2586
2024-05-21 21:49:37 [INFO]: Epoch 011 - training loss: 0.2820, validation loss: 0.2478
2024-05-21 21:49:57 [INFO]: Epoch 012 - training loss: 0.2756, validation loss: 0.2463
2024-05-21 21:50:17 [INFO]: Epoch 013 - training loss: 0.2728, validation loss: 0.2474
2024-05-21 21:50:38 [INFO]: Epoch 014 - training loss: 0.2693, validation loss: 0.2423
2024-05-21 21:50:58 [INFO]: Epoch 015 - training loss: 0.2638, validation loss: 0.2445
2024-05-21 21:51:19 [INFO]: Epoch 016 - training loss: 0.2648, validation loss: 0.2536
2024-05-21 21:51:39 [INFO]: Epoch 017 - training loss: 0.2612, validation loss: 0.2419
2024-05-21 21:52:00 [INFO]: Epoch 018 - training loss: 0.2578, validation loss: 0.2379
2024-05-21 21:52:20 [INFO]: Epoch 019 - training loss: 0.2566, validation loss: 0.2400
2024-05-21 21:52:41 [INFO]: Epoch 020 - training loss: 0.2548, validation loss: 0.2351
2024-05-21 21:53:02 [INFO]: Epoch 021 - training loss: 0.2545, validation loss: 0.2351
2024-05-21 21:53:22 [INFO]: Epoch 022 - training loss: 0.2538, validation loss: 0.2356
2024-05-21 21:53:37 [INFO]: Epoch 023 - training loss: 0.2522, validation loss: 0.2345
2024-05-21 21:53:51 [INFO]: Epoch 024 - training loss: 0.2499, validation loss: 0.2278
2024-05-21 21:54:04 [INFO]: Epoch 025 - training loss: 0.2491, validation loss: 0.2399
2024-05-21 21:54:16 [INFO]: Epoch 026 - training loss: 0.2482, validation loss: 0.2295
2024-05-21 21:54:30 [INFO]: Epoch 027 - training loss: 0.2456, validation loss: 0.2295
2024-05-21 21:54:43 [INFO]: Epoch 028 - training loss: 0.2451, validation loss: 0.2355
2024-05-21 21:54:56 [INFO]: Epoch 029 - training loss: 0.2440, validation loss: 0.2350
2024-05-21 21:55:09 [INFO]: Epoch 030 - training loss: 0.2435, validation loss: 0.2246
2024-05-21 21:55:22 [INFO]: Epoch 031 - training loss: 0.2429, validation loss: 0.2367
2024-05-21 21:55:36 [INFO]: Epoch 032 - training loss: 0.2404, validation loss: 0.2357
2024-05-21 21:55:50 [INFO]: Epoch 033 - training loss: 0.2412, validation loss: 0.2325
2024-05-21 21:56:03 [INFO]: Epoch 034 - training loss: 0.2412, validation loss: 0.2353
2024-05-21 21:56:18 [INFO]: Epoch 035 - training loss: 0.2385, validation loss: 0.2343
2024-05-21 21:56:33 [INFO]: Epoch 036 - training loss: 0.2388, validation loss: 0.2267
2024-05-21 21:56:48 [INFO]: Epoch 037 - training loss: 0.2394, validation loss: 0.2419
2024-05-21 21:57:05 [INFO]: Epoch 038 - training loss: 0.2376, validation loss: 0.2293
2024-05-21 21:57:27 [INFO]: Epoch 039 - training loss: 0.2390, validation loss: 0.2319
2024-05-21 21:57:48 [INFO]: Epoch 040 - training loss: 0.2378, validation loss: 0.2372
2024-05-21 21:57:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-21 21:57:48 [INFO]: Finished training. The best model is from epoch#30.
2024-05-21 21:57:48 [INFO]: Saved the model to saved_results/round_0/SAITS_physionet2012/20240521_T214615/SAITS.pypots
2024-05-21 21:57:49 [INFO]: SAITS on PhysioNet-2012: MAE=0.2006, MSE=0.2188
2024-05-21 21:57:52 [INFO]: Successfully saved to saved_results/round_0/SAITS_physionet2012/imputation.pkl
2024-05-21 21:57:52 [INFO]: Using the given device: cuda:0
2024-05-21 21:57:52 [INFO]: Model files will be saved to saved_results/round_0/Transformer_physionet2012/20240521_T215752
2024-05-21 21:57:52 [INFO]: Tensorboard file will be saved to saved_results/round_0/Transformer_physionet2012/20240521_T215752/tensorboard
2024-05-21 21:57:52 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-21 21:58:04 [INFO]: Epoch 001 - training loss: 0.8351, validation loss: 0.4329
2024-05-21 21:58:16 [INFO]: Epoch 002 - training loss: 0.5514, validation loss: 0.3982
2024-05-21 21:58:28 [INFO]: Epoch 003 - training loss: 0.4808, validation loss: 0.3793
2024-05-21 21:58:40 [INFO]: Epoch 004 - training loss: 0.4388, validation loss: 0.3553
2024-05-21 21:58:51 [INFO]: Epoch 005 - training loss: 0.4090, validation loss: 0.3396
2024-05-21 21:59:03 [INFO]: Epoch 006 - training loss: 0.3890, validation loss: 0.3309
2024-05-21 21:59:15 [INFO]: Epoch 007 - training loss: 0.3704, validation loss: 0.3221
2024-05-21 21:59:27 [INFO]: Epoch 008 - training loss: 0.3567, validation loss: 0.3106
2024-05-21 21:59:39 [INFO]: Epoch 009 - training loss: 0.3458, validation loss: 0.3043
2024-05-21 21:59:51 [INFO]: Epoch 010 - training loss: 0.3362, validation loss: 0.3049
2024-05-21 22:00:03 [INFO]: Epoch 011 - training loss: 0.3319, validation loss: 0.2930
2024-05-21 22:00:16 [INFO]: Epoch 012 - training loss: 0.3219, validation loss: 0.2916
2024-05-21 22:00:28 [INFO]: Epoch 013 - training loss: 0.3172, validation loss: 0.2804
2024-05-21 22:00:40 [INFO]: Epoch 014 - training loss: 0.3147, validation loss: 0.2756
2024-05-21 22:00:52 [INFO]: Epoch 015 - training loss: 0.3104, validation loss: 0.2732
2024-05-21 22:01:04 [INFO]: Epoch 016 - training loss: 0.3049, validation loss: 0.2785
2024-05-21 22:01:17 [INFO]: Epoch 017 - training loss: 0.3045, validation loss: 0.2759
2024-05-21 22:01:29 [INFO]: Epoch 018 - training loss: 0.2979, validation loss: 0.2751
2024-05-21 22:01:41 [INFO]: Epoch 019 - training loss: 0.2957, validation loss: 0.2726
2024-05-21 22:01:53 [INFO]: Epoch 020 - training loss: 0.2928, validation loss: 0.2677
2024-05-21 22:02:05 [INFO]: Epoch 021 - training loss: 0.2888, validation loss: 0.2663
2024-05-21 22:02:18 [INFO]: Epoch 022 - training loss: 0.2867, validation loss: 0.2614
2024-05-21 22:02:30 [INFO]: Epoch 023 - training loss: 0.2859, validation loss: 0.2600
2024-05-21 22:02:42 [INFO]: Epoch 024 - training loss: 0.2819, validation loss: 0.2573
2024-05-21 22:02:54 [INFO]: Epoch 025 - training loss: 0.2805, validation loss: 0.2545
2024-05-21 22:03:06 [INFO]: Epoch 026 - training loss: 0.2797, validation loss: 0.2564
2024-05-21 22:03:18 [INFO]: Epoch 027 - training loss: 0.2777, validation loss: 0.2470
2024-05-21 22:03:30 [INFO]: Epoch 028 - training loss: 0.2765, validation loss: 0.2551
2024-05-21 22:03:42 [INFO]: Epoch 029 - training loss: 0.2745, validation loss: 0.2484
2024-05-21 22:03:54 [INFO]: Epoch 030 - training loss: 0.2741, validation loss: 0.2492
2024-05-21 22:04:06 [INFO]: Epoch 031 - training loss: 0.2721, validation loss: 0.2543
2024-05-21 22:04:18 [INFO]: Epoch 032 - training loss: 0.2706, validation loss: 0.2460
2024-05-21 22:04:30 [INFO]: Epoch 033 - training loss: 0.2679, validation loss: 0.2431
2024-05-21 22:04:42 [INFO]: Epoch 034 - training loss: 0.2690, validation loss: 0.2518
2024-05-21 22:04:55 [INFO]: Epoch 035 - training loss: 0.2664, validation loss: 0.2464
2024-05-21 22:05:07 [INFO]: Epoch 036 - training loss: 0.2652, validation loss: 0.2437
2024-05-21 22:05:19 [INFO]: Epoch 037 - training loss: 0.2651, validation loss: 0.2469
2024-05-21 22:05:31 [INFO]: Epoch 038 - training loss: 0.2650, validation loss: 0.2448
2024-05-21 22:05:44 [INFO]: Epoch 039 - training loss: 0.2626, validation loss: 0.2451
2024-05-21 22:05:56 [INFO]: Epoch 040 - training loss: 0.2636, validation loss: 0.2407
2024-05-21 22:06:08 [INFO]: Epoch 041 - training loss: 0.2625, validation loss: 0.2385
2024-05-21 22:06:20 [INFO]: Epoch 042 - training loss: 0.2616, validation loss: 0.2357
2024-05-21 22:06:32 [INFO]: Epoch 043 - training loss: 0.2590, validation loss: 0.2418
2024-05-21 22:06:44 [INFO]: Epoch 044 - training loss: 0.2569, validation loss: 0.2361
2024-05-21 22:06:56 [INFO]: Epoch 045 - training loss: 0.2579, validation loss: 0.2470
2024-05-21 22:07:08 [INFO]: Epoch 046 - training loss: 0.2583, validation loss: 0.2345
2024-05-21 22:07:20 [INFO]: Epoch 047 - training loss: 0.2567, validation loss: 0.2354
2024-05-21 22:07:33 [INFO]: Epoch 048 - training loss: 0.2545, validation loss: 0.2387
2024-05-21 22:07:45 [INFO]: Epoch 049 - training loss: 0.2545, validation loss: 0.2407
2024-05-21 22:07:57 [INFO]: Epoch 050 - training loss: 0.2560, validation loss: 0.2367
2024-05-21 22:08:10 [INFO]: Epoch 051 - training loss: 0.2538, validation loss: 0.2410
2024-05-21 22:08:22 [INFO]: Epoch 052 - training loss: 0.2531, validation loss: 0.2370
2024-05-21 22:08:34 [INFO]: Epoch 053 - training loss: 0.2522, validation loss: 0.2356
2024-05-21 22:08:46 [INFO]: Epoch 054 - training loss: 0.2513, validation loss: 0.2331
2024-05-21 22:08:58 [INFO]: Epoch 055 - training loss: 0.2526, validation loss: 0.2329
2024-05-21 22:09:10 [INFO]: Epoch 056 - training loss: 0.2522, validation loss: 0.2341
2024-05-21 22:09:21 [INFO]: Epoch 057 - training loss: 0.2516, validation loss: 0.2352
2024-05-21 22:09:33 [INFO]: Epoch 058 - training loss: 0.2496, validation loss: 0.2368
2024-05-21 22:09:44 [INFO]: Epoch 059 - training loss: 0.2495, validation loss: 0.2404
2024-05-21 22:09:56 [INFO]: Epoch 060 - training loss: 0.2490, validation loss: 0.2355
2024-05-21 22:10:08 [INFO]: Epoch 061 - training loss: 0.2496, validation loss: 0.2339
2024-05-21 22:10:20 [INFO]: Epoch 062 - training loss: 0.2491, validation loss: 0.2388
2024-05-21 22:10:32 [INFO]: Epoch 063 - training loss: 0.2475, validation loss: 0.2367
2024-05-21 22:10:44 [INFO]: Epoch 064 - training loss: 0.2482, validation loss: 0.2341
2024-05-21 22:10:56 [INFO]: Epoch 065 - training loss: 0.2477, validation loss: 0.2303
2024-05-21 22:11:08 [INFO]: Epoch 066 - training loss: 0.2469, validation loss: 0.2328
2024-05-21 22:11:20 [INFO]: Epoch 067 - training loss: 0.2464, validation loss: 0.2340
2024-05-21 22:11:32 [INFO]: Epoch 068 - training loss: 0.2461, validation loss: 0.2290
2024-05-21 22:11:43 [INFO]: Epoch 069 - training loss: 0.2452, validation loss: 0.2329
2024-05-21 22:11:55 [INFO]: Epoch 070 - training loss: 0.2445, validation loss: 0.2326
2024-05-21 22:12:06 [INFO]: Epoch 071 - training loss: 0.2452, validation loss: 0.2382
2024-05-21 22:12:17 [INFO]: Epoch 072 - training loss: 0.2444, validation loss: 0.2350
2024-05-21 22:12:29 [INFO]: Epoch 073 - training loss: 0.2436, validation loss: 0.2287
2024-05-21 22:12:40 [INFO]: Epoch 074 - training loss: 0.2440, validation loss: 0.2317
2024-05-21 22:12:52 [INFO]: Epoch 075 - training loss: 0.2447, validation loss: 0.2265
2024-05-21 22:13:04 [INFO]: Epoch 076 - training loss: 0.2427, validation loss: 0.2315
2024-05-21 22:13:16 [INFO]: Epoch 077 - training loss: 0.2419, validation loss: 0.2288
2024-05-21 22:13:28 [INFO]: Epoch 078 - training loss: 0.2426, validation loss: 0.2324
2024-05-21 22:13:40 [INFO]: Epoch 079 - training loss: 0.2416, validation loss: 0.2291
2024-05-21 22:13:52 [INFO]: Epoch 080 - training loss: 0.2417, validation loss: 0.2342
2024-05-21 22:14:04 [INFO]: Epoch 081 - training loss: 0.2425, validation loss: 0.2294
2024-05-21 22:14:16 [INFO]: Epoch 082 - training loss: 0.2424, validation loss: 0.2307
2024-05-21 22:14:28 [INFO]: Epoch 083 - training loss: 0.2416, validation loss: 0.2304
2024-05-21 22:14:41 [INFO]: Epoch 084 - training loss: 0.2407, validation loss: 0.2315
2024-05-21 22:14:53 [INFO]: Epoch 085 - training loss: 0.2403, validation loss: 0.2302
2024-05-21 22:14:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-21 22:14:53 [INFO]: Finished training. The best model is from epoch#75.
2024-05-21 22:14:53 [INFO]: Saved the model to saved_results/round_0/Transformer_physionet2012/20240521_T215752/Transformer.pypots
2024-05-21 22:14:54 [INFO]: Transformer on PhysioNet-2012: MAE=0.2045, MSE=0.2164
2024-05-21 22:14:56 [INFO]: Successfully saved to saved_results/round_0/Transformer_physionet2012/imputation.pkl
2024-05-21 22:14:56 [INFO]: Using the given device: cuda:0
2024-05-21 22:14:56 [INFO]: Model files will be saved to saved_results/round_0/TimesNet_physionet2012/20240521_T221456
2024-05-21 22:14:56 [INFO]: Tensorboard file will be saved to saved_results/round_0/TimesNet_physionet2012/20240521_T221456/tensorboard
2024-05-21 22:14:57 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-21 22:15:11 [INFO]: Epoch 001 - training loss: 0.4638, validation loss: 0.3537
2024-05-21 22:15:22 [INFO]: Epoch 002 - training loss: 0.3194, validation loss: 0.3060
2024-05-21 22:15:34 [INFO]: Epoch 003 - training loss: 0.4062, validation loss: 0.3093
2024-05-21 22:15:44 [INFO]: Epoch 004 - training loss: 0.3237, validation loss: 0.3108
2024-05-21 22:15:56 [INFO]: Epoch 005 - training loss: 0.3084, validation loss: 0.2924
2024-05-21 22:16:07 [INFO]: Epoch 006 - training loss: 0.4303, validation loss: 0.3023
2024-05-21 22:16:17 [INFO]: Epoch 007 - training loss: 0.3493, validation loss: 0.3020
2024-05-21 22:16:29 [INFO]: Epoch 008 - training loss: 0.4138, validation loss: 0.3357
2024-05-21 22:16:39 [INFO]: Epoch 009 - training loss: 0.5061, validation loss: 0.3419
2024-05-21 22:16:51 [INFO]: Epoch 010 - training loss: 0.4513, validation loss: 0.3251
2024-05-21 22:17:02 [INFO]: Epoch 011 - training loss: 0.3436, validation loss: 0.3148
2024-05-21 22:17:13 [INFO]: Epoch 012 - training loss: 0.5472, validation loss: 0.3172
2024-05-21 22:17:24 [INFO]: Epoch 013 - training loss: 0.4229, validation loss: 0.3028
2024-05-21 22:17:35 [INFO]: Epoch 014 - training loss: 0.3920, validation loss: 0.3108
2024-05-21 22:17:46 [INFO]: Epoch 015 - training loss: 0.3398, validation loss: 0.2973
2024-05-21 22:17:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-21 22:17:46 [INFO]: Finished training. The best model is from epoch#5.
2024-05-21 22:17:46 [INFO]: Saved the model to saved_results/round_0/TimesNet_physionet2012/20240521_T221456/TimesNet.pypots
2024-05-21 22:17:47 [INFO]: TimesNet on PhysioNet-2012: MAE=0.2841, MSE=0.2950
2024-05-21 22:17:52 [INFO]: Successfully saved to saved_results/round_0/TimesNet_physionet2012/imputation.pkl
2024-05-21 22:17:52 [INFO]: Using the given device: cuda:0
2024-05-21 22:17:52 [INFO]: Model files will be saved to saved_results/round_0/CSDI_physionet2012/20240521_T221752
2024-05-21 22:17:52 [INFO]: Tensorboard file will be saved to saved_results/round_0/CSDI_physionet2012/20240521_T221752/tensorboard
2024-05-21 22:17:52 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-21 22:23:30 [INFO]: Epoch 001 - training loss: 0.3403, validation loss: 0.2455
2024-05-21 22:23:30 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch1_loss0.24553687994678816.pypots
2024-05-21 22:29:08 [INFO]: Epoch 002 - training loss: 0.2609, validation loss: 0.2144
2024-05-21 22:29:08 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch2_loss0.21441174919406572.pypots
2024-05-21 22:34:46 [INFO]: Epoch 003 - training loss: 0.2439, validation loss: 0.2038
2024-05-21 22:34:46 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch3_loss0.20384738817811013.pypots
2024-05-21 22:40:24 [INFO]: Epoch 004 - training loss: 0.2422, validation loss: 0.2007
2024-05-21 22:40:24 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch4_loss0.20071320980787277.pypots
2024-05-21 22:46:02 [INFO]: Epoch 005 - training loss: 0.2348, validation loss: 0.1937
2024-05-21 22:46:02 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch5_loss0.19371081292629241.pypots
2024-05-21 22:51:40 [INFO]: Epoch 006 - training loss: 0.2357, validation loss: 0.1903
2024-05-21 22:51:40 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch6_loss0.19026139502724013.pypots
2024-05-21 22:57:52 [INFO]: Epoch 007 - training loss: 0.2299, validation loss: 0.1878
2024-05-21 22:57:52 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch7_loss0.18778757626811662.pypots
2024-05-21 23:04:16 [INFO]: Epoch 008 - training loss: 0.2300, validation loss: 0.1882
2024-05-21 23:04:16 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch8_loss0.1882245975236098.pypots
2024-05-21 23:10:39 [INFO]: Epoch 009 - training loss: 0.2237, validation loss: 0.1837
2024-05-21 23:10:39 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch9_loss0.1836755909025669.pypots
2024-05-21 23:17:03 [INFO]: Epoch 010 - training loss: 0.2208, validation loss: 0.1850
2024-05-21 23:17:03 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch10_loss0.18499612510204316.pypots
2024-05-21 23:23:27 [INFO]: Epoch 011 - training loss: 0.2190, validation loss: 0.1835
2024-05-21 23:23:27 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch11_loss0.1835162152846654.pypots
2024-05-21 23:30:04 [INFO]: Epoch 012 - training loss: 0.2156, validation loss: 0.1822
2024-05-21 23:30:04 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch12_loss0.18220062429706255.pypots
2024-05-21 23:34:09 [INFO]: Epoch 013 - training loss: 0.2226, validation loss: 0.1807
2024-05-21 23:34:10 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch13_loss0.18070537572105724.pypots
2024-05-21 23:37:57 [INFO]: Epoch 014 - training loss: 0.2216, validation loss: 0.1783
2024-05-21 23:37:57 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch14_loss0.17826957404613494.pypots
2024-05-21 23:41:45 [INFO]: Epoch 015 - training loss: 0.2254, validation loss: 0.1810
2024-05-21 23:41:45 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch15_loss0.18101792683204015.pypots
2024-05-21 23:45:38 [INFO]: Epoch 016 - training loss: 0.2182, validation loss: 0.1778
2024-05-21 23:45:38 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch16_loss0.17784832219282787.pypots
2024-05-21 23:49:40 [INFO]: Epoch 017 - training loss: 0.2216, validation loss: 0.1778
2024-05-21 23:49:40 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch17_loss0.17776321843266488.pypots
2024-05-21 23:53:26 [INFO]: Epoch 018 - training loss: 0.2246, validation loss: 0.1786
2024-05-21 23:53:26 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch18_loss0.17857828885316848.pypots
2024-05-21 23:56:41 [INFO]: Epoch 019 - training loss: 0.2164, validation loss: 0.1751
2024-05-21 23:56:41 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch19_loss0.17510357052087783.pypots
2024-05-21 23:59:56 [INFO]: Epoch 020 - training loss: 0.2194, validation loss: 0.1765
2024-05-21 23:59:56 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch20_loss0.17648542920748392.pypots
2024-05-22 00:03:11 [INFO]: Epoch 021 - training loss: 0.2207, validation loss: 0.1742
2024-05-22 00:03:11 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch21_loss0.1741585522890091.pypots
2024-05-22 00:06:27 [INFO]: Epoch 022 - training loss: 0.2098, validation loss: 0.1725
2024-05-22 00:06:27 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch22_loss0.17248154456416767.pypots
2024-05-22 00:09:42 [INFO]: Epoch 023 - training loss: 0.2151, validation loss: 0.1739
2024-05-22 00:09:42 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch23_loss0.17389756813645363.pypots
2024-05-22 00:12:57 [INFO]: Epoch 024 - training loss: 0.2204, validation loss: 0.1742
2024-05-22 00:12:57 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch24_loss0.17416718875368437.pypots
2024-05-22 00:16:13 [INFO]: Epoch 025 - training loss: 0.2132, validation loss: 0.1754
2024-05-22 00:16:13 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch25_loss0.17544379482666653.pypots
2024-05-22 00:19:28 [INFO]: Epoch 026 - training loss: 0.2195, validation loss: 0.1730
2024-05-22 00:19:28 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch26_loss0.1730042373140653.pypots
2024-05-22 00:22:43 [INFO]: Epoch 027 - training loss: 0.2155, validation loss: 0.1733
2024-05-22 00:22:43 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch27_loss0.17334435979525248.pypots
2024-05-22 00:25:58 [INFO]: Epoch 028 - training loss: 0.2179, validation loss: 0.1767
2024-05-22 00:25:58 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch28_loss0.17667425374190013.pypots
2024-05-22 00:29:13 [INFO]: Epoch 029 - training loss: 0.2143, validation loss: 0.1739
2024-05-22 00:29:13 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch29_loss0.17385242482026417.pypots
2024-05-22 00:32:28 [INFO]: Epoch 030 - training loss: 0.2191, validation loss: 0.1733
2024-05-22 00:32:28 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch30_loss0.17332850247621537.pypots
2024-05-22 00:35:43 [INFO]: Epoch 031 - training loss: 0.2176, validation loss: 0.1729
2024-05-22 00:35:43 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch31_loss0.17288428495327632.pypots
2024-05-22 00:38:58 [INFO]: Epoch 032 - training loss: 0.2111, validation loss: 0.1717
2024-05-22 00:38:58 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch32_loss0.17167818893988926.pypots
2024-05-22 00:42:13 [INFO]: Epoch 033 - training loss: 0.2109, validation loss: 0.1706
2024-05-22 00:42:13 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch33_loss0.17061266899108887.pypots
2024-05-22 00:45:28 [INFO]: Epoch 034 - training loss: 0.2128, validation loss: 0.1693
2024-05-22 00:45:28 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch34_loss0.16931305900216104.pypots
2024-05-22 00:48:43 [INFO]: Epoch 035 - training loss: 0.2137, validation loss: 0.1726
2024-05-22 00:48:43 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch35_loss0.1725942241648833.pypots
2024-05-22 00:51:58 [INFO]: Epoch 036 - training loss: 0.2098, validation loss: 0.1716
2024-05-22 00:51:58 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch36_loss0.17161433125535647.pypots
2024-05-22 00:55:13 [INFO]: Epoch 037 - training loss: 0.2151, validation loss: 0.1701
2024-05-22 00:55:13 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch37_loss0.17009670635064442.pypots
2024-05-22 00:58:29 [INFO]: Epoch 038 - training loss: 0.2157, validation loss: 0.1719
2024-05-22 00:58:29 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch38_loss0.17186317443847657.pypots
2024-05-22 01:01:44 [INFO]: Epoch 039 - training loss: 0.2158, validation loss: 0.1691
2024-05-22 01:01:44 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch39_loss0.16909244681398075.pypots
2024-05-22 01:04:59 [INFO]: Epoch 040 - training loss: 0.2165, validation loss: 0.1699
2024-05-22 01:04:59 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch40_loss0.16990960165858268.pypots
2024-05-22 01:08:14 [INFO]: Epoch 041 - training loss: 0.2141, validation loss: 0.1728
2024-05-22 01:08:14 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch41_loss0.17276243691643078.pypots
2024-05-22 01:11:30 [INFO]: Epoch 042 - training loss: 0.2117, validation loss: 0.1690
2024-05-22 01:11:30 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch42_loss0.16901835252841313.pypots
2024-05-22 01:14:45 [INFO]: Epoch 043 - training loss: 0.2092, validation loss: 0.1684
2024-05-22 01:14:45 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch43_loss0.1683582437535127.pypots
2024-05-22 01:18:01 [INFO]: Epoch 044 - training loss: 0.2082, validation loss: 0.1668
2024-05-22 01:18:01 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch44_loss0.16676703815658886.pypots
2024-05-22 01:21:17 [INFO]: Epoch 045 - training loss: 0.2066, validation loss: 0.1669
2024-05-22 01:21:17 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch45_loss0.16688280949989956.pypots
2024-05-22 01:24:32 [INFO]: Epoch 046 - training loss: 0.2095, validation loss: 0.1672
2024-05-22 01:24:32 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch46_loss0.16718791921933493.pypots
2024-05-22 01:27:47 [INFO]: Epoch 047 - training loss: 0.2117, validation loss: 0.1674
2024-05-22 01:27:47 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch47_loss0.1674372392396132.pypots
2024-05-22 01:31:02 [INFO]: Epoch 048 - training loss: 0.2117, validation loss: 0.1668
2024-05-22 01:31:02 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch48_loss0.1668366534014543.pypots
2024-05-22 01:34:17 [INFO]: Epoch 049 - training loss: 0.2103, validation loss: 0.1672
2024-05-22 01:34:17 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch49_loss0.1671685961385568.pypots
2024-05-22 01:37:32 [INFO]: Epoch 050 - training loss: 0.2045, validation loss: 0.1684
2024-05-22 01:37:32 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch50_loss0.16840041329463323.pypots
2024-05-22 01:40:48 [INFO]: Epoch 051 - training loss: 0.2086, validation loss: 0.1663
2024-05-22 01:40:48 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch51_loss0.16626841425895691.pypots
2024-05-22 01:44:03 [INFO]: Epoch 052 - training loss: 0.2079, validation loss: 0.1661
2024-05-22 01:44:03 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch52_loss0.16606262748440107.pypots
2024-05-22 01:47:18 [INFO]: Epoch 053 - training loss: 0.2121, validation loss: 0.1660
2024-05-22 01:47:18 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch53_loss0.16604319115479788.pypots
2024-05-22 01:50:33 [INFO]: Epoch 054 - training loss: 0.2017, validation loss: 0.1662
2024-05-22 01:50:33 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch54_loss0.16624394655227662.pypots
2024-05-22 01:53:48 [INFO]: Epoch 055 - training loss: 0.2082, validation loss: 0.1678
2024-05-22 01:53:48 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch55_loss0.16780283624927203.pypots
2024-05-22 01:57:03 [INFO]: Epoch 056 - training loss: 0.2076, validation loss: 0.1668
2024-05-22 01:57:03 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch56_loss0.16679256384571392.pypots
2024-05-22 02:00:19 [INFO]: Epoch 057 - training loss: 0.2129, validation loss: 0.1644
2024-05-22 02:00:19 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch57_loss0.16442282423377036.pypots
2024-05-22 02:03:35 [INFO]: Epoch 058 - training loss: 0.2087, validation loss: 0.1650
2024-05-22 02:03:35 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch58_loss0.164989160746336.pypots
2024-05-22 02:06:51 [INFO]: Epoch 059 - training loss: 0.2060, validation loss: 0.1649
2024-05-22 02:06:51 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch59_loss0.16493379523356755.pypots
2024-05-22 02:10:07 [INFO]: Epoch 060 - training loss: 0.2057, validation loss: 0.1680
2024-05-22 02:10:07 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch60_loss0.16795982296268144.pypots
2024-05-22 02:13:23 [INFO]: Epoch 061 - training loss: 0.2167, validation loss: 0.1650
2024-05-22 02:13:23 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch61_loss0.16498957326014838.pypots
2024-05-22 02:16:39 [INFO]: Epoch 062 - training loss: 0.2057, validation loss: 0.1656
2024-05-22 02:16:39 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch62_loss0.16560519834359486.pypots
2024-05-22 02:19:55 [INFO]: Epoch 063 - training loss: 0.2071, validation loss: 0.1652
2024-05-22 02:19:55 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch63_loss0.1652089255551497.pypots
2024-05-22 02:23:11 [INFO]: Epoch 064 - training loss: 0.2088, validation loss: 0.1654
2024-05-22 02:23:11 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch64_loss0.1653550314406554.pypots
2024-05-22 02:26:27 [INFO]: Epoch 065 - training loss: 0.2162, validation loss: 0.1689
2024-05-22 02:26:27 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch65_loss0.16885025352239608.pypots
2024-05-22 02:29:42 [INFO]: Epoch 066 - training loss: 0.2026, validation loss: 0.1649
2024-05-22 02:29:42 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch66_loss0.16490103006362916.pypots
2024-05-22 02:32:58 [INFO]: Epoch 067 - training loss: 0.2067, validation loss: 0.1659
2024-05-22 02:32:58 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI_epoch67_loss0.16586932068069776.pypots
2024-05-22 02:32:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 02:32:58 [INFO]: Finished training. The best model is from epoch#57.
2024-05-22 02:32:58 [INFO]: Saved the model to saved_results/round_0/CSDI_physionet2012/20240521_T221752/CSDI.pypots
2024-05-22 03:05:37 [INFO]: CSDI on PhysioNet-2012: MAE=0.2128, MSE=0.2315
2024-05-22 05:20:08 [INFO]: Successfully saved to saved_results/round_0/CSDI_physionet2012/imputation.pkl
2024-05-22 05:20:08 [INFO]: Using the given device: cuda:0
2024-05-22 05:20:08 [INFO]: Model files will be saved to saved_results/round_0/GPVAE_physionet2012/20240522_T052008
2024-05-22 05:20:08 [INFO]: Tensorboard file will be saved to saved_results/round_0/GPVAE_physionet2012/20240522_T052008/tensorboard
2024-05-22 05:20:08 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-22 05:20:15 [INFO]: Epoch 001 - training loss: 29972.9935, validation loss: 0.6811
2024-05-22 05:20:21 [INFO]: Epoch 002 - training loss: 23118.5663, validation loss: 0.6522
2024-05-22 05:20:28 [INFO]: Epoch 003 - training loss: 22939.6345, validation loss: 0.6464
2024-05-22 05:20:34 [INFO]: Epoch 004 - training loss: 22882.3788, validation loss: 0.6430
2024-05-22 05:20:41 [INFO]: Epoch 005 - training loss: 22858.5211, validation loss: 0.6407
2024-05-22 05:20:47 [INFO]: Epoch 006 - training loss: 22846.5113, validation loss: 0.6277
2024-05-22 05:20:53 [INFO]: Epoch 007 - training loss: 22839.1795, validation loss: 0.6204
2024-05-22 05:20:59 [INFO]: Epoch 008 - training loss: 22834.2874, validation loss: 0.6125
2024-05-22 05:21:05 [INFO]: Epoch 009 - training loss: 22831.6145, validation loss: 0.6212
2024-05-22 05:21:12 [INFO]: Epoch 010 - training loss: 22830.4915, validation loss: 0.6057
2024-05-22 05:21:18 [INFO]: Epoch 011 - training loss: 22826.8984, validation loss: 0.5961
2024-05-22 05:21:24 [INFO]: Epoch 012 - training loss: 22824.1793, validation loss: 0.5831
2024-05-22 05:21:30 [INFO]: Epoch 013 - training loss: 22820.7357, validation loss: 0.5772
2024-05-22 05:21:36 [INFO]: Epoch 014 - training loss: 22819.2310, validation loss: 0.5645
2024-05-22 05:21:41 [INFO]: Epoch 015 - training loss: 22816.4360, validation loss: 0.5669
2024-05-22 05:21:47 [INFO]: Epoch 016 - training loss: 22814.2516, validation loss: 0.5603
2024-05-22 05:21:53 [INFO]: Epoch 017 - training loss: 22813.6013, validation loss: 0.5534
2024-05-22 05:21:58 [INFO]: Epoch 018 - training loss: 22811.7066, validation loss: 0.5515
2024-05-22 05:22:04 [INFO]: Epoch 019 - training loss: 22810.6124, validation loss: 0.5403
2024-05-22 05:22:10 [INFO]: Epoch 020 - training loss: 22807.8171, validation loss: 0.5267
2024-05-22 05:22:16 [INFO]: Epoch 021 - training loss: 22805.4607, validation loss: 0.5162
2024-05-22 05:22:22 [INFO]: Epoch 022 - training loss: 22803.5644, validation loss: 0.5150
2024-05-22 05:22:29 [INFO]: Epoch 023 - training loss: 22802.7180, validation loss: 0.5037
2024-05-22 05:22:35 [INFO]: Epoch 024 - training loss: 22801.7945, validation loss: 0.5094
2024-05-22 05:22:42 [INFO]: Epoch 025 - training loss: 22800.2454, validation loss: 0.5009
2024-05-22 05:22:48 [INFO]: Epoch 026 - training loss: 22798.3436, validation loss: 0.4898
2024-05-22 05:22:53 [INFO]: Epoch 027 - training loss: 22797.5669, validation loss: 0.4896
2024-05-22 05:22:59 [INFO]: Epoch 028 - training loss: 22795.5345, validation loss: 0.4820
2024-05-22 05:23:05 [INFO]: Epoch 029 - training loss: 22794.7669, validation loss: 0.4737
2024-05-22 05:23:11 [INFO]: Epoch 030 - training loss: 22793.6817, validation loss: 0.4744
2024-05-22 05:23:17 [INFO]: Epoch 031 - training loss: 22793.8975, validation loss: 0.4721
2024-05-22 05:23:24 [INFO]: Epoch 032 - training loss: 22793.1015, validation loss: 0.4784
2024-05-22 05:23:30 [INFO]: Epoch 033 - training loss: 22792.4906, validation loss: 0.4773
2024-05-22 05:23:36 [INFO]: Epoch 034 - training loss: 22791.9309, validation loss: 0.4701
2024-05-22 05:23:42 [INFO]: Epoch 035 - training loss: 22791.8984, validation loss: 0.4673
2024-05-22 05:23:49 [INFO]: Epoch 036 - training loss: 22791.2750, validation loss: 0.4684
2024-05-22 05:23:54 [INFO]: Epoch 037 - training loss: 22790.8808, validation loss: 0.4760
2024-05-22 05:24:00 [INFO]: Epoch 038 - training loss: 22790.6238, validation loss: 0.4654
2024-05-22 05:24:05 [INFO]: Epoch 039 - training loss: 22790.0455, validation loss: 0.4831
2024-05-22 05:24:10 [INFO]: Epoch 040 - training loss: 22790.9241, validation loss: 0.4611
2024-05-22 05:24:16 [INFO]: Epoch 041 - training loss: 22789.2707, validation loss: 0.4583
2024-05-22 05:24:22 [INFO]: Epoch 042 - training loss: 22788.6167, validation loss: 0.4571
2024-05-22 05:24:29 [INFO]: Epoch 043 - training loss: 22787.9910, validation loss: 0.4584
2024-05-22 05:24:35 [INFO]: Epoch 044 - training loss: 22787.6846, validation loss: 0.4594
2024-05-22 05:24:41 [INFO]: Epoch 045 - training loss: 22788.3449, validation loss: 0.4518
2024-05-22 05:24:48 [INFO]: Epoch 046 - training loss: 22787.0098, validation loss: 0.4510
2024-05-22 05:24:54 [INFO]: Epoch 047 - training loss: 22786.7744, validation loss: 0.4519
2024-05-22 05:25:00 [INFO]: Epoch 048 - training loss: 22786.1626, validation loss: 0.4517
2024-05-22 05:25:07 [INFO]: Epoch 049 - training loss: 22786.3460, validation loss: 0.4493
2024-05-22 05:25:13 [INFO]: Epoch 050 - training loss: 22786.0551, validation loss: 0.4549
2024-05-22 05:25:20 [INFO]: Epoch 051 - training loss: 22785.5063, validation loss: 0.4533
2024-05-22 05:25:26 [INFO]: Epoch 052 - training loss: 22785.1218, validation loss: 0.4533
2024-05-22 05:25:32 [INFO]: Epoch 053 - training loss: 22784.7974, validation loss: 0.4527
2024-05-22 05:25:39 [INFO]: Epoch 054 - training loss: 22784.8002, validation loss: 0.4523
2024-05-22 05:25:45 [INFO]: Epoch 055 - training loss: 22784.5886, validation loss: 0.4546
2024-05-22 05:25:51 [INFO]: Epoch 056 - training loss: 22785.6245, validation loss: 0.4572
2024-05-22 05:25:57 [INFO]: Epoch 057 - training loss: 22784.5610, validation loss: 0.4553
2024-05-22 05:26:03 [INFO]: Epoch 058 - training loss: 22784.7248, validation loss: 0.4530
2024-05-22 05:26:10 [INFO]: Epoch 059 - training loss: 22783.8060, validation loss: 0.4452
2024-05-22 05:26:16 [INFO]: Epoch 060 - training loss: 22783.6623, validation loss: 0.4537
2024-05-22 05:26:21 [INFO]: Epoch 061 - training loss: 22783.2707, validation loss: 0.4589
2024-05-22 05:26:27 [INFO]: Epoch 062 - training loss: 22783.6987, validation loss: 0.4516
2024-05-22 05:26:33 [INFO]: Epoch 063 - training loss: 22782.9178, validation loss: 0.4500
2024-05-22 05:26:38 [INFO]: Epoch 064 - training loss: 22782.7803, validation loss: 0.4522
2024-05-22 05:26:44 [INFO]: Epoch 065 - training loss: 22782.3554, validation loss: 0.4520
2024-05-22 05:26:50 [INFO]: Epoch 066 - training loss: 22782.3201, validation loss: 0.4501
2024-05-22 05:26:56 [INFO]: Epoch 067 - training loss: 22781.7798, validation loss: 0.4515
2024-05-22 05:27:02 [INFO]: Epoch 068 - training loss: 22782.2609, validation loss: 0.4497
2024-05-22 05:27:08 [INFO]: Epoch 069 - training loss: 22782.0351, validation loss: 0.4485
2024-05-22 05:27:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 05:27:08 [INFO]: Finished training. The best model is from epoch#59.
2024-05-22 05:27:08 [INFO]: Saved the model to saved_results/round_0/GPVAE_physionet2012/20240522_T052008/GPVAE.pypots
2024-05-22 05:27:09 [INFO]: GP-VAE on PhysioNet-2012: MAE=0.4054, MSE=0.4423
2024-05-22 05:27:14 [INFO]: Successfully saved to saved_results/round_0/GPVAE_physionet2012/imputation.pkl
2024-05-22 05:27:14 [INFO]: Using the given device: cuda:0
2024-05-22 05:27:14 [INFO]: Model files will be saved to saved_results/round_0/USGAN_physionet2012/20240522_T052714
2024-05-22 05:27:14 [INFO]: Tensorboard file will be saved to saved_results/round_0/USGAN_physionet2012/20240522_T052714/tensorboard
2024-05-22 05:27:14 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-22 05:34:09 [INFO]: Epoch 001 - generator training loss: 0.4824, discriminator training loss: 0.2835, validation loss: 0.4732
2024-05-22 05:45:00 [INFO]: Epoch 002 - generator training loss: 0.4362, discriminator training loss: 0.1306, validation loss: 0.4205
2024-05-22 06:03:56 [INFO]: Epoch 003 - generator training loss: 0.4047, discriminator training loss: 0.0823, validation loss: 0.3830
2024-05-22 06:22:58 [INFO]: Epoch 004 - generator training loss: 0.3866, discriminator training loss: 0.0620, validation loss: 0.3664
2024-05-22 06:27:59 [INFO]: Epoch 005 - generator training loss: 0.3705, discriminator training loss: 0.0500, validation loss: 0.3507
2024-05-22 06:33:07 [INFO]: Epoch 006 - generator training loss: 0.3598, discriminator training loss: 0.0426, validation loss: 0.3408
2024-05-22 06:38:15 [INFO]: Epoch 007 - generator training loss: 0.3471, discriminator training loss: 0.0376, validation loss: 0.3282
2024-05-22 06:43:26 [INFO]: Epoch 008 - generator training loss: 0.3356, discriminator training loss: 0.0343, validation loss: 0.3124
2024-05-22 06:48:35 [INFO]: Epoch 009 - generator training loss: 0.3236, discriminator training loss: 0.0318, validation loss: 0.3056
2024-05-22 06:53:38 [INFO]: Epoch 010 - generator training loss: 0.3152, discriminator training loss: 0.0300, validation loss: 0.2978
2024-05-22 06:58:41 [INFO]: Epoch 011 - generator training loss: 0.3071, discriminator training loss: 0.0287, validation loss: 0.2933
2024-05-22 07:03:46 [INFO]: Epoch 012 - generator training loss: 0.3015, discriminator training loss: 0.0276, validation loss: 0.2906
2024-05-22 07:08:54 [INFO]: Epoch 013 - generator training loss: 0.2954, discriminator training loss: 0.0266, validation loss: 0.2864
2024-05-22 07:14:04 [INFO]: Epoch 014 - generator training loss: 0.2901, discriminator training loss: 0.0258, validation loss: 0.2854
2024-05-22 07:19:13 [INFO]: Epoch 015 - generator training loss: 0.2841, discriminator training loss: 0.0251, validation loss: 0.2852
2024-05-22 07:24:25 [INFO]: Epoch 016 - generator training loss: 0.2817, discriminator training loss: 0.0245, validation loss: 0.2794
2024-05-22 07:29:35 [INFO]: Epoch 017 - generator training loss: 0.2784, discriminator training loss: 0.0240, validation loss: 0.2824
2024-05-22 07:38:45 [INFO]: Epoch 018 - generator training loss: 0.2763, discriminator training loss: 0.0235, validation loss: 0.2763
2024-05-22 07:43:51 [INFO]: Epoch 019 - generator training loss: 0.2708, discriminator training loss: 0.0230, validation loss: 0.2742
2024-05-22 07:48:58 [INFO]: Epoch 020 - generator training loss: 0.2692, discriminator training loss: 0.0226, validation loss: 0.2750
2024-05-22 07:54:06 [INFO]: Epoch 021 - generator training loss: 0.2671, discriminator training loss: 0.0224, validation loss: 0.2754
2024-05-22 07:59:12 [INFO]: Epoch 022 - generator training loss: 0.2647, discriminator training loss: 0.0220, validation loss: 0.2746
2024-05-22 08:04:26 [INFO]: Epoch 023 - generator training loss: 0.2646, discriminator training loss: 0.0219, validation loss: 0.2753
2024-05-22 08:11:31 [INFO]: Epoch 024 - generator training loss: 0.2605, discriminator training loss: 0.0218, validation loss: 0.2741
2024-05-22 08:24:21 [INFO]: Epoch 025 - generator training loss: 0.2600, discriminator training loss: 0.0215, validation loss: 0.2737
2024-05-22 08:43:18 [INFO]: Epoch 026 - generator training loss: 0.2558, discriminator training loss: 0.0215, validation loss: 0.2739
2024-05-22 09:02:29 [INFO]: Epoch 027 - generator training loss: 0.2553, discriminator training loss: 0.0213, validation loss: 0.2717
2024-05-22 09:08:44 [INFO]: Epoch 028 - generator training loss: 0.2539, discriminator training loss: 0.0211, validation loss: 0.2794
2024-05-22 09:13:52 [INFO]: Epoch 029 - generator training loss: 0.2517, discriminator training loss: 0.0209, validation loss: 0.2734
2024-05-22 09:19:00 [INFO]: Epoch 030 - generator training loss: 0.2472, discriminator training loss: 0.0206, validation loss: 0.2752
2024-05-22 09:24:08 [INFO]: Epoch 031 - generator training loss: 0.2435, discriminator training loss: 0.0205, validation loss: 0.2788
2024-05-22 09:29:16 [INFO]: Epoch 032 - generator training loss: 0.2515, discriminator training loss: 0.0205, validation loss: 0.2823
2024-05-22 09:37:33 [INFO]: Epoch 033 - generator training loss: 0.2506, discriminator training loss: 0.0202, validation loss: 0.2758
2024-05-22 09:42:41 [INFO]: Epoch 034 - generator training loss: 0.2433, discriminator training loss: 0.0202, validation loss: 0.2762
2024-05-22 09:47:50 [INFO]: Epoch 035 - generator training loss: 0.2382, discriminator training loss: 0.0202, validation loss: 0.2717
2024-05-22 09:52:55 [INFO]: Epoch 036 - generator training loss: 0.2365, discriminator training loss: 0.0200, validation loss: 0.2828
2024-05-22 09:58:06 [INFO]: Epoch 037 - generator training loss: 0.2341, discriminator training loss: 0.0198, validation loss: 0.2751
2024-05-22 09:58:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 09:58:06 [INFO]: Finished training. The best model is from epoch#27.
2024-05-22 09:58:07 [INFO]: Saved the model to saved_results/round_0/USGAN_physionet2012/20240522_T052714/USGAN.pypots
2024-05-22 09:58:48 [INFO]: US-GAN on PhysioNet-2012: MAE=0.2755, MSE=0.2762
2024-05-22 10:01:30 [INFO]: Successfully saved to saved_results/round_0/USGAN_physionet2012/imputation.pkl
2024-05-22 10:01:30 [INFO]: Using the given device: cuda:0
2024-05-22 10:01:30 [INFO]: Model files will be saved to saved_results/round_0/BRITS_physionet2012/20240522_T100130
2024-05-22 10:01:30 [INFO]: Tensorboard file will be saved to saved_results/round_0/BRITS_physionet2012/20240522_T100130/tensorboard
2024-05-22 10:01:31 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-22 10:04:56 [INFO]: Epoch 001 - training loss: 0.9461, validation loss: 0.4311
2024-05-22 10:08:05 [INFO]: Epoch 002 - training loss: 0.7695, validation loss: 0.3773
2024-05-22 10:11:14 [INFO]: Epoch 003 - training loss: 0.7105, validation loss: 0.3540
2024-05-22 10:14:20 [INFO]: Epoch 004 - training loss: 0.6763, validation loss: 0.3425
2024-05-22 10:17:27 [INFO]: Epoch 005 - training loss: 0.6545, validation loss: 0.3372
2024-05-22 10:20:35 [INFO]: Epoch 006 - training loss: 0.6404, validation loss: 0.3320
2024-05-22 10:23:41 [INFO]: Epoch 007 - training loss: 0.6294, validation loss: 0.3293
2024-05-22 10:26:47 [INFO]: Epoch 008 - training loss: 0.6211, validation loss: 0.3251
2024-05-22 10:29:54 [INFO]: Epoch 009 - training loss: 0.6138, validation loss: 0.3223
2024-05-22 10:33:02 [INFO]: Epoch 010 - training loss: 0.6068, validation loss: 0.3223
2024-05-22 10:36:06 [INFO]: Epoch 011 - training loss: 0.6004, validation loss: 0.3202
2024-05-22 10:39:13 [INFO]: Epoch 012 - training loss: 0.5941, validation loss: 0.3202
2024-05-22 10:42:33 [INFO]: Epoch 013 - training loss: 0.5885, validation loss: 0.3220
2024-05-22 10:47:21 [INFO]: Epoch 014 - training loss: 0.5846, validation loss: 0.3283
2024-05-22 10:51:59 [INFO]: Epoch 015 - training loss: 0.5820, validation loss: 0.3292
2024-05-22 11:02:45 [INFO]: Epoch 016 - training loss: 0.5762, validation loss: 0.3303
2024-05-22 11:13:37 [INFO]: Epoch 017 - training loss: 0.5726, validation loss: 0.3297
2024-05-22 11:24:43 [INFO]: Epoch 018 - training loss: 0.5686, validation loss: 0.3347
2024-05-22 11:28:54 [INFO]: Epoch 019 - training loss: 0.5659, validation loss: 0.3357
2024-05-22 11:31:59 [INFO]: Epoch 020 - training loss: 0.5628, validation loss: 0.3351
2024-05-22 11:35:07 [INFO]: Epoch 021 - training loss: 0.5604, validation loss: 0.3369
2024-05-22 11:35:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 11:35:07 [INFO]: Finished training. The best model is from epoch#11.
2024-05-22 11:35:07 [INFO]: Saved the model to saved_results/round_0/BRITS_physionet2012/20240522_T100130/BRITS.pypots
2024-05-22 11:35:47 [INFO]: BRITS on PhysioNet-2012: MAE=0.2465, MSE=0.3214
2024-05-22 11:38:30 [INFO]: Successfully saved to saved_results/round_0/BRITS_physionet2012/imputation.pkl
2024-05-22 11:38:30 [INFO]: Using the given device: cuda:0
2024-05-22 11:38:30 [INFO]: Model files will be saved to saved_results/round_0/MRNN_physionet2012/20240522_T113830
2024-05-22 11:38:30 [INFO]: Tensorboard file will be saved to saved_results/round_0/MRNN_physionet2012/20240522_T113830/tensorboard
2024-05-22 11:38:30 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-22 11:39:07 [INFO]: Epoch 001 - training loss: 0.8175, validation loss: 0.9179
2024-05-22 11:39:07 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN_epoch1_loss0.9179312855005264.pypots
2024-05-22 11:39:28 [INFO]: Epoch 002 - training loss: 0.5536, validation loss: 0.8905
2024-05-22 11:39:28 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN_epoch2_loss0.890525859594345.pypots
2024-05-22 11:39:49 [INFO]: Epoch 003 - training loss: 0.5144, validation loss: 0.8827
2024-05-22 11:39:49 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN_epoch3_loss0.8826790660619735.pypots
2024-05-22 11:40:14 [INFO]: Epoch 004 - training loss: 0.4931, validation loss: 0.8806
2024-05-22 11:40:14 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN_epoch4_loss0.8806014607350031.pypots
2024-05-22 11:40:41 [INFO]: Epoch 005 - training loss: 0.4741, validation loss: 0.8841
2024-05-22 11:40:41 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN_epoch5_loss0.8840795358022054.pypots
2024-05-22 11:41:06 [INFO]: Epoch 006 - training loss: 0.4716, validation loss: 0.8892
2024-05-22 11:41:06 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN_epoch6_loss0.8892357448736826.pypots
2024-05-22 11:41:32 [INFO]: Epoch 007 - training loss: 0.4633, validation loss: 0.8902
2024-05-22 11:41:32 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN_epoch7_loss0.8901832262674968.pypots
2024-05-22 11:41:51 [INFO]: Epoch 008 - training loss: 0.4573, validation loss: 0.8926
2024-05-22 11:41:51 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN_epoch8_loss0.8926081200440724.pypots
2024-05-22 11:42:08 [INFO]: Epoch 009 - training loss: 0.4517, validation loss: 0.8945
2024-05-22 11:42:08 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN_epoch9_loss0.8945367852846782.pypots
2024-05-22 11:42:29 [INFO]: Epoch 010 - training loss: 0.4515, validation loss: 0.8962
2024-05-22 11:42:29 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN_epoch10_loss0.8961647361516952.pypots
2024-05-22 11:42:46 [INFO]: Epoch 011 - training loss: 0.4420, validation loss: 0.8994
2024-05-22 11:42:46 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN_epoch11_loss0.8994088103373845.pypots
2024-05-22 11:43:03 [INFO]: Epoch 012 - training loss: 0.4416, validation loss: 0.9051
2024-05-22 11:43:03 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN_epoch12_loss0.9050598760445913.pypots
2024-05-22 11:43:19 [INFO]: Epoch 013 - training loss: 0.4362, validation loss: 0.9058
2024-05-22 11:43:19 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN_epoch13_loss0.9058262318372726.pypots
2024-05-22 11:43:38 [INFO]: Epoch 014 - training loss: 0.4364, validation loss: 0.9083
2024-05-22 11:43:38 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN_epoch14_loss0.9082987308502197.pypots
2024-05-22 11:43:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 11:43:38 [INFO]: Finished training. The best model is from epoch#4.
2024-05-22 11:43:38 [INFO]: Saved the model to saved_results/round_0/MRNN_physionet2012/20240522_T113830/MRNN.pypots
2024-05-22 11:43:44 [INFO]: MRNN on PhysioNet-2012: MAE=0.6831, MSE=0.8913
2024-05-22 11:44:10 [INFO]: Successfully saved to saved_results/round_0/MRNN_physionet2012/imputation.pkl
2024-05-22 11:44:10 [INFO]: Using the given device: cpu
2024-05-22 11:44:10 [INFO]: LOCF on PhysioNet-2012: MAE=0.4110, MSE=0.5688
2024-05-22 11:44:11 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_physionet2012".
2024-05-22 11:44:11 [INFO]: Successfully saved to saved_results/round_0/LOCF_physionet2012/imputation.pkl
2024-05-22 11:44:11 [INFO]: Median on PhysioNet-2012: MAE=0.6855, MSE=0.9913
2024-05-22 11:44:12 [INFO]: Successfully created the given path "saved_results/round_0/Median_physionet2012".
2024-05-22 11:44:12 [INFO]: Successfully saved to saved_results/round_0/Median_physionet2012/imputation.pkl
2024-05-22 11:44:12 [INFO]: Mean on PhysioNet-2012: MAE=0.7017, MSE=0.9536
2024-05-22 11:44:13 [INFO]: Successfully created the given path "saved_results/round_0/Mean_physionet2012".
2024-05-22 11:44:13 [INFO]: Successfully saved to saved_results/round_0/Mean_physionet2012/imputation.pkl
2024-05-22 11:44:13 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-22 11:44:13 [INFO]: Using the given device: cuda:0
2024-05-22 11:44:13 [INFO]: Model files will be saved to saved_results/round_1/SAITS_physionet2012/20240522_T114413
2024-05-22 11:44:13 [INFO]: Tensorboard file will be saved to saved_results/round_1/SAITS_physionet2012/20240522_T114413/tensorboard
2024-05-22 11:44:13 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-22 11:44:26 [INFO]: Epoch 001 - training loss: 0.8621, validation loss: 0.3894
2024-05-22 11:44:36 [INFO]: Epoch 002 - training loss: 0.5009, validation loss: 0.3468
2024-05-22 11:44:49 [INFO]: Epoch 003 - training loss: 0.4146, validation loss: 0.3139
2024-05-22 11:45:03 [INFO]: Epoch 004 - training loss: 0.3662, validation loss: 0.2932
2024-05-22 11:45:17 [INFO]: Epoch 005 - training loss: 0.3398, validation loss: 0.2800
2024-05-22 11:45:29 [INFO]: Epoch 006 - training loss: 0.3246, validation loss: 0.2655
2024-05-22 11:45:42 [INFO]: Epoch 007 - training loss: 0.3096, validation loss: 0.2629
2024-05-22 11:45:55 [INFO]: Epoch 008 - training loss: 0.2987, validation loss: 0.2618
2024-05-22 11:46:08 [INFO]: Epoch 009 - training loss: 0.2926, validation loss: 0.2553
2024-05-22 11:46:23 [INFO]: Epoch 010 - training loss: 0.2844, validation loss: 0.2554
2024-05-22 11:46:37 [INFO]: Epoch 011 - training loss: 0.2804, validation loss: 0.2507
2024-05-22 11:46:52 [INFO]: Epoch 012 - training loss: 0.2784, validation loss: 0.2483
2024-05-22 11:47:06 [INFO]: Epoch 013 - training loss: 0.2740, validation loss: 0.2424
2024-05-22 11:47:19 [INFO]: Epoch 014 - training loss: 0.2704, validation loss: 0.2426
2024-05-22 11:47:30 [INFO]: Epoch 015 - training loss: 0.2660, validation loss: 0.2415
2024-05-22 11:47:43 [INFO]: Epoch 016 - training loss: 0.2636, validation loss: 0.2441
2024-05-22 11:47:56 [INFO]: Epoch 017 - training loss: 0.2632, validation loss: 0.2450
2024-05-22 11:48:09 [INFO]: Epoch 018 - training loss: 0.2606, validation loss: 0.2428
2024-05-22 11:48:25 [INFO]: Epoch 019 - training loss: 0.2598, validation loss: 0.2479
2024-05-22 11:48:41 [INFO]: Epoch 020 - training loss: 0.2566, validation loss: 0.2339
2024-05-22 11:48:56 [INFO]: Epoch 021 - training loss: 0.2549, validation loss: 0.2341
2024-05-22 11:49:11 [INFO]: Epoch 022 - training loss: 0.2544, validation loss: 0.2351
2024-05-22 11:49:26 [INFO]: Epoch 023 - training loss: 0.2526, validation loss: 0.2405
2024-05-22 11:49:40 [INFO]: Epoch 024 - training loss: 0.2505, validation loss: 0.2303
2024-05-22 11:49:53 [INFO]: Epoch 025 - training loss: 0.2484, validation loss: 0.2333
2024-05-22 11:50:09 [INFO]: Epoch 026 - training loss: 0.2501, validation loss: 0.2357
2024-05-22 11:50:27 [INFO]: Epoch 027 - training loss: 0.2522, validation loss: 0.2422
2024-05-22 11:50:45 [INFO]: Epoch 028 - training loss: 0.2479, validation loss: 0.2315
2024-05-22 11:51:04 [INFO]: Epoch 029 - training loss: 0.2480, validation loss: 0.2389
2024-05-22 11:51:22 [INFO]: Epoch 030 - training loss: 0.2465, validation loss: 0.2359
2024-05-22 11:51:40 [INFO]: Epoch 031 - training loss: 0.2449, validation loss: 0.2309
2024-05-22 11:51:58 [INFO]: Epoch 032 - training loss: 0.2443, validation loss: 0.2380
2024-05-22 11:52:16 [INFO]: Epoch 033 - training loss: 0.2431, validation loss: 0.2279
2024-05-22 11:52:34 [INFO]: Epoch 034 - training loss: 0.2419, validation loss: 0.2326
2024-05-22 11:52:53 [INFO]: Epoch 035 - training loss: 0.2402, validation loss: 0.2335
2024-05-22 11:53:12 [INFO]: Epoch 036 - training loss: 0.2409, validation loss: 0.2299
2024-05-22 11:53:25 [INFO]: Epoch 037 - training loss: 0.2412, validation loss: 0.2279
2024-05-22 11:53:38 [INFO]: Epoch 038 - training loss: 0.2393, validation loss: 0.2292
2024-05-22 11:53:51 [INFO]: Epoch 039 - training loss: 0.2395, validation loss: 0.2190
2024-05-22 11:54:04 [INFO]: Epoch 040 - training loss: 0.2386, validation loss: 0.2303
2024-05-22 11:54:18 [INFO]: Epoch 041 - training loss: 0.2403, validation loss: 0.2353
2024-05-22 11:54:31 [INFO]: Epoch 042 - training loss: 0.2387, validation loss: 0.2292
2024-05-22 11:54:44 [INFO]: Epoch 043 - training loss: 0.2381, validation loss: 0.2273
2024-05-22 11:54:58 [INFO]: Epoch 044 - training loss: 0.2359, validation loss: 0.2321
2024-05-22 11:55:11 [INFO]: Epoch 045 - training loss: 0.2354, validation loss: 0.2306
2024-05-22 11:55:24 [INFO]: Epoch 046 - training loss: 0.2355, validation loss: 0.2335
2024-05-22 11:55:37 [INFO]: Epoch 047 - training loss: 0.2355, validation loss: 0.2211
2024-05-22 11:55:50 [INFO]: Epoch 048 - training loss: 0.2326, validation loss: 0.2265
2024-05-22 11:56:02 [INFO]: Epoch 049 - training loss: 0.2347, validation loss: 0.2277
2024-05-22 11:56:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 11:56:02 [INFO]: Finished training. The best model is from epoch#39.
2024-05-22 11:56:02 [INFO]: Saved the model to saved_results/round_1/SAITS_physionet2012/20240522_T114413/SAITS.pypots
2024-05-22 11:56:03 [INFO]: SAITS on PhysioNet-2012: MAE=0.2014, MSE=0.2129
2024-05-22 11:56:06 [INFO]: Successfully saved to saved_results/round_1/SAITS_physionet2012/imputation.pkl
2024-05-22 11:56:06 [INFO]: Using the given device: cuda:0
2024-05-22 11:56:06 [INFO]: Model files will be saved to saved_results/round_1/Transformer_physionet2012/20240522_T115606
2024-05-22 11:56:06 [INFO]: Tensorboard file will be saved to saved_results/round_1/Transformer_physionet2012/20240522_T115606/tensorboard
2024-05-22 11:56:06 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-22 11:56:13 [INFO]: Epoch 001 - training loss: 0.8379, validation loss: 0.4526
2024-05-22 11:56:20 [INFO]: Epoch 002 - training loss: 0.5516, validation loss: 0.4271
2024-05-22 11:56:28 [INFO]: Epoch 003 - training loss: 0.4787, validation loss: 0.3828
2024-05-22 11:56:35 [INFO]: Epoch 004 - training loss: 0.4429, validation loss: 0.3574
2024-05-22 11:56:43 [INFO]: Epoch 005 - training loss: 0.4104, validation loss: 0.3431
2024-05-22 11:56:51 [INFO]: Epoch 006 - training loss: 0.3889, validation loss: 0.3264
2024-05-22 11:56:58 [INFO]: Epoch 007 - training loss: 0.3669, validation loss: 0.3168
2024-05-22 11:57:06 [INFO]: Epoch 008 - training loss: 0.3537, validation loss: 0.3091
2024-05-22 11:57:13 [INFO]: Epoch 009 - training loss: 0.3459, validation loss: 0.3021
2024-05-22 11:57:20 [INFO]: Epoch 010 - training loss: 0.3362, validation loss: 0.2951
2024-05-22 11:57:28 [INFO]: Epoch 011 - training loss: 0.3284, validation loss: 0.2966
2024-05-22 11:57:36 [INFO]: Epoch 012 - training loss: 0.3238, validation loss: 0.2861
2024-05-22 11:57:44 [INFO]: Epoch 013 - training loss: 0.3184, validation loss: 0.2801
2024-05-22 11:57:51 [INFO]: Epoch 014 - training loss: 0.3129, validation loss: 0.2787
2024-05-22 11:57:58 [INFO]: Epoch 015 - training loss: 0.3094, validation loss: 0.2782
2024-05-22 11:58:05 [INFO]: Epoch 016 - training loss: 0.3048, validation loss: 0.2717
2024-05-22 11:58:12 [INFO]: Epoch 017 - training loss: 0.3024, validation loss: 0.2716
2024-05-22 11:58:19 [INFO]: Epoch 018 - training loss: 0.2976, validation loss: 0.2722
2024-05-22 11:58:25 [INFO]: Epoch 019 - training loss: 0.2944, validation loss: 0.2680
2024-05-22 11:58:31 [INFO]: Epoch 020 - training loss: 0.2931, validation loss: 0.2643
2024-05-22 11:58:37 [INFO]: Epoch 021 - training loss: 0.2913, validation loss: 0.2647
2024-05-22 11:58:42 [INFO]: Epoch 022 - training loss: 0.2894, validation loss: 0.2612
2024-05-22 11:58:49 [INFO]: Epoch 023 - training loss: 0.2871, validation loss: 0.2518
2024-05-22 11:58:57 [INFO]: Epoch 024 - training loss: 0.2834, validation loss: 0.2528
2024-05-22 11:59:04 [INFO]: Epoch 025 - training loss: 0.2831, validation loss: 0.2527
2024-05-22 11:59:11 [INFO]: Epoch 026 - training loss: 0.2824, validation loss: 0.2555
2024-05-22 11:59:18 [INFO]: Epoch 027 - training loss: 0.2789, validation loss: 0.2483
2024-05-22 11:59:25 [INFO]: Epoch 028 - training loss: 0.2784, validation loss: 0.2510
2024-05-22 11:59:33 [INFO]: Epoch 029 - training loss: 0.2771, validation loss: 0.2435
2024-05-22 11:59:41 [INFO]: Epoch 030 - training loss: 0.2761, validation loss: 0.2495
2024-05-22 11:59:48 [INFO]: Epoch 031 - training loss: 0.2732, validation loss: 0.2503
2024-05-22 11:59:56 [INFO]: Epoch 032 - training loss: 0.2718, validation loss: 0.2469
2024-05-22 12:00:04 [INFO]: Epoch 033 - training loss: 0.2712, validation loss: 0.2457
2024-05-22 12:00:12 [INFO]: Epoch 034 - training loss: 0.2694, validation loss: 0.2442
2024-05-22 12:00:20 [INFO]: Epoch 035 - training loss: 0.2702, validation loss: 0.2420
2024-05-22 12:00:28 [INFO]: Epoch 036 - training loss: 0.2675, validation loss: 0.2403
2024-05-22 12:00:36 [INFO]: Epoch 037 - training loss: 0.2672, validation loss: 0.2375
2024-05-22 12:00:44 [INFO]: Epoch 038 - training loss: 0.2640, validation loss: 0.2431
2024-05-22 12:00:52 [INFO]: Epoch 039 - training loss: 0.2649, validation loss: 0.2382
2024-05-22 12:01:00 [INFO]: Epoch 040 - training loss: 0.2643, validation loss: 0.2375
2024-05-22 12:01:08 [INFO]: Epoch 041 - training loss: 0.2624, validation loss: 0.2367
2024-05-22 12:01:15 [INFO]: Epoch 042 - training loss: 0.2621, validation loss: 0.2425
2024-05-22 12:01:23 [INFO]: Epoch 043 - training loss: 0.2595, validation loss: 0.2352
2024-05-22 12:01:30 [INFO]: Epoch 044 - training loss: 0.2599, validation loss: 0.2405
2024-05-22 12:01:38 [INFO]: Epoch 045 - training loss: 0.2586, validation loss: 0.2375
2024-05-22 12:01:46 [INFO]: Epoch 046 - training loss: 0.2571, validation loss: 0.2378
2024-05-22 12:01:54 [INFO]: Epoch 047 - training loss: 0.2575, validation loss: 0.2365
2024-05-22 12:02:01 [INFO]: Epoch 048 - training loss: 0.2572, validation loss: 0.2354
2024-05-22 12:02:09 [INFO]: Epoch 049 - training loss: 0.2561, validation loss: 0.2373
2024-05-22 12:02:16 [INFO]: Epoch 050 - training loss: 0.2563, validation loss: 0.2371
2024-05-22 12:02:23 [INFO]: Epoch 051 - training loss: 0.2556, validation loss: 0.2383
2024-05-22 12:02:29 [INFO]: Epoch 052 - training loss: 0.2548, validation loss: 0.2384
2024-05-22 12:02:35 [INFO]: Epoch 053 - training loss: 0.2524, validation loss: 0.2319
2024-05-22 12:02:42 [INFO]: Epoch 054 - training loss: 0.2535, validation loss: 0.2345
2024-05-22 12:02:49 [INFO]: Epoch 055 - training loss: 0.2528, validation loss: 0.2336
2024-05-22 12:02:57 [INFO]: Epoch 056 - training loss: 0.2528, validation loss: 0.2339
2024-05-22 12:03:05 [INFO]: Epoch 057 - training loss: 0.2518, validation loss: 0.2309
2024-05-22 12:03:13 [INFO]: Epoch 058 - training loss: 0.2504, validation loss: 0.2328
2024-05-22 12:03:20 [INFO]: Epoch 059 - training loss: 0.2503, validation loss: 0.2359
2024-05-22 12:03:28 [INFO]: Epoch 060 - training loss: 0.2502, validation loss: 0.2394
2024-05-22 12:03:36 [INFO]: Epoch 061 - training loss: 0.2504, validation loss: 0.2310
2024-05-22 12:03:43 [INFO]: Epoch 062 - training loss: 0.2486, validation loss: 0.2332
2024-05-22 12:03:50 [INFO]: Epoch 063 - training loss: 0.2505, validation loss: 0.2399
2024-05-22 12:03:58 [INFO]: Epoch 064 - training loss: 0.2487, validation loss: 0.2341
2024-05-22 12:04:05 [INFO]: Epoch 065 - training loss: 0.2481, validation loss: 0.2289
2024-05-22 12:04:12 [INFO]: Epoch 066 - training loss: 0.2483, validation loss: 0.2331
2024-05-22 12:04:20 [INFO]: Epoch 067 - training loss: 0.2464, validation loss: 0.2378
2024-05-22 12:04:27 [INFO]: Epoch 068 - training loss: 0.2466, validation loss: 0.2377
2024-05-22 12:04:36 [INFO]: Epoch 069 - training loss: 0.2473, validation loss: 0.2422
2024-05-22 12:04:43 [INFO]: Epoch 070 - training loss: 0.2464, validation loss: 0.2304
2024-05-22 12:04:50 [INFO]: Epoch 071 - training loss: 0.2449, validation loss: 0.2334
2024-05-22 12:04:58 [INFO]: Epoch 072 - training loss: 0.2453, validation loss: 0.2281
2024-05-22 12:05:06 [INFO]: Epoch 073 - training loss: 0.2459, validation loss: 0.2286
2024-05-22 12:05:13 [INFO]: Epoch 074 - training loss: 0.2457, validation loss: 0.2318
2024-05-22 12:05:19 [INFO]: Epoch 075 - training loss: 0.2444, validation loss: 0.2272
2024-05-22 12:05:24 [INFO]: Epoch 076 - training loss: 0.2436, validation loss: 0.2328
2024-05-22 12:05:30 [INFO]: Epoch 077 - training loss: 0.2443, validation loss: 0.2288
2024-05-22 12:05:38 [INFO]: Epoch 078 - training loss: 0.2428, validation loss: 0.2288
2024-05-22 12:05:45 [INFO]: Epoch 079 - training loss: 0.2422, validation loss: 0.2298
2024-05-22 12:05:53 [INFO]: Epoch 080 - training loss: 0.2429, validation loss: 0.2313
2024-05-22 12:06:01 [INFO]: Epoch 081 - training loss: 0.2423, validation loss: 0.2280
2024-05-22 12:06:08 [INFO]: Epoch 082 - training loss: 0.2430, validation loss: 0.2285
2024-05-22 12:06:16 [INFO]: Epoch 083 - training loss: 0.2421, validation loss: 0.2263
2024-05-22 12:06:24 [INFO]: Epoch 084 - training loss: 0.2414, validation loss: 0.2283
2024-05-22 12:06:32 [INFO]: Epoch 085 - training loss: 0.2410, validation loss: 0.2315
2024-05-22 12:06:39 [INFO]: Epoch 086 - training loss: 0.2416, validation loss: 0.2267
2024-05-22 12:06:46 [INFO]: Epoch 087 - training loss: 0.2397, validation loss: 0.2232
2024-05-22 12:06:54 [INFO]: Epoch 088 - training loss: 0.2412, validation loss: 0.2345
2024-05-22 12:07:01 [INFO]: Epoch 089 - training loss: 0.2412, validation loss: 0.2291
2024-05-22 12:07:08 [INFO]: Epoch 090 - training loss: 0.2398, validation loss: 0.2236
2024-05-22 12:07:16 [INFO]: Epoch 091 - training loss: 0.2389, validation loss: 0.2245
2024-05-22 12:07:24 [INFO]: Epoch 092 - training loss: 0.2395, validation loss: 0.2286
2024-05-22 12:07:31 [INFO]: Epoch 093 - training loss: 0.2397, validation loss: 0.2309
2024-05-22 12:07:40 [INFO]: Epoch 094 - training loss: 0.2399, validation loss: 0.2300
2024-05-22 12:07:48 [INFO]: Epoch 095 - training loss: 0.2387, validation loss: 0.2254
2024-05-22 12:07:57 [INFO]: Epoch 096 - training loss: 0.2384, validation loss: 0.2273
2024-05-22 12:08:05 [INFO]: Epoch 097 - training loss: 0.2379, validation loss: 0.2249
2024-05-22 12:08:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:08:05 [INFO]: Finished training. The best model is from epoch#87.
2024-05-22 12:08:05 [INFO]: Saved the model to saved_results/round_1/Transformer_physionet2012/20240522_T115606/Transformer.pypots
2024-05-22 12:08:06 [INFO]: Transformer on PhysioNet-2012: MAE=0.2026, MSE=0.2150
2024-05-22 12:08:07 [INFO]: Successfully saved to saved_results/round_1/Transformer_physionet2012/imputation.pkl
2024-05-22 12:08:07 [INFO]: Using the given device: cuda:0
2024-05-22 12:08:07 [INFO]: Model files will be saved to saved_results/round_1/TimesNet_physionet2012/20240522_T120807
2024-05-22 12:08:07 [INFO]: Tensorboard file will be saved to saved_results/round_1/TimesNet_physionet2012/20240522_T120807/tensorboard
2024-05-22 12:08:08 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-22 12:08:13 [INFO]: Epoch 001 - training loss: 0.3926, validation loss: 0.3282
2024-05-22 12:08:19 [INFO]: Epoch 002 - training loss: 0.3949, validation loss: 0.3161
2024-05-22 12:08:24 [INFO]: Epoch 003 - training loss: 0.3349, validation loss: 0.3141
2024-05-22 12:08:30 [INFO]: Epoch 004 - training loss: 0.3626, validation loss: 0.3021
2024-05-22 12:08:36 [INFO]: Epoch 005 - training loss: 0.4508, validation loss: 0.2976
2024-05-22 12:08:41 [INFO]: Epoch 006 - training loss: 0.3793, validation loss: 0.3054
2024-05-22 12:08:47 [INFO]: Epoch 007 - training loss: 0.3209, validation loss: 0.3112
2024-05-22 12:08:52 [INFO]: Epoch 008 - training loss: 0.3204, validation loss: 0.2995
2024-05-22 12:08:58 [INFO]: Epoch 009 - training loss: 0.4596, validation loss: 0.3074
2024-05-22 12:09:03 [INFO]: Epoch 010 - training loss: 0.4413, validation loss: 0.3147
2024-05-22 12:09:09 [INFO]: Epoch 011 - training loss: 0.3501, validation loss: 0.2979
2024-05-22 12:09:14 [INFO]: Epoch 012 - training loss: 0.3946, validation loss: 0.2950
2024-05-22 12:09:19 [INFO]: Epoch 013 - training loss: 0.3544, validation loss: 0.3001
2024-05-22 12:09:25 [INFO]: Epoch 014 - training loss: 0.3745, validation loss: 0.2917
2024-05-22 12:09:30 [INFO]: Epoch 015 - training loss: 0.3485, validation loss: 0.2875
2024-05-22 12:09:36 [INFO]: Epoch 016 - training loss: 0.2986, validation loss: 0.2854
2024-05-22 12:09:41 [INFO]: Epoch 017 - training loss: 0.3421, validation loss: 0.2821
2024-05-22 12:09:47 [INFO]: Epoch 018 - training loss: 0.3048, validation loss: 0.2862
2024-05-22 12:09:52 [INFO]: Epoch 019 - training loss: 0.3481, validation loss: 0.2811
2024-05-22 12:09:57 [INFO]: Epoch 020 - training loss: 0.3062, validation loss: 0.2842
2024-05-22 12:10:02 [INFO]: Epoch 021 - training loss: 0.3371, validation loss: 0.2820
2024-05-22 12:10:08 [INFO]: Epoch 022 - training loss: 0.3054, validation loss: 0.2878
2024-05-22 12:10:13 [INFO]: Epoch 023 - training loss: 0.3885, validation loss: 0.2752
2024-05-22 12:10:18 [INFO]: Epoch 024 - training loss: 0.2888, validation loss: 0.2759
2024-05-22 12:10:23 [INFO]: Epoch 025 - training loss: 0.2976, validation loss: 0.2754
2024-05-22 12:10:29 [INFO]: Epoch 026 - training loss: 0.2973, validation loss: 0.2739
2024-05-22 12:10:34 [INFO]: Epoch 027 - training loss: 0.3707, validation loss: 0.2759
2024-05-22 12:10:39 [INFO]: Epoch 028 - training loss: 0.2994, validation loss: 0.2723
2024-05-22 12:10:45 [INFO]: Epoch 029 - training loss: 0.3654, validation loss: 0.2699
2024-05-22 12:10:49 [INFO]: Epoch 030 - training loss: 0.3771, validation loss: 0.2710
2024-05-22 12:10:55 [INFO]: Epoch 031 - training loss: 0.3302, validation loss: 0.2724
2024-05-22 12:11:00 [INFO]: Epoch 032 - training loss: 0.3033, validation loss: 0.2730
2024-05-22 12:11:05 [INFO]: Epoch 033 - training loss: 0.3027, validation loss: 0.2693
2024-05-22 12:11:10 [INFO]: Epoch 034 - training loss: 0.3261, validation loss: 0.2693
2024-05-22 12:11:16 [INFO]: Epoch 035 - training loss: 0.2975, validation loss: 0.2712
2024-05-22 12:11:21 [INFO]: Epoch 036 - training loss: 0.2959, validation loss: 0.2709
2024-05-22 12:11:26 [INFO]: Epoch 037 - training loss: 0.2938, validation loss: 0.2660
2024-05-22 12:11:31 [INFO]: Epoch 038 - training loss: 0.2959, validation loss: 0.2652
2024-05-22 12:11:36 [INFO]: Epoch 039 - training loss: 0.3018, validation loss: 0.2728
2024-05-22 12:11:41 [INFO]: Epoch 040 - training loss: 0.3033, validation loss: 0.2695
2024-05-22 12:11:46 [INFO]: Epoch 041 - training loss: 0.4067, validation loss: 0.2659
2024-05-22 12:11:51 [INFO]: Epoch 042 - training loss: 0.2932, validation loss: 0.2660
2024-05-22 12:11:56 [INFO]: Epoch 043 - training loss: 0.2796, validation loss: 0.2672
2024-05-22 12:12:01 [INFO]: Epoch 044 - training loss: 0.3244, validation loss: 0.2715
2024-05-22 12:12:06 [INFO]: Epoch 045 - training loss: 0.3042, validation loss: 0.2689
2024-05-22 12:12:11 [INFO]: Epoch 046 - training loss: 0.2846, validation loss: 0.2626
2024-05-22 12:12:16 [INFO]: Epoch 047 - training loss: 0.3340, validation loss: 0.2798
2024-05-22 12:12:22 [INFO]: Epoch 048 - training loss: 0.2791, validation loss: 0.2653
2024-05-22 12:12:27 [INFO]: Epoch 049 - training loss: 0.2878, validation loss: 0.2694
2024-05-22 12:12:32 [INFO]: Epoch 050 - training loss: 0.3168, validation loss: 0.2635
2024-05-22 12:12:37 [INFO]: Epoch 051 - training loss: 0.2797, validation loss: 0.2640
2024-05-22 12:12:42 [INFO]: Epoch 052 - training loss: 0.3698, validation loss: 0.2668
2024-05-22 12:12:47 [INFO]: Epoch 053 - training loss: 0.2800, validation loss: 0.2721
2024-05-22 12:12:52 [INFO]: Epoch 054 - training loss: 0.2862, validation loss: 0.2638
2024-05-22 12:12:57 [INFO]: Epoch 055 - training loss: 0.3268, validation loss: 0.2588
2024-05-22 12:13:03 [INFO]: Epoch 056 - training loss: 0.2973, validation loss: 0.2652
2024-05-22 12:13:08 [INFO]: Epoch 057 - training loss: 0.3548, validation loss: 0.2624
2024-05-22 12:13:13 [INFO]: Epoch 058 - training loss: 0.2852, validation loss: 0.2618
2024-05-22 12:13:18 [INFO]: Epoch 059 - training loss: 0.2791, validation loss: 0.2635
2024-05-22 12:13:23 [INFO]: Epoch 060 - training loss: 0.2917, validation loss: 0.2672
2024-05-22 12:13:28 [INFO]: Epoch 061 - training loss: 0.3968, validation loss: 0.2674
2024-05-22 12:13:33 [INFO]: Epoch 062 - training loss: 0.3133, validation loss: 0.2635
2024-05-22 12:13:38 [INFO]: Epoch 063 - training loss: 0.2925, validation loss: 0.2614
2024-05-22 12:13:43 [INFO]: Epoch 064 - training loss: 0.2849, validation loss: 0.2652
2024-05-22 12:13:48 [INFO]: Epoch 065 - training loss: 0.2836, validation loss: 0.2604
2024-05-22 12:13:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:13:48 [INFO]: Finished training. The best model is from epoch#55.
2024-05-22 12:13:49 [INFO]: Saved the model to saved_results/round_1/TimesNet_physionet2012/20240522_T120807/TimesNet.pypots
2024-05-22 12:13:49 [INFO]: TimesNet on PhysioNet-2012: MAE=0.2567, MSE=0.2630
2024-05-22 12:13:51 [INFO]: Successfully saved to saved_results/round_1/TimesNet_physionet2012/imputation.pkl
2024-05-22 12:13:51 [INFO]: Using the given device: cuda:0
2024-05-22 12:13:51 [INFO]: Model files will be saved to saved_results/round_1/CSDI_physionet2012/20240522_T121351
2024-05-22 12:13:51 [INFO]: Tensorboard file will be saved to saved_results/round_1/CSDI_physionet2012/20240522_T121351/tensorboard
2024-05-22 12:13:51 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-22 12:17:07 [INFO]: Epoch 001 - training loss: 0.3387, validation loss: 0.2464
2024-05-22 12:17:07 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch1_loss0.24636218597491583.pypots
2024-05-22 12:20:24 [INFO]: Epoch 002 - training loss: 0.2575, validation loss: 0.2125
2024-05-22 12:20:24 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch2_loss0.21247548883159956.pypots
2024-05-22 12:23:41 [INFO]: Epoch 003 - training loss: 0.2449, validation loss: 0.2069
2024-05-22 12:23:41 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch3_loss0.2068516214688619.pypots
2024-05-22 12:26:58 [INFO]: Epoch 004 - training loss: 0.2405, validation loss: 0.2004
2024-05-22 12:26:58 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch4_loss0.2004440352320671.pypots
2024-05-22 12:30:15 [INFO]: Epoch 005 - training loss: 0.2371, validation loss: 0.1942
2024-05-22 12:30:15 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch5_loss0.19415593047936758.pypots
2024-05-22 12:33:31 [INFO]: Epoch 006 - training loss: 0.2333, validation loss: 0.1906
2024-05-22 12:33:31 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch6_loss0.19055946270624796.pypots
2024-05-22 12:36:47 [INFO]: Epoch 007 - training loss: 0.2328, validation loss: 0.1878
2024-05-22 12:36:48 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch7_loss0.18775247658292452.pypots
2024-05-22 12:40:04 [INFO]: Epoch 008 - training loss: 0.2237, validation loss: 0.1865
2024-05-22 12:40:05 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch8_loss0.18652640556295713.pypots
2024-05-22 12:43:22 [INFO]: Epoch 009 - training loss: 0.2243, validation loss: 0.1868
2024-05-22 12:43:22 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch9_loss0.18681632752219837.pypots
2024-05-22 12:46:38 [INFO]: Epoch 010 - training loss: 0.2291, validation loss: 0.1881
2024-05-22 12:46:38 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch10_loss0.1880817485352357.pypots
2024-05-22 12:49:55 [INFO]: Epoch 011 - training loss: 0.2242, validation loss: 0.1825
2024-05-22 12:49:55 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch11_loss0.18248779351512592.pypots
2024-05-22 12:53:13 [INFO]: Epoch 012 - training loss: 0.2227, validation loss: 0.1865
2024-05-22 12:53:13 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch12_loss0.18653748780488968.pypots
2024-05-22 12:56:30 [INFO]: Epoch 013 - training loss: 0.2194, validation loss: 0.1817
2024-05-22 12:56:30 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch13_loss0.18172757824261984.pypots
2024-05-22 12:59:47 [INFO]: Epoch 014 - training loss: 0.2156, validation loss: 0.1822
2024-05-22 12:59:47 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch14_loss0.18220024332404136.pypots
2024-05-22 13:03:03 [INFO]: Epoch 015 - training loss: 0.2202, validation loss: 0.1792
2024-05-22 13:03:03 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch15_loss0.17921687165896097.pypots
2024-05-22 13:06:19 [INFO]: Epoch 016 - training loss: 0.2239, validation loss: 0.1816
2024-05-22 13:06:19 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch16_loss0.1815909892320633.pypots
2024-05-22 13:09:36 [INFO]: Epoch 017 - training loss: 0.2144, validation loss: 0.1792
2024-05-22 13:09:36 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch17_loss0.1791534148156643.pypots
2024-05-22 13:12:52 [INFO]: Epoch 018 - training loss: 0.2128, validation loss: 0.1787
2024-05-22 13:12:52 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch18_loss0.178670933842659.pypots
2024-05-22 13:16:08 [INFO]: Epoch 019 - training loss: 0.2212, validation loss: 0.1764
2024-05-22 13:16:08 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch19_loss0.17639614442984264.pypots
2024-05-22 13:19:25 [INFO]: Epoch 020 - training loss: 0.2198, validation loss: 0.1730
2024-05-22 13:19:25 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch20_loss0.17300887753566105.pypots
2024-05-22 13:22:41 [INFO]: Epoch 021 - training loss: 0.2284, validation loss: 0.1759
2024-05-22 13:22:41 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch21_loss0.1759235498805841.pypots
2024-05-22 13:25:58 [INFO]: Epoch 022 - training loss: 0.2192, validation loss: 0.1767
2024-05-22 13:25:58 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch22_loss0.1766800731420517.pypots
2024-05-22 13:29:14 [INFO]: Epoch 023 - training loss: 0.2117, validation loss: 0.1733
2024-05-22 13:29:14 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch23_loss0.17329347307483356.pypots
2024-05-22 13:32:30 [INFO]: Epoch 024 - training loss: 0.2151, validation loss: 0.1755
2024-05-22 13:32:30 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch24_loss0.17545427282651266.pypots
2024-05-22 13:35:47 [INFO]: Epoch 025 - training loss: 0.2180, validation loss: 0.1754
2024-05-22 13:35:47 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch25_loss0.17535383105278016.pypots
2024-05-22 13:39:05 [INFO]: Epoch 026 - training loss: 0.2180, validation loss: 0.1733
2024-05-22 13:39:05 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch26_loss0.1732536621391773.pypots
2024-05-22 13:42:22 [INFO]: Epoch 027 - training loss: 0.2188, validation loss: 0.1733
2024-05-22 13:42:22 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch27_loss0.17328792214393615.pypots
2024-05-22 13:45:39 [INFO]: Epoch 028 - training loss: 0.2257, validation loss: 0.1723
2024-05-22 13:45:39 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch28_loss0.17228135491410893.pypots
2024-05-22 13:48:56 [INFO]: Epoch 029 - training loss: 0.2082, validation loss: 0.1729
2024-05-22 13:48:56 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch29_loss0.17286654288570086.pypots
2024-05-22 13:52:12 [INFO]: Epoch 030 - training loss: 0.2114, validation loss: 0.1726
2024-05-22 13:52:12 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch30_loss0.1726352574924628.pypots
2024-05-22 13:55:28 [INFO]: Epoch 031 - training loss: 0.2112, validation loss: 0.1731
2024-05-22 13:55:28 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch31_loss0.17310086836417515.pypots
2024-05-22 13:58:45 [INFO]: Epoch 032 - training loss: 0.2109, validation loss: 0.1729
2024-05-22 13:58:45 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch32_loss0.17291143635908762.pypots
2024-05-22 14:02:01 [INFO]: Epoch 033 - training loss: 0.2140, validation loss: 0.1693
2024-05-22 14:02:01 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch33_loss0.1693254997332891.pypots
2024-05-22 14:05:18 [INFO]: Epoch 034 - training loss: 0.2063, validation loss: 0.1690
2024-05-22 14:05:18 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch34_loss0.1689996326963107.pypots
2024-05-22 14:08:34 [INFO]: Epoch 035 - training loss: 0.2195, validation loss: 0.1703
2024-05-22 14:08:34 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch35_loss0.17033025870720545.pypots
2024-05-22 14:11:52 [INFO]: Epoch 036 - training loss: 0.2104, validation loss: 0.1718
2024-05-22 14:11:52 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch36_loss0.1718204361697038.pypots
2024-05-22 14:15:10 [INFO]: Epoch 037 - training loss: 0.2126, validation loss: 0.1705
2024-05-22 14:15:10 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch37_loss0.1705459011097749.pypots
2024-05-22 14:18:27 [INFO]: Epoch 038 - training loss: 0.2099, validation loss: 0.1687
2024-05-22 14:18:27 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch38_loss0.16873145302136738.pypots
2024-05-22 14:21:45 [INFO]: Epoch 039 - training loss: 0.2163, validation loss: 0.1695
2024-05-22 14:21:45 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch39_loss0.16947164113322893.pypots
2024-05-22 14:25:03 [INFO]: Epoch 040 - training loss: 0.2143, validation loss: 0.1684
2024-05-22 14:25:03 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch40_loss0.16843352590998015.pypots
2024-05-22 14:28:20 [INFO]: Epoch 041 - training loss: 0.2133, validation loss: 0.1688
2024-05-22 14:28:20 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch41_loss0.16883929048975307.pypots
2024-05-22 14:31:38 [INFO]: Epoch 042 - training loss: 0.2112, validation loss: 0.1715
2024-05-22 14:31:38 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch42_loss0.17153295452396075.pypots
2024-05-22 14:34:56 [INFO]: Epoch 043 - training loss: 0.2127, validation loss: 0.1675
2024-05-22 14:34:56 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch43_loss0.16746604144573213.pypots
2024-05-22 14:38:14 [INFO]: Epoch 044 - training loss: 0.2112, validation loss: 0.1700
2024-05-22 14:38:14 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch44_loss0.16996358359853428.pypots
2024-05-22 14:41:31 [INFO]: Epoch 045 - training loss: 0.2079, validation loss: 0.1671
2024-05-22 14:41:31 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch45_loss0.16712250610192617.pypots
2024-05-22 14:44:49 [INFO]: Epoch 046 - training loss: 0.2130, validation loss: 0.1660
2024-05-22 14:44:49 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch46_loss0.16597205127278963.pypots
2024-05-22 14:48:06 [INFO]: Epoch 047 - training loss: 0.2130, validation loss: 0.1670
2024-05-22 14:48:06 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch47_loss0.16699331775307655.pypots
2024-05-22 14:51:24 [INFO]: Epoch 048 - training loss: 0.2136, validation loss: 0.1683
2024-05-22 14:51:24 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch48_loss0.16833784927924475.pypots
2024-05-22 14:54:41 [INFO]: Epoch 049 - training loss: 0.2172, validation loss: 0.1661
2024-05-22 14:54:41 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch49_loss0.1660941205918789.pypots
2024-05-22 14:57:58 [INFO]: Epoch 050 - training loss: 0.2111, validation loss: 0.1669
2024-05-22 14:57:58 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch50_loss0.16688497240344682.pypots
2024-05-22 15:01:16 [INFO]: Epoch 051 - training loss: 0.2075, validation loss: 0.1660
2024-05-22 15:01:16 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch51_loss0.16600727265079815.pypots
2024-05-22 15:04:33 [INFO]: Epoch 052 - training loss: 0.2053, validation loss: 0.1649
2024-05-22 15:04:33 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch52_loss0.16494876916209858.pypots
2024-05-22 15:07:51 [INFO]: Epoch 053 - training loss: 0.2093, validation loss: 0.1660
2024-05-22 15:07:51 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch53_loss0.1659805677831173.pypots
2024-05-22 15:11:09 [INFO]: Epoch 054 - training loss: 0.2116, validation loss: 0.1688
2024-05-22 15:11:09 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch54_loss0.16875208194057148.pypots
2024-05-22 15:14:35 [INFO]: Epoch 055 - training loss: 0.2082, validation loss: 0.1669
2024-05-22 15:14:35 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch55_loss0.16693599993983904.pypots
2024-05-22 15:18:36 [INFO]: Epoch 056 - training loss: 0.2127, validation loss: 0.1660
2024-05-22 15:18:36 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch56_loss0.16597580115000407.pypots
2024-05-22 15:22:48 [INFO]: Epoch 057 - training loss: 0.2038, validation loss: 0.1639
2024-05-22 15:22:49 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch57_loss0.16392990276217462.pypots
2024-05-22 15:26:53 [INFO]: Epoch 058 - training loss: 0.2140, validation loss: 0.1671
2024-05-22 15:26:53 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch58_loss0.16710408156116804.pypots
2024-05-22 15:30:30 [INFO]: Epoch 059 - training loss: 0.2076, validation loss: 0.1668
2024-05-22 15:30:31 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch59_loss0.16681619609395662.pypots
2024-05-22 15:35:44 [INFO]: Epoch 060 - training loss: 0.2060, validation loss: 0.1655
2024-05-22 15:35:44 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch60_loss0.1654529131948948.pypots
2024-05-22 15:41:08 [INFO]: Epoch 061 - training loss: 0.2136, validation loss: 0.1651
2024-05-22 15:41:08 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch61_loss0.1651175305247307.pypots
2024-05-22 15:46:35 [INFO]: Epoch 062 - training loss: 0.2100, validation loss: 0.1650
2024-05-22 15:46:35 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch62_loss0.16499614243706068.pypots
2024-05-22 15:51:59 [INFO]: Epoch 063 - training loss: 0.2048, validation loss: 0.1649
2024-05-22 15:52:00 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch63_loss0.16488753085335095.pypots
2024-05-22 15:57:25 [INFO]: Epoch 064 - training loss: 0.2042, validation loss: 0.1648
2024-05-22 15:57:25 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch64_loss0.164817110200723.pypots
2024-05-22 16:02:49 [INFO]: Epoch 065 - training loss: 0.2068, validation loss: 0.1651
2024-05-22 16:02:49 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch65_loss0.16510102525353432.pypots
2024-05-22 16:08:14 [INFO]: Epoch 066 - training loss: 0.2086, validation loss: 0.1649
2024-05-22 16:08:14 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch66_loss0.1649027422070503.pypots
2024-05-22 16:13:39 [INFO]: Epoch 067 - training loss: 0.2025, validation loss: 0.1650
2024-05-22 16:13:39 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI_epoch67_loss0.16499155908823013.pypots
2024-05-22 16:13:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:13:39 [INFO]: Finished training. The best model is from epoch#57.
2024-05-22 16:13:39 [INFO]: Saved the model to saved_results/round_1/CSDI_physionet2012/20240522_T121351/CSDI.pypots
2024-05-22 16:52:27 [INFO]: CSDI on PhysioNet-2012: MAE=0.2154, MSE=0.2714
2024-05-22 18:57:36 [INFO]: Successfully saved to saved_results/round_1/CSDI_physionet2012/imputation.pkl
2024-05-22 18:57:36 [INFO]: Using the given device: cuda:0
2024-05-22 18:57:36 [INFO]: Model files will be saved to saved_results/round_1/GPVAE_physionet2012/20240522_T185736
2024-05-22 18:57:36 [INFO]: Tensorboard file will be saved to saved_results/round_1/GPVAE_physionet2012/20240522_T185736/tensorboard
2024-05-22 18:57:36 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-22 18:57:41 [INFO]: Epoch 001 - training loss: 29926.2735, validation loss: 0.7236
2024-05-22 18:57:46 [INFO]: Epoch 002 - training loss: 23119.9755, validation loss: 0.6532
2024-05-22 18:57:52 [INFO]: Epoch 003 - training loss: 22936.7488, validation loss: 0.6565
2024-05-22 18:57:57 [INFO]: Epoch 004 - training loss: 22880.2766, validation loss: 0.6389
2024-05-22 18:58:02 [INFO]: Epoch 005 - training loss: 22856.3437, validation loss: 0.6380
2024-05-22 18:58:08 [INFO]: Epoch 006 - training loss: 22845.2482, validation loss: 0.6198
2024-05-22 18:58:14 [INFO]: Epoch 007 - training loss: 22838.4814, validation loss: 0.6132
2024-05-22 18:58:19 [INFO]: Epoch 008 - training loss: 22835.1436, validation loss: 0.6091
2024-05-22 18:58:25 [INFO]: Epoch 009 - training loss: 22830.1333, validation loss: 0.6091
2024-05-22 18:58:30 [INFO]: Epoch 010 - training loss: 22828.0673, validation loss: 0.6176
2024-05-22 18:58:35 [INFO]: Epoch 011 - training loss: 22827.5887, validation loss: 0.6038
2024-05-22 18:58:40 [INFO]: Epoch 012 - training loss: 22826.1085, validation loss: 0.5921
2024-05-22 18:58:45 [INFO]: Epoch 013 - training loss: 22822.1162, validation loss: 0.5690
2024-05-22 18:58:50 [INFO]: Epoch 014 - training loss: 22817.6270, validation loss: 0.5507
2024-05-22 18:58:55 [INFO]: Epoch 015 - training loss: 22814.2550, validation loss: 0.5386
2024-05-22 18:59:00 [INFO]: Epoch 016 - training loss: 22811.5572, validation loss: 0.5245
2024-05-22 18:59:04 [INFO]: Epoch 017 - training loss: 22810.0630, validation loss: 0.5165
2024-05-22 18:59:09 [INFO]: Epoch 018 - training loss: 22806.9327, validation loss: 0.5110
2024-05-22 18:59:15 [INFO]: Epoch 019 - training loss: 22804.1081, validation loss: 0.5169
2024-05-22 18:59:20 [INFO]: Epoch 020 - training loss: 22802.8215, validation loss: 0.4980
2024-05-22 18:59:24 [INFO]: Epoch 021 - training loss: 22802.1331, validation loss: 0.4956
2024-05-22 18:59:30 [INFO]: Epoch 022 - training loss: 22800.8785, validation loss: 0.4916
2024-05-22 18:59:36 [INFO]: Epoch 023 - training loss: 22800.0240, validation loss: 0.4957
2024-05-22 18:59:41 [INFO]: Epoch 024 - training loss: 22799.2849, validation loss: 0.4911
2024-05-22 18:59:46 [INFO]: Epoch 025 - training loss: 22798.7464, validation loss: 0.4896
2024-05-22 18:59:52 [INFO]: Epoch 026 - training loss: 22798.4688, validation loss: 0.4891
2024-05-22 18:59:57 [INFO]: Epoch 027 - training loss: 22797.3853, validation loss: 0.4980
2024-05-22 19:00:02 [INFO]: Epoch 028 - training loss: 22797.0681, validation loss: 0.4853
2024-05-22 19:00:07 [INFO]: Epoch 029 - training loss: 22795.7561, validation loss: 0.4757
2024-05-22 19:00:12 [INFO]: Epoch 030 - training loss: 22794.7977, validation loss: 0.4773
2024-05-22 19:00:17 [INFO]: Epoch 031 - training loss: 22794.5290, validation loss: 0.4713
2024-05-22 19:00:22 [INFO]: Epoch 032 - training loss: 22792.9150, validation loss: 0.4716
2024-05-22 19:00:27 [INFO]: Epoch 033 - training loss: 22792.6338, validation loss: 0.4677
2024-05-22 19:00:32 [INFO]: Epoch 034 - training loss: 22791.5436, validation loss: 0.4678
2024-05-22 19:00:37 [INFO]: Epoch 035 - training loss: 22791.2766, validation loss: 0.4663
2024-05-22 19:00:42 [INFO]: Epoch 036 - training loss: 22791.1807, validation loss: 0.4598
2024-05-22 19:00:47 [INFO]: Epoch 037 - training loss: 22790.1931, validation loss: 0.4612
2024-05-22 19:00:52 [INFO]: Epoch 038 - training loss: 22789.7732, validation loss: 0.4633
2024-05-22 19:00:58 [INFO]: Epoch 039 - training loss: 22789.3722, validation loss: 0.4663
2024-05-22 19:01:03 [INFO]: Epoch 040 - training loss: 22788.7590, validation loss: 0.4589
2024-05-22 19:01:09 [INFO]: Epoch 041 - training loss: 22789.0011, validation loss: 0.4669
2024-05-22 19:01:15 [INFO]: Epoch 042 - training loss: 22788.5858, validation loss: 0.4544
2024-05-22 19:01:20 [INFO]: Epoch 043 - training loss: 22787.9377, validation loss: 0.4573
2024-05-22 19:01:26 [INFO]: Epoch 044 - training loss: 22787.8948, validation loss: 0.4610
2024-05-22 19:01:31 [INFO]: Epoch 045 - training loss: 22787.3903, validation loss: 0.4567
2024-05-22 19:01:37 [INFO]: Epoch 046 - training loss: 22787.2514, validation loss: 0.4577
2024-05-22 19:01:42 [INFO]: Epoch 047 - training loss: 22787.4812, validation loss: 0.4598
2024-05-22 19:01:48 [INFO]: Epoch 048 - training loss: 22787.4656, validation loss: 0.4566
2024-05-22 19:01:54 [INFO]: Epoch 049 - training loss: 22786.2825, validation loss: 0.4557
2024-05-22 19:01:59 [INFO]: Epoch 050 - training loss: 22786.3080, validation loss: 0.4533
2024-05-22 19:02:05 [INFO]: Epoch 051 - training loss: 22785.5158, validation loss: 0.4548
2024-05-22 19:02:10 [INFO]: Epoch 052 - training loss: 22784.6696, validation loss: 0.4501
2024-05-22 19:02:15 [INFO]: Epoch 053 - training loss: 22784.4744, validation loss: 0.4510
2024-05-22 19:02:21 [INFO]: Epoch 054 - training loss: 22784.2130, validation loss: 0.4548
2024-05-22 19:02:27 [INFO]: Epoch 055 - training loss: 22784.5833, validation loss: 0.4490
2024-05-22 19:02:32 [INFO]: Epoch 056 - training loss: 22783.5802, validation loss: 0.4480
2024-05-22 19:02:38 [INFO]: Epoch 057 - training loss: 22784.1491, validation loss: 0.4570
2024-05-22 19:02:43 [INFO]: Epoch 058 - training loss: 22783.7594, validation loss: 0.4534
2024-05-22 19:02:49 [INFO]: Epoch 059 - training loss: 22782.9325, validation loss: 0.4526
2024-05-22 19:02:55 [INFO]: Epoch 060 - training loss: 22782.9208, validation loss: 0.4523
2024-05-22 19:03:00 [INFO]: Epoch 061 - training loss: 22782.7674, validation loss: 0.4474
2024-05-22 19:03:07 [INFO]: Epoch 062 - training loss: 22783.2217, validation loss: 0.4484
2024-05-22 19:03:12 [INFO]: Epoch 063 - training loss: 22782.5521, validation loss: 0.4474
2024-05-22 19:03:18 [INFO]: Epoch 064 - training loss: 22782.0462, validation loss: 0.4496
2024-05-22 19:03:23 [INFO]: Epoch 065 - training loss: 22781.8700, validation loss: 0.4533
2024-05-22 19:03:29 [INFO]: Epoch 066 - training loss: 22783.2020, validation loss: 0.4454
2024-05-22 19:03:34 [INFO]: Epoch 067 - training loss: 22781.6635, validation loss: 0.4468
2024-05-22 19:03:39 [INFO]: Epoch 068 - training loss: 22781.4846, validation loss: 0.4442
2024-05-22 19:03:44 [INFO]: Epoch 069 - training loss: 22780.9690, validation loss: 0.4474
2024-05-22 19:03:49 [INFO]: Epoch 070 - training loss: 22781.1534, validation loss: 0.4441
2024-05-22 19:03:54 [INFO]: Epoch 071 - training loss: 22780.9619, validation loss: 0.4435
2024-05-22 19:04:00 [INFO]: Epoch 072 - training loss: 22781.8527, validation loss: 0.4455
2024-05-22 19:04:05 [INFO]: Epoch 073 - training loss: 22780.8569, validation loss: 0.4462
2024-05-22 19:04:11 [INFO]: Epoch 074 - training loss: 22780.5304, validation loss: 0.4424
2024-05-22 19:04:17 [INFO]: Epoch 075 - training loss: 22780.6438, validation loss: 0.4383
2024-05-22 19:04:22 [INFO]: Epoch 076 - training loss: 22780.1733, validation loss: 0.4481
2024-05-22 19:04:27 [INFO]: Epoch 077 - training loss: 22780.1502, validation loss: 0.4429
2024-05-22 19:04:33 [INFO]: Epoch 078 - training loss: 22779.7726, validation loss: 0.4382
2024-05-22 19:04:38 [INFO]: Epoch 079 - training loss: 22779.6048, validation loss: 0.4386
2024-05-22 19:04:43 [INFO]: Epoch 080 - training loss: 22779.6401, validation loss: 0.4389
2024-05-22 19:04:49 [INFO]: Epoch 081 - training loss: 22779.5128, validation loss: 0.4339
2024-05-22 19:04:54 [INFO]: Epoch 082 - training loss: 22779.7133, validation loss: 0.4370
2024-05-22 19:05:00 [INFO]: Epoch 083 - training loss: 22780.2553, validation loss: 0.4351
2024-05-22 19:05:06 [INFO]: Epoch 084 - training loss: 22779.0442, validation loss: 0.4391
2024-05-22 19:05:11 [INFO]: Epoch 085 - training loss: 22778.8051, validation loss: 0.4365
2024-05-22 19:05:16 [INFO]: Epoch 086 - training loss: 22778.5576, validation loss: 0.4372
2024-05-22 19:05:22 [INFO]: Epoch 087 - training loss: 22778.3065, validation loss: 0.4336
2024-05-22 19:05:27 [INFO]: Epoch 088 - training loss: 22778.3619, validation loss: 0.4336
2024-05-22 19:05:33 [INFO]: Epoch 089 - training loss: 22777.9457, validation loss: 0.4406
2024-05-22 19:05:39 [INFO]: Epoch 090 - training loss: 22778.1565, validation loss: 0.4341
2024-05-22 19:05:45 [INFO]: Epoch 091 - training loss: 22777.8469, validation loss: 0.4307
2024-05-22 19:05:50 [INFO]: Epoch 092 - training loss: 22777.9547, validation loss: 0.4400
2024-05-22 19:05:56 [INFO]: Epoch 093 - training loss: 22778.6354, validation loss: 0.4345
2024-05-22 19:06:02 [INFO]: Epoch 094 - training loss: 22777.5573, validation loss: 0.4341
2024-05-22 19:06:07 [INFO]: Epoch 095 - training loss: 22777.2968, validation loss: 0.4308
2024-05-22 19:06:13 [INFO]: Epoch 096 - training loss: 22777.3055, validation loss: 0.4350
2024-05-22 19:06:19 [INFO]: Epoch 097 - training loss: 22777.5986, validation loss: 0.4304
2024-05-22 19:06:25 [INFO]: Epoch 098 - training loss: 22776.8809, validation loss: 0.4289
2024-05-22 19:06:31 [INFO]: Epoch 099 - training loss: 22776.9813, validation loss: 0.4306
2024-05-22 19:06:37 [INFO]: Epoch 100 - training loss: 22776.5862, validation loss: 0.4386
2024-05-22 19:06:42 [INFO]: Epoch 101 - training loss: 22777.0856, validation loss: 0.4308
2024-05-22 19:06:48 [INFO]: Epoch 102 - training loss: 22776.4334, validation loss: 0.4315
2024-05-22 19:06:53 [INFO]: Epoch 103 - training loss: 22776.8016, validation loss: 0.4309
2024-05-22 19:06:59 [INFO]: Epoch 104 - training loss: 22776.4423, validation loss: 0.4355
2024-05-22 19:07:05 [INFO]: Epoch 105 - training loss: 22777.1246, validation loss: 0.4349
2024-05-22 19:07:10 [INFO]: Epoch 106 - training loss: 22776.3516, validation loss: 0.4321
2024-05-22 19:07:15 [INFO]: Epoch 107 - training loss: 22776.5105, validation loss: 0.4299
2024-05-22 19:07:21 [INFO]: Epoch 108 - training loss: 22776.3938, validation loss: 0.4276
2024-05-22 19:07:26 [INFO]: Epoch 109 - training loss: 22776.6029, validation loss: 0.4318
2024-05-22 19:07:32 [INFO]: Epoch 110 - training loss: 22776.2363, validation loss: 0.4298
2024-05-22 19:07:37 [INFO]: Epoch 111 - training loss: 22775.7885, validation loss: 0.4281
2024-05-22 19:07:43 [INFO]: Epoch 112 - training loss: 22776.1282, validation loss: 0.4286
2024-05-22 19:07:49 [INFO]: Epoch 113 - training loss: 22775.5899, validation loss: 0.4296
2024-05-22 19:07:54 [INFO]: Epoch 114 - training loss: 22775.4717, validation loss: 0.4281
2024-05-22 19:08:00 [INFO]: Epoch 115 - training loss: 22775.2216, validation loss: 0.4274
2024-05-22 19:08:05 [INFO]: Epoch 116 - training loss: 22775.3260, validation loss: 0.4298
2024-05-22 19:08:11 [INFO]: Epoch 117 - training loss: 22775.6446, validation loss: 0.4282
2024-05-22 19:08:16 [INFO]: Epoch 118 - training loss: 22775.1032, validation loss: 0.4313
2024-05-22 19:08:22 [INFO]: Epoch 119 - training loss: 22775.0411, validation loss: 0.4259
2024-05-22 19:08:27 [INFO]: Epoch 120 - training loss: 22774.9622, validation loss: 0.4263
2024-05-22 19:08:33 [INFO]: Epoch 121 - training loss: 22774.8230, validation loss: 0.4241
2024-05-22 19:08:39 [INFO]: Epoch 122 - training loss: 22775.5122, validation loss: 0.4264
2024-05-22 19:08:45 [INFO]: Epoch 123 - training loss: 22775.1632, validation loss: 0.4300
2024-05-22 19:08:50 [INFO]: Epoch 124 - training loss: 22774.9279, validation loss: 0.4303
2024-05-22 19:08:56 [INFO]: Epoch 125 - training loss: 22774.9739, validation loss: 0.4260
2024-05-22 19:09:02 [INFO]: Epoch 126 - training loss: 22775.0449, validation loss: 0.4284
2024-05-22 19:09:08 [INFO]: Epoch 127 - training loss: 22775.3429, validation loss: 0.4303
2024-05-22 19:09:14 [INFO]: Epoch 128 - training loss: 22774.6299, validation loss: 0.4287
2024-05-22 19:09:21 [INFO]: Epoch 129 - training loss: 22775.1355, validation loss: 0.4267
2024-05-22 19:09:27 [INFO]: Epoch 130 - training loss: 22774.2925, validation loss: 0.4253
2024-05-22 19:09:33 [INFO]: Epoch 131 - training loss: 22775.1122, validation loss: 0.4301
2024-05-22 19:09:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 19:09:33 [INFO]: Finished training. The best model is from epoch#121.
2024-05-22 19:09:33 [INFO]: Saved the model to saved_results/round_1/GPVAE_physionet2012/20240522_T185736/GPVAE.pypots
2024-05-22 19:09:34 [INFO]: GP-VAE on PhysioNet-2012: MAE=0.3954, MSE=0.4249
2024-05-22 19:09:37 [INFO]: Successfully saved to saved_results/round_1/GPVAE_physionet2012/imputation.pkl
2024-05-22 19:09:37 [INFO]: Using the given device: cuda:0
2024-05-22 19:09:37 [INFO]: Model files will be saved to saved_results/round_1/USGAN_physionet2012/20240522_T190937
2024-05-22 19:09:37 [INFO]: Tensorboard file will be saved to saved_results/round_1/USGAN_physionet2012/20240522_T190937/tensorboard
2024-05-22 19:09:37 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-22 19:13:45 [INFO]: Epoch 001 - generator training loss: 0.4959, discriminator training loss: 0.2817, validation loss: 0.4719
2024-05-22 19:17:32 [INFO]: Epoch 002 - generator training loss: 0.4334, discriminator training loss: 0.1284, validation loss: 0.4245
2024-05-22 19:21:17 [INFO]: Epoch 003 - generator training loss: 0.4154, discriminator training loss: 0.0812, validation loss: 0.3986
2024-05-22 19:25:02 [INFO]: Epoch 004 - generator training loss: 0.3978, discriminator training loss: 0.0612, validation loss: 0.3770
2024-05-22 19:28:45 [INFO]: Epoch 005 - generator training loss: 0.3797, discriminator training loss: 0.0496, validation loss: 0.3631
2024-05-22 19:32:32 [INFO]: Epoch 006 - generator training loss: 0.3686, discriminator training loss: 0.0424, validation loss: 0.3480
2024-05-22 19:36:26 [INFO]: Epoch 007 - generator training loss: 0.3568, discriminator training loss: 0.0375, validation loss: 0.3325
2024-05-22 19:40:08 [INFO]: Epoch 008 - generator training loss: 0.3434, discriminator training loss: 0.0344, validation loss: 0.3272
2024-05-22 19:44:02 [INFO]: Epoch 009 - generator training loss: 0.3375, discriminator training loss: 0.0322, validation loss: 0.3169
2024-05-22 19:46:04 [INFO]: Epoch 010 - generator training loss: 0.3244, discriminator training loss: 0.0305, validation loss: 0.3127
2024-05-22 19:48:02 [INFO]: Epoch 011 - generator training loss: 0.3145, discriminator training loss: 0.0291, validation loss: 0.2993
2024-05-22 19:50:02 [INFO]: Epoch 012 - generator training loss: 0.3092, discriminator training loss: 0.0280, validation loss: 0.2932
2024-05-22 19:51:51 [INFO]: Epoch 013 - generator training loss: 0.3005, discriminator training loss: 0.0270, validation loss: 0.2924
2024-05-22 19:53:39 [INFO]: Epoch 014 - generator training loss: 0.2951, discriminator training loss: 0.0263, validation loss: 0.2843
2024-05-22 19:55:30 [INFO]: Epoch 015 - generator training loss: 0.2897, discriminator training loss: 0.0255, validation loss: 0.2847
2024-05-22 19:57:22 [INFO]: Epoch 016 - generator training loss: 0.2856, discriminator training loss: 0.0248, validation loss: 0.2811
2024-05-22 19:59:13 [INFO]: Epoch 017 - generator training loss: 0.2803, discriminator training loss: 0.0244, validation loss: 0.2811
2024-05-22 20:01:14 [INFO]: Epoch 018 - generator training loss: 0.2786, discriminator training loss: 0.0237, validation loss: 0.2765
2024-05-22 20:03:07 [INFO]: Epoch 019 - generator training loss: 0.2738, discriminator training loss: 0.0233, validation loss: 0.2764
2024-05-22 20:04:59 [INFO]: Epoch 020 - generator training loss: 0.2724, discriminator training loss: 0.0229, validation loss: 0.2783
2024-05-22 20:06:53 [INFO]: Epoch 021 - generator training loss: 0.2683, discriminator training loss: 0.0226, validation loss: 0.2725
2024-05-22 20:08:47 [INFO]: Epoch 022 - generator training loss: 0.2659, discriminator training loss: 0.0223, validation loss: 0.2748
2024-05-22 20:10:38 [INFO]: Epoch 023 - generator training loss: 0.2647, discriminator training loss: 0.0219, validation loss: 0.2721
2024-05-22 20:12:44 [INFO]: Epoch 024 - generator training loss: 0.2599, discriminator training loss: 0.0216, validation loss: 0.2701
2024-05-22 20:14:44 [INFO]: Epoch 025 - generator training loss: 0.2602, discriminator training loss: 0.0214, validation loss: 0.2721
2024-05-22 20:16:41 [INFO]: Epoch 026 - generator training loss: 0.2577, discriminator training loss: 0.0212, validation loss: 0.2728
2024-05-22 20:18:38 [INFO]: Epoch 027 - generator training loss: 0.2564, discriminator training loss: 0.0208, validation loss: 0.2713
2024-05-22 20:20:34 [INFO]: Epoch 028 - generator training loss: 0.2510, discriminator training loss: 0.0206, validation loss: 0.2782
2024-05-22 20:22:31 [INFO]: Epoch 029 - generator training loss: 0.2518, discriminator training loss: 0.0205, validation loss: 0.2733
2024-05-22 20:24:28 [INFO]: Epoch 030 - generator training loss: 0.2494, discriminator training loss: 0.0203, validation loss: 0.2742
2024-05-22 20:26:28 [INFO]: Epoch 031 - generator training loss: 0.2457, discriminator training loss: 0.0202, validation loss: 0.2788
2024-05-22 20:28:28 [INFO]: Epoch 032 - generator training loss: 0.2464, discriminator training loss: 0.0199, validation loss: 0.2784
2024-05-22 20:30:29 [INFO]: Epoch 033 - generator training loss: 0.2431, discriminator training loss: 0.0197, validation loss: 0.2846
2024-05-22 20:32:29 [INFO]: Epoch 034 - generator training loss: 0.2456, discriminator training loss: 0.0196, validation loss: 0.2768
2024-05-22 20:32:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 20:32:29 [INFO]: Finished training. The best model is from epoch#24.
2024-05-22 20:32:29 [INFO]: Saved the model to saved_results/round_1/USGAN_physionet2012/20240522_T190937/USGAN.pypots
2024-05-22 20:32:44 [INFO]: US-GAN on PhysioNet-2012: MAE=0.2794, MSE=0.2791
2024-05-22 20:33:42 [INFO]: Successfully saved to saved_results/round_1/USGAN_physionet2012/imputation.pkl
2024-05-22 20:33:42 [INFO]: Using the given device: cuda:0
2024-05-22 20:33:42 [INFO]: Model files will be saved to saved_results/round_1/BRITS_physionet2012/20240522_T203342
2024-05-22 20:33:42 [INFO]: Tensorboard file will be saved to saved_results/round_1/BRITS_physionet2012/20240522_T203342/tensorboard
2024-05-22 20:33:42 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-22 20:35:16 [INFO]: Epoch 001 - training loss: 0.9433, validation loss: 0.4271
2024-05-22 20:36:33 [INFO]: Epoch 002 - training loss: 0.7712, validation loss: 0.3795
2024-05-22 20:37:49 [INFO]: Epoch 003 - training loss: 0.7136, validation loss: 0.3544
2024-05-22 20:39:04 [INFO]: Epoch 004 - training loss: 0.6785, validation loss: 0.3427
2024-05-22 20:40:21 [INFO]: Epoch 005 - training loss: 0.6561, validation loss: 0.3332
2024-05-22 20:41:44 [INFO]: Epoch 006 - training loss: 0.6419, validation loss: 0.3321
2024-05-22 20:43:04 [INFO]: Epoch 007 - training loss: 0.6312, validation loss: 0.3278
2024-05-22 20:44:24 [INFO]: Epoch 008 - training loss: 0.6227, validation loss: 0.3289
2024-05-22 20:45:45 [INFO]: Epoch 009 - training loss: 0.6153, validation loss: 0.3260
2024-05-22 20:47:00 [INFO]: Epoch 010 - training loss: 0.6086, validation loss: 0.3262
2024-05-22 20:48:13 [INFO]: Epoch 011 - training loss: 0.6023, validation loss: 0.3233
2024-05-22 20:49:27 [INFO]: Epoch 012 - training loss: 0.5968, validation loss: 0.3271
2024-05-22 20:50:45 [INFO]: Epoch 013 - training loss: 0.5915, validation loss: 0.3293
2024-05-22 20:51:57 [INFO]: Epoch 014 - training loss: 0.5905, validation loss: 0.3283
2024-05-22 20:53:13 [INFO]: Epoch 015 - training loss: 0.5841, validation loss: 0.3274
2024-05-22 20:54:35 [INFO]: Epoch 016 - training loss: 0.5789, validation loss: 0.3270
2024-05-22 20:55:56 [INFO]: Epoch 017 - training loss: 0.5742, validation loss: 0.3332
2024-05-22 20:57:20 [INFO]: Epoch 018 - training loss: 0.5704, validation loss: 0.3353
2024-05-22 20:58:37 [INFO]: Epoch 019 - training loss: 0.5688, validation loss: 0.3351
2024-05-22 21:00:01 [INFO]: Epoch 020 - training loss: 0.5650, validation loss: 0.3370
2024-05-22 21:01:24 [INFO]: Epoch 021 - training loss: 0.5619, validation loss: 0.3381
2024-05-22 21:01:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:01:24 [INFO]: Finished training. The best model is from epoch#11.
2024-05-22 21:01:24 [INFO]: Saved the model to saved_results/round_1/BRITS_physionet2012/20240522_T203342/BRITS.pypots
2024-05-22 21:01:39 [INFO]: BRITS on PhysioNet-2012: MAE=0.2470, MSE=0.3245
2024-05-22 21:02:37 [INFO]: Successfully saved to saved_results/round_1/BRITS_physionet2012/imputation.pkl
2024-05-22 21:02:37 [INFO]: Using the given device: cuda:0
2024-05-22 21:02:37 [INFO]: Model files will be saved to saved_results/round_1/MRNN_physionet2012/20240522_T210237
2024-05-22 21:02:37 [INFO]: Tensorboard file will be saved to saved_results/round_1/MRNN_physionet2012/20240522_T210237/tensorboard
2024-05-22 21:02:37 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-22 21:03:14 [INFO]: Epoch 001 - training loss: 0.8401, validation loss: 0.9051
2024-05-22 21:03:14 [INFO]: Saved the model to saved_results/round_1/MRNN_physionet2012/20240522_T210237/MRNN_epoch1_loss0.9050850649674733.pypots
2024-05-22 21:03:31 [INFO]: Epoch 002 - training loss: 0.5549, validation loss: 0.8860
2024-05-22 21:03:31 [INFO]: Saved the model to saved_results/round_1/MRNN_physionet2012/20240522_T210237/MRNN_epoch2_loss0.8859922548135122.pypots
2024-05-22 21:03:57 [INFO]: Epoch 003 - training loss: 0.5118, validation loss: 0.8801
2024-05-22 21:03:57 [INFO]: Saved the model to saved_results/round_1/MRNN_physionet2012/20240522_T210237/MRNN_epoch3_loss0.8801029562950134.pypots
2024-05-22 21:04:18 [INFO]: Epoch 004 - training loss: 0.4933, validation loss: 0.8831
2024-05-22 21:04:18 [INFO]: Saved the model to saved_results/round_1/MRNN_physionet2012/20240522_T210237/MRNN_epoch4_loss0.8831004530191422.pypots
2024-05-22 21:04:35 [INFO]: Epoch 005 - training loss: 0.4785, validation loss: 0.8857
2024-05-22 21:04:35 [INFO]: Saved the model to saved_results/round_1/MRNN_physionet2012/20240522_T210237/MRNN_epoch5_loss0.885742708047231.pypots
2024-05-22 21:04:52 [INFO]: Epoch 006 - training loss: 0.4706, validation loss: 0.8909
2024-05-22 21:04:52 [INFO]: Saved the model to saved_results/round_1/MRNN_physionet2012/20240522_T210237/MRNN_epoch6_loss0.8908691227436065.pypots
2024-05-22 21:05:09 [INFO]: Epoch 007 - training loss: 0.4630, validation loss: 0.8925
2024-05-22 21:05:09 [INFO]: Saved the model to saved_results/round_1/MRNN_physionet2012/20240522_T210237/MRNN_epoch7_loss0.8924992819627126.pypots
2024-05-22 21:05:28 [INFO]: Epoch 008 - training loss: 0.4614, validation loss: 0.8955
2024-05-22 21:05:28 [INFO]: Saved the model to saved_results/round_1/MRNN_physionet2012/20240522_T210237/MRNN_epoch8_loss0.8955343713363012.pypots
2024-05-22 21:05:49 [INFO]: Epoch 009 - training loss: 0.4466, validation loss: 0.8969
2024-05-22 21:05:49 [INFO]: Saved the model to saved_results/round_1/MRNN_physionet2012/20240522_T210237/MRNN_epoch9_loss0.8969359636306763.pypots
2024-05-22 21:06:12 [INFO]: Epoch 010 - training loss: 0.4518, validation loss: 0.8991
2024-05-22 21:06:12 [INFO]: Saved the model to saved_results/round_1/MRNN_physionet2012/20240522_T210237/MRNN_epoch10_loss0.899138821164767.pypots
2024-05-22 21:06:31 [INFO]: Epoch 011 - training loss: 0.4482, validation loss: 0.9036
2024-05-22 21:06:31 [INFO]: Saved the model to saved_results/round_1/MRNN_physionet2012/20240522_T210237/MRNN_epoch11_loss0.9035513659318288.pypots
2024-05-22 21:06:50 [INFO]: Epoch 012 - training loss: 0.4528, validation loss: 0.9094
2024-05-22 21:06:50 [INFO]: Saved the model to saved_results/round_1/MRNN_physionet2012/20240522_T210237/MRNN_epoch12_loss0.9094387958447139.pypots
2024-05-22 21:07:09 [INFO]: Epoch 013 - training loss: 0.4400, validation loss: 0.9097
2024-05-22 21:07:09 [INFO]: Saved the model to saved_results/round_1/MRNN_physionet2012/20240522_T210237/MRNN_epoch13_loss0.9097352693478267.pypots
2024-05-22 21:07:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:07:09 [INFO]: Finished training. The best model is from epoch#3.
2024-05-22 21:07:09 [INFO]: Saved the model to saved_results/round_1/MRNN_physionet2012/20240522_T210237/MRNN.pypots
2024-05-22 21:07:16 [INFO]: MRNN on PhysioNet-2012: MAE=0.6835, MSE=0.8936
2024-05-22 21:07:41 [INFO]: Successfully saved to saved_results/round_1/MRNN_physionet2012/imputation.pkl
2024-05-22 21:07:41 [INFO]: Using the given device: cpu
2024-05-22 21:07:41 [INFO]: LOCF on PhysioNet-2012: MAE=0.4110, MSE=0.5688
2024-05-22 21:07:42 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_physionet2012".
2024-05-22 21:07:42 [INFO]: Successfully saved to saved_results/round_1/LOCF_physionet2012/imputation.pkl
2024-05-22 21:07:42 [INFO]: Median on PhysioNet-2012: MAE=0.6855, MSE=0.9913
2024-05-22 21:07:43 [INFO]: Successfully created the given path "saved_results/round_1/Median_physionet2012".
2024-05-22 21:07:43 [INFO]: Successfully saved to saved_results/round_1/Median_physionet2012/imputation.pkl
2024-05-22 21:07:43 [INFO]: Mean on PhysioNet-2012: MAE=0.7017, MSE=0.9536
2024-05-22 21:07:43 [INFO]: Successfully created the given path "saved_results/round_1/Mean_physionet2012".
2024-05-22 21:07:43 [INFO]: Successfully saved to saved_results/round_1/Mean_physionet2012/imputation.pkl
2024-05-22 21:07:43 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-22 21:07:43 [INFO]: Using the given device: cuda:0
2024-05-22 21:07:43 [INFO]: Model files will be saved to saved_results/round_2/SAITS_physionet2012/20240522_T210743
2024-05-22 21:07:43 [INFO]: Tensorboard file will be saved to saved_results/round_2/SAITS_physionet2012/20240522_T210743/tensorboard
2024-05-22 21:07:43 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-22 21:07:56 [INFO]: Epoch 001 - training loss: 0.7603, validation loss: 0.3958
2024-05-22 21:08:10 [INFO]: Epoch 002 - training loss: 0.4807, validation loss: 0.3449
2024-05-22 21:08:23 [INFO]: Epoch 003 - training loss: 0.4142, validation loss: 0.3192
2024-05-22 21:08:36 [INFO]: Epoch 004 - training loss: 0.3733, validation loss: 0.2978
2024-05-22 21:08:49 [INFO]: Epoch 005 - training loss: 0.3439, validation loss: 0.2826
2024-05-22 21:09:02 [INFO]: Epoch 006 - training loss: 0.3260, validation loss: 0.2698
2024-05-22 21:09:14 [INFO]: Epoch 007 - training loss: 0.3121, validation loss: 0.2609
2024-05-22 21:09:25 [INFO]: Epoch 008 - training loss: 0.2993, validation loss: 0.2592
2024-05-22 21:09:37 [INFO]: Epoch 009 - training loss: 0.2924, validation loss: 0.2560
2024-05-22 21:09:50 [INFO]: Epoch 010 - training loss: 0.2838, validation loss: 0.2529
2024-05-22 21:10:03 [INFO]: Epoch 011 - training loss: 0.2806, validation loss: 0.2436
2024-05-22 21:10:17 [INFO]: Epoch 012 - training loss: 0.2758, validation loss: 0.2477
2024-05-22 21:10:29 [INFO]: Epoch 013 - training loss: 0.2695, validation loss: 0.2531
2024-05-22 21:10:42 [INFO]: Epoch 014 - training loss: 0.2674, validation loss: 0.2541
2024-05-22 21:10:55 [INFO]: Epoch 015 - training loss: 0.2664, validation loss: 0.2526
2024-05-22 21:11:08 [INFO]: Epoch 016 - training loss: 0.2633, validation loss: 0.2464
2024-05-22 21:11:21 [INFO]: Epoch 017 - training loss: 0.2604, validation loss: 0.2459
2024-05-22 21:11:34 [INFO]: Epoch 018 - training loss: 0.2580, validation loss: 0.2461
2024-05-22 21:11:47 [INFO]: Epoch 019 - training loss: 0.2563, validation loss: 0.2362
2024-05-22 21:12:01 [INFO]: Epoch 020 - training loss: 0.2545, validation loss: 0.2392
2024-05-22 21:12:14 [INFO]: Epoch 021 - training loss: 0.2531, validation loss: 0.2329
2024-05-22 21:12:28 [INFO]: Epoch 022 - training loss: 0.2514, validation loss: 0.2402
2024-05-22 21:12:41 [INFO]: Epoch 023 - training loss: 0.2506, validation loss: 0.2366
2024-05-22 21:12:55 [INFO]: Epoch 024 - training loss: 0.2497, validation loss: 0.2410
2024-05-22 21:13:08 [INFO]: Epoch 025 - training loss: 0.2488, validation loss: 0.2386
2024-05-22 21:13:21 [INFO]: Epoch 026 - training loss: 0.2484, validation loss: 0.2308
2024-05-22 21:13:35 [INFO]: Epoch 027 - training loss: 0.2456, validation loss: 0.2370
2024-05-22 21:13:48 [INFO]: Epoch 028 - training loss: 0.2453, validation loss: 0.2383
2024-05-22 21:14:01 [INFO]: Epoch 029 - training loss: 0.2453, validation loss: 0.2348
2024-05-22 21:14:15 [INFO]: Epoch 030 - training loss: 0.2436, validation loss: 0.2375
2024-05-22 21:14:28 [INFO]: Epoch 031 - training loss: 0.2428, validation loss: 0.2317
2024-05-22 21:14:41 [INFO]: Epoch 032 - training loss: 0.2410, validation loss: 0.2317
2024-05-22 21:14:54 [INFO]: Epoch 033 - training loss: 0.2417, validation loss: 0.2373
2024-05-22 21:15:07 [INFO]: Epoch 034 - training loss: 0.2404, validation loss: 0.2388
2024-05-22 21:15:20 [INFO]: Epoch 035 - training loss: 0.2386, validation loss: 0.2225
2024-05-22 21:15:33 [INFO]: Epoch 036 - training loss: 0.2378, validation loss: 0.2315
2024-05-22 21:15:46 [INFO]: Epoch 037 - training loss: 0.2382, validation loss: 0.2223
2024-05-22 21:15:57 [INFO]: Epoch 038 - training loss: 0.2370, validation loss: 0.2320
2024-05-22 21:16:09 [INFO]: Epoch 039 - training loss: 0.2368, validation loss: 0.2378
2024-05-22 21:16:22 [INFO]: Epoch 040 - training loss: 0.2353, validation loss: 0.2318
2024-05-22 21:16:35 [INFO]: Epoch 041 - training loss: 0.2353, validation loss: 0.2317
2024-05-22 21:16:48 [INFO]: Epoch 042 - training loss: 0.2364, validation loss: 0.2367
2024-05-22 21:17:01 [INFO]: Epoch 043 - training loss: 0.2359, validation loss: 0.2288
2024-05-22 21:17:14 [INFO]: Epoch 044 - training loss: 0.2350, validation loss: 0.2292
2024-05-22 21:17:27 [INFO]: Epoch 045 - training loss: 0.2337, validation loss: 0.2362
2024-05-22 21:17:36 [INFO]: Epoch 046 - training loss: 0.2322, validation loss: 0.2304
2024-05-22 21:17:49 [INFO]: Epoch 047 - training loss: 0.2324, validation loss: 0.2311
2024-05-22 21:17:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:17:49 [INFO]: Finished training. The best model is from epoch#37.
2024-05-22 21:17:49 [INFO]: Saved the model to saved_results/round_2/SAITS_physionet2012/20240522_T210743/SAITS.pypots
2024-05-22 21:17:50 [INFO]: SAITS on PhysioNet-2012: MAE=0.1983, MSE=0.2155
2024-05-22 21:17:52 [INFO]: Successfully saved to saved_results/round_2/SAITS_physionet2012/imputation.pkl
2024-05-22 21:17:52 [INFO]: Using the given device: cuda:0
2024-05-22 21:17:52 [INFO]: Model files will be saved to saved_results/round_2/Transformer_physionet2012/20240522_T211752
2024-05-22 21:17:52 [INFO]: Tensorboard file will be saved to saved_results/round_2/Transformer_physionet2012/20240522_T211752/tensorboard
2024-05-22 21:17:52 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-22 21:18:00 [INFO]: Epoch 001 - training loss: 0.8741, validation loss: 0.4388
2024-05-22 21:18:07 [INFO]: Epoch 002 - training loss: 0.5475, validation loss: 0.3920
2024-05-22 21:18:15 [INFO]: Epoch 003 - training loss: 0.4776, validation loss: 0.3789
2024-05-22 21:18:22 [INFO]: Epoch 004 - training loss: 0.4366, validation loss: 0.3572
2024-05-22 21:18:29 [INFO]: Epoch 005 - training loss: 0.4041, validation loss: 0.3392
2024-05-22 21:18:36 [INFO]: Epoch 006 - training loss: 0.3847, validation loss: 0.3312
2024-05-22 21:18:44 [INFO]: Epoch 007 - training loss: 0.3693, validation loss: 0.3190
2024-05-22 21:18:51 [INFO]: Epoch 008 - training loss: 0.3566, validation loss: 0.3118
2024-05-22 21:18:58 [INFO]: Epoch 009 - training loss: 0.3463, validation loss: 0.3020
2024-05-22 21:19:05 [INFO]: Epoch 010 - training loss: 0.3362, validation loss: 0.2921
2024-05-22 21:19:13 [INFO]: Epoch 011 - training loss: 0.3307, validation loss: 0.2914
2024-05-22 21:19:20 [INFO]: Epoch 012 - training loss: 0.3240, validation loss: 0.2864
2024-05-22 21:19:27 [INFO]: Epoch 013 - training loss: 0.3177, validation loss: 0.2816
2024-05-22 21:19:34 [INFO]: Epoch 014 - training loss: 0.3148, validation loss: 0.2871
2024-05-22 21:19:41 [INFO]: Epoch 015 - training loss: 0.3091, validation loss: 0.2785
2024-05-22 21:19:48 [INFO]: Epoch 016 - training loss: 0.3057, validation loss: 0.2750
2024-05-22 21:19:54 [INFO]: Epoch 017 - training loss: 0.3014, validation loss: 0.2718
2024-05-22 21:20:00 [INFO]: Epoch 018 - training loss: 0.2986, validation loss: 0.2746
2024-05-22 21:20:06 [INFO]: Epoch 019 - training loss: 0.2961, validation loss: 0.2652
2024-05-22 21:20:13 [INFO]: Epoch 020 - training loss: 0.2945, validation loss: 0.2589
2024-05-22 21:20:20 [INFO]: Epoch 021 - training loss: 0.2907, validation loss: 0.2612
2024-05-22 21:20:26 [INFO]: Epoch 022 - training loss: 0.2860, validation loss: 0.2653
2024-05-22 21:20:32 [INFO]: Epoch 023 - training loss: 0.2840, validation loss: 0.2533
2024-05-22 21:20:39 [INFO]: Epoch 024 - training loss: 0.2831, validation loss: 0.2538
2024-05-22 21:20:46 [INFO]: Epoch 025 - training loss: 0.2815, validation loss: 0.2506
2024-05-22 21:20:53 [INFO]: Epoch 026 - training loss: 0.2794, validation loss: 0.2559
2024-05-22 21:21:01 [INFO]: Epoch 027 - training loss: 0.2774, validation loss: 0.2564
2024-05-22 21:21:09 [INFO]: Epoch 028 - training loss: 0.2777, validation loss: 0.2471
2024-05-22 21:21:16 [INFO]: Epoch 029 - training loss: 0.2740, validation loss: 0.2449
2024-05-22 21:21:24 [INFO]: Epoch 030 - training loss: 0.2740, validation loss: 0.2516
2024-05-22 21:21:31 [INFO]: Epoch 031 - training loss: 0.2732, validation loss: 0.2491
2024-05-22 21:21:38 [INFO]: Epoch 032 - training loss: 0.2702, validation loss: 0.2484
2024-05-22 21:21:46 [INFO]: Epoch 033 - training loss: 0.2693, validation loss: 0.2423
2024-05-22 21:21:53 [INFO]: Epoch 034 - training loss: 0.2682, validation loss: 0.2437
2024-05-22 21:22:00 [INFO]: Epoch 035 - training loss: 0.2673, validation loss: 0.2455
2024-05-22 21:22:08 [INFO]: Epoch 036 - training loss: 0.2667, validation loss: 0.2466
2024-05-22 21:22:15 [INFO]: Epoch 037 - training loss: 0.2658, validation loss: 0.2424
2024-05-22 21:22:23 [INFO]: Epoch 038 - training loss: 0.2635, validation loss: 0.2372
2024-05-22 21:22:31 [INFO]: Epoch 039 - training loss: 0.2634, validation loss: 0.2445
2024-05-22 21:22:38 [INFO]: Epoch 040 - training loss: 0.2625, validation loss: 0.2426
2024-05-22 21:22:45 [INFO]: Epoch 041 - training loss: 0.2606, validation loss: 0.2421
2024-05-22 21:22:53 [INFO]: Epoch 042 - training loss: 0.2596, validation loss: 0.2434
2024-05-22 21:23:00 [INFO]: Epoch 043 - training loss: 0.2598, validation loss: 0.2336
2024-05-22 21:23:07 [INFO]: Epoch 044 - training loss: 0.2596, validation loss: 0.2370
2024-05-22 21:23:14 [INFO]: Epoch 045 - training loss: 0.2589, validation loss: 0.2370
2024-05-22 21:23:21 [INFO]: Epoch 046 - training loss: 0.2576, validation loss: 0.2425
2024-05-22 21:23:28 [INFO]: Epoch 047 - training loss: 0.2578, validation loss: 0.2443
2024-05-22 21:23:36 [INFO]: Epoch 048 - training loss: 0.2561, validation loss: 0.2340
2024-05-22 21:23:43 [INFO]: Epoch 049 - training loss: 0.2559, validation loss: 0.2351
2024-05-22 21:23:51 [INFO]: Epoch 050 - training loss: 0.2557, validation loss: 0.2323
2024-05-22 21:23:58 [INFO]: Epoch 051 - training loss: 0.2542, validation loss: 0.2321
2024-05-22 21:24:05 [INFO]: Epoch 052 - training loss: 0.2558, validation loss: 0.2284
2024-05-22 21:24:12 [INFO]: Epoch 053 - training loss: 0.2553, validation loss: 0.2381
2024-05-22 21:24:19 [INFO]: Epoch 054 - training loss: 0.2521, validation loss: 0.2305
2024-05-22 21:24:27 [INFO]: Epoch 055 - training loss: 0.2532, validation loss: 0.2271
2024-05-22 21:24:34 [INFO]: Epoch 056 - training loss: 0.2529, validation loss: 0.2326
2024-05-22 21:24:41 [INFO]: Epoch 057 - training loss: 0.2517, validation loss: 0.2379
2024-05-22 21:24:48 [INFO]: Epoch 058 - training loss: 0.2510, validation loss: 0.2334
2024-05-22 21:24:56 [INFO]: Epoch 059 - training loss: 0.2520, validation loss: 0.2337
2024-05-22 21:25:03 [INFO]: Epoch 060 - training loss: 0.2504, validation loss: 0.2343
2024-05-22 21:25:10 [INFO]: Epoch 061 - training loss: 0.2499, validation loss: 0.2288
2024-05-22 21:25:17 [INFO]: Epoch 062 - training loss: 0.2492, validation loss: 0.2390
2024-05-22 21:25:24 [INFO]: Epoch 063 - training loss: 0.2497, validation loss: 0.2323
2024-05-22 21:25:31 [INFO]: Epoch 064 - training loss: 0.2483, validation loss: 0.2300
2024-05-22 21:25:39 [INFO]: Epoch 065 - training loss: 0.2486, validation loss: 0.2347
2024-05-22 21:25:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:25:39 [INFO]: Finished training. The best model is from epoch#55.
2024-05-22 21:25:39 [INFO]: Saved the model to saved_results/round_2/Transformer_physionet2012/20240522_T211752/Transformer.pypots
2024-05-22 21:25:39 [INFO]: Transformer on PhysioNet-2012: MAE=0.2095, MSE=0.2248
2024-05-22 21:25:40 [INFO]: Successfully saved to saved_results/round_2/Transformer_physionet2012/imputation.pkl
2024-05-22 21:25:40 [INFO]: Using the given device: cuda:0
2024-05-22 21:25:40 [INFO]: Model files will be saved to saved_results/round_2/TimesNet_physionet2012/20240522_T212540
2024-05-22 21:25:40 [INFO]: Tensorboard file will be saved to saved_results/round_2/TimesNet_physionet2012/20240522_T212540/tensorboard
2024-05-22 21:25:41 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-22 21:25:44 [INFO]: Epoch 001 - training loss: 0.3799, validation loss: 0.3233
2024-05-22 21:25:48 [INFO]: Epoch 002 - training loss: 0.3788, validation loss: 0.3488
2024-05-22 21:25:51 [INFO]: Epoch 003 - training loss: 0.5530, validation loss: 0.3514
2024-05-22 21:25:55 [INFO]: Epoch 004 - training loss: 0.4472, validation loss: 0.3580
2024-05-22 21:25:59 [INFO]: Epoch 005 - training loss: 1.4634, validation loss: 0.3820
2024-05-22 21:26:02 [INFO]: Epoch 006 - training loss: 0.5169, validation loss: 0.3387
2024-05-22 21:26:06 [INFO]: Epoch 007 - training loss: 0.4301, validation loss: 0.3430
2024-05-22 21:26:10 [INFO]: Epoch 008 - training loss: 0.4125, validation loss: 0.3313
2024-05-22 21:26:13 [INFO]: Epoch 009 - training loss: 0.5178, validation loss: 0.3228
2024-05-22 21:26:17 [INFO]: Epoch 010 - training loss: 0.4401, validation loss: 0.3393
2024-05-22 21:26:20 [INFO]: Epoch 011 - training loss: 0.3927, validation loss: 0.3155
2024-05-22 21:26:24 [INFO]: Epoch 012 - training loss: 0.3360, validation loss: 0.3083
2024-05-22 21:26:28 [INFO]: Epoch 013 - training loss: 0.4254, validation loss: 0.3259
2024-05-22 21:26:31 [INFO]: Epoch 014 - training loss: 0.4477, validation loss: 0.3098
2024-05-22 21:26:35 [INFO]: Epoch 015 - training loss: 0.3292, validation loss: 0.3063
2024-05-22 21:26:39 [INFO]: Epoch 016 - training loss: 0.3279, validation loss: 0.3032
2024-05-22 21:26:42 [INFO]: Epoch 017 - training loss: 0.3778, validation loss: 0.3076
2024-05-22 21:26:46 [INFO]: Epoch 018 - training loss: 0.3220, validation loss: 0.2994
2024-05-22 21:26:50 [INFO]: Epoch 019 - training loss: 0.3649, validation loss: 0.2992
2024-05-22 21:26:54 [INFO]: Epoch 020 - training loss: 0.3110, validation loss: 0.2988
2024-05-22 21:26:57 [INFO]: Epoch 021 - training loss: 0.3224, validation loss: 0.2978
2024-05-22 21:27:01 [INFO]: Epoch 022 - training loss: 0.3131, validation loss: 0.2935
2024-05-22 21:27:05 [INFO]: Epoch 023 - training loss: 0.3921, validation loss: 0.2979
2024-05-22 21:27:08 [INFO]: Epoch 024 - training loss: 0.3964, validation loss: 0.2918
2024-05-22 21:27:12 [INFO]: Epoch 025 - training loss: 0.3411, validation loss: 0.2865
2024-05-22 21:27:15 [INFO]: Epoch 026 - training loss: 0.3165, validation loss: 0.2886
2024-05-22 21:27:19 [INFO]: Epoch 027 - training loss: 0.3053, validation loss: 0.2867
2024-05-22 21:27:23 [INFO]: Epoch 028 - training loss: 0.2950, validation loss: 0.2829
2024-05-22 21:27:27 [INFO]: Epoch 029 - training loss: 0.3622, validation loss: 0.2871
2024-05-22 21:27:30 [INFO]: Epoch 030 - training loss: 0.2981, validation loss: 0.2850
2024-05-22 21:27:34 [INFO]: Epoch 031 - training loss: 0.3031, validation loss: 0.2817
2024-05-22 21:27:37 [INFO]: Epoch 032 - training loss: 0.3711, validation loss: 0.2827
2024-05-22 21:27:41 [INFO]: Epoch 033 - training loss: 0.3183, validation loss: 0.2794
2024-05-22 21:27:44 [INFO]: Epoch 034 - training loss: 0.2999, validation loss: 0.2785
2024-05-22 21:27:48 [INFO]: Epoch 035 - training loss: 0.3412, validation loss: 0.2805
2024-05-22 21:27:52 [INFO]: Epoch 036 - training loss: 0.3142, validation loss: 0.2782
2024-05-22 21:27:55 [INFO]: Epoch 037 - training loss: 0.3053, validation loss: 0.2827
2024-05-22 21:27:59 [INFO]: Epoch 038 - training loss: 0.3096, validation loss: 0.2755
2024-05-22 21:28:03 [INFO]: Epoch 039 - training loss: 0.3324, validation loss: 0.2737
2024-05-22 21:28:07 [INFO]: Epoch 040 - training loss: 0.2831, validation loss: 0.2734
2024-05-22 21:28:10 [INFO]: Epoch 041 - training loss: 0.2931, validation loss: 0.2746
2024-05-22 21:28:14 [INFO]: Epoch 042 - training loss: 0.2977, validation loss: 0.2729
2024-05-22 21:28:18 [INFO]: Epoch 043 - training loss: 0.2804, validation loss: 0.2722
2024-05-22 21:28:22 [INFO]: Epoch 044 - training loss: 0.3835, validation loss: 0.2756
2024-05-22 21:28:26 [INFO]: Epoch 045 - training loss: 0.2952, validation loss: 0.2752
2024-05-22 21:28:30 [INFO]: Epoch 046 - training loss: 0.2897, validation loss: 0.2723
2024-05-22 21:28:33 [INFO]: Epoch 047 - training loss: 0.3753, validation loss: 0.2717
2024-05-22 21:28:37 [INFO]: Epoch 048 - training loss: 0.4121, validation loss: 0.2725
2024-05-22 21:28:41 [INFO]: Epoch 049 - training loss: 0.3634, validation loss: 0.2705
2024-05-22 21:28:46 [INFO]: Epoch 050 - training loss: 0.2968, validation loss: 0.2714
2024-05-22 21:28:50 [INFO]: Epoch 051 - training loss: 0.2836, validation loss: 0.2755
2024-05-22 21:28:54 [INFO]: Epoch 052 - training loss: 0.3313, validation loss: 0.2703
2024-05-22 21:28:58 [INFO]: Epoch 053 - training loss: 0.2891, validation loss: 0.2846
2024-05-22 21:29:02 [INFO]: Epoch 054 - training loss: 0.3767, validation loss: 0.2738
2024-05-22 21:29:06 [INFO]: Epoch 055 - training loss: 0.2907, validation loss: 0.2709
2024-05-22 21:29:10 [INFO]: Epoch 056 - training loss: 0.2840, validation loss: 0.2745
2024-05-22 21:29:13 [INFO]: Epoch 057 - training loss: 0.3719, validation loss: 0.2700
2024-05-22 21:29:17 [INFO]: Epoch 058 - training loss: 0.3432, validation loss: 0.2725
2024-05-22 21:29:20 [INFO]: Epoch 059 - training loss: 0.3862, validation loss: 0.2689
2024-05-22 21:29:24 [INFO]: Epoch 060 - training loss: 0.4077, validation loss: 0.2650
2024-05-22 21:29:28 [INFO]: Epoch 061 - training loss: 0.3630, validation loss: 0.2673
2024-05-22 21:29:31 [INFO]: Epoch 062 - training loss: 0.3154, validation loss: 0.2732
2024-05-22 21:29:35 [INFO]: Epoch 063 - training loss: 0.3749, validation loss: 0.2670
2024-05-22 21:29:38 [INFO]: Epoch 064 - training loss: 0.3364, validation loss: 0.2746
2024-05-22 21:29:42 [INFO]: Epoch 065 - training loss: 0.2997, validation loss: 0.2683
2024-05-22 21:29:46 [INFO]: Epoch 066 - training loss: 0.2851, validation loss: 0.2664
2024-05-22 21:29:50 [INFO]: Epoch 067 - training loss: 0.2826, validation loss: 0.2642
2024-05-22 21:29:54 [INFO]: Epoch 068 - training loss: 0.3649, validation loss: 0.2647
2024-05-22 21:29:58 [INFO]: Epoch 069 - training loss: 0.2911, validation loss: 0.2651
2024-05-22 21:30:02 [INFO]: Epoch 070 - training loss: 0.3147, validation loss: 0.3204
2024-05-22 21:30:06 [INFO]: Epoch 071 - training loss: 0.3102, validation loss: 0.2710
2024-05-22 21:30:10 [INFO]: Epoch 072 - training loss: 0.3999, validation loss: 0.2661
2024-05-22 21:30:13 [INFO]: Epoch 073 - training loss: 0.2998, validation loss: 0.2656
2024-05-22 21:30:17 [INFO]: Epoch 074 - training loss: 0.2943, validation loss: 0.2670
2024-05-22 21:30:21 [INFO]: Epoch 075 - training loss: 0.2891, validation loss: 0.2631
2024-05-22 21:30:25 [INFO]: Epoch 076 - training loss: 0.2786, validation loss: 0.2625
2024-05-22 21:30:29 [INFO]: Epoch 077 - training loss: 0.3270, validation loss: 0.2606
2024-05-22 21:30:33 [INFO]: Epoch 078 - training loss: 0.2734, validation loss: 0.2618
2024-05-22 21:30:36 [INFO]: Epoch 079 - training loss: 0.2851, validation loss: 0.2686
2024-05-22 21:30:40 [INFO]: Epoch 080 - training loss: 0.2705, validation loss: 0.2634
2024-05-22 21:30:44 [INFO]: Epoch 081 - training loss: 0.2825, validation loss: 0.2639
2024-05-22 21:30:47 [INFO]: Epoch 082 - training loss: 0.3421, validation loss: 0.2612
2024-05-22 21:30:52 [INFO]: Epoch 083 - training loss: 0.2706, validation loss: 0.2617
2024-05-22 21:30:56 [INFO]: Epoch 084 - training loss: 0.2685, validation loss: 0.2604
2024-05-22 21:31:00 [INFO]: Epoch 085 - training loss: 0.2850, validation loss: 0.2637
2024-05-22 21:31:04 [INFO]: Epoch 086 - training loss: 0.2719, validation loss: 0.2623
2024-05-22 21:31:07 [INFO]: Epoch 087 - training loss: 0.3465, validation loss: 0.2628
2024-05-22 21:31:11 [INFO]: Epoch 088 - training loss: 0.2847, validation loss: 0.2614
2024-05-22 21:31:15 [INFO]: Epoch 089 - training loss: 0.3131, validation loss: 0.2625
2024-05-22 21:31:18 [INFO]: Epoch 090 - training loss: 0.3254, validation loss: 0.2650
2024-05-22 21:31:23 [INFO]: Epoch 091 - training loss: 0.2784, validation loss: 0.2647
2024-05-22 21:31:26 [INFO]: Epoch 092 - training loss: 0.2776, validation loss: 0.2637
2024-05-22 21:31:30 [INFO]: Epoch 093 - training loss: 0.2719, validation loss: 0.2642
2024-05-22 21:31:34 [INFO]: Epoch 094 - training loss: 0.2730, validation loss: 0.2620
2024-05-22 21:31:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:31:34 [INFO]: Finished training. The best model is from epoch#84.
2024-05-22 21:31:34 [INFO]: Saved the model to saved_results/round_2/TimesNet_physionet2012/20240522_T212540/TimesNet.pypots
2024-05-22 21:31:34 [INFO]: TimesNet on PhysioNet-2012: MAE=0.2583, MSE=0.2637
2024-05-22 21:31:35 [INFO]: Successfully saved to saved_results/round_2/TimesNet_physionet2012/imputation.pkl
2024-05-22 21:31:35 [INFO]: Using the given device: cuda:0
2024-05-22 21:31:35 [INFO]: Model files will be saved to saved_results/round_2/CSDI_physionet2012/20240522_T213135
2024-05-22 21:31:35 [INFO]: Tensorboard file will be saved to saved_results/round_2/CSDI_physionet2012/20240522_T213135/tensorboard
2024-05-22 21:31:35 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-22 21:33:57 [INFO]: Epoch 001 - training loss: 0.3478, validation loss: 0.2554
2024-05-22 21:33:57 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch1_loss0.25544078821937244.pypots
2024-05-22 21:36:20 [INFO]: Epoch 002 - training loss: 0.2622, validation loss: 0.2153
2024-05-22 21:36:20 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch2_loss0.21534925177693368.pypots
2024-05-22 21:38:43 [INFO]: Epoch 003 - training loss: 0.2502, validation loss: 0.2026
2024-05-22 21:38:43 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch3_loss0.20257757604122162.pypots
2024-05-22 21:41:06 [INFO]: Epoch 004 - training loss: 0.2368, validation loss: 0.2022
2024-05-22 21:41:06 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch4_loss0.2022396499911944.pypots
2024-05-22 21:43:29 [INFO]: Epoch 005 - training loss: 0.2360, validation loss: 0.2010
2024-05-22 21:43:29 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch5_loss0.20102530270814895.pypots
2024-05-22 21:45:52 [INFO]: Epoch 006 - training loss: 0.2392, validation loss: 0.1976
2024-05-22 21:45:52 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch6_loss0.19758516401052476.pypots
2024-05-22 21:48:15 [INFO]: Epoch 007 - training loss: 0.2285, validation loss: 0.1898
2024-05-22 21:48:15 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch7_loss0.18979633823037148.pypots
2024-05-22 21:50:38 [INFO]: Epoch 008 - training loss: 0.2379, validation loss: 0.1872
2024-05-22 21:50:38 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch8_loss0.18716963678598403.pypots
2024-05-22 21:53:01 [INFO]: Epoch 009 - training loss: 0.2271, validation loss: 0.1843
2024-05-22 21:53:01 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch9_loss0.1842562052110831.pypots
2024-05-22 21:55:24 [INFO]: Epoch 010 - training loss: 0.2311, validation loss: 0.1814
2024-05-22 21:55:24 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch10_loss0.18142269601424535.pypots
2024-05-22 21:57:47 [INFO]: Epoch 011 - training loss: 0.2262, validation loss: 0.1831
2024-05-22 21:57:47 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch11_loss0.1830779194831848.pypots
2024-05-22 22:00:09 [INFO]: Epoch 012 - training loss: 0.2226, validation loss: 0.1832
2024-05-22 22:00:09 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch12_loss0.18318190276622773.pypots
2024-05-22 22:02:32 [INFO]: Epoch 013 - training loss: 0.2199, validation loss: 0.1818
2024-05-22 22:02:32 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch13_loss0.18178820858399072.pypots
2024-05-22 22:04:55 [INFO]: Epoch 014 - training loss: 0.2243, validation loss: 0.1799
2024-05-22 22:04:55 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch14_loss0.1798832006752491.pypots
2024-05-22 22:07:18 [INFO]: Epoch 015 - training loss: 0.2217, validation loss: 0.1797
2024-05-22 22:07:18 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch15_loss0.17971532170971236.pypots
2024-05-22 22:09:41 [INFO]: Epoch 016 - training loss: 0.2237, validation loss: 0.1794
2024-05-22 22:09:41 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch16_loss0.17939132824540138.pypots
2024-05-22 22:12:04 [INFO]: Epoch 017 - training loss: 0.2206, validation loss: 0.1764
2024-05-22 22:12:04 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch17_loss0.1763614480694135.pypots
2024-05-22 22:14:27 [INFO]: Epoch 018 - training loss: 0.2230, validation loss: 0.1750
2024-05-22 22:14:27 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch18_loss0.17503555516401928.pypots
2024-05-22 22:16:50 [INFO]: Epoch 019 - training loss: 0.2125, validation loss: 0.1779
2024-05-22 22:16:50 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch19_loss0.17792467350761096.pypots
2024-05-22 22:19:13 [INFO]: Epoch 020 - training loss: 0.2151, validation loss: 0.1763
2024-05-22 22:19:13 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch20_loss0.17627394596735638.pypots
2024-05-22 22:21:36 [INFO]: Epoch 021 - training loss: 0.2135, validation loss: 0.1769
2024-05-22 22:21:36 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch21_loss0.17689487263560294.pypots
2024-05-22 22:23:59 [INFO]: Epoch 022 - training loss: 0.2160, validation loss: 0.1773
2024-05-22 22:23:59 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch22_loss0.17725738535324734.pypots
2024-05-22 22:26:22 [INFO]: Epoch 023 - training loss: 0.2206, validation loss: 0.1731
2024-05-22 22:26:22 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch23_loss0.17313986793160438.pypots
2024-05-22 22:28:45 [INFO]: Epoch 024 - training loss: 0.2204, validation loss: 0.1750
2024-05-22 22:28:45 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch24_loss0.1749913603067398.pypots
2024-05-22 22:31:08 [INFO]: Epoch 025 - training loss: 0.2128, validation loss: 0.1742
2024-05-22 22:31:08 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch25_loss0.17424357583125433.pypots
2024-05-22 22:33:31 [INFO]: Epoch 026 - training loss: 0.2218, validation loss: 0.1736
2024-05-22 22:33:31 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch26_loss0.17356899107495943.pypots
2024-05-22 22:35:54 [INFO]: Epoch 027 - training loss: 0.2158, validation loss: 0.1721
2024-05-22 22:35:54 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch27_loss0.17207284222046534.pypots
2024-05-22 22:38:17 [INFO]: Epoch 028 - training loss: 0.2136, validation loss: 0.1734
2024-05-22 22:38:17 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch28_loss0.17335274840394657.pypots
2024-05-22 22:40:40 [INFO]: Epoch 029 - training loss: 0.2161, validation loss: 0.1737
2024-05-22 22:40:40 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch29_loss0.17369485994180042.pypots
2024-05-22 22:43:03 [INFO]: Epoch 030 - training loss: 0.2162, validation loss: 0.1730
2024-05-22 22:43:03 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch30_loss0.17301846370100976.pypots
2024-05-22 22:45:26 [INFO]: Epoch 031 - training loss: 0.2183, validation loss: 0.1739
2024-05-22 22:45:26 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch31_loss0.17386575266718865.pypots
2024-05-22 22:47:49 [INFO]: Epoch 032 - training loss: 0.2085, validation loss: 0.1702
2024-05-22 22:47:49 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch32_loss0.17016707807779313.pypots
2024-05-22 22:50:12 [INFO]: Epoch 033 - training loss: 0.2142, validation loss: 0.1710
2024-05-22 22:50:12 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch33_loss0.17098895733555158.pypots
2024-05-22 22:52:35 [INFO]: Epoch 034 - training loss: 0.2053, validation loss: 0.1727
2024-05-22 22:52:35 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch34_loss0.17270865539709726.pypots
2024-05-22 22:54:58 [INFO]: Epoch 035 - training loss: 0.2144, validation loss: 0.1740
2024-05-22 22:54:58 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch35_loss0.1739628126223882.pypots
2024-05-22 22:57:21 [INFO]: Epoch 036 - training loss: 0.2144, validation loss: 0.1724
2024-05-22 22:57:21 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch36_loss0.17240408112605413.pypots
2024-05-22 22:59:44 [INFO]: Epoch 037 - training loss: 0.2122, validation loss: 0.1709
2024-05-22 22:59:44 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch37_loss0.17089514310161272.pypots
2024-05-22 23:02:07 [INFO]: Epoch 038 - training loss: 0.2085, validation loss: 0.1716
2024-05-22 23:02:07 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch38_loss0.17163542409737906.pypots
2024-05-22 23:04:30 [INFO]: Epoch 039 - training loss: 0.2038, validation loss: 0.1678
2024-05-22 23:04:30 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch39_loss0.1678394156197707.pypots
2024-05-22 23:06:53 [INFO]: Epoch 040 - training loss: 0.2034, validation loss: 0.1684
2024-05-22 23:06:53 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch40_loss0.16843648602565128.pypots
2024-05-22 23:09:16 [INFO]: Epoch 041 - training loss: 0.2074, validation loss: 0.1707
2024-05-22 23:09:16 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch41_loss0.17066960806647938.pypots
2024-05-22 23:11:39 [INFO]: Epoch 042 - training loss: 0.2130, validation loss: 0.1672
2024-05-22 23:11:39 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch42_loss0.1672006162504355.pypots
2024-05-22 23:14:02 [INFO]: Epoch 043 - training loss: 0.2126, validation loss: 0.1692
2024-05-22 23:14:02 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch43_loss0.1691613309085369.pypots
2024-05-22 23:16:25 [INFO]: Epoch 044 - training loss: 0.2075, validation loss: 0.1680
2024-05-22 23:16:25 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch44_loss0.16803132941325505.pypots
2024-05-22 23:18:48 [INFO]: Epoch 045 - training loss: 0.2070, validation loss: 0.1700
2024-05-22 23:18:48 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch45_loss0.1700247657795747.pypots
2024-05-22 23:21:11 [INFO]: Epoch 046 - training loss: 0.2128, validation loss: 0.1659
2024-05-22 23:21:11 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch46_loss0.16594912161429723.pypots
2024-05-22 23:23:34 [INFO]: Epoch 047 - training loss: 0.2099, validation loss: 0.1691
2024-05-22 23:23:34 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch47_loss0.16912603427966436.pypots
2024-05-22 23:25:57 [INFO]: Epoch 048 - training loss: 0.2106, validation loss: 0.1671
2024-05-22 23:25:57 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch48_loss0.16706434761484465.pypots
2024-05-22 23:28:20 [INFO]: Epoch 049 - training loss: 0.2119, validation loss: 0.1660
2024-05-22 23:28:20 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch49_loss0.16597069054841995.pypots
2024-05-22 23:30:43 [INFO]: Epoch 050 - training loss: 0.2061, validation loss: 0.1670
2024-05-22 23:30:43 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch50_loss0.16700712541739146.pypots
2024-05-22 23:33:05 [INFO]: Epoch 051 - training loss: 0.2125, validation loss: 0.1680
2024-05-22 23:33:05 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch51_loss0.16801805396874744.pypots
2024-05-22 23:35:28 [INFO]: Epoch 052 - training loss: 0.2109, validation loss: 0.1663
2024-05-22 23:35:28 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch52_loss0.16634141157070795.pypots
2024-05-22 23:37:51 [INFO]: Epoch 053 - training loss: 0.2064, validation loss: 0.1694
2024-05-22 23:37:51 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch53_loss0.1694138410190741.pypots
2024-05-22 23:40:14 [INFO]: Epoch 054 - training loss: 0.2108, validation loss: 0.1676
2024-05-22 23:40:14 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch54_loss0.16755711361765863.pypots
2024-05-22 23:42:37 [INFO]: Epoch 055 - training loss: 0.2103, validation loss: 0.1670
2024-05-22 23:42:37 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch55_loss0.16697517658273378.pypots
2024-05-22 23:45:00 [INFO]: Epoch 056 - training loss: 0.2024, validation loss: 0.1646
2024-05-22 23:45:00 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch56_loss0.16460145240028698.pypots
2024-05-22 23:47:23 [INFO]: Epoch 057 - training loss: 0.2064, validation loss: 0.1656
2024-05-22 23:47:23 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch57_loss0.1655803715189298.pypots
2024-05-22 23:49:46 [INFO]: Epoch 058 - training loss: 0.2109, validation loss: 0.1666
2024-05-22 23:49:46 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch58_loss0.1666122004389763.pypots
2024-05-22 23:52:09 [INFO]: Epoch 059 - training loss: 0.2067, validation loss: 0.1652
2024-05-22 23:52:09 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch59_loss0.16522129078706105.pypots
2024-05-22 23:54:31 [INFO]: Epoch 060 - training loss: 0.2067, validation loss: 0.1659
2024-05-22 23:54:31 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch60_loss0.16593227287133536.pypots
2024-05-22 23:56:54 [INFO]: Epoch 061 - training loss: 0.2061, validation loss: 0.1647
2024-05-22 23:56:54 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch61_loss0.16466929589708645.pypots
2024-05-22 23:59:17 [INFO]: Epoch 062 - training loss: 0.2003, validation loss: 0.1646
2024-05-22 23:59:17 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch62_loss0.16464685872197152.pypots
2024-05-23 00:01:40 [INFO]: Epoch 063 - training loss: 0.2011, validation loss: 0.1635
2024-05-23 00:01:40 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch63_loss0.1634619342784087.pypots
2024-05-23 00:04:03 [INFO]: Epoch 064 - training loss: 0.2006, validation loss: 0.1643
2024-05-23 00:04:03 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch64_loss0.16431233137845994.pypots
2024-05-23 00:06:26 [INFO]: Epoch 065 - training loss: 0.2028, validation loss: 0.1645
2024-05-23 00:06:26 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch65_loss0.16452314580480257.pypots
2024-05-23 00:08:49 [INFO]: Epoch 066 - training loss: 0.2062, validation loss: 0.1655
2024-05-23 00:08:49 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch66_loss0.1655398373802503.pypots
2024-05-23 00:11:12 [INFO]: Epoch 067 - training loss: 0.2056, validation loss: 0.1665
2024-05-23 00:11:12 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch67_loss0.16645225311319034.pypots
2024-05-23 00:13:35 [INFO]: Epoch 068 - training loss: 0.1993, validation loss: 0.1649
2024-05-23 00:13:35 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch68_loss0.16485858658949534.pypots
2024-05-23 00:15:58 [INFO]: Epoch 069 - training loss: 0.2106, validation loss: 0.1639
2024-05-23 00:15:58 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch69_loss0.16386071667075158.pypots
2024-05-23 00:18:21 [INFO]: Epoch 070 - training loss: 0.2024, validation loss: 0.1644
2024-05-23 00:18:21 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch70_loss0.16438479945063592.pypots
2024-05-23 00:20:44 [INFO]: Epoch 071 - training loss: 0.2059, validation loss: 0.1640
2024-05-23 00:20:44 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch71_loss0.16404959683616957.pypots
2024-05-23 00:23:06 [INFO]: Epoch 072 - training loss: 0.2038, validation loss: 0.1644
2024-05-23 00:23:06 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch72_loss0.1643742874264717.pypots
2024-05-23 00:25:29 [INFO]: Epoch 073 - training loss: 0.2022, validation loss: 0.1642
2024-05-23 00:25:29 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI_epoch73_loss0.16424171502391496.pypots
2024-05-23 00:25:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 00:25:29 [INFO]: Finished training. The best model is from epoch#63.
2024-05-23 00:25:29 [INFO]: Saved the model to saved_results/round_2/CSDI_physionet2012/20240522_T213135/CSDI.pypots
2024-05-23 00:49:16 [INFO]: CSDI on PhysioNet-2012: MAE=0.2205, MSE=0.3328
2024-05-23 02:24:23 [INFO]: Successfully saved to saved_results/round_2/CSDI_physionet2012/imputation.pkl
2024-05-23 02:24:23 [INFO]: Using the given device: cuda:0
2024-05-23 02:24:23 [INFO]: Model files will be saved to saved_results/round_2/GPVAE_physionet2012/20240523_T022423
2024-05-23 02:24:23 [INFO]: Tensorboard file will be saved to saved_results/round_2/GPVAE_physionet2012/20240523_T022423/tensorboard
2024-05-23 02:24:23 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-23 02:24:27 [INFO]: Epoch 001 - training loss: 30125.7256, validation loss: 0.6943
2024-05-23 02:24:31 [INFO]: Epoch 002 - training loss: 23121.9220, validation loss: 0.6511
2024-05-23 02:24:35 [INFO]: Epoch 003 - training loss: 22935.9069, validation loss: 0.6508
2024-05-23 02:24:40 [INFO]: Epoch 004 - training loss: 22879.1699, validation loss: 0.6470
2024-05-23 02:24:44 [INFO]: Epoch 005 - training loss: 22856.6735, validation loss: 0.6393
2024-05-23 02:24:48 [INFO]: Epoch 006 - training loss: 22844.5866, validation loss: 0.6229
2024-05-23 02:24:52 [INFO]: Epoch 007 - training loss: 22837.6468, validation loss: 0.6142
2024-05-23 02:24:56 [INFO]: Epoch 008 - training loss: 22833.2791, validation loss: 0.6037
2024-05-23 02:25:00 [INFO]: Epoch 009 - training loss: 22829.1731, validation loss: 0.5901
2024-05-23 02:25:04 [INFO]: Epoch 010 - training loss: 22825.0679, validation loss: 0.5779
2024-05-23 02:25:08 [INFO]: Epoch 011 - training loss: 22821.2858, validation loss: 0.5757
2024-05-23 02:25:12 [INFO]: Epoch 012 - training loss: 22818.8939, validation loss: 0.5563
2024-05-23 02:25:16 [INFO]: Epoch 013 - training loss: 22815.7321, validation loss: 0.5438
2024-05-23 02:25:20 [INFO]: Epoch 014 - training loss: 22813.2178, validation loss: 0.5394
2024-05-23 02:25:24 [INFO]: Epoch 015 - training loss: 22812.1249, validation loss: 0.5322
2024-05-23 02:25:28 [INFO]: Epoch 016 - training loss: 22810.1767, validation loss: 0.5297
2024-05-23 02:25:32 [INFO]: Epoch 017 - training loss: 22808.1441, validation loss: 0.5263
2024-05-23 02:25:36 [INFO]: Epoch 018 - training loss: 22806.7029, validation loss: 0.5425
2024-05-23 02:25:40 [INFO]: Epoch 019 - training loss: 22807.7813, validation loss: 0.5224
2024-05-23 02:25:44 [INFO]: Epoch 020 - training loss: 22805.3509, validation loss: 0.5388
2024-05-23 02:25:48 [INFO]: Epoch 021 - training loss: 22805.2653, validation loss: 0.5179
2024-05-23 02:25:52 [INFO]: Epoch 022 - training loss: 22803.6317, validation loss: 0.5126
2024-05-23 02:25:56 [INFO]: Epoch 023 - training loss: 22802.0558, validation loss: 0.5013
2024-05-23 02:26:00 [INFO]: Epoch 024 - training loss: 22800.6706, validation loss: 0.5016
2024-05-23 02:26:04 [INFO]: Epoch 025 - training loss: 22800.1517, validation loss: 0.4939
2024-05-23 02:26:08 [INFO]: Epoch 026 - training loss: 22797.9269, validation loss: 0.4871
2024-05-23 02:26:12 [INFO]: Epoch 027 - training loss: 22797.2071, validation loss: 0.4953
2024-05-23 02:26:16 [INFO]: Epoch 028 - training loss: 22796.2155, validation loss: 0.4801
2024-05-23 02:26:20 [INFO]: Epoch 029 - training loss: 22795.1878, validation loss: 0.4872
2024-05-23 02:26:24 [INFO]: Epoch 030 - training loss: 22794.3100, validation loss: 0.4749
2024-05-23 02:26:28 [INFO]: Epoch 031 - training loss: 22792.9705, validation loss: 0.4732
2024-05-23 02:26:33 [INFO]: Epoch 032 - training loss: 22792.4688, validation loss: 0.4684
2024-05-23 02:26:37 [INFO]: Epoch 033 - training loss: 22792.0788, validation loss: 0.4679
2024-05-23 02:26:41 [INFO]: Epoch 034 - training loss: 22791.9505, validation loss: 0.4687
2024-05-23 02:26:45 [INFO]: Epoch 035 - training loss: 22791.1228, validation loss: 0.4705
2024-05-23 02:26:49 [INFO]: Epoch 036 - training loss: 22791.1823, validation loss: 0.4674
2024-05-23 02:26:54 [INFO]: Epoch 037 - training loss: 22790.2610, validation loss: 0.4634
2024-05-23 02:26:58 [INFO]: Epoch 038 - training loss: 22789.8292, validation loss: 0.4715
2024-05-23 02:27:02 [INFO]: Epoch 039 - training loss: 22789.6612, validation loss: 0.4635
2024-05-23 02:27:06 [INFO]: Epoch 040 - training loss: 22788.8608, validation loss: 0.4605
2024-05-23 02:27:10 [INFO]: Epoch 041 - training loss: 22788.2658, validation loss: 0.4544
2024-05-23 02:27:14 [INFO]: Epoch 042 - training loss: 22788.1464, validation loss: 0.4575
2024-05-23 02:27:19 [INFO]: Epoch 043 - training loss: 22787.2068, validation loss: 0.4537
2024-05-23 02:27:23 [INFO]: Epoch 044 - training loss: 22786.8548, validation loss: 0.4574
2024-05-23 02:27:27 [INFO]: Epoch 045 - training loss: 22786.6355, validation loss: 0.4627
2024-05-23 02:27:31 [INFO]: Epoch 046 - training loss: 22788.2266, validation loss: 0.4534
2024-05-23 02:27:35 [INFO]: Epoch 047 - training loss: 22786.2395, validation loss: 0.4561
2024-05-23 02:27:38 [INFO]: Epoch 048 - training loss: 22786.2676, validation loss: 0.4558
2024-05-23 02:27:42 [INFO]: Epoch 049 - training loss: 22785.3480, validation loss: 0.4546
2024-05-23 02:27:47 [INFO]: Epoch 050 - training loss: 22785.4699, validation loss: 0.4507
2024-05-23 02:27:51 [INFO]: Epoch 051 - training loss: 22784.7665, validation loss: 0.4544
2024-05-23 02:27:55 [INFO]: Epoch 052 - training loss: 22785.0131, validation loss: 0.4557
2024-05-23 02:27:59 [INFO]: Epoch 053 - training loss: 22784.7391, validation loss: 0.4543
2024-05-23 02:28:03 [INFO]: Epoch 054 - training loss: 22784.1891, validation loss: 0.4577
2024-05-23 02:28:07 [INFO]: Epoch 055 - training loss: 22784.5696, validation loss: 0.4539
2024-05-23 02:28:11 [INFO]: Epoch 056 - training loss: 22783.8494, validation loss: 0.4570
2024-05-23 02:28:15 [INFO]: Epoch 057 - training loss: 22784.1775, validation loss: 0.4495
2024-05-23 02:28:19 [INFO]: Epoch 058 - training loss: 22784.4056, validation loss: 0.4535
2024-05-23 02:28:23 [INFO]: Epoch 059 - training loss: 22783.7069, validation loss: 0.4519
2024-05-23 02:28:27 [INFO]: Epoch 060 - training loss: 22783.0747, validation loss: 0.4515
2024-05-23 02:28:31 [INFO]: Epoch 061 - training loss: 22782.6084, validation loss: 0.4516
2024-05-23 02:28:35 [INFO]: Epoch 062 - training loss: 22782.7428, validation loss: 0.4512
2024-05-23 02:28:39 [INFO]: Epoch 063 - training loss: 22782.0671, validation loss: 0.4471
2024-05-23 02:28:43 [INFO]: Epoch 064 - training loss: 22782.7110, validation loss: 0.4521
2024-05-23 02:28:47 [INFO]: Epoch 065 - training loss: 22782.2111, validation loss: 0.4505
2024-05-23 02:28:51 [INFO]: Epoch 066 - training loss: 22782.0392, validation loss: 0.4507
2024-05-23 02:28:55 [INFO]: Epoch 067 - training loss: 22781.6637, validation loss: 0.4461
2024-05-23 02:28:59 [INFO]: Epoch 068 - training loss: 22781.3179, validation loss: 0.4485
2024-05-23 02:29:03 [INFO]: Epoch 069 - training loss: 22781.3305, validation loss: 0.4470
2024-05-23 02:29:07 [INFO]: Epoch 070 - training loss: 22781.5741, validation loss: 0.4464
2024-05-23 02:29:11 [INFO]: Epoch 071 - training loss: 22782.0446, validation loss: 0.4467
2024-05-23 02:29:15 [INFO]: Epoch 072 - training loss: 22780.9591, validation loss: 0.4457
2024-05-23 02:29:19 [INFO]: Epoch 073 - training loss: 22781.4487, validation loss: 0.4482
2024-05-23 02:29:23 [INFO]: Epoch 074 - training loss: 22780.3042, validation loss: 0.4451
2024-05-23 02:29:27 [INFO]: Epoch 075 - training loss: 22780.2744, validation loss: 0.4524
2024-05-23 02:29:31 [INFO]: Epoch 076 - training loss: 22780.8392, validation loss: 0.4438
2024-05-23 02:29:35 [INFO]: Epoch 077 - training loss: 22780.1266, validation loss: 0.4426
2024-05-23 02:29:39 [INFO]: Epoch 078 - training loss: 22779.9567, validation loss: 0.4431
2024-05-23 02:29:44 [INFO]: Epoch 079 - training loss: 22779.6939, validation loss: 0.4425
2024-05-23 02:29:47 [INFO]: Epoch 080 - training loss: 22779.5975, validation loss: 0.4430
2024-05-23 02:29:51 [INFO]: Epoch 081 - training loss: 22779.1552, validation loss: 0.4413
2024-05-23 02:29:55 [INFO]: Epoch 082 - training loss: 22779.2237, validation loss: 0.4406
2024-05-23 02:29:59 [INFO]: Epoch 083 - training loss: 22778.9675, validation loss: 0.4428
2024-05-23 02:30:03 [INFO]: Epoch 084 - training loss: 22779.3992, validation loss: 0.4424
2024-05-23 02:30:07 [INFO]: Epoch 085 - training loss: 22779.0730, validation loss: 0.4399
2024-05-23 02:30:10 [INFO]: Epoch 086 - training loss: 22778.9723, validation loss: 0.4406
2024-05-23 02:30:14 [INFO]: Epoch 087 - training loss: 22779.2054, validation loss: 0.4392
2024-05-23 02:30:18 [INFO]: Epoch 088 - training loss: 22778.5780, validation loss: 0.4422
2024-05-23 02:30:22 [INFO]: Epoch 089 - training loss: 22778.7703, validation loss: 0.4389
2024-05-23 02:30:26 [INFO]: Epoch 090 - training loss: 22778.3284, validation loss: 0.4452
2024-05-23 02:30:30 [INFO]: Epoch 091 - training loss: 22778.3756, validation loss: 0.4406
2024-05-23 02:30:35 [INFO]: Epoch 092 - training loss: 22778.3575, validation loss: 0.4376
2024-05-23 02:30:39 [INFO]: Epoch 093 - training loss: 22778.0909, validation loss: 0.4341
2024-05-23 02:30:43 [INFO]: Epoch 094 - training loss: 22777.5750, validation loss: 0.4388
2024-05-23 02:30:47 [INFO]: Epoch 095 - training loss: 22778.6392, validation loss: 0.4421
2024-05-23 02:30:51 [INFO]: Epoch 096 - training loss: 22778.0859, validation loss: 0.4404
2024-05-23 02:30:55 [INFO]: Epoch 097 - training loss: 22777.9326, validation loss: 0.4353
2024-05-23 02:30:59 [INFO]: Epoch 098 - training loss: 22777.3507, validation loss: 0.4364
2024-05-23 02:31:03 [INFO]: Epoch 099 - training loss: 22777.4341, validation loss: 0.4340
2024-05-23 02:31:07 [INFO]: Epoch 100 - training loss: 22776.8141, validation loss: 0.4367
2024-05-23 02:31:11 [INFO]: Epoch 101 - training loss: 22777.1823, validation loss: 0.4396
2024-05-23 02:31:15 [INFO]: Epoch 102 - training loss: 22777.1977, validation loss: 0.4472
2024-05-23 02:31:19 [INFO]: Epoch 103 - training loss: 22777.7590, validation loss: 0.4375
2024-05-23 02:31:23 [INFO]: Epoch 104 - training loss: 22776.9497, validation loss: 0.4380
2024-05-23 02:31:27 [INFO]: Epoch 105 - training loss: 22777.0648, validation loss: 0.4387
2024-05-23 02:31:31 [INFO]: Epoch 106 - training loss: 22776.8427, validation loss: 0.4347
2024-05-23 02:31:35 [INFO]: Epoch 107 - training loss: 22776.6996, validation loss: 0.4333
2024-05-23 02:31:39 [INFO]: Epoch 108 - training loss: 22776.3392, validation loss: 0.4325
2024-05-23 02:31:43 [INFO]: Epoch 109 - training loss: 22776.5270, validation loss: 0.4341
2024-05-23 02:31:47 [INFO]: Epoch 110 - training loss: 22776.6963, validation loss: 0.4340
2024-05-23 02:31:51 [INFO]: Epoch 111 - training loss: 22776.4525, validation loss: 0.4330
2024-05-23 02:31:55 [INFO]: Epoch 112 - training loss: 22776.4947, validation loss: 0.4315
2024-05-23 02:32:00 [INFO]: Epoch 113 - training loss: 22776.0059, validation loss: 0.4351
2024-05-23 02:32:04 [INFO]: Epoch 114 - training loss: 22776.0089, validation loss: 0.4377
2024-05-23 02:32:08 [INFO]: Epoch 115 - training loss: 22776.3170, validation loss: 0.4340
2024-05-23 02:32:12 [INFO]: Epoch 116 - training loss: 22775.7694, validation loss: 0.4350
2024-05-23 02:32:16 [INFO]: Epoch 117 - training loss: 22775.8701, validation loss: 0.4348
2024-05-23 02:32:20 [INFO]: Epoch 118 - training loss: 22776.3893, validation loss: 0.4293
2024-05-23 02:32:24 [INFO]: Epoch 119 - training loss: 22776.0051, validation loss: 0.4306
2024-05-23 02:32:28 [INFO]: Epoch 120 - training loss: 22775.7606, validation loss: 0.4360
2024-05-23 02:32:33 [INFO]: Epoch 121 - training loss: 22775.6207, validation loss: 0.4330
2024-05-23 02:32:37 [INFO]: Epoch 122 - training loss: 22775.6765, validation loss: 0.4338
2024-05-23 02:32:41 [INFO]: Epoch 123 - training loss: 22775.4689, validation loss: 0.4391
2024-05-23 02:32:45 [INFO]: Epoch 124 - training loss: 22775.6724, validation loss: 0.4350
2024-05-23 02:32:49 [INFO]: Epoch 125 - training loss: 22775.7275, validation loss: 0.4297
2024-05-23 02:32:53 [INFO]: Epoch 126 - training loss: 22775.0426, validation loss: 0.4330
2024-05-23 02:32:57 [INFO]: Epoch 127 - training loss: 22775.5015, validation loss: 0.4316
2024-05-23 02:33:01 [INFO]: Epoch 128 - training loss: 22775.1472, validation loss: 0.4315
2024-05-23 02:33:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 02:33:01 [INFO]: Finished training. The best model is from epoch#118.
2024-05-23 02:33:01 [INFO]: Saved the model to saved_results/round_2/GPVAE_physionet2012/20240523_T022423/GPVAE.pypots
2024-05-23 02:33:02 [INFO]: GP-VAE on PhysioNet-2012: MAE=0.3930, MSE=0.4198
2024-05-23 02:33:04 [INFO]: Successfully saved to saved_results/round_2/GPVAE_physionet2012/imputation.pkl
2024-05-23 02:33:04 [INFO]: Using the given device: cuda:0
2024-05-23 02:33:04 [INFO]: Model files will be saved to saved_results/round_2/USGAN_physionet2012/20240523_T023304
2024-05-23 02:33:04 [INFO]: Tensorboard file will be saved to saved_results/round_2/USGAN_physionet2012/20240523_T023304/tensorboard
2024-05-23 02:33:04 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-23 02:35:19 [INFO]: Epoch 001 - generator training loss: 0.5014, discriminator training loss: 0.2812, validation loss: 0.4841
2024-05-23 02:37:16 [INFO]: Epoch 002 - generator training loss: 0.4478, discriminator training loss: 0.1282, validation loss: 0.4286
2024-05-23 02:39:11 [INFO]: Epoch 003 - generator training loss: 0.4203, discriminator training loss: 0.0809, validation loss: 0.3974
2024-05-23 02:41:08 [INFO]: Epoch 004 - generator training loss: 0.4008, discriminator training loss: 0.0608, validation loss: 0.3813
2024-05-23 02:43:05 [INFO]: Epoch 005 - generator training loss: 0.3859, discriminator training loss: 0.0492, validation loss: 0.3645
2024-05-23 02:45:04 [INFO]: Epoch 006 - generator training loss: 0.3729, discriminator training loss: 0.0419, validation loss: 0.3533
2024-05-23 02:47:00 [INFO]: Epoch 007 - generator training loss: 0.3610, discriminator training loss: 0.0372, validation loss: 0.3370
2024-05-23 02:48:56 [INFO]: Epoch 008 - generator training loss: 0.3497, discriminator training loss: 0.0340, validation loss: 0.3281
2024-05-23 02:50:52 [INFO]: Epoch 009 - generator training loss: 0.3371, discriminator training loss: 0.0317, validation loss: 0.3213
2024-05-23 02:52:49 [INFO]: Epoch 010 - generator training loss: 0.3300, discriminator training loss: 0.0300, validation loss: 0.3129
2024-05-23 02:54:44 [INFO]: Epoch 011 - generator training loss: 0.3206, discriminator training loss: 0.0285, validation loss: 0.3140
2024-05-23 02:56:40 [INFO]: Epoch 012 - generator training loss: 0.3138, discriminator training loss: 0.0274, validation loss: 0.3000
2024-05-23 02:58:37 [INFO]: Epoch 013 - generator training loss: 0.3065, discriminator training loss: 0.0263, validation loss: 0.2947
2024-05-23 03:00:32 [INFO]: Epoch 014 - generator training loss: 0.2994, discriminator training loss: 0.0257, validation loss: 0.2953
2024-05-23 03:02:28 [INFO]: Epoch 015 - generator training loss: 0.2933, discriminator training loss: 0.0250, validation loss: 0.2866
2024-05-23 03:04:21 [INFO]: Epoch 016 - generator training loss: 0.2898, discriminator training loss: 0.0244, validation loss: 0.2865
2024-05-23 03:06:09 [INFO]: Epoch 017 - generator training loss: 0.2860, discriminator training loss: 0.0239, validation loss: 0.2841
2024-05-23 03:07:57 [INFO]: Epoch 018 - generator training loss: 0.2818, discriminator training loss: 0.0235, validation loss: 0.2814
2024-05-23 03:09:44 [INFO]: Epoch 019 - generator training loss: 0.2799, discriminator training loss: 0.0229, validation loss: 0.2807
2024-05-23 03:11:31 [INFO]: Epoch 020 - generator training loss: 0.2758, discriminator training loss: 0.0226, validation loss: 0.2766
2024-05-23 03:13:22 [INFO]: Epoch 021 - generator training loss: 0.2744, discriminator training loss: 0.0223, validation loss: 0.2801
2024-05-23 03:15:20 [INFO]: Epoch 022 - generator training loss: 0.2735, discriminator training loss: 0.0221, validation loss: 0.2798
2024-05-23 03:17:16 [INFO]: Epoch 023 - generator training loss: 0.2722, discriminator training loss: 0.0220, validation loss: 0.2782
2024-05-23 03:19:09 [INFO]: Epoch 024 - generator training loss: 0.2663, discriminator training loss: 0.0218, validation loss: 0.2836
2024-05-23 03:21:05 [INFO]: Epoch 025 - generator training loss: 0.2646, discriminator training loss: 0.0215, validation loss: 0.2726
2024-05-23 03:23:03 [INFO]: Epoch 026 - generator training loss: 0.2599, discriminator training loss: 0.0215, validation loss: 0.2706
2024-05-23 03:24:58 [INFO]: Epoch 027 - generator training loss: 0.2587, discriminator training loss: 0.0213, validation loss: 0.2715
2024-05-23 03:26:54 [INFO]: Epoch 028 - generator training loss: 0.2592, discriminator training loss: 0.0211, validation loss: 0.2702
2024-05-23 03:28:51 [INFO]: Epoch 029 - generator training loss: 0.2559, discriminator training loss: 0.0209, validation loss: 0.2704
2024-05-23 03:30:51 [INFO]: Epoch 030 - generator training loss: 0.2595, discriminator training loss: 0.0207, validation loss: 0.2792
2024-05-23 03:32:51 [INFO]: Epoch 031 - generator training loss: 0.2571, discriminator training loss: 0.0205, validation loss: 0.2712
2024-05-23 03:34:47 [INFO]: Epoch 032 - generator training loss: 0.2500, discriminator training loss: 0.0203, validation loss: 0.2704
2024-05-23 03:36:41 [INFO]: Epoch 033 - generator training loss: 0.2461, discriminator training loss: 0.0202, validation loss: 0.2716
2024-05-23 03:38:30 [INFO]: Epoch 034 - generator training loss: 0.2451, discriminator training loss: 0.0201, validation loss: 0.2780
2024-05-23 03:40:17 [INFO]: Epoch 035 - generator training loss: 0.2422, discriminator training loss: 0.0198, validation loss: 0.2710
2024-05-23 03:42:04 [INFO]: Epoch 036 - generator training loss: 0.2398, discriminator training loss: 0.0197, validation loss: 0.2731
2024-05-23 03:43:52 [INFO]: Epoch 037 - generator training loss: 0.2427, discriminator training loss: 0.0196, validation loss: 0.2739
2024-05-23 03:45:43 [INFO]: Epoch 038 - generator training loss: 0.2398, discriminator training loss: 0.0195, validation loss: 0.2748
2024-05-23 03:45:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 03:45:43 [INFO]: Finished training. The best model is from epoch#28.
2024-05-23 03:45:43 [INFO]: Saved the model to saved_results/round_2/USGAN_physionet2012/20240523_T023304/USGAN.pypots
2024-05-23 03:45:58 [INFO]: US-GAN on PhysioNet-2012: MAE=0.2769, MSE=0.2798
2024-05-23 03:46:56 [INFO]: Successfully saved to saved_results/round_2/USGAN_physionet2012/imputation.pkl
2024-05-23 03:46:56 [INFO]: Using the given device: cuda:0
2024-05-23 03:46:56 [INFO]: Model files will be saved to saved_results/round_2/BRITS_physionet2012/20240523_T034656
2024-05-23 03:46:56 [INFO]: Tensorboard file will be saved to saved_results/round_2/BRITS_physionet2012/20240523_T034656/tensorboard
2024-05-23 03:46:56 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-23 03:48:31 [INFO]: Epoch 001 - training loss: 0.9405, validation loss: 0.4234
2024-05-23 03:49:48 [INFO]: Epoch 002 - training loss: 0.7634, validation loss: 0.3761
2024-05-23 03:51:05 [INFO]: Epoch 003 - training loss: 0.7068, validation loss: 0.3537
2024-05-23 03:52:16 [INFO]: Epoch 004 - training loss: 0.6737, validation loss: 0.3438
2024-05-23 03:53:31 [INFO]: Epoch 005 - training loss: 0.6526, validation loss: 0.3367
2024-05-23 03:54:47 [INFO]: Epoch 006 - training loss: 0.6390, validation loss: 0.3365
2024-05-23 03:56:01 [INFO]: Epoch 007 - training loss: 0.6299, validation loss: 0.3290
2024-05-23 03:57:14 [INFO]: Epoch 008 - training loss: 0.6214, validation loss: 0.3302
2024-05-23 03:58:31 [INFO]: Epoch 009 - training loss: 0.6172, validation loss: 0.3329
2024-05-23 03:59:47 [INFO]: Epoch 010 - training loss: 0.6083, validation loss: 0.3256
2024-05-23 04:01:01 [INFO]: Epoch 011 - training loss: 0.6011, validation loss: 0.3285
2024-05-23 04:02:16 [INFO]: Epoch 012 - training loss: 0.5951, validation loss: 0.3231
2024-05-23 04:03:30 [INFO]: Epoch 013 - training loss: 0.5905, validation loss: 0.3252
2024-05-23 04:04:46 [INFO]: Epoch 014 - training loss: 0.5848, validation loss: 0.3283
2024-05-23 04:06:01 [INFO]: Epoch 015 - training loss: 0.5800, validation loss: 0.3297
2024-05-23 04:07:16 [INFO]: Epoch 016 - training loss: 0.5760, validation loss: 0.3369
2024-05-23 04:08:35 [INFO]: Epoch 017 - training loss: 0.5747, validation loss: 0.3366
2024-05-23 04:09:53 [INFO]: Epoch 018 - training loss: 0.5687, validation loss: 0.3345
2024-05-23 04:11:09 [INFO]: Epoch 019 - training loss: 0.5661, validation loss: 0.3376
2024-05-23 04:12:26 [INFO]: Epoch 020 - training loss: 0.5636, validation loss: 0.3390
2024-05-23 04:13:43 [INFO]: Epoch 021 - training loss: 0.5641, validation loss: 0.3395
2024-05-23 04:15:01 [INFO]: Epoch 022 - training loss: 0.5719, validation loss: 0.3496
2024-05-23 04:15:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 04:15:01 [INFO]: Finished training. The best model is from epoch#12.
2024-05-23 04:15:01 [INFO]: Saved the model to saved_results/round_2/BRITS_physionet2012/20240523_T034656/BRITS.pypots
2024-05-23 04:15:16 [INFO]: BRITS on PhysioNet-2012: MAE=0.2516, MSE=0.3336
2024-05-23 04:16:13 [INFO]: Successfully saved to saved_results/round_2/BRITS_physionet2012/imputation.pkl
2024-05-23 04:16:13 [INFO]: Using the given device: cuda:0
2024-05-23 04:16:13 [INFO]: Model files will be saved to saved_results/round_2/MRNN_physionet2012/20240523_T041613
2024-05-23 04:16:13 [INFO]: Tensorboard file will be saved to saved_results/round_2/MRNN_physionet2012/20240523_T041613/tensorboard
2024-05-23 04:16:13 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-23 04:16:48 [INFO]: Epoch 001 - training loss: 0.8055, validation loss: 0.9126
2024-05-23 04:16:48 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN_epoch1_loss0.9126459926366806.pypots
2024-05-23 04:17:04 [INFO]: Epoch 002 - training loss: 0.5583, validation loss: 0.8886
2024-05-23 04:17:04 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN_epoch2_loss0.8886038323243459.pypots
2024-05-23 04:17:20 [INFO]: Epoch 003 - training loss: 0.5219, validation loss: 0.8818
2024-05-23 04:17:20 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN_epoch3_loss0.8818043778340022.pypots
2024-05-23 04:17:36 [INFO]: Epoch 004 - training loss: 0.4998, validation loss: 0.8786
2024-05-23 04:17:36 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN_epoch4_loss0.8786323388417562.pypots
2024-05-23 04:17:52 [INFO]: Epoch 005 - training loss: 0.4871, validation loss: 0.8819
2024-05-23 04:17:52 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN_epoch5_loss0.8819303611914316.pypots
2024-05-23 04:18:08 [INFO]: Epoch 006 - training loss: 0.4769, validation loss: 0.8862
2024-05-23 04:18:08 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN_epoch6_loss0.8862022538979848.pypots
2024-05-23 04:18:24 [INFO]: Epoch 007 - training loss: 0.4690, validation loss: 0.8893
2024-05-23 04:18:24 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN_epoch7_loss0.8892693847417832.pypots
2024-05-23 04:18:41 [INFO]: Epoch 008 - training loss: 0.4678, validation loss: 0.8931
2024-05-23 04:18:41 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN_epoch8_loss0.8930764893690745.pypots
2024-05-23 04:18:57 [INFO]: Epoch 009 - training loss: 0.4570, validation loss: 0.8918
2024-05-23 04:18:57 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN_epoch9_loss0.8917655040820439.pypots
2024-05-23 04:19:13 [INFO]: Epoch 010 - training loss: 0.4509, validation loss: 0.8960
2024-05-23 04:19:13 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN_epoch10_loss0.8959964325030645.pypots
2024-05-23 04:19:29 [INFO]: Epoch 011 - training loss: 0.4499, validation loss: 0.8957
2024-05-23 04:19:29 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN_epoch11_loss0.895655017097791.pypots
2024-05-23 04:19:45 [INFO]: Epoch 012 - training loss: 0.4482, validation loss: 0.9015
2024-05-23 04:19:45 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN_epoch12_loss0.9015477726856868.pypots
2024-05-23 04:20:01 [INFO]: Epoch 013 - training loss: 0.4482, validation loss: 0.9026
2024-05-23 04:20:01 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN_epoch13_loss0.902563555041949.pypots
2024-05-23 04:20:18 [INFO]: Epoch 014 - training loss: 0.4412, validation loss: 0.9049
2024-05-23 04:20:18 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN_epoch14_loss0.9048694362243016.pypots
2024-05-23 04:20:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 04:20:18 [INFO]: Finished training. The best model is from epoch#4.
2024-05-23 04:20:18 [INFO]: Saved the model to saved_results/round_2/MRNN_physionet2012/20240523_T041613/MRNN.pypots
2024-05-23 04:20:24 [INFO]: MRNN on PhysioNet-2012: MAE=0.6821, MSE=0.8895
2024-05-23 04:20:50 [INFO]: Successfully saved to saved_results/round_2/MRNN_physionet2012/imputation.pkl
2024-05-23 04:20:50 [INFO]: Using the given device: cpu
2024-05-23 04:20:50 [INFO]: LOCF on PhysioNet-2012: MAE=0.4110, MSE=0.5688
2024-05-23 04:20:50 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_physionet2012".
2024-05-23 04:20:50 [INFO]: Successfully saved to saved_results/round_2/LOCF_physionet2012/imputation.pkl
2024-05-23 04:20:50 [INFO]: Median on PhysioNet-2012: MAE=0.6855, MSE=0.9913
2024-05-23 04:20:51 [INFO]: Successfully created the given path "saved_results/round_2/Median_physionet2012".
2024-05-23 04:20:51 [INFO]: Successfully saved to saved_results/round_2/Median_physionet2012/imputation.pkl
2024-05-23 04:20:51 [INFO]: Mean on PhysioNet-2012: MAE=0.7017, MSE=0.9536
2024-05-23 04:20:52 [INFO]: Successfully created the given path "saved_results/round_2/Mean_physionet2012".
2024-05-23 04:20:52 [INFO]: Successfully saved to saved_results/round_2/Mean_physionet2012/imputation.pkl
2024-05-23 04:20:52 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-23 04:20:52 [INFO]: Using the given device: cuda:0
2024-05-23 04:20:52 [INFO]: Model files will be saved to saved_results/round_3/SAITS_physionet2012/20240523_T042052
2024-05-23 04:20:52 [INFO]: Tensorboard file will be saved to saved_results/round_3/SAITS_physionet2012/20240523_T042052/tensorboard
2024-05-23 04:20:52 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-23 04:21:05 [INFO]: Epoch 001 - training loss: 0.8356, validation loss: 0.4081
2024-05-23 04:21:17 [INFO]: Epoch 002 - training loss: 0.4927, validation loss: 0.3463
2024-05-23 04:21:30 [INFO]: Epoch 003 - training loss: 0.4151, validation loss: 0.3263
2024-05-23 04:21:43 [INFO]: Epoch 004 - training loss: 0.3718, validation loss: 0.2951
2024-05-23 04:21:55 [INFO]: Epoch 005 - training loss: 0.3416, validation loss: 0.2760
2024-05-23 04:22:08 [INFO]: Epoch 006 - training loss: 0.3233, validation loss: 0.2647
2024-05-23 04:22:21 [INFO]: Epoch 007 - training loss: 0.3097, validation loss: 0.2594
2024-05-23 04:22:34 [INFO]: Epoch 008 - training loss: 0.3008, validation loss: 0.2571
2024-05-23 04:22:46 [INFO]: Epoch 009 - training loss: 0.2939, validation loss: 0.2604
2024-05-23 04:22:58 [INFO]: Epoch 010 - training loss: 0.2845, validation loss: 0.2471
2024-05-23 04:23:10 [INFO]: Epoch 011 - training loss: 0.2816, validation loss: 0.2514
2024-05-23 04:23:23 [INFO]: Epoch 012 - training loss: 0.2760, validation loss: 0.2451
2024-05-23 04:23:36 [INFO]: Epoch 013 - training loss: 0.2735, validation loss: 0.2503
2024-05-23 04:23:49 [INFO]: Epoch 014 - training loss: 0.2701, validation loss: 0.2511
2024-05-23 04:24:02 [INFO]: Epoch 015 - training loss: 0.2695, validation loss: 0.2467
2024-05-23 04:24:14 [INFO]: Epoch 016 - training loss: 0.2654, validation loss: 0.2413
2024-05-23 04:24:27 [INFO]: Epoch 017 - training loss: 0.2620, validation loss: 0.2400
2024-05-23 04:24:40 [INFO]: Epoch 018 - training loss: 0.2610, validation loss: 0.2330
2024-05-23 04:24:52 [INFO]: Epoch 019 - training loss: 0.2595, validation loss: 0.2386
2024-05-23 04:25:05 [INFO]: Epoch 020 - training loss: 0.2579, validation loss: 0.2448
2024-05-23 04:25:18 [INFO]: Epoch 021 - training loss: 0.2571, validation loss: 0.2419
2024-05-23 04:25:30 [INFO]: Epoch 022 - training loss: 0.2539, validation loss: 0.2411
2024-05-23 04:25:43 [INFO]: Epoch 023 - training loss: 0.2524, validation loss: 0.2369
2024-05-23 04:25:56 [INFO]: Epoch 024 - training loss: 0.2507, validation loss: 0.2354
2024-05-23 04:26:09 [INFO]: Epoch 025 - training loss: 0.2509, validation loss: 0.2294
2024-05-23 04:26:21 [INFO]: Epoch 026 - training loss: 0.2493, validation loss: 0.2465
2024-05-23 04:26:34 [INFO]: Epoch 027 - training loss: 0.2493, validation loss: 0.2355
2024-05-23 04:26:47 [INFO]: Epoch 028 - training loss: 0.2474, validation loss: 0.2312
2024-05-23 04:27:00 [INFO]: Epoch 029 - training loss: 0.2468, validation loss: 0.2280
2024-05-23 04:27:13 [INFO]: Epoch 030 - training loss: 0.2458, validation loss: 0.2245
2024-05-23 04:27:26 [INFO]: Epoch 031 - training loss: 0.2452, validation loss: 0.2327
2024-05-23 04:27:39 [INFO]: Epoch 032 - training loss: 0.2457, validation loss: 0.2221
2024-05-23 04:27:52 [INFO]: Epoch 033 - training loss: 0.2455, validation loss: 0.2369
2024-05-23 04:28:05 [INFO]: Epoch 034 - training loss: 0.2437, validation loss: 0.2397
2024-05-23 04:28:18 [INFO]: Epoch 035 - training loss: 0.2413, validation loss: 0.2315
2024-05-23 04:28:31 [INFO]: Epoch 036 - training loss: 0.2413, validation loss: 0.2353
2024-05-23 04:28:43 [INFO]: Epoch 037 - training loss: 0.2407, validation loss: 0.2232
2024-05-23 04:28:56 [INFO]: Epoch 038 - training loss: 0.2404, validation loss: 0.2380
2024-05-23 04:29:09 [INFO]: Epoch 039 - training loss: 0.2405, validation loss: 0.2361
2024-05-23 04:29:22 [INFO]: Epoch 040 - training loss: 0.2389, validation loss: 0.2340
2024-05-23 04:29:34 [INFO]: Epoch 041 - training loss: 0.2385, validation loss: 0.2327
2024-05-23 04:29:47 [INFO]: Epoch 042 - training loss: 0.2375, validation loss: 0.2330
2024-05-23 04:29:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 04:29:47 [INFO]: Finished training. The best model is from epoch#32.
2024-05-23 04:29:47 [INFO]: Saved the model to saved_results/round_3/SAITS_physionet2012/20240523_T042052/SAITS.pypots
2024-05-23 04:29:48 [INFO]: SAITS on PhysioNet-2012: MAE=0.2025, MSE=0.2200
2024-05-23 04:29:50 [INFO]: Successfully saved to saved_results/round_3/SAITS_physionet2012/imputation.pkl
2024-05-23 04:29:50 [INFO]: Using the given device: cuda:0
2024-05-23 04:29:50 [INFO]: Model files will be saved to saved_results/round_3/Transformer_physionet2012/20240523_T042950
2024-05-23 04:29:50 [INFO]: Tensorboard file will be saved to saved_results/round_3/Transformer_physionet2012/20240523_T042950/tensorboard
2024-05-23 04:29:50 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-23 04:29:57 [INFO]: Epoch 001 - training loss: 0.8873, validation loss: 0.4430
2024-05-23 04:30:04 [INFO]: Epoch 002 - training loss: 0.5529, validation loss: 0.3962
2024-05-23 04:30:11 [INFO]: Epoch 003 - training loss: 0.4829, validation loss: 0.3785
2024-05-23 04:30:18 [INFO]: Epoch 004 - training loss: 0.4373, validation loss: 0.3543
2024-05-23 04:30:25 [INFO]: Epoch 005 - training loss: 0.4107, validation loss: 0.3381
2024-05-23 04:30:32 [INFO]: Epoch 006 - training loss: 0.3881, validation loss: 0.3298
2024-05-23 04:30:39 [INFO]: Epoch 007 - training loss: 0.3698, validation loss: 0.3136
2024-05-23 04:30:46 [INFO]: Epoch 008 - training loss: 0.3587, validation loss: 0.3144
2024-05-23 04:30:53 [INFO]: Epoch 009 - training loss: 0.3469, validation loss: 0.2999
2024-05-23 04:31:00 [INFO]: Epoch 010 - training loss: 0.3365, validation loss: 0.2987
2024-05-23 04:31:07 [INFO]: Epoch 011 - training loss: 0.3307, validation loss: 0.2949
2024-05-23 04:31:14 [INFO]: Epoch 012 - training loss: 0.3255, validation loss: 0.2880
2024-05-23 04:31:21 [INFO]: Epoch 013 - training loss: 0.3194, validation loss: 0.2834
2024-05-23 04:31:28 [INFO]: Epoch 014 - training loss: 0.3133, validation loss: 0.2783
2024-05-23 04:31:35 [INFO]: Epoch 015 - training loss: 0.3111, validation loss: 0.2790
2024-05-23 04:31:42 [INFO]: Epoch 016 - training loss: 0.3066, validation loss: 0.2700
2024-05-23 04:31:49 [INFO]: Epoch 017 - training loss: 0.3030, validation loss: 0.2622
2024-05-23 04:31:54 [INFO]: Epoch 018 - training loss: 0.2985, validation loss: 0.2626
2024-05-23 04:32:01 [INFO]: Epoch 019 - training loss: 0.2955, validation loss: 0.2634
2024-05-23 04:32:08 [INFO]: Epoch 020 - training loss: 0.2938, validation loss: 0.2650
2024-05-23 04:32:15 [INFO]: Epoch 021 - training loss: 0.2903, validation loss: 0.2613
2024-05-23 04:32:22 [INFO]: Epoch 022 - training loss: 0.2885, validation loss: 0.2562
2024-05-23 04:32:29 [INFO]: Epoch 023 - training loss: 0.2849, validation loss: 0.2614
2024-05-23 04:32:36 [INFO]: Epoch 024 - training loss: 0.2851, validation loss: 0.2580
2024-05-23 04:32:44 [INFO]: Epoch 025 - training loss: 0.2830, validation loss: 0.2586
2024-05-23 04:32:51 [INFO]: Epoch 026 - training loss: 0.2794, validation loss: 0.2550
2024-05-23 04:32:58 [INFO]: Epoch 027 - training loss: 0.2777, validation loss: 0.2518
2024-05-23 04:33:06 [INFO]: Epoch 028 - training loss: 0.2782, validation loss: 0.2503
2024-05-23 04:33:13 [INFO]: Epoch 029 - training loss: 0.2764, validation loss: 0.2496
2024-05-23 04:33:20 [INFO]: Epoch 030 - training loss: 0.2725, validation loss: 0.2495
2024-05-23 04:33:27 [INFO]: Epoch 031 - training loss: 0.2724, validation loss: 0.2541
2024-05-23 04:33:34 [INFO]: Epoch 032 - training loss: 0.2721, validation loss: 0.2436
2024-05-23 04:33:41 [INFO]: Epoch 033 - training loss: 0.2718, validation loss: 0.2502
2024-05-23 04:33:48 [INFO]: Epoch 034 - training loss: 0.2693, validation loss: 0.2480
2024-05-23 04:33:55 [INFO]: Epoch 035 - training loss: 0.2672, validation loss: 0.2487
2024-05-23 04:34:02 [INFO]: Epoch 036 - training loss: 0.2681, validation loss: 0.2564
2024-05-23 04:34:10 [INFO]: Epoch 037 - training loss: 0.2657, validation loss: 0.2436
2024-05-23 04:34:17 [INFO]: Epoch 038 - training loss: 0.2660, validation loss: 0.2405
2024-05-23 04:34:24 [INFO]: Epoch 039 - training loss: 0.2627, validation loss: 0.2415
2024-05-23 04:34:31 [INFO]: Epoch 040 - training loss: 0.2631, validation loss: 0.2406
2024-05-23 04:34:39 [INFO]: Epoch 041 - training loss: 0.2636, validation loss: 0.2398
2024-05-23 04:34:46 [INFO]: Epoch 042 - training loss: 0.2601, validation loss: 0.2435
2024-05-23 04:34:54 [INFO]: Epoch 043 - training loss: 0.2608, validation loss: 0.2434
2024-05-23 04:35:01 [INFO]: Epoch 044 - training loss: 0.2592, validation loss: 0.2378
2024-05-23 04:35:08 [INFO]: Epoch 045 - training loss: 0.2597, validation loss: 0.2414
2024-05-23 04:35:16 [INFO]: Epoch 046 - training loss: 0.2585, validation loss: 0.2371
2024-05-23 04:35:23 [INFO]: Epoch 047 - training loss: 0.2570, validation loss: 0.2389
2024-05-23 04:35:30 [INFO]: Epoch 048 - training loss: 0.2569, validation loss: 0.2303
2024-05-23 04:35:37 [INFO]: Epoch 049 - training loss: 0.2553, validation loss: 0.2362
2024-05-23 04:35:45 [INFO]: Epoch 050 - training loss: 0.2569, validation loss: 0.2386
2024-05-23 04:35:52 [INFO]: Epoch 051 - training loss: 0.2539, validation loss: 0.2410
2024-05-23 04:35:59 [INFO]: Epoch 052 - training loss: 0.2545, validation loss: 0.2419
2024-05-23 04:36:06 [INFO]: Epoch 053 - training loss: 0.2547, validation loss: 0.2345
2024-05-23 04:36:13 [INFO]: Epoch 054 - training loss: 0.2532, validation loss: 0.2345
2024-05-23 04:36:20 [INFO]: Epoch 055 - training loss: 0.2532, validation loss: 0.2355
2024-05-23 04:36:27 [INFO]: Epoch 056 - training loss: 0.2526, validation loss: 0.2365
2024-05-23 04:36:34 [INFO]: Epoch 057 - training loss: 0.2527, validation loss: 0.2367
2024-05-23 04:36:42 [INFO]: Epoch 058 - training loss: 0.2513, validation loss: 0.2332
2024-05-23 04:36:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 04:36:42 [INFO]: Finished training. The best model is from epoch#48.
2024-05-23 04:36:42 [INFO]: Saved the model to saved_results/round_3/Transformer_physionet2012/20240523_T042950/Transformer.pypots
2024-05-23 04:36:42 [INFO]: Transformer on PhysioNet-2012: MAE=0.2100, MSE=0.2268
2024-05-23 04:36:44 [INFO]: Successfully saved to saved_results/round_3/Transformer_physionet2012/imputation.pkl
2024-05-23 04:36:44 [INFO]: Using the given device: cuda:0
2024-05-23 04:36:44 [INFO]: Model files will be saved to saved_results/round_3/TimesNet_physionet2012/20240523_T043644
2024-05-23 04:36:44 [INFO]: Tensorboard file will be saved to saved_results/round_3/TimesNet_physionet2012/20240523_T043644/tensorboard
2024-05-23 04:36:44 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-23 04:36:48 [INFO]: Epoch 001 - training loss: 0.4026, validation loss: 0.3626
2024-05-23 04:36:52 [INFO]: Epoch 002 - training loss: 0.3983, validation loss: 0.4094
2024-05-23 04:36:55 [INFO]: Epoch 003 - training loss: 0.4235, validation loss: 0.3665
2024-05-23 04:37:00 [INFO]: Epoch 004 - training loss: 0.4773, validation loss: 0.3380
2024-05-23 04:37:03 [INFO]: Epoch 005 - training loss: 0.8419, validation loss: 0.3374
2024-05-23 04:37:07 [INFO]: Epoch 006 - training loss: 0.5745, validation loss: 0.3247
2024-05-23 04:37:11 [INFO]: Epoch 007 - training loss: 0.4354, validation loss: 0.3222
2024-05-23 04:37:14 [INFO]: Epoch 008 - training loss: 0.3681, validation loss: 0.3148
2024-05-23 04:37:18 [INFO]: Epoch 009 - training loss: 0.3470, validation loss: 0.3054
2024-05-23 04:37:21 [INFO]: Epoch 010 - training loss: 0.3720, validation loss: 0.3041
2024-05-23 04:37:25 [INFO]: Epoch 011 - training loss: 0.4491, validation loss: 0.3024
2024-05-23 04:37:29 [INFO]: Epoch 012 - training loss: 0.4063, validation loss: 0.3066
2024-05-23 04:37:33 [INFO]: Epoch 013 - training loss: 0.3105, validation loss: 0.2984
2024-05-23 04:37:36 [INFO]: Epoch 014 - training loss: 0.3080, validation loss: 0.2911
2024-05-23 04:37:40 [INFO]: Epoch 015 - training loss: 0.3448, validation loss: 0.2896
2024-05-23 04:37:44 [INFO]: Epoch 016 - training loss: 0.2975, validation loss: 0.2921
2024-05-23 04:37:47 [INFO]: Epoch 017 - training loss: 0.3182, validation loss: 0.2893
2024-05-23 04:37:51 [INFO]: Epoch 018 - training loss: 0.3173, validation loss: 0.2847
2024-05-23 04:37:54 [INFO]: Epoch 019 - training loss: 0.2959, validation loss: 0.2920
2024-05-23 04:37:58 [INFO]: Epoch 020 - training loss: 0.4256, validation loss: 0.2833
2024-05-23 04:38:01 [INFO]: Epoch 021 - training loss: 0.4020, validation loss: 0.2824
2024-05-23 04:38:05 [INFO]: Epoch 022 - training loss: 0.2902, validation loss: 0.2816
2024-05-23 04:38:09 [INFO]: Epoch 023 - training loss: 0.3231, validation loss: 0.2809
2024-05-23 04:38:12 [INFO]: Epoch 024 - training loss: 0.3228, validation loss: 0.2814
2024-05-23 04:38:16 [INFO]: Epoch 025 - training loss: 0.3250, validation loss: 0.2900
2024-05-23 04:38:19 [INFO]: Epoch 026 - training loss: 0.2977, validation loss: 0.2786
2024-05-23 04:38:23 [INFO]: Epoch 027 - training loss: 0.3088, validation loss: 0.2815
2024-05-23 04:38:27 [INFO]: Epoch 028 - training loss: 0.3087, validation loss: 0.2748
2024-05-23 04:38:30 [INFO]: Epoch 029 - training loss: 0.3148, validation loss: 0.2795
2024-05-23 04:38:35 [INFO]: Epoch 030 - training loss: 0.3339, validation loss: 0.2761
2024-05-23 04:38:38 [INFO]: Epoch 031 - training loss: 0.4341, validation loss: 0.2747
2024-05-23 04:38:42 [INFO]: Epoch 032 - training loss: 0.2894, validation loss: 0.2718
2024-05-23 04:38:46 [INFO]: Epoch 033 - training loss: 0.3796, validation loss: 0.2746
2024-05-23 04:38:49 [INFO]: Epoch 034 - training loss: 0.2912, validation loss: 0.2726
2024-05-23 04:38:53 [INFO]: Epoch 035 - training loss: 0.2854, validation loss: 0.2723
2024-05-23 04:38:56 [INFO]: Epoch 036 - training loss: 0.3316, validation loss: 0.2709
2024-05-23 04:39:00 [INFO]: Epoch 037 - training loss: 0.3095, validation loss: 0.2702
2024-05-23 04:39:03 [INFO]: Epoch 038 - training loss: 0.3653, validation loss: 0.2698
2024-05-23 04:39:07 [INFO]: Epoch 039 - training loss: 0.3688, validation loss: 0.2746
2024-05-23 04:39:11 [INFO]: Epoch 040 - training loss: 0.3021, validation loss: 0.2674
2024-05-23 04:39:14 [INFO]: Epoch 041 - training loss: 0.3298, validation loss: 0.2766
2024-05-23 04:39:18 [INFO]: Epoch 042 - training loss: 0.3633, validation loss: 0.2694
2024-05-23 04:39:21 [INFO]: Epoch 043 - training loss: 0.3412, validation loss: 0.2721
2024-05-23 04:39:25 [INFO]: Epoch 044 - training loss: 0.2919, validation loss: 0.2738
2024-05-23 04:39:28 [INFO]: Epoch 045 - training loss: 0.2907, validation loss: 0.2667
2024-05-23 04:39:32 [INFO]: Epoch 046 - training loss: 0.2963, validation loss: 0.2663
2024-05-23 04:39:36 [INFO]: Epoch 047 - training loss: 0.3002, validation loss: 0.2796
2024-05-23 04:39:39 [INFO]: Epoch 048 - training loss: 0.3328, validation loss: 0.2652
2024-05-23 04:39:43 [INFO]: Epoch 049 - training loss: 0.3002, validation loss: 0.2797
2024-05-23 04:39:46 [INFO]: Epoch 050 - training loss: 0.3052, validation loss: 0.2729
2024-05-23 04:39:50 [INFO]: Epoch 051 - training loss: 0.2786, validation loss: 0.2712
2024-05-23 04:39:53 [INFO]: Epoch 052 - training loss: 0.3230, validation loss: 0.2618
2024-05-23 04:39:57 [INFO]: Epoch 053 - training loss: 0.2839, validation loss: 0.2642
2024-05-23 04:40:00 [INFO]: Epoch 054 - training loss: 0.2902, validation loss: 0.2613
2024-05-23 04:40:04 [INFO]: Epoch 055 - training loss: 0.2939, validation loss: 0.2644
2024-05-23 04:40:07 [INFO]: Epoch 056 - training loss: 0.3934, validation loss: 0.2625
2024-05-23 04:40:11 [INFO]: Epoch 057 - training loss: 0.3467, validation loss: 0.2657
2024-05-23 04:40:15 [INFO]: Epoch 058 - training loss: 0.3499, validation loss: 0.2618
2024-05-23 04:40:18 [INFO]: Epoch 059 - training loss: 0.2859, validation loss: 0.2618
2024-05-23 04:40:22 [INFO]: Epoch 060 - training loss: 0.3558, validation loss: 0.2615
2024-05-23 04:40:25 [INFO]: Epoch 061 - training loss: 0.2812, validation loss: 0.2637
2024-05-23 04:40:29 [INFO]: Epoch 062 - training loss: 0.2786, validation loss: 0.2680
2024-05-23 04:40:33 [INFO]: Epoch 063 - training loss: 0.3298, validation loss: 0.2637
2024-05-23 04:40:36 [INFO]: Epoch 064 - training loss: 0.2780, validation loss: 0.2635
2024-05-23 04:40:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 04:40:36 [INFO]: Finished training. The best model is from epoch#54.
2024-05-23 04:40:36 [INFO]: Saved the model to saved_results/round_3/TimesNet_physionet2012/20240523_T043644/TimesNet.pypots
2024-05-23 04:40:37 [INFO]: TimesNet on PhysioNet-2012: MAE=0.2598, MSE=0.2670
2024-05-23 04:40:38 [INFO]: Successfully saved to saved_results/round_3/TimesNet_physionet2012/imputation.pkl
2024-05-23 04:40:38 [INFO]: Using the given device: cuda:0
2024-05-23 04:40:38 [INFO]: Model files will be saved to saved_results/round_3/CSDI_physionet2012/20240523_T044038
2024-05-23 04:40:38 [INFO]: Tensorboard file will be saved to saved_results/round_3/CSDI_physionet2012/20240523_T044038/tensorboard
2024-05-23 04:40:38 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-23 04:43:00 [INFO]: Epoch 001 - training loss: 0.3404, validation loss: 0.2514
2024-05-23 04:43:00 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch1_loss0.2514394814769427.pypots
2024-05-23 04:45:23 [INFO]: Epoch 002 - training loss: 0.2641, validation loss: 0.2139
2024-05-23 04:45:23 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch2_loss0.21388084664940835.pypots
2024-05-23 04:47:46 [INFO]: Epoch 003 - training loss: 0.2528, validation loss: 0.2041
2024-05-23 04:47:46 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch3_loss0.2041112187008063.pypots
2024-05-23 04:50:09 [INFO]: Epoch 004 - training loss: 0.2407, validation loss: 0.1982
2024-05-23 04:50:09 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch4_loss0.1982172794640064.pypots
2024-05-23 04:52:32 [INFO]: Epoch 005 - training loss: 0.2419, validation loss: 0.1944
2024-05-23 04:52:32 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch5_loss0.19442998891075453.pypots
2024-05-23 04:54:55 [INFO]: Epoch 006 - training loss: 0.2347, validation loss: 0.1905
2024-05-23 04:54:55 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch6_loss0.19045479968190193.pypots
2024-05-23 04:57:18 [INFO]: Epoch 007 - training loss: 0.2313, validation loss: 0.1901
2024-05-23 04:57:18 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch7_loss0.19009210442503294.pypots
2024-05-23 04:59:41 [INFO]: Epoch 008 - training loss: 0.2213, validation loss: 0.1866
2024-05-23 04:59:41 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch8_loss0.18660247102379798.pypots
2024-05-23 05:02:04 [INFO]: Epoch 009 - training loss: 0.2312, validation loss: 0.1842
2024-05-23 05:02:04 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch9_loss0.18418611312905947.pypots
2024-05-23 05:04:27 [INFO]: Epoch 010 - training loss: 0.2214, validation loss: 0.1829
2024-05-23 05:04:27 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch10_loss0.18294269268711408.pypots
2024-05-23 05:06:50 [INFO]: Epoch 011 - training loss: 0.2287, validation loss: 0.1807
2024-05-23 05:06:50 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch11_loss0.18073563600579898.pypots
2024-05-23 05:09:13 [INFO]: Epoch 012 - training loss: 0.2173, validation loss: 0.1831
2024-05-23 05:09:13 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch12_loss0.18312753488620123.pypots
2024-05-23 05:11:36 [INFO]: Epoch 013 - training loss: 0.2274, validation loss: 0.1800
2024-05-23 05:11:36 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch13_loss0.17999068299929302.pypots
2024-05-23 05:13:59 [INFO]: Epoch 014 - training loss: 0.2225, validation loss: 0.1806
2024-05-23 05:13:59 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch14_loss0.1806252953906854.pypots
2024-05-23 05:16:22 [INFO]: Epoch 015 - training loss: 0.2189, validation loss: 0.1792
2024-05-23 05:16:22 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch15_loss0.1791701023777326.pypots
2024-05-23 05:18:45 [INFO]: Epoch 016 - training loss: 0.2181, validation loss: 0.1779
2024-05-23 05:18:45 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch16_loss0.1778597148756186.pypots
2024-05-23 05:21:08 [INFO]: Epoch 017 - training loss: 0.2219, validation loss: 0.1804
2024-05-23 05:21:08 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch17_loss0.18038355559110641.pypots
2024-05-23 05:23:31 [INFO]: Epoch 018 - training loss: 0.2222, validation loss: 0.1789
2024-05-23 05:23:31 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch18_loss0.17893837342659633.pypots
2024-05-23 05:25:54 [INFO]: Epoch 019 - training loss: 0.2241, validation loss: 0.1768
2024-05-23 05:25:54 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch19_loss0.1768193485836188.pypots
2024-05-23 05:28:17 [INFO]: Epoch 020 - training loss: 0.2208, validation loss: 0.1745
2024-05-23 05:28:17 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch20_loss0.17450869729121526.pypots
2024-05-23 05:30:40 [INFO]: Epoch 021 - training loss: 0.2219, validation loss: 0.1762
2024-05-23 05:30:40 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch21_loss0.17624989673495292.pypots
2024-05-23 05:33:03 [INFO]: Epoch 022 - training loss: 0.2189, validation loss: 0.1775
2024-05-23 05:33:03 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch22_loss0.1775069423019886.pypots
2024-05-23 05:35:26 [INFO]: Epoch 023 - training loss: 0.2167, validation loss: 0.1752
2024-05-23 05:35:27 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch23_loss0.17523864681522053.pypots
2024-05-23 05:37:50 [INFO]: Epoch 024 - training loss: 0.2213, validation loss: 0.1736
2024-05-23 05:37:50 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch24_loss0.17362503781914712.pypots
2024-05-23 05:40:13 [INFO]: Epoch 025 - training loss: 0.2170, validation loss: 0.1722
2024-05-23 05:40:13 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch25_loss0.1722259946167469.pypots
2024-05-23 05:42:36 [INFO]: Epoch 026 - training loss: 0.2194, validation loss: 0.1750
2024-05-23 05:42:36 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch26_loss0.17496318221092225.pypots
2024-05-23 05:44:59 [INFO]: Epoch 027 - training loss: 0.2157, validation loss: 0.1763
2024-05-23 05:44:59 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch27_loss0.17627200161417325.pypots
2024-05-23 05:47:22 [INFO]: Epoch 028 - training loss: 0.2154, validation loss: 0.1725
2024-05-23 05:47:22 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch28_loss0.17245392203330995.pypots
2024-05-23 05:49:45 [INFO]: Epoch 029 - training loss: 0.2177, validation loss: 0.1723
2024-05-23 05:49:45 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch29_loss0.17227596789598465.pypots
2024-05-23 05:52:08 [INFO]: Epoch 030 - training loss: 0.2212, validation loss: 0.1740
2024-05-23 05:52:08 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch30_loss0.17400359312693278.pypots
2024-05-23 05:54:31 [INFO]: Epoch 031 - training loss: 0.2236, validation loss: 0.1723
2024-05-23 05:54:31 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch31_loss0.17225410913427672.pypots
2024-05-23 05:56:54 [INFO]: Epoch 032 - training loss: 0.2177, validation loss: 0.1705
2024-05-23 05:56:54 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch32_loss0.1705365739762783.pypots
2024-05-23 05:59:17 [INFO]: Epoch 033 - training loss: 0.2150, validation loss: 0.1710
2024-05-23 05:59:17 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch33_loss0.1710234709084034.pypots
2024-05-23 06:01:40 [INFO]: Epoch 034 - training loss: 0.2140, validation loss: 0.1689
2024-05-23 06:01:40 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch34_loss0.1688754864037037.pypots
2024-05-23 06:04:03 [INFO]: Epoch 035 - training loss: 0.2148, validation loss: 0.1697
2024-05-23 06:04:03 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch35_loss0.16972364857792854.pypots
2024-05-23 06:06:26 [INFO]: Epoch 036 - training loss: 0.2226, validation loss: 0.1689
2024-05-23 06:06:26 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch36_loss0.16887728398044904.pypots
2024-05-23 06:08:49 [INFO]: Epoch 037 - training loss: 0.2126, validation loss: 0.1702
2024-05-23 06:08:49 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch37_loss0.1702483519911766.pypots
2024-05-23 06:11:11 [INFO]: Epoch 038 - training loss: 0.2188, validation loss: 0.1697
2024-05-23 06:11:11 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch38_loss0.16969562619924544.pypots
2024-05-23 06:13:34 [INFO]: Epoch 039 - training loss: 0.2107, validation loss: 0.1669
2024-05-23 06:13:34 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch39_loss0.166931464523077.pypots
2024-05-23 06:15:57 [INFO]: Epoch 040 - training loss: 0.2066, validation loss: 0.1678
2024-05-23 06:15:57 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch40_loss0.1678209535777569.pypots
2024-05-23 06:18:20 [INFO]: Epoch 041 - training loss: 0.2087, validation loss: 0.1693
2024-05-23 06:18:20 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch41_loss0.1693044123550256.pypots
2024-05-23 06:20:43 [INFO]: Epoch 042 - training loss: 0.2208, validation loss: 0.1683
2024-05-23 06:20:43 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch42_loss0.16829802617430686.pypots
2024-05-23 06:23:06 [INFO]: Epoch 043 - training loss: 0.2096, validation loss: 0.1680
2024-05-23 06:23:06 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch43_loss0.16803283567229907.pypots
2024-05-23 06:25:29 [INFO]: Epoch 044 - training loss: 0.2060, validation loss: 0.1683
2024-05-23 06:25:29 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch44_loss0.16830966497461.pypots
2024-05-23 06:27:52 [INFO]: Epoch 045 - training loss: 0.2131, validation loss: 0.1659
2024-05-23 06:27:52 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch45_loss0.1658674898246924.pypots
2024-05-23 06:30:15 [INFO]: Epoch 046 - training loss: 0.2066, validation loss: 0.1669
2024-05-23 06:30:15 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch46_loss0.16685535262028375.pypots
2024-05-23 06:32:38 [INFO]: Epoch 047 - training loss: 0.2078, validation loss: 0.1716
2024-05-23 06:32:38 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch47_loss0.17162961463133494.pypots
2024-05-23 06:35:01 [INFO]: Epoch 048 - training loss: 0.2090, validation loss: 0.1665
2024-05-23 06:35:01 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch48_loss0.16645161708196005.pypots
2024-05-23 06:37:23 [INFO]: Epoch 049 - training loss: 0.2120, validation loss: 0.1660
2024-05-23 06:37:23 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch49_loss0.16597031876444818.pypots
2024-05-23 06:39:46 [INFO]: Epoch 050 - training loss: 0.2113, validation loss: 0.1680
2024-05-23 06:39:46 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch50_loss0.16803022722403207.pypots
2024-05-23 06:42:09 [INFO]: Epoch 051 - training loss: 0.2094, validation loss: 0.1690
2024-05-23 06:42:09 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch51_loss0.16899364615480106.pypots
2024-05-23 06:44:32 [INFO]: Epoch 052 - training loss: 0.2101, validation loss: 0.1686
2024-05-23 06:44:32 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch52_loss0.16863348310192425.pypots
2024-05-23 06:46:55 [INFO]: Epoch 053 - training loss: 0.2057, validation loss: 0.1665
2024-05-23 06:46:55 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch53_loss0.16651383663217226.pypots
2024-05-23 06:49:17 [INFO]: Epoch 054 - training loss: 0.2066, validation loss: 0.1674
2024-05-23 06:49:18 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch54_loss0.16736498177051545.pypots
2024-05-23 06:51:40 [INFO]: Epoch 055 - training loss: 0.2094, validation loss: 0.1646
2024-05-23 06:51:40 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch55_loss0.1645565077662468.pypots
2024-05-23 06:54:03 [INFO]: Epoch 056 - training loss: 0.2108, validation loss: 0.1679
2024-05-23 06:54:03 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch56_loss0.16792936051885288.pypots
2024-05-23 06:56:26 [INFO]: Epoch 057 - training loss: 0.2114, validation loss: 0.1658
2024-05-23 06:56:26 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch57_loss0.16576576679944993.pypots
2024-05-23 06:58:49 [INFO]: Epoch 058 - training loss: 0.2101, validation loss: 0.1659
2024-05-23 06:58:49 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch58_loss0.16589739074309667.pypots
2024-05-23 07:01:11 [INFO]: Epoch 059 - training loss: 0.2092, validation loss: 0.1658
2024-05-23 07:01:11 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch59_loss0.16583596542477608.pypots
2024-05-23 07:03:34 [INFO]: Epoch 060 - training loss: 0.2093, validation loss: 0.1632
2024-05-23 07:03:34 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch60_loss0.16322489852706593.pypots
2024-05-23 07:05:57 [INFO]: Epoch 061 - training loss: 0.2125, validation loss: 0.1656
2024-05-23 07:05:57 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch61_loss0.16556718250115712.pypots
2024-05-23 07:08:20 [INFO]: Epoch 062 - training loss: 0.2133, validation loss: 0.1646
2024-05-23 07:08:20 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch62_loss0.16461208934585253.pypots
2024-05-23 07:10:43 [INFO]: Epoch 063 - training loss: 0.2082, validation loss: 0.1632
2024-05-23 07:10:43 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch63_loss0.16323630859454472.pypots
2024-05-23 07:13:06 [INFO]: Epoch 064 - training loss: 0.2032, validation loss: 0.1646
2024-05-23 07:13:06 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch64_loss0.164594350506862.pypots
2024-05-23 07:15:29 [INFO]: Epoch 065 - training loss: 0.2101, validation loss: 0.1640
2024-05-23 07:15:29 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch65_loss0.16402508889635403.pypots
2024-05-23 07:17:52 [INFO]: Epoch 066 - training loss: 0.2085, validation loss: 0.1634
2024-05-23 07:17:52 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch66_loss0.1633581039806207.pypots
2024-05-23 07:20:15 [INFO]: Epoch 067 - training loss: 0.2115, validation loss: 0.1646
2024-05-23 07:20:15 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch67_loss0.1646427606542905.pypots
2024-05-23 07:22:38 [INFO]: Epoch 068 - training loss: 0.2036, validation loss: 0.1637
2024-05-23 07:22:38 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch68_loss0.16366457243760427.pypots
2024-05-23 07:25:01 [INFO]: Epoch 069 - training loss: 0.2110, validation loss: 0.1642
2024-05-23 07:25:01 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch69_loss0.16424699475367863.pypots
2024-05-23 07:27:24 [INFO]: Epoch 070 - training loss: 0.2059, validation loss: 0.1629
2024-05-23 07:27:24 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch70_loss0.1629214107990265.pypots
2024-05-23 07:29:46 [INFO]: Epoch 071 - training loss: 0.2135, validation loss: 0.1636
2024-05-23 07:29:46 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch71_loss0.16358420153458914.pypots
2024-05-23 07:32:09 [INFO]: Epoch 072 - training loss: 0.2043, validation loss: 0.1629
2024-05-23 07:32:09 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch72_loss0.16287523011366525.pypots
2024-05-23 07:34:32 [INFO]: Epoch 073 - training loss: 0.2049, validation loss: 0.1638
2024-05-23 07:34:32 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch73_loss0.16383480702837308.pypots
2024-05-23 07:36:55 [INFO]: Epoch 074 - training loss: 0.2061, validation loss: 0.1624
2024-05-23 07:36:55 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch74_loss0.16239646226167678.pypots
2024-05-23 07:39:18 [INFO]: Epoch 075 - training loss: 0.2007, validation loss: 0.1641
2024-05-23 07:39:18 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch75_loss0.1640846808751424.pypots
2024-05-23 07:41:41 [INFO]: Epoch 076 - training loss: 0.2053, validation loss: 0.1623
2024-05-23 07:41:41 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch76_loss0.16234445373217266.pypots
2024-05-23 07:44:04 [INFO]: Epoch 077 - training loss: 0.2113, validation loss: 0.1626
2024-05-23 07:44:04 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch77_loss0.16261593028903007.pypots
2024-05-23 07:46:27 [INFO]: Epoch 078 - training loss: 0.2098, validation loss: 0.1624
2024-05-23 07:46:27 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch78_loss0.1623648372789224.pypots
2024-05-23 07:48:50 [INFO]: Epoch 079 - training loss: 0.2034, validation loss: 0.1648
2024-05-23 07:48:50 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch79_loss0.16480539565285046.pypots
2024-05-23 07:51:13 [INFO]: Epoch 080 - training loss: 0.1983, validation loss: 0.1640
2024-05-23 07:51:13 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch80_loss0.16398817946513494.pypots
2024-05-23 07:53:36 [INFO]: Epoch 081 - training loss: 0.2066, validation loss: 0.1628
2024-05-23 07:53:36 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch81_loss0.162756401548783.pypots
2024-05-23 07:55:59 [INFO]: Epoch 082 - training loss: 0.2096, validation loss: 0.1631
2024-05-23 07:55:59 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch82_loss0.16310610522826513.pypots
2024-05-23 07:58:21 [INFO]: Epoch 083 - training loss: 0.2053, validation loss: 0.1631
2024-05-23 07:58:22 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch83_loss0.1631107951203982.pypots
2024-05-23 08:00:44 [INFO]: Epoch 084 - training loss: 0.1999, validation loss: 0.1612
2024-05-23 08:00:44 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch84_loss0.16120024621486664.pypots
2024-05-23 08:03:07 [INFO]: Epoch 085 - training loss: 0.2015, validation loss: 0.1617
2024-05-23 08:03:07 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch85_loss0.16171776379148164.pypots
2024-05-23 08:05:30 [INFO]: Epoch 086 - training loss: 0.2047, validation loss: 0.1603
2024-05-23 08:05:30 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch86_loss0.16025641237696012.pypots
2024-05-23 08:07:53 [INFO]: Epoch 087 - training loss: 0.2010, validation loss: 0.1610
2024-05-23 08:07:53 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch87_loss0.16104493662714958.pypots
2024-05-23 08:10:16 [INFO]: Epoch 088 - training loss: 0.2049, validation loss: 0.1616
2024-05-23 08:10:16 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch88_loss0.16156688680251438.pypots
2024-05-23 08:12:39 [INFO]: Epoch 089 - training loss: 0.2037, validation loss: 0.1614
2024-05-23 08:12:39 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch89_loss0.16141385833422342.pypots
2024-05-23 08:15:02 [INFO]: Epoch 090 - training loss: 0.2088, validation loss: 0.1611
2024-05-23 08:15:02 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch90_loss0.16107548202077548.pypots
2024-05-23 08:17:25 [INFO]: Epoch 091 - training loss: 0.2047, validation loss: 0.1618
2024-05-23 08:17:25 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch91_loss0.16181488980849584.pypots
2024-05-23 08:19:47 [INFO]: Epoch 092 - training loss: 0.2018, validation loss: 0.1607
2024-05-23 08:19:47 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch92_loss0.16066849033037822.pypots
2024-05-23 08:22:10 [INFO]: Epoch 093 - training loss: 0.2017, validation loss: 0.1618
2024-05-23 08:22:10 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch93_loss0.16175449043512344.pypots
2024-05-23 08:24:33 [INFO]: Epoch 094 - training loss: 0.2026, validation loss: 0.1606
2024-05-23 08:24:33 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch94_loss0.16060430879394214.pypots
2024-05-23 08:26:56 [INFO]: Epoch 095 - training loss: 0.2010, validation loss: 0.1607
2024-05-23 08:26:56 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch95_loss0.16073459684848784.pypots
2024-05-23 08:29:19 [INFO]: Epoch 096 - training loss: 0.2083, validation loss: 0.1610
2024-05-23 08:29:19 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI_epoch96_loss0.16104255219300587.pypots
2024-05-23 08:29:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 08:29:19 [INFO]: Finished training. The best model is from epoch#86.
2024-05-23 08:29:19 [INFO]: Saved the model to saved_results/round_3/CSDI_physionet2012/20240523_T044038/CSDI.pypots
2024-05-23 08:53:07 [INFO]: CSDI on PhysioNet-2012: MAE=0.2157, MSE=0.2842
2024-05-23 10:28:17 [INFO]: Successfully saved to saved_results/round_3/CSDI_physionet2012/imputation.pkl
2024-05-23 10:28:17 [INFO]: Using the given device: cuda:0
2024-05-23 10:28:17 [INFO]: Model files will be saved to saved_results/round_3/GPVAE_physionet2012/20240523_T102817
2024-05-23 10:28:17 [INFO]: Tensorboard file will be saved to saved_results/round_3/GPVAE_physionet2012/20240523_T102817/tensorboard
2024-05-23 10:28:17 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-23 10:28:21 [INFO]: Epoch 001 - training loss: 29954.3569, validation loss: 0.6976
2024-05-23 10:28:25 [INFO]: Epoch 002 - training loss: 23126.7776, validation loss: 0.6518
2024-05-23 10:28:29 [INFO]: Epoch 003 - training loss: 22941.5416, validation loss: 0.6507
2024-05-23 10:28:33 [INFO]: Epoch 004 - training loss: 22882.7428, validation loss: 0.6435
2024-05-23 10:28:37 [INFO]: Epoch 005 - training loss: 22859.1240, validation loss: 0.6328
2024-05-23 10:28:41 [INFO]: Epoch 006 - training loss: 22847.2186, validation loss: 0.6291
2024-05-23 10:28:45 [INFO]: Epoch 007 - training loss: 22839.8385, validation loss: 0.6262
2024-05-23 10:28:49 [INFO]: Epoch 008 - training loss: 22835.6396, validation loss: 0.6119
2024-05-23 10:28:53 [INFO]: Epoch 009 - training loss: 22830.9000, validation loss: 0.6063
2024-05-23 10:28:57 [INFO]: Epoch 010 - training loss: 22828.2992, validation loss: 0.6036
2024-05-23 10:29:01 [INFO]: Epoch 011 - training loss: 22825.6480, validation loss: 0.5931
2024-05-23 10:29:05 [INFO]: Epoch 012 - training loss: 22823.5836, validation loss: 0.5812
2024-05-23 10:29:09 [INFO]: Epoch 013 - training loss: 22820.3726, validation loss: 0.5601
2024-05-23 10:29:13 [INFO]: Epoch 014 - training loss: 22817.5655, validation loss: 0.5531
2024-05-23 10:29:17 [INFO]: Epoch 015 - training loss: 22814.9192, validation loss: 0.5468
2024-05-23 10:29:21 [INFO]: Epoch 016 - training loss: 22811.6981, validation loss: 0.5326
2024-05-23 10:29:25 [INFO]: Epoch 017 - training loss: 22809.9573, validation loss: 0.5305
2024-05-23 10:29:29 [INFO]: Epoch 018 - training loss: 22808.7217, validation loss: 0.5269
2024-05-23 10:29:34 [INFO]: Epoch 019 - training loss: 22807.6383, validation loss: 0.5187
2024-05-23 10:29:38 [INFO]: Epoch 020 - training loss: 22805.0590, validation loss: 0.5139
2024-05-23 10:29:42 [INFO]: Epoch 021 - training loss: 22802.9208, validation loss: 0.5082
2024-05-23 10:29:46 [INFO]: Epoch 022 - training loss: 22801.9749, validation loss: 0.5045
2024-05-23 10:29:50 [INFO]: Epoch 023 - training loss: 22801.6274, validation loss: 0.5038
2024-05-23 10:29:54 [INFO]: Epoch 024 - training loss: 22800.7906, validation loss: 0.4996
2024-05-23 10:29:58 [INFO]: Epoch 025 - training loss: 22799.2566, validation loss: 0.4997
2024-05-23 10:30:02 [INFO]: Epoch 026 - training loss: 22798.9645, validation loss: 0.4930
2024-05-23 10:30:06 [INFO]: Epoch 027 - training loss: 22797.7411, validation loss: 0.4892
2024-05-23 10:30:10 [INFO]: Epoch 028 - training loss: 22796.7165, validation loss: 0.4849
2024-05-23 10:30:14 [INFO]: Epoch 029 - training loss: 22796.3114, validation loss: 0.4936
2024-05-23 10:30:18 [INFO]: Epoch 030 - training loss: 22795.1801, validation loss: 0.4789
2024-05-23 10:30:22 [INFO]: Epoch 031 - training loss: 22794.3887, validation loss: 0.4746
2024-05-23 10:30:26 [INFO]: Epoch 032 - training loss: 22794.0483, validation loss: 0.4756
2024-05-23 10:30:30 [INFO]: Epoch 033 - training loss: 22793.6230, validation loss: 0.4752
2024-05-23 10:30:34 [INFO]: Epoch 034 - training loss: 22792.1021, validation loss: 0.4667
2024-05-23 10:30:39 [INFO]: Epoch 035 - training loss: 22792.3240, validation loss: 0.4706
2024-05-23 10:30:43 [INFO]: Epoch 036 - training loss: 22791.2817, validation loss: 0.4629
2024-05-23 10:30:47 [INFO]: Epoch 037 - training loss: 22790.7576, validation loss: 0.4634
2024-05-23 10:30:51 [INFO]: Epoch 038 - training loss: 22789.9382, validation loss: 0.4638
2024-05-23 10:30:54 [INFO]: Epoch 039 - training loss: 22789.7436, validation loss: 0.4612
2024-05-23 10:30:58 [INFO]: Epoch 040 - training loss: 22790.0870, validation loss: 0.4582
2024-05-23 10:31:02 [INFO]: Epoch 041 - training loss: 22788.6606, validation loss: 0.4587
2024-05-23 10:31:06 [INFO]: Epoch 042 - training loss: 22788.0588, validation loss: 0.4645
2024-05-23 10:31:10 [INFO]: Epoch 043 - training loss: 22787.8283, validation loss: 0.4530
2024-05-23 10:31:15 [INFO]: Epoch 044 - training loss: 22787.0569, validation loss: 0.4527
2024-05-23 10:31:19 [INFO]: Epoch 045 - training loss: 22786.7697, validation loss: 0.4486
2024-05-23 10:31:23 [INFO]: Epoch 046 - training loss: 22786.2342, validation loss: 0.4554
2024-05-23 10:31:27 [INFO]: Epoch 047 - training loss: 22786.9618, validation loss: 0.4512
2024-05-23 10:31:31 [INFO]: Epoch 048 - training loss: 22786.7887, validation loss: 0.4515
2024-05-23 10:31:35 [INFO]: Epoch 049 - training loss: 22786.7197, validation loss: 0.4538
2024-05-23 10:31:39 [INFO]: Epoch 050 - training loss: 22785.3568, validation loss: 0.4515
2024-05-23 10:31:43 [INFO]: Epoch 051 - training loss: 22784.9973, validation loss: 0.4530
2024-05-23 10:31:47 [INFO]: Epoch 052 - training loss: 22784.6936, validation loss: 0.4518
2024-05-23 10:31:51 [INFO]: Epoch 053 - training loss: 22784.0159, validation loss: 0.4533
2024-05-23 10:31:55 [INFO]: Epoch 054 - training loss: 22783.8240, validation loss: 0.4520
2024-05-23 10:31:59 [INFO]: Epoch 055 - training loss: 22783.6223, validation loss: 0.4494
2024-05-23 10:31:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 10:31:59 [INFO]: Finished training. The best model is from epoch#45.
2024-05-23 10:31:59 [INFO]: Saved the model to saved_results/round_3/GPVAE_physionet2012/20240523_T102817/GPVAE.pypots
2024-05-23 10:32:00 [INFO]: GP-VAE on PhysioNet-2012: MAE=0.4081, MSE=0.4475
2024-05-23 10:32:02 [INFO]: Successfully saved to saved_results/round_3/GPVAE_physionet2012/imputation.pkl
2024-05-23 10:32:02 [INFO]: Using the given device: cuda:0
2024-05-23 10:32:02 [INFO]: Model files will be saved to saved_results/round_3/USGAN_physionet2012/20240523_T103202
2024-05-23 10:32:02 [INFO]: Tensorboard file will be saved to saved_results/round_3/USGAN_physionet2012/20240523_T103202/tensorboard
2024-05-23 10:32:02 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-23 10:34:12 [INFO]: Epoch 001 - generator training loss: 0.4956, discriminator training loss: 0.2832, validation loss: 0.4772
2024-05-23 10:36:04 [INFO]: Epoch 002 - generator training loss: 0.4444, discriminator training loss: 0.1295, validation loss: 0.4289
2024-05-23 10:38:03 [INFO]: Epoch 003 - generator training loss: 0.4149, discriminator training loss: 0.0820, validation loss: 0.3995
2024-05-23 10:40:06 [INFO]: Epoch 004 - generator training loss: 0.3933, discriminator training loss: 0.0617, validation loss: 0.3793
2024-05-23 10:42:10 [INFO]: Epoch 005 - generator training loss: 0.3832, discriminator training loss: 0.0499, validation loss: 0.3648
2024-05-23 10:44:12 [INFO]: Epoch 006 - generator training loss: 0.3693, discriminator training loss: 0.0425, validation loss: 0.3457
2024-05-23 10:46:17 [INFO]: Epoch 007 - generator training loss: 0.3593, discriminator training loss: 0.0376, validation loss: 0.3402
2024-05-23 10:48:15 [INFO]: Epoch 008 - generator training loss: 0.3482, discriminator training loss: 0.0343, validation loss: 0.3286
2024-05-23 10:50:13 [INFO]: Epoch 009 - generator training loss: 0.3400, discriminator training loss: 0.0318, validation loss: 0.3208
2024-05-23 10:52:07 [INFO]: Epoch 010 - generator training loss: 0.3307, discriminator training loss: 0.0300, validation loss: 0.3139
2024-05-23 10:54:01 [INFO]: Epoch 011 - generator training loss: 0.3241, discriminator training loss: 0.0288, validation loss: 0.3075
2024-05-23 10:55:55 [INFO]: Epoch 012 - generator training loss: 0.3155, discriminator training loss: 0.0276, validation loss: 0.3051
2024-05-23 10:57:47 [INFO]: Epoch 013 - generator training loss: 0.3090, discriminator training loss: 0.0267, validation loss: 0.3003
2024-05-23 10:59:40 [INFO]: Epoch 014 - generator training loss: 0.3022, discriminator training loss: 0.0259, validation loss: 0.2985
2024-05-23 11:01:29 [INFO]: Epoch 015 - generator training loss: 0.2964, discriminator training loss: 0.0251, validation loss: 0.2917
2024-05-23 11:03:18 [INFO]: Epoch 016 - generator training loss: 0.2916, discriminator training loss: 0.0246, validation loss: 0.2869
2024-05-23 11:05:09 [INFO]: Epoch 017 - generator training loss: 0.2877, discriminator training loss: 0.0241, validation loss: 0.2937
2024-05-23 11:07:00 [INFO]: Epoch 018 - generator training loss: 0.2846, discriminator training loss: 0.0236, validation loss: 0.2882
2024-05-23 11:08:51 [INFO]: Epoch 019 - generator training loss: 0.2780, discriminator training loss: 0.0231, validation loss: 0.2789
2024-05-23 11:10:44 [INFO]: Epoch 020 - generator training loss: 0.2743, discriminator training loss: 0.0227, validation loss: 0.2776
2024-05-23 11:12:35 [INFO]: Epoch 021 - generator training loss: 0.2774, discriminator training loss: 0.0224, validation loss: 0.2777
2024-05-23 11:14:26 [INFO]: Epoch 022 - generator training loss: 0.2700, discriminator training loss: 0.0221, validation loss: 0.2779
2024-05-23 11:16:19 [INFO]: Epoch 023 - generator training loss: 0.2677, discriminator training loss: 0.0217, validation loss: 0.2782
2024-05-23 11:18:22 [INFO]: Epoch 024 - generator training loss: 0.2643, discriminator training loss: 0.0214, validation loss: 0.2767
2024-05-23 11:20:22 [INFO]: Epoch 025 - generator training loss: 0.2619, discriminator training loss: 0.0211, validation loss: 0.2784
2024-05-23 11:22:19 [INFO]: Epoch 026 - generator training loss: 0.2609, discriminator training loss: 0.0207, validation loss: 0.2762
2024-05-23 11:24:17 [INFO]: Epoch 027 - generator training loss: 0.2625, discriminator training loss: 0.0206, validation loss: 0.2790
2024-05-23 11:26:15 [INFO]: Epoch 028 - generator training loss: 0.2554, discriminator training loss: 0.0203, validation loss: 0.2742
2024-05-23 11:28:14 [INFO]: Epoch 029 - generator training loss: 0.2579, discriminator training loss: 0.0204, validation loss: 0.2768
2024-05-23 11:30:18 [INFO]: Epoch 030 - generator training loss: 0.2528, discriminator training loss: 0.0203, validation loss: 0.2891
2024-05-23 11:32:19 [INFO]: Epoch 031 - generator training loss: 0.2538, discriminator training loss: 0.0203, validation loss: 0.2763
2024-05-23 11:34:17 [INFO]: Epoch 032 - generator training loss: 0.2483, discriminator training loss: 0.0202, validation loss: 0.2773
2024-05-23 11:36:14 [INFO]: Epoch 033 - generator training loss: 0.2528, discriminator training loss: 0.0200, validation loss: 0.2739
2024-05-23 11:38:09 [INFO]: Epoch 034 - generator training loss: 0.2452, discriminator training loss: 0.0199, validation loss: 0.2716
2024-05-23 11:40:04 [INFO]: Epoch 035 - generator training loss: 0.2433, discriminator training loss: 0.0199, validation loss: 0.2763
2024-05-23 11:42:01 [INFO]: Epoch 036 - generator training loss: 0.2442, discriminator training loss: 0.0197, validation loss: 0.2789
2024-05-23 11:43:58 [INFO]: Epoch 037 - generator training loss: 0.2438, discriminator training loss: 0.0196, validation loss: 0.2745
2024-05-23 11:45:55 [INFO]: Epoch 038 - generator training loss: 0.2395, discriminator training loss: 0.0195, validation loss: 0.2804
2024-05-23 11:47:56 [INFO]: Epoch 039 - generator training loss: 0.2357, discriminator training loss: 0.0194, validation loss: 0.2727
2024-05-23 11:49:54 [INFO]: Epoch 040 - generator training loss: 0.2343, discriminator training loss: 0.0193, validation loss: 0.2750
2024-05-23 11:51:53 [INFO]: Epoch 041 - generator training loss: 0.2323, discriminator training loss: 0.0191, validation loss: 0.2758
2024-05-23 11:53:50 [INFO]: Epoch 042 - generator training loss: 0.2297, discriminator training loss: 0.0191, validation loss: 0.2821
2024-05-23 11:55:49 [INFO]: Epoch 043 - generator training loss: 0.2371, discriminator training loss: 0.0191, validation loss: 0.2809
2024-05-23 11:57:44 [INFO]: Epoch 044 - generator training loss: 0.2376, discriminator training loss: 0.0189, validation loss: 0.2779
2024-05-23 11:57:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 11:57:44 [INFO]: Finished training. The best model is from epoch#34.
2024-05-23 11:57:44 [INFO]: Saved the model to saved_results/round_3/USGAN_physionet2012/20240523_T103202/USGAN.pypots
2024-05-23 11:57:58 [INFO]: US-GAN on PhysioNet-2012: MAE=0.2776, MSE=0.2792
2024-05-23 11:58:57 [INFO]: Successfully saved to saved_results/round_3/USGAN_physionet2012/imputation.pkl
2024-05-23 11:58:57 [INFO]: Using the given device: cuda:0
2024-05-23 11:58:57 [INFO]: Model files will be saved to saved_results/round_3/BRITS_physionet2012/20240523_T115857
2024-05-23 11:58:57 [INFO]: Tensorboard file will be saved to saved_results/round_3/BRITS_physionet2012/20240523_T115857/tensorboard
2024-05-23 11:58:57 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-23 12:00:33 [INFO]: Epoch 001 - training loss: 0.9496, validation loss: 0.4381
2024-05-23 12:01:50 [INFO]: Epoch 002 - training loss: 0.7778, validation loss: 0.3829
2024-05-23 12:03:06 [INFO]: Epoch 003 - training loss: 0.7157, validation loss: 0.3587
2024-05-23 12:04:22 [INFO]: Epoch 004 - training loss: 0.6790, validation loss: 0.3442
2024-05-23 12:05:41 [INFO]: Epoch 005 - training loss: 0.6556, validation loss: 0.3372
2024-05-23 12:07:02 [INFO]: Epoch 006 - training loss: 0.6400, validation loss: 0.3308
2024-05-23 12:08:20 [INFO]: Epoch 007 - training loss: 0.6294, validation loss: 0.3297
2024-05-23 12:09:32 [INFO]: Epoch 008 - training loss: 0.6211, validation loss: 0.3260
2024-05-23 12:10:46 [INFO]: Epoch 009 - training loss: 0.6137, validation loss: 0.3241
2024-05-23 12:12:00 [INFO]: Epoch 010 - training loss: 0.6073, validation loss: 0.3273
2024-05-23 12:13:14 [INFO]: Epoch 011 - training loss: 0.6012, validation loss: 0.3263
2024-05-23 12:14:30 [INFO]: Epoch 012 - training loss: 0.5960, validation loss: 0.3283
2024-05-23 12:15:56 [INFO]: Epoch 013 - training loss: 0.5928, validation loss: 0.3261
2024-05-23 12:17:23 [INFO]: Epoch 014 - training loss: 0.5854, validation loss: 0.3235
2024-05-23 12:18:46 [INFO]: Epoch 015 - training loss: 0.5828, validation loss: 0.3294
2024-05-23 12:20:10 [INFO]: Epoch 016 - training loss: 0.5780, validation loss: 0.3269
2024-05-23 12:21:29 [INFO]: Epoch 017 - training loss: 0.5738, validation loss: 0.3297
2024-05-23 12:22:44 [INFO]: Epoch 018 - training loss: 0.5767, validation loss: 0.3347
2024-05-23 12:23:57 [INFO]: Epoch 019 - training loss: 0.5682, validation loss: 0.3340
2024-05-23 12:25:12 [INFO]: Epoch 020 - training loss: 0.5649, validation loss: 0.3385
2024-05-23 12:26:27 [INFO]: Epoch 021 - training loss: 0.5627, validation loss: 0.3382
2024-05-23 12:27:54 [INFO]: Epoch 022 - training loss: 0.5621, validation loss: 0.3475
2024-05-23 12:29:22 [INFO]: Epoch 023 - training loss: 0.5601, validation loss: 0.3416
2024-05-23 12:30:45 [INFO]: Epoch 024 - training loss: 0.5547, validation loss: 0.3409
2024-05-23 12:30:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 12:30:45 [INFO]: Finished training. The best model is from epoch#14.
2024-05-23 12:30:45 [INFO]: Saved the model to saved_results/round_3/BRITS_physionet2012/20240523_T115857/BRITS.pypots
2024-05-23 12:31:00 [INFO]: BRITS on PhysioNet-2012: MAE=0.2454, MSE=0.3268
2024-05-23 12:31:58 [INFO]: Successfully saved to saved_results/round_3/BRITS_physionet2012/imputation.pkl
2024-05-23 12:31:58 [INFO]: Using the given device: cuda:0
2024-05-23 12:31:58 [INFO]: Model files will be saved to saved_results/round_3/MRNN_physionet2012/20240523_T123158
2024-05-23 12:31:58 [INFO]: Tensorboard file will be saved to saved_results/round_3/MRNN_physionet2012/20240523_T123158/tensorboard
2024-05-23 12:31:58 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-23 12:32:43 [INFO]: Epoch 001 - training loss: 0.8843, validation loss: 0.9185
2024-05-23 12:32:43 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN_epoch1_loss0.9185333957274755.pypots
2024-05-23 12:33:11 [INFO]: Epoch 002 - training loss: 0.5712, validation loss: 0.8907
2024-05-23 12:33:11 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN_epoch2_loss0.8907430877288183.pypots
2024-05-23 12:33:39 [INFO]: Epoch 003 - training loss: 0.5245, validation loss: 0.8835
2024-05-23 12:33:39 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN_epoch3_loss0.8834621002276738.pypots
2024-05-23 12:34:04 [INFO]: Epoch 004 - training loss: 0.5004, validation loss: 0.8826
2024-05-23 12:34:04 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN_epoch4_loss0.8826132118701935.pypots
2024-05-23 12:34:29 [INFO]: Epoch 005 - training loss: 0.4824, validation loss: 0.8859
2024-05-23 12:34:29 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN_epoch5_loss0.8858796566724777.pypots
2024-05-23 12:34:54 [INFO]: Epoch 006 - training loss: 0.4799, validation loss: 0.8891
2024-05-23 12:34:54 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN_epoch6_loss0.8890529056390126.pypots
2024-05-23 12:35:18 [INFO]: Epoch 007 - training loss: 0.4714, validation loss: 0.8909
2024-05-23 12:35:18 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN_epoch7_loss0.8909342736005783.pypots
2024-05-23 12:35:42 [INFO]: Epoch 008 - training loss: 0.4580, validation loss: 0.8933
2024-05-23 12:35:42 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN_epoch8_loss0.8932818949222565.pypots
2024-05-23 12:36:07 [INFO]: Epoch 009 - training loss: 0.4548, validation loss: 0.8943
2024-05-23 12:36:07 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN_epoch9_loss0.8942942440509796.pypots
2024-05-23 12:36:27 [INFO]: Epoch 010 - training loss: 0.4560, validation loss: 0.8977
2024-05-23 12:36:27 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN_epoch10_loss0.8976929247379303.pypots
2024-05-23 12:36:48 [INFO]: Epoch 011 - training loss: 0.4475, validation loss: 0.9007
2024-05-23 12:36:48 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN_epoch11_loss0.9007418761650722.pypots
2024-05-23 12:37:11 [INFO]: Epoch 012 - training loss: 0.4465, validation loss: 0.9016
2024-05-23 12:37:11 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN_epoch12_loss0.9015571276346842.pypots
2024-05-23 12:37:28 [INFO]: Epoch 013 - training loss: 0.4417, validation loss: 0.9087
2024-05-23 12:37:28 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN_epoch13_loss0.9086804737647375.pypots
2024-05-23 12:37:45 [INFO]: Epoch 014 - training loss: 0.4449, validation loss: 0.9071
2024-05-23 12:37:45 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN_epoch14_loss0.9071173399686814.pypots
2024-05-23 12:37:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 12:37:45 [INFO]: Finished training. The best model is from epoch#4.
2024-05-23 12:37:45 [INFO]: Saved the model to saved_results/round_3/MRNN_physionet2012/20240523_T123158/MRNN.pypots
2024-05-23 12:37:51 [INFO]: MRNN on PhysioNet-2012: MAE=0.6839, MSE=0.8920
2024-05-23 12:38:17 [INFO]: Successfully saved to saved_results/round_3/MRNN_physionet2012/imputation.pkl
2024-05-23 12:38:17 [INFO]: Using the given device: cpu
2024-05-23 12:38:17 [INFO]: LOCF on PhysioNet-2012: MAE=0.4110, MSE=0.5688
2024-05-23 12:38:17 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_physionet2012".
2024-05-23 12:38:17 [INFO]: Successfully saved to saved_results/round_3/LOCF_physionet2012/imputation.pkl
2024-05-23 12:38:18 [INFO]: Median on PhysioNet-2012: MAE=0.6855, MSE=0.9913
2024-05-23 12:38:18 [INFO]: Successfully created the given path "saved_results/round_3/Median_physionet2012".
2024-05-23 12:38:18 [INFO]: Successfully saved to saved_results/round_3/Median_physionet2012/imputation.pkl
2024-05-23 12:38:18 [INFO]: Mean on PhysioNet-2012: MAE=0.7017, MSE=0.9536
2024-05-23 12:38:19 [INFO]: Successfully created the given path "saved_results/round_3/Mean_physionet2012".
2024-05-23 12:38:19 [INFO]: Successfully saved to saved_results/round_3/Mean_physionet2012/imputation.pkl
2024-05-23 12:38:19 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-23 12:38:19 [INFO]: Using the given device: cuda:0
2024-05-23 12:38:19 [INFO]: Model files will be saved to saved_results/round_4/SAITS_physionet2012/20240523_T123819
2024-05-23 12:38:19 [INFO]: Tensorboard file will be saved to saved_results/round_4/SAITS_physionet2012/20240523_T123819/tensorboard
2024-05-23 12:38:19 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-23 12:38:32 [INFO]: Epoch 001 - training loss: 0.8161, validation loss: 0.4026
2024-05-23 12:38:45 [INFO]: Epoch 002 - training loss: 0.4903, validation loss: 0.3520
2024-05-23 12:38:58 [INFO]: Epoch 003 - training loss: 0.4186, validation loss: 0.3186
2024-05-23 12:39:11 [INFO]: Epoch 004 - training loss: 0.3743, validation loss: 0.2998
2024-05-23 12:39:24 [INFO]: Epoch 005 - training loss: 0.3457, validation loss: 0.2869
2024-05-23 12:39:37 [INFO]: Epoch 006 - training loss: 0.3270, validation loss: 0.2730
2024-05-23 12:39:51 [INFO]: Epoch 007 - training loss: 0.3115, validation loss: 0.2640
2024-05-23 12:40:04 [INFO]: Epoch 008 - training loss: 0.2995, validation loss: 0.2658
2024-05-23 12:40:15 [INFO]: Epoch 009 - training loss: 0.2939, validation loss: 0.2588
2024-05-23 12:40:28 [INFO]: Epoch 010 - training loss: 0.2860, validation loss: 0.2569
2024-05-23 12:40:39 [INFO]: Epoch 011 - training loss: 0.2805, validation loss: 0.2513
2024-05-23 12:40:50 [INFO]: Epoch 012 - training loss: 0.2759, validation loss: 0.2469
2024-05-23 12:41:00 [INFO]: Epoch 013 - training loss: 0.2723, validation loss: 0.2475
2024-05-23 12:41:12 [INFO]: Epoch 014 - training loss: 0.2714, validation loss: 0.2421
2024-05-23 12:41:26 [INFO]: Epoch 015 - training loss: 0.2660, validation loss: 0.2448
2024-05-23 12:41:35 [INFO]: Epoch 016 - training loss: 0.2633, validation loss: 0.2434
2024-05-23 12:41:46 [INFO]: Epoch 017 - training loss: 0.2602, validation loss: 0.2457
2024-05-23 12:41:59 [INFO]: Epoch 018 - training loss: 0.2600, validation loss: 0.2371
2024-05-23 12:42:12 [INFO]: Epoch 019 - training loss: 0.2570, validation loss: 0.2393
2024-05-23 12:42:24 [INFO]: Epoch 020 - training loss: 0.2553, validation loss: 0.2414
2024-05-23 12:42:36 [INFO]: Epoch 021 - training loss: 0.2548, validation loss: 0.2333
2024-05-23 12:42:46 [INFO]: Epoch 022 - training loss: 0.2521, validation loss: 0.2403
2024-05-23 12:42:58 [INFO]: Epoch 023 - training loss: 0.2493, validation loss: 0.2246
2024-05-23 12:43:08 [INFO]: Epoch 024 - training loss: 0.2480, validation loss: 0.2371
2024-05-23 12:43:18 [INFO]: Epoch 025 - training loss: 0.2461, validation loss: 0.2383
2024-05-23 12:43:26 [INFO]: Epoch 026 - training loss: 0.2457, validation loss: 0.2302
2024-05-23 12:43:34 [INFO]: Epoch 027 - training loss: 0.2457, validation loss: 0.2367
2024-05-23 12:43:45 [INFO]: Epoch 028 - training loss: 0.2441, validation loss: 0.2302
2024-05-23 12:43:55 [INFO]: Epoch 029 - training loss: 0.2445, validation loss: 0.2360
2024-05-23 12:44:04 [INFO]: Epoch 030 - training loss: 0.2419, validation loss: 0.2360
2024-05-23 12:44:13 [INFO]: Epoch 031 - training loss: 0.2422, validation loss: 0.2430
2024-05-23 12:44:26 [INFO]: Epoch 032 - training loss: 0.2406, validation loss: 0.2380
2024-05-23 12:44:39 [INFO]: Epoch 033 - training loss: 0.2404, validation loss: 0.2356
2024-05-23 12:44:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 12:44:39 [INFO]: Finished training. The best model is from epoch#23.
2024-05-23 12:44:39 [INFO]: Saved the model to saved_results/round_4/SAITS_physionet2012/20240523_T123819/SAITS.pypots
2024-05-23 12:44:40 [INFO]: SAITS on PhysioNet-2012: MAE=0.2018, MSE=0.2210
2024-05-23 12:44:42 [INFO]: Successfully saved to saved_results/round_4/SAITS_physionet2012/imputation.pkl
2024-05-23 12:44:42 [INFO]: Using the given device: cuda:0
2024-05-23 12:44:42 [INFO]: Model files will be saved to saved_results/round_4/Transformer_physionet2012/20240523_T124442
2024-05-23 12:44:42 [INFO]: Tensorboard file will be saved to saved_results/round_4/Transformer_physionet2012/20240523_T124442/tensorboard
2024-05-23 12:44:42 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-23 12:44:49 [INFO]: Epoch 001 - training loss: 0.8723, validation loss: 0.4333
2024-05-23 12:44:56 [INFO]: Epoch 002 - training loss: 0.5483, validation loss: 0.4009
2024-05-23 12:45:03 [INFO]: Epoch 003 - training loss: 0.4769, validation loss: 0.3689
2024-05-23 12:45:10 [INFO]: Epoch 004 - training loss: 0.4389, validation loss: 0.3528
2024-05-23 12:45:18 [INFO]: Epoch 005 - training loss: 0.4075, validation loss: 0.3364
2024-05-23 12:45:25 [INFO]: Epoch 006 - training loss: 0.3844, validation loss: 0.3264
2024-05-23 12:45:33 [INFO]: Epoch 007 - training loss: 0.3677, validation loss: 0.3188
2024-05-23 12:45:40 [INFO]: Epoch 008 - training loss: 0.3525, validation loss: 0.3100
2024-05-23 12:45:47 [INFO]: Epoch 009 - training loss: 0.3444, validation loss: 0.3000
2024-05-23 12:45:55 [INFO]: Epoch 010 - training loss: 0.3370, validation loss: 0.2914
2024-05-23 12:46:02 [INFO]: Epoch 011 - training loss: 0.3281, validation loss: 0.2907
2024-05-23 12:46:09 [INFO]: Epoch 012 - training loss: 0.3240, validation loss: 0.2863
2024-05-23 12:46:16 [INFO]: Epoch 013 - training loss: 0.3169, validation loss: 0.2791
2024-05-23 12:46:24 [INFO]: Epoch 014 - training loss: 0.3111, validation loss: 0.2824
2024-05-23 12:46:31 [INFO]: Epoch 015 - training loss: 0.3074, validation loss: 0.2746
2024-05-23 12:46:38 [INFO]: Epoch 016 - training loss: 0.3047, validation loss: 0.2678
2024-05-23 12:46:45 [INFO]: Epoch 017 - training loss: 0.3005, validation loss: 0.2686
2024-05-23 12:46:52 [INFO]: Epoch 018 - training loss: 0.2980, validation loss: 0.2687
2024-05-23 12:47:00 [INFO]: Epoch 019 - training loss: 0.2969, validation loss: 0.2658
2024-05-23 12:47:07 [INFO]: Epoch 020 - training loss: 0.2922, validation loss: 0.2661
2024-05-23 12:47:15 [INFO]: Epoch 021 - training loss: 0.2888, validation loss: 0.2588
2024-05-23 12:47:22 [INFO]: Epoch 022 - training loss: 0.2856, validation loss: 0.2545
2024-05-23 12:47:30 [INFO]: Epoch 023 - training loss: 0.2865, validation loss: 0.2576
2024-05-23 12:47:38 [INFO]: Epoch 024 - training loss: 0.2818, validation loss: 0.2453
2024-05-23 12:47:45 [INFO]: Epoch 025 - training loss: 0.2805, validation loss: 0.2541
2024-05-23 12:47:53 [INFO]: Epoch 026 - training loss: 0.2783, validation loss: 0.2529
2024-05-23 12:48:00 [INFO]: Epoch 027 - training loss: 0.2793, validation loss: 0.2512
2024-05-23 12:48:07 [INFO]: Epoch 028 - training loss: 0.2764, validation loss: 0.2500
2024-05-23 12:48:14 [INFO]: Epoch 029 - training loss: 0.2751, validation loss: 0.2412
2024-05-23 12:48:21 [INFO]: Epoch 030 - training loss: 0.2722, validation loss: 0.2498
2024-05-23 12:48:28 [INFO]: Epoch 031 - training loss: 0.2710, validation loss: 0.2456
2024-05-23 12:48:35 [INFO]: Epoch 032 - training loss: 0.2698, validation loss: 0.2523
2024-05-23 12:48:42 [INFO]: Epoch 033 - training loss: 0.2691, validation loss: 0.2450
2024-05-23 12:48:49 [INFO]: Epoch 034 - training loss: 0.2678, validation loss: 0.2396
2024-05-23 12:48:56 [INFO]: Epoch 035 - training loss: 0.2668, validation loss: 0.2452
2024-05-23 12:49:03 [INFO]: Epoch 036 - training loss: 0.2667, validation loss: 0.2460
2024-05-23 12:49:10 [INFO]: Epoch 037 - training loss: 0.2646, validation loss: 0.2422
2024-05-23 12:49:17 [INFO]: Epoch 038 - training loss: 0.2641, validation loss: 0.2477
2024-05-23 12:49:25 [INFO]: Epoch 039 - training loss: 0.2610, validation loss: 0.2389
2024-05-23 12:49:32 [INFO]: Epoch 040 - training loss: 0.2613, validation loss: 0.2413
2024-05-23 12:49:40 [INFO]: Epoch 041 - training loss: 0.2616, validation loss: 0.2386
2024-05-23 12:49:47 [INFO]: Epoch 042 - training loss: 0.2595, validation loss: 0.2389
2024-05-23 12:49:55 [INFO]: Epoch 043 - training loss: 0.2589, validation loss: 0.2411
2024-05-23 12:50:03 [INFO]: Epoch 044 - training loss: 0.2586, validation loss: 0.2425
2024-05-23 12:50:11 [INFO]: Epoch 045 - training loss: 0.2576, validation loss: 0.2411
2024-05-23 12:50:18 [INFO]: Epoch 046 - training loss: 0.2561, validation loss: 0.2408
2024-05-23 12:50:26 [INFO]: Epoch 047 - training loss: 0.2564, validation loss: 0.2364
2024-05-23 12:50:33 [INFO]: Epoch 048 - training loss: 0.2547, validation loss: 0.2427
2024-05-23 12:50:41 [INFO]: Epoch 049 - training loss: 0.2557, validation loss: 0.2402
2024-05-23 12:50:48 [INFO]: Epoch 050 - training loss: 0.2535, validation loss: 0.2391
2024-05-23 12:50:55 [INFO]: Epoch 051 - training loss: 0.2529, validation loss: 0.2337
2024-05-23 12:51:01 [INFO]: Epoch 052 - training loss: 0.2516, validation loss: 0.2310
2024-05-23 12:51:08 [INFO]: Epoch 053 - training loss: 0.2529, validation loss: 0.2355
2024-05-23 12:51:15 [INFO]: Epoch 054 - training loss: 0.2521, validation loss: 0.2347
2024-05-23 12:51:23 [INFO]: Epoch 055 - training loss: 0.2527, validation loss: 0.2366
2024-05-23 12:51:30 [INFO]: Epoch 056 - training loss: 0.2502, validation loss: 0.2369
2024-05-23 12:51:38 [INFO]: Epoch 057 - training loss: 0.2500, validation loss: 0.2361
2024-05-23 12:51:45 [INFO]: Epoch 058 - training loss: 0.2492, validation loss: 0.2373
2024-05-23 12:51:53 [INFO]: Epoch 059 - training loss: 0.2494, validation loss: 0.2386
2024-05-23 12:51:59 [INFO]: Epoch 060 - training loss: 0.2488, validation loss: 0.2289
2024-05-23 12:52:06 [INFO]: Epoch 061 - training loss: 0.2471, validation loss: 0.2290
2024-05-23 12:52:13 [INFO]: Epoch 062 - training loss: 0.2488, validation loss: 0.2359
2024-05-23 12:52:21 [INFO]: Epoch 063 - training loss: 0.2478, validation loss: 0.2329
2024-05-23 12:52:29 [INFO]: Epoch 064 - training loss: 0.2465, validation loss: 0.2334
2024-05-23 12:52:36 [INFO]: Epoch 065 - training loss: 0.2458, validation loss: 0.2371
2024-05-23 12:52:43 [INFO]: Epoch 066 - training loss: 0.2469, validation loss: 0.2342
2024-05-23 12:52:50 [INFO]: Epoch 067 - training loss: 0.2476, validation loss: 0.2318
2024-05-23 12:52:57 [INFO]: Epoch 068 - training loss: 0.2459, validation loss: 0.2306
2024-05-23 12:53:04 [INFO]: Epoch 069 - training loss: 0.2450, validation loss: 0.2311
2024-05-23 12:53:11 [INFO]: Epoch 070 - training loss: 0.2449, validation loss: 0.2358
2024-05-23 12:53:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 12:53:11 [INFO]: Finished training. The best model is from epoch#60.
2024-05-23 12:53:11 [INFO]: Saved the model to saved_results/round_4/Transformer_physionet2012/20240523_T124442/Transformer.pypots
2024-05-23 12:53:12 [INFO]: Transformer on PhysioNet-2012: MAE=0.2078, MSE=0.2221
2024-05-23 12:53:13 [INFO]: Successfully saved to saved_results/round_4/Transformer_physionet2012/imputation.pkl
2024-05-23 12:53:13 [INFO]: Using the given device: cuda:0
2024-05-23 12:53:13 [INFO]: Model files will be saved to saved_results/round_4/TimesNet_physionet2012/20240523_T125313
2024-05-23 12:53:13 [INFO]: Tensorboard file will be saved to saved_results/round_4/TimesNet_physionet2012/20240523_T125313/tensorboard
2024-05-23 12:53:13 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-23 12:53:17 [INFO]: Epoch 001 - training loss: 0.4026, validation loss: 0.3793
2024-05-23 12:53:20 [INFO]: Epoch 002 - training loss: 0.4418, validation loss: 0.3336
2024-05-23 12:53:24 [INFO]: Epoch 003 - training loss: 0.4848, validation loss: 0.3151
2024-05-23 12:53:28 [INFO]: Epoch 004 - training loss: 0.3669, validation loss: 0.3179
2024-05-23 12:53:31 [INFO]: Epoch 005 - training loss: 0.3603, validation loss: 0.3207
2024-05-23 12:53:35 [INFO]: Epoch 006 - training loss: 0.4737, validation loss: 0.3236
2024-05-23 12:53:39 [INFO]: Epoch 007 - training loss: 0.4338, validation loss: 0.3192
2024-05-23 12:53:42 [INFO]: Epoch 008 - training loss: 0.3819, validation loss: 0.3157
2024-05-23 12:53:46 [INFO]: Epoch 009 - training loss: 0.4099, validation loss: 0.3194
2024-05-23 12:53:50 [INFO]: Epoch 010 - training loss: 0.4334, validation loss: 0.3139
2024-05-23 12:53:53 [INFO]: Epoch 011 - training loss: 0.3616, validation loss: 0.3057
2024-05-23 12:53:57 [INFO]: Epoch 012 - training loss: 0.3339, validation loss: 0.3004
2024-05-23 12:54:00 [INFO]: Epoch 013 - training loss: 0.3972, validation loss: 0.2984
2024-05-23 12:54:04 [INFO]: Epoch 014 - training loss: 0.3047, validation loss: 0.3011
2024-05-23 12:54:08 [INFO]: Epoch 015 - training loss: 0.3532, validation loss: 0.2922
2024-05-23 12:54:11 [INFO]: Epoch 016 - training loss: 0.3413, validation loss: 0.2944
2024-05-23 12:54:15 [INFO]: Epoch 017 - training loss: 0.3514, validation loss: 0.2893
2024-05-23 12:54:19 [INFO]: Epoch 018 - training loss: 0.3176, validation loss: 0.2901
2024-05-23 12:54:22 [INFO]: Epoch 019 - training loss: 0.2994, validation loss: 0.2898
2024-05-23 12:54:26 [INFO]: Epoch 020 - training loss: 0.3219, validation loss: 0.2915
2024-05-23 12:54:30 [INFO]: Epoch 021 - training loss: 0.3744, validation loss: 0.2858
2024-05-23 12:54:33 [INFO]: Epoch 022 - training loss: 0.3838, validation loss: 0.2825
2024-05-23 12:54:38 [INFO]: Epoch 023 - training loss: 0.3393, validation loss: 0.2854
2024-05-23 12:54:41 [INFO]: Epoch 024 - training loss: 0.3209, validation loss: 0.2824
2024-05-23 12:54:45 [INFO]: Epoch 025 - training loss: 0.2996, validation loss: 0.2861
2024-05-23 12:54:49 [INFO]: Epoch 026 - training loss: 0.3027, validation loss: 0.2809
2024-05-23 12:54:53 [INFO]: Epoch 027 - training loss: 0.3034, validation loss: 0.2821
2024-05-23 12:54:56 [INFO]: Epoch 028 - training loss: 0.2977, validation loss: 0.2770
2024-05-23 12:55:00 [INFO]: Epoch 029 - training loss: 0.3890, validation loss: 0.2801
2024-05-23 12:55:03 [INFO]: Epoch 030 - training loss: 0.3186, validation loss: 0.2781
2024-05-23 12:55:07 [INFO]: Epoch 031 - training loss: 0.3055, validation loss: 0.2810
2024-05-23 12:55:10 [INFO]: Epoch 032 - training loss: 0.3453, validation loss: 0.2852
2024-05-23 12:55:14 [INFO]: Epoch 033 - training loss: 0.3115, validation loss: 0.2788
2024-05-23 12:55:17 [INFO]: Epoch 034 - training loss: 0.3053, validation loss: 0.2760
2024-05-23 12:55:21 [INFO]: Epoch 035 - training loss: 0.3008, validation loss: 0.2760
2024-05-23 12:55:24 [INFO]: Epoch 036 - training loss: 0.4085, validation loss: 0.2705
2024-05-23 12:55:28 [INFO]: Epoch 037 - training loss: 0.2838, validation loss: 0.2750
2024-05-23 12:55:32 [INFO]: Epoch 038 - training loss: 0.2949, validation loss: 0.2730
2024-05-23 12:55:36 [INFO]: Epoch 039 - training loss: 0.3278, validation loss: 0.2727
2024-05-23 12:55:40 [INFO]: Epoch 040 - training loss: 0.2992, validation loss: 0.2705
2024-05-23 12:55:43 [INFO]: Epoch 041 - training loss: 0.3603, validation loss: 0.2872
2024-05-23 12:55:47 [INFO]: Epoch 042 - training loss: 0.3943, validation loss: 0.2694
2024-05-23 12:55:50 [INFO]: Epoch 043 - training loss: 0.3274, validation loss: 0.2671
2024-05-23 12:55:54 [INFO]: Epoch 044 - training loss: 0.3029, validation loss: 0.2670
2024-05-23 12:55:58 [INFO]: Epoch 045 - training loss: 0.2920, validation loss: 0.2739
2024-05-23 12:56:01 [INFO]: Epoch 046 - training loss: 0.2833, validation loss: 0.2768
2024-05-23 12:56:05 [INFO]: Epoch 047 - training loss: 0.3060, validation loss: 0.2714
2024-05-23 12:56:09 [INFO]: Epoch 048 - training loss: 0.3409, validation loss: 0.2675
2024-05-23 12:56:12 [INFO]: Epoch 049 - training loss: 0.2913, validation loss: 0.2736
2024-05-23 12:56:16 [INFO]: Epoch 050 - training loss: 0.2869, validation loss: 0.2656
2024-05-23 12:56:20 [INFO]: Epoch 051 - training loss: 0.3532, validation loss: 0.2673
2024-05-23 12:56:23 [INFO]: Epoch 052 - training loss: 0.3020, validation loss: 0.2661
2024-05-23 12:56:27 [INFO]: Epoch 053 - training loss: 0.2945, validation loss: 0.2717
2024-05-23 12:56:30 [INFO]: Epoch 054 - training loss: 0.2957, validation loss: 0.2742
2024-05-23 12:56:34 [INFO]: Epoch 055 - training loss: 0.3556, validation loss: 0.2637
2024-05-23 12:56:38 [INFO]: Epoch 056 - training loss: 0.2842, validation loss: 0.2636
2024-05-23 12:56:41 [INFO]: Epoch 057 - training loss: 0.3241, validation loss: 0.2655
2024-05-23 12:56:45 [INFO]: Epoch 058 - training loss: 0.3311, validation loss: 0.2696
2024-05-23 12:56:49 [INFO]: Epoch 059 - training loss: 0.2835, validation loss: 0.2662
2024-05-23 12:56:53 [INFO]: Epoch 060 - training loss: 0.2849, validation loss: 0.2656
2024-05-23 12:56:57 [INFO]: Epoch 061 - training loss: 0.2957, validation loss: 0.2648
2024-05-23 12:57:00 [INFO]: Epoch 062 - training loss: 0.2832, validation loss: 0.2633
2024-05-23 12:57:04 [INFO]: Epoch 063 - training loss: 0.2857, validation loss: 0.2609
2024-05-23 12:57:08 [INFO]: Epoch 064 - training loss: 0.3276, validation loss: 0.2640
2024-05-23 12:57:12 [INFO]: Epoch 065 - training loss: 0.2847, validation loss: 0.2617
2024-05-23 12:57:16 [INFO]: Epoch 066 - training loss: 0.4216, validation loss: 0.2682
2024-05-23 12:57:20 [INFO]: Epoch 067 - training loss: 0.2788, validation loss: 0.2631
2024-05-23 12:57:23 [INFO]: Epoch 068 - training loss: 0.3474, validation loss: 0.2626
2024-05-23 12:57:27 [INFO]: Epoch 069 - training loss: 0.2999, validation loss: 0.2611
2024-05-23 12:57:30 [INFO]: Epoch 070 - training loss: 0.2699, validation loss: 0.2659
2024-05-23 12:57:34 [INFO]: Epoch 071 - training loss: 0.2880, validation loss: 0.2685
2024-05-23 12:57:38 [INFO]: Epoch 072 - training loss: 0.3250, validation loss: 0.2607
2024-05-23 12:57:41 [INFO]: Epoch 073 - training loss: 0.2725, validation loss: 0.2640
2024-05-23 12:57:45 [INFO]: Epoch 074 - training loss: 0.3305, validation loss: 0.2626
2024-05-23 12:57:48 [INFO]: Epoch 075 - training loss: 0.2800, validation loss: 0.2633
2024-05-23 12:57:52 [INFO]: Epoch 076 - training loss: 0.2765, validation loss: 0.2622
2024-05-23 12:57:56 [INFO]: Epoch 077 - training loss: 0.3359, validation loss: 0.2640
2024-05-23 12:57:59 [INFO]: Epoch 078 - training loss: 0.2815, validation loss: 0.2631
2024-05-23 12:58:03 [INFO]: Epoch 079 - training loss: 0.2877, validation loss: 0.2669
2024-05-23 12:58:06 [INFO]: Epoch 080 - training loss: 0.2736, validation loss: 0.2637
2024-05-23 12:58:10 [INFO]: Epoch 081 - training loss: 0.3534, validation loss: 0.2732
2024-05-23 12:58:14 [INFO]: Epoch 082 - training loss: 0.3520, validation loss: 0.2620
2024-05-23 12:58:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 12:58:14 [INFO]: Finished training. The best model is from epoch#72.
2024-05-23 12:58:14 [INFO]: Saved the model to saved_results/round_4/TimesNet_physionet2012/20240523_T125313/TimesNet.pypots
2024-05-23 12:58:14 [INFO]: TimesNet on PhysioNet-2012: MAE=0.2574, MSE=0.2623
2024-05-23 12:58:15 [INFO]: Successfully saved to saved_results/round_4/TimesNet_physionet2012/imputation.pkl
2024-05-23 12:58:15 [INFO]: Using the given device: cuda:0
2024-05-23 12:58:15 [INFO]: Model files will be saved to saved_results/round_4/CSDI_physionet2012/20240523_T125815
2024-05-23 12:58:15 [INFO]: Tensorboard file will be saved to saved_results/round_4/CSDI_physionet2012/20240523_T125815/tensorboard
2024-05-23 12:58:15 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-23 13:00:37 [INFO]: Epoch 001 - training loss: 0.3388, validation loss: 0.2404
2024-05-23 13:00:37 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch1_loss0.2404410682618618.pypots
2024-05-23 13:03:00 [INFO]: Epoch 002 - training loss: 0.2677, validation loss: 0.2189
2024-05-23 13:03:00 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch2_loss0.21888084237774214.pypots
2024-05-23 13:05:24 [INFO]: Epoch 003 - training loss: 0.2441, validation loss: 0.2107
2024-05-23 13:05:24 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch3_loss0.21068490743637086.pypots
2024-05-23 13:07:47 [INFO]: Epoch 004 - training loss: 0.2346, validation loss: 0.1961
2024-05-23 13:07:47 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch4_loss0.19610243439674377.pypots
2024-05-23 13:10:11 [INFO]: Epoch 005 - training loss: 0.2310, validation loss: 0.1932
2024-05-23 13:10:11 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch5_loss0.1931978866457939.pypots
2024-05-23 13:12:34 [INFO]: Epoch 006 - training loss: 0.2324, validation loss: 0.1878
2024-05-23 13:12:34 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch6_loss0.18784370894233385.pypots
2024-05-23 13:14:57 [INFO]: Epoch 007 - training loss: 0.2314, validation loss: 0.1906
2024-05-23 13:14:57 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch7_loss0.19063436662157376.pypots
2024-05-23 13:17:21 [INFO]: Epoch 008 - training loss: 0.2281, validation loss: 0.1846
2024-05-23 13:17:21 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch8_loss0.18459195991357166.pypots
2024-05-23 13:19:45 [INFO]: Epoch 009 - training loss: 0.2220, validation loss: 0.1877
2024-05-23 13:19:45 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch9_loss0.18772902339696884.pypots
2024-05-23 13:22:08 [INFO]: Epoch 010 - training loss: 0.2240, validation loss: 0.1837
2024-05-23 13:22:08 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch10_loss0.18365880946318308.pypots
2024-05-23 13:24:31 [INFO]: Epoch 011 - training loss: 0.2215, validation loss: 0.1842
2024-05-23 13:24:31 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch11_loss0.1842312517265479.pypots
2024-05-23 13:26:54 [INFO]: Epoch 012 - training loss: 0.2202, validation loss: 0.1804
2024-05-23 13:26:54 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch12_loss0.1803544191022714.pypots
2024-05-23 13:29:17 [INFO]: Epoch 013 - training loss: 0.2287, validation loss: 0.1810
2024-05-23 13:29:17 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch13_loss0.18102980479598046.pypots
2024-05-23 13:31:40 [INFO]: Epoch 014 - training loss: 0.2206, validation loss: 0.1814
2024-05-23 13:31:40 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch14_loss0.18140813236435255.pypots
2024-05-23 13:34:03 [INFO]: Epoch 015 - training loss: 0.2233, validation loss: 0.1805
2024-05-23 13:34:03 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch15_loss0.1804875964919726.pypots
2024-05-23 13:36:26 [INFO]: Epoch 016 - training loss: 0.2142, validation loss: 0.1784
2024-05-23 13:36:26 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch16_loss0.17837477549910546.pypots
2024-05-23 13:38:49 [INFO]: Epoch 017 - training loss: 0.2217, validation loss: 0.1755
2024-05-23 13:38:49 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch17_loss0.175473981599013.pypots
2024-05-23 13:41:12 [INFO]: Epoch 018 - training loss: 0.2115, validation loss: 0.1824
2024-05-23 13:41:12 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch18_loss0.1824246548116207.pypots
2024-05-23 13:43:35 [INFO]: Epoch 019 - training loss: 0.2186, validation loss: 0.1755
2024-05-23 13:43:35 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch19_loss0.17549748967091242.pypots
2024-05-23 13:45:58 [INFO]: Epoch 020 - training loss: 0.2166, validation loss: 0.1760
2024-05-23 13:45:58 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch20_loss0.1760329025487105.pypots
2024-05-23 13:48:21 [INFO]: Epoch 021 - training loss: 0.2157, validation loss: 0.1772
2024-05-23 13:48:21 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch21_loss0.17721034958958626.pypots
2024-05-23 13:50:44 [INFO]: Epoch 022 - training loss: 0.2191, validation loss: 0.1761
2024-05-23 13:50:44 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch22_loss0.17605713208516438.pypots
2024-05-23 13:53:07 [INFO]: Epoch 023 - training loss: 0.2125, validation loss: 0.1727
2024-05-23 13:53:07 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch23_loss0.1727319022019704.pypots
2024-05-23 13:55:30 [INFO]: Epoch 024 - training loss: 0.2197, validation loss: 0.1738
2024-05-23 13:55:30 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch24_loss0.17382820099592208.pypots
2024-05-23 13:57:55 [INFO]: Epoch 025 - training loss: 0.2190, validation loss: 0.1732
2024-05-23 13:57:55 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch25_loss0.1731514684855938.pypots
2024-05-23 14:00:18 [INFO]: Epoch 026 - training loss: 0.2130, validation loss: 0.1726
2024-05-23 14:00:18 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch26_loss0.1726094757517179.pypots
2024-05-23 14:02:41 [INFO]: Epoch 027 - training loss: 0.2146, validation loss: 0.1734
2024-05-23 14:02:41 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch27_loss0.17339947149157525.pypots
2024-05-23 14:05:04 [INFO]: Epoch 028 - training loss: 0.2070, validation loss: 0.1723
2024-05-23 14:05:04 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch28_loss0.17226792499423027.pypots
2024-05-23 14:07:27 [INFO]: Epoch 029 - training loss: 0.2147, validation loss: 0.1713
2024-05-23 14:07:27 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch29_loss0.1712817830344041.pypots
2024-05-23 14:09:49 [INFO]: Epoch 030 - training loss: 0.2171, validation loss: 0.1751
2024-05-23 14:09:50 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch30_loss0.17510474051038424.pypots
2024-05-23 14:12:12 [INFO]: Epoch 031 - training loss: 0.2216, validation loss: 0.1721
2024-05-23 14:12:12 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch31_loss0.17210915088653564.pypots
2024-05-23 14:14:35 [INFO]: Epoch 032 - training loss: 0.2160, validation loss: 0.1703
2024-05-23 14:14:35 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch32_loss0.17034827520449955.pypots
2024-05-23 14:16:58 [INFO]: Epoch 033 - training loss: 0.2173, validation loss: 0.1707
2024-05-23 14:16:58 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch33_loss0.17067710136373837.pypots
2024-05-23 14:19:21 [INFO]: Epoch 034 - training loss: 0.2124, validation loss: 0.1707
2024-05-23 14:19:21 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch34_loss0.1707025279601415.pypots
2024-05-23 14:21:44 [INFO]: Epoch 035 - training loss: 0.2098, validation loss: 0.1747
2024-05-23 14:21:44 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch35_loss0.1746900421877702.pypots
2024-05-23 14:24:07 [INFO]: Epoch 036 - training loss: 0.2140, validation loss: 0.1695
2024-05-23 14:24:07 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch36_loss0.1694847621023655.pypots
2024-05-23 14:26:30 [INFO]: Epoch 037 - training loss: 0.2204, validation loss: 0.1703
2024-05-23 14:26:30 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch37_loss0.17026041621963184.pypots
2024-05-23 14:28:53 [INFO]: Epoch 038 - training loss: 0.2130, validation loss: 0.1687
2024-05-23 14:28:53 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch38_loss0.16873867164055506.pypots
2024-05-23 14:31:16 [INFO]: Epoch 039 - training loss: 0.2076, validation loss: 0.1703
2024-05-23 14:31:16 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch39_loss0.1702513503531615.pypots
2024-05-23 14:33:39 [INFO]: Epoch 040 - training loss: 0.2163, validation loss: 0.1684
2024-05-23 14:33:39 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch40_loss0.16843774964412053.pypots
2024-05-23 14:36:02 [INFO]: Epoch 041 - training loss: 0.2134, validation loss: 0.1718
2024-05-23 14:36:02 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch41_loss0.1718314747015635.pypots
2024-05-23 14:38:25 [INFO]: Epoch 042 - training loss: 0.2104, validation loss: 0.1692
2024-05-23 14:38:25 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch42_loss0.1692259505391121.pypots
2024-05-23 14:40:48 [INFO]: Epoch 043 - training loss: 0.2083, validation loss: 0.1680
2024-05-23 14:40:48 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch43_loss0.16804923738042513.pypots
2024-05-23 14:43:11 [INFO]: Epoch 044 - training loss: 0.2101, validation loss: 0.1678
2024-05-23 14:43:11 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch44_loss0.16776290610432626.pypots
2024-05-23 14:45:34 [INFO]: Epoch 045 - training loss: 0.2151, validation loss: 0.1680
2024-05-23 14:45:34 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch45_loss0.1679771083096663.pypots
2024-05-23 14:47:57 [INFO]: Epoch 046 - training loss: 0.2090, validation loss: 0.1685
2024-05-23 14:47:57 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch46_loss0.1685071585079034.pypots
2024-05-23 14:50:19 [INFO]: Epoch 047 - training loss: 0.2058, validation loss: 0.1674
2024-05-23 14:50:19 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch47_loss0.16740820159514744.pypots
2024-05-23 14:52:42 [INFO]: Epoch 048 - training loss: 0.2116, validation loss: 0.1671
2024-05-23 14:52:42 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch48_loss0.16706152508656183.pypots
2024-05-23 14:55:05 [INFO]: Epoch 049 - training loss: 0.2183, validation loss: 0.1665
2024-05-23 14:55:05 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch49_loss0.16652250389258066.pypots
2024-05-23 14:57:28 [INFO]: Epoch 050 - training loss: 0.2107, validation loss: 0.1678
2024-05-23 14:57:28 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch50_loss0.16776543160279592.pypots
2024-05-23 14:59:51 [INFO]: Epoch 051 - training loss: 0.2064, validation loss: 0.1679
2024-05-23 14:59:51 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch51_loss0.16785174856583276.pypots
2024-05-23 15:02:14 [INFO]: Epoch 052 - training loss: 0.2077, validation loss: 0.1677
2024-05-23 15:02:14 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch52_loss0.1677235819399357.pypots
2024-05-23 15:04:37 [INFO]: Epoch 053 - training loss: 0.2150, validation loss: 0.1676
2024-05-23 15:04:37 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch53_loss0.16760599240660667.pypots
2024-05-23 15:07:00 [INFO]: Epoch 054 - training loss: 0.2101, validation loss: 0.1663
2024-05-23 15:07:00 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch54_loss0.16629842792948088.pypots
2024-05-23 15:09:23 [INFO]: Epoch 055 - training loss: 0.2105, validation loss: 0.1663
2024-05-23 15:09:23 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch55_loss0.1662599802017212.pypots
2024-05-23 15:11:46 [INFO]: Epoch 056 - training loss: 0.2123, validation loss: 0.1674
2024-05-23 15:11:46 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch56_loss0.16742862289150556.pypots
2024-05-23 15:14:09 [INFO]: Epoch 057 - training loss: 0.2103, validation loss: 0.1672
2024-05-23 15:14:09 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch57_loss0.16724774713317553.pypots
2024-05-23 15:16:32 [INFO]: Epoch 058 - training loss: 0.2104, validation loss: 0.1671
2024-05-23 15:16:32 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch58_loss0.16711317002773285.pypots
2024-05-23 15:18:55 [INFO]: Epoch 059 - training loss: 0.2091, validation loss: 0.1645
2024-05-23 15:18:55 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch59_loss0.1645476631820202.pypots
2024-05-23 15:21:18 [INFO]: Epoch 060 - training loss: 0.2037, validation loss: 0.1657
2024-05-23 15:21:18 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch60_loss0.16571652193864186.pypots
2024-05-23 15:23:43 [INFO]: Epoch 061 - training loss: 0.2149, validation loss: 0.1647
2024-05-23 15:23:43 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch61_loss0.16470267698168756.pypots
2024-05-23 15:26:06 [INFO]: Epoch 062 - training loss: 0.2095, validation loss: 0.1650
2024-05-23 15:26:06 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch62_loss0.1650191900630792.pypots
2024-05-23 15:28:29 [INFO]: Epoch 063 - training loss: 0.2046, validation loss: 0.1663
2024-05-23 15:28:29 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch63_loss0.1662738251189391.pypots
2024-05-23 15:30:52 [INFO]: Epoch 064 - training loss: 0.2131, validation loss: 0.1654
2024-05-23 15:30:52 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch64_loss0.16541247988740604.pypots
2024-05-23 15:33:15 [INFO]: Epoch 065 - training loss: 0.2049, validation loss: 0.1651
2024-05-23 15:33:15 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch65_loss0.1651476966838042.pypots
2024-05-23 15:35:38 [INFO]: Epoch 066 - training loss: 0.2121, validation loss: 0.1643
2024-05-23 15:35:38 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch66_loss0.16433542122443517.pypots
2024-05-23 15:38:01 [INFO]: Epoch 067 - training loss: 0.2057, validation loss: 0.1669
2024-05-23 15:38:01 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch67_loss0.16691550066073735.pypots
2024-05-23 15:40:24 [INFO]: Epoch 068 - training loss: 0.2055, validation loss: 0.1652
2024-05-23 15:40:24 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch68_loss0.16524468163649242.pypots
2024-05-23 15:42:47 [INFO]: Epoch 069 - training loss: 0.2063, validation loss: 0.1638
2024-05-23 15:42:47 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch69_loss0.1637599714100361.pypots
2024-05-23 15:45:10 [INFO]: Epoch 070 - training loss: 0.2063, validation loss: 0.1652
2024-05-23 15:45:10 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch70_loss0.16519280448555945.pypots
2024-05-23 15:47:33 [INFO]: Epoch 071 - training loss: 0.2073, validation loss: 0.1677
2024-05-23 15:47:33 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch71_loss0.16768395230174066.pypots
2024-05-23 15:49:56 [INFO]: Epoch 072 - training loss: 0.2056, validation loss: 0.1636
2024-05-23 15:49:56 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch72_loss0.163632187495629.pypots
2024-05-23 15:52:19 [INFO]: Epoch 073 - training loss: 0.2073, validation loss: 0.1634
2024-05-23 15:52:19 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch73_loss0.16343145047624905.pypots
2024-05-23 15:54:42 [INFO]: Epoch 074 - training loss: 0.2064, validation loss: 0.1643
2024-05-23 15:54:42 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch74_loss0.16432389964660007.pypots
2024-05-23 15:57:05 [INFO]: Epoch 075 - training loss: 0.2021, validation loss: 0.1646
2024-05-23 15:57:05 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch75_loss0.16458476359645527.pypots
2024-05-23 15:59:28 [INFO]: Epoch 076 - training loss: 0.2118, validation loss: 0.1632
2024-05-23 15:59:28 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch76_loss0.16317296028137207.pypots
2024-05-23 16:01:51 [INFO]: Epoch 077 - training loss: 0.2036, validation loss: 0.1640
2024-05-23 16:01:51 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch77_loss0.1640430067976316.pypots
2024-05-23 16:04:14 [INFO]: Epoch 078 - training loss: 0.2070, validation loss: 0.1639
2024-05-23 16:04:14 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch78_loss0.1638611264526844.pypots
2024-05-23 16:06:37 [INFO]: Epoch 079 - training loss: 0.2045, validation loss: 0.1633
2024-05-23 16:06:37 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch79_loss0.163291201988856.pypots
2024-05-23 16:09:00 [INFO]: Epoch 080 - training loss: 0.2095, validation loss: 0.1632
2024-05-23 16:09:00 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch80_loss0.16319952681660652.pypots
2024-05-23 16:11:23 [INFO]: Epoch 081 - training loss: 0.2039, validation loss: 0.1692
2024-05-23 16:11:23 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch81_loss0.16916820481419564.pypots
2024-05-23 16:13:46 [INFO]: Epoch 082 - training loss: 0.2040, validation loss: 0.1627
2024-05-23 16:13:46 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch82_loss0.16270544826984407.pypots
2024-05-23 16:16:10 [INFO]: Epoch 083 - training loss: 0.2008, validation loss: 0.1622
2024-05-23 16:16:10 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch83_loss0.162177707751592.pypots
2024-05-23 16:18:33 [INFO]: Epoch 084 - training loss: 0.2028, validation loss: 0.1631
2024-05-23 16:18:33 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch84_loss0.16308729648590087.pypots
2024-05-23 16:20:56 [INFO]: Epoch 085 - training loss: 0.2125, validation loss: 0.1634
2024-05-23 16:20:56 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch85_loss0.1634425344566504.pypots
2024-05-23 16:23:19 [INFO]: Epoch 086 - training loss: 0.2089, validation loss: 0.1636
2024-05-23 16:23:19 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch86_loss0.16361983691652615.pypots
2024-05-23 16:25:42 [INFO]: Epoch 087 - training loss: 0.1994, validation loss: 0.1634
2024-05-23 16:25:43 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch87_loss0.1634117218355338.pypots
2024-05-23 16:28:05 [INFO]: Epoch 088 - training loss: 0.2114, validation loss: 0.1629
2024-05-23 16:28:05 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch88_loss0.16287785843014718.pypots
2024-05-23 16:30:28 [INFO]: Epoch 089 - training loss: 0.2036, validation loss: 0.1623
2024-05-23 16:30:28 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch89_loss0.16226090217630068.pypots
2024-05-23 16:32:51 [INFO]: Epoch 090 - training loss: 0.2098, validation loss: 0.1614
2024-05-23 16:32:51 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch90_loss0.16144571204980215.pypots
2024-05-23 16:35:14 [INFO]: Epoch 091 - training loss: 0.2053, validation loss: 0.1620
2024-05-23 16:35:14 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch91_loss0.1620014044145743.pypots
2024-05-23 16:37:37 [INFO]: Epoch 092 - training loss: 0.2003, validation loss: 0.1625
2024-05-23 16:37:37 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch92_loss0.16245458995302517.pypots
2024-05-23 16:40:00 [INFO]: Epoch 093 - training loss: 0.2014, validation loss: 0.1632
2024-05-23 16:40:00 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch93_loss0.1631553550561269.pypots
2024-05-23 16:42:23 [INFO]: Epoch 094 - training loss: 0.2035, validation loss: 0.1618
2024-05-23 16:42:23 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch94_loss0.1618078666428725.pypots
2024-05-23 16:44:46 [INFO]: Epoch 095 - training loss: 0.2021, validation loss: 0.1621
2024-05-23 16:44:46 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch95_loss0.16211062123378117.pypots
2024-05-23 16:47:09 [INFO]: Epoch 096 - training loss: 0.2015, validation loss: 0.1612
2024-05-23 16:47:09 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch96_loss0.16122608582178752.pypots
2024-05-23 16:49:32 [INFO]: Epoch 097 - training loss: 0.2076, validation loss: 0.1620
2024-05-23 16:49:32 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch97_loss0.16195329477389653.pypots
2024-05-23 16:51:55 [INFO]: Epoch 098 - training loss: 0.1987, validation loss: 0.1629
2024-05-23 16:51:55 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch98_loss0.1628942832350731.pypots
2024-05-23 16:54:18 [INFO]: Epoch 099 - training loss: 0.2035, validation loss: 0.1612
2024-05-23 16:54:18 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch99_loss0.1612413150568803.pypots
2024-05-23 16:56:41 [INFO]: Epoch 100 - training loss: 0.2072, validation loss: 0.1617
2024-05-23 16:56:41 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch100_loss0.16172823136051495.pypots
2024-05-23 16:59:04 [INFO]: Epoch 101 - training loss: 0.2025, validation loss: 0.1624
2024-05-23 16:59:04 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch101_loss0.16239536056915918.pypots
2024-05-23 17:01:27 [INFO]: Epoch 102 - training loss: 0.2017, validation loss: 0.1626
2024-05-23 17:01:27 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch102_loss0.1625744380056858.pypots
2024-05-23 17:03:50 [INFO]: Epoch 103 - training loss: 0.1971, validation loss: 0.1618
2024-05-23 17:03:50 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch103_loss0.16176942537228267.pypots
2024-05-23 17:06:13 [INFO]: Epoch 104 - training loss: 0.2053, validation loss: 0.1616
2024-05-23 17:06:13 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch104_loss0.16155289684732754.pypots
2024-05-23 17:08:36 [INFO]: Epoch 105 - training loss: 0.2014, validation loss: 0.1615
2024-05-23 17:08:36 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch105_loss0.1614807091653347.pypots
2024-05-23 17:10:58 [INFO]: Epoch 106 - training loss: 0.2045, validation loss: 0.1631
2024-05-23 17:10:58 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI_epoch106_loss0.16313292210300764.pypots
2024-05-23 17:10:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:10:58 [INFO]: Finished training. The best model is from epoch#96.
2024-05-23 17:10:59 [INFO]: Saved the model to saved_results/round_4/CSDI_physionet2012/20240523_T125815/CSDI.pypots
2024-05-23 17:34:47 [INFO]: CSDI on PhysioNet-2012: MAE=0.2188, MSE=0.2441
2024-05-23 19:10:01 [INFO]: Successfully saved to saved_results/round_4/CSDI_physionet2012/imputation.pkl
2024-05-23 19:10:01 [INFO]: Using the given device: cuda:0
2024-05-23 19:10:01 [INFO]: Model files will be saved to saved_results/round_4/GPVAE_physionet2012/20240523_T191001
2024-05-23 19:10:01 [INFO]: Tensorboard file will be saved to saved_results/round_4/GPVAE_physionet2012/20240523_T191001/tensorboard
2024-05-23 19:10:01 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-23 19:10:05 [INFO]: Epoch 001 - training loss: 30100.8411, validation loss: 0.6943
2024-05-23 19:10:10 [INFO]: Epoch 002 - training loss: 23118.2457, validation loss: 0.6689
2024-05-23 19:10:14 [INFO]: Epoch 003 - training loss: 22937.0091, validation loss: 0.6468
2024-05-23 19:10:18 [INFO]: Epoch 004 - training loss: 22880.3264, validation loss: 0.6384
2024-05-23 19:10:22 [INFO]: Epoch 005 - training loss: 22857.3828, validation loss: 0.6319
2024-05-23 19:10:26 [INFO]: Epoch 006 - training loss: 22845.6372, validation loss: 0.6270
2024-05-23 19:10:29 [INFO]: Epoch 007 - training loss: 22838.7664, validation loss: 0.6205
2024-05-23 19:10:33 [INFO]: Epoch 008 - training loss: 22834.3266, validation loss: 0.6122
2024-05-23 19:10:37 [INFO]: Epoch 009 - training loss: 22831.9442, validation loss: 0.6124
2024-05-23 19:10:41 [INFO]: Epoch 010 - training loss: 22828.6207, validation loss: 0.6044
2024-05-23 19:10:45 [INFO]: Epoch 011 - training loss: 22824.3304, validation loss: 0.5769
2024-05-23 19:10:49 [INFO]: Epoch 012 - training loss: 22821.0171, validation loss: 0.5734
2024-05-23 19:10:53 [INFO]: Epoch 013 - training loss: 22818.7036, validation loss: 0.5749
2024-05-23 19:10:57 [INFO]: Epoch 014 - training loss: 22817.3772, validation loss: 0.5669
2024-05-23 19:11:01 [INFO]: Epoch 015 - training loss: 22814.8509, validation loss: 0.5564
2024-05-23 19:11:04 [INFO]: Epoch 016 - training loss: 22814.1116, validation loss: 0.5431
2024-05-23 19:11:08 [INFO]: Epoch 017 - training loss: 22810.5885, validation loss: 0.5686
2024-05-23 19:11:13 [INFO]: Epoch 018 - training loss: 22808.8716, validation loss: 0.5255
2024-05-23 19:11:17 [INFO]: Epoch 019 - training loss: 22806.9813, validation loss: 0.5243
2024-05-23 19:11:21 [INFO]: Epoch 020 - training loss: 22804.5874, validation loss: 0.5065
2024-05-23 19:11:25 [INFO]: Epoch 021 - training loss: 22803.8098, validation loss: 0.5034
2024-05-23 19:11:29 [INFO]: Epoch 022 - training loss: 22802.2630, validation loss: 0.5091
2024-05-23 19:11:33 [INFO]: Epoch 023 - training loss: 22802.3211, validation loss: 0.4964
2024-05-23 19:11:36 [INFO]: Epoch 024 - training loss: 22799.7778, validation loss: 0.5023
2024-05-23 19:11:40 [INFO]: Epoch 025 - training loss: 22798.4644, validation loss: 0.4871
2024-05-23 19:11:43 [INFO]: Epoch 026 - training loss: 22798.0965, validation loss: 0.4850
2024-05-23 19:11:47 [INFO]: Epoch 027 - training loss: 22796.7174, validation loss: 0.4800
2024-05-23 19:11:51 [INFO]: Epoch 028 - training loss: 22795.4117, validation loss: 0.4744
2024-05-23 19:11:55 [INFO]: Epoch 029 - training loss: 22794.4748, validation loss: 0.4764
2024-05-23 19:11:59 [INFO]: Epoch 030 - training loss: 22793.8942, validation loss: 0.4763
2024-05-23 19:12:03 [INFO]: Epoch 031 - training loss: 22793.2056, validation loss: 0.4719
2024-05-23 19:12:07 [INFO]: Epoch 032 - training loss: 22793.2196, validation loss: 0.4740
2024-05-23 19:12:11 [INFO]: Epoch 033 - training loss: 22792.4376, validation loss: 0.4749
2024-05-23 19:12:15 [INFO]: Epoch 034 - training loss: 22791.3039, validation loss: 0.4658
2024-05-23 19:12:20 [INFO]: Epoch 035 - training loss: 22790.8527, validation loss: 0.4690
2024-05-23 19:12:24 [INFO]: Epoch 036 - training loss: 22790.7548, validation loss: 0.4636
2024-05-23 19:12:28 [INFO]: Epoch 037 - training loss: 22790.9232, validation loss: 0.4641
2024-05-23 19:12:32 [INFO]: Epoch 038 - training loss: 22789.8476, validation loss: 0.4649
2024-05-23 19:12:36 [INFO]: Epoch 039 - training loss: 22789.0947, validation loss: 0.4623
2024-05-23 19:12:40 [INFO]: Epoch 040 - training loss: 22789.1128, validation loss: 0.4615
2024-05-23 19:12:44 [INFO]: Epoch 041 - training loss: 22788.7139, validation loss: 0.4607
2024-05-23 19:12:48 [INFO]: Epoch 042 - training loss: 22788.0631, validation loss: 0.4561
2024-05-23 19:12:52 [INFO]: Epoch 043 - training loss: 22787.6556, validation loss: 0.4531
2024-05-23 19:12:56 [INFO]: Epoch 044 - training loss: 22787.2001, validation loss: 0.4516
2024-05-23 19:13:00 [INFO]: Epoch 045 - training loss: 22786.5153, validation loss: 0.4524
2024-05-23 19:13:04 [INFO]: Epoch 046 - training loss: 22787.1402, validation loss: 0.4529
2024-05-23 19:13:08 [INFO]: Epoch 047 - training loss: 22787.4603, validation loss: 0.4485
2024-05-23 19:13:12 [INFO]: Epoch 048 - training loss: 22786.0406, validation loss: 0.4539
2024-05-23 19:13:16 [INFO]: Epoch 049 - training loss: 22785.5686, validation loss: 0.4548
2024-05-23 19:13:20 [INFO]: Epoch 050 - training loss: 22785.2388, validation loss: 0.4472
2024-05-23 19:13:24 [INFO]: Epoch 051 - training loss: 22785.2206, validation loss: 0.4491
2024-05-23 19:13:28 [INFO]: Epoch 052 - training loss: 22784.7568, validation loss: 0.4546
2024-05-23 19:13:32 [INFO]: Epoch 053 - training loss: 22784.2905, validation loss: 0.4522
2024-05-23 19:13:36 [INFO]: Epoch 054 - training loss: 22784.3118, validation loss: 0.4504
2024-05-23 19:13:41 [INFO]: Epoch 055 - training loss: 22785.0561, validation loss: 0.4465
2024-05-23 19:13:45 [INFO]: Epoch 056 - training loss: 22783.7780, validation loss: 0.4557
2024-05-23 19:13:49 [INFO]: Epoch 057 - training loss: 22783.3807, validation loss: 0.4504
2024-05-23 19:13:53 [INFO]: Epoch 058 - training loss: 22783.5959, validation loss: 0.4508
2024-05-23 19:13:57 [INFO]: Epoch 059 - training loss: 22783.2487, validation loss: 0.4474
2024-05-23 19:14:01 [INFO]: Epoch 060 - training loss: 22782.7135, validation loss: 0.4503
2024-05-23 19:14:05 [INFO]: Epoch 061 - training loss: 22782.7230, validation loss: 0.4479
2024-05-23 19:14:10 [INFO]: Epoch 062 - training loss: 22782.2695, validation loss: 0.4489
2024-05-23 19:14:14 [INFO]: Epoch 063 - training loss: 22781.9854, validation loss: 0.4483
2024-05-23 19:14:18 [INFO]: Epoch 064 - training loss: 22782.7616, validation loss: 0.4480
2024-05-23 19:14:22 [INFO]: Epoch 065 - training loss: 22781.8678, validation loss: 0.4449
2024-05-23 19:14:26 [INFO]: Epoch 066 - training loss: 22781.7724, validation loss: 0.4438
2024-05-23 19:14:30 [INFO]: Epoch 067 - training loss: 22781.7072, validation loss: 0.4441
2024-05-23 19:14:35 [INFO]: Epoch 068 - training loss: 22781.5998, validation loss: 0.4491
2024-05-23 19:14:38 [INFO]: Epoch 069 - training loss: 22781.0698, validation loss: 0.4467
2024-05-23 19:14:42 [INFO]: Epoch 070 - training loss: 22781.1083, validation loss: 0.4435
2024-05-23 19:14:47 [INFO]: Epoch 071 - training loss: 22780.8112, validation loss: 0.4431
2024-05-23 19:14:51 [INFO]: Epoch 072 - training loss: 22780.6288, validation loss: 0.4482
2024-05-23 19:14:55 [INFO]: Epoch 073 - training loss: 22780.5865, validation loss: 0.4438
2024-05-23 19:14:59 [INFO]: Epoch 074 - training loss: 22780.7193, validation loss: 0.4417
2024-05-23 19:15:03 [INFO]: Epoch 075 - training loss: 22780.7889, validation loss: 0.4444
2024-05-23 19:15:07 [INFO]: Epoch 076 - training loss: 22780.3666, validation loss: 0.4449
2024-05-23 19:15:11 [INFO]: Epoch 077 - training loss: 22780.1610, validation loss: 0.4419
2024-05-23 19:15:15 [INFO]: Epoch 078 - training loss: 22781.2202, validation loss: 0.4437
2024-05-23 19:15:19 [INFO]: Epoch 079 - training loss: 22780.3558, validation loss: 0.4396
2024-05-23 19:15:23 [INFO]: Epoch 080 - training loss: 22779.7319, validation loss: 0.4410
2024-05-23 19:15:27 [INFO]: Epoch 081 - training loss: 22779.5174, validation loss: 0.4393
2024-05-23 19:15:31 [INFO]: Epoch 082 - training loss: 22779.5225, validation loss: 0.4383
2024-05-23 19:15:35 [INFO]: Epoch 083 - training loss: 22779.4058, validation loss: 0.4389
2024-05-23 19:15:39 [INFO]: Epoch 084 - training loss: 22779.4323, validation loss: 0.4417
2024-05-23 19:15:43 [INFO]: Epoch 085 - training loss: 22779.6295, validation loss: 0.4440
2024-05-23 19:15:47 [INFO]: Epoch 086 - training loss: 22779.1701, validation loss: 0.4370
2024-05-23 19:15:51 [INFO]: Epoch 087 - training loss: 22779.4619, validation loss: 0.4440
2024-05-23 19:15:55 [INFO]: Epoch 088 - training loss: 22778.8446, validation loss: 0.4362
2024-05-23 19:15:59 [INFO]: Epoch 089 - training loss: 22778.8210, validation loss: 0.4404
2024-05-23 19:16:03 [INFO]: Epoch 090 - training loss: 22778.7284, validation loss: 0.4405
2024-05-23 19:16:07 [INFO]: Epoch 091 - training loss: 22778.8864, validation loss: 0.4375
2024-05-23 19:16:11 [INFO]: Epoch 092 - training loss: 22778.3970, validation loss: 0.4393
2024-05-23 19:16:16 [INFO]: Epoch 093 - training loss: 22778.0125, validation loss: 0.4382
2024-05-23 19:16:20 [INFO]: Epoch 094 - training loss: 22778.4966, validation loss: 0.4412
2024-05-23 19:16:24 [INFO]: Epoch 095 - training loss: 22778.3614, validation loss: 0.4430
2024-05-23 19:16:28 [INFO]: Epoch 096 - training loss: 22777.9007, validation loss: 0.4377
2024-05-23 19:16:32 [INFO]: Epoch 097 - training loss: 22777.8764, validation loss: 0.4353
2024-05-23 19:16:36 [INFO]: Epoch 098 - training loss: 22777.9224, validation loss: 0.4358
2024-05-23 19:16:41 [INFO]: Epoch 099 - training loss: 22777.6311, validation loss: 0.4379
2024-05-23 19:16:46 [INFO]: Epoch 100 - training loss: 22777.5774, validation loss: 0.4406
2024-05-23 19:16:50 [INFO]: Epoch 101 - training loss: 22777.8923, validation loss: 0.4372
2024-05-23 19:16:54 [INFO]: Epoch 102 - training loss: 22777.4819, validation loss: 0.4367
2024-05-23 19:16:58 [INFO]: Epoch 103 - training loss: 22777.1447, validation loss: 0.4368
2024-05-23 19:17:02 [INFO]: Epoch 104 - training loss: 22777.4912, validation loss: 0.4331
2024-05-23 19:17:07 [INFO]: Epoch 105 - training loss: 22777.0133, validation loss: 0.4341
2024-05-23 19:17:11 [INFO]: Epoch 106 - training loss: 22776.8455, validation loss: 0.4373
2024-05-23 19:17:15 [INFO]: Epoch 107 - training loss: 22776.9328, validation loss: 0.4365
2024-05-23 19:17:19 [INFO]: Epoch 108 - training loss: 22776.7136, validation loss: 0.4343
2024-05-23 19:17:23 [INFO]: Epoch 109 - training loss: 22776.9496, validation loss: 0.4357
2024-05-23 19:17:27 [INFO]: Epoch 110 - training loss: 22776.3856, validation loss: 0.4354
2024-05-23 19:17:31 [INFO]: Epoch 111 - training loss: 22777.1940, validation loss: 0.4334
2024-05-23 19:17:35 [INFO]: Epoch 112 - training loss: 22776.4514, validation loss: 0.4392
2024-05-23 19:17:39 [INFO]: Epoch 113 - training loss: 22776.7496, validation loss: 0.4328
2024-05-23 19:17:43 [INFO]: Epoch 114 - training loss: 22776.0034, validation loss: 0.4368
2024-05-23 19:17:47 [INFO]: Epoch 115 - training loss: 22775.8658, validation loss: 0.4343
2024-05-23 19:17:52 [INFO]: Epoch 116 - training loss: 22776.0258, validation loss: 0.4327
2024-05-23 19:17:56 [INFO]: Epoch 117 - training loss: 22776.1534, validation loss: 0.4326
2024-05-23 19:18:00 [INFO]: Epoch 118 - training loss: 22775.7535, validation loss: 0.4355
2024-05-23 19:18:04 [INFO]: Epoch 119 - training loss: 22776.1035, validation loss: 0.4327
2024-05-23 19:18:08 [INFO]: Epoch 120 - training loss: 22775.6861, validation loss: 0.4328
2024-05-23 19:18:12 [INFO]: Epoch 121 - training loss: 22776.0622, validation loss: 0.4344
2024-05-23 19:18:16 [INFO]: Epoch 122 - training loss: 22775.7356, validation loss: 0.4351
2024-05-23 19:18:20 [INFO]: Epoch 123 - training loss: 22775.4188, validation loss: 0.4321
2024-05-23 19:18:24 [INFO]: Epoch 124 - training loss: 22775.4102, validation loss: 0.4312
2024-05-23 19:18:29 [INFO]: Epoch 125 - training loss: 22775.5744, validation loss: 0.4351
2024-05-23 19:18:33 [INFO]: Epoch 126 - training loss: 22775.8072, validation loss: 0.4304
2024-05-23 19:18:37 [INFO]: Epoch 127 - training loss: 22775.4699, validation loss: 0.4315
2024-05-23 19:18:41 [INFO]: Epoch 128 - training loss: 22774.9975, validation loss: 0.4318
2024-05-23 19:18:45 [INFO]: Epoch 129 - training loss: 22774.8448, validation loss: 0.4327
2024-05-23 19:18:49 [INFO]: Epoch 130 - training loss: 22774.8234, validation loss: 0.4352
2024-05-23 19:18:53 [INFO]: Epoch 131 - training loss: 22775.0079, validation loss: 0.4306
2024-05-23 19:18:57 [INFO]: Epoch 132 - training loss: 22774.8676, validation loss: 0.4301
2024-05-23 19:19:01 [INFO]: Epoch 133 - training loss: 22774.8954, validation loss: 0.4294
2024-05-23 19:19:05 [INFO]: Epoch 134 - training loss: 22775.2358, validation loss: 0.4310
2024-05-23 19:19:09 [INFO]: Epoch 135 - training loss: 22774.7886, validation loss: 0.4319
2024-05-23 19:19:13 [INFO]: Epoch 136 - training loss: 22775.1186, validation loss: 0.4316
2024-05-23 19:19:17 [INFO]: Epoch 137 - training loss: 22774.8965, validation loss: 0.4317
2024-05-23 19:19:21 [INFO]: Epoch 138 - training loss: 22774.4823, validation loss: 0.4245
2024-05-23 19:19:25 [INFO]: Epoch 139 - training loss: 22774.4951, validation loss: 0.4309
2024-05-23 19:19:29 [INFO]: Epoch 140 - training loss: 22774.4208, validation loss: 0.4316
2024-05-23 19:19:33 [INFO]: Epoch 141 - training loss: 22774.1405, validation loss: 0.4291
2024-05-23 19:19:37 [INFO]: Epoch 142 - training loss: 22774.3087, validation loss: 0.4275
2024-05-23 19:19:41 [INFO]: Epoch 143 - training loss: 22774.0989, validation loss: 0.4300
2024-05-23 19:19:45 [INFO]: Epoch 144 - training loss: 22774.3805, validation loss: 0.4308
2024-05-23 19:19:49 [INFO]: Epoch 145 - training loss: 22774.2039, validation loss: 0.4352
2024-05-23 19:19:53 [INFO]: Epoch 146 - training loss: 22773.7691, validation loss: 0.4297
2024-05-23 19:19:57 [INFO]: Epoch 147 - training loss: 22773.9068, validation loss: 0.4257
2024-05-23 19:20:01 [INFO]: Epoch 148 - training loss: 22775.5856, validation loss: 0.4253
2024-05-23 19:20:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:20:01 [INFO]: Finished training. The best model is from epoch#138.
2024-05-23 19:20:01 [INFO]: Saved the model to saved_results/round_4/GPVAE_physionet2012/20240523_T191001/GPVAE.pypots
2024-05-23 19:20:02 [INFO]: GP-VAE on PhysioNet-2012: MAE=0.3923, MSE=0.4181
2024-05-23 19:20:04 [INFO]: Successfully saved to saved_results/round_4/GPVAE_physionet2012/imputation.pkl
2024-05-23 19:20:04 [INFO]: Using the given device: cuda:0
2024-05-23 19:20:04 [INFO]: Model files will be saved to saved_results/round_4/USGAN_physionet2012/20240523_T192004
2024-05-23 19:20:04 [INFO]: Tensorboard file will be saved to saved_results/round_4/USGAN_physionet2012/20240523_T192004/tensorboard
2024-05-23 19:20:04 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-23 19:22:20 [INFO]: Epoch 001 - generator training loss: 0.4954, discriminator training loss: 0.2800, validation loss: 0.4901
2024-05-23 19:24:15 [INFO]: Epoch 002 - generator training loss: 0.4472, discriminator training loss: 0.1287, validation loss: 0.4346
2024-05-23 19:26:12 [INFO]: Epoch 003 - generator training loss: 0.4158, discriminator training loss: 0.0816, validation loss: 0.4027
2024-05-23 19:28:09 [INFO]: Epoch 004 - generator training loss: 0.4000, discriminator training loss: 0.0611, validation loss: 0.3815
2024-05-23 19:30:06 [INFO]: Epoch 005 - generator training loss: 0.3878, discriminator training loss: 0.0493, validation loss: 0.3701
2024-05-23 19:32:02 [INFO]: Epoch 006 - generator training loss: 0.3759, discriminator training loss: 0.0419, validation loss: 0.3550
2024-05-23 19:33:59 [INFO]: Epoch 007 - generator training loss: 0.3629, discriminator training loss: 0.0371, validation loss: 0.3437
2024-05-23 19:35:55 [INFO]: Epoch 008 - generator training loss: 0.3511, discriminator training loss: 0.0338, validation loss: 0.3327
2024-05-23 19:37:51 [INFO]: Epoch 009 - generator training loss: 0.3431, discriminator training loss: 0.0316, validation loss: 0.3214
2024-05-23 19:39:51 [INFO]: Epoch 010 - generator training loss: 0.3325, discriminator training loss: 0.0298, validation loss: 0.3136
2024-05-23 19:41:48 [INFO]: Epoch 011 - generator training loss: 0.3237, discriminator training loss: 0.0284, validation loss: 0.3076
2024-05-23 19:43:45 [INFO]: Epoch 012 - generator training loss: 0.3155, discriminator training loss: 0.0271, validation loss: 0.3001
2024-05-23 19:45:43 [INFO]: Epoch 013 - generator training loss: 0.3100, discriminator training loss: 0.0264, validation loss: 0.2992
2024-05-23 19:47:37 [INFO]: Epoch 014 - generator training loss: 0.3039, discriminator training loss: 0.0256, validation loss: 0.2945
2024-05-23 19:49:28 [INFO]: Epoch 015 - generator training loss: 0.2981, discriminator training loss: 0.0249, validation loss: 0.2918
2024-05-23 19:51:21 [INFO]: Epoch 016 - generator training loss: 0.2925, discriminator training loss: 0.0244, validation loss: 0.3006
2024-05-23 19:53:16 [INFO]: Epoch 017 - generator training loss: 0.2890, discriminator training loss: 0.0239, validation loss: 0.2841
2024-05-23 19:55:09 [INFO]: Epoch 018 - generator training loss: 0.2849, discriminator training loss: 0.0234, validation loss: 0.2780
2024-05-23 19:57:01 [INFO]: Epoch 019 - generator training loss: 0.2797, discriminator training loss: 0.0230, validation loss: 0.2794
2024-05-23 19:58:53 [INFO]: Epoch 020 - generator training loss: 0.2767, discriminator training loss: 0.0226, validation loss: 0.2781
2024-05-23 20:00:45 [INFO]: Epoch 021 - generator training loss: 0.2757, discriminator training loss: 0.0223, validation loss: 0.2781
2024-05-23 20:02:33 [INFO]: Epoch 022 - generator training loss: 0.2706, discriminator training loss: 0.0219, validation loss: 0.2738
2024-05-23 20:04:23 [INFO]: Epoch 023 - generator training loss: 0.2679, discriminator training loss: 0.0216, validation loss: 0.2749
2024-05-23 20:06:20 [INFO]: Epoch 024 - generator training loss: 0.2664, discriminator training loss: 0.0213, validation loss: 0.2768
2024-05-23 20:08:14 [INFO]: Epoch 025 - generator training loss: 0.2659, discriminator training loss: 0.0212, validation loss: 0.2740
2024-05-23 20:10:10 [INFO]: Epoch 026 - generator training loss: 0.2635, discriminator training loss: 0.0210, validation loss: 0.2750
2024-05-23 20:12:06 [INFO]: Epoch 027 - generator training loss: 0.2601, discriminator training loss: 0.0209, validation loss: 0.2774
2024-05-23 20:14:00 [INFO]: Epoch 028 - generator training loss: 0.2617, discriminator training loss: 0.0209, validation loss: 0.2734
2024-05-23 20:15:58 [INFO]: Epoch 029 - generator training loss: 0.2586, discriminator training loss: 0.0206, validation loss: 0.2756
2024-05-23 20:18:00 [INFO]: Epoch 030 - generator training loss: 0.2532, discriminator training loss: 0.0204, validation loss: 0.2797
2024-05-23 20:19:59 [INFO]: Epoch 031 - generator training loss: 0.2526, discriminator training loss: 0.0205, validation loss: 0.2854
2024-05-23 20:21:55 [INFO]: Epoch 032 - generator training loss: 0.2527, discriminator training loss: 0.0203, validation loss: 0.2741
2024-05-23 20:23:51 [INFO]: Epoch 033 - generator training loss: 0.2487, discriminator training loss: 0.0201, validation loss: 0.2731
2024-05-23 20:25:50 [INFO]: Epoch 034 - generator training loss: 0.2517, discriminator training loss: 0.0201, validation loss: 0.2819
2024-05-23 20:27:48 [INFO]: Epoch 035 - generator training loss: 0.2540, discriminator training loss: 0.0199, validation loss: 0.2754
2024-05-23 20:29:46 [INFO]: Epoch 036 - generator training loss: 0.2455, discriminator training loss: 0.0196, validation loss: 0.2740
2024-05-23 20:31:43 [INFO]: Epoch 037 - generator training loss: 0.2403, discriminator training loss: 0.0196, validation loss: 0.2732
2024-05-23 20:33:40 [INFO]: Epoch 038 - generator training loss: 0.2409, discriminator training loss: 0.0194, validation loss: 0.2759
2024-05-23 20:35:31 [INFO]: Epoch 039 - generator training loss: 0.2357, discriminator training loss: 0.0193, validation loss: 0.2755
2024-05-23 20:37:27 [INFO]: Epoch 040 - generator training loss: 0.2387, discriminator training loss: 0.0191, validation loss: 0.2810
2024-05-23 20:39:24 [INFO]: Epoch 041 - generator training loss: 0.2365, discriminator training loss: 0.0190, validation loss: 0.2790
2024-05-23 20:41:21 [INFO]: Epoch 042 - generator training loss: 0.2340, discriminator training loss: 0.0189, validation loss: 0.2791
2024-05-23 20:43:18 [INFO]: Epoch 043 - generator training loss: 0.2333, discriminator training loss: 0.0188, validation loss: 0.2727
2024-05-23 20:45:13 [INFO]: Epoch 044 - generator training loss: 0.2280, discriminator training loss: 0.0185, validation loss: 0.2861
2024-05-23 20:47:04 [INFO]: Epoch 045 - generator training loss: 0.2280, discriminator training loss: 0.0184, validation loss: 0.2764
2024-05-23 20:48:55 [INFO]: Epoch 046 - generator training loss: 0.2241, discriminator training loss: 0.0183, validation loss: 0.2807
2024-05-23 20:50:48 [INFO]: Epoch 047 - generator training loss: 0.2308, discriminator training loss: 0.0183, validation loss: 0.2864
2024-05-23 20:52:38 [INFO]: Epoch 048 - generator training loss: 0.2238, discriminator training loss: 0.0182, validation loss: 0.2843
2024-05-23 20:54:30 [INFO]: Epoch 049 - generator training loss: 0.2285, discriminator training loss: 0.0180, validation loss: 0.2776
2024-05-23 20:56:22 [INFO]: Epoch 050 - generator training loss: 0.2219, discriminator training loss: 0.0179, validation loss: 0.2893
2024-05-23 20:58:11 [INFO]: Epoch 051 - generator training loss: 0.2251, discriminator training loss: 0.0179, validation loss: 0.2766
2024-05-23 21:00:01 [INFO]: Epoch 052 - generator training loss: 0.2176, discriminator training loss: 0.0178, validation loss: 0.2794
2024-05-23 21:01:50 [INFO]: Epoch 053 - generator training loss: 0.2165, discriminator training loss: 0.0177, validation loss: 0.2794
2024-05-23 21:01:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:01:50 [INFO]: Finished training. The best model is from epoch#43.
2024-05-23 21:01:50 [INFO]: Saved the model to saved_results/round_4/USGAN_physionet2012/20240523_T192004/USGAN.pypots
2024-05-23 21:02:05 [INFO]: US-GAN on PhysioNet-2012: MAE=0.2746, MSE=0.2744
2024-05-23 21:03:05 [INFO]: Successfully saved to saved_results/round_4/USGAN_physionet2012/imputation.pkl
2024-05-23 21:03:05 [INFO]: Using the given device: cuda:0
2024-05-23 21:03:05 [INFO]: Model files will be saved to saved_results/round_4/BRITS_physionet2012/20240523_T210305
2024-05-23 21:03:05 [INFO]: Tensorboard file will be saved to saved_results/round_4/BRITS_physionet2012/20240523_T210305/tensorboard
2024-05-23 21:03:05 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-23 21:04:35 [INFO]: Epoch 001 - training loss: 0.9476, validation loss: 0.4327
2024-05-23 21:05:45 [INFO]: Epoch 002 - training loss: 0.7725, validation loss: 0.3798
2024-05-23 21:06:57 [INFO]: Epoch 003 - training loss: 0.7121, validation loss: 0.3554
2024-05-23 21:08:11 [INFO]: Epoch 004 - training loss: 0.6778, validation loss: 0.3453
2024-05-23 21:09:23 [INFO]: Epoch 005 - training loss: 0.6564, validation loss: 0.3381
2024-05-23 21:10:37 [INFO]: Epoch 006 - training loss: 0.6424, validation loss: 0.3339
2024-05-23 21:11:48 [INFO]: Epoch 007 - training loss: 0.6320, validation loss: 0.3329
2024-05-23 21:13:00 [INFO]: Epoch 008 - training loss: 0.6237, validation loss: 0.3250
2024-05-23 21:14:10 [INFO]: Epoch 009 - training loss: 0.6164, validation loss: 0.3277
2024-05-23 21:15:23 [INFO]: Epoch 010 - training loss: 0.6098, validation loss: 0.3297
2024-05-23 21:16:35 [INFO]: Epoch 011 - training loss: 0.6034, validation loss: 0.3228
2024-05-23 21:17:47 [INFO]: Epoch 012 - training loss: 0.5985, validation loss: 0.3267
2024-05-23 21:19:01 [INFO]: Epoch 013 - training loss: 0.5915, validation loss: 0.3205
2024-05-23 21:20:14 [INFO]: Epoch 014 - training loss: 0.5864, validation loss: 0.3252
2024-05-23 21:21:28 [INFO]: Epoch 015 - training loss: 0.5812, validation loss: 0.3269
2024-05-23 21:22:38 [INFO]: Epoch 016 - training loss: 0.5774, validation loss: 0.3292
2024-05-23 21:23:51 [INFO]: Epoch 017 - training loss: 0.5789, validation loss: 0.3347
2024-05-23 21:25:04 [INFO]: Epoch 018 - training loss: 0.5738, validation loss: 0.3308
2024-05-23 21:26:18 [INFO]: Epoch 019 - training loss: 0.5679, validation loss: 0.3398
2024-05-23 21:27:31 [INFO]: Epoch 020 - training loss: 0.5647, validation loss: 0.3361
2024-05-23 21:28:44 [INFO]: Epoch 021 - training loss: 0.5625, validation loss: 0.3408
2024-05-23 21:29:57 [INFO]: Epoch 022 - training loss: 0.5598, validation loss: 0.3374
2024-05-23 21:31:13 [INFO]: Epoch 023 - training loss: 0.5584, validation loss: 0.3444
2024-05-23 21:31:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:31:13 [INFO]: Finished training. The best model is from epoch#13.
2024-05-23 21:31:13 [INFO]: Saved the model to saved_results/round_4/BRITS_physionet2012/20240523_T210305/BRITS.pypots
2024-05-23 21:31:28 [INFO]: BRITS on PhysioNet-2012: MAE=0.2470, MSE=0.3257
2024-05-23 21:32:25 [INFO]: Successfully saved to saved_results/round_4/BRITS_physionet2012/imputation.pkl
2024-05-23 21:32:25 [INFO]: Using the given device: cuda:0
2024-05-23 21:32:25 [INFO]: Model files will be saved to saved_results/round_4/MRNN_physionet2012/20240523_T213225
2024-05-23 21:32:25 [INFO]: Tensorboard file will be saved to saved_results/round_4/MRNN_physionet2012/20240523_T213225/tensorboard
2024-05-23 21:32:25 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-23 21:33:00 [INFO]: Epoch 001 - training loss: 0.8529, validation loss: 0.9153
2024-05-23 21:33:00 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN_epoch1_loss0.9152965048948923.pypots
2024-05-23 21:33:17 [INFO]: Epoch 002 - training loss: 0.5617, validation loss: 0.8897
2024-05-23 21:33:17 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN_epoch2_loss0.8897409876187642.pypots
2024-05-23 21:33:33 [INFO]: Epoch 003 - training loss: 0.5155, validation loss: 0.8821
2024-05-23 21:33:33 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN_epoch3_loss0.8821279088656108.pypots
2024-05-23 21:33:51 [INFO]: Epoch 004 - training loss: 0.4984, validation loss: 0.8807
2024-05-23 21:33:51 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN_epoch4_loss0.8807435403267543.pypots
2024-05-23 21:34:08 [INFO]: Epoch 005 - training loss: 0.4791, validation loss: 0.8826
2024-05-23 21:34:08 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN_epoch5_loss0.8826413542032242.pypots
2024-05-23 21:34:25 [INFO]: Epoch 006 - training loss: 0.4733, validation loss: 0.8866
2024-05-23 21:34:25 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN_epoch6_loss0.8866426547368368.pypots
2024-05-23 21:34:41 [INFO]: Epoch 007 - training loss: 0.4618, validation loss: 0.8902
2024-05-23 21:34:41 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN_epoch7_loss0.8901720901330312.pypots
2024-05-23 21:34:58 [INFO]: Epoch 008 - training loss: 0.4591, validation loss: 0.8914
2024-05-23 21:34:58 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN_epoch8_loss0.8913809359073639.pypots
2024-05-23 21:35:14 [INFO]: Epoch 009 - training loss: 0.4586, validation loss: 0.8934
2024-05-23 21:35:14 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN_epoch9_loss0.8934081445137659.pypots
2024-05-23 21:35:30 [INFO]: Epoch 010 - training loss: 0.4515, validation loss: 0.8970
2024-05-23 21:35:30 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN_epoch10_loss0.8969772100448609.pypots
2024-05-23 21:35:47 [INFO]: Epoch 011 - training loss: 0.4478, validation loss: 0.8963
2024-05-23 21:35:47 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN_epoch11_loss0.8963041464487712.pypots
2024-05-23 21:36:07 [INFO]: Epoch 012 - training loss: 0.4489, validation loss: 0.8987
2024-05-23 21:36:07 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN_epoch12_loss0.8987445016702016.pypots
2024-05-23 21:36:26 [INFO]: Epoch 013 - training loss: 0.4432, validation loss: 0.9033
2024-05-23 21:36:26 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN_epoch13_loss0.9032862593730291.pypots
2024-05-23 21:36:43 [INFO]: Epoch 014 - training loss: 0.4356, validation loss: 0.9039
2024-05-23 21:36:43 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN_epoch14_loss0.9038952469825745.pypots
2024-05-23 21:36:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:36:43 [INFO]: Finished training. The best model is from epoch#4.
2024-05-23 21:36:43 [INFO]: Saved the model to saved_results/round_4/MRNN_physionet2012/20240523_T213225/MRNN.pypots
2024-05-23 21:36:50 [INFO]: MRNN on PhysioNet-2012: MAE=0.6817, MSE=0.8881
2024-05-23 21:37:16 [INFO]: Successfully saved to saved_results/round_4/MRNN_physionet2012/imputation.pkl
2024-05-23 21:37:16 [INFO]: Using the given device: cpu
2024-05-23 21:37:16 [INFO]: LOCF on PhysioNet-2012: MAE=0.4110, MSE=0.5688
2024-05-23 21:37:16 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_physionet2012".
2024-05-23 21:37:16 [INFO]: Successfully saved to saved_results/round_4/LOCF_physionet2012/imputation.pkl
2024-05-23 21:37:17 [INFO]: Median on PhysioNet-2012: MAE=0.6855, MSE=0.9913
2024-05-23 21:37:17 [INFO]: Successfully created the given path "saved_results/round_4/Median_physionet2012".
2024-05-23 21:37:17 [INFO]: Successfully saved to saved_results/round_4/Median_physionet2012/imputation.pkl
2024-05-23 21:37:17 [INFO]: Mean on PhysioNet-2012: MAE=0.7017, MSE=0.9536
2024-05-23 21:37:18 [INFO]: Successfully created the given path "saved_results/round_4/Mean_physionet2012".
2024-05-23 21:37:18 [INFO]: Successfully saved to saved_results/round_4/Mean_physionet2012/imputation.pkl
2024-05-23 21:37:18 [INFO]: 
SAITS on data/physionet_2012: MAE=0.2010.0014543654028906792, MSE=0.2180.002991666150591966
Transformer on data/physionet_2012: MAE=0.2070.002911300941143573, MSE=0.2210.004615876683751148
TimesNet on data/physionet_2012: MAE=0.2630.010471576255758272, MSE=0.2700.01248290560713391
CSDI on data/physionet_2012: MAE=0.2170.0027107032907920997, MSE=0.2730.035380831748371006
GPVAE on data/physionet_2012: MAE=0.3990.006573114846279624, MSE=0.4310.012061920586354363
USGAN on data/physionet_2012: MAE=0.2770.001662904722891557, MSE=0.2780.002094452017282375
BRITS on data/physionet_2012: MAE=0.2480.0021249301792231603, MSE=0.3260.004024585214682076
MRNN on data/physionet_2012: MAE=0.6830.000823914206730512, MSE=0.8910.0019194167928959945
LOCF on data/physionet_2012: MAE=0.4115.551115123125783e-17, MSE=0.5690.0
Median on data/physionet_2012: MAE=0.6850.0, MSE=0.9911.1102230246251565e-16
Mean on data/physionet_2012: MAE=0.7020.0, MSE=0.9540.0

