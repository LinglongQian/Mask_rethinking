2024-05-22 16:21:44 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-22 16:21:45 [INFO]: Using the given device: cuda:0
2024-05-22 16:21:45 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/SAITS_air_quality/20240522_T162145
2024-05-22 16:21:45 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/SAITS_air_quality/20240522_T162145/tensorboard
2024-05-22 16:21:45 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-22 16:21:54 [INFO]: Epoch 001 - training loss: 1.0553, validation loss: 0.4918
2024-05-22 16:21:55 [INFO]: Epoch 002 - training loss: 0.7634, validation loss: 0.3716
2024-05-22 16:21:56 [INFO]: Epoch 003 - training loss: 0.6584, validation loss: 0.2951
2024-05-22 16:21:56 [INFO]: Epoch 004 - training loss: 0.5806, validation loss: 0.2547
2024-05-22 16:21:57 [INFO]: Epoch 005 - training loss: 0.5244, validation loss: 0.2333
2024-05-22 16:21:58 [INFO]: Epoch 006 - training loss: 0.4863, validation loss: 0.2236
2024-05-22 16:21:58 [INFO]: Epoch 007 - training loss: 0.4622, validation loss: 0.2105
2024-05-22 16:21:59 [INFO]: Epoch 008 - training loss: 0.4413, validation loss: 0.2056
2024-05-22 16:22:00 [INFO]: Epoch 009 - training loss: 0.4269, validation loss: 0.2006
2024-05-22 16:22:00 [INFO]: Epoch 010 - training loss: 0.4173, validation loss: 0.1967
2024-05-22 16:22:01 [INFO]: Epoch 011 - training loss: 0.4059, validation loss: 0.1906
2024-05-22 16:22:01 [INFO]: Epoch 012 - training loss: 0.3985, validation loss: 0.1870
2024-05-22 16:22:02 [INFO]: Epoch 013 - training loss: 0.3903, validation loss: 0.1831
2024-05-22 16:22:03 [INFO]: Epoch 014 - training loss: 0.3819, validation loss: 0.1817
2024-05-22 16:22:03 [INFO]: Epoch 015 - training loss: 0.3769, validation loss: 0.1786
2024-05-22 16:22:04 [INFO]: Epoch 016 - training loss: 0.3711, validation loss: 0.1768
2024-05-22 16:22:05 [INFO]: Epoch 017 - training loss: 0.3668, validation loss: 0.1740
2024-05-22 16:22:05 [INFO]: Epoch 018 - training loss: 0.3615, validation loss: 0.1727
2024-05-22 16:22:06 [INFO]: Epoch 019 - training loss: 0.3578, validation loss: 0.1696
2024-05-22 16:22:06 [INFO]: Epoch 020 - training loss: 0.3533, validation loss: 0.1678
2024-05-22 16:22:07 [INFO]: Epoch 021 - training loss: 0.3496, validation loss: 0.1667
2024-05-22 16:22:08 [INFO]: Epoch 022 - training loss: 0.3467, validation loss: 0.1650
2024-05-22 16:22:08 [INFO]: Epoch 023 - training loss: 0.3432, validation loss: 0.1643
2024-05-22 16:22:09 [INFO]: Epoch 024 - training loss: 0.3406, validation loss: 0.1619
2024-05-22 16:22:10 [INFO]: Epoch 025 - training loss: 0.3384, validation loss: 0.1604
2024-05-22 16:22:10 [INFO]: Epoch 026 - training loss: 0.3358, validation loss: 0.1606
2024-05-22 16:22:11 [INFO]: Epoch 027 - training loss: 0.3330, validation loss: 0.1582
2024-05-22 16:22:11 [INFO]: Epoch 028 - training loss: 0.3309, validation loss: 0.1569
2024-05-22 16:22:12 [INFO]: Epoch 029 - training loss: 0.3272, validation loss: 0.1553
2024-05-22 16:22:13 [INFO]: Epoch 030 - training loss: 0.3264, validation loss: 0.1542
2024-05-22 16:22:13 [INFO]: Epoch 031 - training loss: 0.3232, validation loss: 0.1543
2024-05-22 16:22:14 [INFO]: Epoch 032 - training loss: 0.3215, validation loss: 0.1525
2024-05-22 16:22:15 [INFO]: Epoch 033 - training loss: 0.3198, validation loss: 0.1502
2024-05-22 16:22:15 [INFO]: Epoch 034 - training loss: 0.3168, validation loss: 0.1507
2024-05-22 16:22:16 [INFO]: Epoch 035 - training loss: 0.3180, validation loss: 0.1501
2024-05-22 16:22:17 [INFO]: Epoch 036 - training loss: 0.3147, validation loss: 0.1492
2024-05-22 16:22:17 [INFO]: Epoch 037 - training loss: 0.3134, validation loss: 0.1470
2024-05-22 16:22:18 [INFO]: Epoch 038 - training loss: 0.3090, validation loss: 0.1472
2024-05-22 16:22:19 [INFO]: Epoch 039 - training loss: 0.3090, validation loss: 0.1455
2024-05-22 16:22:19 [INFO]: Epoch 040 - training loss: 0.3064, validation loss: 0.1438
2024-05-22 16:22:20 [INFO]: Epoch 041 - training loss: 0.3047, validation loss: 0.1433
2024-05-22 16:22:20 [INFO]: Epoch 042 - training loss: 0.3020, validation loss: 0.1423
2024-05-22 16:22:21 [INFO]: Epoch 043 - training loss: 0.3017, validation loss: 0.1411
2024-05-22 16:22:22 [INFO]: Epoch 044 - training loss: 0.3010, validation loss: 0.1404
2024-05-22 16:22:22 [INFO]: Epoch 045 - training loss: 0.2979, validation loss: 0.1406
2024-05-22 16:22:23 [INFO]: Epoch 046 - training loss: 0.2985, validation loss: 0.1388
2024-05-22 16:22:24 [INFO]: Epoch 047 - training loss: 0.2973, validation loss: 0.1377
2024-05-22 16:22:24 [INFO]: Epoch 048 - training loss: 0.2935, validation loss: 0.1381
2024-05-22 16:22:25 [INFO]: Epoch 049 - training loss: 0.2941, validation loss: 0.1374
2024-05-22 16:22:26 [INFO]: Epoch 050 - training loss: 0.2913, validation loss: 0.1363
2024-05-22 16:22:26 [INFO]: Epoch 051 - training loss: 0.2914, validation loss: 0.1366
2024-05-22 16:22:27 [INFO]: Epoch 052 - training loss: 0.2900, validation loss: 0.1349
2024-05-22 16:22:27 [INFO]: Epoch 053 - training loss: 0.2887, validation loss: 0.1340
2024-05-22 16:22:28 [INFO]: Epoch 054 - training loss: 0.2867, validation loss: 0.1341
2024-05-22 16:22:29 [INFO]: Epoch 055 - training loss: 0.2851, validation loss: 0.1331
2024-05-22 16:22:29 [INFO]: Epoch 056 - training loss: 0.2842, validation loss: 0.1321
2024-05-22 16:22:30 [INFO]: Epoch 057 - training loss: 0.2826, validation loss: 0.1311
2024-05-22 16:22:31 [INFO]: Epoch 058 - training loss: 0.2826, validation loss: 0.1311
2024-05-22 16:22:31 [INFO]: Epoch 059 - training loss: 0.2807, validation loss: 0.1303
2024-05-22 16:22:32 [INFO]: Epoch 060 - training loss: 0.2803, validation loss: 0.1299
2024-05-22 16:22:33 [INFO]: Epoch 061 - training loss: 0.2782, validation loss: 0.1297
2024-05-22 16:22:33 [INFO]: Epoch 062 - training loss: 0.2772, validation loss: 0.1284
2024-05-22 16:22:34 [INFO]: Epoch 063 - training loss: 0.2758, validation loss: 0.1276
2024-05-22 16:22:34 [INFO]: Epoch 064 - training loss: 0.2749, validation loss: 0.1267
2024-05-22 16:22:35 [INFO]: Epoch 065 - training loss: 0.2730, validation loss: 0.1282
2024-05-22 16:22:36 [INFO]: Epoch 066 - training loss: 0.2722, validation loss: 0.1265
2024-05-22 16:22:36 [INFO]: Epoch 067 - training loss: 0.2706, validation loss: 0.1256
2024-05-22 16:22:37 [INFO]: Epoch 068 - training loss: 0.2705, validation loss: 0.1250
2024-05-22 16:22:38 [INFO]: Epoch 069 - training loss: 0.2683, validation loss: 0.1248
2024-05-22 16:22:38 [INFO]: Epoch 070 - training loss: 0.2677, validation loss: 0.1250
2024-05-22 16:22:39 [INFO]: Epoch 071 - training loss: 0.2664, validation loss: 0.1241
2024-05-22 16:22:39 [INFO]: Epoch 072 - training loss: 0.2665, validation loss: 0.1225
2024-05-22 16:22:40 [INFO]: Epoch 073 - training loss: 0.2671, validation loss: 0.1226
2024-05-22 16:22:41 [INFO]: Epoch 074 - training loss: 0.2646, validation loss: 0.1220
2024-05-22 16:22:41 [INFO]: Epoch 075 - training loss: 0.2629, validation loss: 0.1214
2024-05-22 16:22:42 [INFO]: Epoch 076 - training loss: 0.2623, validation loss: 0.1215
2024-05-22 16:22:43 [INFO]: Epoch 077 - training loss: 0.2618, validation loss: 0.1208
2024-05-22 16:22:43 [INFO]: Epoch 078 - training loss: 0.2614, validation loss: 0.1210
2024-05-22 16:22:44 [INFO]: Epoch 079 - training loss: 0.2606, validation loss: 0.1201
2024-05-22 16:22:44 [INFO]: Epoch 080 - training loss: 0.2579, validation loss: 0.1193
2024-05-22 16:22:45 [INFO]: Epoch 081 - training loss: 0.2581, validation loss: 0.1193
2024-05-22 16:22:46 [INFO]: Epoch 082 - training loss: 0.2580, validation loss: 0.1196
2024-05-22 16:22:46 [INFO]: Epoch 083 - training loss: 0.2566, validation loss: 0.1186
2024-05-22 16:22:47 [INFO]: Epoch 084 - training loss: 0.2549, validation loss: 0.1176
2024-05-22 16:22:48 [INFO]: Epoch 085 - training loss: 0.2539, validation loss: 0.1177
2024-05-22 16:22:48 [INFO]: Epoch 086 - training loss: 0.2537, validation loss: 0.1170
2024-05-22 16:22:49 [INFO]: Epoch 087 - training loss: 0.2548, validation loss: 0.1169
2024-05-22 16:22:49 [INFO]: Epoch 088 - training loss: 0.2545, validation loss: 0.1162
2024-05-22 16:22:50 [INFO]: Epoch 089 - training loss: 0.2526, validation loss: 0.1163
2024-05-22 16:22:51 [INFO]: Epoch 090 - training loss: 0.2508, validation loss: 0.1151
2024-05-22 16:22:51 [INFO]: Epoch 091 - training loss: 0.2504, validation loss: 0.1157
2024-05-22 16:22:52 [INFO]: Epoch 092 - training loss: 0.2499, validation loss: 0.1149
2024-05-22 16:22:53 [INFO]: Epoch 093 - training loss: 0.2496, validation loss: 0.1152
2024-05-22 16:22:53 [INFO]: Epoch 094 - training loss: 0.2477, validation loss: 0.1148
2024-05-22 16:22:54 [INFO]: Epoch 095 - training loss: 0.2480, validation loss: 0.1147
2024-05-22 16:22:54 [INFO]: Epoch 096 - training loss: 0.2477, validation loss: 0.1145
2024-05-22 16:22:55 [INFO]: Epoch 097 - training loss: 0.2488, validation loss: 0.1141
2024-05-22 16:22:56 [INFO]: Epoch 098 - training loss: 0.2462, validation loss: 0.1137
2024-05-22 16:22:56 [INFO]: Epoch 099 - training loss: 0.2453, validation loss: 0.1144
2024-05-22 16:22:57 [INFO]: Epoch 100 - training loss: 0.2471, validation loss: 0.1136
2024-05-22 16:22:58 [INFO]: Epoch 101 - training loss: 0.2460, validation loss: 0.1131
2024-05-22 16:22:58 [INFO]: Epoch 102 - training loss: 0.2445, validation loss: 0.1132
2024-05-22 16:22:59 [INFO]: Epoch 103 - training loss: 0.2432, validation loss: 0.1130
2024-05-22 16:22:59 [INFO]: Epoch 104 - training loss: 0.2432, validation loss: 0.1127
2024-05-22 16:23:00 [INFO]: Epoch 105 - training loss: 0.2431, validation loss: 0.1121
2024-05-22 16:23:01 [INFO]: Epoch 106 - training loss: 0.2430, validation loss: 0.1120
2024-05-22 16:23:01 [INFO]: Epoch 107 - training loss: 0.2430, validation loss: 0.1120
2024-05-22 16:23:02 [INFO]: Epoch 108 - training loss: 0.2424, validation loss: 0.1112
2024-05-22 16:23:03 [INFO]: Epoch 109 - training loss: 0.2411, validation loss: 0.1123
2024-05-22 16:23:03 [INFO]: Epoch 110 - training loss: 0.2409, validation loss: 0.1113
2024-05-22 16:23:04 [INFO]: Epoch 111 - training loss: 0.2392, validation loss: 0.1124
2024-05-22 16:23:04 [INFO]: Epoch 112 - training loss: 0.2387, validation loss: 0.1111
2024-05-22 16:23:05 [INFO]: Epoch 113 - training loss: 0.2377, validation loss: 0.1105
2024-05-22 16:23:06 [INFO]: Epoch 114 - training loss: 0.2378, validation loss: 0.1109
2024-05-22 16:23:06 [INFO]: Epoch 115 - training loss: 0.2390, validation loss: 0.1107
2024-05-22 16:23:07 [INFO]: Epoch 116 - training loss: 0.2380, validation loss: 0.1104
2024-05-22 16:23:08 [INFO]: Epoch 117 - training loss: 0.2359, validation loss: 0.1103
2024-05-22 16:23:08 [INFO]: Epoch 118 - training loss: 0.2355, validation loss: 0.1101
2024-05-22 16:23:09 [INFO]: Epoch 119 - training loss: 0.2346, validation loss: 0.1096
2024-05-22 16:23:09 [INFO]: Epoch 120 - training loss: 0.2337, validation loss: 0.1094
2024-05-22 16:23:10 [INFO]: Epoch 121 - training loss: 0.2330, validation loss: 0.1090
2024-05-22 16:23:11 [INFO]: Epoch 122 - training loss: 0.2341, validation loss: 0.1090
2024-05-22 16:23:11 [INFO]: Epoch 123 - training loss: 0.2346, validation loss: 0.1090
2024-05-22 16:23:12 [INFO]: Epoch 124 - training loss: 0.2325, validation loss: 0.1084
2024-05-22 16:23:13 [INFO]: Epoch 125 - training loss: 0.2328, validation loss: 0.1089
2024-05-22 16:23:13 [INFO]: Epoch 126 - training loss: 0.2319, validation loss: 0.1078
2024-05-22 16:23:14 [INFO]: Epoch 127 - training loss: 0.2328, validation loss: 0.1091
2024-05-22 16:23:14 [INFO]: Epoch 128 - training loss: 0.2310, validation loss: 0.1086
2024-05-22 16:23:15 [INFO]: Epoch 129 - training loss: 0.2305, validation loss: 0.1081
2024-05-22 16:23:16 [INFO]: Epoch 130 - training loss: 0.2302, validation loss: 0.1075
2024-05-22 16:23:16 [INFO]: Epoch 131 - training loss: 0.2301, validation loss: 0.1080
2024-05-22 16:23:17 [INFO]: Epoch 132 - training loss: 0.2307, validation loss: 0.1076
2024-05-22 16:23:18 [INFO]: Epoch 133 - training loss: 0.2293, validation loss: 0.1078
2024-05-22 16:23:18 [INFO]: Epoch 134 - training loss: 0.2281, validation loss: 0.1079
2024-05-22 16:23:19 [INFO]: Epoch 135 - training loss: 0.2277, validation loss: 0.1070
2024-05-22 16:23:19 [INFO]: Epoch 136 - training loss: 0.2285, validation loss: 0.1090
2024-05-22 16:23:20 [INFO]: Epoch 137 - training loss: 0.2281, validation loss: 0.1072
2024-05-22 16:23:21 [INFO]: Epoch 138 - training loss: 0.2266, validation loss: 0.1071
2024-05-22 16:23:21 [INFO]: Epoch 139 - training loss: 0.2255, validation loss: 0.1071
2024-05-22 16:23:22 [INFO]: Epoch 140 - training loss: 0.2267, validation loss: 0.1063
2024-05-22 16:23:23 [INFO]: Epoch 141 - training loss: 0.2265, validation loss: 0.1066
2024-05-22 16:23:23 [INFO]: Epoch 142 - training loss: 0.2250, validation loss: 0.1061
2024-05-22 16:23:24 [INFO]: Epoch 143 - training loss: 0.2248, validation loss: 0.1056
2024-05-22 16:23:24 [INFO]: Epoch 144 - training loss: 0.2241, validation loss: 0.1047
2024-05-22 16:23:25 [INFO]: Epoch 145 - training loss: 0.2246, validation loss: 0.1064
2024-05-22 16:23:26 [INFO]: Epoch 146 - training loss: 0.2238, validation loss: 0.1050
2024-05-22 16:23:26 [INFO]: Epoch 147 - training loss: 0.2254, validation loss: 0.1058
2024-05-22 16:23:27 [INFO]: Epoch 148 - training loss: 0.2225, validation loss: 0.1054
2024-05-22 16:23:28 [INFO]: Epoch 149 - training loss: 0.2230, validation loss: 0.1047
2024-05-22 16:23:28 [INFO]: Epoch 150 - training loss: 0.2242, validation loss: 0.1050
2024-05-22 16:23:29 [INFO]: Epoch 151 - training loss: 0.2229, validation loss: 0.1044
2024-05-22 16:23:29 [INFO]: Epoch 152 - training loss: 0.2220, validation loss: 0.1045
2024-05-22 16:23:30 [INFO]: Epoch 153 - training loss: 0.2208, validation loss: 0.1037
2024-05-22 16:23:31 [INFO]: Epoch 154 - training loss: 0.2207, validation loss: 0.1043
2024-05-22 16:23:31 [INFO]: Epoch 155 - training loss: 0.2223, validation loss: 0.1040
2024-05-22 16:23:32 [INFO]: Epoch 156 - training loss: 0.2197, validation loss: 0.1038
2024-05-22 16:23:33 [INFO]: Epoch 157 - training loss: 0.2198, validation loss: 0.1040
2024-05-22 16:23:33 [INFO]: Epoch 158 - training loss: 0.2198, validation loss: 0.1033
2024-05-22 16:23:34 [INFO]: Epoch 159 - training loss: 0.2191, validation loss: 0.1035
2024-05-22 16:23:34 [INFO]: Epoch 160 - training loss: 0.2207, validation loss: 0.1037
2024-05-22 16:23:35 [INFO]: Epoch 161 - training loss: 0.2190, validation loss: 0.1033
2024-05-22 16:23:36 [INFO]: Epoch 162 - training loss: 0.2204, validation loss: 0.1031
2024-05-22 16:23:36 [INFO]: Epoch 163 - training loss: 0.2190, validation loss: 0.1027
2024-05-22 16:23:37 [INFO]: Epoch 164 - training loss: 0.2172, validation loss: 0.1026
2024-05-22 16:23:38 [INFO]: Epoch 165 - training loss: 0.2181, validation loss: 0.1029
2024-05-22 16:23:38 [INFO]: Epoch 166 - training loss: 0.2183, validation loss: 0.1024
2024-05-22 16:23:39 [INFO]: Epoch 167 - training loss: 0.2169, validation loss: 0.1027
2024-05-22 16:23:39 [INFO]: Epoch 168 - training loss: 0.2170, validation loss: 0.1029
2024-05-22 16:23:40 [INFO]: Epoch 169 - training loss: 0.2182, validation loss: 0.1020
2024-05-22 16:23:41 [INFO]: Epoch 170 - training loss: 0.2174, validation loss: 0.1020
2024-05-22 16:23:41 [INFO]: Epoch 171 - training loss: 0.2173, validation loss: 0.1022
2024-05-22 16:23:42 [INFO]: Epoch 172 - training loss: 0.2197, validation loss: 0.1031
2024-05-22 16:23:43 [INFO]: Epoch 173 - training loss: 0.2152, validation loss: 0.1016
2024-05-22 16:23:43 [INFO]: Epoch 174 - training loss: 0.2143, validation loss: 0.1015
2024-05-22 16:23:44 [INFO]: Epoch 175 - training loss: 0.2149, validation loss: 0.1026
2024-05-22 16:23:45 [INFO]: Epoch 176 - training loss: 0.2145, validation loss: 0.1014
2024-05-22 16:23:45 [INFO]: Epoch 177 - training loss: 0.2140, validation loss: 0.1012
2024-05-22 16:23:46 [INFO]: Epoch 178 - training loss: 0.2156, validation loss: 0.1014
2024-05-22 16:23:46 [INFO]: Epoch 179 - training loss: 0.2135, validation loss: 0.1009
2024-05-22 16:23:47 [INFO]: Epoch 180 - training loss: 0.2143, validation loss: 0.1016
2024-05-22 16:23:48 [INFO]: Epoch 181 - training loss: 0.2137, validation loss: 0.1010
2024-05-22 16:23:48 [INFO]: Epoch 182 - training loss: 0.2173, validation loss: 0.1003
2024-05-22 16:23:49 [INFO]: Epoch 183 - training loss: 0.2131, validation loss: 0.1003
2024-05-22 16:23:49 [INFO]: Epoch 184 - training loss: 0.2122, validation loss: 0.1006
2024-05-22 16:23:50 [INFO]: Epoch 185 - training loss: 0.2117, validation loss: 0.1011
2024-05-22 16:23:51 [INFO]: Epoch 186 - training loss: 0.2124, validation loss: 0.1004
2024-05-22 16:23:51 [INFO]: Epoch 187 - training loss: 0.2114, validation loss: 0.0996
2024-05-22 16:23:52 [INFO]: Epoch 188 - training loss: 0.2109, validation loss: 0.1003
2024-05-22 16:23:53 [INFO]: Epoch 189 - training loss: 0.2110, validation loss: 0.0998
2024-05-22 16:23:53 [INFO]: Epoch 190 - training loss: 0.2116, validation loss: 0.1007
2024-05-22 16:23:54 [INFO]: Epoch 191 - training loss: 0.2104, validation loss: 0.0991
2024-05-22 16:23:54 [INFO]: Epoch 192 - training loss: 0.2101, validation loss: 0.0993
2024-05-22 16:23:55 [INFO]: Epoch 193 - training loss: 0.2092, validation loss: 0.0997
2024-05-22 16:23:56 [INFO]: Epoch 194 - training loss: 0.2093, validation loss: 0.1000
2024-05-22 16:23:56 [INFO]: Epoch 195 - training loss: 0.2107, validation loss: 0.1001
2024-05-22 16:23:57 [INFO]: Epoch 196 - training loss: 0.2097, validation loss: 0.1000
2024-05-22 16:23:58 [INFO]: Epoch 197 - training loss: 0.2094, validation loss: 0.0996
2024-05-22 16:23:58 [INFO]: Epoch 198 - training loss: 0.2079, validation loss: 0.0996
2024-05-22 16:23:59 [INFO]: Epoch 199 - training loss: 0.2083, validation loss: 0.0997
2024-05-22 16:23:59 [INFO]: Epoch 200 - training loss: 0.2079, validation loss: 0.0994
2024-05-22 16:24:00 [INFO]: Epoch 201 - training loss: 0.2081, validation loss: 0.0993
2024-05-22 16:24:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:24:00 [INFO]: Finished training. The best model is from epoch#191.
2024-05-22 16:24:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/SAITS_air_quality/20240522_T162145/SAITS.pypots
2024-05-22 16:24:00 [INFO]: SAITS on Air-Quality: MAE=0.1471, MSE=0.1070
2024-05-22 16:24:00 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/SAITS_air_quality/imputation.pkl
2024-05-22 16:24:00 [INFO]: Using the given device: cuda:0
2024-05-22 16:24:00 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/Transformer_air_quality/20240522_T162400
2024-05-22 16:24:00 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/Transformer_air_quality/20240522_T162400/tensorboard
2024-05-22 16:24:00 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-22 16:24:01 [INFO]: Epoch 001 - training loss: 0.9047, validation loss: 0.4473
2024-05-22 16:24:01 [INFO]: Epoch 002 - training loss: 0.5774, validation loss: 0.3251
2024-05-22 16:24:01 [INFO]: Epoch 003 - training loss: 0.4858, validation loss: 0.2690
2024-05-22 16:24:01 [INFO]: Epoch 004 - training loss: 0.4401, validation loss: 0.2407
2024-05-22 16:24:02 [INFO]: Epoch 005 - training loss: 0.4114, validation loss: 0.2294
2024-05-22 16:24:02 [INFO]: Epoch 006 - training loss: 0.3910, validation loss: 0.2165
2024-05-22 16:24:02 [INFO]: Epoch 007 - training loss: 0.3797, validation loss: 0.2093
2024-05-22 16:24:03 [INFO]: Epoch 008 - training loss: 0.3641, validation loss: 0.2067
2024-05-22 16:24:03 [INFO]: Epoch 009 - training loss: 0.3568, validation loss: 0.1981
2024-05-22 16:24:03 [INFO]: Epoch 010 - training loss: 0.3473, validation loss: 0.1945
2024-05-22 16:24:03 [INFO]: Epoch 011 - training loss: 0.3414, validation loss: 0.1909
2024-05-22 16:24:04 [INFO]: Epoch 012 - training loss: 0.3352, validation loss: 0.1865
2024-05-22 16:24:04 [INFO]: Epoch 013 - training loss: 0.3286, validation loss: 0.1833
2024-05-22 16:24:04 [INFO]: Epoch 014 - training loss: 0.3269, validation loss: 0.1801
2024-05-22 16:24:04 [INFO]: Epoch 015 - training loss: 0.3251, validation loss: 0.1760
2024-05-22 16:24:05 [INFO]: Epoch 016 - training loss: 0.3199, validation loss: 0.1730
2024-05-22 16:24:05 [INFO]: Epoch 017 - training loss: 0.3158, validation loss: 0.1705
2024-05-22 16:24:05 [INFO]: Epoch 018 - training loss: 0.3107, validation loss: 0.1675
2024-05-22 16:24:06 [INFO]: Epoch 019 - training loss: 0.3109, validation loss: 0.1663
2024-05-22 16:24:06 [INFO]: Epoch 020 - training loss: 0.3088, validation loss: 0.1640
2024-05-22 16:24:06 [INFO]: Epoch 021 - training loss: 0.3041, validation loss: 0.1638
2024-05-22 16:24:06 [INFO]: Epoch 022 - training loss: 0.3012, validation loss: 0.1624
2024-05-22 16:24:07 [INFO]: Epoch 023 - training loss: 0.2990, validation loss: 0.1600
2024-05-22 16:24:07 [INFO]: Epoch 024 - training loss: 0.2991, validation loss: 0.1593
2024-05-22 16:24:07 [INFO]: Epoch 025 - training loss: 0.2960, validation loss: 0.1570
2024-05-22 16:24:08 [INFO]: Epoch 026 - training loss: 0.2922, validation loss: 0.1577
2024-05-22 16:24:08 [INFO]: Epoch 027 - training loss: 0.2907, validation loss: 0.1566
2024-05-22 16:24:08 [INFO]: Epoch 028 - training loss: 0.2907, validation loss: 0.1559
2024-05-22 16:24:08 [INFO]: Epoch 029 - training loss: 0.2880, validation loss: 0.1548
2024-05-22 16:24:09 [INFO]: Epoch 030 - training loss: 0.2855, validation loss: 0.1548
2024-05-22 16:24:09 [INFO]: Epoch 031 - training loss: 0.2843, validation loss: 0.1539
2024-05-22 16:24:09 [INFO]: Epoch 032 - training loss: 0.2844, validation loss: 0.1525
2024-05-22 16:24:09 [INFO]: Epoch 033 - training loss: 0.2820, validation loss: 0.1527
2024-05-22 16:24:10 [INFO]: Epoch 034 - training loss: 0.2815, validation loss: 0.1532
2024-05-22 16:24:10 [INFO]: Epoch 035 - training loss: 0.2783, validation loss: 0.1520
2024-05-22 16:24:10 [INFO]: Epoch 036 - training loss: 0.2797, validation loss: 0.1506
2024-05-22 16:24:11 [INFO]: Epoch 037 - training loss: 0.2766, validation loss: 0.1519
2024-05-22 16:24:11 [INFO]: Epoch 038 - training loss: 0.2733, validation loss: 0.1488
2024-05-22 16:24:11 [INFO]: Epoch 039 - training loss: 0.2741, validation loss: 0.1497
2024-05-22 16:24:11 [INFO]: Epoch 040 - training loss: 0.2729, validation loss: 0.1489
2024-05-22 16:24:12 [INFO]: Epoch 041 - training loss: 0.2717, validation loss: 0.1485
2024-05-22 16:24:12 [INFO]: Epoch 042 - training loss: 0.2713, validation loss: 0.1480
2024-05-22 16:24:12 [INFO]: Epoch 043 - training loss: 0.2725, validation loss: 0.1486
2024-05-22 16:24:12 [INFO]: Epoch 044 - training loss: 0.2680, validation loss: 0.1467
2024-05-22 16:24:13 [INFO]: Epoch 045 - training loss: 0.2680, validation loss: 0.1465
2024-05-22 16:24:13 [INFO]: Epoch 046 - training loss: 0.2719, validation loss: 0.1471
2024-05-22 16:24:13 [INFO]: Epoch 047 - training loss: 0.2692, validation loss: 0.1468
2024-05-22 16:24:14 [INFO]: Epoch 048 - training loss: 0.2657, validation loss: 0.1467
2024-05-22 16:24:14 [INFO]: Epoch 049 - training loss: 0.2638, validation loss: 0.1453
2024-05-22 16:24:14 [INFO]: Epoch 050 - training loss: 0.2628, validation loss: 0.1453
2024-05-22 16:24:14 [INFO]: Epoch 051 - training loss: 0.2608, validation loss: 0.1446
2024-05-22 16:24:15 [INFO]: Epoch 052 - training loss: 0.2599, validation loss: 0.1430
2024-05-22 16:24:15 [INFO]: Epoch 053 - training loss: 0.2589, validation loss: 0.1457
2024-05-22 16:24:15 [INFO]: Epoch 054 - training loss: 0.2609, validation loss: 0.1451
2024-05-22 16:24:16 [INFO]: Epoch 055 - training loss: 0.2614, validation loss: 0.1462
2024-05-22 16:24:16 [INFO]: Epoch 056 - training loss: 0.2592, validation loss: 0.1429
2024-05-22 16:24:16 [INFO]: Epoch 057 - training loss: 0.2564, validation loss: 0.1433
2024-05-22 16:24:16 [INFO]: Epoch 058 - training loss: 0.2569, validation loss: 0.1437
2024-05-22 16:24:17 [INFO]: Epoch 059 - training loss: 0.2561, validation loss: 0.1426
2024-05-22 16:24:17 [INFO]: Epoch 060 - training loss: 0.2534, validation loss: 0.1418
2024-05-22 16:24:17 [INFO]: Epoch 061 - training loss: 0.2555, validation loss: 0.1439
2024-05-22 16:24:17 [INFO]: Epoch 062 - training loss: 0.2551, validation loss: 0.1441
2024-05-22 16:24:18 [INFO]: Epoch 063 - training loss: 0.2580, validation loss: 0.1425
2024-05-22 16:24:18 [INFO]: Epoch 064 - training loss: 0.2538, validation loss: 0.1403
2024-05-22 16:24:18 [INFO]: Epoch 065 - training loss: 0.2507, validation loss: 0.1386
2024-05-22 16:24:19 [INFO]: Epoch 066 - training loss: 0.2507, validation loss: 0.1409
2024-05-22 16:24:19 [INFO]: Epoch 067 - training loss: 0.2489, validation loss: 0.1398
2024-05-22 16:24:19 [INFO]: Epoch 068 - training loss: 0.2488, validation loss: 0.1424
2024-05-22 16:24:19 [INFO]: Epoch 069 - training loss: 0.2519, validation loss: 0.1407
2024-05-22 16:24:20 [INFO]: Epoch 070 - training loss: 0.2509, validation loss: 0.1430
2024-05-22 16:24:20 [INFO]: Epoch 071 - training loss: 0.2479, validation loss: 0.1370
2024-05-22 16:24:20 [INFO]: Epoch 072 - training loss: 0.2467, validation loss: 0.1382
2024-05-22 16:24:20 [INFO]: Epoch 073 - training loss: 0.2446, validation loss: 0.1366
2024-05-22 16:24:21 [INFO]: Epoch 074 - training loss: 0.2437, validation loss: 0.1385
2024-05-22 16:24:21 [INFO]: Epoch 075 - training loss: 0.2461, validation loss: 0.1381
2024-05-22 16:24:21 [INFO]: Epoch 076 - training loss: 0.2432, validation loss: 0.1364
2024-05-22 16:24:22 [INFO]: Epoch 077 - training loss: 0.2413, validation loss: 0.1378
2024-05-22 16:24:22 [INFO]: Epoch 078 - training loss: 0.2423, validation loss: 0.1391
2024-05-22 16:24:22 [INFO]: Epoch 079 - training loss: 0.2429, validation loss: 0.1365
2024-05-22 16:24:22 [INFO]: Epoch 080 - training loss: 0.2437, validation loss: 0.1391
2024-05-22 16:24:23 [INFO]: Epoch 081 - training loss: 0.2422, validation loss: 0.1362
2024-05-22 16:24:23 [INFO]: Epoch 082 - training loss: 0.2408, validation loss: 0.1367
2024-05-22 16:24:23 [INFO]: Epoch 083 - training loss: 0.2394, validation loss: 0.1343
2024-05-22 16:24:24 [INFO]: Epoch 084 - training loss: 0.2407, validation loss: 0.1352
2024-05-22 16:24:24 [INFO]: Epoch 085 - training loss: 0.2403, validation loss: 0.1352
2024-05-22 16:24:24 [INFO]: Epoch 086 - training loss: 0.2390, validation loss: 0.1357
2024-05-22 16:24:24 [INFO]: Epoch 087 - training loss: 0.2364, validation loss: 0.1341
2024-05-22 16:24:25 [INFO]: Epoch 088 - training loss: 0.2357, validation loss: 0.1342
2024-05-22 16:24:25 [INFO]: Epoch 089 - training loss: 0.2382, validation loss: 0.1356
2024-05-22 16:24:25 [INFO]: Epoch 090 - training loss: 0.2355, validation loss: 0.1338
2024-05-22 16:24:25 [INFO]: Epoch 091 - training loss: 0.2326, validation loss: 0.1329
2024-05-22 16:24:26 [INFO]: Epoch 092 - training loss: 0.2320, validation loss: 0.1332
2024-05-22 16:24:26 [INFO]: Epoch 093 - training loss: 0.2316, validation loss: 0.1326
2024-05-22 16:24:26 [INFO]: Epoch 094 - training loss: 0.2334, validation loss: 0.1335
2024-05-22 16:24:27 [INFO]: Epoch 095 - training loss: 0.2337, validation loss: 0.1336
2024-05-22 16:24:27 [INFO]: Epoch 096 - training loss: 0.2326, validation loss: 0.1324
2024-05-22 16:24:27 [INFO]: Epoch 097 - training loss: 0.2329, validation loss: 0.1317
2024-05-22 16:24:27 [INFO]: Epoch 098 - training loss: 0.2323, validation loss: 0.1324
2024-05-22 16:24:28 [INFO]: Epoch 099 - training loss: 0.2311, validation loss: 0.1324
2024-05-22 16:24:28 [INFO]: Epoch 100 - training loss: 0.2293, validation loss: 0.1298
2024-05-22 16:24:28 [INFO]: Epoch 101 - training loss: 0.2272, validation loss: 0.1332
2024-05-22 16:24:28 [INFO]: Epoch 102 - training loss: 0.2305, validation loss: 0.1328
2024-05-22 16:24:29 [INFO]: Epoch 103 - training loss: 0.2301, validation loss: 0.1315
2024-05-22 16:24:29 [INFO]: Epoch 104 - training loss: 0.2294, validation loss: 0.1298
2024-05-22 16:24:29 [INFO]: Epoch 105 - training loss: 0.2298, validation loss: 0.1303
2024-05-22 16:24:30 [INFO]: Epoch 106 - training loss: 0.2263, validation loss: 0.1313
2024-05-22 16:24:30 [INFO]: Epoch 107 - training loss: 0.2256, validation loss: 0.1319
2024-05-22 16:24:30 [INFO]: Epoch 108 - training loss: 0.2258, validation loss: 0.1311
2024-05-22 16:24:30 [INFO]: Epoch 109 - training loss: 0.2253, validation loss: 0.1299
2024-05-22 16:24:31 [INFO]: Epoch 110 - training loss: 0.2238, validation loss: 0.1289
2024-05-22 16:24:31 [INFO]: Epoch 111 - training loss: 0.2248, validation loss: 0.1289
2024-05-22 16:24:31 [INFO]: Epoch 112 - training loss: 0.2244, validation loss: 0.1288
2024-05-22 16:24:31 [INFO]: Epoch 113 - training loss: 0.2234, validation loss: 0.1285
2024-05-22 16:24:32 [INFO]: Epoch 114 - training loss: 0.2238, validation loss: 0.1294
2024-05-22 16:24:32 [INFO]: Epoch 115 - training loss: 0.2221, validation loss: 0.1289
2024-05-22 16:24:32 [INFO]: Epoch 116 - training loss: 0.2245, validation loss: 0.1288
2024-05-22 16:24:33 [INFO]: Epoch 117 - training loss: 0.2208, validation loss: 0.1290
2024-05-22 16:24:33 [INFO]: Epoch 118 - training loss: 0.2197, validation loss: 0.1277
2024-05-22 16:24:33 [INFO]: Epoch 119 - training loss: 0.2213, validation loss: 0.1285
2024-05-22 16:24:33 [INFO]: Epoch 120 - training loss: 0.2242, validation loss: 0.1291
2024-05-22 16:24:34 [INFO]: Epoch 121 - training loss: 0.2195, validation loss: 0.1268
2024-05-22 16:24:34 [INFO]: Epoch 122 - training loss: 0.2199, validation loss: 0.1303
2024-05-22 16:24:34 [INFO]: Epoch 123 - training loss: 0.2176, validation loss: 0.1272
2024-05-22 16:24:35 [INFO]: Epoch 124 - training loss: 0.2181, validation loss: 0.1274
2024-05-22 16:24:35 [INFO]: Epoch 125 - training loss: 0.2194, validation loss: 0.1272
2024-05-22 16:24:35 [INFO]: Epoch 126 - training loss: 0.2176, validation loss: 0.1273
2024-05-22 16:24:35 [INFO]: Epoch 127 - training loss: 0.2181, validation loss: 0.1254
2024-05-22 16:24:36 [INFO]: Epoch 128 - training loss: 0.2161, validation loss: 0.1262
2024-05-22 16:24:36 [INFO]: Epoch 129 - training loss: 0.2176, validation loss: 0.1265
2024-05-22 16:24:36 [INFO]: Epoch 130 - training loss: 0.2165, validation loss: 0.1260
2024-05-22 16:24:36 [INFO]: Epoch 131 - training loss: 0.2160, validation loss: 0.1265
2024-05-22 16:24:37 [INFO]: Epoch 132 - training loss: 0.2169, validation loss: 0.1261
2024-05-22 16:24:37 [INFO]: Epoch 133 - training loss: 0.2160, validation loss: 0.1250
2024-05-22 16:24:37 [INFO]: Epoch 134 - training loss: 0.2170, validation loss: 0.1264
2024-05-22 16:24:38 [INFO]: Epoch 135 - training loss: 0.2158, validation loss: 0.1242
2024-05-22 16:24:38 [INFO]: Epoch 136 - training loss: 0.2148, validation loss: 0.1260
2024-05-22 16:24:38 [INFO]: Epoch 137 - training loss: 0.2136, validation loss: 0.1242
2024-05-22 16:24:38 [INFO]: Epoch 138 - training loss: 0.2130, validation loss: 0.1241
2024-05-22 16:24:39 [INFO]: Epoch 139 - training loss: 0.2109, validation loss: 0.1243
2024-05-22 16:24:39 [INFO]: Epoch 140 - training loss: 0.2111, validation loss: 0.1246
2024-05-22 16:24:39 [INFO]: Epoch 141 - training loss: 0.2114, validation loss: 0.1241
2024-05-22 16:24:39 [INFO]: Epoch 142 - training loss: 0.2125, validation loss: 0.1235
2024-05-22 16:24:40 [INFO]: Epoch 143 - training loss: 0.2133, validation loss: 0.1242
2024-05-22 16:24:40 [INFO]: Epoch 144 - training loss: 0.2118, validation loss: 0.1242
2024-05-22 16:24:40 [INFO]: Epoch 145 - training loss: 0.2117, validation loss: 0.1227
2024-05-22 16:24:41 [INFO]: Epoch 146 - training loss: 0.2102, validation loss: 0.1230
2024-05-22 16:24:41 [INFO]: Epoch 147 - training loss: 0.2104, validation loss: 0.1228
2024-05-22 16:24:41 [INFO]: Epoch 148 - training loss: 0.2122, validation loss: 0.1237
2024-05-22 16:24:41 [INFO]: Epoch 149 - training loss: 0.2109, validation loss: 0.1223
2024-05-22 16:24:42 [INFO]: Epoch 150 - training loss: 0.2115, validation loss: 0.1222
2024-05-22 16:24:42 [INFO]: Epoch 151 - training loss: 0.2114, validation loss: 0.1222
2024-05-22 16:24:42 [INFO]: Epoch 152 - training loss: 0.2094, validation loss: 0.1247
2024-05-22 16:24:42 [INFO]: Epoch 153 - training loss: 0.2090, validation loss: 0.1222
2024-05-22 16:24:43 [INFO]: Epoch 154 - training loss: 0.2081, validation loss: 0.1224
2024-05-22 16:24:43 [INFO]: Epoch 155 - training loss: 0.2084, validation loss: 0.1221
2024-05-22 16:24:43 [INFO]: Epoch 156 - training loss: 0.2086, validation loss: 0.1210
2024-05-22 16:24:44 [INFO]: Epoch 157 - training loss: 0.2110, validation loss: 0.1250
2024-05-22 16:24:44 [INFO]: Epoch 158 - training loss: 0.2085, validation loss: 0.1208
2024-05-22 16:24:44 [INFO]: Epoch 159 - training loss: 0.2070, validation loss: 0.1207
2024-05-22 16:24:44 [INFO]: Epoch 160 - training loss: 0.2068, validation loss: 0.1211
2024-05-22 16:24:45 [INFO]: Epoch 161 - training loss: 0.2056, validation loss: 0.1203
2024-05-22 16:24:45 [INFO]: Epoch 162 - training loss: 0.2053, validation loss: 0.1220
2024-05-22 16:24:45 [INFO]: Epoch 163 - training loss: 0.2074, validation loss: 0.1216
2024-05-22 16:24:46 [INFO]: Epoch 164 - training loss: 0.2080, validation loss: 0.1227
2024-05-22 16:24:46 [INFO]: Epoch 165 - training loss: 0.2070, validation loss: 0.1192
2024-05-22 16:24:46 [INFO]: Epoch 166 - training loss: 0.2080, validation loss: 0.1216
2024-05-22 16:24:46 [INFO]: Epoch 167 - training loss: 0.2090, validation loss: 0.1197
2024-05-22 16:24:47 [INFO]: Epoch 168 - training loss: 0.2065, validation loss: 0.1193
2024-05-22 16:24:47 [INFO]: Epoch 169 - training loss: 0.2063, validation loss: 0.1208
2024-05-22 16:24:47 [INFO]: Epoch 170 - training loss: 0.2058, validation loss: 0.1207
2024-05-22 16:24:47 [INFO]: Epoch 171 - training loss: 0.2053, validation loss: 0.1192
2024-05-22 16:24:48 [INFO]: Epoch 172 - training loss: 0.2054, validation loss: 0.1194
2024-05-22 16:24:48 [INFO]: Epoch 173 - training loss: 0.2077, validation loss: 0.1187
2024-05-22 16:24:48 [INFO]: Epoch 174 - training loss: 0.2067, validation loss: 0.1199
2024-05-22 16:24:49 [INFO]: Epoch 175 - training loss: 0.2050, validation loss: 0.1206
2024-05-22 16:24:49 [INFO]: Epoch 176 - training loss: 0.2035, validation loss: 0.1191
2024-05-22 16:24:49 [INFO]: Epoch 177 - training loss: 0.2018, validation loss: 0.1185
2024-05-22 16:24:49 [INFO]: Epoch 178 - training loss: 0.2018, validation loss: 0.1204
2024-05-22 16:24:50 [INFO]: Epoch 179 - training loss: 0.2022, validation loss: 0.1183
2024-05-22 16:24:50 [INFO]: Epoch 180 - training loss: 0.2025, validation loss: 0.1182
2024-05-22 16:24:50 [INFO]: Epoch 181 - training loss: 0.2009, validation loss: 0.1190
2024-05-22 16:24:50 [INFO]: Epoch 182 - training loss: 0.1994, validation loss: 0.1174
2024-05-22 16:24:51 [INFO]: Epoch 183 - training loss: 0.1999, validation loss: 0.1182
2024-05-22 16:24:51 [INFO]: Epoch 184 - training loss: 0.1995, validation loss: 0.1188
2024-05-22 16:24:51 [INFO]: Epoch 185 - training loss: 0.1982, validation loss: 0.1173
2024-05-22 16:24:52 [INFO]: Epoch 186 - training loss: 0.1985, validation loss: 0.1195
2024-05-22 16:24:52 [INFO]: Epoch 187 - training loss: 0.2002, validation loss: 0.1199
2024-05-22 16:24:52 [INFO]: Epoch 188 - training loss: 0.1987, validation loss: 0.1167
2024-05-22 16:24:52 [INFO]: Epoch 189 - training loss: 0.1977, validation loss: 0.1183
2024-05-22 16:24:53 [INFO]: Epoch 190 - training loss: 0.1978, validation loss: 0.1168
2024-05-22 16:24:53 [INFO]: Epoch 191 - training loss: 0.1989, validation loss: 0.1175
2024-05-22 16:24:53 [INFO]: Epoch 192 - training loss: 0.2006, validation loss: 0.1170
2024-05-22 16:24:53 [INFO]: Epoch 193 - training loss: 0.1984, validation loss: 0.1162
2024-05-22 16:24:54 [INFO]: Epoch 194 - training loss: 0.1966, validation loss: 0.1172
2024-05-22 16:24:54 [INFO]: Epoch 195 - training loss: 0.1957, validation loss: 0.1157
2024-05-22 16:24:54 [INFO]: Epoch 196 - training loss: 0.1980, validation loss: 0.1164
2024-05-22 16:24:55 [INFO]: Epoch 197 - training loss: 0.1960, validation loss: 0.1165
2024-05-22 16:24:55 [INFO]: Epoch 198 - training loss: 0.1987, validation loss: 0.1156
2024-05-22 16:24:55 [INFO]: Epoch 199 - training loss: 0.1987, validation loss: 0.1162
2024-05-22 16:24:55 [INFO]: Epoch 200 - training loss: 0.1953, validation loss: 0.1178
2024-05-22 16:24:56 [INFO]: Epoch 201 - training loss: 0.1969, validation loss: 0.1163
2024-05-22 16:24:56 [INFO]: Epoch 202 - training loss: 0.1966, validation loss: 0.1176
2024-05-22 16:24:56 [INFO]: Epoch 203 - training loss: 0.1959, validation loss: 0.1164
2024-05-22 16:24:57 [INFO]: Epoch 204 - training loss: 0.1947, validation loss: 0.1163
2024-05-22 16:24:57 [INFO]: Epoch 205 - training loss: 0.1955, validation loss: 0.1176
2024-05-22 16:24:57 [INFO]: Epoch 206 - training loss: 0.1952, validation loss: 0.1153
2024-05-22 16:24:57 [INFO]: Epoch 207 - training loss: 0.1938, validation loss: 0.1156
2024-05-22 16:24:58 [INFO]: Epoch 208 - training loss: 0.1955, validation loss: 0.1151
2024-05-22 16:24:58 [INFO]: Epoch 209 - training loss: 0.1959, validation loss: 0.1147
2024-05-22 16:24:58 [INFO]: Epoch 210 - training loss: 0.1957, validation loss: 0.1159
2024-05-22 16:24:58 [INFO]: Epoch 211 - training loss: 0.1945, validation loss: 0.1172
2024-05-22 16:24:59 [INFO]: Epoch 212 - training loss: 0.1941, validation loss: 0.1152
2024-05-22 16:24:59 [INFO]: Epoch 213 - training loss: 0.1935, validation loss: 0.1147
2024-05-22 16:24:59 [INFO]: Epoch 214 - training loss: 0.1926, validation loss: 0.1145
2024-05-22 16:25:00 [INFO]: Epoch 215 - training loss: 0.1915, validation loss: 0.1144
2024-05-22 16:25:00 [INFO]: Epoch 216 - training loss: 0.1919, validation loss: 0.1132
2024-05-22 16:25:00 [INFO]: Epoch 217 - training loss: 0.1938, validation loss: 0.1174
2024-05-22 16:25:00 [INFO]: Epoch 218 - training loss: 0.1964, validation loss: 0.1150
2024-05-22 16:25:01 [INFO]: Epoch 219 - training loss: 0.1928, validation loss: 0.1141
2024-05-22 16:25:01 [INFO]: Epoch 220 - training loss: 0.1913, validation loss: 0.1148
2024-05-22 16:25:01 [INFO]: Epoch 221 - training loss: 0.1893, validation loss: 0.1131
2024-05-22 16:25:01 [INFO]: Epoch 222 - training loss: 0.1955, validation loss: 0.1137
2024-05-22 16:25:02 [INFO]: Epoch 223 - training loss: 0.1967, validation loss: 0.1145
2024-05-22 16:25:02 [INFO]: Epoch 224 - training loss: 0.1929, validation loss: 0.1143
2024-05-22 16:25:02 [INFO]: Epoch 225 - training loss: 0.1897, validation loss: 0.1144
2024-05-22 16:25:03 [INFO]: Epoch 226 - training loss: 0.1930, validation loss: 0.1134
2024-05-22 16:25:03 [INFO]: Epoch 227 - training loss: 0.1910, validation loss: 0.1146
2024-05-22 16:25:03 [INFO]: Epoch 228 - training loss: 0.1893, validation loss: 0.1140
2024-05-22 16:25:03 [INFO]: Epoch 229 - training loss: 0.1899, validation loss: 0.1158
2024-05-22 16:25:04 [INFO]: Epoch 230 - training loss: 0.1911, validation loss: 0.1136
2024-05-22 16:25:04 [INFO]: Epoch 231 - training loss: 0.1893, validation loss: 0.1131
2024-05-22 16:25:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:25:04 [INFO]: Finished training. The best model is from epoch#221.
2024-05-22 16:25:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/Transformer_air_quality/20240522_T162400/Transformer.pypots
2024-05-22 16:25:04 [INFO]: Transformer on Air-Quality: MAE=0.1577, MSE=0.1193
2024-05-22 16:25:04 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/Transformer_air_quality/imputation.pkl
2024-05-22 16:25:04 [INFO]: Using the given device: cuda:0
2024-05-22 16:25:04 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/TimesNet_air_quality/20240522_T162504
2024-05-22 16:25:04 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/TimesNet_air_quality/20240522_T162504/tensorboard
2024-05-22 16:25:05 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-22 16:25:06 [INFO]: Epoch 001 - training loss: 0.2758, validation loss: 0.2355
2024-05-22 16:25:07 [INFO]: Epoch 002 - training loss: 0.2137, validation loss: 0.2038
2024-05-22 16:25:07 [INFO]: Epoch 003 - training loss: 0.1788, validation loss: 0.2069
2024-05-22 16:25:08 [INFO]: Epoch 004 - training loss: 0.1658, validation loss: 0.2032
2024-05-22 16:25:08 [INFO]: Epoch 005 - training loss: 0.1707, validation loss: 0.1797
2024-05-22 16:25:09 [INFO]: Epoch 006 - training loss: 0.1738, validation loss: 0.1779
2024-05-22 16:25:09 [INFO]: Epoch 007 - training loss: 0.1965, validation loss: 0.1629
2024-05-22 16:25:10 [INFO]: Epoch 008 - training loss: 0.1504, validation loss: 0.1681
2024-05-22 16:25:10 [INFO]: Epoch 009 - training loss: 0.1463, validation loss: 0.1628
2024-05-22 16:25:10 [INFO]: Epoch 010 - training loss: 0.1321, validation loss: 0.1628
2024-05-22 16:25:11 [INFO]: Epoch 011 - training loss: 0.1337, validation loss: 0.1602
2024-05-22 16:25:11 [INFO]: Epoch 012 - training loss: 0.1525, validation loss: 0.1553
2024-05-22 16:25:12 [INFO]: Epoch 013 - training loss: 0.1572, validation loss: 0.1525
2024-05-22 16:25:12 [INFO]: Epoch 014 - training loss: 0.1273, validation loss: 0.1519
2024-05-22 16:25:13 [INFO]: Epoch 015 - training loss: 0.1283, validation loss: 0.1554
2024-05-22 16:25:13 [INFO]: Epoch 016 - training loss: 0.1512, validation loss: 0.1520
2024-05-22 16:25:14 [INFO]: Epoch 017 - training loss: 0.1231, validation loss: 0.1552
2024-05-22 16:25:14 [INFO]: Epoch 018 - training loss: 0.1343, validation loss: 0.1516
2024-05-22 16:25:15 [INFO]: Epoch 019 - training loss: 0.1325, validation loss: 0.1464
2024-05-22 16:25:15 [INFO]: Epoch 020 - training loss: 0.1281, validation loss: 0.1474
2024-05-22 16:25:16 [INFO]: Epoch 021 - training loss: 0.1138, validation loss: 0.1421
2024-05-22 16:25:16 [INFO]: Epoch 022 - training loss: 0.1172, validation loss: 0.1487
2024-05-22 16:25:17 [INFO]: Epoch 023 - training loss: 0.1132, validation loss: 0.1441
2024-05-22 16:25:17 [INFO]: Epoch 024 - training loss: 0.1087, validation loss: 0.1446
2024-05-22 16:25:18 [INFO]: Epoch 025 - training loss: 0.1246, validation loss: 0.1444
2024-05-22 16:25:18 [INFO]: Epoch 026 - training loss: 0.1381, validation loss: 0.1446
2024-05-22 16:25:19 [INFO]: Epoch 027 - training loss: 0.1087, validation loss: 0.1457
2024-05-22 16:25:19 [INFO]: Epoch 028 - training loss: 0.1237, validation loss: 0.1483
2024-05-22 16:25:20 [INFO]: Epoch 029 - training loss: 0.1187, validation loss: 0.1443
2024-05-22 16:25:20 [INFO]: Epoch 030 - training loss: 0.1241, validation loss: 0.1396
2024-05-22 16:25:21 [INFO]: Epoch 031 - training loss: 0.1313, validation loss: 0.1606
2024-05-22 16:25:21 [INFO]: Epoch 032 - training loss: 0.1266, validation loss: 0.1415
2024-05-22 16:25:22 [INFO]: Epoch 033 - training loss: 0.1093, validation loss: 0.1404
2024-05-22 16:25:22 [INFO]: Epoch 034 - training loss: 0.1113, validation loss: 0.1388
2024-05-22 16:25:23 [INFO]: Epoch 035 - training loss: 0.1117, validation loss: 0.1418
2024-05-22 16:25:23 [INFO]: Epoch 036 - training loss: 0.1178, validation loss: 0.1418
2024-05-22 16:25:23 [INFO]: Epoch 037 - training loss: 0.1299, validation loss: 0.1403
2024-05-22 16:25:24 [INFO]: Epoch 038 - training loss: 0.1290, validation loss: 0.1375
2024-05-22 16:25:24 [INFO]: Epoch 039 - training loss: 0.1228, validation loss: 0.1384
2024-05-22 16:25:25 [INFO]: Epoch 040 - training loss: 0.1119, validation loss: 0.1386
2024-05-22 16:25:25 [INFO]: Epoch 041 - training loss: 0.1106, validation loss: 0.1373
2024-05-22 16:25:26 [INFO]: Epoch 042 - training loss: 0.1211, validation loss: 0.1355
2024-05-22 16:25:26 [INFO]: Epoch 043 - training loss: 0.1044, validation loss: 0.1374
2024-05-22 16:25:27 [INFO]: Epoch 044 - training loss: 0.0950, validation loss: 0.1345
2024-05-22 16:25:27 [INFO]: Epoch 045 - training loss: 0.1119, validation loss: 0.1367
2024-05-22 16:25:28 [INFO]: Epoch 046 - training loss: 0.1125, validation loss: 0.1359
2024-05-22 16:25:28 [INFO]: Epoch 047 - training loss: 0.1143, validation loss: 0.1402
2024-05-22 16:25:29 [INFO]: Epoch 048 - training loss: 0.1132, validation loss: 0.1379
2024-05-22 16:25:29 [INFO]: Epoch 049 - training loss: 0.1145, validation loss: 0.1392
2024-05-22 16:25:30 [INFO]: Epoch 050 - training loss: 0.0934, validation loss: 0.1356
2024-05-22 16:25:30 [INFO]: Epoch 051 - training loss: 0.1025, validation loss: 0.1432
2024-05-22 16:25:31 [INFO]: Epoch 052 - training loss: 0.1005, validation loss: 0.1365
2024-05-22 16:25:31 [INFO]: Epoch 053 - training loss: 0.0928, validation loss: 0.1404
2024-05-22 16:25:31 [INFO]: Epoch 054 - training loss: 0.1061, validation loss: 0.1384
2024-05-22 16:25:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:25:31 [INFO]: Finished training. The best model is from epoch#44.
2024-05-22 16:25:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/TimesNet_air_quality/20240522_T162504/TimesNet.pypots
2024-05-22 16:25:32 [INFO]: TimesNet on Air-Quality: MAE=0.1579, MSE=0.1501
2024-05-22 16:25:32 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/TimesNet_air_quality/imputation.pkl
2024-05-22 16:25:32 [INFO]: Using the given device: cuda:0
2024-05-22 16:25:32 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532
2024-05-22 16:25:32 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/tensorboard
2024-05-22 16:25:32 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-22 16:25:49 [INFO]: Epoch 001 - training loss: 0.4971, validation loss: 0.3514
2024-05-22 16:25:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch1_loss0.35139602720737456.pypots
2024-05-22 16:26:05 [INFO]: Epoch 002 - training loss: 0.3127, validation loss: 0.2857
2024-05-22 16:26:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch2_loss0.28569660186767576.pypots
2024-05-22 16:26:22 [INFO]: Epoch 003 - training loss: 0.2640, validation loss: 0.2512
2024-05-22 16:26:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch3_loss0.2512337237596512.pypots
2024-05-22 16:26:38 [INFO]: Epoch 004 - training loss: 0.2348, validation loss: 0.2228
2024-05-22 16:26:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch4_loss0.22278607040643691.pypots
2024-05-22 16:26:55 [INFO]: Epoch 005 - training loss: 0.2268, validation loss: 0.1999
2024-05-22 16:26:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch5_loss0.1998601108789444.pypots
2024-05-22 16:27:11 [INFO]: Epoch 006 - training loss: 0.1942, validation loss: 0.1864
2024-05-22 16:27:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch6_loss0.18637316375970842.pypots
2024-05-22 16:27:27 [INFO]: Epoch 007 - training loss: 0.1808, validation loss: 0.1758
2024-05-22 16:27:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch7_loss0.1758088782429695.pypots
2024-05-22 16:27:44 [INFO]: Epoch 008 - training loss: 0.2088, validation loss: 0.1687
2024-05-22 16:27:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch8_loss0.16872245967388153.pypots
2024-05-22 16:28:00 [INFO]: Epoch 009 - training loss: 0.1857, validation loss: 0.1658
2024-05-22 16:28:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch9_loss0.16577652096748352.pypots
2024-05-22 16:28:17 [INFO]: Epoch 010 - training loss: 0.1844, validation loss: 0.1605
2024-05-22 16:28:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch10_loss0.16048089563846588.pypots
2024-05-22 16:28:33 [INFO]: Epoch 011 - training loss: 0.1853, validation loss: 0.1531
2024-05-22 16:28:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch11_loss0.15314017236232758.pypots
2024-05-22 16:28:50 [INFO]: Epoch 012 - training loss: 0.1717, validation loss: 0.1522
2024-05-22 16:28:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch12_loss0.15218748897314072.pypots
2024-05-22 16:29:06 [INFO]: Epoch 013 - training loss: 0.1815, validation loss: 0.1523
2024-05-22 16:29:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch13_loss0.15230202078819274.pypots
2024-05-22 16:29:23 [INFO]: Epoch 014 - training loss: 0.1910, validation loss: 0.1474
2024-05-22 16:29:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch14_loss0.14738177955150605.pypots
2024-05-22 16:29:39 [INFO]: Epoch 015 - training loss: 0.1625, validation loss: 0.1473
2024-05-22 16:29:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch15_loss0.1473422795534134.pypots
2024-05-22 16:29:56 [INFO]: Epoch 016 - training loss: 0.1681, validation loss: 0.1458
2024-05-22 16:29:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch16_loss0.14580555856227875.pypots
2024-05-22 16:30:12 [INFO]: Epoch 017 - training loss: 0.1794, validation loss: 0.1439
2024-05-22 16:30:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch17_loss0.143929123878479.pypots
2024-05-22 16:30:29 [INFO]: Epoch 018 - training loss: 0.1534, validation loss: 0.1449
2024-05-22 16:30:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch18_loss0.14493642300367354.pypots
2024-05-22 16:30:45 [INFO]: Epoch 019 - training loss: 0.1796, validation loss: 0.1389
2024-05-22 16:30:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch19_loss0.13890360295772552.pypots
2024-05-22 16:31:02 [INFO]: Epoch 020 - training loss: 0.1705, validation loss: 0.1356
2024-05-22 16:31:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch20_loss0.13562777563929557.pypots
2024-05-22 16:31:18 [INFO]: Epoch 021 - training loss: 0.1644, validation loss: 0.1352
2024-05-22 16:31:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch21_loss0.13518362864851952.pypots
2024-05-22 16:31:34 [INFO]: Epoch 022 - training loss: 0.1541, validation loss: 0.1376
2024-05-22 16:31:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch22_loss0.13761652559041976.pypots
2024-05-22 16:31:51 [INFO]: Epoch 023 - training loss: 0.1613, validation loss: 0.1354
2024-05-22 16:31:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch23_loss0.1353936366736889.pypots
2024-05-22 16:32:07 [INFO]: Epoch 024 - training loss: 0.1655, validation loss: 0.1388
2024-05-22 16:32:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch24_loss0.13879090845584868.pypots
2024-05-22 16:32:24 [INFO]: Epoch 025 - training loss: 0.1665, validation loss: 0.1341
2024-05-22 16:32:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch25_loss0.13411130979657174.pypots
2024-05-22 16:32:40 [INFO]: Epoch 026 - training loss: 0.1371, validation loss: 0.1284
2024-05-22 16:32:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch26_loss0.12844961807131766.pypots
2024-05-22 16:32:57 [INFO]: Epoch 027 - training loss: 0.1373, validation loss: 0.1296
2024-05-22 16:32:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch27_loss0.12956611663103104.pypots
2024-05-22 16:33:13 [INFO]: Epoch 028 - training loss: 0.1503, validation loss: 0.1303
2024-05-22 16:33:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch28_loss0.13032766953110694.pypots
2024-05-22 16:33:30 [INFO]: Epoch 029 - training loss: 0.1419, validation loss: 0.1276
2024-05-22 16:33:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch29_loss0.1276300773024559.pypots
2024-05-22 16:33:46 [INFO]: Epoch 030 - training loss: 0.1344, validation loss: 0.1295
2024-05-22 16:33:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch30_loss0.12952782958745956.pypots
2024-05-22 16:34:03 [INFO]: Epoch 031 - training loss: 0.1478, validation loss: 0.1265
2024-05-22 16:34:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch31_loss0.12651990428566934.pypots
2024-05-22 16:34:19 [INFO]: Epoch 032 - training loss: 0.1416, validation loss: 0.1275
2024-05-22 16:34:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch32_loss0.12751853242516517.pypots
2024-05-22 16:34:35 [INFO]: Epoch 033 - training loss: 0.1442, validation loss: 0.1278
2024-05-22 16:34:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch33_loss0.12775740996003151.pypots
2024-05-22 16:34:52 [INFO]: Epoch 034 - training loss: 0.1338, validation loss: 0.1255
2024-05-22 16:34:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch34_loss0.12547945976257324.pypots
2024-05-22 16:35:08 [INFO]: Epoch 035 - training loss: 0.1418, validation loss: 0.1300
2024-05-22 16:35:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch35_loss0.12997982501983643.pypots
2024-05-22 16:35:25 [INFO]: Epoch 036 - training loss: 0.1309, validation loss: 0.1252
2024-05-22 16:35:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch36_loss0.1251875251531601.pypots
2024-05-22 16:35:41 [INFO]: Epoch 037 - training loss: 0.1397, validation loss: 0.1237
2024-05-22 16:35:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch37_loss0.12369528785347939.pypots
2024-05-22 16:35:58 [INFO]: Epoch 038 - training loss: 0.1411, validation loss: 0.1229
2024-05-22 16:35:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch38_loss0.12293512523174285.pypots
2024-05-22 16:36:14 [INFO]: Epoch 039 - training loss: 0.1322, validation loss: 0.1220
2024-05-22 16:36:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch39_loss0.12202899903059006.pypots
2024-05-22 16:36:31 [INFO]: Epoch 040 - training loss: 0.1346, validation loss: 0.1211
2024-05-22 16:36:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch40_loss0.12108650133013725.pypots
2024-05-22 16:36:47 [INFO]: Epoch 041 - training loss: 0.1362, validation loss: 0.1210
2024-05-22 16:36:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch41_loss0.1210431694984436.pypots
2024-05-22 16:37:04 [INFO]: Epoch 042 - training loss: 0.1274, validation loss: 0.1210
2024-05-22 16:37:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch42_loss0.12097029983997346.pypots
2024-05-22 16:37:20 [INFO]: Epoch 043 - training loss: 0.1356, validation loss: 0.1195
2024-05-22 16:37:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch43_loss0.11945800334215165.pypots
2024-05-22 16:37:37 [INFO]: Epoch 044 - training loss: 0.1286, validation loss: 0.1191
2024-05-22 16:37:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch44_loss0.11911464408040047.pypots
2024-05-22 16:37:53 [INFO]: Epoch 045 - training loss: 0.1194, validation loss: 0.1196
2024-05-22 16:37:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch45_loss0.11959588080644608.pypots
2024-05-22 16:38:09 [INFO]: Epoch 046 - training loss: 0.1247, validation loss: 0.1195
2024-05-22 16:38:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch46_loss0.11949636191129684.pypots
2024-05-22 16:38:26 [INFO]: Epoch 047 - training loss: 0.1325, validation loss: 0.1158
2024-05-22 16:38:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch47_loss0.115754646807909.pypots
2024-05-22 16:38:42 [INFO]: Epoch 048 - training loss: 0.1341, validation loss: 0.1160
2024-05-22 16:38:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch48_loss0.11595258712768555.pypots
2024-05-22 16:38:59 [INFO]: Epoch 049 - training loss: 0.1293, validation loss: 0.1143
2024-05-22 16:38:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch49_loss0.1142948403954506.pypots
2024-05-22 16:39:15 [INFO]: Epoch 050 - training loss: 0.1200, validation loss: 0.1151
2024-05-22 16:39:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch50_loss0.11510917395353318.pypots
2024-05-22 16:39:32 [INFO]: Epoch 051 - training loss: 0.1376, validation loss: 0.1172
2024-05-22 16:39:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch51_loss0.11719369813799858.pypots
2024-05-22 16:39:48 [INFO]: Epoch 052 - training loss: 0.1210, validation loss: 0.1134
2024-05-22 16:39:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch52_loss0.11343722715973854.pypots
2024-05-22 16:40:05 [INFO]: Epoch 053 - training loss: 0.1281, validation loss: 0.1154
2024-05-22 16:40:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch53_loss0.11543946191668511.pypots
2024-05-22 16:40:21 [INFO]: Epoch 054 - training loss: 0.1256, validation loss: 0.1364
2024-05-22 16:40:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch54_loss0.13642223849892615.pypots
2024-05-22 16:40:38 [INFO]: Epoch 055 - training loss: 0.1150, validation loss: 0.1146
2024-05-22 16:40:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch55_loss0.11462018564343453.pypots
2024-05-22 16:40:54 [INFO]: Epoch 056 - training loss: 0.1335, validation loss: 0.1195
2024-05-22 16:40:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch56_loss0.11945038065314292.pypots
2024-05-22 16:41:10 [INFO]: Epoch 057 - training loss: 0.1156, validation loss: 0.1197
2024-05-22 16:41:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch57_loss0.11969534978270531.pypots
2024-05-22 16:41:27 [INFO]: Epoch 058 - training loss: 0.1193, validation loss: 0.1137
2024-05-22 16:41:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch58_loss0.11371554881334305.pypots
2024-05-22 16:41:43 [INFO]: Epoch 059 - training loss: 0.1242, validation loss: 0.1101
2024-05-22 16:41:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch59_loss0.11007171645760536.pypots
2024-05-22 16:42:00 [INFO]: Epoch 060 - training loss: 0.1169, validation loss: 0.1079
2024-05-22 16:42:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch60_loss0.10794145986437798.pypots
2024-05-22 16:42:16 [INFO]: Epoch 061 - training loss: 0.1096, validation loss: 0.1087
2024-05-22 16:42:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch61_loss0.1087035745382309.pypots
2024-05-22 16:42:33 [INFO]: Epoch 062 - training loss: 0.1237, validation loss: 0.1085
2024-05-22 16:42:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch62_loss0.10847557708621025.pypots
2024-05-22 16:42:49 [INFO]: Epoch 063 - training loss: 0.1270, validation loss: 0.1096
2024-05-22 16:42:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch63_loss0.10955071449279785.pypots
2024-05-22 16:43:06 [INFO]: Epoch 064 - training loss: 0.1262, validation loss: 0.1068
2024-05-22 16:43:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch64_loss0.10681351944804192.pypots
2024-05-22 16:43:22 [INFO]: Epoch 065 - training loss: 0.1109, validation loss: 0.1083
2024-05-22 16:43:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch65_loss0.10832892581820489.pypots
2024-05-22 16:43:39 [INFO]: Epoch 066 - training loss: 0.1219, validation loss: 0.1076
2024-05-22 16:43:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch66_loss0.10762754827737808.pypots
2024-05-22 16:43:55 [INFO]: Epoch 067 - training loss: 0.1152, validation loss: 0.1140
2024-05-22 16:43:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch67_loss0.11398728415369988.pypots
2024-05-22 16:44:11 [INFO]: Epoch 068 - training loss: 0.1230, validation loss: 0.1094
2024-05-22 16:44:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch68_loss0.10940254628658294.pypots
2024-05-22 16:44:28 [INFO]: Epoch 069 - training loss: 0.1203, validation loss: 0.1075
2024-05-22 16:44:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch69_loss0.1074954777956009.pypots
2024-05-22 16:44:44 [INFO]: Epoch 070 - training loss: 0.1225, validation loss: 0.1075
2024-05-22 16:44:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch70_loss0.10746693015098571.pypots
2024-05-22 16:45:01 [INFO]: Epoch 071 - training loss: 0.1133, validation loss: 0.1071
2024-05-22 16:45:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch71_loss0.10713384151458741.pypots
2024-05-22 16:45:17 [INFO]: Epoch 072 - training loss: 0.1241, validation loss: 0.1081
2024-05-22 16:45:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch72_loss0.10812057256698608.pypots
2024-05-22 16:45:34 [INFO]: Epoch 073 - training loss: 0.1173, validation loss: 0.1072
2024-05-22 16:45:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch73_loss0.10719612836837769.pypots
2024-05-22 16:45:50 [INFO]: Epoch 074 - training loss: 0.1037, validation loss: 0.1066
2024-05-22 16:45:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch74_loss0.10662564933300019.pypots
2024-05-22 16:46:07 [INFO]: Epoch 075 - training loss: 0.1075, validation loss: 0.1059
2024-05-22 16:46:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch75_loss0.10594370290637016.pypots
2024-05-22 16:46:23 [INFO]: Epoch 076 - training loss: 0.1201, validation loss: 0.1039
2024-05-22 16:46:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch76_loss0.1039467342197895.pypots
2024-05-22 16:46:40 [INFO]: Epoch 077 - training loss: 0.1203, validation loss: 0.1059
2024-05-22 16:46:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch77_loss0.10592737644910813.pypots
2024-05-22 16:46:56 [INFO]: Epoch 078 - training loss: 0.0995, validation loss: 0.1044
2024-05-22 16:46:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch78_loss0.10440218895673752.pypots
2024-05-22 16:47:13 [INFO]: Epoch 079 - training loss: 0.1227, validation loss: 0.1043
2024-05-22 16:47:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch79_loss0.10427255481481552.pypots
2024-05-22 16:47:29 [INFO]: Epoch 080 - training loss: 0.1189, validation loss: 0.1054
2024-05-22 16:47:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch80_loss0.10537342727184296.pypots
2024-05-22 16:47:46 [INFO]: Epoch 081 - training loss: 0.1109, validation loss: 0.1055
2024-05-22 16:47:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch81_loss0.10552565976977349.pypots
2024-05-22 16:48:02 [INFO]: Epoch 082 - training loss: 0.1188, validation loss: 0.1083
2024-05-22 16:48:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch82_loss0.10829534083604812.pypots
2024-05-22 16:48:19 [INFO]: Epoch 083 - training loss: 0.1092, validation loss: 0.1044
2024-05-22 16:48:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch83_loss0.10435274615883827.pypots
2024-05-22 16:48:35 [INFO]: Epoch 084 - training loss: 0.1167, validation loss: 0.1064
2024-05-22 16:48:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch84_loss0.10642522647976875.pypots
2024-05-22 16:48:52 [INFO]: Epoch 085 - training loss: 0.1138, validation loss: 0.1044
2024-05-22 16:48:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch85_loss0.10436849370598793.pypots
2024-05-22 16:49:08 [INFO]: Epoch 086 - training loss: 0.1294, validation loss: 0.1034
2024-05-22 16:49:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch86_loss0.10339410156011582.pypots
2024-05-22 16:49:25 [INFO]: Epoch 087 - training loss: 0.1177, validation loss: 0.1046
2024-05-22 16:49:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch87_loss0.10459221079945565.pypots
2024-05-22 16:49:41 [INFO]: Epoch 088 - training loss: 0.1124, validation loss: 0.1068
2024-05-22 16:49:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch88_loss0.10683667808771133.pypots
2024-05-22 16:49:57 [INFO]: Epoch 089 - training loss: 0.1249, validation loss: 0.1081
2024-05-22 16:49:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch89_loss0.10810444578528404.pypots
2024-05-22 16:50:14 [INFO]: Epoch 090 - training loss: 0.1188, validation loss: 0.1032
2024-05-22 16:50:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch90_loss0.10320411995053291.pypots
2024-05-22 16:50:30 [INFO]: Epoch 091 - training loss: 0.1151, validation loss: 0.1018
2024-05-22 16:50:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch91_loss0.10177526399493217.pypots
2024-05-22 16:50:47 [INFO]: Epoch 092 - training loss: 0.1035, validation loss: 0.1033
2024-05-22 16:50:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch92_loss0.10334962978959084.pypots
2024-05-22 16:51:03 [INFO]: Epoch 093 - training loss: 0.1132, validation loss: 0.1037
2024-05-22 16:51:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch93_loss0.10367725938558578.pypots
2024-05-22 16:51:20 [INFO]: Epoch 094 - training loss: 0.1105, validation loss: 0.1051
2024-05-22 16:51:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch94_loss0.10507571548223496.pypots
2024-05-22 16:51:36 [INFO]: Epoch 095 - training loss: 0.1109, validation loss: 0.1057
2024-05-22 16:51:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch95_loss0.10571323186159134.pypots
2024-05-22 16:51:53 [INFO]: Epoch 096 - training loss: 0.1127, validation loss: 0.1011
2024-05-22 16:51:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch96_loss0.10113956555724143.pypots
2024-05-22 16:52:09 [INFO]: Epoch 097 - training loss: 0.1021, validation loss: 0.1012
2024-05-22 16:52:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch97_loss0.10122191980481147.pypots
2024-05-22 16:52:26 [INFO]: Epoch 098 - training loss: 0.1140, validation loss: 0.1013
2024-05-22 16:52:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch98_loss0.10128064900636673.pypots
2024-05-22 16:52:42 [INFO]: Epoch 099 - training loss: 0.1138, validation loss: 0.1017
2024-05-22 16:52:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch99_loss0.10168333724141121.pypots
2024-05-22 16:52:59 [INFO]: Epoch 100 - training loss: 0.1152, validation loss: 0.1020
2024-05-22 16:52:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch100_loss0.10197772309184075.pypots
2024-05-22 16:53:15 [INFO]: Epoch 101 - training loss: 0.1163, validation loss: 0.1020
2024-05-22 16:53:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch101_loss0.10197811871767044.pypots
2024-05-22 16:53:32 [INFO]: Epoch 102 - training loss: 0.1053, validation loss: 0.1025
2024-05-22 16:53:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch102_loss0.10248513892292976.pypots
2024-05-22 16:53:48 [INFO]: Epoch 103 - training loss: 0.1056, validation loss: 0.1007
2024-05-22 16:53:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch103_loss0.1007219322025776.pypots
2024-05-22 16:54:04 [INFO]: Epoch 104 - training loss: 0.0991, validation loss: 0.1008
2024-05-22 16:54:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch104_loss0.10076818093657494.pypots
2024-05-22 16:54:21 [INFO]: Epoch 105 - training loss: 0.1214, validation loss: 0.1017
2024-05-22 16:54:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch105_loss0.10165157243609428.pypots
2024-05-22 16:54:38 [INFO]: Epoch 106 - training loss: 0.1108, validation loss: 0.1007
2024-05-22 16:54:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch106_loss0.10066071301698684.pypots
2024-05-22 16:54:54 [INFO]: Epoch 107 - training loss: 0.1088, validation loss: 0.0998
2024-05-22 16:54:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch107_loss0.09980941489338875.pypots
2024-05-22 16:55:11 [INFO]: Epoch 108 - training loss: 0.1046, validation loss: 0.0995
2024-05-22 16:55:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch108_loss0.0995169885456562.pypots
2024-05-22 16:55:27 [INFO]: Epoch 109 - training loss: 0.1112, validation loss: 0.0992
2024-05-22 16:55:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch109_loss0.09915992617607117.pypots
2024-05-22 16:55:44 [INFO]: Epoch 110 - training loss: 0.1285, validation loss: 0.1008
2024-05-22 16:55:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch110_loss0.10082120522856712.pypots
2024-05-22 16:56:00 [INFO]: Epoch 111 - training loss: 0.1076, validation loss: 0.1006
2024-05-22 16:56:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch111_loss0.10058287680149078.pypots
2024-05-22 16:56:17 [INFO]: Epoch 112 - training loss: 0.1065, validation loss: 0.1027
2024-05-22 16:56:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch112_loss0.10267224162817001.pypots
2024-05-22 16:56:33 [INFO]: Epoch 113 - training loss: 0.1129, validation loss: 0.1002
2024-05-22 16:56:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch113_loss0.10023776292800904.pypots
2024-05-22 16:56:50 [INFO]: Epoch 114 - training loss: 0.1145, validation loss: 0.1016
2024-05-22 16:56:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch114_loss0.1015898458659649.pypots
2024-05-22 16:57:06 [INFO]: Epoch 115 - training loss: 0.1095, validation loss: 0.0997
2024-05-22 16:57:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch115_loss0.09974724724888802.pypots
2024-05-22 16:57:23 [INFO]: Epoch 116 - training loss: 0.1019, validation loss: 0.1021
2024-05-22 16:57:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch116_loss0.10210044831037521.pypots
2024-05-22 16:57:39 [INFO]: Epoch 117 - training loss: 0.1198, validation loss: 0.1058
2024-05-22 16:57:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch117_loss0.10578858479857445.pypots
2024-05-22 16:57:56 [INFO]: Epoch 118 - training loss: 0.1188, validation loss: 0.1026
2024-05-22 16:57:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch118_loss0.10258912518620492.pypots
2024-05-22 16:58:12 [INFO]: Epoch 119 - training loss: 0.1192, validation loss: 0.1021
2024-05-22 16:58:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI_epoch119_loss0.10213713273406029.pypots
2024-05-22 16:58:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:58:12 [INFO]: Finished training. The best model is from epoch#109.
2024-05-22 16:58:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/20240522_T162532/CSDI.pypots
2024-05-22 17:00:30 [INFO]: CSDI on Air-Quality: MAE=0.0966, MSE=0.0915
2024-05-22 17:00:30 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/CSDI_air_quality/imputation.pkl
2024-05-22 17:00:30 [INFO]: Using the given device: cuda:0
2024-05-22 17:00:31 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/GPVAE_air_quality/20240522_T170030
2024-05-22 17:00:31 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/GPVAE_air_quality/20240522_T170030/tensorboard
2024-05-22 17:00:31 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-22 17:00:31 [INFO]: Epoch 001 - training loss: 62978.8193, validation loss: 0.6490
2024-05-22 17:00:31 [INFO]: Epoch 002 - training loss: 42031.6424, validation loss: 0.5465
2024-05-22 17:00:32 [INFO]: Epoch 003 - training loss: 41747.6121, validation loss: 0.5178
2024-05-22 17:00:32 [INFO]: Epoch 004 - training loss: 41614.8319, validation loss: 0.4579
2024-05-22 17:00:32 [INFO]: Epoch 005 - training loss: 41558.0816, validation loss: 0.5345
2024-05-22 17:00:32 [INFO]: Epoch 006 - training loss: 41550.4795, validation loss: 0.3889
2024-05-22 17:00:33 [INFO]: Epoch 007 - training loss: 41462.1535, validation loss: 0.3805
2024-05-22 17:00:33 [INFO]: Epoch 008 - training loss: 41450.1819, validation loss: 0.3447
2024-05-22 17:00:33 [INFO]: Epoch 009 - training loss: 41402.2394, validation loss: 0.3281
2024-05-22 17:00:33 [INFO]: Epoch 010 - training loss: 41371.4109, validation loss: 0.3203
2024-05-22 17:00:34 [INFO]: Epoch 011 - training loss: 41353.6613, validation loss: 0.3150
2024-05-22 17:00:34 [INFO]: Epoch 012 - training loss: 41346.8948, validation loss: 0.3495
2024-05-22 17:00:34 [INFO]: Epoch 013 - training loss: 41390.4387, validation loss: 0.3052
2024-05-22 17:00:35 [INFO]: Epoch 014 - training loss: 41340.8691, validation loss: 0.2912
2024-05-22 17:00:35 [INFO]: Epoch 015 - training loss: 41309.4154, validation loss: 0.2879
2024-05-22 17:00:35 [INFO]: Epoch 016 - training loss: 41297.1068, validation loss: 0.2856
2024-05-22 17:00:35 [INFO]: Epoch 017 - training loss: 41297.6620, validation loss: 0.2943
2024-05-22 17:00:36 [INFO]: Epoch 018 - training loss: 41321.1007, validation loss: 0.2832
2024-05-22 17:00:36 [INFO]: Epoch 019 - training loss: 41298.7302, validation loss: 0.2715
2024-05-22 17:00:36 [INFO]: Epoch 020 - training loss: 41275.2185, validation loss: 0.2624
2024-05-22 17:00:36 [INFO]: Epoch 021 - training loss: 41258.9002, validation loss: 0.2839
2024-05-22 17:00:37 [INFO]: Epoch 022 - training loss: 41298.2556, validation loss: 0.3061
2024-05-22 17:00:37 [INFO]: Epoch 023 - training loss: 41268.1338, validation loss: 0.2704
2024-05-22 17:00:37 [INFO]: Epoch 024 - training loss: 41250.0065, validation loss: 0.2536
2024-05-22 17:00:37 [INFO]: Epoch 025 - training loss: 41237.8176, validation loss: 0.2491
2024-05-22 17:00:37 [INFO]: Epoch 026 - training loss: 41271.7339, validation loss: 0.2774
2024-05-22 17:00:38 [INFO]: Epoch 027 - training loss: 41259.2892, validation loss: 0.2507
2024-05-22 17:00:38 [INFO]: Epoch 028 - training loss: 41238.5069, validation loss: 0.2517
2024-05-22 17:00:38 [INFO]: Epoch 029 - training loss: 41222.8166, validation loss: 0.2430
2024-05-22 17:00:38 [INFO]: Epoch 030 - training loss: 41214.7371, validation loss: 0.2501
2024-05-22 17:00:39 [INFO]: Epoch 031 - training loss: 41206.9094, validation loss: 0.2387
2024-05-22 17:00:39 [INFO]: Epoch 032 - training loss: 41208.3220, validation loss: 0.2347
2024-05-22 17:00:39 [INFO]: Epoch 033 - training loss: 41207.7700, validation loss: 0.2356
2024-05-22 17:00:39 [INFO]: Epoch 034 - training loss: 41203.3284, validation loss: 0.2283
2024-05-22 17:00:40 [INFO]: Epoch 035 - training loss: 41193.4301, validation loss: 0.2305
2024-05-22 17:00:40 [INFO]: Epoch 036 - training loss: 41195.5451, validation loss: 0.2331
2024-05-22 17:00:40 [INFO]: Epoch 037 - training loss: 41195.0657, validation loss: 0.2310
2024-05-22 17:00:40 [INFO]: Epoch 038 - training loss: 41195.2556, validation loss: 0.2322
2024-05-22 17:00:41 [INFO]: Epoch 039 - training loss: 41192.5243, validation loss: 0.2410
2024-05-22 17:00:41 [INFO]: Epoch 040 - training loss: 41210.0049, validation loss: 0.2547
2024-05-22 17:00:41 [INFO]: Epoch 041 - training loss: 41226.6639, validation loss: 0.3081
2024-05-22 17:00:41 [INFO]: Epoch 042 - training loss: 41304.5859, validation loss: 0.2326
2024-05-22 17:00:42 [INFO]: Epoch 043 - training loss: 41265.9200, validation loss: 0.2605
2024-05-22 17:00:42 [INFO]: Epoch 044 - training loss: 41263.7879, validation loss: 0.2442
2024-05-22 17:00:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:00:42 [INFO]: Finished training. The best model is from epoch#34.
2024-05-22 17:00:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/GPVAE_air_quality/20240522_T170030/GPVAE.pypots
2024-05-22 17:00:42 [INFO]: GP-VAE on Air-Quality: MAE=0.3029, MSE=0.2707
2024-05-22 17:00:42 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/GPVAE_air_quality/imputation.pkl
2024-05-22 17:00:42 [INFO]: Using the given device: cuda:0
2024-05-22 17:00:42 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/USGAN_air_quality/20240522_T170042
2024-05-22 17:00:42 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/USGAN_air_quality/20240522_T170042/tensorboard
2024-05-22 17:00:42 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-22 17:00:47 [INFO]: Epoch 001 - generator training loss: 0.6367, discriminator training loss: 0.2736, validation loss: 0.4970
2024-05-22 17:00:50 [INFO]: Epoch 002 - generator training loss: 0.2983, discriminator training loss: 0.0665, validation loss: 0.3717
2024-05-22 17:00:54 [INFO]: Epoch 003 - generator training loss: 0.2195, discriminator training loss: 0.0629, validation loss: 0.3056
2024-05-22 17:00:57 [INFO]: Epoch 004 - generator training loss: 0.1825, discriminator training loss: 0.0619, validation loss: 0.2625
2024-05-22 17:01:01 [INFO]: Epoch 005 - generator training loss: 0.1542, discriminator training loss: 0.0616, validation loss: 0.2344
2024-05-22 17:01:04 [INFO]: Epoch 006 - generator training loss: 0.1354, discriminator training loss: 0.0607, validation loss: 0.2171
2024-05-22 17:01:08 [INFO]: Epoch 007 - generator training loss: 0.1239, discriminator training loss: 0.0607, validation loss: 0.2032
2024-05-22 17:01:11 [INFO]: Epoch 008 - generator training loss: 0.1123, discriminator training loss: 0.0602, validation loss: 0.1927
2024-05-22 17:01:15 [INFO]: Epoch 009 - generator training loss: 0.1046, discriminator training loss: 0.0589, validation loss: 0.1844
2024-05-22 17:01:18 [INFO]: Epoch 010 - generator training loss: 0.0954, discriminator training loss: 0.0585, validation loss: 0.1778
2024-05-22 17:01:22 [INFO]: Epoch 011 - generator training loss: 0.0883, discriminator training loss: 0.0572, validation loss: 0.1718
2024-05-22 17:01:25 [INFO]: Epoch 012 - generator training loss: 0.0832, discriminator training loss: 0.0564, validation loss: 0.1665
2024-05-22 17:01:29 [INFO]: Epoch 013 - generator training loss: 0.0805, discriminator training loss: 0.0556, validation loss: 0.1626
2024-05-22 17:01:32 [INFO]: Epoch 014 - generator training loss: 0.0779, discriminator training loss: 0.0536, validation loss: 0.1594
2024-05-22 17:01:36 [INFO]: Epoch 015 - generator training loss: 0.0761, discriminator training loss: 0.0516, validation loss: 0.1567
2024-05-22 17:01:39 [INFO]: Epoch 016 - generator training loss: 0.0757, discriminator training loss: 0.0504, validation loss: 0.1541
2024-05-22 17:01:43 [INFO]: Epoch 017 - generator training loss: 0.0724, discriminator training loss: 0.0486, validation loss: 0.1517
2024-05-22 17:01:46 [INFO]: Epoch 018 - generator training loss: 0.0716, discriminator training loss: 0.0471, validation loss: 0.1492
2024-05-22 17:01:50 [INFO]: Epoch 019 - generator training loss: 0.0697, discriminator training loss: 0.0462, validation loss: 0.1473
2024-05-22 17:01:53 [INFO]: Epoch 020 - generator training loss: 0.0670, discriminator training loss: 0.0458, validation loss: 0.1451
2024-05-22 17:01:57 [INFO]: Epoch 021 - generator training loss: 0.0652, discriminator training loss: 0.0445, validation loss: 0.1426
2024-05-22 17:02:00 [INFO]: Epoch 022 - generator training loss: 0.0658, discriminator training loss: 0.0435, validation loss: 0.1409
2024-05-22 17:02:04 [INFO]: Epoch 023 - generator training loss: 0.0630, discriminator training loss: 0.0430, validation loss: 0.1384
2024-05-22 17:02:07 [INFO]: Epoch 024 - generator training loss: 0.0620, discriminator training loss: 0.0426, validation loss: 0.1367
2024-05-22 17:02:11 [INFO]: Epoch 025 - generator training loss: 0.0621, discriminator training loss: 0.0417, validation loss: 0.1351
2024-05-22 17:02:14 [INFO]: Epoch 026 - generator training loss: 0.0598, discriminator training loss: 0.0410, validation loss: 0.1337
2024-05-22 17:02:17 [INFO]: Epoch 027 - generator training loss: 0.0591, discriminator training loss: 0.0401, validation loss: 0.1318
2024-05-22 17:02:21 [INFO]: Epoch 028 - generator training loss: 0.0592, discriminator training loss: 0.0392, validation loss: 0.1307
2024-05-22 17:02:24 [INFO]: Epoch 029 - generator training loss: 0.0583, discriminator training loss: 0.0389, validation loss: 0.1293
2024-05-22 17:02:28 [INFO]: Epoch 030 - generator training loss: 0.0576, discriminator training loss: 0.0379, validation loss: 0.1281
2024-05-22 17:02:31 [INFO]: Epoch 031 - generator training loss: 0.0565, discriminator training loss: 0.0369, validation loss: 0.1265
2024-05-22 17:02:35 [INFO]: Epoch 032 - generator training loss: 0.0561, discriminator training loss: 0.0360, validation loss: 0.1256
2024-05-22 17:02:38 [INFO]: Epoch 033 - generator training loss: 0.0555, discriminator training loss: 0.0355, validation loss: 0.1247
2024-05-22 17:02:42 [INFO]: Epoch 034 - generator training loss: 0.0557, discriminator training loss: 0.0345, validation loss: 0.1243
2024-05-22 17:02:45 [INFO]: Epoch 035 - generator training loss: 0.0559, discriminator training loss: 0.0336, validation loss: 0.1228
2024-05-22 17:02:49 [INFO]: Epoch 036 - generator training loss: 0.0541, discriminator training loss: 0.0327, validation loss: 0.1219
2024-05-22 17:02:52 [INFO]: Epoch 037 - generator training loss: 0.0537, discriminator training loss: 0.0321, validation loss: 0.1210
2024-05-22 17:02:56 [INFO]: Epoch 038 - generator training loss: 0.0533, discriminator training loss: 0.0317, validation loss: 0.1200
2024-05-22 17:02:59 [INFO]: Epoch 039 - generator training loss: 0.0521, discriminator training loss: 0.0311, validation loss: 0.1187
2024-05-22 17:03:03 [INFO]: Epoch 040 - generator training loss: 0.0523, discriminator training loss: 0.0305, validation loss: 0.1182
2024-05-22 17:03:06 [INFO]: Epoch 041 - generator training loss: 0.0522, discriminator training loss: 0.0297, validation loss: 0.1171
2024-05-22 17:03:10 [INFO]: Epoch 042 - generator training loss: 0.0510, discriminator training loss: 0.0292, validation loss: 0.1170
2024-05-22 17:03:13 [INFO]: Epoch 043 - generator training loss: 0.0515, discriminator training loss: 0.0285, validation loss: 0.1159
2024-05-22 17:03:17 [INFO]: Epoch 044 - generator training loss: 0.0500, discriminator training loss: 0.0284, validation loss: 0.1153
2024-05-22 17:03:20 [INFO]: Epoch 045 - generator training loss: 0.0495, discriminator training loss: 0.0277, validation loss: 0.1145
2024-05-22 17:03:24 [INFO]: Epoch 046 - generator training loss: 0.0510, discriminator training loss: 0.0273, validation loss: 0.1142
2024-05-22 17:03:27 [INFO]: Epoch 047 - generator training loss: 0.0486, discriminator training loss: 0.0266, validation loss: 0.1137
2024-05-22 17:03:31 [INFO]: Epoch 048 - generator training loss: 0.0490, discriminator training loss: 0.0260, validation loss: 0.1127
2024-05-22 17:03:34 [INFO]: Epoch 049 - generator training loss: 0.0472, discriminator training loss: 0.0258, validation loss: 0.1118
2024-05-22 17:03:37 [INFO]: Epoch 050 - generator training loss: 0.0476, discriminator training loss: 0.0255, validation loss: 0.1110
2024-05-22 17:03:41 [INFO]: Epoch 051 - generator training loss: 0.0466, discriminator training loss: 0.0249, validation loss: 0.1111
2024-05-22 17:03:44 [INFO]: Epoch 052 - generator training loss: 0.0463, discriminator training loss: 0.0245, validation loss: 0.1101
2024-05-22 17:03:48 [INFO]: Epoch 053 - generator training loss: 0.0473, discriminator training loss: 0.0242, validation loss: 0.1096
2024-05-22 17:03:51 [INFO]: Epoch 054 - generator training loss: 0.0458, discriminator training loss: 0.0237, validation loss: 0.1093
2024-05-22 17:03:55 [INFO]: Epoch 055 - generator training loss: 0.0452, discriminator training loss: 0.0233, validation loss: 0.1089
2024-05-22 17:03:58 [INFO]: Epoch 056 - generator training loss: 0.0463, discriminator training loss: 0.0231, validation loss: 0.1081
2024-05-22 17:04:02 [INFO]: Epoch 057 - generator training loss: 0.0445, discriminator training loss: 0.0228, validation loss: 0.1071
2024-05-22 17:04:05 [INFO]: Epoch 058 - generator training loss: 0.0441, discriminator training loss: 0.0225, validation loss: 0.1075
2024-05-22 17:04:09 [INFO]: Epoch 059 - generator training loss: 0.0438, discriminator training loss: 0.0220, validation loss: 0.1068
2024-05-22 17:04:12 [INFO]: Epoch 060 - generator training loss: 0.0433, discriminator training loss: 0.0219, validation loss: 0.1062
2024-05-22 17:04:15 [INFO]: Epoch 061 - generator training loss: 0.0433, discriminator training loss: 0.0215, validation loss: 0.1052
2024-05-22 17:04:19 [INFO]: Epoch 062 - generator training loss: 0.0435, discriminator training loss: 0.0214, validation loss: 0.1048
2024-05-22 17:04:22 [INFO]: Epoch 063 - generator training loss: 0.0427, discriminator training loss: 0.0210, validation loss: 0.1039
2024-05-22 17:04:26 [INFO]: Epoch 064 - generator training loss: 0.0429, discriminator training loss: 0.0207, validation loss: 0.1039
2024-05-22 17:04:29 [INFO]: Epoch 065 - generator training loss: 0.0417, discriminator training loss: 0.0205, validation loss: 0.1030
2024-05-22 17:04:33 [INFO]: Epoch 066 - generator training loss: 0.0412, discriminator training loss: 0.0202, validation loss: 0.1022
2024-05-22 17:04:36 [INFO]: Epoch 067 - generator training loss: 0.0416, discriminator training loss: 0.0198, validation loss: 0.1022
2024-05-22 17:04:40 [INFO]: Epoch 068 - generator training loss: 0.0410, discriminator training loss: 0.0197, validation loss: 0.1016
2024-05-22 17:04:43 [INFO]: Epoch 069 - generator training loss: 0.0412, discriminator training loss: 0.0195, validation loss: 0.1017
2024-05-22 17:04:47 [INFO]: Epoch 070 - generator training loss: 0.0402, discriminator training loss: 0.0197, validation loss: 0.1012
2024-05-22 17:04:50 [INFO]: Epoch 071 - generator training loss: 0.0405, discriminator training loss: 0.0193, validation loss: 0.1007
2024-05-22 17:04:54 [INFO]: Epoch 072 - generator training loss: 0.0399, discriminator training loss: 0.0192, validation loss: 0.1008
2024-05-22 17:04:57 [INFO]: Epoch 073 - generator training loss: 0.0409, discriminator training loss: 0.0190, validation loss: 0.1004
2024-05-22 17:05:01 [INFO]: Epoch 074 - generator training loss: 0.0396, discriminator training loss: 0.0185, validation loss: 0.0997
2024-05-22 17:05:04 [INFO]: Epoch 075 - generator training loss: 0.0392, discriminator training loss: 0.0184, validation loss: 0.0995
2024-05-22 17:05:07 [INFO]: Epoch 076 - generator training loss: 0.0395, discriminator training loss: 0.0183, validation loss: 0.0994
2024-05-22 17:05:11 [INFO]: Epoch 077 - generator training loss: 0.0387, discriminator training loss: 0.0182, validation loss: 0.0995
2024-05-22 17:05:14 [INFO]: Epoch 078 - generator training loss: 0.0384, discriminator training loss: 0.0181, validation loss: 0.0985
2024-05-22 17:05:18 [INFO]: Epoch 079 - generator training loss: 0.0382, discriminator training loss: 0.0181, validation loss: 0.0991
2024-05-22 17:05:21 [INFO]: Epoch 080 - generator training loss: 0.0386, discriminator training loss: 0.0180, validation loss: 0.0988
2024-05-22 17:05:25 [INFO]: Epoch 081 - generator training loss: 0.0381, discriminator training loss: 0.0174, validation loss: 0.0989
2024-05-22 17:05:28 [INFO]: Epoch 082 - generator training loss: 0.0376, discriminator training loss: 0.0175, validation loss: 0.0980
2024-05-22 17:05:31 [INFO]: Epoch 083 - generator training loss: 0.0376, discriminator training loss: 0.0171, validation loss: 0.0979
2024-05-22 17:05:35 [INFO]: Epoch 084 - generator training loss: 0.0382, discriminator training loss: 0.0170, validation loss: 0.0982
2024-05-22 17:05:38 [INFO]: Epoch 085 - generator training loss: 0.0372, discriminator training loss: 0.0170, validation loss: 0.0980
2024-05-22 17:05:42 [INFO]: Epoch 086 - generator training loss: 0.0372, discriminator training loss: 0.0167, validation loss: 0.0981
2024-05-22 17:05:45 [INFO]: Epoch 087 - generator training loss: 0.0370, discriminator training loss: 0.0168, validation loss: 0.0978
2024-05-22 17:05:49 [INFO]: Epoch 088 - generator training loss: 0.0366, discriminator training loss: 0.0167, validation loss: 0.0979
2024-05-22 17:05:52 [INFO]: Epoch 089 - generator training loss: 0.0368, discriminator training loss: 0.0164, validation loss: 0.0981
2024-05-22 17:05:56 [INFO]: Epoch 090 - generator training loss: 0.0364, discriminator training loss: 0.0163, validation loss: 0.0977
2024-05-22 17:06:00 [INFO]: Epoch 091 - generator training loss: 0.0360, discriminator training loss: 0.0163, validation loss: 0.0974
2024-05-22 17:06:03 [INFO]: Epoch 092 - generator training loss: 0.0356, discriminator training loss: 0.0163, validation loss: 0.0971
2024-05-22 17:06:07 [INFO]: Epoch 093 - generator training loss: 0.0353, discriminator training loss: 0.0162, validation loss: 0.0970
2024-05-22 17:06:10 [INFO]: Epoch 094 - generator training loss: 0.0355, discriminator training loss: 0.0160, validation loss: 0.0971
2024-05-22 17:06:14 [INFO]: Epoch 095 - generator training loss: 0.0353, discriminator training loss: 0.0160, validation loss: 0.0975
2024-05-22 17:06:17 [INFO]: Epoch 096 - generator training loss: 0.0353, discriminator training loss: 0.0157, validation loss: 0.0971
2024-05-22 17:06:21 [INFO]: Epoch 097 - generator training loss: 0.0349, discriminator training loss: 0.0156, validation loss: 0.0969
2024-05-22 17:06:24 [INFO]: Epoch 098 - generator training loss: 0.0348, discriminator training loss: 0.0154, validation loss: 0.0975
2024-05-22 17:06:28 [INFO]: Epoch 099 - generator training loss: 0.0361, discriminator training loss: 0.0156, validation loss: 0.0974
2024-05-22 17:06:31 [INFO]: Epoch 100 - generator training loss: 0.0349, discriminator training loss: 0.0154, validation loss: 0.0970
2024-05-22 17:06:35 [INFO]: Epoch 101 - generator training loss: 0.0344, discriminator training loss: 0.0153, validation loss: 0.0974
2024-05-22 17:06:38 [INFO]: Epoch 102 - generator training loss: 0.0339, discriminator training loss: 0.0153, validation loss: 0.0970
2024-05-22 17:06:42 [INFO]: Epoch 103 - generator training loss: 0.0342, discriminator training loss: 0.0152, validation loss: 0.0967
2024-05-22 17:06:45 [INFO]: Epoch 104 - generator training loss: 0.0337, discriminator training loss: 0.0149, validation loss: 0.0967
2024-05-22 17:06:49 [INFO]: Epoch 105 - generator training loss: 0.0339, discriminator training loss: 0.0151, validation loss: 0.0969
2024-05-22 17:06:52 [INFO]: Epoch 106 - generator training loss: 0.0339, discriminator training loss: 0.0152, validation loss: 0.0973
2024-05-22 17:06:56 [INFO]: Epoch 107 - generator training loss: 0.0332, discriminator training loss: 0.0151, validation loss: 0.0974
2024-05-22 17:06:59 [INFO]: Epoch 108 - generator training loss: 0.0333, discriminator training loss: 0.0147, validation loss: 0.0966
2024-05-22 17:07:03 [INFO]: Epoch 109 - generator training loss: 0.0331, discriminator training loss: 0.0147, validation loss: 0.0973
2024-05-22 17:07:06 [INFO]: Epoch 110 - generator training loss: 0.0334, discriminator training loss: 0.0147, validation loss: 0.0973
2024-05-22 17:07:10 [INFO]: Epoch 111 - generator training loss: 0.0326, discriminator training loss: 0.0145, validation loss: 0.0973
2024-05-22 17:07:13 [INFO]: Epoch 112 - generator training loss: 0.0329, discriminator training loss: 0.0143, validation loss: 0.0970
2024-05-22 17:07:17 [INFO]: Epoch 113 - generator training loss: 0.0325, discriminator training loss: 0.0145, validation loss: 0.0974
2024-05-22 17:07:20 [INFO]: Epoch 114 - generator training loss: 0.0325, discriminator training loss: 0.0143, validation loss: 0.0979
2024-05-22 17:07:24 [INFO]: Epoch 115 - generator training loss: 0.0324, discriminator training loss: 0.0144, validation loss: 0.0977
2024-05-22 17:07:27 [INFO]: Epoch 116 - generator training loss: 0.0322, discriminator training loss: 0.0143, validation loss: 0.0978
2024-05-22 17:07:31 [INFO]: Epoch 117 - generator training loss: 0.0331, discriminator training loss: 0.0142, validation loss: 0.0972
2024-05-22 17:07:34 [INFO]: Epoch 118 - generator training loss: 0.0326, discriminator training loss: 0.0140, validation loss: 0.0977
2024-05-22 17:07:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:07:34 [INFO]: Finished training. The best model is from epoch#108.
2024-05-22 17:07:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/USGAN_air_quality/20240522_T170042/USGAN.pypots
2024-05-22 17:07:35 [INFO]: US-GAN on Air-Quality: MAE=0.1685, MSE=0.1077
2024-05-22 17:07:35 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/USGAN_air_quality/imputation.pkl
2024-05-22 17:07:35 [INFO]: Using the given device: cuda:0
2024-05-22 17:07:35 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/BRITS_air_quality/20240522_T170735
2024-05-22 17:07:35 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/BRITS_air_quality/20240522_T170735/tensorboard
2024-05-22 17:07:35 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-22 17:07:38 [INFO]: Epoch 001 - training loss: 1.4046, validation loss: 0.9043
2024-05-22 17:07:40 [INFO]: Epoch 002 - training loss: 1.1354, validation loss: 0.6741
2024-05-22 17:07:42 [INFO]: Epoch 003 - training loss: 0.9444, validation loss: 0.5681
2024-05-22 17:07:45 [INFO]: Epoch 004 - training loss: 0.8359, validation loss: 0.5019
2024-05-22 17:07:47 [INFO]: Epoch 005 - training loss: 0.7609, validation loss: 0.4521
2024-05-22 17:07:49 [INFO]: Epoch 006 - training loss: 0.7029, validation loss: 0.4142
2024-05-22 17:07:52 [INFO]: Epoch 007 - training loss: 0.6572, validation loss: 0.3842
2024-05-22 17:07:54 [INFO]: Epoch 008 - training loss: 0.6227, validation loss: 0.3600
2024-05-22 17:07:56 [INFO]: Epoch 009 - training loss: 0.5979, validation loss: 0.3403
2024-05-22 17:07:58 [INFO]: Epoch 010 - training loss: 0.5751, validation loss: 0.3242
2024-05-22 17:08:01 [INFO]: Epoch 011 - training loss: 0.5578, validation loss: 0.3108
2024-05-22 17:08:03 [INFO]: Epoch 012 - training loss: 0.5427, validation loss: 0.2997
2024-05-22 17:08:06 [INFO]: Epoch 013 - training loss: 0.5299, validation loss: 0.2895
2024-05-22 17:08:08 [INFO]: Epoch 014 - training loss: 0.5180, validation loss: 0.2808
2024-05-22 17:08:10 [INFO]: Epoch 015 - training loss: 0.5072, validation loss: 0.2730
2024-05-22 17:08:12 [INFO]: Epoch 016 - training loss: 0.4987, validation loss: 0.2659
2024-05-22 17:08:15 [INFO]: Epoch 017 - training loss: 0.4873, validation loss: 0.2598
2024-05-22 17:08:17 [INFO]: Epoch 018 - training loss: 0.4792, validation loss: 0.2543
2024-05-22 17:08:19 [INFO]: Epoch 019 - training loss: 0.4717, validation loss: 0.2491
2024-05-22 17:08:22 [INFO]: Epoch 020 - training loss: 0.4635, validation loss: 0.2442
2024-05-22 17:08:24 [INFO]: Epoch 021 - training loss: 0.4577, validation loss: 0.2400
2024-05-22 17:08:26 [INFO]: Epoch 022 - training loss: 0.4509, validation loss: 0.2357
2024-05-22 17:08:29 [INFO]: Epoch 023 - training loss: 0.4446, validation loss: 0.2320
2024-05-22 17:08:31 [INFO]: Epoch 024 - training loss: 0.4389, validation loss: 0.2280
2024-05-22 17:08:33 [INFO]: Epoch 025 - training loss: 0.4330, validation loss: 0.2242
2024-05-22 17:08:36 [INFO]: Epoch 026 - training loss: 0.4270, validation loss: 0.2211
2024-05-22 17:08:38 [INFO]: Epoch 027 - training loss: 0.4224, validation loss: 0.2177
2024-05-22 17:08:40 [INFO]: Epoch 028 - training loss: 0.4174, validation loss: 0.2148
2024-05-22 17:08:42 [INFO]: Epoch 029 - training loss: 0.4120, validation loss: 0.2116
2024-05-22 17:08:45 [INFO]: Epoch 030 - training loss: 0.4072, validation loss: 0.2089
2024-05-22 17:08:47 [INFO]: Epoch 031 - training loss: 0.4040, validation loss: 0.2056
2024-05-22 17:08:49 [INFO]: Epoch 032 - training loss: 0.3985, validation loss: 0.2028
2024-05-22 17:08:52 [INFO]: Epoch 033 - training loss: 0.3944, validation loss: 0.2000
2024-05-22 17:08:54 [INFO]: Epoch 034 - training loss: 0.3905, validation loss: 0.1975
2024-05-22 17:08:56 [INFO]: Epoch 035 - training loss: 0.3859, validation loss: 0.1954
2024-05-22 17:08:58 [INFO]: Epoch 036 - training loss: 0.3818, validation loss: 0.1923
2024-05-22 17:09:01 [INFO]: Epoch 037 - training loss: 0.3789, validation loss: 0.1896
2024-05-22 17:09:03 [INFO]: Epoch 038 - training loss: 0.3754, validation loss: 0.1877
2024-05-22 17:09:05 [INFO]: Epoch 039 - training loss: 0.3721, validation loss: 0.1851
2024-05-22 17:09:08 [INFO]: Epoch 040 - training loss: 0.3684, validation loss: 0.1827
2024-05-22 17:09:10 [INFO]: Epoch 041 - training loss: 0.3646, validation loss: 0.1808
2024-05-22 17:09:12 [INFO]: Epoch 042 - training loss: 0.3629, validation loss: 0.1779
2024-05-22 17:09:15 [INFO]: Epoch 043 - training loss: 0.3590, validation loss: 0.1758
2024-05-22 17:09:17 [INFO]: Epoch 044 - training loss: 0.3556, validation loss: 0.1737
2024-05-22 17:09:19 [INFO]: Epoch 045 - training loss: 0.3529, validation loss: 0.1719
2024-05-22 17:09:22 [INFO]: Epoch 046 - training loss: 0.3503, validation loss: 0.1694
2024-05-22 17:09:24 [INFO]: Epoch 047 - training loss: 0.3477, validation loss: 0.1677
2024-05-22 17:09:26 [INFO]: Epoch 048 - training loss: 0.3460, validation loss: 0.1655
2024-05-22 17:09:28 [INFO]: Epoch 049 - training loss: 0.3431, validation loss: 0.1640
2024-05-22 17:09:31 [INFO]: Epoch 050 - training loss: 0.3402, validation loss: 0.1622
2024-05-22 17:09:33 [INFO]: Epoch 051 - training loss: 0.3377, validation loss: 0.1597
2024-05-22 17:09:35 [INFO]: Epoch 052 - training loss: 0.3356, validation loss: 0.1584
2024-05-22 17:09:38 [INFO]: Epoch 053 - training loss: 0.3341, validation loss: 0.1569
2024-05-22 17:09:40 [INFO]: Epoch 054 - training loss: 0.3321, validation loss: 0.1553
2024-05-22 17:09:42 [INFO]: Epoch 055 - training loss: 0.3299, validation loss: 0.1540
2024-05-22 17:09:45 [INFO]: Epoch 056 - training loss: 0.3276, validation loss: 0.1526
2024-05-22 17:09:47 [INFO]: Epoch 057 - training loss: 0.3261, validation loss: 0.1515
2024-05-22 17:09:49 [INFO]: Epoch 058 - training loss: 0.3239, validation loss: 0.1502
2024-05-22 17:09:52 [INFO]: Epoch 059 - training loss: 0.3221, validation loss: 0.1491
2024-05-22 17:09:54 [INFO]: Epoch 060 - training loss: 0.3212, validation loss: 0.1481
2024-05-22 17:09:56 [INFO]: Epoch 061 - training loss: 0.3184, validation loss: 0.1465
2024-05-22 17:09:59 [INFO]: Epoch 062 - training loss: 0.3172, validation loss: 0.1456
2024-05-22 17:10:01 [INFO]: Epoch 063 - training loss: 0.3152, validation loss: 0.1449
2024-05-22 17:10:03 [INFO]: Epoch 064 - training loss: 0.3149, validation loss: 0.1435
2024-05-22 17:10:06 [INFO]: Epoch 065 - training loss: 0.3126, validation loss: 0.1428
2024-05-22 17:10:08 [INFO]: Epoch 066 - training loss: 0.3117, validation loss: 0.1419
2024-05-22 17:10:10 [INFO]: Epoch 067 - training loss: 0.3099, validation loss: 0.1412
2024-05-22 17:10:12 [INFO]: Epoch 068 - training loss: 0.3095, validation loss: 0.1405
2024-05-22 17:10:15 [INFO]: Epoch 069 - training loss: 0.3071, validation loss: 0.1393
2024-05-22 17:10:17 [INFO]: Epoch 070 - training loss: 0.3062, validation loss: 0.1386
2024-05-22 17:10:19 [INFO]: Epoch 071 - training loss: 0.3055, validation loss: 0.1382
2024-05-22 17:10:22 [INFO]: Epoch 072 - training loss: 0.3043, validation loss: 0.1372
2024-05-22 17:10:24 [INFO]: Epoch 073 - training loss: 0.3029, validation loss: 0.1366
2024-05-22 17:10:26 [INFO]: Epoch 074 - training loss: 0.3011, validation loss: 0.1361
2024-05-22 17:10:29 [INFO]: Epoch 075 - training loss: 0.3002, validation loss: 0.1352
2024-05-22 17:10:31 [INFO]: Epoch 076 - training loss: 0.3002, validation loss: 0.1344
2024-05-22 17:10:33 [INFO]: Epoch 077 - training loss: 0.2984, validation loss: 0.1340
2024-05-22 17:10:36 [INFO]: Epoch 078 - training loss: 0.2975, validation loss: 0.1332
2024-05-22 17:10:38 [INFO]: Epoch 079 - training loss: 0.2967, validation loss: 0.1327
2024-05-22 17:10:41 [INFO]: Epoch 080 - training loss: 0.2957, validation loss: 0.1320
2024-05-22 17:10:43 [INFO]: Epoch 081 - training loss: 0.2945, validation loss: 0.1315
2024-05-22 17:10:45 [INFO]: Epoch 082 - training loss: 0.2937, validation loss: 0.1307
2024-05-22 17:10:48 [INFO]: Epoch 083 - training loss: 0.2926, validation loss: 0.1302
2024-05-22 17:10:50 [INFO]: Epoch 084 - training loss: 0.2925, validation loss: 0.1298
2024-05-22 17:10:53 [INFO]: Epoch 085 - training loss: 0.2914, validation loss: 0.1292
2024-05-22 17:10:55 [INFO]: Epoch 086 - training loss: 0.2905, validation loss: 0.1289
2024-05-22 17:10:58 [INFO]: Epoch 087 - training loss: 0.2889, validation loss: 0.1281
2024-05-22 17:11:00 [INFO]: Epoch 088 - training loss: 0.2887, validation loss: 0.1276
2024-05-22 17:11:03 [INFO]: Epoch 089 - training loss: 0.2874, validation loss: 0.1273
2024-05-22 17:11:05 [INFO]: Epoch 090 - training loss: 0.2864, validation loss: 0.1268
2024-05-22 17:11:07 [INFO]: Epoch 091 - training loss: 0.2865, validation loss: 0.1263
2024-05-22 17:11:09 [INFO]: Epoch 092 - training loss: 0.2850, validation loss: 0.1256
2024-05-22 17:11:12 [INFO]: Epoch 093 - training loss: 0.2849, validation loss: 0.1254
2024-05-22 17:11:14 [INFO]: Epoch 094 - training loss: 0.2845, validation loss: 0.1247
2024-05-22 17:11:17 [INFO]: Epoch 095 - training loss: 0.2834, validation loss: 0.1244
2024-05-22 17:11:19 [INFO]: Epoch 096 - training loss: 0.2822, validation loss: 0.1238
2024-05-22 17:11:21 [INFO]: Epoch 097 - training loss: 0.2822, validation loss: 0.1234
2024-05-22 17:11:24 [INFO]: Epoch 098 - training loss: 0.2814, validation loss: 0.1233
2024-05-22 17:11:26 [INFO]: Epoch 099 - training loss: 0.2807, validation loss: 0.1226
2024-05-22 17:11:28 [INFO]: Epoch 100 - training loss: 0.2800, validation loss: 0.1222
2024-05-22 17:11:31 [INFO]: Epoch 101 - training loss: 0.2790, validation loss: 0.1219
2024-05-22 17:11:33 [INFO]: Epoch 102 - training loss: 0.2785, validation loss: 0.1215
2024-05-22 17:11:35 [INFO]: Epoch 103 - training loss: 0.2787, validation loss: 0.1212
2024-05-22 17:11:38 [INFO]: Epoch 104 - training loss: 0.2778, validation loss: 0.1205
2024-05-22 17:11:40 [INFO]: Epoch 105 - training loss: 0.2769, validation loss: 0.1200
2024-05-22 17:11:42 [INFO]: Epoch 106 - training loss: 0.2759, validation loss: 0.1199
2024-05-22 17:11:44 [INFO]: Epoch 107 - training loss: 0.2756, validation loss: 0.1194
2024-05-22 17:11:47 [INFO]: Epoch 108 - training loss: 0.2749, validation loss: 0.1191
2024-05-22 17:11:49 [INFO]: Epoch 109 - training loss: 0.2747, validation loss: 0.1187
2024-05-22 17:11:51 [INFO]: Epoch 110 - training loss: 0.2735, validation loss: 0.1183
2024-05-22 17:11:54 [INFO]: Epoch 111 - training loss: 0.2732, validation loss: 0.1181
2024-05-22 17:11:56 [INFO]: Epoch 112 - training loss: 0.2730, validation loss: 0.1176
2024-05-22 17:11:58 [INFO]: Epoch 113 - training loss: 0.2724, validation loss: 0.1173
2024-05-22 17:12:01 [INFO]: Epoch 114 - training loss: 0.2718, validation loss: 0.1168
2024-05-22 17:12:03 [INFO]: Epoch 115 - training loss: 0.2717, validation loss: 0.1166
2024-05-22 17:12:05 [INFO]: Epoch 116 - training loss: 0.2709, validation loss: 0.1161
2024-05-22 17:12:07 [INFO]: Epoch 117 - training loss: 0.2707, validation loss: 0.1159
2024-05-22 17:12:10 [INFO]: Epoch 118 - training loss: 0.2700, validation loss: 0.1157
2024-05-22 17:12:12 [INFO]: Epoch 119 - training loss: 0.2694, validation loss: 0.1151
2024-05-22 17:12:14 [INFO]: Epoch 120 - training loss: 0.2688, validation loss: 0.1150
2024-05-22 17:12:17 [INFO]: Epoch 121 - training loss: 0.2684, validation loss: 0.1144
2024-05-22 17:12:19 [INFO]: Epoch 122 - training loss: 0.2677, validation loss: 0.1143
2024-05-22 17:12:21 [INFO]: Epoch 123 - training loss: 0.2676, validation loss: 0.1140
2024-05-22 17:12:24 [INFO]: Epoch 124 - training loss: 0.2665, validation loss: 0.1138
2024-05-22 17:12:26 [INFO]: Epoch 125 - training loss: 0.2668, validation loss: 0.1135
2024-05-22 17:12:28 [INFO]: Epoch 126 - training loss: 0.2660, validation loss: 0.1131
2024-05-22 17:12:31 [INFO]: Epoch 127 - training loss: 0.2659, validation loss: 0.1129
2024-05-22 17:12:33 [INFO]: Epoch 128 - training loss: 0.2655, validation loss: 0.1123
2024-05-22 17:12:35 [INFO]: Epoch 129 - training loss: 0.2653, validation loss: 0.1120
2024-05-22 17:12:38 [INFO]: Epoch 130 - training loss: 0.2651, validation loss: 0.1120
2024-05-22 17:12:40 [INFO]: Epoch 131 - training loss: 0.2642, validation loss: 0.1117
2024-05-22 17:12:42 [INFO]: Epoch 132 - training loss: 0.2636, validation loss: 0.1113
2024-05-22 17:12:45 [INFO]: Epoch 133 - training loss: 0.2634, validation loss: 0.1111
2024-05-22 17:12:47 [INFO]: Epoch 134 - training loss: 0.2627, validation loss: 0.1109
2024-05-22 17:12:49 [INFO]: Epoch 135 - training loss: 0.2618, validation loss: 0.1105
2024-05-22 17:12:51 [INFO]: Epoch 136 - training loss: 0.2621, validation loss: 0.1103
2024-05-22 17:12:54 [INFO]: Epoch 137 - training loss: 0.2613, validation loss: 0.1101
2024-05-22 17:12:56 [INFO]: Epoch 138 - training loss: 0.2615, validation loss: 0.1100
2024-05-22 17:12:58 [INFO]: Epoch 139 - training loss: 0.2608, validation loss: 0.1097
2024-05-22 17:13:01 [INFO]: Epoch 140 - training loss: 0.2604, validation loss: 0.1094
2024-05-22 17:13:03 [INFO]: Epoch 141 - training loss: 0.2597, validation loss: 0.1089
2024-05-22 17:13:05 [INFO]: Epoch 142 - training loss: 0.2597, validation loss: 0.1087
2024-05-22 17:13:08 [INFO]: Epoch 143 - training loss: 0.2589, validation loss: 0.1085
2024-05-22 17:13:10 [INFO]: Epoch 144 - training loss: 0.2589, validation loss: 0.1083
2024-05-22 17:13:12 [INFO]: Epoch 145 - training loss: 0.2587, validation loss: 0.1081
2024-05-22 17:13:15 [INFO]: Epoch 146 - training loss: 0.2581, validation loss: 0.1079
2024-05-22 17:13:17 [INFO]: Epoch 147 - training loss: 0.2577, validation loss: 0.1077
2024-05-22 17:13:19 [INFO]: Epoch 148 - training loss: 0.2576, validation loss: 0.1073
2024-05-22 17:13:22 [INFO]: Epoch 149 - training loss: 0.2570, validation loss: 0.1072
2024-05-22 17:13:24 [INFO]: Epoch 150 - training loss: 0.2568, validation loss: 0.1070
2024-05-22 17:13:26 [INFO]: Epoch 151 - training loss: 0.2568, validation loss: 0.1067
2024-05-22 17:13:29 [INFO]: Epoch 152 - training loss: 0.2563, validation loss: 0.1065
2024-05-22 17:13:31 [INFO]: Epoch 153 - training loss: 0.2558, validation loss: 0.1064
2024-05-22 17:13:33 [INFO]: Epoch 154 - training loss: 0.2556, validation loss: 0.1061
2024-05-22 17:13:36 [INFO]: Epoch 155 - training loss: 0.2552, validation loss: 0.1058
2024-05-22 17:13:38 [INFO]: Epoch 156 - training loss: 0.2548, validation loss: 0.1057
2024-05-22 17:13:40 [INFO]: Epoch 157 - training loss: 0.2549, validation loss: 0.1055
2024-05-22 17:13:42 [INFO]: Epoch 158 - training loss: 0.2542, validation loss: 0.1054
2024-05-22 17:13:45 [INFO]: Epoch 159 - training loss: 0.2542, validation loss: 0.1051
2024-05-22 17:13:47 [INFO]: Epoch 160 - training loss: 0.2536, validation loss: 0.1049
2024-05-22 17:13:49 [INFO]: Epoch 161 - training loss: 0.2535, validation loss: 0.1047
2024-05-22 17:13:52 [INFO]: Epoch 162 - training loss: 0.2535, validation loss: 0.1046
2024-05-22 17:13:54 [INFO]: Epoch 163 - training loss: 0.2527, validation loss: 0.1042
2024-05-22 17:13:56 [INFO]: Epoch 164 - training loss: 0.2524, validation loss: 0.1042
2024-05-22 17:13:59 [INFO]: Epoch 165 - training loss: 0.2524, validation loss: 0.1041
2024-05-22 17:14:01 [INFO]: Epoch 166 - training loss: 0.2519, validation loss: 0.1037
2024-05-22 17:14:03 [INFO]: Epoch 167 - training loss: 0.2520, validation loss: 0.1037
2024-05-22 17:14:06 [INFO]: Epoch 168 - training loss: 0.2517, validation loss: 0.1034
2024-05-22 17:14:08 [INFO]: Epoch 169 - training loss: 0.2509, validation loss: 0.1034
2024-05-22 17:14:10 [INFO]: Epoch 170 - training loss: 0.2507, validation loss: 0.1032
2024-05-22 17:14:12 [INFO]: Epoch 171 - training loss: 0.2508, validation loss: 0.1029
2024-05-22 17:14:15 [INFO]: Epoch 172 - training loss: 0.2507, validation loss: 0.1027
2024-05-22 17:14:17 [INFO]: Epoch 173 - training loss: 0.2503, validation loss: 0.1027
2024-05-22 17:14:19 [INFO]: Epoch 174 - training loss: 0.2499, validation loss: 0.1024
2024-05-22 17:14:22 [INFO]: Epoch 175 - training loss: 0.2503, validation loss: 0.1022
2024-05-22 17:14:24 [INFO]: Epoch 176 - training loss: 0.2502, validation loss: 0.1021
2024-05-22 17:14:26 [INFO]: Epoch 177 - training loss: 0.2489, validation loss: 0.1021
2024-05-22 17:14:29 [INFO]: Epoch 178 - training loss: 0.2491, validation loss: 0.1019
2024-05-22 17:14:31 [INFO]: Epoch 179 - training loss: 0.2487, validation loss: 0.1018
2024-05-22 17:14:33 [INFO]: Epoch 180 - training loss: 0.2485, validation loss: 0.1017
2024-05-22 17:14:36 [INFO]: Epoch 181 - training loss: 0.2485, validation loss: 0.1014
2024-05-22 17:14:38 [INFO]: Epoch 182 - training loss: 0.2477, validation loss: 0.1014
2024-05-22 17:14:40 [INFO]: Epoch 183 - training loss: 0.2478, validation loss: 0.1012
2024-05-22 17:14:43 [INFO]: Epoch 184 - training loss: 0.2473, validation loss: 0.1011
2024-05-22 17:14:45 [INFO]: Epoch 185 - training loss: 0.2474, validation loss: 0.1010
2024-05-22 17:14:47 [INFO]: Epoch 186 - training loss: 0.2469, validation loss: 0.1009
2024-05-22 17:14:49 [INFO]: Epoch 187 - training loss: 0.2466, validation loss: 0.1007
2024-05-22 17:14:52 [INFO]: Epoch 188 - training loss: 0.2465, validation loss: 0.1004
2024-05-22 17:14:54 [INFO]: Epoch 189 - training loss: 0.2463, validation loss: 0.1002
2024-05-22 17:14:57 [INFO]: Epoch 190 - training loss: 0.2470, validation loss: 0.1003
2024-05-22 17:14:59 [INFO]: Epoch 191 - training loss: 0.2455, validation loss: 0.1002
2024-05-22 17:15:01 [INFO]: Epoch 192 - training loss: 0.2452, validation loss: 0.1000
2024-05-22 17:15:03 [INFO]: Epoch 193 - training loss: 0.2461, validation loss: 0.0998
2024-05-22 17:15:06 [INFO]: Epoch 194 - training loss: 0.2452, validation loss: 0.0998
2024-05-22 17:15:08 [INFO]: Epoch 195 - training loss: 0.2451, validation loss: 0.0998
2024-05-22 17:15:11 [INFO]: Epoch 196 - training loss: 0.2449, validation loss: 0.0997
2024-05-22 17:15:13 [INFO]: Epoch 197 - training loss: 0.2443, validation loss: 0.0994
2024-05-22 17:15:15 [INFO]: Epoch 198 - training loss: 0.2445, validation loss: 0.0993
2024-05-22 17:15:18 [INFO]: Epoch 199 - training loss: 0.2440, validation loss: 0.0993
2024-05-22 17:15:20 [INFO]: Epoch 200 - training loss: 0.2442, validation loss: 0.0992
2024-05-22 17:15:22 [INFO]: Epoch 201 - training loss: 0.2440, validation loss: 0.0991
2024-05-22 17:15:25 [INFO]: Epoch 202 - training loss: 0.2440, validation loss: 0.0989
2024-05-22 17:15:27 [INFO]: Epoch 203 - training loss: 0.2431, validation loss: 0.0987
2024-05-22 17:15:29 [INFO]: Epoch 204 - training loss: 0.2432, validation loss: 0.0986
2024-05-22 17:15:32 [INFO]: Epoch 205 - training loss: 0.2423, validation loss: 0.0986
2024-05-22 17:15:34 [INFO]: Epoch 206 - training loss: 0.2439, validation loss: 0.0984
2024-05-22 17:15:36 [INFO]: Epoch 207 - training loss: 0.2427, validation loss: 0.0982
2024-05-22 17:15:39 [INFO]: Epoch 208 - training loss: 0.2430, validation loss: 0.0983
2024-05-22 17:15:41 [INFO]: Epoch 209 - training loss: 0.2431, validation loss: 0.0981
2024-05-22 17:15:44 [INFO]: Epoch 210 - training loss: 0.2421, validation loss: 0.0979
2024-05-22 17:15:46 [INFO]: Epoch 211 - training loss: 0.2417, validation loss: 0.0978
2024-05-22 17:15:48 [INFO]: Epoch 212 - training loss: 0.2418, validation loss: 0.0979
2024-05-22 17:15:50 [INFO]: Epoch 213 - training loss: 0.2419, validation loss: 0.0977
2024-05-22 17:15:53 [INFO]: Epoch 214 - training loss: 0.2410, validation loss: 0.0975
2024-05-22 17:15:55 [INFO]: Epoch 215 - training loss: 0.2409, validation loss: 0.0977
2024-05-22 17:15:57 [INFO]: Epoch 216 - training loss: 0.2407, validation loss: 0.0975
2024-05-22 17:16:00 [INFO]: Epoch 217 - training loss: 0.2411, validation loss: 0.0973
2024-05-22 17:16:02 [INFO]: Epoch 218 - training loss: 0.2406, validation loss: 0.0973
2024-05-22 17:16:05 [INFO]: Epoch 219 - training loss: 0.2406, validation loss: 0.0973
2024-05-22 17:16:07 [INFO]: Epoch 220 - training loss: 0.2409, validation loss: 0.0972
2024-05-22 17:16:09 [INFO]: Epoch 221 - training loss: 0.2398, validation loss: 0.0970
2024-05-22 17:16:12 [INFO]: Epoch 222 - training loss: 0.2403, validation loss: 0.0968
2024-05-22 17:16:14 [INFO]: Epoch 223 - training loss: 0.2397, validation loss: 0.0967
2024-05-22 17:16:16 [INFO]: Epoch 224 - training loss: 0.2397, validation loss: 0.0968
2024-05-22 17:16:19 [INFO]: Epoch 225 - training loss: 0.2391, validation loss: 0.0965
2024-05-22 17:16:21 [INFO]: Epoch 226 - training loss: 0.2390, validation loss: 0.0965
2024-05-22 17:16:24 [INFO]: Epoch 227 - training loss: 0.2394, validation loss: 0.0966
2024-05-22 17:16:26 [INFO]: Epoch 228 - training loss: 0.2388, validation loss: 0.0964
2024-05-22 17:16:28 [INFO]: Epoch 229 - training loss: 0.2387, validation loss: 0.0963
2024-05-22 17:16:31 [INFO]: Epoch 230 - training loss: 0.2390, validation loss: 0.0963
2024-05-22 17:16:33 [INFO]: Epoch 231 - training loss: 0.2381, validation loss: 0.0961
2024-05-22 17:16:35 [INFO]: Epoch 232 - training loss: 0.2384, validation loss: 0.0960
2024-05-22 17:16:38 [INFO]: Epoch 233 - training loss: 0.2379, validation loss: 0.0961
2024-05-22 17:16:40 [INFO]: Epoch 234 - training loss: 0.2383, validation loss: 0.0959
2024-05-22 17:16:43 [INFO]: Epoch 235 - training loss: 0.2376, validation loss: 0.0957
2024-05-22 17:16:45 [INFO]: Epoch 236 - training loss: 0.2378, validation loss: 0.0957
2024-05-22 17:16:47 [INFO]: Epoch 237 - training loss: 0.2379, validation loss: 0.0959
2024-05-22 17:16:49 [INFO]: Epoch 238 - training loss: 0.2373, validation loss: 0.0957
2024-05-22 17:16:52 [INFO]: Epoch 239 - training loss: 0.2370, validation loss: 0.0956
2024-05-22 17:16:54 [INFO]: Epoch 240 - training loss: 0.2365, validation loss: 0.0955
2024-05-22 17:16:57 [INFO]: Epoch 241 - training loss: 0.2372, validation loss: 0.0953
2024-05-22 17:16:59 [INFO]: Epoch 242 - training loss: 0.2368, validation loss: 0.0954
2024-05-22 17:17:01 [INFO]: Epoch 243 - training loss: 0.2368, validation loss: 0.0952
2024-05-22 17:17:03 [INFO]: Epoch 244 - training loss: 0.2362, validation loss: 0.0952
2024-05-22 17:17:06 [INFO]: Epoch 245 - training loss: 0.2365, validation loss: 0.0952
2024-05-22 17:17:08 [INFO]: Epoch 246 - training loss: 0.2365, validation loss: 0.0950
2024-05-22 17:17:11 [INFO]: Epoch 247 - training loss: 0.2368, validation loss: 0.0951
2024-05-22 17:17:13 [INFO]: Epoch 248 - training loss: 0.2357, validation loss: 0.0949
2024-05-22 17:17:15 [INFO]: Epoch 249 - training loss: 0.2357, validation loss: 0.0950
2024-05-22 17:17:18 [INFO]: Epoch 250 - training loss: 0.2356, validation loss: 0.0949
2024-05-22 17:17:20 [INFO]: Epoch 251 - training loss: 0.2361, validation loss: 0.0947
2024-05-22 17:17:22 [INFO]: Epoch 252 - training loss: 0.2358, validation loss: 0.0950
2024-05-22 17:17:25 [INFO]: Epoch 253 - training loss: 0.2348, validation loss: 0.0945
2024-05-22 17:17:27 [INFO]: Epoch 254 - training loss: 0.2350, validation loss: 0.0947
2024-05-22 17:17:30 [INFO]: Epoch 255 - training loss: 0.2345, validation loss: 0.0944
2024-05-22 17:17:32 [INFO]: Epoch 256 - training loss: 0.2347, validation loss: 0.0945
2024-05-22 17:17:34 [INFO]: Epoch 257 - training loss: 0.2348, validation loss: 0.0945
2024-05-22 17:17:36 [INFO]: Epoch 258 - training loss: 0.2343, validation loss: 0.0943
2024-05-22 17:17:39 [INFO]: Epoch 259 - training loss: 0.2344, validation loss: 0.0942
2024-05-22 17:17:41 [INFO]: Epoch 260 - training loss: 0.2340, validation loss: 0.0943
2024-05-22 17:17:43 [INFO]: Epoch 261 - training loss: 0.2339, validation loss: 0.0942
2024-05-22 17:17:46 [INFO]: Epoch 262 - training loss: 0.2343, validation loss: 0.0943
2024-05-22 17:17:48 [INFO]: Epoch 263 - training loss: 0.2336, validation loss: 0.0939
2024-05-22 17:17:51 [INFO]: Epoch 264 - training loss: 0.2333, validation loss: 0.0941
2024-05-22 17:17:53 [INFO]: Epoch 265 - training loss: 0.2338, validation loss: 0.0940
2024-05-22 17:17:55 [INFO]: Epoch 266 - training loss: 0.2332, validation loss: 0.0939
2024-05-22 17:17:58 [INFO]: Epoch 267 - training loss: 0.2334, validation loss: 0.0939
2024-05-22 17:18:00 [INFO]: Epoch 268 - training loss: 0.2335, validation loss: 0.0938
2024-05-22 17:18:02 [INFO]: Epoch 269 - training loss: 0.2332, validation loss: 0.0938
2024-05-22 17:18:05 [INFO]: Epoch 270 - training loss: 0.2336, validation loss: 0.0937
2024-05-22 17:18:07 [INFO]: Epoch 271 - training loss: 0.2330, validation loss: 0.0936
2024-05-22 17:18:09 [INFO]: Epoch 272 - training loss: 0.2323, validation loss: 0.0938
2024-05-22 17:18:11 [INFO]: Epoch 273 - training loss: 0.2324, validation loss: 0.0936
2024-05-22 17:18:14 [INFO]: Epoch 274 - training loss: 0.2322, validation loss: 0.0935
2024-05-22 17:18:17 [INFO]: Epoch 275 - training loss: 0.2326, validation loss: 0.0935
2024-05-22 17:18:19 [INFO]: Epoch 276 - training loss: 0.2323, validation loss: 0.0934
2024-05-22 17:18:21 [INFO]: Epoch 277 - training loss: 0.2321, validation loss: 0.0935
2024-05-22 17:18:24 [INFO]: Epoch 278 - training loss: 0.2318, validation loss: 0.0933
2024-05-22 17:18:26 [INFO]: Epoch 279 - training loss: 0.2316, validation loss: 0.0934
2024-05-22 17:18:28 [INFO]: Epoch 280 - training loss: 0.2316, validation loss: 0.0933
2024-05-22 17:18:30 [INFO]: Epoch 281 - training loss: 0.2316, validation loss: 0.0933
2024-05-22 17:18:33 [INFO]: Epoch 282 - training loss: 0.2312, validation loss: 0.0933
2024-05-22 17:18:35 [INFO]: Epoch 283 - training loss: 0.2311, validation loss: 0.0930
2024-05-22 17:18:38 [INFO]: Epoch 284 - training loss: 0.2310, validation loss: 0.0931
2024-05-22 17:18:40 [INFO]: Epoch 285 - training loss: 0.2310, validation loss: 0.0931
2024-05-22 17:18:42 [INFO]: Epoch 286 - training loss: 0.2312, validation loss: 0.0930
2024-05-22 17:18:45 [INFO]: Epoch 287 - training loss: 0.2308, validation loss: 0.0930
2024-05-22 17:18:47 [INFO]: Epoch 288 - training loss: 0.2306, validation loss: 0.0930
2024-05-22 17:18:49 [INFO]: Epoch 289 - training loss: 0.2299, validation loss: 0.0929
2024-05-22 17:18:51 [INFO]: Epoch 290 - training loss: 0.2307, validation loss: 0.0929
2024-05-22 17:18:54 [INFO]: Epoch 291 - training loss: 0.2312, validation loss: 0.0928
2024-05-22 17:18:56 [INFO]: Epoch 292 - training loss: 0.2305, validation loss: 0.0928
2024-05-22 17:18:58 [INFO]: Epoch 293 - training loss: 0.2303, validation loss: 0.0931
2024-05-22 17:19:01 [INFO]: Epoch 294 - training loss: 0.2302, validation loss: 0.0926
2024-05-22 17:19:03 [INFO]: Epoch 295 - training loss: 0.2306, validation loss: 0.0927
2024-05-22 17:19:05 [INFO]: Epoch 296 - training loss: 0.2297, validation loss: 0.0926
2024-05-22 17:19:08 [INFO]: Epoch 297 - training loss: 0.2295, validation loss: 0.0924
2024-05-22 17:19:10 [INFO]: Epoch 298 - training loss: 0.2302, validation loss: 0.0926
2024-05-22 17:19:12 [INFO]: Epoch 299 - training loss: 0.2299, validation loss: 0.0924
2024-05-22 17:19:15 [INFO]: Epoch 300 - training loss: 0.2294, validation loss: 0.0926
2024-05-22 17:19:15 [INFO]: Finished training. The best model is from epoch#297.
2024-05-22 17:19:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/BRITS_air_quality/20240522_T170735/BRITS.pypots
2024-05-22 17:19:15 [INFO]: BRITS on Air-Quality: MAE=0.1413, MSE=0.1050
2024-05-22 17:19:15 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/BRITS_air_quality/imputation.pkl
2024-05-22 17:19:15 [INFO]: Using the given device: cuda:0
2024-05-22 17:19:15 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915
2024-05-22 17:19:15 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/tensorboard
2024-05-22 17:19:15 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-22 17:19:19 [INFO]: Epoch 001 - training loss: 1.4710, validation loss: 0.7819
2024-05-22 17:19:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch1_loss0.7819238007068634.pypots
2024-05-22 17:19:22 [INFO]: Epoch 002 - training loss: 1.0642, validation loss: 0.7205
2024-05-22 17:19:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch2_loss0.720486781001091.pypots
2024-05-22 17:19:25 [INFO]: Epoch 003 - training loss: 0.9983, validation loss: 0.7000
2024-05-22 17:19:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch3_loss0.699992573261261.pypots
2024-05-22 17:19:28 [INFO]: Epoch 004 - training loss: 0.9672, validation loss: 0.6860
2024-05-22 17:19:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch4_loss0.685977777838707.pypots
2024-05-22 17:19:31 [INFO]: Epoch 005 - training loss: 0.9613, validation loss: 0.6771
2024-05-22 17:19:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch5_loss0.6771334558725357.pypots
2024-05-22 17:19:34 [INFO]: Epoch 006 - training loss: 0.9658, validation loss: 0.6694
2024-05-22 17:19:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch6_loss0.6693621456623078.pypots
2024-05-22 17:19:37 [INFO]: Epoch 007 - training loss: 0.9524, validation loss: 0.6651
2024-05-22 17:19:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch7_loss0.6650593459606171.pypots
2024-05-22 17:19:41 [INFO]: Epoch 008 - training loss: 0.9383, validation loss: 0.6615
2024-05-22 17:19:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch8_loss0.6614803731441498.pypots
2024-05-22 17:19:44 [INFO]: Epoch 009 - training loss: 0.9303, validation loss: 0.6588
2024-05-22 17:19:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch9_loss0.6588328361511231.pypots
2024-05-22 17:19:47 [INFO]: Epoch 010 - training loss: 0.9168, validation loss: 0.6556
2024-05-22 17:19:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch10_loss0.6555686801671982.pypots
2024-05-22 17:19:50 [INFO]: Epoch 011 - training loss: 0.9369, validation loss: 0.6549
2024-05-22 17:19:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch11_loss0.6549494087696075.pypots
2024-05-22 17:19:53 [INFO]: Epoch 012 - training loss: 0.9216, validation loss: 0.6534
2024-05-22 17:19:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch12_loss0.6533635824918747.pypots
2024-05-22 17:19:56 [INFO]: Epoch 013 - training loss: 0.9063, validation loss: 0.6534
2024-05-22 17:19:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch13_loss0.6533721506595611.pypots
2024-05-22 17:19:59 [INFO]: Epoch 014 - training loss: 0.9284, validation loss: 0.6525
2024-05-22 17:19:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch14_loss0.6524587243795394.pypots
2024-05-22 17:20:02 [INFO]: Epoch 015 - training loss: 0.9381, validation loss: 0.6517
2024-05-22 17:20:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch15_loss0.6517030626535416.pypots
2024-05-22 17:20:05 [INFO]: Epoch 016 - training loss: 0.9324, validation loss: 0.6532
2024-05-22 17:20:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch16_loss0.6532471686601639.pypots
2024-05-22 17:20:08 [INFO]: Epoch 017 - training loss: 0.9206, validation loss: 0.6524
2024-05-22 17:20:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch17_loss0.652437511086464.pypots
2024-05-22 17:20:12 [INFO]: Epoch 018 - training loss: 0.9060, validation loss: 0.6516
2024-05-22 17:20:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch18_loss0.6516366690397263.pypots
2024-05-22 17:20:15 [INFO]: Epoch 019 - training loss: 0.9009, validation loss: 0.6508
2024-05-22 17:20:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch19_loss0.650828269124031.pypots
2024-05-22 17:20:18 [INFO]: Epoch 020 - training loss: 0.8955, validation loss: 0.6503
2024-05-22 17:20:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch20_loss0.6502800434827805.pypots
2024-05-22 17:20:21 [INFO]: Epoch 021 - training loss: 0.9096, validation loss: 0.6519
2024-05-22 17:20:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch21_loss0.6519154131412506.pypots
2024-05-22 17:20:24 [INFO]: Epoch 022 - training loss: 0.9026, validation loss: 0.6527
2024-05-22 17:20:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch22_loss0.6527110785245895.pypots
2024-05-22 17:20:27 [INFO]: Epoch 023 - training loss: 0.9016, validation loss: 0.6513
2024-05-22 17:20:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch23_loss0.6513127893209457.pypots
2024-05-22 17:20:30 [INFO]: Epoch 024 - training loss: 0.8911, validation loss: 0.6521
2024-05-22 17:20:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch24_loss0.652071624994278.pypots
2024-05-22 17:20:33 [INFO]: Epoch 025 - training loss: 0.8943, validation loss: 0.6545
2024-05-22 17:20:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch25_loss0.6545364707708359.pypots
2024-05-22 17:20:36 [INFO]: Epoch 026 - training loss: 0.8861, validation loss: 0.6535
2024-05-22 17:20:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch26_loss0.6534717112779618.pypots
2024-05-22 17:20:40 [INFO]: Epoch 027 - training loss: 0.8946, validation loss: 0.6531
2024-05-22 17:20:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch27_loss0.6530625879764557.pypots
2024-05-22 17:20:43 [INFO]: Epoch 028 - training loss: 0.8907, validation loss: 0.6597
2024-05-22 17:20:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch28_loss0.6596685707569122.pypots
2024-05-22 17:20:46 [INFO]: Epoch 029 - training loss: 0.8822, validation loss: 0.6557
2024-05-22 17:20:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch29_loss0.6556579232215881.pypots
2024-05-22 17:20:49 [INFO]: Epoch 030 - training loss: 0.8762, validation loss: 0.6576
2024-05-22 17:20:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN_epoch30_loss0.6576139450073242.pypots
2024-05-22 17:20:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:20:49 [INFO]: Finished training. The best model is from epoch#20.
2024-05-22 17:20:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/20240522_T171915/MRNN.pypots
2024-05-22 17:20:49 [INFO]: MRNN on Air-Quality: MAE=0.5220, MSE=0.6184
2024-05-22 17:20:49 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/MRNN_air_quality/imputation.pkl
2024-05-22 17:20:49 [INFO]: Using the given device: cpu
2024-05-22 17:20:49 [INFO]: LOCF on Air-Quality: MAE=0.2062, MSE=0.2674
2024-05-22 17:20:49 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_air_quality".
2024-05-22 17:20:49 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/LOCF_air_quality/imputation.pkl
2024-05-22 17:20:49 [INFO]: Median on Air-Quality: MAE=0.6602, MSE=1.0006
2024-05-22 17:20:49 [INFO]: Successfully created the given path "saved_results/round_0/Median_air_quality".
2024-05-22 17:20:49 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/Median_air_quality/imputation.pkl
2024-05-22 17:20:49 [INFO]: Mean on Air-Quality: MAE=0.6921, MSE=0.9434
2024-05-22 17:20:49 [INFO]: Successfully created the given path "saved_results/round_0/Mean_air_quality".
2024-05-22 17:20:49 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/Mean_air_quality/imputation.pkl
2024-05-22 17:20:49 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-22 17:20:50 [INFO]: Using the given device: cuda:0
2024-05-22 17:20:50 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/SAITS_air_quality/20240522_T172050
2024-05-22 17:20:50 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/SAITS_air_quality/20240522_T172050/tensorboard
2024-05-22 17:20:50 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-22 17:20:51 [INFO]: Epoch 001 - training loss: 1.0523, validation loss: 0.4898
2024-05-22 17:20:51 [INFO]: Epoch 002 - training loss: 0.7487, validation loss: 0.3751
2024-05-22 17:20:52 [INFO]: Epoch 003 - training loss: 0.6404, validation loss: 0.3048
2024-05-22 17:20:53 [INFO]: Epoch 004 - training loss: 0.5672, validation loss: 0.2605
2024-05-22 17:20:53 [INFO]: Epoch 005 - training loss: 0.5194, validation loss: 0.2340
2024-05-22 17:20:54 [INFO]: Epoch 006 - training loss: 0.4824, validation loss: 0.2214
2024-05-22 17:20:55 [INFO]: Epoch 007 - training loss: 0.4578, validation loss: 0.2125
2024-05-22 17:20:55 [INFO]: Epoch 008 - training loss: 0.4395, validation loss: 0.2068
2024-05-22 17:20:56 [INFO]: Epoch 009 - training loss: 0.4272, validation loss: 0.1993
2024-05-22 17:20:56 [INFO]: Epoch 010 - training loss: 0.4141, validation loss: 0.1947
2024-05-22 17:20:57 [INFO]: Epoch 011 - training loss: 0.4047, validation loss: 0.1922
2024-05-22 17:20:58 [INFO]: Epoch 012 - training loss: 0.3965, validation loss: 0.1870
2024-05-22 17:20:58 [INFO]: Epoch 013 - training loss: 0.3885, validation loss: 0.1825
2024-05-22 17:20:59 [INFO]: Epoch 014 - training loss: 0.3824, validation loss: 0.1801
2024-05-22 17:21:00 [INFO]: Epoch 015 - training loss: 0.3760, validation loss: 0.1787
2024-05-22 17:21:00 [INFO]: Epoch 016 - training loss: 0.3702, validation loss: 0.1771
2024-05-22 17:21:01 [INFO]: Epoch 017 - training loss: 0.3650, validation loss: 0.1741
2024-05-22 17:21:01 [INFO]: Epoch 018 - training loss: 0.3613, validation loss: 0.1721
2024-05-22 17:21:02 [INFO]: Epoch 019 - training loss: 0.3574, validation loss: 0.1721
2024-05-22 17:21:03 [INFO]: Epoch 020 - training loss: 0.3556, validation loss: 0.1692
2024-05-22 17:21:03 [INFO]: Epoch 021 - training loss: 0.3501, validation loss: 0.1678
2024-05-22 17:21:04 [INFO]: Epoch 022 - training loss: 0.3456, validation loss: 0.1648
2024-05-22 17:21:05 [INFO]: Epoch 023 - training loss: 0.3426, validation loss: 0.1639
2024-05-22 17:21:05 [INFO]: Epoch 024 - training loss: 0.3410, validation loss: 0.1620
2024-05-22 17:21:06 [INFO]: Epoch 025 - training loss: 0.3376, validation loss: 0.1609
2024-05-22 17:21:06 [INFO]: Epoch 026 - training loss: 0.3340, validation loss: 0.1595
2024-05-22 17:21:07 [INFO]: Epoch 027 - training loss: 0.3315, validation loss: 0.1579
2024-05-22 17:21:08 [INFO]: Epoch 028 - training loss: 0.3283, validation loss: 0.1568
2024-05-22 17:21:08 [INFO]: Epoch 029 - training loss: 0.3260, validation loss: 0.1561
2024-05-22 17:21:09 [INFO]: Epoch 030 - training loss: 0.3244, validation loss: 0.1548
2024-05-22 17:21:10 [INFO]: Epoch 031 - training loss: 0.3261, validation loss: 0.1535
2024-05-22 17:21:10 [INFO]: Epoch 032 - training loss: 0.3193, validation loss: 0.1506
2024-05-22 17:21:11 [INFO]: Epoch 033 - training loss: 0.3175, validation loss: 0.1493
2024-05-22 17:21:11 [INFO]: Epoch 034 - training loss: 0.3156, validation loss: 0.1484
2024-05-22 17:21:12 [INFO]: Epoch 035 - training loss: 0.3132, validation loss: 0.1472
2024-05-22 17:21:13 [INFO]: Epoch 036 - training loss: 0.3141, validation loss: 0.1478
2024-05-22 17:21:13 [INFO]: Epoch 037 - training loss: 0.3132, validation loss: 0.1455
2024-05-22 17:21:14 [INFO]: Epoch 038 - training loss: 0.3113, validation loss: 0.1444
2024-05-22 17:21:15 [INFO]: Epoch 039 - training loss: 0.3079, validation loss: 0.1431
2024-05-22 17:21:15 [INFO]: Epoch 040 - training loss: 0.3050, validation loss: 0.1420
2024-05-22 17:21:16 [INFO]: Epoch 041 - training loss: 0.3035, validation loss: 0.1403
2024-05-22 17:21:16 [INFO]: Epoch 042 - training loss: 0.3019, validation loss: 0.1401
2024-05-22 17:21:17 [INFO]: Epoch 043 - training loss: 0.3002, validation loss: 0.1392
2024-05-22 17:21:18 [INFO]: Epoch 044 - training loss: 0.2993, validation loss: 0.1372
2024-05-22 17:21:18 [INFO]: Epoch 045 - training loss: 0.2970, validation loss: 0.1366
2024-05-22 17:21:19 [INFO]: Epoch 046 - training loss: 0.2955, validation loss: 0.1366
2024-05-22 17:21:20 [INFO]: Epoch 047 - training loss: 0.2948, validation loss: 0.1349
2024-05-22 17:21:20 [INFO]: Epoch 048 - training loss: 0.2936, validation loss: 0.1346
2024-05-22 17:21:21 [INFO]: Epoch 049 - training loss: 0.2923, validation loss: 0.1337
2024-05-22 17:21:21 [INFO]: Epoch 050 - training loss: 0.2895, validation loss: 0.1335
2024-05-22 17:21:22 [INFO]: Epoch 051 - training loss: 0.2887, validation loss: 0.1332
2024-05-22 17:21:23 [INFO]: Epoch 052 - training loss: 0.2900, validation loss: 0.1327
2024-05-22 17:21:23 [INFO]: Epoch 053 - training loss: 0.2861, validation loss: 0.1311
2024-05-22 17:21:24 [INFO]: Epoch 054 - training loss: 0.2831, validation loss: 0.1307
2024-05-22 17:21:25 [INFO]: Epoch 055 - training loss: 0.2828, validation loss: 0.1290
2024-05-22 17:21:25 [INFO]: Epoch 056 - training loss: 0.2812, validation loss: 0.1286
2024-05-22 17:21:26 [INFO]: Epoch 057 - training loss: 0.2809, validation loss: 0.1279
2024-05-22 17:21:27 [INFO]: Epoch 058 - training loss: 0.2802, validation loss: 0.1284
2024-05-22 17:21:27 [INFO]: Epoch 059 - training loss: 0.2772, validation loss: 0.1275
2024-05-22 17:21:28 [INFO]: Epoch 060 - training loss: 0.2765, validation loss: 0.1271
2024-05-22 17:21:28 [INFO]: Epoch 061 - training loss: 0.2749, validation loss: 0.1253
2024-05-22 17:21:29 [INFO]: Epoch 062 - training loss: 0.2737, validation loss: 0.1258
2024-05-22 17:21:30 [INFO]: Epoch 063 - training loss: 0.2729, validation loss: 0.1248
2024-05-22 17:21:30 [INFO]: Epoch 064 - training loss: 0.2731, validation loss: 0.1248
2024-05-22 17:21:31 [INFO]: Epoch 065 - training loss: 0.2712, validation loss: 0.1244
2024-05-22 17:21:32 [INFO]: Epoch 066 - training loss: 0.2715, validation loss: 0.1230
2024-05-22 17:21:32 [INFO]: Epoch 067 - training loss: 0.2689, validation loss: 0.1234
2024-05-22 17:21:33 [INFO]: Epoch 068 - training loss: 0.2680, validation loss: 0.1234
2024-05-22 17:21:33 [INFO]: Epoch 069 - training loss: 0.2676, validation loss: 0.1224
2024-05-22 17:21:34 [INFO]: Epoch 070 - training loss: 0.2657, validation loss: 0.1223
2024-05-22 17:21:35 [INFO]: Epoch 071 - training loss: 0.2642, validation loss: 0.1221
2024-05-22 17:21:35 [INFO]: Epoch 072 - training loss: 0.2640, validation loss: 0.1215
2024-05-22 17:21:36 [INFO]: Epoch 073 - training loss: 0.2627, validation loss: 0.1214
2024-05-22 17:21:37 [INFO]: Epoch 074 - training loss: 0.2637, validation loss: 0.1209
2024-05-22 17:21:37 [INFO]: Epoch 075 - training loss: 0.2618, validation loss: 0.1210
2024-05-22 17:21:38 [INFO]: Epoch 076 - training loss: 0.2601, validation loss: 0.1195
2024-05-22 17:21:38 [INFO]: Epoch 077 - training loss: 0.2598, validation loss: 0.1194
2024-05-22 17:21:39 [INFO]: Epoch 078 - training loss: 0.2595, validation loss: 0.1192
2024-05-22 17:21:40 [INFO]: Epoch 079 - training loss: 0.2577, validation loss: 0.1194
2024-05-22 17:21:40 [INFO]: Epoch 080 - training loss: 0.2576, validation loss: 0.1192
2024-05-22 17:21:41 [INFO]: Epoch 081 - training loss: 0.2566, validation loss: 0.1185
2024-05-22 17:21:42 [INFO]: Epoch 082 - training loss: 0.2584, validation loss: 0.1175
2024-05-22 17:21:42 [INFO]: Epoch 083 - training loss: 0.2562, validation loss: 0.1172
2024-05-22 17:21:43 [INFO]: Epoch 084 - training loss: 0.2552, validation loss: 0.1180
2024-05-22 17:21:43 [INFO]: Epoch 085 - training loss: 0.2531, validation loss: 0.1175
2024-05-22 17:21:44 [INFO]: Epoch 086 - training loss: 0.2537, validation loss: 0.1166
2024-05-22 17:21:45 [INFO]: Epoch 087 - training loss: 0.2544, validation loss: 0.1165
2024-05-22 17:21:45 [INFO]: Epoch 088 - training loss: 0.2530, validation loss: 0.1172
2024-05-22 17:21:46 [INFO]: Epoch 089 - training loss: 0.2524, validation loss: 0.1163
2024-05-22 17:21:47 [INFO]: Epoch 090 - training loss: 0.2510, validation loss: 0.1161
2024-05-22 17:21:47 [INFO]: Epoch 091 - training loss: 0.2494, validation loss: 0.1161
2024-05-22 17:21:48 [INFO]: Epoch 092 - training loss: 0.2494, validation loss: 0.1152
2024-05-22 17:21:48 [INFO]: Epoch 093 - training loss: 0.2492, validation loss: 0.1150
2024-05-22 17:21:49 [INFO]: Epoch 094 - training loss: 0.2488, validation loss: 0.1149
2024-05-22 17:21:50 [INFO]: Epoch 095 - training loss: 0.2473, validation loss: 0.1143
2024-05-22 17:21:50 [INFO]: Epoch 096 - training loss: 0.2469, validation loss: 0.1142
2024-05-22 17:21:51 [INFO]: Epoch 097 - training loss: 0.2460, validation loss: 0.1142
2024-05-22 17:21:52 [INFO]: Epoch 098 - training loss: 0.2457, validation loss: 0.1140
2024-05-22 17:21:52 [INFO]: Epoch 099 - training loss: 0.2459, validation loss: 0.1145
2024-05-22 17:21:53 [INFO]: Epoch 100 - training loss: 0.2474, validation loss: 0.1135
2024-05-22 17:21:53 [INFO]: Epoch 101 - training loss: 0.2468, validation loss: 0.1131
2024-05-22 17:21:54 [INFO]: Epoch 102 - training loss: 0.2432, validation loss: 0.1135
2024-05-22 17:21:55 [INFO]: Epoch 103 - training loss: 0.2433, validation loss: 0.1131
2024-05-22 17:21:55 [INFO]: Epoch 104 - training loss: 0.2445, validation loss: 0.1120
2024-05-22 17:21:56 [INFO]: Epoch 105 - training loss: 0.2416, validation loss: 0.1125
2024-05-22 17:21:57 [INFO]: Epoch 106 - training loss: 0.2405, validation loss: 0.1126
2024-05-22 17:21:57 [INFO]: Epoch 107 - training loss: 0.2405, validation loss: 0.1117
2024-05-22 17:21:58 [INFO]: Epoch 108 - training loss: 0.2406, validation loss: 0.1120
2024-05-22 17:21:58 [INFO]: Epoch 109 - training loss: 0.2405, validation loss: 0.1110
2024-05-22 17:21:59 [INFO]: Epoch 110 - training loss: 0.2389, validation loss: 0.1113
2024-05-22 17:22:00 [INFO]: Epoch 111 - training loss: 0.2386, validation loss: 0.1114
2024-05-22 17:22:00 [INFO]: Epoch 112 - training loss: 0.2375, validation loss: 0.1100
2024-05-22 17:22:01 [INFO]: Epoch 113 - training loss: 0.2380, validation loss: 0.1109
2024-05-22 17:22:02 [INFO]: Epoch 114 - training loss: 0.2371, validation loss: 0.1108
2024-05-22 17:22:02 [INFO]: Epoch 115 - training loss: 0.2371, validation loss: 0.1099
2024-05-22 17:22:03 [INFO]: Epoch 116 - training loss: 0.2367, validation loss: 0.1099
2024-05-22 17:22:03 [INFO]: Epoch 117 - training loss: 0.2365, validation loss: 0.1096
2024-05-22 17:22:04 [INFO]: Epoch 118 - training loss: 0.2357, validation loss: 0.1101
2024-05-22 17:22:05 [INFO]: Epoch 119 - training loss: 0.2347, validation loss: 0.1093
2024-05-22 17:22:05 [INFO]: Epoch 120 - training loss: 0.2342, validation loss: 0.1101
2024-05-22 17:22:06 [INFO]: Epoch 121 - training loss: 0.2346, validation loss: 0.1095
2024-05-22 17:22:07 [INFO]: Epoch 122 - training loss: 0.2337, validation loss: 0.1094
2024-05-22 17:22:07 [INFO]: Epoch 123 - training loss: 0.2340, validation loss: 0.1086
2024-05-22 17:22:08 [INFO]: Epoch 124 - training loss: 0.2327, validation loss: 0.1088
2024-05-22 17:22:08 [INFO]: Epoch 125 - training loss: 0.2316, validation loss: 0.1082
2024-05-22 17:22:09 [INFO]: Epoch 126 - training loss: 0.2322, validation loss: 0.1082
2024-05-22 17:22:10 [INFO]: Epoch 127 - training loss: 0.2314, validation loss: 0.1082
2024-05-22 17:22:10 [INFO]: Epoch 128 - training loss: 0.2321, validation loss: 0.1078
2024-05-22 17:22:11 [INFO]: Epoch 129 - training loss: 0.2303, validation loss: 0.1079
2024-05-22 17:22:12 [INFO]: Epoch 130 - training loss: 0.2310, validation loss: 0.1080
2024-05-22 17:22:12 [INFO]: Epoch 131 - training loss: 0.2320, validation loss: 0.1077
2024-05-22 17:22:13 [INFO]: Epoch 132 - training loss: 0.2292, validation loss: 0.1075
2024-05-22 17:22:13 [INFO]: Epoch 133 - training loss: 0.2292, validation loss: 0.1072
2024-05-22 17:22:14 [INFO]: Epoch 134 - training loss: 0.2284, validation loss: 0.1075
2024-05-22 17:22:15 [INFO]: Epoch 135 - training loss: 0.2283, validation loss: 0.1076
2024-05-22 17:22:15 [INFO]: Epoch 136 - training loss: 0.2273, validation loss: 0.1065
2024-05-22 17:22:16 [INFO]: Epoch 137 - training loss: 0.2274, validation loss: 0.1064
2024-05-22 17:22:17 [INFO]: Epoch 138 - training loss: 0.2260, validation loss: 0.1062
2024-05-22 17:22:17 [INFO]: Epoch 139 - training loss: 0.2253, validation loss: 0.1078
2024-05-22 17:22:18 [INFO]: Epoch 140 - training loss: 0.2271, validation loss: 0.1063
2024-05-22 17:22:18 [INFO]: Epoch 141 - training loss: 0.2254, validation loss: 0.1062
2024-05-22 17:22:19 [INFO]: Epoch 142 - training loss: 0.2250, validation loss: 0.1059
2024-05-22 17:22:20 [INFO]: Epoch 143 - training loss: 0.2252, validation loss: 0.1069
2024-05-22 17:22:20 [INFO]: Epoch 144 - training loss: 0.2249, validation loss: 0.1052
2024-05-22 17:22:21 [INFO]: Epoch 145 - training loss: 0.2240, validation loss: 0.1049
2024-05-22 17:22:22 [INFO]: Epoch 146 - training loss: 0.2239, validation loss: 0.1047
2024-05-22 17:22:22 [INFO]: Epoch 147 - training loss: 0.2244, validation loss: 0.1067
2024-05-22 17:22:23 [INFO]: Epoch 148 - training loss: 0.2244, validation loss: 0.1044
2024-05-22 17:22:23 [INFO]: Epoch 149 - training loss: 0.2221, validation loss: 0.1037
2024-05-22 17:22:24 [INFO]: Epoch 150 - training loss: 0.2233, validation loss: 0.1041
2024-05-22 17:22:25 [INFO]: Epoch 151 - training loss: 0.2221, validation loss: 0.1046
2024-05-22 17:22:25 [INFO]: Epoch 152 - training loss: 0.2205, validation loss: 0.1046
2024-05-22 17:22:26 [INFO]: Epoch 153 - training loss: 0.2212, validation loss: 0.1042
2024-05-22 17:22:27 [INFO]: Epoch 154 - training loss: 0.2205, validation loss: 0.1039
2024-05-22 17:22:27 [INFO]: Epoch 155 - training loss: 0.2197, validation loss: 0.1037
2024-05-22 17:22:28 [INFO]: Epoch 156 - training loss: 0.2201, validation loss: 0.1038
2024-05-22 17:22:28 [INFO]: Epoch 157 - training loss: 0.2199, validation loss: 0.1028
2024-05-22 17:22:29 [INFO]: Epoch 158 - training loss: 0.2196, validation loss: 0.1033
2024-05-22 17:22:30 [INFO]: Epoch 159 - training loss: 0.2203, validation loss: 0.1055
2024-05-22 17:22:30 [INFO]: Epoch 160 - training loss: 0.2204, validation loss: 0.1025
2024-05-22 17:22:31 [INFO]: Epoch 161 - training loss: 0.2208, validation loss: 0.1036
2024-05-22 17:22:32 [INFO]: Epoch 162 - training loss: 0.2186, validation loss: 0.1027
2024-05-22 17:22:32 [INFO]: Epoch 163 - training loss: 0.2170, validation loss: 0.1012
2024-05-22 17:22:33 [INFO]: Epoch 164 - training loss: 0.2180, validation loss: 0.1026
2024-05-22 17:22:33 [INFO]: Epoch 165 - training loss: 0.2183, validation loss: 0.1027
2024-05-22 17:22:34 [INFO]: Epoch 166 - training loss: 0.2176, validation loss: 0.1024
2024-05-22 17:22:35 [INFO]: Epoch 167 - training loss: 0.2179, validation loss: 0.1014
2024-05-22 17:22:35 [INFO]: Epoch 168 - training loss: 0.2161, validation loss: 0.1021
2024-05-22 17:22:36 [INFO]: Epoch 169 - training loss: 0.2158, validation loss: 0.1022
2024-05-22 17:22:37 [INFO]: Epoch 170 - training loss: 0.2147, validation loss: 0.1017
2024-05-22 17:22:37 [INFO]: Epoch 171 - training loss: 0.2160, validation loss: 0.1013
2024-05-22 17:22:38 [INFO]: Epoch 172 - training loss: 0.2141, validation loss: 0.1015
2024-05-22 17:22:39 [INFO]: Epoch 173 - training loss: 0.2146, validation loss: 0.1015
2024-05-22 17:22:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:22:39 [INFO]: Finished training. The best model is from epoch#163.
2024-05-22 17:22:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/SAITS_air_quality/20240522_T172050/SAITS.pypots
2024-05-22 17:22:39 [INFO]: SAITS on Air-Quality: MAE=0.1485, MSE=0.1094
2024-05-22 17:22:39 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/SAITS_air_quality/imputation.pkl
2024-05-22 17:22:39 [INFO]: Using the given device: cuda:0
2024-05-22 17:22:39 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/Transformer_air_quality/20240522_T172239
2024-05-22 17:22:39 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/Transformer_air_quality/20240522_T172239/tensorboard
2024-05-22 17:22:39 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-22 17:22:39 [INFO]: Epoch 001 - training loss: 0.9045, validation loss: 0.4381
2024-05-22 17:22:39 [INFO]: Epoch 002 - training loss: 0.5709, validation loss: 0.3319
2024-05-22 17:22:40 [INFO]: Epoch 003 - training loss: 0.4888, validation loss: 0.2705
2024-05-22 17:22:40 [INFO]: Epoch 004 - training loss: 0.4419, validation loss: 0.2378
2024-05-22 17:22:40 [INFO]: Epoch 005 - training loss: 0.4127, validation loss: 0.2266
2024-05-22 17:22:40 [INFO]: Epoch 006 - training loss: 0.3938, validation loss: 0.2165
2024-05-22 17:22:41 [INFO]: Epoch 007 - training loss: 0.3774, validation loss: 0.2105
2024-05-22 17:22:41 [INFO]: Epoch 008 - training loss: 0.3665, validation loss: 0.2038
2024-05-22 17:22:41 [INFO]: Epoch 009 - training loss: 0.3550, validation loss: 0.1983
2024-05-22 17:22:42 [INFO]: Epoch 010 - training loss: 0.3471, validation loss: 0.1949
2024-05-22 17:22:42 [INFO]: Epoch 011 - training loss: 0.3413, validation loss: 0.1882
2024-05-22 17:22:42 [INFO]: Epoch 012 - training loss: 0.3384, validation loss: 0.1848
2024-05-22 17:22:42 [INFO]: Epoch 013 - training loss: 0.3295, validation loss: 0.1815
2024-05-22 17:22:43 [INFO]: Epoch 014 - training loss: 0.3264, validation loss: 0.1786
2024-05-22 17:22:43 [INFO]: Epoch 015 - training loss: 0.3240, validation loss: 0.1746
2024-05-22 17:22:43 [INFO]: Epoch 016 - training loss: 0.3206, validation loss: 0.1725
2024-05-22 17:22:44 [INFO]: Epoch 017 - training loss: 0.3171, validation loss: 0.1695
2024-05-22 17:22:44 [INFO]: Epoch 018 - training loss: 0.3159, validation loss: 0.1685
2024-05-22 17:22:44 [INFO]: Epoch 019 - training loss: 0.3090, validation loss: 0.1645
2024-05-22 17:22:44 [INFO]: Epoch 020 - training loss: 0.3072, validation loss: 0.1638
2024-05-22 17:22:45 [INFO]: Epoch 021 - training loss: 0.3040, validation loss: 0.1631
2024-05-22 17:22:45 [INFO]: Epoch 022 - training loss: 0.2993, validation loss: 0.1592
2024-05-22 17:22:45 [INFO]: Epoch 023 - training loss: 0.2997, validation loss: 0.1600
2024-05-22 17:22:45 [INFO]: Epoch 024 - training loss: 0.2976, validation loss: 0.1583
2024-05-22 17:22:46 [INFO]: Epoch 025 - training loss: 0.2946, validation loss: 0.1572
2024-05-22 17:22:46 [INFO]: Epoch 026 - training loss: 0.2942, validation loss: 0.1572
2024-05-22 17:22:46 [INFO]: Epoch 027 - training loss: 0.2918, validation loss: 0.1550
2024-05-22 17:22:47 [INFO]: Epoch 028 - training loss: 0.2894, validation loss: 0.1539
2024-05-22 17:22:47 [INFO]: Epoch 029 - training loss: 0.2860, validation loss: 0.1530
2024-05-22 17:22:47 [INFO]: Epoch 030 - training loss: 0.2859, validation loss: 0.1534
2024-05-22 17:22:47 [INFO]: Epoch 031 - training loss: 0.2838, validation loss: 0.1528
2024-05-22 17:22:48 [INFO]: Epoch 032 - training loss: 0.2848, validation loss: 0.1526
2024-05-22 17:22:48 [INFO]: Epoch 033 - training loss: 0.2836, validation loss: 0.1522
2024-05-22 17:22:48 [INFO]: Epoch 034 - training loss: 0.2809, validation loss: 0.1506
2024-05-22 17:22:49 [INFO]: Epoch 035 - training loss: 0.2793, validation loss: 0.1500
2024-05-22 17:22:49 [INFO]: Epoch 036 - training loss: 0.2841, validation loss: 0.1512
2024-05-22 17:22:49 [INFO]: Epoch 037 - training loss: 0.2795, validation loss: 0.1521
2024-05-22 17:22:49 [INFO]: Epoch 038 - training loss: 0.2783, validation loss: 0.1511
2024-05-22 17:22:50 [INFO]: Epoch 039 - training loss: 0.2767, validation loss: 0.1481
2024-05-22 17:22:50 [INFO]: Epoch 040 - training loss: 0.2755, validation loss: 0.1469
2024-05-22 17:22:50 [INFO]: Epoch 041 - training loss: 0.2743, validation loss: 0.1474
2024-05-22 17:22:51 [INFO]: Epoch 042 - training loss: 0.2718, validation loss: 0.1477
2024-05-22 17:22:51 [INFO]: Epoch 043 - training loss: 0.2696, validation loss: 0.1481
2024-05-22 17:22:51 [INFO]: Epoch 044 - training loss: 0.2710, validation loss: 0.1461
2024-05-22 17:22:51 [INFO]: Epoch 045 - training loss: 0.2700, validation loss: 0.1467
2024-05-22 17:22:52 [INFO]: Epoch 046 - training loss: 0.2696, validation loss: 0.1450
2024-05-22 17:22:52 [INFO]: Epoch 047 - training loss: 0.2667, validation loss: 0.1458
2024-05-22 17:22:52 [INFO]: Epoch 048 - training loss: 0.2648, validation loss: 0.1453
2024-05-22 17:22:52 [INFO]: Epoch 049 - training loss: 0.2665, validation loss: 0.1443
2024-05-22 17:22:53 [INFO]: Epoch 050 - training loss: 0.2649, validation loss: 0.1452
2024-05-22 17:22:53 [INFO]: Epoch 051 - training loss: 0.2612, validation loss: 0.1441
2024-05-22 17:22:53 [INFO]: Epoch 052 - training loss: 0.2609, validation loss: 0.1428
2024-05-22 17:22:54 [INFO]: Epoch 053 - training loss: 0.2621, validation loss: 0.1423
2024-05-22 17:22:54 [INFO]: Epoch 054 - training loss: 0.2624, validation loss: 0.1428
2024-05-22 17:22:54 [INFO]: Epoch 055 - training loss: 0.2602, validation loss: 0.1416
2024-05-22 17:22:54 [INFO]: Epoch 056 - training loss: 0.2594, validation loss: 0.1424
2024-05-22 17:22:55 [INFO]: Epoch 057 - training loss: 0.2580, validation loss: 0.1432
2024-05-22 17:22:55 [INFO]: Epoch 058 - training loss: 0.2580, validation loss: 0.1409
2024-05-22 17:22:55 [INFO]: Epoch 059 - training loss: 0.2553, validation loss: 0.1422
2024-05-22 17:22:56 [INFO]: Epoch 060 - training loss: 0.2570, validation loss: 0.1418
2024-05-22 17:22:56 [INFO]: Epoch 061 - training loss: 0.2566, validation loss: 0.1425
2024-05-22 17:22:56 [INFO]: Epoch 062 - training loss: 0.2541, validation loss: 0.1410
2024-05-22 17:22:56 [INFO]: Epoch 063 - training loss: 0.2522, validation loss: 0.1408
2024-05-22 17:22:57 [INFO]: Epoch 064 - training loss: 0.2511, validation loss: 0.1412
2024-05-22 17:22:57 [INFO]: Epoch 065 - training loss: 0.2511, validation loss: 0.1383
2024-05-22 17:22:57 [INFO]: Epoch 066 - training loss: 0.2498, validation loss: 0.1394
2024-05-22 17:22:58 [INFO]: Epoch 067 - training loss: 0.2497, validation loss: 0.1396
2024-05-22 17:22:58 [INFO]: Epoch 068 - training loss: 0.2492, validation loss: 0.1391
2024-05-22 17:22:58 [INFO]: Epoch 069 - training loss: 0.2490, validation loss: 0.1413
2024-05-22 17:22:58 [INFO]: Epoch 070 - training loss: 0.2486, validation loss: 0.1377
2024-05-22 17:22:59 [INFO]: Epoch 071 - training loss: 0.2491, validation loss: 0.1409
2024-05-22 17:22:59 [INFO]: Epoch 072 - training loss: 0.2489, validation loss: 0.1366
2024-05-22 17:22:59 [INFO]: Epoch 073 - training loss: 0.2462, validation loss: 0.1375
2024-05-22 17:22:59 [INFO]: Epoch 074 - training loss: 0.2463, validation loss: 0.1382
2024-05-22 17:23:00 [INFO]: Epoch 075 - training loss: 0.2452, validation loss: 0.1360
2024-05-22 17:23:00 [INFO]: Epoch 076 - training loss: 0.2419, validation loss: 0.1377
2024-05-22 17:23:00 [INFO]: Epoch 077 - training loss: 0.2453, validation loss: 0.1377
2024-05-22 17:23:01 [INFO]: Epoch 078 - training loss: 0.2486, validation loss: 0.1367
2024-05-22 17:23:01 [INFO]: Epoch 079 - training loss: 0.2456, validation loss: 0.1365
2024-05-22 17:23:01 [INFO]: Epoch 080 - training loss: 0.2417, validation loss: 0.1369
2024-05-22 17:23:01 [INFO]: Epoch 081 - training loss: 0.2414, validation loss: 0.1346
2024-05-22 17:23:02 [INFO]: Epoch 082 - training loss: 0.2401, validation loss: 0.1343
2024-05-22 17:23:02 [INFO]: Epoch 083 - training loss: 0.2402, validation loss: 0.1345
2024-05-22 17:23:02 [INFO]: Epoch 084 - training loss: 0.2388, validation loss: 0.1336
2024-05-22 17:23:03 [INFO]: Epoch 085 - training loss: 0.2414, validation loss: 0.1372
2024-05-22 17:23:03 [INFO]: Epoch 086 - training loss: 0.2394, validation loss: 0.1341
2024-05-22 17:23:03 [INFO]: Epoch 087 - training loss: 0.2373, validation loss: 0.1332
2024-05-22 17:23:03 [INFO]: Epoch 088 - training loss: 0.2355, validation loss: 0.1324
2024-05-22 17:23:04 [INFO]: Epoch 089 - training loss: 0.2355, validation loss: 0.1320
2024-05-22 17:23:04 [INFO]: Epoch 090 - training loss: 0.2339, validation loss: 0.1317
2024-05-22 17:23:04 [INFO]: Epoch 091 - training loss: 0.2337, validation loss: 0.1336
2024-05-22 17:23:05 [INFO]: Epoch 092 - training loss: 0.2367, validation loss: 0.1327
2024-05-22 17:23:05 [INFO]: Epoch 093 - training loss: 0.2345, validation loss: 0.1336
2024-05-22 17:23:05 [INFO]: Epoch 094 - training loss: 0.2332, validation loss: 0.1312
2024-05-22 17:23:05 [INFO]: Epoch 095 - training loss: 0.2315, validation loss: 0.1332
2024-05-22 17:23:06 [INFO]: Epoch 096 - training loss: 0.2314, validation loss: 0.1314
2024-05-22 17:23:06 [INFO]: Epoch 097 - training loss: 0.2311, validation loss: 0.1309
2024-05-22 17:23:06 [INFO]: Epoch 098 - training loss: 0.2306, validation loss: 0.1296
2024-05-22 17:23:06 [INFO]: Epoch 099 - training loss: 0.2316, validation loss: 0.1344
2024-05-22 17:23:07 [INFO]: Epoch 100 - training loss: 0.2331, validation loss: 0.1303
2024-05-22 17:23:07 [INFO]: Epoch 101 - training loss: 0.2293, validation loss: 0.1294
2024-05-22 17:23:07 [INFO]: Epoch 102 - training loss: 0.2306, validation loss: 0.1304
2024-05-22 17:23:08 [INFO]: Epoch 103 - training loss: 0.2293, validation loss: 0.1288
2024-05-22 17:23:08 [INFO]: Epoch 104 - training loss: 0.2279, validation loss: 0.1291
2024-05-22 17:23:08 [INFO]: Epoch 105 - training loss: 0.2284, validation loss: 0.1279
2024-05-22 17:23:08 [INFO]: Epoch 106 - training loss: 0.2296, validation loss: 0.1278
2024-05-22 17:23:09 [INFO]: Epoch 107 - training loss: 0.2264, validation loss: 0.1313
2024-05-22 17:23:09 [INFO]: Epoch 108 - training loss: 0.2263, validation loss: 0.1286
2024-05-22 17:23:09 [INFO]: Epoch 109 - training loss: 0.2247, validation loss: 0.1288
2024-05-22 17:23:10 [INFO]: Epoch 110 - training loss: 0.2236, validation loss: 0.1287
2024-05-22 17:23:10 [INFO]: Epoch 111 - training loss: 0.2247, validation loss: 0.1279
2024-05-22 17:23:10 [INFO]: Epoch 112 - training loss: 0.2255, validation loss: 0.1280
2024-05-22 17:23:10 [INFO]: Epoch 113 - training loss: 0.2265, validation loss: 0.1280
2024-05-22 17:23:11 [INFO]: Epoch 114 - training loss: 0.2249, validation loss: 0.1309
2024-05-22 17:23:11 [INFO]: Epoch 115 - training loss: 0.2232, validation loss: 0.1290
2024-05-22 17:23:11 [INFO]: Epoch 116 - training loss: 0.2251, validation loss: 0.1254
2024-05-22 17:23:11 [INFO]: Epoch 117 - training loss: 0.2222, validation loss: 0.1269
2024-05-22 17:23:12 [INFO]: Epoch 118 - training loss: 0.2198, validation loss: 0.1263
2024-05-22 17:23:12 [INFO]: Epoch 119 - training loss: 0.2217, validation loss: 0.1274
2024-05-22 17:23:12 [INFO]: Epoch 120 - training loss: 0.2246, validation loss: 0.1270
2024-05-22 17:23:13 [INFO]: Epoch 121 - training loss: 0.2205, validation loss: 0.1271
2024-05-22 17:23:13 [INFO]: Epoch 122 - training loss: 0.2192, validation loss: 0.1253
2024-05-22 17:23:13 [INFO]: Epoch 123 - training loss: 0.2170, validation loss: 0.1255
2024-05-22 17:23:13 [INFO]: Epoch 124 - training loss: 0.2175, validation loss: 0.1271
2024-05-22 17:23:14 [INFO]: Epoch 125 - training loss: 0.2198, validation loss: 0.1277
2024-05-22 17:23:14 [INFO]: Epoch 126 - training loss: 0.2184, validation loss: 0.1242
2024-05-22 17:23:14 [INFO]: Epoch 127 - training loss: 0.2205, validation loss: 0.1272
2024-05-22 17:23:15 [INFO]: Epoch 128 - training loss: 0.2178, validation loss: 0.1255
2024-05-22 17:23:15 [INFO]: Epoch 129 - training loss: 0.2158, validation loss: 0.1257
2024-05-22 17:23:15 [INFO]: Epoch 130 - training loss: 0.2187, validation loss: 0.1258
2024-05-22 17:23:15 [INFO]: Epoch 131 - training loss: 0.2195, validation loss: 0.1234
2024-05-22 17:23:16 [INFO]: Epoch 132 - training loss: 0.2178, validation loss: 0.1241
2024-05-22 17:23:16 [INFO]: Epoch 133 - training loss: 0.2195, validation loss: 0.1237
2024-05-22 17:23:16 [INFO]: Epoch 134 - training loss: 0.2164, validation loss: 0.1241
2024-05-22 17:23:17 [INFO]: Epoch 135 - training loss: 0.2158, validation loss: 0.1221
2024-05-22 17:23:17 [INFO]: Epoch 136 - training loss: 0.2181, validation loss: 0.1226
2024-05-22 17:23:17 [INFO]: Epoch 137 - training loss: 0.2151, validation loss: 0.1233
2024-05-22 17:23:17 [INFO]: Epoch 138 - training loss: 0.2129, validation loss: 0.1244
2024-05-22 17:23:18 [INFO]: Epoch 139 - training loss: 0.2144, validation loss: 0.1233
2024-05-22 17:23:18 [INFO]: Epoch 140 - training loss: 0.2131, validation loss: 0.1238
2024-05-22 17:23:18 [INFO]: Epoch 141 - training loss: 0.2115, validation loss: 0.1217
2024-05-22 17:23:18 [INFO]: Epoch 142 - training loss: 0.2120, validation loss: 0.1245
2024-05-22 17:23:19 [INFO]: Epoch 143 - training loss: 0.2119, validation loss: 0.1227
2024-05-22 17:23:19 [INFO]: Epoch 144 - training loss: 0.2115, validation loss: 0.1223
2024-05-22 17:23:19 [INFO]: Epoch 145 - training loss: 0.2109, validation loss: 0.1229
2024-05-22 17:23:20 [INFO]: Epoch 146 - training loss: 0.2112, validation loss: 0.1227
2024-05-22 17:23:20 [INFO]: Epoch 147 - training loss: 0.2108, validation loss: 0.1232
2024-05-22 17:23:20 [INFO]: Epoch 148 - training loss: 0.2123, validation loss: 0.1220
2024-05-22 17:23:20 [INFO]: Epoch 149 - training loss: 0.2120, validation loss: 0.1232
2024-05-22 17:23:21 [INFO]: Epoch 150 - training loss: 0.2098, validation loss: 0.1221
2024-05-22 17:23:21 [INFO]: Epoch 151 - training loss: 0.2098, validation loss: 0.1207
2024-05-22 17:23:21 [INFO]: Epoch 152 - training loss: 0.2099, validation loss: 0.1219
2024-05-22 17:23:22 [INFO]: Epoch 153 - training loss: 0.2088, validation loss: 0.1223
2024-05-22 17:23:22 [INFO]: Epoch 154 - training loss: 0.2085, validation loss: 0.1229
2024-05-22 17:23:22 [INFO]: Epoch 155 - training loss: 0.2114, validation loss: 0.1222
2024-05-22 17:23:22 [INFO]: Epoch 156 - training loss: 0.2114, validation loss: 0.1203
2024-05-22 17:23:23 [INFO]: Epoch 157 - training loss: 0.2098, validation loss: 0.1221
2024-05-22 17:23:23 [INFO]: Epoch 158 - training loss: 0.2075, validation loss: 0.1205
2024-05-22 17:23:23 [INFO]: Epoch 159 - training loss: 0.2086, validation loss: 0.1226
2024-05-22 17:23:24 [INFO]: Epoch 160 - training loss: 0.2090, validation loss: 0.1190
2024-05-22 17:23:24 [INFO]: Epoch 161 - training loss: 0.2071, validation loss: 0.1208
2024-05-22 17:23:24 [INFO]: Epoch 162 - training loss: 0.2064, validation loss: 0.1228
2024-05-22 17:23:24 [INFO]: Epoch 163 - training loss: 0.2063, validation loss: 0.1200
2024-05-22 17:23:25 [INFO]: Epoch 164 - training loss: 0.2053, validation loss: 0.1189
2024-05-22 17:23:25 [INFO]: Epoch 165 - training loss: 0.2062, validation loss: 0.1204
2024-05-22 17:23:25 [INFO]: Epoch 166 - training loss: 0.2058, validation loss: 0.1190
2024-05-22 17:23:25 [INFO]: Epoch 167 - training loss: 0.2074, validation loss: 0.1228
2024-05-22 17:23:26 [INFO]: Epoch 168 - training loss: 0.2112, validation loss: 0.1214
2024-05-22 17:23:26 [INFO]: Epoch 169 - training loss: 0.2055, validation loss: 0.1185
2024-05-22 17:23:26 [INFO]: Epoch 170 - training loss: 0.2036, validation loss: 0.1202
2024-05-22 17:23:27 [INFO]: Epoch 171 - training loss: 0.2029, validation loss: 0.1199
2024-05-22 17:23:27 [INFO]: Epoch 172 - training loss: 0.2053, validation loss: 0.1187
2024-05-22 17:23:27 [INFO]: Epoch 173 - training loss: 0.2044, validation loss: 0.1184
2024-05-22 17:23:27 [INFO]: Epoch 174 - training loss: 0.2041, validation loss: 0.1175
2024-05-22 17:23:28 [INFO]: Epoch 175 - training loss: 0.2043, validation loss: 0.1181
2024-05-22 17:23:28 [INFO]: Epoch 176 - training loss: 0.2020, validation loss: 0.1202
2024-05-22 17:23:28 [INFO]: Epoch 177 - training loss: 0.2025, validation loss: 0.1181
2024-05-22 17:23:29 [INFO]: Epoch 178 - training loss: 0.2040, validation loss: 0.1189
2024-05-22 17:23:29 [INFO]: Epoch 179 - training loss: 0.2013, validation loss: 0.1192
2024-05-22 17:23:29 [INFO]: Epoch 180 - training loss: 0.2011, validation loss: 0.1184
2024-05-22 17:23:29 [INFO]: Epoch 181 - training loss: 0.2033, validation loss: 0.1200
2024-05-22 17:23:30 [INFO]: Epoch 182 - training loss: 0.2027, validation loss: 0.1166
2024-05-22 17:23:30 [INFO]: Epoch 183 - training loss: 0.2055, validation loss: 0.1166
2024-05-22 17:23:30 [INFO]: Epoch 184 - training loss: 0.2040, validation loss: 0.1187
2024-05-22 17:23:31 [INFO]: Epoch 185 - training loss: 0.2015, validation loss: 0.1181
2024-05-22 17:23:31 [INFO]: Epoch 186 - training loss: 0.2002, validation loss: 0.1155
2024-05-22 17:23:31 [INFO]: Epoch 187 - training loss: 0.2004, validation loss: 0.1164
2024-05-22 17:23:31 [INFO]: Epoch 188 - training loss: 0.2011, validation loss: 0.1165
2024-05-22 17:23:32 [INFO]: Epoch 189 - training loss: 0.1990, validation loss: 0.1159
2024-05-22 17:23:32 [INFO]: Epoch 190 - training loss: 0.1992, validation loss: 0.1164
2024-05-22 17:23:32 [INFO]: Epoch 191 - training loss: 0.1982, validation loss: 0.1164
2024-05-22 17:23:33 [INFO]: Epoch 192 - training loss: 0.1972, validation loss: 0.1169
2024-05-22 17:23:33 [INFO]: Epoch 193 - training loss: 0.1968, validation loss: 0.1154
2024-05-22 17:23:33 [INFO]: Epoch 194 - training loss: 0.1971, validation loss: 0.1170
2024-05-22 17:23:33 [INFO]: Epoch 195 - training loss: 0.1971, validation loss: 0.1168
2024-05-22 17:23:34 [INFO]: Epoch 196 - training loss: 0.1978, validation loss: 0.1169
2024-05-22 17:23:34 [INFO]: Epoch 197 - training loss: 0.1977, validation loss: 0.1174
2024-05-22 17:23:34 [INFO]: Epoch 198 - training loss: 0.1972, validation loss: 0.1160
2024-05-22 17:23:34 [INFO]: Epoch 199 - training loss: 0.1973, validation loss: 0.1160
2024-05-22 17:23:35 [INFO]: Epoch 200 - training loss: 0.1996, validation loss: 0.1166
2024-05-22 17:23:35 [INFO]: Epoch 201 - training loss: 0.1972, validation loss: 0.1153
2024-05-22 17:23:35 [INFO]: Epoch 202 - training loss: 0.1959, validation loss: 0.1153
2024-05-22 17:23:36 [INFO]: Epoch 203 - training loss: 0.1962, validation loss: 0.1154
2024-05-22 17:23:36 [INFO]: Epoch 204 - training loss: 0.1960, validation loss: 0.1147
2024-05-22 17:23:36 [INFO]: Epoch 205 - training loss: 0.1963, validation loss: 0.1150
2024-05-22 17:23:36 [INFO]: Epoch 206 - training loss: 0.1996, validation loss: 0.1133
2024-05-22 17:23:37 [INFO]: Epoch 207 - training loss: 0.1978, validation loss: 0.1148
2024-05-22 17:23:37 [INFO]: Epoch 208 - training loss: 0.1962, validation loss: 0.1151
2024-05-22 17:23:37 [INFO]: Epoch 209 - training loss: 0.1941, validation loss: 0.1150
2024-05-22 17:23:38 [INFO]: Epoch 210 - training loss: 0.1943, validation loss: 0.1136
2024-05-22 17:23:38 [INFO]: Epoch 211 - training loss: 0.1946, validation loss: 0.1143
2024-05-22 17:23:38 [INFO]: Epoch 212 - training loss: 0.1932, validation loss: 0.1152
2024-05-22 17:23:38 [INFO]: Epoch 213 - training loss: 0.1927, validation loss: 0.1163
2024-05-22 17:23:39 [INFO]: Epoch 214 - training loss: 0.1940, validation loss: 0.1133
2024-05-22 17:23:39 [INFO]: Epoch 215 - training loss: 0.1968, validation loss: 0.1137
2024-05-22 17:23:39 [INFO]: Epoch 216 - training loss: 0.1938, validation loss: 0.1134
2024-05-22 17:23:40 [INFO]: Epoch 217 - training loss: 0.1917, validation loss: 0.1136
2024-05-22 17:23:40 [INFO]: Epoch 218 - training loss: 0.1935, validation loss: 0.1135
2024-05-22 17:23:40 [INFO]: Epoch 219 - training loss: 0.1939, validation loss: 0.1155
2024-05-22 17:23:40 [INFO]: Epoch 220 - training loss: 0.1935, validation loss: 0.1145
2024-05-22 17:23:41 [INFO]: Epoch 221 - training loss: 0.1936, validation loss: 0.1138
2024-05-22 17:23:41 [INFO]: Epoch 222 - training loss: 0.1911, validation loss: 0.1141
2024-05-22 17:23:41 [INFO]: Epoch 223 - training loss: 0.1905, validation loss: 0.1138
2024-05-22 17:23:41 [INFO]: Epoch 224 - training loss: 0.1897, validation loss: 0.1125
2024-05-22 17:23:42 [INFO]: Epoch 225 - training loss: 0.1912, validation loss: 0.1137
2024-05-22 17:23:42 [INFO]: Epoch 226 - training loss: 0.1905, validation loss: 0.1127
2024-05-22 17:23:42 [INFO]: Epoch 227 - training loss: 0.1908, validation loss: 0.1129
2024-05-22 17:23:43 [INFO]: Epoch 228 - training loss: 0.1916, validation loss: 0.1135
2024-05-22 17:23:43 [INFO]: Epoch 229 - training loss: 0.1916, validation loss: 0.1138
2024-05-22 17:23:43 [INFO]: Epoch 230 - training loss: 0.1924, validation loss: 0.1153
2024-05-22 17:23:43 [INFO]: Epoch 231 - training loss: 0.1924, validation loss: 0.1134
2024-05-22 17:23:44 [INFO]: Epoch 232 - training loss: 0.1921, validation loss: 0.1115
2024-05-22 17:23:44 [INFO]: Epoch 233 - training loss: 0.1906, validation loss: 0.1120
2024-05-22 17:23:44 [INFO]: Epoch 234 - training loss: 0.1885, validation loss: 0.1126
2024-05-22 17:23:45 [INFO]: Epoch 235 - training loss: 0.1874, validation loss: 0.1121
2024-05-22 17:23:45 [INFO]: Epoch 236 - training loss: 0.1876, validation loss: 0.1111
2024-05-22 17:23:45 [INFO]: Epoch 237 - training loss: 0.1895, validation loss: 0.1120
2024-05-22 17:23:45 [INFO]: Epoch 238 - training loss: 0.1899, validation loss: 0.1120
2024-05-22 17:23:46 [INFO]: Epoch 239 - training loss: 0.1881, validation loss: 0.1118
2024-05-22 17:23:46 [INFO]: Epoch 240 - training loss: 0.1874, validation loss: 0.1108
2024-05-22 17:23:46 [INFO]: Epoch 241 - training loss: 0.1861, validation loss: 0.1120
2024-05-22 17:23:47 [INFO]: Epoch 242 - training loss: 0.1894, validation loss: 0.1152
2024-05-22 17:23:47 [INFO]: Epoch 243 - training loss: 0.1936, validation loss: 0.1119
2024-05-22 17:23:47 [INFO]: Epoch 244 - training loss: 0.1897, validation loss: 0.1116
2024-05-22 17:23:47 [INFO]: Epoch 245 - training loss: 0.1885, validation loss: 0.1120
2024-05-22 17:23:48 [INFO]: Epoch 246 - training loss: 0.1873, validation loss: 0.1130
2024-05-22 17:23:48 [INFO]: Epoch 247 - training loss: 0.1865, validation loss: 0.1108
2024-05-22 17:23:48 [INFO]: Epoch 248 - training loss: 0.1863, validation loss: 0.1122
2024-05-22 17:23:48 [INFO]: Epoch 249 - training loss: 0.1857, validation loss: 0.1109
2024-05-22 17:23:49 [INFO]: Epoch 250 - training loss: 0.1847, validation loss: 0.1101
2024-05-22 17:23:49 [INFO]: Epoch 251 - training loss: 0.1872, validation loss: 0.1120
2024-05-22 17:23:49 [INFO]: Epoch 252 - training loss: 0.1863, validation loss: 0.1120
2024-05-22 17:23:50 [INFO]: Epoch 253 - training loss: 0.1847, validation loss: 0.1103
2024-05-22 17:23:50 [INFO]: Epoch 254 - training loss: 0.1855, validation loss: 0.1099
2024-05-22 17:23:50 [INFO]: Epoch 255 - training loss: 0.1868, validation loss: 0.1108
2024-05-22 17:23:50 [INFO]: Epoch 256 - training loss: 0.1860, validation loss: 0.1114
2024-05-22 17:23:51 [INFO]: Epoch 257 - training loss: 0.1845, validation loss: 0.1099
2024-05-22 17:23:51 [INFO]: Epoch 258 - training loss: 0.1844, validation loss: 0.1096
2024-05-22 17:23:51 [INFO]: Epoch 259 - training loss: 0.1847, validation loss: 0.1110
2024-05-22 17:23:52 [INFO]: Epoch 260 - training loss: 0.1878, validation loss: 0.1109
2024-05-22 17:23:52 [INFO]: Epoch 261 - training loss: 0.1878, validation loss: 0.1099
2024-05-22 17:23:52 [INFO]: Epoch 262 - training loss: 0.1881, validation loss: 0.1125
2024-05-22 17:23:52 [INFO]: Epoch 263 - training loss: 0.1870, validation loss: 0.1117
2024-05-22 17:23:53 [INFO]: Epoch 264 - training loss: 0.1845, validation loss: 0.1101
2024-05-22 17:23:53 [INFO]: Epoch 265 - training loss: 0.1847, validation loss: 0.1108
2024-05-22 17:23:53 [INFO]: Epoch 266 - training loss: 0.1834, validation loss: 0.1093
2024-05-22 17:23:54 [INFO]: Epoch 267 - training loss: 0.1828, validation loss: 0.1090
2024-05-22 17:23:54 [INFO]: Epoch 268 - training loss: 0.1822, validation loss: 0.1089
2024-05-22 17:23:54 [INFO]: Epoch 269 - training loss: 0.1825, validation loss: 0.1098
2024-05-22 17:23:54 [INFO]: Epoch 270 - training loss: 0.1812, validation loss: 0.1081
2024-05-22 17:23:55 [INFO]: Epoch 271 - training loss: 0.1820, validation loss: 0.1091
2024-05-22 17:23:55 [INFO]: Epoch 272 - training loss: 0.1823, validation loss: 0.1075
2024-05-22 17:23:55 [INFO]: Epoch 273 - training loss: 0.1819, validation loss: 0.1083
2024-05-22 17:23:55 [INFO]: Epoch 274 - training loss: 0.1814, validation loss: 0.1089
2024-05-22 17:23:56 [INFO]: Epoch 275 - training loss: 0.1827, validation loss: 0.1082
2024-05-22 17:23:56 [INFO]: Epoch 276 - training loss: 0.1821, validation loss: 0.1094
2024-05-22 17:23:56 [INFO]: Epoch 277 - training loss: 0.1834, validation loss: 0.1087
2024-05-22 17:23:57 [INFO]: Epoch 278 - training loss: 0.1830, validation loss: 0.1093
2024-05-22 17:23:57 [INFO]: Epoch 279 - training loss: 0.1810, validation loss: 0.1081
2024-05-22 17:23:57 [INFO]: Epoch 280 - training loss: 0.1805, validation loss: 0.1091
2024-05-22 17:23:57 [INFO]: Epoch 281 - training loss: 0.1840, validation loss: 0.1087
2024-05-22 17:23:58 [INFO]: Epoch 282 - training loss: 0.1816, validation loss: 0.1084
2024-05-22 17:23:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:23:58 [INFO]: Finished training. The best model is from epoch#272.
2024-05-22 17:23:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/Transformer_air_quality/20240522_T172239/Transformer.pypots
2024-05-22 17:23:58 [INFO]: Transformer on Air-Quality: MAE=0.1548, MSE=0.1159
2024-05-22 17:23:58 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/Transformer_air_quality/imputation.pkl
2024-05-22 17:23:58 [INFO]: Using the given device: cuda:0
2024-05-22 17:23:58 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/TimesNet_air_quality/20240522_T172358
2024-05-22 17:23:58 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/TimesNet_air_quality/20240522_T172358/tensorboard
2024-05-22 17:23:58 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-22 17:23:59 [INFO]: Epoch 001 - training loss: 0.2905, validation loss: 0.2543
2024-05-22 17:23:59 [INFO]: Epoch 002 - training loss: 0.2295, validation loss: 0.2148
2024-05-22 17:24:00 [INFO]: Epoch 003 - training loss: 0.2011, validation loss: 0.1867
2024-05-22 17:24:00 [INFO]: Epoch 004 - training loss: 0.1931, validation loss: 0.1812
2024-05-22 17:24:01 [INFO]: Epoch 005 - training loss: 0.1792, validation loss: 0.1760
2024-05-22 17:24:01 [INFO]: Epoch 006 - training loss: 0.1579, validation loss: 0.1658
2024-05-22 17:24:02 [INFO]: Epoch 007 - training loss: 0.1583, validation loss: 0.1640
2024-05-22 17:24:02 [INFO]: Epoch 008 - training loss: 0.1609, validation loss: 0.1607
2024-05-22 17:24:02 [INFO]: Epoch 009 - training loss: 0.1586, validation loss: 0.1575
2024-05-22 17:24:03 [INFO]: Epoch 010 - training loss: 0.1532, validation loss: 0.1574
2024-05-22 17:24:03 [INFO]: Epoch 011 - training loss: 0.1369, validation loss: 0.1501
2024-05-22 17:24:04 [INFO]: Epoch 012 - training loss: 0.1457, validation loss: 0.1506
2024-05-22 17:24:04 [INFO]: Epoch 013 - training loss: 0.1298, validation loss: 0.1513
2024-05-22 17:24:05 [INFO]: Epoch 014 - training loss: 0.1246, validation loss: 0.1486
2024-05-22 17:24:05 [INFO]: Epoch 015 - training loss: 0.1330, validation loss: 0.1531
2024-05-22 17:24:06 [INFO]: Epoch 016 - training loss: 0.1365, validation loss: 0.1496
2024-05-22 17:24:06 [INFO]: Epoch 017 - training loss: 0.1218, validation loss: 0.1572
2024-05-22 17:24:07 [INFO]: Epoch 018 - training loss: 0.1117, validation loss: 0.1468
2024-05-22 17:24:07 [INFO]: Epoch 019 - training loss: 0.1405, validation loss: 0.1467
2024-05-22 17:24:08 [INFO]: Epoch 020 - training loss: 0.1286, validation loss: 0.1530
2024-05-22 17:24:08 [INFO]: Epoch 021 - training loss: 0.1330, validation loss: 0.1527
2024-05-22 17:24:09 [INFO]: Epoch 022 - training loss: 0.1323, validation loss: 0.1465
2024-05-22 17:24:09 [INFO]: Epoch 023 - training loss: 0.1273, validation loss: 0.1461
2024-05-22 17:24:10 [INFO]: Epoch 024 - training loss: 0.1288, validation loss: 0.1403
2024-05-22 17:24:10 [INFO]: Epoch 025 - training loss: 0.1417, validation loss: 0.1471
2024-05-22 17:24:10 [INFO]: Epoch 026 - training loss: 0.1252, validation loss: 0.1435
2024-05-22 17:24:11 [INFO]: Epoch 027 - training loss: 0.1332, validation loss: 0.1486
2024-05-22 17:24:11 [INFO]: Epoch 028 - training loss: 0.1305, validation loss: 0.1379
2024-05-22 17:24:12 [INFO]: Epoch 029 - training loss: 0.1130, validation loss: 0.1467
2024-05-22 17:24:12 [INFO]: Epoch 030 - training loss: 0.1219, validation loss: 0.1406
2024-05-22 17:24:13 [INFO]: Epoch 031 - training loss: 0.1195, validation loss: 0.1426
2024-05-22 17:24:13 [INFO]: Epoch 032 - training loss: 0.1300, validation loss: 0.1406
2024-05-22 17:24:14 [INFO]: Epoch 033 - training loss: 0.1083, validation loss: 0.1363
2024-05-22 17:24:14 [INFO]: Epoch 034 - training loss: 0.1201, validation loss: 0.1415
2024-05-22 17:24:15 [INFO]: Epoch 035 - training loss: 0.1281, validation loss: 0.1397
2024-05-22 17:24:15 [INFO]: Epoch 036 - training loss: 0.1056, validation loss: 0.1499
2024-05-22 17:24:16 [INFO]: Epoch 037 - training loss: 0.0988, validation loss: 0.1357
2024-05-22 17:24:16 [INFO]: Epoch 038 - training loss: 0.1146, validation loss: 0.1407
2024-05-22 17:24:17 [INFO]: Epoch 039 - training loss: 0.1210, validation loss: 0.1411
2024-05-22 17:24:17 [INFO]: Epoch 040 - training loss: 0.1146, validation loss: 0.1353
2024-05-22 17:24:18 [INFO]: Epoch 041 - training loss: 0.1206, validation loss: 0.1316
2024-05-22 17:24:18 [INFO]: Epoch 042 - training loss: 0.0965, validation loss: 0.1340
2024-05-22 17:24:19 [INFO]: Epoch 043 - training loss: 0.1122, validation loss: 0.1371
2024-05-22 17:24:19 [INFO]: Epoch 044 - training loss: 0.1036, validation loss: 0.1342
2024-05-22 17:24:19 [INFO]: Epoch 045 - training loss: 0.0970, validation loss: 0.1326
2024-05-22 17:24:20 [INFO]: Epoch 046 - training loss: 0.1099, validation loss: 0.1322
2024-05-22 17:24:20 [INFO]: Epoch 047 - training loss: 0.1108, validation loss: 0.1371
2024-05-22 17:24:21 [INFO]: Epoch 048 - training loss: 0.1013, validation loss: 0.1336
2024-05-22 17:24:21 [INFO]: Epoch 049 - training loss: 0.1104, validation loss: 0.1302
2024-05-22 17:24:22 [INFO]: Epoch 050 - training loss: 0.1099, validation loss: 0.1295
2024-05-22 17:24:22 [INFO]: Epoch 051 - training loss: 0.1054, validation loss: 0.1358
2024-05-22 17:24:23 [INFO]: Epoch 052 - training loss: 0.1080, validation loss: 0.1288
2024-05-22 17:24:23 [INFO]: Epoch 053 - training loss: 0.0970, validation loss: 0.1283
2024-05-22 17:24:24 [INFO]: Epoch 054 - training loss: 0.1031, validation loss: 0.1312
2024-05-22 17:24:24 [INFO]: Epoch 055 - training loss: 0.1035, validation loss: 0.1325
2024-05-22 17:24:25 [INFO]: Epoch 056 - training loss: 0.1025, validation loss: 0.1288
2024-05-22 17:24:25 [INFO]: Epoch 057 - training loss: 0.1109, validation loss: 0.1297
2024-05-22 17:24:26 [INFO]: Epoch 058 - training loss: 0.0942, validation loss: 0.1391
2024-05-22 17:24:26 [INFO]: Epoch 059 - training loss: 0.1043, validation loss: 0.1273
2024-05-22 17:24:27 [INFO]: Epoch 060 - training loss: 0.0983, validation loss: 0.1266
2024-05-22 17:24:27 [INFO]: Epoch 061 - training loss: 0.1051, validation loss: 0.1276
2024-05-22 17:24:28 [INFO]: Epoch 062 - training loss: 0.1122, validation loss: 0.1310
2024-05-22 17:24:28 [INFO]: Epoch 063 - training loss: 0.1088, validation loss: 0.1387
2024-05-22 17:24:28 [INFO]: Epoch 064 - training loss: 0.0922, validation loss: 0.1302
2024-05-22 17:24:29 [INFO]: Epoch 065 - training loss: 0.1044, validation loss: 0.1322
2024-05-22 17:24:29 [INFO]: Epoch 066 - training loss: 0.0980, validation loss: 0.1359
2024-05-22 17:24:30 [INFO]: Epoch 067 - training loss: 0.1020, validation loss: 0.1426
2024-05-22 17:24:30 [INFO]: Epoch 068 - training loss: 0.1314, validation loss: 0.1315
2024-05-22 17:24:31 [INFO]: Epoch 069 - training loss: 0.1014, validation loss: 0.1315
2024-05-22 17:24:31 [INFO]: Epoch 070 - training loss: 0.0909, validation loss: 0.1256
2024-05-22 17:24:32 [INFO]: Epoch 071 - training loss: 0.0993, validation loss: 0.1283
2024-05-22 17:24:32 [INFO]: Epoch 072 - training loss: 0.0950, validation loss: 0.1263
2024-05-22 17:24:33 [INFO]: Epoch 073 - training loss: 0.0824, validation loss: 0.1253
2024-05-22 17:24:33 [INFO]: Epoch 074 - training loss: 0.0999, validation loss: 0.1311
2024-05-22 17:24:34 [INFO]: Epoch 075 - training loss: 0.0926, validation loss: 0.1257
2024-05-22 17:24:34 [INFO]: Epoch 076 - training loss: 0.0859, validation loss: 0.1299
2024-05-22 17:24:35 [INFO]: Epoch 077 - training loss: 0.0953, validation loss: 0.1259
2024-05-22 17:24:35 [INFO]: Epoch 078 - training loss: 0.0975, validation loss: 0.1291
2024-05-22 17:24:36 [INFO]: Epoch 079 - training loss: 0.0836, validation loss: 0.1272
2024-05-22 17:24:36 [INFO]: Epoch 080 - training loss: 0.0890, validation loss: 0.1273
2024-05-22 17:24:37 [INFO]: Epoch 081 - training loss: 0.0839, validation loss: 0.1256
2024-05-22 17:24:37 [INFO]: Epoch 082 - training loss: 0.0940, validation loss: 0.1230
2024-05-22 17:24:37 [INFO]: Epoch 083 - training loss: 0.0911, validation loss: 0.1302
2024-05-22 17:24:38 [INFO]: Epoch 084 - training loss: 0.0846, validation loss: 0.1304
2024-05-22 17:24:38 [INFO]: Epoch 085 - training loss: 0.0831, validation loss: 0.1356
2024-05-22 17:24:39 [INFO]: Epoch 086 - training loss: 0.0818, validation loss: 0.1274
2024-05-22 17:24:39 [INFO]: Epoch 087 - training loss: 0.0866, validation loss: 0.1275
2024-05-22 17:24:40 [INFO]: Epoch 088 - training loss: 0.0893, validation loss: 0.1273
2024-05-22 17:24:40 [INFO]: Epoch 089 - training loss: 0.0911, validation loss: 0.1273
2024-05-22 17:24:41 [INFO]: Epoch 090 - training loss: 0.1019, validation loss: 0.1298
2024-05-22 17:24:41 [INFO]: Epoch 091 - training loss: 0.0842, validation loss: 0.1299
2024-05-22 17:24:42 [INFO]: Epoch 092 - training loss: 0.0949, validation loss: 0.1261
2024-05-22 17:24:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:24:42 [INFO]: Finished training. The best model is from epoch#82.
2024-05-22 17:24:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/TimesNet_air_quality/20240522_T172358/TimesNet.pypots
2024-05-22 17:24:42 [INFO]: TimesNet on Air-Quality: MAE=0.1523, MSE=0.1457
2024-05-22 17:24:42 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/TimesNet_air_quality/imputation.pkl
2024-05-22 17:24:42 [INFO]: Using the given device: cuda:0
2024-05-22 17:24:42 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442
2024-05-22 17:24:42 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/tensorboard
2024-05-22 17:24:42 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-22 17:24:58 [INFO]: Epoch 001 - training loss: 0.5539, validation loss: 0.3708
2024-05-22 17:24:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch1_loss0.3707821160554886.pypots
2024-05-22 17:25:15 [INFO]: Epoch 002 - training loss: 0.3020, validation loss: 0.3034
2024-05-22 17:25:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch2_loss0.30343874990940095.pypots
2024-05-22 17:25:31 [INFO]: Epoch 003 - training loss: 0.2733, validation loss: 0.2558
2024-05-22 17:25:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch3_loss0.25583960115909576.pypots
2024-05-22 17:25:48 [INFO]: Epoch 004 - training loss: 0.2305, validation loss: 0.2396
2024-05-22 17:25:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch4_loss0.2395523816347122.pypots
2024-05-22 17:26:04 [INFO]: Epoch 005 - training loss: 0.2453, validation loss: 0.1996
2024-05-22 17:26:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch5_loss0.1995951235294342.pypots
2024-05-22 17:26:21 [INFO]: Epoch 006 - training loss: 0.2180, validation loss: 0.1870
2024-05-22 17:26:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch6_loss0.18696776777505875.pypots
2024-05-22 17:26:37 [INFO]: Epoch 007 - training loss: 0.1928, validation loss: 0.1749
2024-05-22 17:26:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch7_loss0.1749318554997444.pypots
2024-05-22 17:26:54 [INFO]: Epoch 008 - training loss: 0.1916, validation loss: 0.1666
2024-05-22 17:26:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch8_loss0.1666371300816536.pypots
2024-05-22 17:27:10 [INFO]: Epoch 009 - training loss: 0.1824, validation loss: 0.1631
2024-05-22 17:27:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch9_loss0.16314868181943892.pypots
2024-05-22 17:27:27 [INFO]: Epoch 010 - training loss: 0.1890, validation loss: 0.1581
2024-05-22 17:27:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch10_loss0.1581394761800766.pypots
2024-05-22 17:27:43 [INFO]: Epoch 011 - training loss: 0.1791, validation loss: 0.1557
2024-05-22 17:27:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch11_loss0.1557352527976036.pypots
2024-05-22 17:28:00 [INFO]: Epoch 012 - training loss: 0.1856, validation loss: 0.1540
2024-05-22 17:28:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch12_loss0.15400516986846924.pypots
2024-05-22 17:28:16 [INFO]: Epoch 013 - training loss: 0.1547, validation loss: 0.1522
2024-05-22 17:28:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch13_loss0.15219037979841232.pypots
2024-05-22 17:28:32 [INFO]: Epoch 014 - training loss: 0.1574, validation loss: 0.1557
2024-05-22 17:28:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch14_loss0.1556576356291771.pypots
2024-05-22 17:28:49 [INFO]: Epoch 015 - training loss: 0.1763, validation loss: 0.1465
2024-05-22 17:28:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch15_loss0.14652754068374635.pypots
2024-05-22 17:29:05 [INFO]: Epoch 016 - training loss: 0.1612, validation loss: 0.1442
2024-05-22 17:29:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch16_loss0.14420360177755356.pypots
2024-05-22 17:29:22 [INFO]: Epoch 017 - training loss: 0.1621, validation loss: 0.1479
2024-05-22 17:29:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch17_loss0.1478788062930107.pypots
2024-05-22 17:29:38 [INFO]: Epoch 018 - training loss: 0.1625, validation loss: 0.1487
2024-05-22 17:29:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch18_loss0.1487415015697479.pypots
2024-05-22 17:29:55 [INFO]: Epoch 019 - training loss: 0.1635, validation loss: 0.1421
2024-05-22 17:29:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch19_loss0.14211004227399826.pypots
2024-05-22 17:30:11 [INFO]: Epoch 020 - training loss: 0.1499, validation loss: 0.1382
2024-05-22 17:30:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch20_loss0.13820651397109032.pypots
2024-05-22 17:30:28 [INFO]: Epoch 021 - training loss: 0.1612, validation loss: 0.1330
2024-05-22 17:30:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch21_loss0.1330365337431431.pypots
2024-05-22 17:30:44 [INFO]: Epoch 022 - training loss: 0.1499, validation loss: 0.1380
2024-05-22 17:30:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch22_loss0.1380393125116825.pypots
2024-05-22 17:31:01 [INFO]: Epoch 023 - training loss: 0.1443, validation loss: 0.1338
2024-05-22 17:31:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch23_loss0.13378455266356468.pypots
2024-05-22 17:31:17 [INFO]: Epoch 024 - training loss: 0.1623, validation loss: 0.1421
2024-05-22 17:31:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch24_loss0.14213278666138648.pypots
2024-05-22 17:31:34 [INFO]: Epoch 025 - training loss: 0.1494, validation loss: 0.1353
2024-05-22 17:31:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch25_loss0.13531530350446702.pypots
2024-05-22 17:31:50 [INFO]: Epoch 026 - training loss: 0.1352, validation loss: 0.1320
2024-05-22 17:31:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch26_loss0.1319891668856144.pypots
2024-05-22 17:32:07 [INFO]: Epoch 027 - training loss: 0.1415, validation loss: 0.1361
2024-05-22 17:32:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch27_loss0.13606084287166595.pypots
2024-05-22 17:32:23 [INFO]: Epoch 028 - training loss: 0.1305, validation loss: 0.1314
2024-05-22 17:32:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch28_loss0.13143231123685836.pypots
2024-05-22 17:32:40 [INFO]: Epoch 029 - training loss: 0.1477, validation loss: 0.1281
2024-05-22 17:32:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch29_loss0.12813466191291809.pypots
2024-05-22 17:32:56 [INFO]: Epoch 030 - training loss: 0.1465, validation loss: 0.1368
2024-05-22 17:32:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch30_loss0.13676725700497627.pypots
2024-05-22 17:33:12 [INFO]: Epoch 031 - training loss: 0.1457, validation loss: 0.1284
2024-05-22 17:33:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch31_loss0.12836630195379256.pypots
2024-05-22 17:33:29 [INFO]: Epoch 032 - training loss: 0.1377, validation loss: 0.1294
2024-05-22 17:33:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch32_loss0.12940728142857552.pypots
2024-05-22 17:33:45 [INFO]: Epoch 033 - training loss: 0.1326, validation loss: 0.1249
2024-05-22 17:33:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch33_loss0.12492870613932609.pypots
2024-05-22 17:34:02 [INFO]: Epoch 034 - training loss: 0.1380, validation loss: 0.1312
2024-05-22 17:34:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch34_loss0.13122237399220466.pypots
2024-05-22 17:34:18 [INFO]: Epoch 035 - training loss: 0.1414, validation loss: 0.1268
2024-05-22 17:34:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch35_loss0.12684692963957786.pypots
2024-05-22 17:34:35 [INFO]: Epoch 036 - training loss: 0.1343, validation loss: 0.1233
2024-05-22 17:34:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch36_loss0.1232625424861908.pypots
2024-05-22 17:34:51 [INFO]: Epoch 037 - training loss: 0.1228, validation loss: 0.1289
2024-05-22 17:34:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch37_loss0.12893230691552163.pypots
2024-05-22 17:35:08 [INFO]: Epoch 038 - training loss: 0.1299, validation loss: 0.1337
2024-05-22 17:35:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch38_loss0.13369475677609444.pypots
2024-05-22 17:35:24 [INFO]: Epoch 039 - training loss: 0.1326, validation loss: 0.1264
2024-05-22 17:35:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch39_loss0.1264334388077259.pypots
2024-05-22 17:35:41 [INFO]: Epoch 040 - training loss: 0.1437, validation loss: 0.1242
2024-05-22 17:35:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch40_loss0.12420170158147811.pypots
2024-05-22 17:35:57 [INFO]: Epoch 041 - training loss: 0.1291, validation loss: 0.1214
2024-05-22 17:35:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch41_loss0.12142926007509232.pypots
2024-05-22 17:36:14 [INFO]: Epoch 042 - training loss: 0.1266, validation loss: 0.1204
2024-05-22 17:36:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch42_loss0.12042026221752167.pypots
2024-05-22 17:36:30 [INFO]: Epoch 043 - training loss: 0.1280, validation loss: 0.1284
2024-05-22 17:36:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch43_loss0.12837565913796425.pypots
2024-05-22 17:36:47 [INFO]: Epoch 044 - training loss: 0.1270, validation loss: 0.1226
2024-05-22 17:36:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch44_loss0.12264916971325875.pypots
2024-05-22 17:37:03 [INFO]: Epoch 045 - training loss: 0.1348, validation loss: 0.1182
2024-05-22 17:37:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch45_loss0.1181885726749897.pypots
2024-05-22 17:37:20 [INFO]: Epoch 046 - training loss: 0.1237, validation loss: 0.1232
2024-05-22 17:37:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch46_loss0.12318701222538948.pypots
2024-05-22 17:37:36 [INFO]: Epoch 047 - training loss: 0.1300, validation loss: 0.1240
2024-05-22 17:37:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch47_loss0.12404736652970313.pypots
2024-05-22 17:37:53 [INFO]: Epoch 048 - training loss: 0.1366, validation loss: 0.1155
2024-05-22 17:37:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch48_loss0.11554821357131004.pypots
2024-05-22 17:38:09 [INFO]: Epoch 049 - training loss: 0.1402, validation loss: 0.1183
2024-05-22 17:38:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch49_loss0.11830770149827004.pypots
2024-05-22 17:38:26 [INFO]: Epoch 050 - training loss: 0.1299, validation loss: 0.1170
2024-05-22 17:38:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch50_loss0.11702052727341652.pypots
2024-05-22 17:38:42 [INFO]: Epoch 051 - training loss: 0.1256, validation loss: 0.1142
2024-05-22 17:38:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch51_loss0.11420726180076599.pypots
2024-05-22 17:38:59 [INFO]: Epoch 052 - training loss: 0.1292, validation loss: 0.1150
2024-05-22 17:38:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch52_loss0.11501815319061279.pypots
2024-05-22 17:39:15 [INFO]: Epoch 053 - training loss: 0.1355, validation loss: 0.1163
2024-05-22 17:39:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch53_loss0.11629596874117851.pypots
2024-05-22 17:39:32 [INFO]: Epoch 054 - training loss: 0.1259, validation loss: 0.1182
2024-05-22 17:39:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch54_loss0.11819734126329422.pypots
2024-05-22 17:39:48 [INFO]: Epoch 055 - training loss: 0.1293, validation loss: 0.1162
2024-05-22 17:39:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch55_loss0.11623204499483109.pypots
2024-05-22 17:40:05 [INFO]: Epoch 056 - training loss: 0.1268, validation loss: 0.1117
2024-05-22 17:40:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch56_loss0.11168678849935532.pypots
2024-05-22 17:40:21 [INFO]: Epoch 057 - training loss: 0.1413, validation loss: 0.1104
2024-05-22 17:40:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch57_loss0.11044181287288665.pypots
2024-05-22 17:40:38 [INFO]: Epoch 058 - training loss: 0.1182, validation loss: 0.1118
2024-05-22 17:40:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch58_loss0.11180060654878617.pypots
2024-05-22 17:40:54 [INFO]: Epoch 059 - training loss: 0.1288, validation loss: 0.1142
2024-05-22 17:40:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch59_loss0.1142276555299759.pypots
2024-05-22 17:41:11 [INFO]: Epoch 060 - training loss: 0.1327, validation loss: 0.1146
2024-05-22 17:41:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch60_loss0.11456792280077935.pypots
2024-05-22 17:41:27 [INFO]: Epoch 061 - training loss: 0.1160, validation loss: 0.1099
2024-05-22 17:41:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch61_loss0.10987531542778015.pypots
2024-05-22 17:41:44 [INFO]: Epoch 062 - training loss: 0.1185, validation loss: 0.1093
2024-05-22 17:41:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch62_loss0.10926245450973511.pypots
2024-05-22 17:42:00 [INFO]: Epoch 063 - training loss: 0.1153, validation loss: 0.1088
2024-05-22 17:42:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch63_loss0.10877511799335479.pypots
2024-05-22 17:42:17 [INFO]: Epoch 064 - training loss: 0.1212, validation loss: 0.1080
2024-05-22 17:42:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch64_loss0.1079901784658432.pypots
2024-05-22 17:42:33 [INFO]: Epoch 065 - training loss: 0.1175, validation loss: 0.1087
2024-05-22 17:42:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch65_loss0.10874796509742737.pypots
2024-05-22 17:42:50 [INFO]: Epoch 066 - training loss: 0.1207, validation loss: 0.1112
2024-05-22 17:42:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch66_loss0.11118186861276627.pypots
2024-05-22 17:43:06 [INFO]: Epoch 067 - training loss: 0.1094, validation loss: 0.1096
2024-05-22 17:43:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch67_loss0.10962540060281753.pypots
2024-05-22 17:43:23 [INFO]: Epoch 068 - training loss: 0.1236, validation loss: 0.1131
2024-05-22 17:43:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch68_loss0.11313276812434196.pypots
2024-05-22 17:43:39 [INFO]: Epoch 069 - training loss: 0.1218, validation loss: 0.1134
2024-05-22 17:43:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch69_loss0.11340137869119644.pypots
2024-05-22 17:43:55 [INFO]: Epoch 070 - training loss: 0.1313, validation loss: 0.1116
2024-05-22 17:43:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch70_loss0.11159728020429611.pypots
2024-05-22 17:44:12 [INFO]: Epoch 071 - training loss: 0.1146, validation loss: 0.1104
2024-05-22 17:44:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch71_loss0.11035058796405792.pypots
2024-05-22 17:44:28 [INFO]: Epoch 072 - training loss: 0.1318, validation loss: 0.1103
2024-05-22 17:44:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch72_loss0.11030422300100326.pypots
2024-05-22 17:44:45 [INFO]: Epoch 073 - training loss: 0.1096, validation loss: 0.1059
2024-05-22 17:44:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch73_loss0.10593903437256813.pypots
2024-05-22 17:45:01 [INFO]: Epoch 074 - training loss: 0.1305, validation loss: 0.1089
2024-05-22 17:45:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch74_loss0.10887149646878243.pypots
2024-05-22 17:45:18 [INFO]: Epoch 075 - training loss: 0.1191, validation loss: 0.1091
2024-05-22 17:45:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch75_loss0.10914926901459694.pypots
2024-05-22 17:45:34 [INFO]: Epoch 076 - training loss: 0.1204, validation loss: 0.1100
2024-05-22 17:45:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch76_loss0.10997423976659775.pypots
2024-05-22 17:45:51 [INFO]: Epoch 077 - training loss: 0.1171, validation loss: 0.1056
2024-05-22 17:45:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch77_loss0.10556043088436126.pypots
2024-05-22 17:46:07 [INFO]: Epoch 078 - training loss: 0.1256, validation loss: 0.1072
2024-05-22 17:46:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch78_loss0.10723944082856178.pypots
2024-05-22 17:46:24 [INFO]: Epoch 079 - training loss: 0.1079, validation loss: 0.1069
2024-05-22 17:46:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch79_loss0.10690837129950523.pypots
2024-05-22 17:46:40 [INFO]: Epoch 080 - training loss: 0.1153, validation loss: 0.1078
2024-05-22 17:46:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch80_loss0.10780296102166176.pypots
2024-05-22 17:46:57 [INFO]: Epoch 081 - training loss: 0.1197, validation loss: 0.1083
2024-05-22 17:46:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch81_loss0.1082659311592579.pypots
2024-05-22 17:47:13 [INFO]: Epoch 082 - training loss: 0.1189, validation loss: 0.1048
2024-05-22 17:47:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch82_loss0.10478710979223252.pypots
2024-05-22 17:47:30 [INFO]: Epoch 083 - training loss: 0.1142, validation loss: 0.1102
2024-05-22 17:47:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch83_loss0.11020364984869957.pypots
2024-05-22 17:47:46 [INFO]: Epoch 084 - training loss: 0.1175, validation loss: 0.1069
2024-05-22 17:47:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch84_loss0.10694949328899384.pypots
2024-05-22 17:48:03 [INFO]: Epoch 085 - training loss: 0.1094, validation loss: 0.1050
2024-05-22 17:48:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch85_loss0.10498898774385453.pypots
2024-05-22 17:48:19 [INFO]: Epoch 086 - training loss: 0.1219, validation loss: 0.1076
2024-05-22 17:48:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch86_loss0.1075753167271614.pypots
2024-05-22 17:48:36 [INFO]: Epoch 087 - training loss: 0.1029, validation loss: 0.1061
2024-05-22 17:48:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch87_loss0.10610983446240425.pypots
2024-05-22 17:48:52 [INFO]: Epoch 088 - training loss: 0.1241, validation loss: 0.1068
2024-05-22 17:48:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch88_loss0.1067795217037201.pypots
2024-05-22 17:49:08 [INFO]: Epoch 089 - training loss: 0.1139, validation loss: 0.1031
2024-05-22 17:49:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch89_loss0.10306455492973328.pypots
2024-05-22 17:49:25 [INFO]: Epoch 090 - training loss: 0.1102, validation loss: 0.1042
2024-05-22 17:49:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch90_loss0.10420074686408043.pypots
2024-05-22 17:49:41 [INFO]: Epoch 091 - training loss: 0.1066, validation loss: 0.1033
2024-05-22 17:49:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch91_loss0.1032985046505928.pypots
2024-05-22 17:49:58 [INFO]: Epoch 092 - training loss: 0.1117, validation loss: 0.1049
2024-05-22 17:49:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch92_loss0.10492416396737099.pypots
2024-05-22 17:50:14 [INFO]: Epoch 093 - training loss: 0.1161, validation loss: 0.1058
2024-05-22 17:50:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch93_loss0.10582159236073493.pypots
2024-05-22 17:50:31 [INFO]: Epoch 094 - training loss: 0.1269, validation loss: 0.1037
2024-05-22 17:50:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch94_loss0.10371195003390313.pypots
2024-05-22 17:50:47 [INFO]: Epoch 095 - training loss: 0.1310, validation loss: 0.1080
2024-05-22 17:50:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch95_loss0.10797536745667458.pypots
2024-05-22 17:51:04 [INFO]: Epoch 096 - training loss: 0.1189, validation loss: 0.1055
2024-05-22 17:51:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch96_loss0.10547412484884262.pypots
2024-05-22 17:51:20 [INFO]: Epoch 097 - training loss: 0.1143, validation loss: 0.1071
2024-05-22 17:51:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch97_loss0.10713801011443139.pypots
2024-05-22 17:51:37 [INFO]: Epoch 098 - training loss: 0.1169, validation loss: 0.1070
2024-05-22 17:51:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch98_loss0.10704808607697487.pypots
2024-05-22 17:51:53 [INFO]: Epoch 099 - training loss: 0.1196, validation loss: 0.1075
2024-05-22 17:51:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI_epoch99_loss0.10746337026357651.pypots
2024-05-22 17:51:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:51:53 [INFO]: Finished training. The best model is from epoch#89.
2024-05-22 17:51:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/20240522_T172442/CSDI.pypots
2024-05-22 17:54:11 [INFO]: CSDI on Air-Quality: MAE=0.1045, MSE=0.0929
2024-05-22 17:54:11 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/CSDI_air_quality/imputation.pkl
2024-05-22 17:54:11 [INFO]: Using the given device: cuda:0
2024-05-22 17:54:11 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/GPVAE_air_quality/20240522_T175411
2024-05-22 17:54:11 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/GPVAE_air_quality/20240522_T175411/tensorboard
2024-05-22 17:54:12 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-22 17:54:12 [INFO]: Epoch 001 - training loss: 63707.2052, validation loss: 0.6330
2024-05-22 17:54:12 [INFO]: Epoch 002 - training loss: 42004.3371, validation loss: 0.5669
2024-05-22 17:54:12 [INFO]: Epoch 003 - training loss: 41744.0444, validation loss: 0.5064
2024-05-22 17:54:13 [INFO]: Epoch 004 - training loss: 41606.4288, validation loss: 0.4409
2024-05-22 17:54:13 [INFO]: Epoch 005 - training loss: 41594.0302, validation loss: 0.4187
2024-05-22 17:54:13 [INFO]: Epoch 006 - training loss: 41496.5308, validation loss: 0.3840
2024-05-22 17:54:13 [INFO]: Epoch 007 - training loss: 41471.8103, validation loss: 0.3643
2024-05-22 17:54:14 [INFO]: Epoch 008 - training loss: 41423.1214, validation loss: 0.3734
2024-05-22 17:54:14 [INFO]: Epoch 009 - training loss: 41392.6058, validation loss: 0.3260
2024-05-22 17:54:14 [INFO]: Epoch 010 - training loss: 41360.6234, validation loss: 0.3141
2024-05-22 17:54:14 [INFO]: Epoch 011 - training loss: 41377.3322, validation loss: 0.3211
2024-05-22 17:54:15 [INFO]: Epoch 012 - training loss: 41340.4725, validation loss: 0.3047
2024-05-22 17:54:15 [INFO]: Epoch 013 - training loss: 41323.6264, validation loss: 0.2893
2024-05-22 17:54:15 [INFO]: Epoch 014 - training loss: 41320.0694, validation loss: 0.3042
2024-05-22 17:54:15 [INFO]: Epoch 015 - training loss: 41373.8124, validation loss: 0.3076
2024-05-22 17:54:16 [INFO]: Epoch 016 - training loss: 41334.5564, validation loss: 0.3022
2024-05-22 17:54:16 [INFO]: Epoch 017 - training loss: 41303.0027, validation loss: 0.2963
2024-05-22 17:54:16 [INFO]: Epoch 018 - training loss: 41281.3009, validation loss: 0.2765
2024-05-22 17:54:16 [INFO]: Epoch 019 - training loss: 41262.0294, validation loss: 0.2702
2024-05-22 17:54:17 [INFO]: Epoch 020 - training loss: 41259.6554, validation loss: 0.2835
2024-05-22 17:54:17 [INFO]: Epoch 021 - training loss: 41288.4945, validation loss: 0.3143
2024-05-22 17:54:17 [INFO]: Epoch 022 - training loss: 41277.7451, validation loss: 0.2660
2024-05-22 17:54:17 [INFO]: Epoch 023 - training loss: 41244.2316, validation loss: 0.2512
2024-05-22 17:54:18 [INFO]: Epoch 024 - training loss: 41241.1957, validation loss: 0.2414
2024-05-22 17:54:18 [INFO]: Epoch 025 - training loss: 41231.8045, validation loss: 0.2483
2024-05-22 17:54:18 [INFO]: Epoch 026 - training loss: 41228.9236, validation loss: 0.2440
2024-05-22 17:54:18 [INFO]: Epoch 027 - training loss: 41224.4719, validation loss: 0.2480
2024-05-22 17:54:19 [INFO]: Epoch 028 - training loss: 41246.7405, validation loss: 0.2433
2024-05-22 17:54:19 [INFO]: Epoch 029 - training loss: 41265.3571, validation loss: 0.2438
2024-05-22 17:54:19 [INFO]: Epoch 030 - training loss: 41227.3514, validation loss: 0.2315
2024-05-22 17:54:19 [INFO]: Epoch 031 - training loss: 41219.3225, validation loss: 0.2379
2024-05-22 17:54:19 [INFO]: Epoch 032 - training loss: 41212.2510, validation loss: 0.2252
2024-05-22 17:54:20 [INFO]: Epoch 033 - training loss: 41208.7859, validation loss: 0.2324
2024-05-22 17:54:20 [INFO]: Epoch 034 - training loss: 41203.0917, validation loss: 0.2517
2024-05-22 17:54:20 [INFO]: Epoch 035 - training loss: 41244.7361, validation loss: 0.2258
2024-05-22 17:54:20 [INFO]: Epoch 036 - training loss: 41217.9852, validation loss: 0.2367
2024-05-22 17:54:21 [INFO]: Epoch 037 - training loss: 41212.6528, validation loss: 0.2368
2024-05-22 17:54:21 [INFO]: Epoch 038 - training loss: 41193.0705, validation loss: 0.2260
2024-05-22 17:54:21 [INFO]: Epoch 039 - training loss: 41193.8573, validation loss: 0.2261
2024-05-22 17:54:21 [INFO]: Epoch 040 - training loss: 41188.4207, validation loss: 0.2367
2024-05-22 17:54:22 [INFO]: Epoch 041 - training loss: 41179.9596, validation loss: 0.2288
2024-05-22 17:54:22 [INFO]: Epoch 042 - training loss: 41182.1276, validation loss: 0.2398
2024-05-22 17:54:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:54:22 [INFO]: Finished training. The best model is from epoch#32.
2024-05-22 17:54:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/GPVAE_air_quality/20240522_T175411/GPVAE.pypots
2024-05-22 17:54:22 [INFO]: GP-VAE on Air-Quality: MAE=0.2954, MSE=0.2529
2024-05-22 17:54:22 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/GPVAE_air_quality/imputation.pkl
2024-05-22 17:54:22 [INFO]: Using the given device: cuda:0
2024-05-22 17:54:22 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/USGAN_air_quality/20240522_T175422
2024-05-22 17:54:22 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/USGAN_air_quality/20240522_T175422/tensorboard
2024-05-22 17:54:22 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-22 17:54:26 [INFO]: Epoch 001 - generator training loss: 0.6231, discriminator training loss: 0.2892, validation loss: 0.4988
2024-05-22 17:54:29 [INFO]: Epoch 002 - generator training loss: 0.2911, discriminator training loss: 0.0673, validation loss: 0.3685
2024-05-22 17:54:33 [INFO]: Epoch 003 - generator training loss: 0.2166, discriminator training loss: 0.0633, validation loss: 0.3042
2024-05-22 17:54:36 [INFO]: Epoch 004 - generator training loss: 0.1798, discriminator training loss: 0.0622, validation loss: 0.2632
2024-05-22 17:54:40 [INFO]: Epoch 005 - generator training loss: 0.1557, discriminator training loss: 0.0615, validation loss: 0.2368
2024-05-22 17:54:43 [INFO]: Epoch 006 - generator training loss: 0.1370, discriminator training loss: 0.0609, validation loss: 0.2188
2024-05-22 17:54:47 [INFO]: Epoch 007 - generator training loss: 0.1217, discriminator training loss: 0.0612, validation loss: 0.2052
2024-05-22 17:54:50 [INFO]: Epoch 008 - generator training loss: 0.1120, discriminator training loss: 0.0600, validation loss: 0.1938
2024-05-22 17:54:54 [INFO]: Epoch 009 - generator training loss: 0.1065, discriminator training loss: 0.0590, validation loss: 0.1857
2024-05-22 17:54:57 [INFO]: Epoch 010 - generator training loss: 0.0950, discriminator training loss: 0.0589, validation loss: 0.1779
2024-05-22 17:55:00 [INFO]: Epoch 011 - generator training loss: 0.0902, discriminator training loss: 0.0576, validation loss: 0.1726
2024-05-22 17:55:04 [INFO]: Epoch 012 - generator training loss: 0.0839, discriminator training loss: 0.0568, validation loss: 0.1673
2024-05-22 17:55:07 [INFO]: Epoch 013 - generator training loss: 0.0818, discriminator training loss: 0.0552, validation loss: 0.1628
2024-05-22 17:55:11 [INFO]: Epoch 014 - generator training loss: 0.0778, discriminator training loss: 0.0537, validation loss: 0.1593
2024-05-22 17:55:14 [INFO]: Epoch 015 - generator training loss: 0.0754, discriminator training loss: 0.0519, validation loss: 0.1566
2024-05-22 17:55:18 [INFO]: Epoch 016 - generator training loss: 0.0748, discriminator training loss: 0.0500, validation loss: 0.1526
2024-05-22 17:55:21 [INFO]: Epoch 017 - generator training loss: 0.0726, discriminator training loss: 0.0483, validation loss: 0.1501
2024-05-22 17:55:24 [INFO]: Epoch 018 - generator training loss: 0.0703, discriminator training loss: 0.0472, validation loss: 0.1473
2024-05-22 17:55:28 [INFO]: Epoch 019 - generator training loss: 0.0690, discriminator training loss: 0.0462, validation loss: 0.1457
2024-05-22 17:55:31 [INFO]: Epoch 020 - generator training loss: 0.0669, discriminator training loss: 0.0451, validation loss: 0.1427
2024-05-22 17:55:35 [INFO]: Epoch 021 - generator training loss: 0.0652, discriminator training loss: 0.0447, validation loss: 0.1403
2024-05-22 17:55:38 [INFO]: Epoch 022 - generator training loss: 0.0650, discriminator training loss: 0.0439, validation loss: 0.1390
2024-05-22 17:55:42 [INFO]: Epoch 023 - generator training loss: 0.0625, discriminator training loss: 0.0434, validation loss: 0.1367
2024-05-22 17:55:45 [INFO]: Epoch 024 - generator training loss: 0.0607, discriminator training loss: 0.0425, validation loss: 0.1353
2024-05-22 17:55:48 [INFO]: Epoch 025 - generator training loss: 0.0596, discriminator training loss: 0.0421, validation loss: 0.1335
2024-05-22 17:55:52 [INFO]: Epoch 026 - generator training loss: 0.0587, discriminator training loss: 0.0408, validation loss: 0.1321
2024-05-22 17:55:55 [INFO]: Epoch 027 - generator training loss: 0.0577, discriminator training loss: 0.0398, validation loss: 0.1304
2024-05-22 17:55:59 [INFO]: Epoch 028 - generator training loss: 0.0568, discriminator training loss: 0.0393, validation loss: 0.1290
2024-05-22 17:56:02 [INFO]: Epoch 029 - generator training loss: 0.0567, discriminator training loss: 0.0385, validation loss: 0.1283
2024-05-22 17:56:06 [INFO]: Epoch 030 - generator training loss: 0.0549, discriminator training loss: 0.0381, validation loss: 0.1269
2024-05-22 17:56:09 [INFO]: Epoch 031 - generator training loss: 0.0546, discriminator training loss: 0.0373, validation loss: 0.1260
2024-05-22 17:56:13 [INFO]: Epoch 032 - generator training loss: 0.0535, discriminator training loss: 0.0364, validation loss: 0.1251
2024-05-22 17:56:16 [INFO]: Epoch 033 - generator training loss: 0.0538, discriminator training loss: 0.0356, validation loss: 0.1242
2024-05-22 17:56:20 [INFO]: Epoch 034 - generator training loss: 0.0532, discriminator training loss: 0.0345, validation loss: 0.1223
2024-05-22 17:56:23 [INFO]: Epoch 035 - generator training loss: 0.0527, discriminator training loss: 0.0342, validation loss: 0.1220
2024-05-22 17:56:26 [INFO]: Epoch 036 - generator training loss: 0.0523, discriminator training loss: 0.0331, validation loss: 0.1203
2024-05-22 17:56:30 [INFO]: Epoch 037 - generator training loss: 0.0511, discriminator training loss: 0.0325, validation loss: 0.1199
2024-05-22 17:56:33 [INFO]: Epoch 038 - generator training loss: 0.0521, discriminator training loss: 0.0318, validation loss: 0.1195
2024-05-22 17:56:37 [INFO]: Epoch 039 - generator training loss: 0.0510, discriminator training loss: 0.0313, validation loss: 0.1188
2024-05-22 17:56:40 [INFO]: Epoch 040 - generator training loss: 0.0503, discriminator training loss: 0.0305, validation loss: 0.1174
2024-05-22 17:56:44 [INFO]: Epoch 041 - generator training loss: 0.0500, discriminator training loss: 0.0299, validation loss: 0.1168
2024-05-22 17:56:47 [INFO]: Epoch 042 - generator training loss: 0.0502, discriminator training loss: 0.0293, validation loss: 0.1160
2024-05-22 17:56:51 [INFO]: Epoch 043 - generator training loss: 0.0495, discriminator training loss: 0.0289, validation loss: 0.1159
2024-05-22 17:56:54 [INFO]: Epoch 044 - generator training loss: 0.0486, discriminator training loss: 0.0285, validation loss: 0.1149
2024-05-22 17:56:58 [INFO]: Epoch 045 - generator training loss: 0.0489, discriminator training loss: 0.0278, validation loss: 0.1141
2024-05-22 17:57:01 [INFO]: Epoch 046 - generator training loss: 0.0488, discriminator training loss: 0.0272, validation loss: 0.1136
2024-05-22 17:57:04 [INFO]: Epoch 047 - generator training loss: 0.0481, discriminator training loss: 0.0267, validation loss: 0.1134
2024-05-22 17:57:08 [INFO]: Epoch 048 - generator training loss: 0.0492, discriminator training loss: 0.0263, validation loss: 0.1127
2024-05-22 17:57:11 [INFO]: Epoch 049 - generator training loss: 0.0475, discriminator training loss: 0.0259, validation loss: 0.1119
2024-05-22 17:57:15 [INFO]: Epoch 050 - generator training loss: 0.0477, discriminator training loss: 0.0256, validation loss: 0.1112
2024-05-22 17:57:18 [INFO]: Epoch 051 - generator training loss: 0.0471, discriminator training loss: 0.0251, validation loss: 0.1114
2024-05-22 17:57:22 [INFO]: Epoch 052 - generator training loss: 0.0464, discriminator training loss: 0.0247, validation loss: 0.1108
2024-05-22 17:57:25 [INFO]: Epoch 053 - generator training loss: 0.0458, discriminator training loss: 0.0244, validation loss: 0.1100
2024-05-22 17:57:28 [INFO]: Epoch 054 - generator training loss: 0.0454, discriminator training loss: 0.0237, validation loss: 0.1096
2024-05-22 17:57:32 [INFO]: Epoch 055 - generator training loss: 0.0460, discriminator training loss: 0.0236, validation loss: 0.1090
2024-05-22 17:57:35 [INFO]: Epoch 056 - generator training loss: 0.0454, discriminator training loss: 0.0231, validation loss: 0.1087
2024-05-22 17:57:39 [INFO]: Epoch 057 - generator training loss: 0.0446, discriminator training loss: 0.0228, validation loss: 0.1078
2024-05-22 17:57:42 [INFO]: Epoch 058 - generator training loss: 0.0438, discriminator training loss: 0.0225, validation loss: 0.1067
2024-05-22 17:57:46 [INFO]: Epoch 059 - generator training loss: 0.0437, discriminator training loss: 0.0223, validation loss: 0.1067
2024-05-22 17:57:49 [INFO]: Epoch 060 - generator training loss: 0.0432, discriminator training loss: 0.0220, validation loss: 0.1063
2024-05-22 17:57:53 [INFO]: Epoch 061 - generator training loss: 0.0428, discriminator training loss: 0.0217, validation loss: 0.1055
2024-05-22 17:57:56 [INFO]: Epoch 062 - generator training loss: 0.0434, discriminator training loss: 0.0218, validation loss: 0.1051
2024-05-22 17:57:59 [INFO]: Epoch 063 - generator training loss: 0.0423, discriminator training loss: 0.0211, validation loss: 0.1045
2024-05-22 17:58:03 [INFO]: Epoch 064 - generator training loss: 0.0419, discriminator training loss: 0.0209, validation loss: 0.1042
2024-05-22 17:58:06 [INFO]: Epoch 065 - generator training loss: 0.0420, discriminator training loss: 0.0208, validation loss: 0.1038
2024-05-22 17:58:10 [INFO]: Epoch 066 - generator training loss: 0.0417, discriminator training loss: 0.0206, validation loss: 0.1035
2024-05-22 17:58:13 [INFO]: Epoch 067 - generator training loss: 0.0411, discriminator training loss: 0.0202, validation loss: 0.1032
2024-05-22 17:58:17 [INFO]: Epoch 068 - generator training loss: 0.0406, discriminator training loss: 0.0198, validation loss: 0.1024
2024-05-22 17:58:20 [INFO]: Epoch 069 - generator training loss: 0.0410, discriminator training loss: 0.0198, validation loss: 0.1023
2024-05-22 17:58:23 [INFO]: Epoch 070 - generator training loss: 0.0399, discriminator training loss: 0.0198, validation loss: 0.1018
2024-05-22 17:58:27 [INFO]: Epoch 071 - generator training loss: 0.0394, discriminator training loss: 0.0195, validation loss: 0.1022
2024-05-22 17:58:30 [INFO]: Epoch 072 - generator training loss: 0.0401, discriminator training loss: 0.0193, validation loss: 0.1023
2024-05-22 17:58:34 [INFO]: Epoch 073 - generator training loss: 0.0396, discriminator training loss: 0.0192, validation loss: 0.1013
2024-05-22 17:58:37 [INFO]: Epoch 074 - generator training loss: 0.0393, discriminator training loss: 0.0187, validation loss: 0.1016
2024-05-22 17:58:41 [INFO]: Epoch 075 - generator training loss: 0.0384, discriminator training loss: 0.0187, validation loss: 0.1008
2024-05-22 17:58:44 [INFO]: Epoch 076 - generator training loss: 0.0396, discriminator training loss: 0.0185, validation loss: 0.1001
2024-05-22 17:58:48 [INFO]: Epoch 077 - generator training loss: 0.0387, discriminator training loss: 0.0183, validation loss: 0.1004
2024-05-22 17:58:51 [INFO]: Epoch 078 - generator training loss: 0.0378, discriminator training loss: 0.0183, validation loss: 0.1007
2024-05-22 17:58:54 [INFO]: Epoch 079 - generator training loss: 0.0381, discriminator training loss: 0.0182, validation loss: 0.1003
2024-05-22 17:58:58 [INFO]: Epoch 080 - generator training loss: 0.0380, discriminator training loss: 0.0182, validation loss: 0.0996
2024-05-22 17:59:01 [INFO]: Epoch 081 - generator training loss: 0.0375, discriminator training loss: 0.0179, validation loss: 0.0995
2024-05-22 17:59:05 [INFO]: Epoch 082 - generator training loss: 0.0379, discriminator training loss: 0.0177, validation loss: 0.0996
2024-05-22 17:59:08 [INFO]: Epoch 083 - generator training loss: 0.0372, discriminator training loss: 0.0173, validation loss: 0.0992
2024-05-22 17:59:12 [INFO]: Epoch 084 - generator training loss: 0.0376, discriminator training loss: 0.0174, validation loss: 0.0996
2024-05-22 17:59:15 [INFO]: Epoch 085 - generator training loss: 0.0366, discriminator training loss: 0.0172, validation loss: 0.0995
2024-05-22 17:59:18 [INFO]: Epoch 086 - generator training loss: 0.0362, discriminator training loss: 0.0173, validation loss: 0.0992
2024-05-22 17:59:22 [INFO]: Epoch 087 - generator training loss: 0.0360, discriminator training loss: 0.0171, validation loss: 0.0990
2024-05-22 17:59:25 [INFO]: Epoch 088 - generator training loss: 0.0357, discriminator training loss: 0.0170, validation loss: 0.0987
2024-05-22 17:59:29 [INFO]: Epoch 089 - generator training loss: 0.0356, discriminator training loss: 0.0167, validation loss: 0.0984
2024-05-22 17:59:32 [INFO]: Epoch 090 - generator training loss: 0.0357, discriminator training loss: 0.0166, validation loss: 0.0981
2024-05-22 17:59:35 [INFO]: Epoch 091 - generator training loss: 0.0360, discriminator training loss: 0.0165, validation loss: 0.0991
2024-05-22 17:59:39 [INFO]: Epoch 092 - generator training loss: 0.0352, discriminator training loss: 0.0163, validation loss: 0.0981
2024-05-22 17:59:42 [INFO]: Epoch 093 - generator training loss: 0.0348, discriminator training loss: 0.0163, validation loss: 0.0984
2024-05-22 17:59:46 [INFO]: Epoch 094 - generator training loss: 0.0346, discriminator training loss: 0.0163, validation loss: 0.0981
2024-05-22 17:59:49 [INFO]: Epoch 095 - generator training loss: 0.0345, discriminator training loss: 0.0160, validation loss: 0.0982
2024-05-22 17:59:53 [INFO]: Epoch 096 - generator training loss: 0.0342, discriminator training loss: 0.0160, validation loss: 0.0981
2024-05-22 17:59:56 [INFO]: Epoch 097 - generator training loss: 0.0340, discriminator training loss: 0.0159, validation loss: 0.0983
2024-05-22 18:00:00 [INFO]: Epoch 098 - generator training loss: 0.0338, discriminator training loss: 0.0157, validation loss: 0.0981
2024-05-22 18:00:03 [INFO]: Epoch 099 - generator training loss: 0.0336, discriminator training loss: 0.0158, validation loss: 0.0978
2024-05-22 18:00:06 [INFO]: Epoch 100 - generator training loss: 0.0336, discriminator training loss: 0.0156, validation loss: 0.0981
2024-05-22 18:00:10 [INFO]: Epoch 101 - generator training loss: 0.0334, discriminator training loss: 0.0155, validation loss: 0.0985
2024-05-22 18:00:13 [INFO]: Epoch 102 - generator training loss: 0.0339, discriminator training loss: 0.0153, validation loss: 0.0994
2024-05-22 18:00:17 [INFO]: Epoch 103 - generator training loss: 0.0335, discriminator training loss: 0.0152, validation loss: 0.0983
2024-05-22 18:00:20 [INFO]: Epoch 104 - generator training loss: 0.0338, discriminator training loss: 0.0152, validation loss: 0.0978
2024-05-22 18:00:24 [INFO]: Epoch 105 - generator training loss: 0.0336, discriminator training loss: 0.0154, validation loss: 0.0978
2024-05-22 18:00:27 [INFO]: Epoch 106 - generator training loss: 0.0327, discriminator training loss: 0.0150, validation loss: 0.0988
2024-05-22 18:00:30 [INFO]: Epoch 107 - generator training loss: 0.0344, discriminator training loss: 0.0151, validation loss: 0.0983
2024-05-22 18:00:34 [INFO]: Epoch 108 - generator training loss: 0.0333, discriminator training loss: 0.0149, validation loss: 0.0981
2024-05-22 18:00:37 [INFO]: Epoch 109 - generator training loss: 0.0328, discriminator training loss: 0.0148, validation loss: 0.0980
2024-05-22 18:00:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 18:00:37 [INFO]: Finished training. The best model is from epoch#99.
2024-05-22 18:00:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/USGAN_air_quality/20240522_T175422/USGAN.pypots
2024-05-22 18:00:38 [INFO]: US-GAN on Air-Quality: MAE=0.1699, MSE=0.1094
2024-05-22 18:00:38 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/USGAN_air_quality/imputation.pkl
2024-05-22 18:00:38 [INFO]: Using the given device: cuda:0
2024-05-22 18:00:38 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/BRITS_air_quality/20240522_T180038
2024-05-22 18:00:38 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/BRITS_air_quality/20240522_T180038/tensorboard
2024-05-22 18:00:38 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-22 18:00:41 [INFO]: Epoch 001 - training loss: 1.3929, validation loss: 0.8878
2024-05-22 18:00:43 [INFO]: Epoch 002 - training loss: 1.1210, validation loss: 0.6590
2024-05-22 18:00:45 [INFO]: Epoch 003 - training loss: 0.9353, validation loss: 0.5551
2024-05-22 18:00:48 [INFO]: Epoch 004 - training loss: 0.8284, validation loss: 0.4891
2024-05-22 18:00:50 [INFO]: Epoch 005 - training loss: 0.7555, validation loss: 0.4425
2024-05-22 18:00:52 [INFO]: Epoch 006 - training loss: 0.6985, validation loss: 0.4058
2024-05-22 18:00:54 [INFO]: Epoch 007 - training loss: 0.6561, validation loss: 0.3788
2024-05-22 18:00:57 [INFO]: Epoch 008 - training loss: 0.6221, validation loss: 0.3556
2024-05-22 18:00:59 [INFO]: Epoch 009 - training loss: 0.5950, validation loss: 0.3377
2024-05-22 18:01:01 [INFO]: Epoch 010 - training loss: 0.5726, validation loss: 0.3216
2024-05-22 18:01:04 [INFO]: Epoch 011 - training loss: 0.5566, validation loss: 0.3085
2024-05-22 18:01:06 [INFO]: Epoch 012 - training loss: 0.5407, validation loss: 0.2977
2024-05-22 18:01:08 [INFO]: Epoch 013 - training loss: 0.5274, validation loss: 0.2879
2024-05-22 18:01:11 [INFO]: Epoch 014 - training loss: 0.5157, validation loss: 0.2790
2024-05-22 18:01:13 [INFO]: Epoch 015 - training loss: 0.5054, validation loss: 0.2719
2024-05-22 18:01:15 [INFO]: Epoch 016 - training loss: 0.4958, validation loss: 0.2652
2024-05-22 18:01:17 [INFO]: Epoch 017 - training loss: 0.4868, validation loss: 0.2595
2024-05-22 18:01:20 [INFO]: Epoch 018 - training loss: 0.4783, validation loss: 0.2536
2024-05-22 18:01:22 [INFO]: Epoch 019 - training loss: 0.4706, validation loss: 0.2488
2024-05-22 18:01:24 [INFO]: Epoch 020 - training loss: 0.4638, validation loss: 0.2441
2024-05-22 18:01:27 [INFO]: Epoch 021 - training loss: 0.4563, validation loss: 0.2395
2024-05-22 18:01:29 [INFO]: Epoch 022 - training loss: 0.4495, validation loss: 0.2356
2024-05-22 18:01:31 [INFO]: Epoch 023 - training loss: 0.4430, validation loss: 0.2317
2024-05-22 18:01:34 [INFO]: Epoch 024 - training loss: 0.4376, validation loss: 0.2285
2024-05-22 18:01:36 [INFO]: Epoch 025 - training loss: 0.4318, validation loss: 0.2250
2024-05-22 18:01:38 [INFO]: Epoch 026 - training loss: 0.4267, validation loss: 0.2211
2024-05-22 18:01:40 [INFO]: Epoch 027 - training loss: 0.4214, validation loss: 0.2182
2024-05-22 18:01:43 [INFO]: Epoch 028 - training loss: 0.4160, validation loss: 0.2149
2024-05-22 18:01:45 [INFO]: Epoch 029 - training loss: 0.4112, validation loss: 0.2117
2024-05-22 18:01:47 [INFO]: Epoch 030 - training loss: 0.4068, validation loss: 0.2088
2024-05-22 18:01:50 [INFO]: Epoch 031 - training loss: 0.4021, validation loss: 0.2062
2024-05-22 18:01:52 [INFO]: Epoch 032 - training loss: 0.3976, validation loss: 0.2040
2024-05-22 18:01:54 [INFO]: Epoch 033 - training loss: 0.3938, validation loss: 0.2012
2024-05-22 18:01:56 [INFO]: Epoch 034 - training loss: 0.3899, validation loss: 0.1986
2024-05-22 18:01:59 [INFO]: Epoch 035 - training loss: 0.3856, validation loss: 0.1962
2024-05-22 18:02:01 [INFO]: Epoch 036 - training loss: 0.3833, validation loss: 0.1935
2024-05-22 18:02:03 [INFO]: Epoch 037 - training loss: 0.3792, validation loss: 0.1910
2024-05-22 18:02:06 [INFO]: Epoch 038 - training loss: 0.3751, validation loss: 0.1888
2024-05-22 18:02:08 [INFO]: Epoch 039 - training loss: 0.3711, validation loss: 0.1863
2024-05-22 18:02:10 [INFO]: Epoch 040 - training loss: 0.3691, validation loss: 0.1841
2024-05-22 18:02:13 [INFO]: Epoch 041 - training loss: 0.3651, validation loss: 0.1824
2024-05-22 18:02:15 [INFO]: Epoch 042 - training loss: 0.3629, validation loss: 0.1797
2024-05-22 18:02:17 [INFO]: Epoch 043 - training loss: 0.3599, validation loss: 0.1781
2024-05-22 18:02:20 [INFO]: Epoch 044 - training loss: 0.3571, validation loss: 0.1758
2024-05-22 18:02:22 [INFO]: Epoch 045 - training loss: 0.3539, validation loss: 0.1745
2024-05-22 18:02:24 [INFO]: Epoch 046 - training loss: 0.3513, validation loss: 0.1723
2024-05-22 18:02:27 [INFO]: Epoch 047 - training loss: 0.3494, validation loss: 0.1704
2024-05-22 18:02:29 [INFO]: Epoch 048 - training loss: 0.3454, validation loss: 0.1685
2024-05-22 18:02:31 [INFO]: Epoch 049 - training loss: 0.3439, validation loss: 0.1674
2024-05-22 18:02:33 [INFO]: Epoch 050 - training loss: 0.3410, validation loss: 0.1656
2024-05-22 18:02:36 [INFO]: Epoch 051 - training loss: 0.3387, validation loss: 0.1638
2024-05-22 18:02:38 [INFO]: Epoch 052 - training loss: 0.3363, validation loss: 0.1625
2024-05-22 18:02:40 [INFO]: Epoch 053 - training loss: 0.3338, validation loss: 0.1612
2024-05-22 18:02:43 [INFO]: Epoch 054 - training loss: 0.3317, validation loss: 0.1596
2024-05-22 18:02:45 [INFO]: Epoch 055 - training loss: 0.3303, validation loss: 0.1585
2024-05-22 18:02:47 [INFO]: Epoch 056 - training loss: 0.3284, validation loss: 0.1569
2024-05-22 18:02:50 [INFO]: Epoch 057 - training loss: 0.3260, validation loss: 0.1555
2024-05-22 18:02:52 [INFO]: Epoch 058 - training loss: 0.3245, validation loss: 0.1544
2024-05-22 18:02:54 [INFO]: Epoch 059 - training loss: 0.3228, validation loss: 0.1532
2024-05-22 18:02:56 [INFO]: Epoch 060 - training loss: 0.3215, validation loss: 0.1519
2024-05-22 18:02:59 [INFO]: Epoch 061 - training loss: 0.3199, validation loss: 0.1508
2024-05-22 18:03:01 [INFO]: Epoch 062 - training loss: 0.3179, validation loss: 0.1498
2024-05-22 18:03:03 [INFO]: Epoch 063 - training loss: 0.3162, validation loss: 0.1487
2024-05-22 18:03:06 [INFO]: Epoch 064 - training loss: 0.3148, validation loss: 0.1476
2024-05-22 18:03:08 [INFO]: Epoch 065 - training loss: 0.3144, validation loss: 0.1466
2024-05-22 18:03:10 [INFO]: Epoch 066 - training loss: 0.3120, validation loss: 0.1458
2024-05-22 18:03:13 [INFO]: Epoch 067 - training loss: 0.3108, validation loss: 0.1446
2024-05-22 18:03:15 [INFO]: Epoch 068 - training loss: 0.3090, validation loss: 0.1440
2024-05-22 18:03:17 [INFO]: Epoch 069 - training loss: 0.3080, validation loss: 0.1429
2024-05-22 18:03:20 [INFO]: Epoch 070 - training loss: 0.3066, validation loss: 0.1420
2024-05-22 18:03:22 [INFO]: Epoch 071 - training loss: 0.3053, validation loss: 0.1411
2024-05-22 18:03:24 [INFO]: Epoch 072 - training loss: 0.3044, validation loss: 0.1405
2024-05-22 18:03:26 [INFO]: Epoch 073 - training loss: 0.3030, validation loss: 0.1396
2024-05-22 18:03:29 [INFO]: Epoch 074 - training loss: 0.3024, validation loss: 0.1387
2024-05-22 18:03:31 [INFO]: Epoch 075 - training loss: 0.3011, validation loss: 0.1382
2024-05-22 18:03:33 [INFO]: Epoch 076 - training loss: 0.2999, validation loss: 0.1373
2024-05-22 18:03:36 [INFO]: Epoch 077 - training loss: 0.2988, validation loss: 0.1367
2024-05-22 18:03:38 [INFO]: Epoch 078 - training loss: 0.2979, validation loss: 0.1360
2024-05-22 18:03:40 [INFO]: Epoch 079 - training loss: 0.2974, validation loss: 0.1355
2024-05-22 18:03:43 [INFO]: Epoch 080 - training loss: 0.2963, validation loss: 0.1343
2024-05-22 18:03:45 [INFO]: Epoch 081 - training loss: 0.2945, validation loss: 0.1338
2024-05-22 18:03:47 [INFO]: Epoch 082 - training loss: 0.2940, validation loss: 0.1334
2024-05-22 18:03:49 [INFO]: Epoch 083 - training loss: 0.2929, validation loss: 0.1326
2024-05-22 18:03:52 [INFO]: Epoch 084 - training loss: 0.2921, validation loss: 0.1319
2024-05-22 18:03:54 [INFO]: Epoch 085 - training loss: 0.2914, validation loss: 0.1315
2024-05-22 18:03:56 [INFO]: Epoch 086 - training loss: 0.2906, validation loss: 0.1311
2024-05-22 18:03:59 [INFO]: Epoch 087 - training loss: 0.2894, validation loss: 0.1305
2024-05-22 18:04:01 [INFO]: Epoch 088 - training loss: 0.2886, validation loss: 0.1301
2024-05-22 18:04:03 [INFO]: Epoch 089 - training loss: 0.2880, validation loss: 0.1294
2024-05-22 18:04:06 [INFO]: Epoch 090 - training loss: 0.2874, validation loss: 0.1289
2024-05-22 18:04:08 [INFO]: Epoch 091 - training loss: 0.2860, validation loss: 0.1285
2024-05-22 18:04:10 [INFO]: Epoch 092 - training loss: 0.2855, validation loss: 0.1281
2024-05-22 18:04:12 [INFO]: Epoch 093 - training loss: 0.2850, validation loss: 0.1277
2024-05-22 18:04:15 [INFO]: Epoch 094 - training loss: 0.2842, validation loss: 0.1272
2024-05-22 18:04:17 [INFO]: Epoch 095 - training loss: 0.2836, validation loss: 0.1267
2024-05-22 18:04:19 [INFO]: Epoch 096 - training loss: 0.2831, validation loss: 0.1262
2024-05-22 18:04:22 [INFO]: Epoch 097 - training loss: 0.2826, validation loss: 0.1258
2024-05-22 18:04:24 [INFO]: Epoch 098 - training loss: 0.2815, validation loss: 0.1253
2024-05-22 18:04:26 [INFO]: Epoch 099 - training loss: 0.2808, validation loss: 0.1250
2024-05-22 18:04:29 [INFO]: Epoch 100 - training loss: 0.2799, validation loss: 0.1244
2024-05-22 18:04:31 [INFO]: Epoch 101 - training loss: 0.2800, validation loss: 0.1240
2024-05-22 18:04:33 [INFO]: Epoch 102 - training loss: 0.2791, validation loss: 0.1235
2024-05-22 18:04:35 [INFO]: Epoch 103 - training loss: 0.2784, validation loss: 0.1232
2024-05-22 18:04:38 [INFO]: Epoch 104 - training loss: 0.2774, validation loss: 0.1228
2024-05-22 18:04:40 [INFO]: Epoch 105 - training loss: 0.2771, validation loss: 0.1223
2024-05-22 18:04:42 [INFO]: Epoch 106 - training loss: 0.2764, validation loss: 0.1218
2024-05-22 18:04:45 [INFO]: Epoch 107 - training loss: 0.2758, validation loss: 0.1215
2024-05-22 18:04:47 [INFO]: Epoch 108 - training loss: 0.2751, validation loss: 0.1211
2024-05-22 18:04:49 [INFO]: Epoch 109 - training loss: 0.2753, validation loss: 0.1209
2024-05-22 18:04:51 [INFO]: Epoch 110 - training loss: 0.2747, validation loss: 0.1204
2024-05-22 18:04:54 [INFO]: Epoch 111 - training loss: 0.2738, validation loss: 0.1202
2024-05-22 18:04:56 [INFO]: Epoch 112 - training loss: 0.2727, validation loss: 0.1197
2024-05-22 18:04:58 [INFO]: Epoch 113 - training loss: 0.2727, validation loss: 0.1192
2024-05-22 18:05:01 [INFO]: Epoch 114 - training loss: 0.2716, validation loss: 0.1190
2024-05-22 18:05:03 [INFO]: Epoch 115 - training loss: 0.2721, validation loss: 0.1186
2024-05-22 18:05:05 [INFO]: Epoch 116 - training loss: 0.2715, validation loss: 0.1182
2024-05-22 18:05:08 [INFO]: Epoch 117 - training loss: 0.2704, validation loss: 0.1179
2024-05-22 18:05:10 [INFO]: Epoch 118 - training loss: 0.2699, validation loss: 0.1176
2024-05-22 18:05:12 [INFO]: Epoch 119 - training loss: 0.2693, validation loss: 0.1172
2024-05-22 18:05:14 [INFO]: Epoch 120 - training loss: 0.2689, validation loss: 0.1166
2024-05-22 18:05:17 [INFO]: Epoch 121 - training loss: 0.2689, validation loss: 0.1164
2024-05-22 18:05:19 [INFO]: Epoch 122 - training loss: 0.2681, validation loss: 0.1161
2024-05-22 18:05:21 [INFO]: Epoch 123 - training loss: 0.2681, validation loss: 0.1157
2024-05-22 18:05:24 [INFO]: Epoch 124 - training loss: 0.2672, validation loss: 0.1157
2024-05-22 18:05:26 [INFO]: Epoch 125 - training loss: 0.2666, validation loss: 0.1152
2024-05-22 18:05:28 [INFO]: Epoch 126 - training loss: 0.2656, validation loss: 0.1149
2024-05-22 18:05:31 [INFO]: Epoch 127 - training loss: 0.2656, validation loss: 0.1146
2024-05-22 18:05:33 [INFO]: Epoch 128 - training loss: 0.2658, validation loss: 0.1141
2024-05-22 18:05:35 [INFO]: Epoch 129 - training loss: 0.2645, validation loss: 0.1139
2024-05-22 18:05:38 [INFO]: Epoch 130 - training loss: 0.2645, validation loss: 0.1135
2024-05-22 18:05:40 [INFO]: Epoch 131 - training loss: 0.2640, validation loss: 0.1132
2024-05-22 18:05:42 [INFO]: Epoch 132 - training loss: 0.2635, validation loss: 0.1128
2024-05-22 18:05:44 [INFO]: Epoch 133 - training loss: 0.2631, validation loss: 0.1126
2024-05-22 18:05:47 [INFO]: Epoch 134 - training loss: 0.2626, validation loss: 0.1123
2024-05-22 18:05:49 [INFO]: Epoch 135 - training loss: 0.2621, validation loss: 0.1121
2024-05-22 18:05:51 [INFO]: Epoch 136 - training loss: 0.2620, validation loss: 0.1118
2024-05-22 18:05:54 [INFO]: Epoch 137 - training loss: 0.2620, validation loss: 0.1114
2024-05-22 18:05:56 [INFO]: Epoch 138 - training loss: 0.2610, validation loss: 0.1114
2024-05-22 18:05:58 [INFO]: Epoch 139 - training loss: 0.2614, validation loss: 0.1110
2024-05-22 18:06:00 [INFO]: Epoch 140 - training loss: 0.2602, validation loss: 0.1108
2024-05-22 18:06:03 [INFO]: Epoch 141 - training loss: 0.2598, validation loss: 0.1105
2024-05-22 18:06:05 [INFO]: Epoch 142 - training loss: 0.2599, validation loss: 0.1103
2024-05-22 18:06:07 [INFO]: Epoch 143 - training loss: 0.2595, validation loss: 0.1099
2024-05-22 18:06:10 [INFO]: Epoch 144 - training loss: 0.2587, validation loss: 0.1098
2024-05-22 18:06:12 [INFO]: Epoch 145 - training loss: 0.2581, validation loss: 0.1096
2024-05-22 18:06:14 [INFO]: Epoch 146 - training loss: 0.2586, validation loss: 0.1091
2024-05-22 18:06:16 [INFO]: Epoch 147 - training loss: 0.2583, validation loss: 0.1090
2024-05-22 18:06:19 [INFO]: Epoch 148 - training loss: 0.2578, validation loss: 0.1086
2024-05-22 18:06:21 [INFO]: Epoch 149 - training loss: 0.2572, validation loss: 0.1084
2024-05-22 18:06:23 [INFO]: Epoch 150 - training loss: 0.2569, validation loss: 0.1084
2024-05-22 18:06:26 [INFO]: Epoch 151 - training loss: 0.2564, validation loss: 0.1079
2024-05-22 18:06:28 [INFO]: Epoch 152 - training loss: 0.2560, validation loss: 0.1077
2024-05-22 18:06:30 [INFO]: Epoch 153 - training loss: 0.2560, validation loss: 0.1077
2024-05-22 18:06:33 [INFO]: Epoch 154 - training loss: 0.2561, validation loss: 0.1074
2024-05-22 18:06:35 [INFO]: Epoch 155 - training loss: 0.2550, validation loss: 0.1072
2024-05-22 18:06:37 [INFO]: Epoch 156 - training loss: 0.2547, validation loss: 0.1070
2024-05-22 18:06:39 [INFO]: Epoch 157 - training loss: 0.2549, validation loss: 0.1068
2024-05-22 18:06:42 [INFO]: Epoch 158 - training loss: 0.2539, validation loss: 0.1064
2024-05-22 18:06:44 [INFO]: Epoch 159 - training loss: 0.2545, validation loss: 0.1062
2024-05-22 18:06:46 [INFO]: Epoch 160 - training loss: 0.2538, validation loss: 0.1062
2024-05-22 18:06:49 [INFO]: Epoch 161 - training loss: 0.2533, validation loss: 0.1059
2024-05-22 18:06:51 [INFO]: Epoch 162 - training loss: 0.2531, validation loss: 0.1059
2024-05-22 18:06:53 [INFO]: Epoch 163 - training loss: 0.2525, validation loss: 0.1055
2024-05-22 18:06:55 [INFO]: Epoch 164 - training loss: 0.2527, validation loss: 0.1052
2024-05-22 18:06:58 [INFO]: Epoch 165 - training loss: 0.2527, validation loss: 0.1052
2024-05-22 18:07:00 [INFO]: Epoch 166 - training loss: 0.2520, validation loss: 0.1049
2024-05-22 18:07:02 [INFO]: Epoch 167 - training loss: 0.2520, validation loss: 0.1049
2024-05-22 18:07:05 [INFO]: Epoch 168 - training loss: 0.2517, validation loss: 0.1047
2024-05-22 18:07:07 [INFO]: Epoch 169 - training loss: 0.2517, validation loss: 0.1046
2024-05-22 18:07:09 [INFO]: Epoch 170 - training loss: 0.2513, validation loss: 0.1042
2024-05-22 18:07:12 [INFO]: Epoch 171 - training loss: 0.2506, validation loss: 0.1041
2024-05-22 18:07:14 [INFO]: Epoch 172 - training loss: 0.2509, validation loss: 0.1039
2024-05-22 18:07:16 [INFO]: Epoch 173 - training loss: 0.2501, validation loss: 0.1039
2024-05-22 18:07:19 [INFO]: Epoch 174 - training loss: 0.2500, validation loss: 0.1035
2024-05-22 18:07:21 [INFO]: Epoch 175 - training loss: 0.2497, validation loss: 0.1034
2024-05-22 18:07:23 [INFO]: Epoch 176 - training loss: 0.2496, validation loss: 0.1034
2024-05-22 18:07:25 [INFO]: Epoch 177 - training loss: 0.2489, validation loss: 0.1034
2024-05-22 18:07:28 [INFO]: Epoch 178 - training loss: 0.2486, validation loss: 0.1030
2024-05-22 18:07:30 [INFO]: Epoch 179 - training loss: 0.2486, validation loss: 0.1029
2024-05-22 18:07:32 [INFO]: Epoch 180 - training loss: 0.2489, validation loss: 0.1026
2024-05-22 18:07:35 [INFO]: Epoch 181 - training loss: 0.2481, validation loss: 0.1026
2024-05-22 18:07:37 [INFO]: Epoch 182 - training loss: 0.2477, validation loss: 0.1023
2024-05-22 18:07:39 [INFO]: Epoch 183 - training loss: 0.2477, validation loss: 0.1023
2024-05-22 18:07:42 [INFO]: Epoch 184 - training loss: 0.2476, validation loss: 0.1021
2024-05-22 18:07:44 [INFO]: Epoch 185 - training loss: 0.2475, validation loss: 0.1018
2024-05-22 18:07:46 [INFO]: Epoch 186 - training loss: 0.2468, validation loss: 0.1018
2024-05-22 18:07:48 [INFO]: Epoch 187 - training loss: 0.2463, validation loss: 0.1017
2024-05-22 18:07:51 [INFO]: Epoch 188 - training loss: 0.2464, validation loss: 0.1016
2024-05-22 18:07:53 [INFO]: Epoch 189 - training loss: 0.2460, validation loss: 0.1013
2024-05-22 18:07:55 [INFO]: Epoch 190 - training loss: 0.2460, validation loss: 0.1013
2024-05-22 18:07:58 [INFO]: Epoch 191 - training loss: 0.2460, validation loss: 0.1011
2024-05-22 18:08:00 [INFO]: Epoch 192 - training loss: 0.2456, validation loss: 0.1009
2024-05-22 18:08:02 [INFO]: Epoch 193 - training loss: 0.2455, validation loss: 0.1008
2024-05-22 18:08:05 [INFO]: Epoch 194 - training loss: 0.2452, validation loss: 0.1008
2024-05-22 18:08:07 [INFO]: Epoch 195 - training loss: 0.2448, validation loss: 0.1005
2024-05-22 18:08:09 [INFO]: Epoch 196 - training loss: 0.2451, validation loss: 0.1005
2024-05-22 18:08:11 [INFO]: Epoch 197 - training loss: 0.2443, validation loss: 0.1003
2024-05-22 18:08:14 [INFO]: Epoch 198 - training loss: 0.2444, validation loss: 0.1002
2024-05-22 18:08:16 [INFO]: Epoch 199 - training loss: 0.2450, validation loss: 0.1001
2024-05-22 18:08:18 [INFO]: Epoch 200 - training loss: 0.2442, validation loss: 0.1000
2024-05-22 18:08:21 [INFO]: Epoch 201 - training loss: 0.2435, validation loss: 0.0997
2024-05-22 18:08:23 [INFO]: Epoch 202 - training loss: 0.2438, validation loss: 0.0999
2024-05-22 18:08:25 [INFO]: Epoch 203 - training loss: 0.2431, validation loss: 0.0996
2024-05-22 18:08:28 [INFO]: Epoch 204 - training loss: 0.2431, validation loss: 0.0994
2024-05-22 18:08:30 [INFO]: Epoch 205 - training loss: 0.2431, validation loss: 0.0993
2024-05-22 18:08:32 [INFO]: Epoch 206 - training loss: 0.2431, validation loss: 0.0991
2024-05-22 18:08:34 [INFO]: Epoch 207 - training loss: 0.2424, validation loss: 0.0990
2024-05-22 18:08:37 [INFO]: Epoch 208 - training loss: 0.2424, validation loss: 0.0991
2024-05-22 18:08:39 [INFO]: Epoch 209 - training loss: 0.2422, validation loss: 0.0991
2024-05-22 18:08:41 [INFO]: Epoch 210 - training loss: 0.2422, validation loss: 0.0989
2024-05-22 18:08:44 [INFO]: Epoch 211 - training loss: 0.2421, validation loss: 0.0986
2024-05-22 18:08:46 [INFO]: Epoch 212 - training loss: 0.2414, validation loss: 0.0987
2024-05-22 18:08:48 [INFO]: Epoch 213 - training loss: 0.2422, validation loss: 0.0985
2024-05-22 18:08:51 [INFO]: Epoch 214 - training loss: 0.2416, validation loss: 0.0983
2024-05-22 18:08:53 [INFO]: Epoch 215 - training loss: 0.2409, validation loss: 0.0983
2024-05-22 18:08:55 [INFO]: Epoch 216 - training loss: 0.2412, validation loss: 0.0982
2024-05-22 18:08:58 [INFO]: Epoch 217 - training loss: 0.2412, validation loss: 0.0980
2024-05-22 18:09:00 [INFO]: Epoch 218 - training loss: 0.2405, validation loss: 0.0981
2024-05-22 18:09:02 [INFO]: Epoch 219 - training loss: 0.2412, validation loss: 0.0981
2024-05-22 18:09:04 [INFO]: Epoch 220 - training loss: 0.2404, validation loss: 0.0979
2024-05-22 18:09:07 [INFO]: Epoch 221 - training loss: 0.2399, validation loss: 0.0978
2024-05-22 18:09:09 [INFO]: Epoch 222 - training loss: 0.2400, validation loss: 0.0976
2024-05-22 18:09:11 [INFO]: Epoch 223 - training loss: 0.2401, validation loss: 0.0976
2024-05-22 18:09:14 [INFO]: Epoch 224 - training loss: 0.2397, validation loss: 0.0976
2024-05-22 18:09:16 [INFO]: Epoch 225 - training loss: 0.2393, validation loss: 0.0974
2024-05-22 18:09:18 [INFO]: Epoch 226 - training loss: 0.2387, validation loss: 0.0971
2024-05-22 18:09:21 [INFO]: Epoch 227 - training loss: 0.2392, validation loss: 0.0972
2024-05-22 18:09:23 [INFO]: Epoch 228 - training loss: 0.2391, validation loss: 0.0970
2024-05-22 18:09:25 [INFO]: Epoch 229 - training loss: 0.2385, validation loss: 0.0971
2024-05-22 18:09:27 [INFO]: Epoch 230 - training loss: 0.2390, validation loss: 0.0969
2024-05-22 18:09:30 [INFO]: Epoch 231 - training loss: 0.2381, validation loss: 0.0969
2024-05-22 18:09:32 [INFO]: Epoch 232 - training loss: 0.2384, validation loss: 0.0968
2024-05-22 18:09:34 [INFO]: Epoch 233 - training loss: 0.2382, validation loss: 0.0967
2024-05-22 18:09:37 [INFO]: Epoch 234 - training loss: 0.2378, validation loss: 0.0969
2024-05-22 18:09:39 [INFO]: Epoch 235 - training loss: 0.2371, validation loss: 0.0966
2024-05-22 18:09:41 [INFO]: Epoch 236 - training loss: 0.2379, validation loss: 0.0965
2024-05-22 18:09:44 [INFO]: Epoch 237 - training loss: 0.2372, validation loss: 0.0964
2024-05-22 18:09:46 [INFO]: Epoch 238 - training loss: 0.2376, validation loss: 0.0964
2024-05-22 18:09:48 [INFO]: Epoch 239 - training loss: 0.2374, validation loss: 0.0964
2024-05-22 18:09:50 [INFO]: Epoch 240 - training loss: 0.2370, validation loss: 0.0962
2024-05-22 18:09:53 [INFO]: Epoch 241 - training loss: 0.2370, validation loss: 0.0960
2024-05-22 18:09:55 [INFO]: Epoch 242 - training loss: 0.2366, validation loss: 0.0960
2024-05-22 18:09:57 [INFO]: Epoch 243 - training loss: 0.2362, validation loss: 0.0962
2024-05-22 18:10:00 [INFO]: Epoch 244 - training loss: 0.2361, validation loss: 0.0959
2024-05-22 18:10:02 [INFO]: Epoch 245 - training loss: 0.2364, validation loss: 0.0958
2024-05-22 18:10:04 [INFO]: Epoch 246 - training loss: 0.2361, validation loss: 0.0956
2024-05-22 18:10:07 [INFO]: Epoch 247 - training loss: 0.2359, validation loss: 0.0956
2024-05-22 18:10:09 [INFO]: Epoch 248 - training loss: 0.2356, validation loss: 0.0955
2024-05-22 18:10:11 [INFO]: Epoch 249 - training loss: 0.2360, validation loss: 0.0956
2024-05-22 18:10:13 [INFO]: Epoch 250 - training loss: 0.2354, validation loss: 0.0955
2024-05-22 18:10:16 [INFO]: Epoch 251 - training loss: 0.2352, validation loss: 0.0953
2024-05-22 18:10:18 [INFO]: Epoch 252 - training loss: 0.2354, validation loss: 0.0953
2024-05-22 18:10:20 [INFO]: Epoch 253 - training loss: 0.2356, validation loss: 0.0954
2024-05-22 18:10:23 [INFO]: Epoch 254 - training loss: 0.2356, validation loss: 0.0951
2024-05-22 18:10:25 [INFO]: Epoch 255 - training loss: 0.2350, validation loss: 0.0952
2024-05-22 18:10:27 [INFO]: Epoch 256 - training loss: 0.2346, validation loss: 0.0951
2024-05-22 18:10:30 [INFO]: Epoch 257 - training loss: 0.2345, validation loss: 0.0952
2024-05-22 18:10:32 [INFO]: Epoch 258 - training loss: 0.2348, validation loss: 0.0949
2024-05-22 18:10:34 [INFO]: Epoch 259 - training loss: 0.2343, validation loss: 0.0950
2024-05-22 18:10:36 [INFO]: Epoch 260 - training loss: 0.2343, validation loss: 0.0948
2024-05-22 18:10:39 [INFO]: Epoch 261 - training loss: 0.2342, validation loss: 0.0950
2024-05-22 18:10:41 [INFO]: Epoch 262 - training loss: 0.2334, validation loss: 0.0948
2024-05-22 18:10:43 [INFO]: Epoch 263 - training loss: 0.2340, validation loss: 0.0948
2024-05-22 18:10:46 [INFO]: Epoch 264 - training loss: 0.2336, validation loss: 0.0947
2024-05-22 18:10:48 [INFO]: Epoch 265 - training loss: 0.2333, validation loss: 0.0946
2024-05-22 18:10:50 [INFO]: Epoch 266 - training loss: 0.2343, validation loss: 0.0944
2024-05-22 18:10:53 [INFO]: Epoch 267 - training loss: 0.2336, validation loss: 0.0944
2024-05-22 18:10:55 [INFO]: Epoch 268 - training loss: 0.2333, validation loss: 0.0942
2024-05-22 18:10:57 [INFO]: Epoch 269 - training loss: 0.2331, validation loss: 0.0942
2024-05-22 18:11:00 [INFO]: Epoch 270 - training loss: 0.2332, validation loss: 0.0942
2024-05-22 18:11:02 [INFO]: Epoch 271 - training loss: 0.2328, validation loss: 0.0941
2024-05-22 18:11:04 [INFO]: Epoch 272 - training loss: 0.2325, validation loss: 0.0942
2024-05-22 18:11:07 [INFO]: Epoch 273 - training loss: 0.2327, validation loss: 0.0944
2024-05-22 18:11:09 [INFO]: Epoch 274 - training loss: 0.2327, validation loss: 0.0940
2024-05-22 18:11:11 [INFO]: Epoch 275 - training loss: 0.2319, validation loss: 0.0941
2024-05-22 18:11:13 [INFO]: Epoch 276 - training loss: 0.2325, validation loss: 0.0940
2024-05-22 18:11:16 [INFO]: Epoch 277 - training loss: 0.2323, validation loss: 0.0939
2024-05-22 18:11:18 [INFO]: Epoch 278 - training loss: 0.2318, validation loss: 0.0938
2024-05-22 18:11:20 [INFO]: Epoch 279 - training loss: 0.2319, validation loss: 0.0939
2024-05-22 18:11:23 [INFO]: Epoch 280 - training loss: 0.2319, validation loss: 0.0938
2024-05-22 18:11:25 [INFO]: Epoch 281 - training loss: 0.2317, validation loss: 0.0940
2024-05-22 18:11:27 [INFO]: Epoch 282 - training loss: 0.2317, validation loss: 0.0938
2024-05-22 18:11:29 [INFO]: Epoch 283 - training loss: 0.2315, validation loss: 0.0936
2024-05-22 18:11:32 [INFO]: Epoch 284 - training loss: 0.2310, validation loss: 0.0938
2024-05-22 18:11:34 [INFO]: Epoch 285 - training loss: 0.2311, validation loss: 0.0936
2024-05-22 18:11:37 [INFO]: Epoch 286 - training loss: 0.2309, validation loss: 0.0937
2024-05-22 18:11:39 [INFO]: Epoch 287 - training loss: 0.2312, validation loss: 0.0936
2024-05-22 18:11:41 [INFO]: Epoch 288 - training loss: 0.2317, validation loss: 0.0936
2024-05-22 18:11:43 [INFO]: Epoch 289 - training loss: 0.2313, validation loss: 0.0936
2024-05-22 18:11:46 [INFO]: Epoch 290 - training loss: 0.2309, validation loss: 0.0933
2024-05-22 18:11:48 [INFO]: Epoch 291 - training loss: 0.2307, validation loss: 0.0934
2024-05-22 18:11:50 [INFO]: Epoch 292 - training loss: 0.2305, validation loss: 0.0934
2024-05-22 18:11:53 [INFO]: Epoch 293 - training loss: 0.2302, validation loss: 0.0933
2024-05-22 18:11:55 [INFO]: Epoch 294 - training loss: 0.2304, validation loss: 0.0933
2024-05-22 18:11:57 [INFO]: Epoch 295 - training loss: 0.2303, validation loss: 0.0934
2024-05-22 18:12:00 [INFO]: Epoch 296 - training loss: 0.2302, validation loss: 0.0934
2024-05-22 18:12:02 [INFO]: Epoch 297 - training loss: 0.2298, validation loss: 0.0931
2024-05-22 18:12:04 [INFO]: Epoch 298 - training loss: 0.2296, validation loss: 0.0932
2024-05-22 18:12:06 [INFO]: Epoch 299 - training loss: 0.2299, validation loss: 0.0932
2024-05-22 18:12:09 [INFO]: Epoch 300 - training loss: 0.2297, validation loss: 0.0930
2024-05-22 18:12:09 [INFO]: Finished training. The best model is from epoch#300.
2024-05-22 18:12:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/BRITS_air_quality/20240522_T180038/BRITS.pypots
2024-05-22 18:12:09 [INFO]: BRITS on Air-Quality: MAE=0.1421, MSE=0.1057
2024-05-22 18:12:09 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/BRITS_air_quality/imputation.pkl
2024-05-22 18:12:09 [INFO]: Using the given device: cuda:0
2024-05-22 18:12:09 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209
2024-05-22 18:12:09 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/tensorboard
2024-05-22 18:12:09 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-22 18:12:13 [INFO]: Epoch 001 - training loss: 1.4600, validation loss: 0.7688
2024-05-22 18:12:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch1_loss0.7687828063964843.pypots
2024-05-22 18:12:16 [INFO]: Epoch 002 - training loss: 1.0617, validation loss: 0.7167
2024-05-22 18:12:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch2_loss0.7166775763034821.pypots
2024-05-22 18:12:19 [INFO]: Epoch 003 - training loss: 1.0041, validation loss: 0.6974
2024-05-22 18:12:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch3_loss0.6973978638648987.pypots
2024-05-22 18:12:22 [INFO]: Epoch 004 - training loss: 0.9696, validation loss: 0.6858
2024-05-22 18:12:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch4_loss0.6858122199773788.pypots
2024-05-22 18:12:25 [INFO]: Epoch 005 - training loss: 0.9360, validation loss: 0.6767
2024-05-22 18:12:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch5_loss0.6767232030630111.pypots
2024-05-22 18:12:29 [INFO]: Epoch 006 - training loss: 0.9591, validation loss: 0.6696
2024-05-22 18:12:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch6_loss0.6695784837007522.pypots
2024-05-22 18:12:32 [INFO]: Epoch 007 - training loss: 0.9454, validation loss: 0.6659
2024-05-22 18:12:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch7_loss0.6659227102994919.pypots
2024-05-22 18:12:35 [INFO]: Epoch 008 - training loss: 0.9348, validation loss: 0.6624
2024-05-22 18:12:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch8_loss0.66241534948349.pypots
2024-05-22 18:12:38 [INFO]: Epoch 009 - training loss: 0.9201, validation loss: 0.6602
2024-05-22 18:12:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch9_loss0.6602005630731582.pypots
2024-05-22 18:12:41 [INFO]: Epoch 010 - training loss: 0.9292, validation loss: 0.6584
2024-05-22 18:12:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch10_loss0.6583721280097962.pypots
2024-05-22 18:12:44 [INFO]: Epoch 011 - training loss: 0.9230, validation loss: 0.6556
2024-05-22 18:12:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch11_loss0.6556078016757965.pypots
2024-05-22 18:12:47 [INFO]: Epoch 012 - training loss: 0.9152, validation loss: 0.6552
2024-05-22 18:12:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch12_loss0.6551730841398239.pypots
2024-05-22 18:12:50 [INFO]: Epoch 013 - training loss: 0.9111, validation loss: 0.6541
2024-05-22 18:12:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch13_loss0.6541229099035263.pypots
2024-05-22 18:12:54 [INFO]: Epoch 014 - training loss: 0.9231, validation loss: 0.6534
2024-05-22 18:12:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch14_loss0.6533874839544296.pypots
2024-05-22 18:12:57 [INFO]: Epoch 015 - training loss: 0.9003, validation loss: 0.6525
2024-05-22 18:12:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch15_loss0.6524523586034775.pypots
2024-05-22 18:13:00 [INFO]: Epoch 016 - training loss: 0.9045, validation loss: 0.6521
2024-05-22 18:13:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch16_loss0.6521268546581268.pypots
2024-05-22 18:13:03 [INFO]: Epoch 017 - training loss: 0.8949, validation loss: 0.6517
2024-05-22 18:13:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch17_loss0.6517484575510025.pypots
2024-05-22 18:13:06 [INFO]: Epoch 018 - training loss: 0.8838, validation loss: 0.6520
2024-05-22 18:13:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch18_loss0.6520290076732635.pypots
2024-05-22 18:13:09 [INFO]: Epoch 019 - training loss: 0.8786, validation loss: 0.6519
2024-05-22 18:13:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch19_loss0.6519235998392106.pypots
2024-05-22 18:13:12 [INFO]: Epoch 020 - training loss: 0.8804, validation loss: 0.6516
2024-05-22 18:13:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch20_loss0.6515725463628769.pypots
2024-05-22 18:13:15 [INFO]: Epoch 021 - training loss: 0.8809, validation loss: 0.6513
2024-05-22 18:13:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch21_loss0.651339054107666.pypots
2024-05-22 18:13:18 [INFO]: Epoch 022 - training loss: 0.8869, validation loss: 0.6520
2024-05-22 18:13:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch22_loss0.6519793778657913.pypots
2024-05-22 18:13:22 [INFO]: Epoch 023 - training loss: 0.8729, validation loss: 0.6519
2024-05-22 18:13:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch23_loss0.6519438028335571.pypots
2024-05-22 18:13:25 [INFO]: Epoch 024 - training loss: 0.8755, validation loss: 0.6521
2024-05-22 18:13:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch24_loss0.6521061152219773.pypots
2024-05-22 18:13:28 [INFO]: Epoch 025 - training loss: 0.8777, validation loss: 0.6542
2024-05-22 18:13:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch25_loss0.6541999012231827.pypots
2024-05-22 18:13:31 [INFO]: Epoch 026 - training loss: 0.8681, validation loss: 0.6549
2024-05-22 18:13:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch26_loss0.6548739820718765.pypots
2024-05-22 18:13:34 [INFO]: Epoch 027 - training loss: 0.8951, validation loss: 0.6546
2024-05-22 18:13:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch27_loss0.6545865088701248.pypots
2024-05-22 18:13:37 [INFO]: Epoch 028 - training loss: 0.8802, validation loss: 0.6542
2024-05-22 18:13:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch28_loss0.6541749924421311.pypots
2024-05-22 18:13:40 [INFO]: Epoch 029 - training loss: 0.8766, validation loss: 0.6590
2024-05-22 18:13:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch29_loss0.6589947462081909.pypots
2024-05-22 18:13:43 [INFO]: Epoch 030 - training loss: 0.8536, validation loss: 0.6556
2024-05-22 18:13:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch30_loss0.6555770009756088.pypots
2024-05-22 18:13:46 [INFO]: Epoch 031 - training loss: 0.8510, validation loss: 0.6638
2024-05-22 18:13:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN_epoch31_loss0.6637968301773072.pypots
2024-05-22 18:13:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 18:13:46 [INFO]: Finished training. The best model is from epoch#21.
2024-05-22 18:13:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/20240522_T181209/MRNN.pypots
2024-05-22 18:13:47 [INFO]: MRNN on Air-Quality: MAE=0.5257, MSE=0.6228
2024-05-22 18:13:47 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/MRNN_air_quality/imputation.pkl
2024-05-22 18:13:47 [INFO]: Using the given device: cpu
2024-05-22 18:13:47 [INFO]: LOCF on Air-Quality: MAE=0.2062, MSE=0.2674
2024-05-22 18:13:47 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_air_quality".
2024-05-22 18:13:47 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/LOCF_air_quality/imputation.pkl
2024-05-22 18:13:47 [INFO]: Median on Air-Quality: MAE=0.6602, MSE=1.0006
2024-05-22 18:13:47 [INFO]: Successfully created the given path "saved_results/round_1/Median_air_quality".
2024-05-22 18:13:47 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/Median_air_quality/imputation.pkl
2024-05-22 18:13:47 [INFO]: Mean on Air-Quality: MAE=0.6921, MSE=0.9434
2024-05-22 18:13:47 [INFO]: Successfully created the given path "saved_results/round_1/Mean_air_quality".
2024-05-22 18:13:47 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/Mean_air_quality/imputation.pkl
2024-05-22 18:13:47 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-22 18:13:47 [INFO]: Using the given device: cuda:0
2024-05-22 18:13:47 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/SAITS_air_quality/20240522_T181347
2024-05-22 18:13:47 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/SAITS_air_quality/20240522_T181347/tensorboard
2024-05-22 18:13:47 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-22 18:13:48 [INFO]: Epoch 001 - training loss: 1.0583, validation loss: 0.4980
2024-05-22 18:13:48 [INFO]: Epoch 002 - training loss: 0.7602, validation loss: 0.3683
2024-05-22 18:13:49 [INFO]: Epoch 003 - training loss: 0.6514, validation loss: 0.2928
2024-05-22 18:13:50 [INFO]: Epoch 004 - training loss: 0.5813, validation loss: 0.2540
2024-05-22 18:13:50 [INFO]: Epoch 005 - training loss: 0.5265, validation loss: 0.2325
2024-05-22 18:13:51 [INFO]: Epoch 006 - training loss: 0.4869, validation loss: 0.2177
2024-05-22 18:13:52 [INFO]: Epoch 007 - training loss: 0.4604, validation loss: 0.2082
2024-05-22 18:13:52 [INFO]: Epoch 008 - training loss: 0.4396, validation loss: 0.2022
2024-05-22 18:13:53 [INFO]: Epoch 009 - training loss: 0.4255, validation loss: 0.1961
2024-05-22 18:13:53 [INFO]: Epoch 010 - training loss: 0.4136, validation loss: 0.1915
2024-05-22 18:13:54 [INFO]: Epoch 011 - training loss: 0.4031, validation loss: 0.1896
2024-05-22 18:13:55 [INFO]: Epoch 012 - training loss: 0.3971, validation loss: 0.1843
2024-05-22 18:13:55 [INFO]: Epoch 013 - training loss: 0.3885, validation loss: 0.1827
2024-05-22 18:13:56 [INFO]: Epoch 014 - training loss: 0.3814, validation loss: 0.1798
2024-05-22 18:13:57 [INFO]: Epoch 015 - training loss: 0.3760, validation loss: 0.1768
2024-05-22 18:13:57 [INFO]: Epoch 016 - training loss: 0.3713, validation loss: 0.1751
2024-05-22 18:13:58 [INFO]: Epoch 017 - training loss: 0.3661, validation loss: 0.1747
2024-05-22 18:13:58 [INFO]: Epoch 018 - training loss: 0.3588, validation loss: 0.1720
2024-05-22 18:13:59 [INFO]: Epoch 019 - training loss: 0.3566, validation loss: 0.1697
2024-05-22 18:14:00 [INFO]: Epoch 020 - training loss: 0.3518, validation loss: 0.1684
2024-05-22 18:14:00 [INFO]: Epoch 021 - training loss: 0.3490, validation loss: 0.1684
2024-05-22 18:14:01 [INFO]: Epoch 022 - training loss: 0.3460, validation loss: 0.1654
2024-05-22 18:14:02 [INFO]: Epoch 023 - training loss: 0.3424, validation loss: 0.1644
2024-05-22 18:14:02 [INFO]: Epoch 024 - training loss: 0.3396, validation loss: 0.1625
2024-05-22 18:14:03 [INFO]: Epoch 025 - training loss: 0.3381, validation loss: 0.1611
2024-05-22 18:14:03 [INFO]: Epoch 026 - training loss: 0.3339, validation loss: 0.1593
2024-05-22 18:14:04 [INFO]: Epoch 027 - training loss: 0.3308, validation loss: 0.1597
2024-05-22 18:14:05 [INFO]: Epoch 028 - training loss: 0.3289, validation loss: 0.1575
2024-05-22 18:14:05 [INFO]: Epoch 029 - training loss: 0.3270, validation loss: 0.1573
2024-05-22 18:14:06 [INFO]: Epoch 030 - training loss: 0.3256, validation loss: 0.1556
2024-05-22 18:14:07 [INFO]: Epoch 031 - training loss: 0.3231, validation loss: 0.1547
2024-05-22 18:14:07 [INFO]: Epoch 032 - training loss: 0.3204, validation loss: 0.1527
2024-05-22 18:14:08 [INFO]: Epoch 033 - training loss: 0.3171, validation loss: 0.1522
2024-05-22 18:14:09 [INFO]: Epoch 034 - training loss: 0.3165, validation loss: 0.1513
2024-05-22 18:14:09 [INFO]: Epoch 035 - training loss: 0.3164, validation loss: 0.1498
2024-05-22 18:14:10 [INFO]: Epoch 036 - training loss: 0.3136, validation loss: 0.1491
2024-05-22 18:14:10 [INFO]: Epoch 037 - training loss: 0.3107, validation loss: 0.1488
2024-05-22 18:14:11 [INFO]: Epoch 038 - training loss: 0.3084, validation loss: 0.1479
2024-05-22 18:14:12 [INFO]: Epoch 039 - training loss: 0.3077, validation loss: 0.1466
2024-05-22 18:14:12 [INFO]: Epoch 040 - training loss: 0.3048, validation loss: 0.1445
2024-05-22 18:14:13 [INFO]: Epoch 041 - training loss: 0.3045, validation loss: 0.1438
2024-05-22 18:14:14 [INFO]: Epoch 042 - training loss: 0.3022, validation loss: 0.1446
2024-05-22 18:14:14 [INFO]: Epoch 043 - training loss: 0.2998, validation loss: 0.1426
2024-05-22 18:14:15 [INFO]: Epoch 044 - training loss: 0.2977, validation loss: 0.1423
2024-05-22 18:14:15 [INFO]: Epoch 045 - training loss: 0.2965, validation loss: 0.1412
2024-05-22 18:14:16 [INFO]: Epoch 046 - training loss: 0.2957, validation loss: 0.1408
2024-05-22 18:14:17 [INFO]: Epoch 047 - training loss: 0.2949, validation loss: 0.1395
2024-05-22 18:14:17 [INFO]: Epoch 048 - training loss: 0.2949, validation loss: 0.1385
2024-05-22 18:14:18 [INFO]: Epoch 049 - training loss: 0.2913, validation loss: 0.1368
2024-05-22 18:14:19 [INFO]: Epoch 050 - training loss: 0.2895, validation loss: 0.1367
2024-05-22 18:14:19 [INFO]: Epoch 051 - training loss: 0.2891, validation loss: 0.1370
2024-05-22 18:14:20 [INFO]: Epoch 052 - training loss: 0.2868, validation loss: 0.1357
2024-05-22 18:14:20 [INFO]: Epoch 053 - training loss: 0.2857, validation loss: 0.1345
2024-05-22 18:14:21 [INFO]: Epoch 054 - training loss: 0.2839, validation loss: 0.1342
2024-05-22 18:14:22 [INFO]: Epoch 055 - training loss: 0.2830, validation loss: 0.1330
2024-05-22 18:14:22 [INFO]: Epoch 056 - training loss: 0.2819, validation loss: 0.1323
2024-05-22 18:14:23 [INFO]: Epoch 057 - training loss: 0.2799, validation loss: 0.1315
2024-05-22 18:14:24 [INFO]: Epoch 058 - training loss: 0.2795, validation loss: 0.1306
2024-05-22 18:14:24 [INFO]: Epoch 059 - training loss: 0.2776, validation loss: 0.1303
2024-05-22 18:14:25 [INFO]: Epoch 060 - training loss: 0.2767, validation loss: 0.1289
2024-05-22 18:14:25 [INFO]: Epoch 061 - training loss: 0.2764, validation loss: 0.1294
2024-05-22 18:14:26 [INFO]: Epoch 062 - training loss: 0.2756, validation loss: 0.1291
2024-05-22 18:14:27 [INFO]: Epoch 063 - training loss: 0.2731, validation loss: 0.1274
2024-05-22 18:14:27 [INFO]: Epoch 064 - training loss: 0.2724, validation loss: 0.1275
2024-05-22 18:14:28 [INFO]: Epoch 065 - training loss: 0.2714, validation loss: 0.1276
2024-05-22 18:14:29 [INFO]: Epoch 066 - training loss: 0.2704, validation loss: 0.1266
2024-05-22 18:14:29 [INFO]: Epoch 067 - training loss: 0.2685, validation loss: 0.1257
2024-05-22 18:14:30 [INFO]: Epoch 068 - training loss: 0.2689, validation loss: 0.1261
2024-05-22 18:14:30 [INFO]: Epoch 069 - training loss: 0.2676, validation loss: 0.1240
2024-05-22 18:14:31 [INFO]: Epoch 070 - training loss: 0.2661, validation loss: 0.1238
2024-05-22 18:14:32 [INFO]: Epoch 071 - training loss: 0.2653, validation loss: 0.1238
2024-05-22 18:14:32 [INFO]: Epoch 072 - training loss: 0.2627, validation loss: 0.1235
2024-05-22 18:14:33 [INFO]: Epoch 073 - training loss: 0.2626, validation loss: 0.1224
2024-05-22 18:14:34 [INFO]: Epoch 074 - training loss: 0.2626, validation loss: 0.1232
2024-05-22 18:14:34 [INFO]: Epoch 075 - training loss: 0.2634, validation loss: 0.1215
2024-05-22 18:14:35 [INFO]: Epoch 076 - training loss: 0.2611, validation loss: 0.1220
2024-05-22 18:14:35 [INFO]: Epoch 077 - training loss: 0.2603, validation loss: 0.1208
2024-05-22 18:14:36 [INFO]: Epoch 078 - training loss: 0.2594, validation loss: 0.1209
2024-05-22 18:14:37 [INFO]: Epoch 079 - training loss: 0.2580, validation loss: 0.1198
2024-05-22 18:14:37 [INFO]: Epoch 080 - training loss: 0.2573, validation loss: 0.1198
2024-05-22 18:14:38 [INFO]: Epoch 081 - training loss: 0.2577, validation loss: 0.1204
2024-05-22 18:14:39 [INFO]: Epoch 082 - training loss: 0.2562, validation loss: 0.1191
2024-05-22 18:14:39 [INFO]: Epoch 083 - training loss: 0.2560, validation loss: 0.1189
2024-05-22 18:14:40 [INFO]: Epoch 084 - training loss: 0.2542, validation loss: 0.1187
2024-05-22 18:14:40 [INFO]: Epoch 085 - training loss: 0.2544, validation loss: 0.1184
2024-05-22 18:14:41 [INFO]: Epoch 086 - training loss: 0.2536, validation loss: 0.1177
2024-05-22 18:14:42 [INFO]: Epoch 087 - training loss: 0.2520, validation loss: 0.1177
2024-05-22 18:14:42 [INFO]: Epoch 088 - training loss: 0.2518, validation loss: 0.1174
2024-05-22 18:14:43 [INFO]: Epoch 089 - training loss: 0.2533, validation loss: 0.1176
2024-05-22 18:14:44 [INFO]: Epoch 090 - training loss: 0.2538, validation loss: 0.1172
2024-05-22 18:14:44 [INFO]: Epoch 091 - training loss: 0.2517, validation loss: 0.1167
2024-05-22 18:14:45 [INFO]: Epoch 092 - training loss: 0.2484, validation loss: 0.1157
2024-05-22 18:14:46 [INFO]: Epoch 093 - training loss: 0.2485, validation loss: 0.1156
2024-05-22 18:14:46 [INFO]: Epoch 094 - training loss: 0.2470, validation loss: 0.1150
2024-05-22 18:14:47 [INFO]: Epoch 095 - training loss: 0.2488, validation loss: 0.1153
2024-05-22 18:14:47 [INFO]: Epoch 096 - training loss: 0.2471, validation loss: 0.1152
2024-05-22 18:14:48 [INFO]: Epoch 097 - training loss: 0.2480, validation loss: 0.1152
2024-05-22 18:14:49 [INFO]: Epoch 098 - training loss: 0.2468, validation loss: 0.1147
2024-05-22 18:14:49 [INFO]: Epoch 099 - training loss: 0.2456, validation loss: 0.1150
2024-05-22 18:14:50 [INFO]: Epoch 100 - training loss: 0.2448, validation loss: 0.1152
2024-05-22 18:14:51 [INFO]: Epoch 101 - training loss: 0.2430, validation loss: 0.1143
2024-05-22 18:14:51 [INFO]: Epoch 102 - training loss: 0.2431, validation loss: 0.1134
2024-05-22 18:14:52 [INFO]: Epoch 103 - training loss: 0.2436, validation loss: 0.1137
2024-05-22 18:14:52 [INFO]: Epoch 104 - training loss: 0.2422, validation loss: 0.1139
2024-05-22 18:14:53 [INFO]: Epoch 105 - training loss: 0.2411, validation loss: 0.1132
2024-05-22 18:14:54 [INFO]: Epoch 106 - training loss: 0.2414, validation loss: 0.1130
2024-05-22 18:14:54 [INFO]: Epoch 107 - training loss: 0.2424, validation loss: 0.1127
2024-05-22 18:14:55 [INFO]: Epoch 108 - training loss: 0.2398, validation loss: 0.1124
2024-05-22 18:14:56 [INFO]: Epoch 109 - training loss: 0.2393, validation loss: 0.1125
2024-05-22 18:14:56 [INFO]: Epoch 110 - training loss: 0.2404, validation loss: 0.1120
2024-05-22 18:14:57 [INFO]: Epoch 111 - training loss: 0.2397, validation loss: 0.1125
2024-05-22 18:14:57 [INFO]: Epoch 112 - training loss: 0.2384, validation loss: 0.1117
2024-05-22 18:14:58 [INFO]: Epoch 113 - training loss: 0.2373, validation loss: 0.1113
2024-05-22 18:14:59 [INFO]: Epoch 114 - training loss: 0.2370, validation loss: 0.1112
2024-05-22 18:14:59 [INFO]: Epoch 115 - training loss: 0.2361, validation loss: 0.1110
2024-05-22 18:15:00 [INFO]: Epoch 116 - training loss: 0.2364, validation loss: 0.1114
2024-05-22 18:15:01 [INFO]: Epoch 117 - training loss: 0.2356, validation loss: 0.1114
2024-05-22 18:15:01 [INFO]: Epoch 118 - training loss: 0.2358, validation loss: 0.1107
2024-05-22 18:15:02 [INFO]: Epoch 119 - training loss: 0.2354, validation loss: 0.1114
2024-05-22 18:15:02 [INFO]: Epoch 120 - training loss: 0.2347, validation loss: 0.1105
2024-05-22 18:15:03 [INFO]: Epoch 121 - training loss: 0.2343, validation loss: 0.1103
2024-05-22 18:15:04 [INFO]: Epoch 122 - training loss: 0.2330, validation loss: 0.1105
2024-05-22 18:15:04 [INFO]: Epoch 123 - training loss: 0.2343, validation loss: 0.1094
2024-05-22 18:15:05 [INFO]: Epoch 124 - training loss: 0.2321, validation loss: 0.1095
2024-05-22 18:15:06 [INFO]: Epoch 125 - training loss: 0.2312, validation loss: 0.1096
2024-05-22 18:15:06 [INFO]: Epoch 126 - training loss: 0.2332, validation loss: 0.1100
2024-05-22 18:15:07 [INFO]: Epoch 127 - training loss: 0.2318, validation loss: 0.1091
2024-05-22 18:15:07 [INFO]: Epoch 128 - training loss: 0.2311, validation loss: 0.1086
2024-05-22 18:15:08 [INFO]: Epoch 129 - training loss: 0.2305, validation loss: 0.1086
2024-05-22 18:15:09 [INFO]: Epoch 130 - training loss: 0.2306, validation loss: 0.1088
2024-05-22 18:15:09 [INFO]: Epoch 131 - training loss: 0.2299, validation loss: 0.1081
2024-05-22 18:15:10 [INFO]: Epoch 132 - training loss: 0.2299, validation loss: 0.1097
2024-05-22 18:15:11 [INFO]: Epoch 133 - training loss: 0.2306, validation loss: 0.1078
2024-05-22 18:15:11 [INFO]: Epoch 134 - training loss: 0.2308, validation loss: 0.1084
2024-05-22 18:15:12 [INFO]: Epoch 135 - training loss: 0.2317, validation loss: 0.1079
2024-05-22 18:15:12 [INFO]: Epoch 136 - training loss: 0.2295, validation loss: 0.1077
2024-05-22 18:15:13 [INFO]: Epoch 137 - training loss: 0.2268, validation loss: 0.1074
2024-05-22 18:15:14 [INFO]: Epoch 138 - training loss: 0.2273, validation loss: 0.1072
2024-05-22 18:15:14 [INFO]: Epoch 139 - training loss: 0.2262, validation loss: 0.1070
2024-05-22 18:15:15 [INFO]: Epoch 140 - training loss: 0.2262, validation loss: 0.1069
2024-05-22 18:15:16 [INFO]: Epoch 141 - training loss: 0.2260, validation loss: 0.1069
2024-05-22 18:15:16 [INFO]: Epoch 142 - training loss: 0.2253, validation loss: 0.1068
2024-05-22 18:15:17 [INFO]: Epoch 143 - training loss: 0.2260, validation loss: 0.1064
2024-05-22 18:15:17 [INFO]: Epoch 144 - training loss: 0.2247, validation loss: 0.1060
2024-05-22 18:15:18 [INFO]: Epoch 145 - training loss: 0.2250, validation loss: 0.1072
2024-05-22 18:15:19 [INFO]: Epoch 146 - training loss: 0.2253, validation loss: 0.1062
2024-05-22 18:15:19 [INFO]: Epoch 147 - training loss: 0.2249, validation loss: 0.1050
2024-05-22 18:15:20 [INFO]: Epoch 148 - training loss: 0.2227, validation loss: 0.1059
2024-05-22 18:15:21 [INFO]: Epoch 149 - training loss: 0.2230, validation loss: 0.1057
2024-05-22 18:15:21 [INFO]: Epoch 150 - training loss: 0.2224, validation loss: 0.1052
2024-05-22 18:15:22 [INFO]: Epoch 151 - training loss: 0.2237, validation loss: 0.1058
2024-05-22 18:15:23 [INFO]: Epoch 152 - training loss: 0.2231, validation loss: 0.1058
2024-05-22 18:15:23 [INFO]: Epoch 153 - training loss: 0.2213, validation loss: 0.1050
2024-05-22 18:15:24 [INFO]: Epoch 154 - training loss: 0.2213, validation loss: 0.1054
2024-05-22 18:15:24 [INFO]: Epoch 155 - training loss: 0.2218, validation loss: 0.1051
2024-05-22 18:15:25 [INFO]: Epoch 156 - training loss: 0.2205, validation loss: 0.1055
2024-05-22 18:15:26 [INFO]: Epoch 157 - training loss: 0.2194, validation loss: 0.1045
2024-05-22 18:15:26 [INFO]: Epoch 158 - training loss: 0.2203, validation loss: 0.1050
2024-05-22 18:15:27 [INFO]: Epoch 159 - training loss: 0.2204, validation loss: 0.1067
2024-05-22 18:15:28 [INFO]: Epoch 160 - training loss: 0.2226, validation loss: 0.1038
2024-05-22 18:15:28 [INFO]: Epoch 161 - training loss: 0.2209, validation loss: 0.1038
2024-05-22 18:15:29 [INFO]: Epoch 162 - training loss: 0.2183, validation loss: 0.1036
2024-05-22 18:15:29 [INFO]: Epoch 163 - training loss: 0.2187, validation loss: 0.1040
2024-05-22 18:15:30 [INFO]: Epoch 164 - training loss: 0.2175, validation loss: 0.1029
2024-05-22 18:15:31 [INFO]: Epoch 165 - training loss: 0.2168, validation loss: 0.1034
2024-05-22 18:15:31 [INFO]: Epoch 166 - training loss: 0.2180, validation loss: 0.1030
2024-05-22 18:15:32 [INFO]: Epoch 167 - training loss: 0.2171, validation loss: 0.1026
2024-05-22 18:15:33 [INFO]: Epoch 168 - training loss: 0.2161, validation loss: 0.1028
2024-05-22 18:15:33 [INFO]: Epoch 169 - training loss: 0.2151, validation loss: 0.1030
2024-05-22 18:15:34 [INFO]: Epoch 170 - training loss: 0.2180, validation loss: 0.1037
2024-05-22 18:15:34 [INFO]: Epoch 171 - training loss: 0.2182, validation loss: 0.1038
2024-05-22 18:15:35 [INFO]: Epoch 172 - training loss: 0.2161, validation loss: 0.1025
2024-05-22 18:15:36 [INFO]: Epoch 173 - training loss: 0.2158, validation loss: 0.1027
2024-05-22 18:15:36 [INFO]: Epoch 174 - training loss: 0.2161, validation loss: 0.1031
2024-05-22 18:15:37 [INFO]: Epoch 175 - training loss: 0.2180, validation loss: 0.1034
2024-05-22 18:15:38 [INFO]: Epoch 176 - training loss: 0.2156, validation loss: 0.1021
2024-05-22 18:15:38 [INFO]: Epoch 177 - training loss: 0.2145, validation loss: 0.1027
2024-05-22 18:15:39 [INFO]: Epoch 178 - training loss: 0.2145, validation loss: 0.1013
2024-05-22 18:15:39 [INFO]: Epoch 179 - training loss: 0.2146, validation loss: 0.1010
2024-05-22 18:15:40 [INFO]: Epoch 180 - training loss: 0.2151, validation loss: 0.1014
2024-05-22 18:15:41 [INFO]: Epoch 181 - training loss: 0.2136, validation loss: 0.1015
2024-05-22 18:15:41 [INFO]: Epoch 182 - training loss: 0.2135, validation loss: 0.1015
2024-05-22 18:15:42 [INFO]: Epoch 183 - training loss: 0.2166, validation loss: 0.1024
2024-05-22 18:15:43 [INFO]: Epoch 184 - training loss: 0.2144, validation loss: 0.1010
2024-05-22 18:15:43 [INFO]: Epoch 185 - training loss: 0.2119, validation loss: 0.1017
2024-05-22 18:15:44 [INFO]: Epoch 186 - training loss: 0.2106, validation loss: 0.1005
2024-05-22 18:15:44 [INFO]: Epoch 187 - training loss: 0.2120, validation loss: 0.1008
2024-05-22 18:15:45 [INFO]: Epoch 188 - training loss: 0.2109, validation loss: 0.1001
2024-05-22 18:15:46 [INFO]: Epoch 189 - training loss: 0.2115, validation loss: 0.1005
2024-05-22 18:15:46 [INFO]: Epoch 190 - training loss: 0.2100, validation loss: 0.1009
2024-05-22 18:15:47 [INFO]: Epoch 191 - training loss: 0.2094, validation loss: 0.1000
2024-05-22 18:15:48 [INFO]: Epoch 192 - training loss: 0.2098, validation loss: 0.1002
2024-05-22 18:15:48 [INFO]: Epoch 193 - training loss: 0.2092, validation loss: 0.1003
2024-05-22 18:15:49 [INFO]: Epoch 194 - training loss: 0.2094, validation loss: 0.0999
2024-05-22 18:15:49 [INFO]: Epoch 195 - training loss: 0.2092, validation loss: 0.0993
2024-05-22 18:15:50 [INFO]: Epoch 196 - training loss: 0.2086, validation loss: 0.0990
2024-05-22 18:15:51 [INFO]: Epoch 197 - training loss: 0.2079, validation loss: 0.1001
2024-05-22 18:15:51 [INFO]: Epoch 198 - training loss: 0.2080, validation loss: 0.0991
2024-05-22 18:15:52 [INFO]: Epoch 199 - training loss: 0.2084, validation loss: 0.1008
2024-05-22 18:15:53 [INFO]: Epoch 200 - training loss: 0.2081, validation loss: 0.0989
2024-05-22 18:15:53 [INFO]: Epoch 201 - training loss: 0.2082, validation loss: 0.0985
2024-05-22 18:15:54 [INFO]: Epoch 202 - training loss: 0.2088, validation loss: 0.0999
2024-05-22 18:15:54 [INFO]: Epoch 203 - training loss: 0.2087, validation loss: 0.0983
2024-05-22 18:15:55 [INFO]: Epoch 204 - training loss: 0.2084, validation loss: 0.0990
2024-05-22 18:15:56 [INFO]: Epoch 205 - training loss: 0.2068, validation loss: 0.0983
2024-05-22 18:15:56 [INFO]: Epoch 206 - training loss: 0.2061, validation loss: 0.0983
2024-05-22 18:15:57 [INFO]: Epoch 207 - training loss: 0.2064, validation loss: 0.0978
2024-05-22 18:15:58 [INFO]: Epoch 208 - training loss: 0.2063, validation loss: 0.0973
2024-05-22 18:15:58 [INFO]: Epoch 209 - training loss: 0.2059, validation loss: 0.0977
2024-05-22 18:15:59 [INFO]: Epoch 210 - training loss: 0.2057, validation loss: 0.0987
2024-05-22 18:16:00 [INFO]: Epoch 211 - training loss: 0.2058, validation loss: 0.0980
2024-05-22 18:16:00 [INFO]: Epoch 212 - training loss: 0.2067, validation loss: 0.0993
2024-05-22 18:16:01 [INFO]: Epoch 213 - training loss: 0.2063, validation loss: 0.0980
2024-05-22 18:16:01 [INFO]: Epoch 214 - training loss: 0.2044, validation loss: 0.0981
2024-05-22 18:16:02 [INFO]: Epoch 215 - training loss: 0.2046, validation loss: 0.0976
2024-05-22 18:16:03 [INFO]: Epoch 216 - training loss: 0.2053, validation loss: 0.0968
2024-05-22 18:16:03 [INFO]: Epoch 217 - training loss: 0.2030, validation loss: 0.0978
2024-05-22 18:16:04 [INFO]: Epoch 218 - training loss: 0.2037, validation loss: 0.0981
2024-05-22 18:16:05 [INFO]: Epoch 219 - training loss: 0.2047, validation loss: 0.0985
2024-05-22 18:16:05 [INFO]: Epoch 220 - training loss: 0.2035, validation loss: 0.0985
2024-05-22 18:16:06 [INFO]: Epoch 221 - training loss: 0.2025, validation loss: 0.0976
2024-05-22 18:16:06 [INFO]: Epoch 222 - training loss: 0.2027, validation loss: 0.0975
2024-05-22 18:16:07 [INFO]: Epoch 223 - training loss: 0.2022, validation loss: 0.0977
2024-05-22 18:16:08 [INFO]: Epoch 224 - training loss: 0.2032, validation loss: 0.0972
2024-05-22 18:16:08 [INFO]: Epoch 225 - training loss: 0.2037, validation loss: 0.0977
2024-05-22 18:16:09 [INFO]: Epoch 226 - training loss: 0.2023, validation loss: 0.0964
2024-05-22 18:16:10 [INFO]: Epoch 227 - training loss: 0.2013, validation loss: 0.0974
2024-05-22 18:16:10 [INFO]: Epoch 228 - training loss: 0.2016, validation loss: 0.0975
2024-05-22 18:16:11 [INFO]: Epoch 229 - training loss: 0.2007, validation loss: 0.0962
2024-05-22 18:16:11 [INFO]: Epoch 230 - training loss: 0.2006, validation loss: 0.0968
2024-05-22 18:16:12 [INFO]: Epoch 231 - training loss: 0.2007, validation loss: 0.0960
2024-05-22 18:16:13 [INFO]: Epoch 232 - training loss: 0.2002, validation loss: 0.0950
2024-05-22 18:16:13 [INFO]: Epoch 233 - training loss: 0.2027, validation loss: 0.0961
2024-05-22 18:16:14 [INFO]: Epoch 234 - training loss: 0.2002, validation loss: 0.0964
2024-05-22 18:16:15 [INFO]: Epoch 235 - training loss: 0.2000, validation loss: 0.0957
2024-05-22 18:16:15 [INFO]: Epoch 236 - training loss: 0.1993, validation loss: 0.0966
2024-05-22 18:16:16 [INFO]: Epoch 237 - training loss: 0.1993, validation loss: 0.0963
2024-05-22 18:16:16 [INFO]: Epoch 238 - training loss: 0.1990, validation loss: 0.0962
2024-05-22 18:16:17 [INFO]: Epoch 239 - training loss: 0.1982, validation loss: 0.0959
2024-05-22 18:16:18 [INFO]: Epoch 240 - training loss: 0.1995, validation loss: 0.0963
2024-05-22 18:16:18 [INFO]: Epoch 241 - training loss: 0.2016, validation loss: 0.0959
2024-05-22 18:16:19 [INFO]: Epoch 242 - training loss: 0.1992, validation loss: 0.0944
2024-05-22 18:16:20 [INFO]: Epoch 243 - training loss: 0.2000, validation loss: 0.0958
2024-05-22 18:16:20 [INFO]: Epoch 244 - training loss: 0.1989, validation loss: 0.0964
2024-05-22 18:16:21 [INFO]: Epoch 245 - training loss: 0.1990, validation loss: 0.0961
2024-05-22 18:16:21 [INFO]: Epoch 246 - training loss: 0.2011, validation loss: 0.0948
2024-05-22 18:16:22 [INFO]: Epoch 247 - training loss: 0.2005, validation loss: 0.0965
2024-05-22 18:16:23 [INFO]: Epoch 248 - training loss: 0.2004, validation loss: 0.0947
2024-05-22 18:16:23 [INFO]: Epoch 249 - training loss: 0.1975, validation loss: 0.0948
2024-05-22 18:16:24 [INFO]: Epoch 250 - training loss: 0.1969, validation loss: 0.0949
2024-05-22 18:16:25 [INFO]: Epoch 251 - training loss: 0.1971, validation loss: 0.0944
2024-05-22 18:16:25 [INFO]: Epoch 252 - training loss: 0.1969, validation loss: 0.0950
2024-05-22 18:16:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 18:16:25 [INFO]: Finished training. The best model is from epoch#242.
2024-05-22 18:16:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/SAITS_air_quality/20240522_T181347/SAITS.pypots
2024-05-22 18:16:25 [INFO]: SAITS on Air-Quality: MAE=0.1416, MSE=0.1022
2024-05-22 18:16:25 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/SAITS_air_quality/imputation.pkl
2024-05-22 18:16:25 [INFO]: Using the given device: cuda:0
2024-05-22 18:16:25 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/Transformer_air_quality/20240522_T181625
2024-05-22 18:16:25 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/Transformer_air_quality/20240522_T181625/tensorboard
2024-05-22 18:16:25 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-22 18:16:26 [INFO]: Epoch 001 - training loss: 0.9104, validation loss: 0.4449
2024-05-22 18:16:26 [INFO]: Epoch 002 - training loss: 0.5771, validation loss: 0.3184
2024-05-22 18:16:26 [INFO]: Epoch 003 - training loss: 0.4865, validation loss: 0.2646
2024-05-22 18:16:27 [INFO]: Epoch 004 - training loss: 0.4403, validation loss: 0.2411
2024-05-22 18:16:27 [INFO]: Epoch 005 - training loss: 0.4109, validation loss: 0.2295
2024-05-22 18:16:27 [INFO]: Epoch 006 - training loss: 0.3934, validation loss: 0.2182
2024-05-22 18:16:27 [INFO]: Epoch 007 - training loss: 0.3800, validation loss: 0.2114
2024-05-22 18:16:28 [INFO]: Epoch 008 - training loss: 0.3675, validation loss: 0.2061
2024-05-22 18:16:28 [INFO]: Epoch 009 - training loss: 0.3562, validation loss: 0.2016
2024-05-22 18:16:28 [INFO]: Epoch 010 - training loss: 0.3503, validation loss: 0.1961
2024-05-22 18:16:29 [INFO]: Epoch 011 - training loss: 0.3417, validation loss: 0.1935
2024-05-22 18:16:29 [INFO]: Epoch 012 - training loss: 0.3393, validation loss: 0.1886
2024-05-22 18:16:29 [INFO]: Epoch 013 - training loss: 0.3321, validation loss: 0.1869
2024-05-22 18:16:29 [INFO]: Epoch 014 - training loss: 0.3284, validation loss: 0.1828
2024-05-22 18:16:30 [INFO]: Epoch 015 - training loss: 0.3236, validation loss: 0.1807
2024-05-22 18:16:30 [INFO]: Epoch 016 - training loss: 0.3210, validation loss: 0.1783
2024-05-22 18:16:30 [INFO]: Epoch 017 - training loss: 0.3154, validation loss: 0.1753
2024-05-22 18:16:31 [INFO]: Epoch 018 - training loss: 0.3129, validation loss: 0.1721
2024-05-22 18:16:31 [INFO]: Epoch 019 - training loss: 0.3095, validation loss: 0.1698
2024-05-22 18:16:31 [INFO]: Epoch 020 - training loss: 0.3104, validation loss: 0.1692
2024-05-22 18:16:31 [INFO]: Epoch 021 - training loss: 0.3075, validation loss: 0.1664
2024-05-22 18:16:32 [INFO]: Epoch 022 - training loss: 0.3083, validation loss: 0.1629
2024-05-22 18:16:32 [INFO]: Epoch 023 - training loss: 0.3037, validation loss: 0.1623
2024-05-22 18:16:32 [INFO]: Epoch 024 - training loss: 0.2986, validation loss: 0.1597
2024-05-22 18:16:32 [INFO]: Epoch 025 - training loss: 0.2950, validation loss: 0.1582
2024-05-22 18:16:33 [INFO]: Epoch 026 - training loss: 0.2928, validation loss: 0.1582
2024-05-22 18:16:33 [INFO]: Epoch 027 - training loss: 0.2908, validation loss: 0.1564
2024-05-22 18:16:33 [INFO]: Epoch 028 - training loss: 0.2890, validation loss: 0.1565
2024-05-22 18:16:34 [INFO]: Epoch 029 - training loss: 0.2879, validation loss: 0.1556
2024-05-22 18:16:34 [INFO]: Epoch 030 - training loss: 0.2869, validation loss: 0.1549
2024-05-22 18:16:34 [INFO]: Epoch 031 - training loss: 0.2855, validation loss: 0.1540
2024-05-22 18:16:34 [INFO]: Epoch 032 - training loss: 0.2839, validation loss: 0.1531
2024-05-22 18:16:35 [INFO]: Epoch 033 - training loss: 0.2807, validation loss: 0.1521
2024-05-22 18:16:35 [INFO]: Epoch 034 - training loss: 0.2797, validation loss: 0.1515
2024-05-22 18:16:35 [INFO]: Epoch 035 - training loss: 0.2815, validation loss: 0.1520
2024-05-22 18:16:36 [INFO]: Epoch 036 - training loss: 0.2814, validation loss: 0.1494
2024-05-22 18:16:36 [INFO]: Epoch 037 - training loss: 0.2799, validation loss: 0.1495
2024-05-22 18:16:36 [INFO]: Epoch 038 - training loss: 0.2787, validation loss: 0.1496
2024-05-22 18:16:36 [INFO]: Epoch 039 - training loss: 0.2758, validation loss: 0.1485
2024-05-22 18:16:37 [INFO]: Epoch 040 - training loss: 0.2755, validation loss: 0.1491
2024-05-22 18:16:37 [INFO]: Epoch 041 - training loss: 0.2770, validation loss: 0.1476
2024-05-22 18:16:37 [INFO]: Epoch 042 - training loss: 0.2741, validation loss: 0.1477
2024-05-22 18:16:38 [INFO]: Epoch 043 - training loss: 0.2706, validation loss: 0.1464
2024-05-22 18:16:38 [INFO]: Epoch 044 - training loss: 0.2712, validation loss: 0.1475
2024-05-22 18:16:38 [INFO]: Epoch 045 - training loss: 0.2717, validation loss: 0.1478
2024-05-22 18:16:38 [INFO]: Epoch 046 - training loss: 0.2696, validation loss: 0.1463
2024-05-22 18:16:39 [INFO]: Epoch 047 - training loss: 0.2673, validation loss: 0.1460
2024-05-22 18:16:39 [INFO]: Epoch 048 - training loss: 0.2649, validation loss: 0.1452
2024-05-22 18:16:39 [INFO]: Epoch 049 - training loss: 0.2654, validation loss: 0.1450
2024-05-22 18:16:39 [INFO]: Epoch 050 - training loss: 0.2702, validation loss: 0.1468
2024-05-22 18:16:40 [INFO]: Epoch 051 - training loss: 0.2642, validation loss: 0.1447
2024-05-22 18:16:40 [INFO]: Epoch 052 - training loss: 0.2614, validation loss: 0.1423
2024-05-22 18:16:40 [INFO]: Epoch 053 - training loss: 0.2605, validation loss: 0.1437
2024-05-22 18:16:41 [INFO]: Epoch 054 - training loss: 0.2598, validation loss: 0.1462
2024-05-22 18:16:41 [INFO]: Epoch 055 - training loss: 0.2598, validation loss: 0.1421
2024-05-22 18:16:41 [INFO]: Epoch 056 - training loss: 0.2581, validation loss: 0.1432
2024-05-22 18:16:41 [INFO]: Epoch 057 - training loss: 0.2581, validation loss: 0.1428
2024-05-22 18:16:42 [INFO]: Epoch 058 - training loss: 0.2577, validation loss: 0.1447
2024-05-22 18:16:42 [INFO]: Epoch 059 - training loss: 0.2565, validation loss: 0.1431
2024-05-22 18:16:42 [INFO]: Epoch 060 - training loss: 0.2551, validation loss: 0.1403
2024-05-22 18:16:43 [INFO]: Epoch 061 - training loss: 0.2551, validation loss: 0.1420
2024-05-22 18:16:43 [INFO]: Epoch 062 - training loss: 0.2544, validation loss: 0.1398
2024-05-22 18:16:43 [INFO]: Epoch 063 - training loss: 0.2545, validation loss: 0.1389
2024-05-22 18:16:43 [INFO]: Epoch 064 - training loss: 0.2532, validation loss: 0.1397
2024-05-22 18:16:44 [INFO]: Epoch 065 - training loss: 0.2523, validation loss: 0.1391
2024-05-22 18:16:44 [INFO]: Epoch 066 - training loss: 0.2504, validation loss: 0.1408
2024-05-22 18:16:44 [INFO]: Epoch 067 - training loss: 0.2504, validation loss: 0.1382
2024-05-22 18:16:45 [INFO]: Epoch 068 - training loss: 0.2499, validation loss: 0.1380
2024-05-22 18:16:45 [INFO]: Epoch 069 - training loss: 0.2518, validation loss: 0.1385
2024-05-22 18:16:45 [INFO]: Epoch 070 - training loss: 0.2502, validation loss: 0.1407
2024-05-22 18:16:45 [INFO]: Epoch 071 - training loss: 0.2480, validation loss: 0.1373
2024-05-22 18:16:46 [INFO]: Epoch 072 - training loss: 0.2471, validation loss: 0.1402
2024-05-22 18:16:46 [INFO]: Epoch 073 - training loss: 0.2454, validation loss: 0.1390
2024-05-22 18:16:46 [INFO]: Epoch 074 - training loss: 0.2427, validation loss: 0.1384
2024-05-22 18:16:47 [INFO]: Epoch 075 - training loss: 0.2433, validation loss: 0.1380
2024-05-22 18:16:47 [INFO]: Epoch 076 - training loss: 0.2434, validation loss: 0.1384
2024-05-22 18:16:47 [INFO]: Epoch 077 - training loss: 0.2424, validation loss: 0.1392
2024-05-22 18:16:47 [INFO]: Epoch 078 - training loss: 0.2457, validation loss: 0.1378
2024-05-22 18:16:48 [INFO]: Epoch 079 - training loss: 0.2437, validation loss: 0.1372
2024-05-22 18:16:48 [INFO]: Epoch 080 - training loss: 0.2408, validation loss: 0.1352
2024-05-22 18:16:48 [INFO]: Epoch 081 - training loss: 0.2433, validation loss: 0.1350
2024-05-22 18:16:48 [INFO]: Epoch 082 - training loss: 0.2407, validation loss: 0.1350
2024-05-22 18:16:49 [INFO]: Epoch 083 - training loss: 0.2390, validation loss: 0.1348
2024-05-22 18:16:49 [INFO]: Epoch 084 - training loss: 0.2393, validation loss: 0.1358
2024-05-22 18:16:49 [INFO]: Epoch 085 - training loss: 0.2375, validation loss: 0.1355
2024-05-22 18:16:50 [INFO]: Epoch 086 - training loss: 0.2362, validation loss: 0.1346
2024-05-22 18:16:50 [INFO]: Epoch 087 - training loss: 0.2349, validation loss: 0.1340
2024-05-22 18:16:50 [INFO]: Epoch 088 - training loss: 0.2363, validation loss: 0.1345
2024-05-22 18:16:50 [INFO]: Epoch 089 - training loss: 0.2373, validation loss: 0.1320
2024-05-22 18:16:51 [INFO]: Epoch 090 - training loss: 0.2358, validation loss: 0.1329
2024-05-22 18:16:51 [INFO]: Epoch 091 - training loss: 0.2354, validation loss: 0.1339
2024-05-22 18:16:51 [INFO]: Epoch 092 - training loss: 0.2375, validation loss: 0.1357
2024-05-22 18:16:52 [INFO]: Epoch 093 - training loss: 0.2354, validation loss: 0.1314
2024-05-22 18:16:52 [INFO]: Epoch 094 - training loss: 0.2345, validation loss: 0.1354
2024-05-22 18:16:52 [INFO]: Epoch 095 - training loss: 0.2318, validation loss: 0.1327
2024-05-22 18:16:52 [INFO]: Epoch 096 - training loss: 0.2312, validation loss: 0.1315
2024-05-22 18:16:53 [INFO]: Epoch 097 - training loss: 0.2288, validation loss: 0.1309
2024-05-22 18:16:53 [INFO]: Epoch 098 - training loss: 0.2290, validation loss: 0.1322
2024-05-22 18:16:53 [INFO]: Epoch 099 - training loss: 0.2298, validation loss: 0.1330
2024-05-22 18:16:54 [INFO]: Epoch 100 - training loss: 0.2322, validation loss: 0.1318
2024-05-22 18:16:54 [INFO]: Epoch 101 - training loss: 0.2313, validation loss: 0.1310
2024-05-22 18:16:54 [INFO]: Epoch 102 - training loss: 0.2284, validation loss: 0.1291
2024-05-22 18:16:54 [INFO]: Epoch 103 - training loss: 0.2282, validation loss: 0.1309
2024-05-22 18:16:55 [INFO]: Epoch 104 - training loss: 0.2282, validation loss: 0.1320
2024-05-22 18:16:55 [INFO]: Epoch 105 - training loss: 0.2263, validation loss: 0.1312
2024-05-22 18:16:55 [INFO]: Epoch 106 - training loss: 0.2265, validation loss: 0.1327
2024-05-22 18:16:56 [INFO]: Epoch 107 - training loss: 0.2288, validation loss: 0.1273
2024-05-22 18:16:56 [INFO]: Epoch 108 - training loss: 0.2265, validation loss: 0.1295
2024-05-22 18:16:56 [INFO]: Epoch 109 - training loss: 0.2267, validation loss: 0.1296
2024-05-22 18:16:56 [INFO]: Epoch 110 - training loss: 0.2253, validation loss: 0.1286
2024-05-22 18:16:57 [INFO]: Epoch 111 - training loss: 0.2252, validation loss: 0.1278
2024-05-22 18:16:57 [INFO]: Epoch 112 - training loss: 0.2251, validation loss: 0.1280
2024-05-22 18:16:57 [INFO]: Epoch 113 - training loss: 0.2233, validation loss: 0.1283
2024-05-22 18:16:57 [INFO]: Epoch 114 - training loss: 0.2248, validation loss: 0.1278
2024-05-22 18:16:58 [INFO]: Epoch 115 - training loss: 0.2235, validation loss: 0.1285
2024-05-22 18:16:58 [INFO]: Epoch 116 - training loss: 0.2220, validation loss: 0.1281
2024-05-22 18:16:58 [INFO]: Epoch 117 - training loss: 0.2233, validation loss: 0.1270
2024-05-22 18:16:59 [INFO]: Epoch 118 - training loss: 0.2216, validation loss: 0.1272
2024-05-22 18:16:59 [INFO]: Epoch 119 - training loss: 0.2193, validation loss: 0.1266
2024-05-22 18:16:59 [INFO]: Epoch 120 - training loss: 0.2205, validation loss: 0.1271
2024-05-22 18:16:59 [INFO]: Epoch 121 - training loss: 0.2196, validation loss: 0.1258
2024-05-22 18:17:00 [INFO]: Epoch 122 - training loss: 0.2196, validation loss: 0.1256
2024-05-22 18:17:00 [INFO]: Epoch 123 - training loss: 0.2195, validation loss: 0.1263
2024-05-22 18:17:00 [INFO]: Epoch 124 - training loss: 0.2198, validation loss: 0.1249
2024-05-22 18:17:01 [INFO]: Epoch 125 - training loss: 0.2166, validation loss: 0.1257
2024-05-22 18:17:01 [INFO]: Epoch 126 - training loss: 0.2158, validation loss: 0.1258
2024-05-22 18:17:01 [INFO]: Epoch 127 - training loss: 0.2191, validation loss: 0.1278
2024-05-22 18:17:01 [INFO]: Epoch 128 - training loss: 0.2177, validation loss: 0.1244
2024-05-22 18:17:02 [INFO]: Epoch 129 - training loss: 0.2165, validation loss: 0.1265
2024-05-22 18:17:02 [INFO]: Epoch 130 - training loss: 0.2167, validation loss: 0.1256
2024-05-22 18:17:02 [INFO]: Epoch 131 - training loss: 0.2161, validation loss: 0.1261
2024-05-22 18:17:03 [INFO]: Epoch 132 - training loss: 0.2149, validation loss: 0.1256
2024-05-22 18:17:03 [INFO]: Epoch 133 - training loss: 0.2149, validation loss: 0.1237
2024-05-22 18:17:03 [INFO]: Epoch 134 - training loss: 0.2167, validation loss: 0.1246
2024-05-22 18:17:03 [INFO]: Epoch 135 - training loss: 0.2134, validation loss: 0.1239
2024-05-22 18:17:04 [INFO]: Epoch 136 - training loss: 0.2119, validation loss: 0.1245
2024-05-22 18:17:04 [INFO]: Epoch 137 - training loss: 0.2145, validation loss: 0.1222
2024-05-22 18:17:04 [INFO]: Epoch 138 - training loss: 0.2135, validation loss: 0.1237
2024-05-22 18:17:04 [INFO]: Epoch 139 - training loss: 0.2123, validation loss: 0.1236
2024-05-22 18:17:05 [INFO]: Epoch 140 - training loss: 0.2142, validation loss: 0.1232
2024-05-22 18:17:05 [INFO]: Epoch 141 - training loss: 0.2147, validation loss: 0.1235
2024-05-22 18:17:05 [INFO]: Epoch 142 - training loss: 0.2128, validation loss: 0.1225
2024-05-22 18:17:06 [INFO]: Epoch 143 - training loss: 0.2109, validation loss: 0.1229
2024-05-22 18:17:06 [INFO]: Epoch 144 - training loss: 0.2111, validation loss: 0.1230
2024-05-22 18:17:06 [INFO]: Epoch 145 - training loss: 0.2110, validation loss: 0.1233
2024-05-22 18:17:06 [INFO]: Epoch 146 - training loss: 0.2105, validation loss: 0.1225
2024-05-22 18:17:07 [INFO]: Epoch 147 - training loss: 0.2122, validation loss: 0.1217
2024-05-22 18:17:07 [INFO]: Epoch 148 - training loss: 0.2114, validation loss: 0.1229
2024-05-22 18:17:07 [INFO]: Epoch 149 - training loss: 0.2099, validation loss: 0.1237
2024-05-22 18:17:08 [INFO]: Epoch 150 - training loss: 0.2102, validation loss: 0.1221
2024-05-22 18:17:08 [INFO]: Epoch 151 - training loss: 0.2088, validation loss: 0.1214
2024-05-22 18:17:08 [INFO]: Epoch 152 - training loss: 0.2098, validation loss: 0.1225
2024-05-22 18:17:08 [INFO]: Epoch 153 - training loss: 0.2098, validation loss: 0.1214
2024-05-22 18:17:09 [INFO]: Epoch 154 - training loss: 0.2096, validation loss: 0.1203
2024-05-22 18:17:09 [INFO]: Epoch 155 - training loss: 0.2083, validation loss: 0.1221
2024-05-22 18:17:09 [INFO]: Epoch 156 - training loss: 0.2081, validation loss: 0.1219
2024-05-22 18:17:10 [INFO]: Epoch 157 - training loss: 0.2084, validation loss: 0.1212
2024-05-22 18:17:10 [INFO]: Epoch 158 - training loss: 0.2078, validation loss: 0.1210
2024-05-22 18:17:10 [INFO]: Epoch 159 - training loss: 0.2076, validation loss: 0.1205
2024-05-22 18:17:10 [INFO]: Epoch 160 - training loss: 0.2079, validation loss: 0.1210
2024-05-22 18:17:11 [INFO]: Epoch 161 - training loss: 0.2080, validation loss: 0.1201
2024-05-22 18:17:11 [INFO]: Epoch 162 - training loss: 0.2052, validation loss: 0.1198
2024-05-22 18:17:11 [INFO]: Epoch 163 - training loss: 0.2066, validation loss: 0.1203
2024-05-22 18:17:12 [INFO]: Epoch 164 - training loss: 0.2065, validation loss: 0.1190
2024-05-22 18:17:12 [INFO]: Epoch 165 - training loss: 0.2052, validation loss: 0.1205
2024-05-22 18:17:12 [INFO]: Epoch 166 - training loss: 0.2056, validation loss: 0.1211
2024-05-22 18:17:12 [INFO]: Epoch 167 - training loss: 0.2061, validation loss: 0.1214
2024-05-22 18:17:13 [INFO]: Epoch 168 - training loss: 0.2070, validation loss: 0.1212
2024-05-22 18:17:13 [INFO]: Epoch 169 - training loss: 0.2099, validation loss: 0.1194
2024-05-22 18:17:13 [INFO]: Epoch 170 - training loss: 0.2055, validation loss: 0.1186
2024-05-22 18:17:13 [INFO]: Epoch 171 - training loss: 0.2018, validation loss: 0.1182
2024-05-22 18:17:14 [INFO]: Epoch 172 - training loss: 0.2021, validation loss: 0.1180
2024-05-22 18:17:14 [INFO]: Epoch 173 - training loss: 0.2021, validation loss: 0.1190
2024-05-22 18:17:14 [INFO]: Epoch 174 - training loss: 0.2033, validation loss: 0.1183
2024-05-22 18:17:15 [INFO]: Epoch 175 - training loss: 0.2033, validation loss: 0.1191
2024-05-22 18:17:15 [INFO]: Epoch 176 - training loss: 0.2038, validation loss: 0.1177
2024-05-22 18:17:15 [INFO]: Epoch 177 - training loss: 0.2015, validation loss: 0.1186
2024-05-22 18:17:15 [INFO]: Epoch 178 - training loss: 0.2025, validation loss: 0.1169
2024-05-22 18:17:16 [INFO]: Epoch 179 - training loss: 0.2011, validation loss: 0.1167
2024-05-22 18:17:16 [INFO]: Epoch 180 - training loss: 0.2016, validation loss: 0.1175
2024-05-22 18:17:16 [INFO]: Epoch 181 - training loss: 0.1992, validation loss: 0.1186
2024-05-22 18:17:17 [INFO]: Epoch 182 - training loss: 0.2008, validation loss: 0.1174
2024-05-22 18:17:17 [INFO]: Epoch 183 - training loss: 0.2027, validation loss: 0.1171
2024-05-22 18:17:17 [INFO]: Epoch 184 - training loss: 0.2013, validation loss: 0.1180
2024-05-22 18:17:17 [INFO]: Epoch 185 - training loss: 0.2020, validation loss: 0.1179
2024-05-22 18:17:18 [INFO]: Epoch 186 - training loss: 0.2003, validation loss: 0.1177
2024-05-22 18:17:18 [INFO]: Epoch 187 - training loss: 0.2003, validation loss: 0.1171
2024-05-22 18:17:18 [INFO]: Epoch 188 - training loss: 0.1983, validation loss: 0.1162
2024-05-22 18:17:19 [INFO]: Epoch 189 - training loss: 0.1990, validation loss: 0.1185
2024-05-22 18:17:19 [INFO]: Epoch 190 - training loss: 0.2004, validation loss: 0.1165
2024-05-22 18:17:19 [INFO]: Epoch 191 - training loss: 0.1978, validation loss: 0.1155
2024-05-22 18:17:20 [INFO]: Epoch 192 - training loss: 0.1987, validation loss: 0.1156
2024-05-22 18:17:20 [INFO]: Epoch 193 - training loss: 0.1985, validation loss: 0.1161
2024-05-22 18:17:20 [INFO]: Epoch 194 - training loss: 0.1987, validation loss: 0.1158
2024-05-22 18:17:20 [INFO]: Epoch 195 - training loss: 0.2013, validation loss: 0.1158
2024-05-22 18:17:21 [INFO]: Epoch 196 - training loss: 0.1986, validation loss: 0.1145
2024-05-22 18:17:21 [INFO]: Epoch 197 - training loss: 0.1959, validation loss: 0.1161
2024-05-22 18:17:21 [INFO]: Epoch 198 - training loss: 0.1957, validation loss: 0.1153
2024-05-22 18:17:21 [INFO]: Epoch 199 - training loss: 0.1968, validation loss: 0.1159
2024-05-22 18:17:22 [INFO]: Epoch 200 - training loss: 0.1968, validation loss: 0.1160
2024-05-22 18:17:22 [INFO]: Epoch 201 - training loss: 0.1958, validation loss: 0.1157
2024-05-22 18:17:22 [INFO]: Epoch 202 - training loss: 0.1957, validation loss: 0.1149
2024-05-22 18:17:23 [INFO]: Epoch 203 - training loss: 0.1942, validation loss: 0.1145
2024-05-22 18:17:23 [INFO]: Epoch 204 - training loss: 0.1956, validation loss: 0.1149
2024-05-22 18:17:23 [INFO]: Epoch 205 - training loss: 0.1950, validation loss: 0.1155
2024-05-22 18:17:23 [INFO]: Epoch 206 - training loss: 0.1949, validation loss: 0.1155
2024-05-22 18:17:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 18:17:23 [INFO]: Finished training. The best model is from epoch#196.
2024-05-22 18:17:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/Transformer_air_quality/20240522_T181625/Transformer.pypots
2024-05-22 18:17:24 [INFO]: Transformer on Air-Quality: MAE=0.1599, MSE=0.1223
2024-05-22 18:17:24 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/Transformer_air_quality/imputation.pkl
2024-05-22 18:17:24 [INFO]: Using the given device: cuda:0
2024-05-22 18:17:24 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/TimesNet_air_quality/20240522_T181724
2024-05-22 18:17:24 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/TimesNet_air_quality/20240522_T181724/tensorboard
2024-05-22 18:17:24 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-22 18:17:24 [INFO]: Epoch 001 - training loss: 0.3059, validation loss: 0.2586
2024-05-22 18:17:25 [INFO]: Epoch 002 - training loss: 0.2098, validation loss: 0.2113
2024-05-22 18:17:25 [INFO]: Epoch 003 - training loss: 0.1926, validation loss: 0.1930
2024-05-22 18:17:26 [INFO]: Epoch 004 - training loss: 0.1832, validation loss: 0.1815
2024-05-22 18:17:26 [INFO]: Epoch 005 - training loss: 0.1702, validation loss: 0.1816
2024-05-22 18:17:27 [INFO]: Epoch 006 - training loss: 0.1645, validation loss: 0.1710
2024-05-22 18:17:27 [INFO]: Epoch 007 - training loss: 0.1559, validation loss: 0.1657
2024-05-22 18:17:28 [INFO]: Epoch 008 - training loss: 0.1651, validation loss: 0.1639
2024-05-22 18:17:28 [INFO]: Epoch 009 - training loss: 0.1504, validation loss: 0.1600
2024-05-22 18:17:29 [INFO]: Epoch 010 - training loss: 0.1474, validation loss: 0.1596
2024-05-22 18:17:29 [INFO]: Epoch 011 - training loss: 0.1378, validation loss: 0.1554
2024-05-22 18:17:30 [INFO]: Epoch 012 - training loss: 0.1432, validation loss: 0.1542
2024-05-22 18:17:30 [INFO]: Epoch 013 - training loss: 0.1421, validation loss: 0.1547
2024-05-22 18:17:31 [INFO]: Epoch 014 - training loss: 0.1357, validation loss: 0.1531
2024-05-22 18:17:31 [INFO]: Epoch 015 - training loss: 0.1250, validation loss: 0.1479
2024-05-22 18:17:32 [INFO]: Epoch 016 - training loss: 0.1367, validation loss: 0.1433
2024-05-22 18:17:32 [INFO]: Epoch 017 - training loss: 0.1222, validation loss: 0.1503
2024-05-22 18:17:32 [INFO]: Epoch 018 - training loss: 0.1342, validation loss: 0.1474
2024-05-22 18:17:33 [INFO]: Epoch 019 - training loss: 0.1451, validation loss: 0.1489
2024-05-22 18:17:33 [INFO]: Epoch 020 - training loss: 0.1153, validation loss: 0.1439
2024-05-22 18:17:34 [INFO]: Epoch 021 - training loss: 0.1285, validation loss: 0.1468
2024-05-22 18:17:34 [INFO]: Epoch 022 - training loss: 0.1414, validation loss: 0.1399
2024-05-22 18:17:35 [INFO]: Epoch 023 - training loss: 0.1229, validation loss: 0.1476
2024-05-22 18:17:35 [INFO]: Epoch 024 - training loss: 0.1292, validation loss: 0.1396
2024-05-22 18:17:36 [INFO]: Epoch 025 - training loss: 0.1250, validation loss: 0.1417
2024-05-22 18:17:36 [INFO]: Epoch 026 - training loss: 0.1480, validation loss: 0.1439
2024-05-22 18:17:37 [INFO]: Epoch 027 - training loss: 0.1191, validation loss: 0.1373
2024-05-22 18:17:37 [INFO]: Epoch 028 - training loss: 0.1135, validation loss: 0.1419
2024-05-22 18:17:38 [INFO]: Epoch 029 - training loss: 0.1269, validation loss: 0.1351
2024-05-22 18:17:38 [INFO]: Epoch 030 - training loss: 0.1213, validation loss: 0.1472
2024-05-22 18:17:39 [INFO]: Epoch 031 - training loss: 0.1104, validation loss: 0.1434
2024-05-22 18:17:39 [INFO]: Epoch 032 - training loss: 0.1023, validation loss: 0.1367
2024-05-22 18:17:40 [INFO]: Epoch 033 - training loss: 0.1086, validation loss: 0.1405
2024-05-22 18:17:40 [INFO]: Epoch 034 - training loss: 0.1048, validation loss: 0.1383
2024-05-22 18:17:40 [INFO]: Epoch 035 - training loss: 0.1054, validation loss: 0.1391
2024-05-22 18:17:41 [INFO]: Epoch 036 - training loss: 0.1134, validation loss: 0.1427
2024-05-22 18:17:41 [INFO]: Epoch 037 - training loss: 0.1138, validation loss: 0.1360
2024-05-22 18:17:42 [INFO]: Epoch 038 - training loss: 0.1173, validation loss: 0.1327
2024-05-22 18:17:42 [INFO]: Epoch 039 - training loss: 0.1193, validation loss: 0.1393
2024-05-22 18:17:43 [INFO]: Epoch 040 - training loss: 0.0920, validation loss: 0.1349
2024-05-22 18:17:43 [INFO]: Epoch 041 - training loss: 0.0984, validation loss: 0.1327
2024-05-22 18:17:44 [INFO]: Epoch 042 - training loss: 0.1000, validation loss: 0.1355
2024-05-22 18:17:44 [INFO]: Epoch 043 - training loss: 0.1008, validation loss: 0.1341
2024-05-22 18:17:45 [INFO]: Epoch 044 - training loss: 0.1089, validation loss: 0.1348
2024-05-22 18:17:45 [INFO]: Epoch 045 - training loss: 0.1079, validation loss: 0.1387
2024-05-22 18:17:46 [INFO]: Epoch 046 - training loss: 0.1229, validation loss: 0.1444
2024-05-22 18:17:46 [INFO]: Epoch 047 - training loss: 0.0987, validation loss: 0.1382
2024-05-22 18:17:47 [INFO]: Epoch 048 - training loss: 0.1077, validation loss: 0.1327
2024-05-22 18:17:47 [INFO]: Epoch 049 - training loss: 0.1022, validation loss: 0.1374
2024-05-22 18:17:48 [INFO]: Epoch 050 - training loss: 0.1131, validation loss: 0.1312
2024-05-22 18:17:48 [INFO]: Epoch 051 - training loss: 0.0976, validation loss: 0.1311
2024-05-22 18:17:49 [INFO]: Epoch 052 - training loss: 0.1054, validation loss: 0.1323
2024-05-22 18:17:49 [INFO]: Epoch 053 - training loss: 0.0997, validation loss: 0.1335
2024-05-22 18:17:49 [INFO]: Epoch 054 - training loss: 0.0851, validation loss: 0.1313
2024-05-22 18:17:50 [INFO]: Epoch 055 - training loss: 0.0979, validation loss: 0.1323
2024-05-22 18:17:50 [INFO]: Epoch 056 - training loss: 0.0996, validation loss: 0.1413
2024-05-22 18:17:51 [INFO]: Epoch 057 - training loss: 0.0998, validation loss: 0.1318
2024-05-22 18:17:51 [INFO]: Epoch 058 - training loss: 0.1067, validation loss: 0.1284
2024-05-22 18:17:52 [INFO]: Epoch 059 - training loss: 0.1011, validation loss: 0.1325
2024-05-22 18:17:52 [INFO]: Epoch 060 - training loss: 0.0944, validation loss: 0.1310
2024-05-22 18:17:53 [INFO]: Epoch 061 - training loss: 0.1018, validation loss: 0.1314
2024-05-22 18:17:53 [INFO]: Epoch 062 - training loss: 0.1013, validation loss: 0.1334
2024-05-22 18:17:54 [INFO]: Epoch 063 - training loss: 0.0979, validation loss: 0.1398
2024-05-22 18:17:54 [INFO]: Epoch 064 - training loss: 0.1112, validation loss: 0.1376
2024-05-22 18:17:55 [INFO]: Epoch 065 - training loss: 0.0970, validation loss: 0.1331
2024-05-22 18:17:55 [INFO]: Epoch 066 - training loss: 0.1009, validation loss: 0.1363
2024-05-22 18:17:56 [INFO]: Epoch 067 - training loss: 0.0993, validation loss: 0.1322
2024-05-22 18:17:56 [INFO]: Epoch 068 - training loss: 0.0874, validation loss: 0.1375
2024-05-22 18:17:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 18:17:56 [INFO]: Finished training. The best model is from epoch#58.
2024-05-22 18:17:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/TimesNet_air_quality/20240522_T181724/TimesNet.pypots
2024-05-22 18:17:56 [INFO]: TimesNet on Air-Quality: MAE=0.1567, MSE=0.1499
2024-05-22 18:17:56 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/TimesNet_air_quality/imputation.pkl
2024-05-22 18:17:56 [INFO]: Using the given device: cuda:0
2024-05-22 18:17:56 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756
2024-05-22 18:17:56 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/tensorboard
2024-05-22 18:17:56 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-22 18:18:13 [INFO]: Epoch 001 - training loss: 0.5011, validation loss: 0.3465
2024-05-22 18:18:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch1_loss0.34654785990715026.pypots
2024-05-22 18:18:29 [INFO]: Epoch 002 - training loss: 0.3114, validation loss: 0.2824
2024-05-22 18:18:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch2_loss0.2824111431837082.pypots
2024-05-22 18:18:46 [INFO]: Epoch 003 - training loss: 0.2700, validation loss: 0.2386
2024-05-22 18:18:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch3_loss0.238566592335701.pypots
2024-05-22 18:19:02 [INFO]: Epoch 004 - training loss: 0.2494, validation loss: 0.2391
2024-05-22 18:19:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch4_loss0.2391280710697174.pypots
2024-05-22 18:19:19 [INFO]: Epoch 005 - training loss: 0.2527, validation loss: 0.2188
2024-05-22 18:19:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch5_loss0.21876142621040345.pypots
2024-05-22 18:19:35 [INFO]: Epoch 006 - training loss: 0.2129, validation loss: 0.1873
2024-05-22 18:19:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch6_loss0.18728532642126083.pypots
2024-05-22 18:19:52 [INFO]: Epoch 007 - training loss: 0.2069, validation loss: 0.1725
2024-05-22 18:19:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch7_loss0.1725105971097946.pypots
2024-05-22 18:20:08 [INFO]: Epoch 008 - training loss: 0.1791, validation loss: 0.1707
2024-05-22 18:20:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch8_loss0.17068727314472198.pypots
2024-05-22 18:20:25 [INFO]: Epoch 009 - training loss: 0.1840, validation loss: 0.1684
2024-05-22 18:20:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch9_loss0.16839919239282608.pypots
2024-05-22 18:20:41 [INFO]: Epoch 010 - training loss: 0.1873, validation loss: 0.1589
2024-05-22 18:20:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch10_loss0.1589441180229187.pypots
2024-05-22 18:20:58 [INFO]: Epoch 011 - training loss: 0.1742, validation loss: 0.1602
2024-05-22 18:20:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch11_loss0.16018886268138885.pypots
2024-05-22 18:21:14 [INFO]: Epoch 012 - training loss: 0.1855, validation loss: 0.1572
2024-05-22 18:21:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch12_loss0.15719558745622636.pypots
2024-05-22 18:21:31 [INFO]: Epoch 013 - training loss: 0.1726, validation loss: 0.1523
2024-05-22 18:21:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch13_loss0.15231521129608155.pypots
2024-05-22 18:21:47 [INFO]: Epoch 014 - training loss: 0.1736, validation loss: 0.1477
2024-05-22 18:21:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch14_loss0.1477205276489258.pypots
2024-05-22 18:22:04 [INFO]: Epoch 015 - training loss: 0.1611, validation loss: 0.1453
2024-05-22 18:22:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch15_loss0.1452668532729149.pypots
2024-05-22 18:22:20 [INFO]: Epoch 016 - training loss: 0.1648, validation loss: 0.1498
2024-05-22 18:22:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch16_loss0.14976921677589417.pypots
2024-05-22 18:22:37 [INFO]: Epoch 017 - training loss: 0.1922, validation loss: 0.1450
2024-05-22 18:22:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch17_loss0.145030976831913.pypots
2024-05-22 18:22:53 [INFO]: Epoch 018 - training loss: 0.1680, validation loss: 0.1394
2024-05-22 18:22:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch18_loss0.13938326612114907.pypots
2024-05-22 18:23:10 [INFO]: Epoch 019 - training loss: 0.1527, validation loss: 0.1358
2024-05-22 18:23:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch19_loss0.13575489968061447.pypots
2024-05-22 18:23:26 [INFO]: Epoch 020 - training loss: 0.1585, validation loss: 0.1347
2024-05-22 18:23:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch20_loss0.13467760533094406.pypots
2024-05-22 18:23:42 [INFO]: Epoch 021 - training loss: 0.1380, validation loss: 0.1433
2024-05-22 18:23:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch21_loss0.14334387555718422.pypots
2024-05-22 18:23:59 [INFO]: Epoch 022 - training loss: 0.1614, validation loss: 0.1384
2024-05-22 18:23:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch22_loss0.1384006507694721.pypots
2024-05-22 18:24:15 [INFO]: Epoch 023 - training loss: 0.1558, validation loss: 0.1357
2024-05-22 18:24:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch23_loss0.13568878695368766.pypots
2024-05-22 18:24:32 [INFO]: Epoch 024 - training loss: 0.1458, validation loss: 0.1308
2024-05-22 18:24:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch24_loss0.1307600647211075.pypots
2024-05-22 18:24:48 [INFO]: Epoch 025 - training loss: 0.1403, validation loss: 0.1333
2024-05-22 18:24:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch25_loss0.13332047760486604.pypots
2024-05-22 18:25:05 [INFO]: Epoch 026 - training loss: 0.1569, validation loss: 0.1297
2024-05-22 18:25:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch26_loss0.1297205440700054.pypots
2024-05-22 18:25:21 [INFO]: Epoch 027 - training loss: 0.1303, validation loss: 0.1295
2024-05-22 18:25:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch27_loss0.12950889021158218.pypots
2024-05-22 18:25:38 [INFO]: Epoch 028 - training loss: 0.1391, validation loss: 0.1312
2024-05-22 18:25:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch28_loss0.13120290637016296.pypots
2024-05-22 18:25:54 [INFO]: Epoch 029 - training loss: 0.1573, validation loss: 0.1321
2024-05-22 18:25:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch29_loss0.13206743448972702.pypots
2024-05-22 18:26:11 [INFO]: Epoch 030 - training loss: 0.1453, validation loss: 0.1283
2024-05-22 18:26:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch30_loss0.12829088866710664.pypots
2024-05-22 18:26:27 [INFO]: Epoch 031 - training loss: 0.1345, validation loss: 0.1262
2024-05-22 18:26:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch31_loss0.12622793167829513.pypots
2024-05-22 18:26:44 [INFO]: Epoch 032 - training loss: 0.1357, validation loss: 0.1256
2024-05-22 18:26:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch32_loss0.12558196634054183.pypots
2024-05-22 18:27:00 [INFO]: Epoch 033 - training loss: 0.1399, validation loss: 0.1217
2024-05-22 18:27:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch33_loss0.12167206332087517.pypots
2024-05-22 18:27:17 [INFO]: Epoch 034 - training loss: 0.1309, validation loss: 0.1251
2024-05-22 18:27:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch34_loss0.12506778165698051.pypots
2024-05-22 18:27:33 [INFO]: Epoch 035 - training loss: 0.1420, validation loss: 0.1247
2024-05-22 18:27:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch35_loss0.12474647909402847.pypots
2024-05-22 18:27:50 [INFO]: Epoch 036 - training loss: 0.1310, validation loss: 0.1236
2024-05-22 18:27:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch36_loss0.12360126450657845.pypots
2024-05-22 18:28:06 [INFO]: Epoch 037 - training loss: 0.1167, validation loss: 0.1189
2024-05-22 18:28:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch37_loss0.11885141581296921.pypots
2024-05-22 18:28:23 [INFO]: Epoch 038 - training loss: 0.1326, validation loss: 0.1197
2024-05-22 18:28:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch38_loss0.11972153335809707.pypots
2024-05-22 18:28:39 [INFO]: Epoch 039 - training loss: 0.1248, validation loss: 0.1189
2024-05-22 18:28:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch39_loss0.11887733042240142.pypots
2024-05-22 18:28:56 [INFO]: Epoch 040 - training loss: 0.1261, validation loss: 0.1166
2024-05-22 18:28:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch40_loss0.11657916232943535.pypots
2024-05-22 18:29:12 [INFO]: Epoch 041 - training loss: 0.1132, validation loss: 0.1194
2024-05-22 18:29:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch41_loss0.11940674334764481.pypots
2024-05-22 18:29:29 [INFO]: Epoch 042 - training loss: 0.1200, validation loss: 0.1166
2024-05-22 18:29:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch42_loss0.11661641672253609.pypots
2024-05-22 18:29:45 [INFO]: Epoch 043 - training loss: 0.1332, validation loss: 0.1136
2024-05-22 18:29:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch43_loss0.11358476802706718.pypots
2024-05-22 18:30:02 [INFO]: Epoch 044 - training loss: 0.1247, validation loss: 0.1137
2024-05-22 18:30:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch44_loss0.11368565559387207.pypots
2024-05-22 18:30:18 [INFO]: Epoch 045 - training loss: 0.1169, validation loss: 0.1126
2024-05-22 18:30:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch45_loss0.11264237016439438.pypots
2024-05-22 18:30:35 [INFO]: Epoch 046 - training loss: 0.1292, validation loss: 0.1168
2024-05-22 18:30:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch46_loss0.11679821014404297.pypots
2024-05-22 18:30:51 [INFO]: Epoch 047 - training loss: 0.1267, validation loss: 0.1125
2024-05-22 18:30:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch47_loss0.11248972415924072.pypots
2024-05-22 18:31:08 [INFO]: Epoch 048 - training loss: 0.1224, validation loss: 0.1105
2024-05-22 18:31:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch48_loss0.11054796427488327.pypots
2024-05-22 18:31:24 [INFO]: Epoch 049 - training loss: 0.1238, validation loss: 0.1130
2024-05-22 18:31:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch49_loss0.11297219172120095.pypots
2024-05-22 18:31:41 [INFO]: Epoch 050 - training loss: 0.1199, validation loss: 0.1092
2024-05-22 18:31:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch50_loss0.10919657200574875.pypots
2024-05-22 18:31:57 [INFO]: Epoch 051 - training loss: 0.1061, validation loss: 0.1116
2024-05-22 18:31:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch51_loss0.1115840919315815.pypots
2024-05-22 18:32:13 [INFO]: Epoch 052 - training loss: 0.1241, validation loss: 0.1113
2024-05-22 18:32:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch52_loss0.11125535145401955.pypots
2024-05-22 18:32:30 [INFO]: Epoch 053 - training loss: 0.1389, validation loss: 0.1167
2024-05-22 18:32:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch53_loss0.11672943532466888.pypots
2024-05-22 18:32:46 [INFO]: Epoch 054 - training loss: 0.1108, validation loss: 0.1107
2024-05-22 18:32:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch54_loss0.11066677793860435.pypots
2024-05-22 18:33:03 [INFO]: Epoch 055 - training loss: 0.1314, validation loss: 0.1136
2024-05-22 18:33:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch55_loss0.1135961078107357.pypots
2024-05-22 18:33:19 [INFO]: Epoch 056 - training loss: 0.1216, validation loss: 0.1075
2024-05-22 18:33:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch56_loss0.1074796698987484.pypots
2024-05-22 18:33:36 [INFO]: Epoch 057 - training loss: 0.1229, validation loss: 0.1109
2024-05-22 18:33:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch57_loss0.110948396474123.pypots
2024-05-22 18:33:52 [INFO]: Epoch 058 - training loss: 0.1128, validation loss: 0.1221
2024-05-22 18:33:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch58_loss0.12213308066129684.pypots
2024-05-22 18:34:09 [INFO]: Epoch 059 - training loss: 0.1375, validation loss: 0.1154
2024-05-22 18:34:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch59_loss0.11539199575781822.pypots
2024-05-22 18:34:25 [INFO]: Epoch 060 - training loss: 0.1306, validation loss: 0.1088
2024-05-22 18:34:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch60_loss0.10876843333244324.pypots
2024-05-22 18:34:42 [INFO]: Epoch 061 - training loss: 0.1239, validation loss: 0.1096
2024-05-22 18:34:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch61_loss0.10955789014697075.pypots
2024-05-22 18:34:58 [INFO]: Epoch 062 - training loss: 0.1148, validation loss: 0.1068
2024-05-22 18:34:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch62_loss0.10681217834353447.pypots
2024-05-22 18:35:15 [INFO]: Epoch 063 - training loss: 0.1235, validation loss: 0.1085
2024-05-22 18:35:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch63_loss0.1084732361137867.pypots
2024-05-22 18:35:31 [INFO]: Epoch 064 - training loss: 0.1330, validation loss: 0.1083
2024-05-22 18:35:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch64_loss0.10832738131284714.pypots
2024-05-22 18:35:48 [INFO]: Epoch 065 - training loss: 0.1166, validation loss: 0.1071
2024-05-22 18:35:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch65_loss0.10705400258302689.pypots
2024-05-22 18:36:04 [INFO]: Epoch 066 - training loss: 0.1209, validation loss: 0.1079
2024-05-22 18:36:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch66_loss0.1079125352203846.pypots
2024-05-22 18:36:21 [INFO]: Epoch 067 - training loss: 0.1172, validation loss: 0.1114
2024-05-22 18:36:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch67_loss0.1114132322371006.pypots
2024-05-22 18:36:37 [INFO]: Epoch 068 - training loss: 0.1140, validation loss: 0.1077
2024-05-22 18:36:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch68_loss0.10765219330787659.pypots
2024-05-22 18:36:54 [INFO]: Epoch 069 - training loss: 0.1286, validation loss: 0.1142
2024-05-22 18:36:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch69_loss0.11415167525410652.pypots
2024-05-22 18:37:10 [INFO]: Epoch 070 - training loss: 0.1205, validation loss: 0.1089
2024-05-22 18:37:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch70_loss0.10889741256833077.pypots
2024-05-22 18:37:27 [INFO]: Epoch 071 - training loss: 0.1145, validation loss: 0.1082
2024-05-22 18:37:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch71_loss0.10821947753429413.pypots
2024-05-22 18:37:43 [INFO]: Epoch 072 - training loss: 0.1318, validation loss: 0.1048
2024-05-22 18:37:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch72_loss0.10481580570340157.pypots
2024-05-22 18:38:00 [INFO]: Epoch 073 - training loss: 0.1332, validation loss: 0.1053
2024-05-22 18:38:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch73_loss0.10528878942131996.pypots
2024-05-22 18:38:16 [INFO]: Epoch 074 - training loss: 0.1219, validation loss: 0.1056
2024-05-22 18:38:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch74_loss0.10557733774185181.pypots
2024-05-22 18:38:33 [INFO]: Epoch 075 - training loss: 0.1068, validation loss: 0.1050
2024-05-22 18:38:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch75_loss0.10496132671833039.pypots
2024-05-22 18:38:49 [INFO]: Epoch 076 - training loss: 0.1259, validation loss: 0.1113
2024-05-22 18:38:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch76_loss0.11129572242498398.pypots
2024-05-22 18:39:06 [INFO]: Epoch 077 - training loss: 0.1273, validation loss: 0.1033
2024-05-22 18:39:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch77_loss0.10326798483729363.pypots
2024-05-22 18:39:22 [INFO]: Epoch 078 - training loss: 0.1286, validation loss: 0.1059
2024-05-22 18:39:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch78_loss0.10589492693543434.pypots
2024-05-22 18:39:38 [INFO]: Epoch 079 - training loss: 0.1185, validation loss: 0.1047
2024-05-22 18:39:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch79_loss0.10469862595200538.pypots
2024-05-22 18:39:55 [INFO]: Epoch 080 - training loss: 0.1143, validation loss: 0.1066
2024-05-22 18:39:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch80_loss0.10660146027803422.pypots
2024-05-22 18:40:11 [INFO]: Epoch 081 - training loss: 0.1201, validation loss: 0.1067
2024-05-22 18:40:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch81_loss0.10667306780815125.pypots
2024-05-22 18:40:28 [INFO]: Epoch 082 - training loss: 0.1225, validation loss: 0.1063
2024-05-22 18:40:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch82_loss0.10627805963158607.pypots
2024-05-22 18:40:44 [INFO]: Epoch 083 - training loss: 0.1144, validation loss: 0.1045
2024-05-22 18:40:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch83_loss0.1045390471816063.pypots
2024-05-22 18:41:01 [INFO]: Epoch 084 - training loss: 0.1083, validation loss: 0.1025
2024-05-22 18:41:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch84_loss0.10251044109463692.pypots
2024-05-22 18:41:17 [INFO]: Epoch 085 - training loss: 0.1198, validation loss: 0.1058
2024-05-22 18:41:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch85_loss0.1058131881058216.pypots
2024-05-22 18:41:34 [INFO]: Epoch 086 - training loss: 0.1074, validation loss: 0.1073
2024-05-22 18:41:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch86_loss0.10732890591025353.pypots
2024-05-22 18:41:50 [INFO]: Epoch 087 - training loss: 0.1329, validation loss: 0.1049
2024-05-22 18:41:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch87_loss0.1048716850578785.pypots
2024-05-22 18:42:07 [INFO]: Epoch 088 - training loss: 0.1298, validation loss: 0.1041
2024-05-22 18:42:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch88_loss0.1040766142308712.pypots
2024-05-22 18:42:23 [INFO]: Epoch 089 - training loss: 0.1320, validation loss: 0.1055
2024-05-22 18:42:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch89_loss0.1054613396525383.pypots
2024-05-22 18:42:40 [INFO]: Epoch 090 - training loss: 0.1357, validation loss: 0.1056
2024-05-22 18:42:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch90_loss0.1056368850171566.pypots
2024-05-22 18:42:56 [INFO]: Epoch 091 - training loss: 0.1158, validation loss: 0.1019
2024-05-22 18:42:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch91_loss0.10190864279866219.pypots
2024-05-22 18:43:13 [INFO]: Epoch 092 - training loss: 0.1094, validation loss: 0.1017
2024-05-22 18:43:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch92_loss0.10165138021111489.pypots
2024-05-22 18:43:29 [INFO]: Epoch 093 - training loss: 0.1061, validation loss: 0.1058
2024-05-22 18:43:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch93_loss0.10584163665771484.pypots
2024-05-22 18:43:46 [INFO]: Epoch 094 - training loss: 0.1234, validation loss: 0.1038
2024-05-22 18:43:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch94_loss0.10384241044521332.pypots
2024-05-22 18:44:02 [INFO]: Epoch 095 - training loss: 0.1251, validation loss: 0.1023
2024-05-22 18:44:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch95_loss0.10230249166488647.pypots
2024-05-22 18:44:19 [INFO]: Epoch 096 - training loss: 0.1080, validation loss: 0.1016
2024-05-22 18:44:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch96_loss0.10164504423737526.pypots
2024-05-22 18:44:35 [INFO]: Epoch 097 - training loss: 0.1088, validation loss: 0.1015
2024-05-22 18:44:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch97_loss0.10148117244243622.pypots
2024-05-22 18:44:52 [INFO]: Epoch 098 - training loss: 0.1247, validation loss: 0.1041
2024-05-22 18:44:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch98_loss0.10406757593154907.pypots
2024-05-22 18:45:08 [INFO]: Epoch 099 - training loss: 0.1017, validation loss: 0.1013
2024-05-22 18:45:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch99_loss0.101250159740448.pypots
2024-05-22 18:45:25 [INFO]: Epoch 100 - training loss: 0.1219, validation loss: 0.1037
2024-05-22 18:45:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch100_loss0.10365041643381119.pypots
2024-05-22 18:45:41 [INFO]: Epoch 101 - training loss: 0.1186, validation loss: 0.1026
2024-05-22 18:45:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch101_loss0.10261055082082748.pypots
2024-05-22 18:45:58 [INFO]: Epoch 102 - training loss: 0.1077, validation loss: 0.1016
2024-05-22 18:45:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch102_loss0.10159723535180092.pypots
2024-05-22 18:46:14 [INFO]: Epoch 103 - training loss: 0.1030, validation loss: 0.1010
2024-05-22 18:46:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch103_loss0.10103484466671944.pypots
2024-05-22 18:46:30 [INFO]: Epoch 104 - training loss: 0.1006, validation loss: 0.1014
2024-05-22 18:46:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch104_loss0.10139093995094299.pypots
2024-05-22 18:46:47 [INFO]: Epoch 105 - training loss: 0.1152, validation loss: 0.1012
2024-05-22 18:46:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch105_loss0.10115058794617653.pypots
2024-05-22 18:47:03 [INFO]: Epoch 106 - training loss: 0.1032, validation loss: 0.1027
2024-05-22 18:47:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch106_loss0.10266896262764931.pypots
2024-05-22 18:47:20 [INFO]: Epoch 107 - training loss: 0.1198, validation loss: 0.1025
2024-05-22 18:47:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch107_loss0.10252592861652374.pypots
2024-05-22 18:47:36 [INFO]: Epoch 108 - training loss: 0.1128, validation loss: 0.1020
2024-05-22 18:47:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch108_loss0.1020448699593544.pypots
2024-05-22 18:47:53 [INFO]: Epoch 109 - training loss: 0.1128, validation loss: 0.0994
2024-05-22 18:47:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch109_loss0.0993673749268055.pypots
2024-05-22 18:48:09 [INFO]: Epoch 110 - training loss: 0.1054, validation loss: 0.1003
2024-05-22 18:48:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch110_loss0.10025078952312469.pypots
2024-05-22 18:48:26 [INFO]: Epoch 111 - training loss: 0.1156, validation loss: 0.1020
2024-05-22 18:48:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch111_loss0.10200726613402367.pypots
2024-05-22 18:48:42 [INFO]: Epoch 112 - training loss: 0.1151, validation loss: 0.1066
2024-05-22 18:48:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch112_loss0.10661999732255936.pypots
2024-05-22 18:48:59 [INFO]: Epoch 113 - training loss: 0.1068, validation loss: 0.0991
2024-05-22 18:48:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch113_loss0.09905727952718735.pypots
2024-05-22 18:49:15 [INFO]: Epoch 114 - training loss: 0.1048, validation loss: 0.1011
2024-05-22 18:49:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch114_loss0.10114040598273277.pypots
2024-05-22 18:49:32 [INFO]: Epoch 115 - training loss: 0.0922, validation loss: 0.1099
2024-05-22 18:49:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch115_loss0.10992186814546585.pypots
2024-05-22 18:49:48 [INFO]: Epoch 116 - training loss: 0.1262, validation loss: 0.0992
2024-05-22 18:49:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch116_loss0.099188631772995.pypots
2024-05-22 18:50:05 [INFO]: Epoch 117 - training loss: 0.1065, validation loss: 0.1010
2024-05-22 18:50:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch117_loss0.10102389007806778.pypots
2024-05-22 18:50:21 [INFO]: Epoch 118 - training loss: 0.1119, validation loss: 0.1062
2024-05-22 18:50:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch118_loss0.10619685724377632.pypots
2024-05-22 18:50:38 [INFO]: Epoch 119 - training loss: 0.1130, validation loss: 0.1016
2024-05-22 18:50:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch119_loss0.10164537355303764.pypots
2024-05-22 18:50:54 [INFO]: Epoch 120 - training loss: 0.0958, validation loss: 0.1000
2024-05-22 18:50:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch120_loss0.09998097196221352.pypots
2024-05-22 18:51:11 [INFO]: Epoch 121 - training loss: 0.1078, validation loss: 0.1004
2024-05-22 18:51:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch121_loss0.10035915002226829.pypots
2024-05-22 18:51:27 [INFO]: Epoch 122 - training loss: 0.1285, validation loss: 0.1052
2024-05-22 18:51:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch122_loss0.10524703562259674.pypots
2024-05-22 18:51:44 [INFO]: Epoch 123 - training loss: 0.1173, validation loss: 0.1035
2024-05-22 18:51:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI_epoch123_loss0.10350307896733284.pypots
2024-05-22 18:51:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 18:51:44 [INFO]: Finished training. The best model is from epoch#113.
2024-05-22 18:51:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/20240522_T181756/CSDI.pypots
2024-05-22 18:54:01 [INFO]: CSDI on Air-Quality: MAE=0.1019, MSE=0.1074
2024-05-22 18:54:01 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/CSDI_air_quality/imputation.pkl
2024-05-22 18:54:01 [INFO]: Using the given device: cuda:0
2024-05-22 18:54:01 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/GPVAE_air_quality/20240522_T185401
2024-05-22 18:54:01 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/GPVAE_air_quality/20240522_T185401/tensorboard
2024-05-22 18:54:01 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-22 18:54:02 [INFO]: Epoch 001 - training loss: 63542.0545, validation loss: 0.6303
2024-05-22 18:54:02 [INFO]: Epoch 002 - training loss: 42060.3043, validation loss: 0.5537
2024-05-22 18:54:02 [INFO]: Epoch 003 - training loss: 41760.3997, validation loss: 0.4851
2024-05-22 18:54:02 [INFO]: Epoch 004 - training loss: 41621.9262, validation loss: 0.4540
2024-05-22 18:54:03 [INFO]: Epoch 005 - training loss: 41534.6338, validation loss: 0.4097
2024-05-22 18:54:03 [INFO]: Epoch 006 - training loss: 41519.3009, validation loss: 0.4141
2024-05-22 18:54:03 [INFO]: Epoch 007 - training loss: 41468.8096, validation loss: 0.3699
2024-05-22 18:54:03 [INFO]: Epoch 008 - training loss: 41421.9460, validation loss: 0.3347
2024-05-22 18:54:04 [INFO]: Epoch 009 - training loss: 41378.6217, validation loss: 0.3244
2024-05-22 18:54:04 [INFO]: Epoch 010 - training loss: 41361.0799, validation loss: 0.3628
2024-05-22 18:54:04 [INFO]: Epoch 011 - training loss: 41405.9703, validation loss: 0.3147
2024-05-22 18:54:04 [INFO]: Epoch 012 - training loss: 41351.9243, validation loss: 0.2987
2024-05-22 18:54:05 [INFO]: Epoch 013 - training loss: 41323.3142, validation loss: 0.2912
2024-05-22 18:54:05 [INFO]: Epoch 014 - training loss: 41320.7821, validation loss: 0.2889
2024-05-22 18:54:05 [INFO]: Epoch 015 - training loss: 41336.1771, validation loss: 0.3033
2024-05-22 18:54:05 [INFO]: Epoch 016 - training loss: 41318.0472, validation loss: 0.2844
2024-05-22 18:54:06 [INFO]: Epoch 017 - training loss: 41301.0023, validation loss: 0.3209
2024-05-22 18:54:06 [INFO]: Epoch 018 - training loss: 41346.7695, validation loss: 0.3016
2024-05-22 18:54:06 [INFO]: Epoch 019 - training loss: 41302.0664, validation loss: 0.2685
2024-05-22 18:54:06 [INFO]: Epoch 020 - training loss: 41270.1069, validation loss: 0.2739
2024-05-22 18:54:07 [INFO]: Epoch 021 - training loss: 41266.8061, validation loss: 0.2658
2024-05-22 18:54:07 [INFO]: Epoch 022 - training loss: 41257.0071, validation loss: 0.2546
2024-05-22 18:54:07 [INFO]: Epoch 023 - training loss: 41248.1314, validation loss: 0.2501
2024-05-22 18:54:07 [INFO]: Epoch 024 - training loss: 41247.6246, validation loss: 0.2976
2024-05-22 18:54:08 [INFO]: Epoch 025 - training loss: 41252.5887, validation loss: 0.2561
2024-05-22 18:54:08 [INFO]: Epoch 026 - training loss: 41233.3260, validation loss: 0.2439
2024-05-22 18:54:08 [INFO]: Epoch 027 - training loss: 41221.8325, validation loss: 0.2345
2024-05-22 18:54:08 [INFO]: Epoch 028 - training loss: 41223.9187, validation loss: 0.2482
2024-05-22 18:54:08 [INFO]: Epoch 029 - training loss: 41279.3050, validation loss: 0.2519
2024-05-22 18:54:09 [INFO]: Epoch 030 - training loss: 41313.6480, validation loss: 0.3144
2024-05-22 18:54:09 [INFO]: Epoch 031 - training loss: 41295.2635, validation loss: 0.2507
2024-05-22 18:54:09 [INFO]: Epoch 032 - training loss: 41233.3280, validation loss: 0.2432
2024-05-22 18:54:09 [INFO]: Epoch 033 - training loss: 41207.8508, validation loss: 0.2376
2024-05-22 18:54:10 [INFO]: Epoch 034 - training loss: 41201.9372, validation loss: 0.2364
2024-05-22 18:54:10 [INFO]: Epoch 035 - training loss: 41202.0394, validation loss: 0.2618
2024-05-22 18:54:10 [INFO]: Epoch 036 - training loss: 41224.8084, validation loss: 0.2364
2024-05-22 18:54:10 [INFO]: Epoch 037 - training loss: 41245.4766, validation loss: 0.2520
2024-05-22 18:54:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 18:54:10 [INFO]: Finished training. The best model is from epoch#27.
2024-05-22 18:54:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/GPVAE_air_quality/20240522_T185401/GPVAE.pypots
2024-05-22 18:54:10 [INFO]: GP-VAE on Air-Quality: MAE=0.3065, MSE=0.2668
2024-05-22 18:54:10 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/GPVAE_air_quality/imputation.pkl
2024-05-22 18:54:10 [INFO]: Using the given device: cuda:0
2024-05-22 18:54:10 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/USGAN_air_quality/20240522_T185410
2024-05-22 18:54:10 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/USGAN_air_quality/20240522_T185410/tensorboard
2024-05-22 18:54:10 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-22 18:54:15 [INFO]: Epoch 001 - generator training loss: 0.6155, discriminator training loss: 0.2837, validation loss: 0.4951
2024-05-22 18:54:18 [INFO]: Epoch 002 - generator training loss: 0.2881, discriminator training loss: 0.0672, validation loss: 0.3615
2024-05-22 18:54:21 [INFO]: Epoch 003 - generator training loss: 0.2133, discriminator training loss: 0.0634, validation loss: 0.2972
2024-05-22 18:54:25 [INFO]: Epoch 004 - generator training loss: 0.1752, discriminator training loss: 0.0626, validation loss: 0.2592
2024-05-22 18:54:28 [INFO]: Epoch 005 - generator training loss: 0.1511, discriminator training loss: 0.0618, validation loss: 0.2333
2024-05-22 18:54:32 [INFO]: Epoch 006 - generator training loss: 0.1353, discriminator training loss: 0.0610, validation loss: 0.2159
2024-05-22 18:54:35 [INFO]: Epoch 007 - generator training loss: 0.1215, discriminator training loss: 0.0604, validation loss: 0.2030
2024-05-22 18:54:38 [INFO]: Epoch 008 - generator training loss: 0.1129, discriminator training loss: 0.0599, validation loss: 0.1927
2024-05-22 18:54:42 [INFO]: Epoch 009 - generator training loss: 0.1032, discriminator training loss: 0.0592, validation loss: 0.1840
2024-05-22 18:54:45 [INFO]: Epoch 010 - generator training loss: 0.0958, discriminator training loss: 0.0583, validation loss: 0.1766
2024-05-22 18:54:49 [INFO]: Epoch 011 - generator training loss: 0.0930, discriminator training loss: 0.0572, validation loss: 0.1710
2024-05-22 18:54:52 [INFO]: Epoch 012 - generator training loss: 0.0872, discriminator training loss: 0.0561, validation loss: 0.1659
2024-05-22 18:54:56 [INFO]: Epoch 013 - generator training loss: 0.0843, discriminator training loss: 0.0544, validation loss: 0.1615
2024-05-22 18:54:59 [INFO]: Epoch 014 - generator training loss: 0.0832, discriminator training loss: 0.0538, validation loss: 0.1577
2024-05-22 18:55:02 [INFO]: Epoch 015 - generator training loss: 0.0788, discriminator training loss: 0.0514, validation loss: 0.1546
2024-05-22 18:55:06 [INFO]: Epoch 016 - generator training loss: 0.0769, discriminator training loss: 0.0495, validation loss: 0.1511
2024-05-22 18:55:09 [INFO]: Epoch 017 - generator training loss: 0.0754, discriminator training loss: 0.0480, validation loss: 0.1481
2024-05-22 18:55:13 [INFO]: Epoch 018 - generator training loss: 0.0732, discriminator training loss: 0.0472, validation loss: 0.1460
2024-05-22 18:55:16 [INFO]: Epoch 019 - generator training loss: 0.0725, discriminator training loss: 0.0462, validation loss: 0.1432
2024-05-22 18:55:19 [INFO]: Epoch 020 - generator training loss: 0.0696, discriminator training loss: 0.0451, validation loss: 0.1410
2024-05-22 18:55:23 [INFO]: Epoch 021 - generator training loss: 0.0678, discriminator training loss: 0.0445, validation loss: 0.1390
2024-05-22 18:55:26 [INFO]: Epoch 022 - generator training loss: 0.0668, discriminator training loss: 0.0438, validation loss: 0.1374
2024-05-22 18:55:30 [INFO]: Epoch 023 - generator training loss: 0.0656, discriminator training loss: 0.0433, validation loss: 0.1353
2024-05-22 18:55:33 [INFO]: Epoch 024 - generator training loss: 0.0644, discriminator training loss: 0.0422, validation loss: 0.1333
2024-05-22 18:55:37 [INFO]: Epoch 025 - generator training loss: 0.0636, discriminator training loss: 0.0413, validation loss: 0.1319
2024-05-22 18:55:40 [INFO]: Epoch 026 - generator training loss: 0.0631, discriminator training loss: 0.0409, validation loss: 0.1303
2024-05-22 18:55:43 [INFO]: Epoch 027 - generator training loss: 0.0627, discriminator training loss: 0.0402, validation loss: 0.1289
2024-05-22 18:55:47 [INFO]: Epoch 028 - generator training loss: 0.0613, discriminator training loss: 0.0390, validation loss: 0.1278
2024-05-22 18:55:50 [INFO]: Epoch 029 - generator training loss: 0.0613, discriminator training loss: 0.0383, validation loss: 0.1268
2024-05-22 18:55:54 [INFO]: Epoch 030 - generator training loss: 0.0595, discriminator training loss: 0.0377, validation loss: 0.1253
2024-05-22 18:55:57 [INFO]: Epoch 031 - generator training loss: 0.0617, discriminator training loss: 0.0366, validation loss: 0.1238
2024-05-22 18:56:01 [INFO]: Epoch 032 - generator training loss: 0.0584, discriminator training loss: 0.0359, validation loss: 0.1230
2024-05-22 18:56:04 [INFO]: Epoch 033 - generator training loss: 0.0587, discriminator training loss: 0.0353, validation loss: 0.1218
2024-05-22 18:56:07 [INFO]: Epoch 034 - generator training loss: 0.0572, discriminator training loss: 0.0346, validation loss: 0.1210
2024-05-22 18:56:11 [INFO]: Epoch 035 - generator training loss: 0.0572, discriminator training loss: 0.0336, validation loss: 0.1203
2024-05-22 18:56:14 [INFO]: Epoch 036 - generator training loss: 0.0572, discriminator training loss: 0.0328, validation loss: 0.1189
2024-05-22 18:56:18 [INFO]: Epoch 037 - generator training loss: 0.0554, discriminator training loss: 0.0326, validation loss: 0.1175
2024-05-22 18:56:21 [INFO]: Epoch 038 - generator training loss: 0.0550, discriminator training loss: 0.0317, validation loss: 0.1166
2024-05-22 18:56:25 [INFO]: Epoch 039 - generator training loss: 0.0546, discriminator training loss: 0.0312, validation loss: 0.1160
2024-05-22 18:56:28 [INFO]: Epoch 040 - generator training loss: 0.0529, discriminator training loss: 0.0305, validation loss: 0.1153
2024-05-22 18:56:31 [INFO]: Epoch 041 - generator training loss: 0.0526, discriminator training loss: 0.0298, validation loss: 0.1147
2024-05-22 18:56:35 [INFO]: Epoch 042 - generator training loss: 0.0535, discriminator training loss: 0.0294, validation loss: 0.1132
2024-05-22 18:56:38 [INFO]: Epoch 043 - generator training loss: 0.0512, discriminator training loss: 0.0287, validation loss: 0.1134
2024-05-22 18:56:42 [INFO]: Epoch 044 - generator training loss: 0.0509, discriminator training loss: 0.0282, validation loss: 0.1123
2024-05-22 18:56:45 [INFO]: Epoch 045 - generator training loss: 0.0502, discriminator training loss: 0.0279, validation loss: 0.1122
2024-05-22 18:56:48 [INFO]: Epoch 046 - generator training loss: 0.0507, discriminator training loss: 0.0273, validation loss: 0.1111
2024-05-22 18:56:52 [INFO]: Epoch 047 - generator training loss: 0.0508, discriminator training loss: 0.0268, validation loss: 0.1108
2024-05-22 18:56:55 [INFO]: Epoch 048 - generator training loss: 0.0492, discriminator training loss: 0.0264, validation loss: 0.1103
2024-05-22 18:56:59 [INFO]: Epoch 049 - generator training loss: 0.0492, discriminator training loss: 0.0263, validation loss: 0.1095
2024-05-22 18:57:02 [INFO]: Epoch 050 - generator training loss: 0.0487, discriminator training loss: 0.0258, validation loss: 0.1094
2024-05-22 18:57:06 [INFO]: Epoch 051 - generator training loss: 0.0482, discriminator training loss: 0.0253, validation loss: 0.1085
2024-05-22 18:57:09 [INFO]: Epoch 052 - generator training loss: 0.0482, discriminator training loss: 0.0248, validation loss: 0.1086
2024-05-22 18:57:12 [INFO]: Epoch 053 - generator training loss: 0.0477, discriminator training loss: 0.0246, validation loss: 0.1080
2024-05-22 18:57:16 [INFO]: Epoch 054 - generator training loss: 0.0475, discriminator training loss: 0.0241, validation loss: 0.1073
2024-05-22 18:57:19 [INFO]: Epoch 055 - generator training loss: 0.0470, discriminator training loss: 0.0238, validation loss: 0.1071
2024-05-22 18:57:23 [INFO]: Epoch 056 - generator training loss: 0.0468, discriminator training loss: 0.0232, validation loss: 0.1068
2024-05-22 18:57:26 [INFO]: Epoch 057 - generator training loss: 0.0467, discriminator training loss: 0.0229, validation loss: 0.1064
2024-05-22 18:57:30 [INFO]: Epoch 058 - generator training loss: 0.0463, discriminator training loss: 0.0227, validation loss: 0.1055
2024-05-22 18:57:33 [INFO]: Epoch 059 - generator training loss: 0.0466, discriminator training loss: 0.0224, validation loss: 0.1054
2024-05-22 18:57:36 [INFO]: Epoch 060 - generator training loss: 0.0459, discriminator training loss: 0.0222, validation loss: 0.1053
2024-05-22 18:57:40 [INFO]: Epoch 061 - generator training loss: 0.0456, discriminator training loss: 0.0221, validation loss: 0.1049
2024-05-22 18:57:43 [INFO]: Epoch 062 - generator training loss: 0.0469, discriminator training loss: 0.0215, validation loss: 0.1045
2024-05-22 18:57:47 [INFO]: Epoch 063 - generator training loss: 0.0454, discriminator training loss: 0.0209, validation loss: 0.1044
2024-05-22 18:57:50 [INFO]: Epoch 064 - generator training loss: 0.0448, discriminator training loss: 0.0210, validation loss: 0.1035
2024-05-22 18:57:53 [INFO]: Epoch 065 - generator training loss: 0.0448, discriminator training loss: 0.0209, validation loss: 0.1039
2024-05-22 18:57:57 [INFO]: Epoch 066 - generator training loss: 0.0455, discriminator training loss: 0.0205, validation loss: 0.1032
2024-05-22 18:58:00 [INFO]: Epoch 067 - generator training loss: 0.0451, discriminator training loss: 0.0204, validation loss: 0.1029
2024-05-22 18:58:04 [INFO]: Epoch 068 - generator training loss: 0.0440, discriminator training loss: 0.0202, validation loss: 0.1033
2024-05-22 18:58:07 [INFO]: Epoch 069 - generator training loss: 0.0447, discriminator training loss: 0.0198, validation loss: 0.1030
2024-05-22 18:58:11 [INFO]: Epoch 070 - generator training loss: 0.0437, discriminator training loss: 0.0197, validation loss: 0.1021
2024-05-22 18:58:14 [INFO]: Epoch 071 - generator training loss: 0.0444, discriminator training loss: 0.0195, validation loss: 0.1027
2024-05-22 18:58:18 [INFO]: Epoch 072 - generator training loss: 0.0429, discriminator training loss: 0.0195, validation loss: 0.1023
2024-05-22 18:58:21 [INFO]: Epoch 073 - generator training loss: 0.0430, discriminator training loss: 0.0190, validation loss: 0.1013
2024-05-22 18:58:25 [INFO]: Epoch 074 - generator training loss: 0.0427, discriminator training loss: 0.0187, validation loss: 0.1016
2024-05-22 18:58:28 [INFO]: Epoch 075 - generator training loss: 0.0424, discriminator training loss: 0.0188, validation loss: 0.1015
2024-05-22 18:58:31 [INFO]: Epoch 076 - generator training loss: 0.0418, discriminator training loss: 0.0185, validation loss: 0.1011
2024-05-22 18:58:35 [INFO]: Epoch 077 - generator training loss: 0.0421, discriminator training loss: 0.0182, validation loss: 0.1002
2024-05-22 18:58:38 [INFO]: Epoch 078 - generator training loss: 0.0419, discriminator training loss: 0.0181, validation loss: 0.1008
2024-05-22 18:58:42 [INFO]: Epoch 079 - generator training loss: 0.0421, discriminator training loss: 0.0182, validation loss: 0.1006
2024-05-22 18:58:46 [INFO]: Epoch 080 - generator training loss: 0.0413, discriminator training loss: 0.0178, validation loss: 0.1001
2024-05-22 18:58:49 [INFO]: Epoch 081 - generator training loss: 0.0420, discriminator training loss: 0.0178, validation loss: 0.1005
2024-05-22 18:58:53 [INFO]: Epoch 082 - generator training loss: 0.0408, discriminator training loss: 0.0175, validation loss: 0.1003
2024-05-22 18:58:56 [INFO]: Epoch 083 - generator training loss: 0.0407, discriminator training loss: 0.0173, validation loss: 0.0998
2024-05-22 18:59:00 [INFO]: Epoch 084 - generator training loss: 0.0404, discriminator training loss: 0.0170, validation loss: 0.0993
2024-05-22 18:59:03 [INFO]: Epoch 085 - generator training loss: 0.0416, discriminator training loss: 0.0171, validation loss: 0.0999
2024-05-22 18:59:06 [INFO]: Epoch 086 - generator training loss: 0.0406, discriminator training loss: 0.0169, validation loss: 0.0996
2024-05-22 18:59:10 [INFO]: Epoch 087 - generator training loss: 0.0401, discriminator training loss: 0.0167, validation loss: 0.0997
2024-05-22 18:59:13 [INFO]: Epoch 088 - generator training loss: 0.0404, discriminator training loss: 0.0166, validation loss: 0.0993
2024-05-22 18:59:17 [INFO]: Epoch 089 - generator training loss: 0.0399, discriminator training loss: 0.0167, validation loss: 0.0997
2024-05-22 18:59:21 [INFO]: Epoch 090 - generator training loss: 0.0402, discriminator training loss: 0.0165, validation loss: 0.0994
2024-05-22 18:59:24 [INFO]: Epoch 091 - generator training loss: 0.0398, discriminator training loss: 0.0163, validation loss: 0.0988
2024-05-22 18:59:27 [INFO]: Epoch 092 - generator training loss: 0.0396, discriminator training loss: 0.0162, validation loss: 0.0988
2024-05-22 18:59:31 [INFO]: Epoch 093 - generator training loss: 0.0398, discriminator training loss: 0.0161, validation loss: 0.0985
2024-05-22 18:59:34 [INFO]: Epoch 094 - generator training loss: 0.0386, discriminator training loss: 0.0160, validation loss: 0.0990
2024-05-22 18:59:38 [INFO]: Epoch 095 - generator training loss: 0.0385, discriminator training loss: 0.0159, validation loss: 0.0982
2024-05-22 18:59:42 [INFO]: Epoch 096 - generator training loss: 0.0384, discriminator training loss: 0.0157, validation loss: 0.0986
2024-05-22 18:59:45 [INFO]: Epoch 097 - generator training loss: 0.0379, discriminator training loss: 0.0158, validation loss: 0.0985
2024-05-22 18:59:49 [INFO]: Epoch 098 - generator training loss: 0.0379, discriminator training loss: 0.0157, validation loss: 0.0988
2024-05-22 18:59:52 [INFO]: Epoch 099 - generator training loss: 0.0377, discriminator training loss: 0.0155, validation loss: 0.0981
2024-05-22 18:59:56 [INFO]: Epoch 100 - generator training loss: 0.0375, discriminator training loss: 0.0154, validation loss: 0.0979
2024-05-22 18:59:59 [INFO]: Epoch 101 - generator training loss: 0.0385, discriminator training loss: 0.0155, validation loss: 0.0978
2024-05-22 19:00:03 [INFO]: Epoch 102 - generator training loss: 0.0373, discriminator training loss: 0.0152, validation loss: 0.0976
2024-05-22 19:00:06 [INFO]: Epoch 103 - generator training loss: 0.0371, discriminator training loss: 0.0151, validation loss: 0.0978
2024-05-22 19:00:10 [INFO]: Epoch 104 - generator training loss: 0.0368, discriminator training loss: 0.0150, validation loss: 0.0978
2024-05-22 19:00:14 [INFO]: Epoch 105 - generator training loss: 0.0385, discriminator training loss: 0.0153, validation loss: 0.0982
2024-05-22 19:00:17 [INFO]: Epoch 106 - generator training loss: 0.0365, discriminator training loss: 0.0152, validation loss: 0.0980
2024-05-22 19:00:20 [INFO]: Epoch 107 - generator training loss: 0.0366, discriminator training loss: 0.0149, validation loss: 0.0978
2024-05-22 19:00:24 [INFO]: Epoch 108 - generator training loss: 0.0369, discriminator training loss: 0.0148, validation loss: 0.0979
2024-05-22 19:00:27 [INFO]: Epoch 109 - generator training loss: 0.0363, discriminator training loss: 0.0147, validation loss: 0.0981
2024-05-22 19:00:31 [INFO]: Epoch 110 - generator training loss: 0.0371, discriminator training loss: 0.0147, validation loss: 0.0980
2024-05-22 19:00:34 [INFO]: Epoch 111 - generator training loss: 0.0359, discriminator training loss: 0.0147, validation loss: 0.0980
2024-05-22 19:00:38 [INFO]: Epoch 112 - generator training loss: 0.0367, discriminator training loss: 0.0146, validation loss: 0.0973
2024-05-22 19:00:41 [INFO]: Epoch 113 - generator training loss: 0.0357, discriminator training loss: 0.0145, validation loss: 0.0978
2024-05-22 19:00:45 [INFO]: Epoch 114 - generator training loss: 0.0352, discriminator training loss: 0.0145, validation loss: 0.0982
2024-05-22 19:00:48 [INFO]: Epoch 115 - generator training loss: 0.0352, discriminator training loss: 0.0143, validation loss: 0.0977
2024-05-22 19:00:52 [INFO]: Epoch 116 - generator training loss: 0.0352, discriminator training loss: 0.0141, validation loss: 0.0985
2024-05-22 19:00:55 [INFO]: Epoch 117 - generator training loss: 0.0349, discriminator training loss: 0.0144, validation loss: 0.0983
2024-05-22 19:00:59 [INFO]: Epoch 118 - generator training loss: 0.0350, discriminator training loss: 0.0142, validation loss: 0.0980
2024-05-22 19:01:02 [INFO]: Epoch 119 - generator training loss: 0.0348, discriminator training loss: 0.0139, validation loss: 0.0982
2024-05-22 19:01:06 [INFO]: Epoch 120 - generator training loss: 0.0346, discriminator training loss: 0.0142, validation loss: 0.0984
2024-05-22 19:01:09 [INFO]: Epoch 121 - generator training loss: 0.0352, discriminator training loss: 0.0139, validation loss: 0.0976
2024-05-22 19:01:12 [INFO]: Epoch 122 - generator training loss: 0.0351, discriminator training loss: 0.0138, validation loss: 0.0988
2024-05-22 19:01:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 19:01:12 [INFO]: Finished training. The best model is from epoch#112.
2024-05-22 19:01:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/USGAN_air_quality/20240522_T185410/USGAN.pypots
2024-05-22 19:01:13 [INFO]: US-GAN on Air-Quality: MAE=0.1710, MSE=0.1083
2024-05-22 19:01:13 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/USGAN_air_quality/imputation.pkl
2024-05-22 19:01:13 [INFO]: Using the given device: cuda:0
2024-05-22 19:01:13 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/BRITS_air_quality/20240522_T190113
2024-05-22 19:01:13 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/BRITS_air_quality/20240522_T190113/tensorboard
2024-05-22 19:01:13 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-22 19:01:16 [INFO]: Epoch 001 - training loss: 1.3986, validation loss: 0.9142
2024-05-22 19:01:18 [INFO]: Epoch 002 - training loss: 1.1228, validation loss: 0.6764
2024-05-22 19:01:21 [INFO]: Epoch 003 - training loss: 0.9356, validation loss: 0.5722
2024-05-22 19:01:23 [INFO]: Epoch 004 - training loss: 0.8332, validation loss: 0.5036
2024-05-22 19:01:26 [INFO]: Epoch 005 - training loss: 0.7595, validation loss: 0.4562
2024-05-22 19:01:28 [INFO]: Epoch 006 - training loss: 0.7053, validation loss: 0.4174
2024-05-22 19:01:30 [INFO]: Epoch 007 - training loss: 0.6600, validation loss: 0.3873
2024-05-22 19:01:33 [INFO]: Epoch 008 - training loss: 0.6271, validation loss: 0.3626
2024-05-22 19:01:35 [INFO]: Epoch 009 - training loss: 0.5983, validation loss: 0.3424
2024-05-22 19:01:37 [INFO]: Epoch 010 - training loss: 0.5755, validation loss: 0.3252
2024-05-22 19:01:40 [INFO]: Epoch 011 - training loss: 0.5580, validation loss: 0.3107
2024-05-22 19:01:42 [INFO]: Epoch 012 - training loss: 0.5417, validation loss: 0.2992
2024-05-22 19:01:44 [INFO]: Epoch 013 - training loss: 0.5279, validation loss: 0.2898
2024-05-22 19:01:47 [INFO]: Epoch 014 - training loss: 0.5159, validation loss: 0.2816
2024-05-22 19:01:49 [INFO]: Epoch 015 - training loss: 0.5052, validation loss: 0.2742
2024-05-22 19:01:51 [INFO]: Epoch 016 - training loss: 0.4965, validation loss: 0.2675
2024-05-22 19:01:54 [INFO]: Epoch 017 - training loss: 0.4869, validation loss: 0.2614
2024-05-22 19:01:56 [INFO]: Epoch 018 - training loss: 0.4785, validation loss: 0.2559
2024-05-22 19:01:59 [INFO]: Epoch 019 - training loss: 0.4729, validation loss: 0.2510
2024-05-22 19:02:01 [INFO]: Epoch 020 - training loss: 0.4627, validation loss: 0.2462
2024-05-22 19:02:03 [INFO]: Epoch 021 - training loss: 0.4555, validation loss: 0.2417
2024-05-22 19:02:06 [INFO]: Epoch 022 - training loss: 0.4496, validation loss: 0.2379
2024-05-22 19:02:08 [INFO]: Epoch 023 - training loss: 0.4431, validation loss: 0.2342
2024-05-22 19:02:10 [INFO]: Epoch 024 - training loss: 0.4369, validation loss: 0.2301
2024-05-22 19:02:13 [INFO]: Epoch 025 - training loss: 0.4306, validation loss: 0.2266
2024-05-22 19:02:15 [INFO]: Epoch 026 - training loss: 0.4253, validation loss: 0.2233
2024-05-22 19:02:18 [INFO]: Epoch 027 - training loss: 0.4209, validation loss: 0.2196
2024-05-22 19:02:20 [INFO]: Epoch 028 - training loss: 0.4151, validation loss: 0.2167
2024-05-22 19:02:22 [INFO]: Epoch 029 - training loss: 0.4099, validation loss: 0.2136
2024-05-22 19:02:25 [INFO]: Epoch 030 - training loss: 0.4053, validation loss: 0.2100
2024-05-22 19:02:27 [INFO]: Epoch 031 - training loss: 0.4020, validation loss: 0.2072
2024-05-22 19:02:29 [INFO]: Epoch 032 - training loss: 0.3972, validation loss: 0.2042
2024-05-22 19:02:32 [INFO]: Epoch 033 - training loss: 0.3922, validation loss: 0.2011
2024-05-22 19:02:34 [INFO]: Epoch 034 - training loss: 0.3882, validation loss: 0.1983
2024-05-22 19:02:37 [INFO]: Epoch 035 - training loss: 0.3850, validation loss: 0.1955
2024-05-22 19:02:39 [INFO]: Epoch 036 - training loss: 0.3802, validation loss: 0.1928
2024-05-22 19:02:41 [INFO]: Epoch 037 - training loss: 0.3774, validation loss: 0.1902
2024-05-22 19:02:44 [INFO]: Epoch 038 - training loss: 0.3732, validation loss: 0.1876
2024-05-22 19:02:46 [INFO]: Epoch 039 - training loss: 0.3712, validation loss: 0.1848
2024-05-22 19:02:48 [INFO]: Epoch 040 - training loss: 0.3673, validation loss: 0.1821
2024-05-22 19:02:51 [INFO]: Epoch 041 - training loss: 0.3632, validation loss: 0.1796
2024-05-22 19:02:53 [INFO]: Epoch 042 - training loss: 0.3610, validation loss: 0.1772
2024-05-22 19:02:56 [INFO]: Epoch 043 - training loss: 0.3580, validation loss: 0.1748
2024-05-22 19:02:58 [INFO]: Epoch 044 - training loss: 0.3557, validation loss: 0.1727
2024-05-22 19:03:00 [INFO]: Epoch 045 - training loss: 0.3526, validation loss: 0.1708
2024-05-22 19:03:03 [INFO]: Epoch 046 - training loss: 0.3501, validation loss: 0.1686
2024-05-22 19:03:05 [INFO]: Epoch 047 - training loss: 0.3472, validation loss: 0.1669
2024-05-22 19:03:07 [INFO]: Epoch 048 - training loss: 0.3450, validation loss: 0.1648
2024-05-22 19:03:10 [INFO]: Epoch 049 - training loss: 0.3417, validation loss: 0.1630
2024-05-22 19:03:12 [INFO]: Epoch 050 - training loss: 0.3394, validation loss: 0.1614
2024-05-22 19:03:15 [INFO]: Epoch 051 - training loss: 0.3378, validation loss: 0.1601
2024-05-22 19:03:17 [INFO]: Epoch 052 - training loss: 0.3357, validation loss: 0.1583
2024-05-22 19:03:19 [INFO]: Epoch 053 - training loss: 0.3335, validation loss: 0.1569
2024-05-22 19:03:22 [INFO]: Epoch 054 - training loss: 0.3306, validation loss: 0.1558
2024-05-22 19:03:24 [INFO]: Epoch 055 - training loss: 0.3291, validation loss: 0.1544
2024-05-22 19:03:26 [INFO]: Epoch 056 - training loss: 0.3278, validation loss: 0.1536
2024-05-22 19:03:29 [INFO]: Epoch 057 - training loss: 0.3248, validation loss: 0.1520
2024-05-22 19:03:31 [INFO]: Epoch 058 - training loss: 0.3243, validation loss: 0.1514
2024-05-22 19:03:33 [INFO]: Epoch 059 - training loss: 0.3217, validation loss: 0.1500
2024-05-22 19:03:36 [INFO]: Epoch 060 - training loss: 0.3197, validation loss: 0.1490
2024-05-22 19:03:38 [INFO]: Epoch 061 - training loss: 0.3183, validation loss: 0.1481
2024-05-22 19:03:41 [INFO]: Epoch 062 - training loss: 0.3165, validation loss: 0.1473
2024-05-22 19:03:43 [INFO]: Epoch 063 - training loss: 0.3152, validation loss: 0.1462
2024-05-22 19:03:45 [INFO]: Epoch 064 - training loss: 0.3136, validation loss: 0.1453
2024-05-22 19:03:48 [INFO]: Epoch 065 - training loss: 0.3119, validation loss: 0.1445
2024-05-22 19:03:50 [INFO]: Epoch 066 - training loss: 0.3108, validation loss: 0.1438
2024-05-22 19:03:52 [INFO]: Epoch 067 - training loss: 0.3095, validation loss: 0.1427
2024-05-22 19:03:55 [INFO]: Epoch 068 - training loss: 0.3079, validation loss: 0.1421
2024-05-22 19:03:57 [INFO]: Epoch 069 - training loss: 0.3073, validation loss: 0.1413
2024-05-22 19:03:59 [INFO]: Epoch 070 - training loss: 0.3050, validation loss: 0.1404
2024-05-22 19:04:02 [INFO]: Epoch 071 - training loss: 0.3049, validation loss: 0.1400
2024-05-22 19:04:04 [INFO]: Epoch 072 - training loss: 0.3031, validation loss: 0.1386
2024-05-22 19:04:06 [INFO]: Epoch 073 - training loss: 0.3018, validation loss: 0.1384
2024-05-22 19:04:09 [INFO]: Epoch 074 - training loss: 0.3008, validation loss: 0.1377
2024-05-22 19:04:11 [INFO]: Epoch 075 - training loss: 0.3003, validation loss: 0.1370
2024-05-22 19:04:13 [INFO]: Epoch 076 - training loss: 0.2988, validation loss: 0.1362
2024-05-22 19:04:16 [INFO]: Epoch 077 - training loss: 0.2979, validation loss: 0.1358
2024-05-22 19:04:18 [INFO]: Epoch 078 - training loss: 0.2970, validation loss: 0.1355
2024-05-22 19:04:20 [INFO]: Epoch 079 - training loss: 0.2957, validation loss: 0.1346
2024-05-22 19:04:23 [INFO]: Epoch 080 - training loss: 0.2952, validation loss: 0.1340
2024-05-22 19:04:25 [INFO]: Epoch 081 - training loss: 0.2940, validation loss: 0.1332
2024-05-22 19:04:27 [INFO]: Epoch 082 - training loss: 0.2934, validation loss: 0.1329
2024-05-22 19:04:30 [INFO]: Epoch 083 - training loss: 0.2921, validation loss: 0.1322
2024-05-22 19:04:32 [INFO]: Epoch 084 - training loss: 0.2909, validation loss: 0.1316
2024-05-22 19:04:34 [INFO]: Epoch 085 - training loss: 0.2909, validation loss: 0.1313
2024-05-22 19:04:37 [INFO]: Epoch 086 - training loss: 0.2897, validation loss: 0.1305
2024-05-22 19:04:39 [INFO]: Epoch 087 - training loss: 0.2891, validation loss: 0.1301
2024-05-22 19:04:41 [INFO]: Epoch 088 - training loss: 0.2883, validation loss: 0.1294
2024-05-22 19:04:44 [INFO]: Epoch 089 - training loss: 0.2873, validation loss: 0.1289
2024-05-22 19:04:46 [INFO]: Epoch 090 - training loss: 0.2871, validation loss: 0.1285
2024-05-22 19:04:48 [INFO]: Epoch 091 - training loss: 0.2860, validation loss: 0.1280
2024-05-22 19:04:51 [INFO]: Epoch 092 - training loss: 0.2845, validation loss: 0.1274
2024-05-22 19:04:53 [INFO]: Epoch 093 - training loss: 0.2844, validation loss: 0.1268
2024-05-22 19:04:55 [INFO]: Epoch 094 - training loss: 0.2832, validation loss: 0.1265
2024-05-22 19:04:58 [INFO]: Epoch 095 - training loss: 0.2829, validation loss: 0.1258
2024-05-22 19:05:00 [INFO]: Epoch 096 - training loss: 0.2826, validation loss: 0.1255
2024-05-22 19:05:02 [INFO]: Epoch 097 - training loss: 0.2812, validation loss: 0.1250
2024-05-22 19:05:05 [INFO]: Epoch 098 - training loss: 0.2809, validation loss: 0.1245
2024-05-22 19:05:07 [INFO]: Epoch 099 - training loss: 0.2794, validation loss: 0.1242
2024-05-22 19:05:09 [INFO]: Epoch 100 - training loss: 0.2800, validation loss: 0.1239
2024-05-22 19:05:11 [INFO]: Epoch 101 - training loss: 0.2790, validation loss: 0.1233
2024-05-22 19:05:14 [INFO]: Epoch 102 - training loss: 0.2786, validation loss: 0.1227
2024-05-22 19:05:16 [INFO]: Epoch 103 - training loss: 0.2778, validation loss: 0.1225
2024-05-22 19:05:18 [INFO]: Epoch 104 - training loss: 0.2776, validation loss: 0.1220
2024-05-22 19:05:21 [INFO]: Epoch 105 - training loss: 0.2767, validation loss: 0.1216
2024-05-22 19:05:23 [INFO]: Epoch 106 - training loss: 0.2758, validation loss: 0.1212
2024-05-22 19:05:25 [INFO]: Epoch 107 - training loss: 0.2761, validation loss: 0.1207
2024-05-22 19:05:28 [INFO]: Epoch 108 - training loss: 0.2752, validation loss: 0.1202
2024-05-22 19:05:30 [INFO]: Epoch 109 - training loss: 0.2741, validation loss: 0.1199
2024-05-22 19:05:32 [INFO]: Epoch 110 - training loss: 0.2737, validation loss: 0.1196
2024-05-22 19:05:35 [INFO]: Epoch 111 - training loss: 0.2732, validation loss: 0.1191
2024-05-22 19:05:37 [INFO]: Epoch 112 - training loss: 0.2727, validation loss: 0.1188
2024-05-22 19:05:39 [INFO]: Epoch 113 - training loss: 0.2725, validation loss: 0.1184
2024-05-22 19:05:42 [INFO]: Epoch 114 - training loss: 0.2722, validation loss: 0.1181
2024-05-22 19:05:44 [INFO]: Epoch 115 - training loss: 0.2711, validation loss: 0.1177
2024-05-22 19:05:46 [INFO]: Epoch 116 - training loss: 0.2707, validation loss: 0.1173
2024-05-22 19:05:49 [INFO]: Epoch 117 - training loss: 0.2700, validation loss: 0.1171
2024-05-22 19:05:51 [INFO]: Epoch 118 - training loss: 0.2698, validation loss: 0.1169
2024-05-22 19:05:53 [INFO]: Epoch 119 - training loss: 0.2693, validation loss: 0.1164
2024-05-22 19:05:56 [INFO]: Epoch 120 - training loss: 0.2686, validation loss: 0.1161
2024-05-22 19:05:58 [INFO]: Epoch 121 - training loss: 0.2681, validation loss: 0.1156
2024-05-22 19:06:00 [INFO]: Epoch 122 - training loss: 0.2677, validation loss: 0.1155
2024-05-22 19:06:02 [INFO]: Epoch 123 - training loss: 0.2671, validation loss: 0.1150
2024-05-22 19:06:05 [INFO]: Epoch 124 - training loss: 0.2672, validation loss: 0.1147
2024-05-22 19:06:07 [INFO]: Epoch 125 - training loss: 0.2668, validation loss: 0.1145
2024-05-22 19:06:09 [INFO]: Epoch 126 - training loss: 0.2658, validation loss: 0.1142
2024-05-22 19:06:12 [INFO]: Epoch 127 - training loss: 0.2654, validation loss: 0.1138
2024-05-22 19:06:14 [INFO]: Epoch 128 - training loss: 0.2652, validation loss: 0.1134
2024-05-22 19:06:16 [INFO]: Epoch 129 - training loss: 0.2647, validation loss: 0.1133
2024-05-22 19:06:19 [INFO]: Epoch 130 - training loss: 0.2638, validation loss: 0.1129
2024-05-22 19:06:21 [INFO]: Epoch 131 - training loss: 0.2644, validation loss: 0.1125
2024-05-22 19:06:23 [INFO]: Epoch 132 - training loss: 0.2634, validation loss: 0.1123
2024-05-22 19:06:26 [INFO]: Epoch 133 - training loss: 0.2630, validation loss: 0.1120
2024-05-22 19:06:28 [INFO]: Epoch 134 - training loss: 0.2623, validation loss: 0.1118
2024-05-22 19:06:30 [INFO]: Epoch 135 - training loss: 0.2627, validation loss: 0.1116
2024-05-22 19:06:33 [INFO]: Epoch 136 - training loss: 0.2617, validation loss: 0.1112
2024-05-22 19:06:35 [INFO]: Epoch 137 - training loss: 0.2615, validation loss: 0.1109
2024-05-22 19:06:37 [INFO]: Epoch 138 - training loss: 0.2610, validation loss: 0.1106
2024-05-22 19:06:40 [INFO]: Epoch 139 - training loss: 0.2604, validation loss: 0.1105
2024-05-22 19:06:42 [INFO]: Epoch 140 - training loss: 0.2601, validation loss: 0.1102
2024-05-22 19:06:44 [INFO]: Epoch 141 - training loss: 0.2594, validation loss: 0.1100
2024-05-22 19:06:47 [INFO]: Epoch 142 - training loss: 0.2592, validation loss: 0.1097
2024-05-22 19:06:49 [INFO]: Epoch 143 - training loss: 0.2590, validation loss: 0.1094
2024-05-22 19:06:51 [INFO]: Epoch 144 - training loss: 0.2589, validation loss: 0.1093
2024-05-22 19:06:53 [INFO]: Epoch 145 - training loss: 0.2584, validation loss: 0.1090
2024-05-22 19:06:56 [INFO]: Epoch 146 - training loss: 0.2587, validation loss: 0.1086
2024-05-22 19:06:58 [INFO]: Epoch 147 - training loss: 0.2578, validation loss: 0.1086
2024-05-22 19:07:00 [INFO]: Epoch 148 - training loss: 0.2575, validation loss: 0.1081
2024-05-22 19:07:03 [INFO]: Epoch 149 - training loss: 0.2569, validation loss: 0.1080
2024-05-22 19:07:05 [INFO]: Epoch 150 - training loss: 0.2567, validation loss: 0.1076
2024-05-22 19:07:07 [INFO]: Epoch 151 - training loss: 0.2564, validation loss: 0.1075
2024-05-22 19:07:10 [INFO]: Epoch 152 - training loss: 0.2563, validation loss: 0.1073
2024-05-22 19:07:12 [INFO]: Epoch 153 - training loss: 0.2557, validation loss: 0.1071
2024-05-22 19:07:14 [INFO]: Epoch 154 - training loss: 0.2555, validation loss: 0.1068
2024-05-22 19:07:17 [INFO]: Epoch 155 - training loss: 0.2557, validation loss: 0.1068
2024-05-22 19:07:19 [INFO]: Epoch 156 - training loss: 0.2548, validation loss: 0.1063
2024-05-22 19:07:21 [INFO]: Epoch 157 - training loss: 0.2548, validation loss: 0.1061
2024-05-22 19:07:24 [INFO]: Epoch 158 - training loss: 0.2542, validation loss: 0.1059
2024-05-22 19:07:26 [INFO]: Epoch 159 - training loss: 0.2540, validation loss: 0.1058
2024-05-22 19:07:28 [INFO]: Epoch 160 - training loss: 0.2539, validation loss: 0.1052
2024-05-22 19:07:31 [INFO]: Epoch 161 - training loss: 0.2535, validation loss: 0.1051
2024-05-22 19:07:33 [INFO]: Epoch 162 - training loss: 0.2530, validation loss: 0.1052
2024-05-22 19:07:35 [INFO]: Epoch 163 - training loss: 0.2530, validation loss: 0.1050
2024-05-22 19:07:37 [INFO]: Epoch 164 - training loss: 0.2527, validation loss: 0.1046
2024-05-22 19:07:40 [INFO]: Epoch 165 - training loss: 0.2520, validation loss: 0.1047
2024-05-22 19:07:42 [INFO]: Epoch 166 - training loss: 0.2517, validation loss: 0.1042
2024-05-22 19:07:44 [INFO]: Epoch 167 - training loss: 0.2512, validation loss: 0.1042
2024-05-22 19:07:47 [INFO]: Epoch 168 - training loss: 0.2511, validation loss: 0.1040
2024-05-22 19:07:49 [INFO]: Epoch 169 - training loss: 0.2512, validation loss: 0.1037
2024-05-22 19:07:51 [INFO]: Epoch 170 - training loss: 0.2506, validation loss: 0.1035
2024-05-22 19:07:54 [INFO]: Epoch 171 - training loss: 0.2508, validation loss: 0.1034
2024-05-22 19:07:56 [INFO]: Epoch 172 - training loss: 0.2503, validation loss: 0.1032
2024-05-22 19:07:58 [INFO]: Epoch 173 - training loss: 0.2498, validation loss: 0.1029
2024-05-22 19:08:01 [INFO]: Epoch 174 - training loss: 0.2498, validation loss: 0.1028
2024-05-22 19:08:03 [INFO]: Epoch 175 - training loss: 0.2498, validation loss: 0.1026
2024-05-22 19:08:05 [INFO]: Epoch 176 - training loss: 0.2489, validation loss: 0.1025
2024-05-22 19:08:08 [INFO]: Epoch 177 - training loss: 0.2490, validation loss: 0.1024
2024-05-22 19:08:10 [INFO]: Epoch 178 - training loss: 0.2487, validation loss: 0.1020
2024-05-22 19:08:12 [INFO]: Epoch 179 - training loss: 0.2490, validation loss: 0.1020
2024-05-22 19:08:15 [INFO]: Epoch 180 - training loss: 0.2479, validation loss: 0.1020
2024-05-22 19:08:17 [INFO]: Epoch 181 - training loss: 0.2477, validation loss: 0.1016
2024-05-22 19:08:19 [INFO]: Epoch 182 - training loss: 0.2477, validation loss: 0.1016
2024-05-22 19:08:22 [INFO]: Epoch 183 - training loss: 0.2478, validation loss: 0.1015
2024-05-22 19:08:24 [INFO]: Epoch 184 - training loss: 0.2472, validation loss: 0.1013
2024-05-22 19:08:26 [INFO]: Epoch 185 - training loss: 0.2474, validation loss: 0.1012
2024-05-22 19:08:29 [INFO]: Epoch 186 - training loss: 0.2468, validation loss: 0.1010
2024-05-22 19:08:31 [INFO]: Epoch 187 - training loss: 0.2466, validation loss: 0.1008
2024-05-22 19:08:33 [INFO]: Epoch 188 - training loss: 0.2464, validation loss: 0.1007
2024-05-22 19:08:36 [INFO]: Epoch 189 - training loss: 0.2458, validation loss: 0.1004
2024-05-22 19:08:38 [INFO]: Epoch 190 - training loss: 0.2463, validation loss: 0.1003
2024-05-22 19:08:40 [INFO]: Epoch 191 - training loss: 0.2462, validation loss: 0.1002
2024-05-22 19:08:43 [INFO]: Epoch 192 - training loss: 0.2453, validation loss: 0.1002
2024-05-22 19:08:45 [INFO]: Epoch 193 - training loss: 0.2451, validation loss: 0.0999
2024-05-22 19:08:47 [INFO]: Epoch 194 - training loss: 0.2452, validation loss: 0.0997
2024-05-22 19:08:49 [INFO]: Epoch 195 - training loss: 0.2449, validation loss: 0.0996
2024-05-22 19:08:52 [INFO]: Epoch 196 - training loss: 0.2446, validation loss: 0.0994
2024-05-22 19:08:54 [INFO]: Epoch 197 - training loss: 0.2444, validation loss: 0.0992
2024-05-22 19:08:56 [INFO]: Epoch 198 - training loss: 0.2439, validation loss: 0.0994
2024-05-22 19:08:59 [INFO]: Epoch 199 - training loss: 0.2444, validation loss: 0.0992
2024-05-22 19:09:01 [INFO]: Epoch 200 - training loss: 0.2444, validation loss: 0.0990
2024-05-22 19:09:03 [INFO]: Epoch 201 - training loss: 0.2436, validation loss: 0.0988
2024-05-22 19:09:06 [INFO]: Epoch 202 - training loss: 0.2433, validation loss: 0.0988
2024-05-22 19:09:08 [INFO]: Epoch 203 - training loss: 0.2434, validation loss: 0.0986
2024-05-22 19:09:10 [INFO]: Epoch 204 - training loss: 0.2432, validation loss: 0.0984
2024-05-22 19:09:13 [INFO]: Epoch 205 - training loss: 0.2427, validation loss: 0.0983
2024-05-22 19:09:15 [INFO]: Epoch 206 - training loss: 0.2426, validation loss: 0.0984
2024-05-22 19:09:17 [INFO]: Epoch 207 - training loss: 0.2426, validation loss: 0.0981
2024-05-22 19:09:20 [INFO]: Epoch 208 - training loss: 0.2417, validation loss: 0.0980
2024-05-22 19:09:22 [INFO]: Epoch 209 - training loss: 0.2420, validation loss: 0.0978
2024-05-22 19:09:24 [INFO]: Epoch 210 - training loss: 0.2419, validation loss: 0.0977
2024-05-22 19:09:27 [INFO]: Epoch 211 - training loss: 0.2422, validation loss: 0.0976
2024-05-22 19:09:29 [INFO]: Epoch 212 - training loss: 0.2415, validation loss: 0.0976
2024-05-22 19:09:31 [INFO]: Epoch 213 - training loss: 0.2410, validation loss: 0.0976
2024-05-22 19:09:33 [INFO]: Epoch 214 - training loss: 0.2413, validation loss: 0.0974
2024-05-22 19:09:36 [INFO]: Epoch 215 - training loss: 0.2415, validation loss: 0.0971
2024-05-22 19:09:38 [INFO]: Epoch 216 - training loss: 0.2412, validation loss: 0.0974
2024-05-22 19:09:40 [INFO]: Epoch 217 - training loss: 0.2405, validation loss: 0.0971
2024-05-22 19:09:43 [INFO]: Epoch 218 - training loss: 0.2403, validation loss: 0.0968
2024-05-22 19:09:45 [INFO]: Epoch 219 - training loss: 0.2402, validation loss: 0.0968
2024-05-22 19:09:47 [INFO]: Epoch 220 - training loss: 0.2404, validation loss: 0.0966
2024-05-22 19:09:50 [INFO]: Epoch 221 - training loss: 0.2401, validation loss: 0.0966
2024-05-22 19:09:52 [INFO]: Epoch 222 - training loss: 0.2405, validation loss: 0.0966
2024-05-22 19:09:54 [INFO]: Epoch 223 - training loss: 0.2401, validation loss: 0.0965
2024-05-22 19:09:57 [INFO]: Epoch 224 - training loss: 0.2397, validation loss: 0.0964
2024-05-22 19:09:59 [INFO]: Epoch 225 - training loss: 0.2395, validation loss: 0.0964
2024-05-22 19:10:01 [INFO]: Epoch 226 - training loss: 0.2394, validation loss: 0.0962
2024-05-22 19:10:04 [INFO]: Epoch 227 - training loss: 0.2392, validation loss: 0.0962
2024-05-22 19:10:06 [INFO]: Epoch 228 - training loss: 0.2385, validation loss: 0.0959
2024-05-22 19:10:08 [INFO]: Epoch 229 - training loss: 0.2385, validation loss: 0.0960
2024-05-22 19:10:11 [INFO]: Epoch 230 - training loss: 0.2386, validation loss: 0.0958
2024-05-22 19:10:13 [INFO]: Epoch 231 - training loss: 0.2382, validation loss: 0.0958
2024-05-22 19:10:15 [INFO]: Epoch 232 - training loss: 0.2384, validation loss: 0.0957
2024-05-22 19:10:18 [INFO]: Epoch 233 - training loss: 0.2381, validation loss: 0.0956
2024-05-22 19:10:20 [INFO]: Epoch 234 - training loss: 0.2376, validation loss: 0.0956
2024-05-22 19:10:22 [INFO]: Epoch 235 - training loss: 0.2375, validation loss: 0.0955
2024-05-22 19:10:25 [INFO]: Epoch 236 - training loss: 0.2375, validation loss: 0.0953
2024-05-22 19:10:27 [INFO]: Epoch 237 - training loss: 0.2371, validation loss: 0.0954
2024-05-22 19:10:29 [INFO]: Epoch 238 - training loss: 0.2371, validation loss: 0.0952
2024-05-22 19:10:31 [INFO]: Epoch 239 - training loss: 0.2378, validation loss: 0.0951
2024-05-22 19:10:34 [INFO]: Epoch 240 - training loss: 0.2377, validation loss: 0.0950
2024-05-22 19:10:36 [INFO]: Epoch 241 - training loss: 0.2373, validation loss: 0.0949
2024-05-22 19:10:38 [INFO]: Epoch 242 - training loss: 0.2363, validation loss: 0.0950
2024-05-22 19:10:41 [INFO]: Epoch 243 - training loss: 0.2365, validation loss: 0.0948
2024-05-22 19:10:43 [INFO]: Epoch 244 - training loss: 0.2361, validation loss: 0.0947
2024-05-22 19:10:45 [INFO]: Epoch 245 - training loss: 0.2360, validation loss: 0.0945
2024-05-22 19:10:48 [INFO]: Epoch 246 - training loss: 0.2360, validation loss: 0.0944
2024-05-22 19:10:50 [INFO]: Epoch 247 - training loss: 0.2356, validation loss: 0.0947
2024-05-22 19:10:52 [INFO]: Epoch 248 - training loss: 0.2359, validation loss: 0.0943
2024-05-22 19:10:55 [INFO]: Epoch 249 - training loss: 0.2358, validation loss: 0.0942
2024-05-22 19:10:57 [INFO]: Epoch 250 - training loss: 0.2356, validation loss: 0.0943
2024-05-22 19:10:59 [INFO]: Epoch 251 - training loss: 0.2352, validation loss: 0.0943
2024-05-22 19:11:02 [INFO]: Epoch 252 - training loss: 0.2348, validation loss: 0.0945
2024-05-22 19:11:04 [INFO]: Epoch 253 - training loss: 0.2352, validation loss: 0.0940
2024-05-22 19:11:06 [INFO]: Epoch 254 - training loss: 0.2344, validation loss: 0.0941
2024-05-22 19:11:09 [INFO]: Epoch 255 - training loss: 0.2350, validation loss: 0.0938
2024-05-22 19:11:11 [INFO]: Epoch 256 - training loss: 0.2350, validation loss: 0.0938
2024-05-22 19:11:13 [INFO]: Epoch 257 - training loss: 0.2349, validation loss: 0.0939
2024-05-22 19:11:16 [INFO]: Epoch 258 - training loss: 0.2346, validation loss: 0.0937
2024-05-22 19:11:18 [INFO]: Epoch 259 - training loss: 0.2341, validation loss: 0.0936
2024-05-22 19:11:20 [INFO]: Epoch 260 - training loss: 0.2339, validation loss: 0.0936
2024-05-22 19:11:23 [INFO]: Epoch 261 - training loss: 0.2337, validation loss: 0.0936
2024-05-22 19:11:25 [INFO]: Epoch 262 - training loss: 0.2334, validation loss: 0.0937
2024-05-22 19:11:27 [INFO]: Epoch 263 - training loss: 0.2337, validation loss: 0.0935
2024-05-22 19:11:29 [INFO]: Epoch 264 - training loss: 0.2337, validation loss: 0.0934
2024-05-22 19:11:32 [INFO]: Epoch 265 - training loss: 0.2334, validation loss: 0.0934
2024-05-22 19:11:34 [INFO]: Epoch 266 - training loss: 0.2338, validation loss: 0.0934
2024-05-22 19:11:36 [INFO]: Epoch 267 - training loss: 0.2329, validation loss: 0.0933
2024-05-22 19:11:39 [INFO]: Epoch 268 - training loss: 0.2329, validation loss: 0.0932
2024-05-22 19:11:41 [INFO]: Epoch 269 - training loss: 0.2332, validation loss: 0.0932
2024-05-22 19:11:44 [INFO]: Epoch 270 - training loss: 0.2327, validation loss: 0.0932
2024-05-22 19:11:46 [INFO]: Epoch 271 - training loss: 0.2327, validation loss: 0.0931
2024-05-22 19:11:48 [INFO]: Epoch 272 - training loss: 0.2327, validation loss: 0.0930
2024-05-22 19:11:50 [INFO]: Epoch 273 - training loss: 0.2321, validation loss: 0.0932
2024-05-22 19:11:53 [INFO]: Epoch 274 - training loss: 0.2322, validation loss: 0.0928
2024-05-22 19:11:55 [INFO]: Epoch 275 - training loss: 0.2322, validation loss: 0.0930
2024-05-22 19:11:57 [INFO]: Epoch 276 - training loss: 0.2324, validation loss: 0.0927
2024-05-22 19:12:00 [INFO]: Epoch 277 - training loss: 0.2319, validation loss: 0.0927
2024-05-22 19:12:02 [INFO]: Epoch 278 - training loss: 0.2313, validation loss: 0.0927
2024-05-22 19:12:04 [INFO]: Epoch 279 - training loss: 0.2325, validation loss: 0.0927
2024-05-22 19:12:07 [INFO]: Epoch 280 - training loss: 0.2316, validation loss: 0.0927
2024-05-22 19:12:09 [INFO]: Epoch 281 - training loss: 0.2317, validation loss: 0.0927
2024-05-22 19:12:11 [INFO]: Epoch 282 - training loss: 0.2315, validation loss: 0.0925
2024-05-22 19:12:14 [INFO]: Epoch 283 - training loss: 0.2312, validation loss: 0.0925
2024-05-22 19:12:16 [INFO]: Epoch 284 - training loss: 0.2309, validation loss: 0.0923
2024-05-22 19:12:18 [INFO]: Epoch 285 - training loss: 0.2309, validation loss: 0.0924
2024-05-22 19:12:21 [INFO]: Epoch 286 - training loss: 0.2311, validation loss: 0.0924
2024-05-22 19:12:23 [INFO]: Epoch 287 - training loss: 0.2311, validation loss: 0.0923
2024-05-22 19:12:25 [INFO]: Epoch 288 - training loss: 0.2305, validation loss: 0.0924
2024-05-22 19:12:28 [INFO]: Epoch 289 - training loss: 0.2303, validation loss: 0.0924
2024-05-22 19:12:30 [INFO]: Epoch 290 - training loss: 0.2309, validation loss: 0.0923
2024-05-22 19:12:32 [INFO]: Epoch 291 - training loss: 0.2302, validation loss: 0.0922
2024-05-22 19:12:34 [INFO]: Epoch 292 - training loss: 0.2305, validation loss: 0.0923
2024-05-22 19:12:37 [INFO]: Epoch 293 - training loss: 0.2304, validation loss: 0.0922
2024-05-22 19:12:39 [INFO]: Epoch 294 - training loss: 0.2301, validation loss: 0.0922
2024-05-22 19:12:41 [INFO]: Epoch 295 - training loss: 0.2302, validation loss: 0.0921
2024-05-22 19:12:44 [INFO]: Epoch 296 - training loss: 0.2299, validation loss: 0.0920
2024-05-22 19:12:46 [INFO]: Epoch 297 - training loss: 0.2300, validation loss: 0.0921
2024-05-22 19:12:48 [INFO]: Epoch 298 - training loss: 0.2296, validation loss: 0.0918
2024-05-22 19:12:51 [INFO]: Epoch 299 - training loss: 0.2294, validation loss: 0.0920
2024-05-22 19:12:53 [INFO]: Epoch 300 - training loss: 0.2294, validation loss: 0.0918
2024-05-22 19:12:53 [INFO]: Finished training. The best model is from epoch#298.
2024-05-22 19:12:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/BRITS_air_quality/20240522_T190113/BRITS.pypots
2024-05-22 19:12:54 [INFO]: BRITS on Air-Quality: MAE=0.1415, MSE=0.1043
2024-05-22 19:12:54 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/BRITS_air_quality/imputation.pkl
2024-05-22 19:12:54 [INFO]: Using the given device: cuda:0
2024-05-22 19:12:54 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254
2024-05-22 19:12:54 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/tensorboard
2024-05-22 19:12:54 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-22 19:12:57 [INFO]: Epoch 001 - training loss: 1.4786, validation loss: 0.7804
2024-05-22 19:12:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch1_loss0.7803782850503922.pypots
2024-05-22 19:13:00 [INFO]: Epoch 002 - training loss: 1.0765, validation loss: 0.7177
2024-05-22 19:13:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch2_loss0.7177242696285248.pypots
2024-05-22 19:13:03 [INFO]: Epoch 003 - training loss: 0.9934, validation loss: 0.6982
2024-05-22 19:13:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch3_loss0.6982216507196426.pypots
2024-05-22 19:13:07 [INFO]: Epoch 004 - training loss: 0.9767, validation loss: 0.6867
2024-05-22 19:13:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch4_loss0.6867355346679688.pypots
2024-05-22 19:13:10 [INFO]: Epoch 005 - training loss: 0.9626, validation loss: 0.6780
2024-05-22 19:13:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch5_loss0.6779990196228027.pypots
2024-05-22 19:13:13 [INFO]: Epoch 006 - training loss: 0.9352, validation loss: 0.6716
2024-05-22 19:13:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch6_loss0.67160504758358.pypots
2024-05-22 19:13:16 [INFO]: Epoch 007 - training loss: 0.9213, validation loss: 0.6664
2024-05-22 19:13:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch7_loss0.666398337483406.pypots
2024-05-22 19:13:19 [INFO]: Epoch 008 - training loss: 0.9285, validation loss: 0.6629
2024-05-22 19:13:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch8_loss0.6628870993852616.pypots
2024-05-22 19:13:22 [INFO]: Epoch 009 - training loss: 0.9166, validation loss: 0.6592
2024-05-22 19:13:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch9_loss0.6592011719942092.pypots
2024-05-22 19:13:25 [INFO]: Epoch 010 - training loss: 0.9179, validation loss: 0.6574
2024-05-22 19:13:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch10_loss0.6573502540588378.pypots
2024-05-22 19:13:28 [INFO]: Epoch 011 - training loss: 0.9112, validation loss: 0.6565
2024-05-22 19:13:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch11_loss0.6565331071615219.pypots
2024-05-22 19:13:31 [INFO]: Epoch 012 - training loss: 0.9285, validation loss: 0.6537
2024-05-22 19:13:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch12_loss0.653657066822052.pypots
2024-05-22 19:13:35 [INFO]: Epoch 013 - training loss: 0.9079, validation loss: 0.6539
2024-05-22 19:13:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch13_loss0.6538599610328675.pypots
2024-05-22 19:13:38 [INFO]: Epoch 014 - training loss: 0.8979, validation loss: 0.6517
2024-05-22 19:13:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch14_loss0.6517379522323609.pypots
2024-05-22 19:13:41 [INFO]: Epoch 015 - training loss: 0.9027, validation loss: 0.6517
2024-05-22 19:13:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch15_loss0.651681536436081.pypots
2024-05-22 19:13:44 [INFO]: Epoch 016 - training loss: 0.8881, validation loss: 0.6506
2024-05-22 19:13:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch16_loss0.6505831599235534.pypots
2024-05-22 19:13:47 [INFO]: Epoch 017 - training loss: 0.8991, validation loss: 0.6520
2024-05-22 19:13:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch17_loss0.6520456433296203.pypots
2024-05-22 19:13:50 [INFO]: Epoch 018 - training loss: 0.8904, validation loss: 0.6502
2024-05-22 19:13:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch18_loss0.6501875758171082.pypots
2024-05-22 19:13:53 [INFO]: Epoch 019 - training loss: 0.8950, validation loss: 0.6523
2024-05-22 19:13:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch19_loss0.6523305028676987.pypots
2024-05-22 19:13:56 [INFO]: Epoch 020 - training loss: 0.8856, validation loss: 0.6498
2024-05-22 19:13:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch20_loss0.649769526720047.pypots
2024-05-22 19:13:59 [INFO]: Epoch 021 - training loss: 0.8755, validation loss: 0.6526
2024-05-22 19:13:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch21_loss0.6526153087615967.pypots
2024-05-22 19:14:03 [INFO]: Epoch 022 - training loss: 0.8872, validation loss: 0.6521
2024-05-22 19:14:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch22_loss0.6520605117082596.pypots
2024-05-22 19:14:06 [INFO]: Epoch 023 - training loss: 0.8830, validation loss: 0.6502
2024-05-22 19:14:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch23_loss0.6501778036355972.pypots
2024-05-22 19:14:09 [INFO]: Epoch 024 - training loss: 0.8635, validation loss: 0.6537
2024-05-22 19:14:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch24_loss0.6537085801362992.pypots
2024-05-22 19:14:12 [INFO]: Epoch 025 - training loss: 0.8673, validation loss: 0.6515
2024-05-22 19:14:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch25_loss0.6514920711517334.pypots
2024-05-22 19:14:15 [INFO]: Epoch 026 - training loss: 0.8793, validation loss: 0.6533
2024-05-22 19:14:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch26_loss0.6532692939043045.pypots
2024-05-22 19:14:18 [INFO]: Epoch 027 - training loss: 0.9094, validation loss: 0.6542
2024-05-22 19:14:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch27_loss0.6542365223169326.pypots
2024-05-22 19:14:21 [INFO]: Epoch 028 - training loss: 0.8726, validation loss: 0.6532
2024-05-22 19:14:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch28_loss0.6531890332698822.pypots
2024-05-22 19:14:24 [INFO]: Epoch 029 - training loss: 0.8680, validation loss: 0.6544
2024-05-22 19:14:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch29_loss0.6544072657823563.pypots
2024-05-22 19:14:27 [INFO]: Epoch 030 - training loss: 0.8845, validation loss: 0.6547
2024-05-22 19:14:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN_epoch30_loss0.6546654015779495.pypots
2024-05-22 19:14:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 19:14:27 [INFO]: Finished training. The best model is from epoch#20.
2024-05-22 19:14:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/20240522_T191254/MRNN.pypots
2024-05-22 19:14:28 [INFO]: MRNN on Air-Quality: MAE=0.5219, MSE=0.6170
2024-05-22 19:14:28 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/MRNN_air_quality/imputation.pkl
2024-05-22 19:14:28 [INFO]: Using the given device: cpu
2024-05-22 19:14:28 [INFO]: LOCF on Air-Quality: MAE=0.2062, MSE=0.2674
2024-05-22 19:14:28 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_air_quality".
2024-05-22 19:14:28 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/LOCF_air_quality/imputation.pkl
2024-05-22 19:14:28 [INFO]: Median on Air-Quality: MAE=0.6602, MSE=1.0006
2024-05-22 19:14:28 [INFO]: Successfully created the given path "saved_results/round_2/Median_air_quality".
2024-05-22 19:14:28 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/Median_air_quality/imputation.pkl
2024-05-22 19:14:28 [INFO]: Mean on Air-Quality: MAE=0.6921, MSE=0.9434
2024-05-22 19:14:28 [INFO]: Successfully created the given path "saved_results/round_2/Mean_air_quality".
2024-05-22 19:14:28 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/Mean_air_quality/imputation.pkl
2024-05-22 19:14:28 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-22 19:14:28 [INFO]: Using the given device: cuda:0
2024-05-22 19:14:28 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/SAITS_air_quality/20240522_T191428
2024-05-22 19:14:28 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/SAITS_air_quality/20240522_T191428/tensorboard
2024-05-22 19:14:28 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-22 19:14:29 [INFO]: Epoch 001 - training loss: 1.0581, validation loss: 0.5012
2024-05-22 19:14:29 [INFO]: Epoch 002 - training loss: 0.7659, validation loss: 0.3767
2024-05-22 19:14:30 [INFO]: Epoch 003 - training loss: 0.6562, validation loss: 0.2966
2024-05-22 19:14:31 [INFO]: Epoch 004 - training loss: 0.5811, validation loss: 0.2599
2024-05-22 19:14:31 [INFO]: Epoch 005 - training loss: 0.5251, validation loss: 0.2343
2024-05-22 19:14:32 [INFO]: Epoch 006 - training loss: 0.4868, validation loss: 0.2222
2024-05-22 19:14:33 [INFO]: Epoch 007 - training loss: 0.4607, validation loss: 0.2115
2024-05-22 19:14:33 [INFO]: Epoch 008 - training loss: 0.4427, validation loss: 0.2047
2024-05-22 19:14:34 [INFO]: Epoch 009 - training loss: 0.4277, validation loss: 0.1994
2024-05-22 19:14:35 [INFO]: Epoch 010 - training loss: 0.4170, validation loss: 0.1939
2024-05-22 19:14:35 [INFO]: Epoch 011 - training loss: 0.4061, validation loss: 0.1898
2024-05-22 19:14:36 [INFO]: Epoch 012 - training loss: 0.3971, validation loss: 0.1853
2024-05-22 19:14:36 [INFO]: Epoch 013 - training loss: 0.3889, validation loss: 0.1834
2024-05-22 19:14:37 [INFO]: Epoch 014 - training loss: 0.3838, validation loss: 0.1808
2024-05-22 19:14:38 [INFO]: Epoch 015 - training loss: 0.3769, validation loss: 0.1810
2024-05-22 19:14:38 [INFO]: Epoch 016 - training loss: 0.3716, validation loss: 0.1768
2024-05-22 19:14:39 [INFO]: Epoch 017 - training loss: 0.3656, validation loss: 0.1740
2024-05-22 19:14:40 [INFO]: Epoch 018 - training loss: 0.3609, validation loss: 0.1719
2024-05-22 19:14:40 [INFO]: Epoch 019 - training loss: 0.3575, validation loss: 0.1696
2024-05-22 19:14:41 [INFO]: Epoch 020 - training loss: 0.3528, validation loss: 0.1680
2024-05-22 19:14:41 [INFO]: Epoch 021 - training loss: 0.3472, validation loss: 0.1665
2024-05-22 19:14:42 [INFO]: Epoch 022 - training loss: 0.3454, validation loss: 0.1642
2024-05-22 19:14:43 [INFO]: Epoch 023 - training loss: 0.3425, validation loss: 0.1652
2024-05-22 19:14:43 [INFO]: Epoch 024 - training loss: 0.3398, validation loss: 0.1628
2024-05-22 19:14:44 [INFO]: Epoch 025 - training loss: 0.3374, validation loss: 0.1602
2024-05-22 19:14:45 [INFO]: Epoch 026 - training loss: 0.3325, validation loss: 0.1589
2024-05-22 19:14:45 [INFO]: Epoch 027 - training loss: 0.3303, validation loss: 0.1582
2024-05-22 19:14:46 [INFO]: Epoch 028 - training loss: 0.3282, validation loss: 0.1565
2024-05-22 19:14:47 [INFO]: Epoch 029 - training loss: 0.3273, validation loss: 0.1545
2024-05-22 19:14:47 [INFO]: Epoch 030 - training loss: 0.3242, validation loss: 0.1526
2024-05-22 19:14:48 [INFO]: Epoch 031 - training loss: 0.3217, validation loss: 0.1513
2024-05-22 19:14:48 [INFO]: Epoch 032 - training loss: 0.3220, validation loss: 0.1515
2024-05-22 19:14:49 [INFO]: Epoch 033 - training loss: 0.3188, validation loss: 0.1497
2024-05-22 19:14:50 [INFO]: Epoch 034 - training loss: 0.3163, validation loss: 0.1484
2024-05-22 19:14:50 [INFO]: Epoch 035 - training loss: 0.3140, validation loss: 0.1470
2024-05-22 19:14:51 [INFO]: Epoch 036 - training loss: 0.3135, validation loss: 0.1456
2024-05-22 19:14:52 [INFO]: Epoch 037 - training loss: 0.3119, validation loss: 0.1435
2024-05-22 19:14:52 [INFO]: Epoch 038 - training loss: 0.3086, validation loss: 0.1429
2024-05-22 19:14:53 [INFO]: Epoch 039 - training loss: 0.3079, validation loss: 0.1415
2024-05-22 19:14:53 [INFO]: Epoch 040 - training loss: 0.3065, validation loss: 0.1401
2024-05-22 19:14:54 [INFO]: Epoch 041 - training loss: 0.3043, validation loss: 0.1396
2024-05-22 19:14:55 [INFO]: Epoch 042 - training loss: 0.3024, validation loss: 0.1379
2024-05-22 19:14:55 [INFO]: Epoch 043 - training loss: 0.3010, validation loss: 0.1371
2024-05-22 19:14:56 [INFO]: Epoch 044 - training loss: 0.2994, validation loss: 0.1357
2024-05-22 19:14:57 [INFO]: Epoch 045 - training loss: 0.2974, validation loss: 0.1347
2024-05-22 19:14:57 [INFO]: Epoch 046 - training loss: 0.2968, validation loss: 0.1343
2024-05-22 19:14:58 [INFO]: Epoch 047 - training loss: 0.2950, validation loss: 0.1327
2024-05-22 19:14:59 [INFO]: Epoch 048 - training loss: 0.2935, validation loss: 0.1318
2024-05-22 19:14:59 [INFO]: Epoch 049 - training loss: 0.2922, validation loss: 0.1309
2024-05-22 19:15:00 [INFO]: Epoch 050 - training loss: 0.2918, validation loss: 0.1299
2024-05-22 19:15:00 [INFO]: Epoch 051 - training loss: 0.2897, validation loss: 0.1305
2024-05-22 19:15:01 [INFO]: Epoch 052 - training loss: 0.2875, validation loss: 0.1284
2024-05-22 19:15:02 [INFO]: Epoch 053 - training loss: 0.2868, validation loss: 0.1283
2024-05-22 19:15:02 [INFO]: Epoch 054 - training loss: 0.2863, validation loss: 0.1277
2024-05-22 19:15:03 [INFO]: Epoch 055 - training loss: 0.2856, validation loss: 0.1272
2024-05-22 19:15:04 [INFO]: Epoch 056 - training loss: 0.2839, validation loss: 0.1253
2024-05-22 19:15:04 [INFO]: Epoch 057 - training loss: 0.2812, validation loss: 0.1250
2024-05-22 19:15:05 [INFO]: Epoch 058 - training loss: 0.2804, validation loss: 0.1256
2024-05-22 19:15:05 [INFO]: Epoch 059 - training loss: 0.2798, validation loss: 0.1248
2024-05-22 19:15:06 [INFO]: Epoch 060 - training loss: 0.2790, validation loss: 0.1245
2024-05-22 19:15:07 [INFO]: Epoch 061 - training loss: 0.2780, validation loss: 0.1239
2024-05-22 19:15:07 [INFO]: Epoch 062 - training loss: 0.2770, validation loss: 0.1231
2024-05-22 19:15:08 [INFO]: Epoch 063 - training loss: 0.2771, validation loss: 0.1233
2024-05-22 19:15:09 [INFO]: Epoch 064 - training loss: 0.2749, validation loss: 0.1235
2024-05-22 19:15:09 [INFO]: Epoch 065 - training loss: 0.2744, validation loss: 0.1221
2024-05-22 19:15:10 [INFO]: Epoch 066 - training loss: 0.2720, validation loss: 0.1217
2024-05-22 19:15:11 [INFO]: Epoch 067 - training loss: 0.2701, validation loss: 0.1218
2024-05-22 19:15:11 [INFO]: Epoch 068 - training loss: 0.2696, validation loss: 0.1212
2024-05-22 19:15:12 [INFO]: Epoch 069 - training loss: 0.2690, validation loss: 0.1202
2024-05-22 19:15:12 [INFO]: Epoch 070 - training loss: 0.2689, validation loss: 0.1204
2024-05-22 19:15:13 [INFO]: Epoch 071 - training loss: 0.2666, validation loss: 0.1206
2024-05-22 19:15:14 [INFO]: Epoch 072 - training loss: 0.2650, validation loss: 0.1202
2024-05-22 19:15:14 [INFO]: Epoch 073 - training loss: 0.2648, validation loss: 0.1194
2024-05-22 19:15:15 [INFO]: Epoch 074 - training loss: 0.2643, validation loss: 0.1193
2024-05-22 19:15:16 [INFO]: Epoch 075 - training loss: 0.2642, validation loss: 0.1190
2024-05-22 19:15:16 [INFO]: Epoch 076 - training loss: 0.2633, validation loss: 0.1188
2024-05-22 19:15:17 [INFO]: Epoch 077 - training loss: 0.2619, validation loss: 0.1182
2024-05-22 19:15:18 [INFO]: Epoch 078 - training loss: 0.2620, validation loss: 0.1181
2024-05-22 19:15:18 [INFO]: Epoch 079 - training loss: 0.2620, validation loss: 0.1185
2024-05-22 19:15:19 [INFO]: Epoch 080 - training loss: 0.2602, validation loss: 0.1173
2024-05-22 19:15:20 [INFO]: Epoch 081 - training loss: 0.2586, validation loss: 0.1182
2024-05-22 19:15:20 [INFO]: Epoch 082 - training loss: 0.2578, validation loss: 0.1163
2024-05-22 19:15:21 [INFO]: Epoch 083 - training loss: 0.2576, validation loss: 0.1163
2024-05-22 19:15:21 [INFO]: Epoch 084 - training loss: 0.2555, validation loss: 0.1169
2024-05-22 19:15:22 [INFO]: Epoch 085 - training loss: 0.2557, validation loss: 0.1157
2024-05-22 19:15:23 [INFO]: Epoch 086 - training loss: 0.2545, validation loss: 0.1159
2024-05-22 19:15:23 [INFO]: Epoch 087 - training loss: 0.2538, validation loss: 0.1158
2024-05-22 19:15:24 [INFO]: Epoch 088 - training loss: 0.2543, validation loss: 0.1162
2024-05-22 19:15:25 [INFO]: Epoch 089 - training loss: 0.2534, validation loss: 0.1155
2024-05-22 19:15:25 [INFO]: Epoch 090 - training loss: 0.2516, validation loss: 0.1152
2024-05-22 19:15:26 [INFO]: Epoch 091 - training loss: 0.2515, validation loss: 0.1149
2024-05-22 19:15:26 [INFO]: Epoch 092 - training loss: 0.2499, validation loss: 0.1139
2024-05-22 19:15:27 [INFO]: Epoch 093 - training loss: 0.2497, validation loss: 0.1138
2024-05-22 19:15:28 [INFO]: Epoch 094 - training loss: 0.2489, validation loss: 0.1139
2024-05-22 19:15:28 [INFO]: Epoch 095 - training loss: 0.2485, validation loss: 0.1130
2024-05-22 19:15:29 [INFO]: Epoch 096 - training loss: 0.2481, validation loss: 0.1143
2024-05-22 19:15:30 [INFO]: Epoch 097 - training loss: 0.2490, validation loss: 0.1140
2024-05-22 19:15:30 [INFO]: Epoch 098 - training loss: 0.2501, validation loss: 0.1132
2024-05-22 19:15:31 [INFO]: Epoch 099 - training loss: 0.2466, validation loss: 0.1126
2024-05-22 19:15:31 [INFO]: Epoch 100 - training loss: 0.2449, validation loss: 0.1127
2024-05-22 19:15:32 [INFO]: Epoch 101 - training loss: 0.2453, validation loss: 0.1128
2024-05-22 19:15:33 [INFO]: Epoch 102 - training loss: 0.2440, validation loss: 0.1122
2024-05-22 19:15:33 [INFO]: Epoch 103 - training loss: 0.2440, validation loss: 0.1114
2024-05-22 19:15:34 [INFO]: Epoch 104 - training loss: 0.2432, validation loss: 0.1112
2024-05-22 19:15:35 [INFO]: Epoch 105 - training loss: 0.2427, validation loss: 0.1114
2024-05-22 19:15:35 [INFO]: Epoch 106 - training loss: 0.2429, validation loss: 0.1108
2024-05-22 19:15:36 [INFO]: Epoch 107 - training loss: 0.2427, validation loss: 0.1110
2024-05-22 19:15:37 [INFO]: Epoch 108 - training loss: 0.2454, validation loss: 0.1111
2024-05-22 19:15:37 [INFO]: Epoch 109 - training loss: 0.2413, validation loss: 0.1107
2024-05-22 19:15:38 [INFO]: Epoch 110 - training loss: 0.2432, validation loss: 0.1108
2024-05-22 19:15:38 [INFO]: Epoch 111 - training loss: 0.2406, validation loss: 0.1107
2024-05-22 19:15:39 [INFO]: Epoch 112 - training loss: 0.2385, validation loss: 0.1102
2024-05-22 19:15:40 [INFO]: Epoch 113 - training loss: 0.2410, validation loss: 0.1094
2024-05-22 19:15:40 [INFO]: Epoch 114 - training loss: 0.2385, validation loss: 0.1091
2024-05-22 19:15:41 [INFO]: Epoch 115 - training loss: 0.2385, validation loss: 0.1099
2024-05-22 19:15:42 [INFO]: Epoch 116 - training loss: 0.2384, validation loss: 0.1087
2024-05-22 19:15:42 [INFO]: Epoch 117 - training loss: 0.2394, validation loss: 0.1087
2024-05-22 19:15:43 [INFO]: Epoch 118 - training loss: 0.2375, validation loss: 0.1083
2024-05-22 19:15:43 [INFO]: Epoch 119 - training loss: 0.2364, validation loss: 0.1085
2024-05-22 19:15:44 [INFO]: Epoch 120 - training loss: 0.2355, validation loss: 0.1087
2024-05-22 19:15:45 [INFO]: Epoch 121 - training loss: 0.2354, validation loss: 0.1089
2024-05-22 19:15:45 [INFO]: Epoch 122 - training loss: 0.2339, validation loss: 0.1080
2024-05-22 19:15:46 [INFO]: Epoch 123 - training loss: 0.2344, validation loss: 0.1076
2024-05-22 19:15:47 [INFO]: Epoch 124 - training loss: 0.2337, validation loss: 0.1083
2024-05-22 19:15:47 [INFO]: Epoch 125 - training loss: 0.2339, validation loss: 0.1085
2024-05-22 19:15:48 [INFO]: Epoch 126 - training loss: 0.2328, validation loss: 0.1084
2024-05-22 19:15:49 [INFO]: Epoch 127 - training loss: 0.2342, validation loss: 0.1082
2024-05-22 19:15:49 [INFO]: Epoch 128 - training loss: 0.2344, validation loss: 0.1075
2024-05-22 19:15:50 [INFO]: Epoch 129 - training loss: 0.2321, validation loss: 0.1073
2024-05-22 19:15:50 [INFO]: Epoch 130 - training loss: 0.2305, validation loss: 0.1067
2024-05-22 19:15:51 [INFO]: Epoch 131 - training loss: 0.2304, validation loss: 0.1060
2024-05-22 19:15:52 [INFO]: Epoch 132 - training loss: 0.2297, validation loss: 0.1063
2024-05-22 19:15:52 [INFO]: Epoch 133 - training loss: 0.2294, validation loss: 0.1056
2024-05-22 19:15:53 [INFO]: Epoch 134 - training loss: 0.2301, validation loss: 0.1059
2024-05-22 19:15:54 [INFO]: Epoch 135 - training loss: 0.2291, validation loss: 0.1057
2024-05-22 19:15:54 [INFO]: Epoch 136 - training loss: 0.2288, validation loss: 0.1065
2024-05-22 19:15:55 [INFO]: Epoch 137 - training loss: 0.2281, validation loss: 0.1064
2024-05-22 19:15:55 [INFO]: Epoch 138 - training loss: 0.2285, validation loss: 0.1057
2024-05-22 19:15:56 [INFO]: Epoch 139 - training loss: 0.2283, validation loss: 0.1063
2024-05-22 19:15:57 [INFO]: Epoch 140 - training loss: 0.2280, validation loss: 0.1076
2024-05-22 19:15:57 [INFO]: Epoch 141 - training loss: 0.2296, validation loss: 0.1059
2024-05-22 19:15:58 [INFO]: Epoch 142 - training loss: 0.2296, validation loss: 0.1059
2024-05-22 19:15:59 [INFO]: Epoch 143 - training loss: 0.2274, validation loss: 0.1049
2024-05-22 19:15:59 [INFO]: Epoch 144 - training loss: 0.2268, validation loss: 0.1052
2024-05-22 19:16:00 [INFO]: Epoch 145 - training loss: 0.2266, validation loss: 0.1059
2024-05-22 19:16:01 [INFO]: Epoch 146 - training loss: 0.2255, validation loss: 0.1053
2024-05-22 19:16:01 [INFO]: Epoch 147 - training loss: 0.2253, validation loss: 0.1055
2024-05-22 19:16:02 [INFO]: Epoch 148 - training loss: 0.2258, validation loss: 0.1042
2024-05-22 19:16:02 [INFO]: Epoch 149 - training loss: 0.2244, validation loss: 0.1049
2024-05-22 19:16:03 [INFO]: Epoch 150 - training loss: 0.2246, validation loss: 0.1036
2024-05-22 19:16:04 [INFO]: Epoch 151 - training loss: 0.2242, validation loss: 0.1042
2024-05-22 19:16:04 [INFO]: Epoch 152 - training loss: 0.2239, validation loss: 0.1051
2024-05-22 19:16:05 [INFO]: Epoch 153 - training loss: 0.2240, validation loss: 0.1045
2024-05-22 19:16:06 [INFO]: Epoch 154 - training loss: 0.2226, validation loss: 0.1037
2024-05-22 19:16:06 [INFO]: Epoch 155 - training loss: 0.2228, validation loss: 0.1038
2024-05-22 19:16:07 [INFO]: Epoch 156 - training loss: 0.2237, validation loss: 0.1041
2024-05-22 19:16:07 [INFO]: Epoch 157 - training loss: 0.2236, validation loss: 0.1033
2024-05-22 19:16:08 [INFO]: Epoch 158 - training loss: 0.2211, validation loss: 0.1036
2024-05-22 19:16:09 [INFO]: Epoch 159 - training loss: 0.2203, validation loss: 0.1032
2024-05-22 19:16:09 [INFO]: Epoch 160 - training loss: 0.2204, validation loss: 0.1035
2024-05-22 19:16:10 [INFO]: Epoch 161 - training loss: 0.2194, validation loss: 0.1027
2024-05-22 19:16:11 [INFO]: Epoch 162 - training loss: 0.2199, validation loss: 0.1025
2024-05-22 19:16:11 [INFO]: Epoch 163 - training loss: 0.2192, validation loss: 0.1021
2024-05-22 19:16:12 [INFO]: Epoch 164 - training loss: 0.2189, validation loss: 0.1023
2024-05-22 19:16:13 [INFO]: Epoch 165 - training loss: 0.2194, validation loss: 0.1024
2024-05-22 19:16:13 [INFO]: Epoch 166 - training loss: 0.2193, validation loss: 0.1025
2024-05-22 19:16:14 [INFO]: Epoch 167 - training loss: 0.2186, validation loss: 0.1028
2024-05-22 19:16:14 [INFO]: Epoch 168 - training loss: 0.2190, validation loss: 0.1030
2024-05-22 19:16:15 [INFO]: Epoch 169 - training loss: 0.2204, validation loss: 0.1027
2024-05-22 19:16:16 [INFO]: Epoch 170 - training loss: 0.2205, validation loss: 0.1036
2024-05-22 19:16:16 [INFO]: Epoch 171 - training loss: 0.2197, validation loss: 0.1014
2024-05-22 19:16:17 [INFO]: Epoch 172 - training loss: 0.2172, validation loss: 0.1025
2024-05-22 19:16:18 [INFO]: Epoch 173 - training loss: 0.2169, validation loss: 0.1012
2024-05-22 19:16:18 [INFO]: Epoch 174 - training loss: 0.2161, validation loss: 0.1014
2024-05-22 19:16:19 [INFO]: Epoch 175 - training loss: 0.2162, validation loss: 0.1012
2024-05-22 19:16:19 [INFO]: Epoch 176 - training loss: 0.2154, validation loss: 0.1012
2024-05-22 19:16:20 [INFO]: Epoch 177 - training loss: 0.2155, validation loss: 0.1022
2024-05-22 19:16:21 [INFO]: Epoch 178 - training loss: 0.2148, validation loss: 0.1014
2024-05-22 19:16:21 [INFO]: Epoch 179 - training loss: 0.2141, validation loss: 0.1007
2024-05-22 19:16:22 [INFO]: Epoch 180 - training loss: 0.2141, validation loss: 0.1005
2024-05-22 19:16:23 [INFO]: Epoch 181 - training loss: 0.2137, validation loss: 0.1003
2024-05-22 19:16:23 [INFO]: Epoch 182 - training loss: 0.2150, validation loss: 0.1010
2024-05-22 19:16:24 [INFO]: Epoch 183 - training loss: 0.2145, validation loss: 0.1002
2024-05-22 19:16:24 [INFO]: Epoch 184 - training loss: 0.2136, validation loss: 0.1007
2024-05-22 19:16:25 [INFO]: Epoch 185 - training loss: 0.2134, validation loss: 0.1000
2024-05-22 19:16:26 [INFO]: Epoch 186 - training loss: 0.2131, validation loss: 0.1006
2024-05-22 19:16:26 [INFO]: Epoch 187 - training loss: 0.2153, validation loss: 0.1007
2024-05-22 19:16:27 [INFO]: Epoch 188 - training loss: 0.2149, validation loss: 0.1013
2024-05-22 19:16:28 [INFO]: Epoch 189 - training loss: 0.2138, validation loss: 0.1001
2024-05-22 19:16:28 [INFO]: Epoch 190 - training loss: 0.2126, validation loss: 0.0997
2024-05-22 19:16:29 [INFO]: Epoch 191 - training loss: 0.2125, validation loss: 0.0998
2024-05-22 19:16:30 [INFO]: Epoch 192 - training loss: 0.2112, validation loss: 0.1008
2024-05-22 19:16:30 [INFO]: Epoch 193 - training loss: 0.2116, validation loss: 0.1006
2024-05-22 19:16:31 [INFO]: Epoch 194 - training loss: 0.2114, validation loss: 0.0997
2024-05-22 19:16:31 [INFO]: Epoch 195 - training loss: 0.2115, validation loss: 0.0998
2024-05-22 19:16:32 [INFO]: Epoch 196 - training loss: 0.2108, validation loss: 0.0992
2024-05-22 19:16:33 [INFO]: Epoch 197 - training loss: 0.2099, validation loss: 0.0997
2024-05-22 19:16:33 [INFO]: Epoch 198 - training loss: 0.2101, validation loss: 0.0995
2024-05-22 19:16:34 [INFO]: Epoch 199 - training loss: 0.2095, validation loss: 0.1001
2024-05-22 19:16:35 [INFO]: Epoch 200 - training loss: 0.2104, validation loss: 0.0992
2024-05-22 19:16:35 [INFO]: Epoch 201 - training loss: 0.2097, validation loss: 0.0980
2024-05-22 19:16:36 [INFO]: Epoch 202 - training loss: 0.2080, validation loss: 0.0988
2024-05-22 19:16:36 [INFO]: Epoch 203 - training loss: 0.2096, validation loss: 0.0988
2024-05-22 19:16:37 [INFO]: Epoch 204 - training loss: 0.2121, validation loss: 0.0993
2024-05-22 19:16:38 [INFO]: Epoch 205 - training loss: 0.2114, validation loss: 0.0988
2024-05-22 19:16:38 [INFO]: Epoch 206 - training loss: 0.2083, validation loss: 0.0991
2024-05-22 19:16:39 [INFO]: Epoch 207 - training loss: 0.2088, validation loss: 0.0988
2024-05-22 19:16:40 [INFO]: Epoch 208 - training loss: 0.2077, validation loss: 0.0993
2024-05-22 19:16:40 [INFO]: Epoch 209 - training loss: 0.2081, validation loss: 0.0995
2024-05-22 19:16:41 [INFO]: Epoch 210 - training loss: 0.2071, validation loss: 0.0981
2024-05-22 19:16:42 [INFO]: Epoch 211 - training loss: 0.2069, validation loss: 0.0980
2024-05-22 19:16:42 [INFO]: Epoch 212 - training loss: 0.2064, validation loss: 0.0986
2024-05-22 19:16:43 [INFO]: Epoch 213 - training loss: 0.2071, validation loss: 0.0989
2024-05-22 19:16:43 [INFO]: Epoch 214 - training loss: 0.2082, validation loss: 0.0983
2024-05-22 19:16:44 [INFO]: Epoch 215 - training loss: 0.2072, validation loss: 0.0972
2024-05-22 19:16:45 [INFO]: Epoch 216 - training loss: 0.2071, validation loss: 0.0976
2024-05-22 19:16:45 [INFO]: Epoch 217 - training loss: 0.2064, validation loss: 0.0969
2024-05-22 19:16:46 [INFO]: Epoch 218 - training loss: 0.2060, validation loss: 0.0969
2024-05-22 19:16:47 [INFO]: Epoch 219 - training loss: 0.2054, validation loss: 0.0979
2024-05-22 19:16:47 [INFO]: Epoch 220 - training loss: 0.2048, validation loss: 0.0966
2024-05-22 19:16:48 [INFO]: Epoch 221 - training loss: 0.2053, validation loss: 0.0965
2024-05-22 19:16:49 [INFO]: Epoch 222 - training loss: 0.2044, validation loss: 0.0980
2024-05-22 19:16:49 [INFO]: Epoch 223 - training loss: 0.2040, validation loss: 0.0976
2024-05-22 19:16:50 [INFO]: Epoch 224 - training loss: 0.2040, validation loss: 0.0975
2024-05-22 19:16:50 [INFO]: Epoch 225 - training loss: 0.2053, validation loss: 0.0970
2024-05-22 19:16:51 [INFO]: Epoch 226 - training loss: 0.2053, validation loss: 0.0969
2024-05-22 19:16:52 [INFO]: Epoch 227 - training loss: 0.2054, validation loss: 0.0962
2024-05-22 19:16:52 [INFO]: Epoch 228 - training loss: 0.2035, validation loss: 0.0956
2024-05-22 19:16:53 [INFO]: Epoch 229 - training loss: 0.2046, validation loss: 0.0961
2024-05-22 19:16:54 [INFO]: Epoch 230 - training loss: 0.2041, validation loss: 0.0965
2024-05-22 19:16:54 [INFO]: Epoch 231 - training loss: 0.2023, validation loss: 0.0967
2024-05-22 19:16:55 [INFO]: Epoch 232 - training loss: 0.2027, validation loss: 0.0961
2024-05-22 19:16:55 [INFO]: Epoch 233 - training loss: 0.2021, validation loss: 0.0967
2024-05-22 19:16:56 [INFO]: Epoch 234 - training loss: 0.2030, validation loss: 0.0969
2024-05-22 19:16:57 [INFO]: Epoch 235 - training loss: 0.2031, validation loss: 0.0958
2024-05-22 19:16:57 [INFO]: Epoch 236 - training loss: 0.2017, validation loss: 0.0960
2024-05-22 19:16:58 [INFO]: Epoch 237 - training loss: 0.2028, validation loss: 0.0962
2024-05-22 19:16:59 [INFO]: Epoch 238 - training loss: 0.2018, validation loss: 0.0962
2024-05-22 19:16:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 19:16:59 [INFO]: Finished training. The best model is from epoch#228.
2024-05-22 19:16:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/SAITS_air_quality/20240522_T191428/SAITS.pypots
2024-05-22 19:16:59 [INFO]: SAITS on Air-Quality: MAE=0.1435, MSE=0.1051
2024-05-22 19:16:59 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/SAITS_air_quality/imputation.pkl
2024-05-22 19:16:59 [INFO]: Using the given device: cuda:0
2024-05-22 19:16:59 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/Transformer_air_quality/20240522_T191659
2024-05-22 19:16:59 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/Transformer_air_quality/20240522_T191659/tensorboard
2024-05-22 19:16:59 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-22 19:16:59 [INFO]: Epoch 001 - training loss: 0.8955, validation loss: 0.4373
2024-05-22 19:16:59 [INFO]: Epoch 002 - training loss: 0.5672, validation loss: 0.3196
2024-05-22 19:17:00 [INFO]: Epoch 003 - training loss: 0.4824, validation loss: 0.2680
2024-05-22 19:17:00 [INFO]: Epoch 004 - training loss: 0.4352, validation loss: 0.2381
2024-05-22 19:17:00 [INFO]: Epoch 005 - training loss: 0.4084, validation loss: 0.2265
2024-05-22 19:17:01 [INFO]: Epoch 006 - training loss: 0.3909, validation loss: 0.2190
2024-05-22 19:17:01 [INFO]: Epoch 007 - training loss: 0.3766, validation loss: 0.2107
2024-05-22 19:17:01 [INFO]: Epoch 008 - training loss: 0.3645, validation loss: 0.2028
2024-05-22 19:17:01 [INFO]: Epoch 009 - training loss: 0.3532, validation loss: 0.1994
2024-05-22 19:17:02 [INFO]: Epoch 010 - training loss: 0.3477, validation loss: 0.1946
2024-05-22 19:17:02 [INFO]: Epoch 011 - training loss: 0.3412, validation loss: 0.1919
2024-05-22 19:17:02 [INFO]: Epoch 012 - training loss: 0.3363, validation loss: 0.1881
2024-05-22 19:17:03 [INFO]: Epoch 013 - training loss: 0.3293, validation loss: 0.1834
2024-05-22 19:17:03 [INFO]: Epoch 014 - training loss: 0.3252, validation loss: 0.1825
2024-05-22 19:17:03 [INFO]: Epoch 015 - training loss: 0.3276, validation loss: 0.1789
2024-05-22 19:17:03 [INFO]: Epoch 016 - training loss: 0.3181, validation loss: 0.1753
2024-05-22 19:17:04 [INFO]: Epoch 017 - training loss: 0.3163, validation loss: 0.1741
2024-05-22 19:17:04 [INFO]: Epoch 018 - training loss: 0.3112, validation loss: 0.1711
2024-05-22 19:17:04 [INFO]: Epoch 019 - training loss: 0.3116, validation loss: 0.1687
2024-05-22 19:17:04 [INFO]: Epoch 020 - training loss: 0.3093, validation loss: 0.1657
2024-05-22 19:17:05 [INFO]: Epoch 021 - training loss: 0.3063, validation loss: 0.1640
2024-05-22 19:17:05 [INFO]: Epoch 022 - training loss: 0.3044, validation loss: 0.1626
2024-05-22 19:17:05 [INFO]: Epoch 023 - training loss: 0.2984, validation loss: 0.1603
2024-05-22 19:17:06 [INFO]: Epoch 024 - training loss: 0.2960, validation loss: 0.1590
2024-05-22 19:17:06 [INFO]: Epoch 025 - training loss: 0.2968, validation loss: 0.1580
2024-05-22 19:17:06 [INFO]: Epoch 026 - training loss: 0.2954, validation loss: 0.1559
2024-05-22 19:17:06 [INFO]: Epoch 027 - training loss: 0.2898, validation loss: 0.1549
2024-05-22 19:17:07 [INFO]: Epoch 028 - training loss: 0.2905, validation loss: 0.1560
2024-05-22 19:17:07 [INFO]: Epoch 029 - training loss: 0.2894, validation loss: 0.1540
2024-05-22 19:17:07 [INFO]: Epoch 030 - training loss: 0.2871, validation loss: 0.1537
2024-05-22 19:17:08 [INFO]: Epoch 031 - training loss: 0.2837, validation loss: 0.1514
2024-05-22 19:17:08 [INFO]: Epoch 032 - training loss: 0.2807, validation loss: 0.1530
2024-05-22 19:17:08 [INFO]: Epoch 033 - training loss: 0.2819, validation loss: 0.1511
2024-05-22 19:17:08 [INFO]: Epoch 034 - training loss: 0.2811, validation loss: 0.1504
2024-05-22 19:17:09 [INFO]: Epoch 035 - training loss: 0.2804, validation loss: 0.1497
2024-05-22 19:17:09 [INFO]: Epoch 036 - training loss: 0.2789, validation loss: 0.1510
2024-05-22 19:17:09 [INFO]: Epoch 037 - training loss: 0.2786, validation loss: 0.1498
2024-05-22 19:17:10 [INFO]: Epoch 038 - training loss: 0.2775, validation loss: 0.1495
2024-05-22 19:17:10 [INFO]: Epoch 039 - training loss: 0.2739, validation loss: 0.1481
2024-05-22 19:17:10 [INFO]: Epoch 040 - training loss: 0.2721, validation loss: 0.1493
2024-05-22 19:17:10 [INFO]: Epoch 041 - training loss: 0.2745, validation loss: 0.1492
2024-05-22 19:17:11 [INFO]: Epoch 042 - training loss: 0.2737, validation loss: 0.1461
2024-05-22 19:17:11 [INFO]: Epoch 043 - training loss: 0.2706, validation loss: 0.1475
2024-05-22 19:17:11 [INFO]: Epoch 044 - training loss: 0.2693, validation loss: 0.1480
2024-05-22 19:17:11 [INFO]: Epoch 045 - training loss: 0.2707, validation loss: 0.1457
2024-05-22 19:17:12 [INFO]: Epoch 046 - training loss: 0.2683, validation loss: 0.1455
2024-05-22 19:17:12 [INFO]: Epoch 047 - training loss: 0.2679, validation loss: 0.1444
2024-05-22 19:17:12 [INFO]: Epoch 048 - training loss: 0.2657, validation loss: 0.1448
2024-05-22 19:17:13 [INFO]: Epoch 049 - training loss: 0.2630, validation loss: 0.1445
2024-05-22 19:17:13 [INFO]: Epoch 050 - training loss: 0.2654, validation loss: 0.1449
2024-05-22 19:17:13 [INFO]: Epoch 051 - training loss: 0.2636, validation loss: 0.1440
2024-05-22 19:17:13 [INFO]: Epoch 052 - training loss: 0.2617, validation loss: 0.1435
2024-05-22 19:17:14 [INFO]: Epoch 053 - training loss: 0.2605, validation loss: 0.1441
2024-05-22 19:17:14 [INFO]: Epoch 054 - training loss: 0.2614, validation loss: 0.1429
2024-05-22 19:17:14 [INFO]: Epoch 055 - training loss: 0.2595, validation loss: 0.1436
2024-05-22 19:17:15 [INFO]: Epoch 056 - training loss: 0.2609, validation loss: 0.1452
2024-05-22 19:17:15 [INFO]: Epoch 057 - training loss: 0.2577, validation loss: 0.1426
2024-05-22 19:17:15 [INFO]: Epoch 058 - training loss: 0.2598, validation loss: 0.1426
2024-05-22 19:17:15 [INFO]: Epoch 059 - training loss: 0.2560, validation loss: 0.1419
2024-05-22 19:17:16 [INFO]: Epoch 060 - training loss: 0.2562, validation loss: 0.1415
2024-05-22 19:17:16 [INFO]: Epoch 061 - training loss: 0.2558, validation loss: 0.1406
2024-05-22 19:17:16 [INFO]: Epoch 062 - training loss: 0.2539, validation loss: 0.1424
2024-05-22 19:17:17 [INFO]: Epoch 063 - training loss: 0.2537, validation loss: 0.1398
2024-05-22 19:17:17 [INFO]: Epoch 064 - training loss: 0.2539, validation loss: 0.1412
2024-05-22 19:17:17 [INFO]: Epoch 065 - training loss: 0.2528, validation loss: 0.1419
2024-05-22 19:17:17 [INFO]: Epoch 066 - training loss: 0.2505, validation loss: 0.1395
2024-05-22 19:17:18 [INFO]: Epoch 067 - training loss: 0.2490, validation loss: 0.1382
2024-05-22 19:17:18 [INFO]: Epoch 068 - training loss: 0.2485, validation loss: 0.1384
2024-05-22 19:17:18 [INFO]: Epoch 069 - training loss: 0.2464, validation loss: 0.1399
2024-05-22 19:17:18 [INFO]: Epoch 070 - training loss: 0.2464, validation loss: 0.1395
2024-05-22 19:17:19 [INFO]: Epoch 071 - training loss: 0.2481, validation loss: 0.1392
2024-05-22 19:17:19 [INFO]: Epoch 072 - training loss: 0.2482, validation loss: 0.1379
2024-05-22 19:17:19 [INFO]: Epoch 073 - training loss: 0.2485, validation loss: 0.1370
2024-05-22 19:17:20 [INFO]: Epoch 074 - training loss: 0.2470, validation loss: 0.1377
2024-05-22 19:17:20 [INFO]: Epoch 075 - training loss: 0.2431, validation loss: 0.1372
2024-05-22 19:17:20 [INFO]: Epoch 076 - training loss: 0.2433, validation loss: 0.1382
2024-05-22 19:17:20 [INFO]: Epoch 077 - training loss: 0.2439, validation loss: 0.1367
2024-05-22 19:17:21 [INFO]: Epoch 078 - training loss: 0.2451, validation loss: 0.1374
2024-05-22 19:17:21 [INFO]: Epoch 079 - training loss: 0.2465, validation loss: 0.1355
2024-05-22 19:17:21 [INFO]: Epoch 080 - training loss: 0.2456, validation loss: 0.1369
2024-05-22 19:17:22 [INFO]: Epoch 081 - training loss: 0.2424, validation loss: 0.1363
2024-05-22 19:17:22 [INFO]: Epoch 082 - training loss: 0.2396, validation loss: 0.1342
2024-05-22 19:17:22 [INFO]: Epoch 083 - training loss: 0.2412, validation loss: 0.1350
2024-05-22 19:17:22 [INFO]: Epoch 084 - training loss: 0.2390, validation loss: 0.1350
2024-05-22 19:17:23 [INFO]: Epoch 085 - training loss: 0.2382, validation loss: 0.1371
2024-05-22 19:17:23 [INFO]: Epoch 086 - training loss: 0.2389, validation loss: 0.1346
2024-05-22 19:17:23 [INFO]: Epoch 087 - training loss: 0.2399, validation loss: 0.1338
2024-05-22 19:17:24 [INFO]: Epoch 088 - training loss: 0.2371, validation loss: 0.1342
2024-05-22 19:17:24 [INFO]: Epoch 089 - training loss: 0.2368, validation loss: 0.1338
2024-05-22 19:17:24 [INFO]: Epoch 090 - training loss: 0.2371, validation loss: 0.1339
2024-05-22 19:17:24 [INFO]: Epoch 091 - training loss: 0.2368, validation loss: 0.1336
2024-05-22 19:17:25 [INFO]: Epoch 092 - training loss: 0.2353, validation loss: 0.1335
2024-05-22 19:17:25 [INFO]: Epoch 093 - training loss: 0.2334, validation loss: 0.1348
2024-05-22 19:17:25 [INFO]: Epoch 094 - training loss: 0.2341, validation loss: 0.1304
2024-05-22 19:17:25 [INFO]: Epoch 095 - training loss: 0.2336, validation loss: 0.1319
2024-05-22 19:17:26 [INFO]: Epoch 096 - training loss: 0.2316, validation loss: 0.1338
2024-05-22 19:17:26 [INFO]: Epoch 097 - training loss: 0.2359, validation loss: 0.1314
2024-05-22 19:17:26 [INFO]: Epoch 098 - training loss: 0.2333, validation loss: 0.1336
2024-05-22 19:17:27 [INFO]: Epoch 099 - training loss: 0.2294, validation loss: 0.1310
2024-05-22 19:17:27 [INFO]: Epoch 100 - training loss: 0.2290, validation loss: 0.1307
2024-05-22 19:17:27 [INFO]: Epoch 101 - training loss: 0.2295, validation loss: 0.1343
2024-05-22 19:17:27 [INFO]: Epoch 102 - training loss: 0.2303, validation loss: 0.1303
2024-05-22 19:17:28 [INFO]: Epoch 103 - training loss: 0.2300, validation loss: 0.1308
2024-05-22 19:17:28 [INFO]: Epoch 104 - training loss: 0.2280, validation loss: 0.1307
2024-05-22 19:17:28 [INFO]: Epoch 105 - training loss: 0.2272, validation loss: 0.1296
2024-05-22 19:17:29 [INFO]: Epoch 106 - training loss: 0.2281, validation loss: 0.1305
2024-05-22 19:17:29 [INFO]: Epoch 107 - training loss: 0.2273, validation loss: 0.1305
2024-05-22 19:17:29 [INFO]: Epoch 108 - training loss: 0.2252, validation loss: 0.1288
2024-05-22 19:17:29 [INFO]: Epoch 109 - training loss: 0.2247, validation loss: 0.1287
2024-05-22 19:17:30 [INFO]: Epoch 110 - training loss: 0.2241, validation loss: 0.1287
2024-05-22 19:17:30 [INFO]: Epoch 111 - training loss: 0.2229, validation loss: 0.1298
2024-05-22 19:17:30 [INFO]: Epoch 112 - training loss: 0.2248, validation loss: 0.1290
2024-05-22 19:17:31 [INFO]: Epoch 113 - training loss: 0.2234, validation loss: 0.1284
2024-05-22 19:17:31 [INFO]: Epoch 114 - training loss: 0.2230, validation loss: 0.1282
2024-05-22 19:17:31 [INFO]: Epoch 115 - training loss: 0.2242, validation loss: 0.1288
2024-05-22 19:17:31 [INFO]: Epoch 116 - training loss: 0.2238, validation loss: 0.1285
2024-05-22 19:17:32 [INFO]: Epoch 117 - training loss: 0.2211, validation loss: 0.1294
2024-05-22 19:17:32 [INFO]: Epoch 118 - training loss: 0.2207, validation loss: 0.1260
2024-05-22 19:17:32 [INFO]: Epoch 119 - training loss: 0.2220, validation loss: 0.1274
2024-05-22 19:17:33 [INFO]: Epoch 120 - training loss: 0.2207, validation loss: 0.1259
2024-05-22 19:17:33 [INFO]: Epoch 121 - training loss: 0.2212, validation loss: 0.1281
2024-05-22 19:17:33 [INFO]: Epoch 122 - training loss: 0.2216, validation loss: 0.1247
2024-05-22 19:17:33 [INFO]: Epoch 123 - training loss: 0.2199, validation loss: 0.1271
2024-05-22 19:17:34 [INFO]: Epoch 124 - training loss: 0.2195, validation loss: 0.1259
2024-05-22 19:17:34 [INFO]: Epoch 125 - training loss: 0.2183, validation loss: 0.1247
2024-05-22 19:17:34 [INFO]: Epoch 126 - training loss: 0.2183, validation loss: 0.1267
2024-05-22 19:17:34 [INFO]: Epoch 127 - training loss: 0.2179, validation loss: 0.1248
2024-05-22 19:17:35 [INFO]: Epoch 128 - training loss: 0.2187, validation loss: 0.1266
2024-05-22 19:17:35 [INFO]: Epoch 129 - training loss: 0.2184, validation loss: 0.1262
2024-05-22 19:17:35 [INFO]: Epoch 130 - training loss: 0.2178, validation loss: 0.1240
2024-05-22 19:17:36 [INFO]: Epoch 131 - training loss: 0.2167, validation loss: 0.1238
2024-05-22 19:17:36 [INFO]: Epoch 132 - training loss: 0.2161, validation loss: 0.1240
2024-05-22 19:17:36 [INFO]: Epoch 133 - training loss: 0.2161, validation loss: 0.1225
2024-05-22 19:17:36 [INFO]: Epoch 134 - training loss: 0.2158, validation loss: 0.1251
2024-05-22 19:17:37 [INFO]: Epoch 135 - training loss: 0.2141, validation loss: 0.1232
2024-05-22 19:17:37 [INFO]: Epoch 136 - training loss: 0.2157, validation loss: 0.1224
2024-05-22 19:17:37 [INFO]: Epoch 137 - training loss: 0.2147, validation loss: 0.1233
2024-05-22 19:17:38 [INFO]: Epoch 138 - training loss: 0.2187, validation loss: 0.1235
2024-05-22 19:17:38 [INFO]: Epoch 139 - training loss: 0.2130, validation loss: 0.1233
2024-05-22 19:17:38 [INFO]: Epoch 140 - training loss: 0.2143, validation loss: 0.1241
2024-05-22 19:17:38 [INFO]: Epoch 141 - training loss: 0.2137, validation loss: 0.1237
2024-05-22 19:17:39 [INFO]: Epoch 142 - training loss: 0.2109, validation loss: 0.1222
2024-05-22 19:17:39 [INFO]: Epoch 143 - training loss: 0.2107, validation loss: 0.1224
2024-05-22 19:17:39 [INFO]: Epoch 144 - training loss: 0.2135, validation loss: 0.1237
2024-05-22 19:17:40 [INFO]: Epoch 145 - training loss: 0.2145, validation loss: 0.1236
2024-05-22 19:17:40 [INFO]: Epoch 146 - training loss: 0.2102, validation loss: 0.1208
2024-05-22 19:17:40 [INFO]: Epoch 147 - training loss: 0.2114, validation loss: 0.1224
2024-05-22 19:17:40 [INFO]: Epoch 148 - training loss: 0.2102, validation loss: 0.1218
2024-05-22 19:17:41 [INFO]: Epoch 149 - training loss: 0.2101, validation loss: 0.1236
2024-05-22 19:17:41 [INFO]: Epoch 150 - training loss: 0.2078, validation loss: 0.1225
2024-05-22 19:17:41 [INFO]: Epoch 151 - training loss: 0.2111, validation loss: 0.1233
2024-05-22 19:17:41 [INFO]: Epoch 152 - training loss: 0.2132, validation loss: 0.1222
2024-05-22 19:17:42 [INFO]: Epoch 153 - training loss: 0.2090, validation loss: 0.1216
2024-05-22 19:17:42 [INFO]: Epoch 154 - training loss: 0.2117, validation loss: 0.1222
2024-05-22 19:17:42 [INFO]: Epoch 155 - training loss: 0.2098, validation loss: 0.1210
2024-05-22 19:17:43 [INFO]: Epoch 156 - training loss: 0.2078, validation loss: 0.1201
2024-05-22 19:17:43 [INFO]: Epoch 157 - training loss: 0.2069, validation loss: 0.1213
2024-05-22 19:17:43 [INFO]: Epoch 158 - training loss: 0.2068, validation loss: 0.1219
2024-05-22 19:17:43 [INFO]: Epoch 159 - training loss: 0.2070, validation loss: 0.1209
2024-05-22 19:17:44 [INFO]: Epoch 160 - training loss: 0.2076, validation loss: 0.1218
2024-05-22 19:17:44 [INFO]: Epoch 161 - training loss: 0.2074, validation loss: 0.1203
2024-05-22 19:17:44 [INFO]: Epoch 162 - training loss: 0.2050, validation loss: 0.1205
2024-05-22 19:17:45 [INFO]: Epoch 163 - training loss: 0.2061, validation loss: 0.1210
2024-05-22 19:17:45 [INFO]: Epoch 164 - training loss: 0.2069, validation loss: 0.1214
2024-05-22 19:17:45 [INFO]: Epoch 165 - training loss: 0.2064, validation loss: 0.1203
2024-05-22 19:17:45 [INFO]: Epoch 166 - training loss: 0.2046, validation loss: 0.1200
2024-05-22 19:17:46 [INFO]: Epoch 167 - training loss: 0.2030, validation loss: 0.1203
2024-05-22 19:17:46 [INFO]: Epoch 168 - training loss: 0.2033, validation loss: 0.1187
2024-05-22 19:17:46 [INFO]: Epoch 169 - training loss: 0.2053, validation loss: 0.1199
2024-05-22 19:17:47 [INFO]: Epoch 170 - training loss: 0.2082, validation loss: 0.1196
2024-05-22 19:17:47 [INFO]: Epoch 171 - training loss: 0.2077, validation loss: 0.1176
2024-05-22 19:17:47 [INFO]: Epoch 172 - training loss: 0.2038, validation loss: 0.1195
2024-05-22 19:17:47 [INFO]: Epoch 173 - training loss: 0.2025, validation loss: 0.1193
2024-05-22 19:17:48 [INFO]: Epoch 174 - training loss: 0.2029, validation loss: 0.1184
2024-05-22 19:17:48 [INFO]: Epoch 175 - training loss: 0.2048, validation loss: 0.1188
2024-05-22 19:17:48 [INFO]: Epoch 176 - training loss: 0.2029, validation loss: 0.1178
2024-05-22 19:17:48 [INFO]: Epoch 177 - training loss: 0.2023, validation loss: 0.1177
2024-05-22 19:17:49 [INFO]: Epoch 178 - training loss: 0.2005, validation loss: 0.1188
2024-05-22 19:17:49 [INFO]: Epoch 179 - training loss: 0.2023, validation loss: 0.1170
2024-05-22 19:17:49 [INFO]: Epoch 180 - training loss: 0.2033, validation loss: 0.1180
2024-05-22 19:17:50 [INFO]: Epoch 181 - training loss: 0.2042, validation loss: 0.1181
2024-05-22 19:17:50 [INFO]: Epoch 182 - training loss: 0.2026, validation loss: 0.1173
2024-05-22 19:17:50 [INFO]: Epoch 183 - training loss: 0.1998, validation loss: 0.1165
2024-05-22 19:17:50 [INFO]: Epoch 184 - training loss: 0.2007, validation loss: 0.1157
2024-05-22 19:17:51 [INFO]: Epoch 185 - training loss: 0.1991, validation loss: 0.1163
2024-05-22 19:17:51 [INFO]: Epoch 186 - training loss: 0.1990, validation loss: 0.1159
2024-05-22 19:17:51 [INFO]: Epoch 187 - training loss: 0.2004, validation loss: 0.1165
2024-05-22 19:17:52 [INFO]: Epoch 188 - training loss: 0.1988, validation loss: 0.1153
2024-05-22 19:17:52 [INFO]: Epoch 189 - training loss: 0.1991, validation loss: 0.1158
2024-05-22 19:17:52 [INFO]: Epoch 190 - training loss: 0.1983, validation loss: 0.1160
2024-05-22 19:17:52 [INFO]: Epoch 191 - training loss: 0.1984, validation loss: 0.1171
2024-05-22 19:17:53 [INFO]: Epoch 192 - training loss: 0.1982, validation loss: 0.1159
2024-05-22 19:17:53 [INFO]: Epoch 193 - training loss: 0.1968, validation loss: 0.1166
2024-05-22 19:17:53 [INFO]: Epoch 194 - training loss: 0.1977, validation loss: 0.1154
2024-05-22 19:17:54 [INFO]: Epoch 195 - training loss: 0.1970, validation loss: 0.1151
2024-05-22 19:17:54 [INFO]: Epoch 196 - training loss: 0.2000, validation loss: 0.1158
2024-05-22 19:17:54 [INFO]: Epoch 197 - training loss: 0.1993, validation loss: 0.1145
2024-05-22 19:17:54 [INFO]: Epoch 198 - training loss: 0.1977, validation loss: 0.1144
2024-05-22 19:17:55 [INFO]: Epoch 199 - training loss: 0.1991, validation loss: 0.1139
2024-05-22 19:17:55 [INFO]: Epoch 200 - training loss: 0.1968, validation loss: 0.1150
2024-05-22 19:17:55 [INFO]: Epoch 201 - training loss: 0.1989, validation loss: 0.1150
2024-05-22 19:17:55 [INFO]: Epoch 202 - training loss: 0.2000, validation loss: 0.1145
2024-05-22 19:17:56 [INFO]: Epoch 203 - training loss: 0.1962, validation loss: 0.1160
2024-05-22 19:17:56 [INFO]: Epoch 204 - training loss: 0.1965, validation loss: 0.1149
2024-05-22 19:17:56 [INFO]: Epoch 205 - training loss: 0.1979, validation loss: 0.1139
2024-05-22 19:17:57 [INFO]: Epoch 206 - training loss: 0.1946, validation loss: 0.1150
2024-05-22 19:17:57 [INFO]: Epoch 207 - training loss: 0.1952, validation loss: 0.1147
2024-05-22 19:17:57 [INFO]: Epoch 208 - training loss: 0.1939, validation loss: 0.1137
2024-05-22 19:17:57 [INFO]: Epoch 209 - training loss: 0.1941, validation loss: 0.1154
2024-05-22 19:17:58 [INFO]: Epoch 210 - training loss: 0.1945, validation loss: 0.1135
2024-05-22 19:17:58 [INFO]: Epoch 211 - training loss: 0.1946, validation loss: 0.1148
2024-05-22 19:17:58 [INFO]: Epoch 212 - training loss: 0.1957, validation loss: 0.1137
2024-05-22 19:17:59 [INFO]: Epoch 213 - training loss: 0.1933, validation loss: 0.1147
2024-05-22 19:17:59 [INFO]: Epoch 214 - training loss: 0.1908, validation loss: 0.1131
2024-05-22 19:17:59 [INFO]: Epoch 215 - training loss: 0.1920, validation loss: 0.1133
2024-05-22 19:17:59 [INFO]: Epoch 216 - training loss: 0.1926, validation loss: 0.1136
2024-05-22 19:18:00 [INFO]: Epoch 217 - training loss: 0.1921, validation loss: 0.1126
2024-05-22 19:18:00 [INFO]: Epoch 218 - training loss: 0.1931, validation loss: 0.1117
2024-05-22 19:18:00 [INFO]: Epoch 219 - training loss: 0.1918, validation loss: 0.1133
2024-05-22 19:18:01 [INFO]: Epoch 220 - training loss: 0.1910, validation loss: 0.1130
2024-05-22 19:18:01 [INFO]: Epoch 221 - training loss: 0.1935, validation loss: 0.1130
2024-05-22 19:18:01 [INFO]: Epoch 222 - training loss: 0.1903, validation loss: 0.1128
2024-05-22 19:18:01 [INFO]: Epoch 223 - training loss: 0.1901, validation loss: 0.1128
2024-05-22 19:18:02 [INFO]: Epoch 224 - training loss: 0.1913, validation loss: 0.1125
2024-05-22 19:18:02 [INFO]: Epoch 225 - training loss: 0.1913, validation loss: 0.1115
2024-05-22 19:18:02 [INFO]: Epoch 226 - training loss: 0.1902, validation loss: 0.1132
2024-05-22 19:18:02 [INFO]: Epoch 227 - training loss: 0.1909, validation loss: 0.1121
2024-05-22 19:18:03 [INFO]: Epoch 228 - training loss: 0.1919, validation loss: 0.1120
2024-05-22 19:18:03 [INFO]: Epoch 229 - training loss: 0.1902, validation loss: 0.1122
2024-05-22 19:18:03 [INFO]: Epoch 230 - training loss: 0.1890, validation loss: 0.1121
2024-05-22 19:18:04 [INFO]: Epoch 231 - training loss: 0.1893, validation loss: 0.1132
2024-05-22 19:18:04 [INFO]: Epoch 232 - training loss: 0.1892, validation loss: 0.1121
2024-05-22 19:18:04 [INFO]: Epoch 233 - training loss: 0.1897, validation loss: 0.1122
2024-05-22 19:18:04 [INFO]: Epoch 234 - training loss: 0.1884, validation loss: 0.1126
2024-05-22 19:18:05 [INFO]: Epoch 235 - training loss: 0.1886, validation loss: 0.1119
2024-05-22 19:18:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 19:18:05 [INFO]: Finished training. The best model is from epoch#225.
2024-05-22 19:18:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/Transformer_air_quality/20240522_T191659/Transformer.pypots
2024-05-22 19:18:05 [INFO]: Transformer on Air-Quality: MAE=0.1567, MSE=0.1189
2024-05-22 19:18:05 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/Transformer_air_quality/imputation.pkl
2024-05-22 19:18:05 [INFO]: Using the given device: cuda:0
2024-05-22 19:18:05 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/TimesNet_air_quality/20240522_T191805
2024-05-22 19:18:05 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/TimesNet_air_quality/20240522_T191805/tensorboard
2024-05-22 19:18:05 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-22 19:18:06 [INFO]: Epoch 001 - training loss: 0.3104, validation loss: 0.2517
2024-05-22 19:18:06 [INFO]: Epoch 002 - training loss: 0.2126, validation loss: 0.2119
2024-05-22 19:18:07 [INFO]: Epoch 003 - training loss: 0.1896, validation loss: 0.1907
2024-05-22 19:18:07 [INFO]: Epoch 004 - training loss: 0.1910, validation loss: 0.1862
2024-05-22 19:18:08 [INFO]: Epoch 005 - training loss: 0.1730, validation loss: 0.1710
2024-05-22 19:18:08 [INFO]: Epoch 006 - training loss: 0.1551, validation loss: 0.1681
2024-05-22 19:18:08 [INFO]: Epoch 007 - training loss: 0.1475, validation loss: 0.1708
2024-05-22 19:18:09 [INFO]: Epoch 008 - training loss: 0.1489, validation loss: 0.1658
2024-05-22 19:18:09 [INFO]: Epoch 009 - training loss: 0.1388, validation loss: 0.1570
2024-05-22 19:18:10 [INFO]: Epoch 010 - training loss: 0.1575, validation loss: 0.1557
2024-05-22 19:18:10 [INFO]: Epoch 011 - training loss: 0.1611, validation loss: 0.1544
2024-05-22 19:18:11 [INFO]: Epoch 012 - training loss: 0.1478, validation loss: 0.1521
2024-05-22 19:18:11 [INFO]: Epoch 013 - training loss: 0.1393, validation loss: 0.1525
2024-05-22 19:18:12 [INFO]: Epoch 014 - training loss: 0.1585, validation loss: 0.1542
2024-05-22 19:18:12 [INFO]: Epoch 015 - training loss: 0.1543, validation loss: 0.1472
2024-05-22 19:18:13 [INFO]: Epoch 016 - training loss: 0.1307, validation loss: 0.1527
2024-05-22 19:18:13 [INFO]: Epoch 017 - training loss: 0.1221, validation loss: 0.1436
2024-05-22 19:18:14 [INFO]: Epoch 018 - training loss: 0.1110, validation loss: 0.1420
2024-05-22 19:18:14 [INFO]: Epoch 019 - training loss: 0.1354, validation loss: 0.1470
2024-05-22 19:18:15 [INFO]: Epoch 020 - training loss: 0.1282, validation loss: 0.1475
2024-05-22 19:18:15 [INFO]: Epoch 021 - training loss: 0.1368, validation loss: 0.1469
2024-05-22 19:18:16 [INFO]: Epoch 022 - training loss: 0.1220, validation loss: 0.1419
2024-05-22 19:18:16 [INFO]: Epoch 023 - training loss: 0.1282, validation loss: 0.1454
2024-05-22 19:18:17 [INFO]: Epoch 024 - training loss: 0.1254, validation loss: 0.1430
2024-05-22 19:18:17 [INFO]: Epoch 025 - training loss: 0.1324, validation loss: 0.1450
2024-05-22 19:18:17 [INFO]: Epoch 026 - training loss: 0.1259, validation loss: 0.1424
2024-05-22 19:18:18 [INFO]: Epoch 027 - training loss: 0.1344, validation loss: 0.1549
2024-05-22 19:18:18 [INFO]: Epoch 028 - training loss: 0.1310, validation loss: 0.1431
2024-05-22 19:18:19 [INFO]: Epoch 029 - training loss: 0.1238, validation loss: 0.1381
2024-05-22 19:18:19 [INFO]: Epoch 030 - training loss: 0.1082, validation loss: 0.1418
2024-05-22 19:18:20 [INFO]: Epoch 031 - training loss: 0.1163, validation loss: 0.1388
2024-05-22 19:18:20 [INFO]: Epoch 032 - training loss: 0.1142, validation loss: 0.1406
2024-05-22 19:18:21 [INFO]: Epoch 033 - training loss: 0.1157, validation loss: 0.1393
2024-05-22 19:18:21 [INFO]: Epoch 034 - training loss: 0.1200, validation loss: 0.1447
2024-05-22 19:18:22 [INFO]: Epoch 035 - training loss: 0.1113, validation loss: 0.1394
2024-05-22 19:18:22 [INFO]: Epoch 036 - training loss: 0.1141, validation loss: 0.1366
2024-05-22 19:18:23 [INFO]: Epoch 037 - training loss: 0.1003, validation loss: 0.1430
2024-05-22 19:18:23 [INFO]: Epoch 038 - training loss: 0.1002, validation loss: 0.1350
2024-05-22 19:18:24 [INFO]: Epoch 039 - training loss: 0.1166, validation loss: 0.1395
2024-05-22 19:18:24 [INFO]: Epoch 040 - training loss: 0.1050, validation loss: 0.1389
2024-05-22 19:18:25 [INFO]: Epoch 041 - training loss: 0.1123, validation loss: 0.1389
2024-05-22 19:18:25 [INFO]: Epoch 042 - training loss: 0.1048, validation loss: 0.1367
2024-05-22 19:18:25 [INFO]: Epoch 043 - training loss: 0.1126, validation loss: 0.1383
2024-05-22 19:18:26 [INFO]: Epoch 044 - training loss: 0.1161, validation loss: 0.1380
2024-05-22 19:18:26 [INFO]: Epoch 045 - training loss: 0.1021, validation loss: 0.1365
2024-05-22 19:18:27 [INFO]: Epoch 046 - training loss: 0.1188, validation loss: 0.1340
2024-05-22 19:18:27 [INFO]: Epoch 047 - training loss: 0.1118, validation loss: 0.1329
2024-05-22 19:18:28 [INFO]: Epoch 048 - training loss: 0.0934, validation loss: 0.1363
2024-05-22 19:18:28 [INFO]: Epoch 049 - training loss: 0.1202, validation loss: 0.1324
2024-05-22 19:18:29 [INFO]: Epoch 050 - training loss: 0.1078, validation loss: 0.1404
2024-05-22 19:18:29 [INFO]: Epoch 051 - training loss: 0.1014, validation loss: 0.1344
2024-05-22 19:18:30 [INFO]: Epoch 052 - training loss: 0.0942, validation loss: 0.1384
2024-05-22 19:18:30 [INFO]: Epoch 053 - training loss: 0.0881, validation loss: 0.1366
2024-05-22 19:18:31 [INFO]: Epoch 054 - training loss: 0.1069, validation loss: 0.1315
2024-05-22 19:18:31 [INFO]: Epoch 055 - training loss: 0.1012, validation loss: 0.1362
2024-05-22 19:18:32 [INFO]: Epoch 056 - training loss: 0.1056, validation loss: 0.1370
2024-05-22 19:18:32 [INFO]: Epoch 057 - training loss: 0.1075, validation loss: 0.1357
2024-05-22 19:18:33 [INFO]: Epoch 058 - training loss: 0.1000, validation loss: 0.1402
2024-05-22 19:18:33 [INFO]: Epoch 059 - training loss: 0.1022, validation loss: 0.1290
2024-05-22 19:18:34 [INFO]: Epoch 060 - training loss: 0.1114, validation loss: 0.1368
2024-05-22 19:18:34 [INFO]: Epoch 061 - training loss: 0.1110, validation loss: 0.1328
2024-05-22 19:18:34 [INFO]: Epoch 062 - training loss: 0.0751, validation loss: 0.1315
2024-05-22 19:18:35 [INFO]: Epoch 063 - training loss: 0.1060, validation loss: 0.1295
2024-05-22 19:18:35 [INFO]: Epoch 064 - training loss: 0.1022, validation loss: 0.1348
2024-05-22 19:18:36 [INFO]: Epoch 065 - training loss: 0.1056, validation loss: 0.1389
2024-05-22 19:18:36 [INFO]: Epoch 066 - training loss: 0.0984, validation loss: 0.1349
2024-05-22 19:18:37 [INFO]: Epoch 067 - training loss: 0.1030, validation loss: 0.1384
2024-05-22 19:18:37 [INFO]: Epoch 068 - training loss: 0.0874, validation loss: 0.1387
2024-05-22 19:18:38 [INFO]: Epoch 069 - training loss: 0.0892, validation loss: 0.1428
2024-05-22 19:18:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 19:18:38 [INFO]: Finished training. The best model is from epoch#59.
2024-05-22 19:18:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/TimesNet_air_quality/20240522_T191805/TimesNet.pypots
2024-05-22 19:18:38 [INFO]: TimesNet on Air-Quality: MAE=0.1553, MSE=0.1567
2024-05-22 19:18:38 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/TimesNet_air_quality/imputation.pkl
2024-05-22 19:18:38 [INFO]: Using the given device: cuda:0
2024-05-22 19:18:38 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838
2024-05-22 19:18:38 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/tensorboard
2024-05-22 19:18:38 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-22 19:18:55 [INFO]: Epoch 001 - training loss: 0.4731, validation loss: 0.3607
2024-05-22 19:18:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch1_loss0.360736221075058.pypots
2024-05-22 19:19:11 [INFO]: Epoch 002 - training loss: 0.3061, validation loss: 0.2775
2024-05-22 19:19:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch2_loss0.2774838864803314.pypots
2024-05-22 19:19:28 [INFO]: Epoch 003 - training loss: 0.2483, validation loss: 0.2414
2024-05-22 19:19:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch3_loss0.24138541221618653.pypots
2024-05-22 19:19:44 [INFO]: Epoch 004 - training loss: 0.2458, validation loss: 0.2094
2024-05-22 19:19:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch4_loss0.20942142009735107.pypots
2024-05-22 19:20:01 [INFO]: Epoch 005 - training loss: 0.2022, validation loss: 0.1851
2024-05-22 19:20:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch5_loss0.18507424145936965.pypots
2024-05-22 19:20:17 [INFO]: Epoch 006 - training loss: 0.1932, validation loss: 0.1825
2024-05-22 19:20:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch6_loss0.1825064942240715.pypots
2024-05-22 19:20:34 [INFO]: Epoch 007 - training loss: 0.1819, validation loss: 0.1709
2024-05-22 19:20:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch7_loss0.17091241627931594.pypots
2024-05-22 19:20:50 [INFO]: Epoch 008 - training loss: 0.2016, validation loss: 0.1632
2024-05-22 19:20:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch8_loss0.1632382944226265.pypots
2024-05-22 19:21:07 [INFO]: Epoch 009 - training loss: 0.1869, validation loss: 0.1565
2024-05-22 19:21:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch9_loss0.15649835914373397.pypots
2024-05-22 19:21:23 [INFO]: Epoch 010 - training loss: 0.1899, validation loss: 0.1532
2024-05-22 19:21:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch10_loss0.15320245772600175.pypots
2024-05-22 19:21:40 [INFO]: Epoch 011 - training loss: 0.1726, validation loss: 0.1597
2024-05-22 19:21:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch11_loss0.15973673313856124.pypots
2024-05-22 19:21:56 [INFO]: Epoch 012 - training loss: 0.1754, validation loss: 0.1482
2024-05-22 19:21:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch12_loss0.1481579899787903.pypots
2024-05-22 19:22:13 [INFO]: Epoch 013 - training loss: 0.1491, validation loss: 0.1430
2024-05-22 19:22:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch13_loss0.1429628074169159.pypots
2024-05-22 19:22:29 [INFO]: Epoch 014 - training loss: 0.1680, validation loss: 0.1464
2024-05-22 19:22:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch14_loss0.1463521346449852.pypots
2024-05-22 19:22:46 [INFO]: Epoch 015 - training loss: 0.1683, validation loss: 0.1469
2024-05-22 19:22:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch15_loss0.1468517228960991.pypots
2024-05-22 19:23:02 [INFO]: Epoch 016 - training loss: 0.1605, validation loss: 0.1423
2024-05-22 19:23:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch16_loss0.1422571934759617.pypots
2024-05-22 19:23:19 [INFO]: Epoch 017 - training loss: 0.1523, validation loss: 0.1401
2024-05-22 19:23:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch17_loss0.1400514893233776.pypots
2024-05-22 19:23:36 [INFO]: Epoch 018 - training loss: 0.1771, validation loss: 0.1587
2024-05-22 19:23:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch18_loss0.1587256982922554.pypots
2024-05-22 19:23:52 [INFO]: Epoch 019 - training loss: 0.1607, validation loss: 0.1418
2024-05-22 19:23:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch19_loss0.1417696051299572.pypots
2024-05-22 19:24:09 [INFO]: Epoch 020 - training loss: 0.1481, validation loss: 0.1385
2024-05-22 19:24:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch20_loss0.1384574443101883.pypots
2024-05-22 19:24:25 [INFO]: Epoch 021 - training loss: 0.1664, validation loss: 0.1388
2024-05-22 19:24:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch21_loss0.13875239640474318.pypots
2024-05-22 19:24:42 [INFO]: Epoch 022 - training loss: 0.1564, validation loss: 0.1350
2024-05-22 19:24:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch22_loss0.13504193127155303.pypots
2024-05-22 19:24:58 [INFO]: Epoch 023 - training loss: 0.1504, validation loss: 0.1346
2024-05-22 19:24:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch23_loss0.13463279828429223.pypots
2024-05-22 19:25:15 [INFO]: Epoch 024 - training loss: 0.1520, validation loss: 0.1328
2024-05-22 19:25:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch24_loss0.13278641253709794.pypots
2024-05-22 19:25:31 [INFO]: Epoch 025 - training loss: 0.1674, validation loss: 0.1331
2024-05-22 19:25:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch25_loss0.1331258900463581.pypots
2024-05-22 19:25:48 [INFO]: Epoch 026 - training loss: 0.1450, validation loss: 0.1291
2024-05-22 19:25:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch26_loss0.12907541543245316.pypots
2024-05-22 19:26:04 [INFO]: Epoch 027 - training loss: 0.1528, validation loss: 0.1291
2024-05-22 19:26:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch27_loss0.12911078110337257.pypots
2024-05-22 19:26:21 [INFO]: Epoch 028 - training loss: 0.1463, validation loss: 0.1279
2024-05-22 19:26:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch28_loss0.127873595058918.pypots
2024-05-22 19:26:38 [INFO]: Epoch 029 - training loss: 0.1387, validation loss: 0.1321
2024-05-22 19:26:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch29_loss0.13205907717347146.pypots
2024-05-22 19:26:54 [INFO]: Epoch 030 - training loss: 0.1382, validation loss: 0.1294
2024-05-22 19:26:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch30_loss0.1293749637901783.pypots
2024-05-22 19:27:11 [INFO]: Epoch 031 - training loss: 0.1436, validation loss: 0.1269
2024-05-22 19:27:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch31_loss0.12685707286000253.pypots
2024-05-22 19:27:27 [INFO]: Epoch 032 - training loss: 0.1487, validation loss: 0.1314
2024-05-22 19:27:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch32_loss0.13142924159765243.pypots
2024-05-22 19:27:44 [INFO]: Epoch 033 - training loss: 0.1468, validation loss: 0.1350
2024-05-22 19:27:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch33_loss0.13501909524202346.pypots
2024-05-22 19:28:00 [INFO]: Epoch 034 - training loss: 0.1314, validation loss: 0.1252
2024-05-22 19:28:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch34_loss0.12519281208515168.pypots
2024-05-22 19:28:17 [INFO]: Epoch 035 - training loss: 0.1467, validation loss: 0.1227
2024-05-22 19:28:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch35_loss0.12268199995160103.pypots
2024-05-22 19:28:33 [INFO]: Epoch 036 - training loss: 0.1474, validation loss: 0.1215
2024-05-22 19:28:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch36_loss0.1215206265449524.pypots
2024-05-22 19:28:50 [INFO]: Epoch 037 - training loss: 0.1397, validation loss: 0.1213
2024-05-22 19:28:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch37_loss0.12132158651947975.pypots
2024-05-22 19:29:06 [INFO]: Epoch 038 - training loss: 0.1202, validation loss: 0.1210
2024-05-22 19:29:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch38_loss0.12096331864595414.pypots
2024-05-22 19:29:23 [INFO]: Epoch 039 - training loss: 0.1296, validation loss: 0.1244
2024-05-22 19:29:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch39_loss0.12437363341450691.pypots
2024-05-22 19:29:40 [INFO]: Epoch 040 - training loss: 0.1338, validation loss: 0.1212
2024-05-22 19:29:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch40_loss0.12123394757509232.pypots
2024-05-22 19:29:56 [INFO]: Epoch 041 - training loss: 0.1309, validation loss: 0.1232
2024-05-22 19:29:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch41_loss0.12319154888391495.pypots
2024-05-22 19:30:13 [INFO]: Epoch 042 - training loss: 0.1454, validation loss: 0.1177
2024-05-22 19:30:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch42_loss0.11771134436130523.pypots
2024-05-22 19:30:29 [INFO]: Epoch 043 - training loss: 0.1466, validation loss: 0.1184
2024-05-22 19:30:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch43_loss0.1184007853269577.pypots
2024-05-22 19:30:46 [INFO]: Epoch 044 - training loss: 0.1212, validation loss: 0.1146
2024-05-22 19:30:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch44_loss0.11456113830208778.pypots
2024-05-22 19:31:02 [INFO]: Epoch 045 - training loss: 0.1315, validation loss: 0.1166
2024-05-22 19:31:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch45_loss0.11658683344721794.pypots
2024-05-22 19:31:19 [INFO]: Epoch 046 - training loss: 0.1314, validation loss: 0.1182
2024-05-22 19:31:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch46_loss0.11815593391656876.pypots
2024-05-22 19:31:35 [INFO]: Epoch 047 - training loss: 0.1248, validation loss: 0.1232
2024-05-22 19:31:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch47_loss0.12320191115140915.pypots
2024-05-22 19:31:52 [INFO]: Epoch 048 - training loss: 0.1448, validation loss: 0.1235
2024-05-22 19:31:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch48_loss0.12353384271264076.pypots
2024-05-22 19:32:08 [INFO]: Epoch 049 - training loss: 0.1410, validation loss: 0.1146
2024-05-22 19:32:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch49_loss0.1146418072283268.pypots
2024-05-22 19:32:25 [INFO]: Epoch 050 - training loss: 0.1200, validation loss: 0.1118
2024-05-22 19:32:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch50_loss0.11181150302290917.pypots
2024-05-22 19:32:42 [INFO]: Epoch 051 - training loss: 0.1291, validation loss: 0.1162
2024-05-22 19:32:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch51_loss0.1161977343261242.pypots
2024-05-22 19:32:58 [INFO]: Epoch 052 - training loss: 0.1324, validation loss: 0.1129
2024-05-22 19:32:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch52_loss0.1129136137664318.pypots
2024-05-22 19:33:15 [INFO]: Epoch 053 - training loss: 0.1251, validation loss: 0.1149
2024-05-22 19:33:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch53_loss0.11491322070360184.pypots
2024-05-22 19:33:31 [INFO]: Epoch 054 - training loss: 0.1228, validation loss: 0.1119
2024-05-22 19:33:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch54_loss0.11194950938224793.pypots
2024-05-22 19:33:48 [INFO]: Epoch 055 - training loss: 0.1155, validation loss: 0.1120
2024-05-22 19:33:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch55_loss0.1119801513850689.pypots
2024-05-22 19:34:04 [INFO]: Epoch 056 - training loss: 0.1239, validation loss: 0.1109
2024-05-22 19:34:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch56_loss0.11089117377996445.pypots
2024-05-22 19:34:21 [INFO]: Epoch 057 - training loss: 0.1228, validation loss: 0.1110
2024-05-22 19:34:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch57_loss0.11102505624294282.pypots
2024-05-22 19:34:37 [INFO]: Epoch 058 - training loss: 0.1311, validation loss: 0.1103
2024-05-22 19:34:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch58_loss0.11032681465148926.pypots
2024-05-22 19:34:54 [INFO]: Epoch 059 - training loss: 0.1189, validation loss: 0.1094
2024-05-22 19:34:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch59_loss0.10941147431731224.pypots
2024-05-22 19:35:10 [INFO]: Epoch 060 - training loss: 0.1191, validation loss: 0.1083
2024-05-22 19:35:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch60_loss0.10833481252193451.pypots
2024-05-22 19:35:27 [INFO]: Epoch 061 - training loss: 0.1115, validation loss: 0.1095
2024-05-22 19:35:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch61_loss0.10948805287480354.pypots
2024-05-22 19:35:44 [INFO]: Epoch 062 - training loss: 0.1100, validation loss: 0.1124
2024-05-22 19:35:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch62_loss0.11236205473542213.pypots
2024-05-22 19:36:00 [INFO]: Epoch 063 - training loss: 0.1248, validation loss: 0.1086
2024-05-22 19:36:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch63_loss0.10863393247127533.pypots
2024-05-22 19:36:17 [INFO]: Epoch 064 - training loss: 0.1062, validation loss: 0.1067
2024-05-22 19:36:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch64_loss0.10666268691420555.pypots
2024-05-22 19:36:33 [INFO]: Epoch 065 - training loss: 0.1248, validation loss: 0.1198
2024-05-22 19:36:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch65_loss0.11979462057352067.pypots
2024-05-22 19:36:50 [INFO]: Epoch 066 - training loss: 0.1302, validation loss: 0.1144
2024-05-22 19:36:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch66_loss0.11437502801418305.pypots
2024-05-22 19:37:06 [INFO]: Epoch 067 - training loss: 0.1217, validation loss: 0.1071
2024-05-22 19:37:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch67_loss0.10712699070572854.pypots
2024-05-22 19:37:23 [INFO]: Epoch 068 - training loss: 0.1166, validation loss: 0.1102
2024-05-22 19:37:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch68_loss0.11019696667790413.pypots
2024-05-22 19:37:39 [INFO]: Epoch 069 - training loss: 0.1223, validation loss: 0.1077
2024-05-22 19:37:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch69_loss0.10770357251167298.pypots
2024-05-22 19:37:56 [INFO]: Epoch 070 - training loss: 0.1327, validation loss: 0.1098
2024-05-22 19:37:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch70_loss0.10975485369563102.pypots
2024-05-22 19:38:12 [INFO]: Epoch 071 - training loss: 0.1238, validation loss: 0.1144
2024-05-22 19:38:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch71_loss0.11436226367950439.pypots
2024-05-22 19:38:29 [INFO]: Epoch 072 - training loss: 0.1233, validation loss: 0.1067
2024-05-22 19:38:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch72_loss0.1067400299012661.pypots
2024-05-22 19:38:45 [INFO]: Epoch 073 - training loss: 0.1304, validation loss: 0.1133
2024-05-22 19:38:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch73_loss0.11330389752984046.pypots
2024-05-22 19:39:02 [INFO]: Epoch 074 - training loss: 0.1220, validation loss: 0.1090
2024-05-22 19:39:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI_epoch74_loss0.10895586237311364.pypots
2024-05-22 19:39:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 19:39:02 [INFO]: Finished training. The best model is from epoch#64.
2024-05-22 19:39:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/20240522_T191838/CSDI.pypots
2024-05-22 19:41:20 [INFO]: CSDI on Air-Quality: MAE=0.1086, MSE=0.1556
2024-05-22 19:41:20 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/CSDI_air_quality/imputation.pkl
2024-05-22 19:41:20 [INFO]: Using the given device: cuda:0
2024-05-22 19:41:20 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/GPVAE_air_quality/20240522_T194120
2024-05-22 19:41:20 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/GPVAE_air_quality/20240522_T194120/tensorboard
2024-05-22 19:41:20 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-22 19:41:20 [INFO]: Epoch 001 - training loss: 63319.7015, validation loss: 0.6270
2024-05-22 19:41:21 [INFO]: Epoch 002 - training loss: 42059.0466, validation loss: 0.5476
2024-05-22 19:41:21 [INFO]: Epoch 003 - training loss: 41756.6678, validation loss: 0.5111
2024-05-22 19:41:21 [INFO]: Epoch 004 - training loss: 41656.9815, validation loss: 0.4563
2024-05-22 19:41:21 [INFO]: Epoch 005 - training loss: 41544.1701, validation loss: 0.4090
2024-05-22 19:41:22 [INFO]: Epoch 006 - training loss: 41497.9686, validation loss: 0.3799
2024-05-22 19:41:22 [INFO]: Epoch 007 - training loss: 41479.6014, validation loss: 0.3787
2024-05-22 19:41:22 [INFO]: Epoch 008 - training loss: 41468.1319, validation loss: 0.3576
2024-05-22 19:41:22 [INFO]: Epoch 009 - training loss: 41412.6921, validation loss: 0.3278
2024-05-22 19:41:23 [INFO]: Epoch 010 - training loss: 41389.5317, validation loss: 0.3273
2024-05-22 19:41:23 [INFO]: Epoch 011 - training loss: 41363.0664, validation loss: 0.3018
2024-05-22 19:41:23 [INFO]: Epoch 012 - training loss: 41338.9685, validation loss: 0.2946
2024-05-22 19:41:23 [INFO]: Epoch 013 - training loss: 41313.3560, validation loss: 0.2895
2024-05-22 19:41:24 [INFO]: Epoch 014 - training loss: 41302.2843, validation loss: 0.2765
2024-05-22 19:41:24 [INFO]: Epoch 015 - training loss: 41310.9758, validation loss: 0.2770
2024-05-22 19:41:24 [INFO]: Epoch 016 - training loss: 41290.0007, validation loss: 0.2706
2024-05-22 19:41:24 [INFO]: Epoch 017 - training loss: 41280.1807, validation loss: 0.2684
2024-05-22 19:41:25 [INFO]: Epoch 018 - training loss: 41285.9349, validation loss: 0.2749
2024-05-22 19:41:25 [INFO]: Epoch 019 - training loss: 41277.0825, validation loss: 0.2869
2024-05-22 19:41:25 [INFO]: Epoch 020 - training loss: 41300.8238, validation loss: 0.2725
2024-05-22 19:41:25 [INFO]: Epoch 021 - training loss: 41269.9178, validation loss: 0.2736
2024-05-22 19:41:26 [INFO]: Epoch 022 - training loss: 41262.2580, validation loss: 0.2698
2024-05-22 19:41:26 [INFO]: Epoch 023 - training loss: 41244.9324, validation loss: 0.2570
2024-05-22 19:41:26 [INFO]: Epoch 024 - training loss: 41233.6740, validation loss: 0.2478
2024-05-22 19:41:26 [INFO]: Epoch 025 - training loss: 41252.1586, validation loss: 0.2803
2024-05-22 19:41:27 [INFO]: Epoch 026 - training loss: 41234.1521, validation loss: 0.2511
2024-05-22 19:41:27 [INFO]: Epoch 027 - training loss: 41225.7756, validation loss: 0.2556
2024-05-22 19:41:27 [INFO]: Epoch 028 - training loss: 41224.4408, validation loss: 0.2390
2024-05-22 19:41:27 [INFO]: Epoch 029 - training loss: 41240.7849, validation loss: 0.2510
2024-05-22 19:41:28 [INFO]: Epoch 030 - training loss: 41221.7080, validation loss: 0.2427
2024-05-22 19:41:28 [INFO]: Epoch 031 - training loss: 41210.7752, validation loss: 0.2299
2024-05-22 19:41:28 [INFO]: Epoch 032 - training loss: 41210.1201, validation loss: 0.2333
2024-05-22 19:41:28 [INFO]: Epoch 033 - training loss: 41220.4740, validation loss: 0.2334
2024-05-22 19:41:29 [INFO]: Epoch 034 - training loss: 41274.0312, validation loss: 0.2637
2024-05-22 19:41:29 [INFO]: Epoch 035 - training loss: 41260.3724, validation loss: 0.2602
2024-05-22 19:41:29 [INFO]: Epoch 036 - training loss: 41218.3675, validation loss: 0.2453
2024-05-22 19:41:29 [INFO]: Epoch 037 - training loss: 41200.8109, validation loss: 0.2345
2024-05-22 19:41:29 [INFO]: Epoch 038 - training loss: 41197.3951, validation loss: 0.2477
2024-05-22 19:41:30 [INFO]: Epoch 039 - training loss: 41221.9754, validation loss: 0.2583
2024-05-22 19:41:30 [INFO]: Epoch 040 - training loss: 41208.0770, validation loss: 0.2225
2024-05-22 19:41:30 [INFO]: Epoch 041 - training loss: 41185.8341, validation loss: 0.2220
2024-05-22 19:41:30 [INFO]: Epoch 042 - training loss: 41180.9578, validation loss: 0.2209
2024-05-22 19:41:31 [INFO]: Epoch 043 - training loss: 41177.2963, validation loss: 0.2282
2024-05-22 19:41:31 [INFO]: Epoch 044 - training loss: 41176.3828, validation loss: 0.2140
2024-05-22 19:41:31 [INFO]: Epoch 045 - training loss: 41187.3760, validation loss: 0.2244
2024-05-22 19:41:31 [INFO]: Epoch 046 - training loss: 41211.6256, validation loss: 0.2419
2024-05-22 19:41:32 [INFO]: Epoch 047 - training loss: 41211.5806, validation loss: 0.2584
2024-05-22 19:41:32 [INFO]: Epoch 048 - training loss: 41199.1911, validation loss: 0.2329
2024-05-22 19:41:32 [INFO]: Epoch 049 - training loss: 41185.6759, validation loss: 0.2181
2024-05-22 19:41:32 [INFO]: Epoch 050 - training loss: 41174.3701, validation loss: 0.2155
2024-05-22 19:41:33 [INFO]: Epoch 051 - training loss: 41176.3736, validation loss: 0.2238
2024-05-22 19:41:33 [INFO]: Epoch 052 - training loss: 41164.6241, validation loss: 0.2120
2024-05-22 19:41:33 [INFO]: Epoch 053 - training loss: 41161.8701, validation loss: 0.2096
2024-05-22 19:41:33 [INFO]: Epoch 054 - training loss: 41164.3319, validation loss: 0.2102
2024-05-22 19:41:34 [INFO]: Epoch 055 - training loss: 41179.4439, validation loss: 0.2103
2024-05-22 19:41:34 [INFO]: Epoch 056 - training loss: 41162.0550, validation loss: 0.2129
2024-05-22 19:41:34 [INFO]: Epoch 057 - training loss: 41175.1950, validation loss: 0.2369
2024-05-22 19:41:34 [INFO]: Epoch 058 - training loss: 41166.3358, validation loss: 0.2139
2024-05-22 19:41:35 [INFO]: Epoch 059 - training loss: 41162.8079, validation loss: 0.2097
2024-05-22 19:41:35 [INFO]: Epoch 060 - training loss: 41160.1215, validation loss: 0.2227
2024-05-22 19:41:35 [INFO]: Epoch 061 - training loss: 41173.2238, validation loss: 0.2219
2024-05-22 19:41:35 [INFO]: Epoch 062 - training loss: 41164.0997, validation loss: 0.2202
2024-05-22 19:41:36 [INFO]: Epoch 063 - training loss: 41165.2772, validation loss: 0.2296
2024-05-22 19:41:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 19:41:36 [INFO]: Finished training. The best model is from epoch#53.
2024-05-22 19:41:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/GPVAE_air_quality/20240522_T194120/GPVAE.pypots
2024-05-22 19:41:36 [INFO]: GP-VAE on Air-Quality: MAE=0.2855, MSE=0.2523
2024-05-22 19:41:36 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/GPVAE_air_quality/imputation.pkl
2024-05-22 19:41:36 [INFO]: Using the given device: cuda:0
2024-05-22 19:41:36 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/USGAN_air_quality/20240522_T194136
2024-05-22 19:41:36 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/USGAN_air_quality/20240522_T194136/tensorboard
2024-05-22 19:41:36 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-22 19:41:40 [INFO]: Epoch 001 - generator training loss: 0.6108, discriminator training loss: 0.2864, validation loss: 0.4870
2024-05-22 19:41:43 [INFO]: Epoch 002 - generator training loss: 0.2979, discriminator training loss: 0.0677, validation loss: 0.3625
2024-05-22 19:41:46 [INFO]: Epoch 003 - generator training loss: 0.2209, discriminator training loss: 0.0628, validation loss: 0.2975
2024-05-22 19:41:50 [INFO]: Epoch 004 - generator training loss: 0.1823, discriminator training loss: 0.0629, validation loss: 0.2629
2024-05-22 19:41:53 [INFO]: Epoch 005 - generator training loss: 0.1569, discriminator training loss: 0.0624, validation loss: 0.2356
2024-05-22 19:41:57 [INFO]: Epoch 006 - generator training loss: 0.1394, discriminator training loss: 0.0610, validation loss: 0.2180
2024-05-22 19:42:00 [INFO]: Epoch 007 - generator training loss: 0.1301, discriminator training loss: 0.0604, validation loss: 0.2045
2024-05-22 19:42:04 [INFO]: Epoch 008 - generator training loss: 0.1160, discriminator training loss: 0.0596, validation loss: 0.1920
2024-05-22 19:42:07 [INFO]: Epoch 009 - generator training loss: 0.1071, discriminator training loss: 0.0594, validation loss: 0.1828
2024-05-22 19:42:10 [INFO]: Epoch 010 - generator training loss: 0.1003, discriminator training loss: 0.0581, validation loss: 0.1753
2024-05-22 19:42:14 [INFO]: Epoch 011 - generator training loss: 0.0927, discriminator training loss: 0.0570, validation loss: 0.1683
2024-05-22 19:42:17 [INFO]: Epoch 012 - generator training loss: 0.0881, discriminator training loss: 0.0556, validation loss: 0.1633
2024-05-22 19:42:21 [INFO]: Epoch 013 - generator training loss: 0.0853, discriminator training loss: 0.0540, validation loss: 0.1588
2024-05-22 19:42:24 [INFO]: Epoch 014 - generator training loss: 0.0822, discriminator training loss: 0.0522, validation loss: 0.1553
2024-05-22 19:42:28 [INFO]: Epoch 015 - generator training loss: 0.0790, discriminator training loss: 0.0505, validation loss: 0.1513
2024-05-22 19:42:31 [INFO]: Epoch 016 - generator training loss: 0.0771, discriminator training loss: 0.0486, validation loss: 0.1488
2024-05-22 19:42:34 [INFO]: Epoch 017 - generator training loss: 0.0750, discriminator training loss: 0.0472, validation loss: 0.1455
2024-05-22 19:42:38 [INFO]: Epoch 018 - generator training loss: 0.0736, discriminator training loss: 0.0469, validation loss: 0.1433
2024-05-22 19:42:41 [INFO]: Epoch 019 - generator training loss: 0.0699, discriminator training loss: 0.0456, validation loss: 0.1414
2024-05-22 19:42:45 [INFO]: Epoch 020 - generator training loss: 0.0716, discriminator training loss: 0.0448, validation loss: 0.1395
2024-05-22 19:42:48 [INFO]: Epoch 021 - generator training loss: 0.0675, discriminator training loss: 0.0435, validation loss: 0.1367
2024-05-22 19:42:52 [INFO]: Epoch 022 - generator training loss: 0.0658, discriminator training loss: 0.0435, validation loss: 0.1352
2024-05-22 19:42:55 [INFO]: Epoch 023 - generator training loss: 0.0641, discriminator training loss: 0.0422, validation loss: 0.1333
2024-05-22 19:42:58 [INFO]: Epoch 024 - generator training loss: 0.0616, discriminator training loss: 0.0425, validation loss: 0.1318
2024-05-22 19:43:02 [INFO]: Epoch 025 - generator training loss: 0.0642, discriminator training loss: 0.0417, validation loss: 0.1307
2024-05-22 19:43:05 [INFO]: Epoch 026 - generator training loss: 0.0595, discriminator training loss: 0.0405, validation loss: 0.1300
2024-05-22 19:43:09 [INFO]: Epoch 027 - generator training loss: 0.0585, discriminator training loss: 0.0396, validation loss: 0.1285
2024-05-22 19:43:12 [INFO]: Epoch 028 - generator training loss: 0.0577, discriminator training loss: 0.0386, validation loss: 0.1277
2024-05-22 19:43:16 [INFO]: Epoch 029 - generator training loss: 0.0578, discriminator training loss: 0.0380, validation loss: 0.1264
2024-05-22 19:43:19 [INFO]: Epoch 030 - generator training loss: 0.0582, discriminator training loss: 0.0372, validation loss: 0.1258
2024-05-22 19:43:22 [INFO]: Epoch 031 - generator training loss: 0.0563, discriminator training loss: 0.0362, validation loss: 0.1243
2024-05-22 19:43:26 [INFO]: Epoch 032 - generator training loss: 0.0553, discriminator training loss: 0.0356, validation loss: 0.1241
2024-05-22 19:43:29 [INFO]: Epoch 033 - generator training loss: 0.0557, discriminator training loss: 0.0347, validation loss: 0.1224
2024-05-22 19:43:33 [INFO]: Epoch 034 - generator training loss: 0.0563, discriminator training loss: 0.0336, validation loss: 0.1215
2024-05-22 19:43:36 [INFO]: Epoch 035 - generator training loss: 0.0546, discriminator training loss: 0.0327, validation loss: 0.1209
2024-05-22 19:43:40 [INFO]: Epoch 036 - generator training loss: 0.0548, discriminator training loss: 0.0322, validation loss: 0.1203
2024-05-22 19:43:43 [INFO]: Epoch 037 - generator training loss: 0.0534, discriminator training loss: 0.0315, validation loss: 0.1194
2024-05-22 19:43:46 [INFO]: Epoch 038 - generator training loss: 0.0550, discriminator training loss: 0.0309, validation loss: 0.1185
2024-05-22 19:43:50 [INFO]: Epoch 039 - generator training loss: 0.0525, discriminator training loss: 0.0304, validation loss: 0.1178
2024-05-22 19:43:53 [INFO]: Epoch 040 - generator training loss: 0.0521, discriminator training loss: 0.0298, validation loss: 0.1167
2024-05-22 19:43:57 [INFO]: Epoch 041 - generator training loss: 0.0536, discriminator training loss: 0.0287, validation loss: 0.1163
2024-05-22 19:44:00 [INFO]: Epoch 042 - generator training loss: 0.0508, discriminator training loss: 0.0285, validation loss: 0.1150
2024-05-22 19:44:04 [INFO]: Epoch 043 - generator training loss: 0.0504, discriminator training loss: 0.0283, validation loss: 0.1147
2024-05-22 19:44:07 [INFO]: Epoch 044 - generator training loss: 0.0505, discriminator training loss: 0.0275, validation loss: 0.1137
2024-05-22 19:44:10 [INFO]: Epoch 045 - generator training loss: 0.0503, discriminator training loss: 0.0269, validation loss: 0.1135
2024-05-22 19:44:14 [INFO]: Epoch 046 - generator training loss: 0.0496, discriminator training loss: 0.0266, validation loss: 0.1130
2024-05-22 19:44:17 [INFO]: Epoch 047 - generator training loss: 0.0498, discriminator training loss: 0.0260, validation loss: 0.1122
2024-05-22 19:44:21 [INFO]: Epoch 048 - generator training loss: 0.0496, discriminator training loss: 0.0256, validation loss: 0.1124
2024-05-22 19:44:24 [INFO]: Epoch 049 - generator training loss: 0.0493, discriminator training loss: 0.0254, validation loss: 0.1113
2024-05-22 19:44:28 [INFO]: Epoch 050 - generator training loss: 0.0489, discriminator training loss: 0.0251, validation loss: 0.1110
2024-05-22 19:44:31 [INFO]: Epoch 051 - generator training loss: 0.0485, discriminator training loss: 0.0244, validation loss: 0.1102
2024-05-22 19:44:34 [INFO]: Epoch 052 - generator training loss: 0.0483, discriminator training loss: 0.0245, validation loss: 0.1094
2024-05-22 19:44:38 [INFO]: Epoch 053 - generator training loss: 0.0482, discriminator training loss: 0.0238, validation loss: 0.1112
2024-05-22 19:44:41 [INFO]: Epoch 054 - generator training loss: 0.0485, discriminator training loss: 0.0235, validation loss: 0.1089
2024-05-22 19:44:45 [INFO]: Epoch 055 - generator training loss: 0.0471, discriminator training loss: 0.0231, validation loss: 0.1087
2024-05-22 19:44:48 [INFO]: Epoch 056 - generator training loss: 0.0478, discriminator training loss: 0.0226, validation loss: 0.1078
2024-05-22 19:44:52 [INFO]: Epoch 057 - generator training loss: 0.0477, discriminator training loss: 0.0224, validation loss: 0.1075
2024-05-22 19:44:55 [INFO]: Epoch 058 - generator training loss: 0.0464, discriminator training loss: 0.0221, validation loss: 0.1080
2024-05-22 19:44:58 [INFO]: Epoch 059 - generator training loss: 0.0488, discriminator training loss: 0.0217, validation loss: 0.1079
2024-05-22 19:45:02 [INFO]: Epoch 060 - generator training loss: 0.0468, discriminator training loss: 0.0215, validation loss: 0.1068
2024-05-22 19:45:05 [INFO]: Epoch 061 - generator training loss: 0.0462, discriminator training loss: 0.0213, validation loss: 0.1064
2024-05-22 19:45:09 [INFO]: Epoch 062 - generator training loss: 0.0452, discriminator training loss: 0.0211, validation loss: 0.1065
2024-05-22 19:45:12 [INFO]: Epoch 063 - generator training loss: 0.0464, discriminator training loss: 0.0212, validation loss: 0.1059
2024-05-22 19:45:16 [INFO]: Epoch 064 - generator training loss: 0.0444, discriminator training loss: 0.0206, validation loss: 0.1054
2024-05-22 19:45:19 [INFO]: Epoch 065 - generator training loss: 0.0451, discriminator training loss: 0.0204, validation loss: 0.1054
2024-05-22 19:45:22 [INFO]: Epoch 066 - generator training loss: 0.0443, discriminator training loss: 0.0199, validation loss: 0.1047
2024-05-22 19:45:26 [INFO]: Epoch 067 - generator training loss: 0.0451, discriminator training loss: 0.0196, validation loss: 0.1050
2024-05-22 19:45:29 [INFO]: Epoch 068 - generator training loss: 0.0457, discriminator training loss: 0.0196, validation loss: 0.1048
2024-05-22 19:45:33 [INFO]: Epoch 069 - generator training loss: 0.0449, discriminator training loss: 0.0195, validation loss: 0.1042
2024-05-22 19:45:36 [INFO]: Epoch 070 - generator training loss: 0.0440, discriminator training loss: 0.0194, validation loss: 0.1032
2024-05-22 19:45:39 [INFO]: Epoch 071 - generator training loss: 0.0432, discriminator training loss: 0.0194, validation loss: 0.1030
2024-05-22 19:45:43 [INFO]: Epoch 072 - generator training loss: 0.0441, discriminator training loss: 0.0191, validation loss: 0.1032
2024-05-22 19:45:46 [INFO]: Epoch 073 - generator training loss: 0.0428, discriminator training loss: 0.0187, validation loss: 0.1027
2024-05-22 19:45:50 [INFO]: Epoch 074 - generator training loss: 0.0429, discriminator training loss: 0.0186, validation loss: 0.1029
2024-05-22 19:45:53 [INFO]: Epoch 075 - generator training loss: 0.0430, discriminator training loss: 0.0185, validation loss: 0.1027
2024-05-22 19:45:57 [INFO]: Epoch 076 - generator training loss: 0.0433, discriminator training loss: 0.0182, validation loss: 0.1026
2024-05-22 19:46:00 [INFO]: Epoch 077 - generator training loss: 0.0421, discriminator training loss: 0.0182, validation loss: 0.1029
2024-05-22 19:46:04 [INFO]: Epoch 078 - generator training loss: 0.0419, discriminator training loss: 0.0180, validation loss: 0.1023
2024-05-22 19:46:07 [INFO]: Epoch 079 - generator training loss: 0.0417, discriminator training loss: 0.0178, validation loss: 0.1017
2024-05-22 19:46:10 [INFO]: Epoch 080 - generator training loss: 0.0418, discriminator training loss: 0.0177, validation loss: 0.1018
2024-05-22 19:46:14 [INFO]: Epoch 081 - generator training loss: 0.0427, discriminator training loss: 0.0176, validation loss: 0.1015
2024-05-22 19:46:17 [INFO]: Epoch 082 - generator training loss: 0.0414, discriminator training loss: 0.0175, validation loss: 0.1023
2024-05-22 19:46:21 [INFO]: Epoch 083 - generator training loss: 0.0412, discriminator training loss: 0.0174, validation loss: 0.1026
2024-05-22 19:46:24 [INFO]: Epoch 084 - generator training loss: 0.0407, discriminator training loss: 0.0172, validation loss: 0.1020
2024-05-22 19:46:28 [INFO]: Epoch 085 - generator training loss: 0.0401, discriminator training loss: 0.0172, validation loss: 0.1017
2024-05-22 19:46:31 [INFO]: Epoch 086 - generator training loss: 0.0400, discriminator training loss: 0.0170, validation loss: 0.1012
2024-05-22 19:46:34 [INFO]: Epoch 087 - generator training loss: 0.0398, discriminator training loss: 0.0168, validation loss: 0.1015
2024-05-22 19:46:38 [INFO]: Epoch 088 - generator training loss: 0.0404, discriminator training loss: 0.0168, validation loss: 0.1008
2024-05-22 19:46:41 [INFO]: Epoch 089 - generator training loss: 0.0398, discriminator training loss: 0.0166, validation loss: 0.1014
2024-05-22 19:46:45 [INFO]: Epoch 090 - generator training loss: 0.0406, discriminator training loss: 0.0169, validation loss: 0.1017
2024-05-22 19:46:48 [INFO]: Epoch 091 - generator training loss: 0.0392, discriminator training loss: 0.0164, validation loss: 0.1016
2024-05-22 19:46:52 [INFO]: Epoch 092 - generator training loss: 0.0399, discriminator training loss: 0.0165, validation loss: 0.1012
2024-05-22 19:46:55 [INFO]: Epoch 093 - generator training loss: 0.0394, discriminator training loss: 0.0160, validation loss: 0.1006
2024-05-22 19:46:58 [INFO]: Epoch 094 - generator training loss: 0.0389, discriminator training loss: 0.0160, validation loss: 0.1014
2024-05-22 19:47:02 [INFO]: Epoch 095 - generator training loss: 0.0389, discriminator training loss: 0.0161, validation loss: 0.1008
2024-05-22 19:47:05 [INFO]: Epoch 096 - generator training loss: 0.0410, discriminator training loss: 0.0159, validation loss: 0.1011
2024-05-22 19:47:09 [INFO]: Epoch 097 - generator training loss: 0.0404, discriminator training loss: 0.0160, validation loss: 0.1012
2024-05-22 19:47:12 [INFO]: Epoch 098 - generator training loss: 0.0393, discriminator training loss: 0.0157, validation loss: 0.1007
2024-05-22 19:47:16 [INFO]: Epoch 099 - generator training loss: 0.0380, discriminator training loss: 0.0155, validation loss: 0.1012
2024-05-22 19:47:19 [INFO]: Epoch 100 - generator training loss: 0.0381, discriminator training loss: 0.0153, validation loss: 0.1016
2024-05-22 19:47:22 [INFO]: Epoch 101 - generator training loss: 0.0375, discriminator training loss: 0.0154, validation loss: 0.1031
2024-05-22 19:47:26 [INFO]: Epoch 102 - generator training loss: 0.0395, discriminator training loss: 0.0155, validation loss: 0.1016
2024-05-22 19:47:29 [INFO]: Epoch 103 - generator training loss: 0.0387, discriminator training loss: 0.0155, validation loss: 0.1006
2024-05-22 19:47:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 19:47:29 [INFO]: Finished training. The best model is from epoch#93.
2024-05-22 19:47:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/USGAN_air_quality/20240522_T194136/USGAN.pypots
2024-05-22 19:47:30 [INFO]: US-GAN on Air-Quality: MAE=0.1728, MSE=0.1134
2024-05-22 19:47:30 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/USGAN_air_quality/imputation.pkl
2024-05-22 19:47:30 [INFO]: Using the given device: cuda:0
2024-05-22 19:47:30 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/BRITS_air_quality/20240522_T194730
2024-05-22 19:47:30 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/BRITS_air_quality/20240522_T194730/tensorboard
2024-05-22 19:47:30 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-22 19:47:33 [INFO]: Epoch 001 - training loss: 1.3916, validation loss: 0.9048
2024-05-22 19:47:35 [INFO]: Epoch 002 - training loss: 1.1215, validation loss: 0.6787
2024-05-22 19:47:37 [INFO]: Epoch 003 - training loss: 0.9351, validation loss: 0.5675
2024-05-22 19:47:40 [INFO]: Epoch 004 - training loss: 0.8281, validation loss: 0.5008
2024-05-22 19:47:42 [INFO]: Epoch 005 - training loss: 0.7524, validation loss: 0.4521
2024-05-22 19:47:44 [INFO]: Epoch 006 - training loss: 0.6963, validation loss: 0.4138
2024-05-22 19:47:46 [INFO]: Epoch 007 - training loss: 0.6527, validation loss: 0.3864
2024-05-22 19:47:49 [INFO]: Epoch 008 - training loss: 0.6187, validation loss: 0.3625
2024-05-22 19:47:51 [INFO]: Epoch 009 - training loss: 0.5922, validation loss: 0.3429
2024-05-22 19:47:53 [INFO]: Epoch 010 - training loss: 0.5736, validation loss: 0.3262
2024-05-22 19:47:56 [INFO]: Epoch 011 - training loss: 0.5554, validation loss: 0.3136
2024-05-22 19:47:58 [INFO]: Epoch 012 - training loss: 0.5399, validation loss: 0.3009
2024-05-22 19:48:00 [INFO]: Epoch 013 - training loss: 0.5257, validation loss: 0.2912
2024-05-22 19:48:03 [INFO]: Epoch 014 - training loss: 0.5158, validation loss: 0.2821
2024-05-22 19:48:05 [INFO]: Epoch 015 - training loss: 0.5050, validation loss: 0.2738
2024-05-22 19:48:07 [INFO]: Epoch 016 - training loss: 0.4948, validation loss: 0.2672
2024-05-22 19:48:10 [INFO]: Epoch 017 - training loss: 0.4856, validation loss: 0.2603
2024-05-22 19:48:12 [INFO]: Epoch 018 - training loss: 0.4768, validation loss: 0.2545
2024-05-22 19:48:14 [INFO]: Epoch 019 - training loss: 0.4695, validation loss: 0.2493
2024-05-22 19:48:16 [INFO]: Epoch 020 - training loss: 0.4623, validation loss: 0.2438
2024-05-22 19:48:19 [INFO]: Epoch 021 - training loss: 0.4546, validation loss: 0.2395
2024-05-22 19:48:21 [INFO]: Epoch 022 - training loss: 0.4483, validation loss: 0.2352
2024-05-22 19:48:23 [INFO]: Epoch 023 - training loss: 0.4417, validation loss: 0.2307
2024-05-22 19:48:26 [INFO]: Epoch 024 - training loss: 0.4360, validation loss: 0.2267
2024-05-22 19:48:28 [INFO]: Epoch 025 - training loss: 0.4311, validation loss: 0.2230
2024-05-22 19:48:30 [INFO]: Epoch 026 - training loss: 0.4245, validation loss: 0.2194
2024-05-22 19:48:32 [INFO]: Epoch 027 - training loss: 0.4204, validation loss: 0.2155
2024-05-22 19:48:35 [INFO]: Epoch 028 - training loss: 0.4145, validation loss: 0.2120
2024-05-22 19:48:37 [INFO]: Epoch 029 - training loss: 0.4100, validation loss: 0.2086
2024-05-22 19:48:39 [INFO]: Epoch 030 - training loss: 0.4051, validation loss: 0.2054
2024-05-22 19:48:42 [INFO]: Epoch 031 - training loss: 0.4010, validation loss: 0.2023
2024-05-22 19:48:44 [INFO]: Epoch 032 - training loss: 0.3965, validation loss: 0.1992
2024-05-22 19:48:46 [INFO]: Epoch 033 - training loss: 0.3913, validation loss: 0.1963
2024-05-22 19:48:49 [INFO]: Epoch 034 - training loss: 0.3880, validation loss: 0.1934
2024-05-22 19:48:51 [INFO]: Epoch 035 - training loss: 0.3845, validation loss: 0.1902
2024-05-22 19:48:53 [INFO]: Epoch 036 - training loss: 0.3810, validation loss: 0.1879
2024-05-22 19:48:55 [INFO]: Epoch 037 - training loss: 0.3761, validation loss: 0.1850
2024-05-22 19:48:58 [INFO]: Epoch 038 - training loss: 0.3730, validation loss: 0.1828
2024-05-22 19:49:00 [INFO]: Epoch 039 - training loss: 0.3698, validation loss: 0.1805
2024-05-22 19:49:02 [INFO]: Epoch 040 - training loss: 0.3664, validation loss: 0.1777
2024-05-22 19:49:05 [INFO]: Epoch 041 - training loss: 0.3634, validation loss: 0.1758
2024-05-22 19:49:07 [INFO]: Epoch 042 - training loss: 0.3605, validation loss: 0.1734
2024-05-22 19:49:09 [INFO]: Epoch 043 - training loss: 0.3572, validation loss: 0.1713
2024-05-22 19:49:11 [INFO]: Epoch 044 - training loss: 0.3550, validation loss: 0.1694
2024-05-22 19:49:14 [INFO]: Epoch 045 - training loss: 0.3516, validation loss: 0.1677
2024-05-22 19:49:16 [INFO]: Epoch 046 - training loss: 0.3493, validation loss: 0.1661
2024-05-22 19:49:18 [INFO]: Epoch 047 - training loss: 0.3469, validation loss: 0.1646
2024-05-22 19:49:21 [INFO]: Epoch 048 - training loss: 0.3443, validation loss: 0.1627
2024-05-22 19:49:23 [INFO]: Epoch 049 - training loss: 0.3416, validation loss: 0.1613
2024-05-22 19:49:25 [INFO]: Epoch 050 - training loss: 0.3400, validation loss: 0.1599
2024-05-22 19:49:28 [INFO]: Epoch 051 - training loss: 0.3372, validation loss: 0.1586
2024-05-22 19:49:30 [INFO]: Epoch 052 - training loss: 0.3348, validation loss: 0.1570
2024-05-22 19:49:32 [INFO]: Epoch 053 - training loss: 0.3331, validation loss: 0.1559
2024-05-22 19:49:35 [INFO]: Epoch 054 - training loss: 0.3309, validation loss: 0.1546
2024-05-22 19:49:37 [INFO]: Epoch 055 - training loss: 0.3291, validation loss: 0.1534
2024-05-22 19:49:39 [INFO]: Epoch 056 - training loss: 0.3276, validation loss: 0.1522
2024-05-22 19:49:42 [INFO]: Epoch 057 - training loss: 0.3253, validation loss: 0.1511
2024-05-22 19:49:44 [INFO]: Epoch 058 - training loss: 0.3238, validation loss: 0.1502
2024-05-22 19:49:46 [INFO]: Epoch 059 - training loss: 0.3221, validation loss: 0.1490
2024-05-22 19:49:48 [INFO]: Epoch 060 - training loss: 0.3206, validation loss: 0.1482
2024-05-22 19:49:51 [INFO]: Epoch 061 - training loss: 0.3185, validation loss: 0.1471
2024-05-22 19:49:53 [INFO]: Epoch 062 - training loss: 0.3164, validation loss: 0.1464
2024-05-22 19:49:55 [INFO]: Epoch 063 - training loss: 0.3153, validation loss: 0.1450
2024-05-22 19:49:58 [INFO]: Epoch 064 - training loss: 0.3140, validation loss: 0.1444
2024-05-22 19:50:00 [INFO]: Epoch 065 - training loss: 0.3132, validation loss: 0.1438
2024-05-22 19:50:02 [INFO]: Epoch 066 - training loss: 0.3110, validation loss: 0.1427
2024-05-22 19:50:05 [INFO]: Epoch 067 - training loss: 0.3105, validation loss: 0.1419
2024-05-22 19:50:07 [INFO]: Epoch 068 - training loss: 0.3086, validation loss: 0.1410
2024-05-22 19:50:09 [INFO]: Epoch 069 - training loss: 0.3067, validation loss: 0.1403
2024-05-22 19:50:12 [INFO]: Epoch 070 - training loss: 0.3055, validation loss: 0.1398
2024-05-22 19:50:14 [INFO]: Epoch 071 - training loss: 0.3043, validation loss: 0.1387
2024-05-22 19:50:16 [INFO]: Epoch 072 - training loss: 0.3038, validation loss: 0.1382
2024-05-22 19:50:19 [INFO]: Epoch 073 - training loss: 0.3022, validation loss: 0.1374
2024-05-22 19:50:21 [INFO]: Epoch 074 - training loss: 0.3013, validation loss: 0.1367
2024-05-22 19:50:23 [INFO]: Epoch 075 - training loss: 0.2997, validation loss: 0.1361
2024-05-22 19:50:25 [INFO]: Epoch 076 - training loss: 0.2990, validation loss: 0.1356
2024-05-22 19:50:28 [INFO]: Epoch 077 - training loss: 0.2980, validation loss: 0.1348
2024-05-22 19:50:30 [INFO]: Epoch 078 - training loss: 0.2971, validation loss: 0.1341
2024-05-22 19:50:32 [INFO]: Epoch 079 - training loss: 0.2957, validation loss: 0.1337
2024-05-22 19:50:35 [INFO]: Epoch 080 - training loss: 0.2950, validation loss: 0.1329
2024-05-22 19:50:37 [INFO]: Epoch 081 - training loss: 0.2943, validation loss: 0.1324
2024-05-22 19:50:39 [INFO]: Epoch 082 - training loss: 0.2931, validation loss: 0.1318
2024-05-22 19:50:41 [INFO]: Epoch 083 - training loss: 0.2924, validation loss: 0.1313
2024-05-22 19:50:44 [INFO]: Epoch 084 - training loss: 0.2917, validation loss: 0.1307
2024-05-22 19:50:46 [INFO]: Epoch 085 - training loss: 0.2908, validation loss: 0.1302
2024-05-22 19:50:48 [INFO]: Epoch 086 - training loss: 0.2899, validation loss: 0.1296
2024-05-22 19:50:51 [INFO]: Epoch 087 - training loss: 0.2887, validation loss: 0.1291
2024-05-22 19:50:53 [INFO]: Epoch 088 - training loss: 0.2876, validation loss: 0.1284
2024-05-22 19:50:55 [INFO]: Epoch 089 - training loss: 0.2880, validation loss: 0.1279
2024-05-22 19:50:58 [INFO]: Epoch 090 - training loss: 0.2878, validation loss: 0.1274
2024-05-22 19:51:00 [INFO]: Epoch 091 - training loss: 0.2858, validation loss: 0.1270
2024-05-22 19:51:02 [INFO]: Epoch 092 - training loss: 0.2852, validation loss: 0.1266
2024-05-22 19:51:04 [INFO]: Epoch 093 - training loss: 0.2850, validation loss: 0.1258
2024-05-22 19:51:07 [INFO]: Epoch 094 - training loss: 0.2842, validation loss: 0.1256
2024-05-22 19:51:09 [INFO]: Epoch 095 - training loss: 0.2829, validation loss: 0.1252
2024-05-22 19:51:11 [INFO]: Epoch 096 - training loss: 0.2824, validation loss: 0.1248
2024-05-22 19:51:14 [INFO]: Epoch 097 - training loss: 0.2817, validation loss: 0.1243
2024-05-22 19:51:16 [INFO]: Epoch 098 - training loss: 0.2811, validation loss: 0.1240
2024-05-22 19:51:18 [INFO]: Epoch 099 - training loss: 0.2805, validation loss: 0.1234
2024-05-22 19:51:21 [INFO]: Epoch 100 - training loss: 0.2796, validation loss: 0.1229
2024-05-22 19:51:23 [INFO]: Epoch 101 - training loss: 0.2793, validation loss: 0.1229
2024-05-22 19:51:25 [INFO]: Epoch 102 - training loss: 0.2789, validation loss: 0.1222
2024-05-22 19:51:28 [INFO]: Epoch 103 - training loss: 0.2779, validation loss: 0.1220
2024-05-22 19:51:30 [INFO]: Epoch 104 - training loss: 0.2777, validation loss: 0.1215
2024-05-22 19:51:32 [INFO]: Epoch 105 - training loss: 0.2773, validation loss: 0.1212
2024-05-22 19:51:34 [INFO]: Epoch 106 - training loss: 0.2755, validation loss: 0.1207
2024-05-22 19:51:37 [INFO]: Epoch 107 - training loss: 0.2761, validation loss: 0.1205
2024-05-22 19:51:39 [INFO]: Epoch 108 - training loss: 0.2750, validation loss: 0.1201
2024-05-22 19:51:41 [INFO]: Epoch 109 - training loss: 0.2742, validation loss: 0.1196
2024-05-22 19:51:44 [INFO]: Epoch 110 - training loss: 0.2737, validation loss: 0.1195
2024-05-22 19:51:46 [INFO]: Epoch 111 - training loss: 0.2727, validation loss: 0.1190
2024-05-22 19:51:48 [INFO]: Epoch 112 - training loss: 0.2728, validation loss: 0.1189
2024-05-22 19:51:51 [INFO]: Epoch 113 - training loss: 0.2719, validation loss: 0.1184
2024-05-22 19:51:53 [INFO]: Epoch 114 - training loss: 0.2715, validation loss: 0.1181
2024-05-22 19:51:55 [INFO]: Epoch 115 - training loss: 0.2713, validation loss: 0.1176
2024-05-22 19:51:57 [INFO]: Epoch 116 - training loss: 0.2706, validation loss: 0.1174
2024-05-22 19:52:00 [INFO]: Epoch 117 - training loss: 0.2707, validation loss: 0.1170
2024-05-22 19:52:02 [INFO]: Epoch 118 - training loss: 0.2694, validation loss: 0.1167
2024-05-22 19:52:04 [INFO]: Epoch 119 - training loss: 0.2694, validation loss: 0.1163
2024-05-22 19:52:07 [INFO]: Epoch 120 - training loss: 0.2690, validation loss: 0.1162
2024-05-22 19:52:09 [INFO]: Epoch 121 - training loss: 0.2684, validation loss: 0.1158
2024-05-22 19:52:11 [INFO]: Epoch 122 - training loss: 0.2686, validation loss: 0.1154
2024-05-22 19:52:13 [INFO]: Epoch 123 - training loss: 0.2669, validation loss: 0.1148
2024-05-22 19:52:16 [INFO]: Epoch 124 - training loss: 0.2672, validation loss: 0.1146
2024-05-22 19:52:18 [INFO]: Epoch 125 - training loss: 0.2659, validation loss: 0.1145
2024-05-22 19:52:20 [INFO]: Epoch 126 - training loss: 0.2660, validation loss: 0.1140
2024-05-22 19:52:23 [INFO]: Epoch 127 - training loss: 0.2658, validation loss: 0.1137
2024-05-22 19:52:25 [INFO]: Epoch 128 - training loss: 0.2653, validation loss: 0.1135
2024-05-22 19:52:27 [INFO]: Epoch 129 - training loss: 0.2647, validation loss: 0.1132
2024-05-22 19:52:30 [INFO]: Epoch 130 - training loss: 0.2639, validation loss: 0.1130
2024-05-22 19:52:32 [INFO]: Epoch 131 - training loss: 0.2639, validation loss: 0.1127
2024-05-22 19:52:34 [INFO]: Epoch 132 - training loss: 0.2634, validation loss: 0.1125
2024-05-22 19:52:36 [INFO]: Epoch 133 - training loss: 0.2629, validation loss: 0.1121
2024-05-22 19:52:39 [INFO]: Epoch 134 - training loss: 0.2624, validation loss: 0.1120
2024-05-22 19:52:41 [INFO]: Epoch 135 - training loss: 0.2625, validation loss: 0.1116
2024-05-22 19:52:43 [INFO]: Epoch 136 - training loss: 0.2613, validation loss: 0.1112
2024-05-22 19:52:46 [INFO]: Epoch 137 - training loss: 0.2614, validation loss: 0.1109
2024-05-22 19:52:48 [INFO]: Epoch 138 - training loss: 0.2608, validation loss: 0.1108
2024-05-22 19:52:50 [INFO]: Epoch 139 - training loss: 0.2606, validation loss: 0.1105
2024-05-22 19:52:52 [INFO]: Epoch 140 - training loss: 0.2605, validation loss: 0.1101
2024-05-22 19:52:55 [INFO]: Epoch 141 - training loss: 0.2597, validation loss: 0.1099
2024-05-22 19:52:57 [INFO]: Epoch 142 - training loss: 0.2594, validation loss: 0.1097
2024-05-22 19:52:59 [INFO]: Epoch 143 - training loss: 0.2596, validation loss: 0.1095
2024-05-22 19:53:02 [INFO]: Epoch 144 - training loss: 0.2590, validation loss: 0.1091
2024-05-22 19:53:04 [INFO]: Epoch 145 - training loss: 0.2583, validation loss: 0.1089
2024-05-22 19:53:06 [INFO]: Epoch 146 - training loss: 0.2583, validation loss: 0.1088
2024-05-22 19:53:09 [INFO]: Epoch 147 - training loss: 0.2577, validation loss: 0.1086
2024-05-22 19:53:11 [INFO]: Epoch 148 - training loss: 0.2575, validation loss: 0.1083
2024-05-22 19:53:13 [INFO]: Epoch 149 - training loss: 0.2574, validation loss: 0.1081
2024-05-22 19:53:16 [INFO]: Epoch 150 - training loss: 0.2562, validation loss: 0.1078
2024-05-22 19:53:18 [INFO]: Epoch 151 - training loss: 0.2567, validation loss: 0.1076
2024-05-22 19:53:20 [INFO]: Epoch 152 - training loss: 0.2561, validation loss: 0.1074
2024-05-22 19:53:22 [INFO]: Epoch 153 - training loss: 0.2557, validation loss: 0.1071
2024-05-22 19:53:25 [INFO]: Epoch 154 - training loss: 0.2551, validation loss: 0.1071
2024-05-22 19:53:27 [INFO]: Epoch 155 - training loss: 0.2549, validation loss: 0.1068
2024-05-22 19:53:29 [INFO]: Epoch 156 - training loss: 0.2545, validation loss: 0.1066
2024-05-22 19:53:32 [INFO]: Epoch 157 - training loss: 0.2546, validation loss: 0.1063
2024-05-22 19:53:34 [INFO]: Epoch 158 - training loss: 0.2542, validation loss: 0.1061
2024-05-22 19:53:36 [INFO]: Epoch 159 - training loss: 0.2537, validation loss: 0.1058
2024-05-22 19:53:39 [INFO]: Epoch 160 - training loss: 0.2538, validation loss: 0.1057
2024-05-22 19:53:41 [INFO]: Epoch 161 - training loss: 0.2534, validation loss: 0.1056
2024-05-22 19:53:43 [INFO]: Epoch 162 - training loss: 0.2533, validation loss: 0.1054
2024-05-22 19:53:45 [INFO]: Epoch 163 - training loss: 0.2529, validation loss: 0.1052
2024-05-22 19:53:48 [INFO]: Epoch 164 - training loss: 0.2533, validation loss: 0.1051
2024-05-22 19:53:50 [INFO]: Epoch 165 - training loss: 0.2524, validation loss: 0.1047
2024-05-22 19:53:52 [INFO]: Epoch 166 - training loss: 0.2516, validation loss: 0.1045
2024-05-22 19:53:55 [INFO]: Epoch 167 - training loss: 0.2519, validation loss: 0.1044
2024-05-22 19:53:57 [INFO]: Epoch 168 - training loss: 0.2514, validation loss: 0.1043
2024-05-22 19:53:59 [INFO]: Epoch 169 - training loss: 0.2511, validation loss: 0.1041
2024-05-22 19:54:01 [INFO]: Epoch 170 - training loss: 0.2507, validation loss: 0.1041
2024-05-22 19:54:04 [INFO]: Epoch 171 - training loss: 0.2510, validation loss: 0.1036
2024-05-22 19:54:06 [INFO]: Epoch 172 - training loss: 0.2499, validation loss: 0.1033
2024-05-22 19:54:08 [INFO]: Epoch 173 - training loss: 0.2498, validation loss: 0.1032
2024-05-22 19:54:11 [INFO]: Epoch 174 - training loss: 0.2498, validation loss: 0.1032
2024-05-22 19:54:13 [INFO]: Epoch 175 - training loss: 0.2496, validation loss: 0.1031
2024-05-22 19:54:15 [INFO]: Epoch 176 - training loss: 0.2496, validation loss: 0.1030
2024-05-22 19:54:18 [INFO]: Epoch 177 - training loss: 0.2496, validation loss: 0.1026
2024-05-22 19:54:20 [INFO]: Epoch 178 - training loss: 0.2485, validation loss: 0.1023
2024-05-22 19:54:22 [INFO]: Epoch 179 - training loss: 0.2483, validation loss: 0.1025
2024-05-22 19:54:24 [INFO]: Epoch 180 - training loss: 0.2484, validation loss: 0.1021
2024-05-22 19:54:27 [INFO]: Epoch 181 - training loss: 0.2476, validation loss: 0.1020
2024-05-22 19:54:29 [INFO]: Epoch 182 - training loss: 0.2477, validation loss: 0.1019
2024-05-22 19:54:31 [INFO]: Epoch 183 - training loss: 0.2472, validation loss: 0.1017
2024-05-22 19:54:34 [INFO]: Epoch 184 - training loss: 0.2476, validation loss: 0.1017
2024-05-22 19:54:36 [INFO]: Epoch 185 - training loss: 0.2469, validation loss: 0.1016
2024-05-22 19:54:38 [INFO]: Epoch 186 - training loss: 0.2468, validation loss: 0.1016
2024-05-22 19:54:41 [INFO]: Epoch 187 - training loss: 0.2469, validation loss: 0.1012
2024-05-22 19:54:43 [INFO]: Epoch 188 - training loss: 0.2462, validation loss: 0.1013
2024-05-22 19:54:45 [INFO]: Epoch 189 - training loss: 0.2464, validation loss: 0.1012
2024-05-22 19:54:48 [INFO]: Epoch 190 - training loss: 0.2459, validation loss: 0.1010
2024-05-22 19:54:50 [INFO]: Epoch 191 - training loss: 0.2456, validation loss: 0.1007
2024-05-22 19:54:52 [INFO]: Epoch 192 - training loss: 0.2456, validation loss: 0.1004
2024-05-22 19:54:54 [INFO]: Epoch 193 - training loss: 0.2455, validation loss: 0.1007
2024-05-22 19:54:57 [INFO]: Epoch 194 - training loss: 0.2452, validation loss: 0.1004
2024-05-22 19:54:59 [INFO]: Epoch 195 - training loss: 0.2447, validation loss: 0.1003
2024-05-22 19:55:01 [INFO]: Epoch 196 - training loss: 0.2450, validation loss: 0.1000
2024-05-22 19:55:04 [INFO]: Epoch 197 - training loss: 0.2445, validation loss: 0.1001
2024-05-22 19:55:06 [INFO]: Epoch 198 - training loss: 0.2440, validation loss: 0.1001
2024-05-22 19:55:08 [INFO]: Epoch 199 - training loss: 0.2443, validation loss: 0.0999
2024-05-22 19:55:10 [INFO]: Epoch 200 - training loss: 0.2438, validation loss: 0.0995
2024-05-22 19:55:13 [INFO]: Epoch 201 - training loss: 0.2433, validation loss: 0.0997
2024-05-22 19:55:15 [INFO]: Epoch 202 - training loss: 0.2431, validation loss: 0.0993
2024-05-22 19:55:17 [INFO]: Epoch 203 - training loss: 0.2428, validation loss: 0.0994
2024-05-22 19:55:20 [INFO]: Epoch 204 - training loss: 0.2432, validation loss: 0.0994
2024-05-22 19:55:22 [INFO]: Epoch 205 - training loss: 0.2429, validation loss: 0.0992
2024-05-22 19:55:24 [INFO]: Epoch 206 - training loss: 0.2422, validation loss: 0.0989
2024-05-22 19:55:27 [INFO]: Epoch 207 - training loss: 0.2426, validation loss: 0.0990
2024-05-22 19:55:29 [INFO]: Epoch 208 - training loss: 0.2421, validation loss: 0.0987
2024-05-22 19:55:31 [INFO]: Epoch 209 - training loss: 0.2423, validation loss: 0.0989
2024-05-22 19:55:33 [INFO]: Epoch 210 - training loss: 0.2424, validation loss: 0.0986
2024-05-22 19:55:36 [INFO]: Epoch 211 - training loss: 0.2416, validation loss: 0.0984
2024-05-22 19:55:38 [INFO]: Epoch 212 - training loss: 0.2415, validation loss: 0.0985
2024-05-22 19:55:40 [INFO]: Epoch 213 - training loss: 0.2416, validation loss: 0.0983
2024-05-22 19:55:43 [INFO]: Epoch 214 - training loss: 0.2410, validation loss: 0.0983
2024-05-22 19:55:45 [INFO]: Epoch 215 - training loss: 0.2409, validation loss: 0.0980
2024-05-22 19:55:47 [INFO]: Epoch 216 - training loss: 0.2409, validation loss: 0.0980
2024-05-22 19:55:49 [INFO]: Epoch 217 - training loss: 0.2403, validation loss: 0.0979
2024-05-22 19:55:52 [INFO]: Epoch 218 - training loss: 0.2409, validation loss: 0.0977
2024-05-22 19:55:54 [INFO]: Epoch 219 - training loss: 0.2403, validation loss: 0.0980
2024-05-22 19:55:56 [INFO]: Epoch 220 - training loss: 0.2401, validation loss: 0.0976
2024-05-22 19:55:59 [INFO]: Epoch 221 - training loss: 0.2396, validation loss: 0.0976
2024-05-22 19:56:01 [INFO]: Epoch 222 - training loss: 0.2401, validation loss: 0.0974
2024-05-22 19:56:03 [INFO]: Epoch 223 - training loss: 0.2390, validation loss: 0.0973
2024-05-22 19:56:06 [INFO]: Epoch 224 - training loss: 0.2390, validation loss: 0.0974
2024-05-22 19:56:08 [INFO]: Epoch 225 - training loss: 0.2393, validation loss: 0.0973
2024-05-22 19:56:10 [INFO]: Epoch 226 - training loss: 0.2393, validation loss: 0.0972
2024-05-22 19:56:12 [INFO]: Epoch 227 - training loss: 0.2393, validation loss: 0.0971
2024-05-22 19:56:15 [INFO]: Epoch 228 - training loss: 0.2390, validation loss: 0.0971
2024-05-22 19:56:17 [INFO]: Epoch 229 - training loss: 0.2387, validation loss: 0.0969
2024-05-22 19:56:19 [INFO]: Epoch 230 - training loss: 0.2379, validation loss: 0.0968
2024-05-22 19:56:22 [INFO]: Epoch 231 - training loss: 0.2379, validation loss: 0.0967
2024-05-22 19:56:24 [INFO]: Epoch 232 - training loss: 0.2379, validation loss: 0.0967
2024-05-22 19:56:26 [INFO]: Epoch 233 - training loss: 0.2379, validation loss: 0.0966
2024-05-22 19:56:29 [INFO]: Epoch 234 - training loss: 0.2381, validation loss: 0.0966
2024-05-22 19:56:31 [INFO]: Epoch 235 - training loss: 0.2382, validation loss: 0.0963
2024-05-22 19:56:33 [INFO]: Epoch 236 - training loss: 0.2371, validation loss: 0.0963
2024-05-22 19:56:35 [INFO]: Epoch 237 - training loss: 0.2379, validation loss: 0.0961
2024-05-22 19:56:38 [INFO]: Epoch 238 - training loss: 0.2373, validation loss: 0.0962
2024-05-22 19:56:40 [INFO]: Epoch 239 - training loss: 0.2368, validation loss: 0.0962
2024-05-22 19:56:42 [INFO]: Epoch 240 - training loss: 0.2371, validation loss: 0.0961
2024-05-22 19:56:45 [INFO]: Epoch 241 - training loss: 0.2367, validation loss: 0.0960
2024-05-22 19:56:47 [INFO]: Epoch 242 - training loss: 0.2371, validation loss: 0.0958
2024-05-22 19:56:49 [INFO]: Epoch 243 - training loss: 0.2369, validation loss: 0.0957
2024-05-22 19:56:52 [INFO]: Epoch 244 - training loss: 0.2360, validation loss: 0.0957
2024-05-22 19:56:54 [INFO]: Epoch 245 - training loss: 0.2358, validation loss: 0.0956
2024-05-22 19:56:56 [INFO]: Epoch 246 - training loss: 0.2359, validation loss: 0.0957
2024-05-22 19:56:58 [INFO]: Epoch 247 - training loss: 0.2362, validation loss: 0.0957
2024-05-22 19:57:01 [INFO]: Epoch 248 - training loss: 0.2355, validation loss: 0.0955
2024-05-22 19:57:03 [INFO]: Epoch 249 - training loss: 0.2354, validation loss: 0.0956
2024-05-22 19:57:05 [INFO]: Epoch 250 - training loss: 0.2354, validation loss: 0.0953
2024-05-22 19:57:08 [INFO]: Epoch 251 - training loss: 0.2349, validation loss: 0.0952
2024-05-22 19:57:10 [INFO]: Epoch 252 - training loss: 0.2352, validation loss: 0.0952
2024-05-22 19:57:12 [INFO]: Epoch 253 - training loss: 0.2351, validation loss: 0.0951
2024-05-22 19:57:15 [INFO]: Epoch 254 - training loss: 0.2348, validation loss: 0.0951
2024-05-22 19:57:17 [INFO]: Epoch 255 - training loss: 0.2345, validation loss: 0.0950
2024-05-22 19:57:19 [INFO]: Epoch 256 - training loss: 0.2347, validation loss: 0.0948
2024-05-22 19:57:21 [INFO]: Epoch 257 - training loss: 0.2347, validation loss: 0.0950
2024-05-22 19:57:24 [INFO]: Epoch 258 - training loss: 0.2342, validation loss: 0.0950
2024-05-22 19:57:26 [INFO]: Epoch 259 - training loss: 0.2344, validation loss: 0.0951
2024-05-22 19:57:28 [INFO]: Epoch 260 - training loss: 0.2350, validation loss: 0.0949
2024-05-22 19:57:31 [INFO]: Epoch 261 - training loss: 0.2344, validation loss: 0.0947
2024-05-22 19:57:33 [INFO]: Epoch 262 - training loss: 0.2338, validation loss: 0.0948
2024-05-22 19:57:35 [INFO]: Epoch 263 - training loss: 0.2339, validation loss: 0.0946
2024-05-22 19:57:38 [INFO]: Epoch 264 - training loss: 0.2340, validation loss: 0.0944
2024-05-22 19:57:40 [INFO]: Epoch 265 - training loss: 0.2339, validation loss: 0.0944
2024-05-22 19:57:42 [INFO]: Epoch 266 - training loss: 0.2334, validation loss: 0.0945
2024-05-22 19:57:44 [INFO]: Epoch 267 - training loss: 0.2333, validation loss: 0.0943
2024-05-22 19:57:47 [INFO]: Epoch 268 - training loss: 0.2333, validation loss: 0.0942
2024-05-22 19:57:49 [INFO]: Epoch 269 - training loss: 0.2327, validation loss: 0.0942
2024-05-22 19:57:51 [INFO]: Epoch 270 - training loss: 0.2326, validation loss: 0.0943
2024-05-22 19:57:54 [INFO]: Epoch 271 - training loss: 0.2327, validation loss: 0.0942
2024-05-22 19:57:56 [INFO]: Epoch 272 - training loss: 0.2324, validation loss: 0.0941
2024-05-22 19:57:58 [INFO]: Epoch 273 - training loss: 0.2321, validation loss: 0.0943
2024-05-22 19:58:00 [INFO]: Epoch 274 - training loss: 0.2325, validation loss: 0.0942
2024-05-22 19:58:03 [INFO]: Epoch 275 - training loss: 0.2322, validation loss: 0.0940
2024-05-22 19:58:05 [INFO]: Epoch 276 - training loss: 0.2317, validation loss: 0.0941
2024-05-22 19:58:07 [INFO]: Epoch 277 - training loss: 0.2320, validation loss: 0.0940
2024-05-22 19:58:10 [INFO]: Epoch 278 - training loss: 0.2320, validation loss: 0.0939
2024-05-22 19:58:12 [INFO]: Epoch 279 - training loss: 0.2319, validation loss: 0.0938
2024-05-22 19:58:14 [INFO]: Epoch 280 - training loss: 0.2311, validation loss: 0.0939
2024-05-22 19:58:17 [INFO]: Epoch 281 - training loss: 0.2315, validation loss: 0.0939
2024-05-22 19:58:19 [INFO]: Epoch 282 - training loss: 0.2319, validation loss: 0.0936
2024-05-22 19:58:21 [INFO]: Epoch 283 - training loss: 0.2312, validation loss: 0.0936
2024-05-22 19:58:24 [INFO]: Epoch 284 - training loss: 0.2309, validation loss: 0.0935
2024-05-22 19:58:26 [INFO]: Epoch 285 - training loss: 0.2308, validation loss: 0.0936
2024-05-22 19:58:28 [INFO]: Epoch 286 - training loss: 0.2309, validation loss: 0.0936
2024-05-22 19:58:30 [INFO]: Epoch 287 - training loss: 0.2305, validation loss: 0.0935
2024-05-22 19:58:33 [INFO]: Epoch 288 - training loss: 0.2312, validation loss: 0.0933
2024-05-22 19:58:35 [INFO]: Epoch 289 - training loss: 0.2312, validation loss: 0.0937
2024-05-22 19:58:37 [INFO]: Epoch 290 - training loss: 0.2304, validation loss: 0.0934
2024-05-22 19:58:40 [INFO]: Epoch 291 - training loss: 0.2306, validation loss: 0.0932
2024-05-22 19:58:42 [INFO]: Epoch 292 - training loss: 0.2303, validation loss: 0.0932
2024-05-22 19:58:44 [INFO]: Epoch 293 - training loss: 0.2300, validation loss: 0.0934
2024-05-22 19:58:46 [INFO]: Epoch 294 - training loss: 0.2302, validation loss: 0.0934
2024-05-22 19:58:49 [INFO]: Epoch 295 - training loss: 0.2298, validation loss: 0.0934
2024-05-22 19:58:51 [INFO]: Epoch 296 - training loss: 0.2298, validation loss: 0.0932
2024-05-22 19:58:53 [INFO]: Epoch 297 - training loss: 0.2297, validation loss: 0.0931
2024-05-22 19:58:56 [INFO]: Epoch 298 - training loss: 0.2297, validation loss: 0.0931
2024-05-22 19:58:58 [INFO]: Epoch 299 - training loss: 0.2295, validation loss: 0.0931
2024-05-22 19:59:00 [INFO]: Epoch 300 - training loss: 0.2296, validation loss: 0.0931
2024-05-22 19:59:00 [INFO]: Finished training. The best model is from epoch#299.
2024-05-22 19:59:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/BRITS_air_quality/20240522_T194730/BRITS.pypots
2024-05-22 19:59:01 [INFO]: BRITS on Air-Quality: MAE=0.1412, MSE=0.1058
2024-05-22 19:59:01 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/BRITS_air_quality/imputation.pkl
2024-05-22 19:59:01 [INFO]: Using the given device: cuda:0
2024-05-22 19:59:01 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901
2024-05-22 19:59:01 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/tensorboard
2024-05-22 19:59:01 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-22 19:59:04 [INFO]: Epoch 001 - training loss: 1.3647, validation loss: 0.7666
2024-05-22 19:59:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch1_loss0.7665806710720062.pypots
2024-05-22 19:59:08 [INFO]: Epoch 002 - training loss: 1.0375, validation loss: 0.7155
2024-05-22 19:59:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch2_loss0.7154699891805649.pypots
2024-05-22 19:59:11 [INFO]: Epoch 003 - training loss: 0.9747, validation loss: 0.6959
2024-05-22 19:59:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch3_loss0.6958722412586212.pypots
2024-05-22 19:59:14 [INFO]: Epoch 004 - training loss: 0.9685, validation loss: 0.6839
2024-05-22 19:59:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch4_loss0.68391914665699.pypots
2024-05-22 19:59:17 [INFO]: Epoch 005 - training loss: 0.9489, validation loss: 0.6767
2024-05-22 19:59:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch5_loss0.6766995877027512.pypots
2024-05-22 19:59:20 [INFO]: Epoch 006 - training loss: 0.9358, validation loss: 0.6702
2024-05-22 19:59:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch6_loss0.6701858609914779.pypots
2024-05-22 19:59:23 [INFO]: Epoch 007 - training loss: 0.9307, validation loss: 0.6657
2024-05-22 19:59:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch7_loss0.6657427787780762.pypots
2024-05-22 19:59:26 [INFO]: Epoch 008 - training loss: 0.9382, validation loss: 0.6624
2024-05-22 19:59:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch8_loss0.6624045103788376.pypots
2024-05-22 19:59:29 [INFO]: Epoch 009 - training loss: 0.9265, validation loss: 0.6593
2024-05-22 19:59:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch9_loss0.6592743784189224.pypots
2024-05-22 19:59:32 [INFO]: Epoch 010 - training loss: 0.9163, validation loss: 0.6576
2024-05-22 19:59:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch10_loss0.6575768917798996.pypots
2024-05-22 19:59:36 [INFO]: Epoch 011 - training loss: 0.9004, validation loss: 0.6551
2024-05-22 19:59:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch11_loss0.6551007002592086.pypots
2024-05-22 19:59:39 [INFO]: Epoch 012 - training loss: 0.8977, validation loss: 0.6548
2024-05-22 19:59:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch12_loss0.6548283934593201.pypots
2024-05-22 19:59:42 [INFO]: Epoch 013 - training loss: 0.8879, validation loss: 0.6540
2024-05-22 19:59:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch13_loss0.653951245546341.pypots
2024-05-22 19:59:45 [INFO]: Epoch 014 - training loss: 0.9163, validation loss: 0.6540
2024-05-22 19:59:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch14_loss0.6539513736963272.pypots
2024-05-22 19:59:48 [INFO]: Epoch 015 - training loss: 0.9048, validation loss: 0.6517
2024-05-22 19:59:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch15_loss0.6517174899578094.pypots
2024-05-22 19:59:51 [INFO]: Epoch 016 - training loss: 0.8889, validation loss: 0.6511
2024-05-22 19:59:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch16_loss0.6510877668857574.pypots
2024-05-22 19:59:54 [INFO]: Epoch 017 - training loss: 0.8792, validation loss: 0.6520
2024-05-22 19:59:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch17_loss0.6519804418087005.pypots
2024-05-22 19:59:57 [INFO]: Epoch 018 - training loss: 0.8803, validation loss: 0.6503
2024-05-22 19:59:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch18_loss0.6503129810094833.pypots
2024-05-22 20:00:00 [INFO]: Epoch 019 - training loss: 0.8600, validation loss: 0.6511
2024-05-22 20:00:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch19_loss0.651057344675064.pypots
2024-05-22 20:00:03 [INFO]: Epoch 020 - training loss: 0.8915, validation loss: 0.6521
2024-05-22 20:00:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch20_loss0.652063301205635.pypots
2024-05-22 20:00:07 [INFO]: Epoch 021 - training loss: 0.8719, validation loss: 0.6503
2024-05-22 20:00:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch21_loss0.650290048122406.pypots
2024-05-22 20:00:10 [INFO]: Epoch 022 - training loss: 0.8540, validation loss: 0.6510
2024-05-22 20:00:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch22_loss0.6509924024343491.pypots
2024-05-22 20:00:13 [INFO]: Epoch 023 - training loss: 0.8526, validation loss: 0.6541
2024-05-22 20:00:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch23_loss0.6541177272796631.pypots
2024-05-22 20:00:16 [INFO]: Epoch 024 - training loss: 0.8542, validation loss: 0.6534
2024-05-22 20:00:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch24_loss0.6533532798290252.pypots
2024-05-22 20:00:19 [INFO]: Epoch 025 - training loss: 0.8463, validation loss: 0.6542
2024-05-22 20:00:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch25_loss0.654210439324379.pypots
2024-05-22 20:00:22 [INFO]: Epoch 026 - training loss: 0.8622, validation loss: 0.6541
2024-05-22 20:00:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch26_loss0.6540849179029464.pypots
2024-05-22 20:00:25 [INFO]: Epoch 027 - training loss: 0.8493, validation loss: 0.6555
2024-05-22 20:00:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch27_loss0.6555070489645004.pypots
2024-05-22 20:00:28 [INFO]: Epoch 028 - training loss: 0.8492, validation loss: 0.6537
2024-05-22 20:00:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch28_loss0.653699180483818.pypots
2024-05-22 20:00:32 [INFO]: Epoch 029 - training loss: 0.8540, validation loss: 0.6571
2024-05-22 20:00:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch29_loss0.657104754447937.pypots
2024-05-22 20:00:35 [INFO]: Epoch 030 - training loss: 0.8506, validation loss: 0.6537
2024-05-22 20:00:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch30_loss0.6537265866994858.pypots
2024-05-22 20:00:38 [INFO]: Epoch 031 - training loss: 0.8466, validation loss: 0.6566
2024-05-22 20:00:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN_epoch31_loss0.6565637558698654.pypots
2024-05-22 20:00:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 20:00:38 [INFO]: Finished training. The best model is from epoch#21.
2024-05-22 20:00:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/20240522_T195901/MRNN.pypots
2024-05-22 20:00:38 [INFO]: MRNN on Air-Quality: MAE=0.5226, MSE=0.6178
2024-05-22 20:00:38 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/MRNN_air_quality/imputation.pkl
2024-05-22 20:00:38 [INFO]: Using the given device: cpu
2024-05-22 20:00:38 [INFO]: LOCF on Air-Quality: MAE=0.2062, MSE=0.2674
2024-05-22 20:00:38 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_air_quality".
2024-05-22 20:00:38 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/LOCF_air_quality/imputation.pkl
2024-05-22 20:00:38 [INFO]: Median on Air-Quality: MAE=0.6602, MSE=1.0006
2024-05-22 20:00:38 [INFO]: Successfully created the given path "saved_results/round_3/Median_air_quality".
2024-05-22 20:00:38 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/Median_air_quality/imputation.pkl
2024-05-22 20:00:38 [INFO]: Mean on Air-Quality: MAE=0.6921, MSE=0.9434
2024-05-22 20:00:38 [INFO]: Successfully created the given path "saved_results/round_3/Mean_air_quality".
2024-05-22 20:00:38 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/Mean_air_quality/imputation.pkl
2024-05-22 20:00:38 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-22 20:00:38 [INFO]: Using the given device: cuda:0
2024-05-22 20:00:38 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/SAITS_air_quality/20240522_T200038
2024-05-22 20:00:38 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/SAITS_air_quality/20240522_T200038/tensorboard
2024-05-22 20:00:38 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-22 20:00:39 [INFO]: Epoch 001 - training loss: 1.0577, validation loss: 0.4827
2024-05-22 20:00:40 [INFO]: Epoch 002 - training loss: 0.7519, validation loss: 0.3664
2024-05-22 20:00:40 [INFO]: Epoch 003 - training loss: 0.6446, validation loss: 0.2922
2024-05-22 20:00:41 [INFO]: Epoch 004 - training loss: 0.5712, validation loss: 0.2538
2024-05-22 20:00:42 [INFO]: Epoch 005 - training loss: 0.5165, validation loss: 0.2354
2024-05-22 20:00:42 [INFO]: Epoch 006 - training loss: 0.4810, validation loss: 0.2191
2024-05-22 20:00:43 [INFO]: Epoch 007 - training loss: 0.4558, validation loss: 0.2107
2024-05-22 20:00:44 [INFO]: Epoch 008 - training loss: 0.4394, validation loss: 0.2016
2024-05-22 20:00:44 [INFO]: Epoch 009 - training loss: 0.4255, validation loss: 0.1975
2024-05-22 20:00:45 [INFO]: Epoch 010 - training loss: 0.4135, validation loss: 0.1921
2024-05-22 20:00:45 [INFO]: Epoch 011 - training loss: 0.4034, validation loss: 0.1891
2024-05-22 20:00:46 [INFO]: Epoch 012 - training loss: 0.3961, validation loss: 0.1858
2024-05-22 20:00:47 [INFO]: Epoch 013 - training loss: 0.3892, validation loss: 0.1833
2024-05-22 20:00:47 [INFO]: Epoch 014 - training loss: 0.3813, validation loss: 0.1800
2024-05-22 20:00:48 [INFO]: Epoch 015 - training loss: 0.3743, validation loss: 0.1781
2024-05-22 20:00:49 [INFO]: Epoch 016 - training loss: 0.3689, validation loss: 0.1750
2024-05-22 20:00:49 [INFO]: Epoch 017 - training loss: 0.3639, validation loss: 0.1725
2024-05-22 20:00:50 [INFO]: Epoch 018 - training loss: 0.3598, validation loss: 0.1710
2024-05-22 20:00:50 [INFO]: Epoch 019 - training loss: 0.3546, validation loss: 0.1682
2024-05-22 20:00:51 [INFO]: Epoch 020 - training loss: 0.3515, validation loss: 0.1677
2024-05-22 20:00:52 [INFO]: Epoch 021 - training loss: 0.3495, validation loss: 0.1650
2024-05-22 20:00:52 [INFO]: Epoch 022 - training loss: 0.3446, validation loss: 0.1635
2024-05-22 20:00:53 [INFO]: Epoch 023 - training loss: 0.3415, validation loss: 0.1642
2024-05-22 20:00:54 [INFO]: Epoch 024 - training loss: 0.3395, validation loss: 0.1620
2024-05-22 20:00:54 [INFO]: Epoch 025 - training loss: 0.3361, validation loss: 0.1607
2024-05-22 20:00:55 [INFO]: Epoch 026 - training loss: 0.3332, validation loss: 0.1576
2024-05-22 20:00:55 [INFO]: Epoch 027 - training loss: 0.3324, validation loss: 0.1570
2024-05-22 20:00:56 [INFO]: Epoch 028 - training loss: 0.3293, validation loss: 0.1560
2024-05-22 20:00:57 [INFO]: Epoch 029 - training loss: 0.3262, validation loss: 0.1538
2024-05-22 20:00:57 [INFO]: Epoch 030 - training loss: 0.3240, validation loss: 0.1524
2024-05-22 20:00:58 [INFO]: Epoch 031 - training loss: 0.3233, validation loss: 0.1521
2024-05-22 20:00:59 [INFO]: Epoch 032 - training loss: 0.3211, validation loss: 0.1505
2024-05-22 20:00:59 [INFO]: Epoch 033 - training loss: 0.3191, validation loss: 0.1480
2024-05-22 20:01:00 [INFO]: Epoch 034 - training loss: 0.3187, validation loss: 0.1483
2024-05-22 20:01:00 [INFO]: Epoch 035 - training loss: 0.3159, validation loss: 0.1469
2024-05-22 20:01:01 [INFO]: Epoch 036 - training loss: 0.3128, validation loss: 0.1447
2024-05-22 20:01:02 [INFO]: Epoch 037 - training loss: 0.3101, validation loss: 0.1444
2024-05-22 20:01:02 [INFO]: Epoch 038 - training loss: 0.3106, validation loss: 0.1425
2024-05-22 20:01:03 [INFO]: Epoch 039 - training loss: 0.3070, validation loss: 0.1415
2024-05-22 20:01:04 [INFO]: Epoch 040 - training loss: 0.3062, validation loss: 0.1403
2024-05-22 20:01:04 [INFO]: Epoch 041 - training loss: 0.3039, validation loss: 0.1394
2024-05-22 20:01:05 [INFO]: Epoch 042 - training loss: 0.3036, validation loss: 0.1390
2024-05-22 20:01:05 [INFO]: Epoch 043 - training loss: 0.3011, validation loss: 0.1369
2024-05-22 20:01:06 [INFO]: Epoch 044 - training loss: 0.3001, validation loss: 0.1359
2024-05-22 20:01:07 [INFO]: Epoch 045 - training loss: 0.2981, validation loss: 0.1357
2024-05-22 20:01:07 [INFO]: Epoch 046 - training loss: 0.2959, validation loss: 0.1351
2024-05-22 20:01:08 [INFO]: Epoch 047 - training loss: 0.2954, validation loss: 0.1340
2024-05-22 20:01:09 [INFO]: Epoch 048 - training loss: 0.2929, validation loss: 0.1334
2024-05-22 20:01:09 [INFO]: Epoch 049 - training loss: 0.2917, validation loss: 0.1324
2024-05-22 20:01:10 [INFO]: Epoch 050 - training loss: 0.2918, validation loss: 0.1312
2024-05-22 20:01:10 [INFO]: Epoch 051 - training loss: 0.2897, validation loss: 0.1310
2024-05-22 20:01:11 [INFO]: Epoch 052 - training loss: 0.2896, validation loss: 0.1293
2024-05-22 20:01:12 [INFO]: Epoch 053 - training loss: 0.2882, validation loss: 0.1296
2024-05-22 20:01:12 [INFO]: Epoch 054 - training loss: 0.2868, validation loss: 0.1294
2024-05-22 20:01:13 [INFO]: Epoch 055 - training loss: 0.2851, validation loss: 0.1282
2024-05-22 20:01:14 [INFO]: Epoch 056 - training loss: 0.2838, validation loss: 0.1279
2024-05-22 20:01:14 [INFO]: Epoch 057 - training loss: 0.2825, validation loss: 0.1267
2024-05-22 20:01:15 [INFO]: Epoch 058 - training loss: 0.2799, validation loss: 0.1272
2024-05-22 20:01:16 [INFO]: Epoch 059 - training loss: 0.2792, validation loss: 0.1267
2024-05-22 20:01:16 [INFO]: Epoch 060 - training loss: 0.2784, validation loss: 0.1259
2024-05-22 20:01:17 [INFO]: Epoch 061 - training loss: 0.2782, validation loss: 0.1249
2024-05-22 20:01:17 [INFO]: Epoch 062 - training loss: 0.2775, validation loss: 0.1246
2024-05-22 20:01:18 [INFO]: Epoch 063 - training loss: 0.2760, validation loss: 0.1237
2024-05-22 20:01:19 [INFO]: Epoch 064 - training loss: 0.2738, validation loss: 0.1235
2024-05-22 20:01:19 [INFO]: Epoch 065 - training loss: 0.2730, validation loss: 0.1227
2024-05-22 20:01:20 [INFO]: Epoch 066 - training loss: 0.2728, validation loss: 0.1231
2024-05-22 20:01:21 [INFO]: Epoch 067 - training loss: 0.2728, validation loss: 0.1228
2024-05-22 20:01:21 [INFO]: Epoch 068 - training loss: 0.2710, validation loss: 0.1215
2024-05-22 20:01:22 [INFO]: Epoch 069 - training loss: 0.2707, validation loss: 0.1211
2024-05-22 20:01:22 [INFO]: Epoch 070 - training loss: 0.2681, validation loss: 0.1218
2024-05-22 20:01:23 [INFO]: Epoch 071 - training loss: 0.2669, validation loss: 0.1204
2024-05-22 20:01:24 [INFO]: Epoch 072 - training loss: 0.2657, validation loss: 0.1198
2024-05-22 20:01:24 [INFO]: Epoch 073 - training loss: 0.2630, validation loss: 0.1202
2024-05-22 20:01:25 [INFO]: Epoch 074 - training loss: 0.2641, validation loss: 0.1196
2024-05-22 20:01:26 [INFO]: Epoch 075 - training loss: 0.2633, validation loss: 0.1191
2024-05-22 20:01:26 [INFO]: Epoch 076 - training loss: 0.2623, validation loss: 0.1188
2024-05-22 20:01:27 [INFO]: Epoch 077 - training loss: 0.2613, validation loss: 0.1186
2024-05-22 20:01:27 [INFO]: Epoch 078 - training loss: 0.2613, validation loss: 0.1181
2024-05-22 20:01:28 [INFO]: Epoch 079 - training loss: 0.2596, validation loss: 0.1185
2024-05-22 20:01:29 [INFO]: Epoch 080 - training loss: 0.2596, validation loss: 0.1176
2024-05-22 20:01:29 [INFO]: Epoch 081 - training loss: 0.2580, validation loss: 0.1173
2024-05-22 20:01:30 [INFO]: Epoch 082 - training loss: 0.2582, validation loss: 0.1167
2024-05-22 20:01:31 [INFO]: Epoch 083 - training loss: 0.2557, validation loss: 0.1161
2024-05-22 20:01:31 [INFO]: Epoch 084 - training loss: 0.2560, validation loss: 0.1160
2024-05-22 20:01:32 [INFO]: Epoch 085 - training loss: 0.2554, validation loss: 0.1165
2024-05-22 20:01:32 [INFO]: Epoch 086 - training loss: 0.2542, validation loss: 0.1158
2024-05-22 20:01:33 [INFO]: Epoch 087 - training loss: 0.2532, validation loss: 0.1158
2024-05-22 20:01:34 [INFO]: Epoch 088 - training loss: 0.2537, validation loss: 0.1159
2024-05-22 20:01:34 [INFO]: Epoch 089 - training loss: 0.2524, validation loss: 0.1151
2024-05-22 20:01:35 [INFO]: Epoch 090 - training loss: 0.2515, validation loss: 0.1147
2024-05-22 20:01:36 [INFO]: Epoch 091 - training loss: 0.2511, validation loss: 0.1153
2024-05-22 20:01:36 [INFO]: Epoch 092 - training loss: 0.2504, validation loss: 0.1140
2024-05-22 20:01:37 [INFO]: Epoch 093 - training loss: 0.2499, validation loss: 0.1147
2024-05-22 20:01:37 [INFO]: Epoch 094 - training loss: 0.2507, validation loss: 0.1140
2024-05-22 20:01:38 [INFO]: Epoch 095 - training loss: 0.2487, validation loss: 0.1137
2024-05-22 20:01:39 [INFO]: Epoch 096 - training loss: 0.2486, validation loss: 0.1133
2024-05-22 20:01:39 [INFO]: Epoch 097 - training loss: 0.2479, validation loss: 0.1132
2024-05-22 20:01:40 [INFO]: Epoch 098 - training loss: 0.2475, validation loss: 0.1123
2024-05-22 20:01:41 [INFO]: Epoch 099 - training loss: 0.2475, validation loss: 0.1130
2024-05-22 20:01:41 [INFO]: Epoch 100 - training loss: 0.2461, validation loss: 0.1123
2024-05-22 20:01:42 [INFO]: Epoch 101 - training loss: 0.2444, validation loss: 0.1118
2024-05-22 20:01:42 [INFO]: Epoch 102 - training loss: 0.2440, validation loss: 0.1118
2024-05-22 20:01:43 [INFO]: Epoch 103 - training loss: 0.2433, validation loss: 0.1119
2024-05-22 20:01:44 [INFO]: Epoch 104 - training loss: 0.2443, validation loss: 0.1117
2024-05-22 20:01:44 [INFO]: Epoch 105 - training loss: 0.2431, validation loss: 0.1109
2024-05-22 20:01:45 [INFO]: Epoch 106 - training loss: 0.2440, validation loss: 0.1114
2024-05-22 20:01:46 [INFO]: Epoch 107 - training loss: 0.2433, validation loss: 0.1120
2024-05-22 20:01:46 [INFO]: Epoch 108 - training loss: 0.2428, validation loss: 0.1106
2024-05-22 20:01:47 [INFO]: Epoch 109 - training loss: 0.2423, validation loss: 0.1104
2024-05-22 20:01:47 [INFO]: Epoch 110 - training loss: 0.2409, validation loss: 0.1106
2024-05-22 20:01:48 [INFO]: Epoch 111 - training loss: 0.2405, validation loss: 0.1103
2024-05-22 20:01:49 [INFO]: Epoch 112 - training loss: 0.2412, validation loss: 0.1111
2024-05-22 20:01:49 [INFO]: Epoch 113 - training loss: 0.2408, validation loss: 0.1096
2024-05-22 20:01:50 [INFO]: Epoch 114 - training loss: 0.2397, validation loss: 0.1091
2024-05-22 20:01:51 [INFO]: Epoch 115 - training loss: 0.2378, validation loss: 0.1101
2024-05-22 20:01:51 [INFO]: Epoch 116 - training loss: 0.2391, validation loss: 0.1091
2024-05-22 20:01:52 [INFO]: Epoch 117 - training loss: 0.2368, validation loss: 0.1086
2024-05-22 20:01:52 [INFO]: Epoch 118 - training loss: 0.2361, validation loss: 0.1090
2024-05-22 20:01:53 [INFO]: Epoch 119 - training loss: 0.2350, validation loss: 0.1087
2024-05-22 20:01:54 [INFO]: Epoch 120 - training loss: 0.2355, validation loss: 0.1087
2024-05-22 20:01:54 [INFO]: Epoch 121 - training loss: 0.2352, validation loss: 0.1085
2024-05-22 20:01:55 [INFO]: Epoch 122 - training loss: 0.2363, validation loss: 0.1090
2024-05-22 20:01:56 [INFO]: Epoch 123 - training loss: 0.2347, validation loss: 0.1088
2024-05-22 20:01:56 [INFO]: Epoch 124 - training loss: 0.2341, validation loss: 0.1078
2024-05-22 20:01:57 [INFO]: Epoch 125 - training loss: 0.2332, validation loss: 0.1087
2024-05-22 20:01:58 [INFO]: Epoch 126 - training loss: 0.2341, validation loss: 0.1073
2024-05-22 20:01:58 [INFO]: Epoch 127 - training loss: 0.2329, validation loss: 0.1072
2024-05-22 20:01:59 [INFO]: Epoch 128 - training loss: 0.2328, validation loss: 0.1071
2024-05-22 20:02:00 [INFO]: Epoch 129 - training loss: 0.2334, validation loss: 0.1077
2024-05-22 20:02:00 [INFO]: Epoch 130 - training loss: 0.2348, validation loss: 0.1071
2024-05-22 20:02:01 [INFO]: Epoch 131 - training loss: 0.2327, validation loss: 0.1068
2024-05-22 20:02:01 [INFO]: Epoch 132 - training loss: 0.2308, validation loss: 0.1061
2024-05-22 20:02:02 [INFO]: Epoch 133 - training loss: 0.2306, validation loss: 0.1065
2024-05-22 20:02:03 [INFO]: Epoch 134 - training loss: 0.2295, validation loss: 0.1062
2024-05-22 20:02:03 [INFO]: Epoch 135 - training loss: 0.2296, validation loss: 0.1061
2024-05-22 20:02:04 [INFO]: Epoch 136 - training loss: 0.2297, validation loss: 0.1054
2024-05-22 20:02:05 [INFO]: Epoch 137 - training loss: 0.2278, validation loss: 0.1054
2024-05-22 20:02:05 [INFO]: Epoch 138 - training loss: 0.2300, validation loss: 0.1051
2024-05-22 20:02:06 [INFO]: Epoch 139 - training loss: 0.2290, validation loss: 0.1052
2024-05-22 20:02:07 [INFO]: Epoch 140 - training loss: 0.2277, validation loss: 0.1049
2024-05-22 20:02:07 [INFO]: Epoch 141 - training loss: 0.2276, validation loss: 0.1046
2024-05-22 20:02:08 [INFO]: Epoch 142 - training loss: 0.2270, validation loss: 0.1040
2024-05-22 20:02:09 [INFO]: Epoch 143 - training loss: 0.2264, validation loss: 0.1045
2024-05-22 20:02:09 [INFO]: Epoch 144 - training loss: 0.2284, validation loss: 0.1041
2024-05-22 20:02:10 [INFO]: Epoch 145 - training loss: 0.2272, validation loss: 0.1042
2024-05-22 20:02:11 [INFO]: Epoch 146 - training loss: 0.2259, validation loss: 0.1042
2024-05-22 20:02:11 [INFO]: Epoch 147 - training loss: 0.2257, validation loss: 0.1042
2024-05-22 20:02:12 [INFO]: Epoch 148 - training loss: 0.2252, validation loss: 0.1033
2024-05-22 20:02:13 [INFO]: Epoch 149 - training loss: 0.2254, validation loss: 0.1036
2024-05-22 20:02:13 [INFO]: Epoch 150 - training loss: 0.2261, validation loss: 0.1038
2024-05-22 20:02:14 [INFO]: Epoch 151 - training loss: 0.2238, validation loss: 0.1036
2024-05-22 20:02:14 [INFO]: Epoch 152 - training loss: 0.2223, validation loss: 0.1032
2024-05-22 20:02:15 [INFO]: Epoch 153 - training loss: 0.2222, validation loss: 0.1032
2024-05-22 20:02:16 [INFO]: Epoch 154 - training loss: 0.2224, validation loss: 0.1033
2024-05-22 20:02:16 [INFO]: Epoch 155 - training loss: 0.2232, validation loss: 0.1028
2024-05-22 20:02:17 [INFO]: Epoch 156 - training loss: 0.2236, validation loss: 0.1027
2024-05-22 20:02:18 [INFO]: Epoch 157 - training loss: 0.2237, validation loss: 0.1027
2024-05-22 20:02:18 [INFO]: Epoch 158 - training loss: 0.2219, validation loss: 0.1024
2024-05-22 20:02:19 [INFO]: Epoch 159 - training loss: 0.2221, validation loss: 0.1026
2024-05-22 20:02:20 [INFO]: Epoch 160 - training loss: 0.2212, validation loss: 0.1022
2024-05-22 20:02:20 [INFO]: Epoch 161 - training loss: 0.2198, validation loss: 0.1022
2024-05-22 20:02:21 [INFO]: Epoch 162 - training loss: 0.2194, validation loss: 0.1021
2024-05-22 20:02:21 [INFO]: Epoch 163 - training loss: 0.2198, validation loss: 0.1020
2024-05-22 20:02:22 [INFO]: Epoch 164 - training loss: 0.2193, validation loss: 0.1021
2024-05-22 20:02:23 [INFO]: Epoch 165 - training loss: 0.2189, validation loss: 0.1016
2024-05-22 20:02:23 [INFO]: Epoch 166 - training loss: 0.2183, validation loss: 0.1017
2024-05-22 20:02:24 [INFO]: Epoch 167 - training loss: 0.2196, validation loss: 0.1026
2024-05-22 20:02:25 [INFO]: Epoch 168 - training loss: 0.2200, validation loss: 0.1008
2024-05-22 20:02:25 [INFO]: Epoch 169 - training loss: 0.2183, validation loss: 0.1011
2024-05-22 20:02:26 [INFO]: Epoch 170 - training loss: 0.2181, validation loss: 0.1007
2024-05-22 20:02:27 [INFO]: Epoch 171 - training loss: 0.2189, validation loss: 0.1013
2024-05-22 20:02:27 [INFO]: Epoch 172 - training loss: 0.2195, validation loss: 0.1010
2024-05-22 20:02:28 [INFO]: Epoch 173 - training loss: 0.2182, validation loss: 0.1011
2024-05-22 20:02:29 [INFO]: Epoch 174 - training loss: 0.2176, validation loss: 0.1004
2024-05-22 20:02:29 [INFO]: Epoch 175 - training loss: 0.2159, validation loss: 0.1011
2024-05-22 20:02:30 [INFO]: Epoch 176 - training loss: 0.2154, validation loss: 0.1007
2024-05-22 20:02:30 [INFO]: Epoch 177 - training loss: 0.2146, validation loss: 0.1001
2024-05-22 20:02:31 [INFO]: Epoch 178 - training loss: 0.2155, validation loss: 0.1002
2024-05-22 20:02:32 [INFO]: Epoch 179 - training loss: 0.2159, validation loss: 0.1002
2024-05-22 20:02:32 [INFO]: Epoch 180 - training loss: 0.2141, validation loss: 0.1004
2024-05-22 20:02:33 [INFO]: Epoch 181 - training loss: 0.2160, validation loss: 0.1002
2024-05-22 20:02:34 [INFO]: Epoch 182 - training loss: 0.2205, validation loss: 0.1005
2024-05-22 20:02:34 [INFO]: Epoch 183 - training loss: 0.2210, validation loss: 0.1004
2024-05-22 20:02:35 [INFO]: Epoch 184 - training loss: 0.2141, validation loss: 0.0996
2024-05-22 20:02:36 [INFO]: Epoch 185 - training loss: 0.2118, validation loss: 0.0997
2024-05-22 20:02:36 [INFO]: Epoch 186 - training loss: 0.2123, validation loss: 0.1000
2024-05-22 20:02:37 [INFO]: Epoch 187 - training loss: 0.2132, validation loss: 0.0993
2024-05-22 20:02:37 [INFO]: Epoch 188 - training loss: 0.2134, validation loss: 0.0999
2024-05-22 20:02:38 [INFO]: Epoch 189 - training loss: 0.2117, validation loss: 0.0988
2024-05-22 20:02:39 [INFO]: Epoch 190 - training loss: 0.2140, validation loss: 0.0993
2024-05-22 20:02:39 [INFO]: Epoch 191 - training loss: 0.2126, validation loss: 0.0988
2024-05-22 20:02:40 [INFO]: Epoch 192 - training loss: 0.2118, validation loss: 0.0987
2024-05-22 20:02:41 [INFO]: Epoch 193 - training loss: 0.2108, validation loss: 0.0981
2024-05-22 20:02:41 [INFO]: Epoch 194 - training loss: 0.2104, validation loss: 0.0985
2024-05-22 20:02:42 [INFO]: Epoch 195 - training loss: 0.2109, validation loss: 0.0981
2024-05-22 20:02:42 [INFO]: Epoch 196 - training loss: 0.2112, validation loss: 0.0983
2024-05-22 20:02:43 [INFO]: Epoch 197 - training loss: 0.2099, validation loss: 0.0980
2024-05-22 20:02:44 [INFO]: Epoch 198 - training loss: 0.2094, validation loss: 0.0993
2024-05-22 20:02:44 [INFO]: Epoch 199 - training loss: 0.2108, validation loss: 0.0979
2024-05-22 20:02:45 [INFO]: Epoch 200 - training loss: 0.2092, validation loss: 0.0978
2024-05-22 20:02:46 [INFO]: Epoch 201 - training loss: 0.2091, validation loss: 0.0979
2024-05-22 20:02:46 [INFO]: Epoch 202 - training loss: 0.2097, validation loss: 0.0977
2024-05-22 20:02:47 [INFO]: Epoch 203 - training loss: 0.2085, validation loss: 0.0976
2024-05-22 20:02:48 [INFO]: Epoch 204 - training loss: 0.2087, validation loss: 0.0980
2024-05-22 20:02:48 [INFO]: Epoch 205 - training loss: 0.2086, validation loss: 0.0973
2024-05-22 20:02:49 [INFO]: Epoch 206 - training loss: 0.2076, validation loss: 0.0969
2024-05-22 20:02:50 [INFO]: Epoch 207 - training loss: 0.2076, validation loss: 0.0972
2024-05-22 20:02:50 [INFO]: Epoch 208 - training loss: 0.2071, validation loss: 0.0973
2024-05-22 20:02:51 [INFO]: Epoch 209 - training loss: 0.2075, validation loss: 0.0968
2024-05-22 20:02:52 [INFO]: Epoch 210 - training loss: 0.2056, validation loss: 0.0967
2024-05-22 20:02:52 [INFO]: Epoch 211 - training loss: 0.2070, validation loss: 0.0974
2024-05-22 20:02:53 [INFO]: Epoch 212 - training loss: 0.2075, validation loss: 0.0974
2024-05-22 20:02:53 [INFO]: Epoch 213 - training loss: 0.2083, validation loss: 0.0973
2024-05-22 20:02:54 [INFO]: Epoch 214 - training loss: 0.2084, validation loss: 0.0963
2024-05-22 20:02:55 [INFO]: Epoch 215 - training loss: 0.2071, validation loss: 0.0969
2024-05-22 20:02:55 [INFO]: Epoch 216 - training loss: 0.2063, validation loss: 0.0966
2024-05-22 20:02:56 [INFO]: Epoch 217 - training loss: 0.2080, validation loss: 0.0971
2024-05-22 20:02:57 [INFO]: Epoch 218 - training loss: 0.2071, validation loss: 0.0964
2024-05-22 20:02:57 [INFO]: Epoch 219 - training loss: 0.2066, validation loss: 0.0964
2024-05-22 20:02:58 [INFO]: Epoch 220 - training loss: 0.2069, validation loss: 0.0957
2024-05-22 20:02:59 [INFO]: Epoch 221 - training loss: 0.2044, validation loss: 0.0960
2024-05-22 20:02:59 [INFO]: Epoch 222 - training loss: 0.2037, validation loss: 0.0955
2024-05-22 20:03:00 [INFO]: Epoch 223 - training loss: 0.2044, validation loss: 0.0959
2024-05-22 20:03:00 [INFO]: Epoch 224 - training loss: 0.2035, validation loss: 0.0965
2024-05-22 20:03:01 [INFO]: Epoch 225 - training loss: 0.2031, validation loss: 0.0961
2024-05-22 20:03:02 [INFO]: Epoch 226 - training loss: 0.2048, validation loss: 0.0950
2024-05-22 20:03:02 [INFO]: Epoch 227 - training loss: 0.2044, validation loss: 0.0953
2024-05-22 20:03:03 [INFO]: Epoch 228 - training loss: 0.2041, validation loss: 0.0958
2024-05-22 20:03:04 [INFO]: Epoch 229 - training loss: 0.2032, validation loss: 0.0956
2024-05-22 20:03:04 [INFO]: Epoch 230 - training loss: 0.2037, validation loss: 0.0954
2024-05-22 20:03:05 [INFO]: Epoch 231 - training loss: 0.2027, validation loss: 0.0952
2024-05-22 20:03:06 [INFO]: Epoch 232 - training loss: 0.2060, validation loss: 0.0961
2024-05-22 20:03:06 [INFO]: Epoch 233 - training loss: 0.2044, validation loss: 0.0954
2024-05-22 20:03:07 [INFO]: Epoch 234 - training loss: 0.2029, validation loss: 0.0959
2024-05-22 20:03:07 [INFO]: Epoch 235 - training loss: 0.2032, validation loss: 0.0950
2024-05-22 20:03:08 [INFO]: Epoch 236 - training loss: 0.2029, validation loss: 0.0956
2024-05-22 20:03:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 20:03:08 [INFO]: Finished training. The best model is from epoch#226.
2024-05-22 20:03:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/SAITS_air_quality/20240522_T200038/SAITS.pypots
2024-05-22 20:03:08 [INFO]: SAITS on Air-Quality: MAE=0.1453, MSE=0.1049
2024-05-22 20:03:08 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/SAITS_air_quality/imputation.pkl
2024-05-22 20:03:08 [INFO]: Using the given device: cuda:0
2024-05-22 20:03:08 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/Transformer_air_quality/20240522_T200308
2024-05-22 20:03:08 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/Transformer_air_quality/20240522_T200308/tensorboard
2024-05-22 20:03:08 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-22 20:03:09 [INFO]: Epoch 001 - training loss: 0.9562, validation loss: 0.4567
2024-05-22 20:03:09 [INFO]: Epoch 002 - training loss: 0.5886, validation loss: 0.3366
2024-05-22 20:03:09 [INFO]: Epoch 003 - training loss: 0.4950, validation loss: 0.2719
2024-05-22 20:03:09 [INFO]: Epoch 004 - training loss: 0.4438, validation loss: 0.2428
2024-05-22 20:03:10 [INFO]: Epoch 005 - training loss: 0.4136, validation loss: 0.2314
2024-05-22 20:03:10 [INFO]: Epoch 006 - training loss: 0.3919, validation loss: 0.2199
2024-05-22 20:03:10 [INFO]: Epoch 007 - training loss: 0.3788, validation loss: 0.2126
2024-05-22 20:03:11 [INFO]: Epoch 008 - training loss: 0.3683, validation loss: 0.2066
2024-05-22 20:03:11 [INFO]: Epoch 009 - training loss: 0.3538, validation loss: 0.2011
2024-05-22 20:03:11 [INFO]: Epoch 010 - training loss: 0.3492, validation loss: 0.1975
2024-05-22 20:03:11 [INFO]: Epoch 011 - training loss: 0.3439, validation loss: 0.1922
2024-05-22 20:03:12 [INFO]: Epoch 012 - training loss: 0.3398, validation loss: 0.1914
2024-05-22 20:03:12 [INFO]: Epoch 013 - training loss: 0.3334, validation loss: 0.1855
2024-05-22 20:03:12 [INFO]: Epoch 014 - training loss: 0.3255, validation loss: 0.1827
2024-05-22 20:03:13 [INFO]: Epoch 015 - training loss: 0.3232, validation loss: 0.1825
2024-05-22 20:03:13 [INFO]: Epoch 016 - training loss: 0.3216, validation loss: 0.1769
2024-05-22 20:03:13 [INFO]: Epoch 017 - training loss: 0.3152, validation loss: 0.1728
2024-05-22 20:03:13 [INFO]: Epoch 018 - training loss: 0.3116, validation loss: 0.1717
2024-05-22 20:03:14 [INFO]: Epoch 019 - training loss: 0.3115, validation loss: 0.1692
2024-05-22 20:03:14 [INFO]: Epoch 020 - training loss: 0.3062, validation loss: 0.1653
2024-05-22 20:03:14 [INFO]: Epoch 021 - training loss: 0.3052, validation loss: 0.1647
2024-05-22 20:03:14 [INFO]: Epoch 022 - training loss: 0.3035, validation loss: 0.1647
2024-05-22 20:03:15 [INFO]: Epoch 023 - training loss: 0.3012, validation loss: 0.1621
2024-05-22 20:03:15 [INFO]: Epoch 024 - training loss: 0.2964, validation loss: 0.1602
2024-05-22 20:03:16 [INFO]: Epoch 025 - training loss: 0.2929, validation loss: 0.1587
2024-05-22 20:03:16 [INFO]: Epoch 026 - training loss: 0.2939, validation loss: 0.1593
2024-05-22 20:03:16 [INFO]: Epoch 027 - training loss: 0.2913, validation loss: 0.1577
2024-05-22 20:03:17 [INFO]: Epoch 028 - training loss: 0.2904, validation loss: 0.1553
2024-05-22 20:03:17 [INFO]: Epoch 029 - training loss: 0.2883, validation loss: 0.1551
2024-05-22 20:03:17 [INFO]: Epoch 030 - training loss: 0.2855, validation loss: 0.1544
2024-05-22 20:03:18 [INFO]: Epoch 031 - training loss: 0.2838, validation loss: 0.1536
2024-05-22 20:03:18 [INFO]: Epoch 032 - training loss: 0.2841, validation loss: 0.1539
2024-05-22 20:03:18 [INFO]: Epoch 033 - training loss: 0.2813, validation loss: 0.1519
2024-05-22 20:03:19 [INFO]: Epoch 034 - training loss: 0.2807, validation loss: 0.1528
2024-05-22 20:03:19 [INFO]: Epoch 035 - training loss: 0.2805, validation loss: 0.1521
2024-05-22 20:03:19 [INFO]: Epoch 036 - training loss: 0.2782, validation loss: 0.1513
2024-05-22 20:03:19 [INFO]: Epoch 037 - training loss: 0.2774, validation loss: 0.1514
2024-05-22 20:03:20 [INFO]: Epoch 038 - training loss: 0.2769, validation loss: 0.1490
2024-05-22 20:03:20 [INFO]: Epoch 039 - training loss: 0.2747, validation loss: 0.1494
2024-05-22 20:03:20 [INFO]: Epoch 040 - training loss: 0.2781, validation loss: 0.1486
2024-05-22 20:03:20 [INFO]: Epoch 041 - training loss: 0.2798, validation loss: 0.1482
2024-05-22 20:03:21 [INFO]: Epoch 042 - training loss: 0.2718, validation loss: 0.1481
2024-05-22 20:03:21 [INFO]: Epoch 043 - training loss: 0.2707, validation loss: 0.1482
2024-05-22 20:03:21 [INFO]: Epoch 044 - training loss: 0.2719, validation loss: 0.1460
2024-05-22 20:03:22 [INFO]: Epoch 045 - training loss: 0.2698, validation loss: 0.1464
2024-05-22 20:03:22 [INFO]: Epoch 046 - training loss: 0.2668, validation loss: 0.1451
2024-05-22 20:03:22 [INFO]: Epoch 047 - training loss: 0.2675, validation loss: 0.1442
2024-05-22 20:03:22 [INFO]: Epoch 048 - training loss: 0.2660, validation loss: 0.1442
2024-05-22 20:03:23 [INFO]: Epoch 049 - training loss: 0.2642, validation loss: 0.1456
2024-05-22 20:03:23 [INFO]: Epoch 050 - training loss: 0.2639, validation loss: 0.1427
2024-05-22 20:03:23 [INFO]: Epoch 051 - training loss: 0.2626, validation loss: 0.1445
2024-05-22 20:03:24 [INFO]: Epoch 052 - training loss: 0.2603, validation loss: 0.1430
2024-05-22 20:03:24 [INFO]: Epoch 053 - training loss: 0.2612, validation loss: 0.1416
2024-05-22 20:03:24 [INFO]: Epoch 054 - training loss: 0.2595, validation loss: 0.1428
2024-05-22 20:03:24 [INFO]: Epoch 055 - training loss: 0.2594, validation loss: 0.1421
2024-05-22 20:03:25 [INFO]: Epoch 056 - training loss: 0.2580, validation loss: 0.1418
2024-05-22 20:03:25 [INFO]: Epoch 057 - training loss: 0.2575, validation loss: 0.1429
2024-05-22 20:03:25 [INFO]: Epoch 058 - training loss: 0.2568, validation loss: 0.1403
2024-05-22 20:03:26 [INFO]: Epoch 059 - training loss: 0.2556, validation loss: 0.1417
2024-05-22 20:03:26 [INFO]: Epoch 060 - training loss: 0.2556, validation loss: 0.1410
2024-05-22 20:03:26 [INFO]: Epoch 061 - training loss: 0.2558, validation loss: 0.1411
2024-05-22 20:03:26 [INFO]: Epoch 062 - training loss: 0.2538, validation loss: 0.1403
2024-05-22 20:03:27 [INFO]: Epoch 063 - training loss: 0.2538, validation loss: 0.1412
2024-05-22 20:03:27 [INFO]: Epoch 064 - training loss: 0.2544, validation loss: 0.1397
2024-05-22 20:03:27 [INFO]: Epoch 065 - training loss: 0.2523, validation loss: 0.1400
2024-05-22 20:03:28 [INFO]: Epoch 066 - training loss: 0.2510, validation loss: 0.1393
2024-05-22 20:03:28 [INFO]: Epoch 067 - training loss: 0.2514, validation loss: 0.1393
2024-05-22 20:03:28 [INFO]: Epoch 068 - training loss: 0.2506, validation loss: 0.1408
2024-05-22 20:03:28 [INFO]: Epoch 069 - training loss: 0.2487, validation loss: 0.1399
2024-05-22 20:03:29 [INFO]: Epoch 070 - training loss: 0.2482, validation loss: 0.1374
2024-05-22 20:03:29 [INFO]: Epoch 071 - training loss: 0.2510, validation loss: 0.1380
2024-05-22 20:03:29 [INFO]: Epoch 072 - training loss: 0.2482, validation loss: 0.1387
2024-05-22 20:03:30 [INFO]: Epoch 073 - training loss: 0.2445, validation loss: 0.1362
2024-05-22 20:03:30 [INFO]: Epoch 074 - training loss: 0.2438, validation loss: 0.1373
2024-05-22 20:03:30 [INFO]: Epoch 075 - training loss: 0.2432, validation loss: 0.1364
2024-05-22 20:03:31 [INFO]: Epoch 076 - training loss: 0.2441, validation loss: 0.1362
2024-05-22 20:03:31 [INFO]: Epoch 077 - training loss: 0.2433, validation loss: 0.1354
2024-05-22 20:03:31 [INFO]: Epoch 078 - training loss: 0.2437, validation loss: 0.1335
2024-05-22 20:03:31 [INFO]: Epoch 079 - training loss: 0.2419, validation loss: 0.1364
2024-05-22 20:03:32 [INFO]: Epoch 080 - training loss: 0.2437, validation loss: 0.1336
2024-05-22 20:03:32 [INFO]: Epoch 081 - training loss: 0.2421, validation loss: 0.1364
2024-05-22 20:03:32 [INFO]: Epoch 082 - training loss: 0.2440, validation loss: 0.1354
2024-05-22 20:03:32 [INFO]: Epoch 083 - training loss: 0.2404, validation loss: 0.1343
2024-05-22 20:03:33 [INFO]: Epoch 084 - training loss: 0.2372, validation loss: 0.1335
2024-05-22 20:03:33 [INFO]: Epoch 085 - training loss: 0.2369, validation loss: 0.1347
2024-05-22 20:03:33 [INFO]: Epoch 086 - training loss: 0.2371, validation loss: 0.1348
2024-05-22 20:03:34 [INFO]: Epoch 087 - training loss: 0.2369, validation loss: 0.1316
2024-05-22 20:03:34 [INFO]: Epoch 088 - training loss: 0.2347, validation loss: 0.1315
2024-05-22 20:03:34 [INFO]: Epoch 089 - training loss: 0.2341, validation loss: 0.1338
2024-05-22 20:03:34 [INFO]: Epoch 090 - training loss: 0.2352, validation loss: 0.1325
2024-05-22 20:03:35 [INFO]: Epoch 091 - training loss: 0.2335, validation loss: 0.1321
2024-05-22 20:03:35 [INFO]: Epoch 092 - training loss: 0.2375, validation loss: 0.1329
2024-05-22 20:03:35 [INFO]: Epoch 093 - training loss: 0.2366, validation loss: 0.1321
2024-05-22 20:03:36 [INFO]: Epoch 094 - training loss: 0.2347, validation loss: 0.1314
2024-05-22 20:03:36 [INFO]: Epoch 095 - training loss: 0.2363, validation loss: 0.1314
2024-05-22 20:03:36 [INFO]: Epoch 096 - training loss: 0.2320, validation loss: 0.1335
2024-05-22 20:03:36 [INFO]: Epoch 097 - training loss: 0.2331, validation loss: 0.1321
2024-05-22 20:03:37 [INFO]: Epoch 098 - training loss: 0.2319, validation loss: 0.1297
2024-05-22 20:03:37 [INFO]: Epoch 099 - training loss: 0.2304, validation loss: 0.1297
2024-05-22 20:03:37 [INFO]: Epoch 100 - training loss: 0.2294, validation loss: 0.1302
2024-05-22 20:03:38 [INFO]: Epoch 101 - training loss: 0.2282, validation loss: 0.1291
2024-05-22 20:03:38 [INFO]: Epoch 102 - training loss: 0.2282, validation loss: 0.1308
2024-05-22 20:03:38 [INFO]: Epoch 103 - training loss: 0.2294, validation loss: 0.1296
2024-05-22 20:03:38 [INFO]: Epoch 104 - training loss: 0.2292, validation loss: 0.1290
2024-05-22 20:03:39 [INFO]: Epoch 105 - training loss: 0.2322, validation loss: 0.1267
2024-05-22 20:03:39 [INFO]: Epoch 106 - training loss: 0.2277, validation loss: 0.1294
2024-05-22 20:03:39 [INFO]: Epoch 107 - training loss: 0.2316, validation loss: 0.1350
2024-05-22 20:03:40 [INFO]: Epoch 108 - training loss: 0.2322, validation loss: 0.1304
2024-05-22 20:03:40 [INFO]: Epoch 109 - training loss: 0.2258, validation loss: 0.1281
2024-05-22 20:03:40 [INFO]: Epoch 110 - training loss: 0.2251, validation loss: 0.1274
2024-05-22 20:03:40 [INFO]: Epoch 111 - training loss: 0.2264, validation loss: 0.1284
2024-05-22 20:03:41 [INFO]: Epoch 112 - training loss: 0.2258, validation loss: 0.1278
2024-05-22 20:03:41 [INFO]: Epoch 113 - training loss: 0.2243, validation loss: 0.1278
2024-05-22 20:03:41 [INFO]: Epoch 114 - training loss: 0.2254, validation loss: 0.1277
2024-05-22 20:03:42 [INFO]: Epoch 115 - training loss: 0.2217, validation loss: 0.1275
2024-05-22 20:03:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 20:03:42 [INFO]: Finished training. The best model is from epoch#105.
2024-05-22 20:03:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/Transformer_air_quality/20240522_T200308/Transformer.pypots
2024-05-22 20:03:42 [INFO]: Transformer on Air-Quality: MAE=0.1698, MSE=0.1365
2024-05-22 20:03:42 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/Transformer_air_quality/imputation.pkl
2024-05-22 20:03:42 [INFO]: Using the given device: cuda:0
2024-05-22 20:03:42 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/TimesNet_air_quality/20240522_T200342
2024-05-22 20:03:42 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/TimesNet_air_quality/20240522_T200342/tensorboard
2024-05-22 20:03:42 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-22 20:03:42 [INFO]: Epoch 001 - training loss: 0.2930, validation loss: 0.2460
2024-05-22 20:03:43 [INFO]: Epoch 002 - training loss: 0.2536, validation loss: 0.2126
2024-05-22 20:03:43 [INFO]: Epoch 003 - training loss: 0.2135, validation loss: 0.1946
2024-05-22 20:03:44 [INFO]: Epoch 004 - training loss: 0.1899, validation loss: 0.1960
2024-05-22 20:03:44 [INFO]: Epoch 005 - training loss: 0.1928, validation loss: 0.1884
2024-05-22 20:03:45 [INFO]: Epoch 006 - training loss: 0.1671, validation loss: 0.1746
2024-05-22 20:03:45 [INFO]: Epoch 007 - training loss: 0.1519, validation loss: 0.1673
2024-05-22 20:03:46 [INFO]: Epoch 008 - training loss: 0.1469, validation loss: 0.1658
2024-05-22 20:03:47 [INFO]: Epoch 009 - training loss: 0.1518, validation loss: 0.1610
2024-05-22 20:03:47 [INFO]: Epoch 010 - training loss: 0.1524, validation loss: 0.1598
2024-05-22 20:03:47 [INFO]: Epoch 011 - training loss: 0.1439, validation loss: 0.1551
2024-05-22 20:03:48 [INFO]: Epoch 012 - training loss: 0.1313, validation loss: 0.1526
2024-05-22 20:03:48 [INFO]: Epoch 013 - training loss: 0.1608, validation loss: 0.1486
2024-05-22 20:03:49 [INFO]: Epoch 014 - training loss: 0.1517, validation loss: 0.1555
2024-05-22 20:03:49 [INFO]: Epoch 015 - training loss: 0.1462, validation loss: 0.1598
2024-05-22 20:03:50 [INFO]: Epoch 016 - training loss: 0.1305, validation loss: 0.1458
2024-05-22 20:03:50 [INFO]: Epoch 017 - training loss: 0.1368, validation loss: 0.1496
2024-05-22 20:03:51 [INFO]: Epoch 018 - training loss: 0.1330, validation loss: 0.1512
2024-05-22 20:03:51 [INFO]: Epoch 019 - training loss: 0.1299, validation loss: 0.1471
2024-05-22 20:03:52 [INFO]: Epoch 020 - training loss: 0.1438, validation loss: 0.1452
2024-05-22 20:03:52 [INFO]: Epoch 021 - training loss: 0.1521, validation loss: 0.1481
2024-05-22 20:03:53 [INFO]: Epoch 022 - training loss: 0.1231, validation loss: 0.1438
2024-05-22 20:03:53 [INFO]: Epoch 023 - training loss: 0.1279, validation loss: 0.1409
2024-05-22 20:03:54 [INFO]: Epoch 024 - training loss: 0.1168, validation loss: 0.1386
2024-05-22 20:03:55 [INFO]: Epoch 025 - training loss: 0.1140, validation loss: 0.1375
2024-05-22 20:03:55 [INFO]: Epoch 026 - training loss: 0.1189, validation loss: 0.1409
2024-05-22 20:03:56 [INFO]: Epoch 027 - training loss: 0.1157, validation loss: 0.1365
2024-05-22 20:03:56 [INFO]: Epoch 028 - training loss: 0.1140, validation loss: 0.1371
2024-05-22 20:03:57 [INFO]: Epoch 029 - training loss: 0.1212, validation loss: 0.1395
2024-05-22 20:03:57 [INFO]: Epoch 030 - training loss: 0.1193, validation loss: 0.1422
2024-05-22 20:03:57 [INFO]: Epoch 031 - training loss: 0.1151, validation loss: 0.1397
2024-05-22 20:03:58 [INFO]: Epoch 032 - training loss: 0.1274, validation loss: 0.1400
2024-05-22 20:03:58 [INFO]: Epoch 033 - training loss: 0.1102, validation loss: 0.1371
2024-05-22 20:03:59 [INFO]: Epoch 034 - training loss: 0.1171, validation loss: 0.1377
2024-05-22 20:03:59 [INFO]: Epoch 035 - training loss: 0.1013, validation loss: 0.1414
2024-05-22 20:04:00 [INFO]: Epoch 036 - training loss: 0.1063, validation loss: 0.1341
2024-05-22 20:04:00 [INFO]: Epoch 037 - training loss: 0.0941, validation loss: 0.1382
2024-05-22 20:04:01 [INFO]: Epoch 038 - training loss: 0.1137, validation loss: 0.1366
2024-05-22 20:04:01 [INFO]: Epoch 039 - training loss: 0.1196, validation loss: 0.1377
2024-05-22 20:04:02 [INFO]: Epoch 040 - training loss: 0.1069, validation loss: 0.1310
2024-05-22 20:04:02 [INFO]: Epoch 041 - training loss: 0.1216, validation loss: 0.1315
2024-05-22 20:04:03 [INFO]: Epoch 042 - training loss: 0.1274, validation loss: 0.1282
2024-05-22 20:04:03 [INFO]: Epoch 043 - training loss: 0.1026, validation loss: 0.1293
2024-05-22 20:04:04 [INFO]: Epoch 044 - training loss: 0.1035, validation loss: 0.1365
2024-05-22 20:04:04 [INFO]: Epoch 045 - training loss: 0.1020, validation loss: 0.1299
2024-05-22 20:04:05 [INFO]: Epoch 046 - training loss: 0.1054, validation loss: 0.1298
2024-05-22 20:04:05 [INFO]: Epoch 047 - training loss: 0.1138, validation loss: 0.1358
2024-05-22 20:04:06 [INFO]: Epoch 048 - training loss: 0.1150, validation loss: 0.1331
2024-05-22 20:04:06 [INFO]: Epoch 049 - training loss: 0.1197, validation loss: 0.1290
2024-05-22 20:04:07 [INFO]: Epoch 050 - training loss: 0.1225, validation loss: 0.1327
2024-05-22 20:04:07 [INFO]: Epoch 051 - training loss: 0.1120, validation loss: 0.1365
2024-05-22 20:04:08 [INFO]: Epoch 052 - training loss: 0.1016, validation loss: 0.1362
2024-05-22 20:04:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 20:04:08 [INFO]: Finished training. The best model is from epoch#42.
2024-05-22 20:04:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/TimesNet_air_quality/20240522_T200342/TimesNet.pypots
2024-05-22 20:04:08 [INFO]: TimesNet on Air-Quality: MAE=0.1590, MSE=0.1502
2024-05-22 20:04:08 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/TimesNet_air_quality/imputation.pkl
2024-05-22 20:04:08 [INFO]: Using the given device: cuda:0
2024-05-22 20:04:08 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408
2024-05-22 20:04:08 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/tensorboard
2024-05-22 20:04:08 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-22 20:04:24 [INFO]: Epoch 001 - training loss: 0.4763, validation loss: 0.3475
2024-05-22 20:04:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch1_loss0.34746384918689727.pypots
2024-05-22 20:04:41 [INFO]: Epoch 002 - training loss: 0.2917, validation loss: 0.2712
2024-05-22 20:04:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch2_loss0.271174980700016.pypots
2024-05-22 20:04:57 [INFO]: Epoch 003 - training loss: 0.2540, validation loss: 0.2281
2024-05-22 20:04:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch3_loss0.22813665717840195.pypots
2024-05-22 20:05:14 [INFO]: Epoch 004 - training loss: 0.2181, validation loss: 0.1891
2024-05-22 20:05:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch4_loss0.1891465961933136.pypots
2024-05-22 20:05:31 [INFO]: Epoch 005 - training loss: 0.1934, validation loss: 0.1799
2024-05-22 20:05:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch5_loss0.17992777228355408.pypots
2024-05-22 20:05:47 [INFO]: Epoch 006 - training loss: 0.1884, validation loss: 0.1651
2024-05-22 20:05:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch6_loss0.16511708050966262.pypots
2024-05-22 20:06:04 [INFO]: Epoch 007 - training loss: 0.1932, validation loss: 0.1652
2024-05-22 20:06:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch7_loss0.16520582139492035.pypots
2024-05-22 20:06:20 [INFO]: Epoch 008 - training loss: 0.1760, validation loss: 0.1553
2024-05-22 20:06:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch8_loss0.1552694782614708.pypots
2024-05-22 20:06:37 [INFO]: Epoch 009 - training loss: 0.1753, validation loss: 0.1529
2024-05-22 20:06:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch9_loss0.15287706702947618.pypots
2024-05-22 20:06:53 [INFO]: Epoch 010 - training loss: 0.1755, validation loss: 0.1520
2024-05-22 20:06:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch10_loss0.15204385668039322.pypots
2024-05-22 20:07:10 [INFO]: Epoch 011 - training loss: 0.1763, validation loss: 0.1497
2024-05-22 20:07:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch11_loss0.14973761439323424.pypots
2024-05-22 20:07:27 [INFO]: Epoch 012 - training loss: 0.1567, validation loss: 0.1494
2024-05-22 20:07:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch12_loss0.1493736431002617.pypots
2024-05-22 20:07:43 [INFO]: Epoch 013 - training loss: 0.1718, validation loss: 0.1540
2024-05-22 20:07:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch13_loss0.15397606045007706.pypots
2024-05-22 20:08:00 [INFO]: Epoch 014 - training loss: 0.1738, validation loss: 0.1424
2024-05-22 20:08:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch14_loss0.14239143654704095.pypots
2024-05-22 20:08:16 [INFO]: Epoch 015 - training loss: 0.1581, validation loss: 0.1457
2024-05-22 20:08:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch15_loss0.14567359983921052.pypots
2024-05-22 20:08:33 [INFO]: Epoch 016 - training loss: 0.1580, validation loss: 0.1403
2024-05-22 20:08:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch16_loss0.1403036206960678.pypots
2024-05-22 20:08:49 [INFO]: Epoch 017 - training loss: 0.1546, validation loss: 0.1392
2024-05-22 20:08:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch17_loss0.13921570256352425.pypots
2024-05-22 20:09:06 [INFO]: Epoch 018 - training loss: 0.1659, validation loss: 0.1431
2024-05-22 20:09:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch18_loss0.143144079297781.pypots
2024-05-22 20:09:23 [INFO]: Epoch 019 - training loss: 0.1755, validation loss: 0.1390
2024-05-22 20:09:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch19_loss0.13899221196770667.pypots
2024-05-22 20:09:39 [INFO]: Epoch 020 - training loss: 0.1666, validation loss: 0.1372
2024-05-22 20:09:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch20_loss0.13724874779582025.pypots
2024-05-22 20:09:56 [INFO]: Epoch 021 - training loss: 0.1631, validation loss: 0.1394
2024-05-22 20:09:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch21_loss0.13943906947970391.pypots
2024-05-22 20:10:12 [INFO]: Epoch 022 - training loss: 0.1668, validation loss: 0.1395
2024-05-22 20:10:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch22_loss0.13945364579558372.pypots
2024-05-22 20:10:29 [INFO]: Epoch 023 - training loss: 0.1572, validation loss: 0.1346
2024-05-22 20:10:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch23_loss0.13464627861976625.pypots
2024-05-22 20:10:45 [INFO]: Epoch 024 - training loss: 0.1505, validation loss: 0.1325
2024-05-22 20:10:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch24_loss0.13246645480394365.pypots
2024-05-22 20:11:02 [INFO]: Epoch 025 - training loss: 0.1299, validation loss: 0.1329
2024-05-22 20:11:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch25_loss0.13293140828609468.pypots
2024-05-22 20:11:18 [INFO]: Epoch 026 - training loss: 0.1379, validation loss: 0.1355
2024-05-22 20:11:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch26_loss0.13546589985489846.pypots
2024-05-22 20:11:35 [INFO]: Epoch 027 - training loss: 0.1473, validation loss: 0.1302
2024-05-22 20:11:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch27_loss0.13021574094891547.pypots
2024-05-22 20:11:52 [INFO]: Epoch 028 - training loss: 0.1363, validation loss: 0.1343
2024-05-22 20:11:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch28_loss0.13426158502697944.pypots
2024-05-22 20:12:08 [INFO]: Epoch 029 - training loss: 0.1469, validation loss: 0.1310
2024-05-22 20:12:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch29_loss0.1310298666357994.pypots
2024-05-22 20:12:25 [INFO]: Epoch 030 - training loss: 0.1452, validation loss: 0.1320
2024-05-22 20:12:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch30_loss0.13203384801745416.pypots
2024-05-22 20:12:41 [INFO]: Epoch 031 - training loss: 0.1454, validation loss: 0.1294
2024-05-22 20:12:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch31_loss0.12935170233249665.pypots
2024-05-22 20:12:58 [INFO]: Epoch 032 - training loss: 0.1411, validation loss: 0.1274
2024-05-22 20:12:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch32_loss0.1274141177535057.pypots
2024-05-22 20:13:14 [INFO]: Epoch 033 - training loss: 0.1413, validation loss: 0.1274
2024-05-22 20:13:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch33_loss0.12735613510012628.pypots
2024-05-22 20:13:31 [INFO]: Epoch 034 - training loss: 0.1395, validation loss: 0.1315
2024-05-22 20:13:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch34_loss0.13146261349320412.pypots
2024-05-22 20:13:47 [INFO]: Epoch 035 - training loss: 0.1532, validation loss: 0.1278
2024-05-22 20:13:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch35_loss0.12784745991230012.pypots
2024-05-22 20:14:04 [INFO]: Epoch 036 - training loss: 0.1377, validation loss: 0.1311
2024-05-22 20:14:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch36_loss0.13110590353608131.pypots
2024-05-22 20:14:20 [INFO]: Epoch 037 - training loss: 0.1459, validation loss: 0.1268
2024-05-22 20:14:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch37_loss0.12678068801760672.pypots
2024-05-22 20:14:37 [INFO]: Epoch 038 - training loss: 0.1382, validation loss: 0.1262
2024-05-22 20:14:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch38_loss0.1262476250529289.pypots
2024-05-22 20:14:54 [INFO]: Epoch 039 - training loss: 0.1275, validation loss: 0.1283
2024-05-22 20:14:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch39_loss0.1282591812312603.pypots
2024-05-22 20:15:10 [INFO]: Epoch 040 - training loss: 0.1378, validation loss: 0.1239
2024-05-22 20:15:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch40_loss0.12385385259985923.pypots
2024-05-22 20:15:27 [INFO]: Epoch 041 - training loss: 0.1344, validation loss: 0.1242
2024-05-22 20:15:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch41_loss0.12418698072433472.pypots
2024-05-22 20:15:43 [INFO]: Epoch 042 - training loss: 0.1335, validation loss: 0.1185
2024-05-22 20:15:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch42_loss0.11854156106710434.pypots
2024-05-22 20:16:00 [INFO]: Epoch 043 - training loss: 0.1372, validation loss: 0.1191
2024-05-22 20:16:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch43_loss0.11913198381662368.pypots
2024-05-22 20:16:17 [INFO]: Epoch 044 - training loss: 0.1390, validation loss: 0.1214
2024-05-22 20:16:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch44_loss0.12142545282840729.pypots
2024-05-22 20:16:33 [INFO]: Epoch 045 - training loss: 0.1441, validation loss: 0.1172
2024-05-22 20:16:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch45_loss0.11715409308671951.pypots
2024-05-22 20:16:50 [INFO]: Epoch 046 - training loss: 0.1342, validation loss: 0.1222
2024-05-22 20:16:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch46_loss0.12221095636487007.pypots
2024-05-22 20:17:06 [INFO]: Epoch 047 - training loss: 0.1198, validation loss: 0.1308
2024-05-22 20:17:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch47_loss0.13080644235014915.pypots
2024-05-22 20:17:23 [INFO]: Epoch 048 - training loss: 0.1297, validation loss: 0.1184
2024-05-22 20:17:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch48_loss0.118438982963562.pypots
2024-05-22 20:17:39 [INFO]: Epoch 049 - training loss: 0.1083, validation loss: 0.1137
2024-05-22 20:17:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch49_loss0.11369875892996788.pypots
2024-05-22 20:17:56 [INFO]: Epoch 050 - training loss: 0.1257, validation loss: 0.1177
2024-05-22 20:17:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch50_loss0.11773632243275642.pypots
2024-05-22 20:18:12 [INFO]: Epoch 051 - training loss: 0.1165, validation loss: 0.1186
2024-05-22 20:18:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch51_loss0.11864007636904716.pypots
2024-05-22 20:18:29 [INFO]: Epoch 052 - training loss: 0.1258, validation loss: 0.1136
2024-05-22 20:18:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch52_loss0.11358005851507187.pypots
2024-05-22 20:18:45 [INFO]: Epoch 053 - training loss: 0.1260, validation loss: 0.1149
2024-05-22 20:18:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch53_loss0.11493163406848908.pypots
2024-05-22 20:19:02 [INFO]: Epoch 054 - training loss: 0.1286, validation loss: 0.1156
2024-05-22 20:19:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch54_loss0.11560529693961144.pypots
2024-05-22 20:19:19 [INFO]: Epoch 055 - training loss: 0.1111, validation loss: 0.1143
2024-05-22 20:19:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch55_loss0.1143308348953724.pypots
2024-05-22 20:19:35 [INFO]: Epoch 056 - training loss: 0.1310, validation loss: 0.1110
2024-05-22 20:19:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch56_loss0.11097865924239159.pypots
2024-05-22 20:19:52 [INFO]: Epoch 057 - training loss: 0.1371, validation loss: 0.1134
2024-05-22 20:19:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch57_loss0.11339392587542534.pypots
2024-05-22 20:20:08 [INFO]: Epoch 058 - training loss: 0.1134, validation loss: 0.1190
2024-05-22 20:20:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch58_loss0.11901731565594673.pypots
2024-05-22 20:20:25 [INFO]: Epoch 059 - training loss: 0.1221, validation loss: 0.1139
2024-05-22 20:20:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch59_loss0.11385350748896599.pypots
2024-05-22 20:20:41 [INFO]: Epoch 060 - training loss: 0.1238, validation loss: 0.1094
2024-05-22 20:20:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch60_loss0.10943132415413856.pypots
2024-05-22 20:20:58 [INFO]: Epoch 061 - training loss: 0.1195, validation loss: 0.1089
2024-05-22 20:20:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch61_loss0.1088920459151268.pypots
2024-05-22 20:21:14 [INFO]: Epoch 062 - training loss: 0.1206, validation loss: 0.1085
2024-05-22 20:21:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch62_loss0.10845063254237175.pypots
2024-05-22 20:21:31 [INFO]: Epoch 063 - training loss: 0.1060, validation loss: 0.1096
2024-05-22 20:21:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch63_loss0.10963801890611649.pypots
2024-05-22 20:21:47 [INFO]: Epoch 064 - training loss: 0.1155, validation loss: 0.1072
2024-05-22 20:21:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch64_loss0.10723340883851051.pypots
2024-05-22 20:22:04 [INFO]: Epoch 065 - training loss: 0.1297, validation loss: 0.1135
2024-05-22 20:22:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch65_loss0.11353742033243179.pypots
2024-05-22 20:22:20 [INFO]: Epoch 066 - training loss: 0.1337, validation loss: 0.1079
2024-05-22 20:22:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch66_loss0.1079049825668335.pypots
2024-05-22 20:22:37 [INFO]: Epoch 067 - training loss: 0.1308, validation loss: 0.1081
2024-05-22 20:22:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch67_loss0.1081140011548996.pypots
2024-05-22 20:22:53 [INFO]: Epoch 068 - training loss: 0.1115, validation loss: 0.1084
2024-05-22 20:22:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch68_loss0.10842117741703987.pypots
2024-05-22 20:23:10 [INFO]: Epoch 069 - training loss: 0.1110, validation loss: 0.1081
2024-05-22 20:23:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch69_loss0.10809030905365943.pypots
2024-05-22 20:23:26 [INFO]: Epoch 070 - training loss: 0.1282, validation loss: 0.1077
2024-05-22 20:23:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch70_loss0.10767618790268899.pypots
2024-05-22 20:23:43 [INFO]: Epoch 071 - training loss: 0.1099, validation loss: 0.1078
2024-05-22 20:23:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch71_loss0.10783039554953575.pypots
2024-05-22 20:24:00 [INFO]: Epoch 072 - training loss: 0.1257, validation loss: 0.1092
2024-05-22 20:24:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch72_loss0.10915962010622024.pypots
2024-05-22 20:24:16 [INFO]: Epoch 073 - training loss: 0.1120, validation loss: 0.1084
2024-05-22 20:24:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch73_loss0.10838868170976639.pypots
2024-05-22 20:24:33 [INFO]: Epoch 074 - training loss: 0.1098, validation loss: 0.1063
2024-05-22 20:24:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch74_loss0.10626762360334396.pypots
2024-05-22 20:24:49 [INFO]: Epoch 075 - training loss: 0.1109, validation loss: 0.1062
2024-05-22 20:24:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch75_loss0.10621099844574929.pypots
2024-05-22 20:25:06 [INFO]: Epoch 076 - training loss: 0.1205, validation loss: 0.1071
2024-05-22 20:25:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch76_loss0.10705986544489861.pypots
2024-05-22 20:25:22 [INFO]: Epoch 077 - training loss: 0.1132, validation loss: 0.1100
2024-05-22 20:25:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch77_loss0.10995382890105247.pypots
2024-05-22 20:25:39 [INFO]: Epoch 078 - training loss: 0.1193, validation loss: 0.1091
2024-05-22 20:25:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch78_loss0.10909401401877403.pypots
2024-05-22 20:25:55 [INFO]: Epoch 079 - training loss: 0.1129, validation loss: 0.1066
2024-05-22 20:25:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch79_loss0.10664950460195541.pypots
2024-05-22 20:26:12 [INFO]: Epoch 080 - training loss: 0.1151, validation loss: 0.1074
2024-05-22 20:26:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch80_loss0.10743719264864922.pypots
2024-05-22 20:26:29 [INFO]: Epoch 081 - training loss: 0.1195, validation loss: 0.1058
2024-05-22 20:26:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch81_loss0.10581691563129425.pypots
2024-05-22 20:26:45 [INFO]: Epoch 082 - training loss: 0.1130, validation loss: 0.1115
2024-05-22 20:26:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch82_loss0.11145909354090691.pypots
2024-05-22 20:27:02 [INFO]: Epoch 083 - training loss: 0.1081, validation loss: 0.1071
2024-05-22 20:27:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch83_loss0.10713919773697853.pypots
2024-05-22 20:27:18 [INFO]: Epoch 084 - training loss: 0.1074, validation loss: 0.1060
2024-05-22 20:27:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch84_loss0.1060391791164875.pypots
2024-05-22 20:27:35 [INFO]: Epoch 085 - training loss: 0.1309, validation loss: 0.1043
2024-05-22 20:27:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch85_loss0.10433319956064224.pypots
2024-05-22 20:27:51 [INFO]: Epoch 086 - training loss: 0.1130, validation loss: 0.1057
2024-05-22 20:27:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch86_loss0.10572243332862855.pypots
2024-05-22 20:28:08 [INFO]: Epoch 087 - training loss: 0.1147, validation loss: 0.1059
2024-05-22 20:28:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch87_loss0.10585461780428887.pypots
2024-05-22 20:28:24 [INFO]: Epoch 088 - training loss: 0.1289, validation loss: 0.1049
2024-05-22 20:28:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch88_loss0.10488412976264953.pypots
2024-05-22 20:28:41 [INFO]: Epoch 089 - training loss: 0.1202, validation loss: 0.1072
2024-05-22 20:28:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch89_loss0.10724953636527061.pypots
2024-05-22 20:28:57 [INFO]: Epoch 090 - training loss: 0.1104, validation loss: 0.1054
2024-05-22 20:28:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch90_loss0.1054276742041111.pypots
2024-05-22 20:29:14 [INFO]: Epoch 091 - training loss: 0.1197, validation loss: 0.1060
2024-05-22 20:29:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch91_loss0.10604237914085388.pypots
2024-05-22 20:29:31 [INFO]: Epoch 092 - training loss: 0.1274, validation loss: 0.1056
2024-05-22 20:29:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch92_loss0.10557598471641541.pypots
2024-05-22 20:29:47 [INFO]: Epoch 093 - training loss: 0.1152, validation loss: 0.1045
2024-05-22 20:29:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch93_loss0.10450710207223893.pypots
2024-05-22 20:30:04 [INFO]: Epoch 094 - training loss: 0.1169, validation loss: 0.1046
2024-05-22 20:30:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch94_loss0.10456980168819427.pypots
2024-05-22 20:30:20 [INFO]: Epoch 095 - training loss: 0.1127, validation loss: 0.1042
2024-05-22 20:30:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch95_loss0.10419268235564232.pypots
2024-05-22 20:30:37 [INFO]: Epoch 096 - training loss: 0.1051, validation loss: 0.1106
2024-05-22 20:30:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch96_loss0.11058552414178849.pypots
2024-05-22 20:30:53 [INFO]: Epoch 097 - training loss: 0.1130, validation loss: 0.1036
2024-05-22 20:30:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch97_loss0.10364021956920624.pypots
2024-05-22 20:31:10 [INFO]: Epoch 098 - training loss: 0.1084, validation loss: 0.1092
2024-05-22 20:31:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch98_loss0.10919535011053086.pypots
2024-05-22 20:31:26 [INFO]: Epoch 099 - training loss: 0.1158, validation loss: 0.1049
2024-05-22 20:31:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch99_loss0.10485232397913932.pypots
2024-05-22 20:31:43 [INFO]: Epoch 100 - training loss: 0.1203, validation loss: 0.1070
2024-05-22 20:31:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch100_loss0.10701869279146195.pypots
2024-05-22 20:31:59 [INFO]: Epoch 101 - training loss: 0.1183, validation loss: 0.1040
2024-05-22 20:31:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch101_loss0.10401459857821464.pypots
2024-05-22 20:32:16 [INFO]: Epoch 102 - training loss: 0.1176, validation loss: 0.1054
2024-05-22 20:32:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch102_loss0.10536326244473457.pypots
2024-05-22 20:32:33 [INFO]: Epoch 103 - training loss: 0.1247, validation loss: 0.1060
2024-05-22 20:32:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch103_loss0.10598528683185578.pypots
2024-05-22 20:32:49 [INFO]: Epoch 104 - training loss: 0.1091, validation loss: 0.1025
2024-05-22 20:32:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch104_loss0.10245678946375847.pypots
2024-05-22 20:33:06 [INFO]: Epoch 105 - training loss: 0.1084, validation loss: 0.1015
2024-05-22 20:33:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch105_loss0.10147846043109894.pypots
2024-05-22 20:33:22 [INFO]: Epoch 106 - training loss: 0.1181, validation loss: 0.1005
2024-05-22 20:33:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch106_loss0.1004669837653637.pypots
2024-05-22 20:33:39 [INFO]: Epoch 107 - training loss: 0.1075, validation loss: 0.1006
2024-05-22 20:33:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch107_loss0.1006140686571598.pypots
2024-05-22 20:33:55 [INFO]: Epoch 108 - training loss: 0.1177, validation loss: 0.1001
2024-05-22 20:33:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch108_loss0.10005567073822022.pypots
2024-05-22 20:34:12 [INFO]: Epoch 109 - training loss: 0.1152, validation loss: 0.1001
2024-05-22 20:34:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch109_loss0.10008818060159683.pypots
2024-05-22 20:34:28 [INFO]: Epoch 110 - training loss: 0.1120, validation loss: 0.1025
2024-05-22 20:34:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch110_loss0.10247054249048233.pypots
2024-05-22 20:34:45 [INFO]: Epoch 111 - training loss: 0.1184, validation loss: 0.1097
2024-05-22 20:34:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch111_loss0.10974887609481812.pypots
2024-05-22 20:35:01 [INFO]: Epoch 112 - training loss: 0.1258, validation loss: 0.1044
2024-05-22 20:35:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch112_loss0.10441031157970429.pypots
2024-05-22 20:35:18 [INFO]: Epoch 113 - training loss: 0.1140, validation loss: 0.1027
2024-05-22 20:35:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch113_loss0.10269023180007934.pypots
2024-05-22 20:35:34 [INFO]: Epoch 114 - training loss: 0.1150, validation loss: 0.1016
2024-05-22 20:35:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch114_loss0.10159216821193695.pypots
2024-05-22 20:35:51 [INFO]: Epoch 115 - training loss: 0.1174, validation loss: 0.1024
2024-05-22 20:35:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch115_loss0.10237695053219795.pypots
2024-05-22 20:36:07 [INFO]: Epoch 116 - training loss: 0.1224, validation loss: 0.1025
2024-05-22 20:36:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch116_loss0.10253020375967026.pypots
2024-05-22 20:36:24 [INFO]: Epoch 117 - training loss: 0.1189, validation loss: 0.1011
2024-05-22 20:36:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch117_loss0.10113634169101715.pypots
2024-05-22 20:36:40 [INFO]: Epoch 118 - training loss: 0.1144, validation loss: 0.1003
2024-05-22 20:36:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI_epoch118_loss0.10031553134322166.pypots
2024-05-22 20:36:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 20:36:40 [INFO]: Finished training. The best model is from epoch#108.
2024-05-22 20:36:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/20240522_T200408/CSDI.pypots
2024-05-22 20:38:58 [INFO]: CSDI on Air-Quality: MAE=0.1026, MSE=0.1737
2024-05-22 20:38:58 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/CSDI_air_quality/imputation.pkl
2024-05-22 20:38:58 [INFO]: Using the given device: cuda:0
2024-05-22 20:38:58 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/GPVAE_air_quality/20240522_T203858
2024-05-22 20:38:58 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/GPVAE_air_quality/20240522_T203858/tensorboard
2024-05-22 20:38:58 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-22 20:38:58 [INFO]: Epoch 001 - training loss: 63530.3913, validation loss: 0.6413
2024-05-22 20:38:59 [INFO]: Epoch 002 - training loss: 42098.5392, validation loss: 0.5476
2024-05-22 20:38:59 [INFO]: Epoch 003 - training loss: 41747.6882, validation loss: 0.5104
2024-05-22 20:38:59 [INFO]: Epoch 004 - training loss: 41633.8753, validation loss: 0.4694
2024-05-22 20:38:59 [INFO]: Epoch 005 - training loss: 41540.6541, validation loss: 0.4153
2024-05-22 20:39:00 [INFO]: Epoch 006 - training loss: 41493.5683, validation loss: 0.4104
2024-05-22 20:39:00 [INFO]: Epoch 007 - training loss: 41452.0968, validation loss: 0.3513
2024-05-22 20:39:00 [INFO]: Epoch 008 - training loss: 41421.7335, validation loss: 0.3338
2024-05-22 20:39:00 [INFO]: Epoch 009 - training loss: 41398.5187, validation loss: 0.3171
2024-05-22 20:39:01 [INFO]: Epoch 010 - training loss: 41421.3961, validation loss: 0.3617
2024-05-22 20:39:01 [INFO]: Epoch 011 - training loss: 41387.2659, validation loss: 0.3120
2024-05-22 20:39:01 [INFO]: Epoch 012 - training loss: 41333.4973, validation loss: 0.3095
2024-05-22 20:39:01 [INFO]: Epoch 013 - training loss: 41315.3095, validation loss: 0.2943
2024-05-22 20:39:02 [INFO]: Epoch 014 - training loss: 41320.0320, validation loss: 0.2880
2024-05-22 20:39:02 [INFO]: Epoch 015 - training loss: 41298.2578, validation loss: 0.2868
2024-05-22 20:39:02 [INFO]: Epoch 016 - training loss: 41320.9414, validation loss: 0.2828
2024-05-22 20:39:02 [INFO]: Epoch 017 - training loss: 41315.0975, validation loss: 0.2839
2024-05-22 20:39:03 [INFO]: Epoch 018 - training loss: 41284.3504, validation loss: 0.2910
2024-05-22 20:39:03 [INFO]: Epoch 019 - training loss: 41272.0929, validation loss: 0.2638
2024-05-22 20:39:03 [INFO]: Epoch 020 - training loss: 41264.0514, validation loss: 0.2653
2024-05-22 20:39:03 [INFO]: Epoch 021 - training loss: 41247.0978, validation loss: 0.2602
2024-05-22 20:39:04 [INFO]: Epoch 022 - training loss: 41249.5314, validation loss: 0.2519
2024-05-22 20:39:04 [INFO]: Epoch 023 - training loss: 41262.2060, validation loss: 0.2746
2024-05-22 20:39:04 [INFO]: Epoch 024 - training loss: 41252.5229, validation loss: 0.2517
2024-05-22 20:39:04 [INFO]: Epoch 025 - training loss: 41250.3206, validation loss: 0.2542
2024-05-22 20:39:05 [INFO]: Epoch 026 - training loss: 41256.0606, validation loss: 0.2828
2024-05-22 20:39:05 [INFO]: Epoch 027 - training loss: 41251.9688, validation loss: 0.2692
2024-05-22 20:39:05 [INFO]: Epoch 028 - training loss: 41232.9528, validation loss: 0.2418
2024-05-22 20:39:05 [INFO]: Epoch 029 - training loss: 41221.4841, validation loss: 0.2550
2024-05-22 20:39:06 [INFO]: Epoch 030 - training loss: 41225.7909, validation loss: 0.2436
2024-05-22 20:39:06 [INFO]: Epoch 031 - training loss: 41213.3423, validation loss: 0.2553
2024-05-22 20:39:06 [INFO]: Epoch 032 - training loss: 41209.3080, validation loss: 0.2507
2024-05-22 20:39:06 [INFO]: Epoch 033 - training loss: 41202.4010, validation loss: 0.2368
2024-05-22 20:39:07 [INFO]: Epoch 034 - training loss: 41194.5354, validation loss: 0.2378
2024-05-22 20:39:07 [INFO]: Epoch 035 - training loss: 41193.3070, validation loss: 0.2310
2024-05-22 20:39:07 [INFO]: Epoch 036 - training loss: 41210.2723, validation loss: 0.2406
2024-05-22 20:39:07 [INFO]: Epoch 037 - training loss: 41224.5707, validation loss: 0.2478
2024-05-22 20:39:08 [INFO]: Epoch 038 - training loss: 41209.8958, validation loss: 0.2502
2024-05-22 20:39:08 [INFO]: Epoch 039 - training loss: 41208.1027, validation loss: 0.2527
2024-05-22 20:39:08 [INFO]: Epoch 040 - training loss: 41211.0347, validation loss: 0.2283
2024-05-22 20:39:08 [INFO]: Epoch 041 - training loss: 41189.6253, validation loss: 0.2403
2024-05-22 20:39:09 [INFO]: Epoch 042 - training loss: 41233.5440, validation loss: 0.2374
2024-05-22 20:39:09 [INFO]: Epoch 043 - training loss: 41231.2804, validation loss: 0.2560
2024-05-22 20:39:09 [INFO]: Epoch 044 - training loss: 41248.8291, validation loss: 0.2517
2024-05-22 20:39:09 [INFO]: Epoch 045 - training loss: 41191.4800, validation loss: 0.2241
2024-05-22 20:39:10 [INFO]: Epoch 046 - training loss: 41180.8354, validation loss: 0.2252
2024-05-22 20:39:10 [INFO]: Epoch 047 - training loss: 41168.1188, validation loss: 0.2134
2024-05-22 20:39:10 [INFO]: Epoch 048 - training loss: 41164.1848, validation loss: 0.2130
2024-05-22 20:39:10 [INFO]: Epoch 049 - training loss: 41167.4245, validation loss: 0.2225
2024-05-22 20:39:11 [INFO]: Epoch 050 - training loss: 41165.0448, validation loss: 0.2164
2024-05-22 20:39:11 [INFO]: Epoch 051 - training loss: 41162.6479, validation loss: 0.2131
2024-05-22 20:39:11 [INFO]: Epoch 052 - training loss: 41164.6745, validation loss: 0.2208
2024-05-22 20:39:11 [INFO]: Epoch 053 - training loss: 41172.4310, validation loss: 0.2248
2024-05-22 20:39:12 [INFO]: Epoch 054 - training loss: 41183.1850, validation loss: 0.2177
2024-05-22 20:39:12 [INFO]: Epoch 055 - training loss: 41165.5836, validation loss: 0.2126
2024-05-22 20:39:12 [INFO]: Epoch 056 - training loss: 41176.3403, validation loss: 0.2369
2024-05-22 20:39:12 [INFO]: Epoch 057 - training loss: 41212.5185, validation loss: 0.2194
2024-05-22 20:39:12 [INFO]: Epoch 058 - training loss: 41164.5285, validation loss: 0.2033
2024-05-22 20:39:13 [INFO]: Epoch 059 - training loss: 41162.9381, validation loss: 0.2083
2024-05-22 20:39:13 [INFO]: Epoch 060 - training loss: 41164.1324, validation loss: 0.2506
2024-05-22 20:39:13 [INFO]: Epoch 061 - training loss: 41166.2224, validation loss: 0.2183
2024-05-22 20:39:13 [INFO]: Epoch 062 - training loss: 41152.2597, validation loss: 0.2154
2024-05-22 20:39:14 [INFO]: Epoch 063 - training loss: 41147.7747, validation loss: 0.2121
2024-05-22 20:39:14 [INFO]: Epoch 064 - training loss: 41143.7869, validation loss: 0.1982
2024-05-22 20:39:14 [INFO]: Epoch 065 - training loss: 41157.2244, validation loss: 0.2248
2024-05-22 20:39:14 [INFO]: Epoch 066 - training loss: 41164.6204, validation loss: 0.2080
2024-05-22 20:39:15 [INFO]: Epoch 067 - training loss: 41143.0783, validation loss: 0.2052
2024-05-22 20:39:15 [INFO]: Epoch 068 - training loss: 41145.1377, validation loss: 0.2099
2024-05-22 20:39:15 [INFO]: Epoch 069 - training loss: 41143.6944, validation loss: 0.2118
2024-05-22 20:39:15 [INFO]: Epoch 070 - training loss: 41149.6366, validation loss: 0.2027
2024-05-22 20:39:16 [INFO]: Epoch 071 - training loss: 41148.0203, validation loss: 0.2116
2024-05-22 20:39:16 [INFO]: Epoch 072 - training loss: 41198.9660, validation loss: 0.2537
2024-05-22 20:39:16 [INFO]: Epoch 073 - training loss: 41212.5302, validation loss: 0.2205
2024-05-22 20:39:16 [INFO]: Epoch 074 - training loss: 41193.5611, validation loss: 0.2253
2024-05-22 20:39:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 20:39:16 [INFO]: Finished training. The best model is from epoch#64.
2024-05-22 20:39:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/GPVAE_air_quality/20240522_T203858/GPVAE.pypots
2024-05-22 20:39:16 [INFO]: GP-VAE on Air-Quality: MAE=0.2900, MSE=0.2398
2024-05-22 20:39:16 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/GPVAE_air_quality/imputation.pkl
2024-05-22 20:39:16 [INFO]: Using the given device: cuda:0
2024-05-22 20:39:16 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/USGAN_air_quality/20240522_T203916
2024-05-22 20:39:16 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/USGAN_air_quality/20240522_T203916/tensorboard
2024-05-22 20:39:16 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-22 20:39:20 [INFO]: Epoch 001 - generator training loss: 0.6058, discriminator training loss: 0.2863, validation loss: 0.4911
2024-05-22 20:39:24 [INFO]: Epoch 002 - generator training loss: 0.2906, discriminator training loss: 0.0674, validation loss: 0.3604
2024-05-22 20:39:27 [INFO]: Epoch 003 - generator training loss: 0.2146, discriminator training loss: 0.0632, validation loss: 0.2939
2024-05-22 20:39:31 [INFO]: Epoch 004 - generator training loss: 0.1776, discriminator training loss: 0.0620, validation loss: 0.2564
2024-05-22 20:39:34 [INFO]: Epoch 005 - generator training loss: 0.1574, discriminator training loss: 0.0617, validation loss: 0.2300
2024-05-22 20:39:38 [INFO]: Epoch 006 - generator training loss: 0.1352, discriminator training loss: 0.0612, validation loss: 0.2118
2024-05-22 20:39:41 [INFO]: Epoch 007 - generator training loss: 0.1222, discriminator training loss: 0.0608, validation loss: 0.1989
2024-05-22 20:39:44 [INFO]: Epoch 008 - generator training loss: 0.1122, discriminator training loss: 0.0602, validation loss: 0.1892
2024-05-22 20:39:48 [INFO]: Epoch 009 - generator training loss: 0.1046, discriminator training loss: 0.0603, validation loss: 0.1804
2024-05-22 20:39:51 [INFO]: Epoch 010 - generator training loss: 0.0974, discriminator training loss: 0.0591, validation loss: 0.1735
2024-05-22 20:39:55 [INFO]: Epoch 011 - generator training loss: 0.0934, discriminator training loss: 0.0578, validation loss: 0.1679
2024-05-22 20:39:58 [INFO]: Epoch 012 - generator training loss: 0.0873, discriminator training loss: 0.0568, validation loss: 0.1631
2024-05-22 20:40:01 [INFO]: Epoch 013 - generator training loss: 0.0842, discriminator training loss: 0.0561, validation loss: 0.1588
2024-05-22 20:40:05 [INFO]: Epoch 014 - generator training loss: 0.0811, discriminator training loss: 0.0544, validation loss: 0.1543
2024-05-22 20:40:08 [INFO]: Epoch 015 - generator training loss: 0.0776, discriminator training loss: 0.0530, validation loss: 0.1510
2024-05-22 20:40:12 [INFO]: Epoch 016 - generator training loss: 0.0775, discriminator training loss: 0.0517, validation loss: 0.1480
2024-05-22 20:40:15 [INFO]: Epoch 017 - generator training loss: 0.0752, discriminator training loss: 0.0494, validation loss: 0.1455
2024-05-22 20:40:19 [INFO]: Epoch 018 - generator training loss: 0.0733, discriminator training loss: 0.0477, validation loss: 0.1431
2024-05-22 20:40:22 [INFO]: Epoch 019 - generator training loss: 0.0718, discriminator training loss: 0.0473, validation loss: 0.1403
2024-05-22 20:40:25 [INFO]: Epoch 020 - generator training loss: 0.0697, discriminator training loss: 0.0456, validation loss: 0.1383
2024-05-22 20:40:29 [INFO]: Epoch 021 - generator training loss: 0.0668, discriminator training loss: 0.0448, validation loss: 0.1364
2024-05-22 20:40:32 [INFO]: Epoch 022 - generator training loss: 0.0649, discriminator training loss: 0.0439, validation loss: 0.1344
2024-05-22 20:40:36 [INFO]: Epoch 023 - generator training loss: 0.0634, discriminator training loss: 0.0431, validation loss: 0.1329
2024-05-22 20:40:39 [INFO]: Epoch 024 - generator training loss: 0.0626, discriminator training loss: 0.0423, validation loss: 0.1314
2024-05-22 20:40:42 [INFO]: Epoch 025 - generator training loss: 0.0628, discriminator training loss: 0.0415, validation loss: 0.1303
2024-05-22 20:40:46 [INFO]: Epoch 026 - generator training loss: 0.0601, discriminator training loss: 0.0408, validation loss: 0.1290
2024-05-22 20:40:49 [INFO]: Epoch 027 - generator training loss: 0.0593, discriminator training loss: 0.0399, validation loss: 0.1276
2024-05-22 20:40:53 [INFO]: Epoch 028 - generator training loss: 0.0593, discriminator training loss: 0.0391, validation loss: 0.1265
2024-05-22 20:40:56 [INFO]: Epoch 029 - generator training loss: 0.0583, discriminator training loss: 0.0381, validation loss: 0.1251
2024-05-22 20:41:00 [INFO]: Epoch 030 - generator training loss: 0.0587, discriminator training loss: 0.0375, validation loss: 0.1248
2024-05-22 20:41:03 [INFO]: Epoch 031 - generator training loss: 0.0570, discriminator training loss: 0.0366, validation loss: 0.1238
2024-05-22 20:41:06 [INFO]: Epoch 032 - generator training loss: 0.0567, discriminator training loss: 0.0357, validation loss: 0.1228
2024-05-22 20:41:10 [INFO]: Epoch 033 - generator training loss: 0.0572, discriminator training loss: 0.0346, validation loss: 0.1218
2024-05-22 20:41:13 [INFO]: Epoch 034 - generator training loss: 0.0555, discriminator training loss: 0.0346, validation loss: 0.1215
2024-05-22 20:41:17 [INFO]: Epoch 035 - generator training loss: 0.0559, discriminator training loss: 0.0337, validation loss: 0.1203
2024-05-22 20:41:20 [INFO]: Epoch 036 - generator training loss: 0.0562, discriminator training loss: 0.0327, validation loss: 0.1191
2024-05-22 20:41:23 [INFO]: Epoch 037 - generator training loss: 0.0549, discriminator training loss: 0.0323, validation loss: 0.1181
2024-05-22 20:41:27 [INFO]: Epoch 038 - generator training loss: 0.0549, discriminator training loss: 0.0314, validation loss: 0.1183
2024-05-22 20:41:30 [INFO]: Epoch 039 - generator training loss: 0.0532, discriminator training loss: 0.0313, validation loss: 0.1173
2024-05-22 20:41:34 [INFO]: Epoch 040 - generator training loss: 0.0544, discriminator training loss: 0.0303, validation loss: 0.1173
2024-05-22 20:41:37 [INFO]: Epoch 041 - generator training loss: 0.0537, discriminator training loss: 0.0295, validation loss: 0.1169
2024-05-22 20:41:41 [INFO]: Epoch 042 - generator training loss: 0.0533, discriminator training loss: 0.0291, validation loss: 0.1155
2024-05-22 20:41:44 [INFO]: Epoch 043 - generator training loss: 0.0536, discriminator training loss: 0.0286, validation loss: 0.1157
2024-05-22 20:41:48 [INFO]: Epoch 044 - generator training loss: 0.0527, discriminator training loss: 0.0284, validation loss: 0.1150
2024-05-22 20:41:51 [INFO]: Epoch 045 - generator training loss: 0.0524, discriminator training loss: 0.0277, validation loss: 0.1147
2024-05-22 20:41:54 [INFO]: Epoch 046 - generator training loss: 0.0517, discriminator training loss: 0.0272, validation loss: 0.1138
2024-05-22 20:41:58 [INFO]: Epoch 047 - generator training loss: 0.0536, discriminator training loss: 0.0267, validation loss: 0.1130
2024-05-22 20:42:01 [INFO]: Epoch 048 - generator training loss: 0.0512, discriminator training loss: 0.0261, validation loss: 0.1124
2024-05-22 20:42:05 [INFO]: Epoch 049 - generator training loss: 0.0511, discriminator training loss: 0.0257, validation loss: 0.1129
2024-05-22 20:42:08 [INFO]: Epoch 050 - generator training loss: 0.0514, discriminator training loss: 0.0252, validation loss: 0.1123
2024-05-22 20:42:12 [INFO]: Epoch 051 - generator training loss: 0.0521, discriminator training loss: 0.0249, validation loss: 0.1112
2024-05-22 20:42:15 [INFO]: Epoch 052 - generator training loss: 0.0502, discriminator training loss: 0.0245, validation loss: 0.1108
2024-05-22 20:42:18 [INFO]: Epoch 053 - generator training loss: 0.0494, discriminator training loss: 0.0241, validation loss: 0.1120
2024-05-22 20:42:22 [INFO]: Epoch 054 - generator training loss: 0.0497, discriminator training loss: 0.0237, validation loss: 0.1109
2024-05-22 20:42:25 [INFO]: Epoch 055 - generator training loss: 0.0491, discriminator training loss: 0.0233, validation loss: 0.1104
2024-05-22 20:42:29 [INFO]: Epoch 056 - generator training loss: 0.0488, discriminator training loss: 0.0230, validation loss: 0.1102
2024-05-22 20:42:32 [INFO]: Epoch 057 - generator training loss: 0.0499, discriminator training loss: 0.0226, validation loss: 0.1096
2024-05-22 20:42:35 [INFO]: Epoch 058 - generator training loss: 0.0490, discriminator training loss: 0.0222, validation loss: 0.1090
2024-05-22 20:42:39 [INFO]: Epoch 059 - generator training loss: 0.0481, discriminator training loss: 0.0220, validation loss: 0.1095
2024-05-22 20:42:42 [INFO]: Epoch 060 - generator training loss: 0.0501, discriminator training loss: 0.0217, validation loss: 0.1087
2024-05-22 20:42:46 [INFO]: Epoch 061 - generator training loss: 0.0491, discriminator training loss: 0.0216, validation loss: 0.1087
2024-05-22 20:42:49 [INFO]: Epoch 062 - generator training loss: 0.0473, discriminator training loss: 0.0211, validation loss: 0.1082
2024-05-22 20:42:53 [INFO]: Epoch 063 - generator training loss: 0.0470, discriminator training loss: 0.0209, validation loss: 0.1081
2024-05-22 20:42:56 [INFO]: Epoch 064 - generator training loss: 0.0467, discriminator training loss: 0.0206, validation loss: 0.1074
2024-05-22 20:42:59 [INFO]: Epoch 065 - generator training loss: 0.0463, discriminator training loss: 0.0205, validation loss: 0.1072
2024-05-22 20:43:03 [INFO]: Epoch 066 - generator training loss: 0.0464, discriminator training loss: 0.0203, validation loss: 0.1070
2024-05-22 20:43:06 [INFO]: Epoch 067 - generator training loss: 0.0459, discriminator training loss: 0.0203, validation loss: 0.1065
2024-05-22 20:43:10 [INFO]: Epoch 068 - generator training loss: 0.0456, discriminator training loss: 0.0196, validation loss: 0.1070
2024-05-22 20:43:13 [INFO]: Epoch 069 - generator training loss: 0.0454, discriminator training loss: 0.0195, validation loss: 0.1072
2024-05-22 20:43:16 [INFO]: Epoch 070 - generator training loss: 0.0466, discriminator training loss: 0.0192, validation loss: 0.1061
2024-05-22 20:43:20 [INFO]: Epoch 071 - generator training loss: 0.0456, discriminator training loss: 0.0190, validation loss: 0.1065
2024-05-22 20:43:23 [INFO]: Epoch 072 - generator training loss: 0.0446, discriminator training loss: 0.0191, validation loss: 0.1054
2024-05-22 20:43:27 [INFO]: Epoch 073 - generator training loss: 0.0444, discriminator training loss: 0.0188, validation loss: 0.1062
2024-05-22 20:43:30 [INFO]: Epoch 074 - generator training loss: 0.0445, discriminator training loss: 0.0185, validation loss: 0.1057
2024-05-22 20:43:34 [INFO]: Epoch 075 - generator training loss: 0.0440, discriminator training loss: 0.0183, validation loss: 0.1049
2024-05-22 20:43:37 [INFO]: Epoch 076 - generator training loss: 0.0433, discriminator training loss: 0.0180, validation loss: 0.1047
2024-05-22 20:43:40 [INFO]: Epoch 077 - generator training loss: 0.0435, discriminator training loss: 0.0178, validation loss: 0.1049
2024-05-22 20:43:44 [INFO]: Epoch 078 - generator training loss: 0.0431, discriminator training loss: 0.0178, validation loss: 0.1047
2024-05-22 20:43:47 [INFO]: Epoch 079 - generator training loss: 0.0436, discriminator training loss: 0.0176, validation loss: 0.1042
2024-05-22 20:43:51 [INFO]: Epoch 080 - generator training loss: 0.0431, discriminator training loss: 0.0173, validation loss: 0.1043
2024-05-22 20:43:54 [INFO]: Epoch 081 - generator training loss: 0.0429, discriminator training loss: 0.0174, validation loss: 0.1038
2024-05-22 20:43:58 [INFO]: Epoch 082 - generator training loss: 0.0428, discriminator training loss: 0.0173, validation loss: 0.1042
2024-05-22 20:44:01 [INFO]: Epoch 083 - generator training loss: 0.0416, discriminator training loss: 0.0170, validation loss: 0.1039
2024-05-22 20:44:05 [INFO]: Epoch 084 - generator training loss: 0.0417, discriminator training loss: 0.0169, validation loss: 0.1039
2024-05-22 20:44:08 [INFO]: Epoch 085 - generator training loss: 0.0417, discriminator training loss: 0.0167, validation loss: 0.1038
2024-05-22 20:44:12 [INFO]: Epoch 086 - generator training loss: 0.0413, discriminator training loss: 0.0166, validation loss: 0.1034
2024-05-22 20:44:15 [INFO]: Epoch 087 - generator training loss: 0.0412, discriminator training loss: 0.0165, validation loss: 0.1037
2024-05-22 20:44:18 [INFO]: Epoch 088 - generator training loss: 0.0417, discriminator training loss: 0.0164, validation loss: 0.1038
2024-05-22 20:44:22 [INFO]: Epoch 089 - generator training loss: 0.0410, discriminator training loss: 0.0162, validation loss: 0.1047
2024-05-22 20:44:25 [INFO]: Epoch 090 - generator training loss: 0.0408, discriminator training loss: 0.0162, validation loss: 0.1037
2024-05-22 20:44:29 [INFO]: Epoch 091 - generator training loss: 0.0404, discriminator training loss: 0.0161, validation loss: 0.1041
2024-05-22 20:44:32 [INFO]: Epoch 092 - generator training loss: 0.0405, discriminator training loss: 0.0162, validation loss: 0.1040
2024-05-22 20:44:36 [INFO]: Epoch 093 - generator training loss: 0.0401, discriminator training loss: 0.0158, validation loss: 0.1034
2024-05-22 20:44:39 [INFO]: Epoch 094 - generator training loss: 0.0403, discriminator training loss: 0.0156, validation loss: 0.1035
2024-05-22 20:44:43 [INFO]: Epoch 095 - generator training loss: 0.0394, discriminator training loss: 0.0157, validation loss: 0.1036
2024-05-22 20:44:46 [INFO]: Epoch 096 - generator training loss: 0.0407, discriminator training loss: 0.0156, validation loss: 0.1037
2024-05-22 20:44:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 20:44:46 [INFO]: Finished training. The best model is from epoch#86.
2024-05-22 20:44:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/USGAN_air_quality/20240522_T203916/USGAN.pypots
2024-05-22 20:44:47 [INFO]: US-GAN on Air-Quality: MAE=0.1769, MSE=0.1175
2024-05-22 20:44:47 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/USGAN_air_quality/imputation.pkl
2024-05-22 20:44:47 [INFO]: Using the given device: cuda:0
2024-05-22 20:44:47 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/BRITS_air_quality/20240522_T204447
2024-05-22 20:44:47 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/BRITS_air_quality/20240522_T204447/tensorboard
2024-05-22 20:44:47 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-22 20:44:50 [INFO]: Epoch 001 - training loss: 1.3946, validation loss: 0.9072
2024-05-22 20:44:52 [INFO]: Epoch 002 - training loss: 1.1231, validation loss: 0.6754
2024-05-22 20:44:54 [INFO]: Epoch 003 - training loss: 0.9367, validation loss: 0.5690
2024-05-22 20:44:57 [INFO]: Epoch 004 - training loss: 0.8295, validation loss: 0.4989
2024-05-22 20:44:59 [INFO]: Epoch 005 - training loss: 0.7540, validation loss: 0.4481
2024-05-22 20:45:01 [INFO]: Epoch 006 - training loss: 0.6975, validation loss: 0.4110
2024-05-22 20:45:04 [INFO]: Epoch 007 - training loss: 0.6550, validation loss: 0.3812
2024-05-22 20:45:06 [INFO]: Epoch 008 - training loss: 0.6219, validation loss: 0.3570
2024-05-22 20:45:08 [INFO]: Epoch 009 - training loss: 0.5950, validation loss: 0.3379
2024-05-22 20:45:11 [INFO]: Epoch 010 - training loss: 0.5743, validation loss: 0.3218
2024-05-22 20:45:13 [INFO]: Epoch 011 - training loss: 0.5551, validation loss: 0.3078
2024-05-22 20:45:15 [INFO]: Epoch 012 - training loss: 0.5398, validation loss: 0.2970
2024-05-22 20:45:18 [INFO]: Epoch 013 - training loss: 0.5268, validation loss: 0.2874
2024-05-22 20:45:20 [INFO]: Epoch 014 - training loss: 0.5148, validation loss: 0.2787
2024-05-22 20:45:22 [INFO]: Epoch 015 - training loss: 0.5053, validation loss: 0.2713
2024-05-22 20:45:25 [INFO]: Epoch 016 - training loss: 0.4950, validation loss: 0.2648
2024-05-22 20:45:27 [INFO]: Epoch 017 - training loss: 0.4875, validation loss: 0.2591
2024-05-22 20:45:29 [INFO]: Epoch 018 - training loss: 0.4782, validation loss: 0.2538
2024-05-22 20:45:32 [INFO]: Epoch 019 - training loss: 0.4710, validation loss: 0.2483
2024-05-22 20:45:34 [INFO]: Epoch 020 - training loss: 0.4635, validation loss: 0.2438
2024-05-22 20:45:36 [INFO]: Epoch 021 - training loss: 0.4571, validation loss: 0.2392
2024-05-22 20:45:39 [INFO]: Epoch 022 - training loss: 0.4500, validation loss: 0.2351
2024-05-22 20:45:41 [INFO]: Epoch 023 - training loss: 0.4443, validation loss: 0.2310
2024-05-22 20:45:43 [INFO]: Epoch 024 - training loss: 0.4380, validation loss: 0.2269
2024-05-22 20:45:45 [INFO]: Epoch 025 - training loss: 0.4324, validation loss: 0.2238
2024-05-22 20:45:48 [INFO]: Epoch 026 - training loss: 0.4268, validation loss: 0.2201
2024-05-22 20:45:50 [INFO]: Epoch 027 - training loss: 0.4215, validation loss: 0.2170
2024-05-22 20:45:52 [INFO]: Epoch 028 - training loss: 0.4163, validation loss: 0.2139
2024-05-22 20:45:55 [INFO]: Epoch 029 - training loss: 0.4116, validation loss: 0.2101
2024-05-22 20:45:57 [INFO]: Epoch 030 - training loss: 0.4083, validation loss: 0.2077
2024-05-22 20:45:59 [INFO]: Epoch 031 - training loss: 0.4020, validation loss: 0.2038
2024-05-22 20:46:02 [INFO]: Epoch 032 - training loss: 0.3973, validation loss: 0.2007
2024-05-22 20:46:04 [INFO]: Epoch 033 - training loss: 0.3926, validation loss: 0.1984
2024-05-22 20:46:06 [INFO]: Epoch 034 - training loss: 0.3896, validation loss: 0.1957
2024-05-22 20:46:09 [INFO]: Epoch 035 - training loss: 0.3856, validation loss: 0.1927
2024-05-22 20:46:11 [INFO]: Epoch 036 - training loss: 0.3815, validation loss: 0.1899
2024-05-22 20:46:13 [INFO]: Epoch 037 - training loss: 0.3782, validation loss: 0.1875
2024-05-22 20:46:16 [INFO]: Epoch 038 - training loss: 0.3747, validation loss: 0.1851
2024-05-22 20:46:18 [INFO]: Epoch 039 - training loss: 0.3710, validation loss: 0.1827
2024-05-22 20:46:21 [INFO]: Epoch 040 - training loss: 0.3688, validation loss: 0.1802
2024-05-22 20:46:23 [INFO]: Epoch 041 - training loss: 0.3659, validation loss: 0.1780
2024-05-22 20:46:25 [INFO]: Epoch 042 - training loss: 0.3618, validation loss: 0.1758
2024-05-22 20:46:28 [INFO]: Epoch 043 - training loss: 0.3593, validation loss: 0.1737
2024-05-22 20:46:30 [INFO]: Epoch 044 - training loss: 0.3559, validation loss: 0.1722
2024-05-22 20:46:32 [INFO]: Epoch 045 - training loss: 0.3528, validation loss: 0.1699
2024-05-22 20:46:35 [INFO]: Epoch 046 - training loss: 0.3505, validation loss: 0.1680
2024-05-22 20:46:37 [INFO]: Epoch 047 - training loss: 0.3484, validation loss: 0.1662
2024-05-22 20:46:39 [INFO]: Epoch 048 - training loss: 0.3458, validation loss: 0.1643
2024-05-22 20:46:42 [INFO]: Epoch 049 - training loss: 0.3441, validation loss: 0.1626
2024-05-22 20:46:44 [INFO]: Epoch 050 - training loss: 0.3410, validation loss: 0.1606
2024-05-22 20:46:46 [INFO]: Epoch 051 - training loss: 0.3398, validation loss: 0.1588
2024-05-22 20:46:49 [INFO]: Epoch 052 - training loss: 0.3362, validation loss: 0.1577
2024-05-22 20:46:51 [INFO]: Epoch 053 - training loss: 0.3342, validation loss: 0.1563
2024-05-22 20:46:53 [INFO]: Epoch 054 - training loss: 0.3319, validation loss: 0.1547
2024-05-22 20:46:56 [INFO]: Epoch 055 - training loss: 0.3306, validation loss: 0.1538
2024-05-22 20:46:58 [INFO]: Epoch 056 - training loss: 0.3275, validation loss: 0.1522
2024-05-22 20:47:00 [INFO]: Epoch 057 - training loss: 0.3261, validation loss: 0.1507
2024-05-22 20:47:03 [INFO]: Epoch 058 - training loss: 0.3247, validation loss: 0.1501
2024-05-22 20:47:05 [INFO]: Epoch 059 - training loss: 0.3234, validation loss: 0.1485
2024-05-22 20:47:07 [INFO]: Epoch 060 - training loss: 0.3205, validation loss: 0.1475
2024-05-22 20:47:10 [INFO]: Epoch 061 - training loss: 0.3200, validation loss: 0.1470
2024-05-22 20:47:12 [INFO]: Epoch 062 - training loss: 0.3188, validation loss: 0.1459
2024-05-22 20:47:14 [INFO]: Epoch 063 - training loss: 0.3165, validation loss: 0.1444
2024-05-22 20:47:17 [INFO]: Epoch 064 - training loss: 0.3142, validation loss: 0.1437
2024-05-22 20:47:19 [INFO]: Epoch 065 - training loss: 0.3135, validation loss: 0.1428
2024-05-22 20:47:21 [INFO]: Epoch 066 - training loss: 0.3118, validation loss: 0.1419
2024-05-22 20:47:24 [INFO]: Epoch 067 - training loss: 0.3097, validation loss: 0.1413
2024-05-22 20:47:26 [INFO]: Epoch 068 - training loss: 0.3094, validation loss: 0.1403
2024-05-22 20:47:28 [INFO]: Epoch 069 - training loss: 0.3081, validation loss: 0.1396
2024-05-22 20:47:31 [INFO]: Epoch 070 - training loss: 0.3058, validation loss: 0.1388
2024-05-22 20:47:33 [INFO]: Epoch 071 - training loss: 0.3051, validation loss: 0.1381
2024-05-22 20:47:35 [INFO]: Epoch 072 - training loss: 0.3045, validation loss: 0.1374
2024-05-22 20:47:37 [INFO]: Epoch 073 - training loss: 0.3024, validation loss: 0.1366
2024-05-22 20:47:40 [INFO]: Epoch 074 - training loss: 0.3021, validation loss: 0.1361
2024-05-22 20:47:42 [INFO]: Epoch 075 - training loss: 0.3000, validation loss: 0.1354
2024-05-22 20:47:44 [INFO]: Epoch 076 - training loss: 0.2993, validation loss: 0.1347
2024-05-22 20:47:47 [INFO]: Epoch 077 - training loss: 0.2988, validation loss: 0.1341
2024-05-22 20:47:49 [INFO]: Epoch 078 - training loss: 0.2976, validation loss: 0.1336
2024-05-22 20:47:51 [INFO]: Epoch 079 - training loss: 0.2970, validation loss: 0.1329
2024-05-22 20:47:54 [INFO]: Epoch 080 - training loss: 0.2959, validation loss: 0.1325
2024-05-22 20:47:56 [INFO]: Epoch 081 - training loss: 0.2956, validation loss: 0.1318
2024-05-22 20:47:58 [INFO]: Epoch 082 - training loss: 0.2940, validation loss: 0.1310
2024-05-22 20:48:01 [INFO]: Epoch 083 - training loss: 0.2945, validation loss: 0.1307
2024-05-22 20:48:03 [INFO]: Epoch 084 - training loss: 0.2919, validation loss: 0.1301
2024-05-22 20:48:06 [INFO]: Epoch 085 - training loss: 0.2909, validation loss: 0.1298
2024-05-22 20:48:08 [INFO]: Epoch 086 - training loss: 0.2902, validation loss: 0.1291
2024-05-22 20:48:10 [INFO]: Epoch 087 - training loss: 0.2899, validation loss: 0.1286
2024-05-22 20:48:13 [INFO]: Epoch 088 - training loss: 0.2886, validation loss: 0.1281
2024-05-22 20:48:15 [INFO]: Epoch 089 - training loss: 0.2877, validation loss: 0.1277
2024-05-22 20:48:17 [INFO]: Epoch 090 - training loss: 0.2869, validation loss: 0.1270
2024-05-22 20:48:20 [INFO]: Epoch 091 - training loss: 0.2862, validation loss: 0.1267
2024-05-22 20:48:22 [INFO]: Epoch 092 - training loss: 0.2853, validation loss: 0.1263
2024-05-22 20:48:24 [INFO]: Epoch 093 - training loss: 0.2848, validation loss: 0.1257
2024-05-22 20:48:27 [INFO]: Epoch 094 - training loss: 0.2839, validation loss: 0.1254
2024-05-22 20:48:29 [INFO]: Epoch 095 - training loss: 0.2836, validation loss: 0.1250
2024-05-22 20:48:31 [INFO]: Epoch 096 - training loss: 0.2833, validation loss: 0.1244
2024-05-22 20:48:34 [INFO]: Epoch 097 - training loss: 0.2824, validation loss: 0.1242
2024-05-22 20:48:36 [INFO]: Epoch 098 - training loss: 0.2819, validation loss: 0.1237
2024-05-22 20:48:38 [INFO]: Epoch 099 - training loss: 0.2808, validation loss: 0.1233
2024-05-22 20:48:41 [INFO]: Epoch 100 - training loss: 0.2798, validation loss: 0.1228
2024-05-22 20:48:43 [INFO]: Epoch 101 - training loss: 0.2799, validation loss: 0.1225
2024-05-22 20:48:45 [INFO]: Epoch 102 - training loss: 0.2785, validation loss: 0.1220
2024-05-22 20:48:48 [INFO]: Epoch 103 - training loss: 0.2783, validation loss: 0.1216
2024-05-22 20:48:50 [INFO]: Epoch 104 - training loss: 0.2778, validation loss: 0.1213
2024-05-22 20:48:52 [INFO]: Epoch 105 - training loss: 0.2773, validation loss: 0.1210
2024-05-22 20:48:55 [INFO]: Epoch 106 - training loss: 0.2761, validation loss: 0.1205
2024-05-22 20:48:57 [INFO]: Epoch 107 - training loss: 0.2758, validation loss: 0.1203
2024-05-22 20:48:59 [INFO]: Epoch 108 - training loss: 0.2757, validation loss: 0.1199
2024-05-22 20:49:02 [INFO]: Epoch 109 - training loss: 0.2748, validation loss: 0.1194
2024-05-22 20:49:04 [INFO]: Epoch 110 - training loss: 0.2738, validation loss: 0.1192
2024-05-22 20:49:06 [INFO]: Epoch 111 - training loss: 0.2736, validation loss: 0.1188
2024-05-22 20:49:09 [INFO]: Epoch 112 - training loss: 0.2735, validation loss: 0.1184
2024-05-22 20:49:11 [INFO]: Epoch 113 - training loss: 0.2721, validation loss: 0.1180
2024-05-22 20:49:13 [INFO]: Epoch 114 - training loss: 0.2719, validation loss: 0.1176
2024-05-22 20:49:16 [INFO]: Epoch 115 - training loss: 0.2719, validation loss: 0.1173
2024-05-22 20:49:18 [INFO]: Epoch 116 - training loss: 0.2715, validation loss: 0.1171
2024-05-22 20:49:20 [INFO]: Epoch 117 - training loss: 0.2699, validation loss: 0.1165
2024-05-22 20:49:23 [INFO]: Epoch 118 - training loss: 0.2698, validation loss: 0.1163
2024-05-22 20:49:25 [INFO]: Epoch 119 - training loss: 0.2693, validation loss: 0.1160
2024-05-22 20:49:27 [INFO]: Epoch 120 - training loss: 0.2694, validation loss: 0.1157
2024-05-22 20:49:30 [INFO]: Epoch 121 - training loss: 0.2686, validation loss: 0.1155
2024-05-22 20:49:32 [INFO]: Epoch 122 - training loss: 0.2679, validation loss: 0.1151
2024-05-22 20:49:34 [INFO]: Epoch 123 - training loss: 0.2679, validation loss: 0.1148
2024-05-22 20:49:37 [INFO]: Epoch 124 - training loss: 0.2668, validation loss: 0.1145
2024-05-22 20:49:39 [INFO]: Epoch 125 - training loss: 0.2667, validation loss: 0.1142
2024-05-22 20:49:41 [INFO]: Epoch 126 - training loss: 0.2661, validation loss: 0.1139
2024-05-22 20:49:44 [INFO]: Epoch 127 - training loss: 0.2662, validation loss: 0.1137
2024-05-22 20:49:46 [INFO]: Epoch 128 - training loss: 0.2655, validation loss: 0.1133
2024-05-22 20:49:49 [INFO]: Epoch 129 - training loss: 0.2653, validation loss: 0.1130
2024-05-22 20:49:51 [INFO]: Epoch 130 - training loss: 0.2644, validation loss: 0.1129
2024-05-22 20:49:53 [INFO]: Epoch 131 - training loss: 0.2649, validation loss: 0.1124
2024-05-22 20:49:56 [INFO]: Epoch 132 - training loss: 0.2634, validation loss: 0.1123
2024-05-22 20:49:58 [INFO]: Epoch 133 - training loss: 0.2632, validation loss: 0.1119
2024-05-22 20:50:00 [INFO]: Epoch 134 - training loss: 0.2627, validation loss: 0.1118
2024-05-22 20:50:03 [INFO]: Epoch 135 - training loss: 0.2623, validation loss: 0.1113
2024-05-22 20:50:05 [INFO]: Epoch 136 - training loss: 0.2620, validation loss: 0.1111
2024-05-22 20:50:07 [INFO]: Epoch 137 - training loss: 0.2616, validation loss: 0.1108
2024-05-22 20:50:10 [INFO]: Epoch 138 - training loss: 0.2609, validation loss: 0.1105
2024-05-22 20:50:12 [INFO]: Epoch 139 - training loss: 0.2605, validation loss: 0.1103
2024-05-22 20:50:14 [INFO]: Epoch 140 - training loss: 0.2613, validation loss: 0.1101
2024-05-22 20:50:17 [INFO]: Epoch 141 - training loss: 0.2596, validation loss: 0.1096
2024-05-22 20:50:19 [INFO]: Epoch 142 - training loss: 0.2594, validation loss: 0.1096
2024-05-22 20:50:21 [INFO]: Epoch 143 - training loss: 0.2594, validation loss: 0.1092
2024-05-22 20:50:24 [INFO]: Epoch 144 - training loss: 0.2591, validation loss: 0.1091
2024-05-22 20:50:26 [INFO]: Epoch 145 - training loss: 0.2592, validation loss: 0.1088
2024-05-22 20:50:28 [INFO]: Epoch 146 - training loss: 0.2586, validation loss: 0.1086
2024-05-22 20:50:31 [INFO]: Epoch 147 - training loss: 0.2584, validation loss: 0.1084
2024-05-22 20:50:33 [INFO]: Epoch 148 - training loss: 0.2579, validation loss: 0.1080
2024-05-22 20:50:35 [INFO]: Epoch 149 - training loss: 0.2574, validation loss: 0.1081
2024-05-22 20:50:38 [INFO]: Epoch 150 - training loss: 0.2571, validation loss: 0.1076
2024-05-22 20:50:40 [INFO]: Epoch 151 - training loss: 0.2566, validation loss: 0.1074
2024-05-22 20:50:42 [INFO]: Epoch 152 - training loss: 0.2563, validation loss: 0.1071
2024-05-22 20:50:45 [INFO]: Epoch 153 - training loss: 0.2555, validation loss: 0.1070
2024-05-22 20:50:47 [INFO]: Epoch 154 - training loss: 0.2558, validation loss: 0.1068
2024-05-22 20:50:49 [INFO]: Epoch 155 - training loss: 0.2560, validation loss: 0.1066
2024-05-22 20:50:52 [INFO]: Epoch 156 - training loss: 0.2550, validation loss: 0.1062
2024-05-22 20:50:54 [INFO]: Epoch 157 - training loss: 0.2544, validation loss: 0.1062
2024-05-22 20:50:56 [INFO]: Epoch 158 - training loss: 0.2560, validation loss: 0.1060
2024-05-22 20:50:59 [INFO]: Epoch 159 - training loss: 0.2544, validation loss: 0.1058
2024-05-22 20:51:01 [INFO]: Epoch 160 - training loss: 0.2540, validation loss: 0.1056
2024-05-22 20:51:03 [INFO]: Epoch 161 - training loss: 0.2538, validation loss: 0.1054
2024-05-22 20:51:06 [INFO]: Epoch 162 - training loss: 0.2537, validation loss: 0.1051
2024-05-22 20:51:08 [INFO]: Epoch 163 - training loss: 0.2527, validation loss: 0.1050
2024-05-22 20:51:10 [INFO]: Epoch 164 - training loss: 0.2529, validation loss: 0.1049
2024-05-22 20:51:13 [INFO]: Epoch 165 - training loss: 0.2527, validation loss: 0.1047
2024-05-22 20:51:15 [INFO]: Epoch 166 - training loss: 0.2521, validation loss: 0.1045
2024-05-22 20:51:17 [INFO]: Epoch 167 - training loss: 0.2518, validation loss: 0.1043
2024-05-22 20:51:20 [INFO]: Epoch 168 - training loss: 0.2518, validation loss: 0.1041
2024-05-22 20:51:22 [INFO]: Epoch 169 - training loss: 0.2513, validation loss: 0.1038
2024-05-22 20:51:24 [INFO]: Epoch 170 - training loss: 0.2508, validation loss: 0.1037
2024-05-22 20:51:27 [INFO]: Epoch 171 - training loss: 0.2508, validation loss: 0.1036
2024-05-22 20:51:29 [INFO]: Epoch 172 - training loss: 0.2508, validation loss: 0.1033
2024-05-22 20:51:31 [INFO]: Epoch 173 - training loss: 0.2504, validation loss: 0.1036
2024-05-22 20:51:34 [INFO]: Epoch 174 - training loss: 0.2500, validation loss: 0.1030
2024-05-22 20:51:36 [INFO]: Epoch 175 - training loss: 0.2494, validation loss: 0.1030
2024-05-22 20:51:39 [INFO]: Epoch 176 - training loss: 0.2491, validation loss: 0.1028
2024-05-22 20:51:41 [INFO]: Epoch 177 - training loss: 0.2491, validation loss: 0.1027
2024-05-22 20:51:43 [INFO]: Epoch 178 - training loss: 0.2486, validation loss: 0.1023
2024-05-22 20:51:46 [INFO]: Epoch 179 - training loss: 0.2488, validation loss: 0.1024
2024-05-22 20:51:48 [INFO]: Epoch 180 - training loss: 0.2483, validation loss: 0.1021
2024-05-22 20:51:50 [INFO]: Epoch 181 - training loss: 0.2489, validation loss: 0.1020
2024-05-22 20:51:53 [INFO]: Epoch 182 - training loss: 0.2478, validation loss: 0.1018
2024-05-22 20:51:55 [INFO]: Epoch 183 - training loss: 0.2478, validation loss: 0.1019
2024-05-22 20:51:57 [INFO]: Epoch 184 - training loss: 0.2478, validation loss: 0.1016
2024-05-22 20:52:00 [INFO]: Epoch 185 - training loss: 0.2470, validation loss: 0.1016
2024-05-22 20:52:02 [INFO]: Epoch 186 - training loss: 0.2472, validation loss: 0.1014
2024-05-22 20:52:04 [INFO]: Epoch 187 - training loss: 0.2472, validation loss: 0.1012
2024-05-22 20:52:07 [INFO]: Epoch 188 - training loss: 0.2472, validation loss: 0.1012
2024-05-22 20:52:09 [INFO]: Epoch 189 - training loss: 0.2465, validation loss: 0.1011
2024-05-22 20:52:11 [INFO]: Epoch 190 - training loss: 0.2461, validation loss: 0.1010
2024-05-22 20:52:14 [INFO]: Epoch 191 - training loss: 0.2458, validation loss: 0.1007
2024-05-22 20:52:16 [INFO]: Epoch 192 - training loss: 0.2455, validation loss: 0.1007
2024-05-22 20:52:18 [INFO]: Epoch 193 - training loss: 0.2457, validation loss: 0.1004
2024-05-22 20:52:21 [INFO]: Epoch 194 - training loss: 0.2453, validation loss: 0.1005
2024-05-22 20:52:23 [INFO]: Epoch 195 - training loss: 0.2453, validation loss: 0.1002
2024-05-22 20:52:25 [INFO]: Epoch 196 - training loss: 0.2452, validation loss: 0.1002
2024-05-22 20:52:28 [INFO]: Epoch 197 - training loss: 0.2448, validation loss: 0.1000
2024-05-22 20:52:30 [INFO]: Epoch 198 - training loss: 0.2445, validation loss: 0.0999
2024-05-22 20:52:32 [INFO]: Epoch 199 - training loss: 0.2444, validation loss: 0.0999
2024-05-22 20:52:35 [INFO]: Epoch 200 - training loss: 0.2444, validation loss: 0.0997
2024-05-22 20:52:37 [INFO]: Epoch 201 - training loss: 0.2438, validation loss: 0.0995
2024-05-22 20:52:39 [INFO]: Epoch 202 - training loss: 0.2437, validation loss: 0.0994
2024-05-22 20:52:42 [INFO]: Epoch 203 - training loss: 0.2437, validation loss: 0.0994
2024-05-22 20:52:44 [INFO]: Epoch 204 - training loss: 0.2437, validation loss: 0.0994
2024-05-22 20:52:46 [INFO]: Epoch 205 - training loss: 0.2435, validation loss: 0.0991
2024-05-22 20:52:49 [INFO]: Epoch 206 - training loss: 0.2429, validation loss: 0.0990
2024-05-22 20:52:51 [INFO]: Epoch 207 - training loss: 0.2426, validation loss: 0.0991
2024-05-22 20:52:53 [INFO]: Epoch 208 - training loss: 0.2429, validation loss: 0.0988
2024-05-22 20:52:56 [INFO]: Epoch 209 - training loss: 0.2424, validation loss: 0.0987
2024-05-22 20:52:58 [INFO]: Epoch 210 - training loss: 0.2422, validation loss: 0.0987
2024-05-22 20:53:00 [INFO]: Epoch 211 - training loss: 0.2421, validation loss: 0.0984
2024-05-22 20:53:03 [INFO]: Epoch 212 - training loss: 0.2421, validation loss: 0.0983
2024-05-22 20:53:05 [INFO]: Epoch 213 - training loss: 0.2421, validation loss: 0.0981
2024-05-22 20:53:07 [INFO]: Epoch 214 - training loss: 0.2413, validation loss: 0.0983
2024-05-22 20:53:10 [INFO]: Epoch 215 - training loss: 0.2417, validation loss: 0.0980
2024-05-22 20:53:12 [INFO]: Epoch 216 - training loss: 0.2416, validation loss: 0.0980
2024-05-22 20:53:15 [INFO]: Epoch 217 - training loss: 0.2409, validation loss: 0.0979
2024-05-22 20:53:17 [INFO]: Epoch 218 - training loss: 0.2405, validation loss: 0.0979
2024-05-22 20:53:19 [INFO]: Epoch 219 - training loss: 0.2413, validation loss: 0.0979
2024-05-22 20:53:22 [INFO]: Epoch 220 - training loss: 0.2405, validation loss: 0.0976
2024-05-22 20:53:24 [INFO]: Epoch 221 - training loss: 0.2403, validation loss: 0.0975
2024-05-22 20:53:26 [INFO]: Epoch 222 - training loss: 0.2400, validation loss: 0.0975
2024-05-22 20:53:28 [INFO]: Epoch 223 - training loss: 0.2401, validation loss: 0.0973
2024-05-22 20:53:31 [INFO]: Epoch 224 - training loss: 0.2397, validation loss: 0.0972
2024-05-22 20:53:33 [INFO]: Epoch 225 - training loss: 0.2397, validation loss: 0.0972
2024-05-22 20:53:35 [INFO]: Epoch 226 - training loss: 0.2394, validation loss: 0.0972
2024-05-22 20:53:38 [INFO]: Epoch 227 - training loss: 0.2395, validation loss: 0.0971
2024-05-22 20:53:40 [INFO]: Epoch 228 - training loss: 0.2393, validation loss: 0.0969
2024-05-22 20:53:42 [INFO]: Epoch 229 - training loss: 0.2386, validation loss: 0.0970
2024-05-22 20:53:45 [INFO]: Epoch 230 - training loss: 0.2385, validation loss: 0.0970
2024-05-22 20:53:47 [INFO]: Epoch 231 - training loss: 0.2384, validation loss: 0.0967
2024-05-22 20:53:49 [INFO]: Epoch 232 - training loss: 0.2383, validation loss: 0.0968
2024-05-22 20:53:52 [INFO]: Epoch 233 - training loss: 0.2378, validation loss: 0.0967
2024-05-22 20:53:54 [INFO]: Epoch 234 - training loss: 0.2380, validation loss: 0.0963
2024-05-22 20:53:56 [INFO]: Epoch 235 - training loss: 0.2378, validation loss: 0.0966
2024-05-22 20:53:59 [INFO]: Epoch 236 - training loss: 0.2374, validation loss: 0.0964
2024-05-22 20:54:01 [INFO]: Epoch 237 - training loss: 0.2378, validation loss: 0.0963
2024-05-22 20:54:03 [INFO]: Epoch 238 - training loss: 0.2375, validation loss: 0.0964
2024-05-22 20:54:06 [INFO]: Epoch 239 - training loss: 0.2373, validation loss: 0.0961
2024-05-22 20:54:08 [INFO]: Epoch 240 - training loss: 0.2369, validation loss: 0.0961
2024-05-22 20:54:10 [INFO]: Epoch 241 - training loss: 0.2371, validation loss: 0.0961
2024-05-22 20:54:13 [INFO]: Epoch 242 - training loss: 0.2368, validation loss: 0.0960
2024-05-22 20:54:15 [INFO]: Epoch 243 - training loss: 0.2367, validation loss: 0.0958
2024-05-22 20:54:17 [INFO]: Epoch 244 - training loss: 0.2363, validation loss: 0.0960
2024-05-22 20:54:20 [INFO]: Epoch 245 - training loss: 0.2366, validation loss: 0.0958
2024-05-22 20:54:22 [INFO]: Epoch 246 - training loss: 0.2362, validation loss: 0.0956
2024-05-22 20:54:24 [INFO]: Epoch 247 - training loss: 0.2366, validation loss: 0.0955
2024-05-22 20:54:27 [INFO]: Epoch 248 - training loss: 0.2359, validation loss: 0.0957
2024-05-22 20:54:29 [INFO]: Epoch 249 - training loss: 0.2357, validation loss: 0.0955
2024-05-22 20:54:31 [INFO]: Epoch 250 - training loss: 0.2353, validation loss: 0.0955
2024-05-22 20:54:34 [INFO]: Epoch 251 - training loss: 0.2356, validation loss: 0.0954
2024-05-22 20:54:36 [INFO]: Epoch 252 - training loss: 0.2356, validation loss: 0.0953
2024-05-22 20:54:38 [INFO]: Epoch 253 - training loss: 0.2351, validation loss: 0.0951
2024-05-22 20:54:41 [INFO]: Epoch 254 - training loss: 0.2350, validation loss: 0.0950
2024-05-22 20:54:43 [INFO]: Epoch 255 - training loss: 0.2351, validation loss: 0.0950
2024-05-22 20:54:45 [INFO]: Epoch 256 - training loss: 0.2349, validation loss: 0.0952
2024-05-22 20:54:48 [INFO]: Epoch 257 - training loss: 0.2346, validation loss: 0.0950
2024-05-22 20:54:50 [INFO]: Epoch 258 - training loss: 0.2348, validation loss: 0.0949
2024-05-22 20:54:52 [INFO]: Epoch 259 - training loss: 0.2344, validation loss: 0.0949
2024-05-22 20:54:55 [INFO]: Epoch 260 - training loss: 0.2340, validation loss: 0.0947
2024-05-22 20:54:57 [INFO]: Epoch 261 - training loss: 0.2345, validation loss: 0.0948
2024-05-22 20:54:59 [INFO]: Epoch 262 - training loss: 0.2340, validation loss: 0.0946
2024-05-22 20:55:02 [INFO]: Epoch 263 - training loss: 0.2338, validation loss: 0.0944
2024-05-22 20:55:04 [INFO]: Epoch 264 - training loss: 0.2341, validation loss: 0.0947
2024-05-22 20:55:07 [INFO]: Epoch 265 - training loss: 0.2339, validation loss: 0.0946
2024-05-22 20:55:09 [INFO]: Epoch 266 - training loss: 0.2334, validation loss: 0.0943
2024-05-22 20:55:11 [INFO]: Epoch 267 - training loss: 0.2335, validation loss: 0.0945
2024-05-22 20:55:14 [INFO]: Epoch 268 - training loss: 0.2335, validation loss: 0.0943
2024-05-22 20:55:16 [INFO]: Epoch 269 - training loss: 0.2331, validation loss: 0.0943
2024-05-22 20:55:18 [INFO]: Epoch 270 - training loss: 0.2331, validation loss: 0.0943
2024-05-22 20:55:21 [INFO]: Epoch 271 - training loss: 0.2329, validation loss: 0.0944
2024-05-22 20:55:23 [INFO]: Epoch 272 - training loss: 0.2323, validation loss: 0.0941
2024-05-22 20:55:25 [INFO]: Epoch 273 - training loss: 0.2324, validation loss: 0.0943
2024-05-22 20:55:28 [INFO]: Epoch 274 - training loss: 0.2324, validation loss: 0.0939
2024-05-22 20:55:30 [INFO]: Epoch 275 - training loss: 0.2324, validation loss: 0.0941
2024-05-22 20:55:32 [INFO]: Epoch 276 - training loss: 0.2322, validation loss: 0.0940
2024-05-22 20:55:34 [INFO]: Epoch 277 - training loss: 0.2321, validation loss: 0.0940
2024-05-22 20:55:37 [INFO]: Epoch 278 - training loss: 0.2324, validation loss: 0.0940
2024-05-22 20:55:39 [INFO]: Epoch 279 - training loss: 0.2319, validation loss: 0.0939
2024-05-22 20:55:41 [INFO]: Epoch 280 - training loss: 0.2314, validation loss: 0.0936
2024-05-22 20:55:44 [INFO]: Epoch 281 - training loss: 0.2318, validation loss: 0.0938
2024-05-22 20:55:46 [INFO]: Epoch 282 - training loss: 0.2319, validation loss: 0.0938
2024-05-22 20:55:48 [INFO]: Epoch 283 - training loss: 0.2315, validation loss: 0.0938
2024-05-22 20:55:51 [INFO]: Epoch 284 - training loss: 0.2315, validation loss: 0.0936
2024-05-22 20:55:53 [INFO]: Epoch 285 - training loss: 0.2306, validation loss: 0.0936
2024-05-22 20:55:55 [INFO]: Epoch 286 - training loss: 0.2307, validation loss: 0.0935
2024-05-22 20:55:58 [INFO]: Epoch 287 - training loss: 0.2309, validation loss: 0.0935
2024-05-22 20:56:00 [INFO]: Epoch 288 - training loss: 0.2309, validation loss: 0.0935
2024-05-22 20:56:02 [INFO]: Epoch 289 - training loss: 0.2307, validation loss: 0.0934
2024-05-22 20:56:05 [INFO]: Epoch 290 - training loss: 0.2308, validation loss: 0.0934
2024-05-22 20:56:07 [INFO]: Epoch 291 - training loss: 0.2307, validation loss: 0.0932
2024-05-22 20:56:09 [INFO]: Epoch 292 - training loss: 0.2307, validation loss: 0.0933
2024-05-22 20:56:12 [INFO]: Epoch 293 - training loss: 0.2303, validation loss: 0.0932
2024-05-22 20:56:14 [INFO]: Epoch 294 - training loss: 0.2307, validation loss: 0.0932
2024-05-22 20:56:16 [INFO]: Epoch 295 - training loss: 0.2299, validation loss: 0.0933
2024-05-22 20:56:19 [INFO]: Epoch 296 - training loss: 0.2309, validation loss: 0.0931
2024-05-22 20:56:21 [INFO]: Epoch 297 - training loss: 0.2300, validation loss: 0.0931
2024-05-22 20:56:23 [INFO]: Epoch 298 - training loss: 0.2299, validation loss: 0.0931
2024-05-22 20:56:26 [INFO]: Epoch 299 - training loss: 0.2299, validation loss: 0.0928
2024-05-22 20:56:28 [INFO]: Epoch 300 - training loss: 0.2296, validation loss: 0.0931
2024-05-22 20:56:28 [INFO]: Finished training. The best model is from epoch#299.
2024-05-22 20:56:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/BRITS_air_quality/20240522_T204447/BRITS.pypots
2024-05-22 20:56:29 [INFO]: BRITS on Air-Quality: MAE=0.1417, MSE=0.1050
2024-05-22 20:56:29 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/BRITS_air_quality/imputation.pkl
2024-05-22 20:56:29 [INFO]: Using the given device: cuda:0
2024-05-22 20:56:29 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629
2024-05-22 20:56:29 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/tensorboard
2024-05-22 20:56:29 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-22 20:56:32 [INFO]: Epoch 001 - training loss: 1.4228, validation loss: 0.7800
2024-05-22 20:56:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch1_loss0.780009537935257.pypots
2024-05-22 20:56:35 [INFO]: Epoch 002 - training loss: 1.0652, validation loss: 0.7233
2024-05-22 20:56:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch2_loss0.723251274228096.pypots
2024-05-22 20:56:39 [INFO]: Epoch 003 - training loss: 0.9989, validation loss: 0.6988
2024-05-22 20:56:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch3_loss0.6988216042518616.pypots
2024-05-22 20:56:42 [INFO]: Epoch 004 - training loss: 0.9716, validation loss: 0.6849
2024-05-22 20:56:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch4_loss0.6848958492279053.pypots
2024-05-22 20:56:45 [INFO]: Epoch 005 - training loss: 0.9593, validation loss: 0.6769
2024-05-22 20:56:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch5_loss0.6768644601106644.pypots
2024-05-22 20:56:48 [INFO]: Epoch 006 - training loss: 0.9377, validation loss: 0.6706
2024-05-22 20:56:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch6_loss0.6706412762403489.pypots
2024-05-22 20:56:51 [INFO]: Epoch 007 - training loss: 0.9248, validation loss: 0.6656
2024-05-22 20:56:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch7_loss0.6655601561069489.pypots
2024-05-22 20:56:54 [INFO]: Epoch 008 - training loss: 0.9270, validation loss: 0.6616
2024-05-22 20:56:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch8_loss0.6616070538759231.pypots
2024-05-22 20:56:58 [INFO]: Epoch 009 - training loss: 0.9151, validation loss: 0.6587
2024-05-22 20:56:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch9_loss0.6587251365184784.pypots
2024-05-22 20:57:01 [INFO]: Epoch 010 - training loss: 0.9142, validation loss: 0.6568
2024-05-22 20:57:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch10_loss0.6568463116884231.pypots
2024-05-22 20:57:04 [INFO]: Epoch 011 - training loss: 0.9034, validation loss: 0.6550
2024-05-22 20:57:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch11_loss0.6550414592027665.pypots
2024-05-22 20:57:07 [INFO]: Epoch 012 - training loss: 0.9091, validation loss: 0.6532
2024-05-22 20:57:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch12_loss0.6532010108232498.pypots
2024-05-22 20:57:10 [INFO]: Epoch 013 - training loss: 0.9165, validation loss: 0.6540
2024-05-22 20:57:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch13_loss0.6540270298719406.pypots
2024-05-22 20:57:13 [INFO]: Epoch 014 - training loss: 0.9056, validation loss: 0.6510
2024-05-22 20:57:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch14_loss0.6510399013757706.pypots
2024-05-22 20:57:16 [INFO]: Epoch 015 - training loss: 0.9125, validation loss: 0.6530
2024-05-22 20:57:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch15_loss0.6530428618192673.pypots
2024-05-22 20:57:20 [INFO]: Epoch 016 - training loss: 0.9038, validation loss: 0.6515
2024-05-22 20:57:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch16_loss0.6514932781457901.pypots
2024-05-22 20:57:23 [INFO]: Epoch 017 - training loss: 0.8891, validation loss: 0.6506
2024-05-22 20:57:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch17_loss0.6505733668804169.pypots
2024-05-22 20:57:26 [INFO]: Epoch 018 - training loss: 0.8916, validation loss: 0.6500
2024-05-22 20:57:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch18_loss0.6499841958284378.pypots
2024-05-22 20:57:29 [INFO]: Epoch 019 - training loss: 0.8884, validation loss: 0.6516
2024-05-22 20:57:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch19_loss0.6516348600387574.pypots
2024-05-22 20:57:32 [INFO]: Epoch 020 - training loss: 0.8786, validation loss: 0.6519
2024-05-22 20:57:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch20_loss0.6518907159566879.pypots
2024-05-22 20:57:35 [INFO]: Epoch 021 - training loss: 0.8807, validation loss: 0.6513
2024-05-22 20:57:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch21_loss0.6512634783983231.pypots
2024-05-22 20:57:38 [INFO]: Epoch 022 - training loss: 0.8886, validation loss: 0.6546
2024-05-22 20:57:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch22_loss0.6545663088560104.pypots
2024-05-22 20:57:42 [INFO]: Epoch 023 - training loss: 0.8752, validation loss: 0.6520
2024-05-22 20:57:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch23_loss0.6520239472389221.pypots
2024-05-22 20:57:45 [INFO]: Epoch 024 - training loss: 0.8824, validation loss: 0.6539
2024-05-22 20:57:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch24_loss0.653887128829956.pypots
2024-05-22 20:57:48 [INFO]: Epoch 025 - training loss: 0.8733, validation loss: 0.6537
2024-05-22 20:57:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch25_loss0.653733280301094.pypots
2024-05-22 20:57:51 [INFO]: Epoch 026 - training loss: 0.8722, validation loss: 0.6531
2024-05-22 20:57:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch26_loss0.6531382262706756.pypots
2024-05-22 20:57:54 [INFO]: Epoch 027 - training loss: 0.8810, validation loss: 0.6540
2024-05-22 20:57:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch27_loss0.653973987698555.pypots
2024-05-22 20:57:57 [INFO]: Epoch 028 - training loss: 0.8627, validation loss: 0.6557
2024-05-22 20:57:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN_epoch28_loss0.6557109206914902.pypots
2024-05-22 20:57:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 20:57:57 [INFO]: Finished training. The best model is from epoch#18.
2024-05-22 20:57:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/20240522_T205629/MRNN.pypots
2024-05-22 20:57:58 [INFO]: MRNN on Air-Quality: MAE=0.5217, MSE=0.6162
2024-05-22 20:57:58 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/MRNN_air_quality/imputation.pkl
2024-05-22 20:57:58 [INFO]: Using the given device: cpu
2024-05-22 20:57:58 [INFO]: LOCF on Air-Quality: MAE=0.2062, MSE=0.2674
2024-05-22 20:57:58 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_air_quality".
2024-05-22 20:57:58 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/LOCF_air_quality/imputation.pkl
2024-05-22 20:57:58 [INFO]: Median on Air-Quality: MAE=0.6602, MSE=1.0006
2024-05-22 20:57:58 [INFO]: Successfully created the given path "saved_results/round_4/Median_air_quality".
2024-05-22 20:57:58 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/Median_air_quality/imputation.pkl
2024-05-22 20:57:58 [INFO]: Mean on Air-Quality: MAE=0.6921, MSE=0.9434
2024-05-22 20:57:58 [INFO]: Successfully created the given path "saved_results/round_4/Mean_air_quality".
2024-05-22 20:57:58 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/Mean_air_quality/imputation.pkl
2024-05-22 20:57:58 [INFO]: 
SAITS on data/air_quality: MAE=0.1450.0024824007532371316, MSE=0.1060.0023956162485004335
Transformer on data/air_quality: MAE=0.1600.005268811260766577, MSE=0.1230.0072399983773449575
TimesNet on data/air_quality: MAE=0.1560.0023262362437057823, MSE=0.1510.0035056838433611868
CSDI on data/air_quality: MAE=0.1030.003870997306452506, MSE=0.1240.033955338223864685
GPVAE on data/air_quality: MAE=0.2960.007806182634714216, MSE=0.2560.011092033904615958
USGAN on data/air_quality: MAE=0.1720.0028977514521304187, MSE=0.1110.003713695380231889
BRITS on data/air_quality: MAE=0.1420.00031626408171587036, MSE=0.1050.000543793055684535
MRNN on data/air_quality: MAE=0.5230.0014861779722234061, MSE=0.6180.0023176816878239413
LOCF on data/air_quality: MAE=0.2062.7755575615628914e-17, MSE=0.2670.0
Median on data/air_quality: MAE=0.6600.0, MSE=1.0010.0
Mean on data/air_quality: MAE=0.6920.0, MSE=0.9430.0

