2024-05-25 03:42:53 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-25 03:42:53 [INFO]: Using the given device: cuda:0
2024-05-25 03:42:54 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/SAITS_air_quality/20240525_T034254
2024-05-25 03:42:54 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/SAITS_air_quality/20240525_T034254/tensorboard
2024-05-25 03:42:54 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 03:42:59 [INFO]: Epoch 001 - training loss: 1.0415, validation loss: 0.5110
2024-05-25 03:42:59 [INFO]: Epoch 002 - training loss: 0.7529, validation loss: 0.3961
2024-05-25 03:43:00 [INFO]: Epoch 003 - training loss: 0.6486, validation loss: 0.3206
2024-05-25 03:43:01 [INFO]: Epoch 004 - training loss: 0.5730, validation loss: 0.2842
2024-05-25 03:43:01 [INFO]: Epoch 005 - training loss: 0.5195, validation loss: 0.2613
2024-05-25 03:43:02 [INFO]: Epoch 006 - training loss: 0.4789, validation loss: 0.2486
2024-05-25 03:43:02 [INFO]: Epoch 007 - training loss: 0.4515, validation loss: 0.2390
2024-05-25 03:43:03 [INFO]: Epoch 008 - training loss: 0.4329, validation loss: 0.2321
2024-05-25 03:43:04 [INFO]: Epoch 009 - training loss: 0.4172, validation loss: 0.2259
2024-05-25 03:43:04 [INFO]: Epoch 010 - training loss: 0.4060, validation loss: 0.2201
2024-05-25 03:43:05 [INFO]: Epoch 011 - training loss: 0.3946, validation loss: 0.2171
2024-05-25 03:43:05 [INFO]: Epoch 012 - training loss: 0.3876, validation loss: 0.2133
2024-05-25 03:43:06 [INFO]: Epoch 013 - training loss: 0.3798, validation loss: 0.2124
2024-05-25 03:43:07 [INFO]: Epoch 014 - training loss: 0.3731, validation loss: 0.2056
2024-05-25 03:43:07 [INFO]: Epoch 015 - training loss: 0.3655, validation loss: 0.2035
2024-05-25 03:43:08 [INFO]: Epoch 016 - training loss: 0.3605, validation loss: 0.2001
2024-05-25 03:43:08 [INFO]: Epoch 017 - training loss: 0.3538, validation loss: 0.1981
2024-05-25 03:43:09 [INFO]: Epoch 018 - training loss: 0.3499, validation loss: 0.1982
2024-05-25 03:43:10 [INFO]: Epoch 019 - training loss: 0.3452, validation loss: 0.1940
2024-05-25 03:43:10 [INFO]: Epoch 020 - training loss: 0.3412, validation loss: 0.1895
2024-05-25 03:43:11 [INFO]: Epoch 021 - training loss: 0.3361, validation loss: 0.1870
2024-05-25 03:43:11 [INFO]: Epoch 022 - training loss: 0.3319, validation loss: 0.1873
2024-05-25 03:43:12 [INFO]: Epoch 023 - training loss: 0.3289, validation loss: 0.1837
2024-05-25 03:43:13 [INFO]: Epoch 024 - training loss: 0.3250, validation loss: 0.1824
2024-05-25 03:43:13 [INFO]: Epoch 025 - training loss: 0.3233, validation loss: 0.1810
2024-05-25 03:43:14 [INFO]: Epoch 026 - training loss: 0.3195, validation loss: 0.1801
2024-05-25 03:43:14 [INFO]: Epoch 027 - training loss: 0.3153, validation loss: 0.1780
2024-05-25 03:43:15 [INFO]: Epoch 028 - training loss: 0.3132, validation loss: 0.1768
2024-05-25 03:43:16 [INFO]: Epoch 029 - training loss: 0.3098, validation loss: 0.1748
2024-05-25 03:43:16 [INFO]: Epoch 030 - training loss: 0.3079, validation loss: 0.1733
2024-05-25 03:43:17 [INFO]: Epoch 031 - training loss: 0.3052, validation loss: 0.1719
2024-05-25 03:43:18 [INFO]: Epoch 032 - training loss: 0.3037, validation loss: 0.1709
2024-05-25 03:43:18 [INFO]: Epoch 033 - training loss: 0.3012, validation loss: 0.1700
2024-05-25 03:43:19 [INFO]: Epoch 034 - training loss: 0.2989, validation loss: 0.1682
2024-05-25 03:43:19 [INFO]: Epoch 035 - training loss: 0.2966, validation loss: 0.1662
2024-05-25 03:43:20 [INFO]: Epoch 036 - training loss: 0.2945, validation loss: 0.1657
2024-05-25 03:43:21 [INFO]: Epoch 037 - training loss: 0.2923, validation loss: 0.1655
2024-05-25 03:43:21 [INFO]: Epoch 038 - training loss: 0.2916, validation loss: 0.1629
2024-05-25 03:43:22 [INFO]: Epoch 039 - training loss: 0.2905, validation loss: 0.1628
2024-05-25 03:43:22 [INFO]: Epoch 040 - training loss: 0.2873, validation loss: 0.1616
2024-05-25 03:43:23 [INFO]: Epoch 041 - training loss: 0.2852, validation loss: 0.1605
2024-05-25 03:43:24 [INFO]: Epoch 042 - training loss: 0.2826, validation loss: 0.1610
2024-05-25 03:43:24 [INFO]: Epoch 043 - training loss: 0.2821, validation loss: 0.1602
2024-05-25 03:43:25 [INFO]: Epoch 044 - training loss: 0.2791, validation loss: 0.1582
2024-05-25 03:43:25 [INFO]: Epoch 045 - training loss: 0.2767, validation loss: 0.1574
2024-05-25 03:43:26 [INFO]: Epoch 046 - training loss: 0.2753, validation loss: 0.1562
2024-05-25 03:43:27 [INFO]: Epoch 047 - training loss: 0.2733, validation loss: 0.1551
2024-05-25 03:43:27 [INFO]: Epoch 048 - training loss: 0.2730, validation loss: 0.1552
2024-05-25 03:43:28 [INFO]: Epoch 049 - training loss: 0.2713, validation loss: 0.1550
2024-05-25 03:43:28 [INFO]: Epoch 050 - training loss: 0.2694, validation loss: 0.1530
2024-05-25 03:43:29 [INFO]: Epoch 051 - training loss: 0.2674, validation loss: 0.1519
2024-05-25 03:43:30 [INFO]: Epoch 052 - training loss: 0.2670, validation loss: 0.1512
2024-05-25 03:43:30 [INFO]: Epoch 053 - training loss: 0.2650, validation loss: 0.1502
2024-05-25 03:43:31 [INFO]: Epoch 054 - training loss: 0.2633, validation loss: 0.1485
2024-05-25 03:43:31 [INFO]: Epoch 055 - training loss: 0.2628, validation loss: 0.1498
2024-05-25 03:43:32 [INFO]: Epoch 056 - training loss: 0.2604, validation loss: 0.1470
2024-05-25 03:43:33 [INFO]: Epoch 057 - training loss: 0.2589, validation loss: 0.1464
2024-05-25 03:43:33 [INFO]: Epoch 058 - training loss: 0.2573, validation loss: 0.1464
2024-05-25 03:43:34 [INFO]: Epoch 059 - training loss: 0.2559, validation loss: 0.1456
2024-05-25 03:43:34 [INFO]: Epoch 060 - training loss: 0.2554, validation loss: 0.1444
2024-05-25 03:43:35 [INFO]: Epoch 061 - training loss: 0.2527, validation loss: 0.1440
2024-05-25 03:43:36 [INFO]: Epoch 062 - training loss: 0.2515, validation loss: 0.1421
2024-05-25 03:43:36 [INFO]: Epoch 063 - training loss: 0.2509, validation loss: 0.1411
2024-05-25 03:43:37 [INFO]: Epoch 064 - training loss: 0.2499, validation loss: 0.1412
2024-05-25 03:43:37 [INFO]: Epoch 065 - training loss: 0.2481, validation loss: 0.1412
2024-05-25 03:43:38 [INFO]: Epoch 066 - training loss: 0.2482, validation loss: 0.1401
2024-05-25 03:43:39 [INFO]: Epoch 067 - training loss: 0.2454, validation loss: 0.1391
2024-05-25 03:43:39 [INFO]: Epoch 068 - training loss: 0.2439, validation loss: 0.1393
2024-05-25 03:43:40 [INFO]: Epoch 069 - training loss: 0.2423, validation loss: 0.1383
2024-05-25 03:43:41 [INFO]: Epoch 070 - training loss: 0.2409, validation loss: 0.1376
2024-05-25 03:43:41 [INFO]: Epoch 071 - training loss: 0.2401, validation loss: 0.1371
2024-05-25 03:43:42 [INFO]: Epoch 072 - training loss: 0.2390, validation loss: 0.1361
2024-05-25 03:43:42 [INFO]: Epoch 073 - training loss: 0.2379, validation loss: 0.1356
2024-05-25 03:43:43 [INFO]: Epoch 074 - training loss: 0.2365, validation loss: 0.1359
2024-05-25 03:43:44 [INFO]: Epoch 075 - training loss: 0.2358, validation loss: 0.1359
2024-05-25 03:43:44 [INFO]: Epoch 076 - training loss: 0.2353, validation loss: 0.1344
2024-05-25 03:43:45 [INFO]: Epoch 077 - training loss: 0.2316, validation loss: 0.1340
2024-05-25 03:43:45 [INFO]: Epoch 078 - training loss: 0.2323, validation loss: 0.1343
2024-05-25 03:43:46 [INFO]: Epoch 079 - training loss: 0.2306, validation loss: 0.1330
2024-05-25 03:43:47 [INFO]: Epoch 080 - training loss: 0.2305, validation loss: 0.1330
2024-05-25 03:43:47 [INFO]: Epoch 081 - training loss: 0.2296, validation loss: 0.1337
2024-05-25 03:43:48 [INFO]: Epoch 082 - training loss: 0.2279, validation loss: 0.1324
2024-05-25 03:43:48 [INFO]: Epoch 083 - training loss: 0.2271, validation loss: 0.1334
2024-05-25 03:43:49 [INFO]: Epoch 084 - training loss: 0.2263, validation loss: 0.1317
2024-05-25 03:43:50 [INFO]: Epoch 085 - training loss: 0.2262, validation loss: 0.1310
2024-05-25 03:43:50 [INFO]: Epoch 086 - training loss: 0.2258, validation loss: 0.1308
2024-05-25 03:43:51 [INFO]: Epoch 087 - training loss: 0.2245, validation loss: 0.1317
2024-05-25 03:43:51 [INFO]: Epoch 088 - training loss: 0.2240, validation loss: 0.1316
2024-05-25 03:43:52 [INFO]: Epoch 089 - training loss: 0.2224, validation loss: 0.1307
2024-05-25 03:43:53 [INFO]: Epoch 090 - training loss: 0.2214, validation loss: 0.1304
2024-05-25 03:43:53 [INFO]: Epoch 091 - training loss: 0.2209, validation loss: 0.1306
2024-05-25 03:43:54 [INFO]: Epoch 092 - training loss: 0.2192, validation loss: 0.1294
2024-05-25 03:43:54 [INFO]: Epoch 093 - training loss: 0.2181, validation loss: 0.1292
2024-05-25 03:43:55 [INFO]: Epoch 094 - training loss: 0.2172, validation loss: 0.1291
2024-05-25 03:43:56 [INFO]: Epoch 095 - training loss: 0.2171, validation loss: 0.1292
2024-05-25 03:43:56 [INFO]: Epoch 096 - training loss: 0.2176, validation loss: 0.1294
2024-05-25 03:43:57 [INFO]: Epoch 097 - training loss: 0.2159, validation loss: 0.1288
2024-05-25 03:43:57 [INFO]: Epoch 098 - training loss: 0.2146, validation loss: 0.1284
2024-05-25 03:43:58 [INFO]: Epoch 099 - training loss: 0.2145, validation loss: 0.1280
2024-05-25 03:43:59 [INFO]: Epoch 100 - training loss: 0.2132, validation loss: 0.1275
2024-05-25 03:43:59 [INFO]: Epoch 101 - training loss: 0.2133, validation loss: 0.1279
2024-05-25 03:44:00 [INFO]: Epoch 102 - training loss: 0.2133, validation loss: 0.1272
2024-05-25 03:44:01 [INFO]: Epoch 103 - training loss: 0.2120, validation loss: 0.1265
2024-05-25 03:44:01 [INFO]: Epoch 104 - training loss: 0.2113, validation loss: 0.1268
2024-05-25 03:44:02 [INFO]: Epoch 105 - training loss: 0.2111, validation loss: 0.1278
2024-05-25 03:44:02 [INFO]: Epoch 106 - training loss: 0.2101, validation loss: 0.1268
2024-05-25 03:44:03 [INFO]: Epoch 107 - training loss: 0.2095, validation loss: 0.1262
2024-05-25 03:44:04 [INFO]: Epoch 108 - training loss: 0.2100, validation loss: 0.1267
2024-05-25 03:44:04 [INFO]: Epoch 109 - training loss: 0.2081, validation loss: 0.1257
2024-05-25 03:44:05 [INFO]: Epoch 110 - training loss: 0.2067, validation loss: 0.1256
2024-05-25 03:44:05 [INFO]: Epoch 111 - training loss: 0.2057, validation loss: 0.1265
2024-05-25 03:44:06 [INFO]: Epoch 112 - training loss: 0.2057, validation loss: 0.1257
2024-05-25 03:44:07 [INFO]: Epoch 113 - training loss: 0.2053, validation loss: 0.1257
2024-05-25 03:44:07 [INFO]: Epoch 114 - training loss: 0.2049, validation loss: 0.1252
2024-05-25 03:44:08 [INFO]: Epoch 115 - training loss: 0.2040, validation loss: 0.1248
2024-05-25 03:44:08 [INFO]: Epoch 116 - training loss: 0.2035, validation loss: 0.1247
2024-05-25 03:44:09 [INFO]: Epoch 117 - training loss: 0.2027, validation loss: 0.1241
2024-05-25 03:44:10 [INFO]: Epoch 118 - training loss: 0.2021, validation loss: 0.1235
2024-05-25 03:44:10 [INFO]: Epoch 119 - training loss: 0.2015, validation loss: 0.1242
2024-05-25 03:44:11 [INFO]: Epoch 120 - training loss: 0.2011, validation loss: 0.1237
2024-05-25 03:44:11 [INFO]: Epoch 121 - training loss: 0.2005, validation loss: 0.1238
2024-05-25 03:44:12 [INFO]: Epoch 122 - training loss: 0.1992, validation loss: 0.1222
2024-05-25 03:44:13 [INFO]: Epoch 123 - training loss: 0.1998, validation loss: 0.1251
2024-05-25 03:44:13 [INFO]: Epoch 124 - training loss: 0.1995, validation loss: 0.1234
2024-05-25 03:44:14 [INFO]: Epoch 125 - training loss: 0.1990, validation loss: 0.1233
2024-05-25 03:44:14 [INFO]: Epoch 126 - training loss: 0.1983, validation loss: 0.1243
2024-05-25 03:44:15 [INFO]: Epoch 127 - training loss: 0.1988, validation loss: 0.1230
2024-05-25 03:44:16 [INFO]: Epoch 128 - training loss: 0.1976, validation loss: 0.1226
2024-05-25 03:44:16 [INFO]: Epoch 129 - training loss: 0.1967, validation loss: 0.1216
2024-05-25 03:44:17 [INFO]: Epoch 130 - training loss: 0.1958, validation loss: 0.1214
2024-05-25 03:44:17 [INFO]: Epoch 131 - training loss: 0.1955, validation loss: 0.1225
2024-05-25 03:44:18 [INFO]: Epoch 132 - training loss: 0.1960, validation loss: 0.1217
2024-05-25 03:44:19 [INFO]: Epoch 133 - training loss: 0.1965, validation loss: 0.1225
2024-05-25 03:44:19 [INFO]: Epoch 134 - training loss: 0.1960, validation loss: 0.1217
2024-05-25 03:44:20 [INFO]: Epoch 135 - training loss: 0.1940, validation loss: 0.1223
2024-05-25 03:44:20 [INFO]: Epoch 136 - training loss: 0.1929, validation loss: 0.1214
2024-05-25 03:44:21 [INFO]: Epoch 137 - training loss: 0.1930, validation loss: 0.1205
2024-05-25 03:44:22 [INFO]: Epoch 138 - training loss: 0.1920, validation loss: 0.1208
2024-05-25 03:44:22 [INFO]: Epoch 139 - training loss: 0.1921, validation loss: 0.1199
2024-05-25 03:44:23 [INFO]: Epoch 140 - training loss: 0.1911, validation loss: 0.1211
2024-05-25 03:44:23 [INFO]: Epoch 141 - training loss: 0.1911, validation loss: 0.1205
2024-05-25 03:44:24 [INFO]: Epoch 142 - training loss: 0.1917, validation loss: 0.1194
2024-05-25 03:44:25 [INFO]: Epoch 143 - training loss: 0.1912, validation loss: 0.1207
2024-05-25 03:44:25 [INFO]: Epoch 144 - training loss: 0.1902, validation loss: 0.1192
2024-05-25 03:44:26 [INFO]: Epoch 145 - training loss: 0.1885, validation loss: 0.1201
2024-05-25 03:44:27 [INFO]: Epoch 146 - training loss: 0.1881, validation loss: 0.1194
2024-05-25 03:44:27 [INFO]: Epoch 147 - training loss: 0.1885, validation loss: 0.1197
2024-05-25 03:44:28 [INFO]: Epoch 148 - training loss: 0.1879, validation loss: 0.1185
2024-05-25 03:44:28 [INFO]: Epoch 149 - training loss: 0.1867, validation loss: 0.1189
2024-05-25 03:44:29 [INFO]: Epoch 150 - training loss: 0.1860, validation loss: 0.1181
2024-05-25 03:44:30 [INFO]: Epoch 151 - training loss: 0.1864, validation loss: 0.1181
2024-05-25 03:44:30 [INFO]: Epoch 152 - training loss: 0.1865, validation loss: 0.1175
2024-05-25 03:44:31 [INFO]: Epoch 153 - training loss: 0.1858, validation loss: 0.1172
2024-05-25 03:44:31 [INFO]: Epoch 154 - training loss: 0.1856, validation loss: 0.1179
2024-05-25 03:44:32 [INFO]: Epoch 155 - training loss: 0.1858, validation loss: 0.1184
2024-05-25 03:44:33 [INFO]: Epoch 156 - training loss: 0.1843, validation loss: 0.1176
2024-05-25 03:44:33 [INFO]: Epoch 157 - training loss: 0.1845, validation loss: 0.1177
2024-05-25 03:44:34 [INFO]: Epoch 158 - training loss: 0.1847, validation loss: 0.1178
2024-05-25 03:44:34 [INFO]: Epoch 159 - training loss: 0.1838, validation loss: 0.1185
2024-05-25 03:44:35 [INFO]: Epoch 160 - training loss: 0.1826, validation loss: 0.1178
2024-05-25 03:44:36 [INFO]: Epoch 161 - training loss: 0.1823, validation loss: 0.1170
2024-05-25 03:44:36 [INFO]: Epoch 162 - training loss: 0.1836, validation loss: 0.1185
2024-05-25 03:44:37 [INFO]: Epoch 163 - training loss: 0.1849, validation loss: 0.1181
2024-05-25 03:44:37 [INFO]: Epoch 164 - training loss: 0.1825, validation loss: 0.1162
2024-05-25 03:44:38 [INFO]: Epoch 165 - training loss: 0.1808, validation loss: 0.1170
2024-05-25 03:44:39 [INFO]: Epoch 166 - training loss: 0.1807, validation loss: 0.1160
2024-05-25 03:44:39 [INFO]: Epoch 167 - training loss: 0.1810, validation loss: 0.1169
2024-05-25 03:44:40 [INFO]: Epoch 168 - training loss: 0.1801, validation loss: 0.1157
2024-05-25 03:44:40 [INFO]: Epoch 169 - training loss: 0.1792, validation loss: 0.1156
2024-05-25 03:44:41 [INFO]: Epoch 170 - training loss: 0.1791, validation loss: 0.1158
2024-05-25 03:44:42 [INFO]: Epoch 171 - training loss: 0.1783, validation loss: 0.1161
2024-05-25 03:44:42 [INFO]: Epoch 172 - training loss: 0.1781, validation loss: 0.1161
2024-05-25 03:44:43 [INFO]: Epoch 173 - training loss: 0.1784, validation loss: 0.1165
2024-05-25 03:44:43 [INFO]: Epoch 174 - training loss: 0.1779, validation loss: 0.1146
2024-05-25 03:44:44 [INFO]: Epoch 175 - training loss: 0.1773, validation loss: 0.1166
2024-05-25 03:44:45 [INFO]: Epoch 176 - training loss: 0.1765, validation loss: 0.1171
2024-05-25 03:44:45 [INFO]: Epoch 177 - training loss: 0.1773, validation loss: 0.1152
2024-05-25 03:44:46 [INFO]: Epoch 178 - training loss: 0.1772, validation loss: 0.1149
2024-05-25 03:44:46 [INFO]: Epoch 179 - training loss: 0.1760, validation loss: 0.1142
2024-05-25 03:44:47 [INFO]: Epoch 180 - training loss: 0.1761, validation loss: 0.1148
2024-05-25 03:44:48 [INFO]: Epoch 181 - training loss: 0.1753, validation loss: 0.1149
2024-05-25 03:44:48 [INFO]: Epoch 182 - training loss: 0.1749, validation loss: 0.1149
2024-05-25 03:44:49 [INFO]: Epoch 183 - training loss: 0.1755, validation loss: 0.1153
2024-05-25 03:44:49 [INFO]: Epoch 184 - training loss: 0.1754, validation loss: 0.1148
2024-05-25 03:44:50 [INFO]: Epoch 185 - training loss: 0.1740, validation loss: 0.1139
2024-05-25 03:44:51 [INFO]: Epoch 186 - training loss: 0.1732, validation loss: 0.1149
2024-05-25 03:44:51 [INFO]: Epoch 187 - training loss: 0.1734, validation loss: 0.1150
2024-05-25 03:44:52 [INFO]: Epoch 188 - training loss: 0.1729, validation loss: 0.1129
2024-05-25 03:44:53 [INFO]: Epoch 189 - training loss: 0.1725, validation loss: 0.1144
2024-05-25 03:44:53 [INFO]: Epoch 190 - training loss: 0.1718, validation loss: 0.1139
2024-05-25 03:44:54 [INFO]: Epoch 191 - training loss: 0.1714, validation loss: 0.1140
2024-05-25 03:44:54 [INFO]: Epoch 192 - training loss: 0.1718, validation loss: 0.1144
2024-05-25 03:44:55 [INFO]: Epoch 193 - training loss: 0.1716, validation loss: 0.1129
2024-05-25 03:44:56 [INFO]: Epoch 194 - training loss: 0.1709, validation loss: 0.1140
2024-05-25 03:44:56 [INFO]: Epoch 195 - training loss: 0.1708, validation loss: 0.1144
2024-05-25 03:44:57 [INFO]: Epoch 196 - training loss: 0.1708, validation loss: 0.1136
2024-05-25 03:44:57 [INFO]: Epoch 197 - training loss: 0.1701, validation loss: 0.1126
2024-05-25 03:44:58 [INFO]: Epoch 198 - training loss: 0.1706, validation loss: 0.1135
2024-05-25 03:44:59 [INFO]: Epoch 199 - training loss: 0.1703, validation loss: 0.1123
2024-05-25 03:44:59 [INFO]: Epoch 200 - training loss: 0.1717, validation loss: 0.1133
2024-05-25 03:45:00 [INFO]: Epoch 201 - training loss: 0.1714, validation loss: 0.1120
2024-05-25 03:45:00 [INFO]: Epoch 202 - training loss: 0.1699, validation loss: 0.1135
2024-05-25 03:45:01 [INFO]: Epoch 203 - training loss: 0.1680, validation loss: 0.1135
2024-05-25 03:45:02 [INFO]: Epoch 204 - training loss: 0.1677, validation loss: 0.1120
2024-05-25 03:45:02 [INFO]: Epoch 205 - training loss: 0.1670, validation loss: 0.1127
2024-05-25 03:45:03 [INFO]: Epoch 206 - training loss: 0.1704, validation loss: 0.1116
2024-05-25 03:45:03 [INFO]: Epoch 207 - training loss: 0.1683, validation loss: 0.1132
2024-05-25 03:45:04 [INFO]: Epoch 208 - training loss: 0.1674, validation loss: 0.1132
2024-05-25 03:45:05 [INFO]: Epoch 209 - training loss: 0.1663, validation loss: 0.1128
2024-05-25 03:45:05 [INFO]: Epoch 210 - training loss: 0.1668, validation loss: 0.1124
2024-05-25 03:45:06 [INFO]: Epoch 211 - training loss: 0.1662, validation loss: 0.1108
2024-05-25 03:45:06 [INFO]: Epoch 212 - training loss: 0.1659, validation loss: 0.1115
2024-05-25 03:45:07 [INFO]: Epoch 213 - training loss: 0.1662, validation loss: 0.1123
2024-05-25 03:45:08 [INFO]: Epoch 214 - training loss: 0.1656, validation loss: 0.1111
2024-05-25 03:45:08 [INFO]: Epoch 215 - training loss: 0.1646, validation loss: 0.1103
2024-05-25 03:45:09 [INFO]: Epoch 216 - training loss: 0.1651, validation loss: 0.1115
2024-05-25 03:45:09 [INFO]: Epoch 217 - training loss: 0.1670, validation loss: 0.1118
2024-05-25 03:45:10 [INFO]: Epoch 218 - training loss: 0.1646, validation loss: 0.1108
2024-05-25 03:45:10 [INFO]: Epoch 219 - training loss: 0.1644, validation loss: 0.1115
2024-05-25 03:45:11 [INFO]: Epoch 220 - training loss: 0.1631, validation loss: 0.1112
2024-05-25 03:45:12 [INFO]: Epoch 221 - training loss: 0.1629, validation loss: 0.1113
2024-05-25 03:45:12 [INFO]: Epoch 222 - training loss: 0.1641, validation loss: 0.1109
2024-05-25 03:45:13 [INFO]: Epoch 223 - training loss: 0.1639, validation loss: 0.1113
2024-05-25 03:45:13 [INFO]: Epoch 224 - training loss: 0.1628, validation loss: 0.1125
2024-05-25 03:45:14 [INFO]: Epoch 225 - training loss: 0.1628, validation loss: 0.1113
2024-05-25 03:45:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:45:14 [INFO]: Finished training. The best model is from epoch#215.
2024-05-25 03:45:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/SAITS_air_quality/20240525_T034254/SAITS.pypots
2024-05-25 03:45:14 [INFO]: SAITS on Air-Quality: MAE=0.1514, MSE=0.2159
2024-05-25 03:45:14 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/SAITS_air_quality/imputation.pkl
2024-05-25 03:45:14 [INFO]: Using the given device: cuda:0
2024-05-25 03:45:14 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/Transformer_air_quality/20240525_T034514
2024-05-25 03:45:14 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/Transformer_air_quality/20240525_T034514/tensorboard
2024-05-25 03:45:14 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 03:45:15 [INFO]: Epoch 001 - training loss: 0.8845, validation loss: 0.4561
2024-05-25 03:45:15 [INFO]: Epoch 002 - training loss: 0.5551, validation loss: 0.3384
2024-05-25 03:45:15 [INFO]: Epoch 003 - training loss: 0.4599, validation loss: 0.2904
2024-05-25 03:45:15 [INFO]: Epoch 004 - training loss: 0.4142, validation loss: 0.2623
2024-05-25 03:45:16 [INFO]: Epoch 005 - training loss: 0.3825, validation loss: 0.2464
2024-05-25 03:45:16 [INFO]: Epoch 006 - training loss: 0.3667, validation loss: 0.2412
2024-05-25 03:45:16 [INFO]: Epoch 007 - training loss: 0.3461, validation loss: 0.2297
2024-05-25 03:45:16 [INFO]: Epoch 008 - training loss: 0.3343, validation loss: 0.2223
2024-05-25 03:45:17 [INFO]: Epoch 009 - training loss: 0.3241, validation loss: 0.2163
2024-05-25 03:45:17 [INFO]: Epoch 010 - training loss: 0.3142, validation loss: 0.2127
2024-05-25 03:45:17 [INFO]: Epoch 011 - training loss: 0.3090, validation loss: 0.2075
2024-05-25 03:45:17 [INFO]: Epoch 012 - training loss: 0.3010, validation loss: 0.2040
2024-05-25 03:45:18 [INFO]: Epoch 013 - training loss: 0.2937, validation loss: 0.1995
2024-05-25 03:45:18 [INFO]: Epoch 014 - training loss: 0.2913, validation loss: 0.1950
2024-05-25 03:45:18 [INFO]: Epoch 015 - training loss: 0.2883, validation loss: 0.1917
2024-05-25 03:45:18 [INFO]: Epoch 016 - training loss: 0.2838, validation loss: 0.1911
2024-05-25 03:45:19 [INFO]: Epoch 017 - training loss: 0.2771, validation loss: 0.1883
2024-05-25 03:45:19 [INFO]: Epoch 018 - training loss: 0.2730, validation loss: 0.1860
2024-05-25 03:45:19 [INFO]: Epoch 019 - training loss: 0.2700, validation loss: 0.1821
2024-05-25 03:45:19 [INFO]: Epoch 020 - training loss: 0.2654, validation loss: 0.1825
2024-05-25 03:45:20 [INFO]: Epoch 021 - training loss: 0.2649, validation loss: 0.1791
2024-05-25 03:45:20 [INFO]: Epoch 022 - training loss: 0.2611, validation loss: 0.1776
2024-05-25 03:45:20 [INFO]: Epoch 023 - training loss: 0.2576, validation loss: 0.1759
2024-05-25 03:45:20 [INFO]: Epoch 024 - training loss: 0.2555, validation loss: 0.1763
2024-05-25 03:45:21 [INFO]: Epoch 025 - training loss: 0.2527, validation loss: 0.1737
2024-05-25 03:45:21 [INFO]: Epoch 026 - training loss: 0.2481, validation loss: 0.1733
2024-05-25 03:45:21 [INFO]: Epoch 027 - training loss: 0.2465, validation loss: 0.1721
2024-05-25 03:45:21 [INFO]: Epoch 028 - training loss: 0.2504, validation loss: 0.1726
2024-05-25 03:45:22 [INFO]: Epoch 029 - training loss: 0.2448, validation loss: 0.1687
2024-05-25 03:45:22 [INFO]: Epoch 030 - training loss: 0.2395, validation loss: 0.1712
2024-05-25 03:45:22 [INFO]: Epoch 031 - training loss: 0.2384, validation loss: 0.1692
2024-05-25 03:45:22 [INFO]: Epoch 032 - training loss: 0.2357, validation loss: 0.1689
2024-05-25 03:45:23 [INFO]: Epoch 033 - training loss: 0.2352, validation loss: 0.1672
2024-05-25 03:45:23 [INFO]: Epoch 034 - training loss: 0.2326, validation loss: 0.1652
2024-05-25 03:45:23 [INFO]: Epoch 035 - training loss: 0.2334, validation loss: 0.1684
2024-05-25 03:45:23 [INFO]: Epoch 036 - training loss: 0.2290, validation loss: 0.1635
2024-05-25 03:45:24 [INFO]: Epoch 037 - training loss: 0.2253, validation loss: 0.1641
2024-05-25 03:45:24 [INFO]: Epoch 038 - training loss: 0.2237, validation loss: 0.1632
2024-05-25 03:45:24 [INFO]: Epoch 039 - training loss: 0.2248, validation loss: 0.1631
2024-05-25 03:45:24 [INFO]: Epoch 040 - training loss: 0.2243, validation loss: 0.1614
2024-05-25 03:45:25 [INFO]: Epoch 041 - training loss: 0.2206, validation loss: 0.1606
2024-05-25 03:45:25 [INFO]: Epoch 042 - training loss: 0.2167, validation loss: 0.1609
2024-05-25 03:45:25 [INFO]: Epoch 043 - training loss: 0.2190, validation loss: 0.1615
2024-05-25 03:45:25 [INFO]: Epoch 044 - training loss: 0.2166, validation loss: 0.1594
2024-05-25 03:45:26 [INFO]: Epoch 045 - training loss: 0.2150, validation loss: 0.1584
2024-05-25 03:45:26 [INFO]: Epoch 046 - training loss: 0.2118, validation loss: 0.1584
2024-05-25 03:45:26 [INFO]: Epoch 047 - training loss: 0.2112, validation loss: 0.1583
2024-05-25 03:45:26 [INFO]: Epoch 048 - training loss: 0.2094, validation loss: 0.1592
2024-05-25 03:45:27 [INFO]: Epoch 049 - training loss: 0.2082, validation loss: 0.1567
2024-05-25 03:45:27 [INFO]: Epoch 050 - training loss: 0.2082, validation loss: 0.1568
2024-05-25 03:45:27 [INFO]: Epoch 051 - training loss: 0.2075, validation loss: 0.1571
2024-05-25 03:45:27 [INFO]: Epoch 052 - training loss: 0.2055, validation loss: 0.1573
2024-05-25 03:45:28 [INFO]: Epoch 053 - training loss: 0.2050, validation loss: 0.1569
2024-05-25 03:45:28 [INFO]: Epoch 054 - training loss: 0.2059, validation loss: 0.1551
2024-05-25 03:45:28 [INFO]: Epoch 055 - training loss: 0.2056, validation loss: 0.1550
2024-05-25 03:45:28 [INFO]: Epoch 056 - training loss: 0.2020, validation loss: 0.1542
2024-05-25 03:45:29 [INFO]: Epoch 057 - training loss: 0.1996, validation loss: 0.1539
2024-05-25 03:45:29 [INFO]: Epoch 058 - training loss: 0.1991, validation loss: 0.1531
2024-05-25 03:45:29 [INFO]: Epoch 059 - training loss: 0.1980, validation loss: 0.1529
2024-05-25 03:45:29 [INFO]: Epoch 060 - training loss: 0.1953, validation loss: 0.1525
2024-05-25 03:45:30 [INFO]: Epoch 061 - training loss: 0.1979, validation loss: 0.1532
2024-05-25 03:45:30 [INFO]: Epoch 062 - training loss: 0.1977, validation loss: 0.1531
2024-05-25 03:45:30 [INFO]: Epoch 063 - training loss: 0.1927, validation loss: 0.1515
2024-05-25 03:45:30 [INFO]: Epoch 064 - training loss: 0.1901, validation loss: 0.1520
2024-05-25 03:45:31 [INFO]: Epoch 065 - training loss: 0.1895, validation loss: 0.1505
2024-05-25 03:45:31 [INFO]: Epoch 066 - training loss: 0.1911, validation loss: 0.1483
2024-05-25 03:45:31 [INFO]: Epoch 067 - training loss: 0.1899, validation loss: 0.1505
2024-05-25 03:45:31 [INFO]: Epoch 068 - training loss: 0.1880, validation loss: 0.1499
2024-05-25 03:45:32 [INFO]: Epoch 069 - training loss: 0.1876, validation loss: 0.1489
2024-05-25 03:45:32 [INFO]: Epoch 070 - training loss: 0.1863, validation loss: 0.1536
2024-05-25 03:45:32 [INFO]: Epoch 071 - training loss: 0.1888, validation loss: 0.1500
2024-05-25 03:45:32 [INFO]: Epoch 072 - training loss: 0.1851, validation loss: 0.1486
2024-05-25 03:45:33 [INFO]: Epoch 073 - training loss: 0.1837, validation loss: 0.1476
2024-05-25 03:45:33 [INFO]: Epoch 074 - training loss: 0.1816, validation loss: 0.1491
2024-05-25 03:45:33 [INFO]: Epoch 075 - training loss: 0.1819, validation loss: 0.1493
2024-05-25 03:45:33 [INFO]: Epoch 076 - training loss: 0.1830, validation loss: 0.1480
2024-05-25 03:45:34 [INFO]: Epoch 077 - training loss: 0.1809, validation loss: 0.1462
2024-05-25 03:45:34 [INFO]: Epoch 078 - training loss: 0.1795, validation loss: 0.1481
2024-05-25 03:45:34 [INFO]: Epoch 079 - training loss: 0.1787, validation loss: 0.1465
2024-05-25 03:45:34 [INFO]: Epoch 080 - training loss: 0.1785, validation loss: 0.1461
2024-05-25 03:45:35 [INFO]: Epoch 081 - training loss: 0.1792, validation loss: 0.1452
2024-05-25 03:45:35 [INFO]: Epoch 082 - training loss: 0.1764, validation loss: 0.1474
2024-05-25 03:45:35 [INFO]: Epoch 083 - training loss: 0.1767, validation loss: 0.1438
2024-05-25 03:45:35 [INFO]: Epoch 084 - training loss: 0.1752, validation loss: 0.1454
2024-05-25 03:45:36 [INFO]: Epoch 085 - training loss: 0.1747, validation loss: 0.1443
2024-05-25 03:45:36 [INFO]: Epoch 086 - training loss: 0.1747, validation loss: 0.1436
2024-05-25 03:45:36 [INFO]: Epoch 087 - training loss: 0.1748, validation loss: 0.1440
2024-05-25 03:45:36 [INFO]: Epoch 088 - training loss: 0.1736, validation loss: 0.1428
2024-05-25 03:45:37 [INFO]: Epoch 089 - training loss: 0.1721, validation loss: 0.1435
2024-05-25 03:45:37 [INFO]: Epoch 090 - training loss: 0.1707, validation loss: 0.1422
2024-05-25 03:45:37 [INFO]: Epoch 091 - training loss: 0.1700, validation loss: 0.1435
2024-05-25 03:45:37 [INFO]: Epoch 092 - training loss: 0.1695, validation loss: 0.1425
2024-05-25 03:45:38 [INFO]: Epoch 093 - training loss: 0.1671, validation loss: 0.1439
2024-05-25 03:45:38 [INFO]: Epoch 094 - training loss: 0.1670, validation loss: 0.1424
2024-05-25 03:45:38 [INFO]: Epoch 095 - training loss: 0.1662, validation loss: 0.1407
2024-05-25 03:45:38 [INFO]: Epoch 096 - training loss: 0.1686, validation loss: 0.1408
2024-05-25 03:45:39 [INFO]: Epoch 097 - training loss: 0.1694, validation loss: 0.1430
2024-05-25 03:45:39 [INFO]: Epoch 098 - training loss: 0.1663, validation loss: 0.1420
2024-05-25 03:45:39 [INFO]: Epoch 099 - training loss: 0.1646, validation loss: 0.1417
2024-05-25 03:45:39 [INFO]: Epoch 100 - training loss: 0.1659, validation loss: 0.1412
2024-05-25 03:45:40 [INFO]: Epoch 101 - training loss: 0.1663, validation loss: 0.1409
2024-05-25 03:45:40 [INFO]: Epoch 102 - training loss: 0.1634, validation loss: 0.1411
2024-05-25 03:45:40 [INFO]: Epoch 103 - training loss: 0.1631, validation loss: 0.1409
2024-05-25 03:45:40 [INFO]: Epoch 104 - training loss: 0.1611, validation loss: 0.1400
2024-05-25 03:45:41 [INFO]: Epoch 105 - training loss: 0.1604, validation loss: 0.1423
2024-05-25 03:45:41 [INFO]: Epoch 106 - training loss: 0.1596, validation loss: 0.1407
2024-05-25 03:45:41 [INFO]: Epoch 107 - training loss: 0.1592, validation loss: 0.1403
2024-05-25 03:45:41 [INFO]: Epoch 108 - training loss: 0.1580, validation loss: 0.1403
2024-05-25 03:45:42 [INFO]: Epoch 109 - training loss: 0.1584, validation loss: 0.1390
2024-05-25 03:45:42 [INFO]: Epoch 110 - training loss: 0.1596, validation loss: 0.1402
2024-05-25 03:45:42 [INFO]: Epoch 111 - training loss: 0.1597, validation loss: 0.1397
2024-05-25 03:45:42 [INFO]: Epoch 112 - training loss: 0.1577, validation loss: 0.1395
2024-05-25 03:45:43 [INFO]: Epoch 113 - training loss: 0.1557, validation loss: 0.1369
2024-05-25 03:45:43 [INFO]: Epoch 114 - training loss: 0.1551, validation loss: 0.1380
2024-05-25 03:45:43 [INFO]: Epoch 115 - training loss: 0.1569, validation loss: 0.1384
2024-05-25 03:45:43 [INFO]: Epoch 116 - training loss: 0.1537, validation loss: 0.1377
2024-05-25 03:45:44 [INFO]: Epoch 117 - training loss: 0.1560, validation loss: 0.1386
2024-05-25 03:45:44 [INFO]: Epoch 118 - training loss: 0.1558, validation loss: 0.1374
2024-05-25 03:45:44 [INFO]: Epoch 119 - training loss: 0.1535, validation loss: 0.1377
2024-05-25 03:45:44 [INFO]: Epoch 120 - training loss: 0.1545, validation loss: 0.1370
2024-05-25 03:45:45 [INFO]: Epoch 121 - training loss: 0.1532, validation loss: 0.1379
2024-05-25 03:45:45 [INFO]: Epoch 122 - training loss: 0.1527, validation loss: 0.1369
2024-05-25 03:45:45 [INFO]: Epoch 123 - training loss: 0.1528, validation loss: 0.1360
2024-05-25 03:45:45 [INFO]: Epoch 124 - training loss: 0.1517, validation loss: 0.1389
2024-05-25 03:45:46 [INFO]: Epoch 125 - training loss: 0.1510, validation loss: 0.1372
2024-05-25 03:45:46 [INFO]: Epoch 126 - training loss: 0.1498, validation loss: 0.1353
2024-05-25 03:45:46 [INFO]: Epoch 127 - training loss: 0.1507, validation loss: 0.1398
2024-05-25 03:45:46 [INFO]: Epoch 128 - training loss: 0.1501, validation loss: 0.1354
2024-05-25 03:45:47 [INFO]: Epoch 129 - training loss: 0.1482, validation loss: 0.1349
2024-05-25 03:45:47 [INFO]: Epoch 130 - training loss: 0.1470, validation loss: 0.1358
2024-05-25 03:45:47 [INFO]: Epoch 131 - training loss: 0.1469, validation loss: 0.1353
2024-05-25 03:45:47 [INFO]: Epoch 132 - training loss: 0.1490, validation loss: 0.1379
2024-05-25 03:45:48 [INFO]: Epoch 133 - training loss: 0.1473, validation loss: 0.1355
2024-05-25 03:45:48 [INFO]: Epoch 134 - training loss: 0.1466, validation loss: 0.1364
2024-05-25 03:45:48 [INFO]: Epoch 135 - training loss: 0.1438, validation loss: 0.1357
2024-05-25 03:45:48 [INFO]: Epoch 136 - training loss: 0.1438, validation loss: 0.1344
2024-05-25 03:45:49 [INFO]: Epoch 137 - training loss: 0.1475, validation loss: 0.1352
2024-05-25 03:45:49 [INFO]: Epoch 138 - training loss: 0.1447, validation loss: 0.1360
2024-05-25 03:45:49 [INFO]: Epoch 139 - training loss: 0.1463, validation loss: 0.1347
2024-05-25 03:45:49 [INFO]: Epoch 140 - training loss: 0.1444, validation loss: 0.1350
2024-05-25 03:45:50 [INFO]: Epoch 141 - training loss: 0.1428, validation loss: 0.1351
2024-05-25 03:45:50 [INFO]: Epoch 142 - training loss: 0.1415, validation loss: 0.1356
2024-05-25 03:45:50 [INFO]: Epoch 143 - training loss: 0.1424, validation loss: 0.1363
2024-05-25 03:45:50 [INFO]: Epoch 144 - training loss: 0.1425, validation loss: 0.1342
2024-05-25 03:45:51 [INFO]: Epoch 145 - training loss: 0.1410, validation loss: 0.1344
2024-05-25 03:45:51 [INFO]: Epoch 146 - training loss: 0.1429, validation loss: 0.1368
2024-05-25 03:45:51 [INFO]: Epoch 147 - training loss: 0.1423, validation loss: 0.1351
2024-05-25 03:45:51 [INFO]: Epoch 148 - training loss: 0.1410, validation loss: 0.1347
2024-05-25 03:45:52 [INFO]: Epoch 149 - training loss: 0.1408, validation loss: 0.1371
2024-05-25 03:45:52 [INFO]: Epoch 150 - training loss: 0.1400, validation loss: 0.1334
2024-05-25 03:45:52 [INFO]: Epoch 151 - training loss: 0.1385, validation loss: 0.1350
2024-05-25 03:45:52 [INFO]: Epoch 152 - training loss: 0.1412, validation loss: 0.1364
2024-05-25 03:45:53 [INFO]: Epoch 153 - training loss: 0.1421, validation loss: 0.1364
2024-05-25 03:45:53 [INFO]: Epoch 154 - training loss: 0.1447, validation loss: 0.1356
2024-05-25 03:45:53 [INFO]: Epoch 155 - training loss: 0.1392, validation loss: 0.1330
2024-05-25 03:45:53 [INFO]: Epoch 156 - training loss: 0.1374, validation loss: 0.1361
2024-05-25 03:45:54 [INFO]: Epoch 157 - training loss: 0.1396, validation loss: 0.1347
2024-05-25 03:45:54 [INFO]: Epoch 158 - training loss: 0.1390, validation loss: 0.1347
2024-05-25 03:45:54 [INFO]: Epoch 159 - training loss: 0.1368, validation loss: 0.1340
2024-05-25 03:45:54 [INFO]: Epoch 160 - training loss: 0.1368, validation loss: 0.1363
2024-05-25 03:45:55 [INFO]: Epoch 161 - training loss: 0.1382, validation loss: 0.1336
2024-05-25 03:45:55 [INFO]: Epoch 162 - training loss: 0.1390, validation loss: 0.1368
2024-05-25 03:45:55 [INFO]: Epoch 163 - training loss: 0.1393, validation loss: 0.1347
2024-05-25 03:45:55 [INFO]: Epoch 164 - training loss: 0.1348, validation loss: 0.1338
2024-05-25 03:45:56 [INFO]: Epoch 165 - training loss: 0.1337, validation loss: 0.1317
2024-05-25 03:45:56 [INFO]: Epoch 166 - training loss: 0.1333, validation loss: 0.1315
2024-05-25 03:45:56 [INFO]: Epoch 167 - training loss: 0.1326, validation loss: 0.1342
2024-05-25 03:45:56 [INFO]: Epoch 168 - training loss: 0.1333, validation loss: 0.1338
2024-05-25 03:45:57 [INFO]: Epoch 169 - training loss: 0.1324, validation loss: 0.1333
2024-05-25 03:45:57 [INFO]: Epoch 170 - training loss: 0.1325, validation loss: 0.1325
2024-05-25 03:45:57 [INFO]: Epoch 171 - training loss: 0.1315, validation loss: 0.1321
2024-05-25 03:45:57 [INFO]: Epoch 172 - training loss: 0.1301, validation loss: 0.1322
2024-05-25 03:45:58 [INFO]: Epoch 173 - training loss: 0.1291, validation loss: 0.1318
2024-05-25 03:45:58 [INFO]: Epoch 174 - training loss: 0.1303, validation loss: 0.1329
2024-05-25 03:45:58 [INFO]: Epoch 175 - training loss: 0.1299, validation loss: 0.1325
2024-05-25 03:45:58 [INFO]: Epoch 176 - training loss: 0.1315, validation loss: 0.1329
2024-05-25 03:45:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:45:58 [INFO]: Finished training. The best model is from epoch#166.
2024-05-25 03:45:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/Transformer_air_quality/20240525_T034514/Transformer.pypots
2024-05-25 03:45:58 [INFO]: Transformer on Air-Quality: MAE=0.1664, MSE=0.2466
2024-05-25 03:45:58 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Transformer_air_quality/imputation.pkl
2024-05-25 03:45:58 [INFO]: Using the given device: cuda:0
2024-05-25 03:45:58 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/TimesNet_air_quality/20240525_T034558
2024-05-25 03:45:58 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/TimesNet_air_quality/20240525_T034558/tensorboard
2024-05-25 03:45:59 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 03:46:00 [INFO]: Epoch 001 - training loss: 0.2826, validation loss: 0.2834
2024-05-25 03:46:00 [INFO]: Epoch 002 - training loss: 0.2377, validation loss: 0.2536
2024-05-25 03:46:01 [INFO]: Epoch 003 - training loss: 0.2481, validation loss: 0.2413
2024-05-25 03:46:01 [INFO]: Epoch 004 - training loss: 0.1731, validation loss: 0.2289
2024-05-25 03:46:02 [INFO]: Epoch 005 - training loss: 0.1520, validation loss: 0.2167
2024-05-25 03:46:02 [INFO]: Epoch 006 - training loss: 0.1488, validation loss: 0.2169
2024-05-25 03:46:03 [INFO]: Epoch 007 - training loss: 0.1455, validation loss: 0.2090
2024-05-25 03:46:03 [INFO]: Epoch 008 - training loss: 0.1311, validation loss: 0.2064
2024-05-25 03:46:03 [INFO]: Epoch 009 - training loss: 0.1376, validation loss: 0.2004
2024-05-25 03:46:04 [INFO]: Epoch 010 - training loss: 0.1311, validation loss: 0.1977
2024-05-25 03:46:04 [INFO]: Epoch 011 - training loss: 0.1240, validation loss: 0.1960
2024-05-25 03:46:05 [INFO]: Epoch 012 - training loss: 0.1102, validation loss: 0.1900
2024-05-25 03:46:05 [INFO]: Epoch 013 - training loss: 0.1051, validation loss: 0.1997
2024-05-25 03:46:06 [INFO]: Epoch 014 - training loss: 0.1030, validation loss: 0.1869
2024-05-25 03:46:06 [INFO]: Epoch 015 - training loss: 0.1009, validation loss: 0.1875
2024-05-25 03:46:07 [INFO]: Epoch 016 - training loss: 0.1031, validation loss: 0.1898
2024-05-25 03:46:07 [INFO]: Epoch 017 - training loss: 0.0951, validation loss: 0.1842
2024-05-25 03:46:08 [INFO]: Epoch 018 - training loss: 0.0942, validation loss: 0.1854
2024-05-25 03:46:08 [INFO]: Epoch 019 - training loss: 0.0903, validation loss: 0.1935
2024-05-25 03:46:09 [INFO]: Epoch 020 - training loss: 0.1047, validation loss: 0.1837
2024-05-25 03:46:09 [INFO]: Epoch 021 - training loss: 0.1024, validation loss: 0.1841
2024-05-25 03:46:09 [INFO]: Epoch 022 - training loss: 0.0909, validation loss: 0.1838
2024-05-25 03:46:10 [INFO]: Epoch 023 - training loss: 0.0829, validation loss: 0.1787
2024-05-25 03:46:10 [INFO]: Epoch 024 - training loss: 0.0807, validation loss: 0.1796
2024-05-25 03:46:11 [INFO]: Epoch 025 - training loss: 0.0823, validation loss: 0.1769
2024-05-25 03:46:11 [INFO]: Epoch 026 - training loss: 0.0807, validation loss: 0.1761
2024-05-25 03:46:12 [INFO]: Epoch 027 - training loss: 0.0831, validation loss: 0.1806
2024-05-25 03:46:12 [INFO]: Epoch 028 - training loss: 0.0995, validation loss: 0.1809
2024-05-25 03:46:13 [INFO]: Epoch 029 - training loss: 0.0867, validation loss: 0.1733
2024-05-25 03:46:13 [INFO]: Epoch 030 - training loss: 0.0816, validation loss: 0.1759
2024-05-25 03:46:14 [INFO]: Epoch 031 - training loss: 0.0726, validation loss: 0.1733
2024-05-25 03:46:14 [INFO]: Epoch 032 - training loss: 0.0710, validation loss: 0.1728
2024-05-25 03:46:15 [INFO]: Epoch 033 - training loss: 0.0690, validation loss: 0.1725
2024-05-25 03:46:15 [INFO]: Epoch 034 - training loss: 0.0658, validation loss: 0.1719
2024-05-25 03:46:16 [INFO]: Epoch 035 - training loss: 0.0665, validation loss: 0.1737
2024-05-25 03:46:16 [INFO]: Epoch 036 - training loss: 0.0698, validation loss: 0.1729
2024-05-25 03:46:16 [INFO]: Epoch 037 - training loss: 0.0676, validation loss: 0.1710
2024-05-25 03:46:17 [INFO]: Epoch 038 - training loss: 0.0633, validation loss: 0.1720
2024-05-25 03:46:17 [INFO]: Epoch 039 - training loss: 0.0614, validation loss: 0.1745
2024-05-25 03:46:18 [INFO]: Epoch 040 - training loss: 0.0617, validation loss: 0.1698
2024-05-25 03:46:18 [INFO]: Epoch 041 - training loss: 0.0617, validation loss: 0.1726
2024-05-25 03:46:19 [INFO]: Epoch 042 - training loss: 0.0611, validation loss: 0.1711
2024-05-25 03:46:19 [INFO]: Epoch 043 - training loss: 0.0622, validation loss: 0.1747
2024-05-25 03:46:20 [INFO]: Epoch 044 - training loss: 0.0602, validation loss: 0.1721
2024-05-25 03:46:20 [INFO]: Epoch 045 - training loss: 0.0614, validation loss: 0.1726
2024-05-25 03:46:21 [INFO]: Epoch 046 - training loss: 0.0608, validation loss: 0.1752
2024-05-25 03:46:21 [INFO]: Epoch 047 - training loss: 0.0636, validation loss: 0.1740
2024-05-25 03:46:22 [INFO]: Epoch 048 - training loss: 0.0585, validation loss: 0.1696
2024-05-25 03:46:22 [INFO]: Epoch 049 - training loss: 0.0606, validation loss: 0.1734
2024-05-25 03:46:22 [INFO]: Epoch 050 - training loss: 0.0573, validation loss: 0.1700
2024-05-25 03:46:23 [INFO]: Epoch 051 - training loss: 0.0592, validation loss: 0.1690
2024-05-25 03:46:23 [INFO]: Epoch 052 - training loss: 0.0706, validation loss: 0.1752
2024-05-25 03:46:24 [INFO]: Epoch 053 - training loss: 0.0770, validation loss: 0.1751
2024-05-25 03:46:24 [INFO]: Epoch 054 - training loss: 0.0597, validation loss: 0.1735
2024-05-25 03:46:25 [INFO]: Epoch 055 - training loss: 0.0663, validation loss: 0.1789
2024-05-25 03:46:25 [INFO]: Epoch 056 - training loss: 0.0638, validation loss: 0.1712
2024-05-25 03:46:26 [INFO]: Epoch 057 - training loss: 0.0565, validation loss: 0.1699
2024-05-25 03:46:26 [INFO]: Epoch 058 - training loss: 0.0524, validation loss: 0.1685
2024-05-25 03:46:27 [INFO]: Epoch 059 - training loss: 0.0492, validation loss: 0.1677
2024-05-25 03:46:27 [INFO]: Epoch 060 - training loss: 0.0489, validation loss: 0.1697
2024-05-25 03:46:28 [INFO]: Epoch 061 - training loss: 0.0480, validation loss: 0.1681
2024-05-25 03:46:28 [INFO]: Epoch 062 - training loss: 0.0470, validation loss: 0.1705
2024-05-25 03:46:28 [INFO]: Epoch 063 - training loss: 0.0465, validation loss: 0.1681
2024-05-25 03:46:29 [INFO]: Epoch 064 - training loss: 0.0459, validation loss: 0.1674
2024-05-25 03:46:29 [INFO]: Epoch 065 - training loss: 0.0437, validation loss: 0.1696
2024-05-25 03:46:30 [INFO]: Epoch 066 - training loss: 0.0434, validation loss: 0.1695
2024-05-25 03:46:30 [INFO]: Epoch 067 - training loss: 0.0431, validation loss: 0.1673
2024-05-25 03:46:31 [INFO]: Epoch 068 - training loss: 0.0460, validation loss: 0.1672
2024-05-25 03:46:31 [INFO]: Epoch 069 - training loss: 0.0439, validation loss: 0.1697
2024-05-25 03:46:32 [INFO]: Epoch 070 - training loss: 0.0454, validation loss: 0.1700
2024-05-25 03:46:32 [INFO]: Epoch 071 - training loss: 0.0441, validation loss: 0.1709
2024-05-25 03:46:33 [INFO]: Epoch 072 - training loss: 0.0442, validation loss: 0.1714
2024-05-25 03:46:33 [INFO]: Epoch 073 - training loss: 0.0442, validation loss: 0.1728
2024-05-25 03:46:34 [INFO]: Epoch 074 - training loss: 0.0447, validation loss: 0.1672
2024-05-25 03:46:34 [INFO]: Epoch 075 - training loss: 0.0472, validation loss: 0.1735
2024-05-25 03:46:34 [INFO]: Epoch 076 - training loss: 0.0480, validation loss: 0.1699
2024-05-25 03:46:35 [INFO]: Epoch 077 - training loss: 0.0412, validation loss: 0.1718
2024-05-25 03:46:35 [INFO]: Epoch 078 - training loss: 0.0411, validation loss: 0.1684
2024-05-25 03:46:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:46:35 [INFO]: Finished training. The best model is from epoch#68.
2024-05-25 03:46:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/TimesNet_air_quality/20240525_T034558/TimesNet.pypots
2024-05-25 03:46:36 [INFO]: TimesNet on Air-Quality: MAE=0.1706, MSE=0.3182
2024-05-25 03:46:36 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/TimesNet_air_quality/imputation.pkl
2024-05-25 03:46:36 [INFO]: Using the given device: cuda:0
2024-05-25 03:46:36 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636
2024-05-25 03:46:36 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/tensorboard
2024-05-25 03:46:36 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 03:46:52 [INFO]: Epoch 001 - training loss: 0.5116, validation loss: 0.3231
2024-05-25 03:46:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch1_loss0.32306748926639556.pypots
2024-05-25 03:47:09 [INFO]: Epoch 002 - training loss: 0.2723, validation loss: 0.2608
2024-05-25 03:47:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch2_loss0.2608268827199936.pypots
2024-05-25 03:47:26 [INFO]: Epoch 003 - training loss: 0.2674, validation loss: 0.2289
2024-05-25 03:47:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch3_loss0.22894927859306335.pypots
2024-05-25 03:47:43 [INFO]: Epoch 004 - training loss: 0.2145, validation loss: 0.1932
2024-05-25 03:47:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch4_loss0.19322287440299987.pypots
2024-05-25 03:47:59 [INFO]: Epoch 005 - training loss: 0.1925, validation loss: 0.1733
2024-05-25 03:47:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch5_loss0.17327970564365386.pypots
2024-05-25 03:48:16 [INFO]: Epoch 006 - training loss: 0.1672, validation loss: 0.1735
2024-05-25 03:48:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch6_loss0.1734967589378357.pypots
2024-05-25 03:48:33 [INFO]: Epoch 007 - training loss: 0.1718, validation loss: 0.1660
2024-05-25 03:48:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch7_loss0.16595511883497238.pypots
2024-05-25 03:48:49 [INFO]: Epoch 008 - training loss: 0.1640, validation loss: 0.1520
2024-05-25 03:48:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch8_loss0.1520360827445984.pypots
2024-05-25 03:49:06 [INFO]: Epoch 009 - training loss: 0.1539, validation loss: 0.1615
2024-05-25 03:49:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch9_loss0.16153503954410553.pypots
2024-05-25 03:49:23 [INFO]: Epoch 010 - training loss: 0.1516, validation loss: 0.1608
2024-05-25 03:49:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch10_loss0.16082267165184022.pypots
2024-05-25 03:49:39 [INFO]: Epoch 011 - training loss: 0.1617, validation loss: 0.1513
2024-05-25 03:49:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch11_loss0.15131150633096696.pypots
2024-05-25 03:49:56 [INFO]: Epoch 012 - training loss: 0.1690, validation loss: 0.1492
2024-05-25 03:49:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch12_loss0.14921003133058547.pypots
2024-05-25 03:50:13 [INFO]: Epoch 013 - training loss: 0.1537, validation loss: 0.1437
2024-05-25 03:50:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch13_loss0.14366838634014129.pypots
2024-05-25 03:50:29 [INFO]: Epoch 014 - training loss: 0.1596, validation loss: 0.1459
2024-05-25 03:50:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch14_loss0.14587865620851517.pypots
2024-05-25 03:50:46 [INFO]: Epoch 015 - training loss: 0.1508, validation loss: 0.1419
2024-05-25 03:50:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch15_loss0.14190666154026985.pypots
2024-05-25 03:51:03 [INFO]: Epoch 016 - training loss: 0.1683, validation loss: 0.1409
2024-05-25 03:51:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch16_loss0.1409103311598301.pypots
2024-05-25 03:51:19 [INFO]: Epoch 017 - training loss: 0.1545, validation loss: 0.1477
2024-05-25 03:51:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch17_loss0.14771635681390763.pypots
2024-05-25 03:51:36 [INFO]: Epoch 018 - training loss: 0.1502, validation loss: 0.1395
2024-05-25 03:51:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch18_loss0.13954476341605188.pypots
2024-05-25 03:51:53 [INFO]: Epoch 019 - training loss: 0.1339, validation loss: 0.1395
2024-05-25 03:51:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch19_loss0.1395118147134781.pypots
2024-05-25 03:52:09 [INFO]: Epoch 020 - training loss: 0.1331, validation loss: 0.1353
2024-05-25 03:52:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch20_loss0.1352805145084858.pypots
2024-05-25 03:52:26 [INFO]: Epoch 021 - training loss: 0.1495, validation loss: 0.1359
2024-05-25 03:52:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch21_loss0.135889832675457.pypots
2024-05-25 03:52:43 [INFO]: Epoch 022 - training loss: 0.1446, validation loss: 0.1384
2024-05-25 03:52:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch22_loss0.13837597742676735.pypots
2024-05-25 03:52:59 [INFO]: Epoch 023 - training loss: 0.1462, validation loss: 0.1324
2024-05-25 03:52:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch23_loss0.13237110301852226.pypots
2024-05-25 03:53:16 [INFO]: Epoch 024 - training loss: 0.1349, validation loss: 0.1325
2024-05-25 03:53:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch24_loss0.13253883719444276.pypots
2024-05-25 03:53:33 [INFO]: Epoch 025 - training loss: 0.1395, validation loss: 0.1448
2024-05-25 03:53:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch25_loss0.14484762102365495.pypots
2024-05-25 03:53:49 [INFO]: Epoch 026 - training loss: 0.1578, validation loss: 0.1304
2024-05-25 03:53:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch26_loss0.130418548732996.pypots
2024-05-25 03:54:06 [INFO]: Epoch 027 - training loss: 0.1484, validation loss: 0.1318
2024-05-25 03:54:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch27_loss0.13184826523065568.pypots
2024-05-25 03:54:23 [INFO]: Epoch 028 - training loss: 0.1261, validation loss: 0.1278
2024-05-25 03:54:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch28_loss0.1278477668762207.pypots
2024-05-25 03:54:39 [INFO]: Epoch 029 - training loss: 0.1253, validation loss: 0.1280
2024-05-25 03:54:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch29_loss0.12803872674703598.pypots
2024-05-25 03:54:56 [INFO]: Epoch 030 - training loss: 0.1297, validation loss: 0.1309
2024-05-25 03:54:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch30_loss0.13088977336883545.pypots
2024-05-25 03:55:13 [INFO]: Epoch 031 - training loss: 0.1272, validation loss: 0.1291
2024-05-25 03:55:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch31_loss0.12914069667458533.pypots
2024-05-25 03:55:29 [INFO]: Epoch 032 - training loss: 0.1356, validation loss: 0.1270
2024-05-25 03:55:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch32_loss0.12696916460990906.pypots
2024-05-25 03:55:46 [INFO]: Epoch 033 - training loss: 0.1228, validation loss: 0.1338
2024-05-25 03:55:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch33_loss0.13377992436289787.pypots
2024-05-25 03:56:03 [INFO]: Epoch 034 - training loss: 0.1250, validation loss: 0.1271
2024-05-25 03:56:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch34_loss0.12707151845097542.pypots
2024-05-25 03:56:19 [INFO]: Epoch 035 - training loss: 0.1301, validation loss: 0.1265
2024-05-25 03:56:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch35_loss0.1265319801867008.pypots
2024-05-25 03:56:36 [INFO]: Epoch 036 - training loss: 0.1195, validation loss: 0.1255
2024-05-25 03:56:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch36_loss0.12552206367254257.pypots
2024-05-25 03:56:53 [INFO]: Epoch 037 - training loss: 0.1417, validation loss: 0.1248
2024-05-25 03:56:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch37_loss0.12477274313569069.pypots
2024-05-25 03:57:09 [INFO]: Epoch 038 - training loss: 0.1260, validation loss: 0.1244
2024-05-25 03:57:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch38_loss0.1243677243590355.pypots
2024-05-25 03:57:26 [INFO]: Epoch 039 - training loss: 0.1265, validation loss: 0.1231
2024-05-25 03:57:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch39_loss0.12310876920819283.pypots
2024-05-25 03:57:43 [INFO]: Epoch 040 - training loss: 0.1359, validation loss: 0.1219
2024-05-25 03:57:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch40_loss0.12186920717358589.pypots
2024-05-25 03:57:59 [INFO]: Epoch 041 - training loss: 0.1258, validation loss: 0.1235
2024-05-25 03:57:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch41_loss0.12349051088094712.pypots
2024-05-25 03:58:16 [INFO]: Epoch 042 - training loss: 0.1240, validation loss: 0.1266
2024-05-25 03:58:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch42_loss0.12661839425563812.pypots
2024-05-25 03:58:33 [INFO]: Epoch 043 - training loss: 0.1297, validation loss: 0.1280
2024-05-25 03:58:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch43_loss0.12802696004509925.pypots
2024-05-25 03:58:49 [INFO]: Epoch 044 - training loss: 0.1237, validation loss: 0.1225
2024-05-25 03:58:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch44_loss0.12251243069767952.pypots
2024-05-25 03:59:06 [INFO]: Epoch 045 - training loss: 0.1360, validation loss: 0.1230
2024-05-25 03:59:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch45_loss0.1229789137840271.pypots
2024-05-25 03:59:23 [INFO]: Epoch 046 - training loss: 0.1167, validation loss: 0.1230
2024-05-25 03:59:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch46_loss0.12301980182528496.pypots
2024-05-25 03:59:39 [INFO]: Epoch 047 - training loss: 0.1313, validation loss: 0.1239
2024-05-25 03:59:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch47_loss0.12390212789177894.pypots
2024-05-25 03:59:56 [INFO]: Epoch 048 - training loss: 0.1251, validation loss: 0.1221
2024-05-25 03:59:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch48_loss0.12214306518435478.pypots
2024-05-25 04:00:12 [INFO]: Epoch 049 - training loss: 0.1226, validation loss: 0.1246
2024-05-25 04:00:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch49_loss0.12458952516317368.pypots
2024-05-25 04:00:29 [INFO]: Epoch 050 - training loss: 0.1147, validation loss: 0.1218
2024-05-25 04:00:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch50_loss0.12182031944394112.pypots
2024-05-25 04:00:46 [INFO]: Epoch 051 - training loss: 0.1115, validation loss: 0.1261
2024-05-25 04:00:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch51_loss0.12612169310450555.pypots
2024-05-25 04:01:02 [INFO]: Epoch 052 - training loss: 0.1298, validation loss: 0.1194
2024-05-25 04:01:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch52_loss0.1194311447441578.pypots
2024-05-25 04:01:19 [INFO]: Epoch 053 - training loss: 0.1279, validation loss: 0.1210
2024-05-25 04:01:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch53_loss0.12098842039704323.pypots
2024-05-25 04:01:36 [INFO]: Epoch 054 - training loss: 0.1281, validation loss: 0.1217
2024-05-25 04:01:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch54_loss0.12170641794800759.pypots
2024-05-25 04:01:53 [INFO]: Epoch 055 - training loss: 0.1069, validation loss: 0.1212
2024-05-25 04:01:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch55_loss0.1211718887090683.pypots
2024-05-25 04:02:09 [INFO]: Epoch 056 - training loss: 0.1093, validation loss: 0.1227
2024-05-25 04:02:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch56_loss0.12269876077771187.pypots
2024-05-25 04:02:26 [INFO]: Epoch 057 - training loss: 0.1219, validation loss: 0.1203
2024-05-25 04:02:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch57_loss0.12028192654252053.pypots
2024-05-25 04:02:43 [INFO]: Epoch 058 - training loss: 0.1220, validation loss: 0.1179
2024-05-25 04:02:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch58_loss0.11788412779569626.pypots
2024-05-25 04:02:59 [INFO]: Epoch 059 - training loss: 0.1228, validation loss: 0.1201
2024-05-25 04:02:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch59_loss0.12010547667741775.pypots
2024-05-25 04:03:16 [INFO]: Epoch 060 - training loss: 0.1088, validation loss: 0.1172
2024-05-25 04:03:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch60_loss0.11721189692616463.pypots
2024-05-25 04:03:33 [INFO]: Epoch 061 - training loss: 0.1212, validation loss: 0.1201
2024-05-25 04:03:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch61_loss0.12014558836817742.pypots
2024-05-25 04:03:49 [INFO]: Epoch 062 - training loss: 0.1153, validation loss: 0.1169
2024-05-25 04:03:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch62_loss0.11694177240133286.pypots
2024-05-25 04:04:06 [INFO]: Epoch 063 - training loss: 0.0981, validation loss: 0.1220
2024-05-25 04:04:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch63_loss0.12198013216257095.pypots
2024-05-25 04:04:23 [INFO]: Epoch 064 - training loss: 0.1155, validation loss: 0.1160
2024-05-25 04:04:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch64_loss0.11597630083560943.pypots
2024-05-25 04:04:39 [INFO]: Epoch 065 - training loss: 0.1043, validation loss: 0.1186
2024-05-25 04:04:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch65_loss0.11864780932664871.pypots
2024-05-25 04:04:56 [INFO]: Epoch 066 - training loss: 0.1153, validation loss: 0.1203
2024-05-25 04:04:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch66_loss0.12031920105218888.pypots
2024-05-25 04:05:13 [INFO]: Epoch 067 - training loss: 0.1266, validation loss: 0.1237
2024-05-25 04:05:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch67_loss0.12371383011341094.pypots
2024-05-25 04:05:29 [INFO]: Epoch 068 - training loss: 0.1073, validation loss: 0.1147
2024-05-25 04:05:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch68_loss0.1147200845181942.pypots
2024-05-25 04:05:46 [INFO]: Epoch 069 - training loss: 0.1177, validation loss: 0.1160
2024-05-25 04:05:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch69_loss0.11598783656954766.pypots
2024-05-25 04:06:03 [INFO]: Epoch 070 - training loss: 0.1137, validation loss: 0.1128
2024-05-25 04:06:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch70_loss0.11278588771820068.pypots
2024-05-25 04:06:19 [INFO]: Epoch 071 - training loss: 0.1112, validation loss: 0.1258
2024-05-25 04:06:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch71_loss0.12584279775619506.pypots
2024-05-25 04:06:36 [INFO]: Epoch 072 - training loss: 0.1172, validation loss: 0.1166
2024-05-25 04:06:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch72_loss0.11658168435096741.pypots
2024-05-25 04:06:53 [INFO]: Epoch 073 - training loss: 0.1140, validation loss: 0.1179
2024-05-25 04:06:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch73_loss0.1178529217839241.pypots
2024-05-25 04:07:09 [INFO]: Epoch 074 - training loss: 0.1129, validation loss: 0.1160
2024-05-25 04:07:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch74_loss0.11601195186376571.pypots
2024-05-25 04:07:26 [INFO]: Epoch 075 - training loss: 0.1295, validation loss: 0.1162
2024-05-25 04:07:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch75_loss0.11618288159370423.pypots
2024-05-25 04:07:43 [INFO]: Epoch 076 - training loss: 0.1170, validation loss: 0.1150
2024-05-25 04:07:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch76_loss0.11503806486725807.pypots
2024-05-25 04:07:59 [INFO]: Epoch 077 - training loss: 0.1068, validation loss: 0.1136
2024-05-25 04:07:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch77_loss0.11358766630291939.pypots
2024-05-25 04:08:16 [INFO]: Epoch 078 - training loss: 0.1141, validation loss: 0.1145
2024-05-25 04:08:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch78_loss0.11451461017131806.pypots
2024-05-25 04:08:33 [INFO]: Epoch 079 - training loss: 0.1184, validation loss: 0.1116
2024-05-25 04:08:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch79_loss0.1115910455584526.pypots
2024-05-25 04:08:49 [INFO]: Epoch 080 - training loss: 0.1047, validation loss: 0.1122
2024-05-25 04:08:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch80_loss0.11215346232056618.pypots
2024-05-25 04:09:06 [INFO]: Epoch 081 - training loss: 0.1131, validation loss: 0.1142
2024-05-25 04:09:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch81_loss0.11419200524687767.pypots
2024-05-25 04:09:23 [INFO]: Epoch 082 - training loss: 0.1134, validation loss: 0.1122
2024-05-25 04:09:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch82_loss0.1121655635535717.pypots
2024-05-25 04:09:39 [INFO]: Epoch 083 - training loss: 0.1146, validation loss: 0.1123
2024-05-25 04:09:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch83_loss0.11233135312795639.pypots
2024-05-25 04:09:56 [INFO]: Epoch 084 - training loss: 0.1034, validation loss: 0.1117
2024-05-25 04:09:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch84_loss0.11169545128941535.pypots
2024-05-25 04:10:13 [INFO]: Epoch 085 - training loss: 0.1102, validation loss: 0.1131
2024-05-25 04:10:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch85_loss0.11311261951923371.pypots
2024-05-25 04:10:29 [INFO]: Epoch 086 - training loss: 0.1037, validation loss: 0.1123
2024-05-25 04:10:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch86_loss0.11233615726232529.pypots
2024-05-25 04:10:46 [INFO]: Epoch 087 - training loss: 0.1176, validation loss: 0.1097
2024-05-25 04:10:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch87_loss0.10968203693628312.pypots
2024-05-25 04:11:03 [INFO]: Epoch 088 - training loss: 0.1118, validation loss: 0.1082
2024-05-25 04:11:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch88_loss0.10816823616623879.pypots
2024-05-25 04:11:19 [INFO]: Epoch 089 - training loss: 0.1100, validation loss: 0.1101
2024-05-25 04:11:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch89_loss0.110120789706707.pypots
2024-05-25 04:11:36 [INFO]: Epoch 090 - training loss: 0.1194, validation loss: 0.1091
2024-05-25 04:11:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch90_loss0.10914612039923668.pypots
2024-05-25 04:11:53 [INFO]: Epoch 091 - training loss: 0.1104, validation loss: 0.1157
2024-05-25 04:11:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch91_loss0.11566095873713493.pypots
2024-05-25 04:12:09 [INFO]: Epoch 092 - training loss: 0.0992, validation loss: 0.1082
2024-05-25 04:12:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch92_loss0.10820791199803352.pypots
2024-05-25 04:12:26 [INFO]: Epoch 093 - training loss: 0.0975, validation loss: 0.1115
2024-05-25 04:12:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch93_loss0.11145373359322548.pypots
2024-05-25 04:12:43 [INFO]: Epoch 094 - training loss: 0.1175, validation loss: 0.1104
2024-05-25 04:12:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch94_loss0.11036211177706719.pypots
2024-05-25 04:12:59 [INFO]: Epoch 095 - training loss: 0.1003, validation loss: 0.1081
2024-05-25 04:12:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch95_loss0.10811995565891266.pypots
2024-05-25 04:13:16 [INFO]: Epoch 096 - training loss: 0.1099, validation loss: 0.1075
2024-05-25 04:13:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch96_loss0.10746584981679916.pypots
2024-05-25 04:13:33 [INFO]: Epoch 097 - training loss: 0.1340, validation loss: 0.1088
2024-05-25 04:13:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch97_loss0.10876263603568077.pypots
2024-05-25 04:13:49 [INFO]: Epoch 098 - training loss: 0.1056, validation loss: 0.1068
2024-05-25 04:13:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch98_loss0.10677719637751579.pypots
2024-05-25 04:14:06 [INFO]: Epoch 099 - training loss: 0.1075, validation loss: 0.1091
2024-05-25 04:14:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch99_loss0.10913168117403985.pypots
2024-05-25 04:14:23 [INFO]: Epoch 100 - training loss: 0.1145, validation loss: 0.1068
2024-05-25 04:14:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch100_loss0.10682813301682473.pypots
2024-05-25 04:14:39 [INFO]: Epoch 101 - training loss: 0.1012, validation loss: 0.1080
2024-05-25 04:14:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch101_loss0.10801131427288055.pypots
2024-05-25 04:14:56 [INFO]: Epoch 102 - training loss: 0.1156, validation loss: 0.1059
2024-05-25 04:14:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch102_loss0.10587997660040856.pypots
2024-05-25 04:15:13 [INFO]: Epoch 103 - training loss: 0.1171, validation loss: 0.1051
2024-05-25 04:15:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch103_loss0.105098644644022.pypots
2024-05-25 04:15:29 [INFO]: Epoch 104 - training loss: 0.0963, validation loss: 0.1110
2024-05-25 04:15:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch104_loss0.11104730144143105.pypots
2024-05-25 04:15:46 [INFO]: Epoch 105 - training loss: 0.1153, validation loss: 0.1067
2024-05-25 04:15:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch105_loss0.10666439533233643.pypots
2024-05-25 04:16:03 [INFO]: Epoch 106 - training loss: 0.1179, validation loss: 0.1078
2024-05-25 04:16:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch106_loss0.10782577469944954.pypots
2024-05-25 04:16:19 [INFO]: Epoch 107 - training loss: 0.1052, validation loss: 0.1073
2024-05-25 04:16:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch107_loss0.10730867981910705.pypots
2024-05-25 04:16:36 [INFO]: Epoch 108 - training loss: 0.1093, validation loss: 0.1086
2024-05-25 04:16:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch108_loss0.10860898941755295.pypots
2024-05-25 04:16:53 [INFO]: Epoch 109 - training loss: 0.1083, validation loss: 0.1068
2024-05-25 04:16:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch109_loss0.10681340396404267.pypots
2024-05-25 04:17:09 [INFO]: Epoch 110 - training loss: 0.1115, validation loss: 0.1058
2024-05-25 04:17:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch110_loss0.10579263567924499.pypots
2024-05-25 04:17:26 [INFO]: Epoch 111 - training loss: 0.1059, validation loss: 0.1064
2024-05-25 04:17:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch111_loss0.10641154795885086.pypots
2024-05-25 04:17:43 [INFO]: Epoch 112 - training loss: 0.0987, validation loss: 0.1049
2024-05-25 04:17:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch112_loss0.104876047372818.pypots
2024-05-25 04:17:59 [INFO]: Epoch 113 - training loss: 0.1101, validation loss: 0.1058
2024-05-25 04:17:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch113_loss0.10580890104174615.pypots
2024-05-25 04:18:16 [INFO]: Epoch 114 - training loss: 0.1018, validation loss: 0.1138
2024-05-25 04:18:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch114_loss0.11381248459219932.pypots
2024-05-25 04:18:33 [INFO]: Epoch 115 - training loss: 0.1081, validation loss: 0.1076
2024-05-25 04:18:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch115_loss0.1076237328350544.pypots
2024-05-25 04:18:49 [INFO]: Epoch 116 - training loss: 0.1028, validation loss: 0.1053
2024-05-25 04:18:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch116_loss0.10528784170746804.pypots
2024-05-25 04:19:06 [INFO]: Epoch 117 - training loss: 0.1078, validation loss: 0.1024
2024-05-25 04:19:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch117_loss0.10242000594735146.pypots
2024-05-25 04:19:23 [INFO]: Epoch 118 - training loss: 0.1118, validation loss: 0.1037
2024-05-25 04:19:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch118_loss0.10367098674178124.pypots
2024-05-25 04:19:39 [INFO]: Epoch 119 - training loss: 0.1097, validation loss: 0.1053
2024-05-25 04:19:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch119_loss0.10534480884671212.pypots
2024-05-25 04:19:56 [INFO]: Epoch 120 - training loss: 0.1021, validation loss: 0.1027
2024-05-25 04:19:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch120_loss0.10272292867302894.pypots
2024-05-25 04:20:13 [INFO]: Epoch 121 - training loss: 0.1042, validation loss: 0.1046
2024-05-25 04:20:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch121_loss0.10459027364850045.pypots
2024-05-25 04:20:29 [INFO]: Epoch 122 - training loss: 0.0964, validation loss: 0.1033
2024-05-25 04:20:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch122_loss0.10327887684106826.pypots
2024-05-25 04:20:46 [INFO]: Epoch 123 - training loss: 0.1033, validation loss: 0.1055
2024-05-25 04:20:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch123_loss0.1055486962199211.pypots
2024-05-25 04:21:03 [INFO]: Epoch 124 - training loss: 0.1106, validation loss: 0.1044
2024-05-25 04:21:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch124_loss0.10437794253230095.pypots
2024-05-25 04:21:19 [INFO]: Epoch 125 - training loss: 0.1210, validation loss: 0.1063
2024-05-25 04:21:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch125_loss0.10627551004290581.pypots
2024-05-25 04:21:36 [INFO]: Epoch 126 - training loss: 0.1113, validation loss: 0.1020
2024-05-25 04:21:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch126_loss0.10200862139463425.pypots
2024-05-25 04:21:53 [INFO]: Epoch 127 - training loss: 0.1063, validation loss: 0.1062
2024-05-25 04:21:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch127_loss0.10616185143589973.pypots
2024-05-25 04:22:09 [INFO]: Epoch 128 - training loss: 0.1095, validation loss: 0.1062
2024-05-25 04:22:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch128_loss0.10621988177299499.pypots
2024-05-25 04:22:26 [INFO]: Epoch 129 - training loss: 0.0967, validation loss: 0.1030
2024-05-25 04:22:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch129_loss0.10298734903335571.pypots
2024-05-25 04:22:43 [INFO]: Epoch 130 - training loss: 0.1036, validation loss: 0.1024
2024-05-25 04:22:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch130_loss0.10235750004649162.pypots
2024-05-25 04:22:59 [INFO]: Epoch 131 - training loss: 0.1032, validation loss: 0.1036
2024-05-25 04:22:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch131_loss0.10355854332447052.pypots
2024-05-25 04:23:16 [INFO]: Epoch 132 - training loss: 0.1119, validation loss: 0.1031
2024-05-25 04:23:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch132_loss0.10306203439831733.pypots
2024-05-25 04:23:33 [INFO]: Epoch 133 - training loss: 0.1047, validation loss: 0.1036
2024-05-25 04:23:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch133_loss0.103598190844059.pypots
2024-05-25 04:23:49 [INFO]: Epoch 134 - training loss: 0.1092, validation loss: 0.1016
2024-05-25 04:23:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch134_loss0.10161705017089843.pypots
2024-05-25 04:24:06 [INFO]: Epoch 135 - training loss: 0.0873, validation loss: 0.1044
2024-05-25 04:24:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch135_loss0.10443013012409211.pypots
2024-05-25 04:24:23 [INFO]: Epoch 136 - training loss: 0.0995, validation loss: 0.1021
2024-05-25 04:24:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch136_loss0.10210787579417228.pypots
2024-05-25 04:24:39 [INFO]: Epoch 137 - training loss: 0.0956, validation loss: 0.1038
2024-05-25 04:24:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch137_loss0.10384947210550308.pypots
2024-05-25 04:24:56 [INFO]: Epoch 138 - training loss: 0.1072, validation loss: 0.1079
2024-05-25 04:24:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch138_loss0.10789792835712433.pypots
2024-05-25 04:25:13 [INFO]: Epoch 139 - training loss: 0.0936, validation loss: 0.1030
2024-05-25 04:25:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch139_loss0.10299012362957001.pypots
2024-05-25 04:25:29 [INFO]: Epoch 140 - training loss: 0.1037, validation loss: 0.1025
2024-05-25 04:25:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch140_loss0.10248644277453423.pypots
2024-05-25 04:25:46 [INFO]: Epoch 141 - training loss: 0.1123, validation loss: 0.1069
2024-05-25 04:25:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch141_loss0.10693755745887756.pypots
2024-05-25 04:26:03 [INFO]: Epoch 142 - training loss: 0.1096, validation loss: 0.1020
2024-05-25 04:26:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch142_loss0.10197558179497719.pypots
2024-05-25 04:26:19 [INFO]: Epoch 143 - training loss: 0.0934, validation loss: 0.1010
2024-05-25 04:26:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch143_loss0.1009738564491272.pypots
2024-05-25 04:26:36 [INFO]: Epoch 144 - training loss: 0.1046, validation loss: 0.1009
2024-05-25 04:26:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch144_loss0.10087479203939438.pypots
2024-05-25 04:26:53 [INFO]: Epoch 145 - training loss: 0.1098, validation loss: 0.1061
2024-05-25 04:26:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch145_loss0.10606686398386955.pypots
2024-05-25 04:27:09 [INFO]: Epoch 146 - training loss: 0.0922, validation loss: 0.1007
2024-05-25 04:27:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch146_loss0.10072041526436806.pypots
2024-05-25 04:27:26 [INFO]: Epoch 147 - training loss: 0.1075, validation loss: 0.1024
2024-05-25 04:27:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch147_loss0.10241876468062401.pypots
2024-05-25 04:27:43 [INFO]: Epoch 148 - training loss: 0.0989, validation loss: 0.1035
2024-05-25 04:27:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch148_loss0.10354308485984802.pypots
2024-05-25 04:27:59 [INFO]: Epoch 149 - training loss: 0.0928, validation loss: 0.1003
2024-05-25 04:27:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch149_loss0.10030390843749046.pypots
2024-05-25 04:28:16 [INFO]: Epoch 150 - training loss: 0.1001, validation loss: 0.1016
2024-05-25 04:28:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch150_loss0.10162266716361046.pypots
2024-05-25 04:28:33 [INFO]: Epoch 151 - training loss: 0.1041, validation loss: 0.1021
2024-05-25 04:28:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch151_loss0.10212924629449845.pypots
2024-05-25 04:28:49 [INFO]: Epoch 152 - training loss: 0.1005, validation loss: 0.1038
2024-05-25 04:28:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch152_loss0.10377886891365051.pypots
2024-05-25 04:29:06 [INFO]: Epoch 153 - training loss: 0.1061, validation loss: 0.1022
2024-05-25 04:29:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch153_loss0.10223735943436622.pypots
2024-05-25 04:29:23 [INFO]: Epoch 154 - training loss: 0.1061, validation loss: 0.1039
2024-05-25 04:29:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch154_loss0.10385322496294976.pypots
2024-05-25 04:29:39 [INFO]: Epoch 155 - training loss: 0.0974, validation loss: 0.0995
2024-05-25 04:29:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch155_loss0.09947261810302735.pypots
2024-05-25 04:29:56 [INFO]: Epoch 156 - training loss: 0.1086, validation loss: 0.1032
2024-05-25 04:29:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch156_loss0.10322271734476089.pypots
2024-05-25 04:30:13 [INFO]: Epoch 157 - training loss: 0.0936, validation loss: 0.1018
2024-05-25 04:30:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch157_loss0.10178460329771041.pypots
2024-05-25 04:30:29 [INFO]: Epoch 158 - training loss: 0.0872, validation loss: 0.1011
2024-05-25 04:30:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch158_loss0.10105332061648369.pypots
2024-05-25 04:30:46 [INFO]: Epoch 159 - training loss: 0.0958, validation loss: 0.1021
2024-05-25 04:30:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch159_loss0.10206466093659401.pypots
2024-05-25 04:31:03 [INFO]: Epoch 160 - training loss: 0.1086, validation loss: 0.1048
2024-05-25 04:31:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch160_loss0.10481553599238395.pypots
2024-05-25 04:31:19 [INFO]: Epoch 161 - training loss: 0.1028, validation loss: 0.1014
2024-05-25 04:31:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch161_loss0.10136161148548126.pypots
2024-05-25 04:31:36 [INFO]: Epoch 162 - training loss: 0.1016, validation loss: 0.1023
2024-05-25 04:31:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch162_loss0.1022779405117035.pypots
2024-05-25 04:31:53 [INFO]: Epoch 163 - training loss: 0.1046, validation loss: 0.1020
2024-05-25 04:31:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch163_loss0.10202530845999717.pypots
2024-05-25 04:32:09 [INFO]: Epoch 164 - training loss: 0.0954, validation loss: 0.1000
2024-05-25 04:32:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch164_loss0.09998072236776352.pypots
2024-05-25 04:32:26 [INFO]: Epoch 165 - training loss: 0.1089, validation loss: 0.0992
2024-05-25 04:32:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch165_loss0.09920455440878868.pypots
2024-05-25 04:32:43 [INFO]: Epoch 166 - training loss: 0.1073, validation loss: 0.1004
2024-05-25 04:32:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch166_loss0.10035385414958001.pypots
2024-05-25 04:32:59 [INFO]: Epoch 167 - training loss: 0.1083, validation loss: 0.1006
2024-05-25 04:32:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch167_loss0.10057795196771621.pypots
2024-05-25 04:33:16 [INFO]: Epoch 168 - training loss: 0.1002, validation loss: 0.1017
2024-05-25 04:33:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch168_loss0.10168537721037865.pypots
2024-05-25 04:33:33 [INFO]: Epoch 169 - training loss: 0.0975, validation loss: 0.1027
2024-05-25 04:33:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch169_loss0.10273132547736168.pypots
2024-05-25 04:33:49 [INFO]: Epoch 170 - training loss: 0.1000, validation loss: 0.0989
2024-05-25 04:33:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch170_loss0.09889027178287506.pypots
2024-05-25 04:34:06 [INFO]: Epoch 171 - training loss: 0.1038, validation loss: 0.1026
2024-05-25 04:34:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch171_loss0.10264207124710083.pypots
2024-05-25 04:34:23 [INFO]: Epoch 172 - training loss: 0.1104, validation loss: 0.1013
2024-05-25 04:34:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch172_loss0.10129068717360497.pypots
2024-05-25 04:34:39 [INFO]: Epoch 173 - training loss: 0.1008, validation loss: 0.1060
2024-05-25 04:34:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch173_loss0.10603351220488548.pypots
2024-05-25 04:34:56 [INFO]: Epoch 174 - training loss: 0.1059, validation loss: 0.1000
2024-05-25 04:34:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch174_loss0.10002227276563644.pypots
2024-05-25 04:35:13 [INFO]: Epoch 175 - training loss: 0.0991, validation loss: 0.0999
2024-05-25 04:35:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch175_loss0.09991652816534043.pypots
2024-05-25 04:35:29 [INFO]: Epoch 176 - training loss: 0.1039, validation loss: 0.1012
2024-05-25 04:35:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch176_loss0.10117918029427528.pypots
2024-05-25 04:35:46 [INFO]: Epoch 177 - training loss: 0.0999, validation loss: 0.1012
2024-05-25 04:35:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch177_loss0.10120112299919129.pypots
2024-05-25 04:36:03 [INFO]: Epoch 178 - training loss: 0.1057, validation loss: 0.1005
2024-05-25 04:36:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch178_loss0.10051551461219788.pypots
2024-05-25 04:36:19 [INFO]: Epoch 179 - training loss: 0.0977, validation loss: 0.1013
2024-05-25 04:36:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch179_loss0.10132647156715394.pypots
2024-05-25 04:36:36 [INFO]: Epoch 180 - training loss: 0.1077, validation loss: 0.1002
2024-05-25 04:36:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI_epoch180_loss0.10020207688212394.pypots
2024-05-25 04:36:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:36:36 [INFO]: Finished training. The best model is from epoch#170.
2024-05-25 04:36:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240525_T034636/CSDI.pypots
2024-05-25 04:38:56 [INFO]: CSDI on Air-Quality: MAE=0.0972, MSE=0.2217
2024-05-25 04:38:56 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/CSDI_air_quality/imputation.pkl
2024-05-25 04:38:56 [INFO]: Using the given device: cuda:0
2024-05-25 04:38:56 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/GPVAE_air_quality/20240525_T043856
2024-05-25 04:38:56 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/GPVAE_air_quality/20240525_T043856/tensorboard
2024-05-25 04:38:56 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 04:38:57 [INFO]: Epoch 001 - training loss: 63433.0464, validation loss: 0.6174
2024-05-25 04:38:57 [INFO]: Epoch 002 - training loss: 41950.6282, validation loss: 0.5630
2024-05-25 04:38:57 [INFO]: Epoch 003 - training loss: 41628.2836, validation loss: 0.5184
2024-05-25 04:38:58 [INFO]: Epoch 004 - training loss: 41510.7733, validation loss: 0.4733
2024-05-25 04:38:58 [INFO]: Epoch 005 - training loss: 41452.0496, validation loss: 0.4501
2024-05-25 04:38:59 [INFO]: Epoch 006 - training loss: 41366.4844, validation loss: 0.3912
2024-05-25 04:38:59 [INFO]: Epoch 007 - training loss: 41311.0123, validation loss: 0.3646
2024-05-25 04:38:59 [INFO]: Epoch 008 - training loss: 41280.8927, validation loss: 0.3441
2024-05-25 04:39:00 [INFO]: Epoch 009 - training loss: 41264.2248, validation loss: 0.3341
2024-05-25 04:39:00 [INFO]: Epoch 010 - training loss: 41228.7005, validation loss: 0.3147
2024-05-25 04:39:00 [INFO]: Epoch 011 - training loss: 41201.6102, validation loss: 0.3135
2024-05-25 04:39:01 [INFO]: Epoch 012 - training loss: 41212.5765, validation loss: 0.3217
2024-05-25 04:39:01 [INFO]: Epoch 013 - training loss: 41187.5516, validation loss: 0.3127
2024-05-25 04:39:01 [INFO]: Epoch 014 - training loss: 41197.1447, validation loss: 0.3160
2024-05-25 04:39:02 [INFO]: Epoch 015 - training loss: 41161.5181, validation loss: 0.2923
2024-05-25 04:39:02 [INFO]: Epoch 016 - training loss: 41155.1641, validation loss: 0.2946
2024-05-25 04:39:02 [INFO]: Epoch 017 - training loss: 41144.5136, validation loss: 0.2938
2024-05-25 04:39:03 [INFO]: Epoch 018 - training loss: 41139.8309, validation loss: 0.2883
2024-05-25 04:39:03 [INFO]: Epoch 019 - training loss: 41146.2338, validation loss: 0.3192
2024-05-25 04:39:04 [INFO]: Epoch 020 - training loss: 41132.9369, validation loss: 0.2716
2024-05-25 04:39:04 [INFO]: Epoch 021 - training loss: 41102.0953, validation loss: 0.2674
2024-05-25 04:39:04 [INFO]: Epoch 022 - training loss: 41090.9935, validation loss: 0.2658
2024-05-25 04:39:05 [INFO]: Epoch 023 - training loss: 41087.0139, validation loss: 0.2667
2024-05-25 04:39:05 [INFO]: Epoch 024 - training loss: 41082.1535, validation loss: 0.2590
2024-05-25 04:39:05 [INFO]: Epoch 025 - training loss: 41073.1432, validation loss: 0.2549
2024-05-25 04:39:06 [INFO]: Epoch 026 - training loss: 41075.6311, validation loss: 0.2634
2024-05-25 04:39:06 [INFO]: Epoch 027 - training loss: 41071.7376, validation loss: 0.2698
2024-05-25 04:39:06 [INFO]: Epoch 028 - training loss: 41115.2083, validation loss: 0.2814
2024-05-25 04:39:07 [INFO]: Epoch 029 - training loss: 41103.8332, validation loss: 0.2846
2024-05-25 04:39:07 [INFO]: Epoch 030 - training loss: 41102.9575, validation loss: 0.2849
2024-05-25 04:39:08 [INFO]: Epoch 031 - training loss: 41076.1152, validation loss: 0.2654
2024-05-25 04:39:08 [INFO]: Epoch 032 - training loss: 41078.7610, validation loss: 0.2476
2024-05-25 04:39:08 [INFO]: Epoch 033 - training loss: 41053.4962, validation loss: 0.2466
2024-05-25 04:39:09 [INFO]: Epoch 034 - training loss: 41055.4240, validation loss: 0.2415
2024-05-25 04:39:09 [INFO]: Epoch 035 - training loss: 41055.3416, validation loss: 0.2424
2024-05-25 04:39:09 [INFO]: Epoch 036 - training loss: 41046.7701, validation loss: 0.2475
2024-05-25 04:39:10 [INFO]: Epoch 037 - training loss: 41047.9226, validation loss: 0.2448
2024-05-25 04:39:10 [INFO]: Epoch 038 - training loss: 41047.0282, validation loss: 0.2447
2024-05-25 04:39:10 [INFO]: Epoch 039 - training loss: 41054.4381, validation loss: 0.2434
2024-05-25 04:39:11 [INFO]: Epoch 040 - training loss: 41042.7169, validation loss: 0.2451
2024-05-25 04:39:11 [INFO]: Epoch 041 - training loss: 41033.0679, validation loss: 0.2437
2024-05-25 04:39:11 [INFO]: Epoch 042 - training loss: 41045.3018, validation loss: 0.2404
2024-05-25 04:39:12 [INFO]: Epoch 043 - training loss: 41024.7843, validation loss: 0.2350
2024-05-25 04:39:12 [INFO]: Epoch 044 - training loss: 41026.2569, validation loss: 0.2371
2024-05-25 04:39:12 [INFO]: Epoch 045 - training loss: 41033.9646, validation loss: 0.2557
2024-05-25 04:39:13 [INFO]: Epoch 046 - training loss: 41094.8822, validation loss: 0.2514
2024-05-25 04:39:13 [INFO]: Epoch 047 - training loss: 41037.2190, validation loss: 0.2505
2024-05-25 04:39:13 [INFO]: Epoch 048 - training loss: 41056.2739, validation loss: 0.2471
2024-05-25 04:39:14 [INFO]: Epoch 049 - training loss: 41076.7632, validation loss: 0.2687
2024-05-25 04:39:14 [INFO]: Epoch 050 - training loss: 41085.7050, validation loss: 0.2372
2024-05-25 04:39:15 [INFO]: Epoch 051 - training loss: 41040.7865, validation loss: 0.2313
2024-05-25 04:39:15 [INFO]: Epoch 052 - training loss: 41023.4864, validation loss: 0.2310
2024-05-25 04:39:15 [INFO]: Epoch 053 - training loss: 41021.2716, validation loss: 0.2399
2024-05-25 04:39:16 [INFO]: Epoch 054 - training loss: 41028.9026, validation loss: 0.2279
2024-05-25 04:39:16 [INFO]: Epoch 055 - training loss: 41018.7526, validation loss: 0.2252
2024-05-25 04:39:16 [INFO]: Epoch 056 - training loss: 41013.6576, validation loss: 0.2232
2024-05-25 04:39:17 [INFO]: Epoch 057 - training loss: 41011.8040, validation loss: 0.2293
2024-05-25 04:39:17 [INFO]: Epoch 058 - training loss: 41010.1959, validation loss: 0.2467
2024-05-25 04:39:18 [INFO]: Epoch 059 - training loss: 41008.8001, validation loss: 0.2287
2024-05-25 04:39:18 [INFO]: Epoch 060 - training loss: 41003.2429, validation loss: 0.2282
2024-05-25 04:39:18 [INFO]: Epoch 061 - training loss: 41006.1808, validation loss: 0.2300
2024-05-25 04:39:19 [INFO]: Epoch 062 - training loss: 41005.9845, validation loss: 0.2244
2024-05-25 04:39:19 [INFO]: Epoch 063 - training loss: 41001.4395, validation loss: 0.2249
2024-05-25 04:39:19 [INFO]: Epoch 064 - training loss: 40999.0448, validation loss: 0.2181
2024-05-25 04:39:20 [INFO]: Epoch 065 - training loss: 40992.8733, validation loss: 0.2181
2024-05-25 04:39:20 [INFO]: Epoch 066 - training loss: 40991.3637, validation loss: 0.2142
2024-05-25 04:39:20 [INFO]: Epoch 067 - training loss: 40988.3999, validation loss: 0.2180
2024-05-25 04:39:21 [INFO]: Epoch 068 - training loss: 40998.6722, validation loss: 0.2427
2024-05-25 04:39:21 [INFO]: Epoch 069 - training loss: 41126.8245, validation loss: 0.2850
2024-05-25 04:39:22 [INFO]: Epoch 070 - training loss: 41107.5872, validation loss: 0.2394
2024-05-25 04:39:22 [INFO]: Epoch 071 - training loss: 41041.6555, validation loss: 0.2344
2024-05-25 04:39:22 [INFO]: Epoch 072 - training loss: 41011.5736, validation loss: 0.2244
2024-05-25 04:39:23 [INFO]: Epoch 073 - training loss: 41001.2199, validation loss: 0.2232
2024-05-25 04:39:23 [INFO]: Epoch 074 - training loss: 40997.0433, validation loss: 0.2290
2024-05-25 04:39:23 [INFO]: Epoch 075 - training loss: 41011.6312, validation loss: 0.2360
2024-05-25 04:39:24 [INFO]: Epoch 076 - training loss: 41026.8281, validation loss: 0.2162
2024-05-25 04:39:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:39:24 [INFO]: Finished training. The best model is from epoch#66.
2024-05-25 04:39:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/GPVAE_air_quality/20240525_T043856/GPVAE.pypots
2024-05-25 04:39:24 [INFO]: GP-VAE on Air-Quality: MAE=0.2739, MSE=0.3254
2024-05-25 04:39:24 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/GPVAE_air_quality/imputation.pkl
2024-05-25 04:39:24 [INFO]: Using the given device: cuda:0
2024-05-25 04:39:24 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/USGAN_air_quality/20240525_T043924
2024-05-25 04:39:24 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/USGAN_air_quality/20240525_T043924/tensorboard
2024-05-25 04:39:24 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 04:39:29 [INFO]: Epoch 001 - generator training loss: 0.5212, discriminator training loss: 0.3800, validation loss: 0.5054
2024-05-25 04:39:34 [INFO]: Epoch 002 - generator training loss: 0.1505, discriminator training loss: 0.2424, validation loss: 0.3804
2024-05-25 04:39:38 [INFO]: Epoch 003 - generator training loss: 0.0953, discriminator training loss: 0.2380, validation loss: 0.3120
2024-05-25 04:39:42 [INFO]: Epoch 004 - generator training loss: 0.0608, discriminator training loss: 0.2372, validation loss: 0.2719
2024-05-25 04:39:46 [INFO]: Epoch 005 - generator training loss: 0.0302, discriminator training loss: 0.2362, validation loss: 0.2461
2024-05-25 04:39:51 [INFO]: Epoch 006 - generator training loss: 0.0134, discriminator training loss: 0.2355, validation loss: 0.2286
2024-05-25 04:39:55 [INFO]: Epoch 007 - generator training loss: -0.0008, discriminator training loss: 0.2343, validation loss: 0.2149
2024-05-25 04:39:59 [INFO]: Epoch 008 - generator training loss: -0.0090, discriminator training loss: 0.2328, validation loss: 0.2042
2024-05-25 04:40:03 [INFO]: Epoch 009 - generator training loss: -0.0185, discriminator training loss: 0.2320, validation loss: 0.1971
2024-05-25 04:40:08 [INFO]: Epoch 010 - generator training loss: -0.0236, discriminator training loss: 0.2305, validation loss: 0.1898
2024-05-25 04:40:12 [INFO]: Epoch 011 - generator training loss: -0.0294, discriminator training loss: 0.2290, validation loss: 0.1838
2024-05-25 04:40:16 [INFO]: Epoch 012 - generator training loss: -0.0345, discriminator training loss: 0.2276, validation loss: 0.1788
2024-05-25 04:40:21 [INFO]: Epoch 013 - generator training loss: -0.0379, discriminator training loss: 0.2261, validation loss: 0.1741
2024-05-25 04:40:25 [INFO]: Epoch 014 - generator training loss: -0.0404, discriminator training loss: 0.2245, validation loss: 0.1705
2024-05-25 04:40:29 [INFO]: Epoch 015 - generator training loss: -0.0423, discriminator training loss: 0.2230, validation loss: 0.1672
2024-05-25 04:40:34 [INFO]: Epoch 016 - generator training loss: -0.0445, discriminator training loss: 0.2214, validation loss: 0.1631
2024-05-25 04:40:38 [INFO]: Epoch 017 - generator training loss: -0.0469, discriminator training loss: 0.2201, validation loss: 0.1607
2024-05-25 04:40:42 [INFO]: Epoch 018 - generator training loss: -0.0467, discriminator training loss: 0.2185, validation loss: 0.1577
2024-05-25 04:40:46 [INFO]: Epoch 019 - generator training loss: -0.0503, discriminator training loss: 0.2170, validation loss: 0.1552
2024-05-25 04:40:51 [INFO]: Epoch 020 - generator training loss: -0.0522, discriminator training loss: 0.2158, validation loss: 0.1529
2024-05-25 04:40:55 [INFO]: Epoch 021 - generator training loss: -0.0519, discriminator training loss: 0.2139, validation loss: 0.1508
2024-05-25 04:40:59 [INFO]: Epoch 022 - generator training loss: -0.0535, discriminator training loss: 0.2124, validation loss: 0.1496
2024-05-25 04:41:04 [INFO]: Epoch 023 - generator training loss: -0.0535, discriminator training loss: 0.2105, validation loss: 0.1471
2024-05-25 04:41:08 [INFO]: Epoch 024 - generator training loss: -0.0540, discriminator training loss: 0.2085, validation loss: 0.1449
2024-05-25 04:41:12 [INFO]: Epoch 025 - generator training loss: -0.0552, discriminator training loss: 0.2069, validation loss: 0.1423
2024-05-25 04:41:16 [INFO]: Epoch 026 - generator training loss: -0.0559, discriminator training loss: 0.2051, validation loss: 0.1400
2024-05-25 04:41:21 [INFO]: Epoch 027 - generator training loss: -0.0569, discriminator training loss: 0.2032, validation loss: 0.1395
2024-05-25 04:41:25 [INFO]: Epoch 028 - generator training loss: -0.0572, discriminator training loss: 0.2017, validation loss: 0.1376
2024-05-25 04:41:29 [INFO]: Epoch 029 - generator training loss: -0.0561, discriminator training loss: 0.1996, validation loss: 0.1361
2024-05-25 04:41:33 [INFO]: Epoch 030 - generator training loss: -0.0568, discriminator training loss: 0.1979, validation loss: 0.1343
2024-05-25 04:41:38 [INFO]: Epoch 031 - generator training loss: -0.0568, discriminator training loss: 0.1962, validation loss: 0.1329
2024-05-25 04:41:42 [INFO]: Epoch 032 - generator training loss: -0.0554, discriminator training loss: 0.1944, validation loss: 0.1317
2024-05-25 04:41:46 [INFO]: Epoch 033 - generator training loss: -0.0567, discriminator training loss: 0.1927, validation loss: 0.1302
2024-05-25 04:41:51 [INFO]: Epoch 034 - generator training loss: -0.0554, discriminator training loss: 0.1912, validation loss: 0.1292
2024-05-25 04:41:55 [INFO]: Epoch 035 - generator training loss: -0.0544, discriminator training loss: 0.1894, validation loss: 0.1278
2024-05-25 04:41:59 [INFO]: Epoch 036 - generator training loss: -0.0558, discriminator training loss: 0.1879, validation loss: 0.1268
2024-05-25 04:42:04 [INFO]: Epoch 037 - generator training loss: -0.0546, discriminator training loss: 0.1863, validation loss: 0.1250
2024-05-25 04:42:08 [INFO]: Epoch 038 - generator training loss: -0.0548, discriminator training loss: 0.1845, validation loss: 0.1242
2024-05-25 04:42:12 [INFO]: Epoch 039 - generator training loss: -0.0531, discriminator training loss: 0.1831, validation loss: 0.1233
2024-05-25 04:42:17 [INFO]: Epoch 040 - generator training loss: -0.0538, discriminator training loss: 0.1814, validation loss: 0.1225
2024-05-25 04:42:21 [INFO]: Epoch 041 - generator training loss: -0.0540, discriminator training loss: 0.1803, validation loss: 0.1206
2024-05-25 04:42:25 [INFO]: Epoch 042 - generator training loss: -0.0521, discriminator training loss: 0.1784, validation loss: 0.1209
2024-05-25 04:42:30 [INFO]: Epoch 043 - generator training loss: -0.0526, discriminator training loss: 0.1773, validation loss: 0.1193
2024-05-25 04:42:34 [INFO]: Epoch 044 - generator training loss: -0.0529, discriminator training loss: 0.1756, validation loss: 0.1181
2024-05-25 04:42:38 [INFO]: Epoch 045 - generator training loss: -0.0522, discriminator training loss: 0.1742, validation loss: 0.1172
2024-05-25 04:42:43 [INFO]: Epoch 046 - generator training loss: -0.0513, discriminator training loss: 0.1731, validation loss: 0.1167
2024-05-25 04:42:47 [INFO]: Epoch 047 - generator training loss: -0.0514, discriminator training loss: 0.1715, validation loss: 0.1162
2024-05-25 04:42:51 [INFO]: Epoch 048 - generator training loss: -0.0504, discriminator training loss: 0.1702, validation loss: 0.1154
2024-05-25 04:42:56 [INFO]: Epoch 049 - generator training loss: -0.0504, discriminator training loss: 0.1690, validation loss: 0.1144
2024-05-25 04:43:00 [INFO]: Epoch 050 - generator training loss: -0.0497, discriminator training loss: 0.1677, validation loss: 0.1136
2024-05-25 04:43:04 [INFO]: Epoch 051 - generator training loss: -0.0498, discriminator training loss: 0.1664, validation loss: 0.1128
2024-05-25 04:43:08 [INFO]: Epoch 052 - generator training loss: -0.0493, discriminator training loss: 0.1652, validation loss: 0.1126
2024-05-25 04:43:13 [INFO]: Epoch 053 - generator training loss: -0.0496, discriminator training loss: 0.1641, validation loss: 0.1118
2024-05-25 04:43:17 [INFO]: Epoch 054 - generator training loss: -0.0487, discriminator training loss: 0.1631, validation loss: 0.1114
2024-05-25 04:43:21 [INFO]: Epoch 055 - generator training loss: -0.0485, discriminator training loss: 0.1622, validation loss: 0.1105
2024-05-25 04:43:26 [INFO]: Epoch 056 - generator training loss: -0.0487, discriminator training loss: 0.1610, validation loss: 0.1103
2024-05-25 04:43:30 [INFO]: Epoch 057 - generator training loss: -0.0478, discriminator training loss: 0.1601, validation loss: 0.1096
2024-05-25 04:43:34 [INFO]: Epoch 058 - generator training loss: -0.0476, discriminator training loss: 0.1593, validation loss: 0.1092
2024-05-25 04:43:38 [INFO]: Epoch 059 - generator training loss: -0.0475, discriminator training loss: 0.1580, validation loss: 0.1090
2024-05-25 04:43:42 [INFO]: Epoch 060 - generator training loss: -0.0455, discriminator training loss: 0.1573, validation loss: 0.1080
2024-05-25 04:43:46 [INFO]: Epoch 061 - generator training loss: -0.0461, discriminator training loss: 0.1561, validation loss: 0.1075
2024-05-25 04:43:50 [INFO]: Epoch 062 - generator training loss: -0.0463, discriminator training loss: 0.1552, validation loss: 0.1073
2024-05-25 04:43:54 [INFO]: Epoch 063 - generator training loss: -0.0462, discriminator training loss: 0.1546, validation loss: 0.1071
2024-05-25 04:43:59 [INFO]: Epoch 064 - generator training loss: -0.0448, discriminator training loss: 0.1541, validation loss: 0.1069
2024-05-25 04:44:03 [INFO]: Epoch 065 - generator training loss: -0.0466, discriminator training loss: 0.1533, validation loss: 0.1056
2024-05-25 04:44:07 [INFO]: Epoch 066 - generator training loss: -0.0444, discriminator training loss: 0.1525, validation loss: 0.1058
2024-05-25 04:44:12 [INFO]: Epoch 067 - generator training loss: -0.0448, discriminator training loss: 0.1518, validation loss: 0.1055
2024-05-25 04:44:16 [INFO]: Epoch 068 - generator training loss: -0.0448, discriminator training loss: 0.1510, validation loss: 0.1048
2024-05-25 04:44:20 [INFO]: Epoch 069 - generator training loss: -0.0455, discriminator training loss: 0.1504, validation loss: 0.1044
2024-05-25 04:44:25 [INFO]: Epoch 070 - generator training loss: -0.0453, discriminator training loss: 0.1495, validation loss: 0.1044
2024-05-25 04:44:29 [INFO]: Epoch 071 - generator training loss: -0.0449, discriminator training loss: 0.1494, validation loss: 0.1040
2024-05-25 04:44:33 [INFO]: Epoch 072 - generator training loss: -0.0436, discriminator training loss: 0.1485, validation loss: 0.1039
2024-05-25 04:44:37 [INFO]: Epoch 073 - generator training loss: -0.0448, discriminator training loss: 0.1481, validation loss: 0.1037
2024-05-25 04:44:42 [INFO]: Epoch 074 - generator training loss: -0.0449, discriminator training loss: 0.1473, validation loss: 0.1030
2024-05-25 04:44:46 [INFO]: Epoch 075 - generator training loss: -0.0450, discriminator training loss: 0.1468, validation loss: 0.1030
2024-05-25 04:44:50 [INFO]: Epoch 076 - generator training loss: -0.0446, discriminator training loss: 0.1465, validation loss: 0.1023
2024-05-25 04:44:55 [INFO]: Epoch 077 - generator training loss: -0.0449, discriminator training loss: 0.1461, validation loss: 0.1022
2024-05-25 04:44:59 [INFO]: Epoch 078 - generator training loss: -0.0448, discriminator training loss: 0.1453, validation loss: 0.1021
2024-05-25 04:45:03 [INFO]: Epoch 079 - generator training loss: -0.0447, discriminator training loss: 0.1449, validation loss: 0.1015
2024-05-25 04:45:08 [INFO]: Epoch 080 - generator training loss: -0.0445, discriminator training loss: 0.1445, validation loss: 0.1017
2024-05-25 04:45:12 [INFO]: Epoch 081 - generator training loss: -0.0445, discriminator training loss: 0.1442, validation loss: 0.1016
2024-05-25 04:45:16 [INFO]: Epoch 082 - generator training loss: -0.0448, discriminator training loss: 0.1437, validation loss: 0.1011
2024-05-25 04:45:20 [INFO]: Epoch 083 - generator training loss: -0.0444, discriminator training loss: 0.1433, validation loss: 0.1012
2024-05-25 04:45:25 [INFO]: Epoch 084 - generator training loss: -0.0448, discriminator training loss: 0.1428, validation loss: 0.1011
2024-05-25 04:45:29 [INFO]: Epoch 085 - generator training loss: -0.0450, discriminator training loss: 0.1431, validation loss: 0.1005
2024-05-25 04:45:33 [INFO]: Epoch 086 - generator training loss: -0.0444, discriminator training loss: 0.1423, validation loss: 0.1004
2024-05-25 04:45:38 [INFO]: Epoch 087 - generator training loss: -0.0450, discriminator training loss: 0.1417, validation loss: 0.1000
2024-05-25 04:45:42 [INFO]: Epoch 088 - generator training loss: -0.0445, discriminator training loss: 0.1415, validation loss: 0.0995
2024-05-25 04:45:46 [INFO]: Epoch 089 - generator training loss: -0.0447, discriminator training loss: 0.1411, validation loss: 0.0996
2024-05-25 04:45:50 [INFO]: Epoch 090 - generator training loss: -0.0457, discriminator training loss: 0.1408, validation loss: 0.0996
2024-05-25 04:45:55 [INFO]: Epoch 091 - generator training loss: -0.0460, discriminator training loss: 0.1404, validation loss: 0.0992
2024-05-25 04:45:59 [INFO]: Epoch 092 - generator training loss: -0.0455, discriminator training loss: 0.1403, validation loss: 0.0993
2024-05-25 04:46:03 [INFO]: Epoch 093 - generator training loss: -0.0460, discriminator training loss: 0.1401, validation loss: 0.0993
2024-05-25 04:46:08 [INFO]: Epoch 094 - generator training loss: -0.0460, discriminator training loss: 0.1397, validation loss: 0.0994
2024-05-25 04:46:12 [INFO]: Epoch 095 - generator training loss: -0.0450, discriminator training loss: 0.1397, validation loss: 0.0995
2024-05-25 04:46:16 [INFO]: Epoch 096 - generator training loss: -0.0457, discriminator training loss: 0.1391, validation loss: 0.0987
2024-05-25 04:46:20 [INFO]: Epoch 097 - generator training loss: -0.0458, discriminator training loss: 0.1389, validation loss: 0.0991
2024-05-25 04:46:25 [INFO]: Epoch 098 - generator training loss: -0.0457, discriminator training loss: 0.1388, validation loss: 0.0985
2024-05-25 04:46:29 [INFO]: Epoch 099 - generator training loss: -0.0457, discriminator training loss: 0.1384, validation loss: 0.0984
2024-05-25 04:46:33 [INFO]: Epoch 100 - generator training loss: -0.0454, discriminator training loss: 0.1381, validation loss: 0.0983
2024-05-25 04:46:38 [INFO]: Epoch 101 - generator training loss: -0.0461, discriminator training loss: 0.1381, validation loss: 0.0982
2024-05-25 04:46:42 [INFO]: Epoch 102 - generator training loss: -0.0469, discriminator training loss: 0.1376, validation loss: 0.0983
2024-05-25 04:46:46 [INFO]: Epoch 103 - generator training loss: -0.0467, discriminator training loss: 0.1379, validation loss: 0.0982
2024-05-25 04:46:50 [INFO]: Epoch 104 - generator training loss: -0.0458, discriminator training loss: 0.1369, validation loss: 0.0983
2024-05-25 04:46:55 [INFO]: Epoch 105 - generator training loss: -0.0467, discriminator training loss: 0.1371, validation loss: 0.0985
2024-05-25 04:46:59 [INFO]: Epoch 106 - generator training loss: -0.0463, discriminator training loss: 0.1368, validation loss: 0.0987
2024-05-25 04:47:03 [INFO]: Epoch 107 - generator training loss: -0.0470, discriminator training loss: 0.1366, validation loss: 0.0978
2024-05-25 04:47:08 [INFO]: Epoch 108 - generator training loss: -0.0463, discriminator training loss: 0.1365, validation loss: 0.0982
2024-05-25 04:47:12 [INFO]: Epoch 109 - generator training loss: -0.0464, discriminator training loss: 0.1362, validation loss: 0.0977
2024-05-25 04:47:16 [INFO]: Epoch 110 - generator training loss: -0.0471, discriminator training loss: 0.1361, validation loss: 0.0980
2024-05-25 04:47:20 [INFO]: Epoch 111 - generator training loss: -0.0470, discriminator training loss: 0.1361, validation loss: 0.0984
2024-05-25 04:47:25 [INFO]: Epoch 112 - generator training loss: -0.0471, discriminator training loss: 0.1361, validation loss: 0.0977
2024-05-25 04:47:29 [INFO]: Epoch 113 - generator training loss: -0.0473, discriminator training loss: 0.1357, validation loss: 0.0970
2024-05-25 04:47:33 [INFO]: Epoch 114 - generator training loss: -0.0478, discriminator training loss: 0.1355, validation loss: 0.0980
2024-05-25 04:47:38 [INFO]: Epoch 115 - generator training loss: -0.0473, discriminator training loss: 0.1354, validation loss: 0.0975
2024-05-25 04:47:42 [INFO]: Epoch 116 - generator training loss: -0.0476, discriminator training loss: 0.1351, validation loss: 0.0978
2024-05-25 04:47:46 [INFO]: Epoch 117 - generator training loss: -0.0466, discriminator training loss: 0.1348, validation loss: 0.0974
2024-05-25 04:47:51 [INFO]: Epoch 118 - generator training loss: -0.0474, discriminator training loss: 0.1351, validation loss: 0.0975
2024-05-25 04:47:55 [INFO]: Epoch 119 - generator training loss: -0.0471, discriminator training loss: 0.1344, validation loss: 0.0972
2024-05-25 04:47:59 [INFO]: Epoch 120 - generator training loss: -0.0475, discriminator training loss: 0.1346, validation loss: 0.0969
2024-05-25 04:48:03 [INFO]: Epoch 121 - generator training loss: -0.0476, discriminator training loss: 0.1344, validation loss: 0.0978
2024-05-25 04:48:08 [INFO]: Epoch 122 - generator training loss: -0.0482, discriminator training loss: 0.1346, validation loss: 0.0964
2024-05-25 04:48:12 [INFO]: Epoch 123 - generator training loss: -0.0482, discriminator training loss: 0.1342, validation loss: 0.0982
2024-05-25 04:48:16 [INFO]: Epoch 124 - generator training loss: -0.0477, discriminator training loss: 0.1340, validation loss: 0.0969
2024-05-25 04:48:20 [INFO]: Epoch 125 - generator training loss: -0.0485, discriminator training loss: 0.1343, validation loss: 0.0981
2024-05-25 04:48:25 [INFO]: Epoch 126 - generator training loss: -0.0480, discriminator training loss: 0.1335, validation loss: 0.0971
2024-05-25 04:48:29 [INFO]: Epoch 127 - generator training loss: -0.0480, discriminator training loss: 0.1338, validation loss: 0.0974
2024-05-25 04:48:33 [INFO]: Epoch 128 - generator training loss: -0.0486, discriminator training loss: 0.1337, validation loss: 0.0973
2024-05-25 04:48:38 [INFO]: Epoch 129 - generator training loss: -0.0490, discriminator training loss: 0.1335, validation loss: 0.0972
2024-05-25 04:48:42 [INFO]: Epoch 130 - generator training loss: -0.0490, discriminator training loss: 0.1336, validation loss: 0.0970
2024-05-25 04:48:46 [INFO]: Epoch 131 - generator training loss: -0.0488, discriminator training loss: 0.1327, validation loss: 0.0971
2024-05-25 04:48:50 [INFO]: Epoch 132 - generator training loss: -0.0493, discriminator training loss: 0.1335, validation loss: 0.0973
2024-05-25 04:48:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:48:50 [INFO]: Finished training. The best model is from epoch#122.
2024-05-25 04:48:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/USGAN_air_quality/20240525_T043924/USGAN.pypots
2024-05-25 04:48:51 [INFO]: US-GAN on Air-Quality: MAE=0.1425, MSE=0.1792
2024-05-25 04:48:51 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/USGAN_air_quality/imputation.pkl
2024-05-25 04:48:51 [INFO]: Using the given device: cuda:0
2024-05-25 04:48:51 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/BRITS_air_quality/20240525_T044851
2024-05-25 04:48:51 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/BRITS_air_quality/20240525_T044851/tensorboard
2024-05-25 04:48:51 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 04:48:55 [INFO]: Epoch 001 - training loss: 1.3943, validation loss: 0.9180
2024-05-25 04:48:58 [INFO]: Epoch 002 - training loss: 1.1260, validation loss: 0.6748
2024-05-25 04:49:01 [INFO]: Epoch 003 - training loss: 0.9297, validation loss: 0.5696
2024-05-25 04:49:04 [INFO]: Epoch 004 - training loss: 0.8194, validation loss: 0.5035
2024-05-25 04:49:07 [INFO]: Epoch 005 - training loss: 0.7484, validation loss: 0.4607
2024-05-25 04:49:09 [INFO]: Epoch 006 - training loss: 0.6922, validation loss: 0.4249
2024-05-25 04:49:12 [INFO]: Epoch 007 - training loss: 0.6519, validation loss: 0.3984
2024-05-25 04:49:15 [INFO]: Epoch 008 - training loss: 0.6196, validation loss: 0.3767
2024-05-25 04:49:18 [INFO]: Epoch 009 - training loss: 0.5975, validation loss: 0.3582
2024-05-25 04:49:21 [INFO]: Epoch 010 - training loss: 0.5739, validation loss: 0.3430
2024-05-25 04:49:24 [INFO]: Epoch 011 - training loss: 0.5587, validation loss: 0.3311
2024-05-25 04:49:27 [INFO]: Epoch 012 - training loss: 0.5445, validation loss: 0.3196
2024-05-25 04:49:30 [INFO]: Epoch 013 - training loss: 0.5315, validation loss: 0.3100
2024-05-25 04:49:32 [INFO]: Epoch 014 - training loss: 0.5191, validation loss: 0.3010
2024-05-25 04:49:35 [INFO]: Epoch 015 - training loss: 0.5095, validation loss: 0.2934
2024-05-25 04:49:38 [INFO]: Epoch 016 - training loss: 0.5002, validation loss: 0.2867
2024-05-25 04:49:41 [INFO]: Epoch 017 - training loss: 0.4910, validation loss: 0.2805
2024-05-25 04:49:44 [INFO]: Epoch 018 - training loss: 0.4834, validation loss: 0.2752
2024-05-25 04:49:47 [INFO]: Epoch 019 - training loss: 0.4760, validation loss: 0.2696
2024-05-25 04:49:50 [INFO]: Epoch 020 - training loss: 0.4682, validation loss: 0.2648
2024-05-25 04:49:53 [INFO]: Epoch 021 - training loss: 0.4626, validation loss: 0.2600
2024-05-25 04:49:56 [INFO]: Epoch 022 - training loss: 0.4566, validation loss: 0.2560
2024-05-25 04:49:58 [INFO]: Epoch 023 - training loss: 0.4485, validation loss: 0.2510
2024-05-25 04:50:01 [INFO]: Epoch 024 - training loss: 0.4430, validation loss: 0.2468
2024-05-25 04:50:04 [INFO]: Epoch 025 - training loss: 0.4368, validation loss: 0.2432
2024-05-25 04:50:07 [INFO]: Epoch 026 - training loss: 0.4313, validation loss: 0.2391
2024-05-25 04:50:10 [INFO]: Epoch 027 - training loss: 0.4271, validation loss: 0.2356
2024-05-25 04:50:13 [INFO]: Epoch 028 - training loss: 0.4210, validation loss: 0.2319
2024-05-25 04:50:16 [INFO]: Epoch 029 - training loss: 0.4169, validation loss: 0.2289
2024-05-25 04:50:19 [INFO]: Epoch 030 - training loss: 0.4121, validation loss: 0.2247
2024-05-25 04:50:22 [INFO]: Epoch 031 - training loss: 0.4075, validation loss: 0.2216
2024-05-25 04:50:24 [INFO]: Epoch 032 - training loss: 0.4041, validation loss: 0.2184
2024-05-25 04:50:27 [INFO]: Epoch 033 - training loss: 0.3989, validation loss: 0.2151
2024-05-25 04:50:30 [INFO]: Epoch 034 - training loss: 0.3958, validation loss: 0.2121
2024-05-25 04:50:33 [INFO]: Epoch 035 - training loss: 0.3908, validation loss: 0.2095
2024-05-25 04:50:36 [INFO]: Epoch 036 - training loss: 0.3871, validation loss: 0.2063
2024-05-25 04:50:39 [INFO]: Epoch 037 - training loss: 0.3840, validation loss: 0.2031
2024-05-25 04:50:42 [INFO]: Epoch 038 - training loss: 0.3797, validation loss: 0.2006
2024-05-25 04:50:45 [INFO]: Epoch 039 - training loss: 0.3770, validation loss: 0.1978
2024-05-25 04:50:48 [INFO]: Epoch 040 - training loss: 0.3742, validation loss: 0.1946
2024-05-25 04:50:50 [INFO]: Epoch 041 - training loss: 0.3700, validation loss: 0.1926
2024-05-25 04:50:53 [INFO]: Epoch 042 - training loss: 0.3669, validation loss: 0.1901
2024-05-25 04:50:56 [INFO]: Epoch 043 - training loss: 0.3644, validation loss: 0.1878
2024-05-25 04:50:59 [INFO]: Epoch 044 - training loss: 0.3629, validation loss: 0.1850
2024-05-25 04:51:02 [INFO]: Epoch 045 - training loss: 0.3591, validation loss: 0.1825
2024-05-25 04:51:05 [INFO]: Epoch 046 - training loss: 0.3567, validation loss: 0.1802
2024-05-25 04:51:07 [INFO]: Epoch 047 - training loss: 0.3541, validation loss: 0.1785
2024-05-25 04:51:10 [INFO]: Epoch 048 - training loss: 0.3519, validation loss: 0.1758
2024-05-25 04:51:13 [INFO]: Epoch 049 - training loss: 0.3486, validation loss: 0.1739
2024-05-25 04:51:16 [INFO]: Epoch 050 - training loss: 0.3470, validation loss: 0.1717
2024-05-25 04:51:19 [INFO]: Epoch 051 - training loss: 0.3446, validation loss: 0.1700
2024-05-25 04:51:22 [INFO]: Epoch 052 - training loss: 0.3426, validation loss: 0.1683
2024-05-25 04:51:25 [INFO]: Epoch 053 - training loss: 0.3404, validation loss: 0.1668
2024-05-25 04:51:27 [INFO]: Epoch 054 - training loss: 0.3382, validation loss: 0.1654
2024-05-25 04:51:30 [INFO]: Epoch 055 - training loss: 0.3365, validation loss: 0.1640
2024-05-25 04:51:33 [INFO]: Epoch 056 - training loss: 0.3341, validation loss: 0.1625
2024-05-25 04:51:36 [INFO]: Epoch 057 - training loss: 0.3323, validation loss: 0.1615
2024-05-25 04:51:39 [INFO]: Epoch 058 - training loss: 0.3311, validation loss: 0.1599
2024-05-25 04:51:42 [INFO]: Epoch 059 - training loss: 0.3296, validation loss: 0.1591
2024-05-25 04:51:45 [INFO]: Epoch 060 - training loss: 0.3283, validation loss: 0.1576
2024-05-25 04:51:48 [INFO]: Epoch 061 - training loss: 0.3260, validation loss: 0.1567
2024-05-25 04:51:51 [INFO]: Epoch 062 - training loss: 0.3242, validation loss: 0.1556
2024-05-25 04:51:53 [INFO]: Epoch 063 - training loss: 0.3238, validation loss: 0.1548
2024-05-25 04:51:56 [INFO]: Epoch 064 - training loss: 0.3218, validation loss: 0.1537
2024-05-25 04:51:59 [INFO]: Epoch 065 - training loss: 0.3201, validation loss: 0.1530
2024-05-25 04:52:02 [INFO]: Epoch 066 - training loss: 0.3200, validation loss: 0.1521
2024-05-25 04:52:05 [INFO]: Epoch 067 - training loss: 0.3171, validation loss: 0.1513
2024-05-25 04:52:08 [INFO]: Epoch 068 - training loss: 0.3161, validation loss: 0.1506
2024-05-25 04:52:11 [INFO]: Epoch 069 - training loss: 0.3148, validation loss: 0.1499
2024-05-25 04:52:14 [INFO]: Epoch 070 - training loss: 0.3136, validation loss: 0.1493
2024-05-25 04:52:16 [INFO]: Epoch 071 - training loss: 0.3119, validation loss: 0.1485
2024-05-25 04:52:19 [INFO]: Epoch 072 - training loss: 0.3114, validation loss: 0.1478
2024-05-25 04:52:22 [INFO]: Epoch 073 - training loss: 0.3104, validation loss: 0.1471
2024-05-25 04:52:25 [INFO]: Epoch 074 - training loss: 0.3088, validation loss: 0.1469
2024-05-25 04:52:28 [INFO]: Epoch 075 - training loss: 0.3081, validation loss: 0.1462
2024-05-25 04:52:31 [INFO]: Epoch 076 - training loss: 0.3064, validation loss: 0.1455
2024-05-25 04:52:34 [INFO]: Epoch 077 - training loss: 0.3051, validation loss: 0.1452
2024-05-25 04:52:37 [INFO]: Epoch 078 - training loss: 0.3047, validation loss: 0.1448
2024-05-25 04:52:39 [INFO]: Epoch 079 - training loss: 0.3037, validation loss: 0.1442
2024-05-25 04:52:42 [INFO]: Epoch 080 - training loss: 0.3025, validation loss: 0.1436
2024-05-25 04:52:45 [INFO]: Epoch 081 - training loss: 0.3022, validation loss: 0.1430
2024-05-25 04:52:48 [INFO]: Epoch 082 - training loss: 0.3010, validation loss: 0.1427
2024-05-25 04:52:51 [INFO]: Epoch 083 - training loss: 0.3004, validation loss: 0.1422
2024-05-25 04:52:54 [INFO]: Epoch 084 - training loss: 0.2994, validation loss: 0.1419
2024-05-25 04:52:57 [INFO]: Epoch 085 - training loss: 0.2989, validation loss: 0.1415
2024-05-25 04:53:00 [INFO]: Epoch 086 - training loss: 0.2980, validation loss: 0.1410
2024-05-25 04:53:03 [INFO]: Epoch 087 - training loss: 0.2975, validation loss: 0.1406
2024-05-25 04:53:06 [INFO]: Epoch 088 - training loss: 0.2961, validation loss: 0.1400
2024-05-25 04:53:08 [INFO]: Epoch 089 - training loss: 0.2959, validation loss: 0.1396
2024-05-25 04:53:11 [INFO]: Epoch 090 - training loss: 0.2949, validation loss: 0.1392
2024-05-25 04:53:14 [INFO]: Epoch 091 - training loss: 0.2935, validation loss: 0.1389
2024-05-25 04:53:17 [INFO]: Epoch 092 - training loss: 0.2930, validation loss: 0.1387
2024-05-25 04:53:20 [INFO]: Epoch 093 - training loss: 0.2918, validation loss: 0.1384
2024-05-25 04:53:23 [INFO]: Epoch 094 - training loss: 0.2916, validation loss: 0.1378
2024-05-25 04:53:26 [INFO]: Epoch 095 - training loss: 0.2912, validation loss: 0.1376
2024-05-25 04:53:29 [INFO]: Epoch 096 - training loss: 0.2902, validation loss: 0.1372
2024-05-25 04:53:32 [INFO]: Epoch 097 - training loss: 0.2890, validation loss: 0.1369
2024-05-25 04:53:34 [INFO]: Epoch 098 - training loss: 0.2886, validation loss: 0.1365
2024-05-25 04:53:37 [INFO]: Epoch 099 - training loss: 0.2876, validation loss: 0.1362
2024-05-25 04:53:40 [INFO]: Epoch 100 - training loss: 0.2879, validation loss: 0.1360
2024-05-25 04:53:43 [INFO]: Epoch 101 - training loss: 0.2868, validation loss: 0.1358
2024-05-25 04:53:46 [INFO]: Epoch 102 - training loss: 0.2861, validation loss: 0.1354
2024-05-25 04:53:49 [INFO]: Epoch 103 - training loss: 0.2859, validation loss: 0.1348
2024-05-25 04:53:52 [INFO]: Epoch 104 - training loss: 0.2848, validation loss: 0.1347
2024-05-25 04:53:55 [INFO]: Epoch 105 - training loss: 0.2844, validation loss: 0.1342
2024-05-25 04:53:58 [INFO]: Epoch 106 - training loss: 0.2840, validation loss: 0.1341
2024-05-25 04:54:00 [INFO]: Epoch 107 - training loss: 0.2833, validation loss: 0.1335
2024-05-25 04:54:03 [INFO]: Epoch 108 - training loss: 0.2826, validation loss: 0.1334
2024-05-25 04:54:06 [INFO]: Epoch 109 - training loss: 0.2827, validation loss: 0.1331
2024-05-25 04:54:09 [INFO]: Epoch 110 - training loss: 0.2813, validation loss: 0.1326
2024-05-25 04:54:12 [INFO]: Epoch 111 - training loss: 0.2808, validation loss: 0.1322
2024-05-25 04:54:15 [INFO]: Epoch 112 - training loss: 0.2806, validation loss: 0.1320
2024-05-25 04:54:18 [INFO]: Epoch 113 - training loss: 0.2802, validation loss: 0.1319
2024-05-25 04:54:21 [INFO]: Epoch 114 - training loss: 0.2791, validation loss: 0.1316
2024-05-25 04:54:23 [INFO]: Epoch 115 - training loss: 0.2791, validation loss: 0.1311
2024-05-25 04:54:26 [INFO]: Epoch 116 - training loss: 0.2782, validation loss: 0.1310
2024-05-25 04:54:29 [INFO]: Epoch 117 - training loss: 0.2786, validation loss: 0.1307
2024-05-25 04:54:32 [INFO]: Epoch 118 - training loss: 0.2774, validation loss: 0.1307
2024-05-25 04:54:35 [INFO]: Epoch 119 - training loss: 0.2764, validation loss: 0.1303
2024-05-25 04:54:38 [INFO]: Epoch 120 - training loss: 0.2764, validation loss: 0.1300
2024-05-25 04:54:41 [INFO]: Epoch 121 - training loss: 0.2767, validation loss: 0.1295
2024-05-25 04:54:44 [INFO]: Epoch 122 - training loss: 0.2759, validation loss: 0.1295
2024-05-25 04:54:46 [INFO]: Epoch 123 - training loss: 0.2749, validation loss: 0.1291
2024-05-25 04:54:49 [INFO]: Epoch 124 - training loss: 0.2743, validation loss: 0.1290
2024-05-25 04:54:52 [INFO]: Epoch 125 - training loss: 0.2741, validation loss: 0.1287
2024-05-25 04:54:55 [INFO]: Epoch 126 - training loss: 0.2733, validation loss: 0.1285
2024-05-25 04:54:58 [INFO]: Epoch 127 - training loss: 0.2729, validation loss: 0.1281
2024-05-25 04:55:01 [INFO]: Epoch 128 - training loss: 0.2725, validation loss: 0.1280
2024-05-25 04:55:04 [INFO]: Epoch 129 - training loss: 0.2718, validation loss: 0.1276
2024-05-25 04:55:07 [INFO]: Epoch 130 - training loss: 0.2723, validation loss: 0.1272
2024-05-25 04:55:10 [INFO]: Epoch 131 - training loss: 0.2714, validation loss: 0.1270
2024-05-25 04:55:12 [INFO]: Epoch 132 - training loss: 0.2708, validation loss: 0.1267
2024-05-25 04:55:15 [INFO]: Epoch 133 - training loss: 0.2700, validation loss: 0.1264
2024-05-25 04:55:18 [INFO]: Epoch 134 - training loss: 0.2698, validation loss: 0.1262
2024-05-25 04:55:21 [INFO]: Epoch 135 - training loss: 0.2694, validation loss: 0.1259
2024-05-25 04:55:24 [INFO]: Epoch 136 - training loss: 0.2689, validation loss: 0.1256
2024-05-25 04:55:27 [INFO]: Epoch 137 - training loss: 0.2683, validation loss: 0.1254
2024-05-25 04:55:30 [INFO]: Epoch 138 - training loss: 0.2682, validation loss: 0.1251
2024-05-25 04:55:33 [INFO]: Epoch 139 - training loss: 0.2683, validation loss: 0.1250
2024-05-25 04:55:36 [INFO]: Epoch 140 - training loss: 0.2675, validation loss: 0.1245
2024-05-25 04:55:39 [INFO]: Epoch 141 - training loss: 0.2670, validation loss: 0.1245
2024-05-25 04:55:41 [INFO]: Epoch 142 - training loss: 0.2666, validation loss: 0.1241
2024-05-25 04:55:44 [INFO]: Epoch 143 - training loss: 0.2665, validation loss: 0.1240
2024-05-25 04:55:47 [INFO]: Epoch 144 - training loss: 0.2661, validation loss: 0.1237
2024-05-25 04:55:50 [INFO]: Epoch 145 - training loss: 0.2662, validation loss: 0.1235
2024-05-25 04:55:53 [INFO]: Epoch 146 - training loss: 0.2664, validation loss: 0.1230
2024-05-25 04:55:56 [INFO]: Epoch 147 - training loss: 0.2656, validation loss: 0.1231
2024-05-25 04:55:59 [INFO]: Epoch 148 - training loss: 0.2647, validation loss: 0.1227
2024-05-25 04:56:02 [INFO]: Epoch 149 - training loss: 0.2643, validation loss: 0.1225
2024-05-25 04:56:05 [INFO]: Epoch 150 - training loss: 0.2643, validation loss: 0.1222
2024-05-25 04:56:07 [INFO]: Epoch 151 - training loss: 0.2639, validation loss: 0.1221
2024-05-25 04:56:10 [INFO]: Epoch 152 - training loss: 0.2629, validation loss: 0.1218
2024-05-25 04:56:13 [INFO]: Epoch 153 - training loss: 0.2627, validation loss: 0.1216
2024-05-25 04:56:16 [INFO]: Epoch 154 - training loss: 0.2630, validation loss: 0.1214
2024-05-25 04:56:19 [INFO]: Epoch 155 - training loss: 0.2624, validation loss: 0.1210
2024-05-25 04:56:22 [INFO]: Epoch 156 - training loss: 0.2618, validation loss: 0.1209
2024-05-25 04:56:25 [INFO]: Epoch 157 - training loss: 0.2616, validation loss: 0.1207
2024-05-25 04:56:28 [INFO]: Epoch 158 - training loss: 0.2611, validation loss: 0.1203
2024-05-25 04:56:30 [INFO]: Epoch 159 - training loss: 0.2606, validation loss: 0.1202
2024-05-25 04:56:33 [INFO]: Epoch 160 - training loss: 0.2611, validation loss: 0.1200
2024-05-25 04:56:36 [INFO]: Epoch 161 - training loss: 0.2603, validation loss: 0.1199
2024-05-25 04:56:39 [INFO]: Epoch 162 - training loss: 0.2603, validation loss: 0.1197
2024-05-25 04:56:42 [INFO]: Epoch 163 - training loss: 0.2598, validation loss: 0.1194
2024-05-25 04:56:45 [INFO]: Epoch 164 - training loss: 0.2595, validation loss: 0.1194
2024-05-25 04:56:48 [INFO]: Epoch 165 - training loss: 0.2588, validation loss: 0.1190
2024-05-25 04:56:51 [INFO]: Epoch 166 - training loss: 0.2586, validation loss: 0.1189
2024-05-25 04:56:53 [INFO]: Epoch 167 - training loss: 0.2584, validation loss: 0.1186
2024-05-25 04:56:56 [INFO]: Epoch 168 - training loss: 0.2586, validation loss: 0.1186
2024-05-25 04:56:59 [INFO]: Epoch 169 - training loss: 0.2580, validation loss: 0.1184
2024-05-25 04:57:02 [INFO]: Epoch 170 - training loss: 0.2575, validation loss: 0.1182
2024-05-25 04:57:05 [INFO]: Epoch 171 - training loss: 0.2572, validation loss: 0.1180
2024-05-25 04:57:08 [INFO]: Epoch 172 - training loss: 0.2576, validation loss: 0.1181
2024-05-25 04:57:11 [INFO]: Epoch 173 - training loss: 0.2571, validation loss: 0.1177
2024-05-25 04:57:14 [INFO]: Epoch 174 - training loss: 0.2571, validation loss: 0.1174
2024-05-25 04:57:17 [INFO]: Epoch 175 - training loss: 0.2568, validation loss: 0.1173
2024-05-25 04:57:19 [INFO]: Epoch 176 - training loss: 0.2566, validation loss: 0.1170
2024-05-25 04:57:22 [INFO]: Epoch 177 - training loss: 0.2559, validation loss: 0.1170
2024-05-25 04:57:25 [INFO]: Epoch 178 - training loss: 0.2557, validation loss: 0.1166
2024-05-25 04:57:28 [INFO]: Epoch 179 - training loss: 0.2556, validation loss: 0.1164
2024-05-25 04:57:31 [INFO]: Epoch 180 - training loss: 0.2554, validation loss: 0.1166
2024-05-25 04:57:34 [INFO]: Epoch 181 - training loss: 0.2549, validation loss: 0.1164
2024-05-25 04:57:37 [INFO]: Epoch 182 - training loss: 0.2546, validation loss: 0.1160
2024-05-25 04:57:40 [INFO]: Epoch 183 - training loss: 0.2546, validation loss: 0.1159
2024-05-25 04:57:43 [INFO]: Epoch 184 - training loss: 0.2544, validation loss: 0.1157
2024-05-25 04:57:46 [INFO]: Epoch 185 - training loss: 0.2542, validation loss: 0.1157
2024-05-25 04:57:48 [INFO]: Epoch 186 - training loss: 0.2538, validation loss: 0.1155
2024-05-25 04:57:51 [INFO]: Epoch 187 - training loss: 0.2538, validation loss: 0.1156
2024-05-25 04:57:54 [INFO]: Epoch 188 - training loss: 0.2531, validation loss: 0.1153
2024-05-25 04:57:57 [INFO]: Epoch 189 - training loss: 0.2536, validation loss: 0.1151
2024-05-25 04:58:00 [INFO]: Epoch 190 - training loss: 0.2529, validation loss: 0.1148
2024-05-25 04:58:03 [INFO]: Epoch 191 - training loss: 0.2519, validation loss: 0.1146
2024-05-25 04:58:06 [INFO]: Epoch 192 - training loss: 0.2528, validation loss: 0.1145
2024-05-25 04:58:09 [INFO]: Epoch 193 - training loss: 0.2526, validation loss: 0.1144
2024-05-25 04:58:12 [INFO]: Epoch 194 - training loss: 0.2519, validation loss: 0.1145
2024-05-25 04:58:14 [INFO]: Epoch 195 - training loss: 0.2518, validation loss: 0.1142
2024-05-25 04:58:17 [INFO]: Epoch 196 - training loss: 0.2513, validation loss: 0.1142
2024-05-25 04:58:20 [INFO]: Epoch 197 - training loss: 0.2515, validation loss: 0.1140
2024-05-25 04:58:23 [INFO]: Epoch 198 - training loss: 0.2509, validation loss: 0.1137
2024-05-25 04:58:26 [INFO]: Epoch 199 - training loss: 0.2507, validation loss: 0.1137
2024-05-25 04:58:29 [INFO]: Epoch 200 - training loss: 0.2506, validation loss: 0.1138
2024-05-25 04:58:31 [INFO]: Epoch 201 - training loss: 0.2508, validation loss: 0.1135
2024-05-25 04:58:34 [INFO]: Epoch 202 - training loss: 0.2499, validation loss: 0.1136
2024-05-25 04:58:37 [INFO]: Epoch 203 - training loss: 0.2500, validation loss: 0.1131
2024-05-25 04:58:40 [INFO]: Epoch 204 - training loss: 0.2503, validation loss: 0.1131
2024-05-25 04:58:43 [INFO]: Epoch 205 - training loss: 0.2491, validation loss: 0.1128
2024-05-25 04:58:46 [INFO]: Epoch 206 - training loss: 0.2496, validation loss: 0.1129
2024-05-25 04:58:49 [INFO]: Epoch 207 - training loss: 0.2490, validation loss: 0.1127
2024-05-25 04:58:52 [INFO]: Epoch 208 - training loss: 0.2490, validation loss: 0.1124
2024-05-25 04:58:54 [INFO]: Epoch 209 - training loss: 0.2490, validation loss: 0.1124
2024-05-25 04:58:57 [INFO]: Epoch 210 - training loss: 0.2489, validation loss: 0.1124
2024-05-25 04:59:00 [INFO]: Epoch 211 - training loss: 0.2483, validation loss: 0.1121
2024-05-25 04:59:03 [INFO]: Epoch 212 - training loss: 0.2482, validation loss: 0.1122
2024-05-25 04:59:06 [INFO]: Epoch 213 - training loss: 0.2486, validation loss: 0.1120
2024-05-25 04:59:09 [INFO]: Epoch 214 - training loss: 0.2479, validation loss: 0.1119
2024-05-25 04:59:12 [INFO]: Epoch 215 - training loss: 0.2475, validation loss: 0.1119
2024-05-25 04:59:15 [INFO]: Epoch 216 - training loss: 0.2479, validation loss: 0.1117
2024-05-25 04:59:17 [INFO]: Epoch 217 - training loss: 0.2472, validation loss: 0.1117
2024-05-25 04:59:20 [INFO]: Epoch 218 - training loss: 0.2474, validation loss: 0.1116
2024-05-25 04:59:23 [INFO]: Epoch 219 - training loss: 0.2471, validation loss: 0.1115
2024-05-25 04:59:26 [INFO]: Epoch 220 - training loss: 0.2469, validation loss: 0.1113
2024-05-25 04:59:29 [INFO]: Epoch 221 - training loss: 0.2471, validation loss: 0.1113
2024-05-25 04:59:32 [INFO]: Epoch 222 - training loss: 0.2462, validation loss: 0.1112
2024-05-25 04:59:35 [INFO]: Epoch 223 - training loss: 0.2460, validation loss: 0.1112
2024-05-25 04:59:38 [INFO]: Epoch 224 - training loss: 0.2463, validation loss: 0.1110
2024-05-25 04:59:41 [INFO]: Epoch 225 - training loss: 0.2457, validation loss: 0.1109
2024-05-25 04:59:44 [INFO]: Epoch 226 - training loss: 0.2457, validation loss: 0.1107
2024-05-25 04:59:46 [INFO]: Epoch 227 - training loss: 0.2453, validation loss: 0.1107
2024-05-25 04:59:49 [INFO]: Epoch 228 - training loss: 0.2453, validation loss: 0.1105
2024-05-25 04:59:52 [INFO]: Epoch 229 - training loss: 0.2455, validation loss: 0.1105
2024-05-25 04:59:55 [INFO]: Epoch 230 - training loss: 0.2450, validation loss: 0.1103
2024-05-25 04:59:58 [INFO]: Epoch 231 - training loss: 0.2449, validation loss: 0.1104
2024-05-25 05:00:01 [INFO]: Epoch 232 - training loss: 0.2443, validation loss: 0.1101
2024-05-25 05:00:04 [INFO]: Epoch 233 - training loss: 0.2445, validation loss: 0.1101
2024-05-25 05:00:07 [INFO]: Epoch 234 - training loss: 0.2439, validation loss: 0.1101
2024-05-25 05:00:10 [INFO]: Epoch 235 - training loss: 0.2442, validation loss: 0.1099
2024-05-25 05:00:12 [INFO]: Epoch 236 - training loss: 0.2442, validation loss: 0.1099
2024-05-25 05:00:15 [INFO]: Epoch 237 - training loss: 0.2442, validation loss: 0.1097
2024-05-25 05:00:18 [INFO]: Epoch 238 - training loss: 0.2435, validation loss: 0.1099
2024-05-25 05:00:21 [INFO]: Epoch 239 - training loss: 0.2436, validation loss: 0.1097
2024-05-25 05:00:24 [INFO]: Epoch 240 - training loss: 0.2431, validation loss: 0.1094
2024-05-25 05:00:27 [INFO]: Epoch 241 - training loss: 0.2428, validation loss: 0.1094
2024-05-25 05:00:30 [INFO]: Epoch 242 - training loss: 0.2429, validation loss: 0.1096
2024-05-25 05:00:33 [INFO]: Epoch 243 - training loss: 0.2428, validation loss: 0.1096
2024-05-25 05:00:36 [INFO]: Epoch 244 - training loss: 0.2424, validation loss: 0.1092
2024-05-25 05:00:38 [INFO]: Epoch 245 - training loss: 0.2424, validation loss: 0.1095
2024-05-25 05:00:41 [INFO]: Epoch 246 - training loss: 0.2424, validation loss: 0.1092
2024-05-25 05:00:44 [INFO]: Epoch 247 - training loss: 0.2428, validation loss: 0.1090
2024-05-25 05:00:47 [INFO]: Epoch 248 - training loss: 0.2424, validation loss: 0.1092
2024-05-25 05:00:50 [INFO]: Epoch 249 - training loss: 0.2423, validation loss: 0.1091
2024-05-25 05:00:53 [INFO]: Epoch 250 - training loss: 0.2417, validation loss: 0.1091
2024-05-25 05:00:56 [INFO]: Epoch 251 - training loss: 0.2419, validation loss: 0.1090
2024-05-25 05:00:59 [INFO]: Epoch 252 - training loss: 0.2410, validation loss: 0.1087
2024-05-25 05:01:02 [INFO]: Epoch 253 - training loss: 0.2416, validation loss: 0.1087
2024-05-25 05:01:04 [INFO]: Epoch 254 - training loss: 0.2418, validation loss: 0.1089
2024-05-25 05:01:07 [INFO]: Epoch 255 - training loss: 0.2411, validation loss: 0.1087
2024-05-25 05:01:10 [INFO]: Epoch 256 - training loss: 0.2407, validation loss: 0.1086
2024-05-25 05:01:13 [INFO]: Epoch 257 - training loss: 0.2404, validation loss: 0.1086
2024-05-25 05:01:16 [INFO]: Epoch 258 - training loss: 0.2405, validation loss: 0.1086
2024-05-25 05:01:19 [INFO]: Epoch 259 - training loss: 0.2404, validation loss: 0.1084
2024-05-25 05:01:22 [INFO]: Epoch 260 - training loss: 0.2400, validation loss: 0.1085
2024-05-25 05:01:25 [INFO]: Epoch 261 - training loss: 0.2398, validation loss: 0.1083
2024-05-25 05:01:27 [INFO]: Epoch 262 - training loss: 0.2396, validation loss: 0.1084
2024-05-25 05:01:30 [INFO]: Epoch 263 - training loss: 0.2400, validation loss: 0.1082
2024-05-25 05:01:33 [INFO]: Epoch 264 - training loss: 0.2395, validation loss: 0.1081
2024-05-25 05:01:36 [INFO]: Epoch 265 - training loss: 0.2390, validation loss: 0.1083
2024-05-25 05:01:39 [INFO]: Epoch 266 - training loss: 0.2395, validation loss: 0.1081
2024-05-25 05:01:42 [INFO]: Epoch 267 - training loss: 0.2398, validation loss: 0.1081
2024-05-25 05:01:45 [INFO]: Epoch 268 - training loss: 0.2397, validation loss: 0.1080
2024-05-25 05:01:48 [INFO]: Epoch 269 - training loss: 0.2392, validation loss: 0.1079
2024-05-25 05:01:51 [INFO]: Epoch 270 - training loss: 0.2389, validation loss: 0.1078
2024-05-25 05:01:54 [INFO]: Epoch 271 - training loss: 0.2389, validation loss: 0.1079
2024-05-25 05:01:56 [INFO]: Epoch 272 - training loss: 0.2386, validation loss: 0.1077
2024-05-25 05:01:59 [INFO]: Epoch 273 - training loss: 0.2385, validation loss: 0.1077
2024-05-25 05:02:02 [INFO]: Epoch 274 - training loss: 0.2385, validation loss: 0.1077
2024-05-25 05:02:05 [INFO]: Epoch 275 - training loss: 0.2381, validation loss: 0.1075
2024-05-25 05:02:08 [INFO]: Epoch 276 - training loss: 0.2381, validation loss: 0.1077
2024-05-25 05:02:11 [INFO]: Epoch 277 - training loss: 0.2376, validation loss: 0.1075
2024-05-25 05:02:14 [INFO]: Epoch 278 - training loss: 0.2378, validation loss: 0.1075
2024-05-25 05:02:17 [INFO]: Epoch 279 - training loss: 0.2379, validation loss: 0.1074
2024-05-25 05:02:19 [INFO]: Epoch 280 - training loss: 0.2376, validation loss: 0.1073
2024-05-25 05:02:22 [INFO]: Epoch 281 - training loss: 0.2379, validation loss: 0.1073
2024-05-25 05:02:25 [INFO]: Epoch 282 - training loss: 0.2378, validation loss: 0.1072
2024-05-25 05:02:28 [INFO]: Epoch 283 - training loss: 0.2374, validation loss: 0.1072
2024-05-25 05:02:31 [INFO]: Epoch 284 - training loss: 0.2377, validation loss: 0.1073
2024-05-25 05:02:34 [INFO]: Epoch 285 - training loss: 0.2372, validation loss: 0.1073
2024-05-25 05:02:37 [INFO]: Epoch 286 - training loss: 0.2367, validation loss: 0.1075
2024-05-25 05:02:40 [INFO]: Epoch 287 - training loss: 0.2367, validation loss: 0.1074
2024-05-25 05:02:43 [INFO]: Epoch 288 - training loss: 0.2365, validation loss: 0.1073
2024-05-25 05:02:45 [INFO]: Epoch 289 - training loss: 0.2368, validation loss: 0.1069
2024-05-25 05:02:48 [INFO]: Epoch 290 - training loss: 0.2365, validation loss: 0.1073
2024-05-25 05:02:51 [INFO]: Epoch 291 - training loss: 0.2366, validation loss: 0.1072
2024-05-25 05:02:54 [INFO]: Epoch 292 - training loss: 0.2364, validation loss: 0.1072
2024-05-25 05:02:57 [INFO]: Epoch 293 - training loss: 0.2360, validation loss: 0.1070
2024-05-25 05:03:00 [INFO]: Epoch 294 - training loss: 0.2365, validation loss: 0.1070
2024-05-25 05:03:03 [INFO]: Epoch 295 - training loss: 0.2363, validation loss: 0.1068
2024-05-25 05:03:06 [INFO]: Epoch 296 - training loss: 0.2366, validation loss: 0.1068
2024-05-25 05:03:09 [INFO]: Epoch 297 - training loss: 0.2356, validation loss: 0.1067
2024-05-25 05:03:11 [INFO]: Epoch 298 - training loss: 0.2354, validation loss: 0.1067
2024-05-25 05:03:14 [INFO]: Epoch 299 - training loss: 0.2352, validation loss: 0.1068
2024-05-25 05:03:17 [INFO]: Epoch 300 - training loss: 0.2355, validation loss: 0.1067
2024-05-25 05:03:17 [INFO]: Finished training. The best model is from epoch#297.
2024-05-25 05:03:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/BRITS_air_quality/20240525_T044851/BRITS.pypots
2024-05-25 05:03:18 [INFO]: BRITS on Air-Quality: MAE=0.1382, MSE=0.1776
2024-05-25 05:03:18 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/BRITS_air_quality/imputation.pkl
2024-05-25 05:03:18 [INFO]: Using the given device: cuda:0
2024-05-25 05:03:18 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318
2024-05-25 05:03:18 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/tensorboard
2024-05-25 05:03:18 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 05:03:23 [INFO]: Epoch 001 - training loss: 1.4537, validation loss: 0.8163
2024-05-25 05:03:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch1_loss0.8163399577140809.pypots
2024-05-25 05:03:27 [INFO]: Epoch 002 - training loss: 1.0584, validation loss: 0.7598
2024-05-25 05:03:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch2_loss0.7598209649324417.pypots
2024-05-25 05:03:31 [INFO]: Epoch 003 - training loss: 0.9746, validation loss: 0.7255
2024-05-25 05:03:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch3_loss0.7255074411630631.pypots
2024-05-25 05:03:35 [INFO]: Epoch 004 - training loss: 0.9762, validation loss: 0.7124
2024-05-25 05:03:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch4_loss0.7123627990484238.pypots
2024-05-25 05:03:39 [INFO]: Epoch 005 - training loss: 0.9387, validation loss: 0.7040
2024-05-25 05:03:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch5_loss0.7040128231048584.pypots
2024-05-25 05:03:42 [INFO]: Epoch 006 - training loss: 0.9278, validation loss: 0.6980
2024-05-25 05:03:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch6_loss0.6980452865362168.pypots
2024-05-25 05:03:46 [INFO]: Epoch 007 - training loss: 0.9160, validation loss: 0.6927
2024-05-25 05:03:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch7_loss0.6927391529083252.pypots
2024-05-25 05:03:50 [INFO]: Epoch 008 - training loss: 0.9040, validation loss: 0.6887
2024-05-25 05:03:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch8_loss0.688660329580307.pypots
2024-05-25 05:03:54 [INFO]: Epoch 009 - training loss: 0.9098, validation loss: 0.6842
2024-05-25 05:03:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch9_loss0.6842371165752411.pypots
2024-05-25 05:03:58 [INFO]: Epoch 010 - training loss: 0.8921, validation loss: 0.6824
2024-05-25 05:03:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch10_loss0.6824200570583343.pypots
2024-05-25 05:04:02 [INFO]: Epoch 011 - training loss: 0.9070, validation loss: 0.6802
2024-05-25 05:04:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch11_loss0.6801586300134659.pypots
2024-05-25 05:04:06 [INFO]: Epoch 012 - training loss: 0.8939, validation loss: 0.6791
2024-05-25 05:04:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch12_loss0.6790740549564361.pypots
2024-05-25 05:04:10 [INFO]: Epoch 013 - training loss: 0.8930, validation loss: 0.6778
2024-05-25 05:04:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch13_loss0.6777854233980178.pypots
2024-05-25 05:04:14 [INFO]: Epoch 014 - training loss: 0.9032, validation loss: 0.6780
2024-05-25 05:04:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch14_loss0.6779666364192962.pypots
2024-05-25 05:04:18 [INFO]: Epoch 015 - training loss: 0.8854, validation loss: 0.6760
2024-05-25 05:04:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch15_loss0.6759735345840454.pypots
2024-05-25 05:04:22 [INFO]: Epoch 016 - training loss: 0.8742, validation loss: 0.6763
2024-05-25 05:04:22 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch16_loss0.676289764046669.pypots
2024-05-25 05:04:26 [INFO]: Epoch 017 - training loss: 0.8854, validation loss: 0.6750
2024-05-25 05:04:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch17_loss0.6750306576490402.pypots
2024-05-25 05:04:30 [INFO]: Epoch 018 - training loss: 0.8619, validation loss: 0.6745
2024-05-25 05:04:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch18_loss0.6744937717914581.pypots
2024-05-25 05:04:34 [INFO]: Epoch 019 - training loss: 0.8648, validation loss: 0.6745
2024-05-25 05:04:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch19_loss0.6744653940200805.pypots
2024-05-25 05:04:38 [INFO]: Epoch 020 - training loss: 0.8593, validation loss: 0.6743
2024-05-25 05:04:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch20_loss0.6742680847644806.pypots
2024-05-25 05:04:42 [INFO]: Epoch 021 - training loss: 0.8374, validation loss: 0.6740
2024-05-25 05:04:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch21_loss0.6739943951368332.pypots
2024-05-25 05:04:46 [INFO]: Epoch 022 - training loss: 0.8490, validation loss: 0.6746
2024-05-25 05:04:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch22_loss0.6746309846639633.pypots
2024-05-25 05:04:50 [INFO]: Epoch 023 - training loss: 0.8608, validation loss: 0.6753
2024-05-25 05:04:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch23_loss0.6753176063299179.pypots
2024-05-25 05:04:54 [INFO]: Epoch 024 - training loss: 0.8605, validation loss: 0.6725
2024-05-25 05:04:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch24_loss0.6724855422973632.pypots
2024-05-25 05:04:58 [INFO]: Epoch 025 - training loss: 0.8447, validation loss: 0.6734
2024-05-25 05:04:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch25_loss0.6734493553638459.pypots
2024-05-25 05:05:02 [INFO]: Epoch 026 - training loss: 0.8567, validation loss: 0.6740
2024-05-25 05:05:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch26_loss0.6739781856536865.pypots
2024-05-25 05:05:06 [INFO]: Epoch 027 - training loss: 0.8642, validation loss: 0.6722
2024-05-25 05:05:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch27_loss0.6721914231777191.pypots
2024-05-25 05:05:10 [INFO]: Epoch 028 - training loss: 0.8460, validation loss: 0.6734
2024-05-25 05:05:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch28_loss0.6733846157789231.pypots
2024-05-25 05:05:14 [INFO]: Epoch 029 - training loss: 0.8440, validation loss: 0.6752
2024-05-25 05:05:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch29_loss0.6752218663692474.pypots
2024-05-25 05:05:18 [INFO]: Epoch 030 - training loss: 0.8873, validation loss: 0.6742
2024-05-25 05:05:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch30_loss0.6742399156093597.pypots
2024-05-25 05:05:21 [INFO]: Epoch 031 - training loss: 0.8588, validation loss: 0.6729
2024-05-25 05:05:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch31_loss0.6728554457426071.pypots
2024-05-25 05:05:25 [INFO]: Epoch 032 - training loss: 0.8433, validation loss: 0.6743
2024-05-25 05:05:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch32_loss0.6743400037288666.pypots
2024-05-25 05:05:29 [INFO]: Epoch 033 - training loss: 0.8670, validation loss: 0.6742
2024-05-25 05:05:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch33_loss0.6742087602615356.pypots
2024-05-25 05:05:33 [INFO]: Epoch 034 - training loss: 0.8534, validation loss: 0.6751
2024-05-25 05:05:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch34_loss0.6750628799200058.pypots
2024-05-25 05:05:37 [INFO]: Epoch 035 - training loss: 0.8285, validation loss: 0.6754
2024-05-25 05:05:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch35_loss0.6753854990005493.pypots
2024-05-25 05:05:41 [INFO]: Epoch 036 - training loss: 0.8159, validation loss: 0.6781
2024-05-25 05:05:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch36_loss0.678122740983963.pypots
2024-05-25 05:05:45 [INFO]: Epoch 037 - training loss: 0.8258, validation loss: 0.6766
2024-05-25 05:05:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN_epoch37_loss0.6765752792358398.pypots
2024-05-25 05:05:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:05:45 [INFO]: Finished training. The best model is from epoch#27.
2024-05-25 05:05:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240525_T050318/MRNN.pypots
2024-05-25 05:05:46 [INFO]: MRNN on Air-Quality: MAE=0.5277, MSE=0.7674
2024-05-25 05:05:46 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/MRNN_air_quality/imputation.pkl
2024-05-25 05:05:46 [INFO]: Using the given device: cpu
2024-05-25 05:05:46 [INFO]: LOCF on Air-Quality: MAE=0.2039, MSE=0.4028
2024-05-25 05:05:46 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_air_quality".
2024-05-25 05:05:46 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/LOCF_air_quality/imputation.pkl
2024-05-25 05:05:46 [INFO]: Median on Air-Quality: MAE=0.6702, MSE=1.1687
2024-05-25 05:05:46 [INFO]: Successfully created the given path "saved_results/round_0/Median_air_quality".
2024-05-25 05:05:46 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Median_air_quality/imputation.pkl
2024-05-25 05:05:46 [INFO]: Mean on Air-Quality: MAE=0.7021, MSE=1.1087
2024-05-25 05:05:46 [INFO]: Successfully created the given path "saved_results/round_0/Mean_air_quality".
2024-05-25 05:05:46 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Mean_air_quality/imputation.pkl
2024-05-25 05:05:46 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-25 05:05:46 [INFO]: Using the given device: cuda:0
2024-05-25 05:05:46 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/SAITS_air_quality/20240525_T050546
2024-05-25 05:05:46 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/SAITS_air_quality/20240525_T050546/tensorboard
2024-05-25 05:05:46 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 05:05:47 [INFO]: Epoch 001 - training loss: 1.0383, validation loss: 0.5102
2024-05-25 05:05:47 [INFO]: Epoch 002 - training loss: 0.7416, validation loss: 0.3981
2024-05-25 05:05:48 [INFO]: Epoch 003 - training loss: 0.6338, validation loss: 0.3283
2024-05-25 05:05:49 [INFO]: Epoch 004 - training loss: 0.5634, validation loss: 0.2922
2024-05-25 05:05:49 [INFO]: Epoch 005 - training loss: 0.5135, validation loss: 0.2676
2024-05-25 05:05:50 [INFO]: Epoch 006 - training loss: 0.4793, validation loss: 0.2500
2024-05-25 05:05:50 [INFO]: Epoch 007 - training loss: 0.4543, validation loss: 0.2410
2024-05-25 05:05:51 [INFO]: Epoch 008 - training loss: 0.4352, validation loss: 0.2330
2024-05-25 05:05:52 [INFO]: Epoch 009 - training loss: 0.4202, validation loss: 0.2273
2024-05-25 05:05:52 [INFO]: Epoch 010 - training loss: 0.4077, validation loss: 0.2216
2024-05-25 05:05:53 [INFO]: Epoch 011 - training loss: 0.3982, validation loss: 0.2182
2024-05-25 05:05:53 [INFO]: Epoch 012 - training loss: 0.3883, validation loss: 0.2121
2024-05-25 05:05:54 [INFO]: Epoch 013 - training loss: 0.3809, validation loss: 0.2110
2024-05-25 05:05:55 [INFO]: Epoch 014 - training loss: 0.3736, validation loss: 0.2062
2024-05-25 05:05:55 [INFO]: Epoch 015 - training loss: 0.3662, validation loss: 0.2047
2024-05-25 05:05:56 [INFO]: Epoch 016 - training loss: 0.3614, validation loss: 0.2002
2024-05-25 05:05:56 [INFO]: Epoch 017 - training loss: 0.3558, validation loss: 0.1971
2024-05-25 05:05:57 [INFO]: Epoch 018 - training loss: 0.3516, validation loss: 0.1938
2024-05-25 05:05:58 [INFO]: Epoch 019 - training loss: 0.3462, validation loss: 0.1911
2024-05-25 05:05:58 [INFO]: Epoch 020 - training loss: 0.3410, validation loss: 0.1886
2024-05-25 05:05:59 [INFO]: Epoch 021 - training loss: 0.3368, validation loss: 0.1883
2024-05-25 05:05:59 [INFO]: Epoch 022 - training loss: 0.3329, validation loss: 0.1863
2024-05-25 05:06:00 [INFO]: Epoch 023 - training loss: 0.3282, validation loss: 0.1836
2024-05-25 05:06:01 [INFO]: Epoch 024 - training loss: 0.3255, validation loss: 0.1826
2024-05-25 05:06:01 [INFO]: Epoch 025 - training loss: 0.3214, validation loss: 0.1796
2024-05-25 05:06:02 [INFO]: Epoch 026 - training loss: 0.3197, validation loss: 0.1777
2024-05-25 05:06:02 [INFO]: Epoch 027 - training loss: 0.3161, validation loss: 0.1759
2024-05-25 05:06:03 [INFO]: Epoch 028 - training loss: 0.3131, validation loss: 0.1730
2024-05-25 05:06:04 [INFO]: Epoch 029 - training loss: 0.3105, validation loss: 0.1733
2024-05-25 05:06:04 [INFO]: Epoch 030 - training loss: 0.3092, validation loss: 0.1697
2024-05-25 05:06:05 [INFO]: Epoch 031 - training loss: 0.3055, validation loss: 0.1685
2024-05-25 05:06:06 [INFO]: Epoch 032 - training loss: 0.3020, validation loss: 0.1674
2024-05-25 05:06:06 [INFO]: Epoch 033 - training loss: 0.3001, validation loss: 0.1652
2024-05-25 05:06:07 [INFO]: Epoch 034 - training loss: 0.2975, validation loss: 0.1640
2024-05-25 05:06:07 [INFO]: Epoch 035 - training loss: 0.2958, validation loss: 0.1627
2024-05-25 05:06:08 [INFO]: Epoch 036 - training loss: 0.2944, validation loss: 0.1602
2024-05-25 05:06:09 [INFO]: Epoch 037 - training loss: 0.2911, validation loss: 0.1594
2024-05-25 05:06:09 [INFO]: Epoch 038 - training loss: 0.2896, validation loss: 0.1576
2024-05-25 05:06:10 [INFO]: Epoch 039 - training loss: 0.2867, validation loss: 0.1570
2024-05-25 05:06:10 [INFO]: Epoch 040 - training loss: 0.2852, validation loss: 0.1565
2024-05-25 05:06:11 [INFO]: Epoch 041 - training loss: 0.2832, validation loss: 0.1553
2024-05-25 05:06:12 [INFO]: Epoch 042 - training loss: 0.2812, validation loss: 0.1530
2024-05-25 05:06:12 [INFO]: Epoch 043 - training loss: 0.2784, validation loss: 0.1525
2024-05-25 05:06:13 [INFO]: Epoch 044 - training loss: 0.2784, validation loss: 0.1518
2024-05-25 05:06:14 [INFO]: Epoch 045 - training loss: 0.2761, validation loss: 0.1501
2024-05-25 05:06:14 [INFO]: Epoch 046 - training loss: 0.2743, validation loss: 0.1492
2024-05-25 05:06:15 [INFO]: Epoch 047 - training loss: 0.2726, validation loss: 0.1490
2024-05-25 05:06:15 [INFO]: Epoch 048 - training loss: 0.2703, validation loss: 0.1488
2024-05-25 05:06:16 [INFO]: Epoch 049 - training loss: 0.2690, validation loss: 0.1464
2024-05-25 05:06:17 [INFO]: Epoch 050 - training loss: 0.2668, validation loss: 0.1461
2024-05-25 05:06:17 [INFO]: Epoch 051 - training loss: 0.2669, validation loss: 0.1456
2024-05-25 05:06:18 [INFO]: Epoch 052 - training loss: 0.2651, validation loss: 0.1451
2024-05-25 05:06:18 [INFO]: Epoch 053 - training loss: 0.2632, validation loss: 0.1445
2024-05-25 05:06:19 [INFO]: Epoch 054 - training loss: 0.2619, validation loss: 0.1442
2024-05-25 05:06:20 [INFO]: Epoch 055 - training loss: 0.2596, validation loss: 0.1432
2024-05-25 05:06:20 [INFO]: Epoch 056 - training loss: 0.2599, validation loss: 0.1425
2024-05-25 05:06:21 [INFO]: Epoch 057 - training loss: 0.2571, validation loss: 0.1429
2024-05-25 05:06:21 [INFO]: Epoch 058 - training loss: 0.2556, validation loss: 0.1424
2024-05-25 05:06:22 [INFO]: Epoch 059 - training loss: 0.2532, validation loss: 0.1427
2024-05-25 05:06:23 [INFO]: Epoch 060 - training loss: 0.2526, validation loss: 0.1406
2024-05-25 05:06:23 [INFO]: Epoch 061 - training loss: 0.2511, validation loss: 0.1401
2024-05-25 05:06:24 [INFO]: Epoch 062 - training loss: 0.2504, validation loss: 0.1397
2024-05-25 05:06:25 [INFO]: Epoch 063 - training loss: 0.2482, validation loss: 0.1386
2024-05-25 05:06:25 [INFO]: Epoch 064 - training loss: 0.2471, validation loss: 0.1396
2024-05-25 05:06:26 [INFO]: Epoch 065 - training loss: 0.2457, validation loss: 0.1408
2024-05-25 05:06:26 [INFO]: Epoch 066 - training loss: 0.2448, validation loss: 0.1375
2024-05-25 05:06:27 [INFO]: Epoch 067 - training loss: 0.2430, validation loss: 0.1385
2024-05-25 05:06:28 [INFO]: Epoch 068 - training loss: 0.2421, validation loss: 0.1382
2024-05-25 05:06:28 [INFO]: Epoch 069 - training loss: 0.2408, validation loss: 0.1392
2024-05-25 05:06:29 [INFO]: Epoch 070 - training loss: 0.2395, validation loss: 0.1357
2024-05-25 05:06:29 [INFO]: Epoch 071 - training loss: 0.2394, validation loss: 0.1366
2024-05-25 05:06:30 [INFO]: Epoch 072 - training loss: 0.2386, validation loss: 0.1364
2024-05-25 05:06:31 [INFO]: Epoch 073 - training loss: 0.2365, validation loss: 0.1360
2024-05-25 05:06:31 [INFO]: Epoch 074 - training loss: 0.2354, validation loss: 0.1353
2024-05-25 05:06:32 [INFO]: Epoch 075 - training loss: 0.2342, validation loss: 0.1354
2024-05-25 05:06:32 [INFO]: Epoch 076 - training loss: 0.2329, validation loss: 0.1351
2024-05-25 05:06:33 [INFO]: Epoch 077 - training loss: 0.2317, validation loss: 0.1342
2024-05-25 05:06:34 [INFO]: Epoch 078 - training loss: 0.2312, validation loss: 0.1333
2024-05-25 05:06:34 [INFO]: Epoch 079 - training loss: 0.2306, validation loss: 0.1337
2024-05-25 05:06:35 [INFO]: Epoch 080 - training loss: 0.2295, validation loss: 0.1338
2024-05-25 05:06:36 [INFO]: Epoch 081 - training loss: 0.2282, validation loss: 0.1321
2024-05-25 05:06:36 [INFO]: Epoch 082 - training loss: 0.2269, validation loss: 0.1324
2024-05-25 05:06:37 [INFO]: Epoch 083 - training loss: 0.2269, validation loss: 0.1327
2024-05-25 05:06:37 [INFO]: Epoch 084 - training loss: 0.2261, validation loss: 0.1314
2024-05-25 05:06:38 [INFO]: Epoch 085 - training loss: 0.2238, validation loss: 0.1320
2024-05-25 05:06:39 [INFO]: Epoch 086 - training loss: 0.2236, validation loss: 0.1309
2024-05-25 05:06:39 [INFO]: Epoch 087 - training loss: 0.2219, validation loss: 0.1313
2024-05-25 05:06:40 [INFO]: Epoch 088 - training loss: 0.2215, validation loss: 0.1311
2024-05-25 05:06:40 [INFO]: Epoch 089 - training loss: 0.2206, validation loss: 0.1307
2024-05-25 05:06:41 [INFO]: Epoch 090 - training loss: 0.2199, validation loss: 0.1305
2024-05-25 05:06:42 [INFO]: Epoch 091 - training loss: 0.2194, validation loss: 0.1312
2024-05-25 05:06:42 [INFO]: Epoch 092 - training loss: 0.2201, validation loss: 0.1302
2024-05-25 05:06:43 [INFO]: Epoch 093 - training loss: 0.2186, validation loss: 0.1304
2024-05-25 05:06:43 [INFO]: Epoch 094 - training loss: 0.2173, validation loss: 0.1303
2024-05-25 05:06:44 [INFO]: Epoch 095 - training loss: 0.2166, validation loss: 0.1293
2024-05-25 05:06:45 [INFO]: Epoch 096 - training loss: 0.2158, validation loss: 0.1285
2024-05-25 05:06:45 [INFO]: Epoch 097 - training loss: 0.2161, validation loss: 0.1289
2024-05-25 05:06:46 [INFO]: Epoch 098 - training loss: 0.2183, validation loss: 0.1282
2024-05-25 05:06:46 [INFO]: Epoch 099 - training loss: 0.2149, validation loss: 0.1292
2024-05-25 05:06:47 [INFO]: Epoch 100 - training loss: 0.2132, validation loss: 0.1275
2024-05-25 05:06:48 [INFO]: Epoch 101 - training loss: 0.2131, validation loss: 0.1272
2024-05-25 05:06:48 [INFO]: Epoch 102 - training loss: 0.2116, validation loss: 0.1279
2024-05-25 05:06:49 [INFO]: Epoch 103 - training loss: 0.2115, validation loss: 0.1273
2024-05-25 05:06:50 [INFO]: Epoch 104 - training loss: 0.2103, validation loss: 0.1282
2024-05-25 05:06:50 [INFO]: Epoch 105 - training loss: 0.2100, validation loss: 0.1264
2024-05-25 05:06:51 [INFO]: Epoch 106 - training loss: 0.2088, validation loss: 0.1281
2024-05-25 05:06:51 [INFO]: Epoch 107 - training loss: 0.2090, validation loss: 0.1274
2024-05-25 05:06:52 [INFO]: Epoch 108 - training loss: 0.2079, validation loss: 0.1267
2024-05-25 05:06:53 [INFO]: Epoch 109 - training loss: 0.2071, validation loss: 0.1254
2024-05-25 05:06:53 [INFO]: Epoch 110 - training loss: 0.2073, validation loss: 0.1257
2024-05-25 05:06:54 [INFO]: Epoch 111 - training loss: 0.2060, validation loss: 0.1254
2024-05-25 05:06:54 [INFO]: Epoch 112 - training loss: 0.2054, validation loss: 0.1246
2024-05-25 05:06:55 [INFO]: Epoch 113 - training loss: 0.2050, validation loss: 0.1242
2024-05-25 05:06:56 [INFO]: Epoch 114 - training loss: 0.2053, validation loss: 0.1256
2024-05-25 05:06:56 [INFO]: Epoch 115 - training loss: 0.2056, validation loss: 0.1254
2024-05-25 05:06:57 [INFO]: Epoch 116 - training loss: 0.2036, validation loss: 0.1240
2024-05-25 05:06:57 [INFO]: Epoch 117 - training loss: 0.2021, validation loss: 0.1235
2024-05-25 05:06:58 [INFO]: Epoch 118 - training loss: 0.2015, validation loss: 0.1239
2024-05-25 05:06:59 [INFO]: Epoch 119 - training loss: 0.2028, validation loss: 0.1230
2024-05-25 05:06:59 [INFO]: Epoch 120 - training loss: 0.2010, validation loss: 0.1233
2024-05-25 05:07:00 [INFO]: Epoch 121 - training loss: 0.2002, validation loss: 0.1225
2024-05-25 05:07:01 [INFO]: Epoch 122 - training loss: 0.2002, validation loss: 0.1221
2024-05-25 05:07:01 [INFO]: Epoch 123 - training loss: 0.1994, validation loss: 0.1228
2024-05-25 05:07:02 [INFO]: Epoch 124 - training loss: 0.1986, validation loss: 0.1218
2024-05-25 05:07:02 [INFO]: Epoch 125 - training loss: 0.1993, validation loss: 0.1222
2024-05-25 05:07:03 [INFO]: Epoch 126 - training loss: 0.1985, validation loss: 0.1213
2024-05-25 05:07:04 [INFO]: Epoch 127 - training loss: 0.1977, validation loss: 0.1221
2024-05-25 05:07:04 [INFO]: Epoch 128 - training loss: 0.1964, validation loss: 0.1211
2024-05-25 05:07:05 [INFO]: Epoch 129 - training loss: 0.1954, validation loss: 0.1204
2024-05-25 05:07:05 [INFO]: Epoch 130 - training loss: 0.1954, validation loss: 0.1206
2024-05-25 05:07:06 [INFO]: Epoch 131 - training loss: 0.1949, validation loss: 0.1212
2024-05-25 05:07:07 [INFO]: Epoch 132 - training loss: 0.1942, validation loss: 0.1205
2024-05-25 05:07:07 [INFO]: Epoch 133 - training loss: 0.1955, validation loss: 0.1195
2024-05-25 05:07:08 [INFO]: Epoch 134 - training loss: 0.1942, validation loss: 0.1199
2024-05-25 05:07:08 [INFO]: Epoch 135 - training loss: 0.1930, validation loss: 0.1201
2024-05-25 05:07:09 [INFO]: Epoch 136 - training loss: 0.1929, validation loss: 0.1191
2024-05-25 05:07:10 [INFO]: Epoch 137 - training loss: 0.1929, validation loss: 0.1192
2024-05-25 05:07:10 [INFO]: Epoch 138 - training loss: 0.1947, validation loss: 0.1197
2024-05-25 05:07:11 [INFO]: Epoch 139 - training loss: 0.1936, validation loss: 0.1187
2024-05-25 05:07:12 [INFO]: Epoch 140 - training loss: 0.1925, validation loss: 0.1186
2024-05-25 05:07:12 [INFO]: Epoch 141 - training loss: 0.1916, validation loss: 0.1181
2024-05-25 05:07:13 [INFO]: Epoch 142 - training loss: 0.1902, validation loss: 0.1163
2024-05-25 05:07:13 [INFO]: Epoch 143 - training loss: 0.1893, validation loss: 0.1172
2024-05-25 05:07:14 [INFO]: Epoch 144 - training loss: 0.1890, validation loss: 0.1176
2024-05-25 05:07:15 [INFO]: Epoch 145 - training loss: 0.1886, validation loss: 0.1179
2024-05-25 05:07:15 [INFO]: Epoch 146 - training loss: 0.1886, validation loss: 0.1180
2024-05-25 05:07:16 [INFO]: Epoch 147 - training loss: 0.1877, validation loss: 0.1170
2024-05-25 05:07:16 [INFO]: Epoch 148 - training loss: 0.1875, validation loss: 0.1160
2024-05-25 05:07:17 [INFO]: Epoch 149 - training loss: 0.1872, validation loss: 0.1168
2024-05-25 05:07:18 [INFO]: Epoch 150 - training loss: 0.1865, validation loss: 0.1177
2024-05-25 05:07:18 [INFO]: Epoch 151 - training loss: 0.1878, validation loss: 0.1164
2024-05-25 05:07:19 [INFO]: Epoch 152 - training loss: 0.1859, validation loss: 0.1167
2024-05-25 05:07:19 [INFO]: Epoch 153 - training loss: 0.1854, validation loss: 0.1171
2024-05-25 05:07:20 [INFO]: Epoch 154 - training loss: 0.1849, validation loss: 0.1161
2024-05-25 05:07:21 [INFO]: Epoch 155 - training loss: 0.1837, validation loss: 0.1163
2024-05-25 05:07:21 [INFO]: Epoch 156 - training loss: 0.1839, validation loss: 0.1168
2024-05-25 05:07:22 [INFO]: Epoch 157 - training loss: 0.1833, validation loss: 0.1151
2024-05-25 05:07:23 [INFO]: Epoch 158 - training loss: 0.1840, validation loss: 0.1158
2024-05-25 05:07:23 [INFO]: Epoch 159 - training loss: 0.1841, validation loss: 0.1162
2024-05-25 05:07:24 [INFO]: Epoch 160 - training loss: 0.1839, validation loss: 0.1159
2024-05-25 05:07:24 [INFO]: Epoch 161 - training loss: 0.1821, validation loss: 0.1146
2024-05-25 05:07:25 [INFO]: Epoch 162 - training loss: 0.1833, validation loss: 0.1167
2024-05-25 05:07:26 [INFO]: Epoch 163 - training loss: 0.1822, validation loss: 0.1152
2024-05-25 05:07:26 [INFO]: Epoch 164 - training loss: 0.1814, validation loss: 0.1133
2024-05-25 05:07:27 [INFO]: Epoch 165 - training loss: 0.1809, validation loss: 0.1151
2024-05-25 05:07:27 [INFO]: Epoch 166 - training loss: 0.1813, validation loss: 0.1143
2024-05-25 05:07:28 [INFO]: Epoch 167 - training loss: 0.1802, validation loss: 0.1164
2024-05-25 05:07:29 [INFO]: Epoch 168 - training loss: 0.1802, validation loss: 0.1150
2024-05-25 05:07:29 [INFO]: Epoch 169 - training loss: 0.1804, validation loss: 0.1144
2024-05-25 05:07:30 [INFO]: Epoch 170 - training loss: 0.1799, validation loss: 0.1142
2024-05-25 05:07:30 [INFO]: Epoch 171 - training loss: 0.1786, validation loss: 0.1135
2024-05-25 05:07:31 [INFO]: Epoch 172 - training loss: 0.1786, validation loss: 0.1144
2024-05-25 05:07:32 [INFO]: Epoch 173 - training loss: 0.1787, validation loss: 0.1120
2024-05-25 05:07:32 [INFO]: Epoch 174 - training loss: 0.1782, validation loss: 0.1138
2024-05-25 05:07:33 [INFO]: Epoch 175 - training loss: 0.1786, validation loss: 0.1145
2024-05-25 05:07:34 [INFO]: Epoch 176 - training loss: 0.1766, validation loss: 0.1135
2024-05-25 05:07:34 [INFO]: Epoch 177 - training loss: 0.1758, validation loss: 0.1140
2024-05-25 05:07:35 [INFO]: Epoch 178 - training loss: 0.1757, validation loss: 0.1125
2024-05-25 05:07:35 [INFO]: Epoch 179 - training loss: 0.1788, validation loss: 0.1149
2024-05-25 05:07:36 [INFO]: Epoch 180 - training loss: 0.1777, validation loss: 0.1139
2024-05-25 05:07:37 [INFO]: Epoch 181 - training loss: 0.1762, validation loss: 0.1119
2024-05-25 05:07:37 [INFO]: Epoch 182 - training loss: 0.1750, validation loss: 0.1120
2024-05-25 05:07:38 [INFO]: Epoch 183 - training loss: 0.1745, validation loss: 0.1144
2024-05-25 05:07:38 [INFO]: Epoch 184 - training loss: 0.1741, validation loss: 0.1139
2024-05-25 05:07:39 [INFO]: Epoch 185 - training loss: 0.1738, validation loss: 0.1125
2024-05-25 05:07:40 [INFO]: Epoch 186 - training loss: 0.1744, validation loss: 0.1127
2024-05-25 05:07:40 [INFO]: Epoch 187 - training loss: 0.1751, validation loss: 0.1136
2024-05-25 05:07:41 [INFO]: Epoch 188 - training loss: 0.1726, validation loss: 0.1110
2024-05-25 05:07:41 [INFO]: Epoch 189 - training loss: 0.1720, validation loss: 0.1134
2024-05-25 05:07:42 [INFO]: Epoch 190 - training loss: 0.1716, validation loss: 0.1115
2024-05-25 05:07:43 [INFO]: Epoch 191 - training loss: 0.1720, validation loss: 0.1114
2024-05-25 05:07:43 [INFO]: Epoch 192 - training loss: 0.1720, validation loss: 0.1131
2024-05-25 05:07:44 [INFO]: Epoch 193 - training loss: 0.1719, validation loss: 0.1117
2024-05-25 05:07:44 [INFO]: Epoch 194 - training loss: 0.1723, validation loss: 0.1135
2024-05-25 05:07:45 [INFO]: Epoch 195 - training loss: 0.1721, validation loss: 0.1113
2024-05-25 05:07:46 [INFO]: Epoch 196 - training loss: 0.1715, validation loss: 0.1113
2024-05-25 05:07:46 [INFO]: Epoch 197 - training loss: 0.1718, validation loss: 0.1123
2024-05-25 05:07:47 [INFO]: Epoch 198 - training loss: 0.1712, validation loss: 0.1102
2024-05-25 05:07:48 [INFO]: Epoch 199 - training loss: 0.1701, validation loss: 0.1110
2024-05-25 05:07:48 [INFO]: Epoch 200 - training loss: 0.1693, validation loss: 0.1098
2024-05-25 05:07:49 [INFO]: Epoch 201 - training loss: 0.1684, validation loss: 0.1114
2024-05-25 05:07:49 [INFO]: Epoch 202 - training loss: 0.1681, validation loss: 0.1107
2024-05-25 05:07:50 [INFO]: Epoch 203 - training loss: 0.1682, validation loss: 0.1143
2024-05-25 05:07:51 [INFO]: Epoch 204 - training loss: 0.1686, validation loss: 0.1115
2024-05-25 05:07:51 [INFO]: Epoch 205 - training loss: 0.1675, validation loss: 0.1112
2024-05-25 05:07:52 [INFO]: Epoch 206 - training loss: 0.1671, validation loss: 0.1114
2024-05-25 05:07:52 [INFO]: Epoch 207 - training loss: 0.1679, validation loss: 0.1110
2024-05-25 05:07:53 [INFO]: Epoch 208 - training loss: 0.1679, validation loss: 0.1102
2024-05-25 05:07:54 [INFO]: Epoch 209 - training loss: 0.1675, validation loss: 0.1104
2024-05-25 05:07:54 [INFO]: Epoch 210 - training loss: 0.1674, validation loss: 0.1113
2024-05-25 05:07:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:07:54 [INFO]: Finished training. The best model is from epoch#200.
2024-05-25 05:07:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/SAITS_air_quality/20240525_T050546/SAITS.pypots
2024-05-25 05:07:54 [INFO]: SAITS on Air-Quality: MAE=0.1514, MSE=0.2184
2024-05-25 05:07:54 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/SAITS_air_quality/imputation.pkl
2024-05-25 05:07:54 [INFO]: Using the given device: cuda:0
2024-05-25 05:07:54 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/Transformer_air_quality/20240525_T050754
2024-05-25 05:07:54 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/Transformer_air_quality/20240525_T050754/tensorboard
2024-05-25 05:07:55 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 05:07:55 [INFO]: Epoch 001 - training loss: 0.9014, validation loss: 0.4589
2024-05-25 05:07:55 [INFO]: Epoch 002 - training loss: 0.5617, validation loss: 0.3455
2024-05-25 05:07:55 [INFO]: Epoch 003 - training loss: 0.4643, validation loss: 0.2897
2024-05-25 05:07:56 [INFO]: Epoch 004 - training loss: 0.4154, validation loss: 0.2661
2024-05-25 05:07:56 [INFO]: Epoch 005 - training loss: 0.3867, validation loss: 0.2497
2024-05-25 05:07:56 [INFO]: Epoch 006 - training loss: 0.3611, validation loss: 0.2406
2024-05-25 05:07:56 [INFO]: Epoch 007 - training loss: 0.3456, validation loss: 0.2335
2024-05-25 05:07:57 [INFO]: Epoch 008 - training loss: 0.3364, validation loss: 0.2225
2024-05-25 05:07:57 [INFO]: Epoch 009 - training loss: 0.3235, validation loss: 0.2183
2024-05-25 05:07:57 [INFO]: Epoch 010 - training loss: 0.3162, validation loss: 0.2137
2024-05-25 05:07:57 [INFO]: Epoch 011 - training loss: 0.3081, validation loss: 0.2084
2024-05-25 05:07:58 [INFO]: Epoch 012 - training loss: 0.3039, validation loss: 0.2066
2024-05-25 05:07:58 [INFO]: Epoch 013 - training loss: 0.2941, validation loss: 0.2018
2024-05-25 05:07:58 [INFO]: Epoch 014 - training loss: 0.2915, validation loss: 0.2013
2024-05-25 05:07:58 [INFO]: Epoch 015 - training loss: 0.2867, validation loss: 0.1954
2024-05-25 05:07:59 [INFO]: Epoch 016 - training loss: 0.2798, validation loss: 0.1919
2024-05-25 05:07:59 [INFO]: Epoch 017 - training loss: 0.2794, validation loss: 0.1886
2024-05-25 05:07:59 [INFO]: Epoch 018 - training loss: 0.2757, validation loss: 0.1886
2024-05-25 05:07:59 [INFO]: Epoch 019 - training loss: 0.2708, validation loss: 0.1861
2024-05-25 05:08:00 [INFO]: Epoch 020 - training loss: 0.2679, validation loss: 0.1818
2024-05-25 05:08:00 [INFO]: Epoch 021 - training loss: 0.2627, validation loss: 0.1824
2024-05-25 05:08:00 [INFO]: Epoch 022 - training loss: 0.2618, validation loss: 0.1803
2024-05-25 05:08:00 [INFO]: Epoch 023 - training loss: 0.2578, validation loss: 0.1786
2024-05-25 05:08:01 [INFO]: Epoch 024 - training loss: 0.2532, validation loss: 0.1777
2024-05-25 05:08:01 [INFO]: Epoch 025 - training loss: 0.2520, validation loss: 0.1756
2024-05-25 05:08:01 [INFO]: Epoch 026 - training loss: 0.2494, validation loss: 0.1734
2024-05-25 05:08:01 [INFO]: Epoch 027 - training loss: 0.2473, validation loss: 0.1723
2024-05-25 05:08:02 [INFO]: Epoch 028 - training loss: 0.2447, validation loss: 0.1702
2024-05-25 05:08:02 [INFO]: Epoch 029 - training loss: 0.2413, validation loss: 0.1705
2024-05-25 05:08:02 [INFO]: Epoch 030 - training loss: 0.2402, validation loss: 0.1702
2024-05-25 05:08:02 [INFO]: Epoch 031 - training loss: 0.2401, validation loss: 0.1697
2024-05-25 05:08:03 [INFO]: Epoch 032 - training loss: 0.2367, validation loss: 0.1660
2024-05-25 05:08:03 [INFO]: Epoch 033 - training loss: 0.2364, validation loss: 0.1682
2024-05-25 05:08:03 [INFO]: Epoch 034 - training loss: 0.2318, validation loss: 0.1670
2024-05-25 05:08:03 [INFO]: Epoch 035 - training loss: 0.2302, validation loss: 0.1669
2024-05-25 05:08:04 [INFO]: Epoch 036 - training loss: 0.2308, validation loss: 0.1648
2024-05-25 05:08:04 [INFO]: Epoch 037 - training loss: 0.2281, validation loss: 0.1638
2024-05-25 05:08:04 [INFO]: Epoch 038 - training loss: 0.2260, validation loss: 0.1646
2024-05-25 05:08:04 [INFO]: Epoch 039 - training loss: 0.2267, validation loss: 0.1632
2024-05-25 05:08:05 [INFO]: Epoch 040 - training loss: 0.2241, validation loss: 0.1625
2024-05-25 05:08:05 [INFO]: Epoch 041 - training loss: 0.2232, validation loss: 0.1617
2024-05-25 05:08:05 [INFO]: Epoch 042 - training loss: 0.2198, validation loss: 0.1607
2024-05-25 05:08:05 [INFO]: Epoch 043 - training loss: 0.2184, validation loss: 0.1611
2024-05-25 05:08:06 [INFO]: Epoch 044 - training loss: 0.2159, validation loss: 0.1596
2024-05-25 05:08:06 [INFO]: Epoch 045 - training loss: 0.2151, validation loss: 0.1590
2024-05-25 05:08:06 [INFO]: Epoch 046 - training loss: 0.2121, validation loss: 0.1591
2024-05-25 05:08:06 [INFO]: Epoch 047 - training loss: 0.2117, validation loss: 0.1595
2024-05-25 05:08:07 [INFO]: Epoch 048 - training loss: 0.2114, validation loss: 0.1618
2024-05-25 05:08:07 [INFO]: Epoch 049 - training loss: 0.2120, validation loss: 0.1580
2024-05-25 05:08:07 [INFO]: Epoch 050 - training loss: 0.2102, validation loss: 0.1602
2024-05-25 05:08:07 [INFO]: Epoch 051 - training loss: 0.2088, validation loss: 0.1590
2024-05-25 05:08:08 [INFO]: Epoch 052 - training loss: 0.2080, validation loss: 0.1575
2024-05-25 05:08:08 [INFO]: Epoch 053 - training loss: 0.2064, validation loss: 0.1563
2024-05-25 05:08:08 [INFO]: Epoch 054 - training loss: 0.2023, validation loss: 0.1568
2024-05-25 05:08:08 [INFO]: Epoch 055 - training loss: 0.2025, validation loss: 0.1572
2024-05-25 05:08:09 [INFO]: Epoch 056 - training loss: 0.2027, validation loss: 0.1550
2024-05-25 05:08:09 [INFO]: Epoch 057 - training loss: 0.1995, validation loss: 0.1551
2024-05-25 05:08:09 [INFO]: Epoch 058 - training loss: 0.1981, validation loss: 0.1538
2024-05-25 05:08:09 [INFO]: Epoch 059 - training loss: 0.1973, validation loss: 0.1549
2024-05-25 05:08:10 [INFO]: Epoch 060 - training loss: 0.1960, validation loss: 0.1536
2024-05-25 05:08:10 [INFO]: Epoch 061 - training loss: 0.1955, validation loss: 0.1535
2024-05-25 05:08:10 [INFO]: Epoch 062 - training loss: 0.1922, validation loss: 0.1533
2024-05-25 05:08:10 [INFO]: Epoch 063 - training loss: 0.1919, validation loss: 0.1525
2024-05-25 05:08:11 [INFO]: Epoch 064 - training loss: 0.1925, validation loss: 0.1530
2024-05-25 05:08:11 [INFO]: Epoch 065 - training loss: 0.1932, validation loss: 0.1509
2024-05-25 05:08:11 [INFO]: Epoch 066 - training loss: 0.1903, validation loss: 0.1520
2024-05-25 05:08:12 [INFO]: Epoch 067 - training loss: 0.1885, validation loss: 0.1534
2024-05-25 05:08:12 [INFO]: Epoch 068 - training loss: 0.1881, validation loss: 0.1519
2024-05-25 05:08:12 [INFO]: Epoch 069 - training loss: 0.1913, validation loss: 0.1499
2024-05-25 05:08:12 [INFO]: Epoch 070 - training loss: 0.1881, validation loss: 0.1492
2024-05-25 05:08:13 [INFO]: Epoch 071 - training loss: 0.1867, validation loss: 0.1508
2024-05-25 05:08:13 [INFO]: Epoch 072 - training loss: 0.1878, validation loss: 0.1503
2024-05-25 05:08:13 [INFO]: Epoch 073 - training loss: 0.1857, validation loss: 0.1510
2024-05-25 05:08:13 [INFO]: Epoch 074 - training loss: 0.1821, validation loss: 0.1491
2024-05-25 05:08:14 [INFO]: Epoch 075 - training loss: 0.1818, validation loss: 0.1506
2024-05-25 05:08:14 [INFO]: Epoch 076 - training loss: 0.1849, validation loss: 0.1478
2024-05-25 05:08:14 [INFO]: Epoch 077 - training loss: 0.1826, validation loss: 0.1464
2024-05-25 05:08:14 [INFO]: Epoch 078 - training loss: 0.1805, validation loss: 0.1511
2024-05-25 05:08:15 [INFO]: Epoch 079 - training loss: 0.1796, validation loss: 0.1470
2024-05-25 05:08:15 [INFO]: Epoch 080 - training loss: 0.1784, validation loss: 0.1464
2024-05-25 05:08:15 [INFO]: Epoch 081 - training loss: 0.1802, validation loss: 0.1465
2024-05-25 05:08:15 [INFO]: Epoch 082 - training loss: 0.1789, validation loss: 0.1456
2024-05-25 05:08:16 [INFO]: Epoch 083 - training loss: 0.1754, validation loss: 0.1471
2024-05-25 05:08:16 [INFO]: Epoch 084 - training loss: 0.1758, validation loss: 0.1465
2024-05-25 05:08:16 [INFO]: Epoch 085 - training loss: 0.1748, validation loss: 0.1454
2024-05-25 05:08:16 [INFO]: Epoch 086 - training loss: 0.1735, validation loss: 0.1441
2024-05-25 05:08:17 [INFO]: Epoch 087 - training loss: 0.1740, validation loss: 0.1448
2024-05-25 05:08:17 [INFO]: Epoch 088 - training loss: 0.1741, validation loss: 0.1458
2024-05-25 05:08:17 [INFO]: Epoch 089 - training loss: 0.1735, validation loss: 0.1446
2024-05-25 05:08:17 [INFO]: Epoch 090 - training loss: 0.1736, validation loss: 0.1437
2024-05-25 05:08:18 [INFO]: Epoch 091 - training loss: 0.1709, validation loss: 0.1451
2024-05-25 05:08:18 [INFO]: Epoch 092 - training loss: 0.1696, validation loss: 0.1431
2024-05-25 05:08:18 [INFO]: Epoch 093 - training loss: 0.1682, validation loss: 0.1429
2024-05-25 05:08:18 [INFO]: Epoch 094 - training loss: 0.1694, validation loss: 0.1436
2024-05-25 05:08:19 [INFO]: Epoch 095 - training loss: 0.1682, validation loss: 0.1434
2024-05-25 05:08:19 [INFO]: Epoch 096 - training loss: 0.1665, validation loss: 0.1432
2024-05-25 05:08:19 [INFO]: Epoch 097 - training loss: 0.1664, validation loss: 0.1424
2024-05-25 05:08:19 [INFO]: Epoch 098 - training loss: 0.1665, validation loss: 0.1430
2024-05-25 05:08:20 [INFO]: Epoch 099 - training loss: 0.1656, validation loss: 0.1430
2024-05-25 05:08:20 [INFO]: Epoch 100 - training loss: 0.1638, validation loss: 0.1421
2024-05-25 05:08:20 [INFO]: Epoch 101 - training loss: 0.1632, validation loss: 0.1403
2024-05-25 05:08:21 [INFO]: Epoch 102 - training loss: 0.1632, validation loss: 0.1413
2024-05-25 05:08:21 [INFO]: Epoch 103 - training loss: 0.1615, validation loss: 0.1407
2024-05-25 05:08:21 [INFO]: Epoch 104 - training loss: 0.1601, validation loss: 0.1398
2024-05-25 05:08:21 [INFO]: Epoch 105 - training loss: 0.1601, validation loss: 0.1421
2024-05-25 05:08:22 [INFO]: Epoch 106 - training loss: 0.1612, validation loss: 0.1407
2024-05-25 05:08:22 [INFO]: Epoch 107 - training loss: 0.1603, validation loss: 0.1422
2024-05-25 05:08:22 [INFO]: Epoch 108 - training loss: 0.1613, validation loss: 0.1404
2024-05-25 05:08:22 [INFO]: Epoch 109 - training loss: 0.1623, validation loss: 0.1389
2024-05-25 05:08:23 [INFO]: Epoch 110 - training loss: 0.1605, validation loss: 0.1415
2024-05-25 05:08:23 [INFO]: Epoch 111 - training loss: 0.1583, validation loss: 0.1393
2024-05-25 05:08:23 [INFO]: Epoch 112 - training loss: 0.1562, validation loss: 0.1398
2024-05-25 05:08:23 [INFO]: Epoch 113 - training loss: 0.1556, validation loss: 0.1388
2024-05-25 05:08:24 [INFO]: Epoch 114 - training loss: 0.1568, validation loss: 0.1382
2024-05-25 05:08:24 [INFO]: Epoch 115 - training loss: 0.1557, validation loss: 0.1389
2024-05-25 05:08:24 [INFO]: Epoch 116 - training loss: 0.1560, validation loss: 0.1389
2024-05-25 05:08:24 [INFO]: Epoch 117 - training loss: 0.1557, validation loss: 0.1412
2024-05-25 05:08:25 [INFO]: Epoch 118 - training loss: 0.1563, validation loss: 0.1374
2024-05-25 05:08:25 [INFO]: Epoch 119 - training loss: 0.1564, validation loss: 0.1377
2024-05-25 05:08:25 [INFO]: Epoch 120 - training loss: 0.1541, validation loss: 0.1385
2024-05-25 05:08:25 [INFO]: Epoch 121 - training loss: 0.1531, validation loss: 0.1390
2024-05-25 05:08:26 [INFO]: Epoch 122 - training loss: 0.1536, validation loss: 0.1384
2024-05-25 05:08:26 [INFO]: Epoch 123 - training loss: 0.1515, validation loss: 0.1365
2024-05-25 05:08:26 [INFO]: Epoch 124 - training loss: 0.1516, validation loss: 0.1383
2024-05-25 05:08:26 [INFO]: Epoch 125 - training loss: 0.1499, validation loss: 0.1378
2024-05-25 05:08:27 [INFO]: Epoch 126 - training loss: 0.1494, validation loss: 0.1372
2024-05-25 05:08:27 [INFO]: Epoch 127 - training loss: 0.1491, validation loss: 0.1352
2024-05-25 05:08:27 [INFO]: Epoch 128 - training loss: 0.1497, validation loss: 0.1369
2024-05-25 05:08:27 [INFO]: Epoch 129 - training loss: 0.1484, validation loss: 0.1380
2024-05-25 05:08:28 [INFO]: Epoch 130 - training loss: 0.1493, validation loss: 0.1367
2024-05-25 05:08:28 [INFO]: Epoch 131 - training loss: 0.1475, validation loss: 0.1357
2024-05-25 05:08:28 [INFO]: Epoch 132 - training loss: 0.1490, validation loss: 0.1362
2024-05-25 05:08:28 [INFO]: Epoch 133 - training loss: 0.1470, validation loss: 0.1371
2024-05-25 05:08:29 [INFO]: Epoch 134 - training loss: 0.1469, validation loss: 0.1361
2024-05-25 05:08:29 [INFO]: Epoch 135 - training loss: 0.1490, validation loss: 0.1379
2024-05-25 05:08:29 [INFO]: Epoch 136 - training loss: 0.1490, validation loss: 0.1372
2024-05-25 05:08:29 [INFO]: Epoch 137 - training loss: 0.1477, validation loss: 0.1367
2024-05-25 05:08:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:08:29 [INFO]: Finished training. The best model is from epoch#127.
2024-05-25 05:08:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/Transformer_air_quality/20240525_T050754/Transformer.pypots
2024-05-25 05:08:30 [INFO]: Transformer on Air-Quality: MAE=0.1683, MSE=0.2522
2024-05-25 05:08:30 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Transformer_air_quality/imputation.pkl
2024-05-25 05:08:30 [INFO]: Using the given device: cuda:0
2024-05-25 05:08:30 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/TimesNet_air_quality/20240525_T050830
2024-05-25 05:08:30 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/TimesNet_air_quality/20240525_T050830/tensorboard
2024-05-25 05:08:30 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 05:08:30 [INFO]: Epoch 001 - training loss: 0.3126, validation loss: 0.2940
2024-05-25 05:08:31 [INFO]: Epoch 002 - training loss: 0.2499, validation loss: 0.2508
2024-05-25 05:08:31 [INFO]: Epoch 003 - training loss: 0.2084, validation loss: 0.2417
2024-05-25 05:08:32 [INFO]: Epoch 004 - training loss: 0.1771, validation loss: 0.2288
2024-05-25 05:08:32 [INFO]: Epoch 005 - training loss: 0.1564, validation loss: 0.2178
2024-05-25 05:08:33 [INFO]: Epoch 006 - training loss: 0.1505, validation loss: 0.2119
2024-05-25 05:08:33 [INFO]: Epoch 007 - training loss: 0.1416, validation loss: 0.2083
2024-05-25 05:08:34 [INFO]: Epoch 008 - training loss: 0.1323, validation loss: 0.2030
2024-05-25 05:08:34 [INFO]: Epoch 009 - training loss: 0.1334, validation loss: 0.1965
2024-05-25 05:08:35 [INFO]: Epoch 010 - training loss: 0.1260, validation loss: 0.2004
2024-05-25 05:08:35 [INFO]: Epoch 011 - training loss: 0.1226, validation loss: 0.1957
2024-05-25 05:08:36 [INFO]: Epoch 012 - training loss: 0.1215, validation loss: 0.1956
2024-05-25 05:08:36 [INFO]: Epoch 013 - training loss: 0.1188, validation loss: 0.1927
2024-05-25 05:08:37 [INFO]: Epoch 014 - training loss: 0.1194, validation loss: 0.1864
2024-05-25 05:08:37 [INFO]: Epoch 015 - training loss: 0.1079, validation loss: 0.1894
2024-05-25 05:08:37 [INFO]: Epoch 016 - training loss: 0.1005, validation loss: 0.1867
2024-05-25 05:08:38 [INFO]: Epoch 017 - training loss: 0.0972, validation loss: 0.1854
2024-05-25 05:08:38 [INFO]: Epoch 018 - training loss: 0.0958, validation loss: 0.1842
2024-05-25 05:08:39 [INFO]: Epoch 019 - training loss: 0.0933, validation loss: 0.1824
2024-05-25 05:08:39 [INFO]: Epoch 020 - training loss: 0.0933, validation loss: 0.1809
2024-05-25 05:08:40 [INFO]: Epoch 021 - training loss: 0.0905, validation loss: 0.1851
2024-05-25 05:08:40 [INFO]: Epoch 022 - training loss: 0.0922, validation loss: 0.1821
2024-05-25 05:08:41 [INFO]: Epoch 023 - training loss: 0.0947, validation loss: 0.1841
2024-05-25 05:08:41 [INFO]: Epoch 024 - training loss: 0.0964, validation loss: 0.1780
2024-05-25 05:08:42 [INFO]: Epoch 025 - training loss: 0.0920, validation loss: 0.1824
2024-05-25 05:08:42 [INFO]: Epoch 026 - training loss: 0.1019, validation loss: 0.1780
2024-05-25 05:08:43 [INFO]: Epoch 027 - training loss: 0.0963, validation loss: 0.1772
2024-05-25 05:08:43 [INFO]: Epoch 028 - training loss: 0.0915, validation loss: 0.1783
2024-05-25 05:08:44 [INFO]: Epoch 029 - training loss: 0.1094, validation loss: 0.1826
2024-05-25 05:08:44 [INFO]: Epoch 030 - training loss: 0.0954, validation loss: 0.1728
2024-05-25 05:08:44 [INFO]: Epoch 031 - training loss: 0.0756, validation loss: 0.1725
2024-05-25 05:08:45 [INFO]: Epoch 032 - training loss: 0.0724, validation loss: 0.1717
2024-05-25 05:08:45 [INFO]: Epoch 033 - training loss: 0.0740, validation loss: 0.1758
2024-05-25 05:08:46 [INFO]: Epoch 034 - training loss: 0.0729, validation loss: 0.1712
2024-05-25 05:08:46 [INFO]: Epoch 035 - training loss: 0.0737, validation loss: 0.1695
2024-05-25 05:08:47 [INFO]: Epoch 036 - training loss: 0.0689, validation loss: 0.1692
2024-05-25 05:08:47 [INFO]: Epoch 037 - training loss: 0.0659, validation loss: 0.1699
2024-05-25 05:08:48 [INFO]: Epoch 038 - training loss: 0.0651, validation loss: 0.1717
2024-05-25 05:08:48 [INFO]: Epoch 039 - training loss: 0.0654, validation loss: 0.1731
2024-05-25 05:08:49 [INFO]: Epoch 040 - training loss: 0.0648, validation loss: 0.1712
2024-05-25 05:08:49 [INFO]: Epoch 041 - training loss: 0.0611, validation loss: 0.1691
2024-05-25 05:08:50 [INFO]: Epoch 042 - training loss: 0.0621, validation loss: 0.1698
2024-05-25 05:08:50 [INFO]: Epoch 043 - training loss: 0.0585, validation loss: 0.1678
2024-05-25 05:08:50 [INFO]: Epoch 044 - training loss: 0.0582, validation loss: 0.1692
2024-05-25 05:08:51 [INFO]: Epoch 045 - training loss: 0.0560, validation loss: 0.1695
2024-05-25 05:08:51 [INFO]: Epoch 046 - training loss: 0.0559, validation loss: 0.1682
2024-05-25 05:08:52 [INFO]: Epoch 047 - training loss: 0.0563, validation loss: 0.1694
2024-05-25 05:08:52 [INFO]: Epoch 048 - training loss: 0.0567, validation loss: 0.1677
2024-05-25 05:08:53 [INFO]: Epoch 049 - training loss: 0.0559, validation loss: 0.1694
2024-05-25 05:08:53 [INFO]: Epoch 050 - training loss: 0.0607, validation loss: 0.1728
2024-05-25 05:08:54 [INFO]: Epoch 051 - training loss: 0.0565, validation loss: 0.1684
2024-05-25 05:08:54 [INFO]: Epoch 052 - training loss: 0.0568, validation loss: 0.1676
2024-05-25 05:08:55 [INFO]: Epoch 053 - training loss: 0.0561, validation loss: 0.1674
2024-05-25 05:08:55 [INFO]: Epoch 054 - training loss: 0.0557, validation loss: 0.1718
2024-05-25 05:08:56 [INFO]: Epoch 055 - training loss: 0.0568, validation loss: 0.1694
2024-05-25 05:08:56 [INFO]: Epoch 056 - training loss: 0.0577, validation loss: 0.1705
2024-05-25 05:08:57 [INFO]: Epoch 057 - training loss: 0.0537, validation loss: 0.1668
2024-05-25 05:08:57 [INFO]: Epoch 058 - training loss: 0.0505, validation loss: 0.1664
2024-05-25 05:08:57 [INFO]: Epoch 059 - training loss: 0.0489, validation loss: 0.1686
2024-05-25 05:08:58 [INFO]: Epoch 060 - training loss: 0.0480, validation loss: 0.1676
2024-05-25 05:08:58 [INFO]: Epoch 061 - training loss: 0.0463, validation loss: 0.1692
2024-05-25 05:08:59 [INFO]: Epoch 062 - training loss: 0.0459, validation loss: 0.1679
2024-05-25 05:08:59 [INFO]: Epoch 063 - training loss: 0.0465, validation loss: 0.1685
2024-05-25 05:09:00 [INFO]: Epoch 064 - training loss: 0.0452, validation loss: 0.1678
2024-05-25 05:09:00 [INFO]: Epoch 065 - training loss: 0.0445, validation loss: 0.1673
2024-05-25 05:09:01 [INFO]: Epoch 066 - training loss: 0.0458, validation loss: 0.1687
2024-05-25 05:09:01 [INFO]: Epoch 067 - training loss: 0.0459, validation loss: 0.1706
2024-05-25 05:09:02 [INFO]: Epoch 068 - training loss: 0.0444, validation loss: 0.1687
2024-05-25 05:09:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:09:02 [INFO]: Finished training. The best model is from epoch#58.
2024-05-25 05:09:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/TimesNet_air_quality/20240525_T050830/TimesNet.pypots
2024-05-25 05:09:02 [INFO]: TimesNet on Air-Quality: MAE=0.1694, MSE=0.3105
2024-05-25 05:09:02 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/TimesNet_air_quality/imputation.pkl
2024-05-25 05:09:02 [INFO]: Using the given device: cuda:0
2024-05-25 05:09:02 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902
2024-05-25 05:09:02 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/tensorboard
2024-05-25 05:09:02 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 05:09:19 [INFO]: Epoch 001 - training loss: 0.4954, validation loss: 0.3434
2024-05-25 05:09:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch1_loss0.34338458478450773.pypots
2024-05-25 05:09:35 [INFO]: Epoch 002 - training loss: 0.3090, validation loss: 0.2689
2024-05-25 05:09:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch2_loss0.26894242614507674.pypots
2024-05-25 05:09:52 [INFO]: Epoch 003 - training loss: 0.2548, validation loss: 0.2569
2024-05-25 05:09:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch3_loss0.2568663388490677.pypots
2024-05-25 05:10:09 [INFO]: Epoch 004 - training loss: 0.2555, validation loss: 0.2192
2024-05-25 05:10:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch4_loss0.21924845278263091.pypots
2024-05-25 05:10:26 [INFO]: Epoch 005 - training loss: 0.2128, validation loss: 0.2034
2024-05-25 05:10:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch5_loss0.20340245664119722.pypots
2024-05-25 05:10:42 [INFO]: Epoch 006 - training loss: 0.2043, validation loss: 0.1821
2024-05-25 05:10:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch6_loss0.1820666953921318.pypots
2024-05-25 05:10:59 [INFO]: Epoch 007 - training loss: 0.1797, validation loss: 0.1660
2024-05-25 05:10:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch7_loss0.16596360206604005.pypots
2024-05-25 05:11:16 [INFO]: Epoch 008 - training loss: 0.1595, validation loss: 0.1652
2024-05-25 05:11:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch8_loss0.16524386554956436.pypots
2024-05-25 05:11:32 [INFO]: Epoch 009 - training loss: 0.1753, validation loss: 0.1637
2024-05-25 05:11:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch9_loss0.16367474496364592.pypots
2024-05-25 05:11:49 [INFO]: Epoch 010 - training loss: 0.1837, validation loss: 0.1515
2024-05-25 05:11:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch10_loss0.1514709159731865.pypots
2024-05-25 05:12:06 [INFO]: Epoch 011 - training loss: 0.1641, validation loss: 0.1641
2024-05-25 05:12:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch11_loss0.16408323496580124.pypots
2024-05-25 05:12:23 [INFO]: Epoch 012 - training loss: 0.1604, validation loss: 0.1466
2024-05-25 05:12:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch12_loss0.1466496154665947.pypots
2024-05-25 05:12:39 [INFO]: Epoch 013 - training loss: 0.1358, validation loss: 0.1438
2024-05-25 05:12:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch13_loss0.14384037256240845.pypots
2024-05-25 05:12:56 [INFO]: Epoch 014 - training loss: 0.1709, validation loss: 0.1432
2024-05-25 05:12:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch14_loss0.14318520277738572.pypots
2024-05-25 05:13:13 [INFO]: Epoch 015 - training loss: 0.1461, validation loss: 0.1400
2024-05-25 05:13:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch15_loss0.13997713029384612.pypots
2024-05-25 05:13:29 [INFO]: Epoch 016 - training loss: 0.1762, validation loss: 0.1463
2024-05-25 05:13:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch16_loss0.1462986022233963.pypots
2024-05-25 05:13:46 [INFO]: Epoch 017 - training loss: 0.1553, validation loss: 0.1395
2024-05-25 05:13:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch17_loss0.13947857096791266.pypots
2024-05-25 05:14:03 [INFO]: Epoch 018 - training loss: 0.1399, validation loss: 0.1421
2024-05-25 05:14:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch18_loss0.14208881109952926.pypots
2024-05-25 05:14:19 [INFO]: Epoch 019 - training loss: 0.1448, validation loss: 0.1384
2024-05-25 05:14:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch19_loss0.1383817173540592.pypots
2024-05-25 05:14:36 [INFO]: Epoch 020 - training loss: 0.1336, validation loss: 0.1361
2024-05-25 05:14:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch20_loss0.13610015511512757.pypots
2024-05-25 05:14:53 [INFO]: Epoch 021 - training loss: 0.1484, validation loss: 0.1349
2024-05-25 05:14:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch21_loss0.13492455929517747.pypots
2024-05-25 05:15:10 [INFO]: Epoch 022 - training loss: 0.1471, validation loss: 0.1339
2024-05-25 05:15:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch22_loss0.1339399479329586.pypots
2024-05-25 05:15:26 [INFO]: Epoch 023 - training loss: 0.1318, validation loss: 0.1328
2024-05-25 05:15:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch23_loss0.13276747316122056.pypots
2024-05-25 05:15:43 [INFO]: Epoch 024 - training loss: 0.1312, validation loss: 0.1313
2024-05-25 05:15:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch24_loss0.13129867538809775.pypots
2024-05-25 05:16:00 [INFO]: Epoch 025 - training loss: 0.1433, validation loss: 0.1308
2024-05-25 05:16:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch25_loss0.13082981556653978.pypots
2024-05-25 05:16:16 [INFO]: Epoch 026 - training loss: 0.1339, validation loss: 0.1353
2024-05-25 05:16:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch26_loss0.13529075384140016.pypots
2024-05-25 05:16:33 [INFO]: Epoch 027 - training loss: 0.1245, validation loss: 0.1289
2024-05-25 05:16:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch27_loss0.1289367288351059.pypots
2024-05-25 05:16:50 [INFO]: Epoch 028 - training loss: 0.1205, validation loss: 0.1273
2024-05-25 05:16:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch28_loss0.127323467284441.pypots
2024-05-25 05:17:07 [INFO]: Epoch 029 - training loss: 0.1283, validation loss: 0.1267
2024-05-25 05:17:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch29_loss0.12667428851127624.pypots
2024-05-25 05:17:23 [INFO]: Epoch 030 - training loss: 0.1290, validation loss: 0.1292
2024-05-25 05:17:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch30_loss0.1291516415774822.pypots
2024-05-25 05:17:40 [INFO]: Epoch 031 - training loss: 0.1217, validation loss: 0.1302
2024-05-25 05:17:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch31_loss0.13024768680334092.pypots
2024-05-25 05:17:57 [INFO]: Epoch 032 - training loss: 0.1346, validation loss: 0.1316
2024-05-25 05:17:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch32_loss0.13155605867505074.pypots
2024-05-25 05:18:13 [INFO]: Epoch 033 - training loss: 0.1413, validation loss: 0.1285
2024-05-25 05:18:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch33_loss0.12845326066017151.pypots
2024-05-25 05:18:30 [INFO]: Epoch 034 - training loss: 0.1338, validation loss: 0.1261
2024-05-25 05:18:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch34_loss0.1260816916823387.pypots
2024-05-25 05:18:47 [INFO]: Epoch 035 - training loss: 0.1274, validation loss: 0.1273
2024-05-25 05:18:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch35_loss0.12729946598410607.pypots
2024-05-25 05:19:04 [INFO]: Epoch 036 - training loss: 0.1176, validation loss: 0.1255
2024-05-25 05:19:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch36_loss0.1255421184003353.pypots
2024-05-25 05:19:20 [INFO]: Epoch 037 - training loss: 0.1338, validation loss: 0.1266
2024-05-25 05:19:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch37_loss0.1266406662762165.pypots
2024-05-25 05:19:37 [INFO]: Epoch 038 - training loss: 0.1285, validation loss: 0.1257
2024-05-25 05:19:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch38_loss0.12569111138582229.pypots
2024-05-25 05:19:54 [INFO]: Epoch 039 - training loss: 0.1264, validation loss: 0.1219
2024-05-25 05:19:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch39_loss0.12186099365353584.pypots
2024-05-25 05:20:10 [INFO]: Epoch 040 - training loss: 0.1144, validation loss: 0.1228
2024-05-25 05:20:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch40_loss0.12283029332756996.pypots
2024-05-25 05:20:27 [INFO]: Epoch 041 - training loss: 0.1391, validation loss: 0.1234
2024-05-25 05:20:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch41_loss0.12344751805067063.pypots
2024-05-25 05:20:44 [INFO]: Epoch 042 - training loss: 0.1144, validation loss: 0.1207
2024-05-25 05:20:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch42_loss0.12067902535200119.pypots
2024-05-25 05:21:00 [INFO]: Epoch 043 - training loss: 0.1157, validation loss: 0.1213
2024-05-25 05:21:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch43_loss0.12125031799077987.pypots
2024-05-25 05:21:17 [INFO]: Epoch 044 - training loss: 0.1236, validation loss: 0.1203
2024-05-25 05:21:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch44_loss0.12032262831926346.pypots
2024-05-25 05:21:34 [INFO]: Epoch 045 - training loss: 0.1129, validation loss: 0.1219
2024-05-25 05:21:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch45_loss0.12192751467227936.pypots
2024-05-25 05:21:51 [INFO]: Epoch 046 - training loss: 0.1338, validation loss: 0.1213
2024-05-25 05:21:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch46_loss0.12128380835056304.pypots
2024-05-25 05:22:07 [INFO]: Epoch 047 - training loss: 0.1300, validation loss: 0.1214
2024-05-25 05:22:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch47_loss0.12142168208956719.pypots
2024-05-25 05:22:24 [INFO]: Epoch 048 - training loss: 0.1326, validation loss: 0.1200
2024-05-25 05:22:24 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch48_loss0.12004714235663413.pypots
2024-05-25 05:22:41 [INFO]: Epoch 049 - training loss: 0.1317, validation loss: 0.1179
2024-05-25 05:22:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch49_loss0.11786366179585457.pypots
2024-05-25 05:22:57 [INFO]: Epoch 050 - training loss: 0.1168, validation loss: 0.1218
2024-05-25 05:22:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch50_loss0.1218398667871952.pypots
2024-05-25 05:23:14 [INFO]: Epoch 051 - training loss: 0.1144, validation loss: 0.1178
2024-05-25 05:23:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch51_loss0.11784439235925674.pypots
2024-05-25 05:23:31 [INFO]: Epoch 052 - training loss: 0.1222, validation loss: 0.1168
2024-05-25 05:23:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch52_loss0.11684207320213318.pypots
2024-05-25 05:23:48 [INFO]: Epoch 053 - training loss: 0.1165, validation loss: 0.1173
2024-05-25 05:23:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch53_loss0.11732731088995933.pypots
2024-05-25 05:24:04 [INFO]: Epoch 054 - training loss: 0.1160, validation loss: 0.1150
2024-05-25 05:24:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch54_loss0.11495503783226013.pypots
2024-05-25 05:24:21 [INFO]: Epoch 055 - training loss: 0.1170, validation loss: 0.1198
2024-05-25 05:24:21 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch55_loss0.11975109353661537.pypots
2024-05-25 05:24:38 [INFO]: Epoch 056 - training loss: 0.1127, validation loss: 0.1199
2024-05-25 05:24:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch56_loss0.11987561360001564.pypots
2024-05-25 05:24:54 [INFO]: Epoch 057 - training loss: 0.1333, validation loss: 0.1162
2024-05-25 05:24:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch57_loss0.11622884199023246.pypots
2024-05-25 05:25:11 [INFO]: Epoch 058 - training loss: 0.1124, validation loss: 0.1172
2024-05-25 05:25:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch58_loss0.11721016094088554.pypots
2024-05-25 05:25:28 [INFO]: Epoch 059 - training loss: 0.1130, validation loss: 0.1158
2024-05-25 05:25:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch59_loss0.11576314270496368.pypots
2024-05-25 05:25:45 [INFO]: Epoch 060 - training loss: 0.1149, validation loss: 0.1163
2024-05-25 05:25:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch60_loss0.11628362983465194.pypots
2024-05-25 05:26:01 [INFO]: Epoch 061 - training loss: 0.1277, validation loss: 0.1151
2024-05-25 05:26:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch61_loss0.11513715982437134.pypots
2024-05-25 05:26:18 [INFO]: Epoch 062 - training loss: 0.1138, validation loss: 0.1133
2024-05-25 05:26:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch62_loss0.11331911683082581.pypots
2024-05-25 05:26:35 [INFO]: Epoch 063 - training loss: 0.1100, validation loss: 0.1137
2024-05-25 05:26:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch63_loss0.1136894054710865.pypots
2024-05-25 05:26:51 [INFO]: Epoch 064 - training loss: 0.1052, validation loss: 0.1177
2024-05-25 05:26:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch64_loss0.11773705929517746.pypots
2024-05-25 05:27:08 [INFO]: Epoch 065 - training loss: 0.1188, validation loss: 0.1133
2024-05-25 05:27:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch65_loss0.113308846950531.pypots
2024-05-25 05:27:25 [INFO]: Epoch 066 - training loss: 0.1146, validation loss: 0.1206
2024-05-25 05:27:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch66_loss0.12064233273267747.pypots
2024-05-25 05:27:42 [INFO]: Epoch 067 - training loss: 0.1256, validation loss: 0.1187
2024-05-25 05:27:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch67_loss0.11874407157301903.pypots
2024-05-25 05:27:58 [INFO]: Epoch 068 - training loss: 0.1092, validation loss: 0.1147
2024-05-25 05:27:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch68_loss0.11467437818646431.pypots
2024-05-25 05:28:15 [INFO]: Epoch 069 - training loss: 0.1197, validation loss: 0.1164
2024-05-25 05:28:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch69_loss0.11643120124936104.pypots
2024-05-25 05:28:32 [INFO]: Epoch 070 - training loss: 0.1310, validation loss: 0.1170
2024-05-25 05:28:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch70_loss0.11697819977998733.pypots
2024-05-25 05:28:48 [INFO]: Epoch 071 - training loss: 0.1080, validation loss: 0.1119
2024-05-25 05:28:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch71_loss0.11192362308502198.pypots
2024-05-25 05:29:05 [INFO]: Epoch 072 - training loss: 0.1171, validation loss: 0.1111
2024-05-25 05:29:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch72_loss0.11113099232316018.pypots
2024-05-25 05:29:22 [INFO]: Epoch 073 - training loss: 0.1252, validation loss: 0.1131
2024-05-25 05:29:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch73_loss0.11308920830488205.pypots
2024-05-25 05:29:38 [INFO]: Epoch 074 - training loss: 0.1061, validation loss: 0.1109
2024-05-25 05:29:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch74_loss0.11092815548181534.pypots
2024-05-25 05:29:55 [INFO]: Epoch 075 - training loss: 0.1105, validation loss: 0.1119
2024-05-25 05:29:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch75_loss0.1119200587272644.pypots
2024-05-25 05:30:12 [INFO]: Epoch 076 - training loss: 0.1154, validation loss: 0.1113
2024-05-25 05:30:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch76_loss0.11126600578427315.pypots
2024-05-25 05:30:29 [INFO]: Epoch 077 - training loss: 0.1245, validation loss: 0.1113
2024-05-25 05:30:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch77_loss0.1113049603998661.pypots
2024-05-25 05:30:45 [INFO]: Epoch 078 - training loss: 0.1233, validation loss: 0.1126
2024-05-25 05:30:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch78_loss0.11264055445790291.pypots
2024-05-25 05:31:02 [INFO]: Epoch 079 - training loss: 0.1149, validation loss: 0.1126
2024-05-25 05:31:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch79_loss0.11259274408221245.pypots
2024-05-25 05:31:19 [INFO]: Epoch 080 - training loss: 0.1145, validation loss: 0.1112
2024-05-25 05:31:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch80_loss0.11119781732559204.pypots
2024-05-25 05:31:35 [INFO]: Epoch 081 - training loss: 0.0924, validation loss: 0.1139
2024-05-25 05:31:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch81_loss0.11388112381100654.pypots
2024-05-25 05:31:52 [INFO]: Epoch 082 - training loss: 0.1222, validation loss: 0.1119
2024-05-25 05:31:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch82_loss0.11194003373384476.pypots
2024-05-25 05:32:09 [INFO]: Epoch 083 - training loss: 0.1013, validation loss: 0.1109
2024-05-25 05:32:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch83_loss0.11094388961791993.pypots
2024-05-25 05:32:26 [INFO]: Epoch 084 - training loss: 0.1187, validation loss: 0.1079
2024-05-25 05:32:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch84_loss0.10785664841532708.pypots
2024-05-25 05:32:42 [INFO]: Epoch 085 - training loss: 0.1181, validation loss: 0.1080
2024-05-25 05:32:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch85_loss0.10801371708512306.pypots
2024-05-25 05:32:59 [INFO]: Epoch 086 - training loss: 0.1153, validation loss: 0.1091
2024-05-25 05:32:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch86_loss0.10909454300999641.pypots
2024-05-25 05:33:16 [INFO]: Epoch 087 - training loss: 0.1129, validation loss: 0.1106
2024-05-25 05:33:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch87_loss0.11057693660259246.pypots
2024-05-25 05:33:33 [INFO]: Epoch 088 - training loss: 0.1092, validation loss: 0.1078
2024-05-25 05:33:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch88_loss0.1078091450035572.pypots
2024-05-25 05:33:49 [INFO]: Epoch 089 - training loss: 0.1153, validation loss: 0.1091
2024-05-25 05:33:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch89_loss0.10909349769353867.pypots
2024-05-25 05:34:06 [INFO]: Epoch 090 - training loss: 0.1065, validation loss: 0.1079
2024-05-25 05:34:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch90_loss0.10792303904891014.pypots
2024-05-25 05:34:23 [INFO]: Epoch 091 - training loss: 0.1180, validation loss: 0.1113
2024-05-25 05:34:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch91_loss0.1112583726644516.pypots
2024-05-25 05:34:39 [INFO]: Epoch 092 - training loss: 0.1060, validation loss: 0.1162
2024-05-25 05:34:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch92_loss0.11622083559632301.pypots
2024-05-25 05:34:56 [INFO]: Epoch 093 - training loss: 0.1007, validation loss: 0.1072
2024-05-25 05:34:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch93_loss0.10724783092737197.pypots
2024-05-25 05:35:13 [INFO]: Epoch 094 - training loss: 0.1031, validation loss: 0.1087
2024-05-25 05:35:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch94_loss0.10866565629839897.pypots
2024-05-25 05:35:29 [INFO]: Epoch 095 - training loss: 0.1065, validation loss: 0.1089
2024-05-25 05:35:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch95_loss0.1088519811630249.pypots
2024-05-25 05:35:46 [INFO]: Epoch 096 - training loss: 0.1072, validation loss: 0.1105
2024-05-25 05:35:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch96_loss0.11047676354646682.pypots
2024-05-25 05:36:03 [INFO]: Epoch 097 - training loss: 0.1110, validation loss: 0.1088
2024-05-25 05:36:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch97_loss0.10876884832978248.pypots
2024-05-25 05:36:20 [INFO]: Epoch 098 - training loss: 0.1155, validation loss: 0.1074
2024-05-25 05:36:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch98_loss0.10739959329366684.pypots
2024-05-25 05:36:36 [INFO]: Epoch 099 - training loss: 0.0979, validation loss: 0.1062
2024-05-25 05:36:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch99_loss0.1061632551252842.pypots
2024-05-25 05:36:53 [INFO]: Epoch 100 - training loss: 0.1047, validation loss: 0.1077
2024-05-25 05:36:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch100_loss0.10767818987369537.pypots
2024-05-25 05:37:10 [INFO]: Epoch 101 - training loss: 0.1123, validation loss: 0.1102
2024-05-25 05:37:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch101_loss0.11023569777607918.pypots
2024-05-25 05:37:26 [INFO]: Epoch 102 - training loss: 0.1134, validation loss: 0.1078
2024-05-25 05:37:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch102_loss0.10779599100351334.pypots
2024-05-25 05:37:43 [INFO]: Epoch 103 - training loss: 0.1082, validation loss: 0.1091
2024-05-25 05:37:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch103_loss0.10909234136343002.pypots
2024-05-25 05:38:00 [INFO]: Epoch 104 - training loss: 0.0973, validation loss: 0.1056
2024-05-25 05:38:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch104_loss0.10561354458332062.pypots
2024-05-25 05:38:17 [INFO]: Epoch 105 - training loss: 0.1134, validation loss: 0.1077
2024-05-25 05:38:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch105_loss0.10771815329790116.pypots
2024-05-25 05:38:33 [INFO]: Epoch 106 - training loss: 0.1063, validation loss: 0.1071
2024-05-25 05:38:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch106_loss0.10709991902112961.pypots
2024-05-25 05:38:50 [INFO]: Epoch 107 - training loss: 0.1001, validation loss: 0.1071
2024-05-25 05:38:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch107_loss0.1071307972073555.pypots
2024-05-25 05:39:07 [INFO]: Epoch 108 - training loss: 0.1135, validation loss: 0.1060
2024-05-25 05:39:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch108_loss0.1059624508023262.pypots
2024-05-25 05:39:23 [INFO]: Epoch 109 - training loss: 0.1126, validation loss: 0.1155
2024-05-25 05:39:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch109_loss0.11546725705265999.pypots
2024-05-25 05:39:40 [INFO]: Epoch 110 - training loss: 0.1060, validation loss: 0.1138
2024-05-25 05:39:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch110_loss0.11377283409237862.pypots
2024-05-25 05:39:57 [INFO]: Epoch 111 - training loss: 0.1062, validation loss: 0.1117
2024-05-25 05:39:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch111_loss0.11170433387160301.pypots
2024-05-25 05:40:14 [INFO]: Epoch 112 - training loss: 0.1201, validation loss: 0.1078
2024-05-25 05:40:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch112_loss0.10778451710939407.pypots
2024-05-25 05:40:30 [INFO]: Epoch 113 - training loss: 0.1138, validation loss: 0.1098
2024-05-25 05:40:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch113_loss0.10984649583697319.pypots
2024-05-25 05:40:47 [INFO]: Epoch 114 - training loss: 0.1037, validation loss: 0.1061
2024-05-25 05:40:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI_epoch114_loss0.1061441384255886.pypots
2024-05-25 05:40:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:40:47 [INFO]: Finished training. The best model is from epoch#104.
2024-05-25 05:40:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240525_T050902/CSDI.pypots
2024-05-25 05:43:07 [INFO]: CSDI on Air-Quality: MAE=0.1071, MSE=0.2500
2024-05-25 05:43:07 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/CSDI_air_quality/imputation.pkl
2024-05-25 05:43:07 [INFO]: Using the given device: cuda:0
2024-05-25 05:43:07 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/GPVAE_air_quality/20240525_T054307
2024-05-25 05:43:07 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/GPVAE_air_quality/20240525_T054307/tensorboard
2024-05-25 05:43:07 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 05:43:08 [INFO]: Epoch 001 - training loss: 64066.8808, validation loss: 0.6421
2024-05-25 05:43:08 [INFO]: Epoch 002 - training loss: 41915.0577, validation loss: 0.5694
2024-05-25 05:43:08 [INFO]: Epoch 003 - training loss: 41629.6101, validation loss: 0.5000
2024-05-25 05:43:09 [INFO]: Epoch 004 - training loss: 41490.4266, validation loss: 0.4489
2024-05-25 05:43:09 [INFO]: Epoch 005 - training loss: 41432.0041, validation loss: 0.4526
2024-05-25 05:43:09 [INFO]: Epoch 006 - training loss: 41372.4719, validation loss: 0.4056
2024-05-25 05:43:10 [INFO]: Epoch 007 - training loss: 41326.9349, validation loss: 0.3686
2024-05-25 05:43:10 [INFO]: Epoch 008 - training loss: 41273.5103, validation loss: 0.3485
2024-05-25 05:43:11 [INFO]: Epoch 009 - training loss: 41245.6495, validation loss: 0.3571
2024-05-25 05:43:11 [INFO]: Epoch 010 - training loss: 41236.9488, validation loss: 0.3468
2024-05-25 05:43:11 [INFO]: Epoch 011 - training loss: 41222.3602, validation loss: 0.3213
2024-05-25 05:43:12 [INFO]: Epoch 012 - training loss: 41193.3008, validation loss: 0.3079
2024-05-25 05:43:12 [INFO]: Epoch 013 - training loss: 41168.4207, validation loss: 0.3070
2024-05-25 05:43:12 [INFO]: Epoch 014 - training loss: 41155.9282, validation loss: 0.3014
2024-05-25 05:43:13 [INFO]: Epoch 015 - training loss: 41154.0596, validation loss: 0.2956
2024-05-25 05:43:13 [INFO]: Epoch 016 - training loss: 41150.6733, validation loss: 0.3057
2024-05-25 05:43:14 [INFO]: Epoch 017 - training loss: 41141.4465, validation loss: 0.3010
2024-05-25 05:43:14 [INFO]: Epoch 018 - training loss: 41144.7085, validation loss: 0.3203
2024-05-25 05:43:14 [INFO]: Epoch 019 - training loss: 41201.6914, validation loss: 0.3093
2024-05-25 05:43:15 [INFO]: Epoch 020 - training loss: 41157.1133, validation loss: 0.3308
2024-05-25 05:43:15 [INFO]: Epoch 021 - training loss: 41146.2992, validation loss: 0.2995
2024-05-25 05:43:15 [INFO]: Epoch 022 - training loss: 41111.2802, validation loss: 0.2719
2024-05-25 05:43:16 [INFO]: Epoch 023 - training loss: 41089.3215, validation loss: 0.2679
2024-05-25 05:43:16 [INFO]: Epoch 024 - training loss: 41084.0165, validation loss: 0.2639
2024-05-25 05:43:16 [INFO]: Epoch 025 - training loss: 41090.6195, validation loss: 0.2731
2024-05-25 05:43:17 [INFO]: Epoch 026 - training loss: 41085.8913, validation loss: 0.2615
2024-05-25 05:43:17 [INFO]: Epoch 027 - training loss: 41072.4482, validation loss: 0.2597
2024-05-25 05:43:18 [INFO]: Epoch 028 - training loss: 41073.7519, validation loss: 0.2582
2024-05-25 05:43:18 [INFO]: Epoch 029 - training loss: 41072.6032, validation loss: 0.2687
2024-05-25 05:43:18 [INFO]: Epoch 030 - training loss: 41090.3859, validation loss: 0.2576
2024-05-25 05:43:19 [INFO]: Epoch 031 - training loss: 41084.3649, validation loss: 0.2580
2024-05-25 05:43:19 [INFO]: Epoch 032 - training loss: 41072.7329, validation loss: 0.2547
2024-05-25 05:43:19 [INFO]: Epoch 033 - training loss: 41066.4664, validation loss: 0.2583
2024-05-25 05:43:20 [INFO]: Epoch 034 - training loss: 41055.1146, validation loss: 0.2563
2024-05-25 05:43:20 [INFO]: Epoch 035 - training loss: 41056.9439, validation loss: 0.2503
2024-05-25 05:43:21 [INFO]: Epoch 036 - training loss: 41051.9343, validation loss: 0.2471
2024-05-25 05:43:21 [INFO]: Epoch 037 - training loss: 41043.1599, validation loss: 0.2389
2024-05-25 05:43:21 [INFO]: Epoch 038 - training loss: 41035.6898, validation loss: 0.2414
2024-05-25 05:43:22 [INFO]: Epoch 039 - training loss: 41031.3326, validation loss: 0.2443
2024-05-25 05:43:22 [INFO]: Epoch 040 - training loss: 41030.4219, validation loss: 0.2445
2024-05-25 05:43:22 [INFO]: Epoch 041 - training loss: 41029.1121, validation loss: 0.2422
2024-05-25 05:43:23 [INFO]: Epoch 042 - training loss: 41049.3523, validation loss: 0.2420
2024-05-25 05:43:23 [INFO]: Epoch 043 - training loss: 41051.9699, validation loss: 0.2412
2024-05-25 05:43:24 [INFO]: Epoch 044 - training loss: 41061.8245, validation loss: 0.2697
2024-05-25 05:43:24 [INFO]: Epoch 045 - training loss: 41150.7111, validation loss: 0.2949
2024-05-25 05:43:24 [INFO]: Epoch 046 - training loss: 41148.8775, validation loss: 0.2625
2024-05-25 05:43:25 [INFO]: Epoch 047 - training loss: 41053.4525, validation loss: 0.2426
2024-05-25 05:43:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:43:25 [INFO]: Finished training. The best model is from epoch#37.
2024-05-25 05:43:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/GPVAE_air_quality/20240525_T054307/GPVAE.pypots
2024-05-25 05:43:25 [INFO]: GP-VAE on Air-Quality: MAE=0.2884, MSE=0.3775
2024-05-25 05:43:25 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/GPVAE_air_quality/imputation.pkl
2024-05-25 05:43:25 [INFO]: Using the given device: cuda:0
2024-05-25 05:43:25 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/USGAN_air_quality/20240525_T054325
2024-05-25 05:43:25 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/USGAN_air_quality/20240525_T054325/tensorboard
2024-05-25 05:43:25 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 05:43:30 [INFO]: Epoch 001 - generator training loss: 0.5257, discriminator training loss: 0.3768, validation loss: 0.5079
2024-05-25 05:43:34 [INFO]: Epoch 002 - generator training loss: 0.1600, discriminator training loss: 0.2419, validation loss: 0.3821
2024-05-25 05:43:39 [INFO]: Epoch 003 - generator training loss: 0.0989, discriminator training loss: 0.2383, validation loss: 0.3215
2024-05-25 05:43:43 [INFO]: Epoch 004 - generator training loss: 0.0546, discriminator training loss: 0.2371, validation loss: 0.2781
2024-05-25 05:43:47 [INFO]: Epoch 005 - generator training loss: 0.0313, discriminator training loss: 0.2367, validation loss: 0.2511
2024-05-25 05:43:52 [INFO]: Epoch 006 - generator training loss: 0.0142, discriminator training loss: 0.2357, validation loss: 0.2344
2024-05-25 05:43:56 [INFO]: Epoch 007 - generator training loss: 0.0017, discriminator training loss: 0.2344, validation loss: 0.2204
2024-05-25 05:44:00 [INFO]: Epoch 008 - generator training loss: -0.0082, discriminator training loss: 0.2335, validation loss: 0.2096
2024-05-25 05:44:04 [INFO]: Epoch 009 - generator training loss: -0.0158, discriminator training loss: 0.2321, validation loss: 0.2002
2024-05-25 05:44:09 [INFO]: Epoch 010 - generator training loss: -0.0213, discriminator training loss: 0.2306, validation loss: 0.1926
2024-05-25 05:44:13 [INFO]: Epoch 011 - generator training loss: -0.0283, discriminator training loss: 0.2288, validation loss: 0.1864
2024-05-25 05:44:17 [INFO]: Epoch 012 - generator training loss: -0.0334, discriminator training loss: 0.2274, validation loss: 0.1806
2024-05-25 05:44:22 [INFO]: Epoch 013 - generator training loss: -0.0372, discriminator training loss: 0.2260, validation loss: 0.1763
2024-05-25 05:44:26 [INFO]: Epoch 014 - generator training loss: -0.0380, discriminator training loss: 0.2245, validation loss: 0.1722
2024-05-25 05:44:30 [INFO]: Epoch 015 - generator training loss: -0.0412, discriminator training loss: 0.2232, validation loss: 0.1689
2024-05-25 05:44:35 [INFO]: Epoch 016 - generator training loss: -0.0455, discriminator training loss: 0.2215, validation loss: 0.1651
2024-05-25 05:44:39 [INFO]: Epoch 017 - generator training loss: -0.0472, discriminator training loss: 0.2198, validation loss: 0.1617
2024-05-25 05:44:43 [INFO]: Epoch 018 - generator training loss: -0.0480, discriminator training loss: 0.2181, validation loss: 0.1591
2024-05-25 05:44:48 [INFO]: Epoch 019 - generator training loss: -0.0490, discriminator training loss: 0.2166, validation loss: 0.1567
2024-05-25 05:44:52 [INFO]: Epoch 020 - generator training loss: -0.0470, discriminator training loss: 0.2150, validation loss: 0.1544
2024-05-25 05:44:56 [INFO]: Epoch 021 - generator training loss: -0.0522, discriminator training loss: 0.2136, validation loss: 0.1516
2024-05-25 05:45:00 [INFO]: Epoch 022 - generator training loss: -0.0520, discriminator training loss: 0.2115, validation loss: 0.1496
2024-05-25 05:45:05 [INFO]: Epoch 023 - generator training loss: -0.0519, discriminator training loss: 0.2099, validation loss: 0.1475
2024-05-25 05:45:09 [INFO]: Epoch 024 - generator training loss: -0.0514, discriminator training loss: 0.2082, validation loss: 0.1460
2024-05-25 05:45:13 [INFO]: Epoch 025 - generator training loss: -0.0529, discriminator training loss: 0.2062, validation loss: 0.1444
2024-05-25 05:45:18 [INFO]: Epoch 026 - generator training loss: -0.0534, discriminator training loss: 0.2046, validation loss: 0.1430
2024-05-25 05:45:22 [INFO]: Epoch 027 - generator training loss: -0.0531, discriminator training loss: 0.2029, validation loss: 0.1412
2024-05-25 05:45:26 [INFO]: Epoch 028 - generator training loss: -0.0528, discriminator training loss: 0.2010, validation loss: 0.1396
2024-05-25 05:45:31 [INFO]: Epoch 029 - generator training loss: -0.0529, discriminator training loss: 0.1992, validation loss: 0.1380
2024-05-25 05:45:35 [INFO]: Epoch 030 - generator training loss: -0.0532, discriminator training loss: 0.1974, validation loss: 0.1371
2024-05-25 05:45:39 [INFO]: Epoch 031 - generator training loss: -0.0532, discriminator training loss: 0.1957, validation loss: 0.1359
2024-05-25 05:45:43 [INFO]: Epoch 032 - generator training loss: -0.0525, discriminator training loss: 0.1940, validation loss: 0.1348
2024-05-25 05:45:48 [INFO]: Epoch 033 - generator training loss: -0.0526, discriminator training loss: 0.1922, validation loss: 0.1335
2024-05-25 05:45:52 [INFO]: Epoch 034 - generator training loss: -0.0505, discriminator training loss: 0.1908, validation loss: 0.1323
2024-05-25 05:45:57 [INFO]: Epoch 035 - generator training loss: -0.0520, discriminator training loss: 0.1889, validation loss: 0.1319
2024-05-25 05:46:01 [INFO]: Epoch 036 - generator training loss: -0.0498, discriminator training loss: 0.1871, validation loss: 0.1308
2024-05-25 05:46:05 [INFO]: Epoch 037 - generator training loss: -0.0512, discriminator training loss: 0.1857, validation loss: 0.1284
2024-05-25 05:46:09 [INFO]: Epoch 038 - generator training loss: -0.0504, discriminator training loss: 0.1838, validation loss: 0.1285
2024-05-25 05:46:14 [INFO]: Epoch 039 - generator training loss: -0.0504, discriminator training loss: 0.1825, validation loss: 0.1277
2024-05-25 05:46:18 [INFO]: Epoch 040 - generator training loss: -0.0497, discriminator training loss: 0.1808, validation loss: 0.1267
2024-05-25 05:46:22 [INFO]: Epoch 041 - generator training loss: -0.0497, discriminator training loss: 0.1794, validation loss: 0.1257
2024-05-25 05:46:27 [INFO]: Epoch 042 - generator training loss: -0.0488, discriminator training loss: 0.1781, validation loss: 0.1254
2024-05-25 05:46:31 [INFO]: Epoch 043 - generator training loss: -0.0471, discriminator training loss: 0.1763, validation loss: 0.1238
2024-05-25 05:46:35 [INFO]: Epoch 044 - generator training loss: -0.0482, discriminator training loss: 0.1747, validation loss: 0.1234
2024-05-25 05:46:40 [INFO]: Epoch 045 - generator training loss: -0.0491, discriminator training loss: 0.1735, validation loss: 0.1226
2024-05-25 05:46:44 [INFO]: Epoch 046 - generator training loss: -0.0464, discriminator training loss: 0.1718, validation loss: 0.1217
2024-05-25 05:46:48 [INFO]: Epoch 047 - generator training loss: -0.0474, discriminator training loss: 0.1705, validation loss: 0.1208
2024-05-25 05:46:52 [INFO]: Epoch 048 - generator training loss: -0.0469, discriminator training loss: 0.1694, validation loss: 0.1203
2024-05-25 05:46:57 [INFO]: Epoch 049 - generator training loss: -0.0452, discriminator training loss: 0.1683, validation loss: 0.1192
2024-05-25 05:47:01 [INFO]: Epoch 050 - generator training loss: -0.0449, discriminator training loss: 0.1669, validation loss: 0.1193
2024-05-25 05:47:05 [INFO]: Epoch 051 - generator training loss: -0.0445, discriminator training loss: 0.1660, validation loss: 0.1191
2024-05-25 05:47:10 [INFO]: Epoch 052 - generator training loss: -0.0445, discriminator training loss: 0.1645, validation loss: 0.1185
2024-05-25 05:47:14 [INFO]: Epoch 053 - generator training loss: -0.0438, discriminator training loss: 0.1635, validation loss: 0.1178
2024-05-25 05:47:18 [INFO]: Epoch 054 - generator training loss: -0.0443, discriminator training loss: 0.1620, validation loss: 0.1181
2024-05-25 05:47:23 [INFO]: Epoch 055 - generator training loss: -0.0434, discriminator training loss: 0.1611, validation loss: 0.1170
2024-05-25 05:47:27 [INFO]: Epoch 056 - generator training loss: -0.0437, discriminator training loss: 0.1603, validation loss: 0.1167
2024-05-25 05:47:31 [INFO]: Epoch 057 - generator training loss: -0.0435, discriminator training loss: 0.1593, validation loss: 0.1162
2024-05-25 05:47:36 [INFO]: Epoch 058 - generator training loss: -0.0436, discriminator training loss: 0.1579, validation loss: 0.1152
2024-05-25 05:47:40 [INFO]: Epoch 059 - generator training loss: -0.0430, discriminator training loss: 0.1574, validation loss: 0.1147
2024-05-25 05:47:44 [INFO]: Epoch 060 - generator training loss: -0.0427, discriminator training loss: 0.1565, validation loss: 0.1146
2024-05-25 05:47:48 [INFO]: Epoch 061 - generator training loss: -0.0425, discriminator training loss: 0.1557, validation loss: 0.1145
2024-05-25 05:47:53 [INFO]: Epoch 062 - generator training loss: -0.0423, discriminator training loss: 0.1551, validation loss: 0.1137
2024-05-25 05:47:57 [INFO]: Epoch 063 - generator training loss: -0.0427, discriminator training loss: 0.1544, validation loss: 0.1136
2024-05-25 05:48:01 [INFO]: Epoch 064 - generator training loss: -0.0423, discriminator training loss: 0.1536, validation loss: 0.1129
2024-05-25 05:48:06 [INFO]: Epoch 065 - generator training loss: -0.0420, discriminator training loss: 0.1527, validation loss: 0.1133
2024-05-25 05:48:10 [INFO]: Epoch 066 - generator training loss: -0.0418, discriminator training loss: 0.1521, validation loss: 0.1122
2024-05-25 05:48:14 [INFO]: Epoch 067 - generator training loss: -0.0406, discriminator training loss: 0.1512, validation loss: 0.1130
2024-05-25 05:48:19 [INFO]: Epoch 068 - generator training loss: -0.0414, discriminator training loss: 0.1507, validation loss: 0.1119
2024-05-25 05:48:23 [INFO]: Epoch 069 - generator training loss: -0.0418, discriminator training loss: 0.1503, validation loss: 0.1117
2024-05-25 05:48:27 [INFO]: Epoch 070 - generator training loss: -0.0419, discriminator training loss: 0.1496, validation loss: 0.1112
2024-05-25 05:48:32 [INFO]: Epoch 071 - generator training loss: -0.0401, discriminator training loss: 0.1488, validation loss: 0.1115
2024-05-25 05:48:36 [INFO]: Epoch 072 - generator training loss: -0.0418, discriminator training loss: 0.1483, validation loss: 0.1116
2024-05-25 05:48:40 [INFO]: Epoch 073 - generator training loss: -0.0416, discriminator training loss: 0.1477, validation loss: 0.1105
2024-05-25 05:48:44 [INFO]: Epoch 074 - generator training loss: -0.0411, discriminator training loss: 0.1471, validation loss: 0.1109
2024-05-25 05:48:49 [INFO]: Epoch 075 - generator training loss: -0.0407, discriminator training loss: 0.1470, validation loss: 0.1097
2024-05-25 05:48:53 [INFO]: Epoch 076 - generator training loss: -0.0415, discriminator training loss: 0.1459, validation loss: 0.1104
2024-05-25 05:48:57 [INFO]: Epoch 077 - generator training loss: -0.0413, discriminator training loss: 0.1461, validation loss: 0.1101
2024-05-25 05:49:02 [INFO]: Epoch 078 - generator training loss: -0.0417, discriminator training loss: 0.1454, validation loss: 0.1099
2024-05-25 05:49:06 [INFO]: Epoch 079 - generator training loss: -0.0412, discriminator training loss: 0.1446, validation loss: 0.1100
2024-05-25 05:49:10 [INFO]: Epoch 080 - generator training loss: -0.0414, discriminator training loss: 0.1442, validation loss: 0.1096
2024-05-25 05:49:15 [INFO]: Epoch 081 - generator training loss: -0.0409, discriminator training loss: 0.1439, validation loss: 0.1095
2024-05-25 05:49:19 [INFO]: Epoch 082 - generator training loss: -0.0421, discriminator training loss: 0.1436, validation loss: 0.1085
2024-05-25 05:49:23 [INFO]: Epoch 083 - generator training loss: -0.0423, discriminator training loss: 0.1433, validation loss: 0.1084
2024-05-25 05:49:27 [INFO]: Epoch 084 - generator training loss: -0.0413, discriminator training loss: 0.1428, validation loss: 0.1085
2024-05-25 05:49:32 [INFO]: Epoch 085 - generator training loss: -0.0425, discriminator training loss: 0.1429, validation loss: 0.1085
2024-05-25 05:49:36 [INFO]: Epoch 086 - generator training loss: -0.0415, discriminator training loss: 0.1425, validation loss: 0.1081
2024-05-25 05:49:41 [INFO]: Epoch 087 - generator training loss: -0.0410, discriminator training loss: 0.1416, validation loss: 0.1082
2024-05-25 05:49:45 [INFO]: Epoch 088 - generator training loss: -0.0416, discriminator training loss: 0.1416, validation loss: 0.1084
2024-05-25 05:49:49 [INFO]: Epoch 089 - generator training loss: -0.0420, discriminator training loss: 0.1414, validation loss: 0.1079
2024-05-25 05:49:54 [INFO]: Epoch 090 - generator training loss: -0.0424, discriminator training loss: 0.1408, validation loss: 0.1070
2024-05-25 05:49:58 [INFO]: Epoch 091 - generator training loss: -0.0415, discriminator training loss: 0.1405, validation loss: 0.1077
2024-05-25 05:50:02 [INFO]: Epoch 092 - generator training loss: -0.0419, discriminator training loss: 0.1405, validation loss: 0.1075
2024-05-25 05:50:06 [INFO]: Epoch 093 - generator training loss: -0.0418, discriminator training loss: 0.1403, validation loss: 0.1063
2024-05-25 05:50:11 [INFO]: Epoch 094 - generator training loss: -0.0419, discriminator training loss: 0.1401, validation loss: 0.1078
2024-05-25 05:50:15 [INFO]: Epoch 095 - generator training loss: -0.0419, discriminator training loss: 0.1394, validation loss: 0.1076
2024-05-25 05:50:19 [INFO]: Epoch 096 - generator training loss: -0.0421, discriminator training loss: 0.1388, validation loss: 0.1063
2024-05-25 05:50:24 [INFO]: Epoch 097 - generator training loss: -0.0428, discriminator training loss: 0.1390, validation loss: 0.1070
2024-05-25 05:50:28 [INFO]: Epoch 098 - generator training loss: -0.0433, discriminator training loss: 0.1386, validation loss: 0.1058
2024-05-25 05:50:32 [INFO]: Epoch 099 - generator training loss: -0.0423, discriminator training loss: 0.1387, validation loss: 0.1064
2024-05-25 05:50:36 [INFO]: Epoch 100 - generator training loss: -0.0425, discriminator training loss: 0.1384, validation loss: 0.1059
2024-05-25 05:50:41 [INFO]: Epoch 101 - generator training loss: -0.0429, discriminator training loss: 0.1379, validation loss: 0.1052
2024-05-25 05:50:45 [INFO]: Epoch 102 - generator training loss: -0.0428, discriminator training loss: 0.1381, validation loss: 0.1050
2024-05-25 05:50:49 [INFO]: Epoch 103 - generator training loss: -0.0432, discriminator training loss: 0.1378, validation loss: 0.1060
2024-05-25 05:50:54 [INFO]: Epoch 104 - generator training loss: -0.0428, discriminator training loss: 0.1378, validation loss: 0.1058
2024-05-25 05:50:58 [INFO]: Epoch 105 - generator training loss: -0.0431, discriminator training loss: 0.1376, validation loss: 0.1063
2024-05-25 05:51:02 [INFO]: Epoch 106 - generator training loss: -0.0430, discriminator training loss: 0.1369, validation loss: 0.1060
2024-05-25 05:51:07 [INFO]: Epoch 107 - generator training loss: -0.0404, discriminator training loss: 0.1368, validation loss: 0.1103
2024-05-25 05:51:11 [INFO]: Epoch 108 - generator training loss: -0.0359, discriminator training loss: 0.1365, validation loss: 0.1069
2024-05-25 05:51:15 [INFO]: Epoch 109 - generator training loss: -0.0400, discriminator training loss: 0.1359, validation loss: 0.1054
2024-05-25 05:51:20 [INFO]: Epoch 110 - generator training loss: -0.0411, discriminator training loss: 0.1362, validation loss: 0.1045
2024-05-25 05:51:24 [INFO]: Epoch 111 - generator training loss: -0.0422, discriminator training loss: 0.1364, validation loss: 0.1048
2024-05-25 05:51:28 [INFO]: Epoch 112 - generator training loss: -0.0414, discriminator training loss: 0.1358, validation loss: 0.1044
2024-05-25 05:51:32 [INFO]: Epoch 113 - generator training loss: -0.0425, discriminator training loss: 0.1356, validation loss: 0.1048
2024-05-25 05:51:37 [INFO]: Epoch 114 - generator training loss: -0.0434, discriminator training loss: 0.1356, validation loss: 0.1048
2024-05-25 05:51:41 [INFO]: Epoch 115 - generator training loss: -0.0436, discriminator training loss: 0.1362, validation loss: 0.1039
2024-05-25 05:51:45 [INFO]: Epoch 116 - generator training loss: -0.0438, discriminator training loss: 0.1354, validation loss: 0.1039
2024-05-25 05:51:50 [INFO]: Epoch 117 - generator training loss: -0.0431, discriminator training loss: 0.1351, validation loss: 0.1036
2024-05-25 05:51:54 [INFO]: Epoch 118 - generator training loss: -0.0437, discriminator training loss: 0.1347, validation loss: 0.1047
2024-05-25 05:51:58 [INFO]: Epoch 119 - generator training loss: -0.0438, discriminator training loss: 0.1349, validation loss: 0.1042
2024-05-25 05:52:03 [INFO]: Epoch 120 - generator training loss: -0.0442, discriminator training loss: 0.1346, validation loss: 0.1041
2024-05-25 05:52:07 [INFO]: Epoch 121 - generator training loss: -0.0440, discriminator training loss: 0.1345, validation loss: 0.1042
2024-05-25 05:52:11 [INFO]: Epoch 122 - generator training loss: -0.0439, discriminator training loss: 0.1345, validation loss: 0.1051
2024-05-25 05:52:16 [INFO]: Epoch 123 - generator training loss: -0.0440, discriminator training loss: 0.1343, validation loss: 0.1058
2024-05-25 05:52:20 [INFO]: Epoch 124 - generator training loss: -0.0444, discriminator training loss: 0.1343, validation loss: 0.1054
2024-05-25 05:52:24 [INFO]: Epoch 125 - generator training loss: -0.0446, discriminator training loss: 0.1340, validation loss: 0.1049
2024-05-25 05:52:29 [INFO]: Epoch 126 - generator training loss: -0.0435, discriminator training loss: 0.1341, validation loss: 0.1047
2024-05-25 05:52:33 [INFO]: Epoch 127 - generator training loss: -0.0449, discriminator training loss: 0.1338, validation loss: 0.1039
2024-05-25 05:52:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:52:33 [INFO]: Finished training. The best model is from epoch#117.
2024-05-25 05:52:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/USGAN_air_quality/20240525_T054325/USGAN.pypots
2024-05-25 05:52:34 [INFO]: US-GAN on Air-Quality: MAE=0.1454, MSE=0.1710
2024-05-25 05:52:34 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/USGAN_air_quality/imputation.pkl
2024-05-25 05:52:34 [INFO]: Using the given device: cuda:0
2024-05-25 05:52:34 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/BRITS_air_quality/20240525_T055234
2024-05-25 05:52:34 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/BRITS_air_quality/20240525_T055234/tensorboard
2024-05-25 05:52:34 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 05:52:37 [INFO]: Epoch 001 - training loss: 1.4159, validation loss: 0.9132
2024-05-25 05:52:40 [INFO]: Epoch 002 - training loss: 1.1394, validation loss: 0.6730
2024-05-25 05:52:43 [INFO]: Epoch 003 - training loss: 0.9510, validation loss: 0.5734
2024-05-25 05:52:46 [INFO]: Epoch 004 - training loss: 0.8414, validation loss: 0.5078
2024-05-25 05:52:49 [INFO]: Epoch 005 - training loss: 0.7684, validation loss: 0.4635
2024-05-25 05:52:52 [INFO]: Epoch 006 - training loss: 0.7103, validation loss: 0.4294
2024-05-25 05:52:55 [INFO]: Epoch 007 - training loss: 0.6654, validation loss: 0.4011
2024-05-25 05:52:58 [INFO]: Epoch 008 - training loss: 0.6313, validation loss: 0.3790
2024-05-25 05:53:01 [INFO]: Epoch 009 - training loss: 0.6053, validation loss: 0.3608
2024-05-25 05:53:04 [INFO]: Epoch 010 - training loss: 0.5817, validation loss: 0.3439
2024-05-25 05:53:06 [INFO]: Epoch 011 - training loss: 0.5656, validation loss: 0.3312
2024-05-25 05:53:09 [INFO]: Epoch 012 - training loss: 0.5489, validation loss: 0.3200
2024-05-25 05:53:12 [INFO]: Epoch 013 - training loss: 0.5350, validation loss: 0.3104
2024-05-25 05:53:15 [INFO]: Epoch 014 - training loss: 0.5253, validation loss: 0.3026
2024-05-25 05:53:18 [INFO]: Epoch 015 - training loss: 0.5138, validation loss: 0.2949
2024-05-25 05:53:21 [INFO]: Epoch 016 - training loss: 0.5045, validation loss: 0.2883
2024-05-25 05:53:24 [INFO]: Epoch 017 - training loss: 0.4951, validation loss: 0.2824
2024-05-25 05:53:27 [INFO]: Epoch 018 - training loss: 0.4872, validation loss: 0.2771
2024-05-25 05:53:30 [INFO]: Epoch 019 - training loss: 0.4784, validation loss: 0.2720
2024-05-25 05:53:33 [INFO]: Epoch 020 - training loss: 0.4717, validation loss: 0.2662
2024-05-25 05:53:36 [INFO]: Epoch 021 - training loss: 0.4641, validation loss: 0.2620
2024-05-25 05:53:38 [INFO]: Epoch 022 - training loss: 0.4579, validation loss: 0.2576
2024-05-25 05:53:41 [INFO]: Epoch 023 - training loss: 0.4510, validation loss: 0.2531
2024-05-25 05:53:44 [INFO]: Epoch 024 - training loss: 0.4450, validation loss: 0.2490
2024-05-25 05:53:47 [INFO]: Epoch 025 - training loss: 0.4390, validation loss: 0.2450
2024-05-25 05:53:50 [INFO]: Epoch 026 - training loss: 0.4350, validation loss: 0.2410
2024-05-25 05:53:53 [INFO]: Epoch 027 - training loss: 0.4282, validation loss: 0.2369
2024-05-25 05:53:56 [INFO]: Epoch 028 - training loss: 0.4235, validation loss: 0.2337
2024-05-25 05:53:59 [INFO]: Epoch 029 - training loss: 0.4193, validation loss: 0.2300
2024-05-25 05:54:02 [INFO]: Epoch 030 - training loss: 0.4139, validation loss: 0.2268
2024-05-25 05:54:05 [INFO]: Epoch 031 - training loss: 0.4100, validation loss: 0.2226
2024-05-25 05:54:08 [INFO]: Epoch 032 - training loss: 0.4046, validation loss: 0.2195
2024-05-25 05:54:10 [INFO]: Epoch 033 - training loss: 0.4002, validation loss: 0.2160
2024-05-25 05:54:13 [INFO]: Epoch 034 - training loss: 0.3964, validation loss: 0.2124
2024-05-25 05:54:16 [INFO]: Epoch 035 - training loss: 0.3924, validation loss: 0.2092
2024-05-25 05:54:19 [INFO]: Epoch 036 - training loss: 0.3889, validation loss: 0.2063
2024-05-25 05:54:22 [INFO]: Epoch 037 - training loss: 0.3857, validation loss: 0.2026
2024-05-25 05:54:25 [INFO]: Epoch 038 - training loss: 0.3820, validation loss: 0.2000
2024-05-25 05:54:28 [INFO]: Epoch 039 - training loss: 0.3783, validation loss: 0.1972
2024-05-25 05:54:31 [INFO]: Epoch 040 - training loss: 0.3750, validation loss: 0.1940
2024-05-25 05:54:34 [INFO]: Epoch 041 - training loss: 0.3721, validation loss: 0.1913
2024-05-25 05:54:37 [INFO]: Epoch 042 - training loss: 0.3689, validation loss: 0.1888
2024-05-25 05:54:40 [INFO]: Epoch 043 - training loss: 0.3668, validation loss: 0.1861
2024-05-25 05:54:42 [INFO]: Epoch 044 - training loss: 0.3637, validation loss: 0.1837
2024-05-25 05:54:45 [INFO]: Epoch 045 - training loss: 0.3609, validation loss: 0.1813
2024-05-25 05:54:48 [INFO]: Epoch 046 - training loss: 0.3586, validation loss: 0.1792
2024-05-25 05:54:51 [INFO]: Epoch 047 - training loss: 0.3559, validation loss: 0.1780
2024-05-25 05:54:54 [INFO]: Epoch 048 - training loss: 0.3532, validation loss: 0.1754
2024-05-25 05:54:57 [INFO]: Epoch 049 - training loss: 0.3508, validation loss: 0.1737
2024-05-25 05:55:00 [INFO]: Epoch 050 - training loss: 0.3474, validation loss: 0.1719
2024-05-25 05:55:03 [INFO]: Epoch 051 - training loss: 0.3456, validation loss: 0.1704
2024-05-25 05:55:06 [INFO]: Epoch 052 - training loss: 0.3435, validation loss: 0.1688
2024-05-25 05:55:08 [INFO]: Epoch 053 - training loss: 0.3413, validation loss: 0.1671
2024-05-25 05:55:11 [INFO]: Epoch 054 - training loss: 0.3394, validation loss: 0.1659
2024-05-25 05:55:14 [INFO]: Epoch 055 - training loss: 0.3377, validation loss: 0.1648
2024-05-25 05:55:17 [INFO]: Epoch 056 - training loss: 0.3361, validation loss: 0.1631
2024-05-25 05:55:20 [INFO]: Epoch 057 - training loss: 0.3338, validation loss: 0.1616
2024-05-25 05:55:23 [INFO]: Epoch 058 - training loss: 0.3319, validation loss: 0.1606
2024-05-25 05:55:26 [INFO]: Epoch 059 - training loss: 0.3301, validation loss: 0.1595
2024-05-25 05:55:29 [INFO]: Epoch 060 - training loss: 0.3285, validation loss: 0.1587
2024-05-25 05:55:32 [INFO]: Epoch 061 - training loss: 0.3272, validation loss: 0.1574
2024-05-25 05:55:35 [INFO]: Epoch 062 - training loss: 0.3257, validation loss: 0.1566
2024-05-25 05:55:38 [INFO]: Epoch 063 - training loss: 0.3246, validation loss: 0.1554
2024-05-25 05:55:40 [INFO]: Epoch 064 - training loss: 0.3223, validation loss: 0.1547
2024-05-25 05:55:43 [INFO]: Epoch 065 - training loss: 0.3213, validation loss: 0.1539
2024-05-25 05:55:46 [INFO]: Epoch 066 - training loss: 0.3195, validation loss: 0.1532
2024-05-25 05:55:49 [INFO]: Epoch 067 - training loss: 0.3182, validation loss: 0.1523
2024-05-25 05:55:52 [INFO]: Epoch 068 - training loss: 0.3172, validation loss: 0.1517
2024-05-25 05:55:55 [INFO]: Epoch 069 - training loss: 0.3161, validation loss: 0.1511
2024-05-25 05:55:58 [INFO]: Epoch 070 - training loss: 0.3138, validation loss: 0.1502
2024-05-25 05:56:01 [INFO]: Epoch 071 - training loss: 0.3135, validation loss: 0.1496
2024-05-25 05:56:04 [INFO]: Epoch 072 - training loss: 0.3116, validation loss: 0.1488
2024-05-25 05:56:07 [INFO]: Epoch 073 - training loss: 0.3113, validation loss: 0.1483
2024-05-25 05:56:10 [INFO]: Epoch 074 - training loss: 0.3099, validation loss: 0.1478
2024-05-25 05:56:12 [INFO]: Epoch 075 - training loss: 0.3098, validation loss: 0.1472
2024-05-25 05:56:15 [INFO]: Epoch 076 - training loss: 0.3083, validation loss: 0.1469
2024-05-25 05:56:18 [INFO]: Epoch 077 - training loss: 0.3072, validation loss: 0.1461
2024-05-25 05:56:21 [INFO]: Epoch 078 - training loss: 0.3059, validation loss: 0.1455
2024-05-25 05:56:24 [INFO]: Epoch 079 - training loss: 0.3047, validation loss: 0.1451
2024-05-25 05:56:27 [INFO]: Epoch 080 - training loss: 0.3045, validation loss: 0.1446
2024-05-25 05:56:30 [INFO]: Epoch 081 - training loss: 0.3024, validation loss: 0.1441
2024-05-25 05:56:33 [INFO]: Epoch 082 - training loss: 0.3015, validation loss: 0.1439
2024-05-25 05:56:36 [INFO]: Epoch 083 - training loss: 0.3010, validation loss: 0.1432
2024-05-25 05:56:39 [INFO]: Epoch 084 - training loss: 0.3000, validation loss: 0.1428
2024-05-25 05:56:41 [INFO]: Epoch 085 - training loss: 0.2991, validation loss: 0.1423
2024-05-25 05:56:44 [INFO]: Epoch 086 - training loss: 0.2986, validation loss: 0.1419
2024-05-25 05:56:47 [INFO]: Epoch 087 - training loss: 0.2974, validation loss: 0.1414
2024-05-25 05:56:50 [INFO]: Epoch 088 - training loss: 0.2975, validation loss: 0.1412
2024-05-25 05:56:53 [INFO]: Epoch 089 - training loss: 0.2956, validation loss: 0.1406
2024-05-25 05:56:56 [INFO]: Epoch 090 - training loss: 0.2953, validation loss: 0.1403
2024-05-25 05:56:59 [INFO]: Epoch 091 - training loss: 0.2944, validation loss: 0.1401
2024-05-25 05:57:02 [INFO]: Epoch 092 - training loss: 0.2943, validation loss: 0.1395
2024-05-25 05:57:05 [INFO]: Epoch 093 - training loss: 0.2927, validation loss: 0.1392
2024-05-25 05:57:08 [INFO]: Epoch 094 - training loss: 0.2925, validation loss: 0.1389
2024-05-25 05:57:10 [INFO]: Epoch 095 - training loss: 0.2914, validation loss: 0.1383
2024-05-25 05:57:13 [INFO]: Epoch 096 - training loss: 0.2915, validation loss: 0.1381
2024-05-25 05:57:16 [INFO]: Epoch 097 - training loss: 0.2902, validation loss: 0.1375
2024-05-25 05:57:19 [INFO]: Epoch 098 - training loss: 0.2895, validation loss: 0.1375
2024-05-25 05:57:22 [INFO]: Epoch 099 - training loss: 0.2894, validation loss: 0.1370
2024-05-25 05:57:25 [INFO]: Epoch 100 - training loss: 0.2879, validation loss: 0.1367
2024-05-25 05:57:27 [INFO]: Epoch 101 - training loss: 0.2872, validation loss: 0.1363
2024-05-25 05:57:30 [INFO]: Epoch 102 - training loss: 0.2873, validation loss: 0.1361
2024-05-25 05:57:33 [INFO]: Epoch 103 - training loss: 0.2864, validation loss: 0.1358
2024-05-25 05:57:36 [INFO]: Epoch 104 - training loss: 0.2859, validation loss: 0.1354
2024-05-25 05:57:39 [INFO]: Epoch 105 - training loss: 0.2854, validation loss: 0.1350
2024-05-25 05:57:42 [INFO]: Epoch 106 - training loss: 0.2845, validation loss: 0.1347
2024-05-25 05:57:45 [INFO]: Epoch 107 - training loss: 0.2834, validation loss: 0.1347
2024-05-25 05:57:48 [INFO]: Epoch 108 - training loss: 0.2837, validation loss: 0.1341
2024-05-25 05:57:51 [INFO]: Epoch 109 - training loss: 0.2831, validation loss: 0.1340
2024-05-25 05:57:54 [INFO]: Epoch 110 - training loss: 0.2828, validation loss: 0.1335
2024-05-25 05:57:57 [INFO]: Epoch 111 - training loss: 0.2812, validation loss: 0.1331
2024-05-25 05:57:59 [INFO]: Epoch 112 - training loss: 0.2813, validation loss: 0.1327
2024-05-25 05:58:02 [INFO]: Epoch 113 - training loss: 0.2804, validation loss: 0.1327
2024-05-25 05:58:05 [INFO]: Epoch 114 - training loss: 0.2798, validation loss: 0.1323
2024-05-25 05:58:08 [INFO]: Epoch 115 - training loss: 0.2796, validation loss: 0.1320
2024-05-25 05:58:11 [INFO]: Epoch 116 - training loss: 0.2797, validation loss: 0.1318
2024-05-25 05:58:14 [INFO]: Epoch 117 - training loss: 0.2791, validation loss: 0.1312
2024-05-25 05:58:17 [INFO]: Epoch 118 - training loss: 0.2784, validation loss: 0.1311
2024-05-25 05:58:20 [INFO]: Epoch 119 - training loss: 0.2772, validation loss: 0.1309
2024-05-25 05:58:23 [INFO]: Epoch 120 - training loss: 0.2769, validation loss: 0.1304
2024-05-25 05:58:26 [INFO]: Epoch 121 - training loss: 0.2770, validation loss: 0.1301
2024-05-25 05:58:29 [INFO]: Epoch 122 - training loss: 0.2763, validation loss: 0.1298
2024-05-25 05:58:31 [INFO]: Epoch 123 - training loss: 0.2758, validation loss: 0.1296
2024-05-25 05:58:34 [INFO]: Epoch 124 - training loss: 0.2761, validation loss: 0.1292
2024-05-25 05:58:37 [INFO]: Epoch 125 - training loss: 0.2750, validation loss: 0.1291
2024-05-25 05:58:40 [INFO]: Epoch 126 - training loss: 0.2749, validation loss: 0.1288
2024-05-25 05:58:43 [INFO]: Epoch 127 - training loss: 0.2739, validation loss: 0.1288
2024-05-25 05:58:46 [INFO]: Epoch 128 - training loss: 0.2734, validation loss: 0.1284
2024-05-25 05:58:49 [INFO]: Epoch 129 - training loss: 0.2734, validation loss: 0.1279
2024-05-25 05:58:52 [INFO]: Epoch 130 - training loss: 0.2722, validation loss: 0.1277
2024-05-25 05:58:55 [INFO]: Epoch 131 - training loss: 0.2722, validation loss: 0.1274
2024-05-25 05:58:58 [INFO]: Epoch 132 - training loss: 0.2713, validation loss: 0.1274
2024-05-25 05:59:00 [INFO]: Epoch 133 - training loss: 0.2712, validation loss: 0.1269
2024-05-25 05:59:03 [INFO]: Epoch 134 - training loss: 0.2710, validation loss: 0.1268
2024-05-25 05:59:06 [INFO]: Epoch 135 - training loss: 0.2701, validation loss: 0.1264
2024-05-25 05:59:09 [INFO]: Epoch 136 - training loss: 0.2692, validation loss: 0.1260
2024-05-25 05:59:12 [INFO]: Epoch 137 - training loss: 0.2695, validation loss: 0.1258
2024-05-25 05:59:15 [INFO]: Epoch 138 - training loss: 0.2691, validation loss: 0.1257
2024-05-25 05:59:18 [INFO]: Epoch 139 - training loss: 0.2686, validation loss: 0.1253
2024-05-25 05:59:21 [INFO]: Epoch 140 - training loss: 0.2683, validation loss: 0.1252
2024-05-25 05:59:24 [INFO]: Epoch 141 - training loss: 0.2682, validation loss: 0.1249
2024-05-25 05:59:27 [INFO]: Epoch 142 - training loss: 0.2678, validation loss: 0.1246
2024-05-25 05:59:29 [INFO]: Epoch 143 - training loss: 0.2669, validation loss: 0.1244
2024-05-25 05:59:32 [INFO]: Epoch 144 - training loss: 0.2676, validation loss: 0.1241
2024-05-25 05:59:35 [INFO]: Epoch 145 - training loss: 0.2666, validation loss: 0.1240
2024-05-25 05:59:38 [INFO]: Epoch 146 - training loss: 0.2661, validation loss: 0.1236
2024-05-25 05:59:41 [INFO]: Epoch 147 - training loss: 0.2658, validation loss: 0.1236
2024-05-25 05:59:44 [INFO]: Epoch 148 - training loss: 0.2655, validation loss: 0.1234
2024-05-25 05:59:47 [INFO]: Epoch 149 - training loss: 0.2653, validation loss: 0.1230
2024-05-25 05:59:50 [INFO]: Epoch 150 - training loss: 0.2649, validation loss: 0.1229
2024-05-25 05:59:53 [INFO]: Epoch 151 - training loss: 0.2639, validation loss: 0.1227
2024-05-25 05:59:56 [INFO]: Epoch 152 - training loss: 0.2636, validation loss: 0.1225
2024-05-25 05:59:59 [INFO]: Epoch 153 - training loss: 0.2639, validation loss: 0.1220
2024-05-25 06:00:01 [INFO]: Epoch 154 - training loss: 0.2633, validation loss: 0.1222
2024-05-25 06:00:04 [INFO]: Epoch 155 - training loss: 0.2628, validation loss: 0.1219
2024-05-25 06:00:07 [INFO]: Epoch 156 - training loss: 0.2623, validation loss: 0.1215
2024-05-25 06:00:10 [INFO]: Epoch 157 - training loss: 0.2629, validation loss: 0.1215
2024-05-25 06:00:13 [INFO]: Epoch 158 - training loss: 0.2618, validation loss: 0.1215
2024-05-25 06:00:16 [INFO]: Epoch 159 - training loss: 0.2617, validation loss: 0.1210
2024-05-25 06:00:19 [INFO]: Epoch 160 - training loss: 0.2615, validation loss: 0.1211
2024-05-25 06:00:22 [INFO]: Epoch 161 - training loss: 0.2610, validation loss: 0.1207
2024-05-25 06:00:25 [INFO]: Epoch 162 - training loss: 0.2609, validation loss: 0.1205
2024-05-25 06:00:28 [INFO]: Epoch 163 - training loss: 0.2607, validation loss: 0.1203
2024-05-25 06:00:31 [INFO]: Epoch 164 - training loss: 0.2600, validation loss: 0.1200
2024-05-25 06:00:33 [INFO]: Epoch 165 - training loss: 0.2602, validation loss: 0.1199
2024-05-25 06:00:36 [INFO]: Epoch 166 - training loss: 0.2598, validation loss: 0.1198
2024-05-25 06:00:39 [INFO]: Epoch 167 - training loss: 0.2591, validation loss: 0.1194
2024-05-25 06:00:42 [INFO]: Epoch 168 - training loss: 0.2592, validation loss: 0.1195
2024-05-25 06:00:45 [INFO]: Epoch 169 - training loss: 0.2592, validation loss: 0.1192
2024-05-25 06:00:48 [INFO]: Epoch 170 - training loss: 0.2584, validation loss: 0.1191
2024-05-25 06:00:51 [INFO]: Epoch 171 - training loss: 0.2579, validation loss: 0.1189
2024-05-25 06:00:54 [INFO]: Epoch 172 - training loss: 0.2582, validation loss: 0.1189
2024-05-25 06:00:57 [INFO]: Epoch 173 - training loss: 0.2572, validation loss: 0.1186
2024-05-25 06:01:00 [INFO]: Epoch 174 - training loss: 0.2577, validation loss: 0.1184
2024-05-25 06:01:02 [INFO]: Epoch 175 - training loss: 0.2570, validation loss: 0.1184
2024-05-25 06:01:05 [INFO]: Epoch 176 - training loss: 0.2566, validation loss: 0.1182
2024-05-25 06:01:08 [INFO]: Epoch 177 - training loss: 0.2570, validation loss: 0.1179
2024-05-25 06:01:11 [INFO]: Epoch 178 - training loss: 0.2560, validation loss: 0.1178
2024-05-25 06:01:14 [INFO]: Epoch 179 - training loss: 0.2557, validation loss: 0.1176
2024-05-25 06:01:17 [INFO]: Epoch 180 - training loss: 0.2565, validation loss: 0.1173
2024-05-25 06:01:20 [INFO]: Epoch 181 - training loss: 0.2554, validation loss: 0.1175
2024-05-25 06:01:23 [INFO]: Epoch 182 - training loss: 0.2555, validation loss: 0.1174
2024-05-25 06:01:26 [INFO]: Epoch 183 - training loss: 0.2550, validation loss: 0.1171
2024-05-25 06:01:29 [INFO]: Epoch 184 - training loss: 0.2549, validation loss: 0.1170
2024-05-25 06:01:32 [INFO]: Epoch 185 - training loss: 0.2549, validation loss: 0.1170
2024-05-25 06:01:34 [INFO]: Epoch 186 - training loss: 0.2541, validation loss: 0.1167
2024-05-25 06:01:37 [INFO]: Epoch 187 - training loss: 0.2541, validation loss: 0.1165
2024-05-25 06:01:40 [INFO]: Epoch 188 - training loss: 0.2544, validation loss: 0.1165
2024-05-25 06:01:43 [INFO]: Epoch 189 - training loss: 0.2535, validation loss: 0.1162
2024-05-25 06:01:46 [INFO]: Epoch 190 - training loss: 0.2534, validation loss: 0.1162
2024-05-25 06:01:49 [INFO]: Epoch 191 - training loss: 0.2533, validation loss: 0.1160
2024-05-25 06:01:52 [INFO]: Epoch 192 - training loss: 0.2526, validation loss: 0.1159
2024-05-25 06:01:55 [INFO]: Epoch 193 - training loss: 0.2525, validation loss: 0.1157
2024-05-25 06:01:58 [INFO]: Epoch 194 - training loss: 0.2523, validation loss: 0.1157
2024-05-25 06:02:01 [INFO]: Epoch 195 - training loss: 0.2529, validation loss: 0.1153
2024-05-25 06:02:03 [INFO]: Epoch 196 - training loss: 0.2525, validation loss: 0.1152
2024-05-25 06:02:06 [INFO]: Epoch 197 - training loss: 0.2523, validation loss: 0.1153
2024-05-25 06:02:09 [INFO]: Epoch 198 - training loss: 0.2518, validation loss: 0.1153
2024-05-25 06:02:12 [INFO]: Epoch 199 - training loss: 0.2516, validation loss: 0.1150
2024-05-25 06:02:15 [INFO]: Epoch 200 - training loss: 0.2512, validation loss: 0.1148
2024-05-25 06:02:18 [INFO]: Epoch 201 - training loss: 0.2510, validation loss: 0.1148
2024-05-25 06:02:21 [INFO]: Epoch 202 - training loss: 0.2504, validation loss: 0.1147
2024-05-25 06:02:24 [INFO]: Epoch 203 - training loss: 0.2509, validation loss: 0.1145
2024-05-25 06:02:27 [INFO]: Epoch 204 - training loss: 0.2500, validation loss: 0.1145
2024-05-25 06:02:30 [INFO]: Epoch 205 - training loss: 0.2505, validation loss: 0.1144
2024-05-25 06:02:33 [INFO]: Epoch 206 - training loss: 0.2498, validation loss: 0.1141
2024-05-25 06:02:36 [INFO]: Epoch 207 - training loss: 0.2499, validation loss: 0.1141
2024-05-25 06:02:38 [INFO]: Epoch 208 - training loss: 0.2498, validation loss: 0.1140
2024-05-25 06:02:41 [INFO]: Epoch 209 - training loss: 0.2494, validation loss: 0.1142
2024-05-25 06:02:44 [INFO]: Epoch 210 - training loss: 0.2495, validation loss: 0.1137
2024-05-25 06:02:47 [INFO]: Epoch 211 - training loss: 0.2491, validation loss: 0.1137
2024-05-25 06:02:50 [INFO]: Epoch 212 - training loss: 0.2485, validation loss: 0.1136
2024-05-25 06:02:53 [INFO]: Epoch 213 - training loss: 0.2489, validation loss: 0.1134
2024-05-25 06:02:56 [INFO]: Epoch 214 - training loss: 0.2484, validation loss: 0.1135
2024-05-25 06:02:59 [INFO]: Epoch 215 - training loss: 0.2484, validation loss: 0.1134
2024-05-25 06:03:02 [INFO]: Epoch 216 - training loss: 0.2479, validation loss: 0.1133
2024-05-25 06:03:04 [INFO]: Epoch 217 - training loss: 0.2477, validation loss: 0.1130
2024-05-25 06:03:07 [INFO]: Epoch 218 - training loss: 0.2476, validation loss: 0.1130
2024-05-25 06:03:10 [INFO]: Epoch 219 - training loss: 0.2473, validation loss: 0.1129
2024-05-25 06:03:13 [INFO]: Epoch 220 - training loss: 0.2473, validation loss: 0.1128
2024-05-25 06:03:16 [INFO]: Epoch 221 - training loss: 0.2465, validation loss: 0.1126
2024-05-25 06:03:19 [INFO]: Epoch 222 - training loss: 0.2465, validation loss: 0.1127
2024-05-25 06:03:22 [INFO]: Epoch 223 - training loss: 0.2467, validation loss: 0.1126
2024-05-25 06:03:25 [INFO]: Epoch 224 - training loss: 0.2462, validation loss: 0.1125
2024-05-25 06:03:28 [INFO]: Epoch 225 - training loss: 0.2466, validation loss: 0.1125
2024-05-25 06:03:31 [INFO]: Epoch 226 - training loss: 0.2462, validation loss: 0.1122
2024-05-25 06:03:34 [INFO]: Epoch 227 - training loss: 0.2461, validation loss: 0.1120
2024-05-25 06:03:36 [INFO]: Epoch 228 - training loss: 0.2455, validation loss: 0.1120
2024-05-25 06:03:39 [INFO]: Epoch 229 - training loss: 0.2455, validation loss: 0.1120
2024-05-25 06:03:42 [INFO]: Epoch 230 - training loss: 0.2453, validation loss: 0.1120
2024-05-25 06:03:45 [INFO]: Epoch 231 - training loss: 0.2457, validation loss: 0.1118
2024-05-25 06:03:48 [INFO]: Epoch 232 - training loss: 0.2452, validation loss: 0.1117
2024-05-25 06:03:51 [INFO]: Epoch 233 - training loss: 0.2454, validation loss: 0.1117
2024-05-25 06:03:54 [INFO]: Epoch 234 - training loss: 0.2444, validation loss: 0.1116
2024-05-25 06:03:57 [INFO]: Epoch 235 - training loss: 0.2445, validation loss: 0.1116
2024-05-25 06:04:00 [INFO]: Epoch 236 - training loss: 0.2452, validation loss: 0.1115
2024-05-25 06:04:03 [INFO]: Epoch 237 - training loss: 0.2444, validation loss: 0.1115
2024-05-25 06:04:05 [INFO]: Epoch 238 - training loss: 0.2447, validation loss: 0.1114
2024-05-25 06:04:08 [INFO]: Epoch 239 - training loss: 0.2441, validation loss: 0.1115
2024-05-25 06:04:11 [INFO]: Epoch 240 - training loss: 0.2440, validation loss: 0.1113
2024-05-25 06:04:14 [INFO]: Epoch 241 - training loss: 0.2434, validation loss: 0.1111
2024-05-25 06:04:17 [INFO]: Epoch 242 - training loss: 0.2438, validation loss: 0.1109
2024-05-25 06:04:20 [INFO]: Epoch 243 - training loss: 0.2441, validation loss: 0.1108
2024-05-25 06:04:23 [INFO]: Epoch 244 - training loss: 0.2431, validation loss: 0.1112
2024-05-25 06:04:26 [INFO]: Epoch 245 - training loss: 0.2432, validation loss: 0.1109
2024-05-25 06:04:29 [INFO]: Epoch 246 - training loss: 0.2431, validation loss: 0.1110
2024-05-25 06:04:32 [INFO]: Epoch 247 - training loss: 0.2424, validation loss: 0.1108
2024-05-25 06:04:34 [INFO]: Epoch 248 - training loss: 0.2425, validation loss: 0.1108
2024-05-25 06:04:37 [INFO]: Epoch 249 - training loss: 0.2419, validation loss: 0.1106
2024-05-25 06:04:40 [INFO]: Epoch 250 - training loss: 0.2423, validation loss: 0.1107
2024-05-25 06:04:43 [INFO]: Epoch 251 - training loss: 0.2423, validation loss: 0.1106
2024-05-25 06:04:46 [INFO]: Epoch 252 - training loss: 0.2420, validation loss: 0.1108
2024-05-25 06:04:49 [INFO]: Epoch 253 - training loss: 0.2417, validation loss: 0.1103
2024-05-25 06:04:52 [INFO]: Epoch 254 - training loss: 0.2414, validation loss: 0.1106
2024-05-25 06:04:55 [INFO]: Epoch 255 - training loss: 0.2416, validation loss: 0.1103
2024-05-25 06:04:57 [INFO]: Epoch 256 - training loss: 0.2416, validation loss: 0.1101
2024-05-25 06:05:00 [INFO]: Epoch 257 - training loss: 0.2409, validation loss: 0.1102
2024-05-25 06:05:03 [INFO]: Epoch 258 - training loss: 0.2407, validation loss: 0.1102
2024-05-25 06:05:06 [INFO]: Epoch 259 - training loss: 0.2405, validation loss: 0.1101
2024-05-25 06:05:09 [INFO]: Epoch 260 - training loss: 0.2407, validation loss: 0.1102
2024-05-25 06:05:12 [INFO]: Epoch 261 - training loss: 0.2402, validation loss: 0.1098
2024-05-25 06:05:15 [INFO]: Epoch 262 - training loss: 0.2402, validation loss: 0.1099
2024-05-25 06:05:18 [INFO]: Epoch 263 - training loss: 0.2400, validation loss: 0.1099
2024-05-25 06:05:21 [INFO]: Epoch 264 - training loss: 0.2402, validation loss: 0.1098
2024-05-25 06:05:24 [INFO]: Epoch 265 - training loss: 0.2401, validation loss: 0.1100
2024-05-25 06:05:26 [INFO]: Epoch 266 - training loss: 0.2397, validation loss: 0.1099
2024-05-25 06:05:29 [INFO]: Epoch 267 - training loss: 0.2396, validation loss: 0.1097
2024-05-25 06:05:32 [INFO]: Epoch 268 - training loss: 0.2396, validation loss: 0.1097
2024-05-25 06:05:35 [INFO]: Epoch 269 - training loss: 0.2400, validation loss: 0.1096
2024-05-25 06:05:38 [INFO]: Epoch 270 - training loss: 0.2394, validation loss: 0.1096
2024-05-25 06:05:41 [INFO]: Epoch 271 - training loss: 0.2392, validation loss: 0.1097
2024-05-25 06:05:44 [INFO]: Epoch 272 - training loss: 0.2396, validation loss: 0.1096
2024-05-25 06:05:47 [INFO]: Epoch 273 - training loss: 0.2387, validation loss: 0.1097
2024-05-25 06:05:50 [INFO]: Epoch 274 - training loss: 0.2385, validation loss: 0.1096
2024-05-25 06:05:53 [INFO]: Epoch 275 - training loss: 0.2386, validation loss: 0.1097
2024-05-25 06:05:56 [INFO]: Epoch 276 - training loss: 0.2387, validation loss: 0.1095
2024-05-25 06:05:58 [INFO]: Epoch 277 - training loss: 0.2378, validation loss: 0.1096
2024-05-25 06:06:01 [INFO]: Epoch 278 - training loss: 0.2381, validation loss: 0.1094
2024-05-25 06:06:04 [INFO]: Epoch 279 - training loss: 0.2381, validation loss: 0.1095
2024-05-25 06:06:07 [INFO]: Epoch 280 - training loss: 0.2381, validation loss: 0.1094
2024-05-25 06:06:10 [INFO]: Epoch 281 - training loss: 0.2382, validation loss: 0.1093
2024-05-25 06:06:13 [INFO]: Epoch 282 - training loss: 0.2378, validation loss: 0.1092
2024-05-25 06:06:16 [INFO]: Epoch 283 - training loss: 0.2373, validation loss: 0.1091
2024-05-25 06:06:19 [INFO]: Epoch 284 - training loss: 0.2377, validation loss: 0.1091
2024-05-25 06:06:22 [INFO]: Epoch 285 - training loss: 0.2374, validation loss: 0.1091
2024-05-25 06:06:25 [INFO]: Epoch 286 - training loss: 0.2377, validation loss: 0.1091
2024-05-25 06:06:27 [INFO]: Epoch 287 - training loss: 0.2374, validation loss: 0.1090
2024-05-25 06:06:30 [INFO]: Epoch 288 - training loss: 0.2370, validation loss: 0.1089
2024-05-25 06:06:33 [INFO]: Epoch 289 - training loss: 0.2365, validation loss: 0.1089
2024-05-25 06:06:36 [INFO]: Epoch 290 - training loss: 0.2368, validation loss: 0.1090
2024-05-25 06:06:39 [INFO]: Epoch 291 - training loss: 0.2370, validation loss: 0.1092
2024-05-25 06:06:42 [INFO]: Epoch 292 - training loss: 0.2370, validation loss: 0.1090
2024-05-25 06:06:45 [INFO]: Epoch 293 - training loss: 0.2365, validation loss: 0.1090
2024-05-25 06:06:48 [INFO]: Epoch 294 - training loss: 0.2364, validation loss: 0.1089
2024-05-25 06:06:51 [INFO]: Epoch 295 - training loss: 0.2363, validation loss: 0.1089
2024-05-25 06:06:54 [INFO]: Epoch 296 - training loss: 0.2362, validation loss: 0.1086
2024-05-25 06:06:57 [INFO]: Epoch 297 - training loss: 0.2361, validation loss: 0.1087
2024-05-25 06:06:59 [INFO]: Epoch 298 - training loss: 0.2367, validation loss: 0.1089
2024-05-25 06:07:02 [INFO]: Epoch 299 - training loss: 0.2364, validation loss: 0.1089
2024-05-25 06:07:05 [INFO]: Epoch 300 - training loss: 0.2356, validation loss: 0.1087
2024-05-25 06:07:05 [INFO]: Finished training. The best model is from epoch#296.
2024-05-25 06:07:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/BRITS_air_quality/20240525_T055234/BRITS.pypots
2024-05-25 06:07:06 [INFO]: BRITS on Air-Quality: MAE=0.1394, MSE=0.1889
2024-05-25 06:07:06 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/BRITS_air_quality/imputation.pkl
2024-05-25 06:07:06 [INFO]: Using the given device: cuda:0
2024-05-25 06:07:06 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706
2024-05-25 06:07:06 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/tensorboard
2024-05-25 06:07:06 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 06:07:11 [INFO]: Epoch 001 - training loss: 1.5073, validation loss: 0.8068
2024-05-25 06:07:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch1_loss0.806837797164917.pypots
2024-05-25 06:07:15 [INFO]: Epoch 002 - training loss: 1.0693, validation loss: 0.7438
2024-05-25 06:07:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch2_loss0.743820282816887.pypots
2024-05-25 06:07:19 [INFO]: Epoch 003 - training loss: 0.9909, validation loss: 0.7258
2024-05-25 06:07:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch3_loss0.7257903814315796.pypots
2024-05-25 06:07:23 [INFO]: Epoch 004 - training loss: 0.9476, validation loss: 0.7113
2024-05-25 06:07:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch4_loss0.7112957417964936.pypots
2024-05-25 06:07:27 [INFO]: Epoch 005 - training loss: 0.9477, validation loss: 0.7033
2024-05-25 06:07:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch5_loss0.7033118069171905.pypots
2024-05-25 06:07:31 [INFO]: Epoch 006 - training loss: 0.9234, validation loss: 0.6966
2024-05-25 06:07:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch6_loss0.6966213554143905.pypots
2024-05-25 06:07:35 [INFO]: Epoch 007 - training loss: 0.9241, validation loss: 0.6923
2024-05-25 06:07:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch7_loss0.6922529995441437.pypots
2024-05-25 06:07:39 [INFO]: Epoch 008 - training loss: 0.9143, validation loss: 0.6873
2024-05-25 06:07:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch8_loss0.6873287677764892.pypots
2024-05-25 06:07:43 [INFO]: Epoch 009 - training loss: 0.9399, validation loss: 0.6847
2024-05-25 06:07:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch9_loss0.6846885293722152.pypots
2024-05-25 06:07:47 [INFO]: Epoch 010 - training loss: 0.9063, validation loss: 0.6824
2024-05-25 06:07:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch10_loss0.6823659539222717.pypots
2024-05-25 06:07:51 [INFO]: Epoch 011 - training loss: 0.8974, validation loss: 0.6800
2024-05-25 06:07:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch11_loss0.6800047636032105.pypots
2024-05-25 06:07:55 [INFO]: Epoch 012 - training loss: 0.8980, validation loss: 0.6799
2024-05-25 06:07:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch12_loss0.679924938082695.pypots
2024-05-25 06:07:59 [INFO]: Epoch 013 - training loss: 0.8864, validation loss: 0.6783
2024-05-25 06:07:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch13_loss0.6782698810100556.pypots
2024-05-25 06:08:03 [INFO]: Epoch 014 - training loss: 0.8789, validation loss: 0.6776
2024-05-25 06:08:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch14_loss0.6776097983121872.pypots
2024-05-25 06:08:07 [INFO]: Epoch 015 - training loss: 0.8850, validation loss: 0.6752
2024-05-25 06:08:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch15_loss0.6752143442630768.pypots
2024-05-25 06:08:11 [INFO]: Epoch 016 - training loss: 0.8756, validation loss: 0.6740
2024-05-25 06:08:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch16_loss0.673990911245346.pypots
2024-05-25 06:08:14 [INFO]: Epoch 017 - training loss: 0.8688, validation loss: 0.6753
2024-05-25 06:08:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch17_loss0.6752931565046311.pypots
2024-05-25 06:08:18 [INFO]: Epoch 018 - training loss: 0.8660, validation loss: 0.6748
2024-05-25 06:08:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch18_loss0.6747993677854538.pypots
2024-05-25 06:08:22 [INFO]: Epoch 019 - training loss: 0.8674, validation loss: 0.6736
2024-05-25 06:08:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch19_loss0.6735729366540909.pypots
2024-05-25 06:08:26 [INFO]: Epoch 020 - training loss: 0.8712, validation loss: 0.6740
2024-05-25 06:08:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch20_loss0.6739704310894012.pypots
2024-05-25 06:08:31 [INFO]: Epoch 021 - training loss: 0.8447, validation loss: 0.6741
2024-05-25 06:08:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch21_loss0.6741160660982132.pypots
2024-05-25 06:08:35 [INFO]: Epoch 022 - training loss: 0.8505, validation loss: 0.6724
2024-05-25 06:08:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch22_loss0.6724274188280106.pypots
2024-05-25 06:08:38 [INFO]: Epoch 023 - training loss: 0.8615, validation loss: 0.6728
2024-05-25 06:08:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch23_loss0.6727745354175567.pypots
2024-05-25 06:08:42 [INFO]: Epoch 024 - training loss: 0.8425, validation loss: 0.6736
2024-05-25 06:08:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch24_loss0.6736449718475341.pypots
2024-05-25 06:08:46 [INFO]: Epoch 025 - training loss: 0.8519, validation loss: 0.6733
2024-05-25 06:08:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch25_loss0.6733256250619888.pypots
2024-05-25 06:08:50 [INFO]: Epoch 026 - training loss: 0.8438, validation loss: 0.6743
2024-05-25 06:08:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch26_loss0.6743302404880523.pypots
2024-05-25 06:08:54 [INFO]: Epoch 027 - training loss: 0.8554, validation loss: 0.6746
2024-05-25 06:08:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch27_loss0.6746064841747283.pypots
2024-05-25 06:08:58 [INFO]: Epoch 028 - training loss: 0.8555, validation loss: 0.6753
2024-05-25 06:08:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch28_loss0.675254687666893.pypots
2024-05-25 06:09:02 [INFO]: Epoch 029 - training loss: 0.8592, validation loss: 0.6734
2024-05-25 06:09:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch29_loss0.6734129190444946.pypots
2024-05-25 06:09:06 [INFO]: Epoch 030 - training loss: 0.8473, validation loss: 0.6761
2024-05-25 06:09:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch30_loss0.6760852932929993.pypots
2024-05-25 06:09:10 [INFO]: Epoch 031 - training loss: 0.8492, validation loss: 0.6726
2024-05-25 06:09:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch31_loss0.6726110845804214.pypots
2024-05-25 06:09:14 [INFO]: Epoch 032 - training loss: 0.8371, validation loss: 0.6745
2024-05-25 06:09:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN_epoch32_loss0.6744994580745697.pypots
2024-05-25 06:09:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:09:14 [INFO]: Finished training. The best model is from epoch#22.
2024-05-25 06:09:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240525_T060706/MRNN.pypots
2024-05-25 06:09:15 [INFO]: MRNN on Air-Quality: MAE=0.5273, MSE=0.7659
2024-05-25 06:09:15 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/MRNN_air_quality/imputation.pkl
2024-05-25 06:09:15 [INFO]: Using the given device: cpu
2024-05-25 06:09:15 [INFO]: LOCF on Air-Quality: MAE=0.2039, MSE=0.4028
2024-05-25 06:09:15 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_air_quality".
2024-05-25 06:09:15 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/LOCF_air_quality/imputation.pkl
2024-05-25 06:09:15 [INFO]: Median on Air-Quality: MAE=0.6702, MSE=1.1687
2024-05-25 06:09:15 [INFO]: Successfully created the given path "saved_results/round_1/Median_air_quality".
2024-05-25 06:09:15 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Median_air_quality/imputation.pkl
2024-05-25 06:09:15 [INFO]: Mean on Air-Quality: MAE=0.7021, MSE=1.1087
2024-05-25 06:09:15 [INFO]: Successfully created the given path "saved_results/round_1/Mean_air_quality".
2024-05-25 06:09:15 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Mean_air_quality/imputation.pkl
2024-05-25 06:09:15 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-25 06:09:15 [INFO]: Using the given device: cuda:0
2024-05-25 06:09:15 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/SAITS_air_quality/20240525_T060915
2024-05-25 06:09:15 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/SAITS_air_quality/20240525_T060915/tensorboard
2024-05-25 06:09:15 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 06:09:16 [INFO]: Epoch 001 - training loss: 1.0425, validation loss: 0.5201
2024-05-25 06:09:17 [INFO]: Epoch 002 - training loss: 0.7507, validation loss: 0.3924
2024-05-25 06:09:17 [INFO]: Epoch 003 - training loss: 0.6464, validation loss: 0.3228
2024-05-25 06:09:18 [INFO]: Epoch 004 - training loss: 0.5729, validation loss: 0.2881
2024-05-25 06:09:19 [INFO]: Epoch 005 - training loss: 0.5205, validation loss: 0.2652
2024-05-25 06:09:19 [INFO]: Epoch 006 - training loss: 0.4828, validation loss: 0.2528
2024-05-25 06:09:20 [INFO]: Epoch 007 - training loss: 0.4546, validation loss: 0.2403
2024-05-25 06:09:20 [INFO]: Epoch 008 - training loss: 0.4342, validation loss: 0.2319
2024-05-25 06:09:21 [INFO]: Epoch 009 - training loss: 0.4191, validation loss: 0.2264
2024-05-25 06:09:22 [INFO]: Epoch 010 - training loss: 0.4060, validation loss: 0.2221
2024-05-25 06:09:22 [INFO]: Epoch 011 - training loss: 0.3981, validation loss: 0.2159
2024-05-25 06:09:23 [INFO]: Epoch 012 - training loss: 0.3868, validation loss: 0.2115
2024-05-25 06:09:23 [INFO]: Epoch 013 - training loss: 0.3782, validation loss: 0.2074
2024-05-25 06:09:24 [INFO]: Epoch 014 - training loss: 0.3705, validation loss: 0.2057
2024-05-25 06:09:25 [INFO]: Epoch 015 - training loss: 0.3647, validation loss: 0.2027
2024-05-25 06:09:25 [INFO]: Epoch 016 - training loss: 0.3595, validation loss: 0.1998
2024-05-25 06:09:26 [INFO]: Epoch 017 - training loss: 0.3542, validation loss: 0.1972
2024-05-25 06:09:26 [INFO]: Epoch 018 - training loss: 0.3491, validation loss: 0.1951
2024-05-25 06:09:27 [INFO]: Epoch 019 - training loss: 0.3431, validation loss: 0.1927
2024-05-25 06:09:28 [INFO]: Epoch 020 - training loss: 0.3395, validation loss: 0.1902
2024-05-25 06:09:28 [INFO]: Epoch 021 - training loss: 0.3349, validation loss: 0.1887
2024-05-25 06:09:29 [INFO]: Epoch 022 - training loss: 0.3323, validation loss: 0.1873
2024-05-25 06:09:30 [INFO]: Epoch 023 - training loss: 0.3290, validation loss: 0.1838
2024-05-25 06:09:30 [INFO]: Epoch 024 - training loss: 0.3245, validation loss: 0.1832
2024-05-25 06:09:31 [INFO]: Epoch 025 - training loss: 0.3219, validation loss: 0.1824
2024-05-25 06:09:31 [INFO]: Epoch 026 - training loss: 0.3191, validation loss: 0.1813
2024-05-25 06:09:32 [INFO]: Epoch 027 - training loss: 0.3159, validation loss: 0.1802
2024-05-25 06:09:33 [INFO]: Epoch 028 - training loss: 0.3130, validation loss: 0.1788
2024-05-25 06:09:33 [INFO]: Epoch 029 - training loss: 0.3111, validation loss: 0.1777
2024-05-25 06:09:34 [INFO]: Epoch 030 - training loss: 0.3077, validation loss: 0.1751
2024-05-25 06:09:34 [INFO]: Epoch 031 - training loss: 0.3041, validation loss: 0.1737
2024-05-25 06:09:35 [INFO]: Epoch 032 - training loss: 0.3037, validation loss: 0.1728
2024-05-25 06:09:36 [INFO]: Epoch 033 - training loss: 0.3008, validation loss: 0.1708
2024-05-25 06:09:36 [INFO]: Epoch 034 - training loss: 0.2983, validation loss: 0.1705
2024-05-25 06:09:37 [INFO]: Epoch 035 - training loss: 0.2950, validation loss: 0.1688
2024-05-25 06:09:37 [INFO]: Epoch 036 - training loss: 0.2950, validation loss: 0.1683
2024-05-25 06:09:38 [INFO]: Epoch 037 - training loss: 0.2927, validation loss: 0.1659
2024-05-25 06:09:39 [INFO]: Epoch 038 - training loss: 0.2903, validation loss: 0.1670
2024-05-25 06:09:39 [INFO]: Epoch 039 - training loss: 0.2883, validation loss: 0.1639
2024-05-25 06:09:40 [INFO]: Epoch 040 - training loss: 0.2852, validation loss: 0.1640
2024-05-25 06:09:40 [INFO]: Epoch 041 - training loss: 0.2844, validation loss: 0.1623
2024-05-25 06:09:41 [INFO]: Epoch 042 - training loss: 0.2826, validation loss: 0.1626
2024-05-25 06:09:42 [INFO]: Epoch 043 - training loss: 0.2805, validation loss: 0.1590
2024-05-25 06:09:42 [INFO]: Epoch 044 - training loss: 0.2788, validation loss: 0.1605
2024-05-25 06:09:43 [INFO]: Epoch 045 - training loss: 0.2781, validation loss: 0.1588
2024-05-25 06:09:44 [INFO]: Epoch 046 - training loss: 0.2744, validation loss: 0.1577
2024-05-25 06:09:44 [INFO]: Epoch 047 - training loss: 0.2738, validation loss: 0.1572
2024-05-25 06:09:45 [INFO]: Epoch 048 - training loss: 0.2728, validation loss: 0.1581
2024-05-25 06:09:45 [INFO]: Epoch 049 - training loss: 0.2716, validation loss: 0.1548
2024-05-25 06:09:46 [INFO]: Epoch 050 - training loss: 0.2703, validation loss: 0.1548
2024-05-25 06:09:47 [INFO]: Epoch 051 - training loss: 0.2672, validation loss: 0.1534
2024-05-25 06:09:47 [INFO]: Epoch 052 - training loss: 0.2645, validation loss: 0.1514
2024-05-25 06:09:48 [INFO]: Epoch 053 - training loss: 0.2640, validation loss: 0.1518
2024-05-25 06:09:48 [INFO]: Epoch 054 - training loss: 0.2626, validation loss: 0.1512
2024-05-25 06:09:49 [INFO]: Epoch 055 - training loss: 0.2616, validation loss: 0.1504
2024-05-25 06:09:50 [INFO]: Epoch 056 - training loss: 0.2602, validation loss: 0.1495
2024-05-25 06:09:50 [INFO]: Epoch 057 - training loss: 0.2585, validation loss: 0.1479
2024-05-25 06:09:51 [INFO]: Epoch 058 - training loss: 0.2564, validation loss: 0.1467
2024-05-25 06:09:52 [INFO]: Epoch 059 - training loss: 0.2557, validation loss: 0.1453
2024-05-25 06:09:52 [INFO]: Epoch 060 - training loss: 0.2545, validation loss: 0.1450
2024-05-25 06:09:53 [INFO]: Epoch 061 - training loss: 0.2515, validation loss: 0.1443
2024-05-25 06:09:53 [INFO]: Epoch 062 - training loss: 0.2515, validation loss: 0.1431
2024-05-25 06:09:54 [INFO]: Epoch 063 - training loss: 0.2506, validation loss: 0.1428
2024-05-25 06:09:55 [INFO]: Epoch 064 - training loss: 0.2480, validation loss: 0.1417
2024-05-25 06:09:55 [INFO]: Epoch 065 - training loss: 0.2461, validation loss: 0.1409
2024-05-25 06:09:56 [INFO]: Epoch 066 - training loss: 0.2459, validation loss: 0.1406
2024-05-25 06:09:56 [INFO]: Epoch 067 - training loss: 0.2444, validation loss: 0.1396
2024-05-25 06:09:57 [INFO]: Epoch 068 - training loss: 0.2430, validation loss: 0.1392
2024-05-25 06:09:58 [INFO]: Epoch 069 - training loss: 0.2415, validation loss: 0.1401
2024-05-25 06:09:58 [INFO]: Epoch 070 - training loss: 0.2406, validation loss: 0.1388
2024-05-25 06:09:59 [INFO]: Epoch 071 - training loss: 0.2404, validation loss: 0.1368
2024-05-25 06:09:59 [INFO]: Epoch 072 - training loss: 0.2392, validation loss: 0.1381
2024-05-25 06:10:00 [INFO]: Epoch 073 - training loss: 0.2365, validation loss: 0.1368
2024-05-25 06:10:01 [INFO]: Epoch 074 - training loss: 0.2352, validation loss: 0.1358
2024-05-25 06:10:01 [INFO]: Epoch 075 - training loss: 0.2343, validation loss: 0.1356
2024-05-25 06:10:02 [INFO]: Epoch 076 - training loss: 0.2326, validation loss: 0.1346
2024-05-25 06:10:03 [INFO]: Epoch 077 - training loss: 0.2328, validation loss: 0.1351
2024-05-25 06:10:03 [INFO]: Epoch 078 - training loss: 0.2308, validation loss: 0.1344
2024-05-25 06:10:04 [INFO]: Epoch 079 - training loss: 0.2296, validation loss: 0.1345
2024-05-25 06:10:04 [INFO]: Epoch 080 - training loss: 0.2290, validation loss: 0.1324
2024-05-25 06:10:05 [INFO]: Epoch 081 - training loss: 0.2283, validation loss: 0.1341
2024-05-25 06:10:06 [INFO]: Epoch 082 - training loss: 0.2279, validation loss: 0.1326
2024-05-25 06:10:06 [INFO]: Epoch 083 - training loss: 0.2272, validation loss: 0.1341
2024-05-25 06:10:07 [INFO]: Epoch 084 - training loss: 0.2250, validation loss: 0.1328
2024-05-25 06:10:07 [INFO]: Epoch 085 - training loss: 0.2249, validation loss: 0.1319
2024-05-25 06:10:08 [INFO]: Epoch 086 - training loss: 0.2239, validation loss: 0.1316
2024-05-25 06:10:09 [INFO]: Epoch 087 - training loss: 0.2228, validation loss: 0.1316
2024-05-25 06:10:09 [INFO]: Epoch 088 - training loss: 0.2222, validation loss: 0.1323
2024-05-25 06:10:10 [INFO]: Epoch 089 - training loss: 0.2211, validation loss: 0.1304
2024-05-25 06:10:10 [INFO]: Epoch 090 - training loss: 0.2193, validation loss: 0.1299
2024-05-25 06:10:11 [INFO]: Epoch 091 - training loss: 0.2197, validation loss: 0.1296
2024-05-25 06:10:12 [INFO]: Epoch 092 - training loss: 0.2190, validation loss: 0.1298
2024-05-25 06:10:12 [INFO]: Epoch 093 - training loss: 0.2174, validation loss: 0.1299
2024-05-25 06:10:13 [INFO]: Epoch 094 - training loss: 0.2172, validation loss: 0.1303
2024-05-25 06:10:13 [INFO]: Epoch 095 - training loss: 0.2186, validation loss: 0.1289
2024-05-25 06:10:14 [INFO]: Epoch 096 - training loss: 0.2160, validation loss: 0.1290
2024-05-25 06:10:15 [INFO]: Epoch 097 - training loss: 0.2145, validation loss: 0.1288
2024-05-25 06:10:15 [INFO]: Epoch 098 - training loss: 0.2138, validation loss: 0.1284
2024-05-25 06:10:16 [INFO]: Epoch 099 - training loss: 0.2142, validation loss: 0.1290
2024-05-25 06:10:17 [INFO]: Epoch 100 - training loss: 0.2137, validation loss: 0.1270
2024-05-25 06:10:17 [INFO]: Epoch 101 - training loss: 0.2125, validation loss: 0.1274
2024-05-25 06:10:18 [INFO]: Epoch 102 - training loss: 0.2127, validation loss: 0.1275
2024-05-25 06:10:18 [INFO]: Epoch 103 - training loss: 0.2111, validation loss: 0.1267
2024-05-25 06:10:19 [INFO]: Epoch 104 - training loss: 0.2103, validation loss: 0.1275
2024-05-25 06:10:20 [INFO]: Epoch 105 - training loss: 0.2099, validation loss: 0.1282
2024-05-25 06:10:20 [INFO]: Epoch 106 - training loss: 0.2099, validation loss: 0.1262
2024-05-25 06:10:21 [INFO]: Epoch 107 - training loss: 0.2084, validation loss: 0.1262
2024-05-25 06:10:21 [INFO]: Epoch 108 - training loss: 0.2075, validation loss: 0.1272
2024-05-25 06:10:22 [INFO]: Epoch 109 - training loss: 0.2080, validation loss: 0.1276
2024-05-25 06:10:23 [INFO]: Epoch 110 - training loss: 0.2075, validation loss: 0.1261
2024-05-25 06:10:23 [INFO]: Epoch 111 - training loss: 0.2064, validation loss: 0.1256
2024-05-25 06:10:24 [INFO]: Epoch 112 - training loss: 0.2062, validation loss: 0.1240
2024-05-25 06:10:24 [INFO]: Epoch 113 - training loss: 0.2051, validation loss: 0.1246
2024-05-25 06:10:25 [INFO]: Epoch 114 - training loss: 0.2037, validation loss: 0.1240
2024-05-25 06:10:26 [INFO]: Epoch 115 - training loss: 0.2036, validation loss: 0.1237
2024-05-25 06:10:26 [INFO]: Epoch 116 - training loss: 0.2039, validation loss: 0.1238
2024-05-25 06:10:27 [INFO]: Epoch 117 - training loss: 0.2051, validation loss: 0.1237
2024-05-25 06:10:28 [INFO]: Epoch 118 - training loss: 0.2019, validation loss: 0.1235
2024-05-25 06:10:28 [INFO]: Epoch 119 - training loss: 0.2013, validation loss: 0.1251
2024-05-25 06:10:29 [INFO]: Epoch 120 - training loss: 0.2010, validation loss: 0.1236
2024-05-25 06:10:29 [INFO]: Epoch 121 - training loss: 0.2010, validation loss: 0.1239
2024-05-25 06:10:30 [INFO]: Epoch 122 - training loss: 0.1998, validation loss: 0.1212
2024-05-25 06:10:31 [INFO]: Epoch 123 - training loss: 0.1993, validation loss: 0.1234
2024-05-25 06:10:31 [INFO]: Epoch 124 - training loss: 0.1991, validation loss: 0.1212
2024-05-25 06:10:32 [INFO]: Epoch 125 - training loss: 0.1980, validation loss: 0.1232
2024-05-25 06:10:32 [INFO]: Epoch 126 - training loss: 0.1988, validation loss: 0.1216
2024-05-25 06:10:33 [INFO]: Epoch 127 - training loss: 0.1973, validation loss: 0.1217
2024-05-25 06:10:34 [INFO]: Epoch 128 - training loss: 0.1966, validation loss: 0.1218
2024-05-25 06:10:34 [INFO]: Epoch 129 - training loss: 0.1960, validation loss: 0.1218
2024-05-25 06:10:35 [INFO]: Epoch 130 - training loss: 0.1960, validation loss: 0.1222
2024-05-25 06:10:35 [INFO]: Epoch 131 - training loss: 0.1957, validation loss: 0.1209
2024-05-25 06:10:36 [INFO]: Epoch 132 - training loss: 0.1955, validation loss: 0.1220
2024-05-25 06:10:37 [INFO]: Epoch 133 - training loss: 0.1943, validation loss: 0.1211
2024-05-25 06:10:37 [INFO]: Epoch 134 - training loss: 0.1946, validation loss: 0.1204
2024-05-25 06:10:38 [INFO]: Epoch 135 - training loss: 0.1930, validation loss: 0.1212
2024-05-25 06:10:39 [INFO]: Epoch 136 - training loss: 0.1929, validation loss: 0.1207
2024-05-25 06:10:39 [INFO]: Epoch 137 - training loss: 0.1928, validation loss: 0.1198
2024-05-25 06:10:40 [INFO]: Epoch 138 - training loss: 0.1918, validation loss: 0.1203
2024-05-25 06:10:40 [INFO]: Epoch 139 - training loss: 0.1923, validation loss: 0.1208
2024-05-25 06:10:41 [INFO]: Epoch 140 - training loss: 0.1916, validation loss: 0.1193
2024-05-25 06:10:42 [INFO]: Epoch 141 - training loss: 0.1915, validation loss: 0.1207
2024-05-25 06:10:42 [INFO]: Epoch 142 - training loss: 0.1923, validation loss: 0.1198
2024-05-25 06:10:43 [INFO]: Epoch 143 - training loss: 0.1898, validation loss: 0.1201
2024-05-25 06:10:43 [INFO]: Epoch 144 - training loss: 0.1893, validation loss: 0.1196
2024-05-25 06:10:44 [INFO]: Epoch 145 - training loss: 0.1894, validation loss: 0.1197
2024-05-25 06:10:45 [INFO]: Epoch 146 - training loss: 0.1895, validation loss: 0.1187
2024-05-25 06:10:45 [INFO]: Epoch 147 - training loss: 0.1886, validation loss: 0.1202
2024-05-25 06:10:46 [INFO]: Epoch 148 - training loss: 0.1881, validation loss: 0.1186
2024-05-25 06:10:46 [INFO]: Epoch 149 - training loss: 0.1877, validation loss: 0.1190
2024-05-25 06:10:47 [INFO]: Epoch 150 - training loss: 0.1869, validation loss: 0.1192
2024-05-25 06:10:48 [INFO]: Epoch 151 - training loss: 0.1865, validation loss: 0.1202
2024-05-25 06:10:48 [INFO]: Epoch 152 - training loss: 0.1861, validation loss: 0.1187
2024-05-25 06:10:49 [INFO]: Epoch 153 - training loss: 0.1853, validation loss: 0.1165
2024-05-25 06:10:50 [INFO]: Epoch 154 - training loss: 0.1861, validation loss: 0.1189
2024-05-25 06:10:50 [INFO]: Epoch 155 - training loss: 0.1853, validation loss: 0.1168
2024-05-25 06:10:51 [INFO]: Epoch 156 - training loss: 0.1847, validation loss: 0.1174
2024-05-25 06:10:51 [INFO]: Epoch 157 - training loss: 0.1845, validation loss: 0.1165
2024-05-25 06:10:52 [INFO]: Epoch 158 - training loss: 0.1833, validation loss: 0.1177
2024-05-25 06:10:53 [INFO]: Epoch 159 - training loss: 0.1831, validation loss: 0.1168
2024-05-25 06:10:53 [INFO]: Epoch 160 - training loss: 0.1824, validation loss: 0.1163
2024-05-25 06:10:54 [INFO]: Epoch 161 - training loss: 0.1820, validation loss: 0.1168
2024-05-25 06:10:54 [INFO]: Epoch 162 - training loss: 0.1818, validation loss: 0.1164
2024-05-25 06:10:55 [INFO]: Epoch 163 - training loss: 0.1821, validation loss: 0.1167
2024-05-25 06:10:56 [INFO]: Epoch 164 - training loss: 0.1842, validation loss: 0.1171
2024-05-25 06:10:56 [INFO]: Epoch 165 - training loss: 0.1825, validation loss: 0.1153
2024-05-25 06:10:57 [INFO]: Epoch 166 - training loss: 0.1811, validation loss: 0.1147
2024-05-25 06:10:57 [INFO]: Epoch 167 - training loss: 0.1812, validation loss: 0.1141
2024-05-25 06:10:58 [INFO]: Epoch 168 - training loss: 0.1803, validation loss: 0.1155
2024-05-25 06:10:59 [INFO]: Epoch 169 - training loss: 0.1799, validation loss: 0.1147
2024-05-25 06:10:59 [INFO]: Epoch 170 - training loss: 0.1797, validation loss: 0.1154
2024-05-25 06:11:00 [INFO]: Epoch 171 - training loss: 0.1790, validation loss: 0.1139
2024-05-25 06:11:00 [INFO]: Epoch 172 - training loss: 0.1787, validation loss: 0.1155
2024-05-25 06:11:01 [INFO]: Epoch 173 - training loss: 0.1802, validation loss: 0.1151
2024-05-25 06:11:02 [INFO]: Epoch 174 - training loss: 0.1783, validation loss: 0.1148
2024-05-25 06:11:02 [INFO]: Epoch 175 - training loss: 0.1780, validation loss: 0.1151
2024-05-25 06:11:03 [INFO]: Epoch 176 - training loss: 0.1777, validation loss: 0.1139
2024-05-25 06:11:04 [INFO]: Epoch 177 - training loss: 0.1783, validation loss: 0.1139
2024-05-25 06:11:04 [INFO]: Epoch 178 - training loss: 0.1772, validation loss: 0.1161
2024-05-25 06:11:05 [INFO]: Epoch 179 - training loss: 0.1767, validation loss: 0.1136
2024-05-25 06:11:05 [INFO]: Epoch 180 - training loss: 0.1754, validation loss: 0.1134
2024-05-25 06:11:06 [INFO]: Epoch 181 - training loss: 0.1758, validation loss: 0.1145
2024-05-25 06:11:07 [INFO]: Epoch 182 - training loss: 0.1753, validation loss: 0.1123
2024-05-25 06:11:07 [INFO]: Epoch 183 - training loss: 0.1759, validation loss: 0.1136
2024-05-25 06:11:08 [INFO]: Epoch 184 - training loss: 0.1787, validation loss: 0.1161
2024-05-25 06:11:08 [INFO]: Epoch 185 - training loss: 0.1783, validation loss: 0.1130
2024-05-25 06:11:09 [INFO]: Epoch 186 - training loss: 0.1759, validation loss: 0.1147
2024-05-25 06:11:10 [INFO]: Epoch 187 - training loss: 0.1747, validation loss: 0.1124
2024-05-25 06:11:10 [INFO]: Epoch 188 - training loss: 0.1733, validation loss: 0.1124
2024-05-25 06:11:11 [INFO]: Epoch 189 - training loss: 0.1731, validation loss: 0.1140
2024-05-25 06:11:11 [INFO]: Epoch 190 - training loss: 0.1725, validation loss: 0.1131
2024-05-25 06:11:12 [INFO]: Epoch 191 - training loss: 0.1719, validation loss: 0.1146
2024-05-25 06:11:13 [INFO]: Epoch 192 - training loss: 0.1715, validation loss: 0.1139
2024-05-25 06:11:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:11:13 [INFO]: Finished training. The best model is from epoch#182.
2024-05-25 06:11:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/SAITS_air_quality/20240525_T060915/SAITS.pypots
2024-05-25 06:11:13 [INFO]: SAITS on Air-Quality: MAE=0.1512, MSE=0.2131
2024-05-25 06:11:13 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/SAITS_air_quality/imputation.pkl
2024-05-25 06:11:13 [INFO]: Using the given device: cuda:0
2024-05-25 06:11:13 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/Transformer_air_quality/20240525_T061113
2024-05-25 06:11:13 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/Transformer_air_quality/20240525_T061113/tensorboard
2024-05-25 06:11:13 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 06:11:13 [INFO]: Epoch 001 - training loss: 0.8823, validation loss: 0.4563
2024-05-25 06:11:14 [INFO]: Epoch 002 - training loss: 0.5502, validation loss: 0.3386
2024-05-25 06:11:14 [INFO]: Epoch 003 - training loss: 0.4571, validation loss: 0.2879
2024-05-25 06:11:14 [INFO]: Epoch 004 - training loss: 0.4115, validation loss: 0.2616
2024-05-25 06:11:14 [INFO]: Epoch 005 - training loss: 0.3828, validation loss: 0.2484
2024-05-25 06:11:15 [INFO]: Epoch 006 - training loss: 0.3628, validation loss: 0.2405
2024-05-25 06:11:15 [INFO]: Epoch 007 - training loss: 0.3486, validation loss: 0.2335
2024-05-25 06:11:15 [INFO]: Epoch 008 - training loss: 0.3330, validation loss: 0.2245
2024-05-25 06:11:15 [INFO]: Epoch 009 - training loss: 0.3220, validation loss: 0.2193
2024-05-25 06:11:16 [INFO]: Epoch 010 - training loss: 0.3141, validation loss: 0.2124
2024-05-25 06:11:16 [INFO]: Epoch 011 - training loss: 0.3078, validation loss: 0.2107
2024-05-25 06:11:16 [INFO]: Epoch 012 - training loss: 0.3008, validation loss: 0.2071
2024-05-25 06:11:16 [INFO]: Epoch 013 - training loss: 0.2946, validation loss: 0.2024
2024-05-25 06:11:17 [INFO]: Epoch 014 - training loss: 0.2911, validation loss: 0.1983
2024-05-25 06:11:17 [INFO]: Epoch 015 - training loss: 0.2854, validation loss: 0.1973
2024-05-25 06:11:17 [INFO]: Epoch 016 - training loss: 0.2800, validation loss: 0.1916
2024-05-25 06:11:17 [INFO]: Epoch 017 - training loss: 0.2752, validation loss: 0.1896
2024-05-25 06:11:18 [INFO]: Epoch 018 - training loss: 0.2731, validation loss: 0.1855
2024-05-25 06:11:18 [INFO]: Epoch 019 - training loss: 0.2694, validation loss: 0.1854
2024-05-25 06:11:18 [INFO]: Epoch 020 - training loss: 0.2671, validation loss: 0.1835
2024-05-25 06:11:18 [INFO]: Epoch 021 - training loss: 0.2660, validation loss: 0.1817
2024-05-25 06:11:19 [INFO]: Epoch 022 - training loss: 0.2602, validation loss: 0.1782
2024-05-25 06:11:19 [INFO]: Epoch 023 - training loss: 0.2565, validation loss: 0.1761
2024-05-25 06:11:19 [INFO]: Epoch 024 - training loss: 0.2546, validation loss: 0.1763
2024-05-25 06:11:19 [INFO]: Epoch 025 - training loss: 0.2515, validation loss: 0.1743
2024-05-25 06:11:20 [INFO]: Epoch 026 - training loss: 0.2504, validation loss: 0.1720
2024-05-25 06:11:20 [INFO]: Epoch 027 - training loss: 0.2502, validation loss: 0.1718
2024-05-25 06:11:20 [INFO]: Epoch 028 - training loss: 0.2478, validation loss: 0.1714
2024-05-25 06:11:20 [INFO]: Epoch 029 - training loss: 0.2454, validation loss: 0.1699
2024-05-25 06:11:21 [INFO]: Epoch 030 - training loss: 0.2439, validation loss: 0.1689
2024-05-25 06:11:21 [INFO]: Epoch 031 - training loss: 0.2420, validation loss: 0.1699
2024-05-25 06:11:21 [INFO]: Epoch 032 - training loss: 0.2384, validation loss: 0.1670
2024-05-25 06:11:21 [INFO]: Epoch 033 - training loss: 0.2360, validation loss: 0.1665
2024-05-25 06:11:22 [INFO]: Epoch 034 - training loss: 0.2327, validation loss: 0.1654
2024-05-25 06:11:22 [INFO]: Epoch 035 - training loss: 0.2301, validation loss: 0.1644
2024-05-25 06:11:22 [INFO]: Epoch 036 - training loss: 0.2283, validation loss: 0.1637
2024-05-25 06:11:22 [INFO]: Epoch 037 - training loss: 0.2257, validation loss: 0.1627
2024-05-25 06:11:23 [INFO]: Epoch 038 - training loss: 0.2246, validation loss: 0.1635
2024-05-25 06:11:23 [INFO]: Epoch 039 - training loss: 0.2219, validation loss: 0.1627
2024-05-25 06:11:23 [INFO]: Epoch 040 - training loss: 0.2213, validation loss: 0.1631
2024-05-25 06:11:23 [INFO]: Epoch 041 - training loss: 0.2203, validation loss: 0.1627
2024-05-25 06:11:24 [INFO]: Epoch 042 - training loss: 0.2186, validation loss: 0.1610
2024-05-25 06:11:24 [INFO]: Epoch 043 - training loss: 0.2175, validation loss: 0.1605
2024-05-25 06:11:24 [INFO]: Epoch 044 - training loss: 0.2165, validation loss: 0.1616
2024-05-25 06:11:24 [INFO]: Epoch 045 - training loss: 0.2172, validation loss: 0.1601
2024-05-25 06:11:25 [INFO]: Epoch 046 - training loss: 0.2167, validation loss: 0.1590
2024-05-25 06:11:25 [INFO]: Epoch 047 - training loss: 0.2123, validation loss: 0.1594
2024-05-25 06:11:25 [INFO]: Epoch 048 - training loss: 0.2118, validation loss: 0.1577
2024-05-25 06:11:25 [INFO]: Epoch 049 - training loss: 0.2088, validation loss: 0.1582
2024-05-25 06:11:26 [INFO]: Epoch 050 - training loss: 0.2079, validation loss: 0.1575
2024-05-25 06:11:26 [INFO]: Epoch 051 - training loss: 0.2059, validation loss: 0.1584
2024-05-25 06:11:26 [INFO]: Epoch 052 - training loss: 0.2048, validation loss: 0.1571
2024-05-25 06:11:26 [INFO]: Epoch 053 - training loss: 0.2041, validation loss: 0.1564
2024-05-25 06:11:27 [INFO]: Epoch 054 - training loss: 0.2037, validation loss: 0.1575
2024-05-25 06:11:27 [INFO]: Epoch 055 - training loss: 0.2045, validation loss: 0.1558
2024-05-25 06:11:27 [INFO]: Epoch 056 - training loss: 0.2024, validation loss: 0.1562
2024-05-25 06:11:27 [INFO]: Epoch 057 - training loss: 0.1992, validation loss: 0.1543
2024-05-25 06:11:28 [INFO]: Epoch 058 - training loss: 0.1988, validation loss: 0.1556
2024-05-25 06:11:28 [INFO]: Epoch 059 - training loss: 0.1987, validation loss: 0.1527
2024-05-25 06:11:28 [INFO]: Epoch 060 - training loss: 0.1981, validation loss: 0.1545
2024-05-25 06:11:28 [INFO]: Epoch 061 - training loss: 0.1947, validation loss: 0.1518
2024-05-25 06:11:29 [INFO]: Epoch 062 - training loss: 0.1946, validation loss: 0.1515
2024-05-25 06:11:29 [INFO]: Epoch 063 - training loss: 0.1918, validation loss: 0.1537
2024-05-25 06:11:29 [INFO]: Epoch 064 - training loss: 0.1929, validation loss: 0.1503
2024-05-25 06:11:30 [INFO]: Epoch 065 - training loss: 0.1927, validation loss: 0.1514
2024-05-25 06:11:30 [INFO]: Epoch 066 - training loss: 0.1904, validation loss: 0.1507
2024-05-25 06:11:30 [INFO]: Epoch 067 - training loss: 0.1905, validation loss: 0.1505
2024-05-25 06:11:30 [INFO]: Epoch 068 - training loss: 0.1883, validation loss: 0.1503
2024-05-25 06:11:31 [INFO]: Epoch 069 - training loss: 0.1865, validation loss: 0.1505
2024-05-25 06:11:31 [INFO]: Epoch 070 - training loss: 0.1879, validation loss: 0.1506
2024-05-25 06:11:31 [INFO]: Epoch 071 - training loss: 0.1864, validation loss: 0.1494
2024-05-25 06:11:31 [INFO]: Epoch 072 - training loss: 0.1848, validation loss: 0.1483
2024-05-25 06:11:32 [INFO]: Epoch 073 - training loss: 0.1848, validation loss: 0.1478
2024-05-25 06:11:32 [INFO]: Epoch 074 - training loss: 0.1827, validation loss: 0.1490
2024-05-25 06:11:32 [INFO]: Epoch 075 - training loss: 0.1838, validation loss: 0.1478
2024-05-25 06:11:32 [INFO]: Epoch 076 - training loss: 0.1836, validation loss: 0.1480
2024-05-25 06:11:33 [INFO]: Epoch 077 - training loss: 0.1803, validation loss: 0.1461
2024-05-25 06:11:33 [INFO]: Epoch 078 - training loss: 0.1808, validation loss: 0.1495
2024-05-25 06:11:33 [INFO]: Epoch 079 - training loss: 0.1800, validation loss: 0.1485
2024-05-25 06:11:33 [INFO]: Epoch 080 - training loss: 0.1801, validation loss: 0.1457
2024-05-25 06:11:34 [INFO]: Epoch 081 - training loss: 0.1797, validation loss: 0.1460
2024-05-25 06:11:34 [INFO]: Epoch 082 - training loss: 0.1779, validation loss: 0.1463
2024-05-25 06:11:34 [INFO]: Epoch 083 - training loss: 0.1754, validation loss: 0.1482
2024-05-25 06:11:34 [INFO]: Epoch 084 - training loss: 0.1748, validation loss: 0.1472
2024-05-25 06:11:35 [INFO]: Epoch 085 - training loss: 0.1771, validation loss: 0.1440
2024-05-25 06:11:35 [INFO]: Epoch 086 - training loss: 0.1751, validation loss: 0.1449
2024-05-25 06:11:35 [INFO]: Epoch 087 - training loss: 0.1732, validation loss: 0.1459
2024-05-25 06:11:35 [INFO]: Epoch 088 - training loss: 0.1712, validation loss: 0.1450
2024-05-25 06:11:36 [INFO]: Epoch 089 - training loss: 0.1716, validation loss: 0.1433
2024-05-25 06:11:36 [INFO]: Epoch 090 - training loss: 0.1702, validation loss: 0.1450
2024-05-25 06:11:36 [INFO]: Epoch 091 - training loss: 0.1684, validation loss: 0.1445
2024-05-25 06:11:36 [INFO]: Epoch 092 - training loss: 0.1684, validation loss: 0.1448
2024-05-25 06:11:37 [INFO]: Epoch 093 - training loss: 0.1686, validation loss: 0.1433
2024-05-25 06:11:37 [INFO]: Epoch 094 - training loss: 0.1677, validation loss: 0.1431
2024-05-25 06:11:37 [INFO]: Epoch 095 - training loss: 0.1673, validation loss: 0.1407
2024-05-25 06:11:37 [INFO]: Epoch 096 - training loss: 0.1730, validation loss: 0.1431
2024-05-25 06:11:38 [INFO]: Epoch 097 - training loss: 0.1667, validation loss: 0.1436
2024-05-25 06:11:38 [INFO]: Epoch 098 - training loss: 0.1646, validation loss: 0.1434
2024-05-25 06:11:38 [INFO]: Epoch 099 - training loss: 0.1634, validation loss: 0.1439
2024-05-25 06:11:38 [INFO]: Epoch 100 - training loss: 0.1633, validation loss: 0.1430
2024-05-25 06:11:39 [INFO]: Epoch 101 - training loss: 0.1646, validation loss: 0.1423
2024-05-25 06:11:39 [INFO]: Epoch 102 - training loss: 0.1622, validation loss: 0.1420
2024-05-25 06:11:39 [INFO]: Epoch 103 - training loss: 0.1631, validation loss: 0.1415
2024-05-25 06:11:39 [INFO]: Epoch 104 - training loss: 0.1598, validation loss: 0.1411
2024-05-25 06:11:40 [INFO]: Epoch 105 - training loss: 0.1630, validation loss: 0.1426
2024-05-25 06:11:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:11:40 [INFO]: Finished training. The best model is from epoch#95.
2024-05-25 06:11:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/Transformer_air_quality/20240525_T061113/Transformer.pypots
2024-05-25 06:11:40 [INFO]: Transformer on Air-Quality: MAE=0.1720, MSE=0.2596
2024-05-25 06:11:40 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Transformer_air_quality/imputation.pkl
2024-05-25 06:11:40 [INFO]: Using the given device: cuda:0
2024-05-25 06:11:40 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/TimesNet_air_quality/20240525_T061140
2024-05-25 06:11:40 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/TimesNet_air_quality/20240525_T061140/tensorboard
2024-05-25 06:11:40 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 06:11:41 [INFO]: Epoch 001 - training loss: 0.3226, validation loss: 0.2910
2024-05-25 06:11:41 [INFO]: Epoch 002 - training loss: 0.2697, validation loss: 0.2617
2024-05-25 06:11:42 [INFO]: Epoch 003 - training loss: 0.2238, validation loss: 0.2436
2024-05-25 06:11:42 [INFO]: Epoch 004 - training loss: 0.1789, validation loss: 0.2364
2024-05-25 06:11:43 [INFO]: Epoch 005 - training loss: 0.1728, validation loss: 0.2231
2024-05-25 06:11:43 [INFO]: Epoch 006 - training loss: 0.1522, validation loss: 0.2173
2024-05-25 06:11:43 [INFO]: Epoch 007 - training loss: 0.1377, validation loss: 0.2104
2024-05-25 06:11:44 [INFO]: Epoch 008 - training loss: 0.1321, validation loss: 0.2082
2024-05-25 06:11:44 [INFO]: Epoch 009 - training loss: 0.1302, validation loss: 0.2043
2024-05-25 06:11:45 [INFO]: Epoch 010 - training loss: 0.1287, validation loss: 0.2024
2024-05-25 06:11:45 [INFO]: Epoch 011 - training loss: 0.1248, validation loss: 0.1974
2024-05-25 06:11:46 [INFO]: Epoch 012 - training loss: 0.1177, validation loss: 0.1960
2024-05-25 06:11:46 [INFO]: Epoch 013 - training loss: 0.1116, validation loss: 0.1906
2024-05-25 06:11:47 [INFO]: Epoch 014 - training loss: 0.1103, validation loss: 0.1932
2024-05-25 06:11:47 [INFO]: Epoch 015 - training loss: 0.1094, validation loss: 0.1875
2024-05-25 06:11:48 [INFO]: Epoch 016 - training loss: 0.0976, validation loss: 0.1875
2024-05-25 06:11:48 [INFO]: Epoch 017 - training loss: 0.0944, validation loss: 0.1870
2024-05-25 06:11:49 [INFO]: Epoch 018 - training loss: 0.0958, validation loss: 0.1866
2024-05-25 06:11:49 [INFO]: Epoch 019 - training loss: 0.0984, validation loss: 0.1911
2024-05-25 06:11:49 [INFO]: Epoch 020 - training loss: 0.1091, validation loss: 0.1862
2024-05-25 06:11:50 [INFO]: Epoch 021 - training loss: 0.1061, validation loss: 0.1935
2024-05-25 06:11:50 [INFO]: Epoch 022 - training loss: 0.1080, validation loss: 0.1893
2024-05-25 06:11:51 [INFO]: Epoch 023 - training loss: 0.1035, validation loss: 0.1837
2024-05-25 06:11:51 [INFO]: Epoch 024 - training loss: 0.0896, validation loss: 0.1803
2024-05-25 06:11:52 [INFO]: Epoch 025 - training loss: 0.0844, validation loss: 0.1763
2024-05-25 06:11:52 [INFO]: Epoch 026 - training loss: 0.0799, validation loss: 0.1805
2024-05-25 06:11:53 [INFO]: Epoch 027 - training loss: 0.0755, validation loss: 0.1767
2024-05-25 06:11:53 [INFO]: Epoch 028 - training loss: 0.0761, validation loss: 0.1788
2024-05-25 06:11:54 [INFO]: Epoch 029 - training loss: 0.0749, validation loss: 0.1760
2024-05-25 06:11:54 [INFO]: Epoch 030 - training loss: 0.0730, validation loss: 0.1793
2024-05-25 06:11:54 [INFO]: Epoch 031 - training loss: 0.0724, validation loss: 0.1766
2024-05-25 06:11:55 [INFO]: Epoch 032 - training loss: 0.0738, validation loss: 0.1757
2024-05-25 06:11:55 [INFO]: Epoch 033 - training loss: 0.0711, validation loss: 0.1725
2024-05-25 06:11:56 [INFO]: Epoch 034 - training loss: 0.0699, validation loss: 0.1784
2024-05-25 06:11:56 [INFO]: Epoch 035 - training loss: 0.0706, validation loss: 0.1740
2024-05-25 06:11:57 [INFO]: Epoch 036 - training loss: 0.0692, validation loss: 0.1772
2024-05-25 06:11:57 [INFO]: Epoch 037 - training loss: 0.0665, validation loss: 0.1712
2024-05-25 06:11:58 [INFO]: Epoch 038 - training loss: 0.0657, validation loss: 0.1757
2024-05-25 06:11:58 [INFO]: Epoch 039 - training loss: 0.0644, validation loss: 0.1724
2024-05-25 06:11:59 [INFO]: Epoch 040 - training loss: 0.0637, validation loss: 0.1770
2024-05-25 06:11:59 [INFO]: Epoch 041 - training loss: 0.0634, validation loss: 0.1717
2024-05-25 06:12:00 [INFO]: Epoch 042 - training loss: 0.0617, validation loss: 0.1725
2024-05-25 06:12:00 [INFO]: Epoch 043 - training loss: 0.0655, validation loss: 0.1719
2024-05-25 06:12:00 [INFO]: Epoch 044 - training loss: 0.0602, validation loss: 0.1712
2024-05-25 06:12:01 [INFO]: Epoch 045 - training loss: 0.0568, validation loss: 0.1718
2024-05-25 06:12:01 [INFO]: Epoch 046 - training loss: 0.0560, validation loss: 0.1727
2024-05-25 06:12:02 [INFO]: Epoch 047 - training loss: 0.0584, validation loss: 0.1728
2024-05-25 06:12:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:12:02 [INFO]: Finished training. The best model is from epoch#37.
2024-05-25 06:12:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/TimesNet_air_quality/20240525_T061140/TimesNet.pypots
2024-05-25 06:12:02 [INFO]: TimesNet on Air-Quality: MAE=0.1718, MSE=0.3176
2024-05-25 06:12:02 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/TimesNet_air_quality/imputation.pkl
2024-05-25 06:12:02 [INFO]: Using the given device: cuda:0
2024-05-25 06:12:02 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202
2024-05-25 06:12:02 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/tensorboard
2024-05-25 06:12:02 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 06:12:19 [INFO]: Epoch 001 - training loss: 0.4943, validation loss: 0.3524
2024-05-25 06:12:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch1_loss0.3524241507053375.pypots
2024-05-25 06:12:36 [INFO]: Epoch 002 - training loss: 0.3052, validation loss: 0.2702
2024-05-25 06:12:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch2_loss0.27015909999608995.pypots
2024-05-25 06:12:52 [INFO]: Epoch 003 - training loss: 0.2602, validation loss: 0.2451
2024-05-25 06:12:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch3_loss0.2451337307691574.pypots
2024-05-25 06:13:09 [INFO]: Epoch 004 - training loss: 0.2456, validation loss: 0.2261
2024-05-25 06:13:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch4_loss0.22606920301914216.pypots
2024-05-25 06:13:26 [INFO]: Epoch 005 - training loss: 0.2204, validation loss: 0.1934
2024-05-25 06:13:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch5_loss0.19338732957839966.pypots
2024-05-25 06:13:42 [INFO]: Epoch 006 - training loss: 0.1859, validation loss: 0.1769
2024-05-25 06:13:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch6_loss0.17686727643013.pypots
2024-05-25 06:13:59 [INFO]: Epoch 007 - training loss: 0.1758, validation loss: 0.1715
2024-05-25 06:13:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch7_loss0.17148535400629045.pypots
2024-05-25 06:14:16 [INFO]: Epoch 008 - training loss: 0.1750, validation loss: 0.1578
2024-05-25 06:14:16 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch8_loss0.1577532932162285.pypots
2024-05-25 06:14:33 [INFO]: Epoch 009 - training loss: 0.1702, validation loss: 0.1575
2024-05-25 06:14:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch9_loss0.15753294080495833.pypots
2024-05-25 06:14:49 [INFO]: Epoch 010 - training loss: 0.1608, validation loss: 0.1531
2024-05-25 06:14:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch10_loss0.1530732497572899.pypots
2024-05-25 06:15:06 [INFO]: Epoch 011 - training loss: 0.1687, validation loss: 0.1518
2024-05-25 06:15:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch11_loss0.15175683945417404.pypots
2024-05-25 06:15:23 [INFO]: Epoch 012 - training loss: 0.1527, validation loss: 0.1504
2024-05-25 06:15:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch12_loss0.15036434084177017.pypots
2024-05-25 06:15:39 [INFO]: Epoch 013 - training loss: 0.1677, validation loss: 0.1496
2024-05-25 06:15:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch13_loss0.14955391138792037.pypots
2024-05-25 06:15:56 [INFO]: Epoch 014 - training loss: 0.1584, validation loss: 0.1451
2024-05-25 06:15:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch14_loss0.14509799033403398.pypots
2024-05-25 06:16:13 [INFO]: Epoch 015 - training loss: 0.1558, validation loss: 0.1446
2024-05-25 06:16:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch15_loss0.14460790306329727.pypots
2024-05-25 06:16:30 [INFO]: Epoch 016 - training loss: 0.1608, validation loss: 0.1421
2024-05-25 06:16:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch16_loss0.1421316646039486.pypots
2024-05-25 06:16:46 [INFO]: Epoch 017 - training loss: 0.1568, validation loss: 0.1441
2024-05-25 06:16:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch17_loss0.1440552741289139.pypots
2024-05-25 06:17:03 [INFO]: Epoch 018 - training loss: 0.1549, validation loss: 0.1410
2024-05-25 06:17:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch18_loss0.14099015891551972.pypots
2024-05-25 06:17:20 [INFO]: Epoch 019 - training loss: 0.1437, validation loss: 0.1438
2024-05-25 06:17:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch19_loss0.14379131197929382.pypots
2024-05-25 06:17:37 [INFO]: Epoch 020 - training loss: 0.1479, validation loss: 0.1387
2024-05-25 06:17:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch20_loss0.1387319952249527.pypots
2024-05-25 06:17:53 [INFO]: Epoch 021 - training loss: 0.1417, validation loss: 0.1326
2024-05-25 06:17:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch21_loss0.13261506333947182.pypots
2024-05-25 06:18:10 [INFO]: Epoch 022 - training loss: 0.1280, validation loss: 0.1361
2024-05-25 06:18:10 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch22_loss0.13609909042716026.pypots
2024-05-25 06:18:27 [INFO]: Epoch 023 - training loss: 0.1434, validation loss: 0.1329
2024-05-25 06:18:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch23_loss0.13292616307735444.pypots
2024-05-25 06:18:43 [INFO]: Epoch 024 - training loss: 0.1419, validation loss: 0.1355
2024-05-25 06:18:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch24_loss0.13553826063871383.pypots
2024-05-25 06:19:00 [INFO]: Epoch 025 - training loss: 0.1493, validation loss: 0.1331
2024-05-25 06:19:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch25_loss0.13313849046826362.pypots
2024-05-25 06:19:17 [INFO]: Epoch 026 - training loss: 0.1331, validation loss: 0.1289
2024-05-25 06:19:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch26_loss0.12890185713768004.pypots
2024-05-25 06:19:34 [INFO]: Epoch 027 - training loss: 0.1338, validation loss: 0.1373
2024-05-25 06:19:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch27_loss0.13730970472097398.pypots
2024-05-25 06:19:50 [INFO]: Epoch 028 - training loss: 0.1411, validation loss: 0.1326
2024-05-25 06:19:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch28_loss0.13255708888173104.pypots
2024-05-25 06:20:07 [INFO]: Epoch 029 - training loss: 0.1311, validation loss: 0.1274
2024-05-25 06:20:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch29_loss0.12738534882664682.pypots
2024-05-25 06:20:24 [INFO]: Epoch 030 - training loss: 0.1441, validation loss: 0.1276
2024-05-25 06:20:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch30_loss0.12764297053217888.pypots
2024-05-25 06:20:41 [INFO]: Epoch 031 - training loss: 0.1207, validation loss: 0.1278
2024-05-25 06:20:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch31_loss0.12782050147652627.pypots
2024-05-25 06:20:57 [INFO]: Epoch 032 - training loss: 0.1391, validation loss: 0.1287
2024-05-25 06:20:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch32_loss0.12869611233472825.pypots
2024-05-25 06:21:14 [INFO]: Epoch 033 - training loss: 0.1142, validation loss: 0.1269
2024-05-25 06:21:14 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch33_loss0.1269150272011757.pypots
2024-05-25 06:21:31 [INFO]: Epoch 034 - training loss: 0.1314, validation loss: 0.1309
2024-05-25 06:21:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch34_loss0.13088993728160858.pypots
2024-05-25 06:21:47 [INFO]: Epoch 035 - training loss: 0.1258, validation loss: 0.1241
2024-05-25 06:21:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch35_loss0.12405666708946228.pypots
2024-05-25 06:22:04 [INFO]: Epoch 036 - training loss: 0.1182, validation loss: 0.1240
2024-05-25 06:22:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch36_loss0.12398926317691802.pypots
2024-05-25 06:22:21 [INFO]: Epoch 037 - training loss: 0.1367, validation loss: 0.1307
2024-05-25 06:22:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch37_loss0.13065454587340355.pypots
2024-05-25 06:22:38 [INFO]: Epoch 038 - training loss: 0.1245, validation loss: 0.1352
2024-05-25 06:22:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch38_loss0.1351607322692871.pypots
2024-05-25 06:22:54 [INFO]: Epoch 039 - training loss: 0.1372, validation loss: 0.1272
2024-05-25 06:22:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch39_loss0.12718375027179718.pypots
2024-05-25 06:23:11 [INFO]: Epoch 040 - training loss: 0.1189, validation loss: 0.1239
2024-05-25 06:23:11 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch40_loss0.12392122000455856.pypots
2024-05-25 06:23:28 [INFO]: Epoch 041 - training loss: 0.1215, validation loss: 0.1245
2024-05-25 06:23:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch41_loss0.12451085522770881.pypots
2024-05-25 06:23:45 [INFO]: Epoch 042 - training loss: 0.1246, validation loss: 0.1239
2024-05-25 06:23:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch42_loss0.12385942041873932.pypots
2024-05-25 06:24:01 [INFO]: Epoch 043 - training loss: 0.1297, validation loss: 0.1243
2024-05-25 06:24:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch43_loss0.12428671643137931.pypots
2024-05-25 06:24:18 [INFO]: Epoch 044 - training loss: 0.1308, validation loss: 0.1289
2024-05-25 06:24:18 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch44_loss0.12885337173938752.pypots
2024-05-25 06:24:35 [INFO]: Epoch 045 - training loss: 0.1217, validation loss: 0.1265
2024-05-25 06:24:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch45_loss0.12648056969046592.pypots
2024-05-25 06:24:51 [INFO]: Epoch 046 - training loss: 0.1311, validation loss: 0.1234
2024-05-25 06:24:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch46_loss0.12342880740761757.pypots
2024-05-25 06:25:08 [INFO]: Epoch 047 - training loss: 0.1193, validation loss: 0.1205
2024-05-25 06:25:08 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch47_loss0.120451320707798.pypots
2024-05-25 06:25:25 [INFO]: Epoch 048 - training loss: 0.1226, validation loss: 0.1216
2024-05-25 06:25:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch48_loss0.12159697860479354.pypots
2024-05-25 06:25:42 [INFO]: Epoch 049 - training loss: 0.1162, validation loss: 0.1217
2024-05-25 06:25:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch49_loss0.12173048555850982.pypots
2024-05-25 06:25:58 [INFO]: Epoch 050 - training loss: 0.1375, validation loss: 0.1200
2024-05-25 06:25:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch50_loss0.12000871673226357.pypots
2024-05-25 06:26:15 [INFO]: Epoch 051 - training loss: 0.1044, validation loss: 0.1210
2024-05-25 06:26:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch51_loss0.12100131139159202.pypots
2024-05-25 06:26:32 [INFO]: Epoch 052 - training loss: 0.1206, validation loss: 0.1199
2024-05-25 06:26:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch52_loss0.1198943629860878.pypots
2024-05-25 06:26:49 [INFO]: Epoch 053 - training loss: 0.1332, validation loss: 0.1191
2024-05-25 06:26:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch53_loss0.11914279162883759.pypots
2024-05-25 06:27:05 [INFO]: Epoch 054 - training loss: 0.1252, validation loss: 0.1229
2024-05-25 06:27:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch54_loss0.12290782406926155.pypots
2024-05-25 06:27:22 [INFO]: Epoch 055 - training loss: 0.1226, validation loss: 0.1245
2024-05-25 06:27:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch55_loss0.12445557340979577.pypots
2024-05-25 06:27:39 [INFO]: Epoch 056 - training loss: 0.1147, validation loss: 0.1202
2024-05-25 06:27:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch56_loss0.12023642808198928.pypots
2024-05-25 06:27:55 [INFO]: Epoch 057 - training loss: 0.1189, validation loss: 0.1218
2024-05-25 06:27:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch57_loss0.1217736653983593.pypots
2024-05-25 06:28:12 [INFO]: Epoch 058 - training loss: 0.1126, validation loss: 0.1178
2024-05-25 06:28:12 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch58_loss0.11781354099512101.pypots
2024-05-25 06:28:29 [INFO]: Epoch 059 - training loss: 0.1136, validation loss: 0.1173
2024-05-25 06:28:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch59_loss0.11731418743729591.pypots
2024-05-25 06:28:46 [INFO]: Epoch 060 - training loss: 0.1064, validation loss: 0.1179
2024-05-25 06:28:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch60_loss0.11785191893577576.pypots
2024-05-25 06:29:02 [INFO]: Epoch 061 - training loss: 0.1222, validation loss: 0.1192
2024-05-25 06:29:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch61_loss0.11918085888028145.pypots
2024-05-25 06:29:19 [INFO]: Epoch 062 - training loss: 0.1131, validation loss: 0.1204
2024-05-25 06:29:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch62_loss0.12037319168448449.pypots
2024-05-25 06:29:36 [INFO]: Epoch 063 - training loss: 0.1205, validation loss: 0.1148
2024-05-25 06:29:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch63_loss0.11476656273007393.pypots
2024-05-25 06:29:52 [INFO]: Epoch 064 - training loss: 0.1149, validation loss: 0.1228
2024-05-25 06:29:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch64_loss0.1228277139365673.pypots
2024-05-25 06:30:09 [INFO]: Epoch 065 - training loss: 0.1280, validation loss: 0.1201
2024-05-25 06:30:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch65_loss0.12011364847421646.pypots
2024-05-25 06:30:26 [INFO]: Epoch 066 - training loss: 0.1210, validation loss: 0.1190
2024-05-25 06:30:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch66_loss0.11898940950632095.pypots
2024-05-25 06:30:43 [INFO]: Epoch 067 - training loss: 0.1154, validation loss: 0.1165
2024-05-25 06:30:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch67_loss0.11650659143924713.pypots
2024-05-25 06:30:59 [INFO]: Epoch 068 - training loss: 0.1132, validation loss: 0.1163
2024-05-25 06:30:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch68_loss0.11634804010391235.pypots
2024-05-25 06:31:16 [INFO]: Epoch 069 - training loss: 0.1130, validation loss: 0.1200
2024-05-25 06:31:16 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch69_loss0.12003531977534294.pypots
2024-05-25 06:31:33 [INFO]: Epoch 070 - training loss: 0.1162, validation loss: 0.1248
2024-05-25 06:31:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch70_loss0.12479592859745026.pypots
2024-05-25 06:31:50 [INFO]: Epoch 071 - training loss: 0.1259, validation loss: 0.1156
2024-05-25 06:31:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch71_loss0.11560090556740761.pypots
2024-05-25 06:32:06 [INFO]: Epoch 072 - training loss: 0.1170, validation loss: 0.1158
2024-05-25 06:32:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch72_loss0.11583462953567505.pypots
2024-05-25 06:32:23 [INFO]: Epoch 073 - training loss: 0.1084, validation loss: 0.1154
2024-05-25 06:32:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI_epoch73_loss0.11541885808110237.pypots
2024-05-25 06:32:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:32:23 [INFO]: Finished training. The best model is from epoch#63.
2024-05-25 06:32:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240525_T061202/CSDI.pypots
2024-05-25 06:34:43 [INFO]: CSDI on Air-Quality: MAE=0.1414, MSE=0.8366
2024-05-25 06:34:43 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/CSDI_air_quality/imputation.pkl
2024-05-25 06:34:43 [INFO]: Using the given device: cuda:0
2024-05-25 06:34:43 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/GPVAE_air_quality/20240525_T063443
2024-05-25 06:34:43 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/GPVAE_air_quality/20240525_T063443/tensorboard
2024-05-25 06:34:43 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 06:34:44 [INFO]: Epoch 001 - training loss: 63111.2840, validation loss: 0.6426
2024-05-25 06:34:44 [INFO]: Epoch 002 - training loss: 41909.4065, validation loss: 0.5591
2024-05-25 06:34:45 [INFO]: Epoch 003 - training loss: 41624.1752, validation loss: 0.5316
2024-05-25 06:34:45 [INFO]: Epoch 004 - training loss: 41504.3717, validation loss: 0.4846
2024-05-25 06:34:45 [INFO]: Epoch 005 - training loss: 41432.5466, validation loss: 0.4463
2024-05-25 06:34:46 [INFO]: Epoch 006 - training loss: 41378.4102, validation loss: 0.4358
2024-05-25 06:34:46 [INFO]: Epoch 007 - training loss: 41329.9311, validation loss: 0.3810
2024-05-25 06:34:46 [INFO]: Epoch 008 - training loss: 41300.4440, validation loss: 0.3844
2024-05-25 06:34:47 [INFO]: Epoch 009 - training loss: 41259.3647, validation loss: 0.3633
2024-05-25 06:34:47 [INFO]: Epoch 010 - training loss: 41240.4973, validation loss: 0.3387
2024-05-25 06:34:48 [INFO]: Epoch 011 - training loss: 41224.5162, validation loss: 0.3422
2024-05-25 06:34:48 [INFO]: Epoch 012 - training loss: 41211.8401, validation loss: 0.3347
2024-05-25 06:34:48 [INFO]: Epoch 013 - training loss: 41199.6538, validation loss: 0.3163
2024-05-25 06:34:49 [INFO]: Epoch 014 - training loss: 41168.2007, validation loss: 0.3205
2024-05-25 06:34:49 [INFO]: Epoch 015 - training loss: 41226.6434, validation loss: 0.3792
2024-05-25 06:34:49 [INFO]: Epoch 016 - training loss: 41267.0832, validation loss: 0.3284
2024-05-25 06:34:50 [INFO]: Epoch 017 - training loss: 41196.0285, validation loss: 0.2921
2024-05-25 06:34:50 [INFO]: Epoch 018 - training loss: 41133.0486, validation loss: 0.2923
2024-05-25 06:34:51 [INFO]: Epoch 019 - training loss: 41129.8696, validation loss: 0.2831
2024-05-25 06:34:51 [INFO]: Epoch 020 - training loss: 41121.2746, validation loss: 0.2849
2024-05-25 06:34:51 [INFO]: Epoch 021 - training loss: 41112.6460, validation loss: 0.2762
2024-05-25 06:34:52 [INFO]: Epoch 022 - training loss: 41120.5525, validation loss: 0.2799
2024-05-25 06:34:52 [INFO]: Epoch 023 - training loss: 41098.5000, validation loss: 0.2691
2024-05-25 06:34:52 [INFO]: Epoch 024 - training loss: 41091.7866, validation loss: 0.2700
2024-05-25 06:34:53 [INFO]: Epoch 025 - training loss: 41120.1670, validation loss: 0.2678
2024-05-25 06:34:53 [INFO]: Epoch 026 - training loss: 41113.0177, validation loss: 0.2867
2024-05-25 06:34:54 [INFO]: Epoch 027 - training loss: 41096.7750, validation loss: 0.2601
2024-05-25 06:34:54 [INFO]: Epoch 028 - training loss: 41084.7341, validation loss: 0.2568
2024-05-25 06:34:54 [INFO]: Epoch 029 - training loss: 41071.8381, validation loss: 0.2558
2024-05-25 06:34:55 [INFO]: Epoch 030 - training loss: 41064.3283, validation loss: 0.2682
2024-05-25 06:34:55 [INFO]: Epoch 031 - training loss: 41064.4146, validation loss: 0.2499
2024-05-25 06:34:55 [INFO]: Epoch 032 - training loss: 41059.3194, validation loss: 0.2486
2024-05-25 06:34:56 [INFO]: Epoch 033 - training loss: 41052.7679, validation loss: 0.2477
2024-05-25 06:34:56 [INFO]: Epoch 034 - training loss: 41055.6781, validation loss: 0.2511
2024-05-25 06:34:57 [INFO]: Epoch 035 - training loss: 41049.2120, validation loss: 0.2475
2024-05-25 06:34:57 [INFO]: Epoch 036 - training loss: 41051.3287, validation loss: 0.2407
2024-05-25 06:34:57 [INFO]: Epoch 037 - training loss: 41042.6266, validation loss: 0.2436
2024-05-25 06:34:58 [INFO]: Epoch 038 - training loss: 41043.6081, validation loss: 0.2419
2024-05-25 06:34:58 [INFO]: Epoch 039 - training loss: 41044.3027, validation loss: 0.2413
2024-05-25 06:34:58 [INFO]: Epoch 040 - training loss: 41046.8602, validation loss: 0.2393
2024-05-25 06:34:59 [INFO]: Epoch 041 - training loss: 41039.6139, validation loss: 0.2559
2024-05-25 06:34:59 [INFO]: Epoch 042 - training loss: 41042.3573, validation loss: 0.2465
2024-05-25 06:35:00 [INFO]: Epoch 043 - training loss: 41032.1685, validation loss: 0.2423
2024-05-25 06:35:00 [INFO]: Epoch 044 - training loss: 41032.1470, validation loss: 0.2420
2024-05-25 06:35:00 [INFO]: Epoch 045 - training loss: 41031.4303, validation loss: 0.2362
2024-05-25 06:35:01 [INFO]: Epoch 046 - training loss: 41073.4690, validation loss: 0.2380
2024-05-25 06:35:01 [INFO]: Epoch 047 - training loss: 41050.2458, validation loss: 0.2681
2024-05-25 06:35:01 [INFO]: Epoch 048 - training loss: 41060.1484, validation loss: 0.2512
2024-05-25 06:35:02 [INFO]: Epoch 049 - training loss: 41043.2836, validation loss: 0.2421
2024-05-25 06:35:02 [INFO]: Epoch 050 - training loss: 41030.7969, validation loss: 0.2341
2024-05-25 06:35:02 [INFO]: Epoch 051 - training loss: 41025.3720, validation loss: 0.2291
2024-05-25 06:35:03 [INFO]: Epoch 052 - training loss: 41013.2902, validation loss: 0.2244
2024-05-25 06:35:03 [INFO]: Epoch 053 - training loss: 41011.3689, validation loss: 0.2298
2024-05-25 06:35:04 [INFO]: Epoch 054 - training loss: 41017.8843, validation loss: 0.2323
2024-05-25 06:35:04 [INFO]: Epoch 055 - training loss: 41011.1499, validation loss: 0.2313
2024-05-25 06:35:04 [INFO]: Epoch 056 - training loss: 41032.0116, validation loss: 0.2542
2024-05-25 06:35:05 [INFO]: Epoch 057 - training loss: 41064.2031, validation loss: 0.2454
2024-05-25 06:35:05 [INFO]: Epoch 058 - training loss: 41072.3328, validation loss: 0.2475
2024-05-25 06:35:05 [INFO]: Epoch 059 - training loss: 41052.1170, validation loss: 0.2445
2024-05-25 06:35:06 [INFO]: Epoch 060 - training loss: 41030.9501, validation loss: 0.2336
2024-05-25 06:35:06 [INFO]: Epoch 061 - training loss: 41011.2216, validation loss: 0.2278
2024-05-25 06:35:07 [INFO]: Epoch 062 - training loss: 41011.5350, validation loss: 0.2370
2024-05-25 06:35:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:35:07 [INFO]: Finished training. The best model is from epoch#52.
2024-05-25 06:35:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/GPVAE_air_quality/20240525_T063443/GPVAE.pypots
2024-05-25 06:35:07 [INFO]: GP-VAE on Air-Quality: MAE=0.2718, MSE=0.3422
2024-05-25 06:35:07 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/GPVAE_air_quality/imputation.pkl
2024-05-25 06:35:07 [INFO]: Using the given device: cuda:0
2024-05-25 06:35:07 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/USGAN_air_quality/20240525_T063507
2024-05-25 06:35:07 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/USGAN_air_quality/20240525_T063507/tensorboard
2024-05-25 06:35:07 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 06:35:12 [INFO]: Epoch 001 - generator training loss: 0.5287, discriminator training loss: 0.3768, validation loss: 0.5137
2024-05-25 06:35:16 [INFO]: Epoch 002 - generator training loss: 0.1562, discriminator training loss: 0.2430, validation loss: 0.3833
2024-05-25 06:35:21 [INFO]: Epoch 003 - generator training loss: 0.0997, discriminator training loss: 0.2381, validation loss: 0.3130
2024-05-25 06:35:25 [INFO]: Epoch 004 - generator training loss: 0.0587, discriminator training loss: 0.2371, validation loss: 0.2709
2024-05-25 06:35:29 [INFO]: Epoch 005 - generator training loss: 0.0339, discriminator training loss: 0.2364, validation loss: 0.2452
2024-05-25 06:35:34 [INFO]: Epoch 006 - generator training loss: 0.0193, discriminator training loss: 0.2352, validation loss: 0.2261
2024-05-25 06:35:38 [INFO]: Epoch 007 - generator training loss: 0.0042, discriminator training loss: 0.2341, validation loss: 0.2121
2024-05-25 06:35:42 [INFO]: Epoch 008 - generator training loss: -0.0097, discriminator training loss: 0.2327, validation loss: 0.2020
2024-05-25 06:35:47 [INFO]: Epoch 009 - generator training loss: -0.0152, discriminator training loss: 0.2316, validation loss: 0.1930
2024-05-25 06:35:51 [INFO]: Epoch 010 - generator training loss: -0.0226, discriminator training loss: 0.2297, validation loss: 0.1856
2024-05-25 06:35:55 [INFO]: Epoch 011 - generator training loss: -0.0276, discriminator training loss: 0.2281, validation loss: 0.1805
2024-05-25 06:36:00 [INFO]: Epoch 012 - generator training loss: -0.0327, discriminator training loss: 0.2268, validation loss: 0.1751
2024-05-25 06:36:04 [INFO]: Epoch 013 - generator training loss: -0.0334, discriminator training loss: 0.2247, validation loss: 0.1706
2024-05-25 06:36:08 [INFO]: Epoch 014 - generator training loss: -0.0382, discriminator training loss: 0.2231, validation loss: 0.1667
2024-05-25 06:36:13 [INFO]: Epoch 015 - generator training loss: -0.0407, discriminator training loss: 0.2213, validation loss: 0.1622
2024-05-25 06:36:17 [INFO]: Epoch 016 - generator training loss: -0.0433, discriminator training loss: 0.2196, validation loss: 0.1596
2024-05-25 06:36:21 [INFO]: Epoch 017 - generator training loss: -0.0463, discriminator training loss: 0.2179, validation loss: 0.1565
2024-05-25 06:36:26 [INFO]: Epoch 018 - generator training loss: -0.0475, discriminator training loss: 0.2168, validation loss: 0.1537
2024-05-25 06:36:30 [INFO]: Epoch 019 - generator training loss: -0.0483, discriminator training loss: 0.2148, validation loss: 0.1510
2024-05-25 06:36:34 [INFO]: Epoch 020 - generator training loss: -0.0497, discriminator training loss: 0.2132, validation loss: 0.1488
2024-05-25 06:36:39 [INFO]: Epoch 021 - generator training loss: -0.0508, discriminator training loss: 0.2118, validation loss: 0.1460
2024-05-25 06:36:43 [INFO]: Epoch 022 - generator training loss: -0.0496, discriminator training loss: 0.2100, validation loss: 0.1447
2024-05-25 06:36:47 [INFO]: Epoch 023 - generator training loss: -0.0515, discriminator training loss: 0.2080, validation loss: 0.1411
2024-05-25 06:36:52 [INFO]: Epoch 024 - generator training loss: -0.0531, discriminator training loss: 0.2066, validation loss: 0.1393
2024-05-25 06:36:56 [INFO]: Epoch 025 - generator training loss: -0.0525, discriminator training loss: 0.2049, validation loss: 0.1374
2024-05-25 06:37:00 [INFO]: Epoch 026 - generator training loss: -0.0540, discriminator training loss: 0.2030, validation loss: 0.1360
2024-05-25 06:37:05 [INFO]: Epoch 027 - generator training loss: -0.0545, discriminator training loss: 0.2014, validation loss: 0.1343
2024-05-25 06:37:09 [INFO]: Epoch 028 - generator training loss: -0.0537, discriminator training loss: 0.1996, validation loss: 0.1325
2024-05-25 06:37:13 [INFO]: Epoch 029 - generator training loss: -0.0539, discriminator training loss: 0.1981, validation loss: 0.1306
2024-05-25 06:37:18 [INFO]: Epoch 030 - generator training loss: -0.0549, discriminator training loss: 0.1963, validation loss: 0.1297
2024-05-25 06:37:22 [INFO]: Epoch 031 - generator training loss: -0.0549, discriminator training loss: 0.1946, validation loss: 0.1278
2024-05-25 06:37:27 [INFO]: Epoch 032 - generator training loss: -0.0528, discriminator training loss: 0.1927, validation loss: 0.1267
2024-05-25 06:37:31 [INFO]: Epoch 033 - generator training loss: -0.0525, discriminator training loss: 0.1911, validation loss: 0.1247
2024-05-25 06:37:35 [INFO]: Epoch 034 - generator training loss: -0.0544, discriminator training loss: 0.1895, validation loss: 0.1244
2024-05-25 06:37:40 [INFO]: Epoch 035 - generator training loss: -0.0532, discriminator training loss: 0.1878, validation loss: 0.1231
2024-05-25 06:37:44 [INFO]: Epoch 036 - generator training loss: -0.0523, discriminator training loss: 0.1862, validation loss: 0.1219
2024-05-25 06:37:48 [INFO]: Epoch 037 - generator training loss: -0.0531, discriminator training loss: 0.1846, validation loss: 0.1210
2024-05-25 06:37:53 [INFO]: Epoch 038 - generator training loss: -0.0523, discriminator training loss: 0.1830, validation loss: 0.1202
2024-05-25 06:37:57 [INFO]: Epoch 039 - generator training loss: -0.0526, discriminator training loss: 0.1814, validation loss: 0.1187
2024-05-25 06:38:01 [INFO]: Epoch 040 - generator training loss: -0.0520, discriminator training loss: 0.1800, validation loss: 0.1183
2024-05-25 06:38:06 [INFO]: Epoch 041 - generator training loss: -0.0512, discriminator training loss: 0.1783, validation loss: 0.1171
2024-05-25 06:38:10 [INFO]: Epoch 042 - generator training loss: -0.0511, discriminator training loss: 0.1769, validation loss: 0.1162
2024-05-25 06:38:14 [INFO]: Epoch 043 - generator training loss: -0.0502, discriminator training loss: 0.1754, validation loss: 0.1158
2024-05-25 06:38:19 [INFO]: Epoch 044 - generator training loss: -0.0501, discriminator training loss: 0.1739, validation loss: 0.1150
2024-05-25 06:38:23 [INFO]: Epoch 045 - generator training loss: -0.0490, discriminator training loss: 0.1726, validation loss: 0.1140
2024-05-25 06:38:27 [INFO]: Epoch 046 - generator training loss: -0.0497, discriminator training loss: 0.1714, validation loss: 0.1137
2024-05-25 06:38:32 [INFO]: Epoch 047 - generator training loss: -0.0489, discriminator training loss: 0.1699, validation loss: 0.1128
2024-05-25 06:38:36 [INFO]: Epoch 048 - generator training loss: -0.0488, discriminator training loss: 0.1688, validation loss: 0.1123
2024-05-25 06:38:41 [INFO]: Epoch 049 - generator training loss: -0.0487, discriminator training loss: 0.1674, validation loss: 0.1118
2024-05-25 06:38:45 [INFO]: Epoch 050 - generator training loss: -0.0484, discriminator training loss: 0.1660, validation loss: 0.1111
2024-05-25 06:38:49 [INFO]: Epoch 051 - generator training loss: -0.0472, discriminator training loss: 0.1651, validation loss: 0.1106
2024-05-25 06:38:54 [INFO]: Epoch 052 - generator training loss: -0.0477, discriminator training loss: 0.1642, validation loss: 0.1097
2024-05-25 06:38:58 [INFO]: Epoch 053 - generator training loss: -0.0462, discriminator training loss: 0.1630, validation loss: 0.1096
2024-05-25 06:39:02 [INFO]: Epoch 054 - generator training loss: -0.0469, discriminator training loss: 0.1618, validation loss: 0.1090
2024-05-25 06:39:07 [INFO]: Epoch 055 - generator training loss: -0.0455, discriminator training loss: 0.1606, validation loss: 0.1081
2024-05-25 06:39:11 [INFO]: Epoch 056 - generator training loss: -0.0462, discriminator training loss: 0.1599, validation loss: 0.1083
2024-05-25 06:39:15 [INFO]: Epoch 057 - generator training loss: -0.0465, discriminator training loss: 0.1592, validation loss: 0.1074
2024-05-25 06:39:20 [INFO]: Epoch 058 - generator training loss: -0.0456, discriminator training loss: 0.1578, validation loss: 0.1076
2024-05-25 06:39:24 [INFO]: Epoch 059 - generator training loss: -0.0455, discriminator training loss: 0.1571, validation loss: 0.1069
2024-05-25 06:39:28 [INFO]: Epoch 060 - generator training loss: -0.0450, discriminator training loss: 0.1560, validation loss: 0.1073
2024-05-25 06:39:33 [INFO]: Epoch 061 - generator training loss: -0.0451, discriminator training loss: 0.1553, validation loss: 0.1063
2024-05-25 06:39:37 [INFO]: Epoch 062 - generator training loss: -0.0449, discriminator training loss: 0.1549, validation loss: 0.1057
2024-05-25 06:39:41 [INFO]: Epoch 063 - generator training loss: -0.0452, discriminator training loss: 0.1543, validation loss: 0.1054
2024-05-25 06:39:45 [INFO]: Epoch 064 - generator training loss: -0.0445, discriminator training loss: 0.1533, validation loss: 0.1051
2024-05-25 06:39:50 [INFO]: Epoch 065 - generator training loss: -0.0450, discriminator training loss: 0.1526, validation loss: 0.1049
2024-05-25 06:39:54 [INFO]: Epoch 066 - generator training loss: -0.0448, discriminator training loss: 0.1521, validation loss: 0.1044
2024-05-25 06:39:59 [INFO]: Epoch 067 - generator training loss: -0.0438, discriminator training loss: 0.1511, validation loss: 0.1038
2024-05-25 06:40:03 [INFO]: Epoch 068 - generator training loss: -0.0449, discriminator training loss: 0.1510, validation loss: 0.1037
2024-05-25 06:40:07 [INFO]: Epoch 069 - generator training loss: -0.0443, discriminator training loss: 0.1503, validation loss: 0.1037
2024-05-25 06:40:12 [INFO]: Epoch 070 - generator training loss: -0.0447, discriminator training loss: 0.1496, validation loss: 0.1033
2024-05-25 06:40:16 [INFO]: Epoch 071 - generator training loss: -0.0440, discriminator training loss: 0.1488, validation loss: 0.1035
2024-05-25 06:40:20 [INFO]: Epoch 072 - generator training loss: -0.0444, discriminator training loss: 0.1486, validation loss: 0.1026
2024-05-25 06:40:25 [INFO]: Epoch 073 - generator training loss: -0.0438, discriminator training loss: 0.1481, validation loss: 0.1020
2024-05-25 06:40:29 [INFO]: Epoch 074 - generator training loss: -0.0431, discriminator training loss: 0.1478, validation loss: 0.1030
2024-05-25 06:40:33 [INFO]: Epoch 075 - generator training loss: -0.0439, discriminator training loss: 0.1471, validation loss: 0.1019
2024-05-25 06:40:38 [INFO]: Epoch 076 - generator training loss: -0.0434, discriminator training loss: 0.1465, validation loss: 0.1013
2024-05-25 06:40:42 [INFO]: Epoch 077 - generator training loss: -0.0451, discriminator training loss: 0.1460, validation loss: 0.1016
2024-05-25 06:40:46 [INFO]: Epoch 078 - generator training loss: -0.0443, discriminator training loss: 0.1458, validation loss: 0.1012
2024-05-25 06:40:51 [INFO]: Epoch 079 - generator training loss: -0.0440, discriminator training loss: 0.1450, validation loss: 0.1012
2024-05-25 06:40:55 [INFO]: Epoch 080 - generator training loss: -0.0439, discriminator training loss: 0.1448, validation loss: 0.1013
2024-05-25 06:40:59 [INFO]: Epoch 081 - generator training loss: -0.0437, discriminator training loss: 0.1445, validation loss: 0.1009
2024-05-25 06:41:04 [INFO]: Epoch 082 - generator training loss: -0.0432, discriminator training loss: 0.1441, validation loss: 0.1007
2024-05-25 06:41:08 [INFO]: Epoch 083 - generator training loss: -0.0440, discriminator training loss: 0.1437, validation loss: 0.1007
2024-05-25 06:41:12 [INFO]: Epoch 084 - generator training loss: -0.0440, discriminator training loss: 0.1433, validation loss: 0.1007
2024-05-25 06:41:16 [INFO]: Epoch 085 - generator training loss: -0.0448, discriminator training loss: 0.1429, validation loss: 0.1004
2024-05-25 06:41:21 [INFO]: Epoch 086 - generator training loss: -0.0440, discriminator training loss: 0.1428, validation loss: 0.0998
2024-05-25 06:41:25 [INFO]: Epoch 087 - generator training loss: -0.0439, discriminator training loss: 0.1422, validation loss: 0.0995
2024-05-25 06:41:29 [INFO]: Epoch 088 - generator training loss: -0.0449, discriminator training loss: 0.1425, validation loss: 0.0993
2024-05-25 06:41:34 [INFO]: Epoch 089 - generator training loss: -0.0441, discriminator training loss: 0.1416, validation loss: 0.0995
2024-05-25 06:41:38 [INFO]: Epoch 090 - generator training loss: -0.0443, discriminator training loss: 0.1418, validation loss: 0.0997
2024-05-25 06:41:42 [INFO]: Epoch 091 - generator training loss: -0.0438, discriminator training loss: 0.1408, validation loss: 0.0994
2024-05-25 06:41:47 [INFO]: Epoch 092 - generator training loss: -0.0448, discriminator training loss: 0.1407, validation loss: 0.0991
2024-05-25 06:41:51 [INFO]: Epoch 093 - generator training loss: -0.0449, discriminator training loss: 0.1406, validation loss: 0.0995
2024-05-25 06:41:55 [INFO]: Epoch 094 - generator training loss: -0.0453, discriminator training loss: 0.1406, validation loss: 0.0991
2024-05-25 06:42:00 [INFO]: Epoch 095 - generator training loss: -0.0448, discriminator training loss: 0.1401, validation loss: 0.0996
2024-05-25 06:42:04 [INFO]: Epoch 096 - generator training loss: -0.0444, discriminator training loss: 0.1396, validation loss: 0.0987
2024-05-25 06:42:08 [INFO]: Epoch 097 - generator training loss: -0.0451, discriminator training loss: 0.1394, validation loss: 0.0990
2024-05-25 06:42:13 [INFO]: Epoch 098 - generator training loss: -0.0448, discriminator training loss: 0.1392, validation loss: 0.0992
2024-05-25 06:42:17 [INFO]: Epoch 099 - generator training loss: -0.0451, discriminator training loss: 0.1388, validation loss: 0.0985
2024-05-25 06:42:21 [INFO]: Epoch 100 - generator training loss: -0.0459, discriminator training loss: 0.1388, validation loss: 0.0991
2024-05-25 06:42:26 [INFO]: Epoch 101 - generator training loss: -0.0459, discriminator training loss: 0.1385, validation loss: 0.0987
2024-05-25 06:42:30 [INFO]: Epoch 102 - generator training loss: -0.0457, discriminator training loss: 0.1383, validation loss: 0.0983
2024-05-25 06:42:34 [INFO]: Epoch 103 - generator training loss: -0.0449, discriminator training loss: 0.1381, validation loss: 0.0991
2024-05-25 06:42:39 [INFO]: Epoch 104 - generator training loss: -0.0451, discriminator training loss: 0.1382, validation loss: 0.0992
2024-05-25 06:42:43 [INFO]: Epoch 105 - generator training loss: -0.0452, discriminator training loss: 0.1376, validation loss: 0.0983
2024-05-25 06:42:47 [INFO]: Epoch 106 - generator training loss: -0.0451, discriminator training loss: 0.1377, validation loss: 0.0999
2024-05-25 06:42:52 [INFO]: Epoch 107 - generator training loss: -0.0459, discriminator training loss: 0.1372, validation loss: 0.0982
2024-05-25 06:42:56 [INFO]: Epoch 108 - generator training loss: -0.0466, discriminator training loss: 0.1374, validation loss: 0.0992
2024-05-25 06:43:00 [INFO]: Epoch 109 - generator training loss: -0.0461, discriminator training loss: 0.1368, validation loss: 0.0983
2024-05-25 06:43:05 [INFO]: Epoch 110 - generator training loss: -0.0455, discriminator training loss: 0.1369, validation loss: 0.0989
2024-05-25 06:43:09 [INFO]: Epoch 111 - generator training loss: -0.0459, discriminator training loss: 0.1366, validation loss: 0.0983
2024-05-25 06:43:14 [INFO]: Epoch 112 - generator training loss: -0.0460, discriminator training loss: 0.1361, validation loss: 0.0983
2024-05-25 06:43:18 [INFO]: Epoch 113 - generator training loss: -0.0461, discriminator training loss: 0.1367, validation loss: 0.0983
2024-05-25 06:43:22 [INFO]: Epoch 114 - generator training loss: -0.0469, discriminator training loss: 0.1363, validation loss: 0.0982
2024-05-25 06:43:26 [INFO]: Epoch 115 - generator training loss: -0.0466, discriminator training loss: 0.1362, validation loss: 0.0986
2024-05-25 06:43:31 [INFO]: Epoch 116 - generator training loss: -0.0466, discriminator training loss: 0.1358, validation loss: 0.0983
2024-05-25 06:43:35 [INFO]: Epoch 117 - generator training loss: -0.0469, discriminator training loss: 0.1356, validation loss: 0.0978
2024-05-25 06:43:39 [INFO]: Epoch 118 - generator training loss: -0.0461, discriminator training loss: 0.1355, validation loss: 0.0988
2024-05-25 06:43:44 [INFO]: Epoch 119 - generator training loss: -0.0470, discriminator training loss: 0.1359, validation loss: 0.0981
2024-05-25 06:43:48 [INFO]: Epoch 120 - generator training loss: -0.0472, discriminator training loss: 0.1353, validation loss: 0.0981
2024-05-25 06:43:53 [INFO]: Epoch 121 - generator training loss: -0.0477, discriminator training loss: 0.1350, validation loss: 0.0988
2024-05-25 06:43:57 [INFO]: Epoch 122 - generator training loss: -0.0465, discriminator training loss: 0.1346, validation loss: 0.0980
2024-05-25 06:44:01 [INFO]: Epoch 123 - generator training loss: -0.0475, discriminator training loss: 0.1346, validation loss: 0.0981
2024-05-25 06:44:06 [INFO]: Epoch 124 - generator training loss: -0.0476, discriminator training loss: 0.1347, validation loss: 0.0989
2024-05-25 06:44:10 [INFO]: Epoch 125 - generator training loss: -0.0478, discriminator training loss: 0.1342, validation loss: 0.0986
2024-05-25 06:44:14 [INFO]: Epoch 126 - generator training loss: -0.0472, discriminator training loss: 0.1343, validation loss: 0.0986
2024-05-25 06:44:18 [INFO]: Epoch 127 - generator training loss: -0.0478, discriminator training loss: 0.1343, validation loss: 0.0987
2024-05-25 06:44:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:44:18 [INFO]: Finished training. The best model is from epoch#117.
2024-05-25 06:44:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/USGAN_air_quality/20240525_T063507/USGAN.pypots
2024-05-25 06:44:19 [INFO]: US-GAN on Air-Quality: MAE=0.1426, MSE=0.1803
2024-05-25 06:44:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/USGAN_air_quality/imputation.pkl
2024-05-25 06:44:19 [INFO]: Using the given device: cuda:0
2024-05-25 06:44:19 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/BRITS_air_quality/20240525_T064419
2024-05-25 06:44:19 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/BRITS_air_quality/20240525_T064419/tensorboard
2024-05-25 06:44:19 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 06:44:23 [INFO]: Epoch 001 - training loss: 1.4038, validation loss: 0.9225
2024-05-25 06:44:26 [INFO]: Epoch 002 - training loss: 1.1395, validation loss: 0.6837
2024-05-25 06:44:29 [INFO]: Epoch 003 - training loss: 0.9457, validation loss: 0.5724
2024-05-25 06:44:32 [INFO]: Epoch 004 - training loss: 0.8339, validation loss: 0.5075
2024-05-25 06:44:35 [INFO]: Epoch 005 - training loss: 0.7634, validation loss: 0.4637
2024-05-25 06:44:38 [INFO]: Epoch 006 - training loss: 0.7067, validation loss: 0.4307
2024-05-25 06:44:41 [INFO]: Epoch 007 - training loss: 0.6650, validation loss: 0.4021
2024-05-25 06:44:43 [INFO]: Epoch 008 - training loss: 0.6320, validation loss: 0.3793
2024-05-25 06:44:46 [INFO]: Epoch 009 - training loss: 0.6050, validation loss: 0.3614
2024-05-25 06:44:49 [INFO]: Epoch 010 - training loss: 0.5851, validation loss: 0.3445
2024-05-25 06:44:52 [INFO]: Epoch 011 - training loss: 0.5650, validation loss: 0.3311
2024-05-25 06:44:55 [INFO]: Epoch 012 - training loss: 0.5513, validation loss: 0.3197
2024-05-25 06:44:58 [INFO]: Epoch 013 - training loss: 0.5365, validation loss: 0.3096
2024-05-25 06:45:01 [INFO]: Epoch 014 - training loss: 0.5261, validation loss: 0.3011
2024-05-25 06:45:04 [INFO]: Epoch 015 - training loss: 0.5147, validation loss: 0.2938
2024-05-25 06:45:07 [INFO]: Epoch 016 - training loss: 0.5053, validation loss: 0.2870
2024-05-25 06:45:10 [INFO]: Epoch 017 - training loss: 0.4959, validation loss: 0.2810
2024-05-25 06:45:13 [INFO]: Epoch 018 - training loss: 0.4885, validation loss: 0.2752
2024-05-25 06:45:16 [INFO]: Epoch 019 - training loss: 0.4796, validation loss: 0.2702
2024-05-25 06:45:19 [INFO]: Epoch 020 - training loss: 0.4721, validation loss: 0.2649
2024-05-25 06:45:22 [INFO]: Epoch 021 - training loss: 0.4667, validation loss: 0.2608
2024-05-25 06:45:24 [INFO]: Epoch 022 - training loss: 0.4592, validation loss: 0.2564
2024-05-25 06:45:27 [INFO]: Epoch 023 - training loss: 0.4525, validation loss: 0.2524
2024-05-25 06:45:30 [INFO]: Epoch 024 - training loss: 0.4472, validation loss: 0.2483
2024-05-25 06:45:33 [INFO]: Epoch 025 - training loss: 0.4404, validation loss: 0.2448
2024-05-25 06:45:36 [INFO]: Epoch 026 - training loss: 0.4360, validation loss: 0.2409
2024-05-25 06:45:39 [INFO]: Epoch 027 - training loss: 0.4306, validation loss: 0.2370
2024-05-25 06:45:42 [INFO]: Epoch 028 - training loss: 0.4250, validation loss: 0.2338
2024-05-25 06:45:45 [INFO]: Epoch 029 - training loss: 0.4216, validation loss: 0.2309
2024-05-25 06:45:48 [INFO]: Epoch 030 - training loss: 0.4158, validation loss: 0.2272
2024-05-25 06:45:51 [INFO]: Epoch 031 - training loss: 0.4121, validation loss: 0.2240
2024-05-25 06:45:54 [INFO]: Epoch 032 - training loss: 0.4070, validation loss: 0.2203
2024-05-25 06:45:57 [INFO]: Epoch 033 - training loss: 0.4020, validation loss: 0.2178
2024-05-25 06:45:59 [INFO]: Epoch 034 - training loss: 0.3986, validation loss: 0.2148
2024-05-25 06:46:02 [INFO]: Epoch 035 - training loss: 0.3948, validation loss: 0.2126
2024-05-25 06:46:05 [INFO]: Epoch 036 - training loss: 0.3909, validation loss: 0.2089
2024-05-25 06:46:08 [INFO]: Epoch 037 - training loss: 0.3878, validation loss: 0.2070
2024-05-25 06:46:11 [INFO]: Epoch 038 - training loss: 0.3836, validation loss: 0.2033
2024-05-25 06:46:14 [INFO]: Epoch 039 - training loss: 0.3810, validation loss: 0.2009
2024-05-25 06:46:17 [INFO]: Epoch 040 - training loss: 0.3776, validation loss: 0.1981
2024-05-25 06:46:20 [INFO]: Epoch 041 - training loss: 0.3737, validation loss: 0.1957
2024-05-25 06:46:23 [INFO]: Epoch 042 - training loss: 0.3714, validation loss: 0.1931
2024-05-25 06:46:26 [INFO]: Epoch 043 - training loss: 0.3685, validation loss: 0.1908
2024-05-25 06:46:29 [INFO]: Epoch 044 - training loss: 0.3645, validation loss: 0.1886
2024-05-25 06:46:32 [INFO]: Epoch 045 - training loss: 0.3618, validation loss: 0.1865
2024-05-25 06:46:34 [INFO]: Epoch 046 - training loss: 0.3589, validation loss: 0.1841
2024-05-25 06:46:37 [INFO]: Epoch 047 - training loss: 0.3566, validation loss: 0.1818
2024-05-25 06:46:40 [INFO]: Epoch 048 - training loss: 0.3541, validation loss: 0.1797
2024-05-25 06:46:43 [INFO]: Epoch 049 - training loss: 0.3522, validation loss: 0.1777
2024-05-25 06:46:46 [INFO]: Epoch 050 - training loss: 0.3492, validation loss: 0.1760
2024-05-25 06:46:49 [INFO]: Epoch 051 - training loss: 0.3469, validation loss: 0.1741
2024-05-25 06:46:52 [INFO]: Epoch 052 - training loss: 0.3447, validation loss: 0.1721
2024-05-25 06:46:55 [INFO]: Epoch 053 - training loss: 0.3442, validation loss: 0.1708
2024-05-25 06:46:58 [INFO]: Epoch 054 - training loss: 0.3402, validation loss: 0.1686
2024-05-25 06:47:01 [INFO]: Epoch 055 - training loss: 0.3389, validation loss: 0.1666
2024-05-25 06:47:04 [INFO]: Epoch 056 - training loss: 0.3367, validation loss: 0.1654
2024-05-25 06:47:07 [INFO]: Epoch 057 - training loss: 0.3351, validation loss: 0.1639
2024-05-25 06:47:10 [INFO]: Epoch 058 - training loss: 0.3333, validation loss: 0.1624
2024-05-25 06:47:12 [INFO]: Epoch 059 - training loss: 0.3312, validation loss: 0.1611
2024-05-25 06:47:15 [INFO]: Epoch 060 - training loss: 0.3292, validation loss: 0.1597
2024-05-25 06:47:18 [INFO]: Epoch 061 - training loss: 0.3282, validation loss: 0.1586
2024-05-25 06:47:21 [INFO]: Epoch 062 - training loss: 0.3263, validation loss: 0.1577
2024-05-25 06:47:24 [INFO]: Epoch 063 - training loss: 0.3241, validation loss: 0.1564
2024-05-25 06:47:27 [INFO]: Epoch 064 - training loss: 0.3231, validation loss: 0.1553
2024-05-25 06:47:30 [INFO]: Epoch 065 - training loss: 0.3216, validation loss: 0.1544
2024-05-25 06:47:33 [INFO]: Epoch 066 - training loss: 0.3202, validation loss: 0.1536
2024-05-25 06:47:36 [INFO]: Epoch 067 - training loss: 0.3183, validation loss: 0.1528
2024-05-25 06:47:39 [INFO]: Epoch 068 - training loss: 0.3174, validation loss: 0.1518
2024-05-25 06:47:42 [INFO]: Epoch 069 - training loss: 0.3157, validation loss: 0.1510
2024-05-25 06:47:45 [INFO]: Epoch 070 - training loss: 0.3147, validation loss: 0.1503
2024-05-25 06:47:47 [INFO]: Epoch 071 - training loss: 0.3136, validation loss: 0.1494
2024-05-25 06:47:50 [INFO]: Epoch 072 - training loss: 0.3123, validation loss: 0.1487
2024-05-25 06:47:53 [INFO]: Epoch 073 - training loss: 0.3111, validation loss: 0.1481
2024-05-25 06:47:56 [INFO]: Epoch 074 - training loss: 0.3094, validation loss: 0.1477
2024-05-25 06:47:59 [INFO]: Epoch 075 - training loss: 0.3082, validation loss: 0.1468
2024-05-25 06:48:02 [INFO]: Epoch 076 - training loss: 0.3076, validation loss: 0.1463
2024-05-25 06:48:05 [INFO]: Epoch 077 - training loss: 0.3068, validation loss: 0.1456
2024-05-25 06:48:08 [INFO]: Epoch 078 - training loss: 0.3050, validation loss: 0.1450
2024-05-25 06:48:11 [INFO]: Epoch 079 - training loss: 0.3048, validation loss: 0.1447
2024-05-25 06:48:14 [INFO]: Epoch 080 - training loss: 0.3033, validation loss: 0.1441
2024-05-25 06:48:17 [INFO]: Epoch 081 - training loss: 0.3032, validation loss: 0.1435
2024-05-25 06:48:20 [INFO]: Epoch 082 - training loss: 0.3017, validation loss: 0.1431
2024-05-25 06:48:22 [INFO]: Epoch 083 - training loss: 0.3007, validation loss: 0.1428
2024-05-25 06:48:25 [INFO]: Epoch 084 - training loss: 0.2995, validation loss: 0.1425
2024-05-25 06:48:28 [INFO]: Epoch 085 - training loss: 0.2995, validation loss: 0.1419
2024-05-25 06:48:31 [INFO]: Epoch 086 - training loss: 0.2986, validation loss: 0.1416
2024-05-25 06:48:34 [INFO]: Epoch 087 - training loss: 0.2973, validation loss: 0.1413
2024-05-25 06:48:37 [INFO]: Epoch 088 - training loss: 0.2960, validation loss: 0.1408
2024-05-25 06:48:40 [INFO]: Epoch 089 - training loss: 0.2958, validation loss: 0.1405
2024-05-25 06:48:43 [INFO]: Epoch 090 - training loss: 0.2957, validation loss: 0.1401
2024-05-25 06:48:45 [INFO]: Epoch 091 - training loss: 0.2943, validation loss: 0.1398
2024-05-25 06:48:48 [INFO]: Epoch 092 - training loss: 0.2929, validation loss: 0.1392
2024-05-25 06:48:51 [INFO]: Epoch 093 - training loss: 0.2929, validation loss: 0.1389
2024-05-25 06:48:54 [INFO]: Epoch 094 - training loss: 0.2924, validation loss: 0.1387
2024-05-25 06:48:57 [INFO]: Epoch 095 - training loss: 0.2910, validation loss: 0.1384
2024-05-25 06:49:00 [INFO]: Epoch 096 - training loss: 0.2908, validation loss: 0.1379
2024-05-25 06:49:03 [INFO]: Epoch 097 - training loss: 0.2899, validation loss: 0.1377
2024-05-25 06:49:06 [INFO]: Epoch 098 - training loss: 0.2899, validation loss: 0.1376
2024-05-25 06:49:09 [INFO]: Epoch 099 - training loss: 0.2888, validation loss: 0.1372
2024-05-25 06:49:12 [INFO]: Epoch 100 - training loss: 0.2880, validation loss: 0.1370
2024-05-25 06:49:15 [INFO]: Epoch 101 - training loss: 0.2875, validation loss: 0.1367
2024-05-25 06:49:18 [INFO]: Epoch 102 - training loss: 0.2863, validation loss: 0.1362
2024-05-25 06:49:21 [INFO]: Epoch 103 - training loss: 0.2863, validation loss: 0.1358
2024-05-25 06:49:24 [INFO]: Epoch 104 - training loss: 0.2858, validation loss: 0.1354
2024-05-25 06:49:26 [INFO]: Epoch 105 - training loss: 0.2851, validation loss: 0.1351
2024-05-25 06:49:29 [INFO]: Epoch 106 - training loss: 0.2848, validation loss: 0.1347
2024-05-25 06:49:32 [INFO]: Epoch 107 - training loss: 0.2845, validation loss: 0.1343
2024-05-25 06:49:35 [INFO]: Epoch 108 - training loss: 0.2831, validation loss: 0.1342
2024-05-25 06:49:38 [INFO]: Epoch 109 - training loss: 0.2824, validation loss: 0.1337
2024-05-25 06:49:41 [INFO]: Epoch 110 - training loss: 0.2814, validation loss: 0.1334
2024-05-25 06:49:44 [INFO]: Epoch 111 - training loss: 0.2815, validation loss: 0.1331
2024-05-25 06:49:47 [INFO]: Epoch 112 - training loss: 0.2814, validation loss: 0.1326
2024-05-25 06:49:50 [INFO]: Epoch 113 - training loss: 0.2797, validation loss: 0.1325
2024-05-25 06:49:53 [INFO]: Epoch 114 - training loss: 0.2801, validation loss: 0.1323
2024-05-25 06:49:56 [INFO]: Epoch 115 - training loss: 0.2790, validation loss: 0.1318
2024-05-25 06:49:59 [INFO]: Epoch 116 - training loss: 0.2786, validation loss: 0.1316
2024-05-25 06:50:01 [INFO]: Epoch 117 - training loss: 0.2780, validation loss: 0.1314
2024-05-25 06:50:04 [INFO]: Epoch 118 - training loss: 0.2774, validation loss: 0.1311
2024-05-25 06:50:07 [INFO]: Epoch 119 - training loss: 0.2783, validation loss: 0.1306
2024-05-25 06:50:10 [INFO]: Epoch 120 - training loss: 0.2769, validation loss: 0.1306
2024-05-25 06:50:13 [INFO]: Epoch 121 - training loss: 0.2763, validation loss: 0.1301
2024-05-25 06:50:16 [INFO]: Epoch 122 - training loss: 0.2754, validation loss: 0.1299
2024-05-25 06:50:19 [INFO]: Epoch 123 - training loss: 0.2754, validation loss: 0.1296
2024-05-25 06:50:22 [INFO]: Epoch 124 - training loss: 0.2754, validation loss: 0.1294
2024-05-25 06:50:25 [INFO]: Epoch 125 - training loss: 0.2744, validation loss: 0.1290
2024-05-25 06:50:28 [INFO]: Epoch 126 - training loss: 0.2742, validation loss: 0.1286
2024-05-25 06:50:31 [INFO]: Epoch 127 - training loss: 0.2738, validation loss: 0.1285
2024-05-25 06:50:34 [INFO]: Epoch 128 - training loss: 0.2728, validation loss: 0.1281
2024-05-25 06:50:36 [INFO]: Epoch 129 - training loss: 0.2729, validation loss: 0.1278
2024-05-25 06:50:39 [INFO]: Epoch 130 - training loss: 0.2722, validation loss: 0.1274
2024-05-25 06:50:42 [INFO]: Epoch 131 - training loss: 0.2718, validation loss: 0.1272
2024-05-25 06:50:45 [INFO]: Epoch 132 - training loss: 0.2717, validation loss: 0.1270
2024-05-25 06:50:48 [INFO]: Epoch 133 - training loss: 0.2710, validation loss: 0.1268
2024-05-25 06:50:51 [INFO]: Epoch 134 - training loss: 0.2704, validation loss: 0.1265
2024-05-25 06:50:54 [INFO]: Epoch 135 - training loss: 0.2702, validation loss: 0.1261
2024-05-25 06:50:57 [INFO]: Epoch 136 - training loss: 0.2695, validation loss: 0.1259
2024-05-25 06:51:00 [INFO]: Epoch 137 - training loss: 0.2689, validation loss: 0.1257
2024-05-25 06:51:03 [INFO]: Epoch 138 - training loss: 0.2689, validation loss: 0.1257
2024-05-25 06:51:06 [INFO]: Epoch 139 - training loss: 0.2686, validation loss: 0.1251
2024-05-25 06:51:09 [INFO]: Epoch 140 - training loss: 0.2676, validation loss: 0.1249
2024-05-25 06:51:11 [INFO]: Epoch 141 - training loss: 0.2677, validation loss: 0.1248
2024-05-25 06:51:15 [INFO]: Epoch 142 - training loss: 0.2675, validation loss: 0.1245
2024-05-25 06:51:17 [INFO]: Epoch 143 - training loss: 0.2665, validation loss: 0.1241
2024-05-25 06:51:20 [INFO]: Epoch 144 - training loss: 0.2666, validation loss: 0.1239
2024-05-25 06:51:23 [INFO]: Epoch 145 - training loss: 0.2664, validation loss: 0.1236
2024-05-25 06:51:26 [INFO]: Epoch 146 - training loss: 0.2667, validation loss: 0.1235
2024-05-25 06:51:29 [INFO]: Epoch 147 - training loss: 0.2663, validation loss: 0.1234
2024-05-25 06:51:32 [INFO]: Epoch 148 - training loss: 0.2651, validation loss: 0.1233
2024-05-25 06:51:35 [INFO]: Epoch 149 - training loss: 0.2643, validation loss: 0.1228
2024-05-25 06:51:38 [INFO]: Epoch 150 - training loss: 0.2644, validation loss: 0.1228
2024-05-25 06:51:41 [INFO]: Epoch 151 - training loss: 0.2637, validation loss: 0.1225
2024-05-25 06:51:44 [INFO]: Epoch 152 - training loss: 0.2638, validation loss: 0.1223
2024-05-25 06:51:47 [INFO]: Epoch 153 - training loss: 0.2636, validation loss: 0.1221
2024-05-25 06:51:50 [INFO]: Epoch 154 - training loss: 0.2628, validation loss: 0.1219
2024-05-25 06:51:52 [INFO]: Epoch 155 - training loss: 0.2626, validation loss: 0.1218
2024-05-25 06:51:55 [INFO]: Epoch 156 - training loss: 0.2621, validation loss: 0.1214
2024-05-25 06:51:58 [INFO]: Epoch 157 - training loss: 0.2618, validation loss: 0.1213
2024-05-25 06:52:01 [INFO]: Epoch 158 - training loss: 0.2616, validation loss: 0.1209
2024-05-25 06:52:04 [INFO]: Epoch 159 - training loss: 0.2615, validation loss: 0.1208
2024-05-25 06:52:07 [INFO]: Epoch 160 - training loss: 0.2608, validation loss: 0.1206
2024-05-25 06:52:10 [INFO]: Epoch 161 - training loss: 0.2610, validation loss: 0.1204
2024-05-25 06:52:13 [INFO]: Epoch 162 - training loss: 0.2603, validation loss: 0.1201
2024-05-25 06:52:16 [INFO]: Epoch 163 - training loss: 0.2605, validation loss: 0.1200
2024-05-25 06:52:19 [INFO]: Epoch 164 - training loss: 0.2605, validation loss: 0.1197
2024-05-25 06:52:22 [INFO]: Epoch 165 - training loss: 0.2595, validation loss: 0.1194
2024-05-25 06:52:25 [INFO]: Epoch 166 - training loss: 0.2591, validation loss: 0.1193
2024-05-25 06:52:28 [INFO]: Epoch 167 - training loss: 0.2591, validation loss: 0.1192
2024-05-25 06:52:30 [INFO]: Epoch 168 - training loss: 0.2587, validation loss: 0.1190
2024-05-25 06:52:33 [INFO]: Epoch 169 - training loss: 0.2584, validation loss: 0.1189
2024-05-25 06:52:36 [INFO]: Epoch 170 - training loss: 0.2577, validation loss: 0.1188
2024-05-25 06:52:39 [INFO]: Epoch 171 - training loss: 0.2584, validation loss: 0.1186
2024-05-25 06:52:42 [INFO]: Epoch 172 - training loss: 0.2575, validation loss: 0.1184
2024-05-25 06:52:45 [INFO]: Epoch 173 - training loss: 0.2572, validation loss: 0.1183
2024-05-25 06:52:48 [INFO]: Epoch 174 - training loss: 0.2570, validation loss: 0.1179
2024-05-25 06:52:51 [INFO]: Epoch 175 - training loss: 0.2568, validation loss: 0.1179
2024-05-25 06:52:54 [INFO]: Epoch 176 - training loss: 0.2572, validation loss: 0.1178
2024-05-25 06:52:57 [INFO]: Epoch 177 - training loss: 0.2566, validation loss: 0.1175
2024-05-25 06:53:00 [INFO]: Epoch 178 - training loss: 0.2564, validation loss: 0.1175
2024-05-25 06:53:03 [INFO]: Epoch 179 - training loss: 0.2557, validation loss: 0.1170
2024-05-25 06:53:05 [INFO]: Epoch 180 - training loss: 0.2553, validation loss: 0.1172
2024-05-25 06:53:08 [INFO]: Epoch 181 - training loss: 0.2549, validation loss: 0.1171
2024-05-25 06:53:11 [INFO]: Epoch 182 - training loss: 0.2556, validation loss: 0.1165
2024-05-25 06:53:14 [INFO]: Epoch 183 - training loss: 0.2543, validation loss: 0.1168
2024-05-25 06:53:17 [INFO]: Epoch 184 - training loss: 0.2550, validation loss: 0.1162
2024-05-25 06:53:20 [INFO]: Epoch 185 - training loss: 0.2540, validation loss: 0.1164
2024-05-25 06:53:23 [INFO]: Epoch 186 - training loss: 0.2539, validation loss: 0.1159
2024-05-25 06:53:26 [INFO]: Epoch 187 - training loss: 0.2537, validation loss: 0.1161
2024-05-25 06:53:29 [INFO]: Epoch 188 - training loss: 0.2535, validation loss: 0.1158
2024-05-25 06:53:32 [INFO]: Epoch 189 - training loss: 0.2535, validation loss: 0.1157
2024-05-25 06:53:35 [INFO]: Epoch 190 - training loss: 0.2532, validation loss: 0.1155
2024-05-25 06:53:38 [INFO]: Epoch 191 - training loss: 0.2530, validation loss: 0.1154
2024-05-25 06:53:41 [INFO]: Epoch 192 - training loss: 0.2529, validation loss: 0.1152
2024-05-25 06:53:44 [INFO]: Epoch 193 - training loss: 0.2521, validation loss: 0.1152
2024-05-25 06:53:46 [INFO]: Epoch 194 - training loss: 0.2523, validation loss: 0.1151
2024-05-25 06:53:49 [INFO]: Epoch 195 - training loss: 0.2517, validation loss: 0.1148
2024-05-25 06:53:52 [INFO]: Epoch 196 - training loss: 0.2516, validation loss: 0.1147
2024-05-25 06:53:55 [INFO]: Epoch 197 - training loss: 0.2520, validation loss: 0.1146
2024-05-25 06:53:58 [INFO]: Epoch 198 - training loss: 0.2516, validation loss: 0.1144
2024-05-25 06:54:01 [INFO]: Epoch 199 - training loss: 0.2508, validation loss: 0.1143
2024-05-25 06:54:04 [INFO]: Epoch 200 - training loss: 0.2511, validation loss: 0.1143
2024-05-25 06:54:07 [INFO]: Epoch 201 - training loss: 0.2509, validation loss: 0.1142
2024-05-25 06:54:10 [INFO]: Epoch 202 - training loss: 0.2501, validation loss: 0.1142
2024-05-25 06:54:13 [INFO]: Epoch 203 - training loss: 0.2497, validation loss: 0.1139
2024-05-25 06:54:16 [INFO]: Epoch 204 - training loss: 0.2501, validation loss: 0.1138
2024-05-25 06:54:19 [INFO]: Epoch 205 - training loss: 0.2496, validation loss: 0.1136
2024-05-25 06:54:21 [INFO]: Epoch 206 - training loss: 0.2497, validation loss: 0.1134
2024-05-25 06:54:24 [INFO]: Epoch 207 - training loss: 0.2493, validation loss: 0.1134
2024-05-25 06:54:27 [INFO]: Epoch 208 - training loss: 0.2486, validation loss: 0.1134
2024-05-25 06:54:30 [INFO]: Epoch 209 - training loss: 0.2495, validation loss: 0.1130
2024-05-25 06:54:33 [INFO]: Epoch 210 - training loss: 0.2491, validation loss: 0.1132
2024-05-25 06:54:36 [INFO]: Epoch 211 - training loss: 0.2489, validation loss: 0.1129
2024-05-25 06:54:39 [INFO]: Epoch 212 - training loss: 0.2483, validation loss: 0.1129
2024-05-25 06:54:42 [INFO]: Epoch 213 - training loss: 0.2478, validation loss: 0.1129
2024-05-25 06:54:45 [INFO]: Epoch 214 - training loss: 0.2482, validation loss: 0.1127
2024-05-25 06:54:48 [INFO]: Epoch 215 - training loss: 0.2478, validation loss: 0.1125
2024-05-25 06:54:51 [INFO]: Epoch 216 - training loss: 0.2474, validation loss: 0.1125
2024-05-25 06:54:54 [INFO]: Epoch 217 - training loss: 0.2477, validation loss: 0.1125
2024-05-25 06:54:57 [INFO]: Epoch 218 - training loss: 0.2468, validation loss: 0.1122
2024-05-25 06:54:59 [INFO]: Epoch 219 - training loss: 0.2473, validation loss: 0.1123
2024-05-25 06:55:02 [INFO]: Epoch 220 - training loss: 0.2470, validation loss: 0.1122
2024-05-25 06:55:05 [INFO]: Epoch 221 - training loss: 0.2465, validation loss: 0.1121
2024-05-25 06:55:08 [INFO]: Epoch 222 - training loss: 0.2466, validation loss: 0.1119
2024-05-25 06:55:11 [INFO]: Epoch 223 - training loss: 0.2465, validation loss: 0.1117
2024-05-25 06:55:14 [INFO]: Epoch 224 - training loss: 0.2463, validation loss: 0.1116
2024-05-25 06:55:17 [INFO]: Epoch 225 - training loss: 0.2459, validation loss: 0.1115
2024-05-25 06:55:20 [INFO]: Epoch 226 - training loss: 0.2462, validation loss: 0.1115
2024-05-25 06:55:23 [INFO]: Epoch 227 - training loss: 0.2460, validation loss: 0.1116
2024-05-25 06:55:26 [INFO]: Epoch 228 - training loss: 0.2459, validation loss: 0.1112
2024-05-25 06:55:29 [INFO]: Epoch 229 - training loss: 0.2454, validation loss: 0.1114
2024-05-25 06:55:32 [INFO]: Epoch 230 - training loss: 0.2453, validation loss: 0.1112
2024-05-25 06:55:35 [INFO]: Epoch 231 - training loss: 0.2454, validation loss: 0.1110
2024-05-25 06:55:37 [INFO]: Epoch 232 - training loss: 0.2445, validation loss: 0.1110
2024-05-25 06:55:40 [INFO]: Epoch 233 - training loss: 0.2443, validation loss: 0.1108
2024-05-25 06:55:43 [INFO]: Epoch 234 - training loss: 0.2449, validation loss: 0.1110
2024-05-25 06:55:46 [INFO]: Epoch 235 - training loss: 0.2439, validation loss: 0.1104
2024-05-25 06:55:49 [INFO]: Epoch 236 - training loss: 0.2443, validation loss: 0.1107
2024-05-25 06:55:52 [INFO]: Epoch 237 - training loss: 0.2441, validation loss: 0.1105
2024-05-25 06:55:55 [INFO]: Epoch 238 - training loss: 0.2437, validation loss: 0.1105
2024-05-25 06:55:57 [INFO]: Epoch 239 - training loss: 0.2433, validation loss: 0.1104
2024-05-25 06:56:00 [INFO]: Epoch 240 - training loss: 0.2439, validation loss: 0.1105
2024-05-25 06:56:03 [INFO]: Epoch 241 - training loss: 0.2434, validation loss: 0.1101
2024-05-25 06:56:06 [INFO]: Epoch 242 - training loss: 0.2432, validation loss: 0.1102
2024-05-25 06:56:09 [INFO]: Epoch 243 - training loss: 0.2430, validation loss: 0.1101
2024-05-25 06:56:12 [INFO]: Epoch 244 - training loss: 0.2431, validation loss: 0.1100
2024-05-25 06:56:15 [INFO]: Epoch 245 - training loss: 0.2425, validation loss: 0.1099
2024-05-25 06:56:18 [INFO]: Epoch 246 - training loss: 0.2420, validation loss: 0.1099
2024-05-25 06:56:21 [INFO]: Epoch 247 - training loss: 0.2421, validation loss: 0.1098
2024-05-25 06:56:23 [INFO]: Epoch 248 - training loss: 0.2421, validation loss: 0.1098
2024-05-25 06:56:26 [INFO]: Epoch 249 - training loss: 0.2420, validation loss: 0.1097
2024-05-25 06:56:29 [INFO]: Epoch 250 - training loss: 0.2418, validation loss: 0.1097
2024-05-25 06:56:32 [INFO]: Epoch 251 - training loss: 0.2420, validation loss: 0.1096
2024-05-25 06:56:35 [INFO]: Epoch 252 - training loss: 0.2414, validation loss: 0.1097
2024-05-25 06:56:38 [INFO]: Epoch 253 - training loss: 0.2413, validation loss: 0.1095
2024-05-25 06:56:41 [INFO]: Epoch 254 - training loss: 0.2415, validation loss: 0.1095
2024-05-25 06:56:44 [INFO]: Epoch 255 - training loss: 0.2416, validation loss: 0.1097
2024-05-25 06:56:47 [INFO]: Epoch 256 - training loss: 0.2419, validation loss: 0.1092
2024-05-25 06:56:50 [INFO]: Epoch 257 - training loss: 0.2407, validation loss: 0.1094
2024-05-25 06:56:53 [INFO]: Epoch 258 - training loss: 0.2408, validation loss: 0.1092
2024-05-25 06:56:55 [INFO]: Epoch 259 - training loss: 0.2405, validation loss: 0.1094
2024-05-25 06:56:58 [INFO]: Epoch 260 - training loss: 0.2403, validation loss: 0.1092
2024-05-25 06:57:01 [INFO]: Epoch 261 - training loss: 0.2402, validation loss: 0.1092
2024-05-25 06:57:04 [INFO]: Epoch 262 - training loss: 0.2401, validation loss: 0.1091
2024-05-25 06:57:07 [INFO]: Epoch 263 - training loss: 0.2401, validation loss: 0.1092
2024-05-25 06:57:10 [INFO]: Epoch 264 - training loss: 0.2402, validation loss: 0.1091
2024-05-25 06:57:13 [INFO]: Epoch 265 - training loss: 0.2398, validation loss: 0.1089
2024-05-25 06:57:16 [INFO]: Epoch 266 - training loss: 0.2398, validation loss: 0.1089
2024-05-25 06:57:19 [INFO]: Epoch 267 - training loss: 0.2394, validation loss: 0.1089
2024-05-25 06:57:22 [INFO]: Epoch 268 - training loss: 0.2391, validation loss: 0.1089
2024-05-25 06:57:25 [INFO]: Epoch 269 - training loss: 0.2394, validation loss: 0.1087
2024-05-25 06:57:28 [INFO]: Epoch 270 - training loss: 0.2388, validation loss: 0.1087
2024-05-25 06:57:30 [INFO]: Epoch 271 - training loss: 0.2389, validation loss: 0.1087
2024-05-25 06:57:33 [INFO]: Epoch 272 - training loss: 0.2386, validation loss: 0.1085
2024-05-25 06:57:36 [INFO]: Epoch 273 - training loss: 0.2397, validation loss: 0.1085
2024-05-25 06:57:39 [INFO]: Epoch 274 - training loss: 0.2385, validation loss: 0.1085
2024-05-25 06:57:42 [INFO]: Epoch 275 - training loss: 0.2382, validation loss: 0.1086
2024-05-25 06:57:45 [INFO]: Epoch 276 - training loss: 0.2381, validation loss: 0.1086
2024-05-25 06:57:48 [INFO]: Epoch 277 - training loss: 0.2379, validation loss: 0.1086
2024-05-25 06:57:51 [INFO]: Epoch 278 - training loss: 0.2381, validation loss: 0.1083
2024-05-25 06:57:54 [INFO]: Epoch 279 - training loss: 0.2376, validation loss: 0.1084
2024-05-25 06:57:57 [INFO]: Epoch 280 - training loss: 0.2380, validation loss: 0.1084
2024-05-25 06:58:00 [INFO]: Epoch 281 - training loss: 0.2373, validation loss: 0.1082
2024-05-25 06:58:03 [INFO]: Epoch 282 - training loss: 0.2371, validation loss: 0.1084
2024-05-25 06:58:06 [INFO]: Epoch 283 - training loss: 0.2372, validation loss: 0.1081
2024-05-25 06:58:09 [INFO]: Epoch 284 - training loss: 0.2372, validation loss: 0.1082
2024-05-25 06:58:12 [INFO]: Epoch 285 - training loss: 0.2368, validation loss: 0.1082
2024-05-25 06:58:14 [INFO]: Epoch 286 - training loss: 0.2368, validation loss: 0.1081
2024-05-25 06:58:17 [INFO]: Epoch 287 - training loss: 0.2370, validation loss: 0.1079
2024-05-25 06:58:20 [INFO]: Epoch 288 - training loss: 0.2367, validation loss: 0.1080
2024-05-25 06:58:23 [INFO]: Epoch 289 - training loss: 0.2364, validation loss: 0.1082
2024-05-25 06:58:26 [INFO]: Epoch 290 - training loss: 0.2366, validation loss: 0.1081
2024-05-25 06:58:29 [INFO]: Epoch 291 - training loss: 0.2364, validation loss: 0.1080
2024-05-25 06:58:32 [INFO]: Epoch 292 - training loss: 0.2367, validation loss: 0.1081
2024-05-25 06:58:35 [INFO]: Epoch 293 - training loss: 0.2360, validation loss: 0.1079
2024-05-25 06:58:38 [INFO]: Epoch 294 - training loss: 0.2366, validation loss: 0.1080
2024-05-25 06:58:41 [INFO]: Epoch 295 - training loss: 0.2360, validation loss: 0.1079
2024-05-25 06:58:44 [INFO]: Epoch 296 - training loss: 0.2360, validation loss: 0.1079
2024-05-25 06:58:47 [INFO]: Epoch 297 - training loss: 0.2356, validation loss: 0.1079
2024-05-25 06:58:50 [INFO]: Epoch 298 - training loss: 0.2351, validation loss: 0.1079
2024-05-25 06:58:52 [INFO]: Epoch 299 - training loss: 0.2353, validation loss: 0.1080
2024-05-25 06:58:55 [INFO]: Epoch 300 - training loss: 0.2349, validation loss: 0.1080
2024-05-25 06:58:55 [INFO]: Finished training. The best model is from epoch#293.
2024-05-25 06:58:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/BRITS_air_quality/20240525_T064419/BRITS.pypots
2024-05-25 06:58:56 [INFO]: BRITS on Air-Quality: MAE=0.1381, MSE=0.1837
2024-05-25 06:58:56 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/BRITS_air_quality/imputation.pkl
2024-05-25 06:58:56 [INFO]: Using the given device: cuda:0
2024-05-25 06:58:56 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856
2024-05-25 06:58:56 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/tensorboard
2024-05-25 06:58:56 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 06:59:01 [INFO]: Epoch 001 - training loss: 1.4204, validation loss: 0.8071
2024-05-25 06:59:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch1_loss0.8071039855480194.pypots
2024-05-25 06:59:05 [INFO]: Epoch 002 - training loss: 1.0475, validation loss: 0.7574
2024-05-25 06:59:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch2_loss0.757416769862175.pypots
2024-05-25 06:59:09 [INFO]: Epoch 003 - training loss: 0.9757, validation loss: 0.7270
2024-05-25 06:59:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch3_loss0.7270396798849106.pypots
2024-05-25 06:59:13 [INFO]: Epoch 004 - training loss: 0.9498, validation loss: 0.7119
2024-05-25 06:59:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch4_loss0.7118531614542007.pypots
2024-05-25 06:59:17 [INFO]: Epoch 005 - training loss: 0.9649, validation loss: 0.7029
2024-05-25 06:59:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch5_loss0.7028569757938385.pypots
2024-05-25 06:59:21 [INFO]: Epoch 006 - training loss: 0.9443, validation loss: 0.6971
2024-05-25 06:59:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch6_loss0.69710773229599.pypots
2024-05-25 06:59:25 [INFO]: Epoch 007 - training loss: 0.9362, validation loss: 0.6923
2024-05-25 06:59:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch7_loss0.6923171430826187.pypots
2024-05-25 06:59:29 [INFO]: Epoch 008 - training loss: 0.9153, validation loss: 0.6897
2024-05-25 06:59:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch8_loss0.6897308230400085.pypots
2024-05-25 06:59:33 [INFO]: Epoch 009 - training loss: 0.9056, validation loss: 0.6851
2024-05-25 06:59:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch9_loss0.6850784718990326.pypots
2024-05-25 06:59:37 [INFO]: Epoch 010 - training loss: 0.8999, validation loss: 0.6826
2024-05-25 06:59:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch10_loss0.6825857847929001.pypots
2024-05-25 06:59:41 [INFO]: Epoch 011 - training loss: 0.9040, validation loss: 0.6804
2024-05-25 06:59:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch11_loss0.6804278880357743.pypots
2024-05-25 06:59:45 [INFO]: Epoch 012 - training loss: 0.8996, validation loss: 0.6793
2024-05-25 06:59:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch12_loss0.6792599141597748.pypots
2024-05-25 06:59:49 [INFO]: Epoch 013 - training loss: 0.8893, validation loss: 0.6789
2024-05-25 06:59:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch13_loss0.6789321899414062.pypots
2024-05-25 06:59:53 [INFO]: Epoch 014 - training loss: 0.8751, validation loss: 0.6788
2024-05-25 06:59:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch14_loss0.6788349956274032.pypots
2024-05-25 06:59:57 [INFO]: Epoch 015 - training loss: 0.8854, validation loss: 0.6759
2024-05-25 06:59:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch15_loss0.6758530259132385.pypots
2024-05-25 07:00:01 [INFO]: Epoch 016 - training loss: 0.8790, validation loss: 0.6760
2024-05-25 07:00:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch16_loss0.6760311901569367.pypots
2024-05-25 07:00:05 [INFO]: Epoch 017 - training loss: 0.8704, validation loss: 0.6748
2024-05-25 07:00:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch17_loss0.674809119105339.pypots
2024-05-25 07:00:09 [INFO]: Epoch 018 - training loss: 0.8881, validation loss: 0.6744
2024-05-25 07:00:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch18_loss0.6743731081485749.pypots
2024-05-25 07:00:13 [INFO]: Epoch 019 - training loss: 0.8978, validation loss: 0.6740
2024-05-25 07:00:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch19_loss0.673951444029808.pypots
2024-05-25 07:00:17 [INFO]: Epoch 020 - training loss: 0.8781, validation loss: 0.6740
2024-05-25 07:00:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch20_loss0.6740088045597077.pypots
2024-05-25 07:00:21 [INFO]: Epoch 021 - training loss: 0.8768, validation loss: 0.6738
2024-05-25 07:00:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch21_loss0.6738419651985168.pypots
2024-05-25 07:00:25 [INFO]: Epoch 022 - training loss: 0.8674, validation loss: 0.6745
2024-05-25 07:00:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch22_loss0.6744739949703217.pypots
2024-05-25 07:00:29 [INFO]: Epoch 023 - training loss: 0.8599, validation loss: 0.6744
2024-05-25 07:00:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch23_loss0.674440187215805.pypots
2024-05-25 07:00:33 [INFO]: Epoch 024 - training loss: 0.8568, validation loss: 0.6736
2024-05-25 07:00:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch24_loss0.6736493676900863.pypots
2024-05-25 07:00:37 [INFO]: Epoch 025 - training loss: 0.8654, validation loss: 0.6732
2024-05-25 07:00:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch25_loss0.6732282340526581.pypots
2024-05-25 07:00:41 [INFO]: Epoch 026 - training loss: 0.8427, validation loss: 0.6740
2024-05-25 07:00:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch26_loss0.6740341067314148.pypots
2024-05-25 07:00:45 [INFO]: Epoch 027 - training loss: 0.8513, validation loss: 0.6735
2024-05-25 07:00:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch27_loss0.6734520554542541.pypots
2024-05-25 07:00:49 [INFO]: Epoch 028 - training loss: 0.8463, validation loss: 0.6727
2024-05-25 07:00:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch28_loss0.6726886749267578.pypots
2024-05-25 07:00:53 [INFO]: Epoch 029 - training loss: 0.8384, validation loss: 0.6729
2024-05-25 07:00:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch29_loss0.6728807538747787.pypots
2024-05-25 07:00:57 [INFO]: Epoch 030 - training loss: 0.8446, validation loss: 0.6763
2024-05-25 07:00:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch30_loss0.6762660324573517.pypots
2024-05-25 07:01:01 [INFO]: Epoch 031 - training loss: 0.8512, validation loss: 0.6742
2024-05-25 07:01:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch31_loss0.6741784960031509.pypots
2024-05-25 07:01:05 [INFO]: Epoch 032 - training loss: 0.8342, validation loss: 0.6748
2024-05-25 07:01:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch32_loss0.6748341143131256.pypots
2024-05-25 07:01:09 [INFO]: Epoch 033 - training loss: 0.8347, validation loss: 0.6747
2024-05-25 07:01:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch33_loss0.6747071385383606.pypots
2024-05-25 07:01:13 [INFO]: Epoch 034 - training loss: 0.8367, validation loss: 0.6745
2024-05-25 07:01:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch34_loss0.6745233207941055.pypots
2024-05-25 07:01:17 [INFO]: Epoch 035 - training loss: 0.8348, validation loss: 0.6754
2024-05-25 07:01:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch35_loss0.6753524214029312.pypots
2024-05-25 07:01:21 [INFO]: Epoch 036 - training loss: 0.8305, validation loss: 0.6762
2024-05-25 07:01:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch36_loss0.6762291997671127.pypots
2024-05-25 07:01:25 [INFO]: Epoch 037 - training loss: 0.8209, validation loss: 0.6739
2024-05-25 07:01:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch37_loss0.6738661706447602.pypots
2024-05-25 07:01:29 [INFO]: Epoch 038 - training loss: 0.8201, validation loss: 0.6771
2024-05-25 07:01:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN_epoch38_loss0.6770679205656052.pypots
2024-05-25 07:01:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:01:29 [INFO]: Finished training. The best model is from epoch#28.
2024-05-25 07:01:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240525_T065856/MRNN.pypots
2024-05-25 07:01:29 [INFO]: MRNN on Air-Quality: MAE=0.5288, MSE=0.7669
2024-05-25 07:01:29 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/MRNN_air_quality/imputation.pkl
2024-05-25 07:01:29 [INFO]: Using the given device: cpu
2024-05-25 07:01:29 [INFO]: LOCF on Air-Quality: MAE=0.2039, MSE=0.4028
2024-05-25 07:01:29 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_air_quality".
2024-05-25 07:01:29 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/LOCF_air_quality/imputation.pkl
2024-05-25 07:01:29 [INFO]: Median on Air-Quality: MAE=0.6702, MSE=1.1687
2024-05-25 07:01:29 [INFO]: Successfully created the given path "saved_results/round_2/Median_air_quality".
2024-05-25 07:01:29 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Median_air_quality/imputation.pkl
2024-05-25 07:01:29 [INFO]: Mean on Air-Quality: MAE=0.7021, MSE=1.1087
2024-05-25 07:01:29 [INFO]: Successfully created the given path "saved_results/round_2/Mean_air_quality".
2024-05-25 07:01:29 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Mean_air_quality/imputation.pkl
2024-05-25 07:01:29 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-25 07:01:29 [INFO]: Using the given device: cuda:0
2024-05-25 07:01:29 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/SAITS_air_quality/20240525_T070129
2024-05-25 07:01:29 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/SAITS_air_quality/20240525_T070129/tensorboard
2024-05-25 07:01:30 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 07:01:30 [INFO]: Epoch 001 - training loss: 1.0453, validation loss: 0.5267
2024-05-25 07:01:31 [INFO]: Epoch 002 - training loss: 0.7579, validation loss: 0.4086
2024-05-25 07:01:32 [INFO]: Epoch 003 - training loss: 0.6539, validation loss: 0.3385
2024-05-25 07:01:32 [INFO]: Epoch 004 - training loss: 0.5814, validation loss: 0.2953
2024-05-25 07:01:33 [INFO]: Epoch 005 - training loss: 0.5273, validation loss: 0.2729
2024-05-25 07:01:33 [INFO]: Epoch 006 - training loss: 0.4873, validation loss: 0.2561
2024-05-25 07:01:34 [INFO]: Epoch 007 - training loss: 0.4563, validation loss: 0.2422
2024-05-25 07:01:35 [INFO]: Epoch 008 - training loss: 0.4365, validation loss: 0.2344
2024-05-25 07:01:35 [INFO]: Epoch 009 - training loss: 0.4225, validation loss: 0.2283
2024-05-25 07:01:36 [INFO]: Epoch 010 - training loss: 0.4078, validation loss: 0.2246
2024-05-25 07:01:37 [INFO]: Epoch 011 - training loss: 0.3988, validation loss: 0.2172
2024-05-25 07:01:37 [INFO]: Epoch 012 - training loss: 0.3893, validation loss: 0.2132
2024-05-25 07:01:38 [INFO]: Epoch 013 - training loss: 0.3804, validation loss: 0.2083
2024-05-25 07:01:38 [INFO]: Epoch 014 - training loss: 0.3718, validation loss: 0.2050
2024-05-25 07:01:39 [INFO]: Epoch 015 - training loss: 0.3663, validation loss: 0.2028
2024-05-25 07:01:40 [INFO]: Epoch 016 - training loss: 0.3595, validation loss: 0.2008
2024-05-25 07:01:40 [INFO]: Epoch 017 - training loss: 0.3545, validation loss: 0.1975
2024-05-25 07:01:41 [INFO]: Epoch 018 - training loss: 0.3485, validation loss: 0.1949
2024-05-25 07:01:41 [INFO]: Epoch 019 - training loss: 0.3435, validation loss: 0.1919
2024-05-25 07:01:42 [INFO]: Epoch 020 - training loss: 0.3395, validation loss: 0.1896
2024-05-25 07:01:43 [INFO]: Epoch 021 - training loss: 0.3356, validation loss: 0.1897
2024-05-25 07:01:43 [INFO]: Epoch 022 - training loss: 0.3320, validation loss: 0.1876
2024-05-25 07:01:44 [INFO]: Epoch 023 - training loss: 0.3271, validation loss: 0.1836
2024-05-25 07:01:45 [INFO]: Epoch 024 - training loss: 0.3263, validation loss: 0.1828
2024-05-25 07:01:45 [INFO]: Epoch 025 - training loss: 0.3215, validation loss: 0.1822
2024-05-25 07:01:46 [INFO]: Epoch 026 - training loss: 0.3173, validation loss: 0.1780
2024-05-25 07:01:46 [INFO]: Epoch 027 - training loss: 0.3143, validation loss: 0.1774
2024-05-25 07:01:47 [INFO]: Epoch 028 - training loss: 0.3122, validation loss: 0.1770
2024-05-25 07:01:48 [INFO]: Epoch 029 - training loss: 0.3089, validation loss: 0.1749
2024-05-25 07:01:48 [INFO]: Epoch 030 - training loss: 0.3064, validation loss: 0.1734
2024-05-25 07:01:49 [INFO]: Epoch 031 - training loss: 0.3047, validation loss: 0.1724
2024-05-25 07:01:49 [INFO]: Epoch 032 - training loss: 0.3018, validation loss: 0.1705
2024-05-25 07:01:50 [INFO]: Epoch 033 - training loss: 0.2994, validation loss: 0.1687
2024-05-25 07:01:51 [INFO]: Epoch 034 - training loss: 0.2978, validation loss: 0.1688
2024-05-25 07:01:51 [INFO]: Epoch 035 - training loss: 0.2960, validation loss: 0.1673
2024-05-25 07:01:52 [INFO]: Epoch 036 - training loss: 0.2932, validation loss: 0.1673
2024-05-25 07:01:53 [INFO]: Epoch 037 - training loss: 0.2898, validation loss: 0.1651
2024-05-25 07:01:53 [INFO]: Epoch 038 - training loss: 0.2894, validation loss: 0.1635
2024-05-25 07:01:54 [INFO]: Epoch 039 - training loss: 0.2872, validation loss: 0.1635
2024-05-25 07:01:54 [INFO]: Epoch 040 - training loss: 0.2855, validation loss: 0.1623
2024-05-25 07:01:55 [INFO]: Epoch 041 - training loss: 0.2837, validation loss: 0.1612
2024-05-25 07:01:56 [INFO]: Epoch 042 - training loss: 0.2818, validation loss: 0.1592
2024-05-25 07:01:56 [INFO]: Epoch 043 - training loss: 0.2802, validation loss: 0.1579
2024-05-25 07:01:57 [INFO]: Epoch 044 - training loss: 0.2791, validation loss: 0.1575
2024-05-25 07:01:57 [INFO]: Epoch 045 - training loss: 0.2773, validation loss: 0.1568
2024-05-25 07:01:58 [INFO]: Epoch 046 - training loss: 0.2759, validation loss: 0.1576
2024-05-25 07:01:59 [INFO]: Epoch 047 - training loss: 0.2734, validation loss: 0.1556
2024-05-25 07:01:59 [INFO]: Epoch 048 - training loss: 0.2730, validation loss: 0.1544
2024-05-25 07:02:00 [INFO]: Epoch 049 - training loss: 0.2716, validation loss: 0.1531
2024-05-25 07:02:01 [INFO]: Epoch 050 - training loss: 0.2690, validation loss: 0.1519
2024-05-25 07:02:01 [INFO]: Epoch 051 - training loss: 0.2686, validation loss: 0.1510
2024-05-25 07:02:02 [INFO]: Epoch 052 - training loss: 0.2663, validation loss: 0.1509
2024-05-25 07:02:02 [INFO]: Epoch 053 - training loss: 0.2651, validation loss: 0.1506
2024-05-25 07:02:03 [INFO]: Epoch 054 - training loss: 0.2660, validation loss: 0.1495
2024-05-25 07:02:04 [INFO]: Epoch 055 - training loss: 0.2630, validation loss: 0.1488
2024-05-25 07:02:04 [INFO]: Epoch 056 - training loss: 0.2602, validation loss: 0.1476
2024-05-25 07:02:05 [INFO]: Epoch 057 - training loss: 0.2592, validation loss: 0.1466
2024-05-25 07:02:06 [INFO]: Epoch 058 - training loss: 0.2578, validation loss: 0.1455
2024-05-25 07:02:06 [INFO]: Epoch 059 - training loss: 0.2570, validation loss: 0.1452
2024-05-25 07:02:07 [INFO]: Epoch 060 - training loss: 0.2549, validation loss: 0.1459
2024-05-25 07:02:07 [INFO]: Epoch 061 - training loss: 0.2541, validation loss: 0.1437
2024-05-25 07:02:08 [INFO]: Epoch 062 - training loss: 0.2534, validation loss: 0.1435
2024-05-25 07:02:09 [INFO]: Epoch 063 - training loss: 0.2505, validation loss: 0.1420
2024-05-25 07:02:09 [INFO]: Epoch 064 - training loss: 0.2500, validation loss: 0.1410
2024-05-25 07:02:10 [INFO]: Epoch 065 - training loss: 0.2482, validation loss: 0.1407
2024-05-25 07:02:10 [INFO]: Epoch 066 - training loss: 0.2476, validation loss: 0.1406
2024-05-25 07:02:11 [INFO]: Epoch 067 - training loss: 0.2453, validation loss: 0.1399
2024-05-25 07:02:12 [INFO]: Epoch 068 - training loss: 0.2452, validation loss: 0.1385
2024-05-25 07:02:12 [INFO]: Epoch 069 - training loss: 0.2430, validation loss: 0.1388
2024-05-25 07:02:13 [INFO]: Epoch 070 - training loss: 0.2423, validation loss: 0.1398
2024-05-25 07:02:14 [INFO]: Epoch 071 - training loss: 0.2417, validation loss: 0.1381
2024-05-25 07:02:14 [INFO]: Epoch 072 - training loss: 0.2400, validation loss: 0.1366
2024-05-25 07:02:15 [INFO]: Epoch 073 - training loss: 0.2398, validation loss: 0.1376
2024-05-25 07:02:15 [INFO]: Epoch 074 - training loss: 0.2388, validation loss: 0.1377
2024-05-25 07:02:16 [INFO]: Epoch 075 - training loss: 0.2368, validation loss: 0.1377
2024-05-25 07:02:17 [INFO]: Epoch 076 - training loss: 0.2357, validation loss: 0.1375
2024-05-25 07:02:17 [INFO]: Epoch 077 - training loss: 0.2341, validation loss: 0.1368
2024-05-25 07:02:18 [INFO]: Epoch 078 - training loss: 0.2335, validation loss: 0.1356
2024-05-25 07:02:18 [INFO]: Epoch 079 - training loss: 0.2324, validation loss: 0.1358
2024-05-25 07:02:19 [INFO]: Epoch 080 - training loss: 0.2323, validation loss: 0.1356
2024-05-25 07:02:20 [INFO]: Epoch 081 - training loss: 0.2315, validation loss: 0.1358
2024-05-25 07:02:20 [INFO]: Epoch 082 - training loss: 0.2290, validation loss: 0.1340
2024-05-25 07:02:21 [INFO]: Epoch 083 - training loss: 0.2281, validation loss: 0.1347
2024-05-25 07:02:22 [INFO]: Epoch 084 - training loss: 0.2277, validation loss: 0.1333
2024-05-25 07:02:22 [INFO]: Epoch 085 - training loss: 0.2268, validation loss: 0.1333
2024-05-25 07:02:23 [INFO]: Epoch 086 - training loss: 0.2256, validation loss: 0.1328
2024-05-25 07:02:23 [INFO]: Epoch 087 - training loss: 0.2251, validation loss: 0.1333
2024-05-25 07:02:24 [INFO]: Epoch 088 - training loss: 0.2239, validation loss: 0.1323
2024-05-25 07:02:25 [INFO]: Epoch 089 - training loss: 0.2233, validation loss: 0.1322
2024-05-25 07:02:25 [INFO]: Epoch 090 - training loss: 0.2230, validation loss: 0.1326
2024-05-25 07:02:26 [INFO]: Epoch 091 - training loss: 0.2223, validation loss: 0.1318
2024-05-25 07:02:26 [INFO]: Epoch 092 - training loss: 0.2210, validation loss: 0.1323
2024-05-25 07:02:27 [INFO]: Epoch 093 - training loss: 0.2210, validation loss: 0.1303
2024-05-25 07:02:28 [INFO]: Epoch 094 - training loss: 0.2208, validation loss: 0.1314
2024-05-25 07:02:28 [INFO]: Epoch 095 - training loss: 0.2197, validation loss: 0.1317
2024-05-25 07:02:29 [INFO]: Epoch 096 - training loss: 0.2182, validation loss: 0.1300
2024-05-25 07:02:29 [INFO]: Epoch 097 - training loss: 0.2166, validation loss: 0.1302
2024-05-25 07:02:30 [INFO]: Epoch 098 - training loss: 0.2162, validation loss: 0.1303
2024-05-25 07:02:31 [INFO]: Epoch 099 - training loss: 0.2151, validation loss: 0.1297
2024-05-25 07:02:31 [INFO]: Epoch 100 - training loss: 0.2148, validation loss: 0.1286
2024-05-25 07:02:32 [INFO]: Epoch 101 - training loss: 0.2141, validation loss: 0.1303
2024-05-25 07:02:33 [INFO]: Epoch 102 - training loss: 0.2139, validation loss: 0.1301
2024-05-25 07:02:33 [INFO]: Epoch 103 - training loss: 0.2124, validation loss: 0.1296
2024-05-25 07:02:34 [INFO]: Epoch 104 - training loss: 0.2121, validation loss: 0.1276
2024-05-25 07:02:34 [INFO]: Epoch 105 - training loss: 0.2115, validation loss: 0.1298
2024-05-25 07:02:35 [INFO]: Epoch 106 - training loss: 0.2113, validation loss: 0.1288
2024-05-25 07:02:36 [INFO]: Epoch 107 - training loss: 0.2103, validation loss: 0.1281
2024-05-25 07:02:36 [INFO]: Epoch 108 - training loss: 0.2099, validation loss: 0.1287
2024-05-25 07:02:37 [INFO]: Epoch 109 - training loss: 0.2100, validation loss: 0.1287
2024-05-25 07:02:38 [INFO]: Epoch 110 - training loss: 0.2109, validation loss: 0.1277
2024-05-25 07:02:38 [INFO]: Epoch 111 - training loss: 0.2080, validation loss: 0.1278
2024-05-25 07:02:39 [INFO]: Epoch 112 - training loss: 0.2060, validation loss: 0.1272
2024-05-25 07:02:39 [INFO]: Epoch 113 - training loss: 0.2065, validation loss: 0.1272
2024-05-25 07:02:40 [INFO]: Epoch 114 - training loss: 0.2064, validation loss: 0.1271
2024-05-25 07:02:41 [INFO]: Epoch 115 - training loss: 0.2052, validation loss: 0.1286
2024-05-25 07:02:41 [INFO]: Epoch 116 - training loss: 0.2056, validation loss: 0.1266
2024-05-25 07:02:42 [INFO]: Epoch 117 - training loss: 0.2057, validation loss: 0.1276
2024-05-25 07:02:42 [INFO]: Epoch 118 - training loss: 0.2086, validation loss: 0.1290
2024-05-25 07:02:43 [INFO]: Epoch 119 - training loss: 0.2035, validation loss: 0.1250
2024-05-25 07:02:44 [INFO]: Epoch 120 - training loss: 0.2031, validation loss: 0.1259
2024-05-25 07:02:44 [INFO]: Epoch 121 - training loss: 0.2019, validation loss: 0.1255
2024-05-25 07:02:45 [INFO]: Epoch 122 - training loss: 0.2014, validation loss: 0.1262
2024-05-25 07:02:46 [INFO]: Epoch 123 - training loss: 0.2023, validation loss: 0.1258
2024-05-25 07:02:46 [INFO]: Epoch 124 - training loss: 0.2023, validation loss: 0.1260
2024-05-25 07:02:47 [INFO]: Epoch 125 - training loss: 0.2000, validation loss: 0.1241
2024-05-25 07:02:47 [INFO]: Epoch 126 - training loss: 0.1990, validation loss: 0.1250
2024-05-25 07:02:48 [INFO]: Epoch 127 - training loss: 0.1990, validation loss: 0.1250
2024-05-25 07:02:49 [INFO]: Epoch 128 - training loss: 0.1982, validation loss: 0.1239
2024-05-25 07:02:49 [INFO]: Epoch 129 - training loss: 0.1977, validation loss: 0.1234
2024-05-25 07:02:50 [INFO]: Epoch 130 - training loss: 0.1979, validation loss: 0.1231
2024-05-25 07:02:50 [INFO]: Epoch 131 - training loss: 0.1966, validation loss: 0.1240
2024-05-25 07:02:51 [INFO]: Epoch 132 - training loss: 0.1958, validation loss: 0.1224
2024-05-25 07:02:52 [INFO]: Epoch 133 - training loss: 0.1967, validation loss: 0.1235
2024-05-25 07:02:52 [INFO]: Epoch 134 - training loss: 0.1955, validation loss: 0.1238
2024-05-25 07:02:53 [INFO]: Epoch 135 - training loss: 0.1950, validation loss: 0.1229
2024-05-25 07:02:54 [INFO]: Epoch 136 - training loss: 0.1944, validation loss: 0.1234
2024-05-25 07:02:54 [INFO]: Epoch 137 - training loss: 0.1938, validation loss: 0.1211
2024-05-25 07:02:55 [INFO]: Epoch 138 - training loss: 0.1929, validation loss: 0.1217
2024-05-25 07:02:55 [INFO]: Epoch 139 - training loss: 0.1924, validation loss: 0.1236
2024-05-25 07:02:56 [INFO]: Epoch 140 - training loss: 0.1942, validation loss: 0.1232
2024-05-25 07:02:57 [INFO]: Epoch 141 - training loss: 0.1928, validation loss: 0.1226
2024-05-25 07:02:57 [INFO]: Epoch 142 - training loss: 0.1924, validation loss: 0.1221
2024-05-25 07:02:58 [INFO]: Epoch 143 - training loss: 0.1915, validation loss: 0.1211
2024-05-25 07:02:58 [INFO]: Epoch 144 - training loss: 0.1913, validation loss: 0.1224
2024-05-25 07:02:59 [INFO]: Epoch 145 - training loss: 0.1895, validation loss: 0.1217
2024-05-25 07:03:00 [INFO]: Epoch 146 - training loss: 0.1896, validation loss: 0.1219
2024-05-25 07:03:00 [INFO]: Epoch 147 - training loss: 0.1902, validation loss: 0.1211
2024-05-25 07:03:01 [INFO]: Epoch 148 - training loss: 0.1896, validation loss: 0.1216
2024-05-25 07:03:02 [INFO]: Epoch 149 - training loss: 0.1890, validation loss: 0.1212
2024-05-25 07:03:02 [INFO]: Epoch 150 - training loss: 0.1889, validation loss: 0.1208
2024-05-25 07:03:03 [INFO]: Epoch 151 - training loss: 0.1878, validation loss: 0.1208
2024-05-25 07:03:03 [INFO]: Epoch 152 - training loss: 0.1886, validation loss: 0.1213
2024-05-25 07:03:04 [INFO]: Epoch 153 - training loss: 0.1880, validation loss: 0.1222
2024-05-25 07:03:05 [INFO]: Epoch 154 - training loss: 0.1875, validation loss: 0.1216
2024-05-25 07:03:05 [INFO]: Epoch 155 - training loss: 0.1867, validation loss: 0.1203
2024-05-25 07:03:06 [INFO]: Epoch 156 - training loss: 0.1862, validation loss: 0.1224
2024-05-25 07:03:06 [INFO]: Epoch 157 - training loss: 0.1866, validation loss: 0.1211
2024-05-25 07:03:07 [INFO]: Epoch 158 - training loss: 0.1858, validation loss: 0.1201
2024-05-25 07:03:08 [INFO]: Epoch 159 - training loss: 0.1864, validation loss: 0.1204
2024-05-25 07:03:08 [INFO]: Epoch 160 - training loss: 0.1839, validation loss: 0.1207
2024-05-25 07:03:09 [INFO]: Epoch 161 - training loss: 0.1836, validation loss: 0.1204
2024-05-25 07:03:10 [INFO]: Epoch 162 - training loss: 0.1844, validation loss: 0.1206
2024-05-25 07:03:10 [INFO]: Epoch 163 - training loss: 0.1836, validation loss: 0.1204
2024-05-25 07:03:11 [INFO]: Epoch 164 - training loss: 0.1850, validation loss: 0.1192
2024-05-25 07:03:11 [INFO]: Epoch 165 - training loss: 0.1837, validation loss: 0.1195
2024-05-25 07:03:12 [INFO]: Epoch 166 - training loss: 0.1831, validation loss: 0.1189
2024-05-25 07:03:13 [INFO]: Epoch 167 - training loss: 0.1827, validation loss: 0.1200
2024-05-25 07:03:13 [INFO]: Epoch 168 - training loss: 0.1807, validation loss: 0.1186
2024-05-25 07:03:14 [INFO]: Epoch 169 - training loss: 0.1804, validation loss: 0.1185
2024-05-25 07:03:14 [INFO]: Epoch 170 - training loss: 0.1799, validation loss: 0.1176
2024-05-25 07:03:15 [INFO]: Epoch 171 - training loss: 0.1792, validation loss: 0.1188
2024-05-25 07:03:16 [INFO]: Epoch 172 - training loss: 0.1800, validation loss: 0.1185
2024-05-25 07:03:16 [INFO]: Epoch 173 - training loss: 0.1796, validation loss: 0.1186
2024-05-25 07:03:17 [INFO]: Epoch 174 - training loss: 0.1796, validation loss: 0.1181
2024-05-25 07:03:17 [INFO]: Epoch 175 - training loss: 0.1789, validation loss: 0.1175
2024-05-25 07:03:18 [INFO]: Epoch 176 - training loss: 0.1792, validation loss: 0.1182
2024-05-25 07:03:19 [INFO]: Epoch 177 - training loss: 0.1814, validation loss: 0.1177
2024-05-25 07:03:19 [INFO]: Epoch 178 - training loss: 0.1784, validation loss: 0.1180
2024-05-25 07:03:20 [INFO]: Epoch 179 - training loss: 0.1769, validation loss: 0.1170
2024-05-25 07:03:20 [INFO]: Epoch 180 - training loss: 0.1770, validation loss: 0.1169
2024-05-25 07:03:21 [INFO]: Epoch 181 - training loss: 0.1771, validation loss: 0.1171
2024-05-25 07:03:22 [INFO]: Epoch 182 - training loss: 0.1770, validation loss: 0.1169
2024-05-25 07:03:22 [INFO]: Epoch 183 - training loss: 0.1765, validation loss: 0.1167
2024-05-25 07:03:23 [INFO]: Epoch 184 - training loss: 0.1759, validation loss: 0.1169
2024-05-25 07:03:23 [INFO]: Epoch 185 - training loss: 0.1758, validation loss: 0.1172
2024-05-25 07:03:24 [INFO]: Epoch 186 - training loss: 0.1760, validation loss: 0.1170
2024-05-25 07:03:25 [INFO]: Epoch 187 - training loss: 0.1747, validation loss: 0.1156
2024-05-25 07:03:25 [INFO]: Epoch 188 - training loss: 0.1740, validation loss: 0.1159
2024-05-25 07:03:26 [INFO]: Epoch 189 - training loss: 0.1741, validation loss: 0.1162
2024-05-25 07:03:27 [INFO]: Epoch 190 - training loss: 0.1746, validation loss: 0.1151
2024-05-25 07:03:27 [INFO]: Epoch 191 - training loss: 0.1737, validation loss: 0.1162
2024-05-25 07:03:28 [INFO]: Epoch 192 - training loss: 0.1756, validation loss: 0.1173
2024-05-25 07:03:28 [INFO]: Epoch 193 - training loss: 0.1758, validation loss: 0.1161
2024-05-25 07:03:29 [INFO]: Epoch 194 - training loss: 0.1765, validation loss: 0.1161
2024-05-25 07:03:30 [INFO]: Epoch 195 - training loss: 0.1746, validation loss: 0.1154
2024-05-25 07:03:30 [INFO]: Epoch 196 - training loss: 0.1725, validation loss: 0.1143
2024-05-25 07:03:31 [INFO]: Epoch 197 - training loss: 0.1725, validation loss: 0.1147
2024-05-25 07:03:32 [INFO]: Epoch 198 - training loss: 0.1716, validation loss: 0.1151
2024-05-25 07:03:32 [INFO]: Epoch 199 - training loss: 0.1720, validation loss: 0.1132
2024-05-25 07:03:33 [INFO]: Epoch 200 - training loss: 0.1712, validation loss: 0.1158
2024-05-25 07:03:33 [INFO]: Epoch 201 - training loss: 0.1720, validation loss: 0.1160
2024-05-25 07:03:34 [INFO]: Epoch 202 - training loss: 0.1728, validation loss: 0.1173
2024-05-25 07:03:35 [INFO]: Epoch 203 - training loss: 0.1717, validation loss: 0.1138
2024-05-25 07:03:35 [INFO]: Epoch 204 - training loss: 0.1706, validation loss: 0.1144
2024-05-25 07:03:36 [INFO]: Epoch 205 - training loss: 0.1705, validation loss: 0.1134
2024-05-25 07:03:36 [INFO]: Epoch 206 - training loss: 0.1707, validation loss: 0.1147
2024-05-25 07:03:37 [INFO]: Epoch 207 - training loss: 0.1709, validation loss: 0.1139
2024-05-25 07:03:38 [INFO]: Epoch 208 - training loss: 0.1692, validation loss: 0.1154
2024-05-25 07:03:38 [INFO]: Epoch 209 - training loss: 0.1694, validation loss: 0.1149
2024-05-25 07:03:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:03:38 [INFO]: Finished training. The best model is from epoch#199.
2024-05-25 07:03:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/SAITS_air_quality/20240525_T070129/SAITS.pypots
2024-05-25 07:03:38 [INFO]: SAITS on Air-Quality: MAE=0.1509, MSE=0.2196
2024-05-25 07:03:38 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/SAITS_air_quality/imputation.pkl
2024-05-25 07:03:38 [INFO]: Using the given device: cuda:0
2024-05-25 07:03:38 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/Transformer_air_quality/20240525_T070338
2024-05-25 07:03:38 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/Transformer_air_quality/20240525_T070338/tensorboard
2024-05-25 07:03:39 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 07:03:39 [INFO]: Epoch 001 - training loss: 0.8882, validation loss: 0.4529
2024-05-25 07:03:39 [INFO]: Epoch 002 - training loss: 0.5492, validation loss: 0.3401
2024-05-25 07:03:39 [INFO]: Epoch 003 - training loss: 0.4621, validation loss: 0.2898
2024-05-25 07:03:40 [INFO]: Epoch 004 - training loss: 0.4132, validation loss: 0.2672
2024-05-25 07:03:40 [INFO]: Epoch 005 - training loss: 0.3836, validation loss: 0.2531
2024-05-25 07:03:40 [INFO]: Epoch 006 - training loss: 0.3645, validation loss: 0.2432
2024-05-25 07:03:40 [INFO]: Epoch 007 - training loss: 0.3489, validation loss: 0.2331
2024-05-25 07:03:41 [INFO]: Epoch 008 - training loss: 0.3351, validation loss: 0.2277
2024-05-25 07:03:41 [INFO]: Epoch 009 - training loss: 0.3239, validation loss: 0.2192
2024-05-25 07:03:41 [INFO]: Epoch 010 - training loss: 0.3154, validation loss: 0.2158
2024-05-25 07:03:41 [INFO]: Epoch 011 - training loss: 0.3098, validation loss: 0.2109
2024-05-25 07:03:42 [INFO]: Epoch 012 - training loss: 0.3038, validation loss: 0.2056
2024-05-25 07:03:42 [INFO]: Epoch 013 - training loss: 0.2950, validation loss: 0.2022
2024-05-25 07:03:42 [INFO]: Epoch 014 - training loss: 0.2892, validation loss: 0.1962
2024-05-25 07:03:42 [INFO]: Epoch 015 - training loss: 0.2857, validation loss: 0.1946
2024-05-25 07:03:43 [INFO]: Epoch 016 - training loss: 0.2810, validation loss: 0.1923
2024-05-25 07:03:43 [INFO]: Epoch 017 - training loss: 0.2766, validation loss: 0.1881
2024-05-25 07:03:43 [INFO]: Epoch 018 - training loss: 0.2736, validation loss: 0.1848
2024-05-25 07:03:43 [INFO]: Epoch 019 - training loss: 0.2720, validation loss: 0.1835
2024-05-25 07:03:44 [INFO]: Epoch 020 - training loss: 0.2674, validation loss: 0.1803
2024-05-25 07:03:44 [INFO]: Epoch 021 - training loss: 0.2644, validation loss: 0.1795
2024-05-25 07:03:44 [INFO]: Epoch 022 - training loss: 0.2626, validation loss: 0.1790
2024-05-25 07:03:44 [INFO]: Epoch 023 - training loss: 0.2558, validation loss: 0.1762
2024-05-25 07:03:45 [INFO]: Epoch 024 - training loss: 0.2538, validation loss: 0.1753
2024-05-25 07:03:45 [INFO]: Epoch 025 - training loss: 0.2525, validation loss: 0.1740
2024-05-25 07:03:45 [INFO]: Epoch 026 - training loss: 0.2508, validation loss: 0.1733
2024-05-25 07:03:45 [INFO]: Epoch 027 - training loss: 0.2487, validation loss: 0.1709
2024-05-25 07:03:46 [INFO]: Epoch 028 - training loss: 0.2456, validation loss: 0.1697
2024-05-25 07:03:46 [INFO]: Epoch 029 - training loss: 0.2437, validation loss: 0.1683
2024-05-25 07:03:46 [INFO]: Epoch 030 - training loss: 0.2411, validation loss: 0.1692
2024-05-25 07:03:46 [INFO]: Epoch 031 - training loss: 0.2382, validation loss: 0.1666
2024-05-25 07:03:47 [INFO]: Epoch 032 - training loss: 0.2363, validation loss: 0.1691
2024-05-25 07:03:47 [INFO]: Epoch 033 - training loss: 0.2354, validation loss: 0.1665
2024-05-25 07:03:47 [INFO]: Epoch 034 - training loss: 0.2317, validation loss: 0.1659
2024-05-25 07:03:48 [INFO]: Epoch 035 - training loss: 0.2318, validation loss: 0.1671
2024-05-25 07:03:48 [INFO]: Epoch 036 - training loss: 0.2284, validation loss: 0.1633
2024-05-25 07:03:48 [INFO]: Epoch 037 - training loss: 0.2277, validation loss: 0.1660
2024-05-25 07:03:48 [INFO]: Epoch 038 - training loss: 0.2264, validation loss: 0.1635
2024-05-25 07:03:49 [INFO]: Epoch 039 - training loss: 0.2245, validation loss: 0.1617
2024-05-25 07:03:49 [INFO]: Epoch 040 - training loss: 0.2218, validation loss: 0.1625
2024-05-25 07:03:49 [INFO]: Epoch 041 - training loss: 0.2280, validation loss: 0.1595
2024-05-25 07:03:49 [INFO]: Epoch 042 - training loss: 0.2204, validation loss: 0.1594
2024-05-25 07:03:50 [INFO]: Epoch 043 - training loss: 0.2180, validation loss: 0.1595
2024-05-25 07:03:50 [INFO]: Epoch 044 - training loss: 0.2186, validation loss: 0.1597
2024-05-25 07:03:50 [INFO]: Epoch 045 - training loss: 0.2170, validation loss: 0.1598
2024-05-25 07:03:50 [INFO]: Epoch 046 - training loss: 0.2137, validation loss: 0.1573
2024-05-25 07:03:51 [INFO]: Epoch 047 - training loss: 0.2135, validation loss: 0.1586
2024-05-25 07:03:51 [INFO]: Epoch 048 - training loss: 0.2111, validation loss: 0.1568
2024-05-25 07:03:51 [INFO]: Epoch 049 - training loss: 0.2093, validation loss: 0.1559
2024-05-25 07:03:51 [INFO]: Epoch 050 - training loss: 0.2074, validation loss: 0.1570
2024-05-25 07:03:52 [INFO]: Epoch 051 - training loss: 0.2060, validation loss: 0.1565
2024-05-25 07:03:52 [INFO]: Epoch 052 - training loss: 0.2054, validation loss: 0.1577
2024-05-25 07:03:52 [INFO]: Epoch 053 - training loss: 0.2041, validation loss: 0.1564
2024-05-25 07:03:52 [INFO]: Epoch 054 - training loss: 0.2031, validation loss: 0.1560
2024-05-25 07:03:53 [INFO]: Epoch 055 - training loss: 0.2028, validation loss: 0.1537
2024-05-25 07:03:53 [INFO]: Epoch 056 - training loss: 0.2016, validation loss: 0.1543
2024-05-25 07:03:53 [INFO]: Epoch 057 - training loss: 0.1999, validation loss: 0.1524
2024-05-25 07:03:53 [INFO]: Epoch 058 - training loss: 0.1992, validation loss: 0.1552
2024-05-25 07:03:54 [INFO]: Epoch 059 - training loss: 0.1963, validation loss: 0.1543
2024-05-25 07:03:54 [INFO]: Epoch 060 - training loss: 0.1971, validation loss: 0.1535
2024-05-25 07:03:54 [INFO]: Epoch 061 - training loss: 0.1952, validation loss: 0.1530
2024-05-25 07:03:54 [INFO]: Epoch 062 - training loss: 0.1966, validation loss: 0.1528
2024-05-25 07:03:55 [INFO]: Epoch 063 - training loss: 0.1949, validation loss: 0.1526
2024-05-25 07:03:55 [INFO]: Epoch 064 - training loss: 0.1961, validation loss: 0.1523
2024-05-25 07:03:55 [INFO]: Epoch 065 - training loss: 0.1912, validation loss: 0.1496
2024-05-25 07:03:55 [INFO]: Epoch 066 - training loss: 0.1901, validation loss: 0.1514
2024-05-25 07:03:56 [INFO]: Epoch 067 - training loss: 0.1927, validation loss: 0.1511
2024-05-25 07:03:56 [INFO]: Epoch 068 - training loss: 0.1926, validation loss: 0.1520
2024-05-25 07:03:56 [INFO]: Epoch 069 - training loss: 0.1892, validation loss: 0.1500
2024-05-25 07:03:56 [INFO]: Epoch 070 - training loss: 0.1863, validation loss: 0.1509
2024-05-25 07:03:57 [INFO]: Epoch 071 - training loss: 0.1859, validation loss: 0.1490
2024-05-25 07:03:57 [INFO]: Epoch 072 - training loss: 0.1852, validation loss: 0.1504
2024-05-25 07:03:57 [INFO]: Epoch 073 - training loss: 0.1829, validation loss: 0.1491
2024-05-25 07:03:57 [INFO]: Epoch 074 - training loss: 0.1810, validation loss: 0.1500
2024-05-25 07:03:58 [INFO]: Epoch 075 - training loss: 0.1810, validation loss: 0.1482
2024-05-25 07:03:58 [INFO]: Epoch 076 - training loss: 0.1839, validation loss: 0.1488
2024-05-25 07:03:58 [INFO]: Epoch 077 - training loss: 0.1805, validation loss: 0.1463
2024-05-25 07:03:58 [INFO]: Epoch 078 - training loss: 0.1795, validation loss: 0.1486
2024-05-25 07:03:59 [INFO]: Epoch 079 - training loss: 0.1799, validation loss: 0.1469
2024-05-25 07:03:59 [INFO]: Epoch 080 - training loss: 0.1780, validation loss: 0.1458
2024-05-25 07:03:59 [INFO]: Epoch 081 - training loss: 0.1770, validation loss: 0.1480
2024-05-25 07:03:59 [INFO]: Epoch 082 - training loss: 0.1767, validation loss: 0.1454
2024-05-25 07:04:00 [INFO]: Epoch 083 - training loss: 0.1750, validation loss: 0.1465
2024-05-25 07:04:00 [INFO]: Epoch 084 - training loss: 0.1740, validation loss: 0.1470
2024-05-25 07:04:00 [INFO]: Epoch 085 - training loss: 0.1734, validation loss: 0.1462
2024-05-25 07:04:00 [INFO]: Epoch 086 - training loss: 0.1773, validation loss: 0.1456
2024-05-25 07:04:01 [INFO]: Epoch 087 - training loss: 0.1733, validation loss: 0.1444
2024-05-25 07:04:01 [INFO]: Epoch 088 - training loss: 0.1729, validation loss: 0.1461
2024-05-25 07:04:01 [INFO]: Epoch 089 - training loss: 0.1717, validation loss: 0.1438
2024-05-25 07:04:02 [INFO]: Epoch 090 - training loss: 0.1702, validation loss: 0.1450
2024-05-25 07:04:02 [INFO]: Epoch 091 - training loss: 0.1695, validation loss: 0.1456
2024-05-25 07:04:02 [INFO]: Epoch 092 - training loss: 0.1697, validation loss: 0.1438
2024-05-25 07:04:02 [INFO]: Epoch 093 - training loss: 0.1703, validation loss: 0.1443
2024-05-25 07:04:03 [INFO]: Epoch 094 - training loss: 0.1729, validation loss: 0.1422
2024-05-25 07:04:03 [INFO]: Epoch 095 - training loss: 0.1688, validation loss: 0.1454
2024-05-25 07:04:03 [INFO]: Epoch 096 - training loss: 0.1688, validation loss: 0.1424
2024-05-25 07:04:03 [INFO]: Epoch 097 - training loss: 0.1662, validation loss: 0.1438
2024-05-25 07:04:04 [INFO]: Epoch 098 - training loss: 0.1657, validation loss: 0.1429
2024-05-25 07:04:04 [INFO]: Epoch 099 - training loss: 0.1670, validation loss: 0.1429
2024-05-25 07:04:04 [INFO]: Epoch 100 - training loss: 0.1644, validation loss: 0.1419
2024-05-25 07:04:04 [INFO]: Epoch 101 - training loss: 0.1632, validation loss: 0.1430
2024-05-25 07:04:05 [INFO]: Epoch 102 - training loss: 0.1624, validation loss: 0.1408
2024-05-25 07:04:05 [INFO]: Epoch 103 - training loss: 0.1620, validation loss: 0.1412
2024-05-25 07:04:05 [INFO]: Epoch 104 - training loss: 0.1617, validation loss: 0.1407
2024-05-25 07:04:05 [INFO]: Epoch 105 - training loss: 0.1623, validation loss: 0.1412
2024-05-25 07:04:06 [INFO]: Epoch 106 - training loss: 0.1606, validation loss: 0.1399
2024-05-25 07:04:06 [INFO]: Epoch 107 - training loss: 0.1614, validation loss: 0.1397
2024-05-25 07:04:06 [INFO]: Epoch 108 - training loss: 0.1609, validation loss: 0.1420
2024-05-25 07:04:06 [INFO]: Epoch 109 - training loss: 0.1595, validation loss: 0.1399
2024-05-25 07:04:07 [INFO]: Epoch 110 - training loss: 0.1600, validation loss: 0.1430
2024-05-25 07:04:07 [INFO]: Epoch 111 - training loss: 0.1591, validation loss: 0.1381
2024-05-25 07:04:07 [INFO]: Epoch 112 - training loss: 0.1572, validation loss: 0.1393
2024-05-25 07:04:07 [INFO]: Epoch 113 - training loss: 0.1568, validation loss: 0.1396
2024-05-25 07:04:08 [INFO]: Epoch 114 - training loss: 0.1579, validation loss: 0.1390
2024-05-25 07:04:08 [INFO]: Epoch 115 - training loss: 0.1584, validation loss: 0.1384
2024-05-25 07:04:08 [INFO]: Epoch 116 - training loss: 0.1592, validation loss: 0.1396
2024-05-25 07:04:08 [INFO]: Epoch 117 - training loss: 0.1559, validation loss: 0.1391
2024-05-25 07:04:09 [INFO]: Epoch 118 - training loss: 0.1535, validation loss: 0.1407
2024-05-25 07:04:09 [INFO]: Epoch 119 - training loss: 0.1540, validation loss: 0.1398
2024-05-25 07:04:09 [INFO]: Epoch 120 - training loss: 0.1525, validation loss: 0.1391
2024-05-25 07:04:09 [INFO]: Epoch 121 - training loss: 0.1533, validation loss: 0.1391
2024-05-25 07:04:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:04:09 [INFO]: Finished training. The best model is from epoch#111.
2024-05-25 07:04:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/Transformer_air_quality/20240525_T070338/Transformer.pypots
2024-05-25 07:04:09 [INFO]: Transformer on Air-Quality: MAE=0.1710, MSE=0.2535
2024-05-25 07:04:09 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Transformer_air_quality/imputation.pkl
2024-05-25 07:04:09 [INFO]: Using the given device: cuda:0
2024-05-25 07:04:09 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/TimesNet_air_quality/20240525_T070409
2024-05-25 07:04:09 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/TimesNet_air_quality/20240525_T070409/tensorboard
2024-05-25 07:04:10 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 07:04:10 [INFO]: Epoch 001 - training loss: 0.2913, validation loss: 0.2698
2024-05-25 07:04:11 [INFO]: Epoch 002 - training loss: 0.2602, validation loss: 0.2511
2024-05-25 07:04:11 [INFO]: Epoch 003 - training loss: 0.2140, validation loss: 0.2339
2024-05-25 07:04:12 [INFO]: Epoch 004 - training loss: 0.1876, validation loss: 0.2200
2024-05-25 07:04:12 [INFO]: Epoch 005 - training loss: 0.1574, validation loss: 0.2120
2024-05-25 07:04:13 [INFO]: Epoch 006 - training loss: 0.1472, validation loss: 0.2050
2024-05-25 07:04:13 [INFO]: Epoch 007 - training loss: 0.1392, validation loss: 0.2045
2024-05-25 07:04:14 [INFO]: Epoch 008 - training loss: 0.1321, validation loss: 0.2008
2024-05-25 07:04:14 [INFO]: Epoch 009 - training loss: 0.1256, validation loss: 0.1943
2024-05-25 07:04:15 [INFO]: Epoch 010 - training loss: 0.1215, validation loss: 0.2009
2024-05-25 07:04:15 [INFO]: Epoch 011 - training loss: 0.1255, validation loss: 0.1897
2024-05-25 07:04:16 [INFO]: Epoch 012 - training loss: 0.1344, validation loss: 0.2002
2024-05-25 07:04:16 [INFO]: Epoch 013 - training loss: 0.1282, validation loss: 0.1916
2024-05-25 07:04:17 [INFO]: Epoch 014 - training loss: 0.1267, validation loss: 0.1962
2024-05-25 07:04:17 [INFO]: Epoch 015 - training loss: 0.1277, validation loss: 0.1879
2024-05-25 07:04:17 [INFO]: Epoch 016 - training loss: 0.1146, validation loss: 0.1922
2024-05-25 07:04:18 [INFO]: Epoch 017 - training loss: 0.1066, validation loss: 0.1849
2024-05-25 07:04:18 [INFO]: Epoch 018 - training loss: 0.1047, validation loss: 0.1818
2024-05-25 07:04:19 [INFO]: Epoch 019 - training loss: 0.0968, validation loss: 0.1839
2024-05-25 07:04:19 [INFO]: Epoch 020 - training loss: 0.0941, validation loss: 0.1794
2024-05-25 07:04:20 [INFO]: Epoch 021 - training loss: 0.0912, validation loss: 0.1836
2024-05-25 07:04:20 [INFO]: Epoch 022 - training loss: 0.0865, validation loss: 0.1781
2024-05-25 07:04:21 [INFO]: Epoch 023 - training loss: 0.0837, validation loss: 0.1775
2024-05-25 07:04:21 [INFO]: Epoch 024 - training loss: 0.0830, validation loss: 0.1751
2024-05-25 07:04:22 [INFO]: Epoch 025 - training loss: 0.0780, validation loss: 0.1761
2024-05-25 07:04:22 [INFO]: Epoch 026 - training loss: 0.0770, validation loss: 0.1753
2024-05-25 07:04:23 [INFO]: Epoch 027 - training loss: 0.0782, validation loss: 0.1768
2024-05-25 07:04:23 [INFO]: Epoch 028 - training loss: 0.0822, validation loss: 0.1792
2024-05-25 07:04:24 [INFO]: Epoch 029 - training loss: 0.0830, validation loss: 0.1765
2024-05-25 07:04:24 [INFO]: Epoch 030 - training loss: 0.0766, validation loss: 0.1748
2024-05-25 07:04:25 [INFO]: Epoch 031 - training loss: 0.0739, validation loss: 0.1760
2024-05-25 07:04:25 [INFO]: Epoch 032 - training loss: 0.0758, validation loss: 0.1726
2024-05-25 07:04:25 [INFO]: Epoch 033 - training loss: 0.0719, validation loss: 0.1732
2024-05-25 07:04:26 [INFO]: Epoch 034 - training loss: 0.0699, validation loss: 0.1715
2024-05-25 07:04:26 [INFO]: Epoch 035 - training loss: 0.0745, validation loss: 0.1780
2024-05-25 07:04:27 [INFO]: Epoch 036 - training loss: 0.0736, validation loss: 0.1722
2024-05-25 07:04:27 [INFO]: Epoch 037 - training loss: 0.0793, validation loss: 0.1716
2024-05-25 07:04:28 [INFO]: Epoch 038 - training loss: 0.0672, validation loss: 0.1711
2024-05-25 07:04:28 [INFO]: Epoch 039 - training loss: 0.0634, validation loss: 0.1703
2024-05-25 07:04:29 [INFO]: Epoch 040 - training loss: 0.0602, validation loss: 0.1695
2024-05-25 07:04:29 [INFO]: Epoch 041 - training loss: 0.0592, validation loss: 0.1714
2024-05-25 07:04:30 [INFO]: Epoch 042 - training loss: 0.0591, validation loss: 0.1696
2024-05-25 07:04:30 [INFO]: Epoch 043 - training loss: 0.0617, validation loss: 0.1711
2024-05-25 07:04:31 [INFO]: Epoch 044 - training loss: 0.0627, validation loss: 0.1705
2024-05-25 07:04:31 [INFO]: Epoch 045 - training loss: 0.0626, validation loss: 0.1693
2024-05-25 07:04:32 [INFO]: Epoch 046 - training loss: 0.0596, validation loss: 0.1716
2024-05-25 07:04:32 [INFO]: Epoch 047 - training loss: 0.0622, validation loss: 0.1686
2024-05-25 07:04:32 [INFO]: Epoch 048 - training loss: 0.0620, validation loss: 0.1703
2024-05-25 07:04:33 [INFO]: Epoch 049 - training loss: 0.0575, validation loss: 0.1686
2024-05-25 07:04:33 [INFO]: Epoch 050 - training loss: 0.0538, validation loss: 0.1712
2024-05-25 07:04:34 [INFO]: Epoch 051 - training loss: 0.0537, validation loss: 0.1684
2024-05-25 07:04:34 [INFO]: Epoch 052 - training loss: 0.0526, validation loss: 0.1705
2024-05-25 07:04:35 [INFO]: Epoch 053 - training loss: 0.0520, validation loss: 0.1676
2024-05-25 07:04:35 [INFO]: Epoch 054 - training loss: 0.0514, validation loss: 0.1701
2024-05-25 07:04:36 [INFO]: Epoch 055 - training loss: 0.0512, validation loss: 0.1780
2024-05-25 07:04:36 [INFO]: Epoch 056 - training loss: 0.0566, validation loss: 0.1797
2024-05-25 07:04:37 [INFO]: Epoch 057 - training loss: 0.0670, validation loss: 0.1864
2024-05-25 07:04:37 [INFO]: Epoch 058 - training loss: 0.0557, validation loss: 0.1727
2024-05-25 07:04:38 [INFO]: Epoch 059 - training loss: 0.0626, validation loss: 0.1679
2024-05-25 07:04:38 [INFO]: Epoch 060 - training loss: 0.0582, validation loss: 0.1765
2024-05-25 07:04:39 [INFO]: Epoch 061 - training loss: 0.0662, validation loss: 0.1790
2024-05-25 07:04:39 [INFO]: Epoch 062 - training loss: 0.0786, validation loss: 0.1954
2024-05-25 07:04:40 [INFO]: Epoch 063 - training loss: 0.0931, validation loss: 0.1929
2024-05-25 07:04:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:04:40 [INFO]: Finished training. The best model is from epoch#53.
2024-05-25 07:04:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/TimesNet_air_quality/20240525_T070409/TimesNet.pypots
2024-05-25 07:04:40 [INFO]: TimesNet on Air-Quality: MAE=0.1751, MSE=0.3544
2024-05-25 07:04:40 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/TimesNet_air_quality/imputation.pkl
2024-05-25 07:04:40 [INFO]: Using the given device: cuda:0
2024-05-25 07:04:40 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440
2024-05-25 07:04:40 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/tensorboard
2024-05-25 07:04:40 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 07:04:57 [INFO]: Epoch 001 - training loss: 0.5229, validation loss: 0.3610
2024-05-25 07:04:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch1_loss0.36098308861255646.pypots
2024-05-25 07:05:13 [INFO]: Epoch 002 - training loss: 0.3166, validation loss: 0.2803
2024-05-25 07:05:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch2_loss0.2802603542804718.pypots
2024-05-25 07:05:30 [INFO]: Epoch 003 - training loss: 0.2550, validation loss: 0.2544
2024-05-25 07:05:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch3_loss0.2543897479772568.pypots
2024-05-25 07:05:47 [INFO]: Epoch 004 - training loss: 0.2566, validation loss: 0.2299
2024-05-25 07:05:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch4_loss0.2299225702881813.pypots
2024-05-25 07:06:03 [INFO]: Epoch 005 - training loss: 0.2096, validation loss: 0.2037
2024-05-25 07:06:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch5_loss0.20367673486471177.pypots
2024-05-25 07:06:20 [INFO]: Epoch 006 - training loss: 0.2075, validation loss: 0.1806
2024-05-25 07:06:20 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch6_loss0.18055015951395034.pypots
2024-05-25 07:06:37 [INFO]: Epoch 007 - training loss: 0.1838, validation loss: 0.1780
2024-05-25 07:06:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch7_loss0.17796091884374618.pypots
2024-05-25 07:06:54 [INFO]: Epoch 008 - training loss: 0.1760, validation loss: 0.1801
2024-05-25 07:06:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch8_loss0.18009616136550904.pypots
2024-05-25 07:07:10 [INFO]: Epoch 009 - training loss: 0.1811, validation loss: 0.1681
2024-05-25 07:07:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch9_loss0.16808934211730958.pypots
2024-05-25 07:07:27 [INFO]: Epoch 010 - training loss: 0.1657, validation loss: 0.1579
2024-05-25 07:07:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch10_loss0.15793731063604355.pypots
2024-05-25 07:07:44 [INFO]: Epoch 011 - training loss: 0.1660, validation loss: 0.1538
2024-05-25 07:07:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch11_loss0.15377651900053024.pypots
2024-05-25 07:08:01 [INFO]: Epoch 012 - training loss: 0.1562, validation loss: 0.1498
2024-05-25 07:08:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch12_loss0.14984873682260513.pypots
2024-05-25 07:08:17 [INFO]: Epoch 013 - training loss: 0.1566, validation loss: 0.1662
2024-05-25 07:08:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch13_loss0.16624014377593993.pypots
2024-05-25 07:08:34 [INFO]: Epoch 014 - training loss: 0.1540, validation loss: 0.1541
2024-05-25 07:08:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch14_loss0.15407546907663344.pypots
2024-05-25 07:08:51 [INFO]: Epoch 015 - training loss: 0.1631, validation loss: 0.1465
2024-05-25 07:08:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch15_loss0.1464955434203148.pypots
2024-05-25 07:09:08 [INFO]: Epoch 016 - training loss: 0.1591, validation loss: 0.1424
2024-05-25 07:09:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch16_loss0.1423873074352741.pypots
2024-05-25 07:09:24 [INFO]: Epoch 017 - training loss: 0.1567, validation loss: 0.1429
2024-05-25 07:09:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch17_loss0.1428862363100052.pypots
2024-05-25 07:09:41 [INFO]: Epoch 018 - training loss: 0.1513, validation loss: 0.1413
2024-05-25 07:09:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch18_loss0.14126905277371407.pypots
2024-05-25 07:09:58 [INFO]: Epoch 019 - training loss: 0.1514, validation loss: 0.1421
2024-05-25 07:09:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch19_loss0.14213369339704512.pypots
2024-05-25 07:10:15 [INFO]: Epoch 020 - training loss: 0.1419, validation loss: 0.1414
2024-05-25 07:10:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch20_loss0.14137300848960876.pypots
2024-05-25 07:10:31 [INFO]: Epoch 021 - training loss: 0.1545, validation loss: 0.1387
2024-05-25 07:10:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch21_loss0.13868939951062204.pypots
2024-05-25 07:10:48 [INFO]: Epoch 022 - training loss: 0.1556, validation loss: 0.1479
2024-05-25 07:10:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch22_loss0.1478861853480339.pypots
2024-05-25 07:11:05 [INFO]: Epoch 023 - training loss: 0.1611, validation loss: 0.1361
2024-05-25 07:11:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch23_loss0.13610860481858253.pypots
2024-05-25 07:11:21 [INFO]: Epoch 024 - training loss: 0.1443, validation loss: 0.1380
2024-05-25 07:11:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch24_loss0.1379993475973606.pypots
2024-05-25 07:11:38 [INFO]: Epoch 025 - training loss: 0.1476, validation loss: 0.1332
2024-05-25 07:11:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch25_loss0.13322339802980424.pypots
2024-05-25 07:11:55 [INFO]: Epoch 026 - training loss: 0.1489, validation loss: 0.1330
2024-05-25 07:11:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch26_loss0.13303058966994286.pypots
2024-05-25 07:12:12 [INFO]: Epoch 027 - training loss: 0.1388, validation loss: 0.1295
2024-05-25 07:12:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch27_loss0.1295377053320408.pypots
2024-05-25 07:12:28 [INFO]: Epoch 028 - training loss: 0.1351, validation loss: 0.1339
2024-05-25 07:12:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch28_loss0.13385552689433097.pypots
2024-05-25 07:12:45 [INFO]: Epoch 029 - training loss: 0.1297, validation loss: 0.1296
2024-05-25 07:12:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch29_loss0.1296091377735138.pypots
2024-05-25 07:13:02 [INFO]: Epoch 030 - training loss: 0.1263, validation loss: 0.1308
2024-05-25 07:13:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch30_loss0.13081017658114433.pypots
2024-05-25 07:13:19 [INFO]: Epoch 031 - training loss: 0.1320, validation loss: 0.1287
2024-05-25 07:13:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch31_loss0.12867719680070877.pypots
2024-05-25 07:13:35 [INFO]: Epoch 032 - training loss: 0.1321, validation loss: 0.1287
2024-05-25 07:13:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch32_loss0.12867754846811294.pypots
2024-05-25 07:13:52 [INFO]: Epoch 033 - training loss: 0.1345, validation loss: 0.1296
2024-05-25 07:13:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch33_loss0.12958068102598191.pypots
2024-05-25 07:14:09 [INFO]: Epoch 034 - training loss: 0.1173, validation loss: 0.1273
2024-05-25 07:14:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch34_loss0.1272713802754879.pypots
2024-05-25 07:14:25 [INFO]: Epoch 035 - training loss: 0.1299, validation loss: 0.1292
2024-05-25 07:14:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch35_loss0.1291636824607849.pypots
2024-05-25 07:14:42 [INFO]: Epoch 036 - training loss: 0.1317, validation loss: 0.1294
2024-05-25 07:14:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch36_loss0.12943772003054618.pypots
2024-05-25 07:14:59 [INFO]: Epoch 037 - training loss: 0.1230, validation loss: 0.1284
2024-05-25 07:14:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch37_loss0.1283664770424366.pypots
2024-05-25 07:15:16 [INFO]: Epoch 038 - training loss: 0.1324, validation loss: 0.1245
2024-05-25 07:15:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch38_loss0.12450964152812957.pypots
2024-05-25 07:15:32 [INFO]: Epoch 039 - training loss: 0.1505, validation loss: 0.1257
2024-05-25 07:15:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch39_loss0.12572982013225556.pypots
2024-05-25 07:15:49 [INFO]: Epoch 040 - training loss: 0.1244, validation loss: 0.1344
2024-05-25 07:15:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch40_loss0.13437457680702208.pypots
2024-05-25 07:16:06 [INFO]: Epoch 041 - training loss: 0.1379, validation loss: 0.1222
2024-05-25 07:16:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch41_loss0.12222536131739617.pypots
2024-05-25 07:16:23 [INFO]: Epoch 042 - training loss: 0.1287, validation loss: 0.1221
2024-05-25 07:16:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch42_loss0.12212048694491387.pypots
2024-05-25 07:16:39 [INFO]: Epoch 043 - training loss: 0.1302, validation loss: 0.1212
2024-05-25 07:16:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch43_loss0.1211562305688858.pypots
2024-05-25 07:16:56 [INFO]: Epoch 044 - training loss: 0.1283, validation loss: 0.1258
2024-05-25 07:16:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch44_loss0.1258312851190567.pypots
2024-05-25 07:17:13 [INFO]: Epoch 045 - training loss: 0.1324, validation loss: 0.1227
2024-05-25 07:17:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch45_loss0.12273077443242073.pypots
2024-05-25 07:17:30 [INFO]: Epoch 046 - training loss: 0.1165, validation loss: 0.1218
2024-05-25 07:17:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch46_loss0.1217581644654274.pypots
2024-05-25 07:17:46 [INFO]: Epoch 047 - training loss: 0.1187, validation loss: 0.1230
2024-05-25 07:17:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch47_loss0.12300036326050759.pypots
2024-05-25 07:18:03 [INFO]: Epoch 048 - training loss: 0.1248, validation loss: 0.1219
2024-05-25 07:18:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch48_loss0.12189939543604851.pypots
2024-05-25 07:18:20 [INFO]: Epoch 049 - training loss: 0.1133, validation loss: 0.1187
2024-05-25 07:18:20 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch49_loss0.11871588006615638.pypots
2024-05-25 07:18:36 [INFO]: Epoch 050 - training loss: 0.1213, validation loss: 0.1212
2024-05-25 07:18:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch50_loss0.12117165774106979.pypots
2024-05-25 07:18:53 [INFO]: Epoch 051 - training loss: 0.1327, validation loss: 0.1185
2024-05-25 07:18:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch51_loss0.1185081996023655.pypots
2024-05-25 07:19:10 [INFO]: Epoch 052 - training loss: 0.1211, validation loss: 0.1202
2024-05-25 07:19:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch52_loss0.12019192576408386.pypots
2024-05-25 07:19:27 [INFO]: Epoch 053 - training loss: 0.1278, validation loss: 0.1207
2024-05-25 07:19:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch53_loss0.12069855257868767.pypots
2024-05-25 07:19:43 [INFO]: Epoch 054 - training loss: 0.1260, validation loss: 0.1231
2024-05-25 07:19:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch54_loss0.12310398742556572.pypots
2024-05-25 07:20:00 [INFO]: Epoch 055 - training loss: 0.1163, validation loss: 0.1212
2024-05-25 07:20:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch55_loss0.12121481820940971.pypots
2024-05-25 07:20:17 [INFO]: Epoch 056 - training loss: 0.1085, validation loss: 0.1258
2024-05-25 07:20:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch56_loss0.12578825950622557.pypots
2024-05-25 07:20:34 [INFO]: Epoch 057 - training loss: 0.1111, validation loss: 0.1206
2024-05-25 07:20:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch57_loss0.12057416662573814.pypots
2024-05-25 07:20:50 [INFO]: Epoch 058 - training loss: 0.1166, validation loss: 0.1183
2024-05-25 07:20:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch58_loss0.11830592900514603.pypots
2024-05-25 07:21:07 [INFO]: Epoch 059 - training loss: 0.1146, validation loss: 0.1209
2024-05-25 07:21:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch59_loss0.12092490941286087.pypots
2024-05-25 07:21:24 [INFO]: Epoch 060 - training loss: 0.1214, validation loss: 0.1187
2024-05-25 07:21:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch60_loss0.1187283806502819.pypots
2024-05-25 07:21:41 [INFO]: Epoch 061 - training loss: 0.1085, validation loss: 0.1164
2024-05-25 07:21:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch61_loss0.11642448008060455.pypots
2024-05-25 07:21:57 [INFO]: Epoch 062 - training loss: 0.1207, validation loss: 0.1170
2024-05-25 07:21:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch62_loss0.11698968932032586.pypots
2024-05-25 07:22:14 [INFO]: Epoch 063 - training loss: 0.1153, validation loss: 0.1152
2024-05-25 07:22:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch63_loss0.11523075178265571.pypots
2024-05-25 07:22:31 [INFO]: Epoch 064 - training loss: 0.1330, validation loss: 0.1202
2024-05-25 07:22:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch64_loss0.12022229507565499.pypots
2024-05-25 07:22:48 [INFO]: Epoch 065 - training loss: 0.1150, validation loss: 0.1169
2024-05-25 07:22:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch65_loss0.11688013151288032.pypots
2024-05-25 07:23:04 [INFO]: Epoch 066 - training loss: 0.1151, validation loss: 0.1187
2024-05-25 07:23:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch66_loss0.11866027414798737.pypots
2024-05-25 07:23:21 [INFO]: Epoch 067 - training loss: 0.1164, validation loss: 0.1163
2024-05-25 07:23:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch67_loss0.11625659763813019.pypots
2024-05-25 07:23:38 [INFO]: Epoch 068 - training loss: 0.1210, validation loss: 0.1137
2024-05-25 07:23:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch68_loss0.11367226392030716.pypots
2024-05-25 07:23:55 [INFO]: Epoch 069 - training loss: 0.1162, validation loss: 0.1157
2024-05-25 07:23:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch69_loss0.11567399352788925.pypots
2024-05-25 07:24:11 [INFO]: Epoch 070 - training loss: 0.1178, validation loss: 0.1139
2024-05-25 07:24:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch70_loss0.11391336843371391.pypots
2024-05-25 07:24:28 [INFO]: Epoch 071 - training loss: 0.1156, validation loss: 0.1186
2024-05-25 07:24:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch71_loss0.1186071939766407.pypots
2024-05-25 07:24:45 [INFO]: Epoch 072 - training loss: 0.1317, validation loss: 0.1232
2024-05-25 07:24:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch72_loss0.12321209460496903.pypots
2024-05-25 07:25:01 [INFO]: Epoch 073 - training loss: 0.1177, validation loss: 0.1201
2024-05-25 07:25:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch73_loss0.12011170163750648.pypots
2024-05-25 07:25:18 [INFO]: Epoch 074 - training loss: 0.1168, validation loss: 0.1148
2024-05-25 07:25:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch74_loss0.11481533944606781.pypots
2024-05-25 07:25:35 [INFO]: Epoch 075 - training loss: 0.1076, validation loss: 0.1142
2024-05-25 07:25:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch75_loss0.1142077013850212.pypots
2024-05-25 07:25:52 [INFO]: Epoch 076 - training loss: 0.1113, validation loss: 0.1133
2024-05-25 07:25:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch76_loss0.11325675994157791.pypots
2024-05-25 07:26:08 [INFO]: Epoch 077 - training loss: 0.1123, validation loss: 0.1139
2024-05-25 07:26:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch77_loss0.11392369121313095.pypots
2024-05-25 07:26:25 [INFO]: Epoch 078 - training loss: 0.1235, validation loss: 0.1148
2024-05-25 07:26:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch78_loss0.11477894708514214.pypots
2024-05-25 07:26:42 [INFO]: Epoch 079 - training loss: 0.1195, validation loss: 0.1120
2024-05-25 07:26:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch79_loss0.11203263327479362.pypots
2024-05-25 07:26:59 [INFO]: Epoch 080 - training loss: 0.1204, validation loss: 0.1161
2024-05-25 07:26:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch80_loss0.11610840857028962.pypots
2024-05-25 07:27:15 [INFO]: Epoch 081 - training loss: 0.1142, validation loss: 0.1157
2024-05-25 07:27:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch81_loss0.11570585891604424.pypots
2024-05-25 07:27:32 [INFO]: Epoch 082 - training loss: 0.1179, validation loss: 0.1116
2024-05-25 07:27:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch82_loss0.11159956231713294.pypots
2024-05-25 07:27:49 [INFO]: Epoch 083 - training loss: 0.1085, validation loss: 0.1125
2024-05-25 07:27:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch83_loss0.11248815059661865.pypots
2024-05-25 07:28:06 [INFO]: Epoch 084 - training loss: 0.1197, validation loss: 0.1118
2024-05-25 07:28:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch84_loss0.11175515800714493.pypots
2024-05-25 07:28:22 [INFO]: Epoch 085 - training loss: 0.1188, validation loss: 0.1105
2024-05-25 07:28:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch85_loss0.11049023196101189.pypots
2024-05-25 07:28:39 [INFO]: Epoch 086 - training loss: 0.1189, validation loss: 0.1122
2024-05-25 07:28:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch86_loss0.11218300834298134.pypots
2024-05-25 07:28:56 [INFO]: Epoch 087 - training loss: 0.1146, validation loss: 0.1144
2024-05-25 07:28:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch87_loss0.11438646987080574.pypots
2024-05-25 07:29:12 [INFO]: Epoch 088 - training loss: 0.0987, validation loss: 0.1128
2024-05-25 07:29:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch88_loss0.11279323622584343.pypots
2024-05-25 07:29:29 [INFO]: Epoch 089 - training loss: 0.1226, validation loss: 0.1139
2024-05-25 07:29:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch89_loss0.11389159187674522.pypots
2024-05-25 07:29:46 [INFO]: Epoch 090 - training loss: 0.1094, validation loss: 0.1157
2024-05-25 07:29:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch90_loss0.11570998653769493.pypots
2024-05-25 07:30:03 [INFO]: Epoch 091 - training loss: 0.1137, validation loss: 0.1126
2024-05-25 07:30:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch91_loss0.11260130330920219.pypots
2024-05-25 07:30:19 [INFO]: Epoch 092 - training loss: 0.1116, validation loss: 0.1090
2024-05-25 07:30:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch92_loss0.1089827299118042.pypots
2024-05-25 07:30:36 [INFO]: Epoch 093 - training loss: 0.1101, validation loss: 0.1095
2024-05-25 07:30:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch93_loss0.10946901589632034.pypots
2024-05-25 07:30:53 [INFO]: Epoch 094 - training loss: 0.1125, validation loss: 0.1104
2024-05-25 07:30:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch94_loss0.1103713221848011.pypots
2024-05-25 07:31:10 [INFO]: Epoch 095 - training loss: 0.0966, validation loss: 0.1122
2024-05-25 07:31:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch95_loss0.11219799742102624.pypots
2024-05-25 07:31:26 [INFO]: Epoch 096 - training loss: 0.1086, validation loss: 0.1093
2024-05-25 07:31:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch96_loss0.10930857583880424.pypots
2024-05-25 07:31:43 [INFO]: Epoch 097 - training loss: 0.1174, validation loss: 0.1085
2024-05-25 07:31:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch97_loss0.10847639068961143.pypots
2024-05-25 07:32:00 [INFO]: Epoch 098 - training loss: 0.1191, validation loss: 0.1097
2024-05-25 07:32:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch98_loss0.10970566272735596.pypots
2024-05-25 07:32:17 [INFO]: Epoch 099 - training loss: 0.1226, validation loss: 0.1156
2024-05-25 07:32:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch99_loss0.11563569977879525.pypots
2024-05-25 07:32:33 [INFO]: Epoch 100 - training loss: 0.1287, validation loss: 0.1108
2024-05-25 07:32:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch100_loss0.1108395867049694.pypots
2024-05-25 07:32:50 [INFO]: Epoch 101 - training loss: 0.1167, validation loss: 0.1089
2024-05-25 07:32:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch101_loss0.10893163681030274.pypots
2024-05-25 07:33:07 [INFO]: Epoch 102 - training loss: 0.1135, validation loss: 0.1071
2024-05-25 07:33:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch102_loss0.10711694732308388.pypots
2024-05-25 07:33:23 [INFO]: Epoch 103 - training loss: 0.1140, validation loss: 0.1076
2024-05-25 07:33:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch103_loss0.10761184245347977.pypots
2024-05-25 07:33:40 [INFO]: Epoch 104 - training loss: 0.1167, validation loss: 0.1083
2024-05-25 07:33:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch104_loss0.10833913162350654.pypots
2024-05-25 07:33:57 [INFO]: Epoch 105 - training loss: 0.1135, validation loss: 0.1075
2024-05-25 07:33:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch105_loss0.10752584785223007.pypots
2024-05-25 07:34:14 [INFO]: Epoch 106 - training loss: 0.0932, validation loss: 0.1066
2024-05-25 07:34:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch106_loss0.10660843625664711.pypots
2024-05-25 07:34:30 [INFO]: Epoch 107 - training loss: 0.1003, validation loss: 0.1063
2024-05-25 07:34:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch107_loss0.1062982700765133.pypots
2024-05-25 07:34:47 [INFO]: Epoch 108 - training loss: 0.1172, validation loss: 0.1079
2024-05-25 07:34:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch108_loss0.10791964754462242.pypots
2024-05-25 07:35:04 [INFO]: Epoch 109 - training loss: 0.1111, validation loss: 0.1072
2024-05-25 07:35:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch109_loss0.10723190233111382.pypots
2024-05-25 07:35:21 [INFO]: Epoch 110 - training loss: 0.1050, validation loss: 0.1037
2024-05-25 07:35:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch110_loss0.10373507216572761.pypots
2024-05-25 07:35:37 [INFO]: Epoch 111 - training loss: 0.1067, validation loss: 0.1086
2024-05-25 07:35:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch111_loss0.10863978415727615.pypots
2024-05-25 07:35:54 [INFO]: Epoch 112 - training loss: 0.1105, validation loss: 0.1064
2024-05-25 07:35:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch112_loss0.10641440898180007.pypots
2024-05-25 07:36:11 [INFO]: Epoch 113 - training loss: 0.1064, validation loss: 0.1053
2024-05-25 07:36:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch113_loss0.10526255965232849.pypots
2024-05-25 07:36:28 [INFO]: Epoch 114 - training loss: 0.1033, validation loss: 0.1079
2024-05-25 07:36:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch114_loss0.10790078788995743.pypots
2024-05-25 07:36:44 [INFO]: Epoch 115 - training loss: 0.1101, validation loss: 0.1101
2024-05-25 07:36:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch115_loss0.11008852124214172.pypots
2024-05-25 07:37:01 [INFO]: Epoch 116 - training loss: 0.1128, validation loss: 0.1060
2024-05-25 07:37:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch116_loss0.1059886209666729.pypots
2024-05-25 07:37:18 [INFO]: Epoch 117 - training loss: 0.0923, validation loss: 0.1072
2024-05-25 07:37:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch117_loss0.10720569863915444.pypots
2024-05-25 07:37:34 [INFO]: Epoch 118 - training loss: 0.1153, validation loss: 0.1045
2024-05-25 07:37:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch118_loss0.10452608913183212.pypots
2024-05-25 07:37:51 [INFO]: Epoch 119 - training loss: 0.1010, validation loss: 0.1059
2024-05-25 07:37:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch119_loss0.10591472312808037.pypots
2024-05-25 07:38:08 [INFO]: Epoch 120 - training loss: 0.0996, validation loss: 0.1059
2024-05-25 07:38:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI_epoch120_loss0.10591933578252792.pypots
2024-05-25 07:38:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:38:08 [INFO]: Finished training. The best model is from epoch#110.
2024-05-25 07:38:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240525_T070440/CSDI.pypots
2024-05-25 07:40:29 [INFO]: CSDI on Air-Quality: MAE=0.1081, MSE=0.2428
2024-05-25 07:40:29 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/CSDI_air_quality/imputation.pkl
2024-05-25 07:40:29 [INFO]: Using the given device: cuda:0
2024-05-25 07:40:29 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/GPVAE_air_quality/20240525_T074029
2024-05-25 07:40:29 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/GPVAE_air_quality/20240525_T074029/tensorboard
2024-05-25 07:40:29 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 07:40:29 [INFO]: Epoch 001 - training loss: 65161.4517, validation loss: 0.6368
2024-05-25 07:40:29 [INFO]: Epoch 002 - training loss: 41960.0327, validation loss: 0.5748
2024-05-25 07:40:30 [INFO]: Epoch 003 - training loss: 41648.5765, validation loss: 0.5266
2024-05-25 07:40:30 [INFO]: Epoch 004 - training loss: 41538.2189, validation loss: 0.4804
2024-05-25 07:40:31 [INFO]: Epoch 005 - training loss: 41434.1942, validation loss: 0.4448
2024-05-25 07:40:31 [INFO]: Epoch 006 - training loss: 41385.2159, validation loss: 0.4255
2024-05-25 07:40:31 [INFO]: Epoch 007 - training loss: 41355.9563, validation loss: 0.3860
2024-05-25 07:40:32 [INFO]: Epoch 008 - training loss: 41296.1155, validation loss: 0.3650
2024-05-25 07:40:32 [INFO]: Epoch 009 - training loss: 41274.1862, validation loss: 0.3638
2024-05-25 07:40:32 [INFO]: Epoch 010 - training loss: 41265.0676, validation loss: 0.3415
2024-05-25 07:40:33 [INFO]: Epoch 011 - training loss: 41221.5707, validation loss: 0.3213
2024-05-25 07:40:33 [INFO]: Epoch 012 - training loss: 41282.6098, validation loss: 0.3934
2024-05-25 07:40:34 [INFO]: Epoch 013 - training loss: 41230.1821, validation loss: 0.3148
2024-05-25 07:40:34 [INFO]: Epoch 014 - training loss: 41189.6033, validation loss: 0.3090
2024-05-25 07:40:34 [INFO]: Epoch 015 - training loss: 41167.4916, validation loss: 0.3008
2024-05-25 07:40:35 [INFO]: Epoch 016 - training loss: 41149.3650, validation loss: 0.2940
2024-05-25 07:40:35 [INFO]: Epoch 017 - training loss: 41137.7830, validation loss: 0.2862
2024-05-25 07:40:35 [INFO]: Epoch 018 - training loss: 41129.3970, validation loss: 0.2866
2024-05-25 07:40:36 [INFO]: Epoch 019 - training loss: 41150.8138, validation loss: 0.2950
2024-05-25 07:40:36 [INFO]: Epoch 020 - training loss: 41120.0230, validation loss: 0.2909
2024-05-25 07:40:37 [INFO]: Epoch 021 - training loss: 41114.9203, validation loss: 0.2815
2024-05-25 07:40:37 [INFO]: Epoch 022 - training loss: 41103.4980, validation loss: 0.2720
2024-05-25 07:40:37 [INFO]: Epoch 023 - training loss: 41098.4148, validation loss: 0.2708
2024-05-25 07:40:38 [INFO]: Epoch 024 - training loss: 41097.8356, validation loss: 0.2668
2024-05-25 07:40:38 [INFO]: Epoch 025 - training loss: 41099.2807, validation loss: 0.2750
2024-05-25 07:40:38 [INFO]: Epoch 026 - training loss: 41132.7054, validation loss: 0.2872
2024-05-25 07:40:39 [INFO]: Epoch 027 - training loss: 41132.1153, validation loss: 0.2643
2024-05-25 07:40:39 [INFO]: Epoch 028 - training loss: 41109.3471, validation loss: 0.3174
2024-05-25 07:40:40 [INFO]: Epoch 029 - training loss: 41145.3934, validation loss: 0.3120
2024-05-25 07:40:40 [INFO]: Epoch 030 - training loss: 41179.3795, validation loss: 0.2785
2024-05-25 07:40:40 [INFO]: Epoch 031 - training loss: 41119.7998, validation loss: 0.2661
2024-05-25 07:40:41 [INFO]: Epoch 032 - training loss: 41087.1059, validation loss: 0.2579
2024-05-25 07:40:41 [INFO]: Epoch 033 - training loss: 41067.6849, validation loss: 0.2553
2024-05-25 07:40:42 [INFO]: Epoch 034 - training loss: 41059.5914, validation loss: 0.2603
2024-05-25 07:40:42 [INFO]: Epoch 035 - training loss: 41056.7451, validation loss: 0.2517
2024-05-25 07:40:42 [INFO]: Epoch 036 - training loss: 41055.3733, validation loss: 0.2581
2024-05-25 07:40:43 [INFO]: Epoch 037 - training loss: 41066.5505, validation loss: 0.2521
2024-05-25 07:40:43 [INFO]: Epoch 038 - training loss: 41054.8505, validation loss: 0.2410
2024-05-25 07:40:43 [INFO]: Epoch 039 - training loss: 41050.9333, validation loss: 0.2557
2024-05-25 07:40:44 [INFO]: Epoch 040 - training loss: 41048.4453, validation loss: 0.2442
2024-05-25 07:40:44 [INFO]: Epoch 041 - training loss: 41034.0799, validation loss: 0.2350
2024-05-25 07:40:45 [INFO]: Epoch 042 - training loss: 41032.8273, validation loss: 0.2362
2024-05-25 07:40:45 [INFO]: Epoch 043 - training loss: 41031.3950, validation loss: 0.2433
2024-05-25 07:40:45 [INFO]: Epoch 044 - training loss: 41029.9715, validation loss: 0.2341
2024-05-25 07:40:46 [INFO]: Epoch 045 - training loss: 41031.5861, validation loss: 0.2400
2024-05-25 07:40:46 [INFO]: Epoch 046 - training loss: 41040.4774, validation loss: 0.2433
2024-05-25 07:40:46 [INFO]: Epoch 047 - training loss: 41032.0995, validation loss: 0.2377
2024-05-25 07:40:47 [INFO]: Epoch 048 - training loss: 41024.1114, validation loss: 0.2453
2024-05-25 07:40:47 [INFO]: Epoch 049 - training loss: 41023.7821, validation loss: 0.2336
2024-05-25 07:40:48 [INFO]: Epoch 050 - training loss: 41017.7924, validation loss: 0.2305
2024-05-25 07:40:48 [INFO]: Epoch 051 - training loss: 41016.0781, validation loss: 0.2292
2024-05-25 07:40:48 [INFO]: Epoch 052 - training loss: 41020.3540, validation loss: 0.2387
2024-05-25 07:40:49 [INFO]: Epoch 053 - training loss: 41074.3950, validation loss: 0.2792
2024-05-25 07:40:49 [INFO]: Epoch 054 - training loss: 41086.7610, validation loss: 0.2524
2024-05-25 07:40:49 [INFO]: Epoch 055 - training loss: 41044.9560, validation loss: 0.2389
2024-05-25 07:40:50 [INFO]: Epoch 056 - training loss: 41028.7371, validation loss: 0.2267
2024-05-25 07:40:50 [INFO]: Epoch 057 - training loss: 41028.1908, validation loss: 0.2323
2024-05-25 07:40:51 [INFO]: Epoch 058 - training loss: 41025.0259, validation loss: 0.2471
2024-05-25 07:40:51 [INFO]: Epoch 059 - training loss: 41025.2104, validation loss: 0.2397
2024-05-25 07:40:51 [INFO]: Epoch 060 - training loss: 41015.3265, validation loss: 0.2230
2024-05-25 07:40:52 [INFO]: Epoch 061 - training loss: 41017.8005, validation loss: 0.2400
2024-05-25 07:40:52 [INFO]: Epoch 062 - training loss: 41036.4084, validation loss: 0.2335
2024-05-25 07:40:52 [INFO]: Epoch 063 - training loss: 41069.6291, validation loss: 0.2505
2024-05-25 07:40:53 [INFO]: Epoch 064 - training loss: 41088.2203, validation loss: 0.2637
2024-05-25 07:40:53 [INFO]: Epoch 065 - training loss: 41063.3367, validation loss: 0.2367
2024-05-25 07:40:54 [INFO]: Epoch 066 - training loss: 41038.2040, validation loss: 0.2257
2024-05-25 07:40:54 [INFO]: Epoch 067 - training loss: 41030.5628, validation loss: 0.2431
2024-05-25 07:40:54 [INFO]: Epoch 068 - training loss: 41028.2108, validation loss: 0.2334
2024-05-25 07:40:55 [INFO]: Epoch 069 - training loss: 41013.6361, validation loss: 0.2199
2024-05-25 07:40:55 [INFO]: Epoch 070 - training loss: 40999.0233, validation loss: 0.2178
2024-05-25 07:40:55 [INFO]: Epoch 071 - training loss: 40995.0207, validation loss: 0.2123
2024-05-25 07:40:56 [INFO]: Epoch 072 - training loss: 40990.0113, validation loss: 0.2154
2024-05-25 07:40:56 [INFO]: Epoch 073 - training loss: 40989.1379, validation loss: 0.2171
2024-05-25 07:40:57 [INFO]: Epoch 074 - training loss: 40991.8976, validation loss: 0.2140
2024-05-25 07:40:57 [INFO]: Epoch 075 - training loss: 40998.9932, validation loss: 0.2374
2024-05-25 07:40:57 [INFO]: Epoch 076 - training loss: 41020.2070, validation loss: 0.2245
2024-05-25 07:40:58 [INFO]: Epoch 077 - training loss: 41073.5467, validation loss: 0.2488
2024-05-25 07:40:58 [INFO]: Epoch 078 - training loss: 41064.1282, validation loss: 0.2338
2024-05-25 07:40:59 [INFO]: Epoch 079 - training loss: 41045.1065, validation loss: 0.2279
2024-05-25 07:40:59 [INFO]: Epoch 080 - training loss: 41012.9847, validation loss: 0.2179
2024-05-25 07:40:59 [INFO]: Epoch 081 - training loss: 40999.9499, validation loss: 0.2145
2024-05-25 07:40:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:40:59 [INFO]: Finished training. The best model is from epoch#71.
2024-05-25 07:40:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/GPVAE_air_quality/20240525_T074029/GPVAE.pypots
2024-05-25 07:40:59 [INFO]: GP-VAE on Air-Quality: MAE=0.2661, MSE=0.3401
2024-05-25 07:40:59 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/GPVAE_air_quality/imputation.pkl
2024-05-25 07:40:59 [INFO]: Using the given device: cuda:0
2024-05-25 07:40:59 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/USGAN_air_quality/20240525_T074059
2024-05-25 07:40:59 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/USGAN_air_quality/20240525_T074059/tensorboard
2024-05-25 07:40:59 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 07:41:04 [INFO]: Epoch 001 - generator training loss: 0.5209, discriminator training loss: 0.3788, validation loss: 0.5249
2024-05-25 07:41:09 [INFO]: Epoch 002 - generator training loss: 0.1568, discriminator training loss: 0.2420, validation loss: 0.4003
2024-05-25 07:41:13 [INFO]: Epoch 003 - generator training loss: 0.1034, discriminator training loss: 0.2382, validation loss: 0.3338
2024-05-25 07:41:18 [INFO]: Epoch 004 - generator training loss: 0.0610, discriminator training loss: 0.2375, validation loss: 0.2903
2024-05-25 07:41:22 [INFO]: Epoch 005 - generator training loss: 0.0399, discriminator training loss: 0.2362, validation loss: 0.2643
2024-05-25 07:41:26 [INFO]: Epoch 006 - generator training loss: 0.0212, discriminator training loss: 0.2356, validation loss: 0.2445
2024-05-25 07:41:31 [INFO]: Epoch 007 - generator training loss: 0.0106, discriminator training loss: 0.2346, validation loss: 0.2312
2024-05-25 07:41:35 [INFO]: Epoch 008 - generator training loss: -0.0017, discriminator training loss: 0.2336, validation loss: 0.2175
2024-05-25 07:41:39 [INFO]: Epoch 009 - generator training loss: -0.0103, discriminator training loss: 0.2324, validation loss: 0.2083
2024-05-25 07:41:44 [INFO]: Epoch 010 - generator training loss: -0.0178, discriminator training loss: 0.2311, validation loss: 0.2009
2024-05-25 07:41:48 [INFO]: Epoch 011 - generator training loss: -0.0196, discriminator training loss: 0.2293, validation loss: 0.1939
2024-05-25 07:41:52 [INFO]: Epoch 012 - generator training loss: -0.0273, discriminator training loss: 0.2277, validation loss: 0.1881
2024-05-25 07:41:57 [INFO]: Epoch 013 - generator training loss: -0.0316, discriminator training loss: 0.2262, validation loss: 0.1837
2024-05-25 07:42:01 [INFO]: Epoch 014 - generator training loss: -0.0341, discriminator training loss: 0.2245, validation loss: 0.1780
2024-05-25 07:42:05 [INFO]: Epoch 015 - generator training loss: -0.0361, discriminator training loss: 0.2232, validation loss: 0.1749
2024-05-25 07:42:10 [INFO]: Epoch 016 - generator training loss: -0.0392, discriminator training loss: 0.2218, validation loss: 0.1714
2024-05-25 07:42:14 [INFO]: Epoch 017 - generator training loss: -0.0415, discriminator training loss: 0.2202, validation loss: 0.1680
2024-05-25 07:42:19 [INFO]: Epoch 018 - generator training loss: -0.0430, discriminator training loss: 0.2188, validation loss: 0.1653
2024-05-25 07:42:23 [INFO]: Epoch 019 - generator training loss: -0.0441, discriminator training loss: 0.2172, validation loss: 0.1622
2024-05-25 07:42:27 [INFO]: Epoch 020 - generator training loss: -0.0424, discriminator training loss: 0.2155, validation loss: 0.1605
2024-05-25 07:42:31 [INFO]: Epoch 021 - generator training loss: -0.0460, discriminator training loss: 0.2138, validation loss: 0.1563
2024-05-25 07:42:36 [INFO]: Epoch 022 - generator training loss: -0.0480, discriminator training loss: 0.2123, validation loss: 0.1548
2024-05-25 07:42:40 [INFO]: Epoch 023 - generator training loss: -0.0493, discriminator training loss: 0.2104, validation loss: 0.1519
2024-05-25 07:42:44 [INFO]: Epoch 024 - generator training loss: -0.0496, discriminator training loss: 0.2086, validation loss: 0.1498
2024-05-25 07:42:49 [INFO]: Epoch 025 - generator training loss: -0.0495, discriminator training loss: 0.2067, validation loss: 0.1488
2024-05-25 07:42:53 [INFO]: Epoch 026 - generator training loss: -0.0498, discriminator training loss: 0.2049, validation loss: 0.1472
2024-05-25 07:42:58 [INFO]: Epoch 027 - generator training loss: -0.0486, discriminator training loss: 0.2029, validation loss: 0.1461
2024-05-25 07:43:02 [INFO]: Epoch 028 - generator training loss: -0.0507, discriminator training loss: 0.2012, validation loss: 0.1434
2024-05-25 07:43:06 [INFO]: Epoch 029 - generator training loss: -0.0492, discriminator training loss: 0.1994, validation loss: 0.1420
2024-05-25 07:43:10 [INFO]: Epoch 030 - generator training loss: -0.0503, discriminator training loss: 0.1974, validation loss: 0.1405
2024-05-25 07:43:15 [INFO]: Epoch 031 - generator training loss: -0.0489, discriminator training loss: 0.1957, validation loss: 0.1393
2024-05-25 07:43:19 [INFO]: Epoch 032 - generator training loss: -0.0504, discriminator training loss: 0.1939, validation loss: 0.1379
2024-05-25 07:43:23 [INFO]: Epoch 033 - generator training loss: -0.0503, discriminator training loss: 0.1921, validation loss: 0.1366
2024-05-25 07:43:28 [INFO]: Epoch 034 - generator training loss: -0.0499, discriminator training loss: 0.1905, validation loss: 0.1357
2024-05-25 07:43:32 [INFO]: Epoch 035 - generator training loss: -0.0497, discriminator training loss: 0.1888, validation loss: 0.1344
2024-05-25 07:43:36 [INFO]: Epoch 036 - generator training loss: -0.0492, discriminator training loss: 0.1871, validation loss: 0.1328
2024-05-25 07:43:41 [INFO]: Epoch 037 - generator training loss: -0.0487, discriminator training loss: 0.1856, validation loss: 0.1316
2024-05-25 07:43:45 [INFO]: Epoch 038 - generator training loss: -0.0486, discriminator training loss: 0.1839, validation loss: 0.1313
2024-05-25 07:43:50 [INFO]: Epoch 039 - generator training loss: -0.0483, discriminator training loss: 0.1824, validation loss: 0.1296
2024-05-25 07:43:54 [INFO]: Epoch 040 - generator training loss: -0.0478, discriminator training loss: 0.1811, validation loss: 0.1287
2024-05-25 07:43:58 [INFO]: Epoch 041 - generator training loss: -0.0474, discriminator training loss: 0.1794, validation loss: 0.1275
2024-05-25 07:44:03 [INFO]: Epoch 042 - generator training loss: -0.0474, discriminator training loss: 0.1779, validation loss: 0.1267
2024-05-25 07:44:07 [INFO]: Epoch 043 - generator training loss: -0.0465, discriminator training loss: 0.1766, validation loss: 0.1259
2024-05-25 07:44:11 [INFO]: Epoch 044 - generator training loss: -0.0464, discriminator training loss: 0.1752, validation loss: 0.1244
2024-05-25 07:44:16 [INFO]: Epoch 045 - generator training loss: -0.0463, discriminator training loss: 0.1740, validation loss: 0.1237
2024-05-25 07:44:20 [INFO]: Epoch 046 - generator training loss: -0.0470, discriminator training loss: 0.1725, validation loss: 0.1230
2024-05-25 07:44:24 [INFO]: Epoch 047 - generator training loss: -0.0460, discriminator training loss: 0.1714, validation loss: 0.1220
2024-05-25 07:44:29 [INFO]: Epoch 048 - generator training loss: -0.0464, discriminator training loss: 0.1698, validation loss: 0.1210
2024-05-25 07:44:33 [INFO]: Epoch 049 - generator training loss: -0.0458, discriminator training loss: 0.1690, validation loss: 0.1205
2024-05-25 07:44:37 [INFO]: Epoch 050 - generator training loss: -0.0460, discriminator training loss: 0.1675, validation loss: 0.1201
2024-05-25 07:44:42 [INFO]: Epoch 051 - generator training loss: -0.0448, discriminator training loss: 0.1665, validation loss: 0.1196
2024-05-25 07:44:46 [INFO]: Epoch 052 - generator training loss: -0.0447, discriminator training loss: 0.1654, validation loss: 0.1189
2024-05-25 07:44:50 [INFO]: Epoch 053 - generator training loss: -0.0439, discriminator training loss: 0.1642, validation loss: 0.1185
2024-05-25 07:44:55 [INFO]: Epoch 054 - generator training loss: -0.0424, discriminator training loss: 0.1632, validation loss: 0.1178
2024-05-25 07:44:59 [INFO]: Epoch 055 - generator training loss: -0.0438, discriminator training loss: 0.1625, validation loss: 0.1176
2024-05-25 07:45:03 [INFO]: Epoch 056 - generator training loss: -0.0444, discriminator training loss: 0.1611, validation loss: 0.1164
2024-05-25 07:45:08 [INFO]: Epoch 057 - generator training loss: -0.0437, discriminator training loss: 0.1604, validation loss: 0.1158
2024-05-25 07:45:12 [INFO]: Epoch 058 - generator training loss: -0.0412, discriminator training loss: 0.1592, validation loss: 0.1157
2024-05-25 07:45:16 [INFO]: Epoch 059 - generator training loss: -0.0431, discriminator training loss: 0.1587, validation loss: 0.1146
2024-05-25 07:45:21 [INFO]: Epoch 060 - generator training loss: -0.0421, discriminator training loss: 0.1579, validation loss: 0.1142
2024-05-25 07:45:25 [INFO]: Epoch 061 - generator training loss: -0.0413, discriminator training loss: 0.1568, validation loss: 0.1145
2024-05-25 07:45:29 [INFO]: Epoch 062 - generator training loss: -0.0430, discriminator training loss: 0.1561, validation loss: 0.1138
2024-05-25 07:45:34 [INFO]: Epoch 063 - generator training loss: -0.0424, discriminator training loss: 0.1555, validation loss: 0.1137
2024-05-25 07:45:38 [INFO]: Epoch 064 - generator training loss: -0.0419, discriminator training loss: 0.1547, validation loss: 0.1130
2024-05-25 07:45:42 [INFO]: Epoch 065 - generator training loss: -0.0407, discriminator training loss: 0.1538, validation loss: 0.1129
2024-05-25 07:45:47 [INFO]: Epoch 066 - generator training loss: -0.0425, discriminator training loss: 0.1533, validation loss: 0.1132
2024-05-25 07:45:51 [INFO]: Epoch 067 - generator training loss: -0.0417, discriminator training loss: 0.1529, validation loss: 0.1130
2024-05-25 07:45:55 [INFO]: Epoch 068 - generator training loss: -0.0423, discriminator training loss: 0.1521, validation loss: 0.1118
2024-05-25 07:46:00 [INFO]: Epoch 069 - generator training loss: -0.0416, discriminator training loss: 0.1511, validation loss: 0.1117
2024-05-25 07:46:04 [INFO]: Epoch 070 - generator training loss: -0.0418, discriminator training loss: 0.1507, validation loss: 0.1112
2024-05-25 07:46:08 [INFO]: Epoch 071 - generator training loss: -0.0420, discriminator training loss: 0.1500, validation loss: 0.1107
2024-05-25 07:46:13 [INFO]: Epoch 072 - generator training loss: -0.0407, discriminator training loss: 0.1496, validation loss: 0.1110
2024-05-25 07:46:17 [INFO]: Epoch 073 - generator training loss: -0.0418, discriminator training loss: 0.1493, validation loss: 0.1105
2024-05-25 07:46:21 [INFO]: Epoch 074 - generator training loss: -0.0412, discriminator training loss: 0.1485, validation loss: 0.1103
2024-05-25 07:46:26 [INFO]: Epoch 075 - generator training loss: -0.0406, discriminator training loss: 0.1479, validation loss: 0.1102
2024-05-25 07:46:30 [INFO]: Epoch 076 - generator training loss: -0.0413, discriminator training loss: 0.1475, validation loss: 0.1101
2024-05-25 07:46:34 [INFO]: Epoch 077 - generator training loss: -0.0408, discriminator training loss: 0.1467, validation loss: 0.1091
2024-05-25 07:46:39 [INFO]: Epoch 078 - generator training loss: -0.0408, discriminator training loss: 0.1467, validation loss: 0.1099
2024-05-25 07:46:43 [INFO]: Epoch 079 - generator training loss: -0.0415, discriminator training loss: 0.1460, validation loss: 0.1087
2024-05-25 07:46:47 [INFO]: Epoch 080 - generator training loss: -0.0410, discriminator training loss: 0.1459, validation loss: 0.1085
2024-05-25 07:46:51 [INFO]: Epoch 081 - generator training loss: -0.0414, discriminator training loss: 0.1454, validation loss: 0.1089
2024-05-25 07:46:56 [INFO]: Epoch 082 - generator training loss: -0.0411, discriminator training loss: 0.1451, validation loss: 0.1083
2024-05-25 07:47:00 [INFO]: Epoch 083 - generator training loss: -0.0411, discriminator training loss: 0.1446, validation loss: 0.1074
2024-05-25 07:47:05 [INFO]: Epoch 084 - generator training loss: -0.0419, discriminator training loss: 0.1437, validation loss: 0.1076
2024-05-25 07:47:09 [INFO]: Epoch 085 - generator training loss: -0.0424, discriminator training loss: 0.1439, validation loss: 0.1078
2024-05-25 07:47:13 [INFO]: Epoch 086 - generator training loss: -0.0418, discriminator training loss: 0.1434, validation loss: 0.1076
2024-05-25 07:47:18 [INFO]: Epoch 087 - generator training loss: -0.0415, discriminator training loss: 0.1429, validation loss: 0.1076
2024-05-25 07:47:22 [INFO]: Epoch 088 - generator training loss: -0.0415, discriminator training loss: 0.1425, validation loss: 0.1073
2024-05-25 07:47:26 [INFO]: Epoch 089 - generator training loss: -0.0413, discriminator training loss: 0.1425, validation loss: 0.1071
2024-05-25 07:47:30 [INFO]: Epoch 090 - generator training loss: -0.0420, discriminator training loss: 0.1422, validation loss: 0.1065
2024-05-25 07:47:35 [INFO]: Epoch 091 - generator training loss: -0.0421, discriminator training loss: 0.1421, validation loss: 0.1067
2024-05-25 07:47:39 [INFO]: Epoch 092 - generator training loss: -0.0421, discriminator training loss: 0.1417, validation loss: 0.1074
2024-05-25 07:47:43 [INFO]: Epoch 093 - generator training loss: -0.0420, discriminator training loss: 0.1412, validation loss: 0.1066
2024-05-25 07:47:47 [INFO]: Epoch 094 - generator training loss: -0.0416, discriminator training loss: 0.1409, validation loss: 0.1064
2024-05-25 07:47:52 [INFO]: Epoch 095 - generator training loss: -0.0420, discriminator training loss: 0.1409, validation loss: 0.1076
2024-05-25 07:47:56 [INFO]: Epoch 096 - generator training loss: -0.0416, discriminator training loss: 0.1406, validation loss: 0.1070
2024-05-25 07:48:00 [INFO]: Epoch 097 - generator training loss: -0.0419, discriminator training loss: 0.1403, validation loss: 0.1061
2024-05-25 07:48:05 [INFO]: Epoch 098 - generator training loss: -0.0425, discriminator training loss: 0.1401, validation loss: 0.1072
2024-05-25 07:48:09 [INFO]: Epoch 099 - generator training loss: -0.0425, discriminator training loss: 0.1400, validation loss: 0.1059
2024-05-25 07:48:13 [INFO]: Epoch 100 - generator training loss: -0.0422, discriminator training loss: 0.1394, validation loss: 0.1063
2024-05-25 07:48:18 [INFO]: Epoch 101 - generator training loss: -0.0421, discriminator training loss: 0.1395, validation loss: 0.1065
2024-05-25 07:48:22 [INFO]: Epoch 102 - generator training loss: -0.0425, discriminator training loss: 0.1388, validation loss: 0.1063
2024-05-25 07:48:26 [INFO]: Epoch 103 - generator training loss: -0.0420, discriminator training loss: 0.1386, validation loss: 0.1053
2024-05-25 07:48:31 [INFO]: Epoch 104 - generator training loss: -0.0425, discriminator training loss: 0.1385, validation loss: 0.1060
2024-05-25 07:48:35 [INFO]: Epoch 105 - generator training loss: -0.0421, discriminator training loss: 0.1387, validation loss: 0.1055
2024-05-25 07:48:39 [INFO]: Epoch 106 - generator training loss: -0.0428, discriminator training loss: 0.1380, validation loss: 0.1065
2024-05-25 07:48:44 [INFO]: Epoch 107 - generator training loss: -0.0422, discriminator training loss: 0.1379, validation loss: 0.1058
2024-05-25 07:48:48 [INFO]: Epoch 108 - generator training loss: -0.0432, discriminator training loss: 0.1379, validation loss: 0.1064
2024-05-25 07:48:52 [INFO]: Epoch 109 - generator training loss: -0.0425, discriminator training loss: 0.1374, validation loss: 0.1056
2024-05-25 07:48:57 [INFO]: Epoch 110 - generator training loss: -0.0434, discriminator training loss: 0.1377, validation loss: 0.1052
2024-05-25 07:49:01 [INFO]: Epoch 111 - generator training loss: -0.0441, discriminator training loss: 0.1375, validation loss: 0.1051
2024-05-25 07:49:05 [INFO]: Epoch 112 - generator training loss: -0.0440, discriminator training loss: 0.1370, validation loss: 0.1047
2024-05-25 07:49:10 [INFO]: Epoch 113 - generator training loss: -0.0438, discriminator training loss: 0.1372, validation loss: 0.1055
2024-05-25 07:49:14 [INFO]: Epoch 114 - generator training loss: -0.0437, discriminator training loss: 0.1370, validation loss: 0.1055
2024-05-25 07:49:18 [INFO]: Epoch 115 - generator training loss: -0.0435, discriminator training loss: 0.1366, validation loss: 0.1057
2024-05-25 07:49:23 [INFO]: Epoch 116 - generator training loss: -0.0438, discriminator training loss: 0.1363, validation loss: 0.1050
2024-05-25 07:49:27 [INFO]: Epoch 117 - generator training loss: -0.0441, discriminator training loss: 0.1363, validation loss: 0.1057
2024-05-25 07:49:31 [INFO]: Epoch 118 - generator training loss: -0.0442, discriminator training loss: 0.1362, validation loss: 0.1055
2024-05-25 07:49:36 [INFO]: Epoch 119 - generator training loss: -0.0443, discriminator training loss: 0.1357, validation loss: 0.1055
2024-05-25 07:49:40 [INFO]: Epoch 120 - generator training loss: -0.0448, discriminator training loss: 0.1360, validation loss: 0.1054
2024-05-25 07:49:44 [INFO]: Epoch 121 - generator training loss: -0.0450, discriminator training loss: 0.1357, validation loss: 0.1060
2024-05-25 07:49:49 [INFO]: Epoch 122 - generator training loss: -0.0444, discriminator training loss: 0.1356, validation loss: 0.1059
2024-05-25 07:49:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:49:49 [INFO]: Finished training. The best model is from epoch#112.
2024-05-25 07:49:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/USGAN_air_quality/20240525_T074059/USGAN.pypots
2024-05-25 07:49:49 [INFO]: US-GAN on Air-Quality: MAE=0.1493, MSE=0.1811
2024-05-25 07:49:49 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/USGAN_air_quality/imputation.pkl
2024-05-25 07:49:49 [INFO]: Using the given device: cuda:0
2024-05-25 07:49:49 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/BRITS_air_quality/20240525_T074949
2024-05-25 07:49:49 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/BRITS_air_quality/20240525_T074949/tensorboard
2024-05-25 07:49:49 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 07:49:53 [INFO]: Epoch 001 - training loss: 1.4106, validation loss: 0.9416
2024-05-25 07:49:56 [INFO]: Epoch 002 - training loss: 1.1406, validation loss: 0.7016
2024-05-25 07:49:59 [INFO]: Epoch 003 - training loss: 0.9482, validation loss: 0.5897
2024-05-25 07:50:02 [INFO]: Epoch 004 - training loss: 0.8367, validation loss: 0.5225
2024-05-25 07:50:05 [INFO]: Epoch 005 - training loss: 0.7636, validation loss: 0.4766
2024-05-25 07:50:08 [INFO]: Epoch 006 - training loss: 0.7080, validation loss: 0.4402
2024-05-25 07:50:11 [INFO]: Epoch 007 - training loss: 0.6658, validation loss: 0.4105
2024-05-25 07:50:14 [INFO]: Epoch 008 - training loss: 0.6310, validation loss: 0.3870
2024-05-25 07:50:16 [INFO]: Epoch 009 - training loss: 0.6047, validation loss: 0.3670
2024-05-25 07:50:19 [INFO]: Epoch 010 - training loss: 0.5825, validation loss: 0.3512
2024-05-25 07:50:22 [INFO]: Epoch 011 - training loss: 0.5670, validation loss: 0.3375
2024-05-25 07:50:25 [INFO]: Epoch 012 - training loss: 0.5495, validation loss: 0.3253
2024-05-25 07:50:28 [INFO]: Epoch 013 - training loss: 0.5371, validation loss: 0.3157
2024-05-25 07:50:31 [INFO]: Epoch 014 - training loss: 0.5261, validation loss: 0.3073
2024-05-25 07:50:34 [INFO]: Epoch 015 - training loss: 0.5139, validation loss: 0.2990
2024-05-25 07:50:37 [INFO]: Epoch 016 - training loss: 0.5051, validation loss: 0.2916
2024-05-25 07:50:40 [INFO]: Epoch 017 - training loss: 0.4951, validation loss: 0.2856
2024-05-25 07:50:43 [INFO]: Epoch 018 - training loss: 0.4890, validation loss: 0.2800
2024-05-25 07:50:46 [INFO]: Epoch 019 - training loss: 0.4796, validation loss: 0.2746
2024-05-25 07:50:48 [INFO]: Epoch 020 - training loss: 0.4714, validation loss: 0.2697
2024-05-25 07:50:51 [INFO]: Epoch 021 - training loss: 0.4651, validation loss: 0.2651
2024-05-25 07:50:54 [INFO]: Epoch 022 - training loss: 0.4585, validation loss: 0.2603
2024-05-25 07:50:57 [INFO]: Epoch 023 - training loss: 0.4519, validation loss: 0.2564
2024-05-25 07:51:00 [INFO]: Epoch 024 - training loss: 0.4458, validation loss: 0.2526
2024-05-25 07:51:03 [INFO]: Epoch 025 - training loss: 0.4398, validation loss: 0.2489
2024-05-25 07:51:06 [INFO]: Epoch 026 - training loss: 0.4338, validation loss: 0.2449
2024-05-25 07:51:09 [INFO]: Epoch 027 - training loss: 0.4288, validation loss: 0.2414
2024-05-25 07:51:12 [INFO]: Epoch 028 - training loss: 0.4243, validation loss: 0.2382
2024-05-25 07:51:15 [INFO]: Epoch 029 - training loss: 0.4190, validation loss: 0.2344
2024-05-25 07:51:18 [INFO]: Epoch 030 - training loss: 0.4151, validation loss: 0.2309
2024-05-25 07:51:20 [INFO]: Epoch 031 - training loss: 0.4105, validation loss: 0.2281
2024-05-25 07:51:23 [INFO]: Epoch 032 - training loss: 0.4061, validation loss: 0.2242
2024-05-25 07:51:26 [INFO]: Epoch 033 - training loss: 0.4024, validation loss: 0.2215
2024-05-25 07:51:29 [INFO]: Epoch 034 - training loss: 0.3976, validation loss: 0.2183
2024-05-25 07:51:32 [INFO]: Epoch 035 - training loss: 0.3936, validation loss: 0.2148
2024-05-25 07:51:35 [INFO]: Epoch 036 - training loss: 0.3898, validation loss: 0.2116
2024-05-25 07:51:38 [INFO]: Epoch 037 - training loss: 0.3866, validation loss: 0.2085
2024-05-25 07:51:41 [INFO]: Epoch 038 - training loss: 0.3835, validation loss: 0.2060
2024-05-25 07:51:44 [INFO]: Epoch 039 - training loss: 0.3797, validation loss: 0.2020
2024-05-25 07:51:47 [INFO]: Epoch 040 - training loss: 0.3769, validation loss: 0.1988
2024-05-25 07:51:50 [INFO]: Epoch 041 - training loss: 0.3738, validation loss: 0.1967
2024-05-25 07:51:53 [INFO]: Epoch 042 - training loss: 0.3699, validation loss: 0.1936
2024-05-25 07:51:56 [INFO]: Epoch 043 - training loss: 0.3667, validation loss: 0.1905
2024-05-25 07:51:59 [INFO]: Epoch 044 - training loss: 0.3641, validation loss: 0.1877
2024-05-25 07:52:01 [INFO]: Epoch 045 - training loss: 0.3616, validation loss: 0.1854
2024-05-25 07:52:04 [INFO]: Epoch 046 - training loss: 0.3589, validation loss: 0.1830
2024-05-25 07:52:07 [INFO]: Epoch 047 - training loss: 0.3559, validation loss: 0.1803
2024-05-25 07:52:10 [INFO]: Epoch 048 - training loss: 0.3536, validation loss: 0.1788
2024-05-25 07:52:13 [INFO]: Epoch 049 - training loss: 0.3516, validation loss: 0.1763
2024-05-25 07:52:16 [INFO]: Epoch 050 - training loss: 0.3489, validation loss: 0.1748
2024-05-25 07:52:19 [INFO]: Epoch 051 - training loss: 0.3466, validation loss: 0.1727
2024-05-25 07:52:22 [INFO]: Epoch 052 - training loss: 0.3438, validation loss: 0.1711
2024-05-25 07:52:25 [INFO]: Epoch 053 - training loss: 0.3417, validation loss: 0.1694
2024-05-25 07:52:28 [INFO]: Epoch 054 - training loss: 0.3395, validation loss: 0.1680
2024-05-25 07:52:31 [INFO]: Epoch 055 - training loss: 0.3379, validation loss: 0.1667
2024-05-25 07:52:34 [INFO]: Epoch 056 - training loss: 0.3361, validation loss: 0.1654
2024-05-25 07:52:37 [INFO]: Epoch 057 - training loss: 0.3342, validation loss: 0.1640
2024-05-25 07:52:39 [INFO]: Epoch 058 - training loss: 0.3322, validation loss: 0.1628
2024-05-25 07:52:42 [INFO]: Epoch 059 - training loss: 0.3302, validation loss: 0.1621
2024-05-25 07:52:45 [INFO]: Epoch 060 - training loss: 0.3291, validation loss: 0.1607
2024-05-25 07:52:48 [INFO]: Epoch 061 - training loss: 0.3267, validation loss: 0.1597
2024-05-25 07:52:51 [INFO]: Epoch 062 - training loss: 0.3256, validation loss: 0.1589
2024-05-25 07:52:54 [INFO]: Epoch 063 - training loss: 0.3250, validation loss: 0.1579
2024-05-25 07:52:57 [INFO]: Epoch 064 - training loss: 0.3228, validation loss: 0.1569
2024-05-25 07:53:00 [INFO]: Epoch 065 - training loss: 0.3209, validation loss: 0.1562
2024-05-25 07:53:03 [INFO]: Epoch 066 - training loss: 0.3198, validation loss: 0.1554
2024-05-25 07:53:06 [INFO]: Epoch 067 - training loss: 0.3183, validation loss: 0.1545
2024-05-25 07:53:09 [INFO]: Epoch 068 - training loss: 0.3172, validation loss: 0.1536
2024-05-25 07:53:11 [INFO]: Epoch 069 - training loss: 0.3158, validation loss: 0.1529
2024-05-25 07:53:14 [INFO]: Epoch 070 - training loss: 0.3155, validation loss: 0.1523
2024-05-25 07:53:17 [INFO]: Epoch 071 - training loss: 0.3129, validation loss: 0.1517
2024-05-25 07:53:20 [INFO]: Epoch 072 - training loss: 0.3121, validation loss: 0.1508
2024-05-25 07:53:23 [INFO]: Epoch 073 - training loss: 0.3113, validation loss: 0.1501
2024-05-25 07:53:26 [INFO]: Epoch 074 - training loss: 0.3102, validation loss: 0.1495
2024-05-25 07:53:29 [INFO]: Epoch 075 - training loss: 0.3088, validation loss: 0.1490
2024-05-25 07:53:32 [INFO]: Epoch 076 - training loss: 0.3079, validation loss: 0.1484
2024-05-25 07:53:35 [INFO]: Epoch 077 - training loss: 0.3066, validation loss: 0.1479
2024-05-25 07:53:38 [INFO]: Epoch 078 - training loss: 0.3053, validation loss: 0.1474
2024-05-25 07:53:41 [INFO]: Epoch 079 - training loss: 0.3047, validation loss: 0.1469
2024-05-25 07:53:44 [INFO]: Epoch 080 - training loss: 0.3032, validation loss: 0.1463
2024-05-25 07:53:47 [INFO]: Epoch 081 - training loss: 0.3030, validation loss: 0.1461
2024-05-25 07:53:49 [INFO]: Epoch 082 - training loss: 0.3027, validation loss: 0.1455
2024-05-25 07:53:52 [INFO]: Epoch 083 - training loss: 0.3012, validation loss: 0.1448
2024-05-25 07:53:55 [INFO]: Epoch 084 - training loss: 0.3005, validation loss: 0.1447
2024-05-25 07:53:58 [INFO]: Epoch 085 - training loss: 0.3000, validation loss: 0.1441
2024-05-25 07:54:01 [INFO]: Epoch 086 - training loss: 0.2986, validation loss: 0.1437
2024-05-25 07:54:04 [INFO]: Epoch 087 - training loss: 0.2981, validation loss: 0.1432
2024-05-25 07:54:07 [INFO]: Epoch 088 - training loss: 0.2967, validation loss: 0.1430
2024-05-25 07:54:10 [INFO]: Epoch 089 - training loss: 0.2963, validation loss: 0.1425
2024-05-25 07:54:13 [INFO]: Epoch 090 - training loss: 0.2954, validation loss: 0.1422
2024-05-25 07:54:16 [INFO]: Epoch 091 - training loss: 0.2951, validation loss: 0.1418
2024-05-25 07:54:19 [INFO]: Epoch 092 - training loss: 0.2933, validation loss: 0.1413
2024-05-25 07:54:22 [INFO]: Epoch 093 - training loss: 0.2930, validation loss: 0.1408
2024-05-25 07:54:24 [INFO]: Epoch 094 - training loss: 0.2932, validation loss: 0.1405
2024-05-25 07:54:27 [INFO]: Epoch 095 - training loss: 0.2914, validation loss: 0.1402
2024-05-25 07:54:30 [INFO]: Epoch 096 - training loss: 0.2911, validation loss: 0.1401
2024-05-25 07:54:33 [INFO]: Epoch 097 - training loss: 0.2902, validation loss: 0.1397
2024-05-25 07:54:36 [INFO]: Epoch 098 - training loss: 0.2902, validation loss: 0.1393
2024-05-25 07:54:39 [INFO]: Epoch 099 - training loss: 0.2889, validation loss: 0.1389
2024-05-25 07:54:42 [INFO]: Epoch 100 - training loss: 0.2884, validation loss: 0.1386
2024-05-25 07:54:45 [INFO]: Epoch 101 - training loss: 0.2880, validation loss: 0.1381
2024-05-25 07:54:48 [INFO]: Epoch 102 - training loss: 0.2864, validation loss: 0.1378
2024-05-25 07:54:51 [INFO]: Epoch 103 - training loss: 0.2867, validation loss: 0.1374
2024-05-25 07:54:53 [INFO]: Epoch 104 - training loss: 0.2861, validation loss: 0.1371
2024-05-25 07:54:56 [INFO]: Epoch 105 - training loss: 0.2851, validation loss: 0.1367
2024-05-25 07:54:59 [INFO]: Epoch 106 - training loss: 0.2846, validation loss: 0.1364
2024-05-25 07:55:02 [INFO]: Epoch 107 - training loss: 0.2836, validation loss: 0.1361
2024-05-25 07:55:05 [INFO]: Epoch 108 - training loss: 0.2830, validation loss: 0.1357
2024-05-25 07:55:08 [INFO]: Epoch 109 - training loss: 0.2831, validation loss: 0.1356
2024-05-25 07:55:11 [INFO]: Epoch 110 - training loss: 0.2823, validation loss: 0.1351
2024-05-25 07:55:14 [INFO]: Epoch 111 - training loss: 0.2816, validation loss: 0.1347
2024-05-25 07:55:17 [INFO]: Epoch 112 - training loss: 0.2810, validation loss: 0.1345
2024-05-25 07:55:20 [INFO]: Epoch 113 - training loss: 0.2806, validation loss: 0.1341
2024-05-25 07:55:22 [INFO]: Epoch 114 - training loss: 0.2801, validation loss: 0.1339
2024-05-25 07:55:25 [INFO]: Epoch 115 - training loss: 0.2800, validation loss: 0.1335
2024-05-25 07:55:28 [INFO]: Epoch 116 - training loss: 0.2792, validation loss: 0.1332
2024-05-25 07:55:31 [INFO]: Epoch 117 - training loss: 0.2787, validation loss: 0.1328
2024-05-25 07:55:34 [INFO]: Epoch 118 - training loss: 0.2785, validation loss: 0.1325
2024-05-25 07:55:37 [INFO]: Epoch 119 - training loss: 0.2773, validation loss: 0.1325
2024-05-25 07:55:40 [INFO]: Epoch 120 - training loss: 0.2772, validation loss: 0.1320
2024-05-25 07:55:43 [INFO]: Epoch 121 - training loss: 0.2764, validation loss: 0.1318
2024-05-25 07:55:46 [INFO]: Epoch 122 - training loss: 0.2761, validation loss: 0.1314
2024-05-25 07:55:49 [INFO]: Epoch 123 - training loss: 0.2756, validation loss: 0.1312
2024-05-25 07:55:52 [INFO]: Epoch 124 - training loss: 0.2753, validation loss: 0.1308
2024-05-25 07:55:55 [INFO]: Epoch 125 - training loss: 0.2749, validation loss: 0.1305
2024-05-25 07:55:58 [INFO]: Epoch 126 - training loss: 0.2742, validation loss: 0.1300
2024-05-25 07:56:01 [INFO]: Epoch 127 - training loss: 0.2739, validation loss: 0.1300
2024-05-25 07:56:03 [INFO]: Epoch 128 - training loss: 0.2737, validation loss: 0.1296
2024-05-25 07:56:06 [INFO]: Epoch 129 - training loss: 0.2724, validation loss: 0.1293
2024-05-25 07:56:09 [INFO]: Epoch 130 - training loss: 0.2724, validation loss: 0.1292
2024-05-25 07:56:12 [INFO]: Epoch 131 - training loss: 0.2721, validation loss: 0.1287
2024-05-25 07:56:15 [INFO]: Epoch 132 - training loss: 0.2717, validation loss: 0.1287
2024-05-25 07:56:18 [INFO]: Epoch 133 - training loss: 0.2709, validation loss: 0.1285
2024-05-25 07:56:21 [INFO]: Epoch 134 - training loss: 0.2707, validation loss: 0.1281
2024-05-25 07:56:24 [INFO]: Epoch 135 - training loss: 0.2701, validation loss: 0.1279
2024-05-25 07:56:27 [INFO]: Epoch 136 - training loss: 0.2699, validation loss: 0.1275
2024-05-25 07:56:30 [INFO]: Epoch 137 - training loss: 0.2699, validation loss: 0.1273
2024-05-25 07:56:33 [INFO]: Epoch 138 - training loss: 0.2691, validation loss: 0.1269
2024-05-25 07:56:36 [INFO]: Epoch 139 - training loss: 0.2693, validation loss: 0.1266
2024-05-25 07:56:38 [INFO]: Epoch 140 - training loss: 0.2685, validation loss: 0.1264
2024-05-25 07:56:41 [INFO]: Epoch 141 - training loss: 0.2684, validation loss: 0.1261
2024-05-25 07:56:44 [INFO]: Epoch 142 - training loss: 0.2675, validation loss: 0.1260
2024-05-25 07:56:47 [INFO]: Epoch 143 - training loss: 0.2673, validation loss: 0.1258
2024-05-25 07:56:50 [INFO]: Epoch 144 - training loss: 0.2666, validation loss: 0.1254
2024-05-25 07:56:53 [INFO]: Epoch 145 - training loss: 0.2669, validation loss: 0.1253
2024-05-25 07:56:56 [INFO]: Epoch 146 - training loss: 0.2668, validation loss: 0.1251
2024-05-25 07:56:59 [INFO]: Epoch 147 - training loss: 0.2657, validation loss: 0.1249
2024-05-25 07:57:02 [INFO]: Epoch 148 - training loss: 0.2658, validation loss: 0.1247
2024-05-25 07:57:05 [INFO]: Epoch 149 - training loss: 0.2655, validation loss: 0.1243
2024-05-25 07:57:08 [INFO]: Epoch 150 - training loss: 0.2648, validation loss: 0.1240
2024-05-25 07:57:11 [INFO]: Epoch 151 - training loss: 0.2646, validation loss: 0.1239
2024-05-25 07:57:13 [INFO]: Epoch 152 - training loss: 0.2638, validation loss: 0.1235
2024-05-25 07:57:16 [INFO]: Epoch 153 - training loss: 0.2639, validation loss: 0.1234
2024-05-25 07:57:19 [INFO]: Epoch 154 - training loss: 0.2643, validation loss: 0.1233
2024-05-25 07:57:22 [INFO]: Epoch 155 - training loss: 0.2626, validation loss: 0.1231
2024-05-25 07:57:25 [INFO]: Epoch 156 - training loss: 0.2622, validation loss: 0.1228
2024-05-25 07:57:28 [INFO]: Epoch 157 - training loss: 0.2624, validation loss: 0.1226
2024-05-25 07:57:31 [INFO]: Epoch 158 - training loss: 0.2622, validation loss: 0.1224
2024-05-25 07:57:34 [INFO]: Epoch 159 - training loss: 0.2618, validation loss: 0.1220
2024-05-25 07:57:37 [INFO]: Epoch 160 - training loss: 0.2612, validation loss: 0.1219
2024-05-25 07:57:40 [INFO]: Epoch 161 - training loss: 0.2609, validation loss: 0.1217
2024-05-25 07:57:43 [INFO]: Epoch 162 - training loss: 0.2613, validation loss: 0.1216
2024-05-25 07:57:46 [INFO]: Epoch 163 - training loss: 0.2602, validation loss: 0.1213
2024-05-25 07:57:48 [INFO]: Epoch 164 - training loss: 0.2602, validation loss: 0.1211
2024-05-25 07:57:51 [INFO]: Epoch 165 - training loss: 0.2600, validation loss: 0.1210
2024-05-25 07:57:54 [INFO]: Epoch 166 - training loss: 0.2606, validation loss: 0.1207
2024-05-25 07:57:57 [INFO]: Epoch 167 - training loss: 0.2597, validation loss: 0.1207
2024-05-25 07:58:00 [INFO]: Epoch 168 - training loss: 0.2588, validation loss: 0.1205
2024-05-25 07:58:03 [INFO]: Epoch 169 - training loss: 0.2585, validation loss: 0.1201
2024-05-25 07:58:06 [INFO]: Epoch 170 - training loss: 0.2583, validation loss: 0.1198
2024-05-25 07:58:09 [INFO]: Epoch 171 - training loss: 0.2583, validation loss: 0.1198
2024-05-25 07:58:12 [INFO]: Epoch 172 - training loss: 0.2574, validation loss: 0.1194
2024-05-25 07:58:15 [INFO]: Epoch 173 - training loss: 0.2576, validation loss: 0.1195
2024-05-25 07:58:18 [INFO]: Epoch 174 - training loss: 0.2570, validation loss: 0.1193
2024-05-25 07:58:21 [INFO]: Epoch 175 - training loss: 0.2572, validation loss: 0.1189
2024-05-25 07:58:24 [INFO]: Epoch 176 - training loss: 0.2571, validation loss: 0.1190
2024-05-25 07:58:27 [INFO]: Epoch 177 - training loss: 0.2567, validation loss: 0.1188
2024-05-25 07:58:29 [INFO]: Epoch 178 - training loss: 0.2563, validation loss: 0.1185
2024-05-25 07:58:32 [INFO]: Epoch 179 - training loss: 0.2564, validation loss: 0.1184
2024-05-25 07:58:35 [INFO]: Epoch 180 - training loss: 0.2560, validation loss: 0.1183
2024-05-25 07:58:38 [INFO]: Epoch 181 - training loss: 0.2553, validation loss: 0.1183
2024-05-25 07:58:41 [INFO]: Epoch 182 - training loss: 0.2554, validation loss: 0.1179
2024-05-25 07:58:44 [INFO]: Epoch 183 - training loss: 0.2553, validation loss: 0.1178
2024-05-25 07:58:47 [INFO]: Epoch 184 - training loss: 0.2548, validation loss: 0.1175
2024-05-25 07:58:50 [INFO]: Epoch 185 - training loss: 0.2543, validation loss: 0.1176
2024-05-25 07:58:53 [INFO]: Epoch 186 - training loss: 0.2544, validation loss: 0.1175
2024-05-25 07:58:56 [INFO]: Epoch 187 - training loss: 0.2544, validation loss: 0.1173
2024-05-25 07:58:59 [INFO]: Epoch 188 - training loss: 0.2540, validation loss: 0.1172
2024-05-25 07:59:02 [INFO]: Epoch 189 - training loss: 0.2539, validation loss: 0.1171
2024-05-25 07:59:04 [INFO]: Epoch 190 - training loss: 0.2532, validation loss: 0.1168
2024-05-25 07:59:07 [INFO]: Epoch 191 - training loss: 0.2532, validation loss: 0.1167
2024-05-25 07:59:10 [INFO]: Epoch 192 - training loss: 0.2533, validation loss: 0.1165
2024-05-25 07:59:13 [INFO]: Epoch 193 - training loss: 0.2530, validation loss: 0.1165
2024-05-25 07:59:16 [INFO]: Epoch 194 - training loss: 0.2528, validation loss: 0.1161
2024-05-25 07:59:19 [INFO]: Epoch 195 - training loss: 0.2522, validation loss: 0.1162
2024-05-25 07:59:22 [INFO]: Epoch 196 - training loss: 0.2521, validation loss: 0.1161
2024-05-25 07:59:25 [INFO]: Epoch 197 - training loss: 0.2516, validation loss: 0.1159
2024-05-25 07:59:28 [INFO]: Epoch 198 - training loss: 0.2517, validation loss: 0.1157
2024-05-25 07:59:31 [INFO]: Epoch 199 - training loss: 0.2509, validation loss: 0.1156
2024-05-25 07:59:34 [INFO]: Epoch 200 - training loss: 0.2514, validation loss: 0.1155
2024-05-25 07:59:36 [INFO]: Epoch 201 - training loss: 0.2509, validation loss: 0.1153
2024-05-25 07:59:39 [INFO]: Epoch 202 - training loss: 0.2512, validation loss: 0.1152
2024-05-25 07:59:42 [INFO]: Epoch 203 - training loss: 0.2501, validation loss: 0.1151
2024-05-25 07:59:45 [INFO]: Epoch 204 - training loss: 0.2505, validation loss: 0.1151
2024-05-25 07:59:48 [INFO]: Epoch 205 - training loss: 0.2501, validation loss: 0.1150
2024-05-25 07:59:51 [INFO]: Epoch 206 - training loss: 0.2503, validation loss: 0.1148
2024-05-25 07:59:54 [INFO]: Epoch 207 - training loss: 0.2496, validation loss: 0.1144
2024-05-25 07:59:57 [INFO]: Epoch 208 - training loss: 0.2492, validation loss: 0.1145
2024-05-25 08:00:00 [INFO]: Epoch 209 - training loss: 0.2491, validation loss: 0.1142
2024-05-25 08:00:03 [INFO]: Epoch 210 - training loss: 0.2488, validation loss: 0.1143
2024-05-25 08:00:06 [INFO]: Epoch 211 - training loss: 0.2492, validation loss: 0.1142
2024-05-25 08:00:09 [INFO]: Epoch 212 - training loss: 0.2487, validation loss: 0.1140
2024-05-25 08:00:12 [INFO]: Epoch 213 - training loss: 0.2481, validation loss: 0.1140
2024-05-25 08:00:14 [INFO]: Epoch 214 - training loss: 0.2483, validation loss: 0.1139
2024-05-25 08:00:17 [INFO]: Epoch 215 - training loss: 0.2484, validation loss: 0.1135
2024-05-25 08:00:20 [INFO]: Epoch 216 - training loss: 0.2481, validation loss: 0.1136
2024-05-25 08:00:23 [INFO]: Epoch 217 - training loss: 0.2487, validation loss: 0.1137
2024-05-25 08:00:26 [INFO]: Epoch 218 - training loss: 0.2476, validation loss: 0.1136
2024-05-25 08:00:29 [INFO]: Epoch 219 - training loss: 0.2473, validation loss: 0.1135
2024-05-25 08:00:32 [INFO]: Epoch 220 - training loss: 0.2470, validation loss: 0.1131
2024-05-25 08:00:35 [INFO]: Epoch 221 - training loss: 0.2472, validation loss: 0.1132
2024-05-25 08:00:38 [INFO]: Epoch 222 - training loss: 0.2464, validation loss: 0.1130
2024-05-25 08:00:41 [INFO]: Epoch 223 - training loss: 0.2468, validation loss: 0.1131
2024-05-25 08:00:44 [INFO]: Epoch 224 - training loss: 0.2466, validation loss: 0.1129
2024-05-25 08:00:46 [INFO]: Epoch 225 - training loss: 0.2462, validation loss: 0.1129
2024-05-25 08:00:49 [INFO]: Epoch 226 - training loss: 0.2465, validation loss: 0.1128
2024-05-25 08:00:52 [INFO]: Epoch 227 - training loss: 0.2461, validation loss: 0.1126
2024-05-25 08:00:55 [INFO]: Epoch 228 - training loss: 0.2456, validation loss: 0.1126
2024-05-25 08:00:58 [INFO]: Epoch 229 - training loss: 0.2460, validation loss: 0.1125
2024-05-25 08:01:01 [INFO]: Epoch 230 - training loss: 0.2455, validation loss: 0.1123
2024-05-25 08:01:04 [INFO]: Epoch 231 - training loss: 0.2455, validation loss: 0.1124
2024-05-25 08:01:07 [INFO]: Epoch 232 - training loss: 0.2456, validation loss: 0.1123
2024-05-25 08:01:10 [INFO]: Epoch 233 - training loss: 0.2452, validation loss: 0.1120
2024-05-25 08:01:13 [INFO]: Epoch 234 - training loss: 0.2442, validation loss: 0.1119
2024-05-25 08:01:16 [INFO]: Epoch 235 - training loss: 0.2451, validation loss: 0.1118
2024-05-25 08:01:19 [INFO]: Epoch 236 - training loss: 0.2441, validation loss: 0.1118
2024-05-25 08:01:21 [INFO]: Epoch 237 - training loss: 0.2444, validation loss: 0.1117
2024-05-25 08:01:24 [INFO]: Epoch 238 - training loss: 0.2437, validation loss: 0.1117
2024-05-25 08:01:27 [INFO]: Epoch 239 - training loss: 0.2437, validation loss: 0.1117
2024-05-25 08:01:30 [INFO]: Epoch 240 - training loss: 0.2442, validation loss: 0.1116
2024-05-25 08:01:33 [INFO]: Epoch 241 - training loss: 0.2436, validation loss: 0.1116
2024-05-25 08:01:36 [INFO]: Epoch 242 - training loss: 0.2437, validation loss: 0.1113
2024-05-25 08:01:39 [INFO]: Epoch 243 - training loss: 0.2432, validation loss: 0.1113
2024-05-25 08:01:42 [INFO]: Epoch 244 - training loss: 0.2429, validation loss: 0.1114
2024-05-25 08:01:45 [INFO]: Epoch 245 - training loss: 0.2434, validation loss: 0.1111
2024-05-25 08:01:48 [INFO]: Epoch 246 - training loss: 0.2431, validation loss: 0.1110
2024-05-25 08:01:51 [INFO]: Epoch 247 - training loss: 0.2428, validation loss: 0.1110
2024-05-25 08:01:54 [INFO]: Epoch 248 - training loss: 0.2427, validation loss: 0.1110
2024-05-25 08:01:56 [INFO]: Epoch 249 - training loss: 0.2427, validation loss: 0.1109
2024-05-25 08:01:59 [INFO]: Epoch 250 - training loss: 0.2423, validation loss: 0.1108
2024-05-25 08:02:02 [INFO]: Epoch 251 - training loss: 0.2422, validation loss: 0.1107
2024-05-25 08:02:05 [INFO]: Epoch 252 - training loss: 0.2421, validation loss: 0.1107
2024-05-25 08:02:08 [INFO]: Epoch 253 - training loss: 0.2414, validation loss: 0.1106
2024-05-25 08:02:11 [INFO]: Epoch 254 - training loss: 0.2413, validation loss: 0.1106
2024-05-25 08:02:14 [INFO]: Epoch 255 - training loss: 0.2415, validation loss: 0.1107
2024-05-25 08:02:17 [INFO]: Epoch 256 - training loss: 0.2414, validation loss: 0.1105
2024-05-25 08:02:19 [INFO]: Epoch 257 - training loss: 0.2417, validation loss: 0.1102
2024-05-25 08:02:22 [INFO]: Epoch 258 - training loss: 0.2415, validation loss: 0.1104
2024-05-25 08:02:25 [INFO]: Epoch 259 - training loss: 0.2414, validation loss: 0.1105
2024-05-25 08:02:28 [INFO]: Epoch 260 - training loss: 0.2405, validation loss: 0.1104
2024-05-25 08:02:31 [INFO]: Epoch 261 - training loss: 0.2405, validation loss: 0.1103
2024-05-25 08:02:34 [INFO]: Epoch 262 - training loss: 0.2403, validation loss: 0.1103
2024-05-25 08:02:37 [INFO]: Epoch 263 - training loss: 0.2401, validation loss: 0.1102
2024-05-25 08:02:40 [INFO]: Epoch 264 - training loss: 0.2405, validation loss: 0.1102
2024-05-25 08:02:43 [INFO]: Epoch 265 - training loss: 0.2400, validation loss: 0.1102
2024-05-25 08:02:46 [INFO]: Epoch 266 - training loss: 0.2404, validation loss: 0.1100
2024-05-25 08:02:48 [INFO]: Epoch 267 - training loss: 0.2400, validation loss: 0.1102
2024-05-25 08:02:51 [INFO]: Epoch 268 - training loss: 0.2396, validation loss: 0.1099
2024-05-25 08:02:54 [INFO]: Epoch 269 - training loss: 0.2391, validation loss: 0.1098
2024-05-25 08:02:57 [INFO]: Epoch 270 - training loss: 0.2395, validation loss: 0.1098
2024-05-25 08:03:00 [INFO]: Epoch 271 - training loss: 0.2391, validation loss: 0.1099
2024-05-25 08:03:03 [INFO]: Epoch 272 - training loss: 0.2390, validation loss: 0.1098
2024-05-25 08:03:06 [INFO]: Epoch 273 - training loss: 0.2391, validation loss: 0.1098
2024-05-25 08:03:09 [INFO]: Epoch 274 - training loss: 0.2391, validation loss: 0.1098
2024-05-25 08:03:12 [INFO]: Epoch 275 - training loss: 0.2391, validation loss: 0.1096
2024-05-25 08:03:15 [INFO]: Epoch 276 - training loss: 0.2384, validation loss: 0.1098
2024-05-25 08:03:18 [INFO]: Epoch 277 - training loss: 0.2383, validation loss: 0.1097
2024-05-25 08:03:21 [INFO]: Epoch 278 - training loss: 0.2382, validation loss: 0.1096
2024-05-25 08:03:23 [INFO]: Epoch 279 - training loss: 0.2384, validation loss: 0.1095
2024-05-25 08:03:26 [INFO]: Epoch 280 - training loss: 0.2380, validation loss: 0.1096
2024-05-25 08:03:29 [INFO]: Epoch 281 - training loss: 0.2384, validation loss: 0.1094
2024-05-25 08:03:32 [INFO]: Epoch 282 - training loss: 0.2378, validation loss: 0.1091
2024-05-25 08:03:35 [INFO]: Epoch 283 - training loss: 0.2378, validation loss: 0.1093
2024-05-25 08:03:38 [INFO]: Epoch 284 - training loss: 0.2377, validation loss: 0.1093
2024-05-25 08:03:41 [INFO]: Epoch 285 - training loss: 0.2373, validation loss: 0.1091
2024-05-25 08:03:44 [INFO]: Epoch 286 - training loss: 0.2373, validation loss: 0.1091
2024-05-25 08:03:47 [INFO]: Epoch 287 - training loss: 0.2375, validation loss: 0.1092
2024-05-25 08:03:50 [INFO]: Epoch 288 - training loss: 0.2374, validation loss: 0.1090
2024-05-25 08:03:53 [INFO]: Epoch 289 - training loss: 0.2370, validation loss: 0.1091
2024-05-25 08:03:56 [INFO]: Epoch 290 - training loss: 0.2369, validation loss: 0.1090
2024-05-25 08:03:58 [INFO]: Epoch 291 - training loss: 0.2373, validation loss: 0.1090
2024-05-25 08:04:01 [INFO]: Epoch 292 - training loss: 0.2368, validation loss: 0.1093
2024-05-25 08:04:04 [INFO]: Epoch 293 - training loss: 0.2366, validation loss: 0.1091
2024-05-25 08:04:07 [INFO]: Epoch 294 - training loss: 0.2368, validation loss: 0.1091
2024-05-25 08:04:10 [INFO]: Epoch 295 - training loss: 0.2366, validation loss: 0.1091
2024-05-25 08:04:13 [INFO]: Epoch 296 - training loss: 0.2367, validation loss: 0.1089
2024-05-25 08:04:16 [INFO]: Epoch 297 - training loss: 0.2366, validation loss: 0.1090
2024-05-25 08:04:19 [INFO]: Epoch 298 - training loss: 0.2359, validation loss: 0.1091
2024-05-25 08:04:22 [INFO]: Epoch 299 - training loss: 0.2361, validation loss: 0.1089
2024-05-25 08:04:25 [INFO]: Epoch 300 - training loss: 0.2358, validation loss: 0.1088
2024-05-25 08:04:25 [INFO]: Finished training. The best model is from epoch#300.
2024-05-25 08:04:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/BRITS_air_quality/20240525_T074949/BRITS.pypots
2024-05-25 08:04:26 [INFO]: BRITS on Air-Quality: MAE=0.1392, MSE=0.1851
2024-05-25 08:04:26 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/BRITS_air_quality/imputation.pkl
2024-05-25 08:04:26 [INFO]: Using the given device: cuda:0
2024-05-25 08:04:26 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426
2024-05-25 08:04:26 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/tensorboard
2024-05-25 08:04:26 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 08:04:30 [INFO]: Epoch 001 - training loss: 1.3961, validation loss: 0.8040
2024-05-25 08:04:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch1_loss0.8039715230464936.pypots
2024-05-25 08:04:34 [INFO]: Epoch 002 - training loss: 1.0397, validation loss: 0.7543
2024-05-25 08:04:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch2_loss0.7543386310338974.pypots
2024-05-25 08:04:38 [INFO]: Epoch 003 - training loss: 0.9732, validation loss: 0.7258
2024-05-25 08:04:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch3_loss0.7257642477750779.pypots
2024-05-25 08:04:42 [INFO]: Epoch 004 - training loss: 0.9548, validation loss: 0.7109
2024-05-25 08:04:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch4_loss0.710867378115654.pypots
2024-05-25 08:04:46 [INFO]: Epoch 005 - training loss: 0.9379, validation loss: 0.7024
2024-05-25 08:04:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch5_loss0.7024319440126419.pypots
2024-05-25 08:04:50 [INFO]: Epoch 006 - training loss: 0.9292, validation loss: 0.6965
2024-05-25 08:04:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch6_loss0.6965025067329407.pypots
2024-05-25 08:04:54 [INFO]: Epoch 007 - training loss: 0.9111, validation loss: 0.6916
2024-05-25 08:04:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch7_loss0.6916243970394135.pypots
2024-05-25 08:04:58 [INFO]: Epoch 008 - training loss: 0.9098, validation loss: 0.6874
2024-05-25 08:04:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch8_loss0.687433385848999.pypots
2024-05-25 08:05:02 [INFO]: Epoch 009 - training loss: 0.9042, validation loss: 0.6848
2024-05-25 08:05:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch9_loss0.6847530364990234.pypots
2024-05-25 08:05:06 [INFO]: Epoch 010 - training loss: 0.9023, validation loss: 0.6815
2024-05-25 08:05:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch10_loss0.6815107792615891.pypots
2024-05-25 08:05:10 [INFO]: Epoch 011 - training loss: 0.9011, validation loss: 0.6800
2024-05-25 08:05:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch11_loss0.6799857646226883.pypots
2024-05-25 08:05:14 [INFO]: Epoch 012 - training loss: 0.9095, validation loss: 0.6790
2024-05-25 08:05:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch12_loss0.6790255248546601.pypots
2024-05-25 08:05:18 [INFO]: Epoch 013 - training loss: 0.8937, validation loss: 0.6788
2024-05-25 08:05:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch13_loss0.6787902325391769.pypots
2024-05-25 08:05:22 [INFO]: Epoch 014 - training loss: 0.8700, validation loss: 0.6765
2024-05-25 08:05:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch14_loss0.6765458166599274.pypots
2024-05-25 08:05:26 [INFO]: Epoch 015 - training loss: 0.8897, validation loss: 0.6763
2024-05-25 08:05:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch15_loss0.6763087391853333.pypots
2024-05-25 08:05:30 [INFO]: Epoch 016 - training loss: 0.8860, validation loss: 0.6749
2024-05-25 08:05:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch16_loss0.674941885471344.pypots
2024-05-25 08:05:34 [INFO]: Epoch 017 - training loss: 0.8903, validation loss: 0.6745
2024-05-25 08:05:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch17_loss0.6745234966278076.pypots
2024-05-25 08:05:38 [INFO]: Epoch 018 - training loss: 0.8627, validation loss: 0.6741
2024-05-25 08:05:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch18_loss0.6741098493337632.pypots
2024-05-25 08:05:42 [INFO]: Epoch 019 - training loss: 0.8595, validation loss: 0.6734
2024-05-25 08:05:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch19_loss0.6734180718660354.pypots
2024-05-25 08:05:46 [INFO]: Epoch 020 - training loss: 0.8588, validation loss: 0.6747
2024-05-25 08:05:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch20_loss0.6747456789016724.pypots
2024-05-25 08:05:50 [INFO]: Epoch 021 - training loss: 0.8686, validation loss: 0.6718
2024-05-25 08:05:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch21_loss0.6718113899230957.pypots
2024-05-25 08:05:54 [INFO]: Epoch 022 - training loss: 0.8425, validation loss: 0.6728
2024-05-25 08:05:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch22_loss0.6727637231349946.pypots
2024-05-25 08:05:58 [INFO]: Epoch 023 - training loss: 0.8604, validation loss: 0.6743
2024-05-25 08:05:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch23_loss0.6742502003908157.pypots
2024-05-25 08:06:02 [INFO]: Epoch 024 - training loss: 0.8478, validation loss: 0.6729
2024-05-25 08:06:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch24_loss0.6729341149330139.pypots
2024-05-25 08:06:06 [INFO]: Epoch 025 - training loss: 0.8474, validation loss: 0.6742
2024-05-25 08:06:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch25_loss0.6741855263710022.pypots
2024-05-25 08:06:10 [INFO]: Epoch 026 - training loss: 0.8465, validation loss: 0.6740
2024-05-25 08:06:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch26_loss0.6739541798830032.pypots
2024-05-25 08:06:14 [INFO]: Epoch 027 - training loss: 0.8411, validation loss: 0.6733
2024-05-25 08:06:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch27_loss0.6732987284660339.pypots
2024-05-25 08:06:18 [INFO]: Epoch 028 - training loss: 0.8413, validation loss: 0.6729
2024-05-25 08:06:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch28_loss0.6729023396968842.pypots
2024-05-25 08:06:22 [INFO]: Epoch 029 - training loss: 0.8646, validation loss: 0.6736
2024-05-25 08:06:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch29_loss0.6736292153596878.pypots
2024-05-25 08:06:26 [INFO]: Epoch 030 - training loss: 0.8612, validation loss: 0.6749
2024-05-25 08:06:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch30_loss0.6749340772628785.pypots
2024-05-25 08:06:30 [INFO]: Epoch 031 - training loss: 0.8316, validation loss: 0.6750
2024-05-25 08:06:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN_epoch31_loss0.6750442504882812.pypots
2024-05-25 08:06:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 08:06:30 [INFO]: Finished training. The best model is from epoch#21.
2024-05-25 08:06:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240525_T080426/MRNN.pypots
2024-05-25 08:06:31 [INFO]: MRNN on Air-Quality: MAE=0.5273, MSE=0.7656
2024-05-25 08:06:31 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/MRNN_air_quality/imputation.pkl
2024-05-25 08:06:31 [INFO]: Using the given device: cpu
2024-05-25 08:06:31 [INFO]: LOCF on Air-Quality: MAE=0.2039, MSE=0.4028
2024-05-25 08:06:31 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_air_quality".
2024-05-25 08:06:31 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/LOCF_air_quality/imputation.pkl
2024-05-25 08:06:31 [INFO]: Median on Air-Quality: MAE=0.6702, MSE=1.1687
2024-05-25 08:06:31 [INFO]: Successfully created the given path "saved_results/round_3/Median_air_quality".
2024-05-25 08:06:31 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Median_air_quality/imputation.pkl
2024-05-25 08:06:31 [INFO]: Mean on Air-Quality: MAE=0.7021, MSE=1.1087
2024-05-25 08:06:31 [INFO]: Successfully created the given path "saved_results/round_3/Mean_air_quality".
2024-05-25 08:06:31 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Mean_air_quality/imputation.pkl
2024-05-25 08:06:31 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-25 08:06:31 [INFO]: Using the given device: cuda:0
2024-05-25 08:06:31 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/SAITS_air_quality/20240525_T080631
2024-05-25 08:06:31 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/SAITS_air_quality/20240525_T080631/tensorboard
2024-05-25 08:06:31 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 08:06:32 [INFO]: Epoch 001 - training loss: 1.0433, validation loss: 0.5051
2024-05-25 08:06:33 [INFO]: Epoch 002 - training loss: 0.7455, validation loss: 0.3904
2024-05-25 08:06:33 [INFO]: Epoch 003 - training loss: 0.6385, validation loss: 0.3170
2024-05-25 08:06:34 [INFO]: Epoch 004 - training loss: 0.5669, validation loss: 0.2796
2024-05-25 08:06:34 [INFO]: Epoch 005 - training loss: 0.5104, validation loss: 0.2613
2024-05-25 08:06:35 [INFO]: Epoch 006 - training loss: 0.4743, validation loss: 0.2476
2024-05-25 08:06:36 [INFO]: Epoch 007 - training loss: 0.4501, validation loss: 0.2379
2024-05-25 08:06:36 [INFO]: Epoch 008 - training loss: 0.4300, validation loss: 0.2319
2024-05-25 08:06:37 [INFO]: Epoch 009 - training loss: 0.4148, validation loss: 0.2248
2024-05-25 08:06:37 [INFO]: Epoch 010 - training loss: 0.4015, validation loss: 0.2190
2024-05-25 08:06:38 [INFO]: Epoch 011 - training loss: 0.3934, validation loss: 0.2155
2024-05-25 08:06:39 [INFO]: Epoch 012 - training loss: 0.3857, validation loss: 0.2102
2024-05-25 08:06:39 [INFO]: Epoch 013 - training loss: 0.3753, validation loss: 0.2071
2024-05-25 08:06:40 [INFO]: Epoch 014 - training loss: 0.3677, validation loss: 0.2031
2024-05-25 08:06:40 [INFO]: Epoch 015 - training loss: 0.3641, validation loss: 0.2021
2024-05-25 08:06:41 [INFO]: Epoch 016 - training loss: 0.3566, validation loss: 0.1965
2024-05-25 08:06:42 [INFO]: Epoch 017 - training loss: 0.3516, validation loss: 0.1951
2024-05-25 08:06:42 [INFO]: Epoch 018 - training loss: 0.3453, validation loss: 0.1925
2024-05-25 08:06:43 [INFO]: Epoch 019 - training loss: 0.3426, validation loss: 0.1908
2024-05-25 08:06:44 [INFO]: Epoch 020 - training loss: 0.3388, validation loss: 0.1893
2024-05-25 08:06:44 [INFO]: Epoch 021 - training loss: 0.3329, validation loss: 0.1861
2024-05-25 08:06:45 [INFO]: Epoch 022 - training loss: 0.3308, validation loss: 0.1848
2024-05-25 08:06:45 [INFO]: Epoch 023 - training loss: 0.3262, validation loss: 0.1827
2024-05-25 08:06:46 [INFO]: Epoch 024 - training loss: 0.3231, validation loss: 0.1819
2024-05-25 08:06:47 [INFO]: Epoch 025 - training loss: 0.3209, validation loss: 0.1793
2024-05-25 08:06:47 [INFO]: Epoch 026 - training loss: 0.3169, validation loss: 0.1789
2024-05-25 08:06:48 [INFO]: Epoch 027 - training loss: 0.3136, validation loss: 0.1755
2024-05-25 08:06:48 [INFO]: Epoch 028 - training loss: 0.3112, validation loss: 0.1736
2024-05-25 08:06:49 [INFO]: Epoch 029 - training loss: 0.3103, validation loss: 0.1750
2024-05-25 08:06:50 [INFO]: Epoch 030 - training loss: 0.3066, validation loss: 0.1730
2024-05-25 08:06:50 [INFO]: Epoch 031 - training loss: 0.3052, validation loss: 0.1722
2024-05-25 08:06:51 [INFO]: Epoch 032 - training loss: 0.3020, validation loss: 0.1706
2024-05-25 08:06:52 [INFO]: Epoch 033 - training loss: 0.2998, validation loss: 0.1703
2024-05-25 08:06:52 [INFO]: Epoch 034 - training loss: 0.2972, validation loss: 0.1673
2024-05-25 08:06:53 [INFO]: Epoch 035 - training loss: 0.2942, validation loss: 0.1660
2024-05-25 08:06:53 [INFO]: Epoch 036 - training loss: 0.2927, validation loss: 0.1649
2024-05-25 08:06:54 [INFO]: Epoch 037 - training loss: 0.2902, validation loss: 0.1644
2024-05-25 08:06:55 [INFO]: Epoch 038 - training loss: 0.2895, validation loss: 0.1630
2024-05-25 08:06:55 [INFO]: Epoch 039 - training loss: 0.2899, validation loss: 0.1629
2024-05-25 08:06:56 [INFO]: Epoch 040 - training loss: 0.2869, validation loss: 0.1605
2024-05-25 08:06:56 [INFO]: Epoch 041 - training loss: 0.2848, validation loss: 0.1604
2024-05-25 08:06:57 [INFO]: Epoch 042 - training loss: 0.2825, validation loss: 0.1604
2024-05-25 08:06:58 [INFO]: Epoch 043 - training loss: 0.2794, validation loss: 0.1584
2024-05-25 08:06:58 [INFO]: Epoch 044 - training loss: 0.2783, validation loss: 0.1577
2024-05-25 08:06:59 [INFO]: Epoch 045 - training loss: 0.2765, validation loss: 0.1561
2024-05-25 08:06:59 [INFO]: Epoch 046 - training loss: 0.2746, validation loss: 0.1561
2024-05-25 08:07:00 [INFO]: Epoch 047 - training loss: 0.2730, validation loss: 0.1550
2024-05-25 08:07:01 [INFO]: Epoch 048 - training loss: 0.2724, validation loss: 0.1542
2024-05-25 08:07:01 [INFO]: Epoch 049 - training loss: 0.2698, validation loss: 0.1531
2024-05-25 08:07:02 [INFO]: Epoch 050 - training loss: 0.2690, validation loss: 0.1516
2024-05-25 08:07:03 [INFO]: Epoch 051 - training loss: 0.2672, validation loss: 0.1521
2024-05-25 08:07:03 [INFO]: Epoch 052 - training loss: 0.2674, validation loss: 0.1518
2024-05-25 08:07:04 [INFO]: Epoch 053 - training loss: 0.2645, validation loss: 0.1498
2024-05-25 08:07:04 [INFO]: Epoch 054 - training loss: 0.2639, validation loss: 0.1491
2024-05-25 08:07:05 [INFO]: Epoch 055 - training loss: 0.2615, validation loss: 0.1491
2024-05-25 08:07:06 [INFO]: Epoch 056 - training loss: 0.2600, validation loss: 0.1491
2024-05-25 08:07:06 [INFO]: Epoch 057 - training loss: 0.2587, validation loss: 0.1465
2024-05-25 08:07:07 [INFO]: Epoch 058 - training loss: 0.2576, validation loss: 0.1462
2024-05-25 08:07:08 [INFO]: Epoch 059 - training loss: 0.2561, validation loss: 0.1453
2024-05-25 08:07:08 [INFO]: Epoch 060 - training loss: 0.2547, validation loss: 0.1445
2024-05-25 08:07:09 [INFO]: Epoch 061 - training loss: 0.2536, validation loss: 0.1438
2024-05-25 08:07:09 [INFO]: Epoch 062 - training loss: 0.2521, validation loss: 0.1437
2024-05-25 08:07:10 [INFO]: Epoch 063 - training loss: 0.2507, validation loss: 0.1438
2024-05-25 08:07:11 [INFO]: Epoch 064 - training loss: 0.2493, validation loss: 0.1429
2024-05-25 08:07:11 [INFO]: Epoch 065 - training loss: 0.2476, validation loss: 0.1431
2024-05-25 08:07:12 [INFO]: Epoch 066 - training loss: 0.2475, validation loss: 0.1419
2024-05-25 08:07:12 [INFO]: Epoch 067 - training loss: 0.2459, validation loss: 0.1420
2024-05-25 08:07:13 [INFO]: Epoch 068 - training loss: 0.2436, validation loss: 0.1393
2024-05-25 08:07:14 [INFO]: Epoch 069 - training loss: 0.2431, validation loss: 0.1391
2024-05-25 08:07:14 [INFO]: Epoch 070 - training loss: 0.2420, validation loss: 0.1394
2024-05-25 08:07:15 [INFO]: Epoch 071 - training loss: 0.2411, validation loss: 0.1398
2024-05-25 08:07:16 [INFO]: Epoch 072 - training loss: 0.2401, validation loss: 0.1394
2024-05-25 08:07:16 [INFO]: Epoch 073 - training loss: 0.2384, validation loss: 0.1389
2024-05-25 08:07:17 [INFO]: Epoch 074 - training loss: 0.2368, validation loss: 0.1389
2024-05-25 08:07:17 [INFO]: Epoch 075 - training loss: 0.2362, validation loss: 0.1369
2024-05-25 08:07:18 [INFO]: Epoch 076 - training loss: 0.2347, validation loss: 0.1374
2024-05-25 08:07:19 [INFO]: Epoch 077 - training loss: 0.2332, validation loss: 0.1368
2024-05-25 08:07:19 [INFO]: Epoch 078 - training loss: 0.2324, validation loss: 0.1359
2024-05-25 08:07:20 [INFO]: Epoch 079 - training loss: 0.2317, validation loss: 0.1361
2024-05-25 08:07:20 [INFO]: Epoch 080 - training loss: 0.2304, validation loss: 0.1358
2024-05-25 08:07:21 [INFO]: Epoch 081 - training loss: 0.2290, validation loss: 0.1350
2024-05-25 08:07:22 [INFO]: Epoch 082 - training loss: 0.2282, validation loss: 0.1352
2024-05-25 08:07:22 [INFO]: Epoch 083 - training loss: 0.2279, validation loss: 0.1344
2024-05-25 08:07:23 [INFO]: Epoch 084 - training loss: 0.2259, validation loss: 0.1337
2024-05-25 08:07:24 [INFO]: Epoch 085 - training loss: 0.2262, validation loss: 0.1334
2024-05-25 08:07:24 [INFO]: Epoch 086 - training loss: 0.2255, validation loss: 0.1321
2024-05-25 08:07:25 [INFO]: Epoch 087 - training loss: 0.2252, validation loss: 0.1332
2024-05-25 08:07:25 [INFO]: Epoch 088 - training loss: 0.2241, validation loss: 0.1340
2024-05-25 08:07:26 [INFO]: Epoch 089 - training loss: 0.2224, validation loss: 0.1324
2024-05-25 08:07:27 [INFO]: Epoch 090 - training loss: 0.2220, validation loss: 0.1324
2024-05-25 08:07:27 [INFO]: Epoch 091 - training loss: 0.2204, validation loss: 0.1331
2024-05-25 08:07:28 [INFO]: Epoch 092 - training loss: 0.2194, validation loss: 0.1321
2024-05-25 08:07:28 [INFO]: Epoch 093 - training loss: 0.2189, validation loss: 0.1313
2024-05-25 08:07:29 [INFO]: Epoch 094 - training loss: 0.2182, validation loss: 0.1319
2024-05-25 08:07:30 [INFO]: Epoch 095 - training loss: 0.2184, validation loss: 0.1315
2024-05-25 08:07:30 [INFO]: Epoch 096 - training loss: 0.2176, validation loss: 0.1304
2024-05-25 08:07:31 [INFO]: Epoch 097 - training loss: 0.2163, validation loss: 0.1308
2024-05-25 08:07:32 [INFO]: Epoch 098 - training loss: 0.2159, validation loss: 0.1303
2024-05-25 08:07:32 [INFO]: Epoch 099 - training loss: 0.2150, validation loss: 0.1305
2024-05-25 08:07:33 [INFO]: Epoch 100 - training loss: 0.2147, validation loss: 0.1295
2024-05-25 08:07:33 [INFO]: Epoch 101 - training loss: 0.2139, validation loss: 0.1304
2024-05-25 08:07:34 [INFO]: Epoch 102 - training loss: 0.2135, validation loss: 0.1296
2024-05-25 08:07:35 [INFO]: Epoch 103 - training loss: 0.2123, validation loss: 0.1283
2024-05-25 08:07:35 [INFO]: Epoch 104 - training loss: 0.2108, validation loss: 0.1276
2024-05-25 08:07:36 [INFO]: Epoch 105 - training loss: 0.2107, validation loss: 0.1276
2024-05-25 08:07:36 [INFO]: Epoch 106 - training loss: 0.2103, validation loss: 0.1287
2024-05-25 08:07:37 [INFO]: Epoch 107 - training loss: 0.2088, validation loss: 0.1280
2024-05-25 08:07:38 [INFO]: Epoch 108 - training loss: 0.2092, validation loss: 0.1273
2024-05-25 08:07:38 [INFO]: Epoch 109 - training loss: 0.2093, validation loss: 0.1275
2024-05-25 08:07:39 [INFO]: Epoch 110 - training loss: 0.2072, validation loss: 0.1271
2024-05-25 08:07:40 [INFO]: Epoch 111 - training loss: 0.2066, validation loss: 0.1263
2024-05-25 08:07:40 [INFO]: Epoch 112 - training loss: 0.2057, validation loss: 0.1276
2024-05-25 08:07:41 [INFO]: Epoch 113 - training loss: 0.2091, validation loss: 0.1271
2024-05-25 08:07:41 [INFO]: Epoch 114 - training loss: 0.2085, validation loss: 0.1262
2024-05-25 08:07:42 [INFO]: Epoch 115 - training loss: 0.2052, validation loss: 0.1265
2024-05-25 08:07:43 [INFO]: Epoch 116 - training loss: 0.2038, validation loss: 0.1265
2024-05-25 08:07:43 [INFO]: Epoch 117 - training loss: 0.2046, validation loss: 0.1258
2024-05-25 08:07:44 [INFO]: Epoch 118 - training loss: 0.2037, validation loss: 0.1262
2024-05-25 08:07:44 [INFO]: Epoch 119 - training loss: 0.2023, validation loss: 0.1263
2024-05-25 08:07:45 [INFO]: Epoch 120 - training loss: 0.2017, validation loss: 0.1262
2024-05-25 08:07:46 [INFO]: Epoch 121 - training loss: 0.2010, validation loss: 0.1248
2024-05-25 08:07:46 [INFO]: Epoch 122 - training loss: 0.2006, validation loss: 0.1242
2024-05-25 08:07:47 [INFO]: Epoch 123 - training loss: 0.2008, validation loss: 0.1246
2024-05-25 08:07:47 [INFO]: Epoch 124 - training loss: 0.1999, validation loss: 0.1246
2024-05-25 08:07:48 [INFO]: Epoch 125 - training loss: 0.1994, validation loss: 0.1251
2024-05-25 08:07:49 [INFO]: Epoch 126 - training loss: 0.1988, validation loss: 0.1244
2024-05-25 08:07:49 [INFO]: Epoch 127 - training loss: 0.1987, validation loss: 0.1239
2024-05-25 08:07:50 [INFO]: Epoch 128 - training loss: 0.1988, validation loss: 0.1235
2024-05-25 08:07:51 [INFO]: Epoch 129 - training loss: 0.1982, validation loss: 0.1239
2024-05-25 08:07:51 [INFO]: Epoch 130 - training loss: 0.1968, validation loss: 0.1248
2024-05-25 08:07:52 [INFO]: Epoch 131 - training loss: 0.1962, validation loss: 0.1242
2024-05-25 08:07:52 [INFO]: Epoch 132 - training loss: 0.1964, validation loss: 0.1237
2024-05-25 08:07:53 [INFO]: Epoch 133 - training loss: 0.1953, validation loss: 0.1233
2024-05-25 08:07:54 [INFO]: Epoch 134 - training loss: 0.1954, validation loss: 0.1230
2024-05-25 08:07:54 [INFO]: Epoch 135 - training loss: 0.1946, validation loss: 0.1231
2024-05-25 08:07:55 [INFO]: Epoch 136 - training loss: 0.1946, validation loss: 0.1236
2024-05-25 08:07:56 [INFO]: Epoch 137 - training loss: 0.1944, validation loss: 0.1219
2024-05-25 08:07:56 [INFO]: Epoch 138 - training loss: 0.1930, validation loss: 0.1216
2024-05-25 08:07:57 [INFO]: Epoch 139 - training loss: 0.1926, validation loss: 0.1234
2024-05-25 08:07:57 [INFO]: Epoch 140 - training loss: 0.1920, validation loss: 0.1222
2024-05-25 08:07:58 [INFO]: Epoch 141 - training loss: 0.1914, validation loss: 0.1220
2024-05-25 08:07:59 [INFO]: Epoch 142 - training loss: 0.1913, validation loss: 0.1224
2024-05-25 08:07:59 [INFO]: Epoch 143 - training loss: 0.1908, validation loss: 0.1227
2024-05-25 08:08:00 [INFO]: Epoch 144 - training loss: 0.1909, validation loss: 0.1214
2024-05-25 08:08:00 [INFO]: Epoch 145 - training loss: 0.1896, validation loss: 0.1219
2024-05-25 08:08:01 [INFO]: Epoch 146 - training loss: 0.1890, validation loss: 0.1218
2024-05-25 08:08:02 [INFO]: Epoch 147 - training loss: 0.1900, validation loss: 0.1214
2024-05-25 08:08:02 [INFO]: Epoch 148 - training loss: 0.1907, validation loss: 0.1217
2024-05-25 08:08:03 [INFO]: Epoch 149 - training loss: 0.1890, validation loss: 0.1226
2024-05-25 08:08:03 [INFO]: Epoch 150 - training loss: 0.1878, validation loss: 0.1209
2024-05-25 08:08:04 [INFO]: Epoch 151 - training loss: 0.1886, validation loss: 0.1208
2024-05-25 08:08:05 [INFO]: Epoch 152 - training loss: 0.1882, validation loss: 0.1204
2024-05-25 08:08:05 [INFO]: Epoch 153 - training loss: 0.1863, validation loss: 0.1196
2024-05-25 08:08:06 [INFO]: Epoch 154 - training loss: 0.1863, validation loss: 0.1216
2024-05-25 08:08:07 [INFO]: Epoch 155 - training loss: 0.1868, validation loss: 0.1208
2024-05-25 08:08:07 [INFO]: Epoch 156 - training loss: 0.1865, validation loss: 0.1200
2024-05-25 08:08:08 [INFO]: Epoch 157 - training loss: 0.1854, validation loss: 0.1192
2024-05-25 08:08:08 [INFO]: Epoch 158 - training loss: 0.1844, validation loss: 0.1200
2024-05-25 08:08:09 [INFO]: Epoch 159 - training loss: 0.1844, validation loss: 0.1195
2024-05-25 08:08:10 [INFO]: Epoch 160 - training loss: 0.1842, validation loss: 0.1193
2024-05-25 08:08:10 [INFO]: Epoch 161 - training loss: 0.1856, validation loss: 0.1191
2024-05-25 08:08:11 [INFO]: Epoch 162 - training loss: 0.1849, validation loss: 0.1192
2024-05-25 08:08:11 [INFO]: Epoch 163 - training loss: 0.1838, validation loss: 0.1190
2024-05-25 08:08:12 [INFO]: Epoch 164 - training loss: 0.1831, validation loss: 0.1189
2024-05-25 08:08:13 [INFO]: Epoch 165 - training loss: 0.1821, validation loss: 0.1202
2024-05-25 08:08:13 [INFO]: Epoch 166 - training loss: 0.1821, validation loss: 0.1198
2024-05-25 08:08:14 [INFO]: Epoch 167 - training loss: 0.1814, validation loss: 0.1206
2024-05-25 08:08:14 [INFO]: Epoch 168 - training loss: 0.1801, validation loss: 0.1193
2024-05-25 08:08:15 [INFO]: Epoch 169 - training loss: 0.1803, validation loss: 0.1196
2024-05-25 08:08:16 [INFO]: Epoch 170 - training loss: 0.1803, validation loss: 0.1199
2024-05-25 08:08:16 [INFO]: Epoch 171 - training loss: 0.1806, validation loss: 0.1185
2024-05-25 08:08:17 [INFO]: Epoch 172 - training loss: 0.1802, validation loss: 0.1196
2024-05-25 08:08:18 [INFO]: Epoch 173 - training loss: 0.1808, validation loss: 0.1193
2024-05-25 08:08:18 [INFO]: Epoch 174 - training loss: 0.1794, validation loss: 0.1188
2024-05-25 08:08:19 [INFO]: Epoch 175 - training loss: 0.1784, validation loss: 0.1183
2024-05-25 08:08:19 [INFO]: Epoch 176 - training loss: 0.1782, validation loss: 0.1169
2024-05-25 08:08:20 [INFO]: Epoch 177 - training loss: 0.1778, validation loss: 0.1188
2024-05-25 08:08:21 [INFO]: Epoch 178 - training loss: 0.1770, validation loss: 0.1165
2024-05-25 08:08:21 [INFO]: Epoch 179 - training loss: 0.1776, validation loss: 0.1174
2024-05-25 08:08:22 [INFO]: Epoch 180 - training loss: 0.1775, validation loss: 0.1181
2024-05-25 08:08:22 [INFO]: Epoch 181 - training loss: 0.1775, validation loss: 0.1168
2024-05-25 08:08:23 [INFO]: Epoch 182 - training loss: 0.1769, validation loss: 0.1181
2024-05-25 08:08:24 [INFO]: Epoch 183 - training loss: 0.1764, validation loss: 0.1184
2024-05-25 08:08:24 [INFO]: Epoch 184 - training loss: 0.1754, validation loss: 0.1175
2024-05-25 08:08:25 [INFO]: Epoch 185 - training loss: 0.1758, validation loss: 0.1178
2024-05-25 08:08:26 [INFO]: Epoch 186 - training loss: 0.1750, validation loss: 0.1160
2024-05-25 08:08:26 [INFO]: Epoch 187 - training loss: 0.1766, validation loss: 0.1172
2024-05-25 08:08:27 [INFO]: Epoch 188 - training loss: 0.1759, validation loss: 0.1181
2024-05-25 08:08:27 [INFO]: Epoch 189 - training loss: 0.1754, validation loss: 0.1165
2024-05-25 08:08:28 [INFO]: Epoch 190 - training loss: 0.1740, validation loss: 0.1173
2024-05-25 08:08:29 [INFO]: Epoch 191 - training loss: 0.1737, validation loss: 0.1162
2024-05-25 08:08:29 [INFO]: Epoch 192 - training loss: 0.1735, validation loss: 0.1174
2024-05-25 08:08:30 [INFO]: Epoch 193 - training loss: 0.1734, validation loss: 0.1171
2024-05-25 08:08:30 [INFO]: Epoch 194 - training loss: 0.1726, validation loss: 0.1159
2024-05-25 08:08:31 [INFO]: Epoch 195 - training loss: 0.1720, validation loss: 0.1161
2024-05-25 08:08:32 [INFO]: Epoch 196 - training loss: 0.1716, validation loss: 0.1178
2024-05-25 08:08:32 [INFO]: Epoch 197 - training loss: 0.1733, validation loss: 0.1163
2024-05-25 08:08:33 [INFO]: Epoch 198 - training loss: 0.1706, validation loss: 0.1165
2024-05-25 08:08:34 [INFO]: Epoch 199 - training loss: 0.1701, validation loss: 0.1171
2024-05-25 08:08:34 [INFO]: Epoch 200 - training loss: 0.1706, validation loss: 0.1152
2024-05-25 08:08:35 [INFO]: Epoch 201 - training loss: 0.1742, validation loss: 0.1184
2024-05-25 08:08:35 [INFO]: Epoch 202 - training loss: 0.1726, validation loss: 0.1167
2024-05-25 08:08:36 [INFO]: Epoch 203 - training loss: 0.1713, validation loss: 0.1174
2024-05-25 08:08:37 [INFO]: Epoch 204 - training loss: 0.1707, validation loss: 0.1163
2024-05-25 08:08:37 [INFO]: Epoch 205 - training loss: 0.1689, validation loss: 0.1165
2024-05-25 08:08:38 [INFO]: Epoch 206 - training loss: 0.1691, validation loss: 0.1154
2024-05-25 08:08:38 [INFO]: Epoch 207 - training loss: 0.1684, validation loss: 0.1161
2024-05-25 08:08:39 [INFO]: Epoch 208 - training loss: 0.1683, validation loss: 0.1155
2024-05-25 08:08:40 [INFO]: Epoch 209 - training loss: 0.1682, validation loss: 0.1144
2024-05-25 08:08:40 [INFO]: Epoch 210 - training loss: 0.1671, validation loss: 0.1151
2024-05-25 08:08:41 [INFO]: Epoch 211 - training loss: 0.1665, validation loss: 0.1145
2024-05-25 08:08:42 [INFO]: Epoch 212 - training loss: 0.1663, validation loss: 0.1152
2024-05-25 08:08:42 [INFO]: Epoch 213 - training loss: 0.1673, validation loss: 0.1155
2024-05-25 08:08:43 [INFO]: Epoch 214 - training loss: 0.1671, validation loss: 0.1144
2024-05-25 08:08:43 [INFO]: Epoch 215 - training loss: 0.1666, validation loss: 0.1149
2024-05-25 08:08:44 [INFO]: Epoch 216 - training loss: 0.1671, validation loss: 0.1137
2024-05-25 08:08:45 [INFO]: Epoch 217 - training loss: 0.1659, validation loss: 0.1144
2024-05-25 08:08:45 [INFO]: Epoch 218 - training loss: 0.1667, validation loss: 0.1144
2024-05-25 08:08:46 [INFO]: Epoch 219 - training loss: 0.1661, validation loss: 0.1145
2024-05-25 08:08:46 [INFO]: Epoch 220 - training loss: 0.1646, validation loss: 0.1131
2024-05-25 08:08:47 [INFO]: Epoch 221 - training loss: 0.1648, validation loss: 0.1138
2024-05-25 08:08:48 [INFO]: Epoch 222 - training loss: 0.1645, validation loss: 0.1129
2024-05-25 08:08:48 [INFO]: Epoch 223 - training loss: 0.1643, validation loss: 0.1127
2024-05-25 08:08:49 [INFO]: Epoch 224 - training loss: 0.1664, validation loss: 0.1144
2024-05-25 08:08:49 [INFO]: Epoch 225 - training loss: 0.1631, validation loss: 0.1132
2024-05-25 08:08:50 [INFO]: Epoch 226 - training loss: 0.1632, validation loss: 0.1140
2024-05-25 08:08:51 [INFO]: Epoch 227 - training loss: 0.1628, validation loss: 0.1142
2024-05-25 08:08:51 [INFO]: Epoch 228 - training loss: 0.1634, validation loss: 0.1136
2024-05-25 08:08:52 [INFO]: Epoch 229 - training loss: 0.1626, validation loss: 0.1131
2024-05-25 08:08:53 [INFO]: Epoch 230 - training loss: 0.1649, validation loss: 0.1146
2024-05-25 08:08:53 [INFO]: Epoch 231 - training loss: 0.1623, validation loss: 0.1126
2024-05-25 08:08:54 [INFO]: Epoch 232 - training loss: 0.1624, validation loss: 0.1138
2024-05-25 08:08:54 [INFO]: Epoch 233 - training loss: 0.1609, validation loss: 0.1136
2024-05-25 08:08:55 [INFO]: Epoch 234 - training loss: 0.1611, validation loss: 0.1137
2024-05-25 08:08:56 [INFO]: Epoch 235 - training loss: 0.1616, validation loss: 0.1120
2024-05-25 08:08:56 [INFO]: Epoch 236 - training loss: 0.1613, validation loss: 0.1131
2024-05-25 08:08:57 [INFO]: Epoch 237 - training loss: 0.1613, validation loss: 0.1116
2024-05-25 08:08:57 [INFO]: Epoch 238 - training loss: 0.1613, validation loss: 0.1128
2024-05-25 08:08:58 [INFO]: Epoch 239 - training loss: 0.1603, validation loss: 0.1141
2024-05-25 08:08:59 [INFO]: Epoch 240 - training loss: 0.1601, validation loss: 0.1125
2024-05-25 08:08:59 [INFO]: Epoch 241 - training loss: 0.1607, validation loss: 0.1132
2024-05-25 08:09:00 [INFO]: Epoch 242 - training loss: 0.1602, validation loss: 0.1143
2024-05-25 08:09:01 [INFO]: Epoch 243 - training loss: 0.1597, validation loss: 0.1134
2024-05-25 08:09:01 [INFO]: Epoch 244 - training loss: 0.1588, validation loss: 0.1126
2024-05-25 08:09:02 [INFO]: Epoch 245 - training loss: 0.1590, validation loss: 0.1143
2024-05-25 08:09:02 [INFO]: Epoch 246 - training loss: 0.1600, validation loss: 0.1125
2024-05-25 08:09:03 [INFO]: Epoch 247 - training loss: 0.1597, validation loss: 0.1129
2024-05-25 08:09:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 08:09:03 [INFO]: Finished training. The best model is from epoch#237.
2024-05-25 08:09:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/SAITS_air_quality/20240525_T080631/SAITS.pypots
2024-05-25 08:09:03 [INFO]: SAITS on Air-Quality: MAE=0.1503, MSE=0.2160
2024-05-25 08:09:03 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/SAITS_air_quality/imputation.pkl
2024-05-25 08:09:03 [INFO]: Using the given device: cuda:0
2024-05-25 08:09:03 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/Transformer_air_quality/20240525_T080903
2024-05-25 08:09:03 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/Transformer_air_quality/20240525_T080903/tensorboard
2024-05-25 08:09:03 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 08:09:04 [INFO]: Epoch 001 - training loss: 0.8956, validation loss: 0.4642
2024-05-25 08:09:04 [INFO]: Epoch 002 - training loss: 0.5551, validation loss: 0.3421
2024-05-25 08:09:04 [INFO]: Epoch 003 - training loss: 0.4648, validation loss: 0.2948
2024-05-25 08:09:04 [INFO]: Epoch 004 - training loss: 0.4197, validation loss: 0.2686
2024-05-25 08:09:05 [INFO]: Epoch 005 - training loss: 0.3869, validation loss: 0.2529
2024-05-25 08:09:05 [INFO]: Epoch 006 - training loss: 0.3647, validation loss: 0.2403
2024-05-25 08:09:05 [INFO]: Epoch 007 - training loss: 0.3483, validation loss: 0.2342
2024-05-25 08:09:05 [INFO]: Epoch 008 - training loss: 0.3376, validation loss: 0.2270
2024-05-25 08:09:06 [INFO]: Epoch 009 - training loss: 0.3249, validation loss: 0.2210
2024-05-25 08:09:06 [INFO]: Epoch 010 - training loss: 0.3147, validation loss: 0.2138
2024-05-25 08:09:06 [INFO]: Epoch 011 - training loss: 0.3088, validation loss: 0.2100
2024-05-25 08:09:06 [INFO]: Epoch 012 - training loss: 0.3036, validation loss: 0.2053
2024-05-25 08:09:07 [INFO]: Epoch 013 - training loss: 0.2989, validation loss: 0.2059
2024-05-25 08:09:07 [INFO]: Epoch 014 - training loss: 0.2928, validation loss: 0.2005
2024-05-25 08:09:07 [INFO]: Epoch 015 - training loss: 0.2873, validation loss: 0.1950
2024-05-25 08:09:07 [INFO]: Epoch 016 - training loss: 0.2830, validation loss: 0.1938
2024-05-25 08:09:08 [INFO]: Epoch 017 - training loss: 0.2786, validation loss: 0.1893
2024-05-25 08:09:08 [INFO]: Epoch 018 - training loss: 0.2741, validation loss: 0.1854
2024-05-25 08:09:08 [INFO]: Epoch 019 - training loss: 0.2691, validation loss: 0.1837
2024-05-25 08:09:08 [INFO]: Epoch 020 - training loss: 0.2664, validation loss: 0.1832
2024-05-25 08:09:09 [INFO]: Epoch 021 - training loss: 0.2645, validation loss: 0.1796
2024-05-25 08:09:09 [INFO]: Epoch 022 - training loss: 0.2614, validation loss: 0.1786
2024-05-25 08:09:09 [INFO]: Epoch 023 - training loss: 0.2583, validation loss: 0.1771
2024-05-25 08:09:09 [INFO]: Epoch 024 - training loss: 0.2564, validation loss: 0.1777
2024-05-25 08:09:10 [INFO]: Epoch 025 - training loss: 0.2546, validation loss: 0.1741
2024-05-25 08:09:10 [INFO]: Epoch 026 - training loss: 0.2488, validation loss: 0.1734
2024-05-25 08:09:10 [INFO]: Epoch 027 - training loss: 0.2468, validation loss: 0.1733
2024-05-25 08:09:10 [INFO]: Epoch 028 - training loss: 0.2467, validation loss: 0.1712
2024-05-25 08:09:11 [INFO]: Epoch 029 - training loss: 0.2432, validation loss: 0.1700
2024-05-25 08:09:11 [INFO]: Epoch 030 - training loss: 0.2451, validation loss: 0.1694
2024-05-25 08:09:11 [INFO]: Epoch 031 - training loss: 0.2432, validation loss: 0.1676
2024-05-25 08:09:11 [INFO]: Epoch 032 - training loss: 0.2378, validation loss: 0.1686
2024-05-25 08:09:12 [INFO]: Epoch 033 - training loss: 0.2356, validation loss: 0.1700
2024-05-25 08:09:12 [INFO]: Epoch 034 - training loss: 0.2335, validation loss: 0.1667
2024-05-25 08:09:12 [INFO]: Epoch 035 - training loss: 0.2343, validation loss: 0.1675
2024-05-25 08:09:12 [INFO]: Epoch 036 - training loss: 0.2293, validation loss: 0.1633
2024-05-25 08:09:13 [INFO]: Epoch 037 - training loss: 0.2273, validation loss: 0.1639
2024-05-25 08:09:13 [INFO]: Epoch 038 - training loss: 0.2261, validation loss: 0.1634
2024-05-25 08:09:13 [INFO]: Epoch 039 - training loss: 0.2258, validation loss: 0.1644
2024-05-25 08:09:14 [INFO]: Epoch 040 - training loss: 0.2233, validation loss: 0.1611
2024-05-25 08:09:14 [INFO]: Epoch 041 - training loss: 0.2210, validation loss: 0.1625
2024-05-25 08:09:14 [INFO]: Epoch 042 - training loss: 0.2181, validation loss: 0.1624
2024-05-25 08:09:14 [INFO]: Epoch 043 - training loss: 0.2183, validation loss: 0.1604
2024-05-25 08:09:15 [INFO]: Epoch 044 - training loss: 0.2184, validation loss: 0.1586
2024-05-25 08:09:15 [INFO]: Epoch 045 - training loss: 0.2152, validation loss: 0.1602
2024-05-25 08:09:15 [INFO]: Epoch 046 - training loss: 0.2141, validation loss: 0.1593
2024-05-25 08:09:15 [INFO]: Epoch 047 - training loss: 0.2131, validation loss: 0.1578
2024-05-25 08:09:16 [INFO]: Epoch 048 - training loss: 0.2106, validation loss: 0.1583
2024-05-25 08:09:16 [INFO]: Epoch 049 - training loss: 0.2090, validation loss: 0.1604
2024-05-25 08:09:16 [INFO]: Epoch 050 - training loss: 0.2110, validation loss: 0.1584
2024-05-25 08:09:16 [INFO]: Epoch 051 - training loss: 0.2098, validation loss: 0.1579
2024-05-25 08:09:17 [INFO]: Epoch 052 - training loss: 0.2069, validation loss: 0.1564
2024-05-25 08:09:17 [INFO]: Epoch 053 - training loss: 0.2045, validation loss: 0.1556
2024-05-25 08:09:17 [INFO]: Epoch 054 - training loss: 0.2039, validation loss: 0.1560
2024-05-25 08:09:17 [INFO]: Epoch 055 - training loss: 0.2030, validation loss: 0.1552
2024-05-25 08:09:18 [INFO]: Epoch 056 - training loss: 0.2003, validation loss: 0.1571
2024-05-25 08:09:18 [INFO]: Epoch 057 - training loss: 0.1989, validation loss: 0.1565
2024-05-25 08:09:18 [INFO]: Epoch 058 - training loss: 0.1986, validation loss: 0.1524
2024-05-25 08:09:18 [INFO]: Epoch 059 - training loss: 0.1980, validation loss: 0.1523
2024-05-25 08:09:19 [INFO]: Epoch 060 - training loss: 0.1964, validation loss: 0.1516
2024-05-25 08:09:19 [INFO]: Epoch 061 - training loss: 0.1952, validation loss: 0.1526
2024-05-25 08:09:19 [INFO]: Epoch 062 - training loss: 0.1956, validation loss: 0.1520
2024-05-25 08:09:19 [INFO]: Epoch 063 - training loss: 0.1944, validation loss: 0.1521
2024-05-25 08:09:20 [INFO]: Epoch 064 - training loss: 0.1946, validation loss: 0.1513
2024-05-25 08:09:20 [INFO]: Epoch 065 - training loss: 0.1943, validation loss: 0.1517
2024-05-25 08:09:20 [INFO]: Epoch 066 - training loss: 0.1924, validation loss: 0.1517
2024-05-25 08:09:20 [INFO]: Epoch 067 - training loss: 0.1913, validation loss: 0.1511
2024-05-25 08:09:21 [INFO]: Epoch 068 - training loss: 0.1903, validation loss: 0.1488
2024-05-25 08:09:21 [INFO]: Epoch 069 - training loss: 0.1913, validation loss: 0.1502
2024-05-25 08:09:21 [INFO]: Epoch 070 - training loss: 0.1904, validation loss: 0.1487
2024-05-25 08:09:21 [INFO]: Epoch 071 - training loss: 0.1878, validation loss: 0.1487
2024-05-25 08:09:22 [INFO]: Epoch 072 - training loss: 0.1861, validation loss: 0.1476
2024-05-25 08:09:22 [INFO]: Epoch 073 - training loss: 0.1879, validation loss: 0.1495
2024-05-25 08:09:22 [INFO]: Epoch 074 - training loss: 0.1861, validation loss: 0.1488
2024-05-25 08:09:22 [INFO]: Epoch 075 - training loss: 0.1833, validation loss: 0.1488
2024-05-25 08:09:23 [INFO]: Epoch 076 - training loss: 0.1820, validation loss: 0.1480
2024-05-25 08:09:23 [INFO]: Epoch 077 - training loss: 0.1829, validation loss: 0.1491
2024-05-25 08:09:23 [INFO]: Epoch 078 - training loss: 0.1809, validation loss: 0.1464
2024-05-25 08:09:23 [INFO]: Epoch 079 - training loss: 0.1800, validation loss: 0.1470
2024-05-25 08:09:24 [INFO]: Epoch 080 - training loss: 0.1786, validation loss: 0.1468
2024-05-25 08:09:24 [INFO]: Epoch 081 - training loss: 0.1774, validation loss: 0.1462
2024-05-25 08:09:24 [INFO]: Epoch 082 - training loss: 0.1770, validation loss: 0.1474
2024-05-25 08:09:24 [INFO]: Epoch 083 - training loss: 0.1770, validation loss: 0.1463
2024-05-25 08:09:25 [INFO]: Epoch 084 - training loss: 0.1756, validation loss: 0.1454
2024-05-25 08:09:25 [INFO]: Epoch 085 - training loss: 0.1756, validation loss: 0.1483
2024-05-25 08:09:25 [INFO]: Epoch 086 - training loss: 0.1753, validation loss: 0.1455
2024-05-25 08:09:25 [INFO]: Epoch 087 - training loss: 0.1748, validation loss: 0.1457
2024-05-25 08:09:26 [INFO]: Epoch 088 - training loss: 0.1727, validation loss: 0.1429
2024-05-25 08:09:26 [INFO]: Epoch 089 - training loss: 0.1706, validation loss: 0.1443
2024-05-25 08:09:26 [INFO]: Epoch 090 - training loss: 0.1725, validation loss: 0.1430
2024-05-25 08:09:26 [INFO]: Epoch 091 - training loss: 0.1709, validation loss: 0.1433
2024-05-25 08:09:27 [INFO]: Epoch 092 - training loss: 0.1693, validation loss: 0.1443
2024-05-25 08:09:27 [INFO]: Epoch 093 - training loss: 0.1673, validation loss: 0.1431
2024-05-25 08:09:27 [INFO]: Epoch 094 - training loss: 0.1700, validation loss: 0.1435
2024-05-25 08:09:27 [INFO]: Epoch 095 - training loss: 0.1696, validation loss: 0.1442
2024-05-25 08:09:28 [INFO]: Epoch 096 - training loss: 0.1685, validation loss: 0.1433
2024-05-25 08:09:28 [INFO]: Epoch 097 - training loss: 0.1673, validation loss: 0.1422
2024-05-25 08:09:28 [INFO]: Epoch 098 - training loss: 0.1655, validation loss: 0.1422
2024-05-25 08:09:28 [INFO]: Epoch 099 - training loss: 0.1682, validation loss: 0.1441
2024-05-25 08:09:29 [INFO]: Epoch 100 - training loss: 0.1685, validation loss: 0.1427
2024-05-25 08:09:29 [INFO]: Epoch 101 - training loss: 0.1658, validation loss: 0.1443
2024-05-25 08:09:29 [INFO]: Epoch 102 - training loss: 0.1635, validation loss: 0.1422
2024-05-25 08:09:29 [INFO]: Epoch 103 - training loss: 0.1627, validation loss: 0.1416
2024-05-25 08:09:30 [INFO]: Epoch 104 - training loss: 0.1642, validation loss: 0.1418
2024-05-25 08:09:30 [INFO]: Epoch 105 - training loss: 0.1622, validation loss: 0.1427
2024-05-25 08:09:30 [INFO]: Epoch 106 - training loss: 0.1620, validation loss: 0.1409
2024-05-25 08:09:31 [INFO]: Epoch 107 - training loss: 0.1607, validation loss: 0.1406
2024-05-25 08:09:31 [INFO]: Epoch 108 - training loss: 0.1602, validation loss: 0.1413
2024-05-25 08:09:31 [INFO]: Epoch 109 - training loss: 0.1597, validation loss: 0.1397
2024-05-25 08:09:31 [INFO]: Epoch 110 - training loss: 0.1595, validation loss: 0.1399
2024-05-25 08:09:32 [INFO]: Epoch 111 - training loss: 0.1573, validation loss: 0.1404
2024-05-25 08:09:32 [INFO]: Epoch 112 - training loss: 0.1562, validation loss: 0.1391
2024-05-25 08:09:32 [INFO]: Epoch 113 - training loss: 0.1606, validation loss: 0.1395
2024-05-25 08:09:32 [INFO]: Epoch 114 - training loss: 0.1610, validation loss: 0.1407
2024-05-25 08:09:33 [INFO]: Epoch 115 - training loss: 0.1558, validation loss: 0.1400
2024-05-25 08:09:33 [INFO]: Epoch 116 - training loss: 0.1541, validation loss: 0.1393
2024-05-25 08:09:33 [INFO]: Epoch 117 - training loss: 0.1555, validation loss: 0.1402
2024-05-25 08:09:33 [INFO]: Epoch 118 - training loss: 0.1550, validation loss: 0.1397
2024-05-25 08:09:34 [INFO]: Epoch 119 - training loss: 0.1544, validation loss: 0.1381
2024-05-25 08:09:34 [INFO]: Epoch 120 - training loss: 0.1531, validation loss: 0.1374
2024-05-25 08:09:34 [INFO]: Epoch 121 - training loss: 0.1574, validation loss: 0.1376
2024-05-25 08:09:34 [INFO]: Epoch 122 - training loss: 0.1536, validation loss: 0.1378
2024-05-25 08:09:35 [INFO]: Epoch 123 - training loss: 0.1516, validation loss: 0.1375
2024-05-25 08:09:35 [INFO]: Epoch 124 - training loss: 0.1525, validation loss: 0.1399
2024-05-25 08:09:35 [INFO]: Epoch 125 - training loss: 0.1523, validation loss: 0.1380
2024-05-25 08:09:35 [INFO]: Epoch 126 - training loss: 0.1521, validation loss: 0.1366
2024-05-25 08:09:36 [INFO]: Epoch 127 - training loss: 0.1527, validation loss: 0.1376
2024-05-25 08:09:36 [INFO]: Epoch 128 - training loss: 0.1497, validation loss: 0.1388
2024-05-25 08:09:36 [INFO]: Epoch 129 - training loss: 0.1501, validation loss: 0.1373
2024-05-25 08:09:36 [INFO]: Epoch 130 - training loss: 0.1482, validation loss: 0.1390
2024-05-25 08:09:37 [INFO]: Epoch 131 - training loss: 0.1491, validation loss: 0.1368
2024-05-25 08:09:37 [INFO]: Epoch 132 - training loss: 0.1495, validation loss: 0.1364
2024-05-25 08:09:37 [INFO]: Epoch 133 - training loss: 0.1483, validation loss: 0.1387
2024-05-25 08:09:37 [INFO]: Epoch 134 - training loss: 0.1479, validation loss: 0.1378
2024-05-25 08:09:38 [INFO]: Epoch 135 - training loss: 0.1473, validation loss: 0.1381
2024-05-25 08:09:38 [INFO]: Epoch 136 - training loss: 0.1453, validation loss: 0.1367
2024-05-25 08:09:38 [INFO]: Epoch 137 - training loss: 0.1462, validation loss: 0.1368
2024-05-25 08:09:38 [INFO]: Epoch 138 - training loss: 0.1460, validation loss: 0.1368
2024-05-25 08:09:39 [INFO]: Epoch 139 - training loss: 0.1476, validation loss: 0.1380
2024-05-25 08:09:39 [INFO]: Epoch 140 - training loss: 0.1457, validation loss: 0.1384
2024-05-25 08:09:39 [INFO]: Epoch 141 - training loss: 0.1452, validation loss: 0.1369
2024-05-25 08:09:39 [INFO]: Epoch 142 - training loss: 0.1447, validation loss: 0.1368
2024-05-25 08:09:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 08:09:39 [INFO]: Finished training. The best model is from epoch#132.
2024-05-25 08:09:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/Transformer_air_quality/20240525_T080903/Transformer.pypots
2024-05-25 08:09:39 [INFO]: Transformer on Air-Quality: MAE=0.1677, MSE=0.2524
2024-05-25 08:09:39 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Transformer_air_quality/imputation.pkl
2024-05-25 08:09:39 [INFO]: Using the given device: cuda:0
2024-05-25 08:09:39 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/TimesNet_air_quality/20240525_T080939
2024-05-25 08:09:39 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/TimesNet_air_quality/20240525_T080939/tensorboard
2024-05-25 08:09:40 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 08:09:40 [INFO]: Epoch 001 - training loss: 0.3111, validation loss: 0.2979
2024-05-25 08:09:41 [INFO]: Epoch 002 - training loss: 0.2440, validation loss: 0.2641
2024-05-25 08:09:41 [INFO]: Epoch 003 - training loss: 0.2043, validation loss: 0.2381
2024-05-25 08:09:42 [INFO]: Epoch 004 - training loss: 0.1749, validation loss: 0.2268
2024-05-25 08:09:42 [INFO]: Epoch 005 - training loss: 0.1555, validation loss: 0.2154
2024-05-25 08:09:43 [INFO]: Epoch 006 - training loss: 0.1490, validation loss: 0.2082
2024-05-25 08:09:43 [INFO]: Epoch 007 - training loss: 0.1415, validation loss: 0.2057
2024-05-25 08:09:44 [INFO]: Epoch 008 - training loss: 0.1359, validation loss: 0.2022
2024-05-25 08:09:44 [INFO]: Epoch 009 - training loss: 0.1393, validation loss: 0.1963
2024-05-25 08:09:44 [INFO]: Epoch 010 - training loss: 0.1256, validation loss: 0.1946
2024-05-25 08:09:45 [INFO]: Epoch 011 - training loss: 0.1225, validation loss: 0.1938
2024-05-25 08:09:45 [INFO]: Epoch 012 - training loss: 0.1153, validation loss: 0.1905
2024-05-25 08:09:46 [INFO]: Epoch 013 - training loss: 0.1158, validation loss: 0.1900
2024-05-25 08:09:46 [INFO]: Epoch 014 - training loss: 0.1312, validation loss: 0.1965
2024-05-25 08:09:47 [INFO]: Epoch 015 - training loss: 0.1260, validation loss: 0.1853
2024-05-25 08:09:47 [INFO]: Epoch 016 - training loss: 0.1124, validation loss: 0.1853
2024-05-25 08:09:48 [INFO]: Epoch 017 - training loss: 0.1052, validation loss: 0.1862
2024-05-25 08:09:48 [INFO]: Epoch 018 - training loss: 0.1025, validation loss: 0.1810
2024-05-25 08:09:49 [INFO]: Epoch 019 - training loss: 0.0970, validation loss: 0.1832
2024-05-25 08:09:49 [INFO]: Epoch 020 - training loss: 0.0961, validation loss: 0.1799
2024-05-25 08:09:50 [INFO]: Epoch 021 - training loss: 0.0918, validation loss: 0.1818
2024-05-25 08:09:50 [INFO]: Epoch 022 - training loss: 0.0931, validation loss: 0.1750
2024-05-25 08:09:51 [INFO]: Epoch 023 - training loss: 0.0849, validation loss: 0.1766
2024-05-25 08:09:51 [INFO]: Epoch 024 - training loss: 0.0802, validation loss: 0.1750
2024-05-25 08:09:52 [INFO]: Epoch 025 - training loss: 0.0775, validation loss: 0.1756
2024-05-25 08:09:52 [INFO]: Epoch 026 - training loss: 0.0780, validation loss: 0.1740
2024-05-25 08:09:53 [INFO]: Epoch 027 - training loss: 0.0813, validation loss: 0.1776
2024-05-25 08:09:53 [INFO]: Epoch 028 - training loss: 0.0754, validation loss: 0.1741
2024-05-25 08:09:53 [INFO]: Epoch 029 - training loss: 0.0754, validation loss: 0.1726
2024-05-25 08:09:54 [INFO]: Epoch 030 - training loss: 0.0738, validation loss: 0.1707
2024-05-25 08:09:54 [INFO]: Epoch 031 - training loss: 0.0738, validation loss: 0.1745
2024-05-25 08:09:55 [INFO]: Epoch 032 - training loss: 0.0711, validation loss: 0.1701
2024-05-25 08:09:55 [INFO]: Epoch 033 - training loss: 0.0686, validation loss: 0.1712
2024-05-25 08:09:56 [INFO]: Epoch 034 - training loss: 0.0667, validation loss: 0.1693
2024-05-25 08:09:56 [INFO]: Epoch 035 - training loss: 0.0687, validation loss: 0.1695
2024-05-25 08:09:57 [INFO]: Epoch 036 - training loss: 0.0665, validation loss: 0.1699
2024-05-25 08:09:57 [INFO]: Epoch 037 - training loss: 0.0650, validation loss: 0.1714
2024-05-25 08:09:58 [INFO]: Epoch 038 - training loss: 0.0643, validation loss: 0.1676
2024-05-25 08:09:58 [INFO]: Epoch 039 - training loss: 0.0621, validation loss: 0.1685
2024-05-25 08:09:59 [INFO]: Epoch 040 - training loss: 0.0621, validation loss: 0.1691
2024-05-25 08:09:59 [INFO]: Epoch 041 - training loss: 0.0622, validation loss: 0.1723
2024-05-25 08:10:00 [INFO]: Epoch 042 - training loss: 0.0669, validation loss: 0.1688
2024-05-25 08:10:00 [INFO]: Epoch 043 - training loss: 0.0640, validation loss: 0.1715
2024-05-25 08:10:01 [INFO]: Epoch 044 - training loss: 0.0593, validation loss: 0.1682
2024-05-25 08:10:01 [INFO]: Epoch 045 - training loss: 0.0567, validation loss: 0.1661
2024-05-25 08:10:01 [INFO]: Epoch 046 - training loss: 0.0558, validation loss: 0.1659
2024-05-25 08:10:02 [INFO]: Epoch 047 - training loss: 0.0567, validation loss: 0.1681
2024-05-25 08:10:02 [INFO]: Epoch 048 - training loss: 0.0563, validation loss: 0.1678
2024-05-25 08:10:03 [INFO]: Epoch 049 - training loss: 0.0537, validation loss: 0.1666
2024-05-25 08:10:03 [INFO]: Epoch 050 - training loss: 0.0525, validation loss: 0.1713
2024-05-25 08:10:04 [INFO]: Epoch 051 - training loss: 0.0533, validation loss: 0.1669
2024-05-25 08:10:04 [INFO]: Epoch 052 - training loss: 0.0539, validation loss: 0.1677
2024-05-25 08:10:05 [INFO]: Epoch 053 - training loss: 0.0562, validation loss: 0.1689
2024-05-25 08:10:05 [INFO]: Epoch 054 - training loss: 0.0526, validation loss: 0.1706
2024-05-25 08:10:06 [INFO]: Epoch 055 - training loss: 0.0533, validation loss: 0.1681
2024-05-25 08:10:06 [INFO]: Epoch 056 - training loss: 0.0534, validation loss: 0.1649
2024-05-25 08:10:07 [INFO]: Epoch 057 - training loss: 0.0542, validation loss: 0.1709
2024-05-25 08:10:07 [INFO]: Epoch 058 - training loss: 0.0510, validation loss: 0.1693
2024-05-25 08:10:08 [INFO]: Epoch 059 - training loss: 0.0507, validation loss: 0.1702
2024-05-25 08:10:08 [INFO]: Epoch 060 - training loss: 0.0517, validation loss: 0.1668
2024-05-25 08:10:08 [INFO]: Epoch 061 - training loss: 0.0512, validation loss: 0.1661
2024-05-25 08:10:09 [INFO]: Epoch 062 - training loss: 0.0467, validation loss: 0.1679
2024-05-25 08:10:09 [INFO]: Epoch 063 - training loss: 0.0457, validation loss: 0.1667
2024-05-25 08:10:10 [INFO]: Epoch 064 - training loss: 0.0466, validation loss: 0.1704
2024-05-25 08:10:10 [INFO]: Epoch 065 - training loss: 0.0462, validation loss: 0.1655
2024-05-25 08:10:11 [INFO]: Epoch 066 - training loss: 0.0447, validation loss: 0.1687
2024-05-25 08:10:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 08:10:11 [INFO]: Finished training. The best model is from epoch#56.
2024-05-25 08:10:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/TimesNet_air_quality/20240525_T080939/TimesNet.pypots
2024-05-25 08:10:11 [INFO]: TimesNet on Air-Quality: MAE=0.1700, MSE=0.3150
2024-05-25 08:10:11 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/TimesNet_air_quality/imputation.pkl
2024-05-25 08:10:11 [INFO]: Using the given device: cuda:0
2024-05-25 08:10:11 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011
2024-05-25 08:10:11 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/tensorboard
2024-05-25 08:10:11 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 08:10:28 [INFO]: Epoch 001 - training loss: 0.5259, validation loss: 0.3410
2024-05-25 08:10:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch1_loss0.34104551672935485.pypots
2024-05-25 08:10:45 [INFO]: Epoch 002 - training loss: 0.3134, validation loss: 0.2659
2024-05-25 08:10:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch2_loss0.26590547114610674.pypots
2024-05-25 08:11:01 [INFO]: Epoch 003 - training loss: 0.2428, validation loss: 0.2389
2024-05-25 08:11:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch3_loss0.23894063532352447.pypots
2024-05-25 08:11:18 [INFO]: Epoch 004 - training loss: 0.2245, validation loss: 0.1985
2024-05-25 08:11:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch4_loss0.19845446348190307.pypots
2024-05-25 08:11:35 [INFO]: Epoch 005 - training loss: 0.2139, validation loss: 0.1861
2024-05-25 08:11:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch5_loss0.1860770270228386.pypots
2024-05-25 08:11:52 [INFO]: Epoch 006 - training loss: 0.1882, validation loss: 0.1812
2024-05-25 08:11:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch6_loss0.18115179985761642.pypots
2024-05-25 08:12:08 [INFO]: Epoch 007 - training loss: 0.1793, validation loss: 0.1665
2024-05-25 08:12:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch7_loss0.16654425412416457.pypots
2024-05-25 08:12:25 [INFO]: Epoch 008 - training loss: 0.1748, validation loss: 0.1609
2024-05-25 08:12:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch8_loss0.16090807020664216.pypots
2024-05-25 08:12:42 [INFO]: Epoch 009 - training loss: 0.1540, validation loss: 0.1589
2024-05-25 08:12:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch9_loss0.15885769277811052.pypots
2024-05-25 08:12:59 [INFO]: Epoch 010 - training loss: 0.1656, validation loss: 0.1611
2024-05-25 08:12:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch10_loss0.1611171245574951.pypots
2024-05-25 08:13:15 [INFO]: Epoch 011 - training loss: 0.1675, validation loss: 0.1619
2024-05-25 08:13:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch11_loss0.16190448105335237.pypots
2024-05-25 08:13:32 [INFO]: Epoch 012 - training loss: 0.1543, validation loss: 0.1581
2024-05-25 08:13:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch12_loss0.15809931606054306.pypots
2024-05-25 08:13:49 [INFO]: Epoch 013 - training loss: 0.1665, validation loss: 0.1514
2024-05-25 08:13:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch13_loss0.1513560652732849.pypots
2024-05-25 08:14:06 [INFO]: Epoch 014 - training loss: 0.1792, validation loss: 0.1476
2024-05-25 08:14:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch14_loss0.14757640063762664.pypots
2024-05-25 08:14:23 [INFO]: Epoch 015 - training loss: 0.1511, validation loss: 0.1490
2024-05-25 08:14:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch15_loss0.14895461797714232.pypots
2024-05-25 08:14:39 [INFO]: Epoch 016 - training loss: 0.1638, validation loss: 0.1475
2024-05-25 08:14:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch16_loss0.14750640988349914.pypots
2024-05-25 08:14:56 [INFO]: Epoch 017 - training loss: 0.1565, validation loss: 0.1479
2024-05-25 08:14:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch17_loss0.14794733077287675.pypots
2024-05-25 08:15:13 [INFO]: Epoch 018 - training loss: 0.1406, validation loss: 0.1445
2024-05-25 08:15:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch18_loss0.14448330849409102.pypots
2024-05-25 08:15:30 [INFO]: Epoch 019 - training loss: 0.1340, validation loss: 0.1425
2024-05-25 08:15:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch19_loss0.14246972501277924.pypots
2024-05-25 08:15:46 [INFO]: Epoch 020 - training loss: 0.1401, validation loss: 0.1497
2024-05-25 08:15:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch20_loss0.14974678456783294.pypots
2024-05-25 08:16:03 [INFO]: Epoch 021 - training loss: 0.1472, validation loss: 0.1382
2024-05-25 08:16:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch21_loss0.1381625011563301.pypots
2024-05-25 08:16:20 [INFO]: Epoch 022 - training loss: 0.1448, validation loss: 0.1362
2024-05-25 08:16:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch22_loss0.13617643490433692.pypots
2024-05-25 08:16:37 [INFO]: Epoch 023 - training loss: 0.1349, validation loss: 0.1390
2024-05-25 08:16:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch23_loss0.13895378559827803.pypots
2024-05-25 08:16:53 [INFO]: Epoch 024 - training loss: 0.1451, validation loss: 0.1375
2024-05-25 08:16:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch24_loss0.13751246333122252.pypots
2024-05-25 08:17:10 [INFO]: Epoch 025 - training loss: 0.1311, validation loss: 0.1372
2024-05-25 08:17:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch25_loss0.1371520794928074.pypots
2024-05-25 08:17:27 [INFO]: Epoch 026 - training loss: 0.1602, validation loss: 0.1350
2024-05-25 08:17:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch26_loss0.1349612832069397.pypots
2024-05-25 08:17:44 [INFO]: Epoch 027 - training loss: 0.1304, validation loss: 0.1320
2024-05-25 08:17:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch27_loss0.13197841197252275.pypots
2024-05-25 08:18:00 [INFO]: Epoch 028 - training loss: 0.1467, validation loss: 0.1336
2024-05-25 08:18:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch28_loss0.13358715027570725.pypots
2024-05-25 08:18:17 [INFO]: Epoch 029 - training loss: 0.1337, validation loss: 0.1336
2024-05-25 08:18:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch29_loss0.13363064154982568.pypots
2024-05-25 08:18:34 [INFO]: Epoch 030 - training loss: 0.1360, validation loss: 0.1354
2024-05-25 08:18:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch30_loss0.13535884618759156.pypots
2024-05-25 08:18:51 [INFO]: Epoch 031 - training loss: 0.1359, validation loss: 0.1371
2024-05-25 08:18:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch31_loss0.13711178600788115.pypots
2024-05-25 08:19:07 [INFO]: Epoch 032 - training loss: 0.1312, validation loss: 0.1327
2024-05-25 08:19:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch32_loss0.1326766885817051.pypots
2024-05-25 08:19:24 [INFO]: Epoch 033 - training loss: 0.1359, validation loss: 0.1344
2024-05-25 08:19:24 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch33_loss0.1343923345208168.pypots
2024-05-25 08:19:41 [INFO]: Epoch 034 - training loss: 0.1343, validation loss: 0.1295
2024-05-25 08:19:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch34_loss0.12954428195953369.pypots
2024-05-25 08:19:58 [INFO]: Epoch 035 - training loss: 0.1308, validation loss: 0.1306
2024-05-25 08:19:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch35_loss0.13061907291412353.pypots
2024-05-25 08:20:14 [INFO]: Epoch 036 - training loss: 0.1210, validation loss: 0.1299
2024-05-25 08:20:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch36_loss0.12991356551647187.pypots
2024-05-25 08:20:31 [INFO]: Epoch 037 - training loss: 0.1341, validation loss: 0.1293
2024-05-25 08:20:31 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch37_loss0.12928355261683463.pypots
2024-05-25 08:20:48 [INFO]: Epoch 038 - training loss: 0.1397, validation loss: 0.1287
2024-05-25 08:20:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch38_loss0.12865503281354904.pypots
2024-05-25 08:21:05 [INFO]: Epoch 039 - training loss: 0.1194, validation loss: 0.1325
2024-05-25 08:21:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch39_loss0.13251033201813697.pypots
2024-05-25 08:21:21 [INFO]: Epoch 040 - training loss: 0.1531, validation loss: 0.1286
2024-05-25 08:21:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch40_loss0.12860737293958663.pypots
2024-05-25 08:21:38 [INFO]: Epoch 041 - training loss: 0.1455, validation loss: 0.1331
2024-05-25 08:21:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch41_loss0.1331239677965641.pypots
2024-05-25 08:21:55 [INFO]: Epoch 042 - training loss: 0.1410, validation loss: 0.1281
2024-05-25 08:21:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch42_loss0.12807784453034401.pypots
2024-05-25 08:22:12 [INFO]: Epoch 043 - training loss: 0.1188, validation loss: 0.1259
2024-05-25 08:22:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch43_loss0.1259452573955059.pypots
2024-05-25 08:22:28 [INFO]: Epoch 044 - training loss: 0.1240, validation loss: 0.1259
2024-05-25 08:22:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch44_loss0.12586212456226348.pypots
2024-05-25 08:22:45 [INFO]: Epoch 045 - training loss: 0.1311, validation loss: 0.1326
2024-05-25 08:22:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch45_loss0.13262961506843568.pypots
2024-05-25 08:23:02 [INFO]: Epoch 046 - training loss: 0.1307, validation loss: 0.1238
2024-05-25 08:23:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch46_loss0.12379623651504516.pypots
2024-05-25 08:23:19 [INFO]: Epoch 047 - training loss: 0.1223, validation loss: 0.1244
2024-05-25 08:23:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch47_loss0.12438689842820168.pypots
2024-05-25 08:23:35 [INFO]: Epoch 048 - training loss: 0.1189, validation loss: 0.1251
2024-05-25 08:23:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch48_loss0.12513405233621597.pypots
2024-05-25 08:23:52 [INFO]: Epoch 049 - training loss: 0.1096, validation loss: 0.1250
2024-05-25 08:23:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch49_loss0.12497870624065399.pypots
2024-05-25 08:24:09 [INFO]: Epoch 050 - training loss: 0.1093, validation loss: 0.1223
2024-05-25 08:24:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch50_loss0.12225846126675606.pypots
2024-05-25 08:24:26 [INFO]: Epoch 051 - training loss: 0.1140, validation loss: 0.1235
2024-05-25 08:24:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch51_loss0.1235092282295227.pypots
2024-05-25 08:24:42 [INFO]: Epoch 052 - training loss: 0.1137, validation loss: 0.1222
2024-05-25 08:24:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch52_loss0.12222773805260659.pypots
2024-05-25 08:24:59 [INFO]: Epoch 053 - training loss: 0.1276, validation loss: 0.1238
2024-05-25 08:24:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch53_loss0.12383086755871772.pypots
2024-05-25 08:25:16 [INFO]: Epoch 054 - training loss: 0.1223, validation loss: 0.1212
2024-05-25 08:25:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch54_loss0.1211546704173088.pypots
2024-05-25 08:25:33 [INFO]: Epoch 055 - training loss: 0.1320, validation loss: 0.1229
2024-05-25 08:25:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch55_loss0.12285665199160575.pypots
2024-05-25 08:25:50 [INFO]: Epoch 056 - training loss: 0.1272, validation loss: 0.1196
2024-05-25 08:25:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch56_loss0.11963405683636666.pypots
2024-05-25 08:26:06 [INFO]: Epoch 057 - training loss: 0.1065, validation loss: 0.1218
2024-05-25 08:26:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch57_loss0.12179371193051339.pypots
2024-05-25 08:26:23 [INFO]: Epoch 058 - training loss: 0.1211, validation loss: 0.1222
2024-05-25 08:26:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch58_loss0.12219449654221534.pypots
2024-05-25 08:26:40 [INFO]: Epoch 059 - training loss: 0.1217, validation loss: 0.1181
2024-05-25 08:26:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch59_loss0.11805240958929061.pypots
2024-05-25 08:26:57 [INFO]: Epoch 060 - training loss: 0.1040, validation loss: 0.1178
2024-05-25 08:26:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch60_loss0.11777385994791985.pypots
2024-05-25 08:27:13 [INFO]: Epoch 061 - training loss: 0.1106, validation loss: 0.1169
2024-05-25 08:27:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch61_loss0.11689563319087029.pypots
2024-05-25 08:27:30 [INFO]: Epoch 062 - training loss: 0.1203, validation loss: 0.1193
2024-05-25 08:27:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch62_loss0.1192879006266594.pypots
2024-05-25 08:27:47 [INFO]: Epoch 063 - training loss: 0.1312, validation loss: 0.1215
2024-05-25 08:27:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch63_loss0.12145926207304.pypots
2024-05-25 08:28:04 [INFO]: Epoch 064 - training loss: 0.1112, validation loss: 0.1179
2024-05-25 08:28:04 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch64_loss0.11794116124510765.pypots
2024-05-25 08:28:20 [INFO]: Epoch 065 - training loss: 0.1225, validation loss: 0.1173
2024-05-25 08:28:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch65_loss0.11730826124548913.pypots
2024-05-25 08:28:37 [INFO]: Epoch 066 - training loss: 0.1168, validation loss: 0.1161
2024-05-25 08:28:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch66_loss0.11614654436707497.pypots
2024-05-25 08:28:54 [INFO]: Epoch 067 - training loss: 0.1057, validation loss: 0.1196
2024-05-25 08:28:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch67_loss0.11961941197514533.pypots
2024-05-25 08:29:11 [INFO]: Epoch 068 - training loss: 0.1125, validation loss: 0.1159
2024-05-25 08:29:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch68_loss0.11588811352849007.pypots
2024-05-25 08:29:28 [INFO]: Epoch 069 - training loss: 0.1209, validation loss: 0.1153
2024-05-25 08:29:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch69_loss0.11534829884767532.pypots
2024-05-25 08:29:44 [INFO]: Epoch 070 - training loss: 0.1133, validation loss: 0.1164
2024-05-25 08:29:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch70_loss0.11635450795292854.pypots
2024-05-25 08:30:01 [INFO]: Epoch 071 - training loss: 0.1163, validation loss: 0.1165
2024-05-25 08:30:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch71_loss0.11649729460477828.pypots
2024-05-25 08:30:18 [INFO]: Epoch 072 - training loss: 0.1022, validation loss: 0.1161
2024-05-25 08:30:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch72_loss0.11613822802901268.pypots
2024-05-25 08:30:35 [INFO]: Epoch 073 - training loss: 0.1174, validation loss: 0.1202
2024-05-25 08:30:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch73_loss0.12020787373185157.pypots
2024-05-25 08:30:51 [INFO]: Epoch 074 - training loss: 0.1114, validation loss: 0.1212
2024-05-25 08:30:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch74_loss0.12121936157345772.pypots
2024-05-25 08:31:08 [INFO]: Epoch 075 - training loss: 0.1121, validation loss: 0.1159
2024-05-25 08:31:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch75_loss0.11588126197457313.pypots
2024-05-25 08:31:25 [INFO]: Epoch 076 - training loss: 0.1157, validation loss: 0.1148
2024-05-25 08:31:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch76_loss0.1148442842066288.pypots
2024-05-25 08:31:42 [INFO]: Epoch 077 - training loss: 0.1241, validation loss: 0.1143
2024-05-25 08:31:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch77_loss0.11431685537099838.pypots
2024-05-25 08:31:58 [INFO]: Epoch 078 - training loss: 0.1032, validation loss: 0.1144
2024-05-25 08:31:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch78_loss0.11438179090619087.pypots
2024-05-25 08:32:15 [INFO]: Epoch 079 - training loss: 0.1105, validation loss: 0.1185
2024-05-25 08:32:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch79_loss0.11845160126686097.pypots
2024-05-25 08:32:32 [INFO]: Epoch 080 - training loss: 0.1163, validation loss: 0.1124
2024-05-25 08:32:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch80_loss0.11243909373879432.pypots
2024-05-25 08:32:49 [INFO]: Epoch 081 - training loss: 0.1134, validation loss: 0.1163
2024-05-25 08:32:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch81_loss0.1162630595266819.pypots
2024-05-25 08:33:06 [INFO]: Epoch 082 - training loss: 0.1140, validation loss: 0.1200
2024-05-25 08:33:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch82_loss0.11997461915016175.pypots
2024-05-25 08:33:22 [INFO]: Epoch 083 - training loss: 0.1225, validation loss: 0.1177
2024-05-25 08:33:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch83_loss0.11772743463516236.pypots
2024-05-25 08:33:39 [INFO]: Epoch 084 - training loss: 0.1193, validation loss: 0.1178
2024-05-25 08:33:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch84_loss0.11784332618117332.pypots
2024-05-25 08:33:56 [INFO]: Epoch 085 - training loss: 0.1220, validation loss: 0.1149
2024-05-25 08:33:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch85_loss0.11489193364977837.pypots
2024-05-25 08:34:13 [INFO]: Epoch 086 - training loss: 0.1093, validation loss: 0.1145
2024-05-25 08:34:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch86_loss0.1145004004240036.pypots
2024-05-25 08:34:30 [INFO]: Epoch 087 - training loss: 0.1014, validation loss: 0.1128
2024-05-25 08:34:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch87_loss0.11284805238246917.pypots
2024-05-25 08:34:46 [INFO]: Epoch 088 - training loss: 0.1061, validation loss: 0.1143
2024-05-25 08:34:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch88_loss0.1142634741961956.pypots
2024-05-25 08:35:03 [INFO]: Epoch 089 - training loss: 0.1165, validation loss: 0.1145
2024-05-25 08:35:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch89_loss0.11452345177531242.pypots
2024-05-25 08:35:20 [INFO]: Epoch 090 - training loss: 0.1120, validation loss: 0.1119
2024-05-25 08:35:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch90_loss0.11190019324421882.pypots
2024-05-25 08:35:37 [INFO]: Epoch 091 - training loss: 0.1006, validation loss: 0.1136
2024-05-25 08:35:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch91_loss0.11364268958568573.pypots
2024-05-25 08:35:54 [INFO]: Epoch 092 - training loss: 0.1085, validation loss: 0.1114
2024-05-25 08:35:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch92_loss0.11135891154408455.pypots
2024-05-25 08:36:11 [INFO]: Epoch 093 - training loss: 0.1045, validation loss: 0.1152
2024-05-25 08:36:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch93_loss0.11516396105289459.pypots
2024-05-25 08:36:27 [INFO]: Epoch 094 - training loss: 0.1087, validation loss: 0.1121
2024-05-25 08:36:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch94_loss0.11207754090428353.pypots
2024-05-25 08:36:44 [INFO]: Epoch 095 - training loss: 0.1103, validation loss: 0.1124
2024-05-25 08:36:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch95_loss0.11244146302342414.pypots
2024-05-25 08:37:01 [INFO]: Epoch 096 - training loss: 0.1084, validation loss: 0.1102
2024-05-25 08:37:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch96_loss0.1101849503815174.pypots
2024-05-25 08:37:18 [INFO]: Epoch 097 - training loss: 0.1178, validation loss: 0.1154
2024-05-25 08:37:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch97_loss0.11539887264370918.pypots
2024-05-25 08:37:35 [INFO]: Epoch 098 - training loss: 0.1178, validation loss: 0.1111
2024-05-25 08:37:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch98_loss0.11108124256134033.pypots
2024-05-25 08:37:51 [INFO]: Epoch 099 - training loss: 0.1212, validation loss: 0.1135
2024-05-25 08:37:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch99_loss0.11348476633429527.pypots
2024-05-25 08:38:08 [INFO]: Epoch 100 - training loss: 0.1116, validation loss: 0.1116
2024-05-25 08:38:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch100_loss0.11157435104250908.pypots
2024-05-25 08:38:25 [INFO]: Epoch 101 - training loss: 0.1141, validation loss: 0.1102
2024-05-25 08:38:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch101_loss0.11017098501324654.pypots
2024-05-25 08:38:42 [INFO]: Epoch 102 - training loss: 0.0935, validation loss: 0.1103
2024-05-25 08:38:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch102_loss0.11031601876020432.pypots
2024-05-25 08:38:58 [INFO]: Epoch 103 - training loss: 0.1009, validation loss: 0.1096
2024-05-25 08:38:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch103_loss0.10962093845009804.pypots
2024-05-25 08:39:15 [INFO]: Epoch 104 - training loss: 0.1070, validation loss: 0.1108
2024-05-25 08:39:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch104_loss0.1107512965798378.pypots
2024-05-25 08:39:32 [INFO]: Epoch 105 - training loss: 0.1060, validation loss: 0.1095
2024-05-25 08:39:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch105_loss0.10949917584657669.pypots
2024-05-25 08:39:49 [INFO]: Epoch 106 - training loss: 0.1026, validation loss: 0.1107
2024-05-25 08:39:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch106_loss0.1106996476650238.pypots
2024-05-25 08:40:05 [INFO]: Epoch 107 - training loss: 0.1144, validation loss: 0.1147
2024-05-25 08:40:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch107_loss0.11474210768938065.pypots
2024-05-25 08:40:22 [INFO]: Epoch 108 - training loss: 0.1003, validation loss: 0.1099
2024-05-25 08:40:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch108_loss0.10989941507577897.pypots
2024-05-25 08:40:39 [INFO]: Epoch 109 - training loss: 0.0976, validation loss: 0.1094
2024-05-25 08:40:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch109_loss0.10942602455615998.pypots
2024-05-25 08:40:56 [INFO]: Epoch 110 - training loss: 0.0977, validation loss: 0.1116
2024-05-25 08:40:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch110_loss0.1115610159933567.pypots
2024-05-25 08:41:12 [INFO]: Epoch 111 - training loss: 0.1151, validation loss: 0.1080
2024-05-25 08:41:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch111_loss0.10800872296094895.pypots
2024-05-25 08:41:29 [INFO]: Epoch 112 - training loss: 0.1123, validation loss: 0.1128
2024-05-25 08:41:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch112_loss0.11280554309487342.pypots
2024-05-25 08:41:46 [INFO]: Epoch 113 - training loss: 0.1108, validation loss: 0.1132
2024-05-25 08:41:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch113_loss0.11321499720215797.pypots
2024-05-25 08:42:03 [INFO]: Epoch 114 - training loss: 0.0995, validation loss: 0.1138
2024-05-25 08:42:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch114_loss0.11384510397911071.pypots
2024-05-25 08:42:19 [INFO]: Epoch 115 - training loss: 0.1055, validation loss: 0.1135
2024-05-25 08:42:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch115_loss0.11353499665856362.pypots
2024-05-25 08:42:36 [INFO]: Epoch 116 - training loss: 0.1142, validation loss: 0.1101
2024-05-25 08:42:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch116_loss0.11011383682489395.pypots
2024-05-25 08:42:53 [INFO]: Epoch 117 - training loss: 0.1176, validation loss: 0.1103
2024-05-25 08:42:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch117_loss0.11026440858840943.pypots
2024-05-25 08:43:10 [INFO]: Epoch 118 - training loss: 0.1136, validation loss: 0.1104
2024-05-25 08:43:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch118_loss0.11041307896375656.pypots
2024-05-25 08:43:26 [INFO]: Epoch 119 - training loss: 0.1094, validation loss: 0.1097
2024-05-25 08:43:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch119_loss0.10966375023126602.pypots
2024-05-25 08:43:43 [INFO]: Epoch 120 - training loss: 0.1139, validation loss: 0.1121
2024-05-25 08:43:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch120_loss0.11207829266786576.pypots
2024-05-25 08:44:00 [INFO]: Epoch 121 - training loss: 0.1072, validation loss: 0.1118
2024-05-25 08:44:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI_epoch121_loss0.1118343211710453.pypots
2024-05-25 08:44:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 08:44:00 [INFO]: Finished training. The best model is from epoch#111.
2024-05-25 08:44:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240525_T081011/CSDI.pypots
2024-05-25 08:46:21 [INFO]: CSDI on Air-Quality: MAE=0.1599, MSE=1.1499
2024-05-25 08:46:21 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/CSDI_air_quality/imputation.pkl
2024-05-25 08:46:21 [INFO]: Using the given device: cuda:0
2024-05-25 08:46:21 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/GPVAE_air_quality/20240525_T084621
2024-05-25 08:46:21 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/GPVAE_air_quality/20240525_T084621/tensorboard
2024-05-25 08:46:21 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 08:46:21 [INFO]: Epoch 001 - training loss: 63907.4141, validation loss: 0.6724
2024-05-25 08:46:22 [INFO]: Epoch 002 - training loss: 41987.7666, validation loss: 0.5709
2024-05-25 08:46:22 [INFO]: Epoch 003 - training loss: 41629.1101, validation loss: 0.4969
2024-05-25 08:46:22 [INFO]: Epoch 004 - training loss: 41485.2335, validation loss: 0.4995
2024-05-25 08:46:23 [INFO]: Epoch 005 - training loss: 41443.8511, validation loss: 0.4249
2024-05-25 08:46:23 [INFO]: Epoch 006 - training loss: 41365.7892, validation loss: 0.3975
2024-05-25 08:46:23 [INFO]: Epoch 007 - training loss: 41320.5916, validation loss: 0.3688
2024-05-25 08:46:24 [INFO]: Epoch 008 - training loss: 41296.4942, validation loss: 0.3518
2024-05-25 08:46:24 [INFO]: Epoch 009 - training loss: 41258.5819, validation loss: 0.3535
2024-05-25 08:46:24 [INFO]: Epoch 010 - training loss: 41239.7490, validation loss: 0.3288
2024-05-25 08:46:25 [INFO]: Epoch 011 - training loss: 41213.0124, validation loss: 0.3298
2024-05-25 08:46:25 [INFO]: Epoch 012 - training loss: 41209.8440, validation loss: 0.3221
2024-05-25 08:46:26 [INFO]: Epoch 013 - training loss: 41184.6215, validation loss: 0.3116
2024-05-25 08:46:26 [INFO]: Epoch 014 - training loss: 41206.7555, validation loss: 0.3149
2024-05-25 08:46:26 [INFO]: Epoch 015 - training loss: 41197.8940, validation loss: 0.3302
2024-05-25 08:46:27 [INFO]: Epoch 016 - training loss: 41175.7004, validation loss: 0.2981
2024-05-25 08:46:27 [INFO]: Epoch 017 - training loss: 41139.2747, validation loss: 0.2847
2024-05-25 08:46:27 [INFO]: Epoch 018 - training loss: 41132.4891, validation loss: 0.2890
2024-05-25 08:46:28 [INFO]: Epoch 019 - training loss: 41118.7292, validation loss: 0.2813
2024-05-25 08:46:28 [INFO]: Epoch 020 - training loss: 41122.5508, validation loss: 0.2807
2024-05-25 08:46:29 [INFO]: Epoch 021 - training loss: 41120.5256, validation loss: 0.2801
2024-05-25 08:46:29 [INFO]: Epoch 022 - training loss: 41116.8380, validation loss: 0.2821
2024-05-25 08:46:29 [INFO]: Epoch 023 - training loss: 41127.7733, validation loss: 0.2865
2024-05-25 08:46:30 [INFO]: Epoch 024 - training loss: 41116.5703, validation loss: 0.2972
2024-05-25 08:46:30 [INFO]: Epoch 025 - training loss: 41112.7574, validation loss: 0.2899
2024-05-25 08:46:30 [INFO]: Epoch 026 - training loss: 41091.3482, validation loss: 0.2612
2024-05-25 08:46:31 [INFO]: Epoch 027 - training loss: 41073.9533, validation loss: 0.2607
2024-05-25 08:46:31 [INFO]: Epoch 028 - training loss: 41081.3553, validation loss: 0.2663
2024-05-25 08:46:32 [INFO]: Epoch 029 - training loss: 41072.2714, validation loss: 0.2551
2024-05-25 08:46:32 [INFO]: Epoch 030 - training loss: 41061.5129, validation loss: 0.2596
2024-05-25 08:46:32 [INFO]: Epoch 031 - training loss: 41058.0595, validation loss: 0.2531
2024-05-25 08:46:33 [INFO]: Epoch 032 - training loss: 41062.2146, validation loss: 0.2556
2024-05-25 08:46:33 [INFO]: Epoch 033 - training loss: 41074.9116, validation loss: 0.2807
2024-05-25 08:46:33 [INFO]: Epoch 034 - training loss: 41078.7377, validation loss: 0.2579
2024-05-25 08:46:34 [INFO]: Epoch 035 - training loss: 41049.1761, validation loss: 0.2467
2024-05-25 08:46:34 [INFO]: Epoch 036 - training loss: 41042.6402, validation loss: 0.2424
2024-05-25 08:46:35 [INFO]: Epoch 037 - training loss: 41038.1905, validation loss: 0.2562
2024-05-25 08:46:35 [INFO]: Epoch 038 - training loss: 41050.3025, validation loss: 0.2403
2024-05-25 08:46:35 [INFO]: Epoch 039 - training loss: 41046.0056, validation loss: 0.2465
2024-05-25 08:46:36 [INFO]: Epoch 040 - training loss: 41043.8532, validation loss: 0.2645
2024-05-25 08:46:36 [INFO]: Epoch 041 - training loss: 41084.1243, validation loss: 0.2902
2024-05-25 08:46:36 [INFO]: Epoch 042 - training loss: 41133.7467, validation loss: 0.2584
2024-05-25 08:46:37 [INFO]: Epoch 043 - training loss: 41091.9447, validation loss: 0.2640
2024-05-25 08:46:37 [INFO]: Epoch 044 - training loss: 41113.6385, validation loss: 0.2683
2024-05-25 08:46:38 [INFO]: Epoch 045 - training loss: 41072.5859, validation loss: 0.3037
2024-05-25 08:46:38 [INFO]: Epoch 046 - training loss: 41090.3215, validation loss: 0.2518
2024-05-25 08:46:38 [INFO]: Epoch 047 - training loss: 41047.0922, validation loss: 0.2591
2024-05-25 08:46:39 [INFO]: Epoch 048 - training loss: 41062.2962, validation loss: 0.2798
2024-05-25 08:46:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 08:46:39 [INFO]: Finished training. The best model is from epoch#38.
2024-05-25 08:46:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/GPVAE_air_quality/20240525_T084621/GPVAE.pypots
2024-05-25 08:46:39 [INFO]: GP-VAE on Air-Quality: MAE=0.3074, MSE=0.3784
2024-05-25 08:46:39 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/GPVAE_air_quality/imputation.pkl
2024-05-25 08:46:39 [INFO]: Using the given device: cuda:0
2024-05-25 08:46:39 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/USGAN_air_quality/20240525_T084639
2024-05-25 08:46:39 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/USGAN_air_quality/20240525_T084639/tensorboard
2024-05-25 08:46:39 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 08:46:44 [INFO]: Epoch 001 - generator training loss: 0.5096, discriminator training loss: 0.3781, validation loss: 0.5018
2024-05-25 08:46:48 [INFO]: Epoch 002 - generator training loss: 0.1449, discriminator training loss: 0.2430, validation loss: 0.3771
2024-05-25 08:46:53 [INFO]: Epoch 003 - generator training loss: 0.0944, discriminator training loss: 0.2386, validation loss: 0.3134
2024-05-25 08:46:57 [INFO]: Epoch 004 - generator training loss: 0.0570, discriminator training loss: 0.2375, validation loss: 0.2767
2024-05-25 08:47:01 [INFO]: Epoch 005 - generator training loss: 0.0359, discriminator training loss: 0.2367, validation loss: 0.2499
2024-05-25 08:47:06 [INFO]: Epoch 006 - generator training loss: 0.0116, discriminator training loss: 0.2358, validation loss: 0.2328
2024-05-25 08:47:10 [INFO]: Epoch 007 - generator training loss: -0.0002, discriminator training loss: 0.2350, validation loss: 0.2201
2024-05-25 08:47:14 [INFO]: Epoch 008 - generator training loss: -0.0103, discriminator training loss: 0.2334, validation loss: 0.2107
2024-05-25 08:47:19 [INFO]: Epoch 009 - generator training loss: -0.0161, discriminator training loss: 0.2326, validation loss: 0.2018
2024-05-25 08:47:23 [INFO]: Epoch 010 - generator training loss: -0.0234, discriminator training loss: 0.2313, validation loss: 0.1968
2024-05-25 08:47:28 [INFO]: Epoch 011 - generator training loss: -0.0282, discriminator training loss: 0.2301, validation loss: 0.1912
2024-05-25 08:47:32 [INFO]: Epoch 012 - generator training loss: -0.0324, discriminator training loss: 0.2286, validation loss: 0.1857
2024-05-25 08:47:36 [INFO]: Epoch 013 - generator training loss: -0.0346, discriminator training loss: 0.2266, validation loss: 0.1829
2024-05-25 08:47:41 [INFO]: Epoch 014 - generator training loss: -0.0378, discriminator training loss: 0.2251, validation loss: 0.1778
2024-05-25 08:47:45 [INFO]: Epoch 015 - generator training loss: -0.0408, discriminator training loss: 0.2234, validation loss: 0.1739
2024-05-25 08:47:49 [INFO]: Epoch 016 - generator training loss: -0.0431, discriminator training loss: 0.2216, validation loss: 0.1698
2024-05-25 08:47:53 [INFO]: Epoch 017 - generator training loss: -0.0432, discriminator training loss: 0.2202, validation loss: 0.1673
2024-05-25 08:47:58 [INFO]: Epoch 018 - generator training loss: -0.0464, discriminator training loss: 0.2189, validation loss: 0.1641
2024-05-25 08:48:02 [INFO]: Epoch 019 - generator training loss: -0.0475, discriminator training loss: 0.2173, validation loss: 0.1611
2024-05-25 08:48:07 [INFO]: Epoch 020 - generator training loss: -0.0479, discriminator training loss: 0.2157, validation loss: 0.1590
2024-05-25 08:48:11 [INFO]: Epoch 021 - generator training loss: -0.0499, discriminator training loss: 0.2139, validation loss: 0.1569
2024-05-25 08:48:15 [INFO]: Epoch 022 - generator training loss: -0.0499, discriminator training loss: 0.2122, validation loss: 0.1539
2024-05-25 08:48:20 [INFO]: Epoch 023 - generator training loss: -0.0513, discriminator training loss: 0.2105, validation loss: 0.1522
2024-05-25 08:48:24 [INFO]: Epoch 024 - generator training loss: -0.0532, discriminator training loss: 0.2089, validation loss: 0.1496
2024-05-25 08:48:28 [INFO]: Epoch 025 - generator training loss: -0.0537, discriminator training loss: 0.2071, validation loss: 0.1476
2024-05-25 08:48:32 [INFO]: Epoch 026 - generator training loss: -0.0535, discriminator training loss: 0.2052, validation loss: 0.1461
2024-05-25 08:48:37 [INFO]: Epoch 027 - generator training loss: -0.0543, discriminator training loss: 0.2036, validation loss: 0.1437
2024-05-25 08:48:41 [INFO]: Epoch 028 - generator training loss: -0.0532, discriminator training loss: 0.2017, validation loss: 0.1430
2024-05-25 08:48:45 [INFO]: Epoch 029 - generator training loss: -0.0522, discriminator training loss: 0.2000, validation loss: 0.1414
2024-05-25 08:48:50 [INFO]: Epoch 030 - generator training loss: -0.0539, discriminator training loss: 0.1983, validation loss: 0.1400
2024-05-25 08:48:54 [INFO]: Epoch 031 - generator training loss: -0.0530, discriminator training loss: 0.1966, validation loss: 0.1380
2024-05-25 08:48:59 [INFO]: Epoch 032 - generator training loss: -0.0533, discriminator training loss: 0.1947, validation loss: 0.1371
2024-05-25 08:49:03 [INFO]: Epoch 033 - generator training loss: -0.0530, discriminator training loss: 0.1929, validation loss: 0.1355
2024-05-25 08:49:07 [INFO]: Epoch 034 - generator training loss: -0.0519, discriminator training loss: 0.1913, validation loss: 0.1340
2024-05-25 08:49:12 [INFO]: Epoch 035 - generator training loss: -0.0513, discriminator training loss: 0.1895, validation loss: 0.1330
2024-05-25 08:49:16 [INFO]: Epoch 036 - generator training loss: -0.0528, discriminator training loss: 0.1878, validation loss: 0.1273
2024-05-25 08:49:20 [INFO]: Epoch 037 - generator training loss: -0.0524, discriminator training loss: 0.1863, validation loss: 0.1259
2024-05-25 08:49:25 [INFO]: Epoch 038 - generator training loss: -0.0524, discriminator training loss: 0.1845, validation loss: 0.1247
2024-05-25 08:49:29 [INFO]: Epoch 039 - generator training loss: -0.0522, discriminator training loss: 0.1830, validation loss: 0.1236
2024-05-25 08:49:33 [INFO]: Epoch 040 - generator training loss: -0.0519, discriminator training loss: 0.1811, validation loss: 0.1229
2024-05-25 08:49:38 [INFO]: Epoch 041 - generator training loss: -0.0516, discriminator training loss: 0.1799, validation loss: 0.1218
2024-05-25 08:49:42 [INFO]: Epoch 042 - generator training loss: -0.0495, discriminator training loss: 0.1784, validation loss: 0.1205
2024-05-25 08:49:46 [INFO]: Epoch 043 - generator training loss: -0.0514, discriminator training loss: 0.1769, validation loss: 0.1205
2024-05-25 08:49:51 [INFO]: Epoch 044 - generator training loss: -0.0505, discriminator training loss: 0.1754, validation loss: 0.1199
2024-05-25 08:49:55 [INFO]: Epoch 045 - generator training loss: -0.0502, discriminator training loss: 0.1739, validation loss: 0.1188
2024-05-25 08:49:59 [INFO]: Epoch 046 - generator training loss: -0.0497, discriminator training loss: 0.1726, validation loss: 0.1181
2024-05-25 08:50:04 [INFO]: Epoch 047 - generator training loss: -0.0489, discriminator training loss: 0.1712, validation loss: 0.1173
2024-05-25 08:50:08 [INFO]: Epoch 048 - generator training loss: -0.0494, discriminator training loss: 0.1700, validation loss: 0.1161
2024-05-25 08:50:12 [INFO]: Epoch 049 - generator training loss: -0.0495, discriminator training loss: 0.1687, validation loss: 0.1153
2024-05-25 08:50:17 [INFO]: Epoch 050 - generator training loss: -0.0489, discriminator training loss: 0.1672, validation loss: 0.1152
2024-05-25 08:50:21 [INFO]: Epoch 051 - generator training loss: -0.0483, discriminator training loss: 0.1661, validation loss: 0.1146
2024-05-25 08:50:25 [INFO]: Epoch 052 - generator training loss: -0.0487, discriminator training loss: 0.1652, validation loss: 0.1137
2024-05-25 08:50:30 [INFO]: Epoch 053 - generator training loss: -0.0486, discriminator training loss: 0.1638, validation loss: 0.1132
2024-05-25 08:50:34 [INFO]: Epoch 054 - generator training loss: -0.0479, discriminator training loss: 0.1627, validation loss: 0.1124
2024-05-25 08:50:38 [INFO]: Epoch 055 - generator training loss: -0.0473, discriminator training loss: 0.1617, validation loss: 0.1115
2024-05-25 08:50:43 [INFO]: Epoch 056 - generator training loss: -0.0466, discriminator training loss: 0.1607, validation loss: 0.1108
2024-05-25 08:50:47 [INFO]: Epoch 057 - generator training loss: -0.0474, discriminator training loss: 0.1596, validation loss: 0.1105
2024-05-25 08:50:51 [INFO]: Epoch 058 - generator training loss: -0.0467, discriminator training loss: 0.1587, validation loss: 0.1106
2024-05-25 08:50:56 [INFO]: Epoch 059 - generator training loss: -0.0461, discriminator training loss: 0.1577, validation loss: 0.1093
2024-05-25 08:51:00 [INFO]: Epoch 060 - generator training loss: -0.0458, discriminator training loss: 0.1569, validation loss: 0.1086
2024-05-25 08:51:04 [INFO]: Epoch 061 - generator training loss: -0.0466, discriminator training loss: 0.1561, validation loss: 0.1093
2024-05-25 08:51:09 [INFO]: Epoch 062 - generator training loss: -0.0447, discriminator training loss: 0.1553, validation loss: 0.1090
2024-05-25 08:51:13 [INFO]: Epoch 063 - generator training loss: -0.0455, discriminator training loss: 0.1544, validation loss: 0.1080
2024-05-25 08:51:17 [INFO]: Epoch 064 - generator training loss: -0.0447, discriminator training loss: 0.1535, validation loss: 0.1074
2024-05-25 08:51:22 [INFO]: Epoch 065 - generator training loss: -0.0454, discriminator training loss: 0.1530, validation loss: 0.1065
2024-05-25 08:51:26 [INFO]: Epoch 066 - generator training loss: -0.0456, discriminator training loss: 0.1525, validation loss: 0.1067
2024-05-25 08:51:30 [INFO]: Epoch 067 - generator training loss: -0.0449, discriminator training loss: 0.1518, validation loss: 0.1061
2024-05-25 08:51:35 [INFO]: Epoch 068 - generator training loss: -0.0450, discriminator training loss: 0.1514, validation loss: 0.1058
2024-05-25 08:51:39 [INFO]: Epoch 069 - generator training loss: -0.0453, discriminator training loss: 0.1503, validation loss: 0.1055
2024-05-25 08:51:43 [INFO]: Epoch 070 - generator training loss: -0.0449, discriminator training loss: 0.1499, validation loss: 0.1048
2024-05-25 08:51:48 [INFO]: Epoch 071 - generator training loss: -0.0444, discriminator training loss: 0.1494, validation loss: 0.1050
2024-05-25 08:51:52 [INFO]: Epoch 072 - generator training loss: -0.0446, discriminator training loss: 0.1487, validation loss: 0.1054
2024-05-25 08:51:56 [INFO]: Epoch 073 - generator training loss: -0.0444, discriminator training loss: 0.1483, validation loss: 0.1043
2024-05-25 08:52:01 [INFO]: Epoch 074 - generator training loss: -0.0437, discriminator training loss: 0.1479, validation loss: 0.1039
2024-05-25 08:52:05 [INFO]: Epoch 075 - generator training loss: -0.0443, discriminator training loss: 0.1470, validation loss: 0.1044
2024-05-25 08:52:09 [INFO]: Epoch 076 - generator training loss: -0.0448, discriminator training loss: 0.1464, validation loss: 0.1029
2024-05-25 08:52:14 [INFO]: Epoch 077 - generator training loss: -0.0445, discriminator training loss: 0.1461, validation loss: 0.1041
2024-05-25 08:52:18 [INFO]: Epoch 078 - generator training loss: -0.0434, discriminator training loss: 0.1458, validation loss: 0.1039
2024-05-25 08:52:23 [INFO]: Epoch 079 - generator training loss: -0.0439, discriminator training loss: 0.1452, validation loss: 0.1034
2024-05-25 08:52:27 [INFO]: Epoch 080 - generator training loss: -0.0436, discriminator training loss: 0.1449, validation loss: 0.1027
2024-05-25 08:52:31 [INFO]: Epoch 081 - generator training loss: -0.0448, discriminator training loss: 0.1442, validation loss: 0.1022
2024-05-25 08:52:36 [INFO]: Epoch 082 - generator training loss: -0.0440, discriminator training loss: 0.1441, validation loss: 0.1027
2024-05-25 08:52:40 [INFO]: Epoch 083 - generator training loss: -0.0440, discriminator training loss: 0.1436, validation loss: 0.1019
2024-05-25 08:52:44 [INFO]: Epoch 084 - generator training loss: -0.0449, discriminator training loss: 0.1432, validation loss: 0.1019
2024-05-25 08:52:48 [INFO]: Epoch 085 - generator training loss: -0.0443, discriminator training loss: 0.1427, validation loss: 0.1023
2024-05-25 08:52:53 [INFO]: Epoch 086 - generator training loss: -0.0450, discriminator training loss: 0.1424, validation loss: 0.1014
2024-05-25 08:52:57 [INFO]: Epoch 087 - generator training loss: -0.0450, discriminator training loss: 0.1421, validation loss: 0.1013
2024-05-25 08:53:02 [INFO]: Epoch 088 - generator training loss: -0.0455, discriminator training loss: 0.1419, validation loss: 0.1015
2024-05-25 08:53:06 [INFO]: Epoch 089 - generator training loss: -0.0453, discriminator training loss: 0.1417, validation loss: 0.1008
2024-05-25 08:53:10 [INFO]: Epoch 090 - generator training loss: -0.0450, discriminator training loss: 0.1412, validation loss: 0.1025
2024-05-25 08:53:15 [INFO]: Epoch 091 - generator training loss: -0.0440, discriminator training loss: 0.1405, validation loss: 0.1010
2024-05-25 08:53:19 [INFO]: Epoch 092 - generator training loss: -0.0445, discriminator training loss: 0.1405, validation loss: 0.1007
2024-05-25 08:53:23 [INFO]: Epoch 093 - generator training loss: -0.0450, discriminator training loss: 0.1408, validation loss: 0.1005
2024-05-25 08:53:28 [INFO]: Epoch 094 - generator training loss: -0.0456, discriminator training loss: 0.1404, validation loss: 0.0998
2024-05-25 08:53:32 [INFO]: Epoch 095 - generator training loss: -0.0454, discriminator training loss: 0.1401, validation loss: 0.1004
2024-05-25 08:53:36 [INFO]: Epoch 096 - generator training loss: -0.0449, discriminator training loss: 0.1397, validation loss: 0.0996
2024-05-25 08:53:40 [INFO]: Epoch 097 - generator training loss: -0.0446, discriminator training loss: 0.1392, validation loss: 0.1004
2024-05-25 08:53:44 [INFO]: Epoch 098 - generator training loss: -0.0423, discriminator training loss: 0.1392, validation loss: 0.1009
2024-05-25 08:53:49 [INFO]: Epoch 099 - generator training loss: -0.0429, discriminator training loss: 0.1389, validation loss: 0.1005
2024-05-25 08:53:53 [INFO]: Epoch 100 - generator training loss: -0.0440, discriminator training loss: 0.1387, validation loss: 0.0999
2024-05-25 08:53:57 [INFO]: Epoch 101 - generator training loss: -0.0445, discriminator training loss: 0.1385, validation loss: 0.1002
2024-05-25 08:54:02 [INFO]: Epoch 102 - generator training loss: -0.0452, discriminator training loss: 0.1384, validation loss: 0.0997
2024-05-25 08:54:06 [INFO]: Epoch 103 - generator training loss: -0.0456, discriminator training loss: 0.1381, validation loss: 0.0995
2024-05-25 08:54:11 [INFO]: Epoch 104 - generator training loss: -0.0459, discriminator training loss: 0.1381, validation loss: 0.0994
2024-05-25 08:54:15 [INFO]: Epoch 105 - generator training loss: -0.0461, discriminator training loss: 0.1378, validation loss: 0.0992
2024-05-25 08:54:19 [INFO]: Epoch 106 - generator training loss: -0.0459, discriminator training loss: 0.1374, validation loss: 0.0997
2024-05-25 08:54:23 [INFO]: Epoch 107 - generator training loss: -0.0459, discriminator training loss: 0.1376, validation loss: 0.0998
2024-05-25 08:54:28 [INFO]: Epoch 108 - generator training loss: -0.0455, discriminator training loss: 0.1375, validation loss: 0.1003
2024-05-25 08:54:32 [INFO]: Epoch 109 - generator training loss: -0.0459, discriminator training loss: 0.1370, validation loss: 0.0992
2024-05-25 08:54:36 [INFO]: Epoch 110 - generator training loss: -0.0460, discriminator training loss: 0.1367, validation loss: 0.0996
2024-05-25 08:54:41 [INFO]: Epoch 111 - generator training loss: -0.0461, discriminator training loss: 0.1362, validation loss: 0.0994
2024-05-25 08:54:45 [INFO]: Epoch 112 - generator training loss: -0.0461, discriminator training loss: 0.1363, validation loss: 0.0996
2024-05-25 08:54:50 [INFO]: Epoch 113 - generator training loss: -0.0466, discriminator training loss: 0.1364, validation loss: 0.0989
2024-05-25 08:54:54 [INFO]: Epoch 114 - generator training loss: -0.0465, discriminator training loss: 0.1361, validation loss: 0.0995
2024-05-25 08:54:58 [INFO]: Epoch 115 - generator training loss: -0.0473, discriminator training loss: 0.1357, validation loss: 0.0989
2024-05-25 08:55:03 [INFO]: Epoch 116 - generator training loss: -0.0465, discriminator training loss: 0.1357, validation loss: 0.0989
2024-05-25 08:55:07 [INFO]: Epoch 117 - generator training loss: -0.0468, discriminator training loss: 0.1354, validation loss: 0.0987
2024-05-25 08:55:11 [INFO]: Epoch 118 - generator training loss: -0.0472, discriminator training loss: 0.1354, validation loss: 0.0991
2024-05-25 08:55:16 [INFO]: Epoch 119 - generator training loss: -0.0467, discriminator training loss: 0.1351, validation loss: 0.0984
2024-05-25 08:55:20 [INFO]: Epoch 120 - generator training loss: -0.0482, discriminator training loss: 0.1347, validation loss: 0.0988
2024-05-25 08:55:24 [INFO]: Epoch 121 - generator training loss: -0.0474, discriminator training loss: 0.1351, validation loss: 0.1001
2024-05-25 08:55:29 [INFO]: Epoch 122 - generator training loss: -0.0461, discriminator training loss: 0.1350, validation loss: 0.0990
2024-05-25 08:55:33 [INFO]: Epoch 123 - generator training loss: -0.0471, discriminator training loss: 0.1348, validation loss: 0.1000
2024-05-25 08:55:37 [INFO]: Epoch 124 - generator training loss: -0.0476, discriminator training loss: 0.1346, validation loss: 0.0988
2024-05-25 08:55:42 [INFO]: Epoch 125 - generator training loss: -0.0481, discriminator training loss: 0.1345, validation loss: 0.0987
2024-05-25 08:55:46 [INFO]: Epoch 126 - generator training loss: -0.0486, discriminator training loss: 0.1347, validation loss: 0.0997
2024-05-25 08:55:50 [INFO]: Epoch 127 - generator training loss: -0.0476, discriminator training loss: 0.1343, validation loss: 0.0990
2024-05-25 08:55:55 [INFO]: Epoch 128 - generator training loss: -0.0471, discriminator training loss: 0.1340, validation loss: 0.0998
2024-05-25 08:55:59 [INFO]: Epoch 129 - generator training loss: -0.0463, discriminator training loss: 0.1341, validation loss: 0.0984
2024-05-25 08:56:03 [INFO]: Epoch 130 - generator training loss: -0.0467, discriminator training loss: 0.1339, validation loss: 0.0997
2024-05-25 08:56:08 [INFO]: Epoch 131 - generator training loss: -0.0467, discriminator training loss: 0.1343, validation loss: 0.0994
2024-05-25 08:56:12 [INFO]: Epoch 132 - generator training loss: -0.0471, discriminator training loss: 0.1339, validation loss: 0.0992
2024-05-25 08:56:16 [INFO]: Epoch 133 - generator training loss: -0.0485, discriminator training loss: 0.1342, validation loss: 0.0990
2024-05-25 08:56:21 [INFO]: Epoch 134 - generator training loss: -0.0479, discriminator training loss: 0.1337, validation loss: 0.0985
2024-05-25 08:56:25 [INFO]: Epoch 135 - generator training loss: -0.0485, discriminator training loss: 0.1337, validation loss: 0.0984
2024-05-25 08:56:29 [INFO]: Epoch 136 - generator training loss: -0.0484, discriminator training loss: 0.1338, validation loss: 0.0987
2024-05-25 08:56:34 [INFO]: Epoch 137 - generator training loss: -0.0484, discriminator training loss: 0.1334, validation loss: 0.0982
2024-05-25 08:56:38 [INFO]: Epoch 138 - generator training loss: -0.0482, discriminator training loss: 0.1333, validation loss: 0.0990
2024-05-25 08:56:42 [INFO]: Epoch 139 - generator training loss: -0.0487, discriminator training loss: 0.1329, validation loss: 0.0989
2024-05-25 08:56:47 [INFO]: Epoch 140 - generator training loss: -0.0493, discriminator training loss: 0.1335, validation loss: 0.0999
2024-05-25 08:56:51 [INFO]: Epoch 141 - generator training loss: -0.0485, discriminator training loss: 0.1329, validation loss: 0.0985
2024-05-25 08:56:55 [INFO]: Epoch 142 - generator training loss: -0.0491, discriminator training loss: 0.1326, validation loss: 0.0990
2024-05-25 08:57:00 [INFO]: Epoch 143 - generator training loss: -0.0491, discriminator training loss: 0.1332, validation loss: 0.0996
2024-05-25 08:57:04 [INFO]: Epoch 144 - generator training loss: -0.0492, discriminator training loss: 0.1325, validation loss: 0.0988
2024-05-25 08:57:08 [INFO]: Epoch 145 - generator training loss: -0.0491, discriminator training loss: 0.1329, validation loss: 0.0993
2024-05-25 08:57:13 [INFO]: Epoch 146 - generator training loss: -0.0491, discriminator training loss: 0.1323, validation loss: 0.0997
2024-05-25 08:57:17 [INFO]: Epoch 147 - generator training loss: -0.0497, discriminator training loss: 0.1323, validation loss: 0.0983
2024-05-25 08:57:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 08:57:17 [INFO]: Finished training. The best model is from epoch#137.
2024-05-25 08:57:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/USGAN_air_quality/20240525_T084639/USGAN.pypots
2024-05-25 08:57:18 [INFO]: US-GAN on Air-Quality: MAE=0.1418, MSE=0.1790
2024-05-25 08:57:18 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/USGAN_air_quality/imputation.pkl
2024-05-25 08:57:18 [INFO]: Using the given device: cuda:0
2024-05-25 08:57:18 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/BRITS_air_quality/20240525_T085718
2024-05-25 08:57:18 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/BRITS_air_quality/20240525_T085718/tensorboard
2024-05-25 08:57:18 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 08:57:22 [INFO]: Epoch 001 - training loss: 1.4209, validation loss: 0.9279
2024-05-25 08:57:24 [INFO]: Epoch 002 - training loss: 1.1487, validation loss: 0.6844
2024-05-25 08:57:27 [INFO]: Epoch 003 - training loss: 0.9528, validation loss: 0.5766
2024-05-25 08:57:30 [INFO]: Epoch 004 - training loss: 0.8431, validation loss: 0.5114
2024-05-25 08:57:33 [INFO]: Epoch 005 - training loss: 0.7656, validation loss: 0.4634
2024-05-25 08:57:36 [INFO]: Epoch 006 - training loss: 0.7071, validation loss: 0.4276
2024-05-25 08:57:39 [INFO]: Epoch 007 - training loss: 0.6609, validation loss: 0.3995
2024-05-25 08:57:42 [INFO]: Epoch 008 - training loss: 0.6267, validation loss: 0.3771
2024-05-25 08:57:45 [INFO]: Epoch 009 - training loss: 0.6001, validation loss: 0.3584
2024-05-25 08:57:48 [INFO]: Epoch 010 - training loss: 0.5795, validation loss: 0.3434
2024-05-25 08:57:51 [INFO]: Epoch 011 - training loss: 0.5615, validation loss: 0.3308
2024-05-25 08:57:54 [INFO]: Epoch 012 - training loss: 0.5474, validation loss: 0.3190
2024-05-25 08:57:56 [INFO]: Epoch 013 - training loss: 0.5332, validation loss: 0.3101
2024-05-25 08:57:59 [INFO]: Epoch 014 - training loss: 0.5221, validation loss: 0.3012
2024-05-25 08:58:02 [INFO]: Epoch 015 - training loss: 0.5123, validation loss: 0.2938
2024-05-25 08:58:05 [INFO]: Epoch 016 - training loss: 0.5026, validation loss: 0.2868
2024-05-25 08:58:08 [INFO]: Epoch 017 - training loss: 0.4935, validation loss: 0.2800
2024-05-25 08:58:11 [INFO]: Epoch 018 - training loss: 0.4856, validation loss: 0.2746
2024-05-25 08:58:14 [INFO]: Epoch 019 - training loss: 0.4777, validation loss: 0.2691
2024-05-25 08:58:17 [INFO]: Epoch 020 - training loss: 0.4710, validation loss: 0.2644
2024-05-25 08:58:20 [INFO]: Epoch 021 - training loss: 0.4632, validation loss: 0.2594
2024-05-25 08:58:23 [INFO]: Epoch 022 - training loss: 0.4571, validation loss: 0.2552
2024-05-25 08:58:26 [INFO]: Epoch 023 - training loss: 0.4510, validation loss: 0.2507
2024-05-25 08:58:28 [INFO]: Epoch 024 - training loss: 0.4443, validation loss: 0.2466
2024-05-25 08:58:31 [INFO]: Epoch 025 - training loss: 0.4391, validation loss: 0.2425
2024-05-25 08:58:34 [INFO]: Epoch 026 - training loss: 0.4331, validation loss: 0.2389
2024-05-25 08:58:37 [INFO]: Epoch 027 - training loss: 0.4295, validation loss: 0.2347
2024-05-25 08:58:40 [INFO]: Epoch 028 - training loss: 0.4252, validation loss: 0.2319
2024-05-25 08:58:43 [INFO]: Epoch 029 - training loss: 0.4197, validation loss: 0.2275
2024-05-25 08:58:46 [INFO]: Epoch 030 - training loss: 0.4133, validation loss: 0.2241
2024-05-25 08:58:49 [INFO]: Epoch 031 - training loss: 0.4098, validation loss: 0.2215
2024-05-25 08:58:52 [INFO]: Epoch 032 - training loss: 0.4051, validation loss: 0.2179
2024-05-25 08:58:55 [INFO]: Epoch 033 - training loss: 0.4002, validation loss: 0.2148
2024-05-25 08:58:58 [INFO]: Epoch 034 - training loss: 0.3979, validation loss: 0.2110
2024-05-25 08:59:00 [INFO]: Epoch 035 - training loss: 0.3938, validation loss: 0.2086
2024-05-25 08:59:03 [INFO]: Epoch 036 - training loss: 0.3896, validation loss: 0.2056
2024-05-25 08:59:06 [INFO]: Epoch 037 - training loss: 0.3859, validation loss: 0.2023
2024-05-25 08:59:09 [INFO]: Epoch 038 - training loss: 0.3833, validation loss: 0.2004
2024-05-25 08:59:12 [INFO]: Epoch 039 - training loss: 0.3794, validation loss: 0.1965
2024-05-25 08:59:15 [INFO]: Epoch 040 - training loss: 0.3751, validation loss: 0.1936
2024-05-25 08:59:18 [INFO]: Epoch 041 - training loss: 0.3720, validation loss: 0.1916
2024-05-25 08:59:21 [INFO]: Epoch 042 - training loss: 0.3691, validation loss: 0.1891
2024-05-25 08:59:24 [INFO]: Epoch 043 - training loss: 0.3661, validation loss: 0.1863
2024-05-25 08:59:27 [INFO]: Epoch 044 - training loss: 0.3640, validation loss: 0.1839
2024-05-25 08:59:30 [INFO]: Epoch 045 - training loss: 0.3623, validation loss: 0.1815
2024-05-25 08:59:33 [INFO]: Epoch 046 - training loss: 0.3575, validation loss: 0.1797
2024-05-25 08:59:35 [INFO]: Epoch 047 - training loss: 0.3550, validation loss: 0.1774
2024-05-25 08:59:38 [INFO]: Epoch 048 - training loss: 0.3529, validation loss: 0.1752
2024-05-25 08:59:41 [INFO]: Epoch 049 - training loss: 0.3496, validation loss: 0.1735
2024-05-25 08:59:44 [INFO]: Epoch 050 - training loss: 0.3482, validation loss: 0.1720
2024-05-25 08:59:47 [INFO]: Epoch 051 - training loss: 0.3454, validation loss: 0.1700
2024-05-25 08:59:50 [INFO]: Epoch 052 - training loss: 0.3437, validation loss: 0.1688
2024-05-25 08:59:53 [INFO]: Epoch 053 - training loss: 0.3418, validation loss: 0.1673
2024-05-25 08:59:56 [INFO]: Epoch 054 - training loss: 0.3394, validation loss: 0.1660
2024-05-25 08:59:59 [INFO]: Epoch 055 - training loss: 0.3374, validation loss: 0.1643
2024-05-25 09:00:02 [INFO]: Epoch 056 - training loss: 0.3353, validation loss: 0.1632
2024-05-25 09:00:05 [INFO]: Epoch 057 - training loss: 0.3332, validation loss: 0.1620
2024-05-25 09:00:07 [INFO]: Epoch 058 - training loss: 0.3315, validation loss: 0.1608
2024-05-25 09:00:10 [INFO]: Epoch 059 - training loss: 0.3306, validation loss: 0.1595
2024-05-25 09:00:13 [INFO]: Epoch 060 - training loss: 0.3280, validation loss: 0.1585
2024-05-25 09:00:16 [INFO]: Epoch 061 - training loss: 0.3267, validation loss: 0.1577
2024-05-25 09:00:19 [INFO]: Epoch 062 - training loss: 0.3247, validation loss: 0.1566
2024-05-25 09:00:22 [INFO]: Epoch 063 - training loss: 0.3230, validation loss: 0.1556
2024-05-25 09:00:25 [INFO]: Epoch 064 - training loss: 0.3214, validation loss: 0.1547
2024-05-25 09:00:28 [INFO]: Epoch 065 - training loss: 0.3202, validation loss: 0.1540
2024-05-25 09:00:31 [INFO]: Epoch 066 - training loss: 0.3188, validation loss: 0.1532
2024-05-25 09:00:34 [INFO]: Epoch 067 - training loss: 0.3179, validation loss: 0.1524
2024-05-25 09:00:37 [INFO]: Epoch 068 - training loss: 0.3169, validation loss: 0.1514
2024-05-25 09:00:40 [INFO]: Epoch 069 - training loss: 0.3149, validation loss: 0.1509
2024-05-25 09:00:42 [INFO]: Epoch 070 - training loss: 0.3131, validation loss: 0.1501
2024-05-25 09:00:45 [INFO]: Epoch 071 - training loss: 0.3127, validation loss: 0.1495
2024-05-25 09:00:48 [INFO]: Epoch 072 - training loss: 0.3117, validation loss: 0.1490
2024-05-25 09:00:51 [INFO]: Epoch 073 - training loss: 0.3113, validation loss: 0.1482
2024-05-25 09:00:54 [INFO]: Epoch 074 - training loss: 0.3093, validation loss: 0.1476
2024-05-25 09:00:57 [INFO]: Epoch 075 - training loss: 0.3084, validation loss: 0.1471
2024-05-25 09:01:00 [INFO]: Epoch 076 - training loss: 0.3070, validation loss: 0.1466
2024-05-25 09:01:02 [INFO]: Epoch 077 - training loss: 0.3060, validation loss: 0.1459
2024-05-25 09:01:05 [INFO]: Epoch 078 - training loss: 0.3046, validation loss: 0.1452
2024-05-25 09:01:08 [INFO]: Epoch 079 - training loss: 0.3042, validation loss: 0.1450
2024-05-25 09:01:11 [INFO]: Epoch 080 - training loss: 0.3035, validation loss: 0.1443
2024-05-25 09:01:14 [INFO]: Epoch 081 - training loss: 0.3021, validation loss: 0.1440
2024-05-25 09:01:17 [INFO]: Epoch 082 - training loss: 0.3009, validation loss: 0.1436
2024-05-25 09:01:20 [INFO]: Epoch 083 - training loss: 0.3008, validation loss: 0.1431
2024-05-25 09:01:23 [INFO]: Epoch 084 - training loss: 0.2999, validation loss: 0.1427
2024-05-25 09:01:26 [INFO]: Epoch 085 - training loss: 0.2986, validation loss: 0.1421
2024-05-25 09:01:29 [INFO]: Epoch 086 - training loss: 0.2983, validation loss: 0.1418
2024-05-25 09:01:32 [INFO]: Epoch 087 - training loss: 0.2969, validation loss: 0.1412
2024-05-25 09:01:35 [INFO]: Epoch 088 - training loss: 0.2962, validation loss: 0.1409
2024-05-25 09:01:37 [INFO]: Epoch 089 - training loss: 0.2952, validation loss: 0.1404
2024-05-25 09:01:40 [INFO]: Epoch 090 - training loss: 0.2957, validation loss: 0.1402
2024-05-25 09:01:43 [INFO]: Epoch 091 - training loss: 0.2937, validation loss: 0.1400
2024-05-25 09:01:46 [INFO]: Epoch 092 - training loss: 0.2932, validation loss: 0.1398
2024-05-25 09:01:49 [INFO]: Epoch 093 - training loss: 0.2927, validation loss: 0.1393
2024-05-25 09:01:52 [INFO]: Epoch 094 - training loss: 0.2916, validation loss: 0.1389
2024-05-25 09:01:55 [INFO]: Epoch 095 - training loss: 0.2906, validation loss: 0.1386
2024-05-25 09:01:58 [INFO]: Epoch 096 - training loss: 0.2907, validation loss: 0.1383
2024-05-25 09:02:01 [INFO]: Epoch 097 - training loss: 0.2903, validation loss: 0.1380
2024-05-25 09:02:04 [INFO]: Epoch 098 - training loss: 0.2896, validation loss: 0.1378
2024-05-25 09:02:06 [INFO]: Epoch 099 - training loss: 0.2885, validation loss: 0.1374
2024-05-25 09:02:09 [INFO]: Epoch 100 - training loss: 0.2878, validation loss: 0.1371
2024-05-25 09:02:12 [INFO]: Epoch 101 - training loss: 0.2880, validation loss: 0.1366
2024-05-25 09:02:15 [INFO]: Epoch 102 - training loss: 0.2861, validation loss: 0.1366
2024-05-25 09:02:18 [INFO]: Epoch 103 - training loss: 0.2858, validation loss: 0.1362
2024-05-25 09:02:21 [INFO]: Epoch 104 - training loss: 0.2855, validation loss: 0.1359
2024-05-25 09:02:24 [INFO]: Epoch 105 - training loss: 0.2847, validation loss: 0.1355
2024-05-25 09:02:27 [INFO]: Epoch 106 - training loss: 0.2842, validation loss: 0.1352
2024-05-25 09:02:30 [INFO]: Epoch 107 - training loss: 0.2834, validation loss: 0.1351
2024-05-25 09:02:33 [INFO]: Epoch 108 - training loss: 0.2829, validation loss: 0.1346
2024-05-25 09:02:36 [INFO]: Epoch 109 - training loss: 0.2825, validation loss: 0.1343
2024-05-25 09:02:39 [INFO]: Epoch 110 - training loss: 0.2816, validation loss: 0.1339
2024-05-25 09:02:41 [INFO]: Epoch 111 - training loss: 0.2817, validation loss: 0.1338
2024-05-25 09:02:44 [INFO]: Epoch 112 - training loss: 0.2801, validation loss: 0.1334
2024-05-25 09:02:47 [INFO]: Epoch 113 - training loss: 0.2799, validation loss: 0.1334
2024-05-25 09:02:50 [INFO]: Epoch 114 - training loss: 0.2801, validation loss: 0.1330
2024-05-25 09:02:53 [INFO]: Epoch 115 - training loss: 0.2790, validation loss: 0.1329
2024-05-25 09:02:56 [INFO]: Epoch 116 - training loss: 0.2781, validation loss: 0.1325
2024-05-25 09:02:59 [INFO]: Epoch 117 - training loss: 0.2783, validation loss: 0.1323
2024-05-25 09:03:02 [INFO]: Epoch 118 - training loss: 0.2780, validation loss: 0.1320
2024-05-25 09:03:05 [INFO]: Epoch 119 - training loss: 0.2768, validation loss: 0.1317
2024-05-25 09:03:08 [INFO]: Epoch 120 - training loss: 0.2762, validation loss: 0.1313
2024-05-25 09:03:10 [INFO]: Epoch 121 - training loss: 0.2753, validation loss: 0.1310
2024-05-25 09:03:13 [INFO]: Epoch 122 - training loss: 0.2758, validation loss: 0.1310
2024-05-25 09:03:16 [INFO]: Epoch 123 - training loss: 0.2754, validation loss: 0.1306
2024-05-25 09:03:19 [INFO]: Epoch 124 - training loss: 0.2745, validation loss: 0.1302
2024-05-25 09:03:22 [INFO]: Epoch 125 - training loss: 0.2743, validation loss: 0.1299
2024-05-25 09:03:25 [INFO]: Epoch 126 - training loss: 0.2734, validation loss: 0.1298
2024-05-25 09:03:28 [INFO]: Epoch 127 - training loss: 0.2739, validation loss: 0.1294
2024-05-25 09:03:31 [INFO]: Epoch 128 - training loss: 0.2732, validation loss: 0.1292
2024-05-25 09:03:34 [INFO]: Epoch 129 - training loss: 0.2719, validation loss: 0.1291
2024-05-25 09:03:37 [INFO]: Epoch 130 - training loss: 0.2718, validation loss: 0.1287
2024-05-25 09:03:40 [INFO]: Epoch 131 - training loss: 0.2716, validation loss: 0.1284
2024-05-25 09:03:43 [INFO]: Epoch 132 - training loss: 0.2711, validation loss: 0.1280
2024-05-25 09:03:46 [INFO]: Epoch 133 - training loss: 0.2707, validation loss: 0.1278
2024-05-25 09:03:49 [INFO]: Epoch 134 - training loss: 0.2700, validation loss: 0.1276
2024-05-25 09:03:51 [INFO]: Epoch 135 - training loss: 0.2694, validation loss: 0.1274
2024-05-25 09:03:54 [INFO]: Epoch 136 - training loss: 0.2697, validation loss: 0.1271
2024-05-25 09:03:57 [INFO]: Epoch 137 - training loss: 0.2690, validation loss: 0.1269
2024-05-25 09:04:00 [INFO]: Epoch 138 - training loss: 0.2685, validation loss: 0.1266
2024-05-25 09:04:03 [INFO]: Epoch 139 - training loss: 0.2684, validation loss: 0.1264
2024-05-25 09:04:06 [INFO]: Epoch 140 - training loss: 0.2681, validation loss: 0.1260
2024-05-25 09:04:09 [INFO]: Epoch 141 - training loss: 0.2673, validation loss: 0.1258
2024-05-25 09:04:12 [INFO]: Epoch 142 - training loss: 0.2668, validation loss: 0.1257
2024-05-25 09:04:15 [INFO]: Epoch 143 - training loss: 0.2666, validation loss: 0.1255
2024-05-25 09:04:18 [INFO]: Epoch 144 - training loss: 0.2663, validation loss: 0.1250
2024-05-25 09:04:21 [INFO]: Epoch 145 - training loss: 0.2656, validation loss: 0.1248
2024-05-25 09:04:23 [INFO]: Epoch 146 - training loss: 0.2654, validation loss: 0.1245
2024-05-25 09:04:26 [INFO]: Epoch 147 - training loss: 0.2651, validation loss: 0.1243
2024-05-25 09:04:29 [INFO]: Epoch 148 - training loss: 0.2648, validation loss: 0.1241
2024-05-25 09:04:32 [INFO]: Epoch 149 - training loss: 0.2643, validation loss: 0.1241
2024-05-25 09:04:35 [INFO]: Epoch 150 - training loss: 0.2641, validation loss: 0.1237
2024-05-25 09:04:38 [INFO]: Epoch 151 - training loss: 0.2633, validation loss: 0.1234
2024-05-25 09:04:41 [INFO]: Epoch 152 - training loss: 0.2635, validation loss: 0.1234
2024-05-25 09:04:44 [INFO]: Epoch 153 - training loss: 0.2638, validation loss: 0.1231
2024-05-25 09:04:47 [INFO]: Epoch 154 - training loss: 0.2625, validation loss: 0.1230
2024-05-25 09:04:50 [INFO]: Epoch 155 - training loss: 0.2631, validation loss: 0.1227
2024-05-25 09:04:53 [INFO]: Epoch 156 - training loss: 0.2621, validation loss: 0.1227
2024-05-25 09:04:55 [INFO]: Epoch 157 - training loss: 0.2623, validation loss: 0.1224
2024-05-25 09:04:58 [INFO]: Epoch 158 - training loss: 0.2617, validation loss: 0.1222
2024-05-25 09:05:01 [INFO]: Epoch 159 - training loss: 0.2611, validation loss: 0.1218
2024-05-25 09:05:04 [INFO]: Epoch 160 - training loss: 0.2610, validation loss: 0.1219
2024-05-25 09:05:07 [INFO]: Epoch 161 - training loss: 0.2601, validation loss: 0.1218
2024-05-25 09:05:10 [INFO]: Epoch 162 - training loss: 0.2598, validation loss: 0.1214
2024-05-25 09:05:13 [INFO]: Epoch 163 - training loss: 0.2605, validation loss: 0.1213
2024-05-25 09:05:16 [INFO]: Epoch 164 - training loss: 0.2594, validation loss: 0.1209
2024-05-25 09:05:19 [INFO]: Epoch 165 - training loss: 0.2592, validation loss: 0.1208
2024-05-25 09:05:22 [INFO]: Epoch 166 - training loss: 0.2592, validation loss: 0.1207
2024-05-25 09:05:25 [INFO]: Epoch 167 - training loss: 0.2592, validation loss: 0.1205
2024-05-25 09:05:28 [INFO]: Epoch 168 - training loss: 0.2583, validation loss: 0.1202
2024-05-25 09:05:30 [INFO]: Epoch 169 - training loss: 0.2584, validation loss: 0.1201
2024-05-25 09:05:33 [INFO]: Epoch 170 - training loss: 0.2579, validation loss: 0.1201
2024-05-25 09:05:36 [INFO]: Epoch 171 - training loss: 0.2577, validation loss: 0.1198
2024-05-25 09:05:39 [INFO]: Epoch 172 - training loss: 0.2581, validation loss: 0.1195
2024-05-25 09:05:42 [INFO]: Epoch 173 - training loss: 0.2573, validation loss: 0.1195
2024-05-25 09:05:45 [INFO]: Epoch 174 - training loss: 0.2569, validation loss: 0.1191
2024-05-25 09:05:48 [INFO]: Epoch 175 - training loss: 0.2566, validation loss: 0.1192
2024-05-25 09:05:51 [INFO]: Epoch 176 - training loss: 0.2567, validation loss: 0.1188
2024-05-25 09:05:54 [INFO]: Epoch 177 - training loss: 0.2560, validation loss: 0.1188
2024-05-25 09:05:57 [INFO]: Epoch 178 - training loss: 0.2561, validation loss: 0.1186
2024-05-25 09:06:00 [INFO]: Epoch 179 - training loss: 0.2560, validation loss: 0.1184
2024-05-25 09:06:03 [INFO]: Epoch 180 - training loss: 0.2555, validation loss: 0.1182
2024-05-25 09:06:06 [INFO]: Epoch 181 - training loss: 0.2552, validation loss: 0.1180
2024-05-25 09:06:08 [INFO]: Epoch 182 - training loss: 0.2547, validation loss: 0.1181
2024-05-25 09:06:11 [INFO]: Epoch 183 - training loss: 0.2546, validation loss: 0.1177
2024-05-25 09:06:14 [INFO]: Epoch 184 - training loss: 0.2545, validation loss: 0.1178
2024-05-25 09:06:17 [INFO]: Epoch 185 - training loss: 0.2545, validation loss: 0.1175
2024-05-25 09:06:20 [INFO]: Epoch 186 - training loss: 0.2540, validation loss: 0.1174
2024-05-25 09:06:23 [INFO]: Epoch 187 - training loss: 0.2541, validation loss: 0.1174
2024-05-25 09:06:26 [INFO]: Epoch 188 - training loss: 0.2534, validation loss: 0.1172
2024-05-25 09:06:29 [INFO]: Epoch 189 - training loss: 0.2534, validation loss: 0.1168
2024-05-25 09:06:32 [INFO]: Epoch 190 - training loss: 0.2526, validation loss: 0.1168
2024-05-25 09:06:35 [INFO]: Epoch 191 - training loss: 0.2537, validation loss: 0.1165
2024-05-25 09:06:38 [INFO]: Epoch 192 - training loss: 0.2523, validation loss: 0.1167
2024-05-25 09:06:41 [INFO]: Epoch 193 - training loss: 0.2521, validation loss: 0.1165
2024-05-25 09:06:43 [INFO]: Epoch 194 - training loss: 0.2520, validation loss: 0.1162
2024-05-25 09:06:46 [INFO]: Epoch 195 - training loss: 0.2519, validation loss: 0.1163
2024-05-25 09:06:49 [INFO]: Epoch 196 - training loss: 0.2517, validation loss: 0.1161
2024-05-25 09:06:52 [INFO]: Epoch 197 - training loss: 0.2512, validation loss: 0.1160
2024-05-25 09:06:55 [INFO]: Epoch 198 - training loss: 0.2509, validation loss: 0.1160
2024-05-25 09:06:58 [INFO]: Epoch 199 - training loss: 0.2515, validation loss: 0.1159
2024-05-25 09:07:01 [INFO]: Epoch 200 - training loss: 0.2508, validation loss: 0.1157
2024-05-25 09:07:04 [INFO]: Epoch 201 - training loss: 0.2500, validation loss: 0.1156
2024-05-25 09:07:07 [INFO]: Epoch 202 - training loss: 0.2505, validation loss: 0.1154
2024-05-25 09:07:10 [INFO]: Epoch 203 - training loss: 0.2499, validation loss: 0.1155
2024-05-25 09:07:13 [INFO]: Epoch 204 - training loss: 0.2500, validation loss: 0.1153
2024-05-25 09:07:15 [INFO]: Epoch 205 - training loss: 0.2500, validation loss: 0.1151
2024-05-25 09:07:18 [INFO]: Epoch 206 - training loss: 0.2496, validation loss: 0.1150
2024-05-25 09:07:21 [INFO]: Epoch 207 - training loss: 0.2491, validation loss: 0.1148
2024-05-25 09:07:24 [INFO]: Epoch 208 - training loss: 0.2487, validation loss: 0.1147
2024-05-25 09:07:27 [INFO]: Epoch 209 - training loss: 0.2488, validation loss: 0.1146
2024-05-25 09:07:30 [INFO]: Epoch 210 - training loss: 0.2488, validation loss: 0.1145
2024-05-25 09:07:33 [INFO]: Epoch 211 - training loss: 0.2484, validation loss: 0.1144
2024-05-25 09:07:36 [INFO]: Epoch 212 - training loss: 0.2481, validation loss: 0.1142
2024-05-25 09:07:39 [INFO]: Epoch 213 - training loss: 0.2481, validation loss: 0.1143
2024-05-25 09:07:42 [INFO]: Epoch 214 - training loss: 0.2482, validation loss: 0.1141
2024-05-25 09:07:45 [INFO]: Epoch 215 - training loss: 0.2479, validation loss: 0.1140
2024-05-25 09:07:48 [INFO]: Epoch 216 - training loss: 0.2476, validation loss: 0.1140
2024-05-25 09:07:51 [INFO]: Epoch 217 - training loss: 0.2476, validation loss: 0.1138
2024-05-25 09:07:53 [INFO]: Epoch 218 - training loss: 0.2480, validation loss: 0.1137
2024-05-25 09:07:56 [INFO]: Epoch 219 - training loss: 0.2471, validation loss: 0.1134
2024-05-25 09:07:59 [INFO]: Epoch 220 - training loss: 0.2473, validation loss: 0.1136
2024-05-25 09:08:02 [INFO]: Epoch 221 - training loss: 0.2471, validation loss: 0.1135
2024-05-25 09:08:05 [INFO]: Epoch 222 - training loss: 0.2464, validation loss: 0.1135
2024-05-25 09:08:08 [INFO]: Epoch 223 - training loss: 0.2462, validation loss: 0.1133
2024-05-25 09:08:11 [INFO]: Epoch 224 - training loss: 0.2459, validation loss: 0.1130
2024-05-25 09:08:14 [INFO]: Epoch 225 - training loss: 0.2457, validation loss: 0.1132
2024-05-25 09:08:16 [INFO]: Epoch 226 - training loss: 0.2456, validation loss: 0.1132
2024-05-25 09:08:19 [INFO]: Epoch 227 - training loss: 0.2455, validation loss: 0.1131
2024-05-25 09:08:22 [INFO]: Epoch 228 - training loss: 0.2453, validation loss: 0.1129
2024-05-25 09:08:25 [INFO]: Epoch 229 - training loss: 0.2453, validation loss: 0.1129
2024-05-25 09:08:28 [INFO]: Epoch 230 - training loss: 0.2445, validation loss: 0.1127
2024-05-25 09:08:31 [INFO]: Epoch 231 - training loss: 0.2448, validation loss: 0.1127
2024-05-25 09:08:34 [INFO]: Epoch 232 - training loss: 0.2448, validation loss: 0.1126
2024-05-25 09:08:37 [INFO]: Epoch 233 - training loss: 0.2443, validation loss: 0.1126
2024-05-25 09:08:40 [INFO]: Epoch 234 - training loss: 0.2443, validation loss: 0.1125
2024-05-25 09:08:43 [INFO]: Epoch 235 - training loss: 0.2438, validation loss: 0.1125
2024-05-25 09:08:46 [INFO]: Epoch 236 - training loss: 0.2441, validation loss: 0.1123
2024-05-25 09:08:49 [INFO]: Epoch 237 - training loss: 0.2437, validation loss: 0.1124
2024-05-25 09:08:51 [INFO]: Epoch 238 - training loss: 0.2441, validation loss: 0.1122
2024-05-25 09:08:54 [INFO]: Epoch 239 - training loss: 0.2439, validation loss: 0.1121
2024-05-25 09:08:57 [INFO]: Epoch 240 - training loss: 0.2437, validation loss: 0.1119
2024-05-25 09:09:00 [INFO]: Epoch 241 - training loss: 0.2431, validation loss: 0.1119
2024-05-25 09:09:03 [INFO]: Epoch 242 - training loss: 0.2435, validation loss: 0.1119
2024-05-25 09:09:06 [INFO]: Epoch 243 - training loss: 0.2431, validation loss: 0.1118
2024-05-25 09:09:09 [INFO]: Epoch 244 - training loss: 0.2429, validation loss: 0.1118
2024-05-25 09:09:12 [INFO]: Epoch 245 - training loss: 0.2425, validation loss: 0.1115
2024-05-25 09:09:15 [INFO]: Epoch 246 - training loss: 0.2426, validation loss: 0.1118
2024-05-25 09:09:18 [INFO]: Epoch 247 - training loss: 0.2424, validation loss: 0.1115
2024-05-25 09:09:21 [INFO]: Epoch 248 - training loss: 0.2420, validation loss: 0.1115
2024-05-25 09:09:23 [INFO]: Epoch 249 - training loss: 0.2418, validation loss: 0.1115
2024-05-25 09:09:26 [INFO]: Epoch 250 - training loss: 0.2420, validation loss: 0.1114
2024-05-25 09:09:29 [INFO]: Epoch 251 - training loss: 0.2421, validation loss: 0.1113
2024-05-25 09:09:32 [INFO]: Epoch 252 - training loss: 0.2414, validation loss: 0.1113
2024-05-25 09:09:35 [INFO]: Epoch 253 - training loss: 0.2418, validation loss: 0.1113
2024-05-25 09:09:38 [INFO]: Epoch 254 - training loss: 0.2420, validation loss: 0.1110
2024-05-25 09:09:41 [INFO]: Epoch 255 - training loss: 0.2408, validation loss: 0.1111
2024-05-25 09:09:44 [INFO]: Epoch 256 - training loss: 0.2409, validation loss: 0.1110
2024-05-25 09:09:47 [INFO]: Epoch 257 - training loss: 0.2409, validation loss: 0.1112
2024-05-25 09:09:50 [INFO]: Epoch 258 - training loss: 0.2409, validation loss: 0.1110
2024-05-25 09:09:53 [INFO]: Epoch 259 - training loss: 0.2406, validation loss: 0.1109
2024-05-25 09:09:55 [INFO]: Epoch 260 - training loss: 0.2402, validation loss: 0.1108
2024-05-25 09:09:59 [INFO]: Epoch 261 - training loss: 0.2400, validation loss: 0.1109
2024-05-25 09:10:01 [INFO]: Epoch 262 - training loss: 0.2398, validation loss: 0.1108
2024-05-25 09:10:04 [INFO]: Epoch 263 - training loss: 0.2400, validation loss: 0.1107
2024-05-25 09:10:07 [INFO]: Epoch 264 - training loss: 0.2399, validation loss: 0.1109
2024-05-25 09:10:10 [INFO]: Epoch 265 - training loss: 0.2398, validation loss: 0.1107
2024-05-25 09:10:13 [INFO]: Epoch 266 - training loss: 0.2392, validation loss: 0.1107
2024-05-25 09:10:16 [INFO]: Epoch 267 - training loss: 0.2400, validation loss: 0.1105
2024-05-25 09:10:19 [INFO]: Epoch 268 - training loss: 0.2391, validation loss: 0.1105
2024-05-25 09:10:22 [INFO]: Epoch 269 - training loss: 0.2390, validation loss: 0.1105
2024-05-25 09:10:25 [INFO]: Epoch 270 - training loss: 0.2391, validation loss: 0.1105
2024-05-25 09:10:28 [INFO]: Epoch 271 - training loss: 0.2390, validation loss: 0.1104
2024-05-25 09:10:31 [INFO]: Epoch 272 - training loss: 0.2390, validation loss: 0.1103
2024-05-25 09:10:33 [INFO]: Epoch 273 - training loss: 0.2390, validation loss: 0.1104
2024-05-25 09:10:36 [INFO]: Epoch 274 - training loss: 0.2391, validation loss: 0.1102
2024-05-25 09:10:39 [INFO]: Epoch 275 - training loss: 0.2385, validation loss: 0.1101
2024-05-25 09:10:42 [INFO]: Epoch 276 - training loss: 0.2382, validation loss: 0.1102
2024-05-25 09:10:45 [INFO]: Epoch 277 - training loss: 0.2382, validation loss: 0.1102
2024-05-25 09:10:48 [INFO]: Epoch 278 - training loss: 0.2384, validation loss: 0.1103
2024-05-25 09:10:51 [INFO]: Epoch 279 - training loss: 0.2382, validation loss: 0.1101
2024-05-25 09:10:54 [INFO]: Epoch 280 - training loss: 0.2381, validation loss: 0.1102
2024-05-25 09:10:57 [INFO]: Epoch 281 - training loss: 0.2378, validation loss: 0.1101
2024-05-25 09:11:00 [INFO]: Epoch 282 - training loss: 0.2377, validation loss: 0.1100
2024-05-25 09:11:03 [INFO]: Epoch 283 - training loss: 0.2374, validation loss: 0.1099
2024-05-25 09:11:06 [INFO]: Epoch 284 - training loss: 0.2375, validation loss: 0.1099
2024-05-25 09:11:09 [INFO]: Epoch 285 - training loss: 0.2368, validation loss: 0.1101
2024-05-25 09:11:11 [INFO]: Epoch 286 - training loss: 0.2368, validation loss: 0.1096
2024-05-25 09:11:14 [INFO]: Epoch 287 - training loss: 0.2372, validation loss: 0.1101
2024-05-25 09:11:17 [INFO]: Epoch 288 - training loss: 0.2364, validation loss: 0.1098
2024-05-25 09:11:20 [INFO]: Epoch 289 - training loss: 0.2369, validation loss: 0.1097
2024-05-25 09:11:23 [INFO]: Epoch 290 - training loss: 0.2371, validation loss: 0.1096
2024-05-25 09:11:26 [INFO]: Epoch 291 - training loss: 0.2364, validation loss: 0.1099
2024-05-25 09:11:29 [INFO]: Epoch 292 - training loss: 0.2361, validation loss: 0.1098
2024-05-25 09:11:32 [INFO]: Epoch 293 - training loss: 0.2362, validation loss: 0.1097
2024-05-25 09:11:35 [INFO]: Epoch 294 - training loss: 0.2365, validation loss: 0.1099
2024-05-25 09:11:38 [INFO]: Epoch 295 - training loss: 0.2359, validation loss: 0.1096
2024-05-25 09:11:41 [INFO]: Epoch 296 - training loss: 0.2358, validation loss: 0.1097
2024-05-25 09:11:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 09:11:41 [INFO]: Finished training. The best model is from epoch#286.
2024-05-25 09:11:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/BRITS_air_quality/20240525_T085718/BRITS.pypots
2024-05-25 09:11:41 [INFO]: BRITS on Air-Quality: MAE=0.1395, MSE=0.1883
2024-05-25 09:11:41 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/BRITS_air_quality/imputation.pkl
2024-05-25 09:11:41 [INFO]: Using the given device: cuda:0
2024-05-25 09:11:41 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141
2024-05-25 09:11:41 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/tensorboard
2024-05-25 09:11:41 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 09:11:46 [INFO]: Epoch 001 - training loss: 1.4187, validation loss: 0.8141
2024-05-25 09:11:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch1_loss0.814086452126503.pypots
2024-05-25 09:11:50 [INFO]: Epoch 002 - training loss: 1.0362, validation loss: 0.7554
2024-05-25 09:11:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch2_loss0.7553922384977341.pypots
2024-05-25 09:11:54 [INFO]: Epoch 003 - training loss: 0.9774, validation loss: 0.7266
2024-05-25 09:11:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch3_loss0.7266177058219909.pypots
2024-05-25 09:11:58 [INFO]: Epoch 004 - training loss: 0.9656, validation loss: 0.7126
2024-05-25 09:11:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch4_loss0.7126413881778717.pypots
2024-05-25 09:12:02 [INFO]: Epoch 005 - training loss: 0.9327, validation loss: 0.7035
2024-05-25 09:12:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch5_loss0.703453540802002.pypots
2024-05-25 09:12:06 [INFO]: Epoch 006 - training loss: 0.9170, validation loss: 0.6968
2024-05-25 09:12:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch6_loss0.6968047469854355.pypots
2024-05-25 09:12:10 [INFO]: Epoch 007 - training loss: 0.9245, validation loss: 0.6918
2024-05-25 09:12:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch7_loss0.6917691141366958.pypots
2024-05-25 09:12:14 [INFO]: Epoch 008 - training loss: 0.9132, validation loss: 0.6870
2024-05-25 09:12:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch8_loss0.6870172381401062.pypots
2024-05-25 09:12:18 [INFO]: Epoch 009 - training loss: 0.9016, validation loss: 0.6845
2024-05-25 09:12:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch9_loss0.6845178544521332.pypots
2024-05-25 09:12:22 [INFO]: Epoch 010 - training loss: 0.9005, validation loss: 0.6826
2024-05-25 09:12:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch10_loss0.6826323956251145.pypots
2024-05-25 09:12:26 [INFO]: Epoch 011 - training loss: 0.8963, validation loss: 0.6803
2024-05-25 09:12:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch11_loss0.6802852153778076.pypots
2024-05-25 09:12:30 [INFO]: Epoch 012 - training loss: 0.9035, validation loss: 0.6792
2024-05-25 09:12:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch12_loss0.679152661561966.pypots
2024-05-25 09:12:34 [INFO]: Epoch 013 - training loss: 0.8964, validation loss: 0.6786
2024-05-25 09:12:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch13_loss0.6785621374845505.pypots
2024-05-25 09:12:38 [INFO]: Epoch 014 - training loss: 0.8768, validation loss: 0.6762
2024-05-25 09:12:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch14_loss0.6761804103851319.pypots
2024-05-25 09:12:42 [INFO]: Epoch 015 - training loss: 0.8877, validation loss: 0.6758
2024-05-25 09:12:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch15_loss0.6758434683084488.pypots
2024-05-25 09:12:46 [INFO]: Epoch 016 - training loss: 0.8786, validation loss: 0.6767
2024-05-25 09:12:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch16_loss0.676683035492897.pypots
2024-05-25 09:12:50 [INFO]: Epoch 017 - training loss: 0.8707, validation loss: 0.6746
2024-05-25 09:12:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch17_loss0.6746005713939667.pypots
2024-05-25 09:12:54 [INFO]: Epoch 018 - training loss: 0.8531, validation loss: 0.6745
2024-05-25 09:12:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch18_loss0.674450820684433.pypots
2024-05-25 09:12:58 [INFO]: Epoch 019 - training loss: 0.8547, validation loss: 0.6742
2024-05-25 09:12:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch19_loss0.6741954535245895.pypots
2024-05-25 09:13:02 [INFO]: Epoch 020 - training loss: 0.8572, validation loss: 0.6735
2024-05-25 09:13:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch20_loss0.6734992623329162.pypots
2024-05-25 09:13:06 [INFO]: Epoch 021 - training loss: 0.8453, validation loss: 0.6742
2024-05-25 09:13:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch21_loss0.6741845607757568.pypots
2024-05-25 09:13:10 [INFO]: Epoch 022 - training loss: 0.8645, validation loss: 0.6734
2024-05-25 09:13:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch22_loss0.6734393090009689.pypots
2024-05-25 09:13:14 [INFO]: Epoch 023 - training loss: 0.8673, validation loss: 0.6727
2024-05-25 09:13:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch23_loss0.6726855725049973.pypots
2024-05-25 09:13:18 [INFO]: Epoch 024 - training loss: 0.8539, validation loss: 0.6727
2024-05-25 09:13:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch24_loss0.6727033972740173.pypots
2024-05-25 09:13:22 [INFO]: Epoch 025 - training loss: 0.8428, validation loss: 0.6739
2024-05-25 09:13:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch25_loss0.6738741815090179.pypots
2024-05-25 09:13:25 [INFO]: Epoch 026 - training loss: 0.8329, validation loss: 0.6727
2024-05-25 09:13:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch26_loss0.6727049052715302.pypots
2024-05-25 09:13:29 [INFO]: Epoch 027 - training loss: 0.8365, validation loss: 0.6739
2024-05-25 09:13:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch27_loss0.6739375948905945.pypots
2024-05-25 09:13:33 [INFO]: Epoch 028 - training loss: 0.8259, validation loss: 0.6733
2024-05-25 09:13:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch28_loss0.6733281254768372.pypots
2024-05-25 09:13:37 [INFO]: Epoch 029 - training loss: 0.8241, validation loss: 0.6740
2024-05-25 09:13:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch29_loss0.6740063220262528.pypots
2024-05-25 09:13:41 [INFO]: Epoch 030 - training loss: 0.8460, validation loss: 0.6759
2024-05-25 09:13:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch30_loss0.6758616477251053.pypots
2024-05-25 09:13:45 [INFO]: Epoch 031 - training loss: 0.8318, validation loss: 0.6755
2024-05-25 09:13:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch31_loss0.6755023449659348.pypots
2024-05-25 09:13:49 [INFO]: Epoch 032 - training loss: 0.8310, validation loss: 0.6748
2024-05-25 09:13:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch32_loss0.6747940361499787.pypots
2024-05-25 09:13:53 [INFO]: Epoch 033 - training loss: 0.8307, validation loss: 0.6734
2024-05-25 09:13:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN_epoch33_loss0.6733753651380538.pypots
2024-05-25 09:13:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 09:13:53 [INFO]: Finished training. The best model is from epoch#23.
2024-05-25 09:13:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240525_T091141/MRNN.pypots
2024-05-25 09:13:54 [INFO]: MRNN on Air-Quality: MAE=0.5276, MSE=0.7641
2024-05-25 09:13:54 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/MRNN_air_quality/imputation.pkl
2024-05-25 09:13:54 [INFO]: Using the given device: cpu
2024-05-25 09:13:54 [INFO]: LOCF on Air-Quality: MAE=0.2039, MSE=0.4028
2024-05-25 09:13:54 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_air_quality".
2024-05-25 09:13:54 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/LOCF_air_quality/imputation.pkl
2024-05-25 09:13:54 [INFO]: Median on Air-Quality: MAE=0.6702, MSE=1.1687
2024-05-25 09:13:54 [INFO]: Successfully created the given path "saved_results/round_4/Median_air_quality".
2024-05-25 09:13:54 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Median_air_quality/imputation.pkl
2024-05-25 09:13:54 [INFO]: Mean on Air-Quality: MAE=0.7021, MSE=1.1087
2024-05-25 09:13:54 [INFO]: Successfully created the given path "saved_results/round_4/Mean_air_quality".
2024-05-25 09:13:54 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Mean_air_quality/imputation.pkl
2024-05-25 09:13:54 [INFO]: 
SAITS on data/air_quality: MAE=0.1510.0004173286924914464, MSE=0.2170.002242083367957825
Transformer on data/air_quality: MAE=0.1690.0021061374704506447, MSE=0.2530.0041509200731409705
TimesNet on data/air_quality: MAE=0.1710.0020214571670909348, MSE=0.3230.01585207803947318
CSDI on data/air_quality: MAE=0.1230.023858587250405402, MSE=0.5400.38304575477132197
GPVAE on data/air_quality: MAE=0.2820.014877233739778936, MSE=0.3530.021383613811272507
USGAN on data/air_quality: MAE=0.1440.002781287581802826, MSE=0.1780.003647094555711301
BRITS on data/air_quality: MAE=0.1390.0006123222274655343, MSE=0.1850.004068187334643792
MRNN on data/air_quality: MAE=0.5280.0005346021943143238, MSE=0.7660.0011272703671758705
LOCF on data/air_quality: MAE=0.2040.0, MSE=0.4030.0
Median on data/air_quality: MAE=0.6700.0, MSE=1.1690.0
Mean on data/air_quality: MAE=0.7020.0, MSE=1.1090.0