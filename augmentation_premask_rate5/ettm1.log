2024-05-24 21:01:08 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-24 21:01:08 [INFO]: Using the given device: cuda:0
2024-05-24 21:01:09 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/SAITS_ettm1/20240524_T210109
2024-05-24 21:01:09 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/SAITS_ettm1/20240524_T210109/tensorboard
2024-05-24 21:01:09 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 21:01:19 [INFO]: Epoch 001 - training loss: 1.1892, validation loss: 0.2262
2024-05-24 21:01:20 [INFO]: Epoch 002 - training loss: 0.9034, validation loss: 0.1106
2024-05-24 21:01:20 [INFO]: Epoch 003 - training loss: 0.7585, validation loss: 0.1004
2024-05-24 21:01:21 [INFO]: Epoch 004 - training loss: 0.7203, validation loss: 0.0767
2024-05-24 21:01:21 [INFO]: Epoch 005 - training loss: 0.7029, validation loss: 0.0872
2024-05-24 21:01:22 [INFO]: Epoch 006 - training loss: 0.6722, validation loss: 0.0619
2024-05-24 21:01:22 [INFO]: Epoch 007 - training loss: 0.6434, validation loss: 0.0638
2024-05-24 21:01:23 [INFO]: Epoch 008 - training loss: 0.6227, validation loss: 0.0602
2024-05-24 21:01:23 [INFO]: Epoch 009 - training loss: 0.6197, validation loss: 0.0822
2024-05-24 21:01:24 [INFO]: Epoch 010 - training loss: 0.6192, validation loss: 0.0742
2024-05-24 21:01:24 [INFO]: Epoch 011 - training loss: 0.6064, validation loss: 0.0558
2024-05-24 21:01:25 [INFO]: Epoch 012 - training loss: 0.5863, validation loss: 0.0539
2024-05-24 21:01:25 [INFO]: Epoch 013 - training loss: 0.5729, validation loss: 0.0456
2024-05-24 21:01:26 [INFO]: Epoch 014 - training loss: 0.5730, validation loss: 0.0472
2024-05-24 21:01:26 [INFO]: Epoch 015 - training loss: 0.5608, validation loss: 0.0577
2024-05-24 21:01:27 [INFO]: Epoch 016 - training loss: 0.5701, validation loss: 0.0457
2024-05-24 21:01:27 [INFO]: Epoch 017 - training loss: 0.5808, validation loss: 0.0527
2024-05-24 21:01:28 [INFO]: Epoch 018 - training loss: 0.5562, validation loss: 0.0458
2024-05-24 21:01:28 [INFO]: Epoch 019 - training loss: 0.5673, validation loss: 0.0518
2024-05-24 21:01:29 [INFO]: Epoch 020 - training loss: 0.5407, validation loss: 0.0554
2024-05-24 21:01:29 [INFO]: Epoch 021 - training loss: 0.5344, validation loss: 0.0496
2024-05-24 21:01:29 [INFO]: Epoch 022 - training loss: 0.5315, validation loss: 0.0478
2024-05-24 21:01:30 [INFO]: Epoch 023 - training loss: 0.5215, validation loss: 0.0426
2024-05-24 21:01:30 [INFO]: Epoch 024 - training loss: 0.5128, validation loss: 0.0379
2024-05-24 21:01:31 [INFO]: Epoch 025 - training loss: 0.5084, validation loss: 0.0530
2024-05-24 21:01:31 [INFO]: Epoch 026 - training loss: 0.5230, validation loss: 0.0386
2024-05-24 21:01:32 [INFO]: Epoch 027 - training loss: 0.5030, validation loss: 0.0354
2024-05-24 21:01:32 [INFO]: Epoch 028 - training loss: 0.4858, validation loss: 0.0435
2024-05-24 21:01:33 [INFO]: Epoch 029 - training loss: 0.4780, validation loss: 0.0405
2024-05-24 21:01:33 [INFO]: Epoch 030 - training loss: 0.4848, validation loss: 0.0489
2024-05-24 21:01:34 [INFO]: Epoch 031 - training loss: 0.5053, validation loss: 0.0435
2024-05-24 21:01:34 [INFO]: Epoch 032 - training loss: 0.4896, validation loss: 0.0429
2024-05-24 21:01:35 [INFO]: Epoch 033 - training loss: 0.4696, validation loss: 0.0402
2024-05-24 21:01:35 [INFO]: Epoch 034 - training loss: 0.4637, validation loss: 0.0449
2024-05-24 21:01:36 [INFO]: Epoch 035 - training loss: 0.4589, validation loss: 0.0378
2024-05-24 21:01:36 [INFO]: Epoch 036 - training loss: 0.4473, validation loss: 0.0397
2024-05-24 21:01:37 [INFO]: Epoch 037 - training loss: 0.4478, validation loss: 0.0455
2024-05-24 21:01:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:01:37 [INFO]: Finished training. The best model is from epoch#27.
2024-05-24 21:01:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/SAITS_ettm1/20240524_T210109/SAITS.pypots
2024-05-24 21:01:37 [INFO]: SAITS on ETTm1: MAE=0.2069, MSE=0.0807
2024-05-24 21:01:37 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/SAITS_ettm1/imputation.pkl
2024-05-24 21:01:37 [INFO]: Using the given device: cuda:0
2024-05-24 21:01:37 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/Transformer_ettm1/20240524_T210137
2024-05-24 21:01:37 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/Transformer_ettm1/20240524_T210137/tensorboard
2024-05-24 21:01:37 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 21:01:37 [INFO]: Epoch 001 - training loss: 1.1340, validation loss: 0.2898
2024-05-24 21:01:37 [INFO]: Epoch 002 - training loss: 0.6615, validation loss: 0.1583
2024-05-24 21:01:38 [INFO]: Epoch 003 - training loss: 0.5344, validation loss: 0.1233
2024-05-24 21:01:38 [INFO]: Epoch 004 - training loss: 0.4829, validation loss: 0.0836
2024-05-24 21:01:38 [INFO]: Epoch 005 - training loss: 0.4513, validation loss: 0.0767
2024-05-24 21:01:38 [INFO]: Epoch 006 - training loss: 0.4173, validation loss: 0.0669
2024-05-24 21:01:38 [INFO]: Epoch 007 - training loss: 0.4058, validation loss: 0.0596
2024-05-24 21:01:38 [INFO]: Epoch 008 - training loss: 0.3845, validation loss: 0.0539
2024-05-24 21:01:39 [INFO]: Epoch 009 - training loss: 0.3753, validation loss: 0.0535
2024-05-24 21:01:39 [INFO]: Epoch 010 - training loss: 0.3694, validation loss: 0.0495
2024-05-24 21:01:39 [INFO]: Epoch 011 - training loss: 0.3585, validation loss: 0.0505
2024-05-24 21:01:39 [INFO]: Epoch 012 - training loss: 0.3527, validation loss: 0.0476
2024-05-24 21:01:40 [INFO]: Epoch 013 - training loss: 0.3416, validation loss: 0.0454
2024-05-24 21:01:40 [INFO]: Epoch 014 - training loss: 0.3446, validation loss: 0.0429
2024-05-24 21:01:40 [INFO]: Epoch 015 - training loss: 0.3256, validation loss: 0.0429
2024-05-24 21:01:40 [INFO]: Epoch 016 - training loss: 0.3286, validation loss: 0.0479
2024-05-24 21:01:40 [INFO]: Epoch 017 - training loss: 0.3246, validation loss: 0.0417
2024-05-24 21:01:41 [INFO]: Epoch 018 - training loss: 0.3190, validation loss: 0.0410
2024-05-24 21:01:41 [INFO]: Epoch 019 - training loss: 0.3115, validation loss: 0.0396
2024-05-24 21:01:41 [INFO]: Epoch 020 - training loss: 0.3043, validation loss: 0.0385
2024-05-24 21:01:41 [INFO]: Epoch 021 - training loss: 0.3041, validation loss: 0.0394
2024-05-24 21:01:41 [INFO]: Epoch 022 - training loss: 0.3092, validation loss: 0.0375
2024-05-24 21:01:42 [INFO]: Epoch 023 - training loss: 0.3066, validation loss: 0.0385
2024-05-24 21:01:42 [INFO]: Epoch 024 - training loss: 0.2982, validation loss: 0.0350
2024-05-24 21:01:42 [INFO]: Epoch 025 - training loss: 0.2884, validation loss: 0.0357
2024-05-24 21:01:42 [INFO]: Epoch 026 - training loss: 0.2801, validation loss: 0.0357
2024-05-24 21:01:42 [INFO]: Epoch 027 - training loss: 0.2906, validation loss: 0.0354
2024-05-24 21:01:43 [INFO]: Epoch 028 - training loss: 0.2981, validation loss: 0.0342
2024-05-24 21:01:43 [INFO]: Epoch 029 - training loss: 0.2834, validation loss: 0.0351
2024-05-24 21:01:43 [INFO]: Epoch 030 - training loss: 0.2735, validation loss: 0.0354
2024-05-24 21:01:43 [INFO]: Epoch 031 - training loss: 0.2727, validation loss: 0.0324
2024-05-24 21:01:43 [INFO]: Epoch 032 - training loss: 0.2647, validation loss: 0.0343
2024-05-24 21:01:44 [INFO]: Epoch 033 - training loss: 0.2690, validation loss: 0.0355
2024-05-24 21:01:44 [INFO]: Epoch 034 - training loss: 0.2656, validation loss: 0.0368
2024-05-24 21:01:44 [INFO]: Epoch 035 - training loss: 0.2736, validation loss: 0.0352
2024-05-24 21:01:44 [INFO]: Epoch 036 - training loss: 0.2701, validation loss: 0.0326
2024-05-24 21:01:44 [INFO]: Epoch 037 - training loss: 0.2601, validation loss: 0.0320
2024-05-24 21:01:45 [INFO]: Epoch 038 - training loss: 0.2540, validation loss: 0.0390
2024-05-24 21:01:45 [INFO]: Epoch 039 - training loss: 0.2702, validation loss: 0.0327
2024-05-24 21:01:45 [INFO]: Epoch 040 - training loss: 0.2647, validation loss: 0.0334
2024-05-24 21:01:45 [INFO]: Epoch 041 - training loss: 0.2613, validation loss: 0.0283
2024-05-24 21:01:45 [INFO]: Epoch 042 - training loss: 0.2498, validation loss: 0.0310
2024-05-24 21:01:45 [INFO]: Epoch 043 - training loss: 0.2465, validation loss: 0.0279
2024-05-24 21:01:46 [INFO]: Epoch 044 - training loss: 0.2367, validation loss: 0.0304
2024-05-24 21:01:46 [INFO]: Epoch 045 - training loss: 0.2460, validation loss: 0.0277
2024-05-24 21:01:46 [INFO]: Epoch 046 - training loss: 0.2382, validation loss: 0.0296
2024-05-24 21:01:46 [INFO]: Epoch 047 - training loss: 0.2417, validation loss: 0.0295
2024-05-24 21:01:46 [INFO]: Epoch 048 - training loss: 0.2394, validation loss: 0.0309
2024-05-24 21:01:47 [INFO]: Epoch 049 - training loss: 0.2312, validation loss: 0.0277
2024-05-24 21:01:47 [INFO]: Epoch 050 - training loss: 0.2289, validation loss: 0.0296
2024-05-24 21:01:47 [INFO]: Epoch 051 - training loss: 0.2366, validation loss: 0.0310
2024-05-24 21:01:47 [INFO]: Epoch 052 - training loss: 0.2312, validation loss: 0.0268
2024-05-24 21:01:47 [INFO]: Epoch 053 - training loss: 0.2266, validation loss: 0.0275
2024-05-24 21:01:48 [INFO]: Epoch 054 - training loss: 0.2301, validation loss: 0.0289
2024-05-24 21:01:48 [INFO]: Epoch 055 - training loss: 0.2280, validation loss: 0.0284
2024-05-24 21:01:48 [INFO]: Epoch 056 - training loss: 0.2272, validation loss: 0.0295
2024-05-24 21:01:48 [INFO]: Epoch 057 - training loss: 0.2252, validation loss: 0.0334
2024-05-24 21:01:48 [INFO]: Epoch 058 - training loss: 0.2314, validation loss: 0.0320
2024-05-24 21:01:49 [INFO]: Epoch 059 - training loss: 0.2278, validation loss: 0.0279
2024-05-24 21:01:49 [INFO]: Epoch 060 - training loss: 0.2228, validation loss: 0.0284
2024-05-24 21:01:49 [INFO]: Epoch 061 - training loss: 0.2177, validation loss: 0.0263
2024-05-24 21:01:49 [INFO]: Epoch 062 - training loss: 0.2161, validation loss: 0.0277
2024-05-24 21:01:49 [INFO]: Epoch 063 - training loss: 0.2175, validation loss: 0.0265
2024-05-24 21:01:50 [INFO]: Epoch 064 - training loss: 0.2107, validation loss: 0.0259
2024-05-24 21:01:50 [INFO]: Epoch 065 - training loss: 0.2089, validation loss: 0.0278
2024-05-24 21:01:50 [INFO]: Epoch 066 - training loss: 0.2147, validation loss: 0.0254
2024-05-24 21:01:50 [INFO]: Epoch 067 - training loss: 0.2091, validation loss: 0.0278
2024-05-24 21:01:50 [INFO]: Epoch 068 - training loss: 0.2131, validation loss: 0.0346
2024-05-24 21:01:51 [INFO]: Epoch 069 - training loss: 0.2264, validation loss: 0.0250
2024-05-24 21:01:51 [INFO]: Epoch 070 - training loss: 0.2050, validation loss: 0.0251
2024-05-24 21:01:51 [INFO]: Epoch 071 - training loss: 0.2098, validation loss: 0.0268
2024-05-24 21:01:51 [INFO]: Epoch 072 - training loss: 0.2089, validation loss: 0.0260
2024-05-24 21:01:51 [INFO]: Epoch 073 - training loss: 0.2103, validation loss: 0.0258
2024-05-24 21:01:51 [INFO]: Epoch 074 - training loss: 0.2027, validation loss: 0.0254
2024-05-24 21:01:52 [INFO]: Epoch 075 - training loss: 0.2048, validation loss: 0.0239
2024-05-24 21:01:52 [INFO]: Epoch 076 - training loss: 0.1963, validation loss: 0.0255
2024-05-24 21:01:52 [INFO]: Epoch 077 - training loss: 0.2049, validation loss: 0.0274
2024-05-24 21:01:52 [INFO]: Epoch 078 - training loss: 0.2012, validation loss: 0.0272
2024-05-24 21:01:52 [INFO]: Epoch 079 - training loss: 0.2156, validation loss: 0.0260
2024-05-24 21:01:53 [INFO]: Epoch 080 - training loss: 0.2044, validation loss: 0.0267
2024-05-24 21:01:53 [INFO]: Epoch 081 - training loss: 0.2016, validation loss: 0.0257
2024-05-24 21:01:53 [INFO]: Epoch 082 - training loss: 0.1987, validation loss: 0.0269
2024-05-24 21:01:53 [INFO]: Epoch 083 - training loss: 0.2003, validation loss: 0.0295
2024-05-24 21:01:53 [INFO]: Epoch 084 - training loss: 0.2056, validation loss: 0.0248
2024-05-24 21:01:54 [INFO]: Epoch 085 - training loss: 0.1960, validation loss: 0.0245
2024-05-24 21:01:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:01:54 [INFO]: Finished training. The best model is from epoch#75.
2024-05-24 21:01:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/Transformer_ettm1/20240524_T210137/Transformer.pypots
2024-05-24 21:01:54 [INFO]: Transformer on ETTm1: MAE=0.1349, MSE=0.0374
2024-05-24 21:01:54 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Transformer_ettm1/imputation.pkl
2024-05-24 21:01:54 [INFO]: Using the given device: cuda:0
2024-05-24 21:01:54 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/TimesNet_ettm1/20240524_T210154
2024-05-24 21:01:54 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/TimesNet_ettm1/20240524_T210154/tensorboard
2024-05-24 21:01:54 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 21:02:00 [INFO]: Epoch 001 - training loss: 0.1323, validation loss: 0.0495
2024-05-24 21:02:00 [INFO]: Epoch 002 - training loss: 0.0580, validation loss: 0.0361
2024-05-24 21:02:00 [INFO]: Epoch 003 - training loss: 0.0452, validation loss: 0.0298
2024-05-24 21:02:01 [INFO]: Epoch 004 - training loss: 0.0386, validation loss: 0.0273
2024-05-24 21:02:01 [INFO]: Epoch 005 - training loss: 0.0361, validation loss: 0.0259
2024-05-24 21:02:01 [INFO]: Epoch 006 - training loss: 0.0339, validation loss: 0.0247
2024-05-24 21:02:01 [INFO]: Epoch 007 - training loss: 0.0317, validation loss: 0.0246
2024-05-24 21:02:01 [INFO]: Epoch 008 - training loss: 0.0316, validation loss: 0.0242
2024-05-24 21:02:02 [INFO]: Epoch 009 - training loss: 0.0317, validation loss: 0.0249
2024-05-24 21:02:02 [INFO]: Epoch 010 - training loss: 0.0292, validation loss: 0.0237
2024-05-24 21:02:02 [INFO]: Epoch 011 - training loss: 0.0257, validation loss: 0.0220
2024-05-24 21:02:02 [INFO]: Epoch 012 - training loss: 0.0253, validation loss: 0.0227
2024-05-24 21:02:02 [INFO]: Epoch 013 - training loss: 0.0301, validation loss: 0.0249
2024-05-24 21:02:02 [INFO]: Epoch 014 - training loss: 0.0316, validation loss: 0.0238
2024-05-24 21:02:03 [INFO]: Epoch 015 - training loss: 0.0262, validation loss: 0.0221
2024-05-24 21:02:03 [INFO]: Epoch 016 - training loss: 0.0232, validation loss: 0.0205
2024-05-24 21:02:03 [INFO]: Epoch 017 - training loss: 0.0220, validation loss: 0.0213
2024-05-24 21:02:03 [INFO]: Epoch 018 - training loss: 0.0270, validation loss: 0.0222
2024-05-24 21:02:03 [INFO]: Epoch 019 - training loss: 0.0287, validation loss: 0.0235
2024-05-24 21:02:04 [INFO]: Epoch 020 - training loss: 0.0263, validation loss: 0.0227
2024-05-24 21:02:04 [INFO]: Epoch 021 - training loss: 0.0245, validation loss: 0.0235
2024-05-24 21:02:04 [INFO]: Epoch 022 - training loss: 0.0219, validation loss: 0.0217
2024-05-24 21:02:04 [INFO]: Epoch 023 - training loss: 0.0208, validation loss: 0.0208
2024-05-24 21:02:04 [INFO]: Epoch 024 - training loss: 0.0223, validation loss: 0.0237
2024-05-24 21:02:05 [INFO]: Epoch 025 - training loss: 0.0234, validation loss: 0.0219
2024-05-24 21:02:05 [INFO]: Epoch 026 - training loss: 0.0200, validation loss: 0.0210
2024-05-24 21:02:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:02:05 [INFO]: Finished training. The best model is from epoch#16.
2024-05-24 21:02:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/TimesNet_ettm1/20240524_T210154/TimesNet.pypots
2024-05-24 21:02:05 [INFO]: TimesNet on ETTm1: MAE=0.1031, MSE=0.0223
2024-05-24 21:02:05 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/TimesNet_ettm1/imputation.pkl
2024-05-24 21:02:05 [INFO]: Using the given device: cuda:0
2024-05-24 21:02:05 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205
2024-05-24 21:02:05 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/tensorboard
2024-05-24 21:02:05 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 21:02:08 [INFO]: Epoch 001 - training loss: 0.6763, validation loss: 0.4447
2024-05-24 21:02:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch1_loss0.44470930844545364.pypots
2024-05-24 21:02:10 [INFO]: Epoch 002 - training loss: 0.3728, validation loss: 0.3768
2024-05-24 21:02:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch2_loss0.3767849877476692.pypots
2024-05-24 21:02:12 [INFO]: Epoch 003 - training loss: 0.3511, validation loss: 0.3642
2024-05-24 21:02:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch3_loss0.3641882687807083.pypots
2024-05-24 21:02:14 [INFO]: Epoch 004 - training loss: 0.3556, validation loss: 0.3081
2024-05-24 21:02:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch4_loss0.30806948244571686.pypots
2024-05-24 21:02:16 [INFO]: Epoch 005 - training loss: 0.3395, validation loss: 0.2964
2024-05-24 21:02:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch5_loss0.2963660880923271.pypots
2024-05-24 21:02:18 [INFO]: Epoch 006 - training loss: 0.3315, validation loss: 0.2902
2024-05-24 21:02:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch6_loss0.2901977226138115.pypots
2024-05-24 21:02:20 [INFO]: Epoch 007 - training loss: 0.2590, validation loss: 0.2829
2024-05-24 21:02:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch7_loss0.2828732132911682.pypots
2024-05-24 21:02:22 [INFO]: Epoch 008 - training loss: 0.2753, validation loss: 0.2678
2024-05-24 21:02:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch8_loss0.2677549347281456.pypots
2024-05-24 21:02:24 [INFO]: Epoch 009 - training loss: 0.2840, validation loss: 0.2733
2024-05-24 21:02:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch9_loss0.273259773850441.pypots
2024-05-24 21:02:27 [INFO]: Epoch 010 - training loss: 0.3060, validation loss: 0.2616
2024-05-24 21:02:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch10_loss0.2616422176361084.pypots
2024-05-24 21:02:29 [INFO]: Epoch 011 - training loss: 0.2397, validation loss: 0.2546
2024-05-24 21:02:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch11_loss0.25459184870123863.pypots
2024-05-24 21:02:31 [INFO]: Epoch 012 - training loss: 0.3147, validation loss: 0.2718
2024-05-24 21:02:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch12_loss0.2717876508831978.pypots
2024-05-24 21:02:33 [INFO]: Epoch 013 - training loss: 0.2668, validation loss: 0.2486
2024-05-24 21:02:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch13_loss0.2485843449831009.pypots
2024-05-24 21:02:35 [INFO]: Epoch 014 - training loss: 0.2375, validation loss: 0.2330
2024-05-24 21:02:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch14_loss0.2329835370182991.pypots
2024-05-24 21:02:37 [INFO]: Epoch 015 - training loss: 0.2627, validation loss: 0.2311
2024-05-24 21:02:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch15_loss0.2311350367963314.pypots
2024-05-24 21:02:39 [INFO]: Epoch 016 - training loss: 0.2212, validation loss: 0.2311
2024-05-24 21:02:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch16_loss0.23111261799931526.pypots
2024-05-24 21:02:41 [INFO]: Epoch 017 - training loss: 0.2275, validation loss: 0.2235
2024-05-24 21:02:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch17_loss0.22349164262413979.pypots
2024-05-24 21:02:43 [INFO]: Epoch 018 - training loss: 0.2261, validation loss: 0.2175
2024-05-24 21:02:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch18_loss0.2174752913415432.pypots
2024-05-24 21:02:45 [INFO]: Epoch 019 - training loss: 0.2205, validation loss: 0.2116
2024-05-24 21:02:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch19_loss0.21157827228307724.pypots
2024-05-24 21:02:47 [INFO]: Epoch 020 - training loss: 0.2109, validation loss: 0.1973
2024-05-24 21:02:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch20_loss0.19732579216361046.pypots
2024-05-24 21:02:49 [INFO]: Epoch 021 - training loss: 0.2245, validation loss: 0.2143
2024-05-24 21:02:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch21_loss0.21429867669939995.pypots
2024-05-24 21:02:51 [INFO]: Epoch 022 - training loss: 0.2224, validation loss: 0.2245
2024-05-24 21:02:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch22_loss0.2245352305471897.pypots
2024-05-24 21:02:53 [INFO]: Epoch 023 - training loss: 0.2413, validation loss: 0.2110
2024-05-24 21:02:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch23_loss0.21099039167165756.pypots
2024-05-24 21:02:55 [INFO]: Epoch 024 - training loss: 0.2563, validation loss: 0.1993
2024-05-24 21:02:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch24_loss0.19927966594696045.pypots
2024-05-24 21:02:57 [INFO]: Epoch 025 - training loss: 0.2712, validation loss: 0.1956
2024-05-24 21:02:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch25_loss0.1955835334956646.pypots
2024-05-24 21:02:59 [INFO]: Epoch 026 - training loss: 0.2273, validation loss: 0.2039
2024-05-24 21:02:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch26_loss0.2038777507841587.pypots
2024-05-24 21:03:01 [INFO]: Epoch 027 - training loss: 0.1948, validation loss: 0.1934
2024-05-24 21:03:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch27_loss0.19342881068587303.pypots
2024-05-24 21:03:03 [INFO]: Epoch 028 - training loss: 0.2069, validation loss: 0.1839
2024-05-24 21:03:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch28_loss0.183896966278553.pypots
2024-05-24 21:03:05 [INFO]: Epoch 029 - training loss: 0.1839, validation loss: 0.1872
2024-05-24 21:03:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch29_loss0.1872049793601036.pypots
2024-05-24 21:03:07 [INFO]: Epoch 030 - training loss: 0.2158, validation loss: 0.2005
2024-05-24 21:03:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch30_loss0.2004946805536747.pypots
2024-05-24 21:03:09 [INFO]: Epoch 031 - training loss: 0.2465, validation loss: 0.2158
2024-05-24 21:03:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch31_loss0.2157796025276184.pypots
2024-05-24 21:03:11 [INFO]: Epoch 032 - training loss: 0.2045, validation loss: 0.1873
2024-05-24 21:03:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch32_loss0.18729211762547493.pypots
2024-05-24 21:03:14 [INFO]: Epoch 033 - training loss: 0.2469, validation loss: 0.1930
2024-05-24 21:03:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch33_loss0.19301634654402733.pypots
2024-05-24 21:03:16 [INFO]: Epoch 034 - training loss: 0.1899, validation loss: 0.2074
2024-05-24 21:03:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch34_loss0.2073885127902031.pypots
2024-05-24 21:03:18 [INFO]: Epoch 035 - training loss: 0.2277, validation loss: 0.1846
2024-05-24 21:03:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch35_loss0.18464570865035057.pypots
2024-05-24 21:03:20 [INFO]: Epoch 036 - training loss: 0.2102, validation loss: 0.1911
2024-05-24 21:03:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch36_loss0.1911042146384716.pypots
2024-05-24 21:03:22 [INFO]: Epoch 037 - training loss: 0.1868, validation loss: 0.1778
2024-05-24 21:03:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch37_loss0.17784486338496208.pypots
2024-05-24 21:03:24 [INFO]: Epoch 038 - training loss: 0.1774, validation loss: 0.1711
2024-05-24 21:03:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch38_loss0.17106393724679947.pypots
2024-05-24 21:03:26 [INFO]: Epoch 039 - training loss: 0.1761, validation loss: 0.1670
2024-05-24 21:03:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch39_loss0.16695865988731384.pypots
2024-05-24 21:03:28 [INFO]: Epoch 040 - training loss: 0.1702, validation loss: 0.1627
2024-05-24 21:03:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch40_loss0.16274189203977585.pypots
2024-05-24 21:03:30 [INFO]: Epoch 041 - training loss: 0.1793, validation loss: 0.1637
2024-05-24 21:03:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch41_loss0.16369105502963066.pypots
2024-05-24 21:03:32 [INFO]: Epoch 042 - training loss: 0.1649, validation loss: 0.1604
2024-05-24 21:03:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch42_loss0.1603676602244377.pypots
2024-05-24 21:03:34 [INFO]: Epoch 043 - training loss: 0.1511, validation loss: 0.1571
2024-05-24 21:03:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch43_loss0.15705612301826477.pypots
2024-05-24 21:03:36 [INFO]: Epoch 044 - training loss: 0.1691, validation loss: 0.1570
2024-05-24 21:03:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch44_loss0.15696698799729347.pypots
2024-05-24 21:03:38 [INFO]: Epoch 045 - training loss: 0.1451, validation loss: 0.1629
2024-05-24 21:03:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch45_loss0.1628977246582508.pypots
2024-05-24 21:03:40 [INFO]: Epoch 046 - training loss: 0.1651, validation loss: 0.1596
2024-05-24 21:03:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch46_loss0.15957661345601082.pypots
2024-05-24 21:03:42 [INFO]: Epoch 047 - training loss: 0.1554, validation loss: 0.1538
2024-05-24 21:03:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch47_loss0.15380145609378815.pypots
2024-05-24 21:03:44 [INFO]: Epoch 048 - training loss: 0.1466, validation loss: 0.1469
2024-05-24 21:03:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch48_loss0.14694229885935783.pypots
2024-05-24 21:03:46 [INFO]: Epoch 049 - training loss: 0.1949, validation loss: 0.1528
2024-05-24 21:03:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch49_loss0.1528112180531025.pypots
2024-05-24 21:03:48 [INFO]: Epoch 050 - training loss: 0.1500, validation loss: 0.1520
2024-05-24 21:03:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch50_loss0.15202012285590172.pypots
2024-05-24 21:03:50 [INFO]: Epoch 051 - training loss: 0.1401, validation loss: 0.1477
2024-05-24 21:03:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch51_loss0.1477164775133133.pypots
2024-05-24 21:03:52 [INFO]: Epoch 052 - training loss: 0.1594, validation loss: 0.1480
2024-05-24 21:03:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch52_loss0.148027915507555.pypots
2024-05-24 21:03:54 [INFO]: Epoch 053 - training loss: 0.1690, validation loss: 0.1470
2024-05-24 21:03:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch53_loss0.14703505113720894.pypots
2024-05-24 21:03:56 [INFO]: Epoch 054 - training loss: 0.1440, validation loss: 0.1509
2024-05-24 21:03:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch54_loss0.15094925463199615.pypots
2024-05-24 21:03:58 [INFO]: Epoch 055 - training loss: 0.1863, validation loss: 0.1726
2024-05-24 21:03:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch55_loss0.17259898781776428.pypots
2024-05-24 21:04:01 [INFO]: Epoch 056 - training loss: 0.1715, validation loss: 0.1696
2024-05-24 21:04:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch56_loss0.16956808790564537.pypots
2024-05-24 21:04:03 [INFO]: Epoch 057 - training loss: 0.1627, validation loss: 0.1601
2024-05-24 21:04:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch57_loss0.16005868837237358.pypots
2024-05-24 21:04:05 [INFO]: Epoch 058 - training loss: 0.1829, validation loss: 0.1638
2024-05-24 21:04:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI_epoch58_loss0.16381115838885307.pypots
2024-05-24 21:04:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:04:05 [INFO]: Finished training. The best model is from epoch#48.
2024-05-24 21:04:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T210205/CSDI.pypots
2024-05-24 21:04:20 [INFO]: CSDI on ETTm1: MAE=0.1640, MSE=0.0599
2024-05-24 21:04:20 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/CSDI_ettm1/imputation.pkl
2024-05-24 21:04:20 [INFO]: Using the given device: cuda:0
2024-05-24 21:04:20 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/GPVAE_ettm1/20240524_T210420
2024-05-24 21:04:20 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/GPVAE_ettm1/20240524_T210420/tensorboard
2024-05-24 21:04:20 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 21:04:22 [INFO]: Epoch 001 - training loss: 23200.7130, validation loss: 1.0175
2024-05-24 21:04:22 [INFO]: Epoch 002 - training loss: 20883.3679, validation loss: 0.9975
2024-05-24 21:04:23 [INFO]: Epoch 003 - training loss: 19022.0804, validation loss: 0.9810
2024-05-24 21:04:23 [INFO]: Epoch 004 - training loss: 16901.1153, validation loss: 0.9354
2024-05-24 21:04:23 [INFO]: Epoch 005 - training loss: 14968.0248, validation loss: 0.8384
2024-05-24 21:04:23 [INFO]: Epoch 006 - training loss: 13627.8572, validation loss: 0.7058
2024-05-24 21:04:23 [INFO]: Epoch 007 - training loss: 12431.9521, validation loss: 0.6075
2024-05-24 21:04:23 [INFO]: Epoch 008 - training loss: 11625.0249, validation loss: 0.5335
2024-05-24 21:04:23 [INFO]: Epoch 009 - training loss: 11158.4413, validation loss: 0.4999
2024-05-24 21:04:23 [INFO]: Epoch 010 - training loss: 10738.2096, validation loss: 0.4916
2024-05-24 21:04:24 [INFO]: Epoch 011 - training loss: 10542.8367, validation loss: 0.4697
2024-05-24 21:04:24 [INFO]: Epoch 012 - training loss: 10524.2462, validation loss: 0.4673
2024-05-24 21:04:24 [INFO]: Epoch 013 - training loss: 10188.7011, validation loss: 0.4633
2024-05-24 21:04:24 [INFO]: Epoch 014 - training loss: 10066.5833, validation loss: 0.4572
2024-05-24 21:04:24 [INFO]: Epoch 015 - training loss: 10004.2562, validation loss: 0.4216
2024-05-24 21:04:24 [INFO]: Epoch 016 - training loss: 9918.8781, validation loss: 0.4057
2024-05-24 21:04:24 [INFO]: Epoch 017 - training loss: 9831.4279, validation loss: 0.3900
2024-05-24 21:04:25 [INFO]: Epoch 018 - training loss: 9807.1403, validation loss: 0.3768
2024-05-24 21:04:25 [INFO]: Epoch 019 - training loss: 9732.4243, validation loss: 0.3551
2024-05-24 21:04:25 [INFO]: Epoch 020 - training loss: 9703.3063, validation loss: 0.3389
2024-05-24 21:04:25 [INFO]: Epoch 021 - training loss: 9668.3579, validation loss: 0.3230
2024-05-24 21:04:25 [INFO]: Epoch 022 - training loss: 9650.0501, validation loss: 0.3093
2024-05-24 21:04:25 [INFO]: Epoch 023 - training loss: 9598.0559, validation loss: 0.2978
2024-05-24 21:04:25 [INFO]: Epoch 024 - training loss: 9575.8744, validation loss: 0.2878
2024-05-24 21:04:25 [INFO]: Epoch 025 - training loss: 9563.5515, validation loss: 0.2748
2024-05-24 21:04:26 [INFO]: Epoch 026 - training loss: 9585.5064, validation loss: 0.2603
2024-05-24 21:04:26 [INFO]: Epoch 027 - training loss: 9527.6358, validation loss: 0.2519
2024-05-24 21:04:26 [INFO]: Epoch 028 - training loss: 9507.5813, validation loss: 0.2467
2024-05-24 21:04:26 [INFO]: Epoch 029 - training loss: 9506.4688, validation loss: 0.2397
2024-05-24 21:04:26 [INFO]: Epoch 030 - training loss: 9554.8967, validation loss: 0.2385
2024-05-24 21:04:26 [INFO]: Epoch 031 - training loss: 9486.6866, validation loss: 0.2309
2024-05-24 21:04:26 [INFO]: Epoch 032 - training loss: 9463.7388, validation loss: 0.2255
2024-05-24 21:04:27 [INFO]: Epoch 033 - training loss: 9458.7739, validation loss: 0.2196
2024-05-24 21:04:27 [INFO]: Epoch 034 - training loss: 9470.1096, validation loss: 0.2153
2024-05-24 21:04:27 [INFO]: Epoch 035 - training loss: 9444.3213, validation loss: 0.2137
2024-05-24 21:04:27 [INFO]: Epoch 036 - training loss: 9449.4946, validation loss: 0.2198
2024-05-24 21:04:27 [INFO]: Epoch 037 - training loss: 9451.7324, validation loss: 0.2084
2024-05-24 21:04:27 [INFO]: Epoch 038 - training loss: 9423.1091, validation loss: 0.2039
2024-05-24 21:04:27 [INFO]: Epoch 039 - training loss: 9421.6221, validation loss: 0.1987
2024-05-24 21:04:27 [INFO]: Epoch 040 - training loss: 9414.9167, validation loss: 0.1928
2024-05-24 21:04:28 [INFO]: Epoch 041 - training loss: 9412.3361, validation loss: 0.1843
2024-05-24 21:04:28 [INFO]: Epoch 042 - training loss: 9407.3682, validation loss: 0.1849
2024-05-24 21:04:28 [INFO]: Epoch 043 - training loss: 9404.0170, validation loss: 0.1824
2024-05-24 21:04:28 [INFO]: Epoch 044 - training loss: 9400.9401, validation loss: 0.1750
2024-05-24 21:04:28 [INFO]: Epoch 045 - training loss: 9393.1937, validation loss: 0.1730
2024-05-24 21:04:28 [INFO]: Epoch 046 - training loss: 9388.2173, validation loss: 0.1684
2024-05-24 21:04:28 [INFO]: Epoch 047 - training loss: 9390.4622, validation loss: 0.1662
2024-05-24 21:04:28 [INFO]: Epoch 048 - training loss: 9384.2411, validation loss: 0.1613
2024-05-24 21:04:29 [INFO]: Epoch 049 - training loss: 9385.1414, validation loss: 0.1579
2024-05-24 21:04:29 [INFO]: Epoch 050 - training loss: 9376.4370, validation loss: 0.1533
2024-05-24 21:04:29 [INFO]: Epoch 051 - training loss: 9376.9314, validation loss: 0.1527
2024-05-24 21:04:29 [INFO]: Epoch 052 - training loss: 9374.7971, validation loss: 0.1478
2024-05-24 21:04:29 [INFO]: Epoch 053 - training loss: 9376.8256, validation loss: 0.1434
2024-05-24 21:04:29 [INFO]: Epoch 054 - training loss: 9369.8323, validation loss: 0.1408
2024-05-24 21:04:29 [INFO]: Epoch 055 - training loss: 9373.2282, validation loss: 0.1388
2024-05-24 21:04:30 [INFO]: Epoch 056 - training loss: 9366.1759, validation loss: 0.1353
2024-05-24 21:04:30 [INFO]: Epoch 057 - training loss: 9361.3283, validation loss: 0.1343
2024-05-24 21:04:30 [INFO]: Epoch 058 - training loss: 9363.0394, validation loss: 0.1301
2024-05-24 21:04:30 [INFO]: Epoch 059 - training loss: 9356.8792, validation loss: 0.1313
2024-05-24 21:04:30 [INFO]: Epoch 060 - training loss: 9359.2010, validation loss: 0.1283
2024-05-24 21:04:30 [INFO]: Epoch 061 - training loss: 9366.2747, validation loss: 0.1264
2024-05-24 21:04:30 [INFO]: Epoch 062 - training loss: 9359.3239, validation loss: 0.1256
2024-05-24 21:04:30 [INFO]: Epoch 063 - training loss: 9354.3787, validation loss: 0.1239
2024-05-24 21:04:31 [INFO]: Epoch 064 - training loss: 9352.6342, validation loss: 0.1226
2024-05-24 21:04:31 [INFO]: Epoch 065 - training loss: 9349.8760, validation loss: 0.1198
2024-05-24 21:04:31 [INFO]: Epoch 066 - training loss: 9346.6063, validation loss: 0.1196
2024-05-24 21:04:31 [INFO]: Epoch 067 - training loss: 9346.9706, validation loss: 0.1177
2024-05-24 21:04:31 [INFO]: Epoch 068 - training loss: 9344.7923, validation loss: 0.1156
2024-05-24 21:04:31 [INFO]: Epoch 069 - training loss: 9345.9719, validation loss: 0.1151
2024-05-24 21:04:31 [INFO]: Epoch 070 - training loss: 9344.5512, validation loss: 0.1144
2024-05-24 21:04:32 [INFO]: Epoch 071 - training loss: 9346.3560, validation loss: 0.1128
2024-05-24 21:04:32 [INFO]: Epoch 072 - training loss: 9345.2519, validation loss: 0.1114
2024-05-24 21:04:32 [INFO]: Epoch 073 - training loss: 9340.0032, validation loss: 0.1105
2024-05-24 21:04:32 [INFO]: Epoch 074 - training loss: 9337.9999, validation loss: 0.1111
2024-05-24 21:04:32 [INFO]: Epoch 075 - training loss: 9339.9420, validation loss: 0.1103
2024-05-24 21:04:32 [INFO]: Epoch 076 - training loss: 9335.9546, validation loss: 0.1094
2024-05-24 21:04:32 [INFO]: Epoch 077 - training loss: 9335.1462, validation loss: 0.1090
2024-05-24 21:04:32 [INFO]: Epoch 078 - training loss: 9334.3178, validation loss: 0.1091
2024-05-24 21:04:33 [INFO]: Epoch 079 - training loss: 9335.7976, validation loss: 0.1075
2024-05-24 21:04:33 [INFO]: Epoch 080 - training loss: 9334.2535, validation loss: 0.1077
2024-05-24 21:04:33 [INFO]: Epoch 081 - training loss: 9335.2419, validation loss: 0.1050
2024-05-24 21:04:33 [INFO]: Epoch 082 - training loss: 9333.6653, validation loss: 0.1050
2024-05-24 21:04:33 [INFO]: Epoch 083 - training loss: 9334.0133, validation loss: 0.1047
2024-05-24 21:04:33 [INFO]: Epoch 084 - training loss: 9330.9211, validation loss: 0.1055
2024-05-24 21:04:33 [INFO]: Epoch 085 - training loss: 9329.8846, validation loss: 0.1032
2024-05-24 21:04:34 [INFO]: Epoch 086 - training loss: 9333.2023, validation loss: 0.1026
2024-05-24 21:04:34 [INFO]: Epoch 087 - training loss: 9328.6171, validation loss: 0.1025
2024-05-24 21:04:34 [INFO]: Epoch 088 - training loss: 9330.1135, validation loss: 0.1007
2024-05-24 21:04:34 [INFO]: Epoch 089 - training loss: 9329.1825, validation loss: 0.1006
2024-05-24 21:04:34 [INFO]: Epoch 090 - training loss: 9328.1208, validation loss: 0.1014
2024-05-24 21:04:34 [INFO]: Epoch 091 - training loss: 9329.4506, validation loss: 0.1014
2024-05-24 21:04:34 [INFO]: Epoch 092 - training loss: 9325.7188, validation loss: 0.0994
2024-05-24 21:04:34 [INFO]: Epoch 093 - training loss: 9327.0359, validation loss: 0.1009
2024-05-24 21:04:35 [INFO]: Epoch 094 - training loss: 9327.3177, validation loss: 0.1000
2024-05-24 21:04:35 [INFO]: Epoch 095 - training loss: 9325.6315, validation loss: 0.0974
2024-05-24 21:04:35 [INFO]: Epoch 096 - training loss: 9326.7448, validation loss: 0.0991
2024-05-24 21:04:35 [INFO]: Epoch 097 - training loss: 9325.6573, validation loss: 0.0981
2024-05-24 21:04:35 [INFO]: Epoch 098 - training loss: 9324.8801, validation loss: 0.0966
2024-05-24 21:04:35 [INFO]: Epoch 099 - training loss: 9325.0670, validation loss: 0.0967
2024-05-24 21:04:35 [INFO]: Epoch 100 - training loss: 9322.0589, validation loss: 0.0956
2024-05-24 21:04:36 [INFO]: Epoch 101 - training loss: 9323.3721, validation loss: 0.0950
2024-05-24 21:04:36 [INFO]: Epoch 102 - training loss: 9322.2225, validation loss: 0.0958
2024-05-24 21:04:36 [INFO]: Epoch 103 - training loss: 9321.4920, validation loss: 0.0942
2024-05-24 21:04:36 [INFO]: Epoch 104 - training loss: 9320.7743, validation loss: 0.0941
2024-05-24 21:04:36 [INFO]: Epoch 105 - training loss: 9319.2772, validation loss: 0.0933
2024-05-24 21:04:36 [INFO]: Epoch 106 - training loss: 9319.5877, validation loss: 0.0930
2024-05-24 21:04:36 [INFO]: Epoch 107 - training loss: 9320.9134, validation loss: 0.0924
2024-05-24 21:04:36 [INFO]: Epoch 108 - training loss: 9320.0046, validation loss: 0.0915
2024-05-24 21:04:37 [INFO]: Epoch 109 - training loss: 9319.7832, validation loss: 0.0915
2024-05-24 21:04:37 [INFO]: Epoch 110 - training loss: 9320.2482, validation loss: 0.0906
2024-05-24 21:04:37 [INFO]: Epoch 111 - training loss: 9319.1932, validation loss: 0.0909
2024-05-24 21:04:37 [INFO]: Epoch 112 - training loss: 9318.3316, validation loss: 0.0905
2024-05-24 21:04:37 [INFO]: Epoch 113 - training loss: 9317.6568, validation loss: 0.0905
2024-05-24 21:04:37 [INFO]: Epoch 114 - training loss: 9318.7665, validation loss: 0.0895
2024-05-24 21:04:37 [INFO]: Epoch 115 - training loss: 9316.9161, validation loss: 0.0891
2024-05-24 21:04:38 [INFO]: Epoch 116 - training loss: 9316.6138, validation loss: 0.0892
2024-05-24 21:04:38 [INFO]: Epoch 117 - training loss: 9317.1190, validation loss: 0.0895
2024-05-24 21:04:38 [INFO]: Epoch 118 - training loss: 9315.5917, validation loss: 0.0889
2024-05-24 21:04:38 [INFO]: Epoch 119 - training loss: 9318.6146, validation loss: 0.0883
2024-05-24 21:04:38 [INFO]: Epoch 120 - training loss: 9316.1819, validation loss: 0.0866
2024-05-24 21:04:38 [INFO]: Epoch 121 - training loss: 9315.4207, validation loss: 0.0881
2024-05-24 21:04:38 [INFO]: Epoch 122 - training loss: 9314.6299, validation loss: 0.0873
2024-05-24 21:04:38 [INFO]: Epoch 123 - training loss: 9315.1203, validation loss: 0.0873
2024-05-24 21:04:39 [INFO]: Epoch 124 - training loss: 9315.9979, validation loss: 0.0863
2024-05-24 21:04:39 [INFO]: Epoch 125 - training loss: 9312.9966, validation loss: 0.0859
2024-05-24 21:04:39 [INFO]: Epoch 126 - training loss: 9315.1760, validation loss: 0.0855
2024-05-24 21:04:39 [INFO]: Epoch 127 - training loss: 9315.4809, validation loss: 0.0858
2024-05-24 21:04:39 [INFO]: Epoch 128 - training loss: 9313.8358, validation loss: 0.0848
2024-05-24 21:04:39 [INFO]: Epoch 129 - training loss: 9315.5103, validation loss: 0.0855
2024-05-24 21:04:39 [INFO]: Epoch 130 - training loss: 9313.8643, validation loss: 0.0855
2024-05-24 21:04:40 [INFO]: Epoch 131 - training loss: 9312.9942, validation loss: 0.0851
2024-05-24 21:04:40 [INFO]: Epoch 132 - training loss: 9313.9902, validation loss: 0.0841
2024-05-24 21:04:40 [INFO]: Epoch 133 - training loss: 9312.3537, validation loss: 0.0843
2024-05-24 21:04:40 [INFO]: Epoch 134 - training loss: 9313.1651, validation loss: 0.0833
2024-05-24 21:04:40 [INFO]: Epoch 135 - training loss: 9313.5487, validation loss: 0.0833
2024-05-24 21:04:40 [INFO]: Epoch 136 - training loss: 9313.5680, validation loss: 0.0845
2024-05-24 21:04:40 [INFO]: Epoch 137 - training loss: 9311.7631, validation loss: 0.0850
2024-05-24 21:04:40 [INFO]: Epoch 138 - training loss: 9311.4276, validation loss: 0.0824
2024-05-24 21:04:41 [INFO]: Epoch 139 - training loss: 9312.1155, validation loss: 0.0815
2024-05-24 21:04:41 [INFO]: Epoch 140 - training loss: 9311.9420, validation loss: 0.0821
2024-05-24 21:04:41 [INFO]: Epoch 141 - training loss: 9311.7877, validation loss: 0.0842
2024-05-24 21:04:41 [INFO]: Epoch 142 - training loss: 9310.9561, validation loss: 0.0833
2024-05-24 21:04:41 [INFO]: Epoch 143 - training loss: 9312.4517, validation loss: 0.0824
2024-05-24 21:04:41 [INFO]: Epoch 144 - training loss: 9312.5051, validation loss: 0.0826
2024-05-24 21:04:41 [INFO]: Epoch 145 - training loss: 9310.4094, validation loss: 0.0821
2024-05-24 21:04:42 [INFO]: Epoch 146 - training loss: 9311.1495, validation loss: 0.0818
2024-05-24 21:04:42 [INFO]: Epoch 147 - training loss: 9311.6545, validation loss: 0.0811
2024-05-24 21:04:42 [INFO]: Epoch 148 - training loss: 9310.4624, validation loss: 0.0814
2024-05-24 21:04:42 [INFO]: Epoch 149 - training loss: 9309.6033, validation loss: 0.0809
2024-05-24 21:04:42 [INFO]: Epoch 150 - training loss: 9310.6199, validation loss: 0.0805
2024-05-24 21:04:42 [INFO]: Epoch 151 - training loss: 9308.6826, validation loss: 0.0802
2024-05-24 21:04:42 [INFO]: Epoch 152 - training loss: 9311.1249, validation loss: 0.0789
2024-05-24 21:04:42 [INFO]: Epoch 153 - training loss: 9309.9072, validation loss: 0.0784
2024-05-24 21:04:43 [INFO]: Epoch 154 - training loss: 9310.2112, validation loss: 0.0783
2024-05-24 21:04:43 [INFO]: Epoch 155 - training loss: 9310.4313, validation loss: 0.0793
2024-05-24 21:04:43 [INFO]: Epoch 156 - training loss: 9308.5509, validation loss: 0.0797
2024-05-24 21:04:43 [INFO]: Epoch 157 - training loss: 9308.8311, validation loss: 0.0781
2024-05-24 21:04:43 [INFO]: Epoch 158 - training loss: 9308.9203, validation loss: 0.0779
2024-05-24 21:04:43 [INFO]: Epoch 159 - training loss: 9307.5066, validation loss: 0.0770
2024-05-24 21:04:43 [INFO]: Epoch 160 - training loss: 9310.4085, validation loss: 0.0785
2024-05-24 21:04:44 [INFO]: Epoch 161 - training loss: 9308.7272, validation loss: 0.0785
2024-05-24 21:04:44 [INFO]: Epoch 162 - training loss: 9308.9202, validation loss: 0.0791
2024-05-24 21:04:44 [INFO]: Epoch 163 - training loss: 9308.0731, validation loss: 0.0790
2024-05-24 21:04:44 [INFO]: Epoch 164 - training loss: 9309.3175, validation loss: 0.0769
2024-05-24 21:04:44 [INFO]: Epoch 165 - training loss: 9307.4702, validation loss: 0.0797
2024-05-24 21:04:44 [INFO]: Epoch 166 - training loss: 9307.5409, validation loss: 0.0760
2024-05-24 21:04:44 [INFO]: Epoch 167 - training loss: 9309.0162, validation loss: 0.0781
2024-05-24 21:04:44 [INFO]: Epoch 168 - training loss: 9307.9498, validation loss: 0.0780
2024-05-24 21:04:45 [INFO]: Epoch 169 - training loss: 9308.4658, validation loss: 0.0770
2024-05-24 21:04:45 [INFO]: Epoch 170 - training loss: 9307.3553, validation loss: 0.0766
2024-05-24 21:04:45 [INFO]: Epoch 171 - training loss: 9308.1724, validation loss: 0.0786
2024-05-24 21:04:45 [INFO]: Epoch 172 - training loss: 9307.9424, validation loss: 0.0763
2024-05-24 21:04:45 [INFO]: Epoch 173 - training loss: 9307.3939, validation loss: 0.0753
2024-05-24 21:04:45 [INFO]: Epoch 174 - training loss: 9307.0159, validation loss: 0.0776
2024-05-24 21:04:45 [INFO]: Epoch 175 - training loss: 9307.0543, validation loss: 0.0773
2024-05-24 21:04:46 [INFO]: Epoch 176 - training loss: 9306.2124, validation loss: 0.0759
2024-05-24 21:04:46 [INFO]: Epoch 177 - training loss: 9307.0620, validation loss: 0.0780
2024-05-24 21:04:46 [INFO]: Epoch 178 - training loss: 9306.6311, validation loss: 0.0764
2024-05-24 21:04:46 [INFO]: Epoch 179 - training loss: 9307.8170, validation loss: 0.0752
2024-05-24 21:04:46 [INFO]: Epoch 180 - training loss: 9307.7258, validation loss: 0.0758
2024-05-24 21:04:46 [INFO]: Epoch 181 - training loss: 9309.3928, validation loss: 0.0754
2024-05-24 21:04:46 [INFO]: Epoch 182 - training loss: 9305.2996, validation loss: 0.0766
2024-05-24 21:04:46 [INFO]: Epoch 183 - training loss: 9306.0570, validation loss: 0.0738
2024-05-24 21:04:47 [INFO]: Epoch 184 - training loss: 9305.5145, validation loss: 0.0743
2024-05-24 21:04:47 [INFO]: Epoch 185 - training loss: 9306.8853, validation loss: 0.0724
2024-05-24 21:04:47 [INFO]: Epoch 186 - training loss: 9307.0044, validation loss: 0.0750
2024-05-24 21:04:47 [INFO]: Epoch 187 - training loss: 9305.9755, validation loss: 0.0758
2024-05-24 21:04:47 [INFO]: Epoch 188 - training loss: 9305.3506, validation loss: 0.0739
2024-05-24 21:04:47 [INFO]: Epoch 189 - training loss: 9305.9592, validation loss: 0.0734
2024-05-24 21:04:47 [INFO]: Epoch 190 - training loss: 9305.7876, validation loss: 0.0748
2024-05-24 21:04:48 [INFO]: Epoch 191 - training loss: 9304.9909, validation loss: 0.0738
2024-05-24 21:04:48 [INFO]: Epoch 192 - training loss: 9307.1187, validation loss: 0.0724
2024-05-24 21:04:48 [INFO]: Epoch 193 - training loss: 9305.2969, validation loss: 0.0731
2024-05-24 21:04:48 [INFO]: Epoch 194 - training loss: 9304.6531, validation loss: 0.0765
2024-05-24 21:04:48 [INFO]: Epoch 195 - training loss: 9306.6642, validation loss: 0.0742
2024-05-24 21:04:48 [INFO]: Epoch 196 - training loss: 9306.7424, validation loss: 0.0723
2024-05-24 21:04:48 [INFO]: Epoch 197 - training loss: 9303.7510, validation loss: 0.0714
2024-05-24 21:04:48 [INFO]: Epoch 198 - training loss: 9304.2664, validation loss: 0.0738
2024-05-24 21:04:49 [INFO]: Epoch 199 - training loss: 9305.3324, validation loss: 0.0739
2024-05-24 21:04:49 [INFO]: Epoch 200 - training loss: 9304.1014, validation loss: 0.0744
2024-05-24 21:04:49 [INFO]: Epoch 201 - training loss: 9303.7296, validation loss: 0.0755
2024-05-24 21:04:49 [INFO]: Epoch 202 - training loss: 9305.4366, validation loss: 0.0736
2024-05-24 21:04:49 [INFO]: Epoch 203 - training loss: 9304.7281, validation loss: 0.0721
2024-05-24 21:04:49 [INFO]: Epoch 204 - training loss: 9303.9612, validation loss: 0.0742
2024-05-24 21:04:49 [INFO]: Epoch 205 - training loss: 9304.3512, validation loss: 0.0706
2024-05-24 21:04:50 [INFO]: Epoch 206 - training loss: 9304.4041, validation loss: 0.0714
2024-05-24 21:04:50 [INFO]: Epoch 207 - training loss: 9303.5775, validation loss: 0.0733
2024-05-24 21:04:50 [INFO]: Epoch 208 - training loss: 9304.2776, validation loss: 0.0738
2024-05-24 21:04:50 [INFO]: Epoch 209 - training loss: 9302.8526, validation loss: 0.0729
2024-05-24 21:04:50 [INFO]: Epoch 210 - training loss: 9304.7850, validation loss: 0.0748
2024-05-24 21:04:50 [INFO]: Epoch 211 - training loss: 9305.8188, validation loss: 0.0704
2024-05-24 21:04:50 [INFO]: Epoch 212 - training loss: 9303.9754, validation loss: 0.0726
2024-05-24 21:04:50 [INFO]: Epoch 213 - training loss: 9303.2183, validation loss: 0.0716
2024-05-24 21:04:51 [INFO]: Epoch 214 - training loss: 9303.9959, validation loss: 0.0730
2024-05-24 21:04:51 [INFO]: Epoch 215 - training loss: 9303.2860, validation loss: 0.0739
2024-05-24 21:04:51 [INFO]: Epoch 216 - training loss: 9303.8479, validation loss: 0.0746
2024-05-24 21:04:51 [INFO]: Epoch 217 - training loss: 9303.1531, validation loss: 0.0717
2024-05-24 21:04:51 [INFO]: Epoch 218 - training loss: 9304.7050, validation loss: 0.0725
2024-05-24 21:04:51 [INFO]: Epoch 219 - training loss: 9303.6553, validation loss: 0.0721
2024-05-24 21:04:51 [INFO]: Epoch 220 - training loss: 9304.8447, validation loss: 0.0717
2024-05-24 21:04:52 [INFO]: Epoch 221 - training loss: 9302.7596, validation loss: 0.0719
2024-05-24 21:04:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:04:52 [INFO]: Finished training. The best model is from epoch#211.
2024-05-24 21:04:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/GPVAE_ettm1/20240524_T210420/GPVAE.pypots
2024-05-24 21:04:52 [INFO]: GP-VAE on ETTm1: MAE=0.2739, MSE=0.1510
2024-05-24 21:04:52 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/GPVAE_ettm1/imputation.pkl
2024-05-24 21:04:52 [INFO]: Using the given device: cuda:0
2024-05-24 21:04:52 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/USGAN_ettm1/20240524_T210452
2024-05-24 21:04:52 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/USGAN_ettm1/20240524_T210452/tensorboard
2024-05-24 21:04:52 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 21:05:03 [INFO]: Epoch 001 - generator training loss: 0.6132, discriminator training loss: 0.3263, validation loss: 0.3119
2024-05-24 21:05:13 [INFO]: Epoch 002 - generator training loss: 0.0484, discriminator training loss: 0.2088, validation loss: 0.0980
2024-05-24 21:05:22 [INFO]: Epoch 003 - generator training loss: -0.0556, discriminator training loss: 0.1968, validation loss: 0.0570
2024-05-24 21:05:31 [INFO]: Epoch 004 - generator training loss: -0.0829, discriminator training loss: 0.1965, validation loss: 0.0463
2024-05-24 21:05:40 [INFO]: Epoch 005 - generator training loss: -0.0827, discriminator training loss: 0.1922, validation loss: 0.0420
2024-05-24 21:05:49 [INFO]: Epoch 006 - generator training loss: -0.0788, discriminator training loss: 0.1882, validation loss: 0.0397
2024-05-24 21:05:58 [INFO]: Epoch 007 - generator training loss: -0.0783, discriminator training loss: 0.1808, validation loss: 0.0381
2024-05-24 21:06:07 [INFO]: Epoch 008 - generator training loss: -0.0685, discriminator training loss: 0.1704, validation loss: 0.0374
2024-05-24 21:06:16 [INFO]: Epoch 009 - generator training loss: -0.0638, discriminator training loss: 0.1615, validation loss: 0.0362
2024-05-24 21:06:25 [INFO]: Epoch 010 - generator training loss: -0.0530, discriminator training loss: 0.1482, validation loss: 0.0356
2024-05-24 21:06:34 [INFO]: Epoch 011 - generator training loss: -0.0411, discriminator training loss: 0.1362, validation loss: 0.0350
2024-05-24 21:06:43 [INFO]: Epoch 012 - generator training loss: -0.0269, discriminator training loss: 0.1215, validation loss: 0.0346
2024-05-24 21:06:52 [INFO]: Epoch 013 - generator training loss: -0.0261, discriminator training loss: 0.1117, validation loss: 0.0350
2024-05-24 21:07:01 [INFO]: Epoch 014 - generator training loss: -0.0176, discriminator training loss: 0.1045, validation loss: 0.0345
2024-05-24 21:07:10 [INFO]: Epoch 015 - generator training loss: -0.0136, discriminator training loss: 0.0961, validation loss: 0.0339
2024-05-24 21:07:19 [INFO]: Epoch 016 - generator training loss: -0.0081, discriminator training loss: 0.0890, validation loss: 0.0331
2024-05-24 21:07:28 [INFO]: Epoch 017 - generator training loss: -0.0105, discriminator training loss: 0.0866, validation loss: 0.0325
2024-05-24 21:07:37 [INFO]: Epoch 018 - generator training loss: -0.0078, discriminator training loss: 0.0844, validation loss: 0.0330
2024-05-24 21:07:46 [INFO]: Epoch 019 - generator training loss: -0.0092, discriminator training loss: 0.0831, validation loss: 0.0322
2024-05-24 21:07:55 [INFO]: Epoch 020 - generator training loss: -0.0046, discriminator training loss: 0.0807, validation loss: 0.0324
2024-05-24 21:08:05 [INFO]: Epoch 021 - generator training loss: -0.0106, discriminator training loss: 0.0806, validation loss: 0.0322
2024-05-24 21:08:14 [INFO]: Epoch 022 - generator training loss: -0.0096, discriminator training loss: 0.0781, validation loss: 0.0318
2024-05-24 21:08:23 [INFO]: Epoch 023 - generator training loss: -0.0070, discriminator training loss: 0.0770, validation loss: 0.0317
2024-05-24 21:08:32 [INFO]: Epoch 024 - generator training loss: -0.0094, discriminator training loss: 0.0763, validation loss: 0.0308
2024-05-24 21:08:41 [INFO]: Epoch 025 - generator training loss: -0.0089, discriminator training loss: 0.0770, validation loss: 0.0305
2024-05-24 21:08:50 [INFO]: Epoch 026 - generator training loss: -0.0068, discriminator training loss: 0.0766, validation loss: 0.0307
2024-05-24 21:08:59 [INFO]: Epoch 027 - generator training loss: -0.0123, discriminator training loss: 0.0766, validation loss: 0.0301
2024-05-24 21:09:08 [INFO]: Epoch 028 - generator training loss: -0.0077, discriminator training loss: 0.0736, validation loss: 0.0320
2024-05-24 21:09:17 [INFO]: Epoch 029 - generator training loss: -0.0060, discriminator training loss: 0.0742, validation loss: 0.0301
2024-05-24 21:09:26 [INFO]: Epoch 030 - generator training loss: -0.0075, discriminator training loss: 0.0747, validation loss: 0.0300
2024-05-24 21:09:35 [INFO]: Epoch 031 - generator training loss: -0.0097, discriminator training loss: 0.0732, validation loss: 0.0297
2024-05-24 21:09:44 [INFO]: Epoch 032 - generator training loss: -0.0106, discriminator training loss: 0.0740, validation loss: 0.0290
2024-05-24 21:09:53 [INFO]: Epoch 033 - generator training loss: -0.0118, discriminator training loss: 0.0749, validation loss: 0.0294
2024-05-24 21:10:02 [INFO]: Epoch 034 - generator training loss: -0.0086, discriminator training loss: 0.0746, validation loss: 0.0308
2024-05-24 21:10:11 [INFO]: Epoch 035 - generator training loss: -0.0088, discriminator training loss: 0.0737, validation loss: 0.0294
2024-05-24 21:10:20 [INFO]: Epoch 036 - generator training loss: -0.0098, discriminator training loss: 0.0711, validation loss: 0.0287
2024-05-24 21:10:29 [INFO]: Epoch 037 - generator training loss: -0.0103, discriminator training loss: 0.0717, validation loss: 0.0283
2024-05-24 21:10:39 [INFO]: Epoch 038 - generator training loss: -0.0130, discriminator training loss: 0.0719, validation loss: 0.0277
2024-05-24 21:10:48 [INFO]: Epoch 039 - generator training loss: -0.0125, discriminator training loss: 0.0722, validation loss: 0.0279
2024-05-24 21:10:57 [INFO]: Epoch 040 - generator training loss: -0.0130, discriminator training loss: 0.0734, validation loss: 0.0280
2024-05-24 21:11:06 [INFO]: Epoch 041 - generator training loss: -0.0107, discriminator training loss: 0.0712, validation loss: 0.0274
2024-05-24 21:11:15 [INFO]: Epoch 042 - generator training loss: -0.0117, discriminator training loss: 0.0719, validation loss: 0.0270
2024-05-24 21:11:24 [INFO]: Epoch 043 - generator training loss: -0.0126, discriminator training loss: 0.0706, validation loss: 0.0286
2024-05-24 21:11:33 [INFO]: Epoch 044 - generator training loss: -0.0130, discriminator training loss: 0.0711, validation loss: 0.0280
2024-05-24 21:11:42 [INFO]: Epoch 045 - generator training loss: -0.0139, discriminator training loss: 0.0704, validation loss: 0.0268
2024-05-24 21:11:51 [INFO]: Epoch 046 - generator training loss: -0.0132, discriminator training loss: 0.0704, validation loss: 0.0265
2024-05-24 21:12:00 [INFO]: Epoch 047 - generator training loss: -0.0155, discriminator training loss: 0.0724, validation loss: 0.0269
2024-05-24 21:12:09 [INFO]: Epoch 048 - generator training loss: -0.0103, discriminator training loss: 0.0714, validation loss: 0.0265
2024-05-24 21:12:18 [INFO]: Epoch 049 - generator training loss: -0.0125, discriminator training loss: 0.0696, validation loss: 0.0289
2024-05-24 21:12:27 [INFO]: Epoch 050 - generator training loss: -0.0141, discriminator training loss: 0.0708, validation loss: 0.0262
2024-05-24 21:12:36 [INFO]: Epoch 051 - generator training loss: -0.0169, discriminator training loss: 0.0718, validation loss: 0.0260
2024-05-24 21:12:46 [INFO]: Epoch 052 - generator training loss: -0.0145, discriminator training loss: 0.0700, validation loss: 0.0265
2024-05-24 21:12:55 [INFO]: Epoch 053 - generator training loss: -0.0131, discriminator training loss: 0.0699, validation loss: 0.0260
2024-05-24 21:13:04 [INFO]: Epoch 054 - generator training loss: -0.0148, discriminator training loss: 0.0692, validation loss: 0.0259
2024-05-24 21:13:13 [INFO]: Epoch 055 - generator training loss: -0.0148, discriminator training loss: 0.0692, validation loss: 0.0260
2024-05-24 21:13:22 [INFO]: Epoch 056 - generator training loss: -0.0137, discriminator training loss: 0.0690, validation loss: 0.0271
2024-05-24 21:13:31 [INFO]: Epoch 057 - generator training loss: -0.0114, discriminator training loss: 0.0696, validation loss: 0.0255
2024-05-24 21:13:40 [INFO]: Epoch 058 - generator training loss: -0.0158, discriminator training loss: 0.0706, validation loss: 0.0257
2024-05-24 21:13:49 [INFO]: Epoch 059 - generator training loss: -0.0141, discriminator training loss: 0.0673, validation loss: 0.0249
2024-05-24 21:13:58 [INFO]: Epoch 060 - generator training loss: -0.0173, discriminator training loss: 0.0692, validation loss: 0.0246
2024-05-24 21:14:07 [INFO]: Epoch 061 - generator training loss: -0.0167, discriminator training loss: 0.0697, validation loss: 0.0249
2024-05-24 21:14:16 [INFO]: Epoch 062 - generator training loss: -0.0161, discriminator training loss: 0.0668, validation loss: 0.0247
2024-05-24 21:14:25 [INFO]: Epoch 063 - generator training loss: -0.0171, discriminator training loss: 0.0683, validation loss: 0.0247
2024-05-24 21:14:34 [INFO]: Epoch 064 - generator training loss: -0.0133, discriminator training loss: 0.0685, validation loss: 0.0250
2024-05-24 21:14:43 [INFO]: Epoch 065 - generator training loss: -0.0174, discriminator training loss: 0.0664, validation loss: 0.0244
2024-05-24 21:14:53 [INFO]: Epoch 066 - generator training loss: -0.0168, discriminator training loss: 0.0680, validation loss: 0.0242
2024-05-24 21:15:02 [INFO]: Epoch 067 - generator training loss: -0.0162, discriminator training loss: 0.0666, validation loss: 0.0237
2024-05-24 21:15:11 [INFO]: Epoch 068 - generator training loss: -0.0182, discriminator training loss: 0.0677, validation loss: 0.0236
2024-05-24 21:15:20 [INFO]: Epoch 069 - generator training loss: -0.0180, discriminator training loss: 0.0694, validation loss: 0.0234
2024-05-24 21:15:29 [INFO]: Epoch 070 - generator training loss: -0.0189, discriminator training loss: 0.0681, validation loss: 0.0238
2024-05-24 21:15:38 [INFO]: Epoch 071 - generator training loss: -0.0168, discriminator training loss: 0.0667, validation loss: 0.0230
2024-05-24 21:15:47 [INFO]: Epoch 072 - generator training loss: -0.0195, discriminator training loss: 0.0679, validation loss: 0.0224
2024-05-24 21:15:56 [INFO]: Epoch 073 - generator training loss: -0.0177, discriminator training loss: 0.0674, validation loss: 0.0229
2024-05-24 21:16:05 [INFO]: Epoch 074 - generator training loss: -0.0189, discriminator training loss: 0.0675, validation loss: 0.0221
2024-05-24 21:16:14 [INFO]: Epoch 075 - generator training loss: -0.0205, discriminator training loss: 0.0687, validation loss: 0.0219
2024-05-24 21:16:23 [INFO]: Epoch 076 - generator training loss: -0.0189, discriminator training loss: 0.0678, validation loss: 0.0217
2024-05-24 21:16:32 [INFO]: Epoch 077 - generator training loss: -0.0205, discriminator training loss: 0.0673, validation loss: 0.0215
2024-05-24 21:16:41 [INFO]: Epoch 078 - generator training loss: -0.0203, discriminator training loss: 0.0662, validation loss: 0.0215
2024-05-24 21:16:50 [INFO]: Epoch 079 - generator training loss: -0.0225, discriminator training loss: 0.0678, validation loss: 0.0214
2024-05-24 21:16:59 [INFO]: Epoch 080 - generator training loss: -0.0224, discriminator training loss: 0.0694, validation loss: 0.0214
2024-05-24 21:17:08 [INFO]: Epoch 081 - generator training loss: -0.0197, discriminator training loss: 0.0688, validation loss: 0.0211
2024-05-24 21:17:17 [INFO]: Epoch 082 - generator training loss: -0.0221, discriminator training loss: 0.0663, validation loss: 0.0211
2024-05-24 21:17:27 [INFO]: Epoch 083 - generator training loss: -0.0220, discriminator training loss: 0.0694, validation loss: 0.0211
2024-05-24 21:17:36 [INFO]: Epoch 084 - generator training loss: -0.0224, discriminator training loss: 0.0699, validation loss: 0.0217
2024-05-24 21:17:45 [INFO]: Epoch 085 - generator training loss: -0.0233, discriminator training loss: 0.0684, validation loss: 0.0211
2024-05-24 21:17:54 [INFO]: Epoch 086 - generator training loss: -0.0209, discriminator training loss: 0.0665, validation loss: 0.0208
2024-05-24 21:18:03 [INFO]: Epoch 087 - generator training loss: -0.0212, discriminator training loss: 0.0684, validation loss: 0.0213
2024-05-24 21:18:12 [INFO]: Epoch 088 - generator training loss: -0.0216, discriminator training loss: 0.0697, validation loss: 0.0230
2024-05-24 21:18:21 [INFO]: Epoch 089 - generator training loss: -0.0198, discriminator training loss: 0.0670, validation loss: 0.0207
2024-05-24 21:18:30 [INFO]: Epoch 090 - generator training loss: -0.0238, discriminator training loss: 0.0637, validation loss: 0.0206
2024-05-24 21:18:39 [INFO]: Epoch 091 - generator training loss: -0.0233, discriminator training loss: 0.0662, validation loss: 0.0205
2024-05-24 21:18:48 [INFO]: Epoch 092 - generator training loss: -0.0238, discriminator training loss: 0.0669, validation loss: 0.0205
2024-05-24 21:18:57 [INFO]: Epoch 093 - generator training loss: -0.0231, discriminator training loss: 0.0651, validation loss: 0.0204
2024-05-24 21:19:06 [INFO]: Epoch 094 - generator training loss: -0.0237, discriminator training loss: 0.0664, validation loss: 0.0209
2024-05-24 21:19:14 [INFO]: Epoch 095 - generator training loss: -0.0225, discriminator training loss: 0.0670, validation loss: 0.0204
2024-05-24 21:19:23 [INFO]: Epoch 096 - generator training loss: -0.0233, discriminator training loss: 0.0667, validation loss: 0.0206
2024-05-24 21:19:32 [INFO]: Epoch 097 - generator training loss: -0.0234, discriminator training loss: 0.0662, validation loss: 0.0200
2024-05-24 21:19:41 [INFO]: Epoch 098 - generator training loss: -0.0240, discriminator training loss: 0.0646, validation loss: 0.0198
2024-05-24 21:19:50 [INFO]: Epoch 099 - generator training loss: -0.0241, discriminator training loss: 0.0686, validation loss: 0.0198
2024-05-24 21:19:58 [INFO]: Epoch 100 - generator training loss: -0.0247, discriminator training loss: 0.0667, validation loss: 0.0199
2024-05-24 21:20:07 [INFO]: Epoch 101 - generator training loss: -0.0226, discriminator training loss: 0.0657, validation loss: 0.0199
2024-05-24 21:20:16 [INFO]: Epoch 102 - generator training loss: -0.0243, discriminator training loss: 0.0676, validation loss: 0.0198
2024-05-24 21:20:25 [INFO]: Epoch 103 - generator training loss: -0.0235, discriminator training loss: 0.0677, validation loss: 0.0196
2024-05-24 21:20:34 [INFO]: Epoch 104 - generator training loss: -0.0249, discriminator training loss: 0.0650, validation loss: 0.0201
2024-05-24 21:20:43 [INFO]: Epoch 105 - generator training loss: -0.0239, discriminator training loss: 0.0643, validation loss: 0.0200
2024-05-24 21:20:51 [INFO]: Epoch 106 - generator training loss: -0.0233, discriminator training loss: 0.0664, validation loss: 0.0193
2024-05-24 21:21:00 [INFO]: Epoch 107 - generator training loss: -0.0238, discriminator training loss: 0.0675, validation loss: 0.0197
2024-05-24 21:21:09 [INFO]: Epoch 108 - generator training loss: -0.0235, discriminator training loss: 0.0675, validation loss: 0.0195
2024-05-24 21:21:18 [INFO]: Epoch 109 - generator training loss: -0.0260, discriminator training loss: 0.0668, validation loss: 0.0196
2024-05-24 21:21:27 [INFO]: Epoch 110 - generator training loss: -0.0250, discriminator training loss: 0.0683, validation loss: 0.0194
2024-05-24 21:21:36 [INFO]: Epoch 111 - generator training loss: -0.0263, discriminator training loss: 0.0650, validation loss: 0.0198
2024-05-24 21:21:44 [INFO]: Epoch 112 - generator training loss: -0.0242, discriminator training loss: 0.0658, validation loss: 0.0190
2024-05-24 21:21:53 [INFO]: Epoch 113 - generator training loss: -0.0233, discriminator training loss: 0.0646, validation loss: 0.0197
2024-05-24 21:22:02 [INFO]: Epoch 114 - generator training loss: -0.0267, discriminator training loss: 0.0652, validation loss: 0.0192
2024-05-24 21:22:11 [INFO]: Epoch 115 - generator training loss: -0.0245, discriminator training loss: 0.0664, validation loss: 0.0194
2024-05-24 21:22:20 [INFO]: Epoch 116 - generator training loss: -0.0247, discriminator training loss: 0.0658, validation loss: 0.0196
2024-05-24 21:22:28 [INFO]: Epoch 117 - generator training loss: -0.0241, discriminator training loss: 0.0657, validation loss: 0.0197
2024-05-24 21:22:37 [INFO]: Epoch 118 - generator training loss: -0.0234, discriminator training loss: 0.0654, validation loss: 0.0201
2024-05-24 21:22:46 [INFO]: Epoch 119 - generator training loss: -0.0232, discriminator training loss: 0.0664, validation loss: 0.0193
2024-05-24 21:22:55 [INFO]: Epoch 120 - generator training loss: -0.0246, discriminator training loss: 0.0651, validation loss: 0.0227
2024-05-24 21:23:04 [INFO]: Epoch 121 - generator training loss: -0.0196, discriminator training loss: 0.0649, validation loss: 0.0211
2024-05-24 21:23:13 [INFO]: Epoch 122 - generator training loss: -0.0212, discriminator training loss: 0.0652, validation loss: 0.0212
2024-05-24 21:23:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:23:13 [INFO]: Finished training. The best model is from epoch#112.
2024-05-24 21:23:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/USGAN_ettm1/20240524_T210452/USGAN.pypots
2024-05-24 21:23:14 [INFO]: US-GAN on ETTm1: MAE=0.1515, MSE=0.0549
2024-05-24 21:23:14 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/USGAN_ettm1/imputation.pkl
2024-05-24 21:23:14 [INFO]: Using the given device: cuda:0
2024-05-24 21:23:14 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/BRITS_ettm1/20240524_T212314
2024-05-24 21:23:14 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/BRITS_ettm1/20240524_T212314/tensorboard
2024-05-24 21:23:14 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 21:23:21 [INFO]: Epoch 001 - training loss: 1.3178, validation loss: 0.2660
2024-05-24 21:23:27 [INFO]: Epoch 002 - training loss: 0.8780, validation loss: 0.0786
2024-05-24 21:23:33 [INFO]: Epoch 003 - training loss: 0.7160, validation loss: 0.0516
2024-05-24 21:23:39 [INFO]: Epoch 004 - training loss: 0.6462, validation loss: 0.0424
2024-05-24 21:23:45 [INFO]: Epoch 005 - training loss: 0.6039, validation loss: 0.0393
2024-05-24 21:23:51 [INFO]: Epoch 006 - training loss: 0.5746, validation loss: 0.0373
2024-05-24 21:23:57 [INFO]: Epoch 007 - training loss: 0.5451, validation loss: 0.0360
2024-05-24 21:24:03 [INFO]: Epoch 008 - training loss: 0.5305, validation loss: 0.0348
2024-05-24 21:24:09 [INFO]: Epoch 009 - training loss: 0.5126, validation loss: 0.0346
2024-05-24 21:24:14 [INFO]: Epoch 010 - training loss: 0.4826, validation loss: 0.0313
2024-05-24 21:24:20 [INFO]: Epoch 011 - training loss: 0.4651, validation loss: 0.0309
2024-05-24 21:24:26 [INFO]: Epoch 012 - training loss: 0.4438, validation loss: 0.0285
2024-05-24 21:24:32 [INFO]: Epoch 013 - training loss: 0.4281, validation loss: 0.0274
2024-05-24 21:24:38 [INFO]: Epoch 014 - training loss: 0.4404, validation loss: 0.0271
2024-05-24 21:24:44 [INFO]: Epoch 015 - training loss: 0.4197, validation loss: 0.0266
2024-05-24 21:24:50 [INFO]: Epoch 016 - training loss: 0.4173, validation loss: 0.0243
2024-05-24 21:24:56 [INFO]: Epoch 017 - training loss: 0.3968, validation loss: 0.0239
2024-05-24 21:25:02 [INFO]: Epoch 018 - training loss: 0.3996, validation loss: 0.0227
2024-05-24 21:25:07 [INFO]: Epoch 019 - training loss: 0.3945, validation loss: 0.0234
2024-05-24 21:25:13 [INFO]: Epoch 020 - training loss: 0.3840, validation loss: 0.0231
2024-05-24 21:25:19 [INFO]: Epoch 021 - training loss: 0.3930, validation loss: 0.0226
2024-05-24 21:25:25 [INFO]: Epoch 022 - training loss: 0.3893, validation loss: 0.0228
2024-05-24 21:25:31 [INFO]: Epoch 023 - training loss: 0.3869, validation loss: 0.0225
2024-05-24 21:25:37 [INFO]: Epoch 024 - training loss: 0.3832, validation loss: 0.0227
2024-05-24 21:25:43 [INFO]: Epoch 025 - training loss: 0.3829, validation loss: 0.0225
2024-05-24 21:25:49 [INFO]: Epoch 026 - training loss: 0.3816, validation loss: 0.0222
2024-05-24 21:25:55 [INFO]: Epoch 027 - training loss: 0.3878, validation loss: 0.0224
2024-05-24 21:26:01 [INFO]: Epoch 028 - training loss: 0.3843, validation loss: 0.0225
2024-05-24 21:26:06 [INFO]: Epoch 029 - training loss: 0.3955, validation loss: 0.0220
2024-05-24 21:26:12 [INFO]: Epoch 030 - training loss: 0.3816, validation loss: 0.0226
2024-05-24 21:26:18 [INFO]: Epoch 031 - training loss: 0.3820, validation loss: 0.0229
2024-05-24 21:26:24 [INFO]: Epoch 032 - training loss: 0.3741, validation loss: 0.0232
2024-05-24 21:26:30 [INFO]: Epoch 033 - training loss: 0.3754, validation loss: 0.0221
2024-05-24 21:26:36 [INFO]: Epoch 034 - training loss: 0.4276, validation loss: 0.0233
2024-05-24 21:26:42 [INFO]: Epoch 035 - training loss: 0.3870, validation loss: 0.0234
2024-05-24 21:26:48 [INFO]: Epoch 036 - training loss: 0.3819, validation loss: 0.0221
2024-05-24 21:26:54 [INFO]: Epoch 037 - training loss: 0.3751, validation loss: 0.0221
2024-05-24 21:27:00 [INFO]: Epoch 038 - training loss: 0.3731, validation loss: 0.0216
2024-05-24 21:27:06 [INFO]: Epoch 039 - training loss: 0.3690, validation loss: 0.0226
2024-05-24 21:27:11 [INFO]: Epoch 040 - training loss: 0.3747, validation loss: 0.0220
2024-05-24 21:27:17 [INFO]: Epoch 041 - training loss: 0.3704, validation loss: 0.0220
2024-05-24 21:27:23 [INFO]: Epoch 042 - training loss: 0.3725, validation loss: 0.0223
2024-05-24 21:27:29 [INFO]: Epoch 043 - training loss: 0.3702, validation loss: 0.0226
2024-05-24 21:27:35 [INFO]: Epoch 044 - training loss: 0.3642, validation loss: 0.0218
2024-05-24 21:27:41 [INFO]: Epoch 045 - training loss: 0.3685, validation loss: 0.0228
2024-05-24 21:27:47 [INFO]: Epoch 046 - training loss: 0.3703, validation loss: 0.0220
2024-05-24 21:27:53 [INFO]: Epoch 047 - training loss: 0.3750, validation loss: 0.0219
2024-05-24 21:27:59 [INFO]: Epoch 048 - training loss: 0.3713, validation loss: 0.0222
2024-05-24 21:27:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:27:59 [INFO]: Finished training. The best model is from epoch#38.
2024-05-24 21:27:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/BRITS_ettm1/20240524_T212314/BRITS.pypots
2024-05-24 21:28:00 [INFO]: BRITS on ETTm1: MAE=0.1266, MSE=0.0482
2024-05-24 21:28:00 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/BRITS_ettm1/imputation.pkl
2024-05-24 21:28:00 [INFO]: Using the given device: cuda:0
2024-05-24 21:28:00 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800
2024-05-24 21:28:00 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/tensorboard
2024-05-24 21:28:00 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 21:28:02 [INFO]: Epoch 001 - training loss: 1.3440, validation loss: 1.2811
2024-05-24 21:28:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch1_loss1.2811254858970642.pypots
2024-05-24 21:28:02 [INFO]: Epoch 002 - training loss: 1.0461, validation loss: 1.1450
2024-05-24 21:28:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch2_loss1.1450165659189224.pypots
2024-05-24 21:28:02 [INFO]: Epoch 003 - training loss: 1.0072, validation loss: 1.0849
2024-05-24 21:28:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch3_loss1.0848724246025085.pypots
2024-05-24 21:28:02 [INFO]: Epoch 004 - training loss: 0.9666, validation loss: 1.0566
2024-05-24 21:28:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch4_loss1.0565884411334991.pypots
2024-05-24 21:28:02 [INFO]: Epoch 005 - training loss: 0.9537, validation loss: 1.0407
2024-05-24 21:28:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch5_loss1.0407107174396515.pypots
2024-05-24 21:28:03 [INFO]: Epoch 006 - training loss: 0.9512, validation loss: 1.0328
2024-05-24 21:28:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch6_loss1.032831832766533.pypots
2024-05-24 21:28:03 [INFO]: Epoch 007 - training loss: 0.9531, validation loss: 1.0265
2024-05-24 21:28:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch7_loss1.0264526456594467.pypots
2024-05-24 21:28:03 [INFO]: Epoch 008 - training loss: 0.9199, validation loss: 1.0207
2024-05-24 21:28:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch8_loss1.0206830203533173.pypots
2024-05-24 21:28:03 [INFO]: Epoch 009 - training loss: 0.9193, validation loss: 1.0110
2024-05-24 21:28:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch9_loss1.01102614402771.pypots
2024-05-24 21:28:03 [INFO]: Epoch 010 - training loss: 0.9211, validation loss: 1.0068
2024-05-24 21:28:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch10_loss1.0067629516124725.pypots
2024-05-24 21:28:04 [INFO]: Epoch 011 - training loss: 0.9099, validation loss: 1.0029
2024-05-24 21:28:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch11_loss1.0029186606407166.pypots
2024-05-24 21:28:04 [INFO]: Epoch 012 - training loss: 0.9004, validation loss: 0.9996
2024-05-24 21:28:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch12_loss0.999576523900032.pypots
2024-05-24 21:28:04 [INFO]: Epoch 013 - training loss: 0.9050, validation loss: 0.9953
2024-05-24 21:28:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch13_loss0.995343491435051.pypots
2024-05-24 21:28:04 [INFO]: Epoch 014 - training loss: 0.9056, validation loss: 0.9967
2024-05-24 21:28:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch14_loss0.9967354834079742.pypots
2024-05-24 21:28:04 [INFO]: Epoch 015 - training loss: 0.8630, validation loss: 0.9965
2024-05-24 21:28:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch15_loss0.9964845329523087.pypots
2024-05-24 21:28:05 [INFO]: Epoch 016 - training loss: 0.8581, validation loss: 0.9952
2024-05-24 21:28:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch16_loss0.9952453821897507.pypots
2024-05-24 21:28:05 [INFO]: Epoch 017 - training loss: 0.8778, validation loss: 0.9953
2024-05-24 21:28:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch17_loss0.9952580332756042.pypots
2024-05-24 21:28:05 [INFO]: Epoch 018 - training loss: 0.8725, validation loss: 0.9953
2024-05-24 21:28:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch18_loss0.995340034365654.pypots
2024-05-24 21:28:05 [INFO]: Epoch 019 - training loss: 0.8482, validation loss: 0.9951
2024-05-24 21:28:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch19_loss0.9951089024543762.pypots
2024-05-24 21:28:05 [INFO]: Epoch 020 - training loss: 0.8615, validation loss: 0.9900
2024-05-24 21:28:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch20_loss0.9899666756391525.pypots
2024-05-24 21:28:05 [INFO]: Epoch 021 - training loss: 0.8521, validation loss: 0.9887
2024-05-24 21:28:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch21_loss0.9887309819459915.pypots
2024-05-24 21:28:06 [INFO]: Epoch 022 - training loss: 0.8425, validation loss: 0.9881
2024-05-24 21:28:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch22_loss0.9880975931882858.pypots
2024-05-24 21:28:06 [INFO]: Epoch 023 - training loss: 0.8619, validation loss: 0.9829
2024-05-24 21:28:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch23_loss0.982914388179779.pypots
2024-05-24 21:28:06 [INFO]: Epoch 024 - training loss: 0.8618, validation loss: 0.9817
2024-05-24 21:28:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch24_loss0.9817256927490234.pypots
2024-05-24 21:28:06 [INFO]: Epoch 025 - training loss: 0.8718, validation loss: 0.9782
2024-05-24 21:28:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch25_loss0.9782442450523376.pypots
2024-05-24 21:28:06 [INFO]: Epoch 026 - training loss: 0.8523, validation loss: 0.9752
2024-05-24 21:28:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch26_loss0.9751516729593277.pypots
2024-05-24 21:28:07 [INFO]: Epoch 027 - training loss: 0.8173, validation loss: 0.9691
2024-05-24 21:28:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch27_loss0.9691194742918015.pypots
2024-05-24 21:28:07 [INFO]: Epoch 028 - training loss: 0.8233, validation loss: 0.9637
2024-05-24 21:28:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch28_loss0.9636944234371185.pypots
2024-05-24 21:28:07 [INFO]: Epoch 029 - training loss: 0.8386, validation loss: 0.9620
2024-05-24 21:28:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch29_loss0.9620132148265839.pypots
2024-05-24 21:28:07 [INFO]: Epoch 030 - training loss: 0.8378, validation loss: 0.9598
2024-05-24 21:28:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch30_loss0.9597599357366562.pypots
2024-05-24 21:28:07 [INFO]: Epoch 031 - training loss: 0.8674, validation loss: 0.9553
2024-05-24 21:28:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch31_loss0.9553207904100418.pypots
2024-05-24 21:28:08 [INFO]: Epoch 032 - training loss: 0.8408, validation loss: 0.9525
2024-05-24 21:28:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch32_loss0.952522411942482.pypots
2024-05-24 21:28:08 [INFO]: Epoch 033 - training loss: 0.8007, validation loss: 0.9453
2024-05-24 21:28:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch33_loss0.9453102499246597.pypots
2024-05-24 21:28:08 [INFO]: Epoch 034 - training loss: 0.8257, validation loss: 0.9449
2024-05-24 21:28:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch34_loss0.9448989629745483.pypots
2024-05-24 21:28:08 [INFO]: Epoch 035 - training loss: 0.8294, validation loss: 0.9410
2024-05-24 21:28:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch35_loss0.940967321395874.pypots
2024-05-24 21:28:08 [INFO]: Epoch 036 - training loss: 0.8059, validation loss: 0.9373
2024-05-24 21:28:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch36_loss0.93733049929142.pypots
2024-05-24 21:28:09 [INFO]: Epoch 037 - training loss: 0.8258, validation loss: 0.9319
2024-05-24 21:28:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch37_loss0.9318750947713852.pypots
2024-05-24 21:28:09 [INFO]: Epoch 038 - training loss: 0.8231, validation loss: 0.9307
2024-05-24 21:28:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch38_loss0.9307201504707336.pypots
2024-05-24 21:28:09 [INFO]: Epoch 039 - training loss: 0.8155, validation loss: 0.9269
2024-05-24 21:28:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch39_loss0.9269010722637177.pypots
2024-05-24 21:28:09 [INFO]: Epoch 040 - training loss: 0.8240, validation loss: 0.9242
2024-05-24 21:28:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch40_loss0.924210324883461.pypots
2024-05-24 21:28:09 [INFO]: Epoch 041 - training loss: 0.8203, validation loss: 0.9187
2024-05-24 21:28:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch41_loss0.918695330619812.pypots
2024-05-24 21:28:10 [INFO]: Epoch 042 - training loss: 0.8408, validation loss: 0.9180
2024-05-24 21:28:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch42_loss0.9179594069719315.pypots
2024-05-24 21:28:10 [INFO]: Epoch 043 - training loss: 0.8221, validation loss: 0.9184
2024-05-24 21:28:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch43_loss0.9183866679668427.pypots
2024-05-24 21:28:10 [INFO]: Epoch 044 - training loss: 0.8108, validation loss: 0.9149
2024-05-24 21:28:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch44_loss0.9148620367050171.pypots
2024-05-24 21:28:10 [INFO]: Epoch 045 - training loss: 0.8285, validation loss: 0.9101
2024-05-24 21:28:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch45_loss0.9100941270589828.pypots
2024-05-24 21:28:10 [INFO]: Epoch 046 - training loss: 0.8242, validation loss: 0.9105
2024-05-24 21:28:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch46_loss0.9104536324739456.pypots
2024-05-24 21:28:11 [INFO]: Epoch 047 - training loss: 0.7971, validation loss: 0.9065
2024-05-24 21:28:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch47_loss0.906459853053093.pypots
2024-05-24 21:28:11 [INFO]: Epoch 048 - training loss: 0.8141, validation loss: 0.9048
2024-05-24 21:28:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch48_loss0.904845342040062.pypots
2024-05-24 21:28:11 [INFO]: Epoch 049 - training loss: 0.8062, validation loss: 0.9043
2024-05-24 21:28:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch49_loss0.9043024182319641.pypots
2024-05-24 21:28:11 [INFO]: Epoch 050 - training loss: 0.8605, validation loss: 0.9017
2024-05-24 21:28:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch50_loss0.9016934484243393.pypots
2024-05-24 21:28:11 [INFO]: Epoch 051 - training loss: 0.8017, validation loss: 0.8998
2024-05-24 21:28:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch51_loss0.89978988468647.pypots
2024-05-24 21:28:11 [INFO]: Epoch 052 - training loss: 0.8037, validation loss: 0.8994
2024-05-24 21:28:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch52_loss0.8993520587682724.pypots
2024-05-24 21:28:12 [INFO]: Epoch 053 - training loss: 0.8120, validation loss: 0.8963
2024-05-24 21:28:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch53_loss0.8962680399417877.pypots
2024-05-24 21:28:12 [INFO]: Epoch 054 - training loss: 0.7992, validation loss: 0.8940
2024-05-24 21:28:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch54_loss0.893990159034729.pypots
2024-05-24 21:28:12 [INFO]: Epoch 055 - training loss: 0.8003, validation loss: 0.8933
2024-05-24 21:28:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch55_loss0.893263041973114.pypots
2024-05-24 21:28:12 [INFO]: Epoch 056 - training loss: 0.7926, validation loss: 0.8928
2024-05-24 21:28:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch56_loss0.8928180634975433.pypots
2024-05-24 21:28:12 [INFO]: Epoch 057 - training loss: 0.8041, validation loss: 0.8907
2024-05-24 21:28:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch57_loss0.8907257318496704.pypots
2024-05-24 21:28:13 [INFO]: Epoch 058 - training loss: 0.7825, validation loss: 0.8873
2024-05-24 21:28:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch58_loss0.887263834476471.pypots
2024-05-24 21:28:13 [INFO]: Epoch 059 - training loss: 0.8339, validation loss: 0.8910
2024-05-24 21:28:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch59_loss0.8909970372915268.pypots
2024-05-24 21:28:13 [INFO]: Epoch 060 - training loss: 0.8259, validation loss: 0.8859
2024-05-24 21:28:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch60_loss0.8858686238527298.pypots
2024-05-24 21:28:13 [INFO]: Epoch 061 - training loss: 0.8033, validation loss: 0.8880
2024-05-24 21:28:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch61_loss0.8879859447479248.pypots
2024-05-24 21:28:13 [INFO]: Epoch 062 - training loss: 0.8108, validation loss: 0.8841
2024-05-24 21:28:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch62_loss0.8841167986392975.pypots
2024-05-24 21:28:14 [INFO]: Epoch 063 - training loss: 0.8332, validation loss: 0.8863
2024-05-24 21:28:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch63_loss0.8862623870372772.pypots
2024-05-24 21:28:14 [INFO]: Epoch 064 - training loss: 0.8004, validation loss: 0.8836
2024-05-24 21:28:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch64_loss0.883583202958107.pypots
2024-05-24 21:28:14 [INFO]: Epoch 065 - training loss: 0.8301, validation loss: 0.8832
2024-05-24 21:28:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch65_loss0.8831628859043121.pypots
2024-05-24 21:28:14 [INFO]: Epoch 066 - training loss: 0.7961, validation loss: 0.8800
2024-05-24 21:28:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch66_loss0.8799736946821213.pypots
2024-05-24 21:28:14 [INFO]: Epoch 067 - training loss: 0.8583, validation loss: 0.8799
2024-05-24 21:28:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch67_loss0.8798903226852417.pypots
2024-05-24 21:28:15 [INFO]: Epoch 068 - training loss: 0.7933, validation loss: 0.8808
2024-05-24 21:28:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch68_loss0.8808117061853409.pypots
2024-05-24 21:28:15 [INFO]: Epoch 069 - training loss: 0.7856, validation loss: 0.8809
2024-05-24 21:28:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch69_loss0.8808877319097519.pypots
2024-05-24 21:28:15 [INFO]: Epoch 070 - training loss: 0.8059, validation loss: 0.8789
2024-05-24 21:28:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch70_loss0.8788630217313766.pypots
2024-05-24 21:28:15 [INFO]: Epoch 071 - training loss: 0.8105, validation loss: 0.8780
2024-05-24 21:28:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch71_loss0.8780232667922974.pypots
2024-05-24 21:28:15 [INFO]: Epoch 072 - training loss: 0.8141, validation loss: 0.8759
2024-05-24 21:28:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch72_loss0.8759324103593826.pypots
2024-05-24 21:28:16 [INFO]: Epoch 073 - training loss: 0.7979, validation loss: 0.8784
2024-05-24 21:28:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch73_loss0.8784296661615372.pypots
2024-05-24 21:28:16 [INFO]: Epoch 074 - training loss: 0.8061, validation loss: 0.8768
2024-05-24 21:28:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch74_loss0.8767551481723785.pypots
2024-05-24 21:28:16 [INFO]: Epoch 075 - training loss: 0.8057, validation loss: 0.8776
2024-05-24 21:28:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch75_loss0.8775599896907806.pypots
2024-05-24 21:28:16 [INFO]: Epoch 076 - training loss: 0.8048, validation loss: 0.8743
2024-05-24 21:28:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch76_loss0.8742538094520569.pypots
2024-05-24 21:28:16 [INFO]: Epoch 077 - training loss: 0.7775, validation loss: 0.8753
2024-05-24 21:28:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch77_loss0.8752760887145996.pypots
2024-05-24 21:28:17 [INFO]: Epoch 078 - training loss: 0.8015, validation loss: 0.8751
2024-05-24 21:28:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch78_loss0.87508425116539.pypots
2024-05-24 21:28:17 [INFO]: Epoch 079 - training loss: 0.7857, validation loss: 0.8756
2024-05-24 21:28:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch79_loss0.8755791634321213.pypots
2024-05-24 21:28:17 [INFO]: Epoch 080 - training loss: 0.8305, validation loss: 0.8749
2024-05-24 21:28:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch80_loss0.8748707473278046.pypots
2024-05-24 21:28:17 [INFO]: Epoch 081 - training loss: 0.7902, validation loss: 0.8734
2024-05-24 21:28:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch81_loss0.8733817636966705.pypots
2024-05-24 21:28:17 [INFO]: Epoch 082 - training loss: 0.7791, validation loss: 0.8730
2024-05-24 21:28:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch82_loss0.8729835748672485.pypots
2024-05-24 21:28:17 [INFO]: Epoch 083 - training loss: 0.7685, validation loss: 0.8729
2024-05-24 21:28:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch83_loss0.8728788048028946.pypots
2024-05-24 21:28:18 [INFO]: Epoch 084 - training loss: 0.7890, validation loss: 0.8736
2024-05-24 21:28:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch84_loss0.873583197593689.pypots
2024-05-24 21:28:18 [INFO]: Epoch 085 - training loss: 0.8258, validation loss: 0.8719
2024-05-24 21:28:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch85_loss0.8718903511762619.pypots
2024-05-24 21:28:18 [INFO]: Epoch 086 - training loss: 0.7850, validation loss: 0.8716
2024-05-24 21:28:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch86_loss0.8715537339448929.pypots
2024-05-24 21:28:18 [INFO]: Epoch 087 - training loss: 0.7761, validation loss: 0.8706
2024-05-24 21:28:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch87_loss0.8706285059452057.pypots
2024-05-24 21:28:18 [INFO]: Epoch 088 - training loss: 0.7848, validation loss: 0.8698
2024-05-24 21:28:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch88_loss0.8697546571493149.pypots
2024-05-24 21:28:19 [INFO]: Epoch 089 - training loss: 0.8019, validation loss: 0.8695
2024-05-24 21:28:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch89_loss0.8694944083690643.pypots
2024-05-24 21:28:19 [INFO]: Epoch 090 - training loss: 0.7856, validation loss: 0.8703
2024-05-24 21:28:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch90_loss0.8702788650989532.pypots
2024-05-24 21:28:19 [INFO]: Epoch 091 - training loss: 0.7688, validation loss: 0.8692
2024-05-24 21:28:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch91_loss0.8691599071025848.pypots
2024-05-24 21:28:19 [INFO]: Epoch 092 - training loss: 0.7838, validation loss: 0.8696
2024-05-24 21:28:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch92_loss0.8696178197860718.pypots
2024-05-24 21:28:19 [INFO]: Epoch 093 - training loss: 0.8009, validation loss: 0.8687
2024-05-24 21:28:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch93_loss0.8687385767698288.pypots
2024-05-24 21:28:20 [INFO]: Epoch 094 - training loss: 0.7970, validation loss: 0.8683
2024-05-24 21:28:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch94_loss0.8683493882417679.pypots
2024-05-24 21:28:20 [INFO]: Epoch 095 - training loss: 0.7889, validation loss: 0.8678
2024-05-24 21:28:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch95_loss0.867772251367569.pypots
2024-05-24 21:28:20 [INFO]: Epoch 096 - training loss: 0.7960, validation loss: 0.8673
2024-05-24 21:28:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch96_loss0.8672970086336136.pypots
2024-05-24 21:28:20 [INFO]: Epoch 097 - training loss: 0.7885, validation loss: 0.8679
2024-05-24 21:28:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch97_loss0.867887482047081.pypots
2024-05-24 21:28:20 [INFO]: Epoch 098 - training loss: 0.7999, validation loss: 0.8664
2024-05-24 21:28:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch98_loss0.866375282406807.pypots
2024-05-24 21:28:21 [INFO]: Epoch 099 - training loss: 0.7868, validation loss: 0.8663
2024-05-24 21:28:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch99_loss0.866318017244339.pypots
2024-05-24 21:28:21 [INFO]: Epoch 100 - training loss: 0.7815, validation loss: 0.8644
2024-05-24 21:28:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch100_loss0.864380493760109.pypots
2024-05-24 21:28:21 [INFO]: Epoch 101 - training loss: 0.8066, validation loss: 0.8644
2024-05-24 21:28:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch101_loss0.8644155114889145.pypots
2024-05-24 21:28:21 [INFO]: Epoch 102 - training loss: 0.7949, validation loss: 0.8658
2024-05-24 21:28:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch102_loss0.8658152967691422.pypots
2024-05-24 21:28:21 [INFO]: Epoch 103 - training loss: 0.7902, validation loss: 0.8653
2024-05-24 21:28:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch103_loss0.8652568608522415.pypots
2024-05-24 21:28:22 [INFO]: Epoch 104 - training loss: 0.8040, validation loss: 0.8650
2024-05-24 21:28:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch104_loss0.8650041222572327.pypots
2024-05-24 21:28:22 [INFO]: Epoch 105 - training loss: 0.8255, validation loss: 0.8644
2024-05-24 21:28:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch105_loss0.8643543571233749.pypots
2024-05-24 21:28:22 [INFO]: Epoch 106 - training loss: 0.7841, validation loss: 0.8630
2024-05-24 21:28:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch106_loss0.8629936575889587.pypots
2024-05-24 21:28:22 [INFO]: Epoch 107 - training loss: 0.7662, validation loss: 0.8611
2024-05-24 21:28:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch107_loss0.8610956966876984.pypots
2024-05-24 21:28:22 [INFO]: Epoch 108 - training loss: 0.7929, validation loss: 0.8632
2024-05-24 21:28:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch108_loss0.8632164150476456.pypots
2024-05-24 21:28:22 [INFO]: Epoch 109 - training loss: 0.8017, validation loss: 0.8623
2024-05-24 21:28:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch109_loss0.8623484224081039.pypots
2024-05-24 21:28:23 [INFO]: Epoch 110 - training loss: 0.7812, validation loss: 0.8627
2024-05-24 21:28:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch110_loss0.862656831741333.pypots
2024-05-24 21:28:23 [INFO]: Epoch 111 - training loss: 0.7916, validation loss: 0.8613
2024-05-24 21:28:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch111_loss0.8612668812274933.pypots
2024-05-24 21:28:23 [INFO]: Epoch 112 - training loss: 0.8078, validation loss: 0.8610
2024-05-24 21:28:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch112_loss0.861043781042099.pypots
2024-05-24 21:28:23 [INFO]: Epoch 113 - training loss: 0.7777, validation loss: 0.8637
2024-05-24 21:28:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch113_loss0.8636996895074844.pypots
2024-05-24 21:28:23 [INFO]: Epoch 114 - training loss: 0.7867, validation loss: 0.8637
2024-05-24 21:28:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch114_loss0.8637368679046631.pypots
2024-05-24 21:28:24 [INFO]: Epoch 115 - training loss: 0.7759, validation loss: 0.8599
2024-05-24 21:28:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch115_loss0.8599324226379395.pypots
2024-05-24 21:28:24 [INFO]: Epoch 116 - training loss: 0.7616, validation loss: 0.8591
2024-05-24 21:28:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch116_loss0.8590589761734009.pypots
2024-05-24 21:28:24 [INFO]: Epoch 117 - training loss: 0.7667, validation loss: 0.8630
2024-05-24 21:28:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch117_loss0.8630280792713165.pypots
2024-05-24 21:28:24 [INFO]: Epoch 118 - training loss: 0.7972, validation loss: 0.8597
2024-05-24 21:28:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch118_loss0.8597445487976074.pypots
2024-05-24 21:28:24 [INFO]: Epoch 119 - training loss: 0.7856, validation loss: 0.8629
2024-05-24 21:28:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch119_loss0.8628682047128677.pypots
2024-05-24 21:28:25 [INFO]: Epoch 120 - training loss: 0.7938, validation loss: 0.8592
2024-05-24 21:28:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch120_loss0.8591597378253937.pypots
2024-05-24 21:28:25 [INFO]: Epoch 121 - training loss: 0.7879, validation loss: 0.8584
2024-05-24 21:28:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch121_loss0.8584023267030716.pypots
2024-05-24 21:28:25 [INFO]: Epoch 122 - training loss: 0.7786, validation loss: 0.8580
2024-05-24 21:28:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch122_loss0.85796719789505.pypots
2024-05-24 21:28:25 [INFO]: Epoch 123 - training loss: 0.7591, validation loss: 0.8577
2024-05-24 21:28:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch123_loss0.8577301055192947.pypots
2024-05-24 21:28:25 [INFO]: Epoch 124 - training loss: 0.7922, validation loss: 0.8596
2024-05-24 21:28:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch124_loss0.8596032112836838.pypots
2024-05-24 21:28:26 [INFO]: Epoch 125 - training loss: 0.7809, validation loss: 0.8562
2024-05-24 21:28:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch125_loss0.856238380074501.pypots
2024-05-24 21:28:26 [INFO]: Epoch 126 - training loss: 0.7789, validation loss: 0.8570
2024-05-24 21:28:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch126_loss0.8569875955581665.pypots
2024-05-24 21:28:26 [INFO]: Epoch 127 - training loss: 0.7878, validation loss: 0.8551
2024-05-24 21:28:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch127_loss0.85514996945858.pypots
2024-05-24 21:28:26 [INFO]: Epoch 128 - training loss: 0.7783, validation loss: 0.8556
2024-05-24 21:28:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch128_loss0.8555846959352493.pypots
2024-05-24 21:28:26 [INFO]: Epoch 129 - training loss: 0.7744, validation loss: 0.8571
2024-05-24 21:28:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch129_loss0.8570517003536224.pypots
2024-05-24 21:28:27 [INFO]: Epoch 130 - training loss: 0.7687, validation loss: 0.8556
2024-05-24 21:28:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch130_loss0.8556462675333023.pypots
2024-05-24 21:28:27 [INFO]: Epoch 131 - training loss: 0.7908, validation loss: 0.8561
2024-05-24 21:28:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch131_loss0.856052502989769.pypots
2024-05-24 21:28:27 [INFO]: Epoch 132 - training loss: 0.7967, validation loss: 0.8568
2024-05-24 21:28:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch132_loss0.8567675054073334.pypots
2024-05-24 21:28:27 [INFO]: Epoch 133 - training loss: 0.7624, validation loss: 0.8566
2024-05-24 21:28:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch133_loss0.8565559089183807.pypots
2024-05-24 21:28:27 [INFO]: Epoch 134 - training loss: 0.7886, validation loss: 0.8559
2024-05-24 21:28:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch134_loss0.8558501303195953.pypots
2024-05-24 21:28:28 [INFO]: Epoch 135 - training loss: 0.7698, validation loss: 0.8526
2024-05-24 21:28:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch135_loss0.8526080250740051.pypots
2024-05-24 21:28:28 [INFO]: Epoch 136 - training loss: 0.7961, validation loss: 0.8541
2024-05-24 21:28:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch136_loss0.8540904074907303.pypots
2024-05-24 21:28:28 [INFO]: Epoch 137 - training loss: 0.7647, validation loss: 0.8502
2024-05-24 21:28:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch137_loss0.8502405881881714.pypots
2024-05-24 21:28:28 [INFO]: Epoch 138 - training loss: 0.7690, validation loss: 0.8509
2024-05-24 21:28:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch138_loss0.8509374260902405.pypots
2024-05-24 21:28:28 [INFO]: Epoch 139 - training loss: 0.7963, validation loss: 0.8517
2024-05-24 21:28:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch139_loss0.8517118692398071.pypots
2024-05-24 21:28:28 [INFO]: Epoch 140 - training loss: 0.7789, validation loss: 0.8506
2024-05-24 21:28:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch140_loss0.8505833745002747.pypots
2024-05-24 21:28:29 [INFO]: Epoch 141 - training loss: 0.7866, validation loss: 0.8539
2024-05-24 21:28:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch141_loss0.8538639098405838.pypots
2024-05-24 21:28:29 [INFO]: Epoch 142 - training loss: 0.7877, validation loss: 0.8498
2024-05-24 21:28:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch142_loss0.8498192131519318.pypots
2024-05-24 21:28:29 [INFO]: Epoch 143 - training loss: 0.7613, validation loss: 0.8517
2024-05-24 21:28:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch143_loss0.8516627997159958.pypots
2024-05-24 21:28:29 [INFO]: Epoch 144 - training loss: 0.7761, validation loss: 0.8513
2024-05-24 21:28:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch144_loss0.8512805104255676.pypots
2024-05-24 21:28:29 [INFO]: Epoch 145 - training loss: 0.7811, validation loss: 0.8525
2024-05-24 21:28:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch145_loss0.8524754494428635.pypots
2024-05-24 21:28:30 [INFO]: Epoch 146 - training loss: 0.7740, validation loss: 0.8492
2024-05-24 21:28:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch146_loss0.8491801470518112.pypots
2024-05-24 21:28:30 [INFO]: Epoch 147 - training loss: 0.7752, validation loss: 0.8500
2024-05-24 21:28:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch147_loss0.8499575108289719.pypots
2024-05-24 21:28:30 [INFO]: Epoch 148 - training loss: 0.8201, validation loss: 0.8496
2024-05-24 21:28:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch148_loss0.8496273308992386.pypots
2024-05-24 21:28:30 [INFO]: Epoch 149 - training loss: 0.7990, validation loss: 0.8515
2024-05-24 21:28:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch149_loss0.8514574617147446.pypots
2024-05-24 21:28:30 [INFO]: Epoch 150 - training loss: 0.7823, validation loss: 0.8548
2024-05-24 21:28:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch150_loss0.8548345267772675.pypots
2024-05-24 21:28:31 [INFO]: Epoch 151 - training loss: 0.7837, validation loss: 0.8468
2024-05-24 21:28:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch151_loss0.8468243479728699.pypots
2024-05-24 21:28:31 [INFO]: Epoch 152 - training loss: 0.7833, validation loss: 0.8494
2024-05-24 21:28:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch152_loss0.8493916094303131.pypots
2024-05-24 21:28:31 [INFO]: Epoch 153 - training loss: 0.7760, validation loss: 0.8489
2024-05-24 21:28:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch153_loss0.8489393889904022.pypots
2024-05-24 21:28:31 [INFO]: Epoch 154 - training loss: 0.7863, validation loss: 0.8504
2024-05-24 21:28:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch154_loss0.8504364341497421.pypots
2024-05-24 21:28:31 [INFO]: Epoch 155 - training loss: 0.7733, validation loss: 0.8468
2024-05-24 21:28:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch155_loss0.8467587232589722.pypots
2024-05-24 21:28:32 [INFO]: Epoch 156 - training loss: 0.7727, validation loss: 0.8485
2024-05-24 21:28:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch156_loss0.8485090136528015.pypots
2024-05-24 21:28:32 [INFO]: Epoch 157 - training loss: 0.7892, validation loss: 0.8474
2024-05-24 21:28:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch157_loss0.8474413007497787.pypots
2024-05-24 21:28:32 [INFO]: Epoch 158 - training loss: 0.7999, validation loss: 0.8463
2024-05-24 21:28:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch158_loss0.8463477194309235.pypots
2024-05-24 21:28:32 [INFO]: Epoch 159 - training loss: 0.7941, validation loss: 0.8457
2024-05-24 21:28:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch159_loss0.8456729650497437.pypots
2024-05-24 21:28:32 [INFO]: Epoch 160 - training loss: 0.7958, validation loss: 0.8475
2024-05-24 21:28:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch160_loss0.8475201725959778.pypots
2024-05-24 21:28:33 [INFO]: Epoch 161 - training loss: 0.7860, validation loss: 0.8473
2024-05-24 21:28:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch161_loss0.8473072201013565.pypots
2024-05-24 21:28:33 [INFO]: Epoch 162 - training loss: 0.7600, validation loss: 0.8457
2024-05-24 21:28:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch162_loss0.8457389771938324.pypots
2024-05-24 21:28:33 [INFO]: Epoch 163 - training loss: 0.7704, validation loss: 0.8465
2024-05-24 21:28:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch163_loss0.8465238511562347.pypots
2024-05-24 21:28:33 [INFO]: Epoch 164 - training loss: 0.7911, validation loss: 0.8458
2024-05-24 21:28:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch164_loss0.8458422869443893.pypots
2024-05-24 21:28:33 [INFO]: Epoch 165 - training loss: 0.7867, validation loss: 0.8451
2024-05-24 21:28:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch165_loss0.8451330065727234.pypots
2024-05-24 21:28:34 [INFO]: Epoch 166 - training loss: 0.8079, validation loss: 0.8444
2024-05-24 21:28:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch166_loss0.8443848937749863.pypots
2024-05-24 21:28:34 [INFO]: Epoch 167 - training loss: 0.7760, validation loss: 0.8460
2024-05-24 21:28:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch167_loss0.8460219204425812.pypots
2024-05-24 21:28:34 [INFO]: Epoch 168 - training loss: 0.8027, validation loss: 0.8425
2024-05-24 21:28:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch168_loss0.8424602746963501.pypots
2024-05-24 21:28:34 [INFO]: Epoch 169 - training loss: 0.7664, validation loss: 0.8467
2024-05-24 21:28:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch169_loss0.8466927260160446.pypots
2024-05-24 21:28:34 [INFO]: Epoch 170 - training loss: 0.7624, validation loss: 0.8441
2024-05-24 21:28:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch170_loss0.8441319614648819.pypots
2024-05-24 21:28:34 [INFO]: Epoch 171 - training loss: 0.7807, validation loss: 0.8461
2024-05-24 21:28:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch171_loss0.8461147546768188.pypots
2024-05-24 21:28:35 [INFO]: Epoch 172 - training loss: 0.7657, validation loss: 0.8460
2024-05-24 21:28:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch172_loss0.8460172265768051.pypots
2024-05-24 21:28:35 [INFO]: Epoch 173 - training loss: 0.7958, validation loss: 0.8452
2024-05-24 21:28:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch173_loss0.8452270328998566.pypots
2024-05-24 21:28:35 [INFO]: Epoch 174 - training loss: 0.7674, validation loss: 0.8438
2024-05-24 21:28:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch174_loss0.8437765538692474.pypots
2024-05-24 21:28:35 [INFO]: Epoch 175 - training loss: 0.7790, validation loss: 0.8409
2024-05-24 21:28:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch175_loss0.8408815264701843.pypots
2024-05-24 21:28:35 [INFO]: Epoch 176 - training loss: 0.7983, validation loss: 0.8448
2024-05-24 21:28:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch176_loss0.8448217362165451.pypots
2024-05-24 21:28:36 [INFO]: Epoch 177 - training loss: 0.7994, validation loss: 0.8440
2024-05-24 21:28:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch177_loss0.8439791053533554.pypots
2024-05-24 21:28:36 [INFO]: Epoch 178 - training loss: 0.7918, validation loss: 0.8443
2024-05-24 21:28:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch178_loss0.8443415462970734.pypots
2024-05-24 21:28:36 [INFO]: Epoch 179 - training loss: 0.7601, validation loss: 0.8425
2024-05-24 21:28:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch179_loss0.8424986898899078.pypots
2024-05-24 21:28:36 [INFO]: Epoch 180 - training loss: 0.7761, validation loss: 0.8444
2024-05-24 21:28:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch180_loss0.8443686217069626.pypots
2024-05-24 21:28:36 [INFO]: Epoch 181 - training loss: 0.7656, validation loss: 0.8464
2024-05-24 21:28:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch181_loss0.8464225679636002.pypots
2024-05-24 21:28:37 [INFO]: Epoch 182 - training loss: 0.7855, validation loss: 0.8456
2024-05-24 21:28:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch182_loss0.8456274420022964.pypots
2024-05-24 21:28:37 [INFO]: Epoch 183 - training loss: 0.7857, validation loss: 0.8415
2024-05-24 21:28:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch183_loss0.841450959444046.pypots
2024-05-24 21:28:37 [INFO]: Epoch 184 - training loss: 0.7886, validation loss: 0.8435
2024-05-24 21:28:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch184_loss0.8434854745864868.pypots
2024-05-24 21:28:37 [INFO]: Epoch 185 - training loss: 0.7933, validation loss: 0.8417
2024-05-24 21:28:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN_epoch185_loss0.8416707217693329.pypots
2024-05-24 21:28:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:28:37 [INFO]: Finished training. The best model is from epoch#175.
2024-05-24 21:28:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T212800/MRNN.pypots
2024-05-24 21:28:38 [INFO]: MRNN on ETTm1: MAE=0.6218, MSE=1.0296
2024-05-24 21:28:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/MRNN_ettm1/imputation.pkl
2024-05-24 21:28:38 [INFO]: Using the given device: cpu
2024-05-24 21:28:38 [INFO]: LOCF on ETTm1: MAE=0.1348, MSE=0.0715
2024-05-24 21:28:38 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_ettm1".
2024-05-24 21:28:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/LOCF_ettm1/imputation.pkl
2024-05-24 21:28:38 [INFO]: Median on ETTm1: MAE=0.6516, MSE=0.8223
2024-05-24 21:28:38 [INFO]: Successfully created the given path "saved_results/round_0/Median_ettm1".
2024-05-24 21:28:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Median_ettm1/imputation.pkl
2024-05-24 21:28:38 [INFO]: Mean on ETTm1: MAE=0.6566, MSE=0.8036
2024-05-24 21:28:38 [INFO]: Successfully created the given path "saved_results/round_0/Mean_ettm1".
2024-05-24 21:28:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Mean_ettm1/imputation.pkl
2024-05-24 21:28:38 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-24 21:28:38 [INFO]: Using the given device: cuda:0
2024-05-24 21:28:38 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/SAITS_ettm1/20240524_T212838
2024-05-24 21:28:38 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/SAITS_ettm1/20240524_T212838/tensorboard
2024-05-24 21:28:38 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 21:28:38 [INFO]: Epoch 001 - training loss: 1.1131, validation loss: 0.2844
2024-05-24 21:28:39 [INFO]: Epoch 002 - training loss: 0.7910, validation loss: 0.1275
2024-05-24 21:28:39 [INFO]: Epoch 003 - training loss: 0.6925, validation loss: 0.0967
2024-05-24 21:28:40 [INFO]: Epoch 004 - training loss: 0.6315, validation loss: 0.0855
2024-05-24 21:28:40 [INFO]: Epoch 005 - training loss: 0.6031, validation loss: 0.0768
2024-05-24 21:28:41 [INFO]: Epoch 006 - training loss: 0.5713, validation loss: 0.0660
2024-05-24 21:28:41 [INFO]: Epoch 007 - training loss: 0.5494, validation loss: 0.0666
2024-05-24 21:28:42 [INFO]: Epoch 008 - training loss: 0.5424, validation loss: 0.0574
2024-05-24 21:28:42 [INFO]: Epoch 009 - training loss: 0.5523, validation loss: 0.0734
2024-05-24 21:28:43 [INFO]: Epoch 010 - training loss: 0.5304, validation loss: 0.0676
2024-05-24 21:28:43 [INFO]: Epoch 011 - training loss: 0.5032, validation loss: 0.0543
2024-05-24 21:28:44 [INFO]: Epoch 012 - training loss: 0.4965, validation loss: 0.0547
2024-05-24 21:28:44 [INFO]: Epoch 013 - training loss: 0.4750, validation loss: 0.0460
2024-05-24 21:28:45 [INFO]: Epoch 014 - training loss: 0.4759, validation loss: 0.0546
2024-05-24 21:28:45 [INFO]: Epoch 015 - training loss: 0.4866, validation loss: 0.0589
2024-05-24 21:28:46 [INFO]: Epoch 016 - training loss: 0.4585, validation loss: 0.0469
2024-05-24 21:28:46 [INFO]: Epoch 017 - training loss: 0.4495, validation loss: 0.0482
2024-05-24 21:28:47 [INFO]: Epoch 018 - training loss: 0.4508, validation loss: 0.0517
2024-05-24 21:28:47 [INFO]: Epoch 019 - training loss: 0.4427, validation loss: 0.0480
2024-05-24 21:28:48 [INFO]: Epoch 020 - training loss: 0.4416, validation loss: 0.0374
2024-05-24 21:28:48 [INFO]: Epoch 021 - training loss: 0.4281, validation loss: 0.0550
2024-05-24 21:28:49 [INFO]: Epoch 022 - training loss: 0.4112, validation loss: 0.0448
2024-05-24 21:28:49 [INFO]: Epoch 023 - training loss: 0.4056, validation loss: 0.0369
2024-05-24 21:28:49 [INFO]: Epoch 024 - training loss: 0.3935, validation loss: 0.0430
2024-05-24 21:28:50 [INFO]: Epoch 025 - training loss: 0.3900, validation loss: 0.0420
2024-05-24 21:28:50 [INFO]: Epoch 026 - training loss: 0.4011, validation loss: 0.0888
2024-05-24 21:28:51 [INFO]: Epoch 027 - training loss: 0.4222, validation loss: 0.0473
2024-05-24 21:28:51 [INFO]: Epoch 028 - training loss: 0.3874, validation loss: 0.0372
2024-05-24 21:28:52 [INFO]: Epoch 029 - training loss: 0.3765, validation loss: 0.0353
2024-05-24 21:28:52 [INFO]: Epoch 030 - training loss: 0.3794, validation loss: 0.0369
2024-05-24 21:28:53 [INFO]: Epoch 031 - training loss: 0.3738, validation loss: 0.0414
2024-05-24 21:28:53 [INFO]: Epoch 032 - training loss: 0.3665, validation loss: 0.0336
2024-05-24 21:28:54 [INFO]: Epoch 033 - training loss: 0.3637, validation loss: 0.0453
2024-05-24 21:28:54 [INFO]: Epoch 034 - training loss: 0.3571, validation loss: 0.0400
2024-05-24 21:28:55 [INFO]: Epoch 035 - training loss: 0.3538, validation loss: 0.0307
2024-05-24 21:28:55 [INFO]: Epoch 036 - training loss: 0.3488, validation loss: 0.0333
2024-05-24 21:28:56 [INFO]: Epoch 037 - training loss: 0.3398, validation loss: 0.0327
2024-05-24 21:28:56 [INFO]: Epoch 038 - training loss: 0.3470, validation loss: 0.0419
2024-05-24 21:28:57 [INFO]: Epoch 039 - training loss: 0.3367, validation loss: 0.0360
2024-05-24 21:28:57 [INFO]: Epoch 040 - training loss: 0.3408, validation loss: 0.0412
2024-05-24 21:28:58 [INFO]: Epoch 041 - training loss: 0.3377, validation loss: 0.0502
2024-05-24 21:28:58 [INFO]: Epoch 042 - training loss: 0.3376, validation loss: 0.0358
2024-05-24 21:28:59 [INFO]: Epoch 043 - training loss: 0.3282, validation loss: 0.0334
2024-05-24 21:28:59 [INFO]: Epoch 044 - training loss: 0.3387, validation loss: 0.0404
2024-05-24 21:29:00 [INFO]: Epoch 045 - training loss: 0.3257, validation loss: 0.0359
2024-05-24 21:29:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:29:00 [INFO]: Finished training. The best model is from epoch#35.
2024-05-24 21:29:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/SAITS_ettm1/20240524_T212838/SAITS.pypots
2024-05-24 21:29:00 [INFO]: SAITS on ETTm1: MAE=0.1504, MSE=0.0450
2024-05-24 21:29:00 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/SAITS_ettm1/imputation.pkl
2024-05-24 21:29:00 [INFO]: Using the given device: cuda:0
2024-05-24 21:29:00 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/Transformer_ettm1/20240524_T212900
2024-05-24 21:29:00 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/Transformer_ettm1/20240524_T212900/tensorboard
2024-05-24 21:29:00 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 21:29:00 [INFO]: Epoch 001 - training loss: 1.3124, validation loss: 0.3238
2024-05-24 21:29:00 [INFO]: Epoch 002 - training loss: 0.6840, validation loss: 0.1731
2024-05-24 21:29:00 [INFO]: Epoch 003 - training loss: 0.5467, validation loss: 0.1096
2024-05-24 21:29:01 [INFO]: Epoch 004 - training loss: 0.4754, validation loss: 0.0895
2024-05-24 21:29:01 [INFO]: Epoch 005 - training loss: 0.4506, validation loss: 0.0740
2024-05-24 21:29:01 [INFO]: Epoch 006 - training loss: 0.4238, validation loss: 0.0646
2024-05-24 21:29:01 [INFO]: Epoch 007 - training loss: 0.4004, validation loss: 0.0586
2024-05-24 21:29:01 [INFO]: Epoch 008 - training loss: 0.3789, validation loss: 0.0561
2024-05-24 21:29:02 [INFO]: Epoch 009 - training loss: 0.3811, validation loss: 0.0547
2024-05-24 21:29:02 [INFO]: Epoch 010 - training loss: 0.3684, validation loss: 0.0594
2024-05-24 21:29:02 [INFO]: Epoch 011 - training loss: 0.3587, validation loss: 0.0511
2024-05-24 21:29:02 [INFO]: Epoch 012 - training loss: 0.3589, validation loss: 0.0482
2024-05-24 21:29:02 [INFO]: Epoch 013 - training loss: 0.3439, validation loss: 0.0453
2024-05-24 21:29:03 [INFO]: Epoch 014 - training loss: 0.3359, validation loss: 0.0428
2024-05-24 21:29:03 [INFO]: Epoch 015 - training loss: 0.3267, validation loss: 0.0426
2024-05-24 21:29:03 [INFO]: Epoch 016 - training loss: 0.3245, validation loss: 0.0438
2024-05-24 21:29:03 [INFO]: Epoch 017 - training loss: 0.3191, validation loss: 0.0418
2024-05-24 21:29:03 [INFO]: Epoch 018 - training loss: 0.3176, validation loss: 0.0386
2024-05-24 21:29:04 [INFO]: Epoch 019 - training loss: 0.3053, validation loss: 0.0529
2024-05-24 21:29:04 [INFO]: Epoch 020 - training loss: 0.3266, validation loss: 0.0485
2024-05-24 21:29:04 [INFO]: Epoch 021 - training loss: 0.3073, validation loss: 0.0355
2024-05-24 21:29:04 [INFO]: Epoch 022 - training loss: 0.2931, validation loss: 0.0366
2024-05-24 21:29:04 [INFO]: Epoch 023 - training loss: 0.3029, validation loss: 0.0395
2024-05-24 21:29:05 [INFO]: Epoch 024 - training loss: 0.2959, validation loss: 0.0344
2024-05-24 21:29:05 [INFO]: Epoch 025 - training loss: 0.2897, validation loss: 0.0352
2024-05-24 21:29:05 [INFO]: Epoch 026 - training loss: 0.2844, validation loss: 0.0324
2024-05-24 21:29:05 [INFO]: Epoch 027 - training loss: 0.2762, validation loss: 0.0342
2024-05-24 21:29:05 [INFO]: Epoch 028 - training loss: 0.2769, validation loss: 0.0339
2024-05-24 21:29:06 [INFO]: Epoch 029 - training loss: 0.2808, validation loss: 0.0333
2024-05-24 21:29:06 [INFO]: Epoch 030 - training loss: 0.2790, validation loss: 0.0335
2024-05-24 21:29:06 [INFO]: Epoch 031 - training loss: 0.2878, validation loss: 0.0338
2024-05-24 21:29:06 [INFO]: Epoch 032 - training loss: 0.2776, validation loss: 0.0323
2024-05-24 21:29:06 [INFO]: Epoch 033 - training loss: 0.2672, validation loss: 0.0328
2024-05-24 21:29:07 [INFO]: Epoch 034 - training loss: 0.2640, validation loss: 0.0350
2024-05-24 21:29:07 [INFO]: Epoch 035 - training loss: 0.2689, validation loss: 0.0351
2024-05-24 21:29:07 [INFO]: Epoch 036 - training loss: 0.2622, validation loss: 0.0294
2024-05-24 21:29:07 [INFO]: Epoch 037 - training loss: 0.2583, validation loss: 0.0331
2024-05-24 21:29:07 [INFO]: Epoch 038 - training loss: 0.2584, validation loss: 0.0306
2024-05-24 21:29:07 [INFO]: Epoch 039 - training loss: 0.2583, validation loss: 0.0298
2024-05-24 21:29:08 [INFO]: Epoch 040 - training loss: 0.2491, validation loss: 0.0315
2024-05-24 21:29:08 [INFO]: Epoch 041 - training loss: 0.2516, validation loss: 0.0360
2024-05-24 21:29:08 [INFO]: Epoch 042 - training loss: 0.2591, validation loss: 0.0315
2024-05-24 21:29:08 [INFO]: Epoch 043 - training loss: 0.2507, validation loss: 0.0279
2024-05-24 21:29:08 [INFO]: Epoch 044 - training loss: 0.2470, validation loss: 0.0293
2024-05-24 21:29:09 [INFO]: Epoch 045 - training loss: 0.2435, validation loss: 0.0288
2024-05-24 21:29:09 [INFO]: Epoch 046 - training loss: 0.2494, validation loss: 0.0290
2024-05-24 21:29:09 [INFO]: Epoch 047 - training loss: 0.2743, validation loss: 0.0326
2024-05-24 21:29:09 [INFO]: Epoch 048 - training loss: 0.2520, validation loss: 0.0328
2024-05-24 21:29:09 [INFO]: Epoch 049 - training loss: 0.2480, validation loss: 0.0294
2024-05-24 21:29:10 [INFO]: Epoch 050 - training loss: 0.2453, validation loss: 0.0300
2024-05-24 21:29:10 [INFO]: Epoch 051 - training loss: 0.2303, validation loss: 0.0294
2024-05-24 21:29:10 [INFO]: Epoch 052 - training loss: 0.2344, validation loss: 0.0266
2024-05-24 21:29:10 [INFO]: Epoch 053 - training loss: 0.2283, validation loss: 0.0311
2024-05-24 21:29:10 [INFO]: Epoch 054 - training loss: 0.2384, validation loss: 0.0319
2024-05-24 21:29:11 [INFO]: Epoch 055 - training loss: 0.2356, validation loss: 0.0294
2024-05-24 21:29:11 [INFO]: Epoch 056 - training loss: 0.2332, validation loss: 0.0284
2024-05-24 21:29:11 [INFO]: Epoch 057 - training loss: 0.2252, validation loss: 0.0264
2024-05-24 21:29:11 [INFO]: Epoch 058 - training loss: 0.2251, validation loss: 0.0304
2024-05-24 21:29:11 [INFO]: Epoch 059 - training loss: 0.2316, validation loss: 0.0285
2024-05-24 21:29:12 [INFO]: Epoch 060 - training loss: 0.2316, validation loss: 0.0271
2024-05-24 21:29:12 [INFO]: Epoch 061 - training loss: 0.2233, validation loss: 0.0297
2024-05-24 21:29:12 [INFO]: Epoch 062 - training loss: 0.2228, validation loss: 0.0279
2024-05-24 21:29:12 [INFO]: Epoch 063 - training loss: 0.2262, validation loss: 0.0272
2024-05-24 21:29:12 [INFO]: Epoch 064 - training loss: 0.2223, validation loss: 0.0327
2024-05-24 21:29:13 [INFO]: Epoch 065 - training loss: 0.2320, validation loss: 0.0297
2024-05-24 21:29:13 [INFO]: Epoch 066 - training loss: 0.2327, validation loss: 0.0287
2024-05-24 21:29:13 [INFO]: Epoch 067 - training loss: 0.2256, validation loss: 0.0271
2024-05-24 21:29:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:29:13 [INFO]: Finished training. The best model is from epoch#57.
2024-05-24 21:29:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/Transformer_ettm1/20240524_T212900/Transformer.pypots
2024-05-24 21:29:13 [INFO]: Transformer on ETTm1: MAE=0.1375, MSE=0.0379
2024-05-24 21:29:13 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Transformer_ettm1/imputation.pkl
2024-05-24 21:29:13 [INFO]: Using the given device: cuda:0
2024-05-24 21:29:13 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/TimesNet_ettm1/20240524_T212913
2024-05-24 21:29:13 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/TimesNet_ettm1/20240524_T212913/tensorboard
2024-05-24 21:29:13 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 21:29:13 [INFO]: Epoch 001 - training loss: 0.1409, validation loss: 0.0576
2024-05-24 21:29:14 [INFO]: Epoch 002 - training loss: 0.0612, validation loss: 0.0354
2024-05-24 21:29:14 [INFO]: Epoch 003 - training loss: 0.0466, validation loss: 0.0372
2024-05-24 21:29:14 [INFO]: Epoch 004 - training loss: 0.0463, validation loss: 0.0308
2024-05-24 21:29:14 [INFO]: Epoch 005 - training loss: 0.0377, validation loss: 0.0274
2024-05-24 21:29:14 [INFO]: Epoch 006 - training loss: 0.0331, validation loss: 0.0254
2024-05-24 21:29:15 [INFO]: Epoch 007 - training loss: 0.0298, validation loss: 0.0239
2024-05-24 21:29:15 [INFO]: Epoch 008 - training loss: 0.0277, validation loss: 0.0224
2024-05-24 21:29:15 [INFO]: Epoch 009 - training loss: 0.0265, validation loss: 0.0226
2024-05-24 21:29:15 [INFO]: Epoch 010 - training loss: 0.0267, validation loss: 0.0222
2024-05-24 21:29:15 [INFO]: Epoch 011 - training loss: 0.0261, validation loss: 0.0219
2024-05-24 21:29:15 [INFO]: Epoch 012 - training loss: 0.0247, validation loss: 0.0228
2024-05-24 21:29:16 [INFO]: Epoch 013 - training loss: 0.0262, validation loss: 0.0226
2024-05-24 21:29:16 [INFO]: Epoch 014 - training loss: 0.0235, validation loss: 0.0211
2024-05-24 21:29:16 [INFO]: Epoch 015 - training loss: 0.0225, validation loss: 0.0216
2024-05-24 21:29:16 [INFO]: Epoch 016 - training loss: 0.0233, validation loss: 0.0213
2024-05-24 21:29:16 [INFO]: Epoch 017 - training loss: 0.0235, validation loss: 0.0211
2024-05-24 21:29:17 [INFO]: Epoch 018 - training loss: 0.0233, validation loss: 0.0220
2024-05-24 21:29:17 [INFO]: Epoch 019 - training loss: 0.0253, validation loss: 0.0216
2024-05-24 21:29:17 [INFO]: Epoch 020 - training loss: 0.0230, validation loss: 0.0217
2024-05-24 21:29:17 [INFO]: Epoch 021 - training loss: 0.0223, validation loss: 0.0240
2024-05-24 21:29:17 [INFO]: Epoch 022 - training loss: 0.0281, validation loss: 0.0250
2024-05-24 21:29:18 [INFO]: Epoch 023 - training loss: 0.0218, validation loss: 0.0232
2024-05-24 21:29:18 [INFO]: Epoch 024 - training loss: 0.0215, validation loss: 0.0226
2024-05-24 21:29:18 [INFO]: Epoch 025 - training loss: 0.0213, validation loss: 0.0222
2024-05-24 21:29:18 [INFO]: Epoch 026 - training loss: 0.0195, validation loss: 0.0215
2024-05-24 21:29:18 [INFO]: Epoch 027 - training loss: 0.0197, validation loss: 0.0217
2024-05-24 21:29:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:29:18 [INFO]: Finished training. The best model is from epoch#17.
2024-05-24 21:29:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/TimesNet_ettm1/20240524_T212913/TimesNet.pypots
2024-05-24 21:29:18 [INFO]: TimesNet on ETTm1: MAE=0.1036, MSE=0.0235
2024-05-24 21:29:18 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/TimesNet_ettm1/imputation.pkl
2024-05-24 21:29:18 [INFO]: Using the given device: cuda:0
2024-05-24 21:29:18 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918
2024-05-24 21:29:18 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/tensorboard
2024-05-24 21:29:18 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 21:29:20 [INFO]: Epoch 001 - training loss: 0.6973, validation loss: 0.4678
2024-05-24 21:29:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch1_loss0.4678352326154709.pypots
2024-05-24 21:29:23 [INFO]: Epoch 002 - training loss: 0.5081, validation loss: 0.3988
2024-05-24 21:29:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch2_loss0.3987617641687393.pypots
2024-05-24 21:29:25 [INFO]: Epoch 003 - training loss: 0.4241, validation loss: 0.3640
2024-05-24 21:29:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch3_loss0.3640179932117462.pypots
2024-05-24 21:29:27 [INFO]: Epoch 004 - training loss: 0.3542, validation loss: 0.3413
2024-05-24 21:29:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch4_loss0.3412531241774559.pypots
2024-05-24 21:29:29 [INFO]: Epoch 005 - training loss: 0.3177, validation loss: 0.3117
2024-05-24 21:29:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch5_loss0.3117015063762665.pypots
2024-05-24 21:29:31 [INFO]: Epoch 006 - training loss: 0.3445, validation loss: 0.2806
2024-05-24 21:29:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch6_loss0.28064167499542236.pypots
2024-05-24 21:29:33 [INFO]: Epoch 007 - training loss: 0.3003, validation loss: 0.2769
2024-05-24 21:29:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch7_loss0.27689238637685776.pypots
2024-05-24 21:29:35 [INFO]: Epoch 008 - training loss: 0.2435, validation loss: 0.2694
2024-05-24 21:29:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch8_loss0.2693650647997856.pypots
2024-05-24 21:29:37 [INFO]: Epoch 009 - training loss: 0.3048, validation loss: 0.2632
2024-05-24 21:29:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch9_loss0.2632021978497505.pypots
2024-05-24 21:29:39 [INFO]: Epoch 010 - training loss: 0.2629, validation loss: 0.2789
2024-05-24 21:29:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch10_loss0.27886220067739487.pypots
2024-05-24 21:29:41 [INFO]: Epoch 011 - training loss: 0.2694, validation loss: 0.2587
2024-05-24 21:29:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch11_loss0.2587326616048813.pypots
2024-05-24 21:29:43 [INFO]: Epoch 012 - training loss: 0.2236, validation loss: 0.2521
2024-05-24 21:29:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch12_loss0.25213633850216866.pypots
2024-05-24 21:29:45 [INFO]: Epoch 013 - training loss: 0.2424, validation loss: 0.2427
2024-05-24 21:29:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch13_loss0.24268946796655655.pypots
2024-05-24 21:29:47 [INFO]: Epoch 014 - training loss: 0.2744, validation loss: 0.2567
2024-05-24 21:29:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch14_loss0.25673454254865646.pypots
2024-05-24 21:29:49 [INFO]: Epoch 015 - training loss: 0.2290, validation loss: 0.2390
2024-05-24 21:29:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch15_loss0.23903264477849007.pypots
2024-05-24 21:29:51 [INFO]: Epoch 016 - training loss: 0.2112, validation loss: 0.2233
2024-05-24 21:29:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch16_loss0.22326524928212166.pypots
2024-05-24 21:29:53 [INFO]: Epoch 017 - training loss: 0.2127, validation loss: 0.2174
2024-05-24 21:29:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch17_loss0.21735308319330215.pypots
2024-05-24 21:29:55 [INFO]: Epoch 018 - training loss: 0.2203, validation loss: 0.2177
2024-05-24 21:29:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch18_loss0.21765729039907455.pypots
2024-05-24 21:29:57 [INFO]: Epoch 019 - training loss: 0.2000, validation loss: 0.2123
2024-05-24 21:29:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch19_loss0.21226897463202477.pypots
2024-05-24 21:29:59 [INFO]: Epoch 020 - training loss: 0.2030, validation loss: 0.2160
2024-05-24 21:29:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch20_loss0.2159985676407814.pypots
2024-05-24 21:30:01 [INFO]: Epoch 021 - training loss: 0.1909, validation loss: 0.2016
2024-05-24 21:30:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch21_loss0.20158321782946587.pypots
2024-05-24 21:30:03 [INFO]: Epoch 022 - training loss: 0.1905, validation loss: 0.2047
2024-05-24 21:30:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch22_loss0.2046685516834259.pypots
2024-05-24 21:30:05 [INFO]: Epoch 023 - training loss: 0.1938, validation loss: 0.2070
2024-05-24 21:30:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch23_loss0.20703885331749916.pypots
2024-05-24 21:30:07 [INFO]: Epoch 024 - training loss: 0.2299, validation loss: 0.2200
2024-05-24 21:30:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch24_loss0.21999745443463326.pypots
2024-05-24 21:30:09 [INFO]: Epoch 025 - training loss: 0.2055, validation loss: 0.1955
2024-05-24 21:30:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch25_loss0.19551963731646538.pypots
2024-05-24 21:30:12 [INFO]: Epoch 026 - training loss: 0.2214, validation loss: 0.2048
2024-05-24 21:30:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch26_loss0.20483215153217316.pypots
2024-05-24 21:30:14 [INFO]: Epoch 027 - training loss: 0.2114, validation loss: 0.1986
2024-05-24 21:30:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch27_loss0.19855335354804993.pypots
2024-05-24 21:30:16 [INFO]: Epoch 028 - training loss: 0.2560, validation loss: 0.1929
2024-05-24 21:30:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch28_loss0.1928759589791298.pypots
2024-05-24 21:30:18 [INFO]: Epoch 029 - training loss: 0.1872, validation loss: 0.2012
2024-05-24 21:30:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch29_loss0.20121635124087334.pypots
2024-05-24 21:30:20 [INFO]: Epoch 030 - training loss: 0.1982, validation loss: 0.2013
2024-05-24 21:30:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch30_loss0.20127447322010994.pypots
2024-05-24 21:30:22 [INFO]: Epoch 031 - training loss: 0.1951, validation loss: 0.1813
2024-05-24 21:30:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch31_loss0.18129923194646835.pypots
2024-05-24 21:30:24 [INFO]: Epoch 032 - training loss: 0.1938, validation loss: 0.1963
2024-05-24 21:30:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch32_loss0.19627447426319122.pypots
2024-05-24 21:30:26 [INFO]: Epoch 033 - training loss: 0.2023, validation loss: 0.2058
2024-05-24 21:30:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch33_loss0.20576165616512299.pypots
2024-05-24 21:30:28 [INFO]: Epoch 034 - training loss: 0.1961, validation loss: 0.1973
2024-05-24 21:30:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch34_loss0.1972656548023224.pypots
2024-05-24 21:30:30 [INFO]: Epoch 035 - training loss: 0.2612, validation loss: 0.1943
2024-05-24 21:30:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch35_loss0.19432835653424263.pypots
2024-05-24 21:30:32 [INFO]: Epoch 036 - training loss: 0.2729, validation loss: 0.2072
2024-05-24 21:30:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch36_loss0.20721717551350594.pypots
2024-05-24 21:30:34 [INFO]: Epoch 037 - training loss: 0.2322, validation loss: 0.2025
2024-05-24 21:30:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch37_loss0.20249128341674805.pypots
2024-05-24 21:30:36 [INFO]: Epoch 038 - training loss: 0.2507, validation loss: 0.1971
2024-05-24 21:30:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch38_loss0.19706709682941437.pypots
2024-05-24 21:30:38 [INFO]: Epoch 039 - training loss: 0.2082, validation loss: 0.1941
2024-05-24 21:30:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch39_loss0.19408510252833366.pypots
2024-05-24 21:30:40 [INFO]: Epoch 040 - training loss: 0.1732, validation loss: 0.1788
2024-05-24 21:30:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch40_loss0.17877700552344322.pypots
2024-05-24 21:30:42 [INFO]: Epoch 041 - training loss: 0.1836, validation loss: 0.1762
2024-05-24 21:30:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch41_loss0.17622479796409607.pypots
2024-05-24 21:30:44 [INFO]: Epoch 042 - training loss: 0.1683, validation loss: 0.1674
2024-05-24 21:30:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch42_loss0.1674301140010357.pypots
2024-05-24 21:30:46 [INFO]: Epoch 043 - training loss: 0.1640, validation loss: 0.1668
2024-05-24 21:30:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch43_loss0.1667940653860569.pypots
2024-05-24 21:30:48 [INFO]: Epoch 044 - training loss: 0.1885, validation loss: 0.1847
2024-05-24 21:30:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch44_loss0.18472319096326828.pypots
2024-05-24 21:30:50 [INFO]: Epoch 045 - training loss: 0.2121, validation loss: 0.1946
2024-05-24 21:30:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch45_loss0.19464627280831337.pypots
2024-05-24 21:30:52 [INFO]: Epoch 046 - training loss: 0.2004, validation loss: 0.1692
2024-05-24 21:30:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch46_loss0.16920758038759232.pypots
2024-05-24 21:30:54 [INFO]: Epoch 047 - training loss: 0.1719, validation loss: 0.1658
2024-05-24 21:30:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch47_loss0.16582241281867027.pypots
2024-05-24 21:30:56 [INFO]: Epoch 048 - training loss: 0.1696, validation loss: 0.1719
2024-05-24 21:30:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch48_loss0.1719457060098648.pypots
2024-05-24 21:30:58 [INFO]: Epoch 049 - training loss: 0.1646, validation loss: 0.1618
2024-05-24 21:30:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch49_loss0.16177745535969734.pypots
2024-05-24 21:31:01 [INFO]: Epoch 050 - training loss: 0.1633, validation loss: 0.1596
2024-05-24 21:31:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch50_loss0.15959831327199936.pypots
2024-05-24 21:31:03 [INFO]: Epoch 051 - training loss: 0.1479, validation loss: 0.1571
2024-05-24 21:31:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch51_loss0.157063327729702.pypots
2024-05-24 21:31:05 [INFO]: Epoch 052 - training loss: 0.1523, validation loss: 0.1553
2024-05-24 21:31:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch52_loss0.15529713034629822.pypots
2024-05-24 21:31:07 [INFO]: Epoch 053 - training loss: 0.1648, validation loss: 0.1658
2024-05-24 21:31:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch53_loss0.165790643543005.pypots
2024-05-24 21:31:09 [INFO]: Epoch 054 - training loss: 0.2394, validation loss: 0.1981
2024-05-24 21:31:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch54_loss0.19812020659446716.pypots
2024-05-24 21:31:11 [INFO]: Epoch 055 - training loss: 0.2023, validation loss: 0.1898
2024-05-24 21:31:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch55_loss0.18977655842900276.pypots
2024-05-24 21:31:13 [INFO]: Epoch 056 - training loss: 0.2034, validation loss: 0.1749
2024-05-24 21:31:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch56_loss0.17491032183170319.pypots
2024-05-24 21:31:15 [INFO]: Epoch 057 - training loss: 0.1747, validation loss: 0.1757
2024-05-24 21:31:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch57_loss0.17568688839673996.pypots
2024-05-24 21:31:17 [INFO]: Epoch 058 - training loss: 0.1951, validation loss: 0.1607
2024-05-24 21:31:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch58_loss0.16069871559739113.pypots
2024-05-24 21:31:19 [INFO]: Epoch 059 - training loss: 0.1724, validation loss: 0.1596
2024-05-24 21:31:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch59_loss0.15955161675810814.pypots
2024-05-24 21:31:21 [INFO]: Epoch 060 - training loss: 0.1834, validation loss: 0.1595
2024-05-24 21:31:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch60_loss0.15952225029468536.pypots
2024-05-24 21:31:23 [INFO]: Epoch 061 - training loss: 0.1726, validation loss: 0.1718
2024-05-24 21:31:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch61_loss0.17176787927746773.pypots
2024-05-24 21:31:25 [INFO]: Epoch 062 - training loss: 0.1947, validation loss: 0.1696
2024-05-24 21:31:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI_epoch62_loss0.1696324273943901.pypots
2024-05-24 21:31:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:31:25 [INFO]: Finished training. The best model is from epoch#52.
2024-05-24 21:31:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T212918/CSDI.pypots
2024-05-24 21:31:41 [INFO]: CSDI on ETTm1: MAE=0.1623, MSE=0.0594
2024-05-24 21:31:41 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/CSDI_ettm1/imputation.pkl
2024-05-24 21:31:41 [INFO]: Using the given device: cuda:0
2024-05-24 21:31:41 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/GPVAE_ettm1/20240524_T213141
2024-05-24 21:31:41 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/GPVAE_ettm1/20240524_T213141/tensorboard
2024-05-24 21:31:41 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 21:31:41 [INFO]: Epoch 001 - training loss: 24863.7816, validation loss: 1.0189
2024-05-24 21:31:41 [INFO]: Epoch 002 - training loss: 22570.5947, validation loss: 1.0051
2024-05-24 21:31:41 [INFO]: Epoch 003 - training loss: 20562.1571, validation loss: 0.9932
2024-05-24 21:31:41 [INFO]: Epoch 004 - training loss: 18507.0858, validation loss: 0.9692
2024-05-24 21:31:42 [INFO]: Epoch 005 - training loss: 16398.2723, validation loss: 0.8984
2024-05-24 21:31:42 [INFO]: Epoch 006 - training loss: 14627.6930, validation loss: 0.7657
2024-05-24 21:31:42 [INFO]: Epoch 007 - training loss: 13346.7555, validation loss: 0.6547
2024-05-24 21:31:42 [INFO]: Epoch 008 - training loss: 12301.9800, validation loss: 0.6169
2024-05-24 21:31:42 [INFO]: Epoch 009 - training loss: 11624.8631, validation loss: 0.5513
2024-05-24 21:31:42 [INFO]: Epoch 010 - training loss: 11179.6992, validation loss: 0.5032
2024-05-24 21:31:42 [INFO]: Epoch 011 - training loss: 10807.0734, validation loss: 0.4853
2024-05-24 21:31:43 [INFO]: Epoch 012 - training loss: 10680.3227, validation loss: 0.4765
2024-05-24 21:31:43 [INFO]: Epoch 013 - training loss: 10484.0181, validation loss: 0.4674
2024-05-24 21:31:43 [INFO]: Epoch 014 - training loss: 10258.6758, validation loss: 0.4523
2024-05-24 21:31:43 [INFO]: Epoch 015 - training loss: 10117.9779, validation loss: 0.4342
2024-05-24 21:31:43 [INFO]: Epoch 016 - training loss: 10118.3493, validation loss: 0.4171
2024-05-24 21:31:43 [INFO]: Epoch 017 - training loss: 10019.4939, validation loss: 0.3900
2024-05-24 21:31:43 [INFO]: Epoch 018 - training loss: 9879.2319, validation loss: 0.3688
2024-05-24 21:31:43 [INFO]: Epoch 019 - training loss: 9830.2382, validation loss: 0.3513
2024-05-24 21:31:44 [INFO]: Epoch 020 - training loss: 9752.6147, validation loss: 0.3308
2024-05-24 21:31:44 [INFO]: Epoch 021 - training loss: 9705.3004, validation loss: 0.3129
2024-05-24 21:31:44 [INFO]: Epoch 022 - training loss: 9683.4788, validation loss: 0.2985
2024-05-24 21:31:44 [INFO]: Epoch 023 - training loss: 9666.4124, validation loss: 0.2878
2024-05-24 21:31:44 [INFO]: Epoch 024 - training loss: 9625.6121, validation loss: 0.2746
2024-05-24 21:31:44 [INFO]: Epoch 025 - training loss: 9634.4307, validation loss: 0.2662
2024-05-24 21:31:44 [INFO]: Epoch 026 - training loss: 9567.8206, validation loss: 0.2604
2024-05-24 21:31:45 [INFO]: Epoch 027 - training loss: 9548.3018, validation loss: 0.2541
2024-05-24 21:31:45 [INFO]: Epoch 028 - training loss: 9547.7514, validation loss: 0.2435
2024-05-24 21:31:45 [INFO]: Epoch 029 - training loss: 9525.0820, validation loss: 0.2373
2024-05-24 21:31:45 [INFO]: Epoch 030 - training loss: 9506.7520, validation loss: 0.2323
2024-05-24 21:31:45 [INFO]: Epoch 031 - training loss: 9487.6178, validation loss: 0.2284
2024-05-24 21:31:45 [INFO]: Epoch 032 - training loss: 9477.6163, validation loss: 0.2227
2024-05-24 21:31:45 [INFO]: Epoch 033 - training loss: 9480.6837, validation loss: 0.2187
2024-05-24 21:31:45 [INFO]: Epoch 034 - training loss: 9477.9120, validation loss: 0.2147
2024-05-24 21:31:46 [INFO]: Epoch 035 - training loss: 9461.2233, validation loss: 0.2088
2024-05-24 21:31:46 [INFO]: Epoch 036 - training loss: 9443.6525, validation loss: 0.2057
2024-05-24 21:31:46 [INFO]: Epoch 037 - training loss: 9437.3097, validation loss: 0.2010
2024-05-24 21:31:46 [INFO]: Epoch 038 - training loss: 9430.0262, validation loss: 0.2002
2024-05-24 21:31:46 [INFO]: Epoch 039 - training loss: 9426.1902, validation loss: 0.1930
2024-05-24 21:31:46 [INFO]: Epoch 040 - training loss: 9423.9349, validation loss: 0.1912
2024-05-24 21:31:46 [INFO]: Epoch 041 - training loss: 9416.0789, validation loss: 0.1846
2024-05-24 21:31:47 [INFO]: Epoch 042 - training loss: 9415.7571, validation loss: 0.1795
2024-05-24 21:31:47 [INFO]: Epoch 043 - training loss: 9407.0283, validation loss: 0.1758
2024-05-24 21:31:47 [INFO]: Epoch 044 - training loss: 9408.2270, validation loss: 0.1696
2024-05-24 21:31:47 [INFO]: Epoch 045 - training loss: 9395.9713, validation loss: 0.1683
2024-05-24 21:31:47 [INFO]: Epoch 046 - training loss: 9400.3892, validation loss: 0.1646
2024-05-24 21:31:47 [INFO]: Epoch 047 - training loss: 9393.6074, validation loss: 0.1582
2024-05-24 21:31:47 [INFO]: Epoch 048 - training loss: 9387.5938, validation loss: 0.1551
2024-05-24 21:31:47 [INFO]: Epoch 049 - training loss: 9384.5966, validation loss: 0.1505
2024-05-24 21:31:48 [INFO]: Epoch 050 - training loss: 9383.6407, validation loss: 0.1502
2024-05-24 21:31:48 [INFO]: Epoch 051 - training loss: 9378.7189, validation loss: 0.1468
2024-05-24 21:31:48 [INFO]: Epoch 052 - training loss: 9374.4357, validation loss: 0.1436
2024-05-24 21:31:48 [INFO]: Epoch 053 - training loss: 9376.7454, validation loss: 0.1417
2024-05-24 21:31:48 [INFO]: Epoch 054 - training loss: 9370.1795, validation loss: 0.1396
2024-05-24 21:31:48 [INFO]: Epoch 055 - training loss: 9368.1581, validation loss: 0.1374
2024-05-24 21:31:48 [INFO]: Epoch 056 - training loss: 9363.2039, validation loss: 0.1344
2024-05-24 21:31:49 [INFO]: Epoch 057 - training loss: 9364.3704, validation loss: 0.1342
2024-05-24 21:31:49 [INFO]: Epoch 058 - training loss: 9361.5626, validation loss: 0.1307
2024-05-24 21:31:49 [INFO]: Epoch 059 - training loss: 9365.9449, validation loss: 0.1311
2024-05-24 21:31:49 [INFO]: Epoch 060 - training loss: 9360.3121, validation loss: 0.1294
2024-05-24 21:31:49 [INFO]: Epoch 061 - training loss: 9355.8665, validation loss: 0.1271
2024-05-24 21:31:49 [INFO]: Epoch 062 - training loss: 9354.2532, validation loss: 0.1273
2024-05-24 21:31:49 [INFO]: Epoch 063 - training loss: 9352.4546, validation loss: 0.1251
2024-05-24 21:31:49 [INFO]: Epoch 064 - training loss: 9349.8707, validation loss: 0.1247
2024-05-24 21:31:50 [INFO]: Epoch 065 - training loss: 9351.0528, validation loss: 0.1222
2024-05-24 21:31:50 [INFO]: Epoch 066 - training loss: 9346.6205, validation loss: 0.1230
2024-05-24 21:31:50 [INFO]: Epoch 067 - training loss: 9346.3018, validation loss: 0.1219
2024-05-24 21:31:50 [INFO]: Epoch 068 - training loss: 9344.9728, validation loss: 0.1203
2024-05-24 21:31:50 [INFO]: Epoch 069 - training loss: 9344.1643, validation loss: 0.1197
2024-05-24 21:31:50 [INFO]: Epoch 070 - training loss: 9343.6736, validation loss: 0.1180
2024-05-24 21:31:50 [INFO]: Epoch 071 - training loss: 9351.8158, validation loss: 0.1195
2024-05-24 21:31:51 [INFO]: Epoch 072 - training loss: 9348.7649, validation loss: 0.1163
2024-05-24 21:31:51 [INFO]: Epoch 073 - training loss: 9344.4016, validation loss: 0.1173
2024-05-24 21:31:51 [INFO]: Epoch 074 - training loss: 9341.2617, validation loss: 0.1163
2024-05-24 21:31:51 [INFO]: Epoch 075 - training loss: 9336.9272, validation loss: 0.1152
2024-05-24 21:31:51 [INFO]: Epoch 076 - training loss: 9336.8079, validation loss: 0.1141
2024-05-24 21:31:51 [INFO]: Epoch 077 - training loss: 9334.6354, validation loss: 0.1125
2024-05-24 21:31:51 [INFO]: Epoch 078 - training loss: 9334.7748, validation loss: 0.1131
2024-05-24 21:31:51 [INFO]: Epoch 079 - training loss: 9339.5759, validation loss: 0.1117
2024-05-24 21:31:52 [INFO]: Epoch 080 - training loss: 9335.3726, validation loss: 0.1113
2024-05-24 21:31:52 [INFO]: Epoch 081 - training loss: 9334.1514, validation loss: 0.1101
2024-05-24 21:31:52 [INFO]: Epoch 082 - training loss: 9332.2830, validation loss: 0.1107
2024-05-24 21:31:52 [INFO]: Epoch 083 - training loss: 9331.7631, validation loss: 0.1084
2024-05-24 21:31:52 [INFO]: Epoch 084 - training loss: 9331.2715, validation loss: 0.1085
2024-05-24 21:31:52 [INFO]: Epoch 085 - training loss: 9329.3047, validation loss: 0.1088
2024-05-24 21:31:52 [INFO]: Epoch 086 - training loss: 9329.9371, validation loss: 0.1080
2024-05-24 21:31:52 [INFO]: Epoch 087 - training loss: 9328.7457, validation loss: 0.1056
2024-05-24 21:31:53 [INFO]: Epoch 088 - training loss: 9329.9406, validation loss: 0.1071
2024-05-24 21:31:53 [INFO]: Epoch 089 - training loss: 9326.8541, validation loss: 0.1048
2024-05-24 21:31:53 [INFO]: Epoch 090 - training loss: 9327.3925, validation loss: 0.1056
2024-05-24 21:31:53 [INFO]: Epoch 091 - training loss: 9326.8289, validation loss: 0.1037
2024-05-24 21:31:53 [INFO]: Epoch 092 - training loss: 9326.5612, validation loss: 0.1025
2024-05-24 21:31:53 [INFO]: Epoch 093 - training loss: 9326.1566, validation loss: 0.1024
2024-05-24 21:31:53 [INFO]: Epoch 094 - training loss: 9324.3475, validation loss: 0.1022
2024-05-24 21:31:54 [INFO]: Epoch 095 - training loss: 9324.8753, validation loss: 0.1025
2024-05-24 21:31:54 [INFO]: Epoch 096 - training loss: 9325.9878, validation loss: 0.1018
2024-05-24 21:31:54 [INFO]: Epoch 097 - training loss: 9324.7271, validation loss: 0.1013
2024-05-24 21:31:54 [INFO]: Epoch 098 - training loss: 9322.9047, validation loss: 0.1014
2024-05-24 21:31:54 [INFO]: Epoch 099 - training loss: 9323.2656, validation loss: 0.0996
2024-05-24 21:31:54 [INFO]: Epoch 100 - training loss: 9322.4600, validation loss: 0.0991
2024-05-24 21:31:54 [INFO]: Epoch 101 - training loss: 9329.3128, validation loss: 0.0999
2024-05-24 21:31:54 [INFO]: Epoch 102 - training loss: 9321.9485, validation loss: 0.0990
2024-05-24 21:31:55 [INFO]: Epoch 103 - training loss: 9321.3680, validation loss: 0.0967
2024-05-24 21:31:55 [INFO]: Epoch 104 - training loss: 9320.9680, validation loss: 0.0985
2024-05-24 21:31:55 [INFO]: Epoch 105 - training loss: 9320.4258, validation loss: 0.0964
2024-05-24 21:31:55 [INFO]: Epoch 106 - training loss: 9320.8629, validation loss: 0.0973
2024-05-24 21:31:55 [INFO]: Epoch 107 - training loss: 9320.4869, validation loss: 0.0962
2024-05-24 21:31:55 [INFO]: Epoch 108 - training loss: 9320.0489, validation loss: 0.0944
2024-05-24 21:31:55 [INFO]: Epoch 109 - training loss: 9318.7493, validation loss: 0.0947
2024-05-24 21:31:56 [INFO]: Epoch 110 - training loss: 9318.8778, validation loss: 0.0935
2024-05-24 21:31:56 [INFO]: Epoch 111 - training loss: 9319.2883, validation loss: 0.0937
2024-05-24 21:31:56 [INFO]: Epoch 112 - training loss: 9317.5002, validation loss: 0.0939
2024-05-24 21:31:56 [INFO]: Epoch 113 - training loss: 9316.9475, validation loss: 0.0936
2024-05-24 21:31:56 [INFO]: Epoch 114 - training loss: 9318.1140, validation loss: 0.0925
2024-05-24 21:31:56 [INFO]: Epoch 115 - training loss: 9317.7663, validation loss: 0.0922
2024-05-24 21:31:56 [INFO]: Epoch 116 - training loss: 9317.4684, validation loss: 0.0927
2024-05-24 21:31:56 [INFO]: Epoch 117 - training loss: 9318.5025, validation loss: 0.0907
2024-05-24 21:31:57 [INFO]: Epoch 118 - training loss: 9317.6049, validation loss: 0.0902
2024-05-24 21:31:57 [INFO]: Epoch 119 - training loss: 9316.6102, validation loss: 0.0906
2024-05-24 21:31:57 [INFO]: Epoch 120 - training loss: 9316.3711, validation loss: 0.0916
2024-05-24 21:31:57 [INFO]: Epoch 121 - training loss: 9314.8982, validation loss: 0.0911
2024-05-24 21:31:57 [INFO]: Epoch 122 - training loss: 9315.3170, validation loss: 0.0907
2024-05-24 21:31:57 [INFO]: Epoch 123 - training loss: 9316.8162, validation loss: 0.0900
2024-05-24 21:31:57 [INFO]: Epoch 124 - training loss: 9313.5267, validation loss: 0.0898
2024-05-24 21:31:58 [INFO]: Epoch 125 - training loss: 9314.4011, validation loss: 0.0881
2024-05-24 21:31:58 [INFO]: Epoch 126 - training loss: 9318.6656, validation loss: 0.0874
2024-05-24 21:31:58 [INFO]: Epoch 127 - training loss: 9314.9164, validation loss: 0.0875
2024-05-24 21:31:58 [INFO]: Epoch 128 - training loss: 9314.0298, validation loss: 0.0874
2024-05-24 21:31:58 [INFO]: Epoch 129 - training loss: 9315.0372, validation loss: 0.0874
2024-05-24 21:31:58 [INFO]: Epoch 130 - training loss: 9313.7245, validation loss: 0.0879
2024-05-24 21:31:58 [INFO]: Epoch 131 - training loss: 9314.2556, validation loss: 0.0873
2024-05-24 21:31:58 [INFO]: Epoch 132 - training loss: 9313.4548, validation loss: 0.0860
2024-05-24 21:31:59 [INFO]: Epoch 133 - training loss: 9313.1637, validation loss: 0.0858
2024-05-24 21:31:59 [INFO]: Epoch 134 - training loss: 9313.9385, validation loss: 0.0850
2024-05-24 21:31:59 [INFO]: Epoch 135 - training loss: 9311.7176, validation loss: 0.0872
2024-05-24 21:31:59 [INFO]: Epoch 136 - training loss: 9311.7085, validation loss: 0.0848
2024-05-24 21:31:59 [INFO]: Epoch 137 - training loss: 9311.8010, validation loss: 0.0869
2024-05-24 21:31:59 [INFO]: Epoch 138 - training loss: 9311.7600, validation loss: 0.0847
2024-05-24 21:31:59 [INFO]: Epoch 139 - training loss: 9310.3468, validation loss: 0.0842
2024-05-24 21:31:59 [INFO]: Epoch 140 - training loss: 9311.6517, validation loss: 0.0849
2024-05-24 21:32:00 [INFO]: Epoch 141 - training loss: 9311.5607, validation loss: 0.0846
2024-05-24 21:32:00 [INFO]: Epoch 142 - training loss: 9311.6177, validation loss: 0.0838
2024-05-24 21:32:00 [INFO]: Epoch 143 - training loss: 9310.1201, validation loss: 0.0839
2024-05-24 21:32:00 [INFO]: Epoch 144 - training loss: 9314.1570, validation loss: 0.0830
2024-05-24 21:32:00 [INFO]: Epoch 145 - training loss: 9310.3480, validation loss: 0.0828
2024-05-24 21:32:00 [INFO]: Epoch 146 - training loss: 9310.1879, validation loss: 0.0820
2024-05-24 21:32:00 [INFO]: Epoch 147 - training loss: 9313.9739, validation loss: 0.0817
2024-05-24 21:32:01 [INFO]: Epoch 148 - training loss: 9310.5152, validation loss: 0.0828
2024-05-24 21:32:01 [INFO]: Epoch 149 - training loss: 9309.5798, validation loss: 0.0824
2024-05-24 21:32:01 [INFO]: Epoch 150 - training loss: 9311.5092, validation loss: 0.0812
2024-05-24 21:32:01 [INFO]: Epoch 151 - training loss: 9309.8347, validation loss: 0.0817
2024-05-24 21:32:01 [INFO]: Epoch 152 - training loss: 9310.2187, validation loss: 0.0840
2024-05-24 21:32:01 [INFO]: Epoch 153 - training loss: 9309.6667, validation loss: 0.0824
2024-05-24 21:32:01 [INFO]: Epoch 154 - training loss: 9310.2007, validation loss: 0.0806
2024-05-24 21:32:01 [INFO]: Epoch 155 - training loss: 9308.2440, validation loss: 0.0802
2024-05-24 21:32:02 [INFO]: Epoch 156 - training loss: 9307.9920, validation loss: 0.0802
2024-05-24 21:32:02 [INFO]: Epoch 157 - training loss: 9308.9593, validation loss: 0.0815
2024-05-24 21:32:02 [INFO]: Epoch 158 - training loss: 9308.9651, validation loss: 0.0807
2024-05-24 21:32:02 [INFO]: Epoch 159 - training loss: 9307.8833, validation loss: 0.0804
2024-05-24 21:32:02 [INFO]: Epoch 160 - training loss: 9308.6058, validation loss: 0.0800
2024-05-24 21:32:02 [INFO]: Epoch 161 - training loss: 9309.6052, validation loss: 0.0807
2024-05-24 21:32:02 [INFO]: Epoch 162 - training loss: 9308.3410, validation loss: 0.0793
2024-05-24 21:32:03 [INFO]: Epoch 163 - training loss: 9309.6103, validation loss: 0.0794
2024-05-24 21:32:03 [INFO]: Epoch 164 - training loss: 9308.4830, validation loss: 0.0821
2024-05-24 21:32:03 [INFO]: Epoch 165 - training loss: 9308.8619, validation loss: 0.0807
2024-05-24 21:32:03 [INFO]: Epoch 166 - training loss: 9307.8324, validation loss: 0.0784
2024-05-24 21:32:03 [INFO]: Epoch 167 - training loss: 9309.5229, validation loss: 0.0802
2024-05-24 21:32:03 [INFO]: Epoch 168 - training loss: 9308.0403, validation loss: 0.0771
2024-05-24 21:32:03 [INFO]: Epoch 169 - training loss: 9307.8088, validation loss: 0.0783
2024-05-24 21:32:03 [INFO]: Epoch 170 - training loss: 9308.2670, validation loss: 0.0785
2024-05-24 21:32:04 [INFO]: Epoch 171 - training loss: 9307.9695, validation loss: 0.0787
2024-05-24 21:32:04 [INFO]: Epoch 172 - training loss: 9306.7856, validation loss: 0.0792
2024-05-24 21:32:04 [INFO]: Epoch 173 - training loss: 9307.5425, validation loss: 0.0786
2024-05-24 21:32:04 [INFO]: Epoch 174 - training loss: 9306.4980, validation loss: 0.0795
2024-05-24 21:32:04 [INFO]: Epoch 175 - training loss: 9307.1687, validation loss: 0.0782
2024-05-24 21:32:04 [INFO]: Epoch 176 - training loss: 9306.5779, validation loss: 0.0772
2024-05-24 21:32:04 [INFO]: Epoch 177 - training loss: 9305.7166, validation loss: 0.0770
2024-05-24 21:32:05 [INFO]: Epoch 178 - training loss: 9305.9669, validation loss: 0.0774
2024-05-24 21:32:05 [INFO]: Epoch 179 - training loss: 9305.9174, validation loss: 0.0778
2024-05-24 21:32:05 [INFO]: Epoch 180 - training loss: 9306.6855, validation loss: 0.0769
2024-05-24 21:32:05 [INFO]: Epoch 181 - training loss: 9308.0834, validation loss: 0.0761
2024-05-24 21:32:05 [INFO]: Epoch 182 - training loss: 9305.3550, validation loss: 0.0764
2024-05-24 21:32:05 [INFO]: Epoch 183 - training loss: 9306.3882, validation loss: 0.0775
2024-05-24 21:32:05 [INFO]: Epoch 184 - training loss: 9305.6021, validation loss: 0.0771
2024-05-24 21:32:05 [INFO]: Epoch 185 - training loss: 9309.2982, validation loss: 0.0779
2024-05-24 21:32:06 [INFO]: Epoch 186 - training loss: 9305.9998, validation loss: 0.0764
2024-05-24 21:32:06 [INFO]: Epoch 187 - training loss: 9305.8701, validation loss: 0.0770
2024-05-24 21:32:06 [INFO]: Epoch 188 - training loss: 9305.6354, validation loss: 0.0766
2024-05-24 21:32:06 [INFO]: Epoch 189 - training loss: 9304.4503, validation loss: 0.0760
2024-05-24 21:32:06 [INFO]: Epoch 190 - training loss: 9306.3020, validation loss: 0.0765
2024-05-24 21:32:06 [INFO]: Epoch 191 - training loss: 9306.3663, validation loss: 0.0767
2024-05-24 21:32:06 [INFO]: Epoch 192 - training loss: 9306.1523, validation loss: 0.0763
2024-05-24 21:32:07 [INFO]: Epoch 193 - training loss: 9306.5836, validation loss: 0.0766
2024-05-24 21:32:07 [INFO]: Epoch 194 - training loss: 9306.7324, validation loss: 0.0757
2024-05-24 21:32:07 [INFO]: Epoch 195 - training loss: 9306.4032, validation loss: 0.0752
2024-05-24 21:32:07 [INFO]: Epoch 196 - training loss: 9315.6011, validation loss: 0.0763
2024-05-24 21:32:07 [INFO]: Epoch 197 - training loss: 9306.1709, validation loss: 0.0772
2024-05-24 21:32:07 [INFO]: Epoch 198 - training loss: 9303.0806, validation loss: 0.0761
2024-05-24 21:32:07 [INFO]: Epoch 199 - training loss: 9305.4800, validation loss: 0.0761
2024-05-24 21:32:07 [INFO]: Epoch 200 - training loss: 9305.5248, validation loss: 0.0764
2024-05-24 21:32:08 [INFO]: Epoch 201 - training loss: 9303.4130, validation loss: 0.0746
2024-05-24 21:32:08 [INFO]: Epoch 202 - training loss: 9304.5649, validation loss: 0.0752
2024-05-24 21:32:08 [INFO]: Epoch 203 - training loss: 9303.7573, validation loss: 0.0770
2024-05-24 21:32:08 [INFO]: Epoch 204 - training loss: 9303.5560, validation loss: 0.0760
2024-05-24 21:32:08 [INFO]: Epoch 205 - training loss: 9303.7630, validation loss: 0.0756
2024-05-24 21:32:08 [INFO]: Epoch 206 - training loss: 9304.0681, validation loss: 0.0750
2024-05-24 21:32:08 [INFO]: Epoch 207 - training loss: 9302.9008, validation loss: 0.0751
2024-05-24 21:32:08 [INFO]: Epoch 208 - training loss: 9305.0753, validation loss: 0.0756
2024-05-24 21:32:09 [INFO]: Epoch 209 - training loss: 9304.2490, validation loss: 0.0771
2024-05-24 21:32:09 [INFO]: Epoch 210 - training loss: 9304.2375, validation loss: 0.0770
2024-05-24 21:32:09 [INFO]: Epoch 211 - training loss: 9302.9458, validation loss: 0.0753
2024-05-24 21:32:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:32:09 [INFO]: Finished training. The best model is from epoch#201.
2024-05-24 21:32:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/GPVAE_ettm1/20240524_T213141/GPVAE.pypots
2024-05-24 21:32:09 [INFO]: GP-VAE on ETTm1: MAE=0.2701, MSE=0.1503
2024-05-24 21:32:09 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/GPVAE_ettm1/imputation.pkl
2024-05-24 21:32:09 [INFO]: Using the given device: cuda:0
2024-05-24 21:32:09 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/USGAN_ettm1/20240524_T213209
2024-05-24 21:32:09 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/USGAN_ettm1/20240524_T213209/tensorboard
2024-05-24 21:32:09 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 21:32:19 [INFO]: Epoch 001 - generator training loss: 0.5958, discriminator training loss: 0.3460, validation loss: 0.3133
2024-05-24 21:32:28 [INFO]: Epoch 002 - generator training loss: 0.0399, discriminator training loss: 0.2099, validation loss: 0.0896
2024-05-24 21:32:37 [INFO]: Epoch 003 - generator training loss: -0.0598, discriminator training loss: 0.1990, validation loss: 0.0557
2024-05-24 21:32:46 [INFO]: Epoch 004 - generator training loss: -0.0840, discriminator training loss: 0.1970, validation loss: 0.0455
2024-05-24 21:32:55 [INFO]: Epoch 005 - generator training loss: -0.0836, discriminator training loss: 0.1898, validation loss: 0.0415
2024-05-24 21:33:04 [INFO]: Epoch 006 - generator training loss: -0.0860, discriminator training loss: 0.1874, validation loss: 0.0390
2024-05-24 21:33:13 [INFO]: Epoch 007 - generator training loss: -0.0769, discriminator training loss: 0.1801, validation loss: 0.0381
2024-05-24 21:33:21 [INFO]: Epoch 008 - generator training loss: -0.0735, discriminator training loss: 0.1738, validation loss: 0.0380
2024-05-24 21:33:30 [INFO]: Epoch 009 - generator training loss: -0.0662, discriminator training loss: 0.1645, validation loss: 0.0362
2024-05-24 21:33:39 [INFO]: Epoch 010 - generator training loss: -0.0574, discriminator training loss: 0.1522, validation loss: 0.0359
2024-05-24 21:33:48 [INFO]: Epoch 011 - generator training loss: -0.0445, discriminator training loss: 0.1381, validation loss: 0.0352
2024-05-24 21:33:56 [INFO]: Epoch 012 - generator training loss: -0.0368, discriminator training loss: 0.1223, validation loss: 0.0340
2024-05-24 21:34:05 [INFO]: Epoch 013 - generator training loss: -0.0289, discriminator training loss: 0.1130, validation loss: 0.0340
2024-05-24 21:34:14 [INFO]: Epoch 014 - generator training loss: -0.0222, discriminator training loss: 0.1042, validation loss: 0.0337
2024-05-24 21:34:23 [INFO]: Epoch 015 - generator training loss: -0.0140, discriminator training loss: 0.0954, validation loss: 0.0333
2024-05-24 21:34:32 [INFO]: Epoch 016 - generator training loss: -0.0161, discriminator training loss: 0.0912, validation loss: 0.0333
2024-05-24 21:34:40 [INFO]: Epoch 017 - generator training loss: -0.0122, discriminator training loss: 0.0859, validation loss: 0.0329
2024-05-24 21:34:49 [INFO]: Epoch 018 - generator training loss: -0.0138, discriminator training loss: 0.0835, validation loss: 0.0321
2024-05-24 21:34:58 [INFO]: Epoch 019 - generator training loss: -0.0135, discriminator training loss: 0.0809, validation loss: 0.0318
2024-05-24 21:35:07 [INFO]: Epoch 020 - generator training loss: -0.0123, discriminator training loss: 0.0807, validation loss: 0.0310
2024-05-24 21:35:16 [INFO]: Epoch 021 - generator training loss: -0.0112, discriminator training loss: 0.0773, validation loss: 0.0306
2024-05-24 21:35:24 [INFO]: Epoch 022 - generator training loss: -0.0078, discriminator training loss: 0.0787, validation loss: 0.0301
2024-05-24 21:35:33 [INFO]: Epoch 023 - generator training loss: -0.0116, discriminator training loss: 0.0765, validation loss: 0.0302
2024-05-24 21:35:42 [INFO]: Epoch 024 - generator training loss: -0.0125, discriminator training loss: 0.0779, validation loss: 0.0296
2024-05-24 21:35:51 [INFO]: Epoch 025 - generator training loss: -0.0105, discriminator training loss: 0.0741, validation loss: 0.0290
2024-05-24 21:36:00 [INFO]: Epoch 026 - generator training loss: -0.0132, discriminator training loss: 0.0743, validation loss: 0.0287
2024-05-24 21:36:09 [INFO]: Epoch 027 - generator training loss: -0.0099, discriminator training loss: 0.0744, validation loss: 0.0284
2024-05-24 21:36:18 [INFO]: Epoch 028 - generator training loss: -0.0129, discriminator training loss: 0.0751, validation loss: 0.0282
2024-05-24 21:36:26 [INFO]: Epoch 029 - generator training loss: -0.0155, discriminator training loss: 0.0732, validation loss: 0.0282
2024-05-24 21:36:35 [INFO]: Epoch 030 - generator training loss: -0.0127, discriminator training loss: 0.0718, validation loss: 0.0275
2024-05-24 21:36:44 [INFO]: Epoch 031 - generator training loss: -0.0106, discriminator training loss: 0.0735, validation loss: 0.0272
2024-05-24 21:36:53 [INFO]: Epoch 032 - generator training loss: -0.0138, discriminator training loss: 0.0707, validation loss: 0.0270
2024-05-24 21:37:01 [INFO]: Epoch 033 - generator training loss: -0.0133, discriminator training loss: 0.0708, validation loss: 0.0270
2024-05-24 21:37:10 [INFO]: Epoch 034 - generator training loss: -0.0125, discriminator training loss: 0.0708, validation loss: 0.0271
2024-05-24 21:37:19 [INFO]: Epoch 035 - generator training loss: -0.0118, discriminator training loss: 0.0722, validation loss: 0.0267
2024-05-24 21:37:28 [INFO]: Epoch 036 - generator training loss: -0.0157, discriminator training loss: 0.0717, validation loss: 0.0268
2024-05-24 21:37:37 [INFO]: Epoch 037 - generator training loss: -0.0133, discriminator training loss: 0.0694, validation loss: 0.0260
2024-05-24 21:37:45 [INFO]: Epoch 038 - generator training loss: -0.0155, discriminator training loss: 0.0704, validation loss: 0.0257
2024-05-24 21:37:54 [INFO]: Epoch 039 - generator training loss: -0.0177, discriminator training loss: 0.0697, validation loss: 0.0251
2024-05-24 21:38:03 [INFO]: Epoch 040 - generator training loss: -0.0196, discriminator training loss: 0.0704, validation loss: 0.0251
2024-05-24 21:38:12 [INFO]: Epoch 041 - generator training loss: -0.0193, discriminator training loss: 0.0705, validation loss: 0.0245
2024-05-24 21:38:21 [INFO]: Epoch 042 - generator training loss: -0.0151, discriminator training loss: 0.0700, validation loss: 0.0243
2024-05-24 21:38:29 [INFO]: Epoch 043 - generator training loss: -0.0167, discriminator training loss: 0.0701, validation loss: 0.0241
2024-05-24 21:38:38 [INFO]: Epoch 044 - generator training loss: -0.0184, discriminator training loss: 0.0705, validation loss: 0.0236
2024-05-24 21:38:47 [INFO]: Epoch 045 - generator training loss: -0.0179, discriminator training loss: 0.0701, validation loss: 0.0235
2024-05-24 21:38:56 [INFO]: Epoch 046 - generator training loss: -0.0217, discriminator training loss: 0.0703, validation loss: 0.0232
2024-05-24 21:39:05 [INFO]: Epoch 047 - generator training loss: -0.0178, discriminator training loss: 0.0695, validation loss: 0.0228
2024-05-24 21:39:14 [INFO]: Epoch 048 - generator training loss: -0.0189, discriminator training loss: 0.0694, validation loss: 0.0232
2024-05-24 21:39:22 [INFO]: Epoch 049 - generator training loss: -0.0184, discriminator training loss: 0.0684, validation loss: 0.0227
2024-05-24 21:39:31 [INFO]: Epoch 050 - generator training loss: -0.0206, discriminator training loss: 0.0690, validation loss: 0.0268
2024-05-24 21:39:40 [INFO]: Epoch 051 - generator training loss: -0.0188, discriminator training loss: 0.0676, validation loss: 0.0246
2024-05-24 21:39:49 [INFO]: Epoch 052 - generator training loss: -0.0162, discriminator training loss: 0.0672, validation loss: 0.0227
2024-05-24 21:39:58 [INFO]: Epoch 053 - generator training loss: -0.0212, discriminator training loss: 0.0694, validation loss: 0.0225
2024-05-24 21:40:06 [INFO]: Epoch 054 - generator training loss: -0.0184, discriminator training loss: 0.0691, validation loss: 0.0227
2024-05-24 21:40:15 [INFO]: Epoch 055 - generator training loss: -0.0210, discriminator training loss: 0.0668, validation loss: 0.0226
2024-05-24 21:40:24 [INFO]: Epoch 056 - generator training loss: -0.0182, discriminator training loss: 0.0670, validation loss: 0.0224
2024-05-24 21:40:33 [INFO]: Epoch 057 - generator training loss: -0.0190, discriminator training loss: 0.0678, validation loss: 0.0224
2024-05-24 21:40:42 [INFO]: Epoch 058 - generator training loss: -0.0205, discriminator training loss: 0.0670, validation loss: 0.0217
2024-05-24 21:40:50 [INFO]: Epoch 059 - generator training loss: -0.0205, discriminator training loss: 0.0658, validation loss: 0.0217
2024-05-24 21:40:59 [INFO]: Epoch 060 - generator training loss: -0.0227, discriminator training loss: 0.0702, validation loss: 0.0223
2024-05-24 21:41:08 [INFO]: Epoch 061 - generator training loss: -0.0217, discriminator training loss: 0.0680, validation loss: 0.0221
2024-05-24 21:41:17 [INFO]: Epoch 062 - generator training loss: -0.0223, discriminator training loss: 0.0672, validation loss: 0.0215
2024-05-24 21:41:25 [INFO]: Epoch 063 - generator training loss: -0.0214, discriminator training loss: 0.0688, validation loss: 0.0236
2024-05-24 21:41:34 [INFO]: Epoch 064 - generator training loss: -0.0223, discriminator training loss: 0.0676, validation loss: 0.0225
2024-05-24 21:41:43 [INFO]: Epoch 065 - generator training loss: -0.0203, discriminator training loss: 0.0675, validation loss: 0.0215
2024-05-24 21:41:52 [INFO]: Epoch 066 - generator training loss: -0.0206, discriminator training loss: 0.0683, validation loss: 0.0217
2024-05-24 21:42:01 [INFO]: Epoch 067 - generator training loss: -0.0200, discriminator training loss: 0.0675, validation loss: 0.0217
2024-05-24 21:42:10 [INFO]: Epoch 068 - generator training loss: -0.0238, discriminator training loss: 0.0678, validation loss: 0.0210
2024-05-24 21:42:18 [INFO]: Epoch 069 - generator training loss: -0.0212, discriminator training loss: 0.0674, validation loss: 0.0207
2024-05-24 21:42:27 [INFO]: Epoch 070 - generator training loss: -0.0210, discriminator training loss: 0.0678, validation loss: 0.0209
2024-05-24 21:42:36 [INFO]: Epoch 071 - generator training loss: -0.0239, discriminator training loss: 0.0658, validation loss: 0.0209
2024-05-24 21:42:45 [INFO]: Epoch 072 - generator training loss: -0.0208, discriminator training loss: 0.0670, validation loss: 0.0206
2024-05-24 21:42:54 [INFO]: Epoch 073 - generator training loss: -0.0204, discriminator training loss: 0.0680, validation loss: 0.0204
2024-05-24 21:43:03 [INFO]: Epoch 074 - generator training loss: -0.0234, discriminator training loss: 0.0658, validation loss: 0.0207
2024-05-24 21:43:11 [INFO]: Epoch 075 - generator training loss: -0.0222, discriminator training loss: 0.0657, validation loss: 0.0203
2024-05-24 21:43:20 [INFO]: Epoch 076 - generator training loss: -0.0238, discriminator training loss: 0.0667, validation loss: 0.0201
2024-05-24 21:43:29 [INFO]: Epoch 077 - generator training loss: -0.0238, discriminator training loss: 0.0668, validation loss: 0.0197
2024-05-24 21:43:38 [INFO]: Epoch 078 - generator training loss: -0.0223, discriminator training loss: 0.0660, validation loss: 0.0200
2024-05-24 21:43:46 [INFO]: Epoch 079 - generator training loss: -0.0250, discriminator training loss: 0.0663, validation loss: 0.0196
2024-05-24 21:43:55 [INFO]: Epoch 080 - generator training loss: -0.0240, discriminator training loss: 0.0678, validation loss: 0.0197
2024-05-24 21:44:04 [INFO]: Epoch 081 - generator training loss: -0.0208, discriminator training loss: 0.0665, validation loss: 0.0199
2024-05-24 21:44:13 [INFO]: Epoch 082 - generator training loss: -0.0242, discriminator training loss: 0.0650, validation loss: 0.0199
2024-05-24 21:44:22 [INFO]: Epoch 083 - generator training loss: -0.0252, discriminator training loss: 0.0668, validation loss: 0.0188
2024-05-24 21:44:30 [INFO]: Epoch 084 - generator training loss: -0.0227, discriminator training loss: 0.0665, validation loss: 0.0192
2024-05-24 21:44:39 [INFO]: Epoch 085 - generator training loss: -0.0237, discriminator training loss: 0.0672, validation loss: 0.0186
2024-05-24 21:44:48 [INFO]: Epoch 086 - generator training loss: -0.0247, discriminator training loss: 0.0675, validation loss: 0.0188
2024-05-24 21:44:57 [INFO]: Epoch 087 - generator training loss: -0.0250, discriminator training loss: 0.0642, validation loss: 0.0195
2024-05-24 21:45:06 [INFO]: Epoch 088 - generator training loss: -0.0248, discriminator training loss: 0.0661, validation loss: 0.0190
2024-05-24 21:45:15 [INFO]: Epoch 089 - generator training loss: -0.0245, discriminator training loss: 0.0650, validation loss: 0.0183
2024-05-24 21:45:23 [INFO]: Epoch 090 - generator training loss: -0.0246, discriminator training loss: 0.0648, validation loss: 0.0183
2024-05-24 21:45:32 [INFO]: Epoch 091 - generator training loss: -0.0251, discriminator training loss: 0.0653, validation loss: 0.0184
2024-05-24 21:45:41 [INFO]: Epoch 092 - generator training loss: -0.0267, discriminator training loss: 0.0671, validation loss: 0.0183
2024-05-24 21:45:50 [INFO]: Epoch 093 - generator training loss: -0.0279, discriminator training loss: 0.0660, validation loss: 0.0182
2024-05-24 21:45:59 [INFO]: Epoch 094 - generator training loss: -0.0250, discriminator training loss: 0.0660, validation loss: 0.0181
2024-05-24 21:46:08 [INFO]: Epoch 095 - generator training loss: -0.0244, discriminator training loss: 0.0658, validation loss: 0.0179
2024-05-24 21:46:16 [INFO]: Epoch 096 - generator training loss: -0.0243, discriminator training loss: 0.0653, validation loss: 0.0181
2024-05-24 21:46:25 [INFO]: Epoch 097 - generator training loss: -0.0256, discriminator training loss: 0.0663, validation loss: 0.0183
2024-05-24 21:46:34 [INFO]: Epoch 098 - generator training loss: -0.0246, discriminator training loss: 0.0655, validation loss: 0.0182
2024-05-24 21:46:43 [INFO]: Epoch 099 - generator training loss: -0.0245, discriminator training loss: 0.0629, validation loss: 0.0179
2024-05-24 21:46:51 [INFO]: Epoch 100 - generator training loss: -0.0278, discriminator training loss: 0.0643, validation loss: 0.0180
2024-05-24 21:47:00 [INFO]: Epoch 101 - generator training loss: -0.0230, discriminator training loss: 0.0651, validation loss: 0.0182
2024-05-24 21:47:09 [INFO]: Epoch 102 - generator training loss: -0.0251, discriminator training loss: 0.0631, validation loss: 0.0190
2024-05-24 21:47:18 [INFO]: Epoch 103 - generator training loss: -0.0274, discriminator training loss: 0.0638, validation loss: 0.0183
2024-05-24 21:47:27 [INFO]: Epoch 104 - generator training loss: -0.0254, discriminator training loss: 0.0647, validation loss: 0.0186
2024-05-24 21:47:35 [INFO]: Epoch 105 - generator training loss: -0.0281, discriminator training loss: 0.0644, validation loss: 0.0177
2024-05-24 21:47:44 [INFO]: Epoch 106 - generator training loss: -0.0252, discriminator training loss: 0.0628, validation loss: 0.0178
2024-05-24 21:47:53 [INFO]: Epoch 107 - generator training loss: -0.0276, discriminator training loss: 0.0666, validation loss: 0.0177
2024-05-24 21:48:02 [INFO]: Epoch 108 - generator training loss: -0.0271, discriminator training loss: 0.0645, validation loss: 0.0175
2024-05-24 21:48:11 [INFO]: Epoch 109 - generator training loss: -0.0274, discriminator training loss: 0.0652, validation loss: 0.0178
2024-05-24 21:48:20 [INFO]: Epoch 110 - generator training loss: -0.0268, discriminator training loss: 0.0662, validation loss: 0.0178
2024-05-24 21:48:28 [INFO]: Epoch 111 - generator training loss: -0.0273, discriminator training loss: 0.0692, validation loss: 0.0178
2024-05-24 21:48:37 [INFO]: Epoch 112 - generator training loss: -0.0261, discriminator training loss: 0.0639, validation loss: 0.0182
2024-05-24 21:48:46 [INFO]: Epoch 113 - generator training loss: -0.0252, discriminator training loss: 0.0655, validation loss: 0.0190
2024-05-24 21:48:55 [INFO]: Epoch 114 - generator training loss: -0.0274, discriminator training loss: 0.0666, validation loss: 0.0174
2024-05-24 21:49:04 [INFO]: Epoch 115 - generator training loss: -0.0267, discriminator training loss: 0.0648, validation loss: 0.0180
2024-05-24 21:49:13 [INFO]: Epoch 116 - generator training loss: -0.0261, discriminator training loss: 0.0652, validation loss: 0.0178
2024-05-24 21:49:21 [INFO]: Epoch 117 - generator training loss: -0.0247, discriminator training loss: 0.0659, validation loss: 0.0179
2024-05-24 21:49:30 [INFO]: Epoch 118 - generator training loss: -0.0265, discriminator training loss: 0.0660, validation loss: 0.0183
2024-05-24 21:49:39 [INFO]: Epoch 119 - generator training loss: -0.0282, discriminator training loss: 0.0653, validation loss: 0.0180
2024-05-24 21:49:48 [INFO]: Epoch 120 - generator training loss: -0.0274, discriminator training loss: 0.0645, validation loss: 0.0180
2024-05-24 21:49:56 [INFO]: Epoch 121 - generator training loss: -0.0249, discriminator training loss: 0.0659, validation loss: 0.0178
2024-05-24 21:50:05 [INFO]: Epoch 122 - generator training loss: -0.0244, discriminator training loss: 0.0660, validation loss: 0.0178
2024-05-24 21:50:14 [INFO]: Epoch 123 - generator training loss: -0.0248, discriminator training loss: 0.0660, validation loss: 0.0187
2024-05-24 21:50:23 [INFO]: Epoch 124 - generator training loss: -0.0255, discriminator training loss: 0.0653, validation loss: 0.0184
2024-05-24 21:50:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:50:23 [INFO]: Finished training. The best model is from epoch#114.
2024-05-24 21:50:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/USGAN_ettm1/20240524_T213209/USGAN.pypots
2024-05-24 21:50:24 [INFO]: US-GAN on ETTm1: MAE=0.1373, MSE=0.0532
2024-05-24 21:50:24 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/USGAN_ettm1/imputation.pkl
2024-05-24 21:50:24 [INFO]: Using the given device: cuda:0
2024-05-24 21:50:24 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/BRITS_ettm1/20240524_T215024
2024-05-24 21:50:24 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/BRITS_ettm1/20240524_T215024/tensorboard
2024-05-24 21:50:24 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 21:50:31 [INFO]: Epoch 001 - training loss: 1.2788, validation loss: 0.2529
2024-05-24 21:50:37 [INFO]: Epoch 002 - training loss: 0.8355, validation loss: 0.0687
2024-05-24 21:50:43 [INFO]: Epoch 003 - training loss: 0.6964, validation loss: 0.0453
2024-05-24 21:50:49 [INFO]: Epoch 004 - training loss: 0.6149, validation loss: 0.0394
2024-05-24 21:50:55 [INFO]: Epoch 005 - training loss: 0.5665, validation loss: 0.0382
2024-05-24 21:51:01 [INFO]: Epoch 006 - training loss: 0.5391, validation loss: 0.0348
2024-05-24 21:51:07 [INFO]: Epoch 007 - training loss: 0.5119, validation loss: 0.0347
2024-05-24 21:51:13 [INFO]: Epoch 008 - training loss: 0.4895, validation loss: 0.0316
2024-05-24 21:51:19 [INFO]: Epoch 009 - training loss: 0.4803, validation loss: 0.0299
2024-05-24 21:51:25 [INFO]: Epoch 010 - training loss: 0.4586, validation loss: 0.0306
2024-05-24 21:51:31 [INFO]: Epoch 011 - training loss: 0.4338, validation loss: 0.0270
2024-05-24 21:51:37 [INFO]: Epoch 012 - training loss: 0.4354, validation loss: 0.0276
2024-05-24 21:51:43 [INFO]: Epoch 013 - training loss: 0.4218, validation loss: 0.0266
2024-05-24 21:51:48 [INFO]: Epoch 014 - training loss: 0.4043, validation loss: 0.0256
2024-05-24 21:51:54 [INFO]: Epoch 015 - training loss: 0.3907, validation loss: 0.0247
2024-05-24 21:52:00 [INFO]: Epoch 016 - training loss: 0.3893, validation loss: 0.0232
2024-05-24 21:52:06 [INFO]: Epoch 017 - training loss: 0.3960, validation loss: 0.0234
2024-05-24 21:52:12 [INFO]: Epoch 018 - training loss: 0.3833, validation loss: 0.0230
2024-05-24 21:52:18 [INFO]: Epoch 019 - training loss: 0.3830, validation loss: 0.0223
2024-05-24 21:52:24 [INFO]: Epoch 020 - training loss: 0.3836, validation loss: 0.0227
2024-05-24 21:52:30 [INFO]: Epoch 021 - training loss: 0.3898, validation loss: 0.0233
2024-05-24 21:52:36 [INFO]: Epoch 022 - training loss: 0.3800, validation loss: 0.0224
2024-05-24 21:52:42 [INFO]: Epoch 023 - training loss: 0.3781, validation loss: 0.0224
2024-05-24 21:52:48 [INFO]: Epoch 024 - training loss: 0.3761, validation loss: 0.0221
2024-05-24 21:52:54 [INFO]: Epoch 025 - training loss: 0.3768, validation loss: 0.0226
2024-05-24 21:53:00 [INFO]: Epoch 026 - training loss: 0.3722, validation loss: 0.0223
2024-05-24 21:53:06 [INFO]: Epoch 027 - training loss: 0.3844, validation loss: 0.0223
2024-05-24 21:53:11 [INFO]: Epoch 028 - training loss: 0.3771, validation loss: 0.0227
2024-05-24 21:53:17 [INFO]: Epoch 029 - training loss: 0.3772, validation loss: 0.0227
2024-05-24 21:53:23 [INFO]: Epoch 030 - training loss: 0.3730, validation loss: 0.0219
2024-05-24 21:53:29 [INFO]: Epoch 031 - training loss: 0.3703, validation loss: 0.0227
2024-05-24 21:53:35 [INFO]: Epoch 032 - training loss: 0.3867, validation loss: 0.0224
2024-05-24 21:53:41 [INFO]: Epoch 033 - training loss: 0.3876, validation loss: 0.0226
2024-05-24 21:53:47 [INFO]: Epoch 034 - training loss: 0.3782, validation loss: 0.0221
2024-05-24 21:53:53 [INFO]: Epoch 035 - training loss: 0.3750, validation loss: 0.0220
2024-05-24 21:53:59 [INFO]: Epoch 036 - training loss: 0.3782, validation loss: 0.0223
2024-05-24 21:54:05 [INFO]: Epoch 037 - training loss: 0.3818, validation loss: 0.0230
2024-05-24 21:54:11 [INFO]: Epoch 038 - training loss: 0.3725, validation loss: 0.0230
2024-05-24 21:54:17 [INFO]: Epoch 039 - training loss: 0.3683, validation loss: 0.0218
2024-05-24 21:54:22 [INFO]: Epoch 040 - training loss: 0.3694, validation loss: 0.0220
2024-05-24 21:54:28 [INFO]: Epoch 041 - training loss: 0.3832, validation loss: 0.0221
2024-05-24 21:54:34 [INFO]: Epoch 042 - training loss: 0.3745, validation loss: 0.0224
2024-05-24 21:54:40 [INFO]: Epoch 043 - training loss: 0.3725, validation loss: 0.0226
2024-05-24 21:54:46 [INFO]: Epoch 044 - training loss: 0.3758, validation loss: 0.0224
2024-05-24 21:54:52 [INFO]: Epoch 045 - training loss: 0.3781, validation loss: 0.0222
2024-05-24 21:54:58 [INFO]: Epoch 046 - training loss: 0.3762, validation loss: 0.0221
2024-05-24 21:55:04 [INFO]: Epoch 047 - training loss: 0.3753, validation loss: 0.0221
2024-05-24 21:55:10 [INFO]: Epoch 048 - training loss: 0.3739, validation loss: 0.0225
2024-05-24 21:55:16 [INFO]: Epoch 049 - training loss: 0.3691, validation loss: 0.0220
2024-05-24 21:55:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:55:16 [INFO]: Finished training. The best model is from epoch#39.
2024-05-24 21:55:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/BRITS_ettm1/20240524_T215024/BRITS.pypots
2024-05-24 21:55:17 [INFO]: BRITS on ETTm1: MAE=0.1295, MSE=0.0501
2024-05-24 21:55:17 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/BRITS_ettm1/imputation.pkl
2024-05-24 21:55:17 [INFO]: Using the given device: cuda:0
2024-05-24 21:55:17 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517
2024-05-24 21:55:17 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/tensorboard
2024-05-24 21:55:17 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 21:55:18 [INFO]: Epoch 001 - training loss: 1.3380, validation loss: 1.3486
2024-05-24 21:55:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch1_loss1.3485773801803589.pypots
2024-05-24 21:55:19 [INFO]: Epoch 002 - training loss: 1.0590, validation loss: 1.2212
2024-05-24 21:55:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch2_loss1.221159741282463.pypots
2024-05-24 21:55:19 [INFO]: Epoch 003 - training loss: 1.0315, validation loss: 1.1165
2024-05-24 21:55:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch3_loss1.1164795905351639.pypots
2024-05-24 21:55:19 [INFO]: Epoch 004 - training loss: 0.9917, validation loss: 1.0749
2024-05-24 21:55:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch4_loss1.0748749077320099.pypots
2024-05-24 21:55:19 [INFO]: Epoch 005 - training loss: 0.9585, validation loss: 1.0672
2024-05-24 21:55:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch5_loss1.0672490298748016.pypots
2024-05-24 21:55:19 [INFO]: Epoch 006 - training loss: 0.9200, validation loss: 1.0573
2024-05-24 21:55:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch6_loss1.0573332905769348.pypots
2024-05-24 21:55:20 [INFO]: Epoch 007 - training loss: 0.9452, validation loss: 1.0541
2024-05-24 21:55:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch7_loss1.054100289940834.pypots
2024-05-24 21:55:20 [INFO]: Epoch 008 - training loss: 0.9447, validation loss: 1.0476
2024-05-24 21:55:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch8_loss1.0475957989692688.pypots
2024-05-24 21:55:20 [INFO]: Epoch 009 - training loss: 0.9148, validation loss: 1.0475
2024-05-24 21:55:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch9_loss1.047545999288559.pypots
2024-05-24 21:55:20 [INFO]: Epoch 010 - training loss: 0.9253, validation loss: 1.0528
2024-05-24 21:55:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch10_loss1.0528135746717453.pypots
2024-05-24 21:55:20 [INFO]: Epoch 011 - training loss: 0.9227, validation loss: 1.0558
2024-05-24 21:55:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch11_loss1.0558327287435532.pypots
2024-05-24 21:55:21 [INFO]: Epoch 012 - training loss: 0.8894, validation loss: 1.0542
2024-05-24 21:55:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch12_loss1.0541928559541702.pypots
2024-05-24 21:55:21 [INFO]: Epoch 013 - training loss: 0.8990, validation loss: 1.0502
2024-05-24 21:55:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch13_loss1.0502028465270996.pypots
2024-05-24 21:55:21 [INFO]: Epoch 014 - training loss: 0.8804, validation loss: 1.0553
2024-05-24 21:55:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch14_loss1.0552816689014435.pypots
2024-05-24 21:55:21 [INFO]: Epoch 015 - training loss: 0.8862, validation loss: 1.0504
2024-05-24 21:55:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch15_loss1.050383985042572.pypots
2024-05-24 21:55:21 [INFO]: Epoch 016 - training loss: 0.8699, validation loss: 1.0505
2024-05-24 21:55:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch16_loss1.0505308508872986.pypots
2024-05-24 21:55:22 [INFO]: Epoch 017 - training loss: 0.8639, validation loss: 1.0481
2024-05-24 21:55:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch17_loss1.0481497049331665.pypots
2024-05-24 21:55:22 [INFO]: Epoch 018 - training loss: 0.8609, validation loss: 1.0451
2024-05-24 21:55:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch18_loss1.0450695902109146.pypots
2024-05-24 21:55:22 [INFO]: Epoch 019 - training loss: 0.8655, validation loss: 1.0457
2024-05-24 21:55:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch19_loss1.0456896275281906.pypots
2024-05-24 21:55:22 [INFO]: Epoch 020 - training loss: 0.8763, validation loss: 1.0426
2024-05-24 21:55:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch20_loss1.0425555408000946.pypots
2024-05-24 21:55:22 [INFO]: Epoch 021 - training loss: 0.8582, validation loss: 1.0336
2024-05-24 21:55:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch21_loss1.0336037427186966.pypots
2024-05-24 21:55:23 [INFO]: Epoch 022 - training loss: 0.8519, validation loss: 1.0272
2024-05-24 21:55:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch22_loss1.0272458493709564.pypots
2024-05-24 21:55:23 [INFO]: Epoch 023 - training loss: 0.8441, validation loss: 1.0229
2024-05-24 21:55:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch23_loss1.0228818655014038.pypots
2024-05-24 21:55:23 [INFO]: Epoch 024 - training loss: 0.8307, validation loss: 1.0203
2024-05-24 21:55:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch24_loss1.0202736407518387.pypots
2024-05-24 21:55:23 [INFO]: Epoch 025 - training loss: 0.8673, validation loss: 1.0195
2024-05-24 21:55:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch25_loss1.0194766968488693.pypots
2024-05-24 21:55:23 [INFO]: Epoch 026 - training loss: 0.8303, validation loss: 1.0179
2024-05-24 21:55:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch26_loss1.0179005712270737.pypots
2024-05-24 21:55:24 [INFO]: Epoch 027 - training loss: 0.8454, validation loss: 1.0108
2024-05-24 21:55:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch27_loss1.0108178704977036.pypots
2024-05-24 21:55:24 [INFO]: Epoch 028 - training loss: 0.8508, validation loss: 1.0084
2024-05-24 21:55:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch28_loss1.0084397792816162.pypots
2024-05-24 21:55:24 [INFO]: Epoch 029 - training loss: 0.8497, validation loss: 1.0085
2024-05-24 21:55:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch29_loss1.0084802061319351.pypots
2024-05-24 21:55:24 [INFO]: Epoch 030 - training loss: 0.8259, validation loss: 1.0037
2024-05-24 21:55:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch30_loss1.003746435046196.pypots
2024-05-24 21:55:24 [INFO]: Epoch 031 - training loss: 0.8321, validation loss: 0.9994
2024-05-24 21:55:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch31_loss0.9993894696235657.pypots
2024-05-24 21:55:25 [INFO]: Epoch 032 - training loss: 0.8259, validation loss: 0.9983
2024-05-24 21:55:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch32_loss0.9982595443725586.pypots
2024-05-24 21:55:25 [INFO]: Epoch 033 - training loss: 0.8388, validation loss: 0.9875
2024-05-24 21:55:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch33_loss0.9875329434871674.pypots
2024-05-24 21:55:25 [INFO]: Epoch 034 - training loss: 0.8261, validation loss: 0.9841
2024-05-24 21:55:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch34_loss0.9840749949216843.pypots
2024-05-24 21:55:25 [INFO]: Epoch 035 - training loss: 0.8072, validation loss: 0.9810
2024-05-24 21:55:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch35_loss0.9810473024845123.pypots
2024-05-24 21:55:25 [INFO]: Epoch 036 - training loss: 0.8237, validation loss: 0.9801
2024-05-24 21:55:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch36_loss0.9801312237977982.pypots
2024-05-24 21:55:25 [INFO]: Epoch 037 - training loss: 0.8200, validation loss: 0.9769
2024-05-24 21:55:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch37_loss0.9769379794597626.pypots
2024-05-24 21:55:26 [INFO]: Epoch 038 - training loss: 0.8329, validation loss: 0.9734
2024-05-24 21:55:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch38_loss0.973411351442337.pypots
2024-05-24 21:55:26 [INFO]: Epoch 039 - training loss: 0.8101, validation loss: 0.9741
2024-05-24 21:55:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch39_loss0.9741493910551071.pypots
2024-05-24 21:55:26 [INFO]: Epoch 040 - training loss: 0.8266, validation loss: 0.9705
2024-05-24 21:55:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch40_loss0.9704779833555222.pypots
2024-05-24 21:55:26 [INFO]: Epoch 041 - training loss: 0.8716, validation loss: 0.9660
2024-05-24 21:55:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch41_loss0.9660001993179321.pypots
2024-05-24 21:55:26 [INFO]: Epoch 042 - training loss: 0.8219, validation loss: 0.9584
2024-05-24 21:55:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch42_loss0.9583695083856583.pypots
2024-05-24 21:55:27 [INFO]: Epoch 043 - training loss: 0.8264, validation loss: 0.9597
2024-05-24 21:55:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch43_loss0.9597259014844894.pypots
2024-05-24 21:55:27 [INFO]: Epoch 044 - training loss: 0.8317, validation loss: 0.9573
2024-05-24 21:55:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch44_loss0.9572717100381851.pypots
2024-05-24 21:55:27 [INFO]: Epoch 045 - training loss: 0.8117, validation loss: 0.9611
2024-05-24 21:55:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch45_loss0.9610718190670013.pypots
2024-05-24 21:55:27 [INFO]: Epoch 046 - training loss: 0.8053, validation loss: 0.9559
2024-05-24 21:55:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch46_loss0.9559063464403152.pypots
2024-05-24 21:55:27 [INFO]: Epoch 047 - training loss: 0.8261, validation loss: 0.9510
2024-05-24 21:55:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch47_loss0.95096355676651.pypots
2024-05-24 21:55:28 [INFO]: Epoch 048 - training loss: 0.8111, validation loss: 0.9504
2024-05-24 21:55:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch48_loss0.9503637403249741.pypots
2024-05-24 21:55:28 [INFO]: Epoch 049 - training loss: 0.8093, validation loss: 0.9505
2024-05-24 21:55:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch49_loss0.9505416303873062.pypots
2024-05-24 21:55:28 [INFO]: Epoch 050 - training loss: 0.7973, validation loss: 0.9460
2024-05-24 21:55:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch50_loss0.9459748864173889.pypots
2024-05-24 21:55:28 [INFO]: Epoch 051 - training loss: 0.8332, validation loss: 0.9464
2024-05-24 21:55:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch51_loss0.946420207619667.pypots
2024-05-24 21:55:28 [INFO]: Epoch 052 - training loss: 0.8282, validation loss: 0.9473
2024-05-24 21:55:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch52_loss0.9473192244768143.pypots
2024-05-24 21:55:29 [INFO]: Epoch 053 - training loss: 0.8320, validation loss: 0.9445
2024-05-24 21:55:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch53_loss0.9444707930088043.pypots
2024-05-24 21:55:29 [INFO]: Epoch 054 - training loss: 0.8125, validation loss: 0.9367
2024-05-24 21:55:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch54_loss0.9367063194513321.pypots
2024-05-24 21:55:29 [INFO]: Epoch 055 - training loss: 0.7993, validation loss: 0.9353
2024-05-24 21:55:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch55_loss0.9352888762950897.pypots
2024-05-24 21:55:29 [INFO]: Epoch 056 - training loss: 0.8071, validation loss: 0.9339
2024-05-24 21:55:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch56_loss0.9339457005262375.pypots
2024-05-24 21:55:29 [INFO]: Epoch 057 - training loss: 0.8132, validation loss: 0.9357
2024-05-24 21:55:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch57_loss0.93574658036232.pypots
2024-05-24 21:55:30 [INFO]: Epoch 058 - training loss: 0.7938, validation loss: 0.9342
2024-05-24 21:55:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch58_loss0.9342367649078369.pypots
2024-05-24 21:55:30 [INFO]: Epoch 059 - training loss: 0.8065, validation loss: 0.9316
2024-05-24 21:55:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch59_loss0.9316010177135468.pypots
2024-05-24 21:55:30 [INFO]: Epoch 060 - training loss: 0.8128, validation loss: 0.9316
2024-05-24 21:55:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch60_loss0.9316438585519791.pypots
2024-05-24 21:55:30 [INFO]: Epoch 061 - training loss: 0.7873, validation loss: 0.9297
2024-05-24 21:55:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch61_loss0.9296996295452118.pypots
2024-05-24 21:55:30 [INFO]: Epoch 062 - training loss: 0.8440, validation loss: 0.9300
2024-05-24 21:55:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch62_loss0.9299585372209549.pypots
2024-05-24 21:55:31 [INFO]: Epoch 063 - training loss: 0.8066, validation loss: 0.9282
2024-05-24 21:55:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch63_loss0.9281617105007172.pypots
2024-05-24 21:55:31 [INFO]: Epoch 064 - training loss: 0.7736, validation loss: 0.9261
2024-05-24 21:55:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch64_loss0.9261458516120911.pypots
2024-05-24 21:55:31 [INFO]: Epoch 065 - training loss: 0.8022, validation loss: 0.9280
2024-05-24 21:55:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch65_loss0.9279546588659286.pypots
2024-05-24 21:55:31 [INFO]: Epoch 066 - training loss: 0.8047, validation loss: 0.9237
2024-05-24 21:55:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch66_loss0.9237111657857895.pypots
2024-05-24 21:55:31 [INFO]: Epoch 067 - training loss: 0.7887, validation loss: 0.9218
2024-05-24 21:55:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch67_loss0.9218144565820694.pypots
2024-05-24 21:55:32 [INFO]: Epoch 068 - training loss: 0.7975, validation loss: 0.9247
2024-05-24 21:55:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch68_loss0.9246832579374313.pypots
2024-05-24 21:55:32 [INFO]: Epoch 069 - training loss: 0.8157, validation loss: 0.9204
2024-05-24 21:55:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch69_loss0.9203580617904663.pypots
2024-05-24 21:55:32 [INFO]: Epoch 070 - training loss: 0.8075, validation loss: 0.9162
2024-05-24 21:55:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch70_loss0.9162152111530304.pypots
2024-05-24 21:55:32 [INFO]: Epoch 071 - training loss: 0.7824, validation loss: 0.9182
2024-05-24 21:55:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch71_loss0.918230339884758.pypots
2024-05-24 21:55:32 [INFO]: Epoch 072 - training loss: 0.8041, validation loss: 0.9190
2024-05-24 21:55:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch72_loss0.9190153628587723.pypots
2024-05-24 21:55:32 [INFO]: Epoch 073 - training loss: 0.8062, validation loss: 0.9167
2024-05-24 21:55:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch73_loss0.9166786819696426.pypots
2024-05-24 21:55:33 [INFO]: Epoch 074 - training loss: 0.7841, validation loss: 0.9158
2024-05-24 21:55:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch74_loss0.9157949090003967.pypots
2024-05-24 21:55:33 [INFO]: Epoch 075 - training loss: 0.7982, validation loss: 0.9161
2024-05-24 21:55:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch75_loss0.9161213040351868.pypots
2024-05-24 21:55:33 [INFO]: Epoch 076 - training loss: 0.8117, validation loss: 0.9125
2024-05-24 21:55:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch76_loss0.9124770909547806.pypots
2024-05-24 21:55:33 [INFO]: Epoch 077 - training loss: 0.7864, validation loss: 0.9123
2024-05-24 21:55:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch77_loss0.9122793525457382.pypots
2024-05-24 21:55:33 [INFO]: Epoch 078 - training loss: 0.7939, validation loss: 0.9102
2024-05-24 21:55:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch78_loss0.9102108329534531.pypots
2024-05-24 21:55:34 [INFO]: Epoch 079 - training loss: 0.7846, validation loss: 0.9100
2024-05-24 21:55:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch79_loss0.909985676407814.pypots
2024-05-24 21:55:34 [INFO]: Epoch 080 - training loss: 0.8005, validation loss: 0.9103
2024-05-24 21:55:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch80_loss0.9103333204984665.pypots
2024-05-24 21:55:34 [INFO]: Epoch 081 - training loss: 0.8075, validation loss: 0.9063
2024-05-24 21:55:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch81_loss0.9063142389059067.pypots
2024-05-24 21:55:34 [INFO]: Epoch 082 - training loss: 0.8108, validation loss: 0.9068
2024-05-24 21:55:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch82_loss0.9068371057510376.pypots
2024-05-24 21:55:34 [INFO]: Epoch 083 - training loss: 0.7774, validation loss: 0.9052
2024-05-24 21:55:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch83_loss0.9051880389451981.pypots
2024-05-24 21:55:35 [INFO]: Epoch 084 - training loss: 0.8303, validation loss: 0.9063
2024-05-24 21:55:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch84_loss0.9063229113817215.pypots
2024-05-24 21:55:35 [INFO]: Epoch 085 - training loss: 0.8131, validation loss: 0.9076
2024-05-24 21:55:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch85_loss0.9075601696968079.pypots
2024-05-24 21:55:35 [INFO]: Epoch 086 - training loss: 0.7794, validation loss: 0.9043
2024-05-24 21:55:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch86_loss0.9043242484331131.pypots
2024-05-24 21:55:35 [INFO]: Epoch 087 - training loss: 0.8362, validation loss: 0.9022
2024-05-24 21:55:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch87_loss0.9021553695201874.pypots
2024-05-24 21:55:35 [INFO]: Epoch 088 - training loss: 0.7687, validation loss: 0.9037
2024-05-24 21:55:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch88_loss0.9036591947078705.pypots
2024-05-24 21:55:36 [INFO]: Epoch 089 - training loss: 0.8034, validation loss: 0.8999
2024-05-24 21:55:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch89_loss0.899907723069191.pypots
2024-05-24 21:55:36 [INFO]: Epoch 090 - training loss: 0.8027, validation loss: 0.8995
2024-05-24 21:55:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch90_loss0.8995181024074554.pypots
2024-05-24 21:55:36 [INFO]: Epoch 091 - training loss: 0.8004, validation loss: 0.8967
2024-05-24 21:55:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch91_loss0.8966789096593857.pypots
2024-05-24 21:55:36 [INFO]: Epoch 092 - training loss: 0.7777, validation loss: 0.9006
2024-05-24 21:55:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch92_loss0.9005719721317291.pypots
2024-05-24 21:55:36 [INFO]: Epoch 093 - training loss: 0.8015, validation loss: 0.8988
2024-05-24 21:55:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch93_loss0.898808017373085.pypots
2024-05-24 21:55:37 [INFO]: Epoch 094 - training loss: 0.7814, validation loss: 0.9011
2024-05-24 21:55:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch94_loss0.9010727256536484.pypots
2024-05-24 21:55:37 [INFO]: Epoch 095 - training loss: 0.8031, validation loss: 0.8946
2024-05-24 21:55:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch95_loss0.8946066200733185.pypots
2024-05-24 21:55:37 [INFO]: Epoch 096 - training loss: 0.7740, validation loss: 0.8951
2024-05-24 21:55:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch96_loss0.8951093107461929.pypots
2024-05-24 21:55:37 [INFO]: Epoch 097 - training loss: 0.8132, validation loss: 0.8959
2024-05-24 21:55:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch97_loss0.8958866894245148.pypots
2024-05-24 21:55:37 [INFO]: Epoch 098 - training loss: 0.7881, validation loss: 0.8930
2024-05-24 21:55:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch98_loss0.8929773569107056.pypots
2024-05-24 21:55:38 [INFO]: Epoch 099 - training loss: 0.7863, validation loss: 0.8958
2024-05-24 21:55:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch99_loss0.895756870508194.pypots
2024-05-24 21:55:38 [INFO]: Epoch 100 - training loss: 0.7897, validation loss: 0.8902
2024-05-24 21:55:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch100_loss0.8902314901351929.pypots
2024-05-24 21:55:38 [INFO]: Epoch 101 - training loss: 0.7833, validation loss: 0.8896
2024-05-24 21:55:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch101_loss0.8896070420742035.pypots
2024-05-24 21:55:38 [INFO]: Epoch 102 - training loss: 0.8260, validation loss: 0.8911
2024-05-24 21:55:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch102_loss0.891121968626976.pypots
2024-05-24 21:55:38 [INFO]: Epoch 103 - training loss: 0.8053, validation loss: 0.8907
2024-05-24 21:55:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch103_loss0.8907304853200912.pypots
2024-05-24 21:55:39 [INFO]: Epoch 104 - training loss: 0.7983, validation loss: 0.8866
2024-05-24 21:55:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch104_loss0.8865824043750763.pypots
2024-05-24 21:55:39 [INFO]: Epoch 105 - training loss: 0.7993, validation loss: 0.8853
2024-05-24 21:55:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch105_loss0.8852911591529846.pypots
2024-05-24 21:55:39 [INFO]: Epoch 106 - training loss: 0.8232, validation loss: 0.8868
2024-05-24 21:55:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch106_loss0.8868266493082047.pypots
2024-05-24 21:55:39 [INFO]: Epoch 107 - training loss: 0.7869, validation loss: 0.8861
2024-05-24 21:55:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch107_loss0.8861207962036133.pypots
2024-05-24 21:55:39 [INFO]: Epoch 108 - training loss: 0.7809, validation loss: 0.8861
2024-05-24 21:55:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch108_loss0.8861352354288101.pypots
2024-05-24 21:55:39 [INFO]: Epoch 109 - training loss: 0.8091, validation loss: 0.8843
2024-05-24 21:55:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch109_loss0.8843126446008682.pypots
2024-05-24 21:55:40 [INFO]: Epoch 110 - training loss: 0.7910, validation loss: 0.8855
2024-05-24 21:55:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch110_loss0.8855246752500534.pypots
2024-05-24 21:55:40 [INFO]: Epoch 111 - training loss: 0.8312, validation loss: 0.8839
2024-05-24 21:55:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch111_loss0.883851483464241.pypots
2024-05-24 21:55:40 [INFO]: Epoch 112 - training loss: 0.8010, validation loss: 0.8816
2024-05-24 21:55:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch112_loss0.8816244602203369.pypots
2024-05-24 21:55:40 [INFO]: Epoch 113 - training loss: 0.7940, validation loss: 0.8807
2024-05-24 21:55:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch113_loss0.8806772083044052.pypots
2024-05-24 21:55:40 [INFO]: Epoch 114 - training loss: 0.7920, validation loss: 0.8784
2024-05-24 21:55:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch114_loss0.878449559211731.pypots
2024-05-24 21:55:41 [INFO]: Epoch 115 - training loss: 0.7764, validation loss: 0.8798
2024-05-24 21:55:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch115_loss0.8797647655010223.pypots
2024-05-24 21:55:41 [INFO]: Epoch 116 - training loss: 0.7732, validation loss: 0.8830
2024-05-24 21:55:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch116_loss0.8829842209815979.pypots
2024-05-24 21:55:41 [INFO]: Epoch 117 - training loss: 0.7823, validation loss: 0.8811
2024-05-24 21:55:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch117_loss0.8811254054307938.pypots
2024-05-24 21:55:41 [INFO]: Epoch 118 - training loss: 0.8043, validation loss: 0.8798
2024-05-24 21:55:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch118_loss0.8797720968723297.pypots
2024-05-24 21:55:41 [INFO]: Epoch 119 - training loss: 0.8005, validation loss: 0.8786
2024-05-24 21:55:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch119_loss0.8786122351884842.pypots
2024-05-24 21:55:42 [INFO]: Epoch 120 - training loss: 0.8021, validation loss: 0.8796
2024-05-24 21:55:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch120_loss0.8796291202306747.pypots
2024-05-24 21:55:42 [INFO]: Epoch 121 - training loss: 0.8105, validation loss: 0.8781
2024-05-24 21:55:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch121_loss0.8781226426362991.pypots
2024-05-24 21:55:42 [INFO]: Epoch 122 - training loss: 0.7694, validation loss: 0.8800
2024-05-24 21:55:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch122_loss0.8799635320901871.pypots
2024-05-24 21:55:42 [INFO]: Epoch 123 - training loss: 0.8278, validation loss: 0.8754
2024-05-24 21:55:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch123_loss0.8754011392593384.pypots
2024-05-24 21:55:42 [INFO]: Epoch 124 - training loss: 0.7816, validation loss: 0.8733
2024-05-24 21:55:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch124_loss0.8732805550098419.pypots
2024-05-24 21:55:43 [INFO]: Epoch 125 - training loss: 0.7675, validation loss: 0.8804
2024-05-24 21:55:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch125_loss0.8804369568824768.pypots
2024-05-24 21:55:43 [INFO]: Epoch 126 - training loss: 0.7828, validation loss: 0.8755
2024-05-24 21:55:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch126_loss0.8754895478487015.pypots
2024-05-24 21:55:43 [INFO]: Epoch 127 - training loss: 0.8001, validation loss: 0.8734
2024-05-24 21:55:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch127_loss0.8733648657798767.pypots
2024-05-24 21:55:43 [INFO]: Epoch 128 - training loss: 0.7794, validation loss: 0.8764
2024-05-24 21:55:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch128_loss0.8763985186815262.pypots
2024-05-24 21:55:43 [INFO]: Epoch 129 - training loss: 0.7788, validation loss: 0.8746
2024-05-24 21:55:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch129_loss0.8746062368154526.pypots
2024-05-24 21:55:44 [INFO]: Epoch 130 - training loss: 0.7870, validation loss: 0.8719
2024-05-24 21:55:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch130_loss0.8718793392181396.pypots
2024-05-24 21:55:44 [INFO]: Epoch 131 - training loss: 0.7849, validation loss: 0.8731
2024-05-24 21:55:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch131_loss0.8730881661176682.pypots
2024-05-24 21:55:44 [INFO]: Epoch 132 - training loss: 0.8312, validation loss: 0.8725
2024-05-24 21:55:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch132_loss0.8724665194749832.pypots
2024-05-24 21:55:44 [INFO]: Epoch 133 - training loss: 0.7925, validation loss: 0.8748
2024-05-24 21:55:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch133_loss0.8748497664928436.pypots
2024-05-24 21:55:44 [INFO]: Epoch 134 - training loss: 0.7824, validation loss: 0.8727
2024-05-24 21:55:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch134_loss0.8726799786090851.pypots
2024-05-24 21:55:45 [INFO]: Epoch 135 - training loss: 0.7974, validation loss: 0.8735
2024-05-24 21:55:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch135_loss0.8735450506210327.pypots
2024-05-24 21:55:45 [INFO]: Epoch 136 - training loss: 0.7752, validation loss: 0.8670
2024-05-24 21:55:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch136_loss0.8670489341020584.pypots
2024-05-24 21:55:45 [INFO]: Epoch 137 - training loss: 0.7819, validation loss: 0.8701
2024-05-24 21:55:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch137_loss0.8701265305280685.pypots
2024-05-24 21:55:45 [INFO]: Epoch 138 - training loss: 0.8064, validation loss: 0.8772
2024-05-24 21:55:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch138_loss0.8771766871213913.pypots
2024-05-24 21:55:45 [INFO]: Epoch 139 - training loss: 0.8163, validation loss: 0.8672
2024-05-24 21:55:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch139_loss0.8671908974647522.pypots
2024-05-24 21:55:45 [INFO]: Epoch 140 - training loss: 0.7806, validation loss: 0.8711
2024-05-24 21:55:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch140_loss0.8711436837911606.pypots
2024-05-24 21:55:46 [INFO]: Epoch 141 - training loss: 0.7974, validation loss: 0.8707
2024-05-24 21:55:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch141_loss0.8706565499305725.pypots
2024-05-24 21:55:46 [INFO]: Epoch 142 - training loss: 0.7769, validation loss: 0.8685
2024-05-24 21:55:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch142_loss0.8684812486171722.pypots
2024-05-24 21:55:46 [INFO]: Epoch 143 - training loss: 0.7856, validation loss: 0.8676
2024-05-24 21:55:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch143_loss0.8676412850618362.pypots
2024-05-24 21:55:46 [INFO]: Epoch 144 - training loss: 0.7913, validation loss: 0.8667
2024-05-24 21:55:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch144_loss0.8666584491729736.pypots
2024-05-24 21:55:46 [INFO]: Epoch 145 - training loss: 0.7756, validation loss: 0.8658
2024-05-24 21:55:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch145_loss0.865835964679718.pypots
2024-05-24 21:55:47 [INFO]: Epoch 146 - training loss: 0.7805, validation loss: 0.8689
2024-05-24 21:55:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch146_loss0.8689331561326981.pypots
2024-05-24 21:55:47 [INFO]: Epoch 147 - training loss: 0.8037, validation loss: 0.8714
2024-05-24 21:55:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch147_loss0.8713980466127396.pypots
2024-05-24 21:55:47 [INFO]: Epoch 148 - training loss: 0.7631, validation loss: 0.8657
2024-05-24 21:55:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch148_loss0.8657429665327072.pypots
2024-05-24 21:55:47 [INFO]: Epoch 149 - training loss: 0.7741, validation loss: 0.8651
2024-05-24 21:55:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch149_loss0.8650690764188766.pypots
2024-05-24 21:55:47 [INFO]: Epoch 150 - training loss: 0.7656, validation loss: 0.8630
2024-05-24 21:55:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch150_loss0.8630407750606537.pypots
2024-05-24 21:55:48 [INFO]: Epoch 151 - training loss: 0.7983, validation loss: 0.8695
2024-05-24 21:55:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch151_loss0.8695156574249268.pypots
2024-05-24 21:55:48 [INFO]: Epoch 152 - training loss: 0.7852, validation loss: 0.8658
2024-05-24 21:55:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch152_loss0.8657752871513367.pypots
2024-05-24 21:55:48 [INFO]: Epoch 153 - training loss: 0.7925, validation loss: 0.8661
2024-05-24 21:55:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch153_loss0.8661246001720428.pypots
2024-05-24 21:55:48 [INFO]: Epoch 154 - training loss: 0.7812, validation loss: 0.8635
2024-05-24 21:55:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch154_loss0.8634934723377228.pypots
2024-05-24 21:55:48 [INFO]: Epoch 155 - training loss: 0.7712, validation loss: 0.8653
2024-05-24 21:55:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch155_loss0.8653358966112137.pypots
2024-05-24 21:55:49 [INFO]: Epoch 156 - training loss: 0.8048, validation loss: 0.8667
2024-05-24 21:55:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch156_loss0.8666779100894928.pypots
2024-05-24 21:55:49 [INFO]: Epoch 157 - training loss: 0.7851, validation loss: 0.8629
2024-05-24 21:55:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch157_loss0.8629001080989838.pypots
2024-05-24 21:55:49 [INFO]: Epoch 158 - training loss: 0.7802, validation loss: 0.8649
2024-05-24 21:55:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch158_loss0.8648944646120071.pypots
2024-05-24 21:55:49 [INFO]: Epoch 159 - training loss: 0.7689, validation loss: 0.8574
2024-05-24 21:55:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch159_loss0.857356920838356.pypots
2024-05-24 21:55:49 [INFO]: Epoch 160 - training loss: 0.7727, validation loss: 0.8586
2024-05-24 21:55:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch160_loss0.8586453050374985.pypots
2024-05-24 21:55:50 [INFO]: Epoch 161 - training loss: 0.7545, validation loss: 0.8584
2024-05-24 21:55:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch161_loss0.8583729416131973.pypots
2024-05-24 21:55:50 [INFO]: Epoch 162 - training loss: 0.7601, validation loss: 0.8656
2024-05-24 21:55:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch162_loss0.8656080961227417.pypots
2024-05-24 21:55:50 [INFO]: Epoch 163 - training loss: 0.7812, validation loss: 0.8633
2024-05-24 21:55:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch163_loss0.8632946759462357.pypots
2024-05-24 21:55:50 [INFO]: Epoch 164 - training loss: 0.7755, validation loss: 0.8620
2024-05-24 21:55:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch164_loss0.8619630038738251.pypots
2024-05-24 21:55:50 [INFO]: Epoch 165 - training loss: 0.7738, validation loss: 0.8631
2024-05-24 21:55:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch165_loss0.8631148040294647.pypots
2024-05-24 21:55:51 [INFO]: Epoch 166 - training loss: 0.7668, validation loss: 0.8592
2024-05-24 21:55:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch166_loss0.8592453896999359.pypots
2024-05-24 21:55:51 [INFO]: Epoch 167 - training loss: 0.7897, validation loss: 0.8586
2024-05-24 21:55:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch167_loss0.8586418777704239.pypots
2024-05-24 21:55:51 [INFO]: Epoch 168 - training loss: 0.7876, validation loss: 0.8607
2024-05-24 21:55:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch168_loss0.8606670945882797.pypots
2024-05-24 21:55:51 [INFO]: Epoch 169 - training loss: 0.7561, validation loss: 0.8553
2024-05-24 21:55:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch169_loss0.855339989066124.pypots
2024-05-24 21:55:51 [INFO]: Epoch 170 - training loss: 0.8078, validation loss: 0.8563
2024-05-24 21:55:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch170_loss0.8563497066497803.pypots
2024-05-24 21:55:52 [INFO]: Epoch 171 - training loss: 0.8028, validation loss: 0.8629
2024-05-24 21:55:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch171_loss0.8628747165203094.pypots
2024-05-24 21:55:52 [INFO]: Epoch 172 - training loss: 0.7727, validation loss: 0.8510
2024-05-24 21:55:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch172_loss0.8509903252124786.pypots
2024-05-24 21:55:52 [INFO]: Epoch 173 - training loss: 0.8216, validation loss: 0.8563
2024-05-24 21:55:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch173_loss0.8562975227832794.pypots
2024-05-24 21:55:52 [INFO]: Epoch 174 - training loss: 0.7990, validation loss: 0.8574
2024-05-24 21:55:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch174_loss0.8574276119470596.pypots
2024-05-24 21:55:52 [INFO]: Epoch 175 - training loss: 0.7775, validation loss: 0.8523
2024-05-24 21:55:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch175_loss0.8523401021957397.pypots
2024-05-24 21:55:52 [INFO]: Epoch 176 - training loss: 0.8215, validation loss: 0.8505
2024-05-24 21:55:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch176_loss0.8504849821329117.pypots
2024-05-24 21:55:53 [INFO]: Epoch 177 - training loss: 0.7877, validation loss: 0.8534
2024-05-24 21:55:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch177_loss0.8534429222345352.pypots
2024-05-24 21:55:53 [INFO]: Epoch 178 - training loss: 0.7816, validation loss: 0.8568
2024-05-24 21:55:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch178_loss0.8568247854709625.pypots
2024-05-24 21:55:53 [INFO]: Epoch 179 - training loss: 0.7853, validation loss: 0.8541
2024-05-24 21:55:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch179_loss0.8540661931037903.pypots
2024-05-24 21:55:53 [INFO]: Epoch 180 - training loss: 0.7886, validation loss: 0.8482
2024-05-24 21:55:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch180_loss0.8482042551040649.pypots
2024-05-24 21:55:53 [INFO]: Epoch 181 - training loss: 0.7801, validation loss: 0.8551
2024-05-24 21:55:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch181_loss0.8551265746355057.pypots
2024-05-24 21:55:54 [INFO]: Epoch 182 - training loss: 0.7689, validation loss: 0.8539
2024-05-24 21:55:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch182_loss0.8538526445627213.pypots
2024-05-24 21:55:54 [INFO]: Epoch 183 - training loss: 0.7698, validation loss: 0.8511
2024-05-24 21:55:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch183_loss0.8511323779821396.pypots
2024-05-24 21:55:54 [INFO]: Epoch 184 - training loss: 0.7882, validation loss: 0.8493
2024-05-24 21:55:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch184_loss0.8493062257766724.pypots
2024-05-24 21:55:54 [INFO]: Epoch 185 - training loss: 0.7904, validation loss: 0.8497
2024-05-24 21:55:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch185_loss0.8497057557106018.pypots
2024-05-24 21:55:54 [INFO]: Epoch 186 - training loss: 0.7894, validation loss: 0.8516
2024-05-24 21:55:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch186_loss0.8515562117099762.pypots
2024-05-24 21:55:55 [INFO]: Epoch 187 - training loss: 0.7757, validation loss: 0.8509
2024-05-24 21:55:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch187_loss0.8508953750133514.pypots
2024-05-24 21:55:55 [INFO]: Epoch 188 - training loss: 0.7655, validation loss: 0.8534
2024-05-24 21:55:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch188_loss0.8533525317907333.pypots
2024-05-24 21:55:55 [INFO]: Epoch 189 - training loss: 0.7920, validation loss: 0.8459
2024-05-24 21:55:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch189_loss0.845895528793335.pypots
2024-05-24 21:55:55 [INFO]: Epoch 190 - training loss: 0.7682, validation loss: 0.8489
2024-05-24 21:55:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch190_loss0.8488931059837341.pypots
2024-05-24 21:55:55 [INFO]: Epoch 191 - training loss: 0.7745, validation loss: 0.8515
2024-05-24 21:55:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch191_loss0.8514972776174545.pypots
2024-05-24 21:55:56 [INFO]: Epoch 192 - training loss: 0.7805, validation loss: 0.8549
2024-05-24 21:55:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch192_loss0.8548649400472641.pypots
2024-05-24 21:55:56 [INFO]: Epoch 193 - training loss: 0.7919, validation loss: 0.8513
2024-05-24 21:55:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch193_loss0.8512856513261795.pypots
2024-05-24 21:55:56 [INFO]: Epoch 194 - training loss: 0.7559, validation loss: 0.8485
2024-05-24 21:55:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch194_loss0.8485329300165176.pypots
2024-05-24 21:55:56 [INFO]: Epoch 195 - training loss: 0.7914, validation loss: 0.8494
2024-05-24 21:55:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch195_loss0.8494111150503159.pypots
2024-05-24 21:55:56 [INFO]: Epoch 196 - training loss: 0.7839, validation loss: 0.8487
2024-05-24 21:55:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch196_loss0.8486869931221008.pypots
2024-05-24 21:55:57 [INFO]: Epoch 197 - training loss: 0.7756, validation loss: 0.8466
2024-05-24 21:55:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch197_loss0.8466062098741531.pypots
2024-05-24 21:55:57 [INFO]: Epoch 198 - training loss: 0.7757, validation loss: 0.8477
2024-05-24 21:55:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch198_loss0.8476816713809967.pypots
2024-05-24 21:55:57 [INFO]: Epoch 199 - training loss: 0.7698, validation loss: 0.8473
2024-05-24 21:55:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN_epoch199_loss0.8472910672426224.pypots
2024-05-24 21:55:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:55:57 [INFO]: Finished training. The best model is from epoch#189.
2024-05-24 21:55:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T215517/MRNN.pypots
2024-05-24 21:55:57 [INFO]: MRNN on ETTm1: MAE=0.6224, MSE=1.0277
2024-05-24 21:55:57 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/MRNN_ettm1/imputation.pkl
2024-05-24 21:55:57 [INFO]: Using the given device: cpu
2024-05-24 21:55:57 [INFO]: LOCF on ETTm1: MAE=0.1348, MSE=0.0715
2024-05-24 21:55:57 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_ettm1".
2024-05-24 21:55:57 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/LOCF_ettm1/imputation.pkl
2024-05-24 21:55:57 [INFO]: Median on ETTm1: MAE=0.6516, MSE=0.8223
2024-05-24 21:55:57 [INFO]: Successfully created the given path "saved_results/round_1/Median_ettm1".
2024-05-24 21:55:57 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Median_ettm1/imputation.pkl
2024-05-24 21:55:57 [INFO]: Mean on ETTm1: MAE=0.6566, MSE=0.8036
2024-05-24 21:55:57 [INFO]: Successfully created the given path "saved_results/round_1/Mean_ettm1".
2024-05-24 21:55:57 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Mean_ettm1/imputation.pkl
2024-05-24 21:55:57 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-24 21:55:57 [INFO]: Using the given device: cuda:0
2024-05-24 21:55:57 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/SAITS_ettm1/20240524_T215557
2024-05-24 21:55:57 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/SAITS_ettm1/20240524_T215557/tensorboard
2024-05-24 21:55:57 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 21:55:58 [INFO]: Epoch 001 - training loss: 1.1371, validation loss: 0.2278
2024-05-24 21:55:58 [INFO]: Epoch 002 - training loss: 0.8002, validation loss: 0.1180
2024-05-24 21:55:59 [INFO]: Epoch 003 - training loss: 0.6999, validation loss: 0.1053
2024-05-24 21:55:59 [INFO]: Epoch 004 - training loss: 0.6617, validation loss: 0.0829
2024-05-24 21:56:00 [INFO]: Epoch 005 - training loss: 0.6513, validation loss: 0.0835
2024-05-24 21:56:00 [INFO]: Epoch 006 - training loss: 0.6011, validation loss: 0.0744
2024-05-24 21:56:01 [INFO]: Epoch 007 - training loss: 0.5617, validation loss: 0.0722
2024-05-24 21:56:01 [INFO]: Epoch 008 - training loss: 0.5399, validation loss: 0.0648
2024-05-24 21:56:02 [INFO]: Epoch 009 - training loss: 0.5386, validation loss: 0.0597
2024-05-24 21:56:02 [INFO]: Epoch 010 - training loss: 0.5213, validation loss: 0.0561
2024-05-24 21:56:03 [INFO]: Epoch 011 - training loss: 0.4911, validation loss: 0.0658
2024-05-24 21:56:03 [INFO]: Epoch 012 - training loss: 0.5061, validation loss: 0.0558
2024-05-24 21:56:04 [INFO]: Epoch 013 - training loss: 0.4905, validation loss: 0.0559
2024-05-24 21:56:04 [INFO]: Epoch 014 - training loss: 0.4736, validation loss: 0.0539
2024-05-24 21:56:05 [INFO]: Epoch 015 - training loss: 0.4911, validation loss: 0.0589
2024-05-24 21:56:05 [INFO]: Epoch 016 - training loss: 0.4567, validation loss: 0.0507
2024-05-24 21:56:06 [INFO]: Epoch 017 - training loss: 0.4881, validation loss: 0.0438
2024-05-24 21:56:06 [INFO]: Epoch 018 - training loss: 0.4682, validation loss: 0.0569
2024-05-24 21:56:07 [INFO]: Epoch 019 - training loss: 0.4506, validation loss: 0.0463
2024-05-24 21:56:07 [INFO]: Epoch 020 - training loss: 0.4204, validation loss: 0.0400
2024-05-24 21:56:08 [INFO]: Epoch 021 - training loss: 0.4489, validation loss: 0.0406
2024-05-24 21:56:08 [INFO]: Epoch 022 - training loss: 0.4275, validation loss: 0.0425
2024-05-24 21:56:09 [INFO]: Epoch 023 - training loss: 0.4172, validation loss: 0.0534
2024-05-24 21:56:09 [INFO]: Epoch 024 - training loss: 0.4148, validation loss: 0.0387
2024-05-24 21:56:10 [INFO]: Epoch 025 - training loss: 0.3972, validation loss: 0.0478
2024-05-24 21:56:10 [INFO]: Epoch 026 - training loss: 0.3989, validation loss: 0.0422
2024-05-24 21:56:11 [INFO]: Epoch 027 - training loss: 0.3971, validation loss: 0.0436
2024-05-24 21:56:11 [INFO]: Epoch 028 - training loss: 0.3898, validation loss: 0.0476
2024-05-24 21:56:12 [INFO]: Epoch 029 - training loss: 0.4116, validation loss: 0.0355
2024-05-24 21:56:12 [INFO]: Epoch 030 - training loss: 0.3755, validation loss: 0.0384
2024-05-24 21:56:13 [INFO]: Epoch 031 - training loss: 0.3837, validation loss: 0.0381
2024-05-24 21:56:13 [INFO]: Epoch 032 - training loss: 0.3760, validation loss: 0.0368
2024-05-24 21:56:14 [INFO]: Epoch 033 - training loss: 0.3629, validation loss: 0.0354
2024-05-24 21:56:14 [INFO]: Epoch 034 - training loss: 0.3720, validation loss: 0.0391
2024-05-24 21:56:15 [INFO]: Epoch 035 - training loss: 0.3629, validation loss: 0.0429
2024-05-24 21:56:15 [INFO]: Epoch 036 - training loss: 0.3720, validation loss: 0.0505
2024-05-24 21:56:16 [INFO]: Epoch 037 - training loss: 0.3956, validation loss: 0.0414
2024-05-24 21:56:16 [INFO]: Epoch 038 - training loss: 0.3590, validation loss: 0.0318
2024-05-24 21:56:16 [INFO]: Epoch 039 - training loss: 0.3798, validation loss: 0.0345
2024-05-24 21:56:17 [INFO]: Epoch 040 - training loss: 0.3607, validation loss: 0.0337
2024-05-24 21:56:17 [INFO]: Epoch 041 - training loss: 0.3463, validation loss: 0.0374
2024-05-24 21:56:18 [INFO]: Epoch 042 - training loss: 0.3337, validation loss: 0.0328
2024-05-24 21:56:18 [INFO]: Epoch 043 - training loss: 0.3420, validation loss: 0.0394
2024-05-24 21:56:19 [INFO]: Epoch 044 - training loss: 0.3352, validation loss: 0.0308
2024-05-24 21:56:19 [INFO]: Epoch 045 - training loss: 0.3373, validation loss: 0.0564
2024-05-24 21:56:20 [INFO]: Epoch 046 - training loss: 0.3445, validation loss: 0.0332
2024-05-24 21:56:20 [INFO]: Epoch 047 - training loss: 0.3275, validation loss: 0.0376
2024-05-24 21:56:21 [INFO]: Epoch 048 - training loss: 0.3176, validation loss: 0.0331
2024-05-24 21:56:21 [INFO]: Epoch 049 - training loss: 0.3348, validation loss: 0.0394
2024-05-24 21:56:22 [INFO]: Epoch 050 - training loss: 0.3351, validation loss: 0.0335
2024-05-24 21:56:22 [INFO]: Epoch 051 - training loss: 0.3204, validation loss: 0.0368
2024-05-24 21:56:23 [INFO]: Epoch 052 - training loss: 0.3177, validation loss: 0.0319
2024-05-24 21:56:23 [INFO]: Epoch 053 - training loss: 0.3117, validation loss: 0.0292
2024-05-24 21:56:24 [INFO]: Epoch 054 - training loss: 0.3134, validation loss: 0.0320
2024-05-24 21:56:24 [INFO]: Epoch 055 - training loss: 0.3248, validation loss: 0.0292
2024-05-24 21:56:25 [INFO]: Epoch 056 - training loss: 0.3137, validation loss: 0.0586
2024-05-24 21:56:25 [INFO]: Epoch 057 - training loss: 0.3299, validation loss: 0.0290
2024-05-24 21:56:26 [INFO]: Epoch 058 - training loss: 0.3140, validation loss: 0.0362
2024-05-24 21:56:26 [INFO]: Epoch 059 - training loss: 0.3034, validation loss: 0.0329
2024-05-24 21:56:27 [INFO]: Epoch 060 - training loss: 0.3033, validation loss: 0.0404
2024-05-24 21:56:27 [INFO]: Epoch 061 - training loss: 0.2990, validation loss: 0.0350
2024-05-24 21:56:28 [INFO]: Epoch 062 - training loss: 0.2976, validation loss: 0.0387
2024-05-24 21:56:28 [INFO]: Epoch 063 - training loss: 0.3023, validation loss: 0.0354
2024-05-24 21:56:29 [INFO]: Epoch 064 - training loss: 0.3059, validation loss: 0.0319
2024-05-24 21:56:29 [INFO]: Epoch 065 - training loss: 0.2930, validation loss: 0.0311
2024-05-24 21:56:30 [INFO]: Epoch 066 - training loss: 0.2888, validation loss: 0.0346
2024-05-24 21:56:30 [INFO]: Epoch 067 - training loss: 0.2913, validation loss: 0.0348
2024-05-24 21:56:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:56:30 [INFO]: Finished training. The best model is from epoch#57.
2024-05-24 21:56:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/SAITS_ettm1/20240524_T215557/SAITS.pypots
2024-05-24 21:56:30 [INFO]: SAITS on ETTm1: MAE=0.1689, MSE=0.0648
2024-05-24 21:56:30 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/SAITS_ettm1/imputation.pkl
2024-05-24 21:56:30 [INFO]: Using the given device: cuda:0
2024-05-24 21:56:30 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/Transformer_ettm1/20240524_T215630
2024-05-24 21:56:30 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/Transformer_ettm1/20240524_T215630/tensorboard
2024-05-24 21:56:30 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 21:56:30 [INFO]: Epoch 001 - training loss: 1.1553, validation loss: 0.3096
2024-05-24 21:56:31 [INFO]: Epoch 002 - training loss: 0.6738, validation loss: 0.1265
2024-05-24 21:56:31 [INFO]: Epoch 003 - training loss: 0.5302, validation loss: 0.1082
2024-05-24 21:56:31 [INFO]: Epoch 004 - training loss: 0.4764, validation loss: 0.0803
2024-05-24 21:56:31 [INFO]: Epoch 005 - training loss: 0.4445, validation loss: 0.0707
2024-05-24 21:56:31 [INFO]: Epoch 006 - training loss: 0.4175, validation loss: 0.0615
2024-05-24 21:56:32 [INFO]: Epoch 007 - training loss: 0.3962, validation loss: 0.0596
2024-05-24 21:56:32 [INFO]: Epoch 008 - training loss: 0.4083, validation loss: 0.0542
2024-05-24 21:56:32 [INFO]: Epoch 009 - training loss: 0.3840, validation loss: 0.0540
2024-05-24 21:56:32 [INFO]: Epoch 010 - training loss: 0.3699, validation loss: 0.0500
2024-05-24 21:56:32 [INFO]: Epoch 011 - training loss: 0.3583, validation loss: 0.0500
2024-05-24 21:56:33 [INFO]: Epoch 012 - training loss: 0.3459, validation loss: 0.0476
2024-05-24 21:56:33 [INFO]: Epoch 013 - training loss: 0.3542, validation loss: 0.0468
2024-05-24 21:56:33 [INFO]: Epoch 014 - training loss: 0.3343, validation loss: 0.0484
2024-05-24 21:56:33 [INFO]: Epoch 015 - training loss: 0.3342, validation loss: 0.0437
2024-05-24 21:56:33 [INFO]: Epoch 016 - training loss: 0.3236, validation loss: 0.0405
2024-05-24 21:56:34 [INFO]: Epoch 017 - training loss: 0.3211, validation loss: 0.0429
2024-05-24 21:56:34 [INFO]: Epoch 018 - training loss: 0.3088, validation loss: 0.0401
2024-05-24 21:56:34 [INFO]: Epoch 019 - training loss: 0.3120, validation loss: 0.0423
2024-05-24 21:56:34 [INFO]: Epoch 020 - training loss: 0.3100, validation loss: 0.0398
2024-05-24 21:56:34 [INFO]: Epoch 021 - training loss: 0.3067, validation loss: 0.0450
2024-05-24 21:56:35 [INFO]: Epoch 022 - training loss: 0.3056, validation loss: 0.0454
2024-05-24 21:56:35 [INFO]: Epoch 023 - training loss: 0.3035, validation loss: 0.0410
2024-05-24 21:56:35 [INFO]: Epoch 024 - training loss: 0.2966, validation loss: 0.0353
2024-05-24 21:56:35 [INFO]: Epoch 025 - training loss: 0.2931, validation loss: 0.0416
2024-05-24 21:56:35 [INFO]: Epoch 026 - training loss: 0.2914, validation loss: 0.0337
2024-05-24 21:56:36 [INFO]: Epoch 027 - training loss: 0.2820, validation loss: 0.0371
2024-05-24 21:56:36 [INFO]: Epoch 028 - training loss: 0.2824, validation loss: 0.0367
2024-05-24 21:56:36 [INFO]: Epoch 029 - training loss: 0.2807, validation loss: 0.0366
2024-05-24 21:56:36 [INFO]: Epoch 030 - training loss: 0.2824, validation loss: 0.0389
2024-05-24 21:56:36 [INFO]: Epoch 031 - training loss: 0.2813, validation loss: 0.0335
2024-05-24 21:56:37 [INFO]: Epoch 032 - training loss: 0.2836, validation loss: 0.0356
2024-05-24 21:56:37 [INFO]: Epoch 033 - training loss: 0.2698, validation loss: 0.0341
2024-05-24 21:56:37 [INFO]: Epoch 034 - training loss: 0.2624, validation loss: 0.0317
2024-05-24 21:56:37 [INFO]: Epoch 035 - training loss: 0.2607, validation loss: 0.0361
2024-05-24 21:56:37 [INFO]: Epoch 036 - training loss: 0.2663, validation loss: 0.0340
2024-05-24 21:56:38 [INFO]: Epoch 037 - training loss: 0.2648, validation loss: 0.0351
2024-05-24 21:56:38 [INFO]: Epoch 038 - training loss: 0.2610, validation loss: 0.0358
2024-05-24 21:56:38 [INFO]: Epoch 039 - training loss: 0.2626, validation loss: 0.0313
2024-05-24 21:56:38 [INFO]: Epoch 040 - training loss: 0.2685, validation loss: 0.0320
2024-05-24 21:56:38 [INFO]: Epoch 041 - training loss: 0.2644, validation loss: 0.0318
2024-05-24 21:56:38 [INFO]: Epoch 042 - training loss: 0.2518, validation loss: 0.0319
2024-05-24 21:56:39 [INFO]: Epoch 043 - training loss: 0.2549, validation loss: 0.0331
2024-05-24 21:56:39 [INFO]: Epoch 044 - training loss: 0.2496, validation loss: 0.0361
2024-05-24 21:56:39 [INFO]: Epoch 045 - training loss: 0.2525, validation loss: 0.0297
2024-05-24 21:56:39 [INFO]: Epoch 046 - training loss: 0.2437, validation loss: 0.0347
2024-05-24 21:56:39 [INFO]: Epoch 047 - training loss: 0.2455, validation loss: 0.0343
2024-05-24 21:56:40 [INFO]: Epoch 048 - training loss: 0.2440, validation loss: 0.0341
2024-05-24 21:56:40 [INFO]: Epoch 049 - training loss: 0.2446, validation loss: 0.0311
2024-05-24 21:56:40 [INFO]: Epoch 050 - training loss: 0.2437, validation loss: 0.0305
2024-05-24 21:56:40 [INFO]: Epoch 051 - training loss: 0.2303, validation loss: 0.0287
2024-05-24 21:56:40 [INFO]: Epoch 052 - training loss: 0.2366, validation loss: 0.0304
2024-05-24 21:56:41 [INFO]: Epoch 053 - training loss: 0.2370, validation loss: 0.0291
2024-05-24 21:56:41 [INFO]: Epoch 054 - training loss: 0.2302, validation loss: 0.0297
2024-05-24 21:56:41 [INFO]: Epoch 055 - training loss: 0.2339, validation loss: 0.0299
2024-05-24 21:56:41 [INFO]: Epoch 056 - training loss: 0.2304, validation loss: 0.0271
2024-05-24 21:56:41 [INFO]: Epoch 057 - training loss: 0.2276, validation loss: 0.0322
2024-05-24 21:56:42 [INFO]: Epoch 058 - training loss: 0.2306, validation loss: 0.0266
2024-05-24 21:56:42 [INFO]: Epoch 059 - training loss: 0.2218, validation loss: 0.0297
2024-05-24 21:56:42 [INFO]: Epoch 060 - training loss: 0.2252, validation loss: 0.0295
2024-05-24 21:56:42 [INFO]: Epoch 061 - training loss: 0.2240, validation loss: 0.0261
2024-05-24 21:56:42 [INFO]: Epoch 062 - training loss: 0.2220, validation loss: 0.0303
2024-05-24 21:56:43 [INFO]: Epoch 063 - training loss: 0.2248, validation loss: 0.0279
2024-05-24 21:56:43 [INFO]: Epoch 064 - training loss: 0.2200, validation loss: 0.0315
2024-05-24 21:56:43 [INFO]: Epoch 065 - training loss: 0.2365, validation loss: 0.0277
2024-05-24 21:56:43 [INFO]: Epoch 066 - training loss: 0.2172, validation loss: 0.0274
2024-05-24 21:56:43 [INFO]: Epoch 067 - training loss: 0.2103, validation loss: 0.0256
2024-05-24 21:56:44 [INFO]: Epoch 068 - training loss: 0.2094, validation loss: 0.0259
2024-05-24 21:56:44 [INFO]: Epoch 069 - training loss: 0.2151, validation loss: 0.0259
2024-05-24 21:56:44 [INFO]: Epoch 070 - training loss: 0.2156, validation loss: 0.0321
2024-05-24 21:56:44 [INFO]: Epoch 071 - training loss: 0.2142, validation loss: 0.0268
2024-05-24 21:56:44 [INFO]: Epoch 072 - training loss: 0.2063, validation loss: 0.0240
2024-05-24 21:56:45 [INFO]: Epoch 073 - training loss: 0.2066, validation loss: 0.0303
2024-05-24 21:56:45 [INFO]: Epoch 074 - training loss: 0.2066, validation loss: 0.0257
2024-05-24 21:56:45 [INFO]: Epoch 075 - training loss: 0.2083, validation loss: 0.0241
2024-05-24 21:56:45 [INFO]: Epoch 076 - training loss: 0.2041, validation loss: 0.0259
2024-05-24 21:56:45 [INFO]: Epoch 077 - training loss: 0.2041, validation loss: 0.0253
2024-05-24 21:56:45 [INFO]: Epoch 078 - training loss: 0.1989, validation loss: 0.0311
2024-05-24 21:56:46 [INFO]: Epoch 079 - training loss: 0.2065, validation loss: 0.0245
2024-05-24 21:56:46 [INFO]: Epoch 080 - training loss: 0.2025, validation loss: 0.0264
2024-05-24 21:56:46 [INFO]: Epoch 081 - training loss: 0.2031, validation loss: 0.0252
2024-05-24 21:56:46 [INFO]: Epoch 082 - training loss: 0.1975, validation loss: 0.0251
2024-05-24 21:56:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:56:46 [INFO]: Finished training. The best model is from epoch#72.
2024-05-24 21:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/Transformer_ettm1/20240524_T215630/Transformer.pypots
2024-05-24 21:56:46 [INFO]: Transformer on ETTm1: MAE=0.1337, MSE=0.0372
2024-05-24 21:56:46 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Transformer_ettm1/imputation.pkl
2024-05-24 21:56:46 [INFO]: Using the given device: cuda:0
2024-05-24 21:56:46 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/TimesNet_ettm1/20240524_T215646
2024-05-24 21:56:46 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/TimesNet_ettm1/20240524_T215646/tensorboard
2024-05-24 21:56:47 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 21:56:47 [INFO]: Epoch 001 - training loss: 0.1333, validation loss: 0.0567
2024-05-24 21:56:47 [INFO]: Epoch 002 - training loss: 0.0701, validation loss: 0.0412
2024-05-24 21:56:47 [INFO]: Epoch 003 - training loss: 0.0545, validation loss: 0.0321
2024-05-24 21:56:47 [INFO]: Epoch 004 - training loss: 0.0438, validation loss: 0.0295
2024-05-24 21:56:47 [INFO]: Epoch 005 - training loss: 0.0389, validation loss: 0.0265
2024-05-24 21:56:48 [INFO]: Epoch 006 - training loss: 0.0342, validation loss: 0.0258
2024-05-24 21:56:48 [INFO]: Epoch 007 - training loss: 0.0301, validation loss: 0.0235
2024-05-24 21:56:48 [INFO]: Epoch 008 - training loss: 0.0291, validation loss: 0.0234
2024-05-24 21:56:48 [INFO]: Epoch 009 - training loss: 0.0280, validation loss: 0.0223
2024-05-24 21:56:48 [INFO]: Epoch 010 - training loss: 0.0271, validation loss: 0.0220
2024-05-24 21:56:49 [INFO]: Epoch 011 - training loss: 0.0263, validation loss: 0.0213
2024-05-24 21:56:49 [INFO]: Epoch 012 - training loss: 0.0260, validation loss: 0.0228
2024-05-24 21:56:49 [INFO]: Epoch 013 - training loss: 0.0298, validation loss: 0.0238
2024-05-24 21:56:49 [INFO]: Epoch 014 - training loss: 0.0294, validation loss: 0.0226
2024-05-24 21:56:49 [INFO]: Epoch 015 - training loss: 0.0257, validation loss: 0.0213
2024-05-24 21:56:50 [INFO]: Epoch 016 - training loss: 0.0237, validation loss: 0.0215
2024-05-24 21:56:50 [INFO]: Epoch 017 - training loss: 0.0237, validation loss: 0.0227
2024-05-24 21:56:50 [INFO]: Epoch 018 - training loss: 0.0223, validation loss: 0.0209
2024-05-24 21:56:50 [INFO]: Epoch 019 - training loss: 0.0217, validation loss: 0.0224
2024-05-24 21:56:50 [INFO]: Epoch 020 - training loss: 0.0235, validation loss: 0.0233
2024-05-24 21:56:51 [INFO]: Epoch 021 - training loss: 0.0214, validation loss: 0.0215
2024-05-24 21:56:51 [INFO]: Epoch 022 - training loss: 0.0203, validation loss: 0.0214
2024-05-24 21:56:51 [INFO]: Epoch 023 - training loss: 0.0200, validation loss: 0.0214
2024-05-24 21:56:51 [INFO]: Epoch 024 - training loss: 0.0198, validation loss: 0.0209
2024-05-24 21:56:51 [INFO]: Epoch 025 - training loss: 0.0198, validation loss: 0.0228
2024-05-24 21:56:51 [INFO]: Epoch 026 - training loss: 0.0235, validation loss: 0.0231
2024-05-24 21:56:52 [INFO]: Epoch 027 - training loss: 0.0195, validation loss: 0.0213
2024-05-24 21:56:52 [INFO]: Epoch 028 - training loss: 0.0187, validation loss: 0.0234
2024-05-24 21:56:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:56:52 [INFO]: Finished training. The best model is from epoch#18.
2024-05-24 21:56:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/TimesNet_ettm1/20240524_T215646/TimesNet.pypots
2024-05-24 21:56:52 [INFO]: TimesNet on ETTm1: MAE=0.1084, MSE=0.0251
2024-05-24 21:56:52 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/TimesNet_ettm1/imputation.pkl
2024-05-24 21:56:52 [INFO]: Using the given device: cuda:0
2024-05-24 21:56:52 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652
2024-05-24 21:56:52 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/tensorboard
2024-05-24 21:56:52 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 21:56:54 [INFO]: Epoch 001 - training loss: 0.6844, validation loss: 0.4428
2024-05-24 21:56:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch1_loss0.4427710026502609.pypots
2024-05-24 21:56:56 [INFO]: Epoch 002 - training loss: 0.4529, validation loss: 0.3915
2024-05-24 21:56:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch2_loss0.3915319889783859.pypots
2024-05-24 21:56:58 [INFO]: Epoch 003 - training loss: 0.3691, validation loss: 0.3867
2024-05-24 21:56:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch3_loss0.3867212384939194.pypots
2024-05-24 21:57:00 [INFO]: Epoch 004 - training loss: 0.3374, validation loss: 0.3431
2024-05-24 21:57:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch4_loss0.3430767357349396.pypots
2024-05-24 21:57:02 [INFO]: Epoch 005 - training loss: 0.3030, validation loss: 0.2962
2024-05-24 21:57:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch5_loss0.2961607724428177.pypots
2024-05-24 21:57:04 [INFO]: Epoch 006 - training loss: 0.2834, validation loss: 0.2803
2024-05-24 21:57:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch6_loss0.2802632227540016.pypots
2024-05-24 21:57:06 [INFO]: Epoch 007 - training loss: 0.2789, validation loss: 0.2746
2024-05-24 21:57:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch7_loss0.2746480628848076.pypots
2024-05-24 21:57:08 [INFO]: Epoch 008 - training loss: 0.2615, validation loss: 0.2720
2024-05-24 21:57:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch8_loss0.27198947966098785.pypots
2024-05-24 21:57:10 [INFO]: Epoch 009 - training loss: 0.2703, validation loss: 0.2613
2024-05-24 21:57:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch9_loss0.26132116466760635.pypots
2024-05-24 21:57:12 [INFO]: Epoch 010 - training loss: 0.2721, validation loss: 0.2488
2024-05-24 21:57:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch10_loss0.24882926046848297.pypots
2024-05-24 21:57:14 [INFO]: Epoch 011 - training loss: 0.2828, validation loss: 0.2528
2024-05-24 21:57:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch11_loss0.25280728191137314.pypots
2024-05-24 21:57:16 [INFO]: Epoch 012 - training loss: 0.2708, validation loss: 0.2445
2024-05-24 21:57:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch12_loss0.24454404041171074.pypots
2024-05-24 21:57:18 [INFO]: Epoch 013 - training loss: 0.2369, validation loss: 0.2446
2024-05-24 21:57:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch13_loss0.24463225156068802.pypots
2024-05-24 21:57:21 [INFO]: Epoch 014 - training loss: 0.2341, validation loss: 0.2289
2024-05-24 21:57:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch14_loss0.22887161001563072.pypots
2024-05-24 21:57:23 [INFO]: Epoch 015 - training loss: 0.3146, validation loss: 0.2699
2024-05-24 21:57:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch15_loss0.2699241191148758.pypots
2024-05-24 21:57:25 [INFO]: Epoch 016 - training loss: 0.2297, validation loss: 0.2278
2024-05-24 21:57:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch16_loss0.2277974858880043.pypots
2024-05-24 21:57:27 [INFO]: Epoch 017 - training loss: 0.2211, validation loss: 0.2143
2024-05-24 21:57:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch17_loss0.2143411785364151.pypots
2024-05-24 21:57:29 [INFO]: Epoch 018 - training loss: 0.2252, validation loss: 0.2089
2024-05-24 21:57:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch18_loss0.2088867425918579.pypots
2024-05-24 21:57:31 [INFO]: Epoch 019 - training loss: 0.2222, validation loss: 0.2039
2024-05-24 21:57:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch19_loss0.20389091223478317.pypots
2024-05-24 21:57:33 [INFO]: Epoch 020 - training loss: 0.2418, validation loss: 0.2112
2024-05-24 21:57:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch20_loss0.2112344354391098.pypots
2024-05-24 21:57:35 [INFO]: Epoch 021 - training loss: 0.2228, validation loss: 0.2001
2024-05-24 21:57:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch21_loss0.20009247213602066.pypots
2024-05-24 21:57:37 [INFO]: Epoch 022 - training loss: 0.2020, validation loss: 0.1946
2024-05-24 21:57:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch22_loss0.19457022845745087.pypots
2024-05-24 21:57:39 [INFO]: Epoch 023 - training loss: 0.1940, validation loss: 0.1985
2024-05-24 21:57:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch23_loss0.1984970159828663.pypots
2024-05-24 21:57:41 [INFO]: Epoch 024 - training loss: 0.2342, validation loss: 0.1875
2024-05-24 21:57:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch24_loss0.18748579174280167.pypots
2024-05-24 21:57:43 [INFO]: Epoch 025 - training loss: 0.2240, validation loss: 0.2081
2024-05-24 21:57:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch25_loss0.208083875477314.pypots
2024-05-24 21:57:45 [INFO]: Epoch 026 - training loss: 0.2534, validation loss: 0.1978
2024-05-24 21:57:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch26_loss0.19784051924943924.pypots
2024-05-24 21:57:47 [INFO]: Epoch 027 - training loss: 0.1655, validation loss: 0.1904
2024-05-24 21:57:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch27_loss0.19039247557520866.pypots
2024-05-24 21:57:49 [INFO]: Epoch 028 - training loss: 0.1698, validation loss: 0.1867
2024-05-24 21:57:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch28_loss0.18668634071946144.pypots
2024-05-24 21:57:51 [INFO]: Epoch 029 - training loss: 0.1806, validation loss: 0.1786
2024-05-24 21:57:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch29_loss0.17861204966902733.pypots
2024-05-24 21:57:53 [INFO]: Epoch 030 - training loss: 0.1883, validation loss: 0.1808
2024-05-24 21:57:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch30_loss0.18076246976852417.pypots
2024-05-24 21:57:55 [INFO]: Epoch 031 - training loss: 0.2426, validation loss: 0.1981
2024-05-24 21:57:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch31_loss0.19811610504984856.pypots
2024-05-24 21:57:57 [INFO]: Epoch 032 - training loss: 0.1985, validation loss: 0.1858
2024-05-24 21:57:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch32_loss0.18579187989234924.pypots
2024-05-24 21:57:59 [INFO]: Epoch 033 - training loss: 0.1817, validation loss: 0.1712
2024-05-24 21:57:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch33_loss0.17118480429053307.pypots
2024-05-24 21:58:01 [INFO]: Epoch 034 - training loss: 0.1811, validation loss: 0.1663
2024-05-24 21:58:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch34_loss0.16632308810949326.pypots
2024-05-24 21:58:03 [INFO]: Epoch 035 - training loss: 0.1662, validation loss: 0.1601
2024-05-24 21:58:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch35_loss0.16006596758961678.pypots
2024-05-24 21:58:05 [INFO]: Epoch 036 - training loss: 0.2502, validation loss: 0.1668
2024-05-24 21:58:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch36_loss0.1668381467461586.pypots
2024-05-24 21:58:07 [INFO]: Epoch 037 - training loss: 0.1712, validation loss: 0.1737
2024-05-24 21:58:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch37_loss0.17366259917616844.pypots
2024-05-24 21:58:10 [INFO]: Epoch 038 - training loss: 0.1736, validation loss: 0.1707
2024-05-24 21:58:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch38_loss0.17069660127162933.pypots
2024-05-24 21:58:12 [INFO]: Epoch 039 - training loss: 0.1519, validation loss: 0.1686
2024-05-24 21:58:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch39_loss0.16864768415689468.pypots
2024-05-24 21:58:14 [INFO]: Epoch 040 - training loss: 0.1617, validation loss: 0.1594
2024-05-24 21:58:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch40_loss0.1593734286725521.pypots
2024-05-24 21:58:16 [INFO]: Epoch 041 - training loss: 0.1687, validation loss: 0.1709
2024-05-24 21:58:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch41_loss0.17087895050644875.pypots
2024-05-24 21:58:18 [INFO]: Epoch 042 - training loss: 0.1705, validation loss: 0.1613
2024-05-24 21:58:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch42_loss0.16126354411244392.pypots
2024-05-24 21:58:20 [INFO]: Epoch 043 - training loss: 0.1545, validation loss: 0.1555
2024-05-24 21:58:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch43_loss0.1555163376033306.pypots
2024-05-24 21:58:22 [INFO]: Epoch 044 - training loss: 0.1367, validation loss: 0.1581
2024-05-24 21:58:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch44_loss0.15811780095100403.pypots
2024-05-24 21:58:24 [INFO]: Epoch 045 - training loss: 0.1854, validation loss: 0.1751
2024-05-24 21:58:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch45_loss0.17511730641126633.pypots
2024-05-24 21:58:26 [INFO]: Epoch 046 - training loss: 0.1609, validation loss: 0.1697
2024-05-24 21:58:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch46_loss0.1696864515542984.pypots
2024-05-24 21:58:28 [INFO]: Epoch 047 - training loss: 0.1411, validation loss: 0.1704
2024-05-24 21:58:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch47_loss0.17038586363196373.pypots
2024-05-24 21:58:30 [INFO]: Epoch 048 - training loss: 0.1609, validation loss: 0.1555
2024-05-24 21:58:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch48_loss0.1555439569056034.pypots
2024-05-24 21:58:32 [INFO]: Epoch 049 - training loss: 0.1459, validation loss: 0.1555
2024-05-24 21:58:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch49_loss0.1554969698190689.pypots
2024-05-24 21:58:34 [INFO]: Epoch 050 - training loss: 0.1559, validation loss: 0.1568
2024-05-24 21:58:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch50_loss0.1568138562142849.pypots
2024-05-24 21:58:36 [INFO]: Epoch 051 - training loss: 0.1553, validation loss: 0.1576
2024-05-24 21:58:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch51_loss0.15756478533148766.pypots
2024-05-24 21:58:38 [INFO]: Epoch 052 - training loss: 0.1753, validation loss: 0.2171
2024-05-24 21:58:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch52_loss0.21714647114276886.pypots
2024-05-24 21:58:40 [INFO]: Epoch 053 - training loss: 0.2253, validation loss: 0.2112
2024-05-24 21:58:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch53_loss0.2111555114388466.pypots
2024-05-24 21:58:42 [INFO]: Epoch 054 - training loss: 0.2050, validation loss: 0.1877
2024-05-24 21:58:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch54_loss0.18765472993254662.pypots
2024-05-24 21:58:44 [INFO]: Epoch 055 - training loss: 0.1907, validation loss: 0.1718
2024-05-24 21:58:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch55_loss0.1718318574130535.pypots
2024-05-24 21:58:46 [INFO]: Epoch 056 - training loss: 0.2306, validation loss: 0.1852
2024-05-24 21:58:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch56_loss0.185228168964386.pypots
2024-05-24 21:58:48 [INFO]: Epoch 057 - training loss: 0.1798, validation loss: 0.1780
2024-05-24 21:58:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch57_loss0.1779668815433979.pypots
2024-05-24 21:58:50 [INFO]: Epoch 058 - training loss: 0.1794, validation loss: 0.1620
2024-05-24 21:58:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch58_loss0.16203754767775536.pypots
2024-05-24 21:58:52 [INFO]: Epoch 059 - training loss: 0.1716, validation loss: 0.1558
2024-05-24 21:58:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI_epoch59_loss0.15583909675478935.pypots
2024-05-24 21:58:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:58:52 [INFO]: Finished training. The best model is from epoch#49.
2024-05-24 21:58:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T215652/CSDI.pypots
2024-05-24 21:59:08 [INFO]: CSDI on ETTm1: MAE=0.1504, MSE=0.0554
2024-05-24 21:59:08 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/CSDI_ettm1/imputation.pkl
2024-05-24 21:59:08 [INFO]: Using the given device: cuda:0
2024-05-24 21:59:08 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/GPVAE_ettm1/20240524_T215908
2024-05-24 21:59:08 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/GPVAE_ettm1/20240524_T215908/tensorboard
2024-05-24 21:59:08 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 21:59:08 [INFO]: Epoch 001 - training loss: 23726.3550, validation loss: 0.9974
2024-05-24 21:59:09 [INFO]: Epoch 002 - training loss: 21574.4409, validation loss: 0.9897
2024-05-24 21:59:09 [INFO]: Epoch 003 - training loss: 19527.1632, validation loss: 0.9764
2024-05-24 21:59:09 [INFO]: Epoch 004 - training loss: 17422.5355, validation loss: 0.9527
2024-05-24 21:59:09 [INFO]: Epoch 005 - training loss: 15585.5972, validation loss: 0.8972
2024-05-24 21:59:09 [INFO]: Epoch 006 - training loss: 13932.8206, validation loss: 0.8007
2024-05-24 21:59:09 [INFO]: Epoch 007 - training loss: 12768.7628, validation loss: 0.6891
2024-05-24 21:59:09 [INFO]: Epoch 008 - training loss: 11959.6292, validation loss: 0.5858
2024-05-24 21:59:10 [INFO]: Epoch 009 - training loss: 11275.1926, validation loss: 0.5318
2024-05-24 21:59:10 [INFO]: Epoch 010 - training loss: 10935.5965, validation loss: 0.5089
2024-05-24 21:59:10 [INFO]: Epoch 011 - training loss: 10605.3005, validation loss: 0.4943
2024-05-24 21:59:10 [INFO]: Epoch 012 - training loss: 10435.1262, validation loss: 0.4992
2024-05-24 21:59:10 [INFO]: Epoch 013 - training loss: 10324.7122, validation loss: 0.4809
2024-05-24 21:59:10 [INFO]: Epoch 014 - training loss: 10171.5590, validation loss: 0.4659
2024-05-24 21:59:10 [INFO]: Epoch 015 - training loss: 10139.0735, validation loss: 0.4487
2024-05-24 21:59:10 [INFO]: Epoch 016 - training loss: 9939.8702, validation loss: 0.4324
2024-05-24 21:59:11 [INFO]: Epoch 017 - training loss: 9852.6149, validation loss: 0.4143
2024-05-24 21:59:11 [INFO]: Epoch 018 - training loss: 9805.1842, validation loss: 0.4009
2024-05-24 21:59:11 [INFO]: Epoch 019 - training loss: 9773.2759, validation loss: 0.3953
2024-05-24 21:59:11 [INFO]: Epoch 020 - training loss: 9708.6396, validation loss: 0.3630
2024-05-24 21:59:11 [INFO]: Epoch 021 - training loss: 9684.4033, validation loss: 0.3397
2024-05-24 21:59:11 [INFO]: Epoch 022 - training loss: 9665.6021, validation loss: 0.3201
2024-05-24 21:59:11 [INFO]: Epoch 023 - training loss: 9622.4075, validation loss: 0.2981
2024-05-24 21:59:12 [INFO]: Epoch 024 - training loss: 9624.5717, validation loss: 0.2748
2024-05-24 21:59:12 [INFO]: Epoch 025 - training loss: 9578.7631, validation loss: 0.2522
2024-05-24 21:59:12 [INFO]: Epoch 026 - training loss: 9559.9940, validation loss: 0.2326
2024-05-24 21:59:12 [INFO]: Epoch 027 - training loss: 9541.5844, validation loss: 0.2157
2024-05-24 21:59:12 [INFO]: Epoch 028 - training loss: 9523.0696, validation loss: 0.2045
2024-05-24 21:59:12 [INFO]: Epoch 029 - training loss: 9510.7410, validation loss: 0.1967
2024-05-24 21:59:12 [INFO]: Epoch 030 - training loss: 9498.7814, validation loss: 0.1906
2024-05-24 21:59:13 [INFO]: Epoch 031 - training loss: 9485.8754, validation loss: 0.1850
2024-05-24 21:59:13 [INFO]: Epoch 032 - training loss: 9479.5683, validation loss: 0.1817
2024-05-24 21:59:13 [INFO]: Epoch 033 - training loss: 9466.1301, validation loss: 0.1797
2024-05-24 21:59:13 [INFO]: Epoch 034 - training loss: 9460.6801, validation loss: 0.1734
2024-05-24 21:59:13 [INFO]: Epoch 035 - training loss: 9450.6319, validation loss: 0.1730
2024-05-24 21:59:13 [INFO]: Epoch 036 - training loss: 9441.9520, validation loss: 0.1712
2024-05-24 21:59:13 [INFO]: Epoch 037 - training loss: 9438.6541, validation loss: 0.1713
2024-05-24 21:59:13 [INFO]: Epoch 038 - training loss: 9432.1335, validation loss: 0.1669
2024-05-24 21:59:14 [INFO]: Epoch 039 - training loss: 9439.8687, validation loss: 0.1653
2024-05-24 21:59:14 [INFO]: Epoch 040 - training loss: 9429.1663, validation loss: 0.1663
2024-05-24 21:59:14 [INFO]: Epoch 041 - training loss: 9417.5941, validation loss: 0.1648
2024-05-24 21:59:14 [INFO]: Epoch 042 - training loss: 9414.2746, validation loss: 0.1612
2024-05-24 21:59:14 [INFO]: Epoch 043 - training loss: 9401.9892, validation loss: 0.1620
2024-05-24 21:59:14 [INFO]: Epoch 044 - training loss: 9402.1053, validation loss: 0.1604
2024-05-24 21:59:14 [INFO]: Epoch 045 - training loss: 9399.7830, validation loss: 0.1588
2024-05-24 21:59:15 [INFO]: Epoch 046 - training loss: 9392.5206, validation loss: 0.1578
2024-05-24 21:59:15 [INFO]: Epoch 047 - training loss: 9391.8580, validation loss: 0.1558
2024-05-24 21:59:15 [INFO]: Epoch 048 - training loss: 9385.8810, validation loss: 0.1558
2024-05-24 21:59:15 [INFO]: Epoch 049 - training loss: 9388.7400, validation loss: 0.1572
2024-05-24 21:59:15 [INFO]: Epoch 050 - training loss: 9382.1935, validation loss: 0.1531
2024-05-24 21:59:15 [INFO]: Epoch 051 - training loss: 9383.0343, validation loss: 0.1535
2024-05-24 21:59:15 [INFO]: Epoch 052 - training loss: 9374.8028, validation loss: 0.1550
2024-05-24 21:59:15 [INFO]: Epoch 053 - training loss: 9374.9260, validation loss: 0.1545
2024-05-24 21:59:16 [INFO]: Epoch 054 - training loss: 9371.7885, validation loss: 0.1501
2024-05-24 21:59:16 [INFO]: Epoch 055 - training loss: 9375.9287, validation loss: 0.1506
2024-05-24 21:59:16 [INFO]: Epoch 056 - training loss: 9367.8793, validation loss: 0.1494
2024-05-24 21:59:16 [INFO]: Epoch 057 - training loss: 9366.0344, validation loss: 0.1470
2024-05-24 21:59:16 [INFO]: Epoch 058 - training loss: 9366.4943, validation loss: 0.1466
2024-05-24 21:59:16 [INFO]: Epoch 059 - training loss: 9364.2096, validation loss: 0.1473
2024-05-24 21:59:16 [INFO]: Epoch 060 - training loss: 9362.1796, validation loss: 0.1454
2024-05-24 21:59:17 [INFO]: Epoch 061 - training loss: 9359.7770, validation loss: 0.1459
2024-05-24 21:59:17 [INFO]: Epoch 062 - training loss: 9355.5137, validation loss: 0.1440
2024-05-24 21:59:17 [INFO]: Epoch 063 - training loss: 9359.3980, validation loss: 0.1428
2024-05-24 21:59:17 [INFO]: Epoch 064 - training loss: 9358.8910, validation loss: 0.1432
2024-05-24 21:59:17 [INFO]: Epoch 065 - training loss: 9351.4361, validation loss: 0.1421
2024-05-24 21:59:17 [INFO]: Epoch 066 - training loss: 9354.9205, validation loss: 0.1404
2024-05-24 21:59:17 [INFO]: Epoch 067 - training loss: 9350.1417, validation loss: 0.1372
2024-05-24 21:59:17 [INFO]: Epoch 068 - training loss: 9353.6075, validation loss: 0.1380
2024-05-24 21:59:18 [INFO]: Epoch 069 - training loss: 9349.6397, validation loss: 0.1361
2024-05-24 21:59:18 [INFO]: Epoch 070 - training loss: 9347.0336, validation loss: 0.1350
2024-05-24 21:59:18 [INFO]: Epoch 071 - training loss: 9362.5040, validation loss: 0.1348
2024-05-24 21:59:18 [INFO]: Epoch 072 - training loss: 9343.4797, validation loss: 0.1325
2024-05-24 21:59:18 [INFO]: Epoch 073 - training loss: 9341.9193, validation loss: 0.1318
2024-05-24 21:59:18 [INFO]: Epoch 074 - training loss: 9341.3894, validation loss: 0.1298
2024-05-24 21:59:18 [INFO]: Epoch 075 - training loss: 9341.2582, validation loss: 0.1295
2024-05-24 21:59:19 [INFO]: Epoch 076 - training loss: 9345.6066, validation loss: 0.1292
2024-05-24 21:59:19 [INFO]: Epoch 077 - training loss: 9339.2536, validation loss: 0.1283
2024-05-24 21:59:19 [INFO]: Epoch 078 - training loss: 9350.1647, validation loss: 0.1268
2024-05-24 21:59:19 [INFO]: Epoch 079 - training loss: 9338.2605, validation loss: 0.1253
2024-05-24 21:59:19 [INFO]: Epoch 080 - training loss: 9338.3041, validation loss: 0.1251
2024-05-24 21:59:19 [INFO]: Epoch 081 - training loss: 9335.0801, validation loss: 0.1248
2024-05-24 21:59:19 [INFO]: Epoch 082 - training loss: 9334.0073, validation loss: 0.1258
2024-05-24 21:59:19 [INFO]: Epoch 083 - training loss: 9335.2885, validation loss: 0.1216
2024-05-24 21:59:20 [INFO]: Epoch 084 - training loss: 9334.8984, validation loss: 0.1232
2024-05-24 21:59:20 [INFO]: Epoch 085 - training loss: 9334.5679, validation loss: 0.1230
2024-05-24 21:59:20 [INFO]: Epoch 086 - training loss: 9331.1885, validation loss: 0.1219
2024-05-24 21:59:20 [INFO]: Epoch 087 - training loss: 9333.4742, validation loss: 0.1189
2024-05-24 21:59:20 [INFO]: Epoch 088 - training loss: 9331.7290, validation loss: 0.1199
2024-05-24 21:59:20 [INFO]: Epoch 089 - training loss: 9330.7960, validation loss: 0.1175
2024-05-24 21:59:20 [INFO]: Epoch 090 - training loss: 9332.1084, validation loss: 0.1172
2024-05-24 21:59:21 [INFO]: Epoch 091 - training loss: 9328.3907, validation loss: 0.1171
2024-05-24 21:59:21 [INFO]: Epoch 092 - training loss: 9327.4196, validation loss: 0.1158
2024-05-24 21:59:21 [INFO]: Epoch 093 - training loss: 9330.1981, validation loss: 0.1158
2024-05-24 21:59:21 [INFO]: Epoch 094 - training loss: 9328.2017, validation loss: 0.1160
2024-05-24 21:59:21 [INFO]: Epoch 095 - training loss: 9327.8697, validation loss: 0.1138
2024-05-24 21:59:21 [INFO]: Epoch 096 - training loss: 9325.4612, validation loss: 0.1116
2024-05-24 21:59:21 [INFO]: Epoch 097 - training loss: 9324.4394, validation loss: 0.1110
2024-05-24 21:59:22 [INFO]: Epoch 098 - training loss: 9328.7026, validation loss: 0.1118
2024-05-24 21:59:22 [INFO]: Epoch 099 - training loss: 9326.3625, validation loss: 0.1106
2024-05-24 21:59:22 [INFO]: Epoch 100 - training loss: 9323.4489, validation loss: 0.1108
2024-05-24 21:59:22 [INFO]: Epoch 101 - training loss: 9323.6378, validation loss: 0.1084
2024-05-24 21:59:22 [INFO]: Epoch 102 - training loss: 9323.1894, validation loss: 0.1078
2024-05-24 21:59:22 [INFO]: Epoch 103 - training loss: 9321.4618, validation loss: 0.1070
2024-05-24 21:59:22 [INFO]: Epoch 104 - training loss: 9321.8947, validation loss: 0.1081
2024-05-24 21:59:22 [INFO]: Epoch 105 - training loss: 9323.7676, validation loss: 0.1075
2024-05-24 21:59:23 [INFO]: Epoch 106 - training loss: 9322.5107, validation loss: 0.1063
2024-05-24 21:59:23 [INFO]: Epoch 107 - training loss: 9322.7841, validation loss: 0.1066
2024-05-24 21:59:23 [INFO]: Epoch 108 - training loss: 9321.2845, validation loss: 0.1054
2024-05-24 21:59:23 [INFO]: Epoch 109 - training loss: 9321.6282, validation loss: 0.1047
2024-05-24 21:59:23 [INFO]: Epoch 110 - training loss: 9320.0339, validation loss: 0.1044
2024-05-24 21:59:23 [INFO]: Epoch 111 - training loss: 9320.6952, validation loss: 0.1047
2024-05-24 21:59:23 [INFO]: Epoch 112 - training loss: 9318.6921, validation loss: 0.1046
2024-05-24 21:59:24 [INFO]: Epoch 113 - training loss: 9321.1946, validation loss: 0.1030
2024-05-24 21:59:24 [INFO]: Epoch 114 - training loss: 9317.8905, validation loss: 0.1016
2024-05-24 21:59:24 [INFO]: Epoch 115 - training loss: 9320.0164, validation loss: 0.1013
2024-05-24 21:59:24 [INFO]: Epoch 116 - training loss: 9318.0599, validation loss: 0.1010
2024-05-24 21:59:24 [INFO]: Epoch 117 - training loss: 9319.9756, validation loss: 0.0995
2024-05-24 21:59:24 [INFO]: Epoch 118 - training loss: 9318.4307, validation loss: 0.0984
2024-05-24 21:59:24 [INFO]: Epoch 119 - training loss: 9318.9263, validation loss: 0.0990
2024-05-24 21:59:24 [INFO]: Epoch 120 - training loss: 9317.3951, validation loss: 0.0995
2024-05-24 21:59:25 [INFO]: Epoch 121 - training loss: 9317.6345, validation loss: 0.0980
2024-05-24 21:59:25 [INFO]: Epoch 122 - training loss: 9316.4853, validation loss: 0.0972
2024-05-24 21:59:25 [INFO]: Epoch 123 - training loss: 9316.5057, validation loss: 0.0986
2024-05-24 21:59:25 [INFO]: Epoch 124 - training loss: 9316.2452, validation loss: 0.0965
2024-05-24 21:59:25 [INFO]: Epoch 125 - training loss: 9317.1810, validation loss: 0.0980
2024-05-24 21:59:25 [INFO]: Epoch 126 - training loss: 9316.7892, validation loss: 0.0976
2024-05-24 21:59:25 [INFO]: Epoch 127 - training loss: 9316.4069, validation loss: 0.0956
2024-05-24 21:59:26 [INFO]: Epoch 128 - training loss: 9314.1374, validation loss: 0.0944
2024-05-24 21:59:26 [INFO]: Epoch 129 - training loss: 9315.3879, validation loss: 0.0962
2024-05-24 21:59:26 [INFO]: Epoch 130 - training loss: 9315.0843, validation loss: 0.0953
2024-05-24 21:59:26 [INFO]: Epoch 131 - training loss: 9314.7016, validation loss: 0.0939
2024-05-24 21:59:26 [INFO]: Epoch 132 - training loss: 9314.2788, validation loss: 0.0942
2024-05-24 21:59:26 [INFO]: Epoch 133 - training loss: 9315.3557, validation loss: 0.0932
2024-05-24 21:59:26 [INFO]: Epoch 134 - training loss: 9312.9719, validation loss: 0.0930
2024-05-24 21:59:27 [INFO]: Epoch 135 - training loss: 9313.5336, validation loss: 0.0925
2024-05-24 21:59:27 [INFO]: Epoch 136 - training loss: 9312.8119, validation loss: 0.0911
2024-05-24 21:59:27 [INFO]: Epoch 137 - training loss: 9313.7974, validation loss: 0.0918
2024-05-24 21:59:27 [INFO]: Epoch 138 - training loss: 9313.2411, validation loss: 0.0929
2024-05-24 21:59:27 [INFO]: Epoch 139 - training loss: 9314.1708, validation loss: 0.0900
2024-05-24 21:59:27 [INFO]: Epoch 140 - training loss: 9314.2603, validation loss: 0.0896
2024-05-24 21:59:27 [INFO]: Epoch 141 - training loss: 9311.4820, validation loss: 0.0884
2024-05-24 21:59:27 [INFO]: Epoch 142 - training loss: 9312.4506, validation loss: 0.0904
2024-05-24 21:59:28 [INFO]: Epoch 143 - training loss: 9311.0594, validation loss: 0.0893
2024-05-24 21:59:28 [INFO]: Epoch 144 - training loss: 9311.3580, validation loss: 0.0897
2024-05-24 21:59:28 [INFO]: Epoch 145 - training loss: 9311.7547, validation loss: 0.0890
2024-05-24 21:59:28 [INFO]: Epoch 146 - training loss: 9311.9011, validation loss: 0.0899
2024-05-24 21:59:28 [INFO]: Epoch 147 - training loss: 9311.4107, validation loss: 0.0884
2024-05-24 21:59:28 [INFO]: Epoch 148 - training loss: 9311.2930, validation loss: 0.0881
2024-05-24 21:59:28 [INFO]: Epoch 149 - training loss: 9310.4289, validation loss: 0.0891
2024-05-24 21:59:29 [INFO]: Epoch 150 - training loss: 9309.8536, validation loss: 0.0871
2024-05-24 21:59:29 [INFO]: Epoch 151 - training loss: 9311.6339, validation loss: 0.0885
2024-05-24 21:59:29 [INFO]: Epoch 152 - training loss: 9310.6815, validation loss: 0.0874
2024-05-24 21:59:29 [INFO]: Epoch 153 - training loss: 9309.4949, validation loss: 0.0863
2024-05-24 21:59:29 [INFO]: Epoch 154 - training loss: 9312.5259, validation loss: 0.0881
2024-05-24 21:59:29 [INFO]: Epoch 155 - training loss: 9310.5758, validation loss: 0.0879
2024-05-24 21:59:29 [INFO]: Epoch 156 - training loss: 9309.9400, validation loss: 0.0878
2024-05-24 21:59:30 [INFO]: Epoch 157 - training loss: 9312.6104, validation loss: 0.0874
2024-05-24 21:59:30 [INFO]: Epoch 158 - training loss: 9309.8094, validation loss: 0.0866
2024-05-24 21:59:30 [INFO]: Epoch 159 - training loss: 9308.3831, validation loss: 0.0850
2024-05-24 21:59:30 [INFO]: Epoch 160 - training loss: 9311.0052, validation loss: 0.0861
2024-05-24 21:59:30 [INFO]: Epoch 161 - training loss: 9309.5196, validation loss: 0.0845
2024-05-24 21:59:30 [INFO]: Epoch 162 - training loss: 9309.2213, validation loss: 0.0846
2024-05-24 21:59:30 [INFO]: Epoch 163 - training loss: 9310.3850, validation loss: 0.0830
2024-05-24 21:59:30 [INFO]: Epoch 164 - training loss: 9309.7941, validation loss: 0.0835
2024-05-24 21:59:31 [INFO]: Epoch 165 - training loss: 9308.9750, validation loss: 0.0845
2024-05-24 21:59:31 [INFO]: Epoch 166 - training loss: 9308.0197, validation loss: 0.0840
2024-05-24 21:59:31 [INFO]: Epoch 167 - training loss: 9309.4967, validation loss: 0.0830
2024-05-24 21:59:31 [INFO]: Epoch 168 - training loss: 9307.8647, validation loss: 0.0826
2024-05-24 21:59:31 [INFO]: Epoch 169 - training loss: 9308.0042, validation loss: 0.0830
2024-05-24 21:59:31 [INFO]: Epoch 170 - training loss: 9309.1978, validation loss: 0.0814
2024-05-24 21:59:31 [INFO]: Epoch 171 - training loss: 9307.8827, validation loss: 0.0822
2024-05-24 21:59:32 [INFO]: Epoch 172 - training loss: 9307.7173, validation loss: 0.0827
2024-05-24 21:59:32 [INFO]: Epoch 173 - training loss: 9307.6111, validation loss: 0.0812
2024-05-24 21:59:32 [INFO]: Epoch 174 - training loss: 9307.8966, validation loss: 0.0819
2024-05-24 21:59:32 [INFO]: Epoch 175 - training loss: 9307.2757, validation loss: 0.0823
2024-05-24 21:59:32 [INFO]: Epoch 176 - training loss: 9307.6973, validation loss: 0.0801
2024-05-24 21:59:32 [INFO]: Epoch 177 - training loss: 9307.1190, validation loss: 0.0798
2024-05-24 21:59:32 [INFO]: Epoch 178 - training loss: 9307.1319, validation loss: 0.0809
2024-05-24 21:59:32 [INFO]: Epoch 179 - training loss: 9306.5574, validation loss: 0.0813
2024-05-24 21:59:33 [INFO]: Epoch 180 - training loss: 9307.5266, validation loss: 0.0801
2024-05-24 21:59:33 [INFO]: Epoch 181 - training loss: 9309.8560, validation loss: 0.0822
2024-05-24 21:59:33 [INFO]: Epoch 182 - training loss: 9305.9874, validation loss: 0.0805
2024-05-24 21:59:33 [INFO]: Epoch 183 - training loss: 9307.9400, validation loss: 0.0787
2024-05-24 21:59:33 [INFO]: Epoch 184 - training loss: 9306.4832, validation loss: 0.0794
2024-05-24 21:59:33 [INFO]: Epoch 185 - training loss: 9306.3775, validation loss: 0.0805
2024-05-24 21:59:33 [INFO]: Epoch 186 - training loss: 9305.6491, validation loss: 0.0799
2024-05-24 21:59:34 [INFO]: Epoch 187 - training loss: 9306.0825, validation loss: 0.0782
2024-05-24 21:59:34 [INFO]: Epoch 188 - training loss: 9305.3668, validation loss: 0.0790
2024-05-24 21:59:34 [INFO]: Epoch 189 - training loss: 9306.0543, validation loss: 0.0798
2024-05-24 21:59:34 [INFO]: Epoch 190 - training loss: 9305.8848, validation loss: 0.0789
2024-05-24 21:59:34 [INFO]: Epoch 191 - training loss: 9307.6176, validation loss: 0.0789
2024-05-24 21:59:34 [INFO]: Epoch 192 - training loss: 9306.2371, validation loss: 0.0785
2024-05-24 21:59:34 [INFO]: Epoch 193 - training loss: 9305.5830, validation loss: 0.0785
2024-05-24 21:59:34 [INFO]: Epoch 194 - training loss: 9306.4785, validation loss: 0.0775
2024-05-24 21:59:35 [INFO]: Epoch 195 - training loss: 9305.9980, validation loss: 0.0766
2024-05-24 21:59:35 [INFO]: Epoch 196 - training loss: 9308.0236, validation loss: 0.0775
2024-05-24 21:59:35 [INFO]: Epoch 197 - training loss: 9305.3981, validation loss: 0.0771
2024-05-24 21:59:35 [INFO]: Epoch 198 - training loss: 9307.7541, validation loss: 0.0771
2024-05-24 21:59:35 [INFO]: Epoch 199 - training loss: 9305.8531, validation loss: 0.0764
2024-05-24 21:59:35 [INFO]: Epoch 200 - training loss: 9306.0208, validation loss: 0.0768
2024-05-24 21:59:35 [INFO]: Epoch 201 - training loss: 9306.3011, validation loss: 0.0776
2024-05-24 21:59:36 [INFO]: Epoch 202 - training loss: 9305.2316, validation loss: 0.0768
2024-05-24 21:59:36 [INFO]: Epoch 203 - training loss: 9304.6198, validation loss: 0.0768
2024-05-24 21:59:36 [INFO]: Epoch 204 - training loss: 9304.7693, validation loss: 0.0759
2024-05-24 21:59:36 [INFO]: Epoch 205 - training loss: 9304.2295, validation loss: 0.0772
2024-05-24 21:59:36 [INFO]: Epoch 206 - training loss: 9304.0517, validation loss: 0.0766
2024-05-24 21:59:36 [INFO]: Epoch 207 - training loss: 9304.2725, validation loss: 0.0762
2024-05-24 21:59:36 [INFO]: Epoch 208 - training loss: 9304.9797, validation loss: 0.0761
2024-05-24 21:59:37 [INFO]: Epoch 209 - training loss: 9304.7426, validation loss: 0.0754
2024-05-24 21:59:37 [INFO]: Epoch 210 - training loss: 9304.0969, validation loss: 0.0776
2024-05-24 21:59:37 [INFO]: Epoch 211 - training loss: 9305.5554, validation loss: 0.0759
2024-05-24 21:59:37 [INFO]: Epoch 212 - training loss: 9306.6088, validation loss: 0.0756
2024-05-24 21:59:37 [INFO]: Epoch 213 - training loss: 9305.5908, validation loss: 0.0764
2024-05-24 21:59:37 [INFO]: Epoch 214 - training loss: 9305.0594, validation loss: 0.0750
2024-05-24 21:59:37 [INFO]: Epoch 215 - training loss: 9303.6689, validation loss: 0.0759
2024-05-24 21:59:37 [INFO]: Epoch 216 - training loss: 9304.6517, validation loss: 0.0760
2024-05-24 21:59:38 [INFO]: Epoch 217 - training loss: 9304.1414, validation loss: 0.0759
2024-05-24 21:59:38 [INFO]: Epoch 218 - training loss: 9303.9039, validation loss: 0.0739
2024-05-24 21:59:38 [INFO]: Epoch 219 - training loss: 9304.6794, validation loss: 0.0748
2024-05-24 21:59:38 [INFO]: Epoch 220 - training loss: 9303.5323, validation loss: 0.0761
2024-05-24 21:59:38 [INFO]: Epoch 221 - training loss: 9304.6412, validation loss: 0.0744
2024-05-24 21:59:38 [INFO]: Epoch 222 - training loss: 9303.8401, validation loss: 0.0761
2024-05-24 21:59:38 [INFO]: Epoch 223 - training loss: 9302.8359, validation loss: 0.0755
2024-05-24 21:59:39 [INFO]: Epoch 224 - training loss: 9303.6476, validation loss: 0.0753
2024-05-24 21:59:39 [INFO]: Epoch 225 - training loss: 9304.5112, validation loss: 0.0746
2024-05-24 21:59:39 [INFO]: Epoch 226 - training loss: 9304.6894, validation loss: 0.0753
2024-05-24 21:59:39 [INFO]: Epoch 227 - training loss: 9303.2955, validation loss: 0.0727
2024-05-24 21:59:39 [INFO]: Epoch 228 - training loss: 9302.4867, validation loss: 0.0740
2024-05-24 21:59:39 [INFO]: Epoch 229 - training loss: 9304.0524, validation loss: 0.0757
2024-05-24 21:59:39 [INFO]: Epoch 230 - training loss: 9302.8460, validation loss: 0.0757
2024-05-24 21:59:40 [INFO]: Epoch 231 - training loss: 9303.6686, validation loss: 0.0745
2024-05-24 21:59:40 [INFO]: Epoch 232 - training loss: 9303.0667, validation loss: 0.0737
2024-05-24 21:59:40 [INFO]: Epoch 233 - training loss: 9303.0284, validation loss: 0.0732
2024-05-24 21:59:40 [INFO]: Epoch 234 - training loss: 9303.1271, validation loss: 0.0732
2024-05-24 21:59:40 [INFO]: Epoch 235 - training loss: 9301.7726, validation loss: 0.0731
2024-05-24 21:59:40 [INFO]: Epoch 236 - training loss: 9302.5104, validation loss: 0.0746
2024-05-24 21:59:40 [INFO]: Epoch 237 - training loss: 9304.3572, validation loss: 0.0736
2024-05-24 21:59:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:59:40 [INFO]: Finished training. The best model is from epoch#227.
2024-05-24 21:59:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/GPVAE_ettm1/20240524_T215908/GPVAE.pypots
2024-05-24 21:59:40 [INFO]: GP-VAE on ETTm1: MAE=0.2675, MSE=0.1527
2024-05-24 21:59:40 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/GPVAE_ettm1/imputation.pkl
2024-05-24 21:59:40 [INFO]: Using the given device: cuda:0
2024-05-24 21:59:40 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/USGAN_ettm1/20240524_T215940
2024-05-24 21:59:40 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/USGAN_ettm1/20240524_T215940/tensorboard
2024-05-24 21:59:40 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 21:59:51 [INFO]: Epoch 001 - generator training loss: 0.5592, discriminator training loss: 0.3241, validation loss: 0.3287
2024-05-24 22:00:00 [INFO]: Epoch 002 - generator training loss: 0.0432, discriminator training loss: 0.2049, validation loss: 0.0913
2024-05-24 22:00:09 [INFO]: Epoch 003 - generator training loss: -0.0696, discriminator training loss: 0.1965, validation loss: 0.0520
2024-05-24 22:00:17 [INFO]: Epoch 004 - generator training loss: -0.0865, discriminator training loss: 0.1943, validation loss: 0.0441
2024-05-24 22:00:26 [INFO]: Epoch 005 - generator training loss: -0.0879, discriminator training loss: 0.1911, validation loss: 0.0400
2024-05-24 22:00:35 [INFO]: Epoch 006 - generator training loss: -0.0817, discriminator training loss: 0.1845, validation loss: 0.0380
2024-05-24 22:00:44 [INFO]: Epoch 007 - generator training loss: -0.0848, discriminator training loss: 0.1828, validation loss: 0.0353
2024-05-24 22:00:53 [INFO]: Epoch 008 - generator training loss: -0.0778, discriminator training loss: 0.1734, validation loss: 0.0346
2024-05-24 22:01:02 [INFO]: Epoch 009 - generator training loss: -0.0698, discriminator training loss: 0.1620, validation loss: 0.0345
2024-05-24 22:01:10 [INFO]: Epoch 010 - generator training loss: -0.0590, discriminator training loss: 0.1492, validation loss: 0.0331
2024-05-24 22:01:19 [INFO]: Epoch 011 - generator training loss: -0.0476, discriminator training loss: 0.1377, validation loss: 0.0334
2024-05-24 22:01:28 [INFO]: Epoch 012 - generator training loss: -0.0345, discriminator training loss: 0.1222, validation loss: 0.0319
2024-05-24 22:01:37 [INFO]: Epoch 013 - generator training loss: -0.0279, discriminator training loss: 0.1080, validation loss: 0.0318
2024-05-24 22:01:45 [INFO]: Epoch 014 - generator training loss: -0.0214, discriminator training loss: 0.0998, validation loss: 0.0316
2024-05-24 22:01:54 [INFO]: Epoch 015 - generator training loss: -0.0183, discriminator training loss: 0.0913, validation loss: 0.0306
2024-05-24 22:02:03 [INFO]: Epoch 016 - generator training loss: -0.0155, discriminator training loss: 0.0886, validation loss: 0.0301
2024-05-24 22:02:12 [INFO]: Epoch 017 - generator training loss: -0.0138, discriminator training loss: 0.0852, validation loss: 0.0298
2024-05-24 22:02:21 [INFO]: Epoch 018 - generator training loss: -0.0136, discriminator training loss: 0.0804, validation loss: 0.0291
2024-05-24 22:02:29 [INFO]: Epoch 019 - generator training loss: -0.0152, discriminator training loss: 0.0789, validation loss: 0.0295
2024-05-24 22:02:38 [INFO]: Epoch 020 - generator training loss: -0.0119, discriminator training loss: 0.0787, validation loss: 0.0288
2024-05-24 22:02:47 [INFO]: Epoch 021 - generator training loss: -0.0154, discriminator training loss: 0.0758, validation loss: 0.0287
2024-05-24 22:02:56 [INFO]: Epoch 022 - generator training loss: -0.0116, discriminator training loss: 0.0759, validation loss: 0.0288
2024-05-24 22:03:05 [INFO]: Epoch 023 - generator training loss: -0.0118, discriminator training loss: 0.0768, validation loss: 0.0285
2024-05-24 22:03:14 [INFO]: Epoch 024 - generator training loss: -0.0128, discriminator training loss: 0.0749, validation loss: 0.0282
2024-05-24 22:03:22 [INFO]: Epoch 025 - generator training loss: -0.0153, discriminator training loss: 0.0736, validation loss: 0.0284
2024-05-24 22:03:32 [INFO]: Epoch 026 - generator training loss: -0.0131, discriminator training loss: 0.0745, validation loss: 0.0275
2024-05-24 22:03:41 [INFO]: Epoch 027 - generator training loss: -0.0149, discriminator training loss: 0.0711, validation loss: 0.0265
2024-05-24 22:03:50 [INFO]: Epoch 028 - generator training loss: -0.0177, discriminator training loss: 0.0738, validation loss: 0.0260
2024-05-24 22:03:59 [INFO]: Epoch 029 - generator training loss: -0.0168, discriminator training loss: 0.0717, validation loss: 0.0256
2024-05-24 22:04:08 [INFO]: Epoch 030 - generator training loss: -0.0176, discriminator training loss: 0.0716, validation loss: 0.0253
2024-05-24 22:04:17 [INFO]: Epoch 031 - generator training loss: -0.0151, discriminator training loss: 0.0742, validation loss: 0.0254
2024-05-24 22:04:26 [INFO]: Epoch 032 - generator training loss: -0.0149, discriminator training loss: 0.0706, validation loss: 0.0261
2024-05-24 22:04:35 [INFO]: Epoch 033 - generator training loss: -0.0153, discriminator training loss: 0.0716, validation loss: 0.0255
2024-05-24 22:04:44 [INFO]: Epoch 034 - generator training loss: -0.0173, discriminator training loss: 0.0713, validation loss: 0.0248
2024-05-24 22:04:53 [INFO]: Epoch 035 - generator training loss: -0.0146, discriminator training loss: 0.0688, validation loss: 0.0244
2024-05-24 22:05:02 [INFO]: Epoch 036 - generator training loss: -0.0171, discriminator training loss: 0.0712, validation loss: 0.0239
2024-05-24 22:05:11 [INFO]: Epoch 037 - generator training loss: -0.0161, discriminator training loss: 0.0693, validation loss: 0.0237
2024-05-24 22:05:20 [INFO]: Epoch 038 - generator training loss: -0.0188, discriminator training loss: 0.0692, validation loss: 0.0235
2024-05-24 22:05:29 [INFO]: Epoch 039 - generator training loss: -0.0162, discriminator training loss: 0.0704, validation loss: 0.0233
2024-05-24 22:05:39 [INFO]: Epoch 040 - generator training loss: -0.0173, discriminator training loss: 0.0685, validation loss: 0.0231
2024-05-24 22:05:48 [INFO]: Epoch 041 - generator training loss: -0.0187, discriminator training loss: 0.0709, validation loss: 0.0232
2024-05-24 22:05:57 [INFO]: Epoch 042 - generator training loss: -0.0184, discriminator training loss: 0.0692, validation loss: 0.0230
2024-05-24 22:06:06 [INFO]: Epoch 043 - generator training loss: -0.0163, discriminator training loss: 0.0683, validation loss: 0.0231
2024-05-24 22:06:15 [INFO]: Epoch 044 - generator training loss: -0.0195, discriminator training loss: 0.0700, validation loss: 0.0233
2024-05-24 22:06:24 [INFO]: Epoch 045 - generator training loss: -0.0211, discriminator training loss: 0.0716, validation loss: 0.0229
2024-05-24 22:06:33 [INFO]: Epoch 046 - generator training loss: -0.0179, discriminator training loss: 0.0702, validation loss: 0.0228
2024-05-24 22:06:42 [INFO]: Epoch 047 - generator training loss: -0.0165, discriminator training loss: 0.0701, validation loss: 0.0224
2024-05-24 22:06:51 [INFO]: Epoch 048 - generator training loss: -0.0177, discriminator training loss: 0.0675, validation loss: 0.0223
2024-05-24 22:07:01 [INFO]: Epoch 049 - generator training loss: -0.0209, discriminator training loss: 0.0679, validation loss: 0.0222
2024-05-24 22:07:10 [INFO]: Epoch 050 - generator training loss: -0.0180, discriminator training loss: 0.0676, validation loss: 0.0234
2024-05-24 22:07:19 [INFO]: Epoch 051 - generator training loss: -0.0189, discriminator training loss: 0.0692, validation loss: 0.0224
2024-05-24 22:07:28 [INFO]: Epoch 052 - generator training loss: -0.0188, discriminator training loss: 0.0683, validation loss: 0.0224
2024-05-24 22:07:37 [INFO]: Epoch 053 - generator training loss: -0.0212, discriminator training loss: 0.0690, validation loss: 0.0229
2024-05-24 22:07:46 [INFO]: Epoch 054 - generator training loss: -0.0196, discriminator training loss: 0.0693, validation loss: 0.0220
2024-05-24 22:07:55 [INFO]: Epoch 055 - generator training loss: -0.0213, discriminator training loss: 0.0681, validation loss: 0.0216
2024-05-24 22:08:04 [INFO]: Epoch 056 - generator training loss: -0.0190, discriminator training loss: 0.0677, validation loss: 0.0214
2024-05-24 22:08:13 [INFO]: Epoch 057 - generator training loss: -0.0208, discriminator training loss: 0.0698, validation loss: 0.0221
2024-05-24 22:08:22 [INFO]: Epoch 058 - generator training loss: -0.0180, discriminator training loss: 0.0683, validation loss: 0.0214
2024-05-24 22:08:31 [INFO]: Epoch 059 - generator training loss: -0.0200, discriminator training loss: 0.0675, validation loss: 0.0219
2024-05-24 22:08:40 [INFO]: Epoch 060 - generator training loss: -0.0196, discriminator training loss: 0.0675, validation loss: 0.0208
2024-05-24 22:08:49 [INFO]: Epoch 061 - generator training loss: -0.0228, discriminator training loss: 0.0667, validation loss: 0.0214
2024-05-24 22:08:58 [INFO]: Epoch 062 - generator training loss: -0.0217, discriminator training loss: 0.0686, validation loss: 0.0207
2024-05-24 22:09:07 [INFO]: Epoch 063 - generator training loss: -0.0191, discriminator training loss: 0.0676, validation loss: 0.0211
2024-05-24 22:09:16 [INFO]: Epoch 064 - generator training loss: -0.0207, discriminator training loss: 0.0670, validation loss: 0.0207
2024-05-24 22:09:25 [INFO]: Epoch 065 - generator training loss: -0.0205, discriminator training loss: 0.0686, validation loss: 0.0206
2024-05-24 22:09:34 [INFO]: Epoch 066 - generator training loss: -0.0211, discriminator training loss: 0.0668, validation loss: 0.0204
2024-05-24 22:09:44 [INFO]: Epoch 067 - generator training loss: -0.0174, discriminator training loss: 0.0683, validation loss: 0.0221
2024-05-24 22:09:53 [INFO]: Epoch 068 - generator training loss: -0.0207, discriminator training loss: 0.0683, validation loss: 0.0220
2024-05-24 22:10:02 [INFO]: Epoch 069 - generator training loss: -0.0190, discriminator training loss: 0.0659, validation loss: 0.0215
2024-05-24 22:10:11 [INFO]: Epoch 070 - generator training loss: -0.0201, discriminator training loss: 0.0670, validation loss: 0.0209
2024-05-24 22:10:20 [INFO]: Epoch 071 - generator training loss: -0.0214, discriminator training loss: 0.0670, validation loss: 0.0207
2024-05-24 22:10:29 [INFO]: Epoch 072 - generator training loss: -0.0230, discriminator training loss: 0.0678, validation loss: 0.0206
2024-05-24 22:10:38 [INFO]: Epoch 073 - generator training loss: -0.0213, discriminator training loss: 0.0679, validation loss: 0.0205
2024-05-24 22:10:47 [INFO]: Epoch 074 - generator training loss: -0.0209, discriminator training loss: 0.0670, validation loss: 0.0202
2024-05-24 22:10:56 [INFO]: Epoch 075 - generator training loss: -0.0219, discriminator training loss: 0.0674, validation loss: 0.0205
2024-05-24 22:11:05 [INFO]: Epoch 076 - generator training loss: -0.0205, discriminator training loss: 0.0672, validation loss: 0.0205
2024-05-24 22:11:14 [INFO]: Epoch 077 - generator training loss: -0.0219, discriminator training loss: 0.0666, validation loss: 0.0202
2024-05-24 22:11:23 [INFO]: Epoch 078 - generator training loss: -0.0213, discriminator training loss: 0.0666, validation loss: 0.0203
2024-05-24 22:11:32 [INFO]: Epoch 079 - generator training loss: -0.0228, discriminator training loss: 0.0665, validation loss: 0.0206
2024-05-24 22:11:41 [INFO]: Epoch 080 - generator training loss: -0.0223, discriminator training loss: 0.0659, validation loss: 0.0202
2024-05-24 22:11:50 [INFO]: Epoch 081 - generator training loss: -0.0217, discriminator training loss: 0.0673, validation loss: 0.0202
2024-05-24 22:12:00 [INFO]: Epoch 082 - generator training loss: -0.0234, discriminator training loss: 0.0680, validation loss: 0.0200
2024-05-24 22:12:09 [INFO]: Epoch 083 - generator training loss: -0.0208, discriminator training loss: 0.0672, validation loss: 0.0200
2024-05-24 22:12:18 [INFO]: Epoch 084 - generator training loss: -0.0218, discriminator training loss: 0.0670, validation loss: 0.0199
2024-05-24 22:12:27 [INFO]: Epoch 085 - generator training loss: -0.0234, discriminator training loss: 0.0655, validation loss: 0.0196
2024-05-24 22:12:36 [INFO]: Epoch 086 - generator training loss: -0.0235, discriminator training loss: 0.0653, validation loss: 0.0197
2024-05-24 22:12:45 [INFO]: Epoch 087 - generator training loss: -0.0240, discriminator training loss: 0.0663, validation loss: 0.0194
2024-05-24 22:12:54 [INFO]: Epoch 088 - generator training loss: -0.0214, discriminator training loss: 0.0680, validation loss: 0.0198
2024-05-24 22:13:03 [INFO]: Epoch 089 - generator training loss: -0.0220, discriminator training loss: 0.0660, validation loss: 0.0196
2024-05-24 22:13:12 [INFO]: Epoch 090 - generator training loss: -0.0236, discriminator training loss: 0.0673, validation loss: 0.0193
2024-05-24 22:13:21 [INFO]: Epoch 091 - generator training loss: -0.0228, discriminator training loss: 0.0674, validation loss: 0.0197
2024-05-24 22:13:31 [INFO]: Epoch 092 - generator training loss: -0.0235, discriminator training loss: 0.0677, validation loss: 0.0202
2024-05-24 22:13:39 [INFO]: Epoch 093 - generator training loss: -0.0225, discriminator training loss: 0.0668, validation loss: 0.0193
2024-05-24 22:13:48 [INFO]: Epoch 094 - generator training loss: -0.0236, discriminator training loss: 0.0661, validation loss: 0.0189
2024-05-24 22:13:57 [INFO]: Epoch 095 - generator training loss: -0.0247, discriminator training loss: 0.0683, validation loss: 0.0198
2024-05-24 22:14:06 [INFO]: Epoch 096 - generator training loss: -0.0233, discriminator training loss: 0.0685, validation loss: 0.0194
2024-05-24 22:14:15 [INFO]: Epoch 097 - generator training loss: -0.0244, discriminator training loss: 0.0640, validation loss: 0.0188
2024-05-24 22:14:24 [INFO]: Epoch 098 - generator training loss: -0.0271, discriminator training loss: 0.0668, validation loss: 0.0207
2024-05-24 22:14:33 [INFO]: Epoch 099 - generator training loss: -0.0241, discriminator training loss: 0.0649, validation loss: 0.0218
2024-05-24 22:14:42 [INFO]: Epoch 100 - generator training loss: -0.0254, discriminator training loss: 0.0676, validation loss: 0.0197
2024-05-24 22:14:51 [INFO]: Epoch 101 - generator training loss: -0.0253, discriminator training loss: 0.0674, validation loss: 0.0189
2024-05-24 22:15:00 [INFO]: Epoch 102 - generator training loss: -0.0238, discriminator training loss: 0.0666, validation loss: 0.0190
2024-05-24 22:15:09 [INFO]: Epoch 103 - generator training loss: -0.0269, discriminator training loss: 0.0649, validation loss: 0.0186
2024-05-24 22:15:18 [INFO]: Epoch 104 - generator training loss: -0.0255, discriminator training loss: 0.0658, validation loss: 0.0187
2024-05-24 22:15:27 [INFO]: Epoch 105 - generator training loss: -0.0243, discriminator training loss: 0.0653, validation loss: 0.0184
2024-05-24 22:15:36 [INFO]: Epoch 106 - generator training loss: -0.0256, discriminator training loss: 0.0658, validation loss: 0.0181
2024-05-24 22:15:46 [INFO]: Epoch 107 - generator training loss: -0.0260, discriminator training loss: 0.0665, validation loss: 0.0184
2024-05-24 22:15:55 [INFO]: Epoch 108 - generator training loss: -0.0276, discriminator training loss: 0.0663, validation loss: 0.0187
2024-05-24 22:16:04 [INFO]: Epoch 109 - generator training loss: -0.0263, discriminator training loss: 0.0666, validation loss: 0.0185
2024-05-24 22:16:13 [INFO]: Epoch 110 - generator training loss: -0.0286, discriminator training loss: 0.0658, validation loss: 0.0185
2024-05-24 22:16:22 [INFO]: Epoch 111 - generator training loss: -0.0251, discriminator training loss: 0.0646, validation loss: 0.0195
2024-05-24 22:16:31 [INFO]: Epoch 112 - generator training loss: -0.0286, discriminator training loss: 0.0654, validation loss: 0.0176
2024-05-24 22:16:40 [INFO]: Epoch 113 - generator training loss: -0.0245, discriminator training loss: 0.0668, validation loss: 0.0189
2024-05-24 22:16:49 [INFO]: Epoch 114 - generator training loss: -0.0260, discriminator training loss: 0.0653, validation loss: 0.0183
2024-05-24 22:16:58 [INFO]: Epoch 115 - generator training loss: -0.0292, discriminator training loss: 0.0663, validation loss: 0.0180
2024-05-24 22:17:07 [INFO]: Epoch 116 - generator training loss: -0.0265, discriminator training loss: 0.0668, validation loss: 0.0181
2024-05-24 22:17:16 [INFO]: Epoch 117 - generator training loss: -0.0276, discriminator training loss: 0.0675, validation loss: 0.0182
2024-05-24 22:17:25 [INFO]: Epoch 118 - generator training loss: -0.0268, discriminator training loss: 0.0660, validation loss: 0.0182
2024-05-24 22:17:34 [INFO]: Epoch 119 - generator training loss: -0.0266, discriminator training loss: 0.0658, validation loss: 0.0183
2024-05-24 22:17:43 [INFO]: Epoch 120 - generator training loss: -0.0276, discriminator training loss: 0.0654, validation loss: 0.0187
2024-05-24 22:17:53 [INFO]: Epoch 121 - generator training loss: -0.0255, discriminator training loss: 0.0654, validation loss: 0.0189
2024-05-24 22:18:02 [INFO]: Epoch 122 - generator training loss: -0.0286, discriminator training loss: 0.0653, validation loss: 0.0180
2024-05-24 22:18:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:18:02 [INFO]: Finished training. The best model is from epoch#112.
2024-05-24 22:18:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/USGAN_ettm1/20240524_T215940/USGAN.pypots
2024-05-24 22:18:03 [INFO]: US-GAN on ETTm1: MAE=0.1301, MSE=0.0450
2024-05-24 22:18:03 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/USGAN_ettm1/imputation.pkl
2024-05-24 22:18:03 [INFO]: Using the given device: cuda:0
2024-05-24 22:18:03 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/BRITS_ettm1/20240524_T221803
2024-05-24 22:18:03 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/BRITS_ettm1/20240524_T221803/tensorboard
2024-05-24 22:18:03 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 22:18:10 [INFO]: Epoch 001 - training loss: 1.3019, validation loss: 0.2913
2024-05-24 22:18:16 [INFO]: Epoch 002 - training loss: 0.8659, validation loss: 0.0836
2024-05-24 22:18:22 [INFO]: Epoch 003 - training loss: 0.7463, validation loss: 0.0610
2024-05-24 22:18:28 [INFO]: Epoch 004 - training loss: 0.6433, validation loss: 0.0506
2024-05-24 22:18:34 [INFO]: Epoch 005 - training loss: 0.5867, validation loss: 0.0436
2024-05-24 22:18:40 [INFO]: Epoch 006 - training loss: 0.5497, validation loss: 0.0380
2024-05-24 22:18:46 [INFO]: Epoch 007 - training loss: 0.5316, validation loss: 0.0348
2024-05-24 22:18:53 [INFO]: Epoch 008 - training loss: 0.5146, validation loss: 0.0353
2024-05-24 22:18:59 [INFO]: Epoch 009 - training loss: 0.4907, validation loss: 0.0311
2024-05-24 22:19:05 [INFO]: Epoch 010 - training loss: 0.4667, validation loss: 0.0298
2024-05-24 22:19:11 [INFO]: Epoch 011 - training loss: 0.4429, validation loss: 0.0282
2024-05-24 22:19:17 [INFO]: Epoch 012 - training loss: 0.4379, validation loss: 0.0270
2024-05-24 22:19:23 [INFO]: Epoch 013 - training loss: 0.4334, validation loss: 0.0267
2024-05-24 22:19:29 [INFO]: Epoch 014 - training loss: 0.4218, validation loss: 0.0255
2024-05-24 22:19:35 [INFO]: Epoch 015 - training loss: 0.4092, validation loss: 0.0250
2024-05-24 22:19:41 [INFO]: Epoch 016 - training loss: 0.4126, validation loss: 0.0241
2024-05-24 22:19:47 [INFO]: Epoch 017 - training loss: 0.4092, validation loss: 0.0236
2024-05-24 22:19:53 [INFO]: Epoch 018 - training loss: 0.3942, validation loss: 0.0236
2024-05-24 22:19:59 [INFO]: Epoch 019 - training loss: 0.3951, validation loss: 0.0233
2024-05-24 22:20:05 [INFO]: Epoch 020 - training loss: 0.3875, validation loss: 0.0225
2024-05-24 22:20:11 [INFO]: Epoch 021 - training loss: 0.3859, validation loss: 0.0229
2024-05-24 22:20:17 [INFO]: Epoch 022 - training loss: 0.3834, validation loss: 0.0225
2024-05-24 22:20:23 [INFO]: Epoch 023 - training loss: 0.3825, validation loss: 0.0229
2024-05-24 22:20:29 [INFO]: Epoch 024 - training loss: 0.3848, validation loss: 0.0228
2024-05-24 22:20:35 [INFO]: Epoch 025 - training loss: 0.4419, validation loss: 0.0231
2024-05-24 22:20:41 [INFO]: Epoch 026 - training loss: 0.4082, validation loss: 0.0248
2024-05-24 22:20:47 [INFO]: Epoch 027 - training loss: 0.4224, validation loss: 0.0242
2024-05-24 22:20:53 [INFO]: Epoch 028 - training loss: 0.3919, validation loss: 0.0225
2024-05-24 22:20:59 [INFO]: Epoch 029 - training loss: 0.3857, validation loss: 0.0230
2024-05-24 22:21:05 [INFO]: Epoch 030 - training loss: 0.3831, validation loss: 0.0238
2024-05-24 22:21:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:21:05 [INFO]: Finished training. The best model is from epoch#20.
2024-05-24 22:21:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/BRITS_ettm1/20240524_T221803/BRITS.pypots
2024-05-24 22:21:06 [INFO]: BRITS on ETTm1: MAE=0.1397, MSE=0.0595
2024-05-24 22:21:06 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/BRITS_ettm1/imputation.pkl
2024-05-24 22:21:06 [INFO]: Using the given device: cuda:0
2024-05-24 22:21:06 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106
2024-05-24 22:21:06 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/tensorboard
2024-05-24 22:21:06 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 22:21:08 [INFO]: Epoch 001 - training loss: 1.4325, validation loss: 1.3079
2024-05-24 22:21:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch1_loss1.3079125732183456.pypots
2024-05-24 22:21:08 [INFO]: Epoch 002 - training loss: 1.0667, validation loss: 1.1337
2024-05-24 22:21:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch2_loss1.133692279458046.pypots
2024-05-24 22:21:08 [INFO]: Epoch 003 - training loss: 0.9777, validation loss: 1.0649
2024-05-24 22:21:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch3_loss1.0648804903030396.pypots
2024-05-24 22:21:08 [INFO]: Epoch 004 - training loss: 0.9635, validation loss: 1.0523
2024-05-24 22:21:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch4_loss1.0523462295532227.pypots
2024-05-24 22:21:09 [INFO]: Epoch 005 - training loss: 0.9506, validation loss: 1.0482
2024-05-24 22:21:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch5_loss1.0481660217046738.pypots
2024-05-24 22:21:09 [INFO]: Epoch 006 - training loss: 0.9167, validation loss: 1.0417
2024-05-24 22:21:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch6_loss1.0417329370975494.pypots
2024-05-24 22:21:09 [INFO]: Epoch 007 - training loss: 0.9271, validation loss: 1.0380
2024-05-24 22:21:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch7_loss1.0379931181669235.pypots
2024-05-24 22:21:09 [INFO]: Epoch 008 - training loss: 0.9080, validation loss: 1.0359
2024-05-24 22:21:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch8_loss1.035940170288086.pypots
2024-05-24 22:21:09 [INFO]: Epoch 009 - training loss: 0.9211, validation loss: 1.0359
2024-05-24 22:21:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch9_loss1.035892739892006.pypots
2024-05-24 22:21:10 [INFO]: Epoch 010 - training loss: 0.9211, validation loss: 1.0383
2024-05-24 22:21:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch10_loss1.038265898823738.pypots
2024-05-24 22:21:10 [INFO]: Epoch 011 - training loss: 0.8936, validation loss: 1.0373
2024-05-24 22:21:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch11_loss1.0373441576957703.pypots
2024-05-24 22:21:10 [INFO]: Epoch 012 - training loss: 0.9108, validation loss: 1.0387
2024-05-24 22:21:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch12_loss1.0386962294578552.pypots
2024-05-24 22:21:10 [INFO]: Epoch 013 - training loss: 0.8967, validation loss: 1.0398
2024-05-24 22:21:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch13_loss1.039776086807251.pypots
2024-05-24 22:21:10 [INFO]: Epoch 014 - training loss: 0.9211, validation loss: 1.0377
2024-05-24 22:21:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch14_loss1.0376888811588287.pypots
2024-05-24 22:21:11 [INFO]: Epoch 015 - training loss: 0.8881, validation loss: 1.0349
2024-05-24 22:21:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch15_loss1.034943774342537.pypots
2024-05-24 22:21:11 [INFO]: Epoch 016 - training loss: 0.8840, validation loss: 1.0325
2024-05-24 22:21:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch16_loss1.0325476825237274.pypots
2024-05-24 22:21:11 [INFO]: Epoch 017 - training loss: 0.8743, validation loss: 1.0323
2024-05-24 22:21:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch17_loss1.0323497503995895.pypots
2024-05-24 22:21:11 [INFO]: Epoch 018 - training loss: 0.8823, validation loss: 1.0312
2024-05-24 22:21:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch18_loss1.0312259197235107.pypots
2024-05-24 22:21:11 [INFO]: Epoch 019 - training loss: 0.8868, validation loss: 1.0311
2024-05-24 22:21:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch19_loss1.0310682356357574.pypots
2024-05-24 22:21:12 [INFO]: Epoch 020 - training loss: 0.8704, validation loss: 1.0280
2024-05-24 22:21:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch20_loss1.0279970616102219.pypots
2024-05-24 22:21:12 [INFO]: Epoch 021 - training loss: 0.8657, validation loss: 1.0226
2024-05-24 22:21:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch21_loss1.022606074810028.pypots
2024-05-24 22:21:12 [INFO]: Epoch 022 - training loss: 0.8691, validation loss: 1.0194
2024-05-24 22:21:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch22_loss1.019425317645073.pypots
2024-05-24 22:21:12 [INFO]: Epoch 023 - training loss: 0.8648, validation loss: 1.0162
2024-05-24 22:21:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch23_loss1.016182541847229.pypots
2024-05-24 22:21:12 [INFO]: Epoch 024 - training loss: 0.8815, validation loss: 1.0097
2024-05-24 22:21:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch24_loss1.0097135305404663.pypots
2024-05-24 22:21:13 [INFO]: Epoch 025 - training loss: 0.8419, validation loss: 1.0012
2024-05-24 22:21:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch25_loss1.0012499690055847.pypots
2024-05-24 22:21:13 [INFO]: Epoch 026 - training loss: 0.8646, validation loss: 0.9954
2024-05-24 22:21:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch26_loss0.9954144656658173.pypots
2024-05-24 22:21:13 [INFO]: Epoch 027 - training loss: 0.8629, validation loss: 0.9877
2024-05-24 22:21:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch27_loss0.9876873195171356.pypots
2024-05-24 22:21:13 [INFO]: Epoch 028 - training loss: 0.8542, validation loss: 0.9777
2024-05-24 22:21:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch28_loss0.9776656031608582.pypots
2024-05-24 22:21:13 [INFO]: Epoch 029 - training loss: 0.8423, validation loss: 0.9718
2024-05-24 22:21:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch29_loss0.9717774391174316.pypots
2024-05-24 22:21:14 [INFO]: Epoch 030 - training loss: 0.8881, validation loss: 0.9668
2024-05-24 22:21:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch30_loss0.9668223559856415.pypots
2024-05-24 22:21:14 [INFO]: Epoch 031 - training loss: 0.8458, validation loss: 0.9585
2024-05-24 22:21:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch31_loss0.9584647566080093.pypots
2024-05-24 22:21:14 [INFO]: Epoch 032 - training loss: 0.8442, validation loss: 0.9554
2024-05-24 22:21:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch32_loss0.955440878868103.pypots
2024-05-24 22:21:14 [INFO]: Epoch 033 - training loss: 0.8309, validation loss: 0.9498
2024-05-24 22:21:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch33_loss0.9497630447149277.pypots
2024-05-24 22:21:14 [INFO]: Epoch 034 - training loss: 0.8289, validation loss: 0.9467
2024-05-24 22:21:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch34_loss0.9466751515865326.pypots
2024-05-24 22:21:15 [INFO]: Epoch 035 - training loss: 0.8309, validation loss: 0.9420
2024-05-24 22:21:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch35_loss0.9419523328542709.pypots
2024-05-24 22:21:15 [INFO]: Epoch 036 - training loss: 0.8364, validation loss: 0.9386
2024-05-24 22:21:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch36_loss0.9385939389467239.pypots
2024-05-24 22:21:15 [INFO]: Epoch 037 - training loss: 0.8274, validation loss: 0.9367
2024-05-24 22:21:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch37_loss0.9366773366928101.pypots
2024-05-24 22:21:15 [INFO]: Epoch 038 - training loss: 0.8312, validation loss: 0.9340
2024-05-24 22:21:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch38_loss0.9339904338121414.pypots
2024-05-24 22:21:15 [INFO]: Epoch 039 - training loss: 0.8358, validation loss: 0.9324
2024-05-24 22:21:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch39_loss0.9324440807104111.pypots
2024-05-24 22:21:16 [INFO]: Epoch 040 - training loss: 0.8348, validation loss: 0.9292
2024-05-24 22:21:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch40_loss0.9292056560516357.pypots
2024-05-24 22:21:16 [INFO]: Epoch 041 - training loss: 0.8062, validation loss: 0.9273
2024-05-24 22:21:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch41_loss0.9273024797439575.pypots
2024-05-24 22:21:16 [INFO]: Epoch 042 - training loss: 0.8292, validation loss: 0.9247
2024-05-24 22:21:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch42_loss0.9247021228075027.pypots
2024-05-24 22:21:16 [INFO]: Epoch 043 - training loss: 0.8263, validation loss: 0.9236
2024-05-24 22:21:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch43_loss0.9236498922109604.pypots
2024-05-24 22:21:16 [INFO]: Epoch 044 - training loss: 0.8173, validation loss: 0.9219
2024-05-24 22:21:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch44_loss0.9219458550214767.pypots
2024-05-24 22:21:17 [INFO]: Epoch 045 - training loss: 0.8307, validation loss: 0.9219
2024-05-24 22:21:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch45_loss0.921898826956749.pypots
2024-05-24 22:21:17 [INFO]: Epoch 046 - training loss: 0.8401, validation loss: 0.9203
2024-05-24 22:21:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch46_loss0.9203131347894669.pypots
2024-05-24 22:21:17 [INFO]: Epoch 047 - training loss: 0.8270, validation loss: 0.9188
2024-05-24 22:21:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch47_loss0.9187901020050049.pypots
2024-05-24 22:21:17 [INFO]: Epoch 048 - training loss: 0.8554, validation loss: 0.9177
2024-05-24 22:21:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch48_loss0.9177059978246689.pypots
2024-05-24 22:21:17 [INFO]: Epoch 049 - training loss: 0.7969, validation loss: 0.9161
2024-05-24 22:21:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch49_loss0.9161135852336884.pypots
2024-05-24 22:21:17 [INFO]: Epoch 050 - training loss: 0.8178, validation loss: 0.9144
2024-05-24 22:21:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch50_loss0.9144210517406464.pypots
2024-05-24 22:21:18 [INFO]: Epoch 051 - training loss: 0.8273, validation loss: 0.9144
2024-05-24 22:21:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch51_loss0.9143571555614471.pypots
2024-05-24 22:21:18 [INFO]: Epoch 052 - training loss: 0.8179, validation loss: 0.9119
2024-05-24 22:21:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch52_loss0.9119140058755875.pypots
2024-05-24 22:21:18 [INFO]: Epoch 053 - training loss: 0.8122, validation loss: 0.9112
2024-05-24 22:21:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch53_loss0.9112301617860794.pypots
2024-05-24 22:21:18 [INFO]: Epoch 054 - training loss: 0.8252, validation loss: 0.9094
2024-05-24 22:21:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch54_loss0.9094255268573761.pypots
2024-05-24 22:21:18 [INFO]: Epoch 055 - training loss: 0.8039, validation loss: 0.9112
2024-05-24 22:21:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch55_loss0.9112247675657272.pypots
2024-05-24 22:21:19 [INFO]: Epoch 056 - training loss: 0.7945, validation loss: 0.9093
2024-05-24 22:21:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch56_loss0.9093146771192551.pypots
2024-05-24 22:21:19 [INFO]: Epoch 057 - training loss: 0.8095, validation loss: 0.9093
2024-05-24 22:21:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch57_loss0.9093005806207657.pypots
2024-05-24 22:21:19 [INFO]: Epoch 058 - training loss: 0.8460, validation loss: 0.9076
2024-05-24 22:21:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch58_loss0.9075752943754196.pypots
2024-05-24 22:21:19 [INFO]: Epoch 059 - training loss: 0.7994, validation loss: 0.9056
2024-05-24 22:21:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch59_loss0.9055896103382111.pypots
2024-05-24 22:21:19 [INFO]: Epoch 060 - training loss: 0.7954, validation loss: 0.9049
2024-05-24 22:21:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch60_loss0.9049145579338074.pypots
2024-05-24 22:21:20 [INFO]: Epoch 061 - training loss: 0.7983, validation loss: 0.9065
2024-05-24 22:21:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch61_loss0.9064625352621078.pypots
2024-05-24 22:21:20 [INFO]: Epoch 062 - training loss: 0.8070, validation loss: 0.9051
2024-05-24 22:21:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch62_loss0.9051083326339722.pypots
2024-05-24 22:21:20 [INFO]: Epoch 063 - training loss: 0.8003, validation loss: 0.9036
2024-05-24 22:21:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch63_loss0.9035795032978058.pypots
2024-05-24 22:21:20 [INFO]: Epoch 064 - training loss: 0.8036, validation loss: 0.9050
2024-05-24 22:21:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch64_loss0.9050018787384033.pypots
2024-05-24 22:21:20 [INFO]: Epoch 065 - training loss: 0.7954, validation loss: 0.9040
2024-05-24 22:21:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch65_loss0.9040278643369675.pypots
2024-05-24 22:21:21 [INFO]: Epoch 066 - training loss: 0.7956, validation loss: 0.9022
2024-05-24 22:21:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch66_loss0.9022273421287537.pypots
2024-05-24 22:21:21 [INFO]: Epoch 067 - training loss: 0.7899, validation loss: 0.9014
2024-05-24 22:21:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch67_loss0.9013736248016357.pypots
2024-05-24 22:21:21 [INFO]: Epoch 068 - training loss: 0.7741, validation loss: 0.9030
2024-05-24 22:21:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch68_loss0.9030071347951889.pypots
2024-05-24 22:21:21 [INFO]: Epoch 069 - training loss: 0.8004, validation loss: 0.9003
2024-05-24 22:21:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch69_loss0.900313213467598.pypots
2024-05-24 22:21:21 [INFO]: Epoch 070 - training loss: 0.8059, validation loss: 0.8993
2024-05-24 22:21:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch70_loss0.899318516254425.pypots
2024-05-24 22:21:22 [INFO]: Epoch 071 - training loss: 0.7972, validation loss: 0.8993
2024-05-24 22:21:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch71_loss0.899258628487587.pypots
2024-05-24 22:21:22 [INFO]: Epoch 072 - training loss: 0.7951, validation loss: 0.8971
2024-05-24 22:21:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch72_loss0.897103562951088.pypots
2024-05-24 22:21:22 [INFO]: Epoch 073 - training loss: 0.8118, validation loss: 0.8972
2024-05-24 22:21:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch73_loss0.8972232937812805.pypots
2024-05-24 22:21:22 [INFO]: Epoch 074 - training loss: 0.8196, validation loss: 0.8957
2024-05-24 22:21:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch74_loss0.8957496881484985.pypots
2024-05-24 22:21:22 [INFO]: Epoch 075 - training loss: 0.8049, validation loss: 0.8969
2024-05-24 22:21:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch75_loss0.8969351202249527.pypots
2024-05-24 22:21:23 [INFO]: Epoch 076 - training loss: 0.8067, validation loss: 0.8966
2024-05-24 22:21:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch76_loss0.8966078460216522.pypots
2024-05-24 22:21:23 [INFO]: Epoch 077 - training loss: 0.8148, validation loss: 0.8972
2024-05-24 22:21:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch77_loss0.8972063362598419.pypots
2024-05-24 22:21:23 [INFO]: Epoch 078 - training loss: 0.8087, validation loss: 0.8960
2024-05-24 22:21:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch78_loss0.8959724009037018.pypots
2024-05-24 22:21:23 [INFO]: Epoch 079 - training loss: 0.7945, validation loss: 0.8958
2024-05-24 22:21:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch79_loss0.8957713693380356.pypots
2024-05-24 22:21:23 [INFO]: Epoch 080 - training loss: 0.8064, validation loss: 0.8941
2024-05-24 22:21:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch80_loss0.8940637111663818.pypots
2024-05-24 22:21:24 [INFO]: Epoch 081 - training loss: 0.7876, validation loss: 0.8944
2024-05-24 22:21:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch81_loss0.8944443315267563.pypots
2024-05-24 22:21:24 [INFO]: Epoch 082 - training loss: 0.7657, validation loss: 0.8935
2024-05-24 22:21:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch82_loss0.8934504687786102.pypots
2024-05-24 22:21:24 [INFO]: Epoch 083 - training loss: 0.7996, validation loss: 0.8925
2024-05-24 22:21:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch83_loss0.8924682289361954.pypots
2024-05-24 22:21:24 [INFO]: Epoch 084 - training loss: 0.7808, validation loss: 0.8927
2024-05-24 22:21:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch84_loss0.8926510959863663.pypots
2024-05-24 22:21:24 [INFO]: Epoch 085 - training loss: 0.7802, validation loss: 0.8920
2024-05-24 22:21:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch85_loss0.8919614255428314.pypots
2024-05-24 22:21:25 [INFO]: Epoch 086 - training loss: 0.8399, validation loss: 0.8923
2024-05-24 22:21:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch86_loss0.8922573179006577.pypots
2024-05-24 22:21:25 [INFO]: Epoch 087 - training loss: 0.8117, validation loss: 0.8942
2024-05-24 22:21:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch87_loss0.8941810876131058.pypots
2024-05-24 22:21:25 [INFO]: Epoch 088 - training loss: 0.8072, validation loss: 0.8932
2024-05-24 22:21:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch88_loss0.8931630849838257.pypots
2024-05-24 22:21:25 [INFO]: Epoch 089 - training loss: 0.7730, validation loss: 0.8924
2024-05-24 22:21:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch89_loss0.8924238085746765.pypots
2024-05-24 22:21:25 [INFO]: Epoch 090 - training loss: 0.7826, validation loss: 0.8903
2024-05-24 22:21:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch90_loss0.8903239220380783.pypots
2024-05-24 22:21:25 [INFO]: Epoch 091 - training loss: 0.8054, validation loss: 0.8915
2024-05-24 22:21:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch91_loss0.8915375620126724.pypots
2024-05-24 22:21:26 [INFO]: Epoch 092 - training loss: 0.7939, validation loss: 0.8892
2024-05-24 22:21:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch92_loss0.8891584575176239.pypots
2024-05-24 22:21:26 [INFO]: Epoch 093 - training loss: 0.8057, validation loss: 0.8894
2024-05-24 22:21:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch93_loss0.8893738836050034.pypots
2024-05-24 22:21:26 [INFO]: Epoch 094 - training loss: 0.7925, validation loss: 0.8904
2024-05-24 22:21:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch94_loss0.8904162347316742.pypots
2024-05-24 22:21:26 [INFO]: Epoch 095 - training loss: 0.8030, validation loss: 0.8900
2024-05-24 22:21:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch95_loss0.8900018632411957.pypots
2024-05-24 22:21:26 [INFO]: Epoch 096 - training loss: 0.7919, validation loss: 0.8890
2024-05-24 22:21:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch96_loss0.8889934122562408.pypots
2024-05-24 22:21:27 [INFO]: Epoch 097 - training loss: 0.7855, validation loss: 0.8885
2024-05-24 22:21:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch97_loss0.8885494470596313.pypots
2024-05-24 22:21:27 [INFO]: Epoch 098 - training loss: 0.8048, validation loss: 0.8887
2024-05-24 22:21:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch98_loss0.8887344598770142.pypots
2024-05-24 22:21:27 [INFO]: Epoch 099 - training loss: 0.7919, validation loss: 0.8879
2024-05-24 22:21:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch99_loss0.8879239112138748.pypots
2024-05-24 22:21:27 [INFO]: Epoch 100 - training loss: 0.7888, validation loss: 0.8884
2024-05-24 22:21:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch100_loss0.8883964419364929.pypots
2024-05-24 22:21:27 [INFO]: Epoch 101 - training loss: 0.7913, validation loss: 0.8887
2024-05-24 22:21:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch101_loss0.8886593580245972.pypots
2024-05-24 22:21:28 [INFO]: Epoch 102 - training loss: 0.7814, validation loss: 0.8888
2024-05-24 22:21:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch102_loss0.8888429999351501.pypots
2024-05-24 22:21:28 [INFO]: Epoch 103 - training loss: 0.7997, validation loss: 0.8886
2024-05-24 22:21:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch103_loss0.8886195570230484.pypots
2024-05-24 22:21:28 [INFO]: Epoch 104 - training loss: 0.7906, validation loss: 0.8866
2024-05-24 22:21:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch104_loss0.8866473734378815.pypots
2024-05-24 22:21:28 [INFO]: Epoch 105 - training loss: 0.8089, validation loss: 0.8844
2024-05-24 22:21:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch105_loss0.8844228833913803.pypots
2024-05-24 22:21:28 [INFO]: Epoch 106 - training loss: 0.8077, validation loss: 0.8878
2024-05-24 22:21:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch106_loss0.8877928853034973.pypots
2024-05-24 22:21:29 [INFO]: Epoch 107 - training loss: 0.7863, validation loss: 0.8852
2024-05-24 22:21:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch107_loss0.8851812034845352.pypots
2024-05-24 22:21:29 [INFO]: Epoch 108 - training loss: 0.7935, validation loss: 0.8851
2024-05-24 22:21:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch108_loss0.885131910443306.pypots
2024-05-24 22:21:29 [INFO]: Epoch 109 - training loss: 0.7849, validation loss: 0.8865
2024-05-24 22:21:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch109_loss0.8865403980016708.pypots
2024-05-24 22:21:29 [INFO]: Epoch 110 - training loss: 0.7937, validation loss: 0.8864
2024-05-24 22:21:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch110_loss0.886354386806488.pypots
2024-05-24 22:21:29 [INFO]: Epoch 111 - training loss: 0.7854, validation loss: 0.8860
2024-05-24 22:21:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch111_loss0.8859801888465881.pypots
2024-05-24 22:21:30 [INFO]: Epoch 112 - training loss: 0.7818, validation loss: 0.8826
2024-05-24 22:21:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch112_loss0.8826242536306381.pypots
2024-05-24 22:21:30 [INFO]: Epoch 113 - training loss: 0.7922, validation loss: 0.8887
2024-05-24 22:21:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch113_loss0.8887323588132858.pypots
2024-05-24 22:21:30 [INFO]: Epoch 114 - training loss: 0.7592, validation loss: 0.8832
2024-05-24 22:21:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch114_loss0.8831733912229538.pypots
2024-05-24 22:21:30 [INFO]: Epoch 115 - training loss: 0.7879, validation loss: 0.8884
2024-05-24 22:21:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch115_loss0.8884008824825287.pypots
2024-05-24 22:21:30 [INFO]: Epoch 116 - training loss: 0.7649, validation loss: 0.8844
2024-05-24 22:21:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch116_loss0.8844432234764099.pypots
2024-05-24 22:21:31 [INFO]: Epoch 117 - training loss: 0.7867, validation loss: 0.8838
2024-05-24 22:21:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch117_loss0.883762538433075.pypots
2024-05-24 22:21:31 [INFO]: Epoch 118 - training loss: 0.8186, validation loss: 0.8832
2024-05-24 22:21:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch118_loss0.8832152038812637.pypots
2024-05-24 22:21:31 [INFO]: Epoch 119 - training loss: 0.7750, validation loss: 0.8829
2024-05-24 22:21:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch119_loss0.8828502148389816.pypots
2024-05-24 22:21:31 [INFO]: Epoch 120 - training loss: 0.7833, validation loss: 0.8821
2024-05-24 22:21:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch120_loss0.882055789232254.pypots
2024-05-24 22:21:31 [INFO]: Epoch 121 - training loss: 0.7876, validation loss: 0.8812
2024-05-24 22:21:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch121_loss0.8811685591936111.pypots
2024-05-24 22:21:32 [INFO]: Epoch 122 - training loss: 0.7567, validation loss: 0.8842
2024-05-24 22:21:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch122_loss0.8841811418533325.pypots
2024-05-24 22:21:32 [INFO]: Epoch 123 - training loss: 0.7805, validation loss: 0.8818
2024-05-24 22:21:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch123_loss0.8818238973617554.pypots
2024-05-24 22:21:32 [INFO]: Epoch 124 - training loss: 0.8082, validation loss: 0.8806
2024-05-24 22:21:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch124_loss0.8805710226297379.pypots
2024-05-24 22:21:32 [INFO]: Epoch 125 - training loss: 0.7909, validation loss: 0.8823
2024-05-24 22:21:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch125_loss0.8823413103818893.pypots
2024-05-24 22:21:32 [INFO]: Epoch 126 - training loss: 0.7806, validation loss: 0.8819
2024-05-24 22:21:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch126_loss0.8818648308515549.pypots
2024-05-24 22:21:33 [INFO]: Epoch 127 - training loss: 0.7816, validation loss: 0.8780
2024-05-24 22:21:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch127_loss0.878043532371521.pypots
2024-05-24 22:21:33 [INFO]: Epoch 128 - training loss: 0.7985, validation loss: 0.8785
2024-05-24 22:21:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch128_loss0.8785206526517868.pypots
2024-05-24 22:21:33 [INFO]: Epoch 129 - training loss: 0.7869, validation loss: 0.8807
2024-05-24 22:21:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch129_loss0.8807290196418762.pypots
2024-05-24 22:21:33 [INFO]: Epoch 130 - training loss: 0.7969, validation loss: 0.8786
2024-05-24 22:21:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch130_loss0.8785675764083862.pypots
2024-05-24 22:21:33 [INFO]: Epoch 131 - training loss: 0.7912, validation loss: 0.8808
2024-05-24 22:21:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch131_loss0.8808299154043198.pypots
2024-05-24 22:21:33 [INFO]: Epoch 132 - training loss: 0.8150, validation loss: 0.8821
2024-05-24 22:21:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch132_loss0.8821343034505844.pypots
2024-05-24 22:21:34 [INFO]: Epoch 133 - training loss: 0.8023, validation loss: 0.8782
2024-05-24 22:21:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch133_loss0.8781723529100418.pypots
2024-05-24 22:21:34 [INFO]: Epoch 134 - training loss: 0.8009, validation loss: 0.8827
2024-05-24 22:21:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch134_loss0.8827283829450607.pypots
2024-05-24 22:21:34 [INFO]: Epoch 135 - training loss: 0.7828, validation loss: 0.8798
2024-05-24 22:21:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch135_loss0.8797949999570847.pypots
2024-05-24 22:21:34 [INFO]: Epoch 136 - training loss: 0.7879, validation loss: 0.8782
2024-05-24 22:21:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch136_loss0.8781535625457764.pypots
2024-05-24 22:21:34 [INFO]: Epoch 137 - training loss: 0.7802, validation loss: 0.8752
2024-05-24 22:21:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch137_loss0.8752346783876419.pypots
2024-05-24 22:21:35 [INFO]: Epoch 138 - training loss: 0.8239, validation loss: 0.8768
2024-05-24 22:21:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch138_loss0.8767896592617035.pypots
2024-05-24 22:21:35 [INFO]: Epoch 139 - training loss: 0.7825, validation loss: 0.8794
2024-05-24 22:21:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch139_loss0.879418358206749.pypots
2024-05-24 22:21:35 [INFO]: Epoch 140 - training loss: 0.7833, validation loss: 0.8746
2024-05-24 22:21:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch140_loss0.8745715171098709.pypots
2024-05-24 22:21:35 [INFO]: Epoch 141 - training loss: 0.7812, validation loss: 0.8782
2024-05-24 22:21:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch141_loss0.8782146573066711.pypots
2024-05-24 22:21:35 [INFO]: Epoch 142 - training loss: 0.7828, validation loss: 0.8758
2024-05-24 22:21:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch142_loss0.8757536709308624.pypots
2024-05-24 22:21:36 [INFO]: Epoch 143 - training loss: 0.7794, validation loss: 0.8782
2024-05-24 22:21:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch143_loss0.8781842142343521.pypots
2024-05-24 22:21:36 [INFO]: Epoch 144 - training loss: 0.7780, validation loss: 0.8759
2024-05-24 22:21:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch144_loss0.8759078532457352.pypots
2024-05-24 22:21:36 [INFO]: Epoch 145 - training loss: 0.7655, validation loss: 0.8755
2024-05-24 22:21:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch145_loss0.8754985332489014.pypots
2024-05-24 22:21:36 [INFO]: Epoch 146 - training loss: 0.7822, validation loss: 0.8745
2024-05-24 22:21:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch146_loss0.8745235353708267.pypots
2024-05-24 22:21:36 [INFO]: Epoch 147 - training loss: 0.7925, validation loss: 0.8751
2024-05-24 22:21:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch147_loss0.8751222342252731.pypots
2024-05-24 22:21:37 [INFO]: Epoch 148 - training loss: 0.7866, validation loss: 0.8740
2024-05-24 22:21:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch148_loss0.8739628046751022.pypots
2024-05-24 22:21:37 [INFO]: Epoch 149 - training loss: 0.8190, validation loss: 0.8706
2024-05-24 22:21:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch149_loss0.8706053495407104.pypots
2024-05-24 22:21:37 [INFO]: Epoch 150 - training loss: 0.7907, validation loss: 0.8705
2024-05-24 22:21:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch150_loss0.8704782128334045.pypots
2024-05-24 22:21:37 [INFO]: Epoch 151 - training loss: 0.7759, validation loss: 0.8760
2024-05-24 22:21:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch151_loss0.876001849770546.pypots
2024-05-24 22:21:37 [INFO]: Epoch 152 - training loss: 0.7842, validation loss: 0.8712
2024-05-24 22:21:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch152_loss0.8712281435728073.pypots
2024-05-24 22:21:38 [INFO]: Epoch 153 - training loss: 0.8093, validation loss: 0.8713
2024-05-24 22:21:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch153_loss0.8712989985942841.pypots
2024-05-24 22:21:38 [INFO]: Epoch 154 - training loss: 0.7959, validation loss: 0.8666
2024-05-24 22:21:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch154_loss0.8666167259216309.pypots
2024-05-24 22:21:38 [INFO]: Epoch 155 - training loss: 0.7676, validation loss: 0.8691
2024-05-24 22:21:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch155_loss0.8691307455301285.pypots
2024-05-24 22:21:38 [INFO]: Epoch 156 - training loss: 0.7773, validation loss: 0.8693
2024-05-24 22:21:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch156_loss0.8693092167377472.pypots
2024-05-24 22:21:38 [INFO]: Epoch 157 - training loss: 0.7652, validation loss: 0.8700
2024-05-24 22:21:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch157_loss0.8699508607387543.pypots
2024-05-24 22:21:39 [INFO]: Epoch 158 - training loss: 0.8292, validation loss: 0.8675
2024-05-24 22:21:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch158_loss0.8674621284008026.pypots
2024-05-24 22:21:39 [INFO]: Epoch 159 - training loss: 0.7748, validation loss: 0.8662
2024-05-24 22:21:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch159_loss0.8662441968917847.pypots
2024-05-24 22:21:39 [INFO]: Epoch 160 - training loss: 0.7780, validation loss: 0.8688
2024-05-24 22:21:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch160_loss0.8688490986824036.pypots
2024-05-24 22:21:39 [INFO]: Epoch 161 - training loss: 0.7738, validation loss: 0.8652
2024-05-24 22:21:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch161_loss0.8651554137468338.pypots
2024-05-24 22:21:39 [INFO]: Epoch 162 - training loss: 0.7783, validation loss: 0.8670
2024-05-24 22:21:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch162_loss0.8669740408658981.pypots
2024-05-24 22:21:40 [INFO]: Epoch 163 - training loss: 0.7737, validation loss: 0.8635
2024-05-24 22:21:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch163_loss0.8634863346815109.pypots
2024-05-24 22:21:40 [INFO]: Epoch 164 - training loss: 0.7669, validation loss: 0.8695
2024-05-24 22:21:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch164_loss0.8694723397493362.pypots
2024-05-24 22:21:40 [INFO]: Epoch 165 - training loss: 0.7852, validation loss: 0.8628
2024-05-24 22:21:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch165_loss0.8627942949533463.pypots
2024-05-24 22:21:40 [INFO]: Epoch 166 - training loss: 0.8011, validation loss: 0.8692
2024-05-24 22:21:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch166_loss0.8692398071289062.pypots
2024-05-24 22:21:40 [INFO]: Epoch 167 - training loss: 0.8438, validation loss: 0.8641
2024-05-24 22:21:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch167_loss0.8641041666269302.pypots
2024-05-24 22:21:41 [INFO]: Epoch 168 - training loss: 0.7959, validation loss: 0.8632
2024-05-24 22:21:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch168_loss0.8631729632616043.pypots
2024-05-24 22:21:41 [INFO]: Epoch 169 - training loss: 0.7730, validation loss: 0.8609
2024-05-24 22:21:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch169_loss0.8609371334314346.pypots
2024-05-24 22:21:41 [INFO]: Epoch 170 - training loss: 0.7821, validation loss: 0.8608
2024-05-24 22:21:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch170_loss0.8608498722314835.pypots
2024-05-24 22:21:41 [INFO]: Epoch 171 - training loss: 0.7852, validation loss: 0.8582
2024-05-24 22:21:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch171_loss0.8581583201885223.pypots
2024-05-24 22:21:41 [INFO]: Epoch 172 - training loss: 0.7763, validation loss: 0.8593
2024-05-24 22:21:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch172_loss0.8592843860387802.pypots
2024-05-24 22:21:42 [INFO]: Epoch 173 - training loss: 0.7782, validation loss: 0.8613
2024-05-24 22:21:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch173_loss0.861296072602272.pypots
2024-05-24 22:21:42 [INFO]: Epoch 174 - training loss: 0.7898, validation loss: 0.8599
2024-05-24 22:21:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch174_loss0.8598598390817642.pypots
2024-05-24 22:21:42 [INFO]: Epoch 175 - training loss: 0.7797, validation loss: 0.8613
2024-05-24 22:21:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch175_loss0.8613499253988266.pypots
2024-05-24 22:21:42 [INFO]: Epoch 176 - training loss: 0.7707, validation loss: 0.8592
2024-05-24 22:21:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch176_loss0.8591626733541489.pypots
2024-05-24 22:21:42 [INFO]: Epoch 177 - training loss: 0.7841, validation loss: 0.8589
2024-05-24 22:21:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch177_loss0.858880877494812.pypots
2024-05-24 22:21:42 [INFO]: Epoch 178 - training loss: 0.7705, validation loss: 0.8629
2024-05-24 22:21:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch178_loss0.8629376292228699.pypots
2024-05-24 22:21:43 [INFO]: Epoch 179 - training loss: 0.7846, validation loss: 0.8577
2024-05-24 22:21:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch179_loss0.8577419966459274.pypots
2024-05-24 22:21:43 [INFO]: Epoch 180 - training loss: 0.7820, validation loss: 0.8585
2024-05-24 22:21:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch180_loss0.8584764152765274.pypots
2024-05-24 22:21:43 [INFO]: Epoch 181 - training loss: 0.7842, validation loss: 0.8565
2024-05-24 22:21:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch181_loss0.8565498739480972.pypots
2024-05-24 22:21:43 [INFO]: Epoch 182 - training loss: 0.7822, validation loss: 0.8572
2024-05-24 22:21:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch182_loss0.8571761548519135.pypots
2024-05-24 22:21:43 [INFO]: Epoch 183 - training loss: 0.7750, validation loss: 0.8607
2024-05-24 22:21:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch183_loss0.8607218116521835.pypots
2024-05-24 22:21:44 [INFO]: Epoch 184 - training loss: 0.7689, validation loss: 0.8536
2024-05-24 22:21:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch184_loss0.8536394238471985.pypots
2024-05-24 22:21:44 [INFO]: Epoch 185 - training loss: 0.7903, validation loss: 0.8590
2024-05-24 22:21:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch185_loss0.858973354101181.pypots
2024-05-24 22:21:44 [INFO]: Epoch 186 - training loss: 0.8256, validation loss: 0.8586
2024-05-24 22:21:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch186_loss0.8585631251335144.pypots
2024-05-24 22:21:44 [INFO]: Epoch 187 - training loss: 0.7766, validation loss: 0.8533
2024-05-24 22:21:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch187_loss0.8532765209674835.pypots
2024-05-24 22:21:44 [INFO]: Epoch 188 - training loss: 0.7777, validation loss: 0.8609
2024-05-24 22:21:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch188_loss0.8609291017055511.pypots
2024-05-24 22:21:45 [INFO]: Epoch 189 - training loss: 0.7757, validation loss: 0.8575
2024-05-24 22:21:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch189_loss0.8574913442134857.pypots
2024-05-24 22:21:45 [INFO]: Epoch 190 - training loss: 0.7898, validation loss: 0.8511
2024-05-24 22:21:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch190_loss0.8511014878749847.pypots
2024-05-24 22:21:45 [INFO]: Epoch 191 - training loss: 0.7850, validation loss: 0.8533
2024-05-24 22:21:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch191_loss0.8532624989748001.pypots
2024-05-24 22:21:45 [INFO]: Epoch 192 - training loss: 0.7798, validation loss: 0.8556
2024-05-24 22:21:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch192_loss0.8556350916624069.pypots
2024-05-24 22:21:45 [INFO]: Epoch 193 - training loss: 0.7947, validation loss: 0.8562
2024-05-24 22:21:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch193_loss0.8562168031930923.pypots
2024-05-24 22:21:46 [INFO]: Epoch 194 - training loss: 0.7703, validation loss: 0.8577
2024-05-24 22:21:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch194_loss0.8576599061489105.pypots
2024-05-24 22:21:46 [INFO]: Epoch 195 - training loss: 0.7773, validation loss: 0.8537
2024-05-24 22:21:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch195_loss0.8537479043006897.pypots
2024-05-24 22:21:46 [INFO]: Epoch 196 - training loss: 0.7817, validation loss: 0.8516
2024-05-24 22:21:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch196_loss0.8515945076942444.pypots
2024-05-24 22:21:46 [INFO]: Epoch 197 - training loss: 0.7866, validation loss: 0.8530
2024-05-24 22:21:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch197_loss0.8529559373855591.pypots
2024-05-24 22:21:46 [INFO]: Epoch 198 - training loss: 0.7672, validation loss: 0.8530
2024-05-24 22:21:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch198_loss0.8530025482177734.pypots
2024-05-24 22:21:47 [INFO]: Epoch 199 - training loss: 0.7802, validation loss: 0.8546
2024-05-24 22:21:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch199_loss0.8545515090227127.pypots
2024-05-24 22:21:47 [INFO]: Epoch 200 - training loss: 0.7719, validation loss: 0.8510
2024-05-24 22:21:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch200_loss0.8509861677885056.pypots
2024-05-24 22:21:47 [INFO]: Epoch 201 - training loss: 0.8082, validation loss: 0.8490
2024-05-24 22:21:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch201_loss0.8489592522382736.pypots
2024-05-24 22:21:47 [INFO]: Epoch 202 - training loss: 0.7627, validation loss: 0.8493
2024-05-24 22:21:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch202_loss0.8493404239416122.pypots
2024-05-24 22:21:47 [INFO]: Epoch 203 - training loss: 0.8109, validation loss: 0.8494
2024-05-24 22:21:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch203_loss0.8493774235248566.pypots
2024-05-24 22:21:48 [INFO]: Epoch 204 - training loss: 0.7956, validation loss: 0.8487
2024-05-24 22:21:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch204_loss0.8487284332513809.pypots
2024-05-24 22:21:48 [INFO]: Epoch 205 - training loss: 0.7714, validation loss: 0.8501
2024-05-24 22:21:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch205_loss0.8500504344701767.pypots
2024-05-24 22:21:48 [INFO]: Epoch 206 - training loss: 0.7657, validation loss: 0.8473
2024-05-24 22:21:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch206_loss0.8473002016544342.pypots
2024-05-24 22:21:48 [INFO]: Epoch 207 - training loss: 0.7816, validation loss: 0.8478
2024-05-24 22:21:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch207_loss0.8477682322263718.pypots
2024-05-24 22:21:48 [INFO]: Epoch 208 - training loss: 0.7816, validation loss: 0.8443
2024-05-24 22:21:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch208_loss0.8442620635032654.pypots
2024-05-24 22:21:49 [INFO]: Epoch 209 - training loss: 0.8189, validation loss: 0.8462
2024-05-24 22:21:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch209_loss0.846188023686409.pypots
2024-05-24 22:21:49 [INFO]: Epoch 210 - training loss: 0.7805, validation loss: 0.8453
2024-05-24 22:21:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch210_loss0.8453357815742493.pypots
2024-05-24 22:21:49 [INFO]: Epoch 211 - training loss: 0.7582, validation loss: 0.8465
2024-05-24 22:21:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch211_loss0.8464710265398026.pypots
2024-05-24 22:21:49 [INFO]: Epoch 212 - training loss: 0.8063, validation loss: 0.8482
2024-05-24 22:21:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch212_loss0.8481859862804413.pypots
2024-05-24 22:21:49 [INFO]: Epoch 213 - training loss: 0.7732, validation loss: 0.8442
2024-05-24 22:21:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch213_loss0.8442201167345047.pypots
2024-05-24 22:21:50 [INFO]: Epoch 214 - training loss: 0.7725, validation loss: 0.8463
2024-05-24 22:21:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch214_loss0.8463484048843384.pypots
2024-05-24 22:21:50 [INFO]: Epoch 215 - training loss: 0.7892, validation loss: 0.8452
2024-05-24 22:21:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch215_loss0.8452401012182236.pypots
2024-05-24 22:21:50 [INFO]: Epoch 216 - training loss: 0.7787, validation loss: 0.8493
2024-05-24 22:21:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch216_loss0.8492567986249924.pypots
2024-05-24 22:21:50 [INFO]: Epoch 217 - training loss: 0.7684, validation loss: 0.8468
2024-05-24 22:21:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch217_loss0.8468157649040222.pypots
2024-05-24 22:21:50 [INFO]: Epoch 218 - training loss: 0.7812, validation loss: 0.8464
2024-05-24 22:21:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch218_loss0.8464326709508896.pypots
2024-05-24 22:21:50 [INFO]: Epoch 219 - training loss: 0.7709, validation loss: 0.8475
2024-05-24 22:21:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch219_loss0.8474681228399277.pypots
2024-05-24 22:21:51 [INFO]: Epoch 220 - training loss: 0.8014, validation loss: 0.8516
2024-05-24 22:21:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch220_loss0.8515615910291672.pypots
2024-05-24 22:21:51 [INFO]: Epoch 221 - training loss: 0.8209, validation loss: 0.8437
2024-05-24 22:21:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch221_loss0.8437493741512299.pypots
2024-05-24 22:21:51 [INFO]: Epoch 222 - training loss: 0.7560, validation loss: 0.8421
2024-05-24 22:21:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch222_loss0.8421130627393723.pypots
2024-05-24 22:21:51 [INFO]: Epoch 223 - training loss: 0.7705, validation loss: 0.8424
2024-05-24 22:21:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch223_loss0.8423640131950378.pypots
2024-05-24 22:21:51 [INFO]: Epoch 224 - training loss: 0.7621, validation loss: 0.8444
2024-05-24 22:21:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch224_loss0.8444200307130814.pypots
2024-05-24 22:21:52 [INFO]: Epoch 225 - training loss: 0.8003, validation loss: 0.8460
2024-05-24 22:21:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch225_loss0.8460212051868439.pypots
2024-05-24 22:21:52 [INFO]: Epoch 226 - training loss: 0.7597, validation loss: 0.8417
2024-05-24 22:21:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch226_loss0.8417264521121979.pypots
2024-05-24 22:21:52 [INFO]: Epoch 227 - training loss: 0.7864, validation loss: 0.8437
2024-05-24 22:21:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch227_loss0.8437090814113617.pypots
2024-05-24 22:21:52 [INFO]: Epoch 228 - training loss: 0.7711, validation loss: 0.8390
2024-05-24 22:21:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch228_loss0.8389987349510193.pypots
2024-05-24 22:21:52 [INFO]: Epoch 229 - training loss: 0.7647, validation loss: 0.8464
2024-05-24 22:21:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch229_loss0.8464113473892212.pypots
2024-05-24 22:21:53 [INFO]: Epoch 230 - training loss: 0.7715, validation loss: 0.8423
2024-05-24 22:21:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch230_loss0.8422592133283615.pypots
2024-05-24 22:21:53 [INFO]: Epoch 231 - training loss: 0.7658, validation loss: 0.8456
2024-05-24 22:21:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch231_loss0.845566987991333.pypots
2024-05-24 22:21:53 [INFO]: Epoch 232 - training loss: 0.7854, validation loss: 0.8439
2024-05-24 22:21:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch232_loss0.8439421057701111.pypots
2024-05-24 22:21:53 [INFO]: Epoch 233 - training loss: 0.7858, validation loss: 0.8429
2024-05-24 22:21:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch233_loss0.8429130613803864.pypots
2024-05-24 22:21:53 [INFO]: Epoch 234 - training loss: 0.7758, validation loss: 0.8439
2024-05-24 22:21:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch234_loss0.8439246267080307.pypots
2024-05-24 22:21:54 [INFO]: Epoch 235 - training loss: 0.7857, validation loss: 0.8412
2024-05-24 22:21:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch235_loss0.8411558568477631.pypots
2024-05-24 22:21:54 [INFO]: Epoch 236 - training loss: 0.7815, validation loss: 0.8417
2024-05-24 22:21:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch236_loss0.8417267799377441.pypots
2024-05-24 22:21:54 [INFO]: Epoch 237 - training loss: 0.7743, validation loss: 0.8408
2024-05-24 22:21:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch237_loss0.840828537940979.pypots
2024-05-24 22:21:54 [INFO]: Epoch 238 - training loss: 0.7834, validation loss: 0.8422
2024-05-24 22:21:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN_epoch238_loss0.8421902507543564.pypots
2024-05-24 22:21:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:21:54 [INFO]: Finished training. The best model is from epoch#228.
2024-05-24 22:21:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T222106/MRNN.pypots
2024-05-24 22:21:55 [INFO]: MRNN on ETTm1: MAE=0.6061, MSE=1.0016
2024-05-24 22:21:55 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/MRNN_ettm1/imputation.pkl
2024-05-24 22:21:55 [INFO]: Using the given device: cpu
2024-05-24 22:21:55 [INFO]: LOCF on ETTm1: MAE=0.1348, MSE=0.0715
2024-05-24 22:21:55 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_ettm1".
2024-05-24 22:21:55 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/LOCF_ettm1/imputation.pkl
2024-05-24 22:21:55 [INFO]: Median on ETTm1: MAE=0.6516, MSE=0.8223
2024-05-24 22:21:55 [INFO]: Successfully created the given path "saved_results/round_2/Median_ettm1".
2024-05-24 22:21:55 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Median_ettm1/imputation.pkl
2024-05-24 22:21:55 [INFO]: Mean on ETTm1: MAE=0.6566, MSE=0.8036
2024-05-24 22:21:55 [INFO]: Successfully created the given path "saved_results/round_2/Mean_ettm1".
2024-05-24 22:21:55 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Mean_ettm1/imputation.pkl
2024-05-24 22:21:55 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-24 22:21:55 [INFO]: Using the given device: cuda:0
2024-05-24 22:21:55 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/SAITS_ettm1/20240524_T222155
2024-05-24 22:21:55 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/SAITS_ettm1/20240524_T222155/tensorboard
2024-05-24 22:21:55 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 22:21:55 [INFO]: Epoch 001 - training loss: 1.1666, validation loss: 0.2354
2024-05-24 22:21:56 [INFO]: Epoch 002 - training loss: 0.8062, validation loss: 0.1347
2024-05-24 22:21:56 [INFO]: Epoch 003 - training loss: 0.7348, validation loss: 0.1116
2024-05-24 22:21:57 [INFO]: Epoch 004 - training loss: 0.6767, validation loss: 0.0834
2024-05-24 22:21:57 [INFO]: Epoch 005 - training loss: 0.6502, validation loss: 0.0845
2024-05-24 22:21:58 [INFO]: Epoch 006 - training loss: 0.6211, validation loss: 0.0581
2024-05-24 22:21:58 [INFO]: Epoch 007 - training loss: 0.6082, validation loss: 0.0744
2024-05-24 22:21:59 [INFO]: Epoch 008 - training loss: 0.5978, validation loss: 0.0589
2024-05-24 22:21:59 [INFO]: Epoch 009 - training loss: 0.5886, validation loss: 0.0499
2024-05-24 22:22:00 [INFO]: Epoch 010 - training loss: 0.5800, validation loss: 0.0530
2024-05-24 22:22:00 [INFO]: Epoch 011 - training loss: 0.5731, validation loss: 0.0759
2024-05-24 22:22:01 [INFO]: Epoch 012 - training loss: 0.5728, validation loss: 0.0567
2024-05-24 22:22:01 [INFO]: Epoch 013 - training loss: 0.5517, validation loss: 0.0431
2024-05-24 22:22:02 [INFO]: Epoch 014 - training loss: 0.5405, validation loss: 0.0540
2024-05-24 22:22:02 [INFO]: Epoch 015 - training loss: 0.5375, validation loss: 0.0509
2024-05-24 22:22:03 [INFO]: Epoch 016 - training loss: 0.5499, validation loss: 0.0412
2024-05-24 22:22:03 [INFO]: Epoch 017 - training loss: 0.5312, validation loss: 0.0529
2024-05-24 22:22:04 [INFO]: Epoch 018 - training loss: 0.5263, validation loss: 0.0404
2024-05-24 22:22:04 [INFO]: Epoch 019 - training loss: 0.5342, validation loss: 0.0468
2024-05-24 22:22:04 [INFO]: Epoch 020 - training loss: 0.5170, validation loss: 0.0532
2024-05-24 22:22:05 [INFO]: Epoch 021 - training loss: 0.5008, validation loss: 0.0526
2024-05-24 22:22:05 [INFO]: Epoch 022 - training loss: 0.5099, validation loss: 0.0450
2024-05-24 22:22:06 [INFO]: Epoch 023 - training loss: 0.4977, validation loss: 0.0416
2024-05-24 22:22:06 [INFO]: Epoch 024 - training loss: 0.4969, validation loss: 0.0454
2024-05-24 22:22:07 [INFO]: Epoch 025 - training loss: 0.5002, validation loss: 0.0613
2024-05-24 22:22:07 [INFO]: Epoch 026 - training loss: 0.4928, validation loss: 0.0419
2024-05-24 22:22:08 [INFO]: Epoch 027 - training loss: 0.4887, validation loss: 0.0518
2024-05-24 22:22:08 [INFO]: Epoch 028 - training loss: 0.5017, validation loss: 0.0394
2024-05-24 22:22:09 [INFO]: Epoch 029 - training loss: 0.4802, validation loss: 0.0385
2024-05-24 22:22:09 [INFO]: Epoch 030 - training loss: 0.4736, validation loss: 0.0451
2024-05-24 22:22:10 [INFO]: Epoch 031 - training loss: 0.4768, validation loss: 0.0399
2024-05-24 22:22:10 [INFO]: Epoch 032 - training loss: 0.4686, validation loss: 0.0396
2024-05-24 22:22:11 [INFO]: Epoch 033 - training loss: 0.4722, validation loss: 0.0510
2024-05-24 22:22:11 [INFO]: Epoch 034 - training loss: 0.4833, validation loss: 0.0480
2024-05-24 22:22:12 [INFO]: Epoch 035 - training loss: 0.4756, validation loss: 0.0607
2024-05-24 22:22:12 [INFO]: Epoch 036 - training loss: 0.4782, validation loss: 0.0449
2024-05-24 22:22:13 [INFO]: Epoch 037 - training loss: 0.4823, validation loss: 0.0453
2024-05-24 22:22:13 [INFO]: Epoch 038 - training loss: 0.4635, validation loss: 0.0514
2024-05-24 22:22:14 [INFO]: Epoch 039 - training loss: 0.4476, validation loss: 0.0476
2024-05-24 22:22:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:22:14 [INFO]: Finished training. The best model is from epoch#29.
2024-05-24 22:22:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/SAITS_ettm1/20240524_T222155/SAITS.pypots
2024-05-24 22:22:14 [INFO]: SAITS on ETTm1: MAE=0.1602, MSE=0.0515
2024-05-24 22:22:14 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/SAITS_ettm1/imputation.pkl
2024-05-24 22:22:14 [INFO]: Using the given device: cuda:0
2024-05-24 22:22:14 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/Transformer_ettm1/20240524_T222214
2024-05-24 22:22:14 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/Transformer_ettm1/20240524_T222214/tensorboard
2024-05-24 22:22:14 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 22:22:14 [INFO]: Epoch 001 - training loss: 1.2446, validation loss: 0.4202
2024-05-24 22:22:14 [INFO]: Epoch 002 - training loss: 0.7033, validation loss: 0.1599
2024-05-24 22:22:15 [INFO]: Epoch 003 - training loss: 0.5480, validation loss: 0.1051
2024-05-24 22:22:15 [INFO]: Epoch 004 - training loss: 0.4860, validation loss: 0.0938
2024-05-24 22:22:15 [INFO]: Epoch 005 - training loss: 0.4493, validation loss: 0.0756
2024-05-24 22:22:15 [INFO]: Epoch 006 - training loss: 0.4214, validation loss: 0.0657
2024-05-24 22:22:15 [INFO]: Epoch 007 - training loss: 0.4029, validation loss: 0.0639
2024-05-24 22:22:16 [INFO]: Epoch 008 - training loss: 0.4054, validation loss: 0.0591
2024-05-24 22:22:16 [INFO]: Epoch 009 - training loss: 0.3805, validation loss: 0.0527
2024-05-24 22:22:16 [INFO]: Epoch 010 - training loss: 0.3731, validation loss: 0.0486
2024-05-24 22:22:16 [INFO]: Epoch 011 - training loss: 0.3526, validation loss: 0.0467
2024-05-24 22:22:16 [INFO]: Epoch 012 - training loss: 0.3463, validation loss: 0.0477
2024-05-24 22:22:16 [INFO]: Epoch 013 - training loss: 0.3479, validation loss: 0.0536
2024-05-24 22:22:17 [INFO]: Epoch 014 - training loss: 0.3503, validation loss: 0.0452
2024-05-24 22:22:17 [INFO]: Epoch 015 - training loss: 0.3322, validation loss: 0.0429
2024-05-24 22:22:17 [INFO]: Epoch 016 - training loss: 0.3267, validation loss: 0.0454
2024-05-24 22:22:17 [INFO]: Epoch 017 - training loss: 0.3252, validation loss: 0.0401
2024-05-24 22:22:17 [INFO]: Epoch 018 - training loss: 0.3159, validation loss: 0.0437
2024-05-24 22:22:18 [INFO]: Epoch 019 - training loss: 0.3153, validation loss: 0.0405
2024-05-24 22:22:18 [INFO]: Epoch 020 - training loss: 0.3063, validation loss: 0.0380
2024-05-24 22:22:18 [INFO]: Epoch 021 - training loss: 0.2999, validation loss: 0.0379
2024-05-24 22:22:18 [INFO]: Epoch 022 - training loss: 0.3017, validation loss: 0.0373
2024-05-24 22:22:18 [INFO]: Epoch 023 - training loss: 0.2952, validation loss: 0.0373
2024-05-24 22:22:19 [INFO]: Epoch 024 - training loss: 0.2950, validation loss: 0.0336
2024-05-24 22:22:19 [INFO]: Epoch 025 - training loss: 0.2820, validation loss: 0.0380
2024-05-24 22:22:19 [INFO]: Epoch 026 - training loss: 0.2867, validation loss: 0.0359
2024-05-24 22:22:19 [INFO]: Epoch 027 - training loss: 0.2780, validation loss: 0.0353
2024-05-24 22:22:19 [INFO]: Epoch 028 - training loss: 0.2853, validation loss: 0.0359
2024-05-24 22:22:20 [INFO]: Epoch 029 - training loss: 0.2793, validation loss: 0.0401
2024-05-24 22:22:20 [INFO]: Epoch 030 - training loss: 0.2811, validation loss: 0.0389
2024-05-24 22:22:20 [INFO]: Epoch 031 - training loss: 0.2791, validation loss: 0.0349
2024-05-24 22:22:20 [INFO]: Epoch 032 - training loss: 0.2798, validation loss: 0.0364
2024-05-24 22:22:20 [INFO]: Epoch 033 - training loss: 0.2741, validation loss: 0.0328
2024-05-24 22:22:21 [INFO]: Epoch 034 - training loss: 0.2654, validation loss: 0.0355
2024-05-24 22:22:21 [INFO]: Epoch 035 - training loss: 0.2684, validation loss: 0.0318
2024-05-24 22:22:21 [INFO]: Epoch 036 - training loss: 0.2627, validation loss: 0.0314
2024-05-24 22:22:21 [INFO]: Epoch 037 - training loss: 0.2598, validation loss: 0.0294
2024-05-24 22:22:21 [INFO]: Epoch 038 - training loss: 0.2595, validation loss: 0.0308
2024-05-24 22:22:22 [INFO]: Epoch 039 - training loss: 0.2516, validation loss: 0.0348
2024-05-24 22:22:22 [INFO]: Epoch 040 - training loss: 0.2580, validation loss: 0.0297
2024-05-24 22:22:22 [INFO]: Epoch 041 - training loss: 0.2478, validation loss: 0.0288
2024-05-24 22:22:22 [INFO]: Epoch 042 - training loss: 0.2491, validation loss: 0.0304
2024-05-24 22:22:22 [INFO]: Epoch 043 - training loss: 0.2535, validation loss: 0.0315
2024-05-24 22:22:23 [INFO]: Epoch 044 - training loss: 0.2452, validation loss: 0.0282
2024-05-24 22:22:23 [INFO]: Epoch 045 - training loss: 0.2419, validation loss: 0.0295
2024-05-24 22:22:23 [INFO]: Epoch 046 - training loss: 0.2413, validation loss: 0.0301
2024-05-24 22:22:23 [INFO]: Epoch 047 - training loss: 0.2363, validation loss: 0.0279
2024-05-24 22:22:23 [INFO]: Epoch 048 - training loss: 0.2373, validation loss: 0.0329
2024-05-24 22:22:24 [INFO]: Epoch 049 - training loss: 0.2409, validation loss: 0.0302
2024-05-24 22:22:24 [INFO]: Epoch 050 - training loss: 0.2358, validation loss: 0.0278
2024-05-24 22:22:24 [INFO]: Epoch 051 - training loss: 0.2334, validation loss: 0.0265
2024-05-24 22:22:24 [INFO]: Epoch 052 - training loss: 0.2278, validation loss: 0.0278
2024-05-24 22:22:24 [INFO]: Epoch 053 - training loss: 0.2213, validation loss: 0.0295
2024-05-24 22:22:25 [INFO]: Epoch 054 - training loss: 0.2299, validation loss: 0.0258
2024-05-24 22:22:25 [INFO]: Epoch 055 - training loss: 0.2262, validation loss: 0.0293
2024-05-24 22:22:25 [INFO]: Epoch 056 - training loss: 0.2369, validation loss: 0.0281
2024-05-24 22:22:25 [INFO]: Epoch 057 - training loss: 0.2265, validation loss: 0.0304
2024-05-24 22:22:25 [INFO]: Epoch 058 - training loss: 0.2361, validation loss: 0.0302
2024-05-24 22:22:25 [INFO]: Epoch 059 - training loss: 0.2275, validation loss: 0.0273
2024-05-24 22:22:26 [INFO]: Epoch 060 - training loss: 0.2208, validation loss: 0.0267
2024-05-24 22:22:26 [INFO]: Epoch 061 - training loss: 0.2192, validation loss: 0.0273
2024-05-24 22:22:26 [INFO]: Epoch 062 - training loss: 0.2233, validation loss: 0.0291
2024-05-24 22:22:26 [INFO]: Epoch 063 - training loss: 0.2254, validation loss: 0.0286
2024-05-24 22:22:26 [INFO]: Epoch 064 - training loss: 0.2211, validation loss: 0.0276
2024-05-24 22:22:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:22:26 [INFO]: Finished training. The best model is from epoch#54.
2024-05-24 22:22:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/Transformer_ettm1/20240524_T222214/Transformer.pypots
2024-05-24 22:22:26 [INFO]: Transformer on ETTm1: MAE=0.1401, MSE=0.0400
2024-05-24 22:22:27 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Transformer_ettm1/imputation.pkl
2024-05-24 22:22:27 [INFO]: Using the given device: cuda:0
2024-05-24 22:22:27 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/TimesNet_ettm1/20240524_T222227
2024-05-24 22:22:27 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/TimesNet_ettm1/20240524_T222227/tensorboard
2024-05-24 22:22:27 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 22:22:27 [INFO]: Epoch 001 - training loss: 0.1665, validation loss: 0.0719
2024-05-24 22:22:27 [INFO]: Epoch 002 - training loss: 0.0845, validation loss: 0.0462
2024-05-24 22:22:27 [INFO]: Epoch 003 - training loss: 0.0515, validation loss: 0.0325
2024-05-24 22:22:27 [INFO]: Epoch 004 - training loss: 0.0435, validation loss: 0.0292
2024-05-24 22:22:28 [INFO]: Epoch 005 - training loss: 0.0392, validation loss: 0.0272
2024-05-24 22:22:28 [INFO]: Epoch 006 - training loss: 0.0383, validation loss: 0.0267
2024-05-24 22:22:28 [INFO]: Epoch 007 - training loss: 0.0335, validation loss: 0.0249
2024-05-24 22:22:28 [INFO]: Epoch 008 - training loss: 0.0322, validation loss: 0.0229
2024-05-24 22:22:28 [INFO]: Epoch 009 - training loss: 0.0300, validation loss: 0.0233
2024-05-24 22:22:29 [INFO]: Epoch 010 - training loss: 0.0319, validation loss: 0.0223
2024-05-24 22:22:29 [INFO]: Epoch 011 - training loss: 0.0289, validation loss: 0.0226
2024-05-24 22:22:29 [INFO]: Epoch 012 - training loss: 0.0280, validation loss: 0.0227
2024-05-24 22:22:29 [INFO]: Epoch 013 - training loss: 0.0265, validation loss: 0.0226
2024-05-24 22:22:29 [INFO]: Epoch 014 - training loss: 0.0297, validation loss: 0.0237
2024-05-24 22:22:30 [INFO]: Epoch 015 - training loss: 0.0264, validation loss: 0.0222
2024-05-24 22:22:30 [INFO]: Epoch 016 - training loss: 0.0241, validation loss: 0.0214
2024-05-24 22:22:30 [INFO]: Epoch 017 - training loss: 0.0246, validation loss: 0.0210
2024-05-24 22:22:30 [INFO]: Epoch 018 - training loss: 0.0235, validation loss: 0.0211
2024-05-24 22:22:30 [INFO]: Epoch 019 - training loss: 0.0227, validation loss: 0.0214
2024-05-24 22:22:31 [INFO]: Epoch 020 - training loss: 0.0277, validation loss: 0.0226
2024-05-24 22:22:31 [INFO]: Epoch 021 - training loss: 0.0230, validation loss: 0.0232
2024-05-24 22:22:31 [INFO]: Epoch 022 - training loss: 0.0217, validation loss: 0.0211
2024-05-24 22:22:31 [INFO]: Epoch 023 - training loss: 0.0221, validation loss: 0.0218
2024-05-24 22:22:31 [INFO]: Epoch 024 - training loss: 0.0249, validation loss: 0.0223
2024-05-24 22:22:32 [INFO]: Epoch 025 - training loss: 0.0212, validation loss: 0.0217
2024-05-24 22:22:32 [INFO]: Epoch 026 - training loss: 0.0205, validation loss: 0.0214
2024-05-24 22:22:32 [INFO]: Epoch 027 - training loss: 0.0213, validation loss: 0.0218
2024-05-24 22:22:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:22:32 [INFO]: Finished training. The best model is from epoch#17.
2024-05-24 22:22:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/TimesNet_ettm1/20240524_T222227/TimesNet.pypots
2024-05-24 22:22:32 [INFO]: TimesNet on ETTm1: MAE=0.1051, MSE=0.0240
2024-05-24 22:22:32 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/TimesNet_ettm1/imputation.pkl
2024-05-24 22:22:32 [INFO]: Using the given device: cuda:0
2024-05-24 22:22:32 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232
2024-05-24 22:22:32 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/tensorboard
2024-05-24 22:22:32 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 22:22:34 [INFO]: Epoch 001 - training loss: 0.7370, validation loss: 0.5953
2024-05-24 22:22:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch1_loss0.5952961146831512.pypots
2024-05-24 22:22:36 [INFO]: Epoch 002 - training loss: 0.4126, validation loss: 0.3901
2024-05-24 22:22:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch2_loss0.39014654606580734.pypots
2024-05-24 22:22:38 [INFO]: Epoch 003 - training loss: 0.3817, validation loss: 0.3572
2024-05-24 22:22:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch3_loss0.35723090171813965.pypots
2024-05-24 22:22:40 [INFO]: Epoch 004 - training loss: 0.3245, validation loss: 0.3041
2024-05-24 22:22:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch4_loss0.30412519723176956.pypots
2024-05-24 22:22:42 [INFO]: Epoch 005 - training loss: 0.2818, validation loss: 0.2869
2024-05-24 22:22:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch5_loss0.28688888251781464.pypots
2024-05-24 22:22:44 [INFO]: Epoch 006 - training loss: 0.3032, validation loss: 0.2847
2024-05-24 22:22:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch6_loss0.2847137451171875.pypots
2024-05-24 22:22:46 [INFO]: Epoch 007 - training loss: 0.3341, validation loss: 0.2731
2024-05-24 22:22:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch7_loss0.2730657532811165.pypots
2024-05-24 22:22:48 [INFO]: Epoch 008 - training loss: 0.2768, validation loss: 0.2674
2024-05-24 22:22:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch8_loss0.26744892448186874.pypots
2024-05-24 22:22:50 [INFO]: Epoch 009 - training loss: 0.3315, validation loss: 0.2697
2024-05-24 22:22:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch9_loss0.2696554437279701.pypots
2024-05-24 22:22:52 [INFO]: Epoch 010 - training loss: 0.2866, validation loss: 0.2515
2024-05-24 22:22:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch10_loss0.25150344148278236.pypots
2024-05-24 22:22:54 [INFO]: Epoch 011 - training loss: 0.3207, validation loss: 0.2686
2024-05-24 22:22:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch11_loss0.26860251277685165.pypots
2024-05-24 22:22:57 [INFO]: Epoch 012 - training loss: 0.2778, validation loss: 0.2525
2024-05-24 22:22:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch12_loss0.2524557001888752.pypots
2024-05-24 22:22:59 [INFO]: Epoch 013 - training loss: 0.2252, validation loss: 0.2421
2024-05-24 22:22:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch13_loss0.24208565801382065.pypots
2024-05-24 22:23:01 [INFO]: Epoch 014 - training loss: 0.2224, validation loss: 0.2338
2024-05-24 22:23:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch14_loss0.23381051793694496.pypots
2024-05-24 22:23:03 [INFO]: Epoch 015 - training loss: 0.2318, validation loss: 0.2331
2024-05-24 22:23:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch15_loss0.23306535184383392.pypots
2024-05-24 22:23:05 [INFO]: Epoch 016 - training loss: 0.2522, validation loss: 0.2307
2024-05-24 22:23:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch16_loss0.23065271973609924.pypots
2024-05-24 22:23:07 [INFO]: Epoch 017 - training loss: 0.2571, validation loss: 0.2244
2024-05-24 22:23:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch17_loss0.22444625198841095.pypots
2024-05-24 22:23:09 [INFO]: Epoch 018 - training loss: 0.2355, validation loss: 0.2353
2024-05-24 22:23:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch18_loss0.23525680601596832.pypots
2024-05-24 22:23:11 [INFO]: Epoch 019 - training loss: 0.2802, validation loss: 0.2303
2024-05-24 22:23:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch19_loss0.23034758865833282.pypots
2024-05-24 22:23:13 [INFO]: Epoch 020 - training loss: 0.2624, validation loss: 0.2308
2024-05-24 22:23:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch20_loss0.23076250031590462.pypots
2024-05-24 22:23:15 [INFO]: Epoch 021 - training loss: 0.2175, validation loss: 0.2130
2024-05-24 22:23:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch21_loss0.21302620321512222.pypots
2024-05-24 22:23:17 [INFO]: Epoch 022 - training loss: 0.2124, validation loss: 0.2025
2024-05-24 22:23:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch22_loss0.20246997475624084.pypots
2024-05-24 22:23:19 [INFO]: Epoch 023 - training loss: 0.2180, validation loss: 0.1991
2024-05-24 22:23:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch23_loss0.19912319630384445.pypots
2024-05-24 22:23:21 [INFO]: Epoch 024 - training loss: 0.1790, validation loss: 0.1938
2024-05-24 22:23:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch24_loss0.19382155314087868.pypots
2024-05-24 22:23:23 [INFO]: Epoch 025 - training loss: 0.1786, validation loss: 0.1940
2024-05-24 22:23:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch25_loss0.19403865560889244.pypots
2024-05-24 22:23:25 [INFO]: Epoch 026 - training loss: 0.1981, validation loss: 0.1963
2024-05-24 22:23:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch26_loss0.19632498919963837.pypots
2024-05-24 22:23:27 [INFO]: Epoch 027 - training loss: 0.1920, validation loss: 0.1893
2024-05-24 22:23:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch27_loss0.18927396833896637.pypots
2024-05-24 22:23:29 [INFO]: Epoch 028 - training loss: 0.2021, validation loss: 0.1901
2024-05-24 22:23:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch28_loss0.19006182998418808.pypots
2024-05-24 22:23:31 [INFO]: Epoch 029 - training loss: 0.2133, validation loss: 0.1860
2024-05-24 22:23:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch29_loss0.18599950522184372.pypots
2024-05-24 22:23:33 [INFO]: Epoch 030 - training loss: 0.1719, validation loss: 0.1818
2024-05-24 22:23:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch30_loss0.18175336346030235.pypots
2024-05-24 22:23:35 [INFO]: Epoch 031 - training loss: 0.1688, validation loss: 0.1806
2024-05-24 22:23:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch31_loss0.1805664785206318.pypots
2024-05-24 22:23:37 [INFO]: Epoch 032 - training loss: 0.1484, validation loss: 0.1736
2024-05-24 22:23:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch32_loss0.17358915507793427.pypots
2024-05-24 22:23:40 [INFO]: Epoch 033 - training loss: 0.1696, validation loss: 0.1723
2024-05-24 22:23:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch33_loss0.17226450890302658.pypots
2024-05-24 22:23:42 [INFO]: Epoch 034 - training loss: 0.1829, validation loss: 0.1729
2024-05-24 22:23:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch34_loss0.17293251678347588.pypots
2024-05-24 22:23:44 [INFO]: Epoch 035 - training loss: 0.1720, validation loss: 0.1771
2024-05-24 22:23:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch35_loss0.17710895091295242.pypots
2024-05-24 22:23:46 [INFO]: Epoch 036 - training loss: 0.1791, validation loss: 0.1924
2024-05-24 22:23:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch36_loss0.19236504286527634.pypots
2024-05-24 22:23:48 [INFO]: Epoch 037 - training loss: 0.2424, validation loss: 0.1957
2024-05-24 22:23:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch37_loss0.19565923511981964.pypots
2024-05-24 22:23:50 [INFO]: Epoch 038 - training loss: 0.2170, validation loss: 0.1969
2024-05-24 22:23:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch38_loss0.1969159059226513.pypots
2024-05-24 22:23:52 [INFO]: Epoch 039 - training loss: 0.1694, validation loss: 0.1814
2024-05-24 22:23:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch39_loss0.18136592209339142.pypots
2024-05-24 22:23:54 [INFO]: Epoch 040 - training loss: 0.1879, validation loss: 0.1770
2024-05-24 22:23:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch40_loss0.1769731231033802.pypots
2024-05-24 22:23:56 [INFO]: Epoch 041 - training loss: 0.2632, validation loss: 0.1753
2024-05-24 22:23:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch41_loss0.17529333010315895.pypots
2024-05-24 22:23:58 [INFO]: Epoch 042 - training loss: 0.1949, validation loss: 0.1919
2024-05-24 22:23:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch42_loss0.19193175062537193.pypots
2024-05-24 22:24:00 [INFO]: Epoch 043 - training loss: 0.2106, validation loss: 0.1844
2024-05-24 22:24:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI_epoch43_loss0.18436836823821068.pypots
2024-05-24 22:24:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:24:00 [INFO]: Finished training. The best model is from epoch#33.
2024-05-24 22:24:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T222232/CSDI.pypots
2024-05-24 22:24:16 [INFO]: CSDI on ETTm1: MAE=0.1709, MSE=0.0700
2024-05-24 22:24:16 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/CSDI_ettm1/imputation.pkl
2024-05-24 22:24:16 [INFO]: Using the given device: cuda:0
2024-05-24 22:24:16 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/GPVAE_ettm1/20240524_T222416
2024-05-24 22:24:16 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/GPVAE_ettm1/20240524_T222416/tensorboard
2024-05-24 22:24:16 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 22:24:16 [INFO]: Epoch 001 - training loss: 23534.9307, validation loss: 0.9693
2024-05-24 22:24:16 [INFO]: Epoch 002 - training loss: 21426.3413, validation loss: 0.9665
2024-05-24 22:24:16 [INFO]: Epoch 003 - training loss: 19299.2827, validation loss: 0.9358
2024-05-24 22:24:16 [INFO]: Epoch 004 - training loss: 17473.9049, validation loss: 0.8736
2024-05-24 22:24:17 [INFO]: Epoch 005 - training loss: 15543.4178, validation loss: 0.7727
2024-05-24 22:24:17 [INFO]: Epoch 006 - training loss: 13822.9246, validation loss: 0.6567
2024-05-24 22:24:17 [INFO]: Epoch 007 - training loss: 12702.5462, validation loss: 0.5586
2024-05-24 22:24:17 [INFO]: Epoch 008 - training loss: 11689.2536, validation loss: 0.5048
2024-05-24 22:24:17 [INFO]: Epoch 009 - training loss: 11263.1956, validation loss: 0.4886
2024-05-24 22:24:17 [INFO]: Epoch 010 - training loss: 10936.3483, validation loss: 0.4784
2024-05-24 22:24:17 [INFO]: Epoch 011 - training loss: 10555.0525, validation loss: 0.4709
2024-05-24 22:24:18 [INFO]: Epoch 012 - training loss: 10390.8348, validation loss: 0.4657
2024-05-24 22:24:18 [INFO]: Epoch 013 - training loss: 10190.9079, validation loss: 0.4471
2024-05-24 22:24:18 [INFO]: Epoch 014 - training loss: 10076.8074, validation loss: 0.4297
2024-05-24 22:24:18 [INFO]: Epoch 015 - training loss: 10028.8748, validation loss: 0.4044
2024-05-24 22:24:18 [INFO]: Epoch 016 - training loss: 9916.5782, validation loss: 0.3773
2024-05-24 22:24:18 [INFO]: Epoch 017 - training loss: 9842.8404, validation loss: 0.3515
2024-05-24 22:24:18 [INFO]: Epoch 018 - training loss: 9774.6385, validation loss: 0.3245
2024-05-24 22:24:19 [INFO]: Epoch 019 - training loss: 9722.6550, validation loss: 0.3048
2024-05-24 22:24:19 [INFO]: Epoch 020 - training loss: 9677.3744, validation loss: 0.2905
2024-05-24 22:24:19 [INFO]: Epoch 021 - training loss: 9669.9700, validation loss: 0.2767
2024-05-24 22:24:19 [INFO]: Epoch 022 - training loss: 9621.6566, validation loss: 0.2662
2024-05-24 22:24:19 [INFO]: Epoch 023 - training loss: 9588.9645, validation loss: 0.2527
2024-05-24 22:24:19 [INFO]: Epoch 024 - training loss: 9563.4352, validation loss: 0.2474
2024-05-24 22:24:19 [INFO]: Epoch 025 - training loss: 9600.1560, validation loss: 0.2405
2024-05-24 22:24:20 [INFO]: Epoch 026 - training loss: 9533.4926, validation loss: 0.2354
2024-05-24 22:24:20 [INFO]: Epoch 027 - training loss: 9521.2518, validation loss: 0.2299
2024-05-24 22:24:20 [INFO]: Epoch 028 - training loss: 9500.5089, validation loss: 0.2282
2024-05-24 22:24:20 [INFO]: Epoch 029 - training loss: 9505.0999, validation loss: 0.2189
2024-05-24 22:24:20 [INFO]: Epoch 030 - training loss: 9478.4031, validation loss: 0.2139
2024-05-24 22:24:20 [INFO]: Epoch 031 - training loss: 9474.1008, validation loss: 0.2104
2024-05-24 22:24:20 [INFO]: Epoch 032 - training loss: 9457.2361, validation loss: 0.2058
2024-05-24 22:24:21 [INFO]: Epoch 033 - training loss: 9452.3342, validation loss: 0.2045
2024-05-24 22:24:21 [INFO]: Epoch 034 - training loss: 9445.9400, validation loss: 0.2006
2024-05-24 22:24:21 [INFO]: Epoch 035 - training loss: 9437.5691, validation loss: 0.1987
2024-05-24 22:24:21 [INFO]: Epoch 036 - training loss: 9449.3718, validation loss: 0.1914
2024-05-24 22:24:21 [INFO]: Epoch 037 - training loss: 9425.9498, validation loss: 0.1869
2024-05-24 22:24:21 [INFO]: Epoch 038 - training loss: 9417.7048, validation loss: 0.1777
2024-05-24 22:24:21 [INFO]: Epoch 039 - training loss: 9422.2416, validation loss: 0.1742
2024-05-24 22:24:22 [INFO]: Epoch 040 - training loss: 9408.0312, validation loss: 0.1719
2024-05-24 22:24:22 [INFO]: Epoch 041 - training loss: 9400.8336, validation loss: 0.1689
2024-05-24 22:24:22 [INFO]: Epoch 042 - training loss: 9398.6255, validation loss: 0.1704
2024-05-24 22:24:22 [INFO]: Epoch 043 - training loss: 9395.8871, validation loss: 0.1631
2024-05-24 22:24:22 [INFO]: Epoch 044 - training loss: 9392.2948, validation loss: 0.1545
2024-05-24 22:24:22 [INFO]: Epoch 045 - training loss: 9407.6564, validation loss: 0.1553
2024-05-24 22:24:22 [INFO]: Epoch 046 - training loss: 9393.2775, validation loss: 0.1541
2024-05-24 22:24:23 [INFO]: Epoch 047 - training loss: 9382.0819, validation loss: 0.1507
2024-05-24 22:24:23 [INFO]: Epoch 048 - training loss: 9391.2517, validation loss: 0.1484
2024-05-24 22:24:23 [INFO]: Epoch 049 - training loss: 9375.0160, validation loss: 0.1484
2024-05-24 22:24:23 [INFO]: Epoch 050 - training loss: 9376.5155, validation loss: 0.1504
2024-05-24 22:24:23 [INFO]: Epoch 051 - training loss: 9370.5690, validation loss: 0.1440
2024-05-24 22:24:23 [INFO]: Epoch 052 - training loss: 9366.9951, validation loss: 0.1457
2024-05-24 22:24:23 [INFO]: Epoch 053 - training loss: 9367.7742, validation loss: 0.1445
2024-05-24 22:24:24 [INFO]: Epoch 054 - training loss: 9362.7825, validation loss: 0.1421
2024-05-24 22:24:24 [INFO]: Epoch 055 - training loss: 9360.9075, validation loss: 0.1418
2024-05-24 22:24:24 [INFO]: Epoch 056 - training loss: 9363.0659, validation loss: 0.1400
2024-05-24 22:24:24 [INFO]: Epoch 057 - training loss: 9358.8733, validation loss: 0.1384
2024-05-24 22:24:24 [INFO]: Epoch 058 - training loss: 9355.2135, validation loss: 0.1383
2024-05-24 22:24:24 [INFO]: Epoch 059 - training loss: 9354.6341, validation loss: 0.1358
2024-05-24 22:24:24 [INFO]: Epoch 060 - training loss: 9352.6705, validation loss: 0.1348
2024-05-24 22:24:25 [INFO]: Epoch 061 - training loss: 9351.6536, validation loss: 0.1351
2024-05-24 22:24:25 [INFO]: Epoch 062 - training loss: 9349.4908, validation loss: 0.1346
2024-05-24 22:24:25 [INFO]: Epoch 063 - training loss: 9356.5923, validation loss: 0.1333
2024-05-24 22:24:25 [INFO]: Epoch 064 - training loss: 9346.6096, validation loss: 0.1315
2024-05-24 22:24:25 [INFO]: Epoch 065 - training loss: 9363.5168, validation loss: 0.1303
2024-05-24 22:24:25 [INFO]: Epoch 066 - training loss: 9344.8245, validation loss: 0.1289
2024-05-24 22:24:25 [INFO]: Epoch 067 - training loss: 9345.8056, validation loss: 0.1280
2024-05-24 22:24:26 [INFO]: Epoch 068 - training loss: 9343.1722, validation loss: 0.1285
2024-05-24 22:24:26 [INFO]: Epoch 069 - training loss: 9339.9328, validation loss: 0.1259
2024-05-24 22:24:26 [INFO]: Epoch 070 - training loss: 9340.1776, validation loss: 0.1253
2024-05-24 22:24:26 [INFO]: Epoch 071 - training loss: 9339.4432, validation loss: 0.1246
2024-05-24 22:24:26 [INFO]: Epoch 072 - training loss: 9339.8650, validation loss: 0.1251
2024-05-24 22:24:26 [INFO]: Epoch 073 - training loss: 9337.8270, validation loss: 0.1243
2024-05-24 22:24:26 [INFO]: Epoch 074 - training loss: 9338.8004, validation loss: 0.1238
2024-05-24 22:24:27 [INFO]: Epoch 075 - training loss: 9335.1462, validation loss: 0.1225
2024-05-24 22:24:27 [INFO]: Epoch 076 - training loss: 9335.0928, validation loss: 0.1222
2024-05-24 22:24:27 [INFO]: Epoch 077 - training loss: 9335.6983, validation loss: 0.1227
2024-05-24 22:24:27 [INFO]: Epoch 078 - training loss: 9333.2258, validation loss: 0.1187
2024-05-24 22:24:27 [INFO]: Epoch 079 - training loss: 9332.7084, validation loss: 0.1188
2024-05-24 22:24:27 [INFO]: Epoch 080 - training loss: 9336.8946, validation loss: 0.1173
2024-05-24 22:24:27 [INFO]: Epoch 081 - training loss: 9333.7742, validation loss: 0.1170
2024-05-24 22:24:28 [INFO]: Epoch 082 - training loss: 9330.0752, validation loss: 0.1162
2024-05-24 22:24:28 [INFO]: Epoch 083 - training loss: 9329.9625, validation loss: 0.1163
2024-05-24 22:24:28 [INFO]: Epoch 084 - training loss: 9330.0535, validation loss: 0.1150
2024-05-24 22:24:28 [INFO]: Epoch 085 - training loss: 9328.2332, validation loss: 0.1150
2024-05-24 22:24:28 [INFO]: Epoch 086 - training loss: 9327.8976, validation loss: 0.1141
2024-05-24 22:24:28 [INFO]: Epoch 087 - training loss: 9330.3577, validation loss: 0.1131
2024-05-24 22:24:28 [INFO]: Epoch 088 - training loss: 9327.8861, validation loss: 0.1136
2024-05-24 22:24:29 [INFO]: Epoch 089 - training loss: 9327.9875, validation loss: 0.1119
2024-05-24 22:24:29 [INFO]: Epoch 090 - training loss: 9327.9165, validation loss: 0.1121
2024-05-24 22:24:29 [INFO]: Epoch 091 - training loss: 9326.3112, validation loss: 0.1110
2024-05-24 22:24:29 [INFO]: Epoch 092 - training loss: 9325.5732, validation loss: 0.1112
2024-05-24 22:24:29 [INFO]: Epoch 093 - training loss: 9323.9941, validation loss: 0.1098
2024-05-24 22:24:29 [INFO]: Epoch 094 - training loss: 9324.1753, validation loss: 0.1085
2024-05-24 22:24:29 [INFO]: Epoch 095 - training loss: 9324.8286, validation loss: 0.1081
2024-05-24 22:24:30 [INFO]: Epoch 096 - training loss: 9326.1500, validation loss: 0.1077
2024-05-24 22:24:30 [INFO]: Epoch 097 - training loss: 9323.7706, validation loss: 0.1064
2024-05-24 22:24:30 [INFO]: Epoch 098 - training loss: 9321.2620, validation loss: 0.1060
2024-05-24 22:24:30 [INFO]: Epoch 099 - training loss: 9323.6263, validation loss: 0.1065
2024-05-24 22:24:30 [INFO]: Epoch 100 - training loss: 9322.9779, validation loss: 0.1065
2024-05-24 22:24:30 [INFO]: Epoch 101 - training loss: 9322.1738, validation loss: 0.1053
2024-05-24 22:24:30 [INFO]: Epoch 102 - training loss: 9320.1894, validation loss: 0.1060
2024-05-24 22:24:31 [INFO]: Epoch 103 - training loss: 9321.4433, validation loss: 0.1042
2024-05-24 22:24:31 [INFO]: Epoch 104 - training loss: 9325.9166, validation loss: 0.1039
2024-05-24 22:24:31 [INFO]: Epoch 105 - training loss: 9319.2782, validation loss: 0.1020
2024-05-24 22:24:31 [INFO]: Epoch 106 - training loss: 9318.3298, validation loss: 0.1039
2024-05-24 22:24:31 [INFO]: Epoch 107 - training loss: 9322.4202, validation loss: 0.1030
2024-05-24 22:24:31 [INFO]: Epoch 108 - training loss: 9320.4924, validation loss: 0.1020
2024-05-24 22:24:31 [INFO]: Epoch 109 - training loss: 9318.6201, validation loss: 0.1017
2024-05-24 22:24:32 [INFO]: Epoch 110 - training loss: 9318.4160, validation loss: 0.1006
2024-05-24 22:24:32 [INFO]: Epoch 111 - training loss: 9317.9969, validation loss: 0.1001
2024-05-24 22:24:32 [INFO]: Epoch 112 - training loss: 9317.6413, validation loss: 0.0987
2024-05-24 22:24:32 [INFO]: Epoch 113 - training loss: 9318.2139, validation loss: 0.0995
2024-05-24 22:24:32 [INFO]: Epoch 114 - training loss: 9316.3487, validation loss: 0.0988
2024-05-24 22:24:32 [INFO]: Epoch 115 - training loss: 9316.1461, validation loss: 0.0978
2024-05-24 22:24:32 [INFO]: Epoch 116 - training loss: 9318.0483, validation loss: 0.0975
2024-05-24 22:24:33 [INFO]: Epoch 117 - training loss: 9315.9072, validation loss: 0.0970
2024-05-24 22:24:33 [INFO]: Epoch 118 - training loss: 9315.4965, validation loss: 0.0978
2024-05-24 22:24:33 [INFO]: Epoch 119 - training loss: 9316.1873, validation loss: 0.0957
2024-05-24 22:24:33 [INFO]: Epoch 120 - training loss: 9314.7539, validation loss: 0.0966
2024-05-24 22:24:33 [INFO]: Epoch 121 - training loss: 9316.9099, validation loss: 0.0953
2024-05-24 22:24:33 [INFO]: Epoch 122 - training loss: 9316.1672, validation loss: 0.0960
2024-05-24 22:24:33 [INFO]: Epoch 123 - training loss: 9314.1281, validation loss: 0.0930
2024-05-24 22:24:34 [INFO]: Epoch 124 - training loss: 9314.8157, validation loss: 0.0939
2024-05-24 22:24:34 [INFO]: Epoch 125 - training loss: 9314.2562, validation loss: 0.0924
2024-05-24 22:24:34 [INFO]: Epoch 126 - training loss: 9315.5554, validation loss: 0.0934
2024-05-24 22:24:34 [INFO]: Epoch 127 - training loss: 9314.8370, validation loss: 0.0928
2024-05-24 22:24:34 [INFO]: Epoch 128 - training loss: 9314.1749, validation loss: 0.0920
2024-05-24 22:24:34 [INFO]: Epoch 129 - training loss: 9312.1376, validation loss: 0.0903
2024-05-24 22:24:34 [INFO]: Epoch 130 - training loss: 9313.2644, validation loss: 0.0928
2024-05-24 22:24:35 [INFO]: Epoch 131 - training loss: 9312.3736, validation loss: 0.0915
2024-05-24 22:24:35 [INFO]: Epoch 132 - training loss: 9311.9214, validation loss: 0.0910
2024-05-24 22:24:35 [INFO]: Epoch 133 - training loss: 9312.7060, validation loss: 0.0919
2024-05-24 22:24:35 [INFO]: Epoch 134 - training loss: 9312.3212, validation loss: 0.0894
2024-05-24 22:24:35 [INFO]: Epoch 135 - training loss: 9312.6154, validation loss: 0.0893
2024-05-24 22:24:35 [INFO]: Epoch 136 - training loss: 9313.4467, validation loss: 0.0904
2024-05-24 22:24:35 [INFO]: Epoch 137 - training loss: 9312.1064, validation loss: 0.0893
2024-05-24 22:24:36 [INFO]: Epoch 138 - training loss: 9312.1793, validation loss: 0.0886
2024-05-24 22:24:36 [INFO]: Epoch 139 - training loss: 9310.3881, validation loss: 0.0878
2024-05-24 22:24:36 [INFO]: Epoch 140 - training loss: 9309.9655, validation loss: 0.0887
2024-05-24 22:24:36 [INFO]: Epoch 141 - training loss: 9312.4803, validation loss: 0.0871
2024-05-24 22:24:36 [INFO]: Epoch 142 - training loss: 9314.1204, validation loss: 0.0866
2024-05-24 22:24:36 [INFO]: Epoch 143 - training loss: 9310.8345, validation loss: 0.0858
2024-05-24 22:24:36 [INFO]: Epoch 144 - training loss: 9310.6962, validation loss: 0.0857
2024-05-24 22:24:37 [INFO]: Epoch 145 - training loss: 9309.0554, validation loss: 0.0865
2024-05-24 22:24:37 [INFO]: Epoch 146 - training loss: 9309.7587, validation loss: 0.0861
2024-05-24 22:24:37 [INFO]: Epoch 147 - training loss: 9310.1931, validation loss: 0.0860
2024-05-24 22:24:37 [INFO]: Epoch 148 - training loss: 9309.6312, validation loss: 0.0857
2024-05-24 22:24:37 [INFO]: Epoch 149 - training loss: 9311.0707, validation loss: 0.0848
2024-05-24 22:24:37 [INFO]: Epoch 150 - training loss: 9308.7698, validation loss: 0.0847
2024-05-24 22:24:37 [INFO]: Epoch 151 - training loss: 9310.6895, validation loss: 0.0846
2024-05-24 22:24:38 [INFO]: Epoch 152 - training loss: 9308.1527, validation loss: 0.0857
2024-05-24 22:24:38 [INFO]: Epoch 153 - training loss: 9309.0588, validation loss: 0.0832
2024-05-24 22:24:38 [INFO]: Epoch 154 - training loss: 9309.2239, validation loss: 0.0839
2024-05-24 22:24:38 [INFO]: Epoch 155 - training loss: 9309.0554, validation loss: 0.0836
2024-05-24 22:24:38 [INFO]: Epoch 156 - training loss: 9307.8043, validation loss: 0.0833
2024-05-24 22:24:38 [INFO]: Epoch 157 - training loss: 9309.9888, validation loss: 0.0828
2024-05-24 22:24:38 [INFO]: Epoch 158 - training loss: 9309.4224, validation loss: 0.0839
2024-05-24 22:24:39 [INFO]: Epoch 159 - training loss: 9307.6996, validation loss: 0.0831
2024-05-24 22:24:39 [INFO]: Epoch 160 - training loss: 9308.3453, validation loss: 0.0829
2024-05-24 22:24:39 [INFO]: Epoch 161 - training loss: 9308.5927, validation loss: 0.0826
2024-05-24 22:24:39 [INFO]: Epoch 162 - training loss: 9308.1033, validation loss: 0.0829
2024-05-24 22:24:39 [INFO]: Epoch 163 - training loss: 9307.0614, validation loss: 0.0825
2024-05-24 22:24:39 [INFO]: Epoch 164 - training loss: 9307.3678, validation loss: 0.0820
2024-05-24 22:24:39 [INFO]: Epoch 165 - training loss: 9307.3708, validation loss: 0.0817
2024-05-24 22:24:40 [INFO]: Epoch 166 - training loss: 9306.3986, validation loss: 0.0827
2024-05-24 22:24:40 [INFO]: Epoch 167 - training loss: 9307.2200, validation loss: 0.0807
2024-05-24 22:24:40 [INFO]: Epoch 168 - training loss: 9306.1497, validation loss: 0.0811
2024-05-24 22:24:40 [INFO]: Epoch 169 - training loss: 9307.0918, validation loss: 0.0813
2024-05-24 22:24:40 [INFO]: Epoch 170 - training loss: 9306.3362, validation loss: 0.0805
2024-05-24 22:24:40 [INFO]: Epoch 171 - training loss: 9305.9188, validation loss: 0.0790
2024-05-24 22:24:40 [INFO]: Epoch 172 - training loss: 9307.9127, validation loss: 0.0798
2024-05-24 22:24:41 [INFO]: Epoch 173 - training loss: 9305.5576, validation loss: 0.0794
2024-05-24 22:24:41 [INFO]: Epoch 174 - training loss: 9306.5120, validation loss: 0.0806
2024-05-24 22:24:41 [INFO]: Epoch 175 - training loss: 9305.6509, validation loss: 0.0791
2024-05-24 22:24:41 [INFO]: Epoch 176 - training loss: 9306.6056, validation loss: 0.0807
2024-05-24 22:24:41 [INFO]: Epoch 177 - training loss: 9306.3560, validation loss: 0.0782
2024-05-24 22:24:41 [INFO]: Epoch 178 - training loss: 9306.4036, validation loss: 0.0798
2024-05-24 22:24:41 [INFO]: Epoch 179 - training loss: 9307.1608, validation loss: 0.0788
2024-05-24 22:24:42 [INFO]: Epoch 180 - training loss: 9306.5593, validation loss: 0.0768
2024-05-24 22:24:42 [INFO]: Epoch 181 - training loss: 9305.2226, validation loss: 0.0796
2024-05-24 22:24:42 [INFO]: Epoch 182 - training loss: 9310.5231, validation loss: 0.0793
2024-05-24 22:24:42 [INFO]: Epoch 183 - training loss: 9305.5328, validation loss: 0.0801
2024-05-24 22:24:42 [INFO]: Epoch 184 - training loss: 9305.3725, validation loss: 0.0792
2024-05-24 22:24:42 [INFO]: Epoch 185 - training loss: 9305.9208, validation loss: 0.0784
2024-05-24 22:24:42 [INFO]: Epoch 186 - training loss: 9305.4262, validation loss: 0.0775
2024-05-24 22:24:43 [INFO]: Epoch 187 - training loss: 9304.0732, validation loss: 0.0774
2024-05-24 22:24:43 [INFO]: Epoch 188 - training loss: 9305.3307, validation loss: 0.0778
2024-05-24 22:24:43 [INFO]: Epoch 189 - training loss: 9304.5291, validation loss: 0.0790
2024-05-24 22:24:43 [INFO]: Epoch 190 - training loss: 9305.4762, validation loss: 0.0777
2024-05-24 22:24:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:24:43 [INFO]: Finished training. The best model is from epoch#180.
2024-05-24 22:24:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/GPVAE_ettm1/20240524_T222416/GPVAE.pypots
2024-05-24 22:24:43 [INFO]: GP-VAE on ETTm1: MAE=0.2919, MSE=0.1697
2024-05-24 22:24:43 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/GPVAE_ettm1/imputation.pkl
2024-05-24 22:24:43 [INFO]: Using the given device: cuda:0
2024-05-24 22:24:43 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/USGAN_ettm1/20240524_T222443
2024-05-24 22:24:43 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/USGAN_ettm1/20240524_T222443/tensorboard
2024-05-24 22:24:43 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 22:24:54 [INFO]: Epoch 001 - generator training loss: 0.5240, discriminator training loss: 0.3243, validation loss: 0.2802
2024-05-24 22:25:03 [INFO]: Epoch 002 - generator training loss: 0.0257, discriminator training loss: 0.2077, validation loss: 0.1001
2024-05-24 22:25:12 [INFO]: Epoch 003 - generator training loss: -0.0624, discriminator training loss: 0.1977, validation loss: 0.0577
2024-05-24 22:25:21 [INFO]: Epoch 004 - generator training loss: -0.0835, discriminator training loss: 0.1973, validation loss: 0.0471
2024-05-24 22:25:30 [INFO]: Epoch 005 - generator training loss: -0.0852, discriminator training loss: 0.1901, validation loss: 0.0416
2024-05-24 22:25:39 [INFO]: Epoch 006 - generator training loss: -0.0850, discriminator training loss: 0.1875, validation loss: 0.0387
2024-05-24 22:25:48 [INFO]: Epoch 007 - generator training loss: -0.0785, discriminator training loss: 0.1795, validation loss: 0.0371
2024-05-24 22:25:57 [INFO]: Epoch 008 - generator training loss: -0.0718, discriminator training loss: 0.1697, validation loss: 0.0349
2024-05-24 22:26:06 [INFO]: Epoch 009 - generator training loss: -0.0626, discriminator training loss: 0.1581, validation loss: 0.0355
2024-05-24 22:26:15 [INFO]: Epoch 010 - generator training loss: -0.0548, discriminator training loss: 0.1456, validation loss: 0.0341
2024-05-24 22:26:24 [INFO]: Epoch 011 - generator training loss: -0.0425, discriminator training loss: 0.1304, validation loss: 0.0336
2024-05-24 22:26:33 [INFO]: Epoch 012 - generator training loss: -0.0315, discriminator training loss: 0.1154, validation loss: 0.0325
2024-05-24 22:26:42 [INFO]: Epoch 013 - generator training loss: -0.0282, discriminator training loss: 0.1083, validation loss: 0.0314
2024-05-24 22:26:52 [INFO]: Epoch 014 - generator training loss: -0.0230, discriminator training loss: 0.1004, validation loss: 0.0318
2024-05-24 22:27:01 [INFO]: Epoch 015 - generator training loss: -0.0170, discriminator training loss: 0.0931, validation loss: 0.0309
2024-05-24 22:27:10 [INFO]: Epoch 016 - generator training loss: -0.0154, discriminator training loss: 0.0902, validation loss: 0.0301
2024-05-24 22:27:19 [INFO]: Epoch 017 - generator training loss: -0.0181, discriminator training loss: 0.0892, validation loss: 0.0301
2024-05-24 22:27:28 [INFO]: Epoch 018 - generator training loss: -0.0145, discriminator training loss: 0.0841, validation loss: 0.0299
2024-05-24 22:27:37 [INFO]: Epoch 019 - generator training loss: -0.0171, discriminator training loss: 0.0833, validation loss: 0.0291
2024-05-24 22:27:46 [INFO]: Epoch 020 - generator training loss: -0.0172, discriminator training loss: 0.0814, validation loss: 0.0288
2024-05-24 22:27:55 [INFO]: Epoch 021 - generator training loss: -0.0153, discriminator training loss: 0.0790, validation loss: 0.0279
2024-05-24 22:28:04 [INFO]: Epoch 022 - generator training loss: -0.0167, discriminator training loss: 0.0802, validation loss: 0.0278
2024-05-24 22:28:13 [INFO]: Epoch 023 - generator training loss: -0.0155, discriminator training loss: 0.0795, validation loss: 0.0274
2024-05-24 22:28:22 [INFO]: Epoch 024 - generator training loss: -0.0156, discriminator training loss: 0.0799, validation loss: 0.0270
2024-05-24 22:28:31 [INFO]: Epoch 025 - generator training loss: -0.0152, discriminator training loss: 0.0775, validation loss: 0.0264
2024-05-24 22:28:40 [INFO]: Epoch 026 - generator training loss: -0.0142, discriminator training loss: 0.0750, validation loss: 0.0263
2024-05-24 22:28:49 [INFO]: Epoch 027 - generator training loss: -0.0170, discriminator training loss: 0.0747, validation loss: 0.0261
2024-05-24 22:28:59 [INFO]: Epoch 028 - generator training loss: -0.0178, discriminator training loss: 0.0740, validation loss: 0.0257
2024-05-24 22:29:08 [INFO]: Epoch 029 - generator training loss: -0.0169, discriminator training loss: 0.0760, validation loss: 0.0250
2024-05-24 22:29:17 [INFO]: Epoch 030 - generator training loss: -0.0187, discriminator training loss: 0.0745, validation loss: 0.0250
2024-05-24 22:29:26 [INFO]: Epoch 031 - generator training loss: -0.0171, discriminator training loss: 0.0732, validation loss: 0.0247
2024-05-24 22:29:35 [INFO]: Epoch 032 - generator training loss: -0.0159, discriminator training loss: 0.0734, validation loss: 0.0248
2024-05-24 22:29:44 [INFO]: Epoch 033 - generator training loss: -0.0165, discriminator training loss: 0.0729, validation loss: 0.0240
2024-05-24 22:29:53 [INFO]: Epoch 034 - generator training loss: -0.0192, discriminator training loss: 0.0736, validation loss: 0.0239
2024-05-24 22:30:02 [INFO]: Epoch 035 - generator training loss: -0.0189, discriminator training loss: 0.0736, validation loss: 0.0233
2024-05-24 22:30:11 [INFO]: Epoch 036 - generator training loss: -0.0204, discriminator training loss: 0.0721, validation loss: 0.0233
2024-05-24 22:30:20 [INFO]: Epoch 037 - generator training loss: -0.0195, discriminator training loss: 0.0727, validation loss: 0.0232
2024-05-24 22:30:29 [INFO]: Epoch 038 - generator training loss: -0.0203, discriminator training loss: 0.0733, validation loss: 0.0224
2024-05-24 22:30:38 [INFO]: Epoch 039 - generator training loss: -0.0182, discriminator training loss: 0.0747, validation loss: 0.0224
2024-05-24 22:30:47 [INFO]: Epoch 040 - generator training loss: -0.0198, discriminator training loss: 0.0701, validation loss: 0.0223
2024-05-24 22:30:56 [INFO]: Epoch 041 - generator training loss: -0.0214, discriminator training loss: 0.0710, validation loss: 0.0220
2024-05-24 22:31:06 [INFO]: Epoch 042 - generator training loss: -0.0208, discriminator training loss: 0.0697, validation loss: 0.0216
2024-05-24 22:31:15 [INFO]: Epoch 043 - generator training loss: -0.0202, discriminator training loss: 0.0701, validation loss: 0.0214
2024-05-24 22:31:24 [INFO]: Epoch 044 - generator training loss: -0.0209, discriminator training loss: 0.0702, validation loss: 0.0212
2024-05-24 22:31:33 [INFO]: Epoch 045 - generator training loss: -0.0237, discriminator training loss: 0.0713, validation loss: 0.0216
2024-05-24 22:31:42 [INFO]: Epoch 046 - generator training loss: -0.0198, discriminator training loss: 0.0710, validation loss: 0.0210
2024-05-24 22:31:51 [INFO]: Epoch 047 - generator training loss: -0.0225, discriminator training loss: 0.0695, validation loss: 0.0206
2024-05-24 22:32:00 [INFO]: Epoch 048 - generator training loss: -0.0210, discriminator training loss: 0.0714, validation loss: 0.0204
2024-05-24 22:32:09 [INFO]: Epoch 049 - generator training loss: -0.0204, discriminator training loss: 0.0698, validation loss: 0.0223
2024-05-24 22:32:18 [INFO]: Epoch 050 - generator training loss: -0.0203, discriminator training loss: 0.0689, validation loss: 0.0218
2024-05-24 22:32:27 [INFO]: Epoch 051 - generator training loss: -0.0211, discriminator training loss: 0.0721, validation loss: 0.0217
2024-05-24 22:32:36 [INFO]: Epoch 052 - generator training loss: -0.0218, discriminator training loss: 0.0710, validation loss: 0.0207
2024-05-24 22:32:45 [INFO]: Epoch 053 - generator training loss: -0.0210, discriminator training loss: 0.0695, validation loss: 0.0206
2024-05-24 22:32:54 [INFO]: Epoch 054 - generator training loss: -0.0236, discriminator training loss: 0.0703, validation loss: 0.0205
2024-05-24 22:33:03 [INFO]: Epoch 055 - generator training loss: -0.0246, discriminator training loss: 0.0715, validation loss: 0.0204
2024-05-24 22:33:12 [INFO]: Epoch 056 - generator training loss: -0.0221, discriminator training loss: 0.0686, validation loss: 0.0206
2024-05-24 22:33:21 [INFO]: Epoch 057 - generator training loss: -0.0221, discriminator training loss: 0.0696, validation loss: 0.0200
2024-05-24 22:33:30 [INFO]: Epoch 058 - generator training loss: -0.0213, discriminator training loss: 0.0676, validation loss: 0.0199
2024-05-24 22:33:39 [INFO]: Epoch 059 - generator training loss: -0.0217, discriminator training loss: 0.0692, validation loss: 0.0201
2024-05-24 22:33:48 [INFO]: Epoch 060 - generator training loss: -0.0233, discriminator training loss: 0.0682, validation loss: 0.0197
2024-05-24 22:33:57 [INFO]: Epoch 061 - generator training loss: -0.0222, discriminator training loss: 0.0685, validation loss: 0.0200
2024-05-24 22:34:06 [INFO]: Epoch 062 - generator training loss: -0.0215, discriminator training loss: 0.0702, validation loss: 0.0198
2024-05-24 22:34:15 [INFO]: Epoch 063 - generator training loss: -0.0200, discriminator training loss: 0.0667, validation loss: 0.0193
2024-05-24 22:34:24 [INFO]: Epoch 064 - generator training loss: -0.0210, discriminator training loss: 0.0682, validation loss: 0.0197
2024-05-24 22:34:33 [INFO]: Epoch 065 - generator training loss: -0.0234, discriminator training loss: 0.0673, validation loss: 0.0197
2024-05-24 22:34:42 [INFO]: Epoch 066 - generator training loss: -0.0225, discriminator training loss: 0.0706, validation loss: 0.0196
2024-05-24 22:34:51 [INFO]: Epoch 067 - generator training loss: -0.0216, discriminator training loss: 0.0703, validation loss: 0.0205
2024-05-24 22:35:00 [INFO]: Epoch 068 - generator training loss: -0.0233, discriminator training loss: 0.0681, validation loss: 0.0192
2024-05-24 22:35:09 [INFO]: Epoch 069 - generator training loss: -0.0231, discriminator training loss: 0.0655, validation loss: 0.0194
2024-05-24 22:35:18 [INFO]: Epoch 070 - generator training loss: -0.0216, discriminator training loss: 0.0682, validation loss: 0.0208
2024-05-24 22:35:27 [INFO]: Epoch 071 - generator training loss: -0.0210, discriminator training loss: 0.0711, validation loss: 0.0189
2024-05-24 22:35:36 [INFO]: Epoch 072 - generator training loss: -0.0218, discriminator training loss: 0.0711, validation loss: 0.0203
2024-05-24 22:35:45 [INFO]: Epoch 073 - generator training loss: -0.0213, discriminator training loss: 0.0673, validation loss: 0.0192
2024-05-24 22:35:55 [INFO]: Epoch 074 - generator training loss: -0.0212, discriminator training loss: 0.0691, validation loss: 0.0204
2024-05-24 22:36:04 [INFO]: Epoch 075 - generator training loss: -0.0236, discriminator training loss: 0.0674, validation loss: 0.0215
2024-05-24 22:36:13 [INFO]: Epoch 076 - generator training loss: -0.0183, discriminator training loss: 0.0691, validation loss: 0.0201
2024-05-24 22:36:22 [INFO]: Epoch 077 - generator training loss: -0.0201, discriminator training loss: 0.0699, validation loss: 0.0196
2024-05-24 22:36:31 [INFO]: Epoch 078 - generator training loss: -0.0238, discriminator training loss: 0.0671, validation loss: 0.0197
2024-05-24 22:36:40 [INFO]: Epoch 079 - generator training loss: -0.0217, discriminator training loss: 0.0691, validation loss: 0.0192
2024-05-24 22:36:49 [INFO]: Epoch 080 - generator training loss: -0.0190, discriminator training loss: 0.0667, validation loss: 0.0194
2024-05-24 22:36:58 [INFO]: Epoch 081 - generator training loss: -0.0231, discriminator training loss: 0.0659, validation loss: 0.0193
2024-05-24 22:36:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:36:58 [INFO]: Finished training. The best model is from epoch#71.
2024-05-24 22:36:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/USGAN_ettm1/20240524_T222443/USGAN.pypots
2024-05-24 22:36:59 [INFO]: US-GAN on ETTm1: MAE=0.1424, MSE=0.0529
2024-05-24 22:36:59 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/USGAN_ettm1/imputation.pkl
2024-05-24 22:36:59 [INFO]: Using the given device: cuda:0
2024-05-24 22:36:59 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/BRITS_ettm1/20240524_T223659
2024-05-24 22:36:59 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/BRITS_ettm1/20240524_T223659/tensorboard
2024-05-24 22:36:59 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 22:37:07 [INFO]: Epoch 001 - training loss: 1.2173, validation loss: 0.2743
2024-05-24 22:37:13 [INFO]: Epoch 002 - training loss: 0.7996, validation loss: 0.0785
2024-05-24 22:37:19 [INFO]: Epoch 003 - training loss: 0.6383, validation loss: 0.0482
2024-05-24 22:37:25 [INFO]: Epoch 004 - training loss: 0.5644, validation loss: 0.0399
2024-05-24 22:37:31 [INFO]: Epoch 005 - training loss: 0.5345, validation loss: 0.0354
2024-05-24 22:37:37 [INFO]: Epoch 006 - training loss: 0.5092, validation loss: 0.0323
2024-05-24 22:37:43 [INFO]: Epoch 007 - training loss: 0.4790, validation loss: 0.0312
2024-05-24 22:37:49 [INFO]: Epoch 008 - training loss: 0.4576, validation loss: 0.0282
2024-05-24 22:37:55 [INFO]: Epoch 009 - training loss: 0.4370, validation loss: 0.0283
2024-05-24 22:38:01 [INFO]: Epoch 010 - training loss: 0.4437, validation loss: 0.0253
2024-05-24 22:38:07 [INFO]: Epoch 011 - training loss: 0.4282, validation loss: 0.0250
2024-05-24 22:38:13 [INFO]: Epoch 012 - training loss: 0.4250, validation loss: 0.0251
2024-05-24 22:38:19 [INFO]: Epoch 013 - training loss: 0.4047, validation loss: 0.0238
2024-05-24 22:38:25 [INFO]: Epoch 014 - training loss: 0.3976, validation loss: 0.0235
2024-05-24 22:38:31 [INFO]: Epoch 015 - training loss: 0.4034, validation loss: 0.0236
2024-05-24 22:38:37 [INFO]: Epoch 016 - training loss: 0.3959, validation loss: 0.0229
2024-05-24 22:38:43 [INFO]: Epoch 017 - training loss: 0.3917, validation loss: 0.0226
2024-05-24 22:38:49 [INFO]: Epoch 018 - training loss: 0.3919, validation loss: 0.0226
2024-05-24 22:38:55 [INFO]: Epoch 019 - training loss: 0.3951, validation loss: 0.0231
2024-05-24 22:39:01 [INFO]: Epoch 020 - training loss: 0.3885, validation loss: 0.0228
2024-05-24 22:39:07 [INFO]: Epoch 021 - training loss: 0.3848, validation loss: 0.0224
2024-05-24 22:39:13 [INFO]: Epoch 022 - training loss: 0.3951, validation loss: 0.0222
2024-05-24 22:39:19 [INFO]: Epoch 023 - training loss: 0.3843, validation loss: 0.0229
2024-05-24 22:39:25 [INFO]: Epoch 024 - training loss: 0.3985, validation loss: 0.0225
2024-05-24 22:39:31 [INFO]: Epoch 025 - training loss: 0.3953, validation loss: 0.0223
2024-05-24 22:39:37 [INFO]: Epoch 026 - training loss: 0.3874, validation loss: 0.0223
2024-05-24 22:39:43 [INFO]: Epoch 027 - training loss: 0.4012, validation loss: 0.0221
2024-05-24 22:39:49 [INFO]: Epoch 028 - training loss: 0.3808, validation loss: 0.0226
2024-05-24 22:39:55 [INFO]: Epoch 029 - training loss: 0.3773, validation loss: 0.0221
2024-05-24 22:40:01 [INFO]: Epoch 030 - training loss: 0.3909, validation loss: 0.0220
2024-05-24 22:40:07 [INFO]: Epoch 031 - training loss: 0.3804, validation loss: 0.0224
2024-05-24 22:40:13 [INFO]: Epoch 032 - training loss: 0.3893, validation loss: 0.0224
2024-05-24 22:40:19 [INFO]: Epoch 033 - training loss: 0.3778, validation loss: 0.0217
2024-05-24 22:40:25 [INFO]: Epoch 034 - training loss: 0.3869, validation loss: 0.0218
2024-05-24 22:40:31 [INFO]: Epoch 035 - training loss: 0.3812, validation loss: 0.0219
2024-05-24 22:40:37 [INFO]: Epoch 036 - training loss: 0.3764, validation loss: 0.0222
2024-05-24 22:40:44 [INFO]: Epoch 037 - training loss: 0.3734, validation loss: 0.0218
2024-05-24 22:40:50 [INFO]: Epoch 038 - training loss: 0.3758, validation loss: 0.0230
2024-05-24 22:40:56 [INFO]: Epoch 039 - training loss: 0.3736, validation loss: 0.0224
2024-05-24 22:41:02 [INFO]: Epoch 040 - training loss: 0.3741, validation loss: 0.0225
2024-05-24 22:41:08 [INFO]: Epoch 041 - training loss: 0.3770, validation loss: 0.0224
2024-05-24 22:41:14 [INFO]: Epoch 042 - training loss: 0.3757, validation loss: 0.0220
2024-05-24 22:41:20 [INFO]: Epoch 043 - training loss: 0.3730, validation loss: 0.0219
2024-05-24 22:41:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:41:20 [INFO]: Finished training. The best model is from epoch#33.
2024-05-24 22:41:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/BRITS_ettm1/20240524_T223659/BRITS.pypots
2024-05-24 22:41:21 [INFO]: BRITS on ETTm1: MAE=0.1284, MSE=0.0505
2024-05-24 22:41:21 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/BRITS_ettm1/imputation.pkl
2024-05-24 22:41:21 [INFO]: Using the given device: cuda:0
2024-05-24 22:41:21 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121
2024-05-24 22:41:21 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/tensorboard
2024-05-24 22:41:21 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 22:41:23 [INFO]: Epoch 001 - training loss: 1.3736, validation loss: 1.3247
2024-05-24 22:41:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch1_loss1.3246746063232422.pypots
2024-05-24 22:41:23 [INFO]: Epoch 002 - training loss: 1.0973, validation loss: 1.1857
2024-05-24 22:41:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch2_loss1.1857020854949951.pypots
2024-05-24 22:41:23 [INFO]: Epoch 003 - training loss: 1.0152, validation loss: 1.1155
2024-05-24 22:41:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch3_loss1.1154769212007523.pypots
2024-05-24 22:41:23 [INFO]: Epoch 004 - training loss: 0.9847, validation loss: 1.0847
2024-05-24 22:41:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch4_loss1.0847446024417877.pypots
2024-05-24 22:41:23 [INFO]: Epoch 005 - training loss: 1.0314, validation loss: 1.0679
2024-05-24 22:41:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch5_loss1.0678682029247284.pypots
2024-05-24 22:41:24 [INFO]: Epoch 006 - training loss: 0.9841, validation loss: 1.0563
2024-05-24 22:41:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch6_loss1.0563246011734009.pypots
2024-05-24 22:41:24 [INFO]: Epoch 007 - training loss: 0.9627, validation loss: 1.0495
2024-05-24 22:41:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch7_loss1.0495302081108093.pypots
2024-05-24 22:41:24 [INFO]: Epoch 008 - training loss: 0.9469, validation loss: 1.0441
2024-05-24 22:41:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch8_loss1.0441162139177322.pypots
2024-05-24 22:41:24 [INFO]: Epoch 009 - training loss: 0.9096, validation loss: 1.0395
2024-05-24 22:41:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch9_loss1.0394528061151505.pypots
2024-05-24 22:41:24 [INFO]: Epoch 010 - training loss: 0.9267, validation loss: 1.0275
2024-05-24 22:41:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch10_loss1.0274501889944077.pypots
2024-05-24 22:41:24 [INFO]: Epoch 011 - training loss: 0.8778, validation loss: 1.0237
2024-05-24 22:41:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch11_loss1.023742213845253.pypots
2024-05-24 22:41:25 [INFO]: Epoch 012 - training loss: 0.9180, validation loss: 1.0135
2024-05-24 22:41:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch12_loss1.0135433971881866.pypots
2024-05-24 22:41:25 [INFO]: Epoch 013 - training loss: 0.9033, validation loss: 1.0110
2024-05-24 22:41:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch13_loss1.011037901043892.pypots
2024-05-24 22:41:25 [INFO]: Epoch 014 - training loss: 0.8926, validation loss: 1.0056
2024-05-24 22:41:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch14_loss1.0056357681751251.pypots
2024-05-24 22:41:25 [INFO]: Epoch 015 - training loss: 0.9025, validation loss: 0.9996
2024-05-24 22:41:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch15_loss0.9995668530464172.pypots
2024-05-24 22:41:25 [INFO]: Epoch 016 - training loss: 0.8832, validation loss: 0.9899
2024-05-24 22:41:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch16_loss0.9898525029420853.pypots
2024-05-24 22:41:26 [INFO]: Epoch 017 - training loss: 0.8670, validation loss: 0.9854
2024-05-24 22:41:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch17_loss0.9853809773921967.pypots
2024-05-24 22:41:26 [INFO]: Epoch 018 - training loss: 0.8513, validation loss: 0.9823
2024-05-24 22:41:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch18_loss0.9823247790336609.pypots
2024-05-24 22:41:26 [INFO]: Epoch 019 - training loss: 0.8702, validation loss: 0.9765
2024-05-24 22:41:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch19_loss0.9764553606510162.pypots
2024-05-24 22:41:26 [INFO]: Epoch 020 - training loss: 0.8555, validation loss: 0.9772
2024-05-24 22:41:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch20_loss0.9771597236394882.pypots
2024-05-24 22:41:26 [INFO]: Epoch 021 - training loss: 0.8734, validation loss: 0.9742
2024-05-24 22:41:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch21_loss0.9742139577865601.pypots
2024-05-24 22:41:27 [INFO]: Epoch 022 - training loss: 0.8489, validation loss: 0.9725
2024-05-24 22:41:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch22_loss0.9725006520748138.pypots
2024-05-24 22:41:27 [INFO]: Epoch 023 - training loss: 0.8564, validation loss: 0.9697
2024-05-24 22:41:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch23_loss0.9696526676416397.pypots
2024-05-24 22:41:27 [INFO]: Epoch 024 - training loss: 0.8564, validation loss: 0.9672
2024-05-24 22:41:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch24_loss0.9671786427497864.pypots
2024-05-24 22:41:27 [INFO]: Epoch 025 - training loss: 0.8596, validation loss: 0.9685
2024-05-24 22:41:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch25_loss0.9684908390045166.pypots
2024-05-24 22:41:27 [INFO]: Epoch 026 - training loss: 0.8854, validation loss: 0.9681
2024-05-24 22:41:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch26_loss0.9681157171726227.pypots
2024-05-24 22:41:28 [INFO]: Epoch 027 - training loss: 0.8511, validation loss: 0.9651
2024-05-24 22:41:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch27_loss0.965076357126236.pypots
2024-05-24 22:41:28 [INFO]: Epoch 028 - training loss: 0.8512, validation loss: 0.9632
2024-05-24 22:41:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch28_loss0.9632260948419571.pypots
2024-05-24 22:41:28 [INFO]: Epoch 029 - training loss: 0.8444, validation loss: 0.9636
2024-05-24 22:41:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch29_loss0.9635589867830276.pypots
2024-05-24 22:41:28 [INFO]: Epoch 030 - training loss: 0.8268, validation loss: 0.9624
2024-05-24 22:41:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch30_loss0.962354987859726.pypots
2024-05-24 22:41:28 [INFO]: Epoch 031 - training loss: 0.8557, validation loss: 0.9625
2024-05-24 22:41:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch31_loss0.96253901720047.pypots
2024-05-24 22:41:29 [INFO]: Epoch 032 - training loss: 0.8570, validation loss: 0.9611
2024-05-24 22:41:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch32_loss0.9610760360956192.pypots
2024-05-24 22:41:29 [INFO]: Epoch 033 - training loss: 0.8344, validation loss: 0.9589
2024-05-24 22:41:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch33_loss0.9588784277439117.pypots
2024-05-24 22:41:29 [INFO]: Epoch 034 - training loss: 0.8190, validation loss: 0.9562
2024-05-24 22:41:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch34_loss0.9561841040849686.pypots
2024-05-24 22:41:29 [INFO]: Epoch 035 - training loss: 0.8434, validation loss: 0.9573
2024-05-24 22:41:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch35_loss0.9573349803686142.pypots
2024-05-24 22:41:29 [INFO]: Epoch 036 - training loss: 0.8690, validation loss: 0.9562
2024-05-24 22:41:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch36_loss0.9561774581670761.pypots
2024-05-24 22:41:30 [INFO]: Epoch 037 - training loss: 0.8130, validation loss: 0.9518
2024-05-24 22:41:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch37_loss0.9517607688903809.pypots
2024-05-24 22:41:30 [INFO]: Epoch 038 - training loss: 0.8312, validation loss: 0.9506
2024-05-24 22:41:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch38_loss0.9506466239690781.pypots
2024-05-24 22:41:30 [INFO]: Epoch 039 - training loss: 0.8303, validation loss: 0.9492
2024-05-24 22:41:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch39_loss0.9491977691650391.pypots
2024-05-24 22:41:30 [INFO]: Epoch 040 - training loss: 0.8272, validation loss: 0.9460
2024-05-24 22:41:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch40_loss0.9459741413593292.pypots
2024-05-24 22:41:30 [INFO]: Epoch 041 - training loss: 0.8221, validation loss: 0.9445
2024-05-24 22:41:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch41_loss0.9444969147443771.pypots
2024-05-24 22:41:31 [INFO]: Epoch 042 - training loss: 0.8168, validation loss: 0.9433
2024-05-24 22:41:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch42_loss0.9432722330093384.pypots
2024-05-24 22:41:31 [INFO]: Epoch 043 - training loss: 0.8214, validation loss: 0.9407
2024-05-24 22:41:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch43_loss0.9407428503036499.pypots
2024-05-24 22:41:31 [INFO]: Epoch 044 - training loss: 0.8260, validation loss: 0.9369
2024-05-24 22:41:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch44_loss0.9369342029094696.pypots
2024-05-24 22:41:31 [INFO]: Epoch 045 - training loss: 0.8157, validation loss: 0.9358
2024-05-24 22:41:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch45_loss0.9357800632715225.pypots
2024-05-24 22:41:31 [INFO]: Epoch 046 - training loss: 0.8224, validation loss: 0.9318
2024-05-24 22:41:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch46_loss0.9318149834871292.pypots
2024-05-24 22:41:32 [INFO]: Epoch 047 - training loss: 0.8234, validation loss: 0.9283
2024-05-24 22:41:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch47_loss0.9283322393894196.pypots
2024-05-24 22:41:32 [INFO]: Epoch 048 - training loss: 0.8073, validation loss: 0.9276
2024-05-24 22:41:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch48_loss0.9275763034820557.pypots
2024-05-24 22:41:32 [INFO]: Epoch 049 - training loss: 0.8164, validation loss: 0.9227
2024-05-24 22:41:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch49_loss0.9226962029933929.pypots
2024-05-24 22:41:32 [INFO]: Epoch 050 - training loss: 0.8050, validation loss: 0.9198
2024-05-24 22:41:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch50_loss0.9198441654443741.pypots
2024-05-24 22:41:32 [INFO]: Epoch 051 - training loss: 0.8155, validation loss: 0.9176
2024-05-24 22:41:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch51_loss0.9175852686166763.pypots
2024-05-24 22:41:33 [INFO]: Epoch 052 - training loss: 0.8333, validation loss: 0.9136
2024-05-24 22:41:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch52_loss0.9135914444923401.pypots
2024-05-24 22:41:33 [INFO]: Epoch 053 - training loss: 0.8252, validation loss: 0.9116
2024-05-24 22:41:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch53_loss0.911641389131546.pypots
2024-05-24 22:41:33 [INFO]: Epoch 054 - training loss: 0.7970, validation loss: 0.9101
2024-05-24 22:41:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch54_loss0.9100830852985382.pypots
2024-05-24 22:41:33 [INFO]: Epoch 055 - training loss: 0.8104, validation loss: 0.9089
2024-05-24 22:41:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch55_loss0.9089374542236328.pypots
2024-05-24 22:41:33 [INFO]: Epoch 056 - training loss: 0.8117, validation loss: 0.9061
2024-05-24 22:41:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch56_loss0.9060984551906586.pypots
2024-05-24 22:41:33 [INFO]: Epoch 057 - training loss: 0.8103, validation loss: 0.9044
2024-05-24 22:41:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch57_loss0.9044109582901001.pypots
2024-05-24 22:41:34 [INFO]: Epoch 058 - training loss: 0.8061, validation loss: 0.9020
2024-05-24 22:41:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch58_loss0.9020400941371918.pypots
2024-05-24 22:41:34 [INFO]: Epoch 059 - training loss: 0.8103, validation loss: 0.9004
2024-05-24 22:41:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch59_loss0.9003632813692093.pypots
2024-05-24 22:41:34 [INFO]: Epoch 060 - training loss: 0.8125, validation loss: 0.9000
2024-05-24 22:41:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch60_loss0.8999811559915543.pypots
2024-05-24 22:41:34 [INFO]: Epoch 061 - training loss: 0.8017, validation loss: 0.8971
2024-05-24 22:41:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch61_loss0.8971015214920044.pypots
2024-05-24 22:41:34 [INFO]: Epoch 062 - training loss: 0.8234, validation loss: 0.8971
2024-05-24 22:41:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch62_loss0.897088497877121.pypots
2024-05-24 22:41:35 [INFO]: Epoch 063 - training loss: 0.8183, validation loss: 0.8981
2024-05-24 22:41:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch63_loss0.8980710655450821.pypots
2024-05-24 22:41:35 [INFO]: Epoch 064 - training loss: 0.8244, validation loss: 0.8954
2024-05-24 22:41:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch64_loss0.8953620493412018.pypots
2024-05-24 22:41:35 [INFO]: Epoch 065 - training loss: 0.8076, validation loss: 0.8945
2024-05-24 22:41:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch65_loss0.8944870978593826.pypots
2024-05-24 22:41:35 [INFO]: Epoch 066 - training loss: 0.8050, validation loss: 0.8949
2024-05-24 22:41:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch66_loss0.8949340432882309.pypots
2024-05-24 22:41:35 [INFO]: Epoch 067 - training loss: 0.8030, validation loss: 0.8937
2024-05-24 22:41:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch67_loss0.8936786204576492.pypots
2024-05-24 22:41:36 [INFO]: Epoch 068 - training loss: 0.8022, validation loss: 0.8927
2024-05-24 22:41:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch68_loss0.8927456736564636.pypots
2024-05-24 22:41:36 [INFO]: Epoch 069 - training loss: 0.8110, validation loss: 0.8941
2024-05-24 22:41:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch69_loss0.894105464220047.pypots
2024-05-24 22:41:36 [INFO]: Epoch 070 - training loss: 0.7925, validation loss: 0.8929
2024-05-24 22:41:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch70_loss0.8929032981395721.pypots
2024-05-24 22:41:36 [INFO]: Epoch 071 - training loss: 0.8091, validation loss: 0.8903
2024-05-24 22:41:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch71_loss0.8902843147516251.pypots
2024-05-24 22:41:36 [INFO]: Epoch 072 - training loss: 0.7834, validation loss: 0.8925
2024-05-24 22:41:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch72_loss0.8924565017223358.pypots
2024-05-24 22:41:37 [INFO]: Epoch 073 - training loss: 0.7804, validation loss: 0.8911
2024-05-24 22:41:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch73_loss0.8910828232765198.pypots
2024-05-24 22:41:37 [INFO]: Epoch 074 - training loss: 0.7935, validation loss: 0.8903
2024-05-24 22:41:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch74_loss0.8903228640556335.pypots
2024-05-24 22:41:37 [INFO]: Epoch 075 - training loss: 0.7795, validation loss: 0.8907
2024-05-24 22:41:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch75_loss0.8907319009304047.pypots
2024-05-24 22:41:37 [INFO]: Epoch 076 - training loss: 0.7893, validation loss: 0.8923
2024-05-24 22:41:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch76_loss0.8922892212867737.pypots
2024-05-24 22:41:37 [INFO]: Epoch 077 - training loss: 0.7689, validation loss: 0.8917
2024-05-24 22:41:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch77_loss0.8917116820812225.pypots
2024-05-24 22:41:38 [INFO]: Epoch 078 - training loss: 0.7949, validation loss: 0.8883
2024-05-24 22:41:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch78_loss0.8882981538772583.pypots
2024-05-24 22:41:38 [INFO]: Epoch 079 - training loss: 0.7923, validation loss: 0.8901
2024-05-24 22:41:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch79_loss0.8900680392980576.pypots
2024-05-24 22:41:38 [INFO]: Epoch 080 - training loss: 0.7684, validation loss: 0.8887
2024-05-24 22:41:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch80_loss0.88868048787117.pypots
2024-05-24 22:41:38 [INFO]: Epoch 081 - training loss: 0.7993, validation loss: 0.8911
2024-05-24 22:41:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch81_loss0.891064926981926.pypots
2024-05-24 22:41:38 [INFO]: Epoch 082 - training loss: 0.8043, validation loss: 0.8899
2024-05-24 22:41:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch82_loss0.8898614794015884.pypots
2024-05-24 22:41:39 [INFO]: Epoch 083 - training loss: 0.7969, validation loss: 0.8883
2024-05-24 22:41:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch83_loss0.8883006870746613.pypots
2024-05-24 22:41:39 [INFO]: Epoch 084 - training loss: 0.7961, validation loss: 0.8869
2024-05-24 22:41:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch84_loss0.8868576288223267.pypots
2024-05-24 22:41:39 [INFO]: Epoch 085 - training loss: 0.7837, validation loss: 0.8884
2024-05-24 22:41:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch85_loss0.8883995413780212.pypots
2024-05-24 22:41:39 [INFO]: Epoch 086 - training loss: 0.8313, validation loss: 0.8885
2024-05-24 22:41:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch86_loss0.8885493576526642.pypots
2024-05-24 22:41:39 [INFO]: Epoch 087 - training loss: 0.8057, validation loss: 0.8882
2024-05-24 22:41:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch87_loss0.8881948441267014.pypots
2024-05-24 22:41:40 [INFO]: Epoch 088 - training loss: 0.7850, validation loss: 0.8863
2024-05-24 22:41:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch88_loss0.8862806260585785.pypots
2024-05-24 22:41:40 [INFO]: Epoch 089 - training loss: 0.7985, validation loss: 0.8885
2024-05-24 22:41:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch89_loss0.8885237127542496.pypots
2024-05-24 22:41:40 [INFO]: Epoch 090 - training loss: 0.7974, validation loss: 0.8863
2024-05-24 22:41:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch90_loss0.8862904608249664.pypots
2024-05-24 22:41:40 [INFO]: Epoch 091 - training loss: 0.7894, validation loss: 0.8897
2024-05-24 22:41:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch91_loss0.8897464573383331.pypots
2024-05-24 22:41:40 [INFO]: Epoch 092 - training loss: 0.8213, validation loss: 0.8860
2024-05-24 22:41:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch92_loss0.8859708458185196.pypots
2024-05-24 22:41:41 [INFO]: Epoch 093 - training loss: 0.8181, validation loss: 0.8854
2024-05-24 22:41:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch93_loss0.8854299783706665.pypots
2024-05-24 22:41:41 [INFO]: Epoch 094 - training loss: 0.8019, validation loss: 0.8875
2024-05-24 22:41:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch94_loss0.8875155448913574.pypots
2024-05-24 22:41:41 [INFO]: Epoch 095 - training loss: 0.7989, validation loss: 0.8862
2024-05-24 22:41:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch95_loss0.8862353563308716.pypots
2024-05-24 22:41:41 [INFO]: Epoch 096 - training loss: 0.8065, validation loss: 0.8829
2024-05-24 22:41:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch96_loss0.8828569054603577.pypots
2024-05-24 22:41:41 [INFO]: Epoch 097 - training loss: 0.7889, validation loss: 0.8847
2024-05-24 22:41:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch97_loss0.8847391307353973.pypots
2024-05-24 22:41:41 [INFO]: Epoch 098 - training loss: 0.7937, validation loss: 0.8848
2024-05-24 22:41:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch98_loss0.884754404425621.pypots
2024-05-24 22:41:42 [INFO]: Epoch 099 - training loss: 0.7993, validation loss: 0.8842
2024-05-24 22:41:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch99_loss0.884183406829834.pypots
2024-05-24 22:41:42 [INFO]: Epoch 100 - training loss: 0.7896, validation loss: 0.8839
2024-05-24 22:41:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch100_loss0.8838728219270706.pypots
2024-05-24 22:41:42 [INFO]: Epoch 101 - training loss: 0.7896, validation loss: 0.8820
2024-05-24 22:41:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch101_loss0.8820002675056458.pypots
2024-05-24 22:41:42 [INFO]: Epoch 102 - training loss: 0.7864, validation loss: 0.8805
2024-05-24 22:41:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch102_loss0.8805296719074249.pypots
2024-05-24 22:41:42 [INFO]: Epoch 103 - training loss: 0.7915, validation loss: 0.8817
2024-05-24 22:41:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch103_loss0.8817280977964401.pypots
2024-05-24 22:41:43 [INFO]: Epoch 104 - training loss: 0.7920, validation loss: 0.8816
2024-05-24 22:41:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch104_loss0.8816206157207489.pypots
2024-05-24 22:41:43 [INFO]: Epoch 105 - training loss: 0.8067, validation loss: 0.8829
2024-05-24 22:41:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch105_loss0.8828999847173691.pypots
2024-05-24 22:41:43 [INFO]: Epoch 106 - training loss: 0.8066, validation loss: 0.8808
2024-05-24 22:41:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch106_loss0.8807650953531265.pypots
2024-05-24 22:41:43 [INFO]: Epoch 107 - training loss: 0.7926, validation loss: 0.8797
2024-05-24 22:41:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch107_loss0.8796726912260056.pypots
2024-05-24 22:41:43 [INFO]: Epoch 108 - training loss: 0.7908, validation loss: 0.8810
2024-05-24 22:41:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch108_loss0.8810069411993027.pypots
2024-05-24 22:41:44 [INFO]: Epoch 109 - training loss: 0.7671, validation loss: 0.8789
2024-05-24 22:41:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch109_loss0.8789228647947311.pypots
2024-05-24 22:41:44 [INFO]: Epoch 110 - training loss: 0.7877, validation loss: 0.8790
2024-05-24 22:41:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch110_loss0.8789517283439636.pypots
2024-05-24 22:41:44 [INFO]: Epoch 111 - training loss: 0.7921, validation loss: 0.8771
2024-05-24 22:41:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch111_loss0.8770566582679749.pypots
2024-05-24 22:41:44 [INFO]: Epoch 112 - training loss: 0.7725, validation loss: 0.8800
2024-05-24 22:41:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch112_loss0.880048394203186.pypots
2024-05-24 22:41:44 [INFO]: Epoch 113 - training loss: 0.7703, validation loss: 0.8779
2024-05-24 22:41:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch113_loss0.8779476284980774.pypots
2024-05-24 22:41:45 [INFO]: Epoch 114 - training loss: 0.7935, validation loss: 0.8791
2024-05-24 22:41:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch114_loss0.8791279941797256.pypots
2024-05-24 22:41:45 [INFO]: Epoch 115 - training loss: 0.7879, validation loss: 0.8793
2024-05-24 22:41:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch115_loss0.8793291747570038.pypots
2024-05-24 22:41:45 [INFO]: Epoch 116 - training loss: 0.7595, validation loss: 0.8777
2024-05-24 22:41:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch116_loss0.8776857554912567.pypots
2024-05-24 22:41:45 [INFO]: Epoch 117 - training loss: 0.7959, validation loss: 0.8753
2024-05-24 22:41:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch117_loss0.8752614855766296.pypots
2024-05-24 22:41:45 [INFO]: Epoch 118 - training loss: 0.8285, validation loss: 0.8784
2024-05-24 22:41:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch118_loss0.8784453123807907.pypots
2024-05-24 22:41:46 [INFO]: Epoch 119 - training loss: 0.8019, validation loss: 0.8773
2024-05-24 22:41:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch119_loss0.8772639632225037.pypots
2024-05-24 22:41:46 [INFO]: Epoch 120 - training loss: 0.8027, validation loss: 0.8779
2024-05-24 22:41:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch120_loss0.8778519183397293.pypots
2024-05-24 22:41:46 [INFO]: Epoch 121 - training loss: 0.7766, validation loss: 0.8789
2024-05-24 22:41:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch121_loss0.8788995891809464.pypots
2024-05-24 22:41:46 [INFO]: Epoch 122 - training loss: 0.7953, validation loss: 0.8727
2024-05-24 22:41:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch122_loss0.8726742565631866.pypots
2024-05-24 22:41:46 [INFO]: Epoch 123 - training loss: 0.7906, validation loss: 0.8788
2024-05-24 22:41:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch123_loss0.878826692700386.pypots
2024-05-24 22:41:47 [INFO]: Epoch 124 - training loss: 0.7796, validation loss: 0.8742
2024-05-24 22:41:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch124_loss0.8741516768932343.pypots
2024-05-24 22:41:47 [INFO]: Epoch 125 - training loss: 0.7888, validation loss: 0.8716
2024-05-24 22:41:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch125_loss0.871620386838913.pypots
2024-05-24 22:41:47 [INFO]: Epoch 126 - training loss: 0.8035, validation loss: 0.8716
2024-05-24 22:41:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch126_loss0.8716420531272888.pypots
2024-05-24 22:41:47 [INFO]: Epoch 127 - training loss: 0.7688, validation loss: 0.8696
2024-05-24 22:41:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch127_loss0.8696479201316833.pypots
2024-05-24 22:41:47 [INFO]: Epoch 128 - training loss: 0.7932, validation loss: 0.8709
2024-05-24 22:41:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch128_loss0.8708681017160416.pypots
2024-05-24 22:41:48 [INFO]: Epoch 129 - training loss: 0.7916, validation loss: 0.8732
2024-05-24 22:41:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch129_loss0.8732075691223145.pypots
2024-05-24 22:41:48 [INFO]: Epoch 130 - training loss: 0.7685, validation loss: 0.8690
2024-05-24 22:41:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch130_loss0.869047999382019.pypots
2024-05-24 22:41:48 [INFO]: Epoch 131 - training loss: 0.7882, validation loss: 0.8741
2024-05-24 22:41:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch131_loss0.8741198033094406.pypots
2024-05-24 22:41:48 [INFO]: Epoch 132 - training loss: 0.7812, validation loss: 0.8747
2024-05-24 22:41:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch132_loss0.8746919929981232.pypots
2024-05-24 22:41:48 [INFO]: Epoch 133 - training loss: 0.7822, validation loss: 0.8718
2024-05-24 22:41:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch133_loss0.8717537820339203.pypots
2024-05-24 22:41:49 [INFO]: Epoch 134 - training loss: 0.7804, validation loss: 0.8716
2024-05-24 22:41:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch134_loss0.8716446161270142.pypots
2024-05-24 22:41:49 [INFO]: Epoch 135 - training loss: 0.7932, validation loss: 0.8702
2024-05-24 22:41:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch135_loss0.8702254295349121.pypots
2024-05-24 22:41:49 [INFO]: Epoch 136 - training loss: 0.7850, validation loss: 0.8676
2024-05-24 22:41:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch136_loss0.8676099926233292.pypots
2024-05-24 22:41:49 [INFO]: Epoch 137 - training loss: 0.7778, validation loss: 0.8709
2024-05-24 22:41:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch137_loss0.8708747625350952.pypots
2024-05-24 22:41:49 [INFO]: Epoch 138 - training loss: 0.7872, validation loss: 0.8650
2024-05-24 22:41:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch138_loss0.865022599697113.pypots
2024-05-24 22:41:49 [INFO]: Epoch 139 - training loss: 0.7685, validation loss: 0.8709
2024-05-24 22:41:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch139_loss0.8709285855293274.pypots
2024-05-24 22:41:50 [INFO]: Epoch 140 - training loss: 0.7609, validation loss: 0.8692
2024-05-24 22:41:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch140_loss0.8691681772470474.pypots
2024-05-24 22:41:50 [INFO]: Epoch 141 - training loss: 0.7779, validation loss: 0.8682
2024-05-24 22:41:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch141_loss0.8682433515787125.pypots
2024-05-24 22:41:50 [INFO]: Epoch 142 - training loss: 0.7967, validation loss: 0.8705
2024-05-24 22:41:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch142_loss0.8704908341169357.pypots
2024-05-24 22:41:50 [INFO]: Epoch 143 - training loss: 0.8010, validation loss: 0.8670
2024-05-24 22:41:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch143_loss0.8670234382152557.pypots
2024-05-24 22:41:50 [INFO]: Epoch 144 - training loss: 0.7975, validation loss: 0.8648
2024-05-24 22:41:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch144_loss0.8647642433643341.pypots
2024-05-24 22:41:51 [INFO]: Epoch 145 - training loss: 0.7774, validation loss: 0.8648
2024-05-24 22:41:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch145_loss0.8648459762334824.pypots
2024-05-24 22:41:51 [INFO]: Epoch 146 - training loss: 0.8272, validation loss: 0.8660
2024-05-24 22:41:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch146_loss0.8660473674535751.pypots
2024-05-24 22:41:51 [INFO]: Epoch 147 - training loss: 0.7840, validation loss: 0.8627
2024-05-24 22:41:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch147_loss0.8627111613750458.pypots
2024-05-24 22:41:51 [INFO]: Epoch 148 - training loss: 0.8005, validation loss: 0.8642
2024-05-24 22:41:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch148_loss0.864247128367424.pypots
2024-05-24 22:41:51 [INFO]: Epoch 149 - training loss: 0.7839, validation loss: 0.8639
2024-05-24 22:41:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch149_loss0.8639063537120819.pypots
2024-05-24 22:41:52 [INFO]: Epoch 150 - training loss: 0.7763, validation loss: 0.8621
2024-05-24 22:41:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch150_loss0.8621456027030945.pypots
2024-05-24 22:41:52 [INFO]: Epoch 151 - training loss: 0.7852, validation loss: 0.8594
2024-05-24 22:41:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch151_loss0.8594332039356232.pypots
2024-05-24 22:41:52 [INFO]: Epoch 152 - training loss: 0.7870, validation loss: 0.8645
2024-05-24 22:41:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch152_loss0.8644547462463379.pypots
2024-05-24 22:41:52 [INFO]: Epoch 153 - training loss: 0.7668, validation loss: 0.8644
2024-05-24 22:41:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch153_loss0.8643963783979416.pypots
2024-05-24 22:41:52 [INFO]: Epoch 154 - training loss: 0.7825, validation loss: 0.8613
2024-05-24 22:41:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch154_loss0.8612859845161438.pypots
2024-05-24 22:41:53 [INFO]: Epoch 155 - training loss: 0.7912, validation loss: 0.8578
2024-05-24 22:41:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch155_loss0.8578236997127533.pypots
2024-05-24 22:41:53 [INFO]: Epoch 156 - training loss: 0.7921, validation loss: 0.8589
2024-05-24 22:41:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch156_loss0.8588902503252029.pypots
2024-05-24 22:41:53 [INFO]: Epoch 157 - training loss: 0.7730, validation loss: 0.8617
2024-05-24 22:41:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch157_loss0.8617023080587387.pypots
2024-05-24 22:41:53 [INFO]: Epoch 158 - training loss: 0.7844, validation loss: 0.8627
2024-05-24 22:41:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch158_loss0.8626874089241028.pypots
2024-05-24 22:41:53 [INFO]: Epoch 159 - training loss: 0.7610, validation loss: 0.8601
2024-05-24 22:41:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch159_loss0.8600568771362305.pypots
2024-05-24 22:41:54 [INFO]: Epoch 160 - training loss: 0.7767, validation loss: 0.8537
2024-05-24 22:41:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch160_loss0.8536756783723831.pypots
2024-05-24 22:41:54 [INFO]: Epoch 161 - training loss: 0.7634, validation loss: 0.8581
2024-05-24 22:41:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch161_loss0.8580804914236069.pypots
2024-05-24 22:41:54 [INFO]: Epoch 162 - training loss: 0.7846, validation loss: 0.8590
2024-05-24 22:41:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch162_loss0.859010636806488.pypots
2024-05-24 22:41:54 [INFO]: Epoch 163 - training loss: 0.7899, validation loss: 0.8570
2024-05-24 22:41:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch163_loss0.8569754064083099.pypots
2024-05-24 22:41:54 [INFO]: Epoch 164 - training loss: 0.7791, validation loss: 0.8544
2024-05-24 22:41:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch164_loss0.854408323764801.pypots
2024-05-24 22:41:55 [INFO]: Epoch 165 - training loss: 0.7774, validation loss: 0.8550
2024-05-24 22:41:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch165_loss0.8550334870815277.pypots
2024-05-24 22:41:55 [INFO]: Epoch 166 - training loss: 0.7610, validation loss: 0.8550
2024-05-24 22:41:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch166_loss0.855044960975647.pypots
2024-05-24 22:41:55 [INFO]: Epoch 167 - training loss: 0.7755, validation loss: 0.8550
2024-05-24 22:41:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch167_loss0.8549857288599014.pypots
2024-05-24 22:41:55 [INFO]: Epoch 168 - training loss: 0.7652, validation loss: 0.8528
2024-05-24 22:41:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch168_loss0.8528494983911514.pypots
2024-05-24 22:41:55 [INFO]: Epoch 169 - training loss: 0.7711, validation loss: 0.8548
2024-05-24 22:41:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch169_loss0.8548335880041122.pypots
2024-05-24 22:41:56 [INFO]: Epoch 170 - training loss: 0.8068, validation loss: 0.8524
2024-05-24 22:41:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch170_loss0.8524495959281921.pypots
2024-05-24 22:41:56 [INFO]: Epoch 171 - training loss: 0.7906, validation loss: 0.8511
2024-05-24 22:41:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch171_loss0.851128876209259.pypots
2024-05-24 22:41:56 [INFO]: Epoch 172 - training loss: 0.7777, validation loss: 0.8501
2024-05-24 22:41:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch172_loss0.8501473665237427.pypots
2024-05-24 22:41:56 [INFO]: Epoch 173 - training loss: 0.7807, validation loss: 0.8535
2024-05-24 22:41:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch173_loss0.853538915514946.pypots
2024-05-24 22:41:56 [INFO]: Epoch 174 - training loss: 0.8219, validation loss: 0.8529
2024-05-24 22:41:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch174_loss0.8529338836669922.pypots
2024-05-24 22:41:57 [INFO]: Epoch 175 - training loss: 0.7831, validation loss: 0.8505
2024-05-24 22:41:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch175_loss0.8504780232906342.pypots
2024-05-24 22:41:57 [INFO]: Epoch 176 - training loss: 0.7950, validation loss: 0.8460
2024-05-24 22:41:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch176_loss0.8460146188735962.pypots
2024-05-24 22:41:57 [INFO]: Epoch 177 - training loss: 0.8054, validation loss: 0.8492
2024-05-24 22:41:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch177_loss0.8492410778999329.pypots
2024-05-24 22:41:57 [INFO]: Epoch 178 - training loss: 0.7950, validation loss: 0.8530
2024-05-24 22:41:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch178_loss0.8529878854751587.pypots
2024-05-24 22:41:57 [INFO]: Epoch 179 - training loss: 0.7735, validation loss: 0.8476
2024-05-24 22:41:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch179_loss0.8475859016180038.pypots
2024-05-24 22:41:57 [INFO]: Epoch 180 - training loss: 0.8126, validation loss: 0.8499
2024-05-24 22:41:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch180_loss0.849868506193161.pypots
2024-05-24 22:41:58 [INFO]: Epoch 181 - training loss: 0.7800, validation loss: 0.8509
2024-05-24 22:41:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch181_loss0.8509110510349274.pypots
2024-05-24 22:41:58 [INFO]: Epoch 182 - training loss: 0.7666, validation loss: 0.8464
2024-05-24 22:41:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch182_loss0.8463874459266663.pypots
2024-05-24 22:41:58 [INFO]: Epoch 183 - training loss: 0.7874, validation loss: 0.8465
2024-05-24 22:41:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch183_loss0.8465093374252319.pypots
2024-05-24 22:41:58 [INFO]: Epoch 184 - training loss: 0.7810, validation loss: 0.8454
2024-05-24 22:41:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch184_loss0.8454096615314484.pypots
2024-05-24 22:41:58 [INFO]: Epoch 185 - training loss: 0.7717, validation loss: 0.8440
2024-05-24 22:41:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch185_loss0.8440120816230774.pypots
2024-05-24 22:41:59 [INFO]: Epoch 186 - training loss: 0.7760, validation loss: 0.8479
2024-05-24 22:41:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch186_loss0.8479498326778412.pypots
2024-05-24 22:41:59 [INFO]: Epoch 187 - training loss: 0.7798, validation loss: 0.8438
2024-05-24 22:41:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch187_loss0.8437653630971909.pypots
2024-05-24 22:41:59 [INFO]: Epoch 188 - training loss: 0.7825, validation loss: 0.8442
2024-05-24 22:41:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch188_loss0.8442413657903671.pypots
2024-05-24 22:41:59 [INFO]: Epoch 189 - training loss: 0.7897, validation loss: 0.8439
2024-05-24 22:41:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch189_loss0.8439212888479233.pypots
2024-05-24 22:41:59 [INFO]: Epoch 190 - training loss: 0.7782, validation loss: 0.8432
2024-05-24 22:41:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch190_loss0.8432170897722244.pypots
2024-05-24 22:42:00 [INFO]: Epoch 191 - training loss: 0.7708, validation loss: 0.8494
2024-05-24 22:42:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch191_loss0.8493678420782089.pypots
2024-05-24 22:42:00 [INFO]: Epoch 192 - training loss: 0.7761, validation loss: 0.8460
2024-05-24 22:42:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch192_loss0.8459857702255249.pypots
2024-05-24 22:42:00 [INFO]: Epoch 193 - training loss: 0.7890, validation loss: 0.8439
2024-05-24 22:42:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch193_loss0.8439390957355499.pypots
2024-05-24 22:42:00 [INFO]: Epoch 194 - training loss: 0.7901, validation loss: 0.8411
2024-05-24 22:42:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch194_loss0.8411220014095306.pypots
2024-05-24 22:42:00 [INFO]: Epoch 195 - training loss: 0.7855, validation loss: 0.8425
2024-05-24 22:42:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch195_loss0.8424632698297501.pypots
2024-05-24 22:42:01 [INFO]: Epoch 196 - training loss: 0.7855, validation loss: 0.8421
2024-05-24 22:42:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch196_loss0.8420739620923996.pypots
2024-05-24 22:42:01 [INFO]: Epoch 197 - training loss: 0.8008, validation loss: 0.8421
2024-05-24 22:42:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch197_loss0.8420687615871429.pypots
2024-05-24 22:42:01 [INFO]: Epoch 198 - training loss: 0.8240, validation loss: 0.8433
2024-05-24 22:42:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch198_loss0.8433368504047394.pypots
2024-05-24 22:42:01 [INFO]: Epoch 199 - training loss: 0.7961, validation loss: 0.8416
2024-05-24 22:42:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch199_loss0.8416498005390167.pypots
2024-05-24 22:42:01 [INFO]: Epoch 200 - training loss: 0.7802, validation loss: 0.8420
2024-05-24 22:42:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch200_loss0.8419709354639053.pypots
2024-05-24 22:42:02 [INFO]: Epoch 201 - training loss: 0.7822, validation loss: 0.8408
2024-05-24 22:42:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch201_loss0.840788409113884.pypots
2024-05-24 22:42:02 [INFO]: Epoch 202 - training loss: 0.7889, validation loss: 0.8390
2024-05-24 22:42:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch202_loss0.8389554768800735.pypots
2024-05-24 22:42:02 [INFO]: Epoch 203 - training loss: 0.7573, validation loss: 0.8398
2024-05-24 22:42:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch203_loss0.8397728502750397.pypots
2024-05-24 22:42:02 [INFO]: Epoch 204 - training loss: 0.7808, validation loss: 0.8437
2024-05-24 22:42:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch204_loss0.8437309265136719.pypots
2024-05-24 22:42:02 [INFO]: Epoch 205 - training loss: 0.8030, validation loss: 0.8393
2024-05-24 22:42:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch205_loss0.8392590433359146.pypots
2024-05-24 22:42:03 [INFO]: Epoch 206 - training loss: 0.7701, validation loss: 0.8382
2024-05-24 22:42:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch206_loss0.8382285982370377.pypots
2024-05-24 22:42:03 [INFO]: Epoch 207 - training loss: 0.8060, validation loss: 0.8400
2024-05-24 22:42:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch207_loss0.8400356471538544.pypots
2024-05-24 22:42:03 [INFO]: Epoch 208 - training loss: 0.7725, validation loss: 0.8382
2024-05-24 22:42:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch208_loss0.8382285982370377.pypots
2024-05-24 22:42:03 [INFO]: Epoch 209 - training loss: 0.7908, validation loss: 0.8411
2024-05-24 22:42:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch209_loss0.8411393761634827.pypots
2024-05-24 22:42:03 [INFO]: Epoch 210 - training loss: 0.7937, validation loss: 0.8416
2024-05-24 22:42:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch210_loss0.8416157364845276.pypots
2024-05-24 22:42:04 [INFO]: Epoch 211 - training loss: 0.7631, validation loss: 0.8387
2024-05-24 22:42:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch211_loss0.8387387841939926.pypots
2024-05-24 22:42:04 [INFO]: Epoch 212 - training loss: 0.7910, validation loss: 0.8370
2024-05-24 22:42:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch212_loss0.837029829621315.pypots
2024-05-24 22:42:04 [INFO]: Epoch 213 - training loss: 0.7603, validation loss: 0.8357
2024-05-24 22:42:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch213_loss0.8357149362564087.pypots
2024-05-24 22:42:04 [INFO]: Epoch 214 - training loss: 0.7733, validation loss: 0.8347
2024-05-24 22:42:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch214_loss0.8347451686859131.pypots
2024-05-24 22:42:04 [INFO]: Epoch 215 - training loss: 0.7809, validation loss: 0.8337
2024-05-24 22:42:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch215_loss0.8336775898933411.pypots
2024-05-24 22:42:05 [INFO]: Epoch 216 - training loss: 0.8216, validation loss: 0.8377
2024-05-24 22:42:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch216_loss0.8377342522144318.pypots
2024-05-24 22:42:05 [INFO]: Epoch 217 - training loss: 0.7901, validation loss: 0.8311
2024-05-24 22:42:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch217_loss0.8311323374509811.pypots
2024-05-24 22:42:05 [INFO]: Epoch 218 - training loss: 0.7788, validation loss: 0.8357
2024-05-24 22:42:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch218_loss0.8356566727161407.pypots
2024-05-24 22:42:05 [INFO]: Epoch 219 - training loss: 0.7689, validation loss: 0.8374
2024-05-24 22:42:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch219_loss0.8373704850673676.pypots
2024-05-24 22:42:05 [INFO]: Epoch 220 - training loss: 0.8033, validation loss: 0.8379
2024-05-24 22:42:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch220_loss0.8378906100988388.pypots
2024-05-24 22:42:06 [INFO]: Epoch 221 - training loss: 0.7872, validation loss: 0.8357
2024-05-24 22:42:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch221_loss0.8356765508651733.pypots
2024-05-24 22:42:06 [INFO]: Epoch 222 - training loss: 0.7811, validation loss: 0.8345
2024-05-24 22:42:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch222_loss0.8345384299755096.pypots
2024-05-24 22:42:06 [INFO]: Epoch 223 - training loss: 0.7837, validation loss: 0.8341
2024-05-24 22:42:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch223_loss0.8341482132673264.pypots
2024-05-24 22:42:06 [INFO]: Epoch 224 - training loss: 0.7666, validation loss: 0.8339
2024-05-24 22:42:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch224_loss0.8338907063007355.pypots
2024-05-24 22:42:06 [INFO]: Epoch 225 - training loss: 0.7899, validation loss: 0.8337
2024-05-24 22:42:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch225_loss0.8336764425039291.pypots
2024-05-24 22:42:06 [INFO]: Epoch 226 - training loss: 0.7757, validation loss: 0.8341
2024-05-24 22:42:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch226_loss0.8341335952281952.pypots
2024-05-24 22:42:07 [INFO]: Epoch 227 - training loss: 0.7858, validation loss: 0.8320
2024-05-24 22:42:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN_epoch227_loss0.8319934159517288.pypots
2024-05-24 22:42:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:42:07 [INFO]: Finished training. The best model is from epoch#217.
2024-05-24 22:42:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T224121/MRNN.pypots
2024-05-24 22:42:07 [INFO]: MRNN on ETTm1: MAE=0.6047, MSE=0.9934
2024-05-24 22:42:07 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/MRNN_ettm1/imputation.pkl
2024-05-24 22:42:07 [INFO]: Using the given device: cpu
2024-05-24 22:42:07 [INFO]: LOCF on ETTm1: MAE=0.1348, MSE=0.0715
2024-05-24 22:42:07 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_ettm1".
2024-05-24 22:42:07 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/LOCF_ettm1/imputation.pkl
2024-05-24 22:42:07 [INFO]: Median on ETTm1: MAE=0.6516, MSE=0.8223
2024-05-24 22:42:07 [INFO]: Successfully created the given path "saved_results/round_3/Median_ettm1".
2024-05-24 22:42:07 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Median_ettm1/imputation.pkl
2024-05-24 22:42:07 [INFO]: Mean on ETTm1: MAE=0.6566, MSE=0.8036
2024-05-24 22:42:07 [INFO]: Successfully created the given path "saved_results/round_3/Mean_ettm1".
2024-05-24 22:42:07 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Mean_ettm1/imputation.pkl
2024-05-24 22:42:07 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-24 22:42:07 [INFO]: Using the given device: cuda:0
2024-05-24 22:42:07 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/SAITS_ettm1/20240524_T224207
2024-05-24 22:42:07 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/SAITS_ettm1/20240524_T224207/tensorboard
2024-05-24 22:42:07 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 22:42:08 [INFO]: Epoch 001 - training loss: 1.1333, validation loss: 0.2394
2024-05-24 22:42:08 [INFO]: Epoch 002 - training loss: 0.8501, validation loss: 0.1530
2024-05-24 22:42:09 [INFO]: Epoch 003 - training loss: 0.7795, validation loss: 0.1227
2024-05-24 22:42:09 [INFO]: Epoch 004 - training loss: 0.7301, validation loss: 0.0896
2024-05-24 22:42:10 [INFO]: Epoch 005 - training loss: 0.7132, validation loss: 0.0826
2024-05-24 22:42:10 [INFO]: Epoch 006 - training loss: 0.6883, validation loss: 0.0663
2024-05-24 22:42:11 [INFO]: Epoch 007 - training loss: 0.6604, validation loss: 0.0593
2024-05-24 22:42:11 [INFO]: Epoch 008 - training loss: 0.6404, validation loss: 0.0718
2024-05-24 22:42:12 [INFO]: Epoch 009 - training loss: 0.6342, validation loss: 0.0594
2024-05-24 22:42:12 [INFO]: Epoch 010 - training loss: 0.6115, validation loss: 0.0627
2024-05-24 22:42:13 [INFO]: Epoch 011 - training loss: 0.6172, validation loss: 0.0566
2024-05-24 22:42:13 [INFO]: Epoch 012 - training loss: 0.6086, validation loss: 0.0463
2024-05-24 22:42:14 [INFO]: Epoch 013 - training loss: 0.5939, validation loss: 0.0488
2024-05-24 22:42:14 [INFO]: Epoch 014 - training loss: 0.5933, validation loss: 0.0542
2024-05-24 22:42:15 [INFO]: Epoch 015 - training loss: 0.6065, validation loss: 0.0471
2024-05-24 22:42:15 [INFO]: Epoch 016 - training loss: 0.5802, validation loss: 0.0517
2024-05-24 22:42:15 [INFO]: Epoch 017 - training loss: 0.5886, validation loss: 0.0710
2024-05-24 22:42:16 [INFO]: Epoch 018 - training loss: 0.5907, validation loss: 0.0504
2024-05-24 22:42:16 [INFO]: Epoch 019 - training loss: 0.5674, validation loss: 0.0597
2024-05-24 22:42:17 [INFO]: Epoch 020 - training loss: 0.5588, validation loss: 0.0590
2024-05-24 22:42:17 [INFO]: Epoch 021 - training loss: 0.5525, validation loss: 0.0427
2024-05-24 22:42:18 [INFO]: Epoch 022 - training loss: 0.5435, validation loss: 0.0420
2024-05-24 22:42:18 [INFO]: Epoch 023 - training loss: 0.5439, validation loss: 0.0455
2024-05-24 22:42:19 [INFO]: Epoch 024 - training loss: 0.5506, validation loss: 0.0427
2024-05-24 22:42:19 [INFO]: Epoch 025 - training loss: 0.5463, validation loss: 0.0406
2024-05-24 22:42:20 [INFO]: Epoch 026 - training loss: 0.5255, validation loss: 0.0470
2024-05-24 22:42:20 [INFO]: Epoch 027 - training loss: 0.5237, validation loss: 0.0399
2024-05-24 22:42:21 [INFO]: Epoch 028 - training loss: 0.5472, validation loss: 0.0582
2024-05-24 22:42:21 [INFO]: Epoch 029 - training loss: 0.5314, validation loss: 0.0366
2024-05-24 22:42:22 [INFO]: Epoch 030 - training loss: 0.5188, validation loss: 0.0480
2024-05-24 22:42:22 [INFO]: Epoch 031 - training loss: 0.5168, validation loss: 0.0338
2024-05-24 22:42:23 [INFO]: Epoch 032 - training loss: 0.5123, validation loss: 0.0366
2024-05-24 22:42:23 [INFO]: Epoch 033 - training loss: 0.5186, validation loss: 0.0467
2024-05-24 22:42:24 [INFO]: Epoch 034 - training loss: 0.5236, validation loss: 0.0376
2024-05-24 22:42:24 [INFO]: Epoch 035 - training loss: 0.5088, validation loss: 0.0368
2024-05-24 22:42:25 [INFO]: Epoch 036 - training loss: 0.5021, validation loss: 0.0488
2024-05-24 22:42:25 [INFO]: Epoch 037 - training loss: 0.5012, validation loss: 0.0585
2024-05-24 22:42:26 [INFO]: Epoch 038 - training loss: 0.4993, validation loss: 0.0384
2024-05-24 22:42:26 [INFO]: Epoch 039 - training loss: 0.5005, validation loss: 0.0346
2024-05-24 22:42:27 [INFO]: Epoch 040 - training loss: 0.4998, validation loss: 0.0577
2024-05-24 22:42:27 [INFO]: Epoch 041 - training loss: 0.5054, validation loss: 0.0390
2024-05-24 22:42:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:42:27 [INFO]: Finished training. The best model is from epoch#31.
2024-05-24 22:42:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/SAITS_ettm1/20240524_T224207/SAITS.pypots
2024-05-24 22:42:27 [INFO]: SAITS on ETTm1: MAE=0.1612, MSE=0.0518
2024-05-24 22:42:27 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/SAITS_ettm1/imputation.pkl
2024-05-24 22:42:27 [INFO]: Using the given device: cuda:0
2024-05-24 22:42:27 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/Transformer_ettm1/20240524_T224227
2024-05-24 22:42:27 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/Transformer_ettm1/20240524_T224227/tensorboard
2024-05-24 22:42:27 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 22:42:28 [INFO]: Epoch 001 - training loss: 1.1215, validation loss: 0.3073
2024-05-24 22:42:28 [INFO]: Epoch 002 - training loss: 0.6751, validation loss: 0.1355
2024-05-24 22:42:28 [INFO]: Epoch 003 - training loss: 0.5360, validation loss: 0.1077
2024-05-24 22:42:28 [INFO]: Epoch 004 - training loss: 0.4762, validation loss: 0.0874
2024-05-24 22:42:28 [INFO]: Epoch 005 - training loss: 0.4361, validation loss: 0.0739
2024-05-24 22:42:29 [INFO]: Epoch 006 - training loss: 0.4206, validation loss: 0.0648
2024-05-24 22:42:29 [INFO]: Epoch 007 - training loss: 0.4045, validation loss: 0.0616
2024-05-24 22:42:29 [INFO]: Epoch 008 - training loss: 0.3913, validation loss: 0.0557
2024-05-24 22:42:29 [INFO]: Epoch 009 - training loss: 0.3733, validation loss: 0.0510
2024-05-24 22:42:29 [INFO]: Epoch 010 - training loss: 0.3680, validation loss: 0.0504
2024-05-24 22:42:30 [INFO]: Epoch 011 - training loss: 0.3550, validation loss: 0.0465
2024-05-24 22:42:30 [INFO]: Epoch 012 - training loss: 0.3485, validation loss: 0.0474
2024-05-24 22:42:30 [INFO]: Epoch 013 - training loss: 0.3356, validation loss: 0.0489
2024-05-24 22:42:30 [INFO]: Epoch 014 - training loss: 0.3459, validation loss: 0.0496
2024-05-24 22:42:30 [INFO]: Epoch 015 - training loss: 0.3358, validation loss: 0.0466
2024-05-24 22:42:31 [INFO]: Epoch 016 - training loss: 0.3355, validation loss: 0.0422
2024-05-24 22:42:31 [INFO]: Epoch 017 - training loss: 0.3294, validation loss: 0.0423
2024-05-24 22:42:31 [INFO]: Epoch 018 - training loss: 0.3141, validation loss: 0.0435
2024-05-24 22:42:31 [INFO]: Epoch 019 - training loss: 0.3070, validation loss: 0.0385
2024-05-24 22:42:31 [INFO]: Epoch 020 - training loss: 0.2979, validation loss: 0.0401
2024-05-24 22:42:31 [INFO]: Epoch 021 - training loss: 0.2942, validation loss: 0.0384
2024-05-24 22:42:32 [INFO]: Epoch 022 - training loss: 0.2933, validation loss: 0.0378
2024-05-24 22:42:32 [INFO]: Epoch 023 - training loss: 0.2895, validation loss: 0.0368
2024-05-24 22:42:32 [INFO]: Epoch 024 - training loss: 0.2903, validation loss: 0.0403
2024-05-24 22:42:32 [INFO]: Epoch 025 - training loss: 0.2958, validation loss: 0.0376
2024-05-24 22:42:32 [INFO]: Epoch 026 - training loss: 0.2950, validation loss: 0.0364
2024-05-24 22:42:33 [INFO]: Epoch 027 - training loss: 0.2820, validation loss: 0.0344
2024-05-24 22:42:33 [INFO]: Epoch 028 - training loss: 0.2755, validation loss: 0.0348
2024-05-24 22:42:33 [INFO]: Epoch 029 - training loss: 0.2700, validation loss: 0.0379
2024-05-24 22:42:33 [INFO]: Epoch 030 - training loss: 0.2799, validation loss: 0.0404
2024-05-24 22:42:33 [INFO]: Epoch 031 - training loss: 0.2794, validation loss: 0.0369
2024-05-24 22:42:34 [INFO]: Epoch 032 - training loss: 0.2684, validation loss: 0.0323
2024-05-24 22:42:34 [INFO]: Epoch 033 - training loss: 0.2700, validation loss: 0.0322
2024-05-24 22:42:34 [INFO]: Epoch 034 - training loss: 0.2698, validation loss: 0.0359
2024-05-24 22:42:34 [INFO]: Epoch 035 - training loss: 0.2647, validation loss: 0.0326
2024-05-24 22:42:34 [INFO]: Epoch 036 - training loss: 0.2560, validation loss: 0.0321
2024-05-24 22:42:35 [INFO]: Epoch 037 - training loss: 0.2609, validation loss: 0.0338
2024-05-24 22:42:35 [INFO]: Epoch 038 - training loss: 0.2534, validation loss: 0.0307
2024-05-24 22:42:35 [INFO]: Epoch 039 - training loss: 0.2540, validation loss: 0.0316
2024-05-24 22:42:35 [INFO]: Epoch 040 - training loss: 0.2499, validation loss: 0.0336
2024-05-24 22:42:35 [INFO]: Epoch 041 - training loss: 0.2577, validation loss: 0.0323
2024-05-24 22:42:36 [INFO]: Epoch 042 - training loss: 0.2450, validation loss: 0.0325
2024-05-24 22:42:36 [INFO]: Epoch 043 - training loss: 0.2447, validation loss: 0.0298
2024-05-24 22:42:36 [INFO]: Epoch 044 - training loss: 0.2438, validation loss: 0.0297
2024-05-24 22:42:36 [INFO]: Epoch 045 - training loss: 0.2428, validation loss: 0.0310
2024-05-24 22:42:36 [INFO]: Epoch 046 - training loss: 0.2453, validation loss: 0.0330
2024-05-24 22:42:37 [INFO]: Epoch 047 - training loss: 0.2430, validation loss: 0.0304
2024-05-24 22:42:37 [INFO]: Epoch 048 - training loss: 0.2404, validation loss: 0.0349
2024-05-24 22:42:37 [INFO]: Epoch 049 - training loss: 0.2497, validation loss: 0.0326
2024-05-24 22:42:37 [INFO]: Epoch 050 - training loss: 0.2375, validation loss: 0.0307
2024-05-24 22:42:37 [INFO]: Epoch 051 - training loss: 0.2364, validation loss: 0.0289
2024-05-24 22:42:38 [INFO]: Epoch 052 - training loss: 0.2335, validation loss: 0.0305
2024-05-24 22:42:38 [INFO]: Epoch 053 - training loss: 0.2337, validation loss: 0.0270
2024-05-24 22:42:38 [INFO]: Epoch 054 - training loss: 0.2278, validation loss: 0.0289
2024-05-24 22:42:38 [INFO]: Epoch 055 - training loss: 0.2347, validation loss: 0.0274
2024-05-24 22:42:38 [INFO]: Epoch 056 - training loss: 0.2276, validation loss: 0.0306
2024-05-24 22:42:39 [INFO]: Epoch 057 - training loss: 0.2238, validation loss: 0.0290
2024-05-24 22:42:39 [INFO]: Epoch 058 - training loss: 0.2310, validation loss: 0.0271
2024-05-24 22:42:39 [INFO]: Epoch 059 - training loss: 0.2295, validation loss: 0.0281
2024-05-24 22:42:39 [INFO]: Epoch 060 - training loss: 0.2227, validation loss: 0.0254
2024-05-24 22:42:39 [INFO]: Epoch 061 - training loss: 0.2187, validation loss: 0.0272
2024-05-24 22:42:40 [INFO]: Epoch 062 - training loss: 0.2148, validation loss: 0.0275
2024-05-24 22:42:40 [INFO]: Epoch 063 - training loss: 0.2183, validation loss: 0.0285
2024-05-24 22:42:40 [INFO]: Epoch 064 - training loss: 0.2214, validation loss: 0.0287
2024-05-24 22:42:40 [INFO]: Epoch 065 - training loss: 0.2172, validation loss: 0.0277
2024-05-24 22:42:40 [INFO]: Epoch 066 - training loss: 0.2160, validation loss: 0.0322
2024-05-24 22:42:40 [INFO]: Epoch 067 - training loss: 0.2221, validation loss: 0.0267
2024-05-24 22:42:41 [INFO]: Epoch 068 - training loss: 0.2104, validation loss: 0.0316
2024-05-24 22:42:41 [INFO]: Epoch 069 - training loss: 0.2227, validation loss: 0.0294
2024-05-24 22:42:41 [INFO]: Epoch 070 - training loss: 0.2217, validation loss: 0.0265
2024-05-24 22:42:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:42:41 [INFO]: Finished training. The best model is from epoch#60.
2024-05-24 22:42:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/Transformer_ettm1/20240524_T224227/Transformer.pypots
2024-05-24 22:42:41 [INFO]: Transformer on ETTm1: MAE=0.1329, MSE=0.0358
2024-05-24 22:42:41 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Transformer_ettm1/imputation.pkl
2024-05-24 22:42:41 [INFO]: Using the given device: cuda:0
2024-05-24 22:42:41 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/TimesNet_ettm1/20240524_T224241
2024-05-24 22:42:41 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/TimesNet_ettm1/20240524_T224241/tensorboard
2024-05-24 22:42:41 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 22:42:42 [INFO]: Epoch 001 - training loss: 0.1391, validation loss: 0.0565
2024-05-24 22:42:42 [INFO]: Epoch 002 - training loss: 0.0610, validation loss: 0.0461
2024-05-24 22:42:42 [INFO]: Epoch 003 - training loss: 0.0464, validation loss: 0.0341
2024-05-24 22:42:42 [INFO]: Epoch 004 - training loss: 0.0422, validation loss: 0.0313
2024-05-24 22:42:42 [INFO]: Epoch 005 - training loss: 0.0425, validation loss: 0.0292
2024-05-24 22:42:42 [INFO]: Epoch 006 - training loss: 0.0424, validation loss: 0.0262
2024-05-24 22:42:43 [INFO]: Epoch 007 - training loss: 0.0373, validation loss: 0.0269
2024-05-24 22:42:43 [INFO]: Epoch 008 - training loss: 0.0311, validation loss: 0.0265
2024-05-24 22:42:43 [INFO]: Epoch 009 - training loss: 0.0310, validation loss: 0.0236
2024-05-24 22:42:43 [INFO]: Epoch 010 - training loss: 0.0285, validation loss: 0.0246
2024-05-24 22:42:43 [INFO]: Epoch 011 - training loss: 0.0279, validation loss: 0.0232
2024-05-24 22:42:44 [INFO]: Epoch 012 - training loss: 0.0258, validation loss: 0.0223
2024-05-24 22:42:44 [INFO]: Epoch 013 - training loss: 0.0244, validation loss: 0.0212
2024-05-24 22:42:44 [INFO]: Epoch 014 - training loss: 0.0236, validation loss: 0.0212
2024-05-24 22:42:44 [INFO]: Epoch 015 - training loss: 0.0249, validation loss: 0.0265
2024-05-24 22:42:44 [INFO]: Epoch 016 - training loss: 0.0379, validation loss: 0.0291
2024-05-24 22:42:45 [INFO]: Epoch 017 - training loss: 0.0361, validation loss: 0.0246
2024-05-24 22:42:45 [INFO]: Epoch 018 - training loss: 0.0284, validation loss: 0.0238
2024-05-24 22:42:45 [INFO]: Epoch 019 - training loss: 0.0286, validation loss: 0.0237
2024-05-24 22:42:45 [INFO]: Epoch 020 - training loss: 0.0243, validation loss: 0.0228
2024-05-24 22:42:45 [INFO]: Epoch 021 - training loss: 0.0233, validation loss: 0.0224
2024-05-24 22:42:46 [INFO]: Epoch 022 - training loss: 0.0255, validation loss: 0.0218
2024-05-24 22:42:46 [INFO]: Epoch 023 - training loss: 0.0244, validation loss: 0.0233
2024-05-24 22:42:46 [INFO]: Epoch 024 - training loss: 0.0278, validation loss: 0.0228
2024-05-24 22:42:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:42:46 [INFO]: Finished training. The best model is from epoch#14.
2024-05-24 22:42:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/TimesNet_ettm1/20240524_T224241/TimesNet.pypots
2024-05-24 22:42:46 [INFO]: TimesNet on ETTm1: MAE=0.1078, MSE=0.0247
2024-05-24 22:42:46 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/TimesNet_ettm1/imputation.pkl
2024-05-24 22:42:46 [INFO]: Using the given device: cuda:0
2024-05-24 22:42:46 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246
2024-05-24 22:42:46 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/tensorboard
2024-05-24 22:42:46 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 22:42:48 [INFO]: Epoch 001 - training loss: 0.6827, validation loss: 0.4375
2024-05-24 22:42:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch1_loss0.4375036433339119.pypots
2024-05-24 22:42:50 [INFO]: Epoch 002 - training loss: 0.3910, validation loss: 0.3685
2024-05-24 22:42:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch2_loss0.3685414269566536.pypots
2024-05-24 22:42:52 [INFO]: Epoch 003 - training loss: 0.3493, validation loss: 0.3432
2024-05-24 22:42:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch3_loss0.3431592881679535.pypots
2024-05-24 22:42:54 [INFO]: Epoch 004 - training loss: 0.3143, validation loss: 0.2954
2024-05-24 22:42:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch4_loss0.29537852108478546.pypots
2024-05-24 22:42:56 [INFO]: Epoch 005 - training loss: 0.3105, validation loss: 0.2928
2024-05-24 22:42:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch5_loss0.29278116673231125.pypots
2024-05-24 22:42:58 [INFO]: Epoch 006 - training loss: 0.2845, validation loss: 0.2702
2024-05-24 22:42:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch6_loss0.27023790031671524.pypots
2024-05-24 22:43:00 [INFO]: Epoch 007 - training loss: 0.2278, validation loss: 0.2604
2024-05-24 22:43:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch7_loss0.2603503167629242.pypots
2024-05-24 22:43:02 [INFO]: Epoch 008 - training loss: 0.2171, validation loss: 0.2516
2024-05-24 22:43:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch8_loss0.25163939222693443.pypots
2024-05-24 22:43:04 [INFO]: Epoch 009 - training loss: 0.2142, validation loss: 0.2424
2024-05-24 22:43:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch9_loss0.24240554496645927.pypots
2024-05-24 22:43:06 [INFO]: Epoch 010 - training loss: 0.2900, validation loss: 0.2331
2024-05-24 22:43:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch10_loss0.23306768760085106.pypots
2024-05-24 22:43:08 [INFO]: Epoch 011 - training loss: 0.2520, validation loss: 0.2526
2024-05-24 22:43:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch11_loss0.2525768540799618.pypots
2024-05-24 22:43:11 [INFO]: Epoch 012 - training loss: 0.2561, validation loss: 0.2520
2024-05-24 22:43:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch12_loss0.2519625350832939.pypots
2024-05-24 22:43:13 [INFO]: Epoch 013 - training loss: 0.2435, validation loss: 0.2317
2024-05-24 22:43:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch13_loss0.2317117676138878.pypots
2024-05-24 22:43:15 [INFO]: Epoch 014 - training loss: 0.2341, validation loss: 0.2235
2024-05-24 22:43:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch14_loss0.22351013496518135.pypots
2024-05-24 22:43:17 [INFO]: Epoch 015 - training loss: 0.2691, validation loss: 0.2164
2024-05-24 22:43:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch15_loss0.21643367037177086.pypots
2024-05-24 22:43:19 [INFO]: Epoch 016 - training loss: 0.2405, validation loss: 0.2134
2024-05-24 22:43:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch16_loss0.21341253817081451.pypots
2024-05-24 22:43:21 [INFO]: Epoch 017 - training loss: 0.2393, validation loss: 0.2102
2024-05-24 22:43:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch17_loss0.21023064851760864.pypots
2024-05-24 22:43:23 [INFO]: Epoch 018 - training loss: 0.2238, validation loss: 0.2209
2024-05-24 22:43:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch18_loss0.22087064757943153.pypots
2024-05-24 22:43:25 [INFO]: Epoch 019 - training loss: 0.2060, validation loss: 0.2011
2024-05-24 22:43:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch19_loss0.20113305002450943.pypots
2024-05-24 22:43:27 [INFO]: Epoch 020 - training loss: 0.2419, validation loss: 0.1992
2024-05-24 22:43:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch20_loss0.1991509236395359.pypots
2024-05-24 22:43:29 [INFO]: Epoch 021 - training loss: 0.2164, validation loss: 0.2169
2024-05-24 22:43:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch21_loss0.2168886587023735.pypots
2024-05-24 22:43:31 [INFO]: Epoch 022 - training loss: 0.2052, validation loss: 0.1970
2024-05-24 22:43:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch22_loss0.19696971774101257.pypots
2024-05-24 22:43:33 [INFO]: Epoch 023 - training loss: 0.1953, validation loss: 0.1866
2024-05-24 22:43:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch23_loss0.1865900307893753.pypots
2024-05-24 22:43:35 [INFO]: Epoch 024 - training loss: 0.1939, validation loss: 0.1912
2024-05-24 22:43:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch24_loss0.19118567928671837.pypots
2024-05-24 22:43:37 [INFO]: Epoch 025 - training loss: 0.2106, validation loss: 0.1750
2024-05-24 22:43:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch25_loss0.17502017319202423.pypots
2024-05-24 22:43:39 [INFO]: Epoch 026 - training loss: 0.1994, validation loss: 0.1823
2024-05-24 22:43:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch26_loss0.18228528648614883.pypots
2024-05-24 22:43:41 [INFO]: Epoch 027 - training loss: 0.2020, validation loss: 0.1787
2024-05-24 22:43:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch27_loss0.17865124344825745.pypots
2024-05-24 22:43:43 [INFO]: Epoch 028 - training loss: 0.2110, validation loss: 0.1903
2024-05-24 22:43:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch28_loss0.19034940004348755.pypots
2024-05-24 22:43:45 [INFO]: Epoch 029 - training loss: 0.1808, validation loss: 0.1725
2024-05-24 22:43:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch29_loss0.1724877916276455.pypots
2024-05-24 22:43:47 [INFO]: Epoch 030 - training loss: 0.1599, validation loss: 0.1724
2024-05-24 22:43:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch30_loss0.1723897010087967.pypots
2024-05-24 22:43:49 [INFO]: Epoch 031 - training loss: 0.1722, validation loss: 0.1709
2024-05-24 22:43:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch31_loss0.17093908041715622.pypots
2024-05-24 22:43:51 [INFO]: Epoch 032 - training loss: 0.1701, validation loss: 0.1651
2024-05-24 22:43:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch32_loss0.16507364436984062.pypots
2024-05-24 22:43:54 [INFO]: Epoch 033 - training loss: 0.1783, validation loss: 0.1684
2024-05-24 22:43:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch33_loss0.16836942732334137.pypots
2024-05-24 22:43:56 [INFO]: Epoch 034 - training loss: 0.1882, validation loss: 0.1677
2024-05-24 22:43:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch34_loss0.16772271320223808.pypots
2024-05-24 22:43:58 [INFO]: Epoch 035 - training loss: 0.1914, validation loss: 0.1648
2024-05-24 22:43:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch35_loss0.16480331122875214.pypots
2024-05-24 22:44:00 [INFO]: Epoch 036 - training loss: 0.1684, validation loss: 0.1575
2024-05-24 22:44:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch36_loss0.15753985196352005.pypots
2024-05-24 22:44:02 [INFO]: Epoch 037 - training loss: 0.2135, validation loss: 0.1735
2024-05-24 22:44:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch37_loss0.17354491353034973.pypots
2024-05-24 22:44:04 [INFO]: Epoch 038 - training loss: 0.1947, validation loss: 0.1688
2024-05-24 22:44:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch38_loss0.16878654807806015.pypots
2024-05-24 22:44:06 [INFO]: Epoch 039 - training loss: 0.1626, validation loss: 0.1584
2024-05-24 22:44:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch39_loss0.15836085006594658.pypots
2024-05-24 22:44:08 [INFO]: Epoch 040 - training loss: 0.1746, validation loss: 0.1607
2024-05-24 22:44:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch40_loss0.1607479527592659.pypots
2024-05-24 22:44:10 [INFO]: Epoch 041 - training loss: 0.1654, validation loss: 0.1524
2024-05-24 22:44:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch41_loss0.15243303775787354.pypots
2024-05-24 22:44:12 [INFO]: Epoch 042 - training loss: 0.1453, validation loss: 0.1472
2024-05-24 22:44:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch42_loss0.1471824310719967.pypots
2024-05-24 22:44:14 [INFO]: Epoch 043 - training loss: 0.1776, validation loss: 0.1709
2024-05-24 22:44:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch43_loss0.17088094726204872.pypots
2024-05-24 22:44:16 [INFO]: Epoch 044 - training loss: 0.1655, validation loss: 0.1617
2024-05-24 22:44:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch44_loss0.16174351423978806.pypots
2024-05-24 22:44:18 [INFO]: Epoch 045 - training loss: 0.1601, validation loss: 0.1616
2024-05-24 22:44:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch45_loss0.16162483394145966.pypots
2024-05-24 22:44:20 [INFO]: Epoch 046 - training loss: 0.2189, validation loss: 0.1645
2024-05-24 22:44:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch46_loss0.16452256217598915.pypots
2024-05-24 22:44:22 [INFO]: Epoch 047 - training loss: 0.1567, validation loss: 0.1547
2024-05-24 22:44:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch47_loss0.1546855866909027.pypots
2024-05-24 22:44:24 [INFO]: Epoch 048 - training loss: 0.1954, validation loss: 0.1676
2024-05-24 22:44:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch48_loss0.167556244879961.pypots
2024-05-24 22:44:26 [INFO]: Epoch 049 - training loss: 0.1704, validation loss: 0.1682
2024-05-24 22:44:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch49_loss0.16822757199406624.pypots
2024-05-24 22:44:28 [INFO]: Epoch 050 - training loss: 0.1743, validation loss: 0.1586
2024-05-24 22:44:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch50_loss0.15856317803263664.pypots
2024-05-24 22:44:30 [INFO]: Epoch 051 - training loss: 0.1940, validation loss: 0.1633
2024-05-24 22:44:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch51_loss0.1633286513388157.pypots
2024-05-24 22:44:32 [INFO]: Epoch 052 - training loss: 0.1817, validation loss: 0.1483
2024-05-24 22:44:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI_epoch52_loss0.14828291535377502.pypots
2024-05-24 22:44:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:44:32 [INFO]: Finished training. The best model is from epoch#42.
2024-05-24 22:44:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T224246/CSDI.pypots
2024-05-24 22:44:48 [INFO]: CSDI on ETTm1: MAE=0.1432, MSE=0.0585
2024-05-24 22:44:48 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/CSDI_ettm1/imputation.pkl
2024-05-24 22:44:48 [INFO]: Using the given device: cuda:0
2024-05-24 22:44:48 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/GPVAE_ettm1/20240524_T224448
2024-05-24 22:44:48 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/GPVAE_ettm1/20240524_T224448/tensorboard
2024-05-24 22:44:48 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 22:44:48 [INFO]: Epoch 001 - training loss: 23287.6831, validation loss: 1.0075
2024-05-24 22:44:49 [INFO]: Epoch 002 - training loss: 21045.9263, validation loss: 0.9965
2024-05-24 22:44:49 [INFO]: Epoch 003 - training loss: 18851.3348, validation loss: 0.9830
2024-05-24 22:44:49 [INFO]: Epoch 004 - training loss: 16957.4529, validation loss: 0.9471
2024-05-24 22:44:49 [INFO]: Epoch 005 - training loss: 14992.9260, validation loss: 0.8856
2024-05-24 22:44:49 [INFO]: Epoch 006 - training loss: 13680.0854, validation loss: 0.7633
2024-05-24 22:44:49 [INFO]: Epoch 007 - training loss: 12518.8990, validation loss: 0.6368
2024-05-24 22:44:49 [INFO]: Epoch 008 - training loss: 11798.2706, validation loss: 0.5464
2024-05-24 22:44:50 [INFO]: Epoch 009 - training loss: 11193.4468, validation loss: 0.4933
2024-05-24 22:44:50 [INFO]: Epoch 010 - training loss: 10836.6329, validation loss: 0.4615
2024-05-24 22:44:50 [INFO]: Epoch 011 - training loss: 10571.1814, validation loss: 0.4375
2024-05-24 22:44:50 [INFO]: Epoch 012 - training loss: 10372.2232, validation loss: 0.4127
2024-05-24 22:44:50 [INFO]: Epoch 013 - training loss: 10163.8501, validation loss: 0.3836
2024-05-24 22:44:50 [INFO]: Epoch 014 - training loss: 10082.4354, validation loss: 0.3558
2024-05-24 22:44:50 [INFO]: Epoch 015 - training loss: 9988.6624, validation loss: 0.3325
2024-05-24 22:44:50 [INFO]: Epoch 016 - training loss: 9889.2886, validation loss: 0.3087
2024-05-24 22:44:51 [INFO]: Epoch 017 - training loss: 9905.5361, validation loss: 0.2979
2024-05-24 22:44:51 [INFO]: Epoch 018 - training loss: 9803.8109, validation loss: 0.2835
2024-05-24 22:44:51 [INFO]: Epoch 019 - training loss: 9777.8137, validation loss: 0.2711
2024-05-24 22:44:51 [INFO]: Epoch 020 - training loss: 9706.2491, validation loss: 0.2635
2024-05-24 22:44:51 [INFO]: Epoch 021 - training loss: 9634.5098, validation loss: 0.2537
2024-05-24 22:44:51 [INFO]: Epoch 022 - training loss: 9602.8047, validation loss: 0.2456
2024-05-24 22:44:51 [INFO]: Epoch 023 - training loss: 9570.9711, validation loss: 0.2351
2024-05-24 22:44:52 [INFO]: Epoch 024 - training loss: 9641.1755, validation loss: 0.2280
2024-05-24 22:44:52 [INFO]: Epoch 025 - training loss: 9547.4752, validation loss: 0.2188
2024-05-24 22:44:52 [INFO]: Epoch 026 - training loss: 9519.5970, validation loss: 0.2138
2024-05-24 22:44:52 [INFO]: Epoch 027 - training loss: 9509.3397, validation loss: 0.2061
2024-05-24 22:44:52 [INFO]: Epoch 028 - training loss: 9497.0455, validation loss: 0.1940
2024-05-24 22:44:52 [INFO]: Epoch 029 - training loss: 9485.1150, validation loss: 0.1895
2024-05-24 22:44:52 [INFO]: Epoch 030 - training loss: 9474.4387, validation loss: 0.1804
2024-05-24 22:44:52 [INFO]: Epoch 031 - training loss: 9470.1824, validation loss: 0.1827
2024-05-24 22:44:53 [INFO]: Epoch 032 - training loss: 9469.3704, validation loss: 0.1804
2024-05-24 22:44:53 [INFO]: Epoch 033 - training loss: 9450.1208, validation loss: 0.1739
2024-05-24 22:44:53 [INFO]: Epoch 034 - training loss: 9450.0775, validation loss: 0.1685
2024-05-24 22:44:53 [INFO]: Epoch 035 - training loss: 9432.0213, validation loss: 0.1634
2024-05-24 22:44:53 [INFO]: Epoch 036 - training loss: 9443.4380, validation loss: 0.1631
2024-05-24 22:44:53 [INFO]: Epoch 037 - training loss: 9417.1684, validation loss: 0.1572
2024-05-24 22:44:53 [INFO]: Epoch 038 - training loss: 9421.5192, validation loss: 0.1544
2024-05-24 22:44:54 [INFO]: Epoch 039 - training loss: 9406.7201, validation loss: 0.1519
2024-05-24 22:44:54 [INFO]: Epoch 040 - training loss: 9414.5729, validation loss: 0.1486
2024-05-24 22:44:54 [INFO]: Epoch 041 - training loss: 9397.0887, validation loss: 0.1500
2024-05-24 22:44:54 [INFO]: Epoch 042 - training loss: 9401.8215, validation loss: 0.1468
2024-05-24 22:44:54 [INFO]: Epoch 043 - training loss: 9393.5487, validation loss: 0.1440
2024-05-24 22:44:54 [INFO]: Epoch 044 - training loss: 9397.6583, validation loss: 0.1416
2024-05-24 22:44:54 [INFO]: Epoch 045 - training loss: 9383.8361, validation loss: 0.1379
2024-05-24 22:44:55 [INFO]: Epoch 046 - training loss: 9386.3811, validation loss: 0.1375
2024-05-24 22:44:55 [INFO]: Epoch 047 - training loss: 9379.1804, validation loss: 0.1350
2024-05-24 22:44:55 [INFO]: Epoch 048 - training loss: 9374.4188, validation loss: 0.1335
2024-05-24 22:44:55 [INFO]: Epoch 049 - training loss: 9372.8791, validation loss: 0.1323
2024-05-24 22:44:55 [INFO]: Epoch 050 - training loss: 9370.4282, validation loss: 0.1300
2024-05-24 22:44:55 [INFO]: Epoch 051 - training loss: 9373.9967, validation loss: 0.1295
2024-05-24 22:44:55 [INFO]: Epoch 052 - training loss: 9370.3550, validation loss: 0.1286
2024-05-24 22:44:55 [INFO]: Epoch 053 - training loss: 9374.1447, validation loss: 0.1275
2024-05-24 22:44:56 [INFO]: Epoch 054 - training loss: 9362.3709, validation loss: 0.1250
2024-05-24 22:44:56 [INFO]: Epoch 055 - training loss: 9361.0305, validation loss: 0.1248
2024-05-24 22:44:56 [INFO]: Epoch 056 - training loss: 9358.2979, validation loss: 0.1234
2024-05-24 22:44:56 [INFO]: Epoch 057 - training loss: 9356.4833, validation loss: 0.1234
2024-05-24 22:44:56 [INFO]: Epoch 058 - training loss: 9357.6439, validation loss: 0.1210
2024-05-24 22:44:56 [INFO]: Epoch 059 - training loss: 9353.4887, validation loss: 0.1211
2024-05-24 22:44:56 [INFO]: Epoch 060 - training loss: 9352.3134, validation loss: 0.1195
2024-05-24 22:44:57 [INFO]: Epoch 061 - training loss: 9349.8798, validation loss: 0.1188
2024-05-24 22:44:57 [INFO]: Epoch 062 - training loss: 9351.0969, validation loss: 0.1183
2024-05-24 22:44:57 [INFO]: Epoch 063 - training loss: 9350.8127, validation loss: 0.1170
2024-05-24 22:44:57 [INFO]: Epoch 064 - training loss: 9346.1591, validation loss: 0.1159
2024-05-24 22:44:57 [INFO]: Epoch 065 - training loss: 9346.5527, validation loss: 0.1143
2024-05-24 22:44:57 [INFO]: Epoch 066 - training loss: 9343.6829, validation loss: 0.1141
2024-05-24 22:44:57 [INFO]: Epoch 067 - training loss: 9343.8348, validation loss: 0.1133
2024-05-24 22:44:58 [INFO]: Epoch 068 - training loss: 9342.5260, validation loss: 0.1129
2024-05-24 22:44:58 [INFO]: Epoch 069 - training loss: 9343.6744, validation loss: 0.1125
2024-05-24 22:44:58 [INFO]: Epoch 070 - training loss: 9338.6423, validation loss: 0.1118
2024-05-24 22:44:58 [INFO]: Epoch 071 - training loss: 9338.8152, validation loss: 0.1105
2024-05-24 22:44:58 [INFO]: Epoch 072 - training loss: 9337.9596, validation loss: 0.1115
2024-05-24 22:44:58 [INFO]: Epoch 073 - training loss: 9338.8038, validation loss: 0.1087
2024-05-24 22:44:58 [INFO]: Epoch 074 - training loss: 9336.7968, validation loss: 0.1091
2024-05-24 22:44:58 [INFO]: Epoch 075 - training loss: 9334.6826, validation loss: 0.1072
2024-05-24 22:44:59 [INFO]: Epoch 076 - training loss: 9337.0165, validation loss: 0.1071
2024-05-24 22:44:59 [INFO]: Epoch 077 - training loss: 9334.5449, validation loss: 0.1060
2024-05-24 22:44:59 [INFO]: Epoch 078 - training loss: 9340.0754, validation loss: 0.1055
2024-05-24 22:44:59 [INFO]: Epoch 079 - training loss: 9334.6925, validation loss: 0.1052
2024-05-24 22:44:59 [INFO]: Epoch 080 - training loss: 9331.0497, validation loss: 0.1048
2024-05-24 22:44:59 [INFO]: Epoch 081 - training loss: 9330.4390, validation loss: 0.1037
2024-05-24 22:45:00 [INFO]: Epoch 082 - training loss: 9329.8693, validation loss: 0.1032
2024-05-24 22:45:00 [INFO]: Epoch 083 - training loss: 9330.8517, validation loss: 0.1029
2024-05-24 22:45:00 [INFO]: Epoch 084 - training loss: 9330.5737, validation loss: 0.1029
2024-05-24 22:45:00 [INFO]: Epoch 085 - training loss: 9329.7998, validation loss: 0.1017
2024-05-24 22:45:00 [INFO]: Epoch 086 - training loss: 9328.8723, validation loss: 0.1024
2024-05-24 22:45:00 [INFO]: Epoch 087 - training loss: 9328.6825, validation loss: 0.1000
2024-05-24 22:45:00 [INFO]: Epoch 088 - training loss: 9327.3694, validation loss: 0.1010
2024-05-24 22:45:00 [INFO]: Epoch 089 - training loss: 9326.6911, validation loss: 0.1003
2024-05-24 22:45:01 [INFO]: Epoch 090 - training loss: 9325.1872, validation loss: 0.0980
2024-05-24 22:45:01 [INFO]: Epoch 091 - training loss: 9325.8834, validation loss: 0.1003
2024-05-24 22:45:01 [INFO]: Epoch 092 - training loss: 9324.3505, validation loss: 0.0996
2024-05-24 22:45:01 [INFO]: Epoch 093 - training loss: 9325.0139, validation loss: 0.0977
2024-05-24 22:45:01 [INFO]: Epoch 094 - training loss: 9325.3023, validation loss: 0.0985
2024-05-24 22:45:01 [INFO]: Epoch 095 - training loss: 9326.0458, validation loss: 0.0960
2024-05-24 22:45:01 [INFO]: Epoch 096 - training loss: 9325.0134, validation loss: 0.0998
2024-05-24 22:45:02 [INFO]: Epoch 097 - training loss: 9323.2317, validation loss: 0.0943
2024-05-24 22:45:02 [INFO]: Epoch 098 - training loss: 9324.1722, validation loss: 0.0970
2024-05-24 22:45:02 [INFO]: Epoch 099 - training loss: 9321.9788, validation loss: 0.0950
2024-05-24 22:45:02 [INFO]: Epoch 100 - training loss: 9321.4240, validation loss: 0.0955
2024-05-24 22:45:02 [INFO]: Epoch 101 - training loss: 9320.4623, validation loss: 0.0936
2024-05-24 22:45:02 [INFO]: Epoch 102 - training loss: 9321.3986, validation loss: 0.0941
2024-05-24 22:45:02 [INFO]: Epoch 103 - training loss: 9319.6883, validation loss: 0.0932
2024-05-24 22:45:02 [INFO]: Epoch 104 - training loss: 9320.5851, validation loss: 0.0933
2024-05-24 22:45:03 [INFO]: Epoch 105 - training loss: 9320.2210, validation loss: 0.0923
2024-05-24 22:45:03 [INFO]: Epoch 106 - training loss: 9319.5192, validation loss: 0.0928
2024-05-24 22:45:03 [INFO]: Epoch 107 - training loss: 9320.3911, validation loss: 0.0925
2024-05-24 22:45:03 [INFO]: Epoch 108 - training loss: 9318.9409, validation loss: 0.0914
2024-05-24 22:45:03 [INFO]: Epoch 109 - training loss: 9317.7111, validation loss: 0.0919
2024-05-24 22:45:03 [INFO]: Epoch 110 - training loss: 9318.1844, validation loss: 0.0903
2024-05-24 22:45:03 [INFO]: Epoch 111 - training loss: 9318.5705, validation loss: 0.0908
2024-05-24 22:45:04 [INFO]: Epoch 112 - training loss: 9316.3190, validation loss: 0.0892
2024-05-24 22:45:04 [INFO]: Epoch 113 - training loss: 9317.1327, validation loss: 0.0909
2024-05-24 22:45:04 [INFO]: Epoch 114 - training loss: 9317.2407, validation loss: 0.0885
2024-05-24 22:45:04 [INFO]: Epoch 115 - training loss: 9316.6705, validation loss: 0.0889
2024-05-24 22:45:04 [INFO]: Epoch 116 - training loss: 9315.4800, validation loss: 0.0884
2024-05-24 22:45:04 [INFO]: Epoch 117 - training loss: 9316.3029, validation loss: 0.0894
2024-05-24 22:45:04 [INFO]: Epoch 118 - training loss: 9316.4985, validation loss: 0.0877
2024-05-24 22:45:05 [INFO]: Epoch 119 - training loss: 9314.8967, validation loss: 0.0887
2024-05-24 22:45:05 [INFO]: Epoch 120 - training loss: 9315.4136, validation loss: 0.0875
2024-05-24 22:45:05 [INFO]: Epoch 121 - training loss: 9314.4931, validation loss: 0.0859
2024-05-24 22:45:05 [INFO]: Epoch 122 - training loss: 9313.5321, validation loss: 0.0866
2024-05-24 22:45:05 [INFO]: Epoch 123 - training loss: 9315.8107, validation loss: 0.0867
2024-05-24 22:45:05 [INFO]: Epoch 124 - training loss: 9318.0901, validation loss: 0.0860
2024-05-24 22:45:05 [INFO]: Epoch 125 - training loss: 9312.9250, validation loss: 0.0858
2024-05-24 22:45:06 [INFO]: Epoch 126 - training loss: 9314.4393, validation loss: 0.0859
2024-05-24 22:45:06 [INFO]: Epoch 127 - training loss: 9315.9210, validation loss: 0.0856
2024-05-24 22:45:06 [INFO]: Epoch 128 - training loss: 9314.3827, validation loss: 0.0847
2024-05-24 22:45:06 [INFO]: Epoch 129 - training loss: 9313.7385, validation loss: 0.0848
2024-05-24 22:45:06 [INFO]: Epoch 130 - training loss: 9313.1100, validation loss: 0.0836
2024-05-24 22:45:06 [INFO]: Epoch 131 - training loss: 9314.2967, validation loss: 0.0838
2024-05-24 22:45:06 [INFO]: Epoch 132 - training loss: 9311.9539, validation loss: 0.0826
2024-05-24 22:45:06 [INFO]: Epoch 133 - training loss: 9313.8924, validation loss: 0.0852
2024-05-24 22:45:07 [INFO]: Epoch 134 - training loss: 9311.6299, validation loss: 0.0825
2024-05-24 22:45:07 [INFO]: Epoch 135 - training loss: 9312.6693, validation loss: 0.0840
2024-05-24 22:45:07 [INFO]: Epoch 136 - training loss: 9311.4344, validation loss: 0.0840
2024-05-24 22:45:07 [INFO]: Epoch 137 - training loss: 9310.7462, validation loss: 0.0835
2024-05-24 22:45:07 [INFO]: Epoch 138 - training loss: 9310.7395, validation loss: 0.0814
2024-05-24 22:45:07 [INFO]: Epoch 139 - training loss: 9311.0609, validation loss: 0.0815
2024-05-24 22:45:07 [INFO]: Epoch 140 - training loss: 9309.7507, validation loss: 0.0815
2024-05-24 22:45:08 [INFO]: Epoch 141 - training loss: 9310.5967, validation loss: 0.0814
2024-05-24 22:45:08 [INFO]: Epoch 142 - training loss: 9309.7555, validation loss: 0.0808
2024-05-24 22:45:08 [INFO]: Epoch 143 - training loss: 9310.7672, validation loss: 0.0806
2024-05-24 22:45:08 [INFO]: Epoch 144 - training loss: 9309.7957, validation loss: 0.0824
2024-05-24 22:45:08 [INFO]: Epoch 145 - training loss: 9311.8524, validation loss: 0.0794
2024-05-24 22:45:08 [INFO]: Epoch 146 - training loss: 9310.9623, validation loss: 0.0793
2024-05-24 22:45:08 [INFO]: Epoch 147 - training loss: 9310.2241, validation loss: 0.0817
2024-05-24 22:45:08 [INFO]: Epoch 148 - training loss: 9311.5797, validation loss: 0.0790
2024-05-24 22:45:09 [INFO]: Epoch 149 - training loss: 9309.6296, validation loss: 0.0812
2024-05-24 22:45:09 [INFO]: Epoch 150 - training loss: 9309.3779, validation loss: 0.0795
2024-05-24 22:45:09 [INFO]: Epoch 151 - training loss: 9308.9172, validation loss: 0.0799
2024-05-24 22:45:09 [INFO]: Epoch 152 - training loss: 9309.1387, validation loss: 0.0797
2024-05-24 22:45:09 [INFO]: Epoch 153 - training loss: 9309.0532, validation loss: 0.0796
2024-05-24 22:45:09 [INFO]: Epoch 154 - training loss: 9310.2062, validation loss: 0.0799
2024-05-24 22:45:09 [INFO]: Epoch 155 - training loss: 9309.2119, validation loss: 0.0795
2024-05-24 22:45:10 [INFO]: Epoch 156 - training loss: 9308.4731, validation loss: 0.0790
2024-05-24 22:45:10 [INFO]: Epoch 157 - training loss: 9308.5428, validation loss: 0.0787
2024-05-24 22:45:10 [INFO]: Epoch 158 - training loss: 9308.2757, validation loss: 0.0797
2024-05-24 22:45:10 [INFO]: Epoch 159 - training loss: 9308.4067, validation loss: 0.0776
2024-05-24 22:45:10 [INFO]: Epoch 160 - training loss: 9307.6196, validation loss: 0.0776
2024-05-24 22:45:10 [INFO]: Epoch 161 - training loss: 9309.0926, validation loss: 0.0782
2024-05-24 22:45:10 [INFO]: Epoch 162 - training loss: 9308.8104, validation loss: 0.0782
2024-05-24 22:45:11 [INFO]: Epoch 163 - training loss: 9306.6328, validation loss: 0.0778
2024-05-24 22:45:11 [INFO]: Epoch 164 - training loss: 9309.2301, validation loss: 0.0769
2024-05-24 22:45:11 [INFO]: Epoch 165 - training loss: 9309.9841, validation loss: 0.0774
2024-05-24 22:45:11 [INFO]: Epoch 166 - training loss: 9308.4097, validation loss: 0.0761
2024-05-24 22:45:11 [INFO]: Epoch 167 - training loss: 9307.0237, validation loss: 0.0780
2024-05-24 22:45:11 [INFO]: Epoch 168 - training loss: 9306.6664, validation loss: 0.0772
2024-05-24 22:45:11 [INFO]: Epoch 169 - training loss: 9306.4946, validation loss: 0.0768
2024-05-24 22:45:11 [INFO]: Epoch 170 - training loss: 9307.1254, validation loss: 0.0768
2024-05-24 22:45:12 [INFO]: Epoch 171 - training loss: 9306.5288, validation loss: 0.0768
2024-05-24 22:45:12 [INFO]: Epoch 172 - training loss: 9308.2084, validation loss: 0.0753
2024-05-24 22:45:12 [INFO]: Epoch 173 - training loss: 9305.6769, validation loss: 0.0779
2024-05-24 22:45:12 [INFO]: Epoch 174 - training loss: 9305.9752, validation loss: 0.0758
2024-05-24 22:45:12 [INFO]: Epoch 175 - training loss: 9307.3118, validation loss: 0.0768
2024-05-24 22:45:12 [INFO]: Epoch 176 - training loss: 9307.3999, validation loss: 0.0753
2024-05-24 22:45:12 [INFO]: Epoch 177 - training loss: 9305.1722, validation loss: 0.0771
2024-05-24 22:45:13 [INFO]: Epoch 178 - training loss: 9309.5576, validation loss: 0.0775
2024-05-24 22:45:13 [INFO]: Epoch 179 - training loss: 9306.3998, validation loss: 0.0760
2024-05-24 22:45:13 [INFO]: Epoch 180 - training loss: 9306.2626, validation loss: 0.0761
2024-05-24 22:45:13 [INFO]: Epoch 181 - training loss: 9306.2986, validation loss: 0.0754
2024-05-24 22:45:13 [INFO]: Epoch 182 - training loss: 9306.4622, validation loss: 0.0748
2024-05-24 22:45:13 [INFO]: Epoch 183 - training loss: 9305.8443, validation loss: 0.0760
2024-05-24 22:45:13 [INFO]: Epoch 184 - training loss: 9304.8304, validation loss: 0.0755
2024-05-24 22:45:14 [INFO]: Epoch 185 - training loss: 9305.0891, validation loss: 0.0746
2024-05-24 22:45:14 [INFO]: Epoch 186 - training loss: 9305.0590, validation loss: 0.0761
2024-05-24 22:45:14 [INFO]: Epoch 187 - training loss: 9305.7028, validation loss: 0.0755
2024-05-24 22:45:14 [INFO]: Epoch 188 - training loss: 9307.4334, validation loss: 0.0743
2024-05-24 22:45:14 [INFO]: Epoch 189 - training loss: 9305.3264, validation loss: 0.0746
2024-05-24 22:45:14 [INFO]: Epoch 190 - training loss: 9305.5154, validation loss: 0.0734
2024-05-24 22:45:14 [INFO]: Epoch 191 - training loss: 9305.7477, validation loss: 0.0753
2024-05-24 22:45:14 [INFO]: Epoch 192 - training loss: 9304.7361, validation loss: 0.0737
2024-05-24 22:45:15 [INFO]: Epoch 193 - training loss: 9305.4235, validation loss: 0.0748
2024-05-24 22:45:15 [INFO]: Epoch 194 - training loss: 9306.0742, validation loss: 0.0743
2024-05-24 22:45:15 [INFO]: Epoch 195 - training loss: 9307.0810, validation loss: 0.0766
2024-05-24 22:45:15 [INFO]: Epoch 196 - training loss: 9305.1874, validation loss: 0.0750
2024-05-24 22:45:15 [INFO]: Epoch 197 - training loss: 9305.4932, validation loss: 0.0736
2024-05-24 22:45:15 [INFO]: Epoch 198 - training loss: 9305.0232, validation loss: 0.0716
2024-05-24 22:45:15 [INFO]: Epoch 199 - training loss: 9305.4484, validation loss: 0.0738
2024-05-24 22:45:16 [INFO]: Epoch 200 - training loss: 9304.1052, validation loss: 0.0731
2024-05-24 22:45:16 [INFO]: Epoch 201 - training loss: 9305.7596, validation loss: 0.0744
2024-05-24 22:45:16 [INFO]: Epoch 202 - training loss: 9304.3395, validation loss: 0.0741
2024-05-24 22:45:16 [INFO]: Epoch 203 - training loss: 9304.5408, validation loss: 0.0733
2024-05-24 22:45:16 [INFO]: Epoch 204 - training loss: 9304.7043, validation loss: 0.0729
2024-05-24 22:45:16 [INFO]: Epoch 205 - training loss: 9305.0099, validation loss: 0.0721
2024-05-24 22:45:16 [INFO]: Epoch 206 - training loss: 9304.3838, validation loss: 0.0721
2024-05-24 22:45:17 [INFO]: Epoch 207 - training loss: 9303.6133, validation loss: 0.0728
2024-05-24 22:45:17 [INFO]: Epoch 208 - training loss: 9304.5990, validation loss: 0.0732
2024-05-24 22:45:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:45:17 [INFO]: Finished training. The best model is from epoch#198.
2024-05-24 22:45:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/GPVAE_ettm1/20240524_T224448/GPVAE.pypots
2024-05-24 22:45:17 [INFO]: GP-VAE on ETTm1: MAE=0.2662, MSE=0.1547
2024-05-24 22:45:17 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/GPVAE_ettm1/imputation.pkl
2024-05-24 22:45:17 [INFO]: Using the given device: cuda:0
2024-05-24 22:45:17 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/USGAN_ettm1/20240524_T224517
2024-05-24 22:45:17 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/USGAN_ettm1/20240524_T224517/tensorboard
2024-05-24 22:45:17 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 22:45:27 [INFO]: Epoch 001 - generator training loss: 0.6087, discriminator training loss: 0.3547, validation loss: 0.3046
2024-05-24 22:45:36 [INFO]: Epoch 002 - generator training loss: 0.0561, discriminator training loss: 0.2104, validation loss: 0.1193
2024-05-24 22:45:45 [INFO]: Epoch 003 - generator training loss: -0.0560, discriminator training loss: 0.2017, validation loss: 0.0672
2024-05-24 22:45:54 [INFO]: Epoch 004 - generator training loss: -0.0822, discriminator training loss: 0.2006, validation loss: 0.0470
2024-05-24 22:46:03 [INFO]: Epoch 005 - generator training loss: -0.0880, discriminator training loss: 0.1962, validation loss: 0.0427
2024-05-24 22:46:12 [INFO]: Epoch 006 - generator training loss: -0.0844, discriminator training loss: 0.1896, validation loss: 0.0409
2024-05-24 22:46:21 [INFO]: Epoch 007 - generator training loss: -0.0821, discriminator training loss: 0.1859, validation loss: 0.0389
2024-05-24 22:46:30 [INFO]: Epoch 008 - generator training loss: -0.0817, discriminator training loss: 0.1824, validation loss: 0.0377
2024-05-24 22:46:38 [INFO]: Epoch 009 - generator training loss: -0.0728, discriminator training loss: 0.1724, validation loss: 0.0364
2024-05-24 22:46:47 [INFO]: Epoch 010 - generator training loss: -0.0598, discriminator training loss: 0.1573, validation loss: 0.0365
2024-05-24 22:46:56 [INFO]: Epoch 011 - generator training loss: -0.0478, discriminator training loss: 0.1410, validation loss: 0.0354
2024-05-24 22:47:05 [INFO]: Epoch 012 - generator training loss: -0.0376, discriminator training loss: 0.1266, validation loss: 0.0407
2024-05-24 22:47:14 [INFO]: Epoch 013 - generator training loss: -0.0235, discriminator training loss: 0.1126, validation loss: 0.0359
2024-05-24 22:47:23 [INFO]: Epoch 014 - generator training loss: -0.0217, discriminator training loss: 0.1046, validation loss: 0.0341
2024-05-24 22:47:31 [INFO]: Epoch 015 - generator training loss: -0.0170, discriminator training loss: 0.0971, validation loss: 0.0334
2024-05-24 22:47:40 [INFO]: Epoch 016 - generator training loss: -0.0154, discriminator training loss: 0.0923, validation loss: 0.0328
2024-05-24 22:47:49 [INFO]: Epoch 017 - generator training loss: -0.0143, discriminator training loss: 0.0891, validation loss: 0.0325
2024-05-24 22:47:58 [INFO]: Epoch 018 - generator training loss: -0.0130, discriminator training loss: 0.0856, validation loss: 0.0319
2024-05-24 22:48:07 [INFO]: Epoch 019 - generator training loss: -0.0124, discriminator training loss: 0.0844, validation loss: 0.0315
2024-05-24 22:48:16 [INFO]: Epoch 020 - generator training loss: -0.0131, discriminator training loss: 0.0833, validation loss: 0.0308
2024-05-24 22:48:25 [INFO]: Epoch 021 - generator training loss: -0.0140, discriminator training loss: 0.0834, validation loss: 0.0306
2024-05-24 22:48:33 [INFO]: Epoch 022 - generator training loss: -0.0114, discriminator training loss: 0.0811, validation loss: 0.0303
2024-05-24 22:48:42 [INFO]: Epoch 023 - generator training loss: -0.0129, discriminator training loss: 0.0801, validation loss: 0.0304
2024-05-24 22:48:51 [INFO]: Epoch 024 - generator training loss: -0.0107, discriminator training loss: 0.0776, validation loss: 0.0300
2024-05-24 22:49:00 [INFO]: Epoch 025 - generator training loss: -0.0131, discriminator training loss: 0.0782, validation loss: 0.0299
2024-05-24 22:49:09 [INFO]: Epoch 026 - generator training loss: -0.0119, discriminator training loss: 0.0782, validation loss: 0.0295
2024-05-24 22:49:18 [INFO]: Epoch 027 - generator training loss: -0.0129, discriminator training loss: 0.0791, validation loss: 0.0283
2024-05-24 22:49:27 [INFO]: Epoch 028 - generator training loss: -0.0131, discriminator training loss: 0.0765, validation loss: 0.0280
2024-05-24 22:49:36 [INFO]: Epoch 029 - generator training loss: -0.0163, discriminator training loss: 0.0768, validation loss: 0.0274
2024-05-24 22:49:44 [INFO]: Epoch 030 - generator training loss: -0.0126, discriminator training loss: 0.0747, validation loss: 0.0280
2024-05-24 22:49:53 [INFO]: Epoch 031 - generator training loss: -0.0111, discriminator training loss: 0.0745, validation loss: 0.0275
2024-05-24 22:50:02 [INFO]: Epoch 032 - generator training loss: -0.0158, discriminator training loss: 0.0768, validation loss: 0.0262
2024-05-24 22:50:11 [INFO]: Epoch 033 - generator training loss: -0.0153, discriminator training loss: 0.0765, validation loss: 0.0263
2024-05-24 22:50:20 [INFO]: Epoch 034 - generator training loss: -0.0132, discriminator training loss: 0.0751, validation loss: 0.0258
2024-05-24 22:50:29 [INFO]: Epoch 035 - generator training loss: -0.0177, discriminator training loss: 0.0739, validation loss: 0.0252
2024-05-24 22:50:38 [INFO]: Epoch 036 - generator training loss: -0.0181, discriminator training loss: 0.0751, validation loss: 0.0252
2024-05-24 22:50:47 [INFO]: Epoch 037 - generator training loss: -0.0165, discriminator training loss: 0.0745, validation loss: 0.0254
2024-05-24 22:50:56 [INFO]: Epoch 038 - generator training loss: -0.0181, discriminator training loss: 0.0718, validation loss: 0.0245
2024-05-24 22:51:05 [INFO]: Epoch 039 - generator training loss: -0.0190, discriminator training loss: 0.0731, validation loss: 0.0245
2024-05-24 22:51:14 [INFO]: Epoch 040 - generator training loss: -0.0175, discriminator training loss: 0.0729, validation loss: 0.0240
2024-05-24 22:51:23 [INFO]: Epoch 041 - generator training loss: -0.0190, discriminator training loss: 0.0708, validation loss: 0.0237
2024-05-24 22:51:32 [INFO]: Epoch 042 - generator training loss: -0.0188, discriminator training loss: 0.0718, validation loss: 0.0234
2024-05-24 22:51:41 [INFO]: Epoch 043 - generator training loss: -0.0208, discriminator training loss: 0.0721, validation loss: 0.0230
2024-05-24 22:51:50 [INFO]: Epoch 044 - generator training loss: -0.0199, discriminator training loss: 0.0715, validation loss: 0.0231
2024-05-24 22:51:59 [INFO]: Epoch 045 - generator training loss: -0.0193, discriminator training loss: 0.0718, validation loss: 0.0226
2024-05-24 22:52:08 [INFO]: Epoch 046 - generator training loss: -0.0202, discriminator training loss: 0.0732, validation loss: 0.0226
2024-05-24 22:52:17 [INFO]: Epoch 047 - generator training loss: -0.0201, discriminator training loss: 0.0719, validation loss: 0.0238
2024-05-24 22:52:26 [INFO]: Epoch 048 - generator training loss: -0.0190, discriminator training loss: 0.0727, validation loss: 0.0227
2024-05-24 22:52:35 [INFO]: Epoch 049 - generator training loss: -0.0187, discriminator training loss: 0.0709, validation loss: 0.0226
2024-05-24 22:52:44 [INFO]: Epoch 050 - generator training loss: -0.0217, discriminator training loss: 0.0697, validation loss: 0.0218
2024-05-24 22:52:53 [INFO]: Epoch 051 - generator training loss: -0.0190, discriminator training loss: 0.0690, validation loss: 0.0209
2024-05-24 22:53:02 [INFO]: Epoch 052 - generator training loss: -0.0187, discriminator training loss: 0.0692, validation loss: 0.0217
2024-05-24 22:53:11 [INFO]: Epoch 053 - generator training loss: -0.0232, discriminator training loss: 0.0729, validation loss: 0.0210
2024-05-24 22:53:20 [INFO]: Epoch 054 - generator training loss: -0.0213, discriminator training loss: 0.0715, validation loss: 0.0208
2024-05-24 22:53:29 [INFO]: Epoch 055 - generator training loss: -0.0193, discriminator training loss: 0.0711, validation loss: 0.0206
2024-05-24 22:53:38 [INFO]: Epoch 056 - generator training loss: -0.0202, discriminator training loss: 0.0711, validation loss: 0.0216
2024-05-24 22:53:47 [INFO]: Epoch 057 - generator training loss: -0.0214, discriminator training loss: 0.0728, validation loss: 0.0206
2024-05-24 22:53:56 [INFO]: Epoch 058 - generator training loss: -0.0206, discriminator training loss: 0.0679, validation loss: 0.0212
2024-05-24 22:54:05 [INFO]: Epoch 059 - generator training loss: -0.0224, discriminator training loss: 0.0697, validation loss: 0.0218
2024-05-24 22:54:14 [INFO]: Epoch 060 - generator training loss: -0.0238, discriminator training loss: 0.0679, validation loss: 0.0212
2024-05-24 22:54:23 [INFO]: Epoch 061 - generator training loss: -0.0242, discriminator training loss: 0.0704, validation loss: 0.0206
2024-05-24 22:54:32 [INFO]: Epoch 062 - generator training loss: -0.0224, discriminator training loss: 0.0702, validation loss: 0.0204
2024-05-24 22:54:41 [INFO]: Epoch 063 - generator training loss: -0.0194, discriminator training loss: 0.0705, validation loss: 0.0203
2024-05-24 22:54:50 [INFO]: Epoch 064 - generator training loss: -0.0230, discriminator training loss: 0.0688, validation loss: 0.0205
2024-05-24 22:54:59 [INFO]: Epoch 065 - generator training loss: -0.0223, discriminator training loss: 0.0672, validation loss: 0.0205
2024-05-24 22:55:08 [INFO]: Epoch 066 - generator training loss: -0.0198, discriminator training loss: 0.0681, validation loss: 0.0202
2024-05-24 22:55:17 [INFO]: Epoch 067 - generator training loss: -0.0244, discriminator training loss: 0.0699, validation loss: 0.0203
2024-05-24 22:55:26 [INFO]: Epoch 068 - generator training loss: -0.0224, discriminator training loss: 0.0710, validation loss: 0.0202
2024-05-24 22:55:35 [INFO]: Epoch 069 - generator training loss: -0.0231, discriminator training loss: 0.0687, validation loss: 0.0202
2024-05-24 22:55:44 [INFO]: Epoch 070 - generator training loss: -0.0241, discriminator training loss: 0.0671, validation loss: 0.0202
2024-05-24 22:55:53 [INFO]: Epoch 071 - generator training loss: -0.0228, discriminator training loss: 0.0684, validation loss: 0.0206
2024-05-24 22:56:01 [INFO]: Epoch 072 - generator training loss: -0.0239, discriminator training loss: 0.0685, validation loss: 0.0202
2024-05-24 22:56:10 [INFO]: Epoch 073 - generator training loss: -0.0246, discriminator training loss: 0.0692, validation loss: 0.0203
2024-05-24 22:56:19 [INFO]: Epoch 074 - generator training loss: -0.0228, discriminator training loss: 0.0686, validation loss: 0.0202
2024-05-24 22:56:28 [INFO]: Epoch 075 - generator training loss: -0.0230, discriminator training loss: 0.0694, validation loss: 0.0197
2024-05-24 22:56:37 [INFO]: Epoch 076 - generator training loss: -0.0218, discriminator training loss: 0.0682, validation loss: 0.0196
2024-05-24 22:56:46 [INFO]: Epoch 077 - generator training loss: -0.0224, discriminator training loss: 0.0671, validation loss: 0.0194
2024-05-24 22:56:55 [INFO]: Epoch 078 - generator training loss: -0.0209, discriminator training loss: 0.0679, validation loss: 0.0210
2024-05-24 22:57:04 [INFO]: Epoch 079 - generator training loss: -0.0226, discriminator training loss: 0.0677, validation loss: 0.0211
2024-05-24 22:57:13 [INFO]: Epoch 080 - generator training loss: -0.0232, discriminator training loss: 0.0680, validation loss: 0.0206
2024-05-24 22:57:22 [INFO]: Epoch 081 - generator training loss: -0.0222, discriminator training loss: 0.0680, validation loss: 0.0197
2024-05-24 22:57:31 [INFO]: Epoch 082 - generator training loss: -0.0217, discriminator training loss: 0.0689, validation loss: 0.0198
2024-05-24 22:57:40 [INFO]: Epoch 083 - generator training loss: -0.0206, discriminator training loss: 0.0683, validation loss: 0.0201
2024-05-24 22:57:49 [INFO]: Epoch 084 - generator training loss: -0.0235, discriminator training loss: 0.0665, validation loss: 0.0198
2024-05-24 22:57:58 [INFO]: Epoch 085 - generator training loss: -0.0231, discriminator training loss: 0.0670, validation loss: 0.0192
2024-05-24 22:58:07 [INFO]: Epoch 086 - generator training loss: -0.0207, discriminator training loss: 0.0685, validation loss: 0.0193
2024-05-24 22:58:16 [INFO]: Epoch 087 - generator training loss: -0.0209, discriminator training loss: 0.0657, validation loss: 0.0196
2024-05-24 22:58:25 [INFO]: Epoch 088 - generator training loss: -0.0222, discriminator training loss: 0.0672, validation loss: 0.0195
2024-05-24 22:58:34 [INFO]: Epoch 089 - generator training loss: -0.0227, discriminator training loss: 0.0672, validation loss: 0.0194
2024-05-24 22:58:43 [INFO]: Epoch 090 - generator training loss: -0.0249, discriminator training loss: 0.0661, validation loss: 0.0191
2024-05-24 22:58:52 [INFO]: Epoch 091 - generator training loss: -0.0241, discriminator training loss: 0.0689, validation loss: 0.0196
2024-05-24 22:59:01 [INFO]: Epoch 092 - generator training loss: -0.0214, discriminator training loss: 0.0681, validation loss: 0.0192
2024-05-24 22:59:10 [INFO]: Epoch 093 - generator training loss: -0.0231, discriminator training loss: 0.0665, validation loss: 0.0191
2024-05-24 22:59:19 [INFO]: Epoch 094 - generator training loss: -0.0219, discriminator training loss: 0.0655, validation loss: 0.0193
2024-05-24 22:59:28 [INFO]: Epoch 095 - generator training loss: -0.0233, discriminator training loss: 0.0666, validation loss: 0.0188
2024-05-24 22:59:37 [INFO]: Epoch 096 - generator training loss: -0.0237, discriminator training loss: 0.0670, validation loss: 0.0189
2024-05-24 22:59:46 [INFO]: Epoch 097 - generator training loss: -0.0225, discriminator training loss: 0.0665, validation loss: 0.0187
2024-05-24 22:59:55 [INFO]: Epoch 098 - generator training loss: -0.0253, discriminator training loss: 0.0647, validation loss: 0.0189
2024-05-24 23:00:04 [INFO]: Epoch 099 - generator training loss: -0.0259, discriminator training loss: 0.0665, validation loss: 0.0186
2024-05-24 23:00:13 [INFO]: Epoch 100 - generator training loss: -0.0230, discriminator training loss: 0.0659, validation loss: 0.0191
2024-05-24 23:00:22 [INFO]: Epoch 101 - generator training loss: -0.0240, discriminator training loss: 0.0661, validation loss: 0.0190
2024-05-24 23:00:31 [INFO]: Epoch 102 - generator training loss: -0.0240, discriminator training loss: 0.0682, validation loss: 0.0190
2024-05-24 23:00:40 [INFO]: Epoch 103 - generator training loss: -0.0241, discriminator training loss: 0.0660, validation loss: 0.0190
2024-05-24 23:00:49 [INFO]: Epoch 104 - generator training loss: -0.0255, discriminator training loss: 0.0677, validation loss: 0.0187
2024-05-24 23:00:58 [INFO]: Epoch 105 - generator training loss: -0.0258, discriminator training loss: 0.0674, validation loss: 0.0185
2024-05-24 23:01:07 [INFO]: Epoch 106 - generator training loss: -0.0237, discriminator training loss: 0.0663, validation loss: 0.0191
2024-05-24 23:01:16 [INFO]: Epoch 107 - generator training loss: -0.0239, discriminator training loss: 0.0665, validation loss: 0.0191
2024-05-24 23:01:25 [INFO]: Epoch 108 - generator training loss: -0.0237, discriminator training loss: 0.0668, validation loss: 0.0193
2024-05-24 23:01:34 [INFO]: Epoch 109 - generator training loss: -0.0254, discriminator training loss: 0.0667, validation loss: 0.0187
2024-05-24 23:01:43 [INFO]: Epoch 110 - generator training loss: -0.0251, discriminator training loss: 0.0645, validation loss: 0.0190
2024-05-24 23:01:52 [INFO]: Epoch 111 - generator training loss: -0.0265, discriminator training loss: 0.0657, validation loss: 0.0192
2024-05-24 23:02:01 [INFO]: Epoch 112 - generator training loss: -0.0252, discriminator training loss: 0.0640, validation loss: 0.0192
2024-05-24 23:02:10 [INFO]: Epoch 113 - generator training loss: -0.0249, discriminator training loss: 0.0653, validation loss: 0.0185
2024-05-24 23:02:19 [INFO]: Epoch 114 - generator training loss: -0.0243, discriminator training loss: 0.0678, validation loss: 0.0184
2024-05-24 23:02:28 [INFO]: Epoch 115 - generator training loss: -0.0240, discriminator training loss: 0.0659, validation loss: 0.0189
2024-05-24 23:02:37 [INFO]: Epoch 116 - generator training loss: -0.0263, discriminator training loss: 0.0674, validation loss: 0.0188
2024-05-24 23:02:46 [INFO]: Epoch 117 - generator training loss: -0.0247, discriminator training loss: 0.0656, validation loss: 0.0186
2024-05-24 23:02:55 [INFO]: Epoch 118 - generator training loss: -0.0252, discriminator training loss: 0.0658, validation loss: 0.0189
2024-05-24 23:03:04 [INFO]: Epoch 119 - generator training loss: -0.0246, discriminator training loss: 0.0645, validation loss: 0.0182
2024-05-24 23:03:13 [INFO]: Epoch 120 - generator training loss: -0.0268, discriminator training loss: 0.0646, validation loss: 0.0187
2024-05-24 23:03:22 [INFO]: Epoch 121 - generator training loss: -0.0251, discriminator training loss: 0.0640, validation loss: 0.0184
2024-05-24 23:03:31 [INFO]: Epoch 122 - generator training loss: -0.0251, discriminator training loss: 0.0632, validation loss: 0.0185
2024-05-24 23:03:40 [INFO]: Epoch 123 - generator training loss: -0.0250, discriminator training loss: 0.0653, validation loss: 0.0183
2024-05-24 23:03:49 [INFO]: Epoch 124 - generator training loss: -0.0247, discriminator training loss: 0.0658, validation loss: 0.0187
2024-05-24 23:03:58 [INFO]: Epoch 125 - generator training loss: -0.0248, discriminator training loss: 0.0650, validation loss: 0.0185
2024-05-24 23:04:07 [INFO]: Epoch 126 - generator training loss: -0.0254, discriminator training loss: 0.0642, validation loss: 0.0187
2024-05-24 23:04:16 [INFO]: Epoch 127 - generator training loss: -0.0270, discriminator training loss: 0.0653, validation loss: 0.0194
2024-05-24 23:04:25 [INFO]: Epoch 128 - generator training loss: -0.0234, discriminator training loss: 0.0649, validation loss: 0.0195
2024-05-24 23:04:34 [INFO]: Epoch 129 - generator training loss: -0.0257, discriminator training loss: 0.0663, validation loss: 0.0185
2024-05-24 23:04:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:04:34 [INFO]: Finished training. The best model is from epoch#119.
2024-05-24 23:04:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/USGAN_ettm1/20240524_T224517/USGAN.pypots
2024-05-24 23:04:35 [INFO]: US-GAN on ETTm1: MAE=0.1323, MSE=0.0442
2024-05-24 23:04:35 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/USGAN_ettm1/imputation.pkl
2024-05-24 23:04:35 [INFO]: Using the given device: cuda:0
2024-05-24 23:04:35 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/BRITS_ettm1/20240524_T230435
2024-05-24 23:04:35 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/BRITS_ettm1/20240524_T230435/tensorboard
2024-05-24 23:04:35 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 23:04:42 [INFO]: Epoch 001 - training loss: 1.3212, validation loss: 0.2774
2024-05-24 23:04:48 [INFO]: Epoch 002 - training loss: 0.8338, validation loss: 0.0845
2024-05-24 23:04:54 [INFO]: Epoch 003 - training loss: 0.6726, validation loss: 0.0512
2024-05-24 23:05:00 [INFO]: Epoch 004 - training loss: 0.6205, validation loss: 0.0413
2024-05-24 23:05:06 [INFO]: Epoch 005 - training loss: 0.5626, validation loss: 0.0372
2024-05-24 23:05:12 [INFO]: Epoch 006 - training loss: 0.5509, validation loss: 0.0352
2024-05-24 23:05:18 [INFO]: Epoch 007 - training loss: 0.5203, validation loss: 0.0341
2024-05-24 23:05:24 [INFO]: Epoch 008 - training loss: 0.4946, validation loss: 0.0318
2024-05-24 23:05:30 [INFO]: Epoch 009 - training loss: 0.4660, validation loss: 0.0297
2024-05-24 23:05:36 [INFO]: Epoch 010 - training loss: 0.4518, validation loss: 0.0287
2024-05-24 23:05:42 [INFO]: Epoch 011 - training loss: 0.4263, validation loss: 0.0261
2024-05-24 23:05:48 [INFO]: Epoch 012 - training loss: 0.4123, validation loss: 0.0248
2024-05-24 23:05:54 [INFO]: Epoch 013 - training loss: 0.4048, validation loss: 0.0236
2024-05-24 23:06:00 [INFO]: Epoch 014 - training loss: 0.4030, validation loss: 0.0236
2024-05-24 23:06:06 [INFO]: Epoch 015 - training loss: 0.3997, validation loss: 0.0230
2024-05-24 23:06:12 [INFO]: Epoch 016 - training loss: 0.3901, validation loss: 0.0231
2024-05-24 23:06:18 [INFO]: Epoch 017 - training loss: 0.3843, validation loss: 0.0227
2024-05-24 23:06:24 [INFO]: Epoch 018 - training loss: 0.3873, validation loss: 0.0227
2024-05-24 23:06:29 [INFO]: Epoch 019 - training loss: 0.3901, validation loss: 0.0227
2024-05-24 23:06:35 [INFO]: Epoch 020 - training loss: 0.3859, validation loss: 0.0229
2024-05-24 23:06:41 [INFO]: Epoch 021 - training loss: 0.3840, validation loss: 0.0226
2024-05-24 23:06:47 [INFO]: Epoch 022 - training loss: 0.3814, validation loss: 0.0221
2024-05-24 23:06:53 [INFO]: Epoch 023 - training loss: 0.3826, validation loss: 0.0225
2024-05-24 23:06:59 [INFO]: Epoch 024 - training loss: 0.3798, validation loss: 0.0222
2024-05-24 23:07:05 [INFO]: Epoch 025 - training loss: 0.3892, validation loss: 0.0228
2024-05-24 23:07:11 [INFO]: Epoch 026 - training loss: 0.3948, validation loss: 0.0226
2024-05-24 23:07:17 [INFO]: Epoch 027 - training loss: 0.3786, validation loss: 0.0224
2024-05-24 23:07:23 [INFO]: Epoch 028 - training loss: 0.3796, validation loss: 0.0217
2024-05-24 23:07:29 [INFO]: Epoch 029 - training loss: 0.3862, validation loss: 0.0226
2024-05-24 23:07:35 [INFO]: Epoch 030 - training loss: 0.3809, validation loss: 0.0222
2024-05-24 23:07:41 [INFO]: Epoch 031 - training loss: 0.3796, validation loss: 0.0222
2024-05-24 23:07:47 [INFO]: Epoch 032 - training loss: 0.3812, validation loss: 0.0224
2024-05-24 23:07:53 [INFO]: Epoch 033 - training loss: 0.3749, validation loss: 0.0222
2024-05-24 23:07:59 [INFO]: Epoch 034 - training loss: 0.3784, validation loss: 0.0225
2024-05-24 23:08:05 [INFO]: Epoch 035 - training loss: 0.3764, validation loss: 0.0221
2024-05-24 23:08:10 [INFO]: Epoch 036 - training loss: 0.3714, validation loss: 0.0222
2024-05-24 23:08:16 [INFO]: Epoch 037 - training loss: 0.3701, validation loss: 0.0219
2024-05-24 23:08:22 [INFO]: Epoch 038 - training loss: 0.3806, validation loss: 0.0224
2024-05-24 23:08:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:08:22 [INFO]: Finished training. The best model is from epoch#28.
2024-05-24 23:08:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/BRITS_ettm1/20240524_T230435/BRITS.pypots
2024-05-24 23:08:23 [INFO]: BRITS on ETTm1: MAE=0.1233, MSE=0.0444
2024-05-24 23:08:23 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/BRITS_ettm1/imputation.pkl
2024-05-24 23:08:23 [INFO]: Using the given device: cuda:0
2024-05-24 23:08:23 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823
2024-05-24 23:08:23 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/tensorboard
2024-05-24 23:08:23 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 23:08:25 [INFO]: Epoch 001 - training loss: 1.3785, validation loss: 1.3448
2024-05-24 23:08:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch1_loss1.344754844903946.pypots
2024-05-24 23:08:25 [INFO]: Epoch 002 - training loss: 1.0885, validation loss: 1.1989
2024-05-24 23:08:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch2_loss1.1989084482192993.pypots
2024-05-24 23:08:26 [INFO]: Epoch 003 - training loss: 1.0128, validation loss: 1.1154
2024-05-24 23:08:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch3_loss1.1153545081615448.pypots
2024-05-24 23:08:26 [INFO]: Epoch 004 - training loss: 0.9849, validation loss: 1.0734
2024-05-24 23:08:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch4_loss1.0734364837408066.pypots
2024-05-24 23:08:26 [INFO]: Epoch 005 - training loss: 0.9943, validation loss: 1.0583
2024-05-24 23:08:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch5_loss1.058251217007637.pypots
2024-05-24 23:08:26 [INFO]: Epoch 006 - training loss: 0.9576, validation loss: 1.0403
2024-05-24 23:08:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch6_loss1.0403482466936111.pypots
2024-05-24 23:08:26 [INFO]: Epoch 007 - training loss: 0.9543, validation loss: 1.0322
2024-05-24 23:08:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch7_loss1.0321550965309143.pypots
2024-05-24 23:08:27 [INFO]: Epoch 008 - training loss: 0.9412, validation loss: 1.0249
2024-05-24 23:08:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch8_loss1.0249255150556564.pypots
2024-05-24 23:08:27 [INFO]: Epoch 009 - training loss: 0.9339, validation loss: 1.0183
2024-05-24 23:08:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch9_loss1.0182661563158035.pypots
2024-05-24 23:08:27 [INFO]: Epoch 010 - training loss: 0.9223, validation loss: 1.0097
2024-05-24 23:08:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch10_loss1.0096594095230103.pypots
2024-05-24 23:08:27 [INFO]: Epoch 011 - training loss: 0.8892, validation loss: 1.0028
2024-05-24 23:08:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch11_loss1.0027647763490677.pypots
2024-05-24 23:08:27 [INFO]: Epoch 012 - training loss: 0.9043, validation loss: 1.0012
2024-05-24 23:08:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch12_loss1.0012257397174835.pypots
2024-05-24 23:08:28 [INFO]: Epoch 013 - training loss: 0.8909, validation loss: 0.9964
2024-05-24 23:08:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch13_loss0.9963915795087814.pypots
2024-05-24 23:08:28 [INFO]: Epoch 014 - training loss: 0.8962, validation loss: 0.9914
2024-05-24 23:08:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch14_loss0.9913622736930847.pypots
2024-05-24 23:08:28 [INFO]: Epoch 015 - training loss: 0.8912, validation loss: 0.9866
2024-05-24 23:08:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch15_loss0.9866384714841843.pypots
2024-05-24 23:08:28 [INFO]: Epoch 016 - training loss: 0.8887, validation loss: 0.9837
2024-05-24 23:08:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch16_loss0.9836951941251755.pypots
2024-05-24 23:08:28 [INFO]: Epoch 017 - training loss: 0.8667, validation loss: 0.9792
2024-05-24 23:08:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch17_loss0.9792391806840897.pypots
2024-05-24 23:08:29 [INFO]: Epoch 018 - training loss: 0.8823, validation loss: 0.9799
2024-05-24 23:08:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch18_loss0.9799129664897919.pypots
2024-05-24 23:08:29 [INFO]: Epoch 019 - training loss: 0.9240, validation loss: 0.9766
2024-05-24 23:08:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch19_loss0.9766286611557007.pypots
2024-05-24 23:08:29 [INFO]: Epoch 020 - training loss: 0.8749, validation loss: 0.9736
2024-05-24 23:08:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch20_loss0.973629504442215.pypots
2024-05-24 23:08:29 [INFO]: Epoch 021 - training loss: 0.8580, validation loss: 0.9708
2024-05-24 23:08:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch21_loss0.9707574099302292.pypots
2024-05-24 23:08:29 [INFO]: Epoch 022 - training loss: 0.8562, validation loss: 0.9685
2024-05-24 23:08:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch22_loss0.968510240316391.pypots
2024-05-24 23:08:30 [INFO]: Epoch 023 - training loss: 0.8696, validation loss: 0.9657
2024-05-24 23:08:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch23_loss0.9657028764486313.pypots
2024-05-24 23:08:30 [INFO]: Epoch 024 - training loss: 0.8676, validation loss: 0.9649
2024-05-24 23:08:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch24_loss0.9648969173431396.pypots
2024-05-24 23:08:30 [INFO]: Epoch 025 - training loss: 0.8890, validation loss: 0.9629
2024-05-24 23:08:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch25_loss0.9628729224205017.pypots
2024-05-24 23:08:30 [INFO]: Epoch 026 - training loss: 0.8494, validation loss: 0.9618
2024-05-24 23:08:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch26_loss0.9617677927017212.pypots
2024-05-24 23:08:30 [INFO]: Epoch 027 - training loss: 0.8375, validation loss: 0.9616
2024-05-24 23:08:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch27_loss0.9616430103778839.pypots
2024-05-24 23:08:31 [INFO]: Epoch 028 - training loss: 0.8494, validation loss: 0.9595
2024-05-24 23:08:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch28_loss0.9595276117324829.pypots
2024-05-24 23:08:31 [INFO]: Epoch 029 - training loss: 0.8711, validation loss: 0.9574
2024-05-24 23:08:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch29_loss0.9573811888694763.pypots
2024-05-24 23:08:31 [INFO]: Epoch 030 - training loss: 0.8346, validation loss: 0.9539
2024-05-24 23:08:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch30_loss0.9539229720830917.pypots
2024-05-24 23:08:31 [INFO]: Epoch 031 - training loss: 0.8285, validation loss: 0.9528
2024-05-24 23:08:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch31_loss0.9527958631515503.pypots
2024-05-24 23:08:31 [INFO]: Epoch 032 - training loss: 0.8233, validation loss: 0.9500
2024-05-24 23:08:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch32_loss0.950018510222435.pypots
2024-05-24 23:08:31 [INFO]: Epoch 033 - training loss: 0.8056, validation loss: 0.9470
2024-05-24 23:08:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch33_loss0.947010338306427.pypots
2024-05-24 23:08:32 [INFO]: Epoch 034 - training loss: 0.8402, validation loss: 0.9452
2024-05-24 23:08:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch34_loss0.945184201002121.pypots
2024-05-24 23:08:32 [INFO]: Epoch 035 - training loss: 0.8423, validation loss: 0.9462
2024-05-24 23:08:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch35_loss0.9461845606565475.pypots
2024-05-24 23:08:32 [INFO]: Epoch 036 - training loss: 0.8274, validation loss: 0.9419
2024-05-24 23:08:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch36_loss0.9419335871934891.pypots
2024-05-24 23:08:32 [INFO]: Epoch 037 - training loss: 0.8443, validation loss: 0.9401
2024-05-24 23:08:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch37_loss0.940099686384201.pypots
2024-05-24 23:08:32 [INFO]: Epoch 038 - training loss: 0.8316, validation loss: 0.9340
2024-05-24 23:08:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch38_loss0.9340124428272247.pypots
2024-05-24 23:08:33 [INFO]: Epoch 039 - training loss: 0.8093, validation loss: 0.9336
2024-05-24 23:08:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch39_loss0.9335554093122482.pypots
2024-05-24 23:08:33 [INFO]: Epoch 040 - training loss: 0.8265, validation loss: 0.9312
2024-05-24 23:08:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch40_loss0.9311901330947876.pypots
2024-05-24 23:08:33 [INFO]: Epoch 041 - training loss: 0.8665, validation loss: 0.9278
2024-05-24 23:08:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch41_loss0.9277855753898621.pypots
2024-05-24 23:08:33 [INFO]: Epoch 042 - training loss: 0.8256, validation loss: 0.9255
2024-05-24 23:08:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch42_loss0.9254806637763977.pypots
2024-05-24 23:08:33 [INFO]: Epoch 043 - training loss: 0.8171, validation loss: 0.9217
2024-05-24 23:08:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch43_loss0.9216817766427994.pypots
2024-05-24 23:08:34 [INFO]: Epoch 044 - training loss: 0.8157, validation loss: 0.9187
2024-05-24 23:08:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch44_loss0.9187008291482925.pypots
2024-05-24 23:08:34 [INFO]: Epoch 045 - training loss: 0.8087, validation loss: 0.9151
2024-05-24 23:08:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch45_loss0.9150901138782501.pypots
2024-05-24 23:08:34 [INFO]: Epoch 046 - training loss: 0.8223, validation loss: 0.9118
2024-05-24 23:08:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch46_loss0.9118118286132812.pypots
2024-05-24 23:08:34 [INFO]: Epoch 047 - training loss: 0.8180, validation loss: 0.9095
2024-05-24 23:08:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch47_loss0.909491091966629.pypots
2024-05-24 23:08:34 [INFO]: Epoch 048 - training loss: 0.8064, validation loss: 0.9063
2024-05-24 23:08:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch48_loss0.9062733203172684.pypots
2024-05-24 23:08:35 [INFO]: Epoch 049 - training loss: 0.8120, validation loss: 0.9037
2024-05-24 23:08:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch49_loss0.9036525636911392.pypots
2024-05-24 23:08:35 [INFO]: Epoch 050 - training loss: 0.8233, validation loss: 0.9002
2024-05-24 23:08:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch50_loss0.9001797735691071.pypots
2024-05-24 23:08:35 [INFO]: Epoch 051 - training loss: 0.8267, validation loss: 0.8969
2024-05-24 23:08:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch51_loss0.8968688398599625.pypots
2024-05-24 23:08:35 [INFO]: Epoch 052 - training loss: 0.8322, validation loss: 0.8938
2024-05-24 23:08:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch52_loss0.8938364088535309.pypots
2024-05-24 23:08:35 [INFO]: Epoch 053 - training loss: 0.8092, validation loss: 0.8940
2024-05-24 23:08:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch53_loss0.8940066397190094.pypots
2024-05-24 23:08:36 [INFO]: Epoch 054 - training loss: 0.7918, validation loss: 0.8916
2024-05-24 23:08:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch54_loss0.8915620893239975.pypots
2024-05-24 23:08:36 [INFO]: Epoch 055 - training loss: 0.8148, validation loss: 0.8878
2024-05-24 23:08:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch55_loss0.8878462612628937.pypots
2024-05-24 23:08:36 [INFO]: Epoch 056 - training loss: 0.8050, validation loss: 0.8856
2024-05-24 23:08:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch56_loss0.8856087625026703.pypots
2024-05-24 23:08:36 [INFO]: Epoch 057 - training loss: 0.8027, validation loss: 0.8845
2024-05-24 23:08:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch57_loss0.8844836354255676.pypots
2024-05-24 23:08:36 [INFO]: Epoch 058 - training loss: 0.7919, validation loss: 0.8834
2024-05-24 23:08:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch58_loss0.883430078625679.pypots
2024-05-24 23:08:37 [INFO]: Epoch 059 - training loss: 0.8016, validation loss: 0.8810
2024-05-24 23:08:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch59_loss0.881035640835762.pypots
2024-05-24 23:08:37 [INFO]: Epoch 060 - training loss: 0.7847, validation loss: 0.8793
2024-05-24 23:08:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch60_loss0.8792744278907776.pypots
2024-05-24 23:08:37 [INFO]: Epoch 061 - training loss: 0.7961, validation loss: 0.8772
2024-05-24 23:08:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch61_loss0.8771521300077438.pypots
2024-05-24 23:08:37 [INFO]: Epoch 062 - training loss: 0.8054, validation loss: 0.8757
2024-05-24 23:08:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch62_loss0.8756731897592545.pypots
2024-05-24 23:08:37 [INFO]: Epoch 063 - training loss: 0.8005, validation loss: 0.8781
2024-05-24 23:08:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch63_loss0.8781073093414307.pypots
2024-05-24 23:08:38 [INFO]: Epoch 064 - training loss: 0.8147, validation loss: 0.8763
2024-05-24 23:08:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch64_loss0.8763389438390732.pypots
2024-05-24 23:08:38 [INFO]: Epoch 065 - training loss: 0.7841, validation loss: 0.8737
2024-05-24 23:08:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch65_loss0.87374547123909.pypots
2024-05-24 23:08:38 [INFO]: Epoch 066 - training loss: 0.7959, validation loss: 0.8745
2024-05-24 23:08:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch66_loss0.8745406568050385.pypots
2024-05-24 23:08:38 [INFO]: Epoch 067 - training loss: 0.8068, validation loss: 0.8736
2024-05-24 23:08:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch67_loss0.8736314177513123.pypots
2024-05-24 23:08:38 [INFO]: Epoch 068 - training loss: 0.8142, validation loss: 0.8722
2024-05-24 23:08:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch68_loss0.8721513152122498.pypots
2024-05-24 23:08:38 [INFO]: Epoch 069 - training loss: 0.7714, validation loss: 0.8709
2024-05-24 23:08:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch69_loss0.8709109872579575.pypots
2024-05-24 23:08:39 [INFO]: Epoch 070 - training loss: 0.7786, validation loss: 0.8703
2024-05-24 23:08:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch70_loss0.8703370839357376.pypots
2024-05-24 23:08:39 [INFO]: Epoch 071 - training loss: 0.7891, validation loss: 0.8696
2024-05-24 23:08:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch71_loss0.8695849180221558.pypots
2024-05-24 23:08:39 [INFO]: Epoch 072 - training loss: 0.7959, validation loss: 0.8682
2024-05-24 23:08:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch72_loss0.8682359457015991.pypots
2024-05-24 23:08:39 [INFO]: Epoch 073 - training loss: 0.7962, validation loss: 0.8691
2024-05-24 23:08:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch73_loss0.86910480260849.pypots
2024-05-24 23:08:39 [INFO]: Epoch 074 - training loss: 0.7875, validation loss: 0.8691
2024-05-24 23:08:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch74_loss0.869120717048645.pypots
2024-05-24 23:08:40 [INFO]: Epoch 075 - training loss: 0.7983, validation loss: 0.8670
2024-05-24 23:08:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch75_loss0.8670420944690704.pypots
2024-05-24 23:08:40 [INFO]: Epoch 076 - training loss: 0.8018, validation loss: 0.8692
2024-05-24 23:08:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch76_loss0.8691625595092773.pypots
2024-05-24 23:08:40 [INFO]: Epoch 077 - training loss: 0.7935, validation loss: 0.8674
2024-05-24 23:08:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch77_loss0.8674112856388092.pypots
2024-05-24 23:08:40 [INFO]: Epoch 078 - training loss: 0.7953, validation loss: 0.8674
2024-05-24 23:08:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch78_loss0.8673512488603592.pypots
2024-05-24 23:08:40 [INFO]: Epoch 079 - training loss: 0.7727, validation loss: 0.8681
2024-05-24 23:08:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch79_loss0.8680908381938934.pypots
2024-05-24 23:08:41 [INFO]: Epoch 080 - training loss: 0.7769, validation loss: 0.8687
2024-05-24 23:08:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch80_loss0.8687189072370529.pypots
2024-05-24 23:08:41 [INFO]: Epoch 081 - training loss: 0.7772, validation loss: 0.8675
2024-05-24 23:08:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch81_loss0.8674574047327042.pypots
2024-05-24 23:08:41 [INFO]: Epoch 082 - training loss: 0.7812, validation loss: 0.8650
2024-05-24 23:08:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch82_loss0.8649543970823288.pypots
2024-05-24 23:08:41 [INFO]: Epoch 083 - training loss: 0.7841, validation loss: 0.8659
2024-05-24 23:08:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch83_loss0.8659401386976242.pypots
2024-05-24 23:08:41 [INFO]: Epoch 084 - training loss: 0.7764, validation loss: 0.8666
2024-05-24 23:08:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch84_loss0.8665805459022522.pypots
2024-05-24 23:08:42 [INFO]: Epoch 085 - training loss: 0.7800, validation loss: 0.8641
2024-05-24 23:08:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch85_loss0.8640850782394409.pypots
2024-05-24 23:08:42 [INFO]: Epoch 086 - training loss: 0.7931, validation loss: 0.8651
2024-05-24 23:08:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch86_loss0.8650973439216614.pypots
2024-05-24 23:08:42 [INFO]: Epoch 087 - training loss: 0.7891, validation loss: 0.8638
2024-05-24 23:08:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch87_loss0.8637571930885315.pypots
2024-05-24 23:08:42 [INFO]: Epoch 088 - training loss: 0.7909, validation loss: 0.8640
2024-05-24 23:08:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch88_loss0.8639665693044662.pypots
2024-05-24 23:08:42 [INFO]: Epoch 089 - training loss: 0.7932, validation loss: 0.8663
2024-05-24 23:08:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch89_loss0.8663298487663269.pypots
2024-05-24 23:08:43 [INFO]: Epoch 090 - training loss: 0.7950, validation loss: 0.8646
2024-05-24 23:08:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch90_loss0.8646166920661926.pypots
2024-05-24 23:08:43 [INFO]: Epoch 091 - training loss: 0.8063, validation loss: 0.8668
2024-05-24 23:08:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch91_loss0.8668123036623001.pypots
2024-05-24 23:08:43 [INFO]: Epoch 092 - training loss: 0.7889, validation loss: 0.8657
2024-05-24 23:08:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch92_loss0.8657305687665939.pypots
2024-05-24 23:08:43 [INFO]: Epoch 093 - training loss: 0.7829, validation loss: 0.8648
2024-05-24 23:08:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch93_loss0.8648209869861603.pypots
2024-05-24 23:08:43 [INFO]: Epoch 094 - training loss: 0.7656, validation loss: 0.8644
2024-05-24 23:08:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch94_loss0.8643503338098526.pypots
2024-05-24 23:08:44 [INFO]: Epoch 095 - training loss: 0.7718, validation loss: 0.8668
2024-05-24 23:08:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch95_loss0.8667867183685303.pypots
2024-05-24 23:08:44 [INFO]: Epoch 096 - training loss: 0.7917, validation loss: 0.8693
2024-05-24 23:08:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch96_loss0.8693008720874786.pypots
2024-05-24 23:08:44 [INFO]: Epoch 097 - training loss: 0.7880, validation loss: 0.8670
2024-05-24 23:08:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN_epoch97_loss0.8670338094234467.pypots
2024-05-24 23:08:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:08:44 [INFO]: Finished training. The best model is from epoch#87.
2024-05-24 23:08:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T230823/MRNN.pypots
2024-05-24 23:08:44 [INFO]: MRNN on ETTm1: MAE=0.6824, MSE=1.1721
2024-05-24 23:08:44 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/MRNN_ettm1/imputation.pkl
2024-05-24 23:08:44 [INFO]: Using the given device: cpu
2024-05-24 23:08:44 [INFO]: LOCF on ETTm1: MAE=0.1348, MSE=0.0715
2024-05-24 23:08:44 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_ettm1".
2024-05-24 23:08:44 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/LOCF_ettm1/imputation.pkl
2024-05-24 23:08:44 [INFO]: Median on ETTm1: MAE=0.6516, MSE=0.8223
2024-05-24 23:08:44 [INFO]: Successfully created the given path "saved_results/round_4/Median_ettm1".
2024-05-24 23:08:44 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Median_ettm1/imputation.pkl
2024-05-24 23:08:44 [INFO]: Mean on ETTm1: MAE=0.6566, MSE=0.8036
2024-05-24 23:08:44 [INFO]: Successfully created the given path "saved_results/round_4/Mean_ettm1".
2024-05-24 23:08:44 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Mean_ettm1/imputation.pkl
2024-05-24 23:08:44 [INFO]: 
SAITS on data/ettm1: MAE=0.1700.01958835341425004, MSE=0.0590.012714394862065648
Transformer on data/ettm1: MAE=0.1360.0026698219366891197, MSE=0.0380.0013495326817965826
TimesNet on data/ettm1: MAE=0.1060.002155620020867463, MSE=0.0240.0009585673866707653
CSDI on data/ettm1: MAE=0.1580.009973401847793639, MSE=0.0610.00492836302606061
GPVAE on data/ettm1: MAE=0.2740.009365356225402119, MSE=0.1560.0071896412697053935
USGAN on data/ettm1: MAE=0.1390.007675255870565083, MSE=0.0500.0044920567239174385
BRITS on data/ettm1: MAE=0.1290.005531603156810575, MSE=0.0510.004974994913152976
MRNN on data/ettm1: MAE=0.6270.028471480313108075, MSE=1.0450.06514869483890871
LOCF on data/ettm1: MAE=0.1350.0, MSE=0.0710.0
Median on data/ettm1: MAE=0.6520.0, MSE=0.8220.0
Mean on data/ettm1: MAE=0.6570.0, MSE=0.8040.0